{
    "2012-08-31T15:17:05-07:00": {
        "576c709724551a5122ae9b9e314b6c400f5f778d": {
            "datetime": "2012-08-31T15:17:05-07:00",
            "summary": "Initial commit",
            "message": "Initial commit\n",
            "diff": {
                "dev/merge_parquet_pr.py": 393,
                "parquet-arrow/src/main/java/org/apache/parquet/arrow/schema/List3Levels.java": 77,
                "parquet-arrow/src/main/java/org/apache/parquet/arrow/schema/SchemaConverter.java": 705,
                "parquet-arrow/src/main/java/org/apache/parquet/arrow/schema/SchemaMapping.java": 201,
                "parquet-arrow/src/test/java/org/apache/parquet/arrow/schema/TestSchemaConverter.java": 530,
                "parquet-avro/src/main/java/org/apache/parquet/avro/AvroCompatRecordMaterializer.java": 46,
                "parquet-avro/src/main/java/org/apache/parquet/avro/AvroConverters.java": 333,
                "parquet-avro/src/main/java/org/apache/parquet/avro/AvroDataSupplier.java": 31,
                "parquet-avro/src/main/java/org/apache/parquet/avro/AvroIndexedRecordConverter.java": 535,
                "parquet-avro/src/main/java/org/apache/parquet/avro/AvroParquetInputFormat.java": 86,
                "parquet-avro/src/main/java/org/apache/parquet/avro/AvroParquetOutputFormat.java": 63,
                "parquet-avro/src/main/java/org/apache/parquet/avro/AvroParquetReader.java": 178,
                "parquet-avro/src/main/java/org/apache/parquet/avro/AvroParquetWriter.java": 193,
                "parquet-avro/src/main/java/org/apache/parquet/avro/AvroReadSupport.java": 180,
                "parquet-avro/src/main/java/org/apache/parquet/avro/AvroRecordConverter.java": 1093,
                "parquet-avro/src/main/java/org/apache/parquet/avro/AvroRecordMaterializer.java": 45,
                "parquet-avro/src/main/java/org/apache/parquet/avro/AvroSchemaConverter.java": 565,
                "parquet-avro/src/main/java/org/apache/parquet/avro/AvroWriteSupport.java": 711,
                "parquet-avro/src/main/java/org/apache/parquet/avro/GenericDataSupplier.java": 28,
                "parquet-avro/src/main/java/org/apache/parquet/avro/ParentValueContainer.java": 238,
                "parquet-avro/src/main/java/org/apache/parquet/avro/ReflectDataSupplier.java": 29,
                "parquet-avro/src/main/java/org/apache/parquet/avro/SpecificDataSupplier.java": 29,
                "parquet-avro/src/main/java/org/apache/parquet/avro/package-info.java": 174,
                "parquet-avro/src/test/java/org/apache/parquet/avro/AvroTestUtil.java": 136,
                "parquet-avro/src/test/java/org/apache/parquet/avro/TestArrayCompatibility.java": 1164,
                "parquet-avro/src/test/java/org/apache/parquet/avro/TestAvroDataSupplier.java": 43,
                "parquet-avro/src/test/java/org/apache/parquet/avro/TestAvroRecordConverter.java": 202,
                "parquet-avro/src/test/java/org/apache/parquet/avro/TestAvroSchemaConverter.java": 942,
                "parquet-avro/src/test/java/org/apache/parquet/avro/TestAvroWriteSupport.java": 61,
                "parquet-avro/src/test/java/org/apache/parquet/avro/TestBackwardCompatibility.java": 68,
                "parquet-avro/src/test/java/org/apache/parquet/avro/TestByteStreamSplitE2E.java": 114,
                "parquet-avro/src/test/java/org/apache/parquet/avro/TestCircularReferences.java": 387,
                "parquet-avro/src/test/java/org/apache/parquet/avro/TestGenericLogicalTypes.java": 296,
                "parquet-avro/src/test/java/org/apache/parquet/avro/TestInputOutputFormat.java": 145,
                "parquet-avro/src/test/java/org/apache/parquet/avro/TestReadWrite.java": 900,
                "parquet-avro/src/test/java/org/apache/parquet/avro/TestReadWriteOldListBehavior.java": 584,
                "parquet-avro/src/test/java/org/apache/parquet/avro/TestReflectInputOutputFormat.java": 496,
                "parquet-avro/src/test/java/org/apache/parquet/avro/TestReflectLogicalTypes.java": 999,
                "parquet-avro/src/test/java/org/apache/parquet/avro/TestReflectReadWrite.java": 240,
                "parquet-avro/src/test/java/org/apache/parquet/avro/TestSpecificInputOutputFormat.java": 287,
                "parquet-avro/src/test/java/org/apache/parquet/avro/TestSpecificReadWrite.java": 360,
                "parquet-avro/src/test/java/org/apache/parquet/avro/TestStringBehavior.java": 330,
                "parquet-benchmarks/src/main/java/org/apache/parquet/benchmarks/BenchmarkConstants.java": 42,
                "parquet-benchmarks/src/main/java/org/apache/parquet/benchmarks/BenchmarkFiles.java": 64,
                "parquet-benchmarks/src/main/java/org/apache/parquet/benchmarks/BenchmarkUtils.java": 46,
                "parquet-benchmarks/src/main/java/org/apache/parquet/benchmarks/DataGenerator.java": 137,
                "parquet-benchmarks/src/main/java/org/apache/parquet/benchmarks/FilteringBenchmarks.java": 430,
                "parquet-benchmarks/src/main/java/org/apache/parquet/benchmarks/NestedNullWritingBenchmarks.java": 156,
                "parquet-benchmarks/src/main/java/org/apache/parquet/benchmarks/PageChecksumDataGenerator.java": 106,
                "parquet-benchmarks/src/main/java/org/apache/parquet/benchmarks/PageChecksumReadBenchmarks.java": 196,
                "parquet-benchmarks/src/main/java/org/apache/parquet/benchmarks/PageChecksumWriteBenchmarks.java": 178,
                "parquet-benchmarks/src/main/java/org/apache/parquet/benchmarks/ReadBenchmarks.java": 131,
                "parquet-benchmarks/src/main/java/org/apache/parquet/benchmarks/WriteBenchmarks.java": 168,
                "parquet-cli/src/main/java/org/apache/parquet/cli/BaseCommand.java": 428,
                "parquet-cli/src/main/java/org/apache/parquet/cli/Command.java": 40,
                "parquet-cli/src/main/java/org/apache/parquet/cli/HadoopFileSystemURLStreamHandler.java": 79,
                "parquet-cli/src/main/java/org/apache/parquet/cli/Help.java": 153,
                "parquet-cli/src/main/java/org/apache/parquet/cli/Main.java": 196,
                "parquet-cli/src/main/java/org/apache/parquet/cli/Util.java": 272,
                "parquet-cli/src/main/java/org/apache/parquet/cli/commands/CSVSchemaCommand.java": 131,
                "parquet-cli/src/main/java/org/apache/parquet/cli/commands/CatCommand.java": 106,
                "parquet-cli/src/main/java/org/apache/parquet/cli/commands/CheckParquet251Command.java": 352,
                "parquet-cli/src/main/java/org/apache/parquet/cli/commands/ColumnMaskingCommand.java": 115,
                "parquet-cli/src/main/java/org/apache/parquet/cli/commands/ColumnSizeCommand.java": 137,
                "parquet-cli/src/main/java/org/apache/parquet/cli/commands/ConvertCSVCommand.java": 204,
                "parquet-cli/src/main/java/org/apache/parquet/cli/commands/ConvertCommand.java": 165,
                "parquet-cli/src/main/java/org/apache/parquet/cli/commands/ParquetMetadataCommand.java": 183,
                "parquet-cli/src/main/java/org/apache/parquet/cli/commands/PruneColumnsCommand.java": 82,
                "parquet-cli/src/main/java/org/apache/parquet/cli/commands/RewriteCommand.java": 131,
                "parquet-cli/src/main/java/org/apache/parquet/cli/commands/ScanCommand.java": 91,
                "parquet-cli/src/main/java/org/apache/parquet/cli/commands/SchemaCommand.java": 132,
                "parquet-cli/src/main/java/org/apache/parquet/cli/commands/ShowBloomFilterCommand.java": 133,
                "parquet-cli/src/main/java/org/apache/parquet/cli/commands/ShowColumnIndexCommand.java": 157,
                "parquet-cli/src/main/java/org/apache/parquet/cli/commands/ShowDictionaryCommand.java": 139,
                "parquet-cli/src/main/java/org/apache/parquet/cli/commands/ShowFooterCommand.java": 101,
                "parquet-cli/src/main/java/org/apache/parquet/cli/commands/ShowPagesCommand.java": 234,
                "parquet-cli/src/main/java/org/apache/parquet/cli/commands/ToAvroCommand.java": 134,
                "parquet-cli/src/main/java/org/apache/parquet/cli/commands/TransCompressionCommand.java": 101,
                "parquet-cli/src/main/java/org/apache/parquet/cli/csv/AvroCSV.java": 258,
                "parquet-cli/src/main/java/org/apache/parquet/cli/csv/AvroCSVReader.java": 121,
                "parquet-cli/src/main/java/org/apache/parquet/cli/csv/CSVProperties.java": 120,
                "parquet-cli/src/main/java/org/apache/parquet/cli/csv/RecordBuilder.java": 200,
                "parquet-cli/src/main/java/org/apache/parquet/cli/json/AvroJson.java": 631,
                "parquet-cli/src/main/java/org/apache/parquet/cli/json/AvroJsonReader.java": 77,
                "parquet-cli/src/main/java/org/apache/parquet/cli/rawpages/RawPagesReader.java": 92,
                "parquet-cli/src/main/java/org/apache/parquet/cli/util/Codecs.java": 52,
                "parquet-cli/src/main/java/org/apache/parquet/cli/util/Expressions.java": 395,
                "parquet-cli/src/main/java/org/apache/parquet/cli/util/Formats.java": 47,
                "parquet-cli/src/main/java/org/apache/parquet/cli/util/GetClassLoader.java": 39,
                "parquet-cli/src/main/java/org/apache/parquet/cli/util/RawUtils.java": 85,
                "parquet-cli/src/main/java/org/apache/parquet/cli/util/RecordException.java": 55,
                "parquet-cli/src/main/java/org/apache/parquet/cli/util/RuntimeIOException.java": 31,
                "parquet-cli/src/main/java/org/apache/parquet/cli/util/Schemas.java": 501,
                "parquet-cli/src/main/java/org/apache/parquet/cli/util/SeekableFSDataInputStream.java": 76,
                "parquet-cli/src/test/java/org/apache/parquet/cli/BaseCommandTest.java": 100,
                "parquet-cli/src/test/java/org/apache/parquet/cli/MainTest.java": 34,
                "parquet-cli/src/test/java/org/apache/parquet/cli/commands/AvroFileTest.java": 53,
                "parquet-cli/src/test/java/org/apache/parquet/cli/commands/CSVFileTest.java": 51,
                "parquet-cli/src/test/java/org/apache/parquet/cli/commands/CSVSchemaCommandTest.java": 39,
                "parquet-cli/src/test/java/org/apache/parquet/cli/commands/CatCommandTest.java": 38,
                "parquet-cli/src/test/java/org/apache/parquet/cli/commands/CheckParquet251CommandTest.java": 38,
                "parquet-cli/src/test/java/org/apache/parquet/cli/commands/ColumnSizeCommandTest.java": 91,
                "parquet-cli/src/test/java/org/apache/parquet/cli/commands/ConvertCSVCommandTest.java": 41,
                "parquet-cli/src/test/java/org/apache/parquet/cli/commands/ConvertCommandTest.java": 41,
                "parquet-cli/src/test/java/org/apache/parquet/cli/commands/FileTest.java": 58,
                "parquet-cli/src/test/java/org/apache/parquet/cli/commands/ParquetFileTest.java": 117,
                "parquet-cli/src/test/java/org/apache/parquet/cli/commands/ParquetMetadataCommandTest.java": 38,
                "parquet-cli/src/test/java/org/apache/parquet/cli/commands/RewriteCommandTest.java": 41,
                "parquet-cli/src/test/java/org/apache/parquet/cli/commands/ScanCommandTest.java": 38,
                "parquet-cli/src/test/java/org/apache/parquet/cli/commands/SchemaCommandTest.java": 68,
                "parquet-cli/src/test/java/org/apache/parquet/cli/commands/ShowBloomFilterCommandTest.java": 41,
                "parquet-cli/src/test/java/org/apache/parquet/cli/commands/ShowColumnIndexTest.java": 38,
                "parquet-cli/src/test/java/org/apache/parquet/cli/commands/ShowDictionaryCommandTest.java": 50,
                "parquet-cli/src/test/java/org/apache/parquet/cli/commands/ShowFooterCommandTest.java": 43,
                "parquet-cli/src/test/java/org/apache/parquet/cli/commands/ShowPagesCommandTest.java": 38,
                "parquet-cli/src/test/java/org/apache/parquet/cli/commands/ToAvroCommandTest.java": 113,
                "parquet-cli/src/test/java/org/apache/parquet/cli/commands/TransCompressionCommandTest.java": 45,
                "parquet-column/src/main/java/org/apache/parquet/CorruptDeltaByteArrays.java": 97,
                "parquet-column/src/main/java/org/apache/parquet/CorruptStatistics.java": 116,
                "parquet-column/src/main/java/org/apache/parquet/column/ColumnDescriptor.java": 156,
                "parquet-column/src/main/java/org/apache/parquet/column/ColumnProperty.java": 137,
                "parquet-column/src/main/java/org/apache/parquet/column/ColumnReadStore.java": 32,
                "parquet-column/src/main/java/org/apache/parquet/column/ColumnReader.java": 117,
                "parquet-column/src/main/java/org/apache/parquet/column/ColumnWriteStore.java": 75,
                "parquet-column/src/main/java/org/apache/parquet/column/ColumnWriter.java": 96,
                "parquet-column/src/main/java/org/apache/parquet/column/Dictionary.java": 63,
                "parquet-column/src/main/java/org/apache/parquet/column/Encoding.java": 309,
                "parquet-column/src/main/java/org/apache/parquet/column/EncodingStats.java": 157,
                "parquet-column/src/main/java/org/apache/parquet/column/MinMax.java": 56,
                "parquet-column/src/main/java/org/apache/parquet/column/ParquetProperties.java": 589,
                "parquet-column/src/main/java/org/apache/parquet/column/UnknownColumnException.java": 40,
                "parquet-column/src/main/java/org/apache/parquet/column/UnknownColumnTypeException.java": 41,
                "parquet-column/src/main/java/org/apache/parquet/column/ValuesType.java": 26,
                "parquet-column/src/main/java/org/apache/parquet/column/impl/ColumnReadStoreImpl.java": 104,
                "parquet-column/src/main/java/org/apache/parquet/column/impl/ColumnReaderBase.java": 790,
                "parquet-column/src/main/java/org/apache/parquet/column/impl/ColumnReaderImpl.java": 58,
                "parquet-column/src/main/java/org/apache/parquet/column/impl/ColumnWriteStoreBase.java": 273,
                "parquet-column/src/main/java/org/apache/parquet/column/impl/ColumnWriteStoreV1.java": 52,
                "parquet-column/src/main/java/org/apache/parquet/column/impl/ColumnWriteStoreV2.java": 46,
                "parquet-column/src/main/java/org/apache/parquet/column/impl/ColumnWriterBase.java": 408,
                "parquet-column/src/main/java/org/apache/parquet/column/impl/ColumnWriterV1.java": 68,
                "parquet-column/src/main/java/org/apache/parquet/column/impl/ColumnWriterV2.java": 94,
                "parquet-column/src/main/java/org/apache/parquet/column/impl/SynchronizingColumnReader.java": 111,
                "parquet-column/src/main/java/org/apache/parquet/column/page/DataPage.java": 72,
                "parquet-column/src/main/java/org/apache/parquet/column/page/DataPageV1.java": 127,
                "parquet-column/src/main/java/org/apache/parquet/column/page/DataPageV2.java": 207,
                "parquet-column/src/main/java/org/apache/parquet/column/page/DictionaryPage.java": 83,
                "parquet-column/src/main/java/org/apache/parquet/column/page/DictionaryPageReadStore.java": 36,
                "parquet-column/src/main/java/org/apache/parquet/column/page/Page.java": 62,
                "parquet-column/src/main/java/org/apache/parquet/column/page/PageReadStore.java": 64,
                "parquet-column/src/main/java/org/apache/parquet/column/page/PageReader.java": 40,
                "parquet-column/src/main/java/org/apache/parquet/column/page/PageWriteStore.java": 35,
                "parquet-column/src/main/java/org/apache/parquet/column/page/PageWriter.java": 102,
                "parquet-column/src/main/java/org/apache/parquet/column/statistics/BinaryStatistics.java": 188,
                "parquet-column/src/main/java/org/apache/parquet/column/statistics/BooleanStatistics.java": 147,
                "parquet-column/src/main/java/org/apache/parquet/column/statistics/DoubleStatistics.java": 147,
                "parquet-column/src/main/java/org/apache/parquet/column/statistics/FloatStatistics.java": 148,
                "parquet-column/src/main/java/org/apache/parquet/column/statistics/IntStatistics.java": 147,
                "parquet-column/src/main/java/org/apache/parquet/column/statistics/LongStatistics.java": 147,
                "parquet-column/src/main/java/org/apache/parquet/column/statistics/Statistics.java": 539,
                "parquet-column/src/main/java/org/apache/parquet/column/statistics/StatisticsClassException.java": 44,
                "parquet-column/src/main/java/org/apache/parquet/column/values/RequiresFallback.java": 51,
                "parquet-column/src/main/java/org/apache/parquet/column/values/RequiresPreviousReader.java": 23,
                "parquet-column/src/main/java/org/apache/parquet/column/values/ValuesReader.java": 205,
                "parquet-column/src/main/java/org/apache/parquet/column/values/ValuesWriter.java": 136,
                "parquet-column/src/main/java/org/apache/parquet/column/values/bitpacking/BitPackingValuesReader.java": 84,
                "parquet-column/src/main/java/org/apache/parquet/column/values/bitpacking/BitPackingValuesWriter.java": 130,
                "parquet-column/src/main/java/org/apache/parquet/column/values/bitpacking/ByteBitPackingValuesReader.java": 99,
                "parquet-column/src/main/java/org/apache/parquet/column/values/bitpacking/ByteBitPackingValuesWriter.java": 86,
                "parquet-column/src/main/java/org/apache/parquet/column/values/bitpacking/DevNullValuesWriter.java": 89,
                "parquet-column/src/main/java/org/apache/parquet/column/values/bloomfilter/AdaptiveBlockSplitBloomFilter.java": 305,
                "parquet-column/src/main/java/org/apache/parquet/column/values/bloomfilter/BlockSplitBloomFilter.java": 424,
                "parquet-column/src/main/java/org/apache/parquet/column/values/bloomfilter/BloomFilter.java": 203,
                "parquet-column/src/main/java/org/apache/parquet/column/values/bloomfilter/BloomFilterWriteStore.java": 35,
                "parquet-column/src/main/java/org/apache/parquet/column/values/bloomfilter/BloomFilterWriter.java": 31,
                "parquet-column/src/main/java/org/apache/parquet/column/values/bloomfilter/HashFunction.java": 41,
                "parquet-column/src/main/java/org/apache/parquet/column/values/bloomfilter/XxHash.java": 40,
                "parquet-column/src/main/java/org/apache/parquet/column/values/bytestreamsplit/ByteStreamSplitValuesReader.java": 111,
                "parquet-column/src/main/java/org/apache/parquet/column/values/bytestreamsplit/ByteStreamSplitValuesReaderForDouble.java": 37,
                "parquet-column/src/main/java/org/apache/parquet/column/values/bytestreamsplit/ByteStreamSplitValuesReaderForFloat.java": 37,
                "parquet-column/src/main/java/org/apache/parquet/column/values/bytestreamsplit/ByteStreamSplitValuesWriter.java": 142,
                "parquet-column/src/main/java/org/apache/parquet/column/values/delta/DeltaBinaryPackingConfig.java": 55,
                "parquet-column/src/main/java/org/apache/parquet/column/values/delta/DeltaBinaryPackingValuesReader.java": 171,
                "parquet-column/src/main/java/org/apache/parquet/column/values/delta/DeltaBinaryPackingValuesWriter.java": 136,
                "parquet-column/src/main/java/org/apache/parquet/column/values/delta/DeltaBinaryPackingValuesWriterForInteger.java": 196,
                "parquet-column/src/main/java/org/apache/parquet/column/values/delta/DeltaBinaryPackingValuesWriterForLong.java": 198,
                "parquet-column/src/main/java/org/apache/parquet/column/values/deltalengthbytearray/DeltaLengthByteArrayValuesReader.java": 80,
                "parquet-column/src/main/java/org/apache/parquet/column/values/deltalengthbytearray/DeltaLengthByteArrayValuesWriter.java": 115,
                "parquet-column/src/main/java/org/apache/parquet/column/values/deltastrings/DeltaByteArrayReader.java": 96,
                "parquet-column/src/main/java/org/apache/parquet/column/values/deltastrings/DeltaByteArrayWriter.java": 100,
                "parquet-column/src/main/java/org/apache/parquet/column/values/dictionary/DictionaryValuesReader.java": 131,
                "parquet-column/src/main/java/org/apache/parquet/column/values/dictionary/DictionaryValuesWriter.java": 597,
                "parquet-column/src/main/java/org/apache/parquet/column/values/dictionary/IntList.java": 159,
                "parquet-column/src/main/java/org/apache/parquet/column/values/dictionary/PlainValuesDictionary.java": 313,
                "parquet-column/src/main/java/org/apache/parquet/column/values/factory/DefaultV1ValuesWriterFactory.java": 122,
                "parquet-column/src/main/java/org/apache/parquet/column/values/factory/DefaultV2ValuesWriterFactory.java": 126,
                "parquet-column/src/main/java/org/apache/parquet/column/values/factory/DefaultValuesWriterFactory.java": 87,
                "parquet-column/src/main/java/org/apache/parquet/column/values/factory/ValuesWriterFactory.java": 52,
                "parquet-column/src/main/java/org/apache/parquet/column/values/fallback/FallbackValuesWriter.java": 204,
                "parquet-column/src/main/java/org/apache/parquet/column/values/plain/BinaryPlainValuesReader.java": 63,
                "parquet-column/src/main/java/org/apache/parquet/column/values/plain/BooleanPlainValuesReader.java": 73,
                "parquet-column/src/main/java/org/apache/parquet/column/values/plain/BooleanPlainValuesWriter.java": 81,
                "parquet-column/src/main/java/org/apache/parquet/column/values/plain/FixedLenByteArrayPlainValuesReader.java": 72,
                "parquet-column/src/main/java/org/apache/parquet/column/values/plain/FixedLenByteArrayPlainValuesWriter.java": 106,
                "parquet-column/src/main/java/org/apache/parquet/column/values/plain/PlainValuesReader.java": 139,
                "parquet-column/src/main/java/org/apache/parquet/column/values/plain/PlainValuesWriter.java": 148,
                "parquet-column/src/main/java/org/apache/parquet/column/values/rle/RunLengthBitPackingHybridDecoder.java": 107,
                "parquet-column/src/main/java/org/apache/parquet/column/values/rle/RunLengthBitPackingHybridEncoder.java": 293,
                "parquet-column/src/main/java/org/apache/parquet/column/values/rle/RunLengthBitPackingHybridValuesReader.java": 68,
                "parquet-column/src/main/java/org/apache/parquet/column/values/rle/RunLengthBitPackingHybridValuesWriter.java": 95,
                "parquet-column/src/main/java/org/apache/parquet/column/values/rle/ZeroIntegerValuesReader.java": 50,
                "parquet-column/src/main/java/org/apache/parquet/example/DummyRecordConverter.java": 114,
                "parquet-column/src/main/java/org/apache/parquet/example/Paper.java": 164,
                "parquet-column/src/main/java/org/apache/parquet/example/data/Group.java": 147,
                "parquet-column/src/main/java/org/apache/parquet/example/data/GroupFactory.java": 25,
                "parquet-column/src/main/java/org/apache/parquet/example/data/GroupValueSource.java": 89,
                "parquet-column/src/main/java/org/apache/parquet/example/data/GroupWriter.java": 62,
                "parquet-column/src/main/java/org/apache/parquet/example/data/simple/BinaryValue.java": 52,
                "parquet-column/src/main/java/org/apache/parquet/example/data/simple/BooleanValue.java": 44,
                "parquet-column/src/main/java/org/apache/parquet/example/data/simple/DoubleValue.java": 45,
                "parquet-column/src/main/java/org/apache/parquet/example/data/simple/FloatValue.java": 45,
                "parquet-column/src/main/java/org/apache/parquet/example/data/simple/Int96Value.java": 46,
                "parquet-column/src/main/java/org/apache/parquet/example/data/simple/IntegerValue.java": 46,
                "parquet-column/src/main/java/org/apache/parquet/example/data/simple/LongValue.java": 45,
                "parquet-column/src/main/java/org/apache/parquet/example/data/simple/NanoTime.java": 80,
                "parquet-column/src/main/java/org/apache/parquet/example/data/simple/Primitive.java": 60,
                "parquet-column/src/main/java/org/apache/parquet/example/data/simple/SimpleGroup.java": 236,
                "parquet-column/src/main/java/org/apache/parquet/example/data/simple/SimpleGroupFactory.java": 38,
                "parquet-column/src/main/java/org/apache/parquet/example/data/simple/convert/GroupRecordConverter.java": 57,
                "parquet-column/src/main/java/org/apache/parquet/example/data/simple/convert/SimpleGroupConverter.java": 67,
                "parquet-column/src/main/java/org/apache/parquet/example/data/simple/convert/SimplePrimitiveConverter.java": 88,
                "parquet-column/src/main/java/org/apache/parquet/filter/AndRecordFilter.java": 65,
                "parquet-column/src/main/java/org/apache/parquet/filter/ColumnPredicates.java": 191,
                "parquet-column/src/main/java/org/apache/parquet/filter/ColumnRecordFilter.java": 76,
                "parquet-column/src/main/java/org/apache/parquet/filter/NotRecordFilter.java": 60,
                "parquet-column/src/main/java/org/apache/parquet/filter/OrRecordFilter.java": 62,
                "parquet-column/src/main/java/org/apache/parquet/filter/PagedRecordFilter.java": 65,
                "parquet-column/src/main/java/org/apache/parquet/filter/RecordFilter.java": 33,
                "parquet-column/src/main/java/org/apache/parquet/filter/UnboundRecordFilter.java": 37,
                "parquet-column/src/main/java/org/apache/parquet/filter2/compat/FilterCompat.java": 181,
                "parquet-column/src/main/java/org/apache/parquet/filter2/predicate/FilterApi.java": 328,
                "parquet-column/src/main/java/org/apache/parquet/filter2/predicate/FilterPredicate.java": 84,
                "parquet-column/src/main/java/org/apache/parquet/filter2/predicate/LogicalInverseRewriter.java": 126,
                "parquet-column/src/main/java/org/apache/parquet/filter2/predicate/LogicalInverter.java": 120,
                "parquet-column/src/main/java/org/apache/parquet/filter2/predicate/Operators.java": 587,
                "parquet-column/src/main/java/org/apache/parquet/filter2/predicate/PrimitiveToBoxedClass.java": 50,
                "parquet-column/src/main/java/org/apache/parquet/filter2/predicate/SchemaCompatibilityValidator.java": 204,
                "parquet-column/src/main/java/org/apache/parquet/filter2/predicate/Statistics.java": 93,
                "parquet-column/src/main/java/org/apache/parquet/filter2/predicate/UserDefinedPredicate.java": 131,
                "parquet-column/src/main/java/org/apache/parquet/filter2/predicate/ValidTypeMap.java": 128,
                "parquet-column/src/main/java/org/apache/parquet/filter2/recordlevel/FilteringGroupConverter.java": 112,
                "parquet-column/src/main/java/org/apache/parquet/filter2/recordlevel/FilteringPrimitiveConverter.java": 109,
                "parquet-column/src/main/java/org/apache/parquet/filter2/recordlevel/FilteringRecordMaterializer.java": 116,
                "parquet-column/src/main/java/org/apache/parquet/filter2/recordlevel/IncrementallyUpdatedFilterPredicate.java": 166,
                "parquet-column/src/main/java/org/apache/parquet/filter2/recordlevel/IncrementallyUpdatedFilterPredicateBuilderBase.java": 116,
                "parquet-column/src/main/java/org/apache/parquet/filter2/recordlevel/IncrementallyUpdatedFilterPredicateEvaluator.java": 62,
                "parquet-column/src/main/java/org/apache/parquet/filter2/recordlevel/IncrementallyUpdatedFilterPredicateResetter.java": 59,
                "parquet-column/src/main/java/org/apache/parquet/internal/column/columnindex/BinaryColumnIndexBuilder.java": 140,
                "parquet-column/src/main/java/org/apache/parquet/internal/column/columnindex/BinaryTruncator.java": 221,
                "parquet-column/src/main/java/org/apache/parquet/internal/column/columnindex/BooleanColumnIndexBuilder.java": 133,
                "parquet-column/src/main/java/org/apache/parquet/internal/column/columnindex/BoundaryOrder.java": 384,
                "parquet-column/src/main/java/org/apache/parquet/internal/column/columnindex/ColumnIndex.java": 60,
                "parquet-column/src/main/java/org/apache/parquet/internal/column/columnindex/ColumnIndexBuilder.java": 686,
                "parquet-column/src/main/java/org/apache/parquet/internal/column/columnindex/DoubleColumnIndexBuilder.java": 155,
                "parquet-column/src/main/java/org/apache/parquet/internal/column/columnindex/FloatColumnIndexBuilder.java": 155,
                "parquet-column/src/main/java/org/apache/parquet/internal/column/columnindex/IndexIterator.java": 89,
                "parquet-column/src/main/java/org/apache/parquet/internal/column/columnindex/IntColumnIndexBuilder.java": 136,
                "parquet-column/src/main/java/org/apache/parquet/internal/column/columnindex/LongColumnIndexBuilder.java": 136,
                "parquet-column/src/main/java/org/apache/parquet/internal/column/columnindex/OffsetIndex.java": 73,
                "parquet-column/src/main/java/org/apache/parquet/internal/column/columnindex/OffsetIndexBuilder.java": 193,
                "parquet-column/src/main/java/org/apache/parquet/internal/filter2/columnindex/ColumnIndexFilter.java": 217,
                "parquet-column/src/main/java/org/apache/parquet/internal/filter2/columnindex/ColumnIndexStore.java": 55,
                "parquet-column/src/main/java/org/apache/parquet/internal/filter2/columnindex/RowRanges.java": 318,
                "parquet-column/src/main/java/org/apache/parquet/io/BaseRecordReader.java": 149,
                "parquet-column/src/main/java/org/apache/parquet/io/ColumnIO.java": 138,
                "parquet-column/src/main/java/org/apache/parquet/io/ColumnIOFactory.java": 174,
                "parquet-column/src/main/java/org/apache/parquet/io/CompilationException.java": 44,
                "parquet-column/src/main/java/org/apache/parquet/io/EmptyRecordReader.java": 48,
                "parquet-column/src/main/java/org/apache/parquet/io/FilteredRecordReader.java": 97,
                "parquet-column/src/main/java/org/apache/parquet/io/GroupColumnIO.java": 121,
                "parquet-column/src/main/java/org/apache/parquet/io/InvalidFileOffsetException.java": 29,
                "parquet-column/src/main/java/org/apache/parquet/io/InvalidRecordException.java": 45,
                "parquet-column/src/main/java/org/apache/parquet/io/MessageColumnIO.java": 534,
                "parquet-column/src/main/java/org/apache/parquet/io/ParquetDecodingException.java": 44,
                "parquet-column/src/main/java/org/apache/parquet/io/ParquetEncodingException.java": 44,
                "parquet-column/src/main/java/org/apache/parquet/io/PrimitiveColumnIO.java": 108,
                "parquet-column/src/main/java/org/apache/parquet/io/RecordConsumerLoggingWrapper.java": 187,
                "parquet-column/src/main/java/org/apache/parquet/io/RecordReader.java": 43,
                "parquet-column/src/main/java/org/apache/parquet/io/RecordReaderImplementation.java": 474,
                "parquet-column/src/main/java/org/apache/parquet/io/ValidatingRecordConsumer.java": 247,
                "parquet-column/src/main/java/org/apache/parquet/io/api/Binary.java": 737,
                "parquet-column/src/main/java/org/apache/parquet/io/api/Converter.java": 37,
                "parquet-column/src/main/java/org/apache/parquet/io/api/GroupConverter.java": 55,
                "parquet-column/src/main/java/org/apache/parquet/io/api/PrimitiveConverter.java": 108,
                "parquet-column/src/main/java/org/apache/parquet/io/api/RecordConsumer.java": 134,
                "parquet-column/src/main/java/org/apache/parquet/io/api/RecordMaterializer.java": 73,
                "parquet-column/src/main/java/org/apache/parquet/schema/ColumnOrder.java": 97,
                "parquet-column/src/main/java/org/apache/parquet/schema/ConversionPatterns.java": 133,
                "parquet-column/src/main/java/org/apache/parquet/schema/DecimalMetadata.java": 62,
                "parquet-column/src/main/java/org/apache/parquet/schema/GroupType.java": 421,
                "parquet-column/src/main/java/org/apache/parquet/schema/IncompatibleSchemaModificationException.java": 46,
                "parquet-column/src/main/java/org/apache/parquet/schema/InvalidSchemaException.java": 31,
                "parquet-column/src/main/java/org/apache/parquet/schema/LogicalTypeAnnotation.java": 1064,
                "parquet-column/src/main/java/org/apache/parquet/schema/MessageType.java": 145,
                "parquet-column/src/main/java/org/apache/parquet/schema/MessageTypeParser.java": 243,
                "parquet-column/src/main/java/org/apache/parquet/schema/OriginalType.java": 48,
                "parquet-column/src/main/java/org/apache/parquet/schema/PrimitiveComparator.java": 279,
                "parquet-column/src/main/java/org/apache/parquet/schema/PrimitiveStringifier.java": 451,
                "parquet-column/src/main/java/org/apache/parquet/schema/PrimitiveType.java": 797,
                "parquet-column/src/main/java/org/apache/parquet/schema/Type.java": 366,
                "parquet-column/src/main/java/org/apache/parquet/schema/TypeConverter.java": 53,
                "parquet-column/src/main/java/org/apache/parquet/schema/TypeUtil.java": 45,
                "parquet-column/src/main/java/org/apache/parquet/schema/TypeVisitor.java": 43,
                "parquet-column/src/main/java/org/apache/parquet/schema/Types.java": 1542,
                "parquet-column/src/test/java/org/apache/parquet/CorruptStatisticsTest.java": 92,
                "parquet-column/src/test/java/org/apache/parquet/FixedBinaryTestUtils.java": 96,
                "parquet-column/src/test/java/org/apache/parquet/ResourceIntensiveTestRule.java": 58,
                "parquet-column/src/test/java/org/apache/parquet/column/TestColumnDescriptor.java": 52,
                "parquet-column/src/test/java/org/apache/parquet/column/TestEncodingStats.java": 202,
                "parquet-column/src/test/java/org/apache/parquet/column/impl/TestColumnReaderImpl.java": 131,
                "parquet-column/src/test/java/org/apache/parquet/column/impl/TestCorruptDeltaByteArrays.java": 269,
                "parquet-column/src/test/java/org/apache/parquet/column/mem/TestMemColumn.java": 246,
                "parquet-column/src/test/java/org/apache/parquet/column/mem/TestMemPageStore.java": 61,
                "parquet-column/src/test/java/org/apache/parquet/column/page/mem/MemPageReader.java": 67,
                "parquet-column/src/test/java/org/apache/parquet/column/page/mem/MemPageStore.java": 78,
                "parquet-column/src/test/java/org/apache/parquet/column/page/mem/MemPageWriter.java": 117,
                "parquet-column/src/test/java/org/apache/parquet/column/statistics/TestStatistics.java": 789,
                "parquet-column/src/test/java/org/apache/parquet/column/values/TestValuesReaderImpl.java": 148,
                "parquet-column/src/test/java/org/apache/parquet/column/values/Utils.java": 76,
                "parquet-column/src/test/java/org/apache/parquet/column/values/bitpacking/BitPackingPerfTest.java": 103,
                "parquet-column/src/test/java/org/apache/parquet/column/values/bitpacking/TestBitPackingColumn.java": 232,
                "parquet-column/src/test/java/org/apache/parquet/column/values/bloomfilter/TestBlockSplitBloomFilter.java": 325,
                "parquet-column/src/test/java/org/apache/parquet/column/values/bytestreamsplit/ByteStreamSplitValuesEndToEndTest.java": 111,
                "parquet-column/src/test/java/org/apache/parquet/column/values/bytestreamsplit/ByteStreamSplitValuesReaderTest.java": 193,
                "parquet-column/src/test/java/org/apache/parquet/column/values/bytestreamsplit/ByteStreamSplitValuesWriterTest.java": 189,
                "parquet-column/src/test/java/org/apache/parquet/column/values/delta/DeltaBinaryPackingValuesWriterForIntegerTest.java": 294,
                "parquet-column/src/test/java/org/apache/parquet/column/values/delta/DeltaBinaryPackingValuesWriterForLongTest.java": 291,
                "parquet-column/src/test/java/org/apache/parquet/column/values/delta/benchmark/BenchMarkTest.java": 41,
                "parquet-column/src/test/java/org/apache/parquet/column/values/delta/benchmark/BenchmarkIntegerOutputSize.java": 107,
                "parquet-column/src/test/java/org/apache/parquet/column/values/delta/benchmark/BenchmarkReadingRandomIntegers.java": 102,
                "parquet-column/src/test/java/org/apache/parquet/column/values/delta/benchmark/RandomWritingBenchmarkTest.java": 76,
                "parquet-column/src/test/java/org/apache/parquet/column/values/delta/benchmark/SmallRangeWritingBenchmarkTest.java": 49,
                "parquet-column/src/test/java/org/apache/parquet/column/values/deltalengthbytearray/TestDeltaLengthByteArray.java": 103,
                "parquet-column/src/test/java/org/apache/parquet/column/values/deltalengthbytearray/benchmark/BenchmarkDeltaLengthByteArray.java": 73,
                "parquet-column/src/test/java/org/apache/parquet/column/values/deltastrings/TestDeltaByteArray.java": 130,
                "parquet-column/src/test/java/org/apache/parquet/column/values/deltastrings/benchmark/BenchmarkDeltaByteArray.java": 103,
                "parquet-column/src/test/java/org/apache/parquet/column/values/dictionary/IntListTest.java": 84,
                "parquet-column/src/test/java/org/apache/parquet/column/values/dictionary/TestDictionary.java": 661,
                "parquet-column/src/test/java/org/apache/parquet/column/values/factory/DefaultValuesWriterFactoryTest.java": 546,
                "parquet-column/src/test/java/org/apache/parquet/column/values/rle/RunLengthBitPackingHybridIntegrationTest.java": 86,
                "parquet-column/src/test/java/org/apache/parquet/column/values/rle/TestRunLengthBitPackingHybridEncoder.java": 329,
                "parquet-column/src/test/java/org/apache/parquet/filter2/predicate/DummyUdp.java": 37,
                "parquet-column/src/test/java/org/apache/parquet/filter2/predicate/TestFilterApiMethods.java": 172,
                "parquet-column/src/test/java/org/apache/parquet/filter2/predicate/TestLogicalInverseRewriter.java": 103,
                "parquet-column/src/test/java/org/apache/parquet/filter2/predicate/TestLogicalInverter.java": 94,
                "parquet-column/src/test/java/org/apache/parquet/filter2/predicate/TestSchemaCompatibilityValidator.java": 142,
                "parquet-column/src/test/java/org/apache/parquet/filter2/predicate/TestValidTypeMap.java": 98,
                "parquet-column/src/test/java/org/apache/parquet/filter2/recordlevel/TestIncrementallyUpdatedFilterPredicateEvaluator.java": 209,
                "parquet-column/src/test/java/org/apache/parquet/filter2/recordlevel/TestIncrementallyUpdatedFilterPredicateResetter.java": 69,
                "parquet-column/src/test/java/org/apache/parquet/filter2/recordlevel/TestValueInspector.java": 97,
                "parquet-column/src/test/java/org/apache/parquet/internal/column/columnindex/TestBinaryTruncator.java": 285,
                "parquet-column/src/test/java/org/apache/parquet/internal/column/columnindex/TestBoundaryOrder.java": 543,
                "parquet-column/src/test/java/org/apache/parquet/internal/column/columnindex/TestColumnIndexBuilder.java": 1728,
                "parquet-column/src/test/java/org/apache/parquet/internal/column/columnindex/TestIndexIterator.java": 63,
                "parquet-column/src/test/java/org/apache/parquet/internal/column/columnindex/TestOffsetIndexBuilder.java": 111,
                "parquet-column/src/test/java/org/apache/parquet/internal/filter2/columnindex/TestColumnIndexFilter.java": 555,
                "parquet-column/src/test/java/org/apache/parquet/internal/filter2/columnindex/TestRowRanges.java": 155,
                "parquet-column/src/test/java/org/apache/parquet/io/ConverterConsumer.java": 125,
                "parquet-column/src/test/java/org/apache/parquet/io/ExpectationValidatingConverter.java": 169,
                "parquet-column/src/test/java/org/apache/parquet/io/ExpectationValidatingRecordConsumer.java": 112,
                "parquet-column/src/test/java/org/apache/parquet/io/PerfTest.java": 128,
                "parquet-column/src/test/java/org/apache/parquet/io/TestColumnIO.java": 709,
                "parquet-column/src/test/java/org/apache/parquet/io/TestFiltered.java": 278,
                "parquet-column/src/test/java/org/apache/parquet/io/api/TestBinary.java": 271,
                "parquet-column/src/test/java/org/apache/parquet/parser/TestParquetParser.java": 374,
                "parquet-column/src/test/java/org/apache/parquet/schema/TestMessageType.java": 247,
                "parquet-column/src/test/java/org/apache/parquet/schema/TestPrimitiveComparator.java": 330,
                "parquet-column/src/test/java/org/apache/parquet/schema/TestPrimitiveStringifier.java": 391,
                "parquet-column/src/test/java/org/apache/parquet/schema/TestRepetitionType.java": 36,
                "parquet-column/src/test/java/org/apache/parquet/schema/TestTypeBuilders.java": 1372,
                "parquet-column/src/test/java/org/apache/parquet/schema/TestTypeBuildersWithLogicalTypes.java": 422,
                "parquet-column/src/test/java/org/apache/parquet/schema/TestTypeUtil.java": 80,
                "parquet-common/src/main/java/org/apache/parquet/Closeables.java": 60,
                "parquet-common/src/main/java/org/apache/parquet/Exceptions.java": 39,
                "parquet-common/src/main/java/org/apache/parquet/Files.java": 54,
                "parquet-common/src/main/java/org/apache/parquet/IOExceptionUtils.java": 45,
                "parquet-common/src/main/java/org/apache/parquet/Ints.java": 44,
                "parquet-common/src/main/java/org/apache/parquet/Log.java": 146,
                "parquet-common/src/main/java/org/apache/parquet/OutputStreamCloseException.java": 46,
                "parquet-common/src/main/java/org/apache/parquet/ParquetRuntimeException.java": 42,
                "parquet-common/src/main/java/org/apache/parquet/Preconditions.java": 251,
                "parquet-common/src/main/java/org/apache/parquet/SemanticVersion.java": 293,
                "parquet-common/src/main/java/org/apache/parquet/ShouldNeverHappenException.java": 40,
                "parquet-common/src/main/java/org/apache/parquet/Strings.java": 132,
                "parquet-common/src/main/java/org/apache/parquet/VersionParser.java": 129,
                "parquet-common/src/main/java/org/apache/parquet/bytes/ByteBufferAllocator.java": 40,
                "parquet-common/src/main/java/org/apache/parquet/bytes/ByteBufferInputStream.java": 160,
                "parquet-common/src/main/java/org/apache/parquet/bytes/BytesInput.java": 545,
                "parquet-common/src/main/java/org/apache/parquet/bytes/BytesUtils.java": 335,
                "parquet-common/src/main/java/org/apache/parquet/bytes/CapacityByteArrayOutputStream.java": 352,
                "parquet-common/src/main/java/org/apache/parquet/bytes/ConcatenatingByteArrayCollector.java": 63,
                "parquet-common/src/main/java/org/apache/parquet/bytes/DirectByteBufferAllocator.java": 43,
                "parquet-common/src/main/java/org/apache/parquet/bytes/HeapByteBufferAllocator.java": 44,
                "parquet-common/src/main/java/org/apache/parquet/bytes/LittleEndianDataInputStream.java": 421,
                "parquet-common/src/main/java/org/apache/parquet/bytes/LittleEndianDataOutputStream.java": 218,
                "parquet-common/src/main/java/org/apache/parquet/bytes/MultiBufferInputStream.java": 382,
                "parquet-common/src/main/java/org/apache/parquet/bytes/SingleBufferInputStream.java": 177,
                "parquet-common/src/main/java/org/apache/parquet/compression/CompressionCodecFactory.java": 47,
                "parquet-common/src/main/java/org/apache/parquet/glob/GlobExpander.java": 129,
                "parquet-common/src/main/java/org/apache/parquet/glob/GlobNode.java": 157,
                "parquet-common/src/main/java/org/apache/parquet/glob/GlobParser.java": 224,
                "parquet-common/src/main/java/org/apache/parquet/glob/WildcardPath.java": 121,
                "parquet-common/src/main/java/org/apache/parquet/hadoop/codec/CompressionCodecNotSupportedException.java": 38,
                "parquet-common/src/main/java/org/apache/parquet/hadoop/metadata/Canonicalizer.java": 61,
                "parquet-common/src/main/java/org/apache/parquet/hadoop/metadata/ColumnPath.java": 88,
                "parquet-common/src/main/java/org/apache/parquet/hadoop/metadata/CompressionCodecName.java": 99,
                "parquet-common/src/main/java/org/apache/parquet/io/DelegatingPositionOutputStream.java": 63,
                "parquet-common/src/main/java/org/apache/parquet/io/DelegatingSeekableInputStream.java": 171,
                "parquet-common/src/main/java/org/apache/parquet/io/InputFile.java": 44,
                "parquet-common/src/main/java/org/apache/parquet/io/LocalInputFile.java": 102,
                "parquet-common/src/main/java/org/apache/parquet/io/LocalOutputFile.java": 107,
                "parquet-common/src/main/java/org/apache/parquet/io/OutputFile.java": 62,
                "parquet-common/src/main/java/org/apache/parquet/io/PositionOutputStream.java": 39,
                "parquet-common/src/main/java/org/apache/parquet/io/SeekableInputStream.java": 108,
                "parquet-common/src/main/java/org/apache/parquet/util/DynConstructors.java": 263,
                "parquet-common/src/main/java/org/apache/parquet/util/DynMethods.java": 506,
                "parquet-common/src/test/java/org/apache/parquet/SemanticVersionTest.java": 114,
                "parquet-common/src/test/java/org/apache/parquet/TestPreconditions.java": 246,
                "parquet-common/src/test/java/org/apache/parquet/TestUtils.java": 70,
                "parquet-common/src/test/java/org/apache/parquet/VersionTest.java": 100,
                "parquet-common/src/test/java/org/apache/parquet/bytes/TestByteBufferInputStreams.java": 589,
                "parquet-common/src/test/java/org/apache/parquet/bytes/TestBytesUtil.java": 49,
                "parquet-common/src/test/java/org/apache/parquet/bytes/TestDeprecatedBufferInputStream.java": 152,
                "parquet-common/src/test/java/org/apache/parquet/bytes/TestMultiBufferInputStream.java": 141,
                "parquet-common/src/test/java/org/apache/parquet/bytes/TestSingleBufferInputStream.java": 130,
                "parquet-common/src/test/java/org/apache/parquet/glob/TestGlob.java": 144,
                "parquet-common/src/test/java/org/apache/parquet/glob/TestWildcardPath.java": 125,
                "parquet-common/src/test/java/org/apache/parquet/io/MockInputStream.java": 56,
                "parquet-common/src/test/java/org/apache/parquet/io/TestDelegatingSeekableInputStream.java": 844,
                "parquet-common/src/test/java/org/apache/parquet/io/TestLocalInputOutput.java": 92,
                "parquet-common/src/test/java/org/apache/parquet/util/Concatenator.java": 82,
                "parquet-common/src/test/java/org/apache/parquet/util/TestDynConstructors.java": 165,
                "parquet-common/src/test/java/org/apache/parquet/util/TestDynMethods.java": 315,
                "parquet-encoding/src/main/java/org/apache/parquet/column/values/bitpacking/BitPacking.java": 717,
                "parquet-encoding/src/main/java/org/apache/parquet/column/values/bitpacking/ByteBasedBitPackingEncoder.java": 142,
                "parquet-encoding/src/main/java/org/apache/parquet/column/values/bitpacking/BytePacker.java": 141,
                "parquet-encoding/src/main/java/org/apache/parquet/column/values/bitpacking/BytePackerFactory.java": 25,
                "parquet-encoding/src/main/java/org/apache/parquet/column/values/bitpacking/BytePackerForLong.java": 109,
                "parquet-encoding/src/main/java/org/apache/parquet/column/values/bitpacking/BytePackerForLongFactory.java": 25,
                "parquet-encoding/src/main/java/org/apache/parquet/column/values/bitpacking/IntPacker.java": 63,
                "parquet-encoding/src/main/java/org/apache/parquet/column/values/bitpacking/IntPackerFactory.java": 25,
                "parquet-encoding/src/main/java/org/apache/parquet/column/values/bitpacking/Packer.java": 137,
                "parquet-encoding/src/test/java/org/apache/parquet/bytes/TestBytesInput.java": 42,
                "parquet-encoding/src/test/java/org/apache/parquet/bytes/TestCapacityByteArrayOutputStream.java": 242,
                "parquet-encoding/src/test/java/org/apache/parquet/column/values/bitpacking/TestBitPacking.java": 233,
                "parquet-encoding/src/test/java/org/apache/parquet/column/values/bitpacking/TestByteBasedBitPackingEncoder.java": 46,
                "parquet-encoding/src/test/java/org/apache/parquet/column/values/bitpacking/TestByteBitPacking.java": 198,
                "parquet-encoding/src/test/java/org/apache/parquet/column/values/bitpacking/TestLemireBitPacking.java": 125,
                "parquet-format-structures/src/main/java/org/apache/parquet/format/BlockCipher.java": 76,
                "parquet-format-structures/src/main/java/org/apache/parquet/format/CliUtils.java": 55,
                "parquet-format-structures/src/main/java/org/apache/parquet/format/InterningProtocol.java": 236,
                "parquet-format-structures/src/main/java/org/apache/parquet/format/InvalidParquetMetadataException.java": 30,
                "parquet-format-structures/src/main/java/org/apache/parquet/format/LogicalTypes.java": 55,
                "parquet-format-structures/src/main/java/org/apache/parquet/format/MetadataValidator.java": 44,
                "parquet-format-structures/src/main/java/org/apache/parquet/format/Util.java": 389,
                "parquet-format-structures/src/main/java/org/apache/parquet/format/event/Consumers.java": 191,
                "parquet-format-structures/src/main/java/org/apache/parquet/format/event/EventBasedThriftReader.java": 126,
                "parquet-format-structures/src/main/java/org/apache/parquet/format/event/FieldConsumer.java": 39,
                "parquet-format-structures/src/main/java/org/apache/parquet/format/event/TypedConsumer.java": 205,
                "parquet-format-structures/src/test/java/org/apache/parquet/format/TestUtil.java": 101,
                "parquet-generator/src/main/java/org/apache/parquet/encoding/Generator.java": 34,
                "parquet-generator/src/main/java/org/apache/parquet/encoding/bitpacking/ByteBasedBitPackingGenerator.java": 319,
                "parquet-generator/src/main/java/org/apache/parquet/encoding/bitpacking/IntBasedBitPackingGenerator.java": 208,
                "parquet-generator/src/main/java/org/apache/parquet/filter2/Generator.java": 28,
                "parquet-generator/src/main/java/org/apache/parquet/filter2/IncrementallyUpdatedFilterPredicateGenerator.java": 335,
                "parquet-generator/src/main/java/org/apache/parquet/version/Generator.java": 28,
                "parquet-generator/src/main/java/org/apache/parquet/version/VersionGenerator.java": 87,
                "parquet-hadoop/src/main/java/org/apache/parquet/HadoopReadOptions.java": 143,
                "parquet-hadoop/src/main/java/org/apache/parquet/ParquetReadOptions.java": 345,
                "parquet-hadoop/src/main/java/org/apache/parquet/crypto/AADPrefixVerifier.java": 32,
                "parquet-hadoop/src/main/java/org/apache/parquet/crypto/AesCipher.java": 164,
                "parquet-hadoop/src/main/java/org/apache/parquet/crypto/AesCtrDecryptor.java": 170,
                "parquet-hadoop/src/main/java/org/apache/parquet/crypto/AesCtrEncryptor.java": 104,
                "parquet-hadoop/src/main/java/org/apache/parquet/crypto/AesGcmDecryptor.java": 151,
                "parquet-hadoop/src/main/java/org/apache/parquet/crypto/AesGcmEncryptor.java": 91,
                "parquet-hadoop/src/main/java/org/apache/parquet/crypto/AesMode.java": 35,
                "parquet-hadoop/src/main/java/org/apache/parquet/crypto/ColumnDecryptionProperties.java": 104,
                "parquet-hadoop/src/main/java/org/apache/parquet/crypto/ColumnEncryptionProperties.java": 195,
                "parquet-hadoop/src/main/java/org/apache/parquet/crypto/DecryptionKeyRetriever.java": 39,
                "parquet-hadoop/src/main/java/org/apache/parquet/crypto/DecryptionPropertiesFactory.java": 88,
                "parquet-hadoop/src/main/java/org/apache/parquet/crypto/EncryptionPropertiesFactory.java": 93,
                "parquet-hadoop/src/main/java/org/apache/parquet/crypto/FileDecryptionProperties.java": 254,
                "parquet-hadoop/src/main/java/org/apache/parquet/crypto/FileEncryptionProperties.java": 278,
                "parquet-hadoop/src/main/java/org/apache/parquet/crypto/InternalColumnDecryptionSetup.java": 74,
                "parquet-hadoop/src/main/java/org/apache/parquet/crypto/InternalColumnEncryptionSetup.java": 82,
                "parquet-hadoop/src/main/java/org/apache/parquet/crypto/InternalFileDecryptor.java": 312,
                "parquet-hadoop/src/main/java/org/apache/parquet/crypto/InternalFileEncryptor.java": 200,
                "parquet-hadoop/src/main/java/org/apache/parquet/crypto/KeyAccessDeniedException.java": 39,
                "parquet-hadoop/src/main/java/org/apache/parquet/crypto/ModuleCipherFactory.java": 73,
                "parquet-hadoop/src/main/java/org/apache/parquet/crypto/ParquetCipher.java": 42,
                "parquet-hadoop/src/main/java/org/apache/parquet/crypto/ParquetCryptoRuntimeException.java": 42,
                "parquet-hadoop/src/main/java/org/apache/parquet/crypto/TagVerificationException.java": 39,
                "parquet-hadoop/src/main/java/org/apache/parquet/crypto/keytools/FileKeyMaterialStore.java": 72,
                "parquet-hadoop/src/main/java/org/apache/parquet/crypto/keytools/FileKeyUnwrapper.java": 178,
                "parquet-hadoop/src/main/java/org/apache/parquet/crypto/keytools/FileKeyWrapper.java": 177,
                "parquet-hadoop/src/main/java/org/apache/parquet/crypto/keytools/HadoopFSKeyMaterialStore.java": 136,
                "parquet-hadoop/src/main/java/org/apache/parquet/crypto/keytools/KeyMaterial.java": 210,
                "parquet-hadoop/src/main/java/org/apache/parquet/crypto/keytools/KeyMetadata.java": 130,
                "parquet-hadoop/src/main/java/org/apache/parquet/crypto/keytools/KeyToolkit.java": 394,
                "parquet-hadoop/src/main/java/org/apache/parquet/crypto/keytools/KmsClient.java": 72,
                "parquet-hadoop/src/main/java/org/apache/parquet/crypto/keytools/LocalWrapKmsClient.java": 181,
                "parquet-hadoop/src/main/java/org/apache/parquet/crypto/keytools/PropertiesDrivenCryptoFactory.java": 258,
                "parquet-hadoop/src/main/java/org/apache/parquet/crypto/keytools/TwoLevelCacheWithExpiration.java": 105,
                "parquet-hadoop/src/main/java/org/apache/parquet/filter2/bloomfilterlevel/BloomFilterImpl.java": 187,
                "parquet-hadoop/src/main/java/org/apache/parquet/filter2/compat/RowGroupFilter.java": 131,
                "parquet-hadoop/src/main/java/org/apache/parquet/filter2/dictionarylevel/DictionaryFilter.java": 570,
                "parquet-hadoop/src/main/java/org/apache/parquet/filter2/statisticslevel/StatisticsFilter.java": 485,
                "parquet-hadoop/src/main/java/org/apache/parquet/format/converter/ParquetMetadataConverter.java": 2080,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/BadConfigurationException.java": 44,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/BloomFilterReader.java": 70,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/CodecFactory.java": 289,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ColumnChunkPageReadStore.java": 364,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ColumnChunkPageWriteStore.java": 462,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ColumnConfigParser.java": 72,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ColumnIndexFilterUtils.java": 162,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ColumnIndexStoreImpl.java": 155,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ColumnIndexValidator.java": 613,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/DictionaryPageReader.java": 115,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/DirectCodecFactory.java": 528,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/DirectZstd.java": 144,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/Footer.java": 53,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/InternalParquetRecordReader.java": 321,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/InternalParquetRecordWriter.java": 209,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/LruCache.java": 195,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/MemoryManager.java": 199,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/Offsets.java": 94,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ParquetEmptyBlockException.java": 41,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ParquetFileReader.java": 1869,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ParquetFileWriter.java": 1731,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ParquetInputFormat.java": 837,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ParquetInputSplit.java": 295,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ParquetMemoryManagerRuntimeException.java": 38,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ParquetOutputCommitter.java": 112,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ParquetOutputFormat.java": 570,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ParquetReader.java": 379,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ParquetRecordReader.java": 233,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ParquetRecordWriter.java": 184,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ParquetWriter.java": 744,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/PrintFooter.java": 265,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/UnmaterializableRecordCounter.java": 103,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/api/DelegatingReadSupport.java": 60,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/api/DelegatingWriteSupport.java": 69,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/api/InitContext.java": 99,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/api/ReadSupport.java": 145,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/api/WriteSupport.java": 140,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/api/package-info.java": 27,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/codec/CleanUtil.java": 111,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/codec/CodecConfig.java": 167,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/codec/Lz4RawCodec.java": 112,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/codec/Lz4RawCompressor.java": 44,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/codec/Lz4RawDecompressor.java": 46,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/codec/NonBlockedCompressor.java": 192,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/codec/NonBlockedCompressorStream.java": 50,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/codec/NonBlockedDecompressor.java": 180,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/codec/NonBlockedDecompressorStream.java": 57,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/codec/SnappyCodec.java": 105,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/codec/SnappyCompressor.java": 38,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/codec/SnappyDecompressor.java": 38,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/codec/SnappyUtil.java": 33,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/codec/ZstandardCodec.java": 130,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/codec/ZstdCompressorStream.java": 70,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/codec/ZstdDecompressorStream.java": 62,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/example/ExampleInputFormat.java": 35,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/example/ExampleOutputFormat.java": 58,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/example/ExampleParquetWriter.java": 118,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/example/GroupReadSupport.java": 49,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/example/GroupWriteSupport.java": 88,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/mapred/Container.java": 37,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/mapred/DeprecatedParquetInputFormat.java": 209,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/mapred/DeprecatedParquetOutputFormat.java": 119,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/mapred/MapredParquetOutputCommitter.java": 42,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/metadata/BlockMetaData.java": 153,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/metadata/ColumnChunkMetaData.java": 683,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/metadata/ColumnChunkProperties.java": 118,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/metadata/ConcatenatingKeyValueMetadataMergeStrategy.java": 61,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/metadata/EncodingList.java": 81,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/metadata/FileMetaData.java": 108,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/metadata/GlobalMetaData.java": 110,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/metadata/KeyValueMetadataMergeStrategy.java": 42,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/metadata/ParquetMetadata.java": 134,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/metadata/StrictKeyValueMetadataMergeStrategy.java": 42,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/package-info.java": 33,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/rewrite/MaskMode.java": 38,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/rewrite/ParquetRewriter.java": 819,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/rewrite/RewriteOptions.java": 262,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/util/ColumnEncryptor.java": 90,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/util/ColumnMasker.java": 98,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/util/ColumnPruner.java": 42,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/util/CompressionConverter.java": 81,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/util/ConfigurationUtil.java": 44,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/util/ContextUtil.java": 315,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/util/H1SeekableInputStream.java": 59,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/util/H2SeekableInputStream.java": 99,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/util/HadoopCodecs.java": 39,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/util/HadoopInputFile.java": 76,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/util/HadoopOutputFile.java": 105,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/util/HadoopPositionOutputStream.java": 66,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/util/HadoopStreams.java": 148,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/util/HiddenFileFilter.java": 39,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/util/SerializationUtil.java": 93,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/util/counters/BenchmarkCounter.java": 112,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/util/counters/CounterLoader.java": 27,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/util/counters/ICounter.java": 28,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/util/counters/mapred/MapRedCounterAdapter.java": 43,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/util/counters/mapred/MapRedCounterLoader.java": 51,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/util/counters/mapreduce/MapReduceCounterAdapter.java": 44,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/util/counters/mapreduce/MapReduceCounterLoader.java": 47,
                "parquet-hadoop/src/main/java/org/apache/parquet/internal/hadoop/metadata/IndexReference.java": 41,
                "parquet-hadoop/src/test/java/org/apache/parquet/DirectWriterTest.java": 102,
                "parquet-hadoop/src/test/java/org/apache/parquet/crypto/DecryptionKeyRetrieverMock.java": 41,
                "parquet-hadoop/src/test/java/org/apache/parquet/crypto/DecryptionPropertiesFactoryTest.java": 43,
                "parquet-hadoop/src/test/java/org/apache/parquet/crypto/EncryptionPropertiesFactoryTest.java": 45,
                "parquet-hadoop/src/test/java/org/apache/parquet/crypto/SampleDecryptionPropertiesFactory.java": 57,
                "parquet-hadoop/src/test/java/org/apache/parquet/crypto/SampleEncryptionPropertiesFactory.java": 58,
                "parquet-hadoop/src/test/java/org/apache/parquet/crypto/SingleRow.java": 139,
                "parquet-hadoop/src/test/java/org/apache/parquet/crypto/TestPropertiesDrivenEncryption.java": 705,
                "parquet-hadoop/src/test/java/org/apache/parquet/crypto/keytools/mocks/InMemoryKMS.java": 116,
                "parquet-hadoop/src/test/java/org/apache/parquet/crypto/keytools/mocks/LocalWrapInMemoryKMS.java": 79,
                "parquet-hadoop/src/test/java/org/apache/parquet/crypto/keytools/samples/VaultClient.java": 184,
                "parquet-hadoop/src/test/java/org/apache/parquet/crypto/propertiesfactory/SchemaControlEncryptionTest.java": 250,
                "parquet-hadoop/src/test/java/org/apache/parquet/crypto/propertiesfactory/SchemaCryptoPropertiesFactory.java": 137,
                "parquet-hadoop/src/test/java/org/apache/parquet/encodings/FileEncodingsIT.java": 564,
                "parquet-hadoop/src/test/java/org/apache/parquet/filter2/TestFiltersWithMissingColumns.java": 275,
                "parquet-hadoop/src/test/java/org/apache/parquet/filter2/compat/TestRowGroupFilter.java": 128,
                "parquet-hadoop/src/test/java/org/apache/parquet/filter2/dictionarylevel/DictionaryFilterTest.java": 839,
                "parquet-hadoop/src/test/java/org/apache/parquet/filter2/recordlevel/PhoneBookWriter.java": 373,
                "parquet-hadoop/src/test/java/org/apache/parquet/filter2/recordlevel/TestRecordLevelFilters.java": 310,
                "parquet-hadoop/src/test/java/org/apache/parquet/filter2/statisticslevel/TestStatisticsFilter.java": 561,
                "parquet-hadoop/src/test/java/org/apache/parquet/format/converter/TestParquetMetadataConverter.java": 1389,
                "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/DeprecatedInputFormatTest.java": 346,
                "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/DeprecatedOutputFormatTest.java": 108,
                "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/ITTestEncryptionOptions.java": 50,
                "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/TestAdaptiveBlockSplitBloomFiltering.java": 78,
                "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/TestBloomFiltering.java": 421,
                "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/TestColumnChunkPageWriteStore.java": 288,
                "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/TestColumnIndexFiltering.java": 617,
                "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/TestDataPageV1Checksums.java": 563,
                "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/TestDirectCodecFactory.java": 178,
                "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/TestEncryptionOptions.java": 752,
                "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/TestInputFormat.java": 555,
                "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/TestInputFormatColumnProjection.java": 180,
                "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/TestInputOutputFormatWithPadding.java": 214,
                "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/TestLargeColumnChunk.java": 145,
                "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/TestLruCache.java": 162,
                "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/TestMemoryManager.java": 189,
                "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/TestMergeMetadataFiles.java": 221,
                "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/TestMultipleWriteRead.java": 250,
                "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/TestParquetFileWriter.java": 1218,
                "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/TestParquetOutputFormatJobSummaryLevel.java": 69,
                "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/TestParquetReader.java": 198,
                "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/TestParquetReaderEmptyBlock.java": 170,
                "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/TestParquetReaderRandomAccess.java": 387,
                "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/TestParquetWriter.java": 431,
                "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/TestParquetWriterAppendBlocks.java": 361,
                "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/TestParquetWriterNewPage.java": 136,
                "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/TestParquetWriterTruncation.java": 125,
                "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/TestReadWriteEncodingStats.java": 122,
                "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/TestSnappyCodec.java": 140,
                "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/TestStoreBloomFilter.java": 132,
                "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/TestUtils.java": 85,
                "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/TestZstandardCodec.java": 173,
                "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/codec/CodecConfigTest.java": 77,
                "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/codec/TestCompressionCodec.java": 177,
                "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/codec/TestInteropReadLz4RawCodec.java": 129,
                "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/example/GroupReadSupportTest.java": 65,
                "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/example/TestInputOutputFormat.java": 364,
                "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/metadata/TestColumnChunkMetaData.java": 83,
                "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/rewrite/ParquetRewriterTest.java": 772,
                "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/util/ColumnEncryptorTest.java": 315,
                "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/util/ColumnMaskerTest.java": 223,
                "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/util/ColumnPrunerTest.java": 246,
                "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/util/CompressionConverterTest.java": 312,
                "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/util/EncDecProperties.java": 94,
                "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/util/EncryptionTestFile.java": 38,
                "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/util/MockHadoopInputStream.java": 87,
                "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/util/TestFileBuilder.java": 198,
                "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/util/TestHadoop2ByteBufferReads.java": 446,
                "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/util/TestSerializationUtil.java": 71,
                "parquet-hadoop/src/test/java/org/apache/parquet/statistics/DataGenerationContext.java": 85,
                "parquet-hadoop/src/test/java/org/apache/parquet/statistics/RandomValues.java": 383,
                "parquet-hadoop/src/test/java/org/apache/parquet/statistics/TestColumnIndexes.java": 304,
                "parquet-hadoop/src/test/java/org/apache/parquet/statistics/TestStatistics.java": 459,
                "parquet-pig/src/main/java/org/apache/parquet/pig/ParquetLoader.java": 575,
                "parquet-pig/src/main/java/org/apache/parquet/pig/ParquetStorer.java": 152,
                "parquet-pig/src/main/java/org/apache/parquet/pig/PigMetaData.java": 91,
                "parquet-pig/src/main/java/org/apache/parquet/pig/PigSchemaConverter.java": 551,
                "parquet-pig/src/main/java/org/apache/parquet/pig/SchemaConversionException.java": 44,
                "parquet-pig/src/main/java/org/apache/parquet/pig/TupleConversionException.java": 42,
                "parquet-pig/src/main/java/org/apache/parquet/pig/TupleReadSupport.java": 191,
                "parquet-pig/src/main/java/org/apache/parquet/pig/TupleWriteSupport.java": 209,
                "parquet-pig/src/main/java/org/apache/parquet/pig/convert/DecimalUtils.java": 65,
                "parquet-pig/src/main/java/org/apache/parquet/pig/convert/MapConverter.java": 190,
                "parquet-pig/src/main/java/org/apache/parquet/pig/convert/ParentValueContainer.java": 32,
                "parquet-pig/src/main/java/org/apache/parquet/pig/convert/TupleConverter.java": 592,
                "parquet-pig/src/main/java/org/apache/parquet/pig/convert/TupleRecordMaterializer.java": 50,
                "parquet-pig/src/main/java/org/apache/parquet/pig/summary/BagSummaryData.java": 72,
                "parquet-pig/src/main/java/org/apache/parquet/pig/summary/EnumStat.java": 115,
                "parquet-pig/src/main/java/org/apache/parquet/pig/summary/FieldSummaryData.java": 178,
                "parquet-pig/src/main/java/org/apache/parquet/pig/summary/MapSummaryData.java": 85,
                "parquet-pig/src/main/java/org/apache/parquet/pig/summary/NumberSummaryData.java": 47,
                "parquet-pig/src/main/java/org/apache/parquet/pig/summary/StringSummaryData.java": 82,
                "parquet-pig/src/main/java/org/apache/parquet/pig/summary/Summary.java": 224,
                "parquet-pig/src/main/java/org/apache/parquet/pig/summary/SummaryData.java": 135,
                "parquet-pig/src/main/java/org/apache/parquet/pig/summary/TupleSummaryData.java": 98,
                "parquet-pig/src/main/java/org/apache/parquet/pig/summary/ValueStat.java": 64,
                "parquet-pig/src/test/java/org/apache/parquet/pig/PerfTest.java": 104,
                "parquet-pig/src/test/java/org/apache/parquet/pig/PerfTest2.java": 185,
                "parquet-pig/src/test/java/org/apache/parquet/pig/PerfTestReadAllCols.java": 47,
                "parquet-pig/src/test/java/org/apache/parquet/pig/TestDecimalUtils.java": 79,
                "parquet-pig/src/test/java/org/apache/parquet/pig/TestParquetLoader.java": 367,
                "parquet-pig/src/test/java/org/apache/parquet/pig/TestParquetStorer.java": 264,
                "parquet-pig/src/test/java/org/apache/parquet/pig/TestPigSchemaConverter.java": 291,
                "parquet-pig/src/test/java/org/apache/parquet/pig/TestTupleRecordConsumer.java": 210,
                "parquet-pig/src/test/java/org/apache/parquet/pig/TupleConsumerPerfTest.java": 206,
                "parquet-pig/src/test/java/org/apache/parquet/pig/summary/TestSummary.java": 158,
                "parquet-plugins/parquet-encoding-vector/src/main/java/org/apache/parquet/column/values/bitpacking/ByteBitPacking512VectorLE.java": 3010,
                "parquet-plugins/parquet-encoding-vector/src/main/java/org/apache/parquet/column/values/bitpacking/ParquetReadRouter.java": 133,
                "parquet-plugins/parquet-encoding-vector/src/main/java/org/apache/parquet/column/values/bitpacking/VectorSupport.java": 27,
                "parquet-plugins/parquet-encoding-vector/src/test/java/org/apache/parquet/column/values/bitpacking/TestByteBitPacking512VectorLE.java": 169,
                "parquet-plugins/parquet-encoding-vector/src/test/java/org/apache/parquet/column/values/bitpacking/TestParquetReadRouter.java": 59,
                "parquet-plugins/parquet-plugins-benchmarks/src/main/java/org/apache/parquet/plugins/benchmarks/ByteBitPackingVectorBenchmarks.java": 92,
                "parquet-protobuf/src/main/java/org/apache/parquet/proto/ProtoConstants.java": 46,
                "parquet-protobuf/src/main/java/org/apache/parquet/proto/ProtoMessageConverter.java": 599,
                "parquet-protobuf/src/main/java/org/apache/parquet/proto/ProtoParquetInputFormat.java": 38,
                "parquet-protobuf/src/main/java/org/apache/parquet/proto/ProtoParquetOutputFormat.java": 52,
                "parquet-protobuf/src/main/java/org/apache/parquet/proto/ProtoParquetReader.java": 101,
                "parquet-protobuf/src/main/java/org/apache/parquet/proto/ProtoParquetWriter.java": 127,
                "parquet-protobuf/src/main/java/org/apache/parquet/proto/ProtoReadSupport.java": 97,
                "parquet-protobuf/src/main/java/org/apache/parquet/proto/ProtoRecordConverter.java": 100,
                "parquet-protobuf/src/main/java/org/apache/parquet/proto/ProtoRecordMaterializer.java": 47,
                "parquet-protobuf/src/main/java/org/apache/parquet/proto/ProtoSchemaConverter.java": 297,
                "parquet-protobuf/src/main/java/org/apache/parquet/proto/ProtoWriteSupport.java": 586,
                "parquet-protobuf/src/test/java/org/apache/parquet/proto/ProtoInputOutputFormatTest.java": 618,
                "parquet-protobuf/src/test/java/org/apache/parquet/proto/ProtoRecordConverterTest.java": 363,
                "parquet-protobuf/src/test/java/org/apache/parquet/proto/ProtoSchemaConverterTest.java": 539,
                "parquet-protobuf/src/test/java/org/apache/parquet/proto/ProtoSchemaEvolutionTest.java": 133,
                "parquet-protobuf/src/test/java/org/apache/parquet/proto/ProtoWriteSupportTest.java": 1204,
                "parquet-protobuf/src/test/java/org/apache/parquet/proto/TestUtils.java": 232,
                "parquet-protobuf/src/test/java/org/apache/parquet/proto/utils/ReadUsingMR.java": 94,
                "parquet-protobuf/src/test/java/org/apache/parquet/proto/utils/WriteUsingMR.java": 121,
                "parquet-thrift/src/main/java/org/apache/parquet/hadoop/thrift/AbstractThriftWriteSupport.java": 129,
                "parquet-thrift/src/main/java/org/apache/parquet/hadoop/thrift/ParquetThriftBytesOutputFormat.java": 96,
                "parquet-thrift/src/main/java/org/apache/parquet/hadoop/thrift/ParquetThriftInputFormat.java": 66,
                "parquet-thrift/src/main/java/org/apache/parquet/hadoop/thrift/ParquetThriftOutputFormat.java": 43,
                "parquet-thrift/src/main/java/org/apache/parquet/hadoop/thrift/TBaseWriteSupport.java": 70,
                "parquet-thrift/src/main/java/org/apache/parquet/hadoop/thrift/ThriftBytesWriteSupport.java": 196,
                "parquet-thrift/src/main/java/org/apache/parquet/hadoop/thrift/ThriftReadSupport.java": 289,
                "parquet-thrift/src/main/java/org/apache/parquet/hadoop/thrift/ThriftToParquetFileWriter.java": 125,
                "parquet-thrift/src/main/java/org/apache/parquet/hadoop/thrift/ThriftWriteSupport.java": 80,
                "parquet-thrift/src/main/java/org/apache/parquet/thrift/BufferedProtocolReadToWrite.java": 738,
                "parquet-thrift/src/main/java/org/apache/parquet/thrift/ConvertedField.java": 169,
                "parquet-thrift/src/main/java/org/apache/parquet/thrift/DecodingSchemaMismatchException.java": 30,
                "parquet-thrift/src/main/java/org/apache/parquet/thrift/FieldIgnoredHandler.java": 45,
                "parquet-thrift/src/main/java/org/apache/parquet/thrift/KeepOnlyFirstPrimitiveFilter.java": 44,
                "parquet-thrift/src/main/java/org/apache/parquet/thrift/ParquetProtocol.java": 282,
                "parquet-thrift/src/main/java/org/apache/parquet/thrift/ParquetReadProtocol.java": 164,
                "parquet-thrift/src/main/java/org/apache/parquet/thrift/ParquetWriteProtocol.java": 778,
                "parquet-thrift/src/main/java/org/apache/parquet/thrift/ProtocolPipe.java": 29,
                "parquet-thrift/src/main/java/org/apache/parquet/thrift/ProtocolReadToWrite.java": 142,
                "parquet-thrift/src/main/java/org/apache/parquet/thrift/SkippableException.java": 47,
                "parquet-thrift/src/main/java/org/apache/parquet/thrift/TBaseRecordConverter.java": 61,
                "parquet-thrift/src/main/java/org/apache/parquet/thrift/ThriftMetaData.java": 147,
                "parquet-thrift/src/main/java/org/apache/parquet/thrift/ThriftParquetReader.java": 139,
                "parquet-thrift/src/main/java/org/apache/parquet/thrift/ThriftParquetWriter.java": 52,
                "parquet-thrift/src/main/java/org/apache/parquet/thrift/ThriftReader.java": 28,
                "parquet-thrift/src/main/java/org/apache/parquet/thrift/ThriftRecordConverter.java": 954,
                "parquet-thrift/src/main/java/org/apache/parquet/thrift/ThriftSchemaConvertVisitor.java": 409,
                "parquet-thrift/src/main/java/org/apache/parquet/thrift/ThriftSchemaConverter.java": 226,
                "parquet-thrift/src/main/java/org/apache/parquet/thrift/pig/ParquetThriftStorer.java": 90,
                "parquet-thrift/src/main/java/org/apache/parquet/thrift/pig/TupleToThriftWriteSupport.java": 79,
                "parquet-thrift/src/main/java/org/apache/parquet/thrift/projection/FieldProjectionFilter.java": 62,
                "parquet-thrift/src/main/java/org/apache/parquet/thrift/projection/FieldsPath.java": 87,
                "parquet-thrift/src/main/java/org/apache/parquet/thrift/projection/StrictFieldProjectionFilter.java": 187,
                "parquet-thrift/src/main/java/org/apache/parquet/thrift/projection/ThriftProjectionException.java": 45,
                "parquet-thrift/src/main/java/org/apache/parquet/thrift/projection/amend/DefaultEventsVisitor.java": 228,
                "parquet-thrift/src/main/java/org/apache/parquet/thrift/projection/amend/DefaultProtocolEventsGenerator.java": 68,
                "parquet-thrift/src/main/java/org/apache/parquet/thrift/projection/amend/ProtocolEventsAmender.java": 171,
                "parquet-thrift/src/main/java/org/apache/parquet/thrift/projection/amend/ReadFieldBeginProtocol.java": 44,
                "parquet-thrift/src/main/java/org/apache/parquet/thrift/projection/deprecated/DeprecatedFieldProjectionFilter.java": 106,
                "parquet-thrift/src/main/java/org/apache/parquet/thrift/projection/deprecated/PathGlobPattern.java": 173,
                "parquet-thrift/src/main/java/org/apache/parquet/thrift/struct/CompatibilityChecker.java": 265,
                "parquet-thrift/src/main/java/org/apache/parquet/thrift/struct/CompatibilityRunner.java": 104,
                "parquet-thrift/src/main/java/org/apache/parquet/thrift/struct/JSON.java": 50,
                "parquet-thrift/src/main/java/org/apache/parquet/thrift/struct/ThriftField.java": 121,
                "parquet-thrift/src/main/java/org/apache/parquet/thrift/struct/ThriftType.java": 698,
                "parquet-thrift/src/main/java/org/apache/parquet/thrift/struct/ThriftTypeID.java": 108,
                "parquet-thrift/src/test/java/org/apache/parquet/hadoop/thrift/TestArrayCompatibility.java": 779,
                "parquet-thrift/src/test/java/org/apache/parquet/hadoop/thrift/TestBinary.java": 86,
                "parquet-thrift/src/test/java/org/apache/parquet/hadoop/thrift/TestCorruptThriftRecords.java": 213,
                "parquet-thrift/src/test/java/org/apache/parquet/hadoop/thrift/TestInputOutputFormat.java": 258,
                "parquet-thrift/src/test/java/org/apache/parquet/hadoop/thrift/TestParquetToThriftReadWriteAndProjection.java": 385,
                "parquet-thrift/src/test/java/org/apache/parquet/hadoop/thrift/TestThriftToParquetFileWriter.java": 360,
                "parquet-thrift/src/test/java/org/apache/parquet/thrift/TestParquetReadProtocol.java": 173,
                "parquet-thrift/src/test/java/org/apache/parquet/thrift/TestParquetWriteProtocol.java": 719,
                "parquet-thrift/src/test/java/org/apache/parquet/thrift/TestProtocolReadToWrite.java": 384,
                "parquet-thrift/src/test/java/org/apache/parquet/thrift/TestThriftMetaData.java": 56,
                "parquet-thrift/src/test/java/org/apache/parquet/thrift/TestThriftParquetReaderWriter.java": 83,
                "parquet-thrift/src/test/java/org/apache/parquet/thrift/TestThriftRecordConverter.java": 101,
                "parquet-thrift/src/test/java/org/apache/parquet/thrift/TestThriftSchemaConvertVisitor.java": 178,
                "parquet-thrift/src/test/java/org/apache/parquet/thrift/TestThriftSchemaConverter.java": 353,
                "parquet-thrift/src/test/java/org/apache/parquet/thrift/TestThriftSchemaConverterProjectUnion.java": 480,
                "parquet-thrift/src/test/java/org/apache/parquet/thrift/TestThriftToPigCompatibility.java": 171,
                "parquet-thrift/src/test/java/org/apache/parquet/thrift/pig/TestParquetThriftStorer.java": 82,
                "parquet-thrift/src/test/java/org/apache/parquet/thrift/projection/TestFieldsPath.java": 162,
                "parquet-thrift/src/test/java/org/apache/parquet/thrift/projection/TestStrictFieldProjectionFilter.java": 119,
                "parquet-thrift/src/test/java/org/apache/parquet/thrift/projection/deprecated/PathGlobPatternTest.java": 59,
                "parquet-thrift/src/test/java/org/apache/parquet/thrift/struct/CompatibilityCheckerTest.java": 132,
                "parquet-thrift/src/test/java/org/apache/parquet/thrift/struct/TestThriftType.java": 70
            },
            "is_test": true,
            "is_fix": false
        },
        "a8c10efccf35977193cab80b0f17d6a2f7d066d9": {
            "datetime": "2012-08-31T15:37:32-07:00",
            "summary": "initial commit",
            "message": "initial commit\n",
            "diff": {
                "redelm-column/src/main/java/redelm/Log.java": 10,
                "redelm-column/src/main/java/redelm/column/ColumnDescriptor.java": 51,
                "redelm-column/src/main/java/redelm/column/ColumnReader.java": 22,
                "redelm-column/src/main/java/redelm/column/ColumnWriter.java": 15,
                "redelm-column/src/main/java/redelm/column/ColumnsStore.java": 13,
                "redelm-column/src/main/java/redelm/column/mem/MemColumn.java": 186,
                "redelm-column/src/main/java/redelm/column/mem/MemColumnsStore.java": 167,
                "redelm-column/src/main/java/redelm/data/Group.java": 41,
                "redelm-column/src/main/java/redelm/data/GroupFactory.java": 7,
                "redelm-column/src/main/java/redelm/data/GroupValueSource.java": 20,
                "redelm-column/src/main/java/redelm/io/ColumnIO.java": 109,
                "redelm-column/src/main/java/redelm/io/ColumnIOFactory.java": 83,
                "redelm-column/src/main/java/redelm/io/GroupColumnIO.java": 105,
                "redelm-column/src/main/java/redelm/io/MessageColumnIO.java": 47,
                "redelm-column/src/main/java/redelm/io/PrimitiveColumnIO.java": 88,
                "redelm-column/src/main/java/redelm/io/RecordConsumer.java": 17,
                "redelm-column/src/main/java/redelm/io/RecordConsumerWrapper.java": 96,
                "redelm-column/src/main/java/redelm/io/RecordReader.java": 195,
                "redelm-column/src/main/java/redelm/io/RecordWriter.java": 26,
                "redelm-column/src/main/java/redelm/schema/GroupType.java": 92,
                "redelm-column/src/main/java/redelm/schema/MessageType.java": 22,
                "redelm-column/src/main/java/redelm/schema/PrimitiveType.java": 150,
                "redelm-column/src/main/java/redelm/schema/Type.java": 65,
                "redelm-column/src/main/java/redelm/schema/TypeVisitor.java": 7,
                "redelm-column/src/test/java/redelm/column/mem/TestMemColumn.java": 55,
                "redelm-column/src/test/java/redelm/data/simple/BinaryValue.java": 16,
                "redelm-column/src/test/java/redelm/data/simple/BoolValue.java": 19,
                "redelm-column/src/test/java/redelm/data/simple/IntValue.java": 21,
                "redelm-column/src/test/java/redelm/data/simple/Primitive.java": 23,
                "redelm-column/src/test/java/redelm/data/simple/SimpleGroup.java": 141,
                "redelm-column/src/test/java/redelm/data/simple/SimpleGroupFactory.java": 20,
                "redelm-column/src/test/java/redelm/data/simple/StringValue.java": 25,
                "redelm-column/src/test/java/redelm/io/PerfTest.java": 80,
                "redelm-column/src/test/java/redelm/io/TestColumnIO.java": 254,
                "redelm-pig/src/main/java/redelm/pig/RedelmLoader.java": 108,
                "redelm-pig/src/main/java/redelm/pig/TupleRecordConsumer.java": 102,
                "redelm-pig/src/test/java/redelm/pig/TestTupleRecordConsumer.java": 20,
                "redelm-thrift/src/main/java/redelm/thrift/SchemaConverter.java": 116,
                "redelm-thrift/src/main/java/redelm/thrift/ThriftConverter.java": 82,
                "redelm-thrift/src/main/java/redelm/thrift/ThriftRandomGenerator.java": 102
            },
            "is_test": true,
            "is_fix": false
        },
        "5fb63e9a0743a23735f5b6043abd202a85173202": {
            "datetime": "2012-09-08T11:13:43-07:00",
            "summary": "refactoring tuples to use indices instead of field names",
            "message": "refactoring tuples to use indices instead of field names\n",
            "diff": {
                "redelm-column/src/main/java/redelm/Log.java": 2,
                "redelm-column/src/main/java/redelm/column/ColumnReader.java": 4,
                "redelm-column/src/main/java/redelm/column/mem/MemColumn.java": 2,
                "redelm-column/src/main/java/redelm/data/Group.java": 45,
                "redelm-column/src/main/java/redelm/data/GroupValueSource.java": 36,
                "redelm-column/src/main/java/redelm/io/ColumnIO.java": 12,
                "redelm-column/src/main/java/redelm/io/GroupColumnIO.java": 11,
                "redelm-column/src/main/java/redelm/io/MessageColumnIO.java": 2,
                "redelm-column/src/main/java/redelm/io/PrimitiveColumnIO.java": 4,
                "redelm-column/src/main/java/redelm/io/RecordConsumer.java": 8,
                "redelm-column/src/main/java/redelm/io/RecordConsumerWrapper.java": 20,
                "redelm-column/src/main/java/redelm/io/RecordReader.java": 161,
                "redelm-column/src/main/java/redelm/schema/PrimitiveType.java": 27,
                "redelm-column/src/test/java/redelm/data/simple/SimpleGroup.java": 67,
                "redelm-column/src/test/java/redelm/io/PerfTest.java": 27,
                "redelm-column/src/test/java/redelm/io/TestColumnIO.java": 24
            },
            "is_test": true,
            "is_fix": false
        },
        "741c6fd77e6ccbebf47eacf021e68379d5063d53": {
            "datetime": "2012-09-08T11:30:01-07:00",
            "summary": "adding push parser test",
            "message": "adding push parser test\n",
            "diff": {
                "redelm-column/src/test/java/redelm/io/TestColumnIO.java": 138
            },
            "is_test": true,
            "is_fix": false
        },
        "a1a04d51312b169e5f2576c146351c67366a6212": {
            "datetime": "2012-09-10T08:35:12-07:00",
            "summary": "move closing records at the begining of the loop",
            "message": "move closing records at the begining of the loop\n",
            "diff": {
                "redelm-column/src/main/java/redelm/io/RecordReader.java": 94,
                "redelm-column/src/test/java/redelm/io/TestColumnIO.java": 130
            },
            "is_test": true,
            "is_fix": false
        },
        "9b68b394fa8f8b339db1b85b5eb1ab744c89ca5c": {
            "datetime": "2012-09-11T16:38:32-07:00",
            "summary": "make field started and ended only once when value is repeated, refactor out SimpleGroupRecordConsumer",
            "message": "make field started and ended only once when value is repeated, refactor out SimpleGroupRecordConsumer\n",
            "diff": {
                "redelm-column/src/main/java/redelm/Log.java": 2,
                "redelm-column/src/main/java/redelm/io/RecordReader.java": 210,
                "redelm-column/src/test/java/redelm/data/simple/SimpleGroupRecordConsumer.java": 76,
                "redelm-column/src/test/java/redelm/io/PerfTest.java": 103,
                "redelm-column/src/test/java/redelm/io/TestColumnIO.java": 58
            },
            "is_test": true,
            "is_fix": false
        },
        "34124edc109127e0819d859fce91df960256571d": {
            "datetime": "2012-09-11T16:42:46-07:00",
            "summary": "remove depedency on Group from RecordReader",
            "message": "remove depedency on Group from RecordReader\n",
            "diff": {
                "redelm-column/src/main/java/redelm/io/ColumnIOFactory.java": 7,
                "redelm-column/src/main/java/redelm/io/MessageColumnIO.java": 6,
                "redelm-column/src/main/java/redelm/io/RecordReader.java": 7,
                "redelm-column/src/test/java/redelm/io/PerfTest.java": 0,
                "redelm-column/src/test/java/redelm/io/TestColumnIO.java": 8
            },
            "is_test": true,
            "is_fix": false
        },
        "968fd551c58a091b5b13387038c57b15035a198e": {
            "datetime": "2012-09-13T15:41:03-07:00",
            "summary": "remove dependency on group from the io implementation",
            "message": "remove dependency on group from the io implementation\n",
            "diff": {
                "redelm-column/src/main/java/redelm/Log.java": 130,
                "redelm-column/src/main/java/redelm/data/GroupWriter.java": 46,
                "redelm-column/src/main/java/redelm/io/ColumnIO.java": 19,
                "redelm-column/src/main/java/redelm/io/ColumnIOFactory.java": 1,
                "redelm-column/src/main/java/redelm/io/GroupColumnIO.java": 22,
                "redelm-column/src/main/java/redelm/io/MessageColumnIO.java": 144,
                "redelm-column/src/main/java/redelm/io/PrimitiveColumnIO.java": 10,
                "redelm-column/src/main/java/redelm/io/RecordReader.java": 1,
                "redelm-column/src/main/java/redelm/io/RecordWriter.java": 26,
                "redelm-column/src/main/java/redelm/schema/GroupType.java": 2,
                "redelm-column/src/main/java/redelm/schema/PrimitiveType.java": 31,
                "redelm-column/src/test/java/redelm/data/simple/SimpleGroup.java": 5,
                "redelm-column/src/test/java/redelm/data/simple/SimpleGroupRecordConsumer.java": 8,
                "redelm-column/src/test/java/redelm/io/PerfTest.java": 0,
                "redelm-column/src/test/java/redelm/io/TestColumnIO.java": 148
            },
            "is_test": true,
            "is_fix": false
        },
        "c4109e21cac4743062f15d800dbec8366201e98b": {
            "datetime": "2012-09-14T08:09:38-07:00",
            "summary": "fix compilation and dependency issue",
            "message": "fix compilation and dependency issue\n",
            "diff": {
                "redelm-pig/src/main/java/redelm/pig/TupleRecordConsumer.java": 34
            },
            "is_test": false,
            "is_fix": false
        },
        "f689f90b485b23c0cc5076088093ec6977358d09": {
            "datetime": "2012-09-14T08:10:48-07:00",
            "summary": "fix compilation issue",
            "message": "fix compilation issue\n",
            "diff": {
                "redelm-pig/src/main/java/redelm/pig/RedelmLoader.java": 2,
                "redelm-pig/src/test/java/redelm/pig/TestTupleRecordConsumer.java": 5
            },
            "is_test": true,
            "is_fix": false
        },
        "82e0324ec300f370d5416e8d60999c910998dc58": {
            "datetime": "2012-09-15T15:29:07-07:00",
            "summary": "pig Tuple consumer and writer",
            "message": "pig Tuple consumer and writer\n",
            "diff": {
                "redelm-column/src/main/java/redelm/Log.java": 14,
                "redelm-column/src/main/java/redelm/data/Group.java": 6,
                "redelm-column/src/main/java/redelm/data/GroupRecordConsumer.java": 44,
                "redelm-column/src/main/java/redelm/data/simple/example/Paper.java": 143,
                "redelm-column/src/main/java/redelm/io/GroupColumnIO.java": 4,
                "redelm-column/src/main/java/redelm/io/MessageColumnIO.java": 5,
                "redelm-column/src/main/java/redelm/io/RecordConsumerWrapper.java": 21,
                "redelm-column/src/test/java/redelm/data/simple/BinaryValue.java": 0,
                "redelm-column/src/test/java/redelm/data/simple/BoolValue.java": 0,
                "redelm-column/src/test/java/redelm/data/simple/IntValue.java": 0,
                "redelm-column/src/test/java/redelm/data/simple/Primitive.java": 0,
                "redelm-column/src/test/java/redelm/data/simple/SimpleGroup.java": 0,
                "redelm-column/src/test/java/redelm/data/simple/SimpleGroupFactory.java": 0,
                "redelm-column/src/test/java/redelm/data/simple/StringValue.java": 0,
                "redelm-column/src/test/java/redelm/io/PerfTest.java": 0,
                "redelm-column/src/test/java/redelm/io/TestColumnIO.java": 170,
                "redelm-pig/src/main/java/redelm/pig/TupleRecordConsumer.java": 49,
                "redelm-pig/src/main/java/redelm/pig/TupleWriter.java": 87,
                "redelm-pig/src/test/java/redelm/pig/TestTupleRecordConsumer.java": 42,
                "redelm-thrift/src/main/java/redelm/thrift/ThriftConverter.java": 6,
                "redelm-thrift/src/main/java/redelm/thrift/ThriftSchemaPrinter.java": 58
            },
            "is_test": true,
            "is_fix": false
        },
        "5e9556105c37c4fa4073a7680d8132fa5c9f261d": {
            "datetime": "2012-09-15T15:29:52-07:00",
            "summary": "temporarily removing thrift stuff",
            "message": "temporarily removing thrift stuff\n",
            "diff": {
                "redelm-thrift/src/main/java/redelm/thrift/SchemaConverter.java": 116,
                "redelm-thrift/src/main/java/redelm/thrift/ThriftConverter.java": 82,
                "redelm-thrift/src/main/java/redelm/thrift/ThriftRandomGenerator.java": 102,
                "redelm-thrift/src/main/java/redelm/thrift/ThriftSchemaPrinter.java": 58
            },
            "is_test": false,
            "is_fix": false
        },
        "f2ea25f2097ea0359e9e4ba0815b6f9a63b3359f": {
            "datetime": "2012-09-15T16:51:08-07:00",
            "summary": "turning off logs",
            "message": "turning off logs\n",
            "diff": {
                "redelm-column/src/main/java/redelm/Log.java": 2,
                "redelm-column/src/test/java/redelm/io/PerfTest.java": 0
            },
            "is_test": true,
            "is_fix": false
        },
        "da7ec4896ec365c7778223f11d91544afad8f764": {
            "datetime": "2012-09-26T18:23:47-07:00",
            "summary": "adding license header",
            "message": "adding license header\n",
            "diff": {
                "redelm-column/src/main/java/redelm/Log.java": 15,
                "redelm-column/src/main/java/redelm/column/ColumnDescriptor.java": 15,
                "redelm-column/src/main/java/redelm/column/ColumnReader.java": 15,
                "redelm-column/src/main/java/redelm/column/ColumnWriter.java": 15,
                "redelm-column/src/main/java/redelm/column/ColumnsStore.java": 15,
                "redelm-column/src/main/java/redelm/column/mem/MemColumn.java": 15,
                "redelm-column/src/main/java/redelm/column/mem/MemColumnsStore.java": 15,
                "redelm-column/src/main/java/redelm/data/Group.java": 15,
                "redelm-column/src/main/java/redelm/data/GroupFactory.java": 15,
                "redelm-column/src/main/java/redelm/data/GroupRecordConsumer.java": 15,
                "redelm-column/src/main/java/redelm/data/GroupValueSource.java": 15,
                "redelm-column/src/main/java/redelm/data/GroupWriter.java": 15,
                "redelm-column/src/main/java/redelm/data/simple/BinaryValue.java": 15,
                "redelm-column/src/main/java/redelm/data/simple/BoolValue.java": 15,
                "redelm-column/src/main/java/redelm/data/simple/IntValue.java": 15,
                "redelm-column/src/main/java/redelm/data/simple/Primitive.java": 15,
                "redelm-column/src/main/java/redelm/data/simple/SimpleGroup.java": 15,
                "redelm-column/src/main/java/redelm/data/simple/SimpleGroupFactory.java": 15,
                "redelm-column/src/main/java/redelm/data/simple/StringValue.java": 15,
                "redelm-column/src/main/java/redelm/data/simple/example/Paper.java": 15,
                "redelm-column/src/main/java/redelm/io/ColumnIO.java": 15,
                "redelm-column/src/main/java/redelm/io/ColumnIOFactory.java": 15,
                "redelm-column/src/main/java/redelm/io/GroupColumnIO.java": 15,
                "redelm-column/src/main/java/redelm/io/MessageColumnIO.java": 15,
                "redelm-column/src/main/java/redelm/io/PrimitiveColumnIO.java": 15,
                "redelm-column/src/main/java/redelm/io/RecordConsumer.java": 15,
                "redelm-column/src/main/java/redelm/io/RecordConsumerWrapper.java": 15,
                "redelm-column/src/main/java/redelm/io/RecordReader.java": 15,
                "redelm-column/src/main/java/redelm/schema/GroupType.java": 15,
                "redelm-column/src/main/java/redelm/schema/MessageType.java": 15,
                "redelm-column/src/main/java/redelm/schema/PrimitiveType.java": 15,
                "redelm-column/src/main/java/redelm/schema/Type.java": 15,
                "redelm-column/src/main/java/redelm/schema/TypeVisitor.java": 15,
                "redelm-column/src/test/java/redelm/column/mem/TestMemColumn.java": 15,
                "redelm-column/src/test/java/redelm/io/PerfTest.java": 0,
                "redelm-column/src/test/java/redelm/io/TestColumnIO.java": 15,
                "redelm-pig/src/main/java/redelm/pig/RedelmLoader.java": 15,
                "redelm-pig/src/main/java/redelm/pig/TupleRecordConsumer.java": 15,
                "redelm-pig/src/main/java/redelm/pig/TupleWriter.java": 15,
                "redelm-pig/src/test/java/redelm/pig/TestTupleRecordConsumer.java": 15
            },
            "is_test": true,
            "is_fix": false
        },
        "cf5ba988c56a2b5166dfeaf13743b9a99fb4a552": {
            "datetime": "2012-09-28T09:53:11-07:00",
            "summary": "fix source encoding",
            "message": "fix source encoding\n",
            "diff": {
                "redelm-column/src/test/java/redelm/io/PerfTest.java": 0
            },
            "is_test": true,
            "is_fix": false
        },
        "2302fe4656a799d20e7a86aee10459eabdc82a6f": {
            "datetime": "2012-10-04T08:39:36-07:00",
            "summary": "first version of the Loader/Storer",
            "message": "first version of the Loader/Storer\n",
            "diff": {
                "redelm-column/src/main/java/redelm/column/mem/MemColumn.java": 20,
                "redelm-column/src/main/java/redelm/column/mem/MemColumnsStore.java": 23,
                "redelm-column/src/main/java/redelm/schema/GroupType.java": 4,
                "redelm-column/src/main/java/redelm/schema/MessageType.java": 63,
                "redelm-column/src/main/java/redelm/schema/PrimitiveType.java": 26,
                "redelm-column/src/test/java/redelm/schema/TestMessageType.java": 15,
                "redelm-pig/src/main/java/redelm/pig/BlockMetaData.java": 52,
                "redelm-pig/src/main/java/redelm/pig/ColumnData.java": 28,
                "redelm-pig/src/main/java/redelm/pig/ColumnMetaData.java": 56,
                "redelm-pig/src/main/java/redelm/pig/Footer.java": 80,
                "redelm-pig/src/main/java/redelm/pig/PigSchemaConverter.java": 83,
                "redelm-pig/src/main/java/redelm/pig/RedelmFileReader.java": 65,
                "redelm-pig/src/main/java/redelm/pig/RedelmFileWriter.java": 74,
                "redelm-pig/src/main/java/redelm/pig/RedelmInputFormat.java": 191,
                "redelm-pig/src/main/java/redelm/pig/RedelmInputSplit.java": 103,
                "redelm-pig/src/main/java/redelm/pig/RedelmLoader.java": 96,
                "redelm-pig/src/main/java/redelm/pig/RedelmOutputFormat.java": 92,
                "redelm-pig/src/main/java/redelm/pig/RedelmStorer.java": 87,
                "redelm-pig/src/main/java/redelm/pig/summary/BagSummaryData.java": 64,
                "redelm-pig/src/main/java/redelm/pig/summary/EnumStat.java": 97,
                "redelm-pig/src/main/java/redelm/pig/summary/FieldSummaryData.java": 166,
                "redelm-pig/src/main/java/redelm/pig/summary/MapSummaryData.java": 75,
                "redelm-pig/src/main/java/redelm/pig/summary/NumberSummaryData.java": 32,
                "redelm-pig/src/main/java/redelm/pig/summary/StringSummaryData.java": 66,
                "redelm-pig/src/main/java/redelm/pig/summary/Summary.java": 265,
                "redelm-pig/src/main/java/redelm/pig/summary/SummaryData.java": 141,
                "redelm-pig/src/main/java/redelm/pig/summary/TupleSummaryData.java": 89,
                "redelm-pig/src/main/java/redelm/pig/summary/ValueStat.java": 46,
                "redelm-pig/src/test/java/redelm/pig/TestPigSchemaConverter.java": 27,
                "redelm-pig/src/test/java/redelm/pig/TestRedelmFileWriter.java": 95,
                "redelm-pig/src/test/java/redelm/pig/TestRedelmStorer.java": 112,
                "redelm-pig/src/test/java/redelm/pig/summary/TestSummary.java": 128
            },
            "is_test": true,
            "is_fix": false
        },
        "575c221dbdc572bac7c6c7219cd172f12f62964e": {
            "datetime": "2012-10-04T22:48:09-07:00",
            "summary": "PrintFooter tool",
            "message": "PrintFooter tool\n",
            "diff": {
                "redelm-pig/src/main/java/redelm/pig/BlockMetaData.java": 1,
                "redelm-pig/src/main/java/redelm/pig/Footer.java": 2,
                "redelm-pig/src/main/java/redelm/pig/PrintFooter.java": 27,
                "redelm-pig/src/main/java/redelm/pig/RedelmFileReader.java": 18,
                "redelm-pig/src/main/java/redelm/pig/RedelmFileWriter.java": 10,
                "redelm-pig/src/main/java/redelm/pig/RedelmInputFormat.java": 35,
                "redelm-pig/src/main/java/redelm/pig/RedelmInputSplit.java": 7,
                "redelm-pig/src/main/java/redelm/pig/RedelmLoader.java": 16,
                "redelm-pig/src/main/java/redelm/pig/RedelmOutputFormat.java": 2
            },
            "is_test": false,
            "is_fix": false
        },
        "bdd363578611c60a10d970323a0e0e60281fdaa9": {
            "datetime": "2012-10-08T18:46:13-07:00",
            "summary": "Add some comments and tests",
            "message": "Add some comments and tests\n",
            "diff": {
                "redelm-column/src/main/java/redelm/column/mem/MemColumn.java": 20,
                "redelm-column/src/main/java/redelm/column/mem/MemColumnsStore.java": 23,
                "redelm-column/src/main/java/redelm/schema/GroupType.java": 4,
                "redelm-column/src/main/java/redelm/schema/MessageType.java": 63,
                "redelm-column/src/main/java/redelm/schema/PrimitiveType.java": 26,
                "redelm-column/src/main/java/redelm/schema/Type.java": 4,
                "redelm-column/src/test/java/redelm/io/TestColumnIO.java": 33,
                "redelm-pig/src/main/java/redelm/pig/RedelmLoader.java": 104,
                "redelm-pig/src/main/java/redelm/pig/TupleWriter.java": 5,
                "redelm-pig/src/test/java/redelm/pig/TestTupleRecordConsumer.java": 14
            },
            "is_test": true,
            "is_fix": false
        },
        "40d512bf0ff7aaba12f6eb13acf37d760535572a": {
            "datetime": "2012-10-10T14:18:07-07:00",
            "summary": "work",
            "message": "work\n",
            "diff": {
                "redelm-column/src/main/java/redelm/column/mem/MemColumn.java": 2,
                "redelm-column/src/main/java/redelm/schema/GroupType.java": 36,
                "redelm-column/src/main/java/redelm/schema/MessageType.java": 71,
                "redelm-column/src/main/java/redelm/schema/PrimitiveType.java": 11,
                "redelm-column/src/main/java/redelm/schema/Type.java": 49,
                "redelm-column/src/test/java/redelm/io/TestColumnIO.java": 6
            },
            "is_test": true,
            "is_fix": false
        },
        "591da70b6153261c1aff895dce6f629e997a2966": {
            "datetime": "2012-10-11T11:27:24-07:00",
            "summary": "adding support for Float and Double",
            "message": "adding support for Float and Double\n",
            "diff": {
                "redelm-column/src/main/java/redelm/column/ColumnReader.java": 4,
                "redelm-column/src/main/java/redelm/column/ColumnWriter.java": 4,
                "redelm-column/src/main/java/redelm/column/mem/MemColumn.java": 102,
                "redelm-column/src/main/java/redelm/column/mem/MemColumnsStore.java": 206,
                "redelm-column/src/main/java/redelm/data/Group.java": 7,
                "redelm-column/src/main/java/redelm/data/GroupRecordConsumer.java": 10,
                "redelm-column/src/main/java/redelm/data/GroupWriter.java": 2,
                "redelm-column/src/main/java/redelm/data/simple/BinaryValue.java": 7,
                "redelm-column/src/main/java/redelm/data/simple/BoolValue.java": 7,
                "redelm-column/src/main/java/redelm/data/simple/DoubleValue.java": 23,
                "redelm-column/src/main/java/redelm/data/simple/FloatValue.java": 23,
                "redelm-column/src/main/java/redelm/data/simple/IntValue.java": 7,
                "redelm-column/src/main/java/redelm/data/simple/Primitive.java": 12,
                "redelm-column/src/main/java/redelm/data/simple/SimpleGroup.java": 16,
                "redelm-column/src/main/java/redelm/data/simple/StringValue.java": 7,
                "redelm-column/src/main/java/redelm/io/GroupColumnIO.java": 4,
                "redelm-column/src/main/java/redelm/io/MessageColumnIO.java": 24,
                "redelm-column/src/main/java/redelm/io/RecordConsumer.java": 2,
                "redelm-column/src/main/java/redelm/io/RecordConsumerWrapper.java": 31,
                "redelm-column/src/main/java/redelm/schema/GroupType.java": 10,
                "redelm-column/src/main/java/redelm/schema/MessageType.java": 1,
                "redelm-column/src/main/java/redelm/schema/PrimitiveType.java": 90,
                "redelm-column/src/main/java/redelm/schema/Type.java": 17,
                "redelm-column/src/test/java/redelm/io/PerfTest.java": 124,
                "redelm-column/src/test/java/redelm/io/TestColumnIO.java": 20,
                "redelm-pig/src/main/java/redelm/pig/PigSchemaConverter.java": 15,
                "redelm-pig/src/main/java/redelm/pig/RedelmFileReader.java": 11,
                "redelm-pig/src/main/java/redelm/pig/RedelmFileWriter.java": 2,
                "redelm-pig/src/main/java/redelm/pig/TupleRecordConsumer.java": 11,
                "redelm-pig/src/test/java/redelm/pig/PerfTest.java": 83,
                "redelm-pig/src/test/java/redelm/pig/PerfTest2.java": 146,
                "redelm-pig/src/test/java/redelm/pig/TestRedelmFileWriter.java": 1
            },
            "is_test": true,
            "is_fix": false
        },
        "00257682aed55ab3ba05ee798cf38b56d51ecf62": {
            "datetime": "2012-10-11T22:07:17-07:00",
            "summary": "fixed tests",
            "message": "fixed tests\n",
            "diff": {
                "redelm-pig/src/test/java/redelm/pig/TestPigSchemaConverter.java": 2
            },
            "is_test": true,
            "is_fix": false
        },
        "246efae86ecfd6a816c619c501b183a0e6dd9190": {
            "datetime": "2012-10-17T23:46:48-07:00",
            "summary": "refactor of the columns",
            "message": "refactor of the columns\n",
            "diff": {
                "redelm-column/src/main/java/redelm/column/BytesOutput.java": 9,
                "redelm-column/src/main/java/redelm/column/ColumnWriter.java": 11,
                "redelm-column/src/main/java/redelm/column/ColumnsStore.java": 4,
                "redelm-column/src/main/java/redelm/column/RedelmByteArrayOutputStream.java": 16,
                "redelm-column/src/main/java/redelm/column/mem/MemColumn.java": 471,
                "redelm-column/src/main/java/redelm/column/mem/MemColumnReader.java": 123,
                "redelm-column/src/main/java/redelm/column/mem/MemColumnWriter.java": 132,
                "redelm-column/src/main/java/redelm/column/mem/MemColumnsStore.java": 289,
                "redelm-column/src/main/java/redelm/column/primitive/PrimitiveColumnReader.java": 33,
                "redelm-column/src/main/java/redelm/column/primitive/PrimitiveColumnWriter.java": 48,
                "redelm-column/src/main/java/redelm/column/primitive/SimplePrimitiveColumnReader.java": 80,
                "redelm-column/src/main/java/redelm/column/primitive/SimplePrimitiveColumnWriter.java": 113,
                "redelm-column/src/main/java/redelm/io/RecordReader.java": 5,
                "redelm-column/src/test/java/redelm/column/mem/TestMemColumn.java": 2,
                "redelm-column/src/test/java/redelm/io/TestColumnIO.java": 50,
                "redelm-pig/src/main/java/redelm/pig/BlockData.java": 23,
                "redelm-pig/src/main/java/redelm/pig/ColumnData.java": 20,
                "redelm-pig/src/main/java/redelm/pig/ColumnMetaData.java": 106,
                "redelm-pig/src/main/java/redelm/pig/RedelmFileReader.java": 34,
                "redelm-pig/src/main/java/redelm/pig/RedelmFileWriter.java": 104,
                "redelm-pig/src/main/java/redelm/pig/RedelmInputFormat.java": 12,
                "redelm-pig/src/main/java/redelm/pig/RedelmOutputFormat.java": 20,
                "redelm-pig/src/test/java/redelm/pig/TestRedelmFileWriter.java": 50
            },
            "is_test": true,
            "is_fix": false
        },
        "527beef0aa1a42872eae1c9378b7bc4822468ed0": {
            "datetime": "2012-10-17T23:50:06-07:00",
            "summary": "adding license headers",
            "message": "adding license headers\n",
            "diff": {
                "redelm-column/src/main/java/redelm/column/BytesOutput.java": 15,
                "redelm-column/src/main/java/redelm/column/RedelmByteArrayOutputStream.java": 15,
                "redelm-column/src/main/java/redelm/column/mem/MemColumnReader.java": 15,
                "redelm-column/src/main/java/redelm/column/mem/MemColumnWriter.java": 15,
                "redelm-column/src/main/java/redelm/column/primitive/PrimitiveColumnReader.java": 15,
                "redelm-column/src/main/java/redelm/column/primitive/PrimitiveColumnWriter.java": 15,
                "redelm-column/src/main/java/redelm/column/primitive/SimplePrimitiveColumnReader.java": 15,
                "redelm-column/src/main/java/redelm/column/primitive/SimplePrimitiveColumnWriter.java": 15,
                "redelm-column/src/main/java/redelm/data/simple/DoubleValue.java": 15,
                "redelm-column/src/main/java/redelm/data/simple/FloatValue.java": 15,
                "redelm-column/src/test/java/redelm/schema/TestMessageType.java": 15,
                "redelm-pig/src/main/java/redelm/pig/BlockData.java": 15,
                "redelm-pig/src/main/java/redelm/pig/BlockMetaData.java": 15,
                "redelm-pig/src/main/java/redelm/pig/ColumnData.java": 15,
                "redelm-pig/src/main/java/redelm/pig/ColumnMetaData.java": 15,
                "redelm-pig/src/main/java/redelm/pig/Footer.java": 15,
                "redelm-pig/src/main/java/redelm/pig/PigSchemaConverter.java": 15,
                "redelm-pig/src/main/java/redelm/pig/PrintFooter.java": 15,
                "redelm-pig/src/main/java/redelm/pig/RedelmFileReader.java": 15,
                "redelm-pig/src/main/java/redelm/pig/RedelmFileWriter.java": 15,
                "redelm-pig/src/main/java/redelm/pig/RedelmInputFormat.java": 15,
                "redelm-pig/src/main/java/redelm/pig/RedelmInputSplit.java": 15,
                "redelm-pig/src/main/java/redelm/pig/RedelmOutputFormat.java": 15,
                "redelm-pig/src/main/java/redelm/pig/RedelmStorer.java": 15,
                "redelm-pig/src/main/java/redelm/pig/summary/BagSummaryData.java": 15,
                "redelm-pig/src/main/java/redelm/pig/summary/EnumStat.java": 15,
                "redelm-pig/src/main/java/redelm/pig/summary/FieldSummaryData.java": 15,
                "redelm-pig/src/main/java/redelm/pig/summary/MapSummaryData.java": 15,
                "redelm-pig/src/main/java/redelm/pig/summary/NumberSummaryData.java": 15,
                "redelm-pig/src/main/java/redelm/pig/summary/StringSummaryData.java": 15,
                "redelm-pig/src/main/java/redelm/pig/summary/Summary.java": 15,
                "redelm-pig/src/main/java/redelm/pig/summary/SummaryData.java": 15,
                "redelm-pig/src/main/java/redelm/pig/summary/TupleSummaryData.java": 15,
                "redelm-pig/src/main/java/redelm/pig/summary/ValueStat.java": 15,
                "redelm-pig/src/test/java/redelm/pig/PerfTest.java": 15,
                "redelm-pig/src/test/java/redelm/pig/PerfTest2.java": 15,
                "redelm-pig/src/test/java/redelm/pig/TestPigSchemaConverter.java": 15,
                "redelm-pig/src/test/java/redelm/pig/TestRedelmFileWriter.java": 15,
                "redelm-pig/src/test/java/redelm/pig/TestRedelmStorer.java": 15,
                "redelm-pig/src/test/java/redelm/pig/summary/TestSummary.java": 15
            },
            "is_test": true,
            "is_fix": false
        },
        "11b8190df05c1ef61a6dc677db378bca62338062": {
            "datetime": "2012-10-17T23:51:46-07:00",
            "summary": "Merge pull request #1 from julienledem/hack_week",
            "message": "Merge pull request #1 from julienledem/hack_week\n\nmerging the PigLoader/Storer from Hack week",
            "diff": {
                "redelm-column/src/main/java/redelm/column/BytesOutput.java": 24,
                "redelm-column/src/main/java/redelm/column/ColumnReader.java": 4,
                "redelm-column/src/main/java/redelm/column/ColumnWriter.java": 15,
                "redelm-column/src/main/java/redelm/column/ColumnsStore.java": 4,
                "redelm-column/src/main/java/redelm/column/RedelmByteArrayOutputStream.java": 31,
                "redelm-column/src/main/java/redelm/column/mem/MemColumn.java": 393,
                "redelm-column/src/main/java/redelm/column/mem/MemColumnReader.java": 138,
                "redelm-column/src/main/java/redelm/column/mem/MemColumnWriter.java": 147,
                "redelm-column/src/main/java/redelm/column/mem/MemColumnsStore.java": 130,
                "redelm-column/src/main/java/redelm/column/primitive/PrimitiveColumnReader.java": 48,
                "redelm-column/src/main/java/redelm/column/primitive/PrimitiveColumnWriter.java": 63,
                "redelm-column/src/main/java/redelm/column/primitive/SimplePrimitiveColumnReader.java": 95,
                "redelm-column/src/main/java/redelm/column/primitive/SimplePrimitiveColumnWriter.java": 128,
                "redelm-column/src/main/java/redelm/data/Group.java": 7,
                "redelm-column/src/main/java/redelm/data/GroupRecordConsumer.java": 10,
                "redelm-column/src/main/java/redelm/data/GroupWriter.java": 2,
                "redelm-column/src/main/java/redelm/data/simple/BinaryValue.java": 7,
                "redelm-column/src/main/java/redelm/data/simple/BoolValue.java": 7,
                "redelm-column/src/main/java/redelm/data/simple/DoubleValue.java": 38,
                "redelm-column/src/main/java/redelm/data/simple/FloatValue.java": 38,
                "redelm-column/src/main/java/redelm/data/simple/IntValue.java": 7,
                "redelm-column/src/main/java/redelm/data/simple/Primitive.java": 12,
                "redelm-column/src/main/java/redelm/data/simple/SimpleGroup.java": 16,
                "redelm-column/src/main/java/redelm/data/simple/StringValue.java": 7,
                "redelm-column/src/main/java/redelm/io/GroupColumnIO.java": 4,
                "redelm-column/src/main/java/redelm/io/MessageColumnIO.java": 24,
                "redelm-column/src/main/java/redelm/io/RecordConsumer.java": 2,
                "redelm-column/src/main/java/redelm/io/RecordConsumerWrapper.java": 31,
                "redelm-column/src/main/java/redelm/io/RecordReader.java": 5,
                "redelm-column/src/main/java/redelm/schema/GroupType.java": 14,
                "redelm-column/src/main/java/redelm/schema/MessageType.java": 64,
                "redelm-column/src/main/java/redelm/schema/PrimitiveType.java": 84,
                "redelm-column/src/main/java/redelm/schema/Type.java": 17,
                "redelm-column/src/test/java/redelm/column/mem/TestMemColumn.java": 2,
                "redelm-column/src/test/java/redelm/io/PerfTest.java": 124,
                "redelm-column/src/test/java/redelm/io/TestColumnIO.java": 70,
                "redelm-column/src/test/java/redelm/schema/TestMessageType.java": 30,
                "redelm-pig/src/main/java/redelm/pig/BlockData.java": 38,
                "redelm-pig/src/main/java/redelm/pig/BlockMetaData.java": 66,
                "redelm-pig/src/main/java/redelm/pig/ColumnData.java": 59,
                "redelm-pig/src/main/java/redelm/pig/ColumnMetaData.java": 125,
                "redelm-pig/src/main/java/redelm/pig/Footer.java": 93,
                "redelm-pig/src/main/java/redelm/pig/PigSchemaConverter.java": 107,
                "redelm-pig/src/main/java/redelm/pig/PrintFooter.java": 42,
                "redelm-pig/src/main/java/redelm/pig/RedelmFileReader.java": 105,
                "redelm-pig/src/main/java/redelm/pig/RedelmFileWriter.java": 173,
                "redelm-pig/src/main/java/redelm/pig/RedelmInputFormat.java": 215,
                "redelm-pig/src/main/java/redelm/pig/RedelmInputSplit.java": 117,
                "redelm-pig/src/main/java/redelm/pig/RedelmLoader.java": 104,
                "redelm-pig/src/main/java/redelm/pig/RedelmOutputFormat.java": 113,
                "redelm-pig/src/main/java/redelm/pig/RedelmStorer.java": 102,
                "redelm-pig/src/main/java/redelm/pig/TupleRecordConsumer.java": 11,
                "redelm-pig/src/main/java/redelm/pig/summary/BagSummaryData.java": 79,
                "redelm-pig/src/main/java/redelm/pig/summary/EnumStat.java": 112,
                "redelm-pig/src/main/java/redelm/pig/summary/FieldSummaryData.java": 181,
                "redelm-pig/src/main/java/redelm/pig/summary/MapSummaryData.java": 90,
                "redelm-pig/src/main/java/redelm/pig/summary/NumberSummaryData.java": 47,
                "redelm-pig/src/main/java/redelm/pig/summary/StringSummaryData.java": 81,
                "redelm-pig/src/main/java/redelm/pig/summary/Summary.java": 280,
                "redelm-pig/src/main/java/redelm/pig/summary/SummaryData.java": 156,
                "redelm-pig/src/main/java/redelm/pig/summary/TupleSummaryData.java": 104,
                "redelm-pig/src/main/java/redelm/pig/summary/ValueStat.java": 61,
                "redelm-pig/src/test/java/redelm/pig/PerfTest.java": 98,
                "redelm-pig/src/test/java/redelm/pig/PerfTest2.java": 161,
                "redelm-pig/src/test/java/redelm/pig/TestPigSchemaConverter.java": 42,
                "redelm-pig/src/test/java/redelm/pig/TestRedelmFileWriter.java": 135,
                "redelm-pig/src/test/java/redelm/pig/TestRedelmStorer.java": 127,
                "redelm-pig/src/test/java/redelm/pig/summary/TestSummary.java": 143
            },
            "is_test": true,
            "is_fix": false
        },
        "1e7152b65092572a7bbe7e58dd18e163fce51cc2": {
            "datetime": "2012-10-18T11:38:26-07:00",
            "summary": "work",
            "message": "work\n",
            "diff": {
                "redelm-column/src/main/java/redelm/parser/RedelmParser.java": 35,
                "redelm-column/src/test/java/redelm/parser/TestRedelmParser.java": 61,
                "redelm-column/src/test/java/redelm/schema/TestMessageType.java": 17,
                "redelm-pig/src/main/java/redelm/pig/BlockMetaData.java": 51,
                "redelm-pig/src/main/java/redelm/pig/ColumnData.java": 28,
                "redelm-pig/src/main/java/redelm/pig/ColumnMetaData.java": 56,
                "redelm-pig/src/main/java/redelm/pig/Footer.java": 78,
                "redelm-pig/src/main/java/redelm/pig/PigSchemaConverter.java": 83,
                "redelm-pig/src/main/java/redelm/pig/PrintFooter.java": 27,
                "redelm-pig/src/main/java/redelm/pig/RedelmFileReader.java": 73,
                "redelm-pig/src/main/java/redelm/pig/RedelmFileWriter.java": 74,
                "redelm-pig/src/main/java/redelm/pig/RedelmInputFormat.java": 205,
                "redelm-pig/src/main/java/redelm/pig/RedelmInputSplit.java": 102,
                "redelm-pig/src/main/java/redelm/pig/RedelmOutputFormat.java": 92,
                "redelm-pig/src/main/java/redelm/pig/RedelmStorer.java": 87,
                "redelm-pig/src/main/java/redelm/pig/summary/BagSummaryData.java": 64,
                "redelm-pig/src/main/java/redelm/pig/summary/EnumStat.java": 97,
                "redelm-pig/src/main/java/redelm/pig/summary/FieldSummaryData.java": 166,
                "redelm-pig/src/main/java/redelm/pig/summary/MapSummaryData.java": 75,
                "redelm-pig/src/main/java/redelm/pig/summary/NumberSummaryData.java": 32,
                "redelm-pig/src/main/java/redelm/pig/summary/StringSummaryData.java": 66,
                "redelm-pig/src/main/java/redelm/pig/summary/Summary.java": 265,
                "redelm-pig/src/main/java/redelm/pig/summary/SummaryData.java": 141,
                "redelm-pig/src/main/java/redelm/pig/summary/TupleSummaryData.java": 89,
                "redelm-pig/src/main/java/redelm/pig/summary/ValueStat.java": 46,
                "redelm-pig/src/test/java/redelm/pig/TestPigSchemaConverter.java": 32,
                "redelm-pig/src/test/java/redelm/pig/TestRedelmFileWriter.java": 98,
                "redelm-pig/src/test/java/redelm/pig/TestRedelmStorer.java": 127,
                "redelm-pig/src/test/java/redelm/pig/summary/TestSummary.java": 128
            },
            "is_test": true,
            "is_fix": false
        },
        "9da016d3ad52385ba0f99f0ee5290bdae785d584": {
            "datetime": "2012-10-18T11:47:04-07:00",
            "summary": "merged",
            "message": "merged\n",
            "diff": {
                "redelm-column/src/main/java/redelm/column/BytesOutput.java": 24,
                "redelm-column/src/main/java/redelm/column/ColumnReader.java": 4,
                "redelm-column/src/main/java/redelm/column/ColumnWriter.java": 15,
                "redelm-column/src/main/java/redelm/column/ColumnsStore.java": 4,
                "redelm-column/src/main/java/redelm/column/RedelmByteArrayOutputStream.java": 31,
                "redelm-column/src/main/java/redelm/column/mem/MemColumn.java": 383,
                "redelm-column/src/main/java/redelm/column/mem/MemColumnReader.java": 138,
                "redelm-column/src/main/java/redelm/column/mem/MemColumnWriter.java": 147,
                "redelm-column/src/main/java/redelm/column/mem/MemColumnsStore.java": 117,
                "redelm-column/src/main/java/redelm/column/primitive/PrimitiveColumnReader.java": 48,
                "redelm-column/src/main/java/redelm/column/primitive/PrimitiveColumnWriter.java": 63,
                "redelm-column/src/main/java/redelm/column/primitive/SimplePrimitiveColumnReader.java": 95,
                "redelm-column/src/main/java/redelm/column/primitive/SimplePrimitiveColumnWriter.java": 128,
                "redelm-column/src/main/java/redelm/data/Group.java": 7,
                "redelm-column/src/main/java/redelm/data/GroupRecordConsumer.java": 10,
                "redelm-column/src/main/java/redelm/data/GroupWriter.java": 2,
                "redelm-column/src/main/java/redelm/data/simple/BinaryValue.java": 7,
                "redelm-column/src/main/java/redelm/data/simple/BoolValue.java": 7,
                "redelm-column/src/main/java/redelm/data/simple/DoubleValue.java": 38,
                "redelm-column/src/main/java/redelm/data/simple/FloatValue.java": 38,
                "redelm-column/src/main/java/redelm/data/simple/IntValue.java": 7,
                "redelm-column/src/main/java/redelm/data/simple/Primitive.java": 12,
                "redelm-column/src/main/java/redelm/data/simple/SimpleGroup.java": 16,
                "redelm-column/src/main/java/redelm/data/simple/StringValue.java": 7,
                "redelm-column/src/main/java/redelm/io/GroupColumnIO.java": 4,
                "redelm-column/src/main/java/redelm/io/MessageColumnIO.java": 24,
                "redelm-column/src/main/java/redelm/io/RecordConsumer.java": 2,
                "redelm-column/src/main/java/redelm/io/RecordConsumerWrapper.java": 31,
                "redelm-column/src/main/java/redelm/io/RecordReader.java": 5,
                "redelm-column/src/main/java/redelm/schema/GroupType.java": 10,
                "redelm-column/src/main/java/redelm/schema/MessageType.java": 71,
                "redelm-column/src/main/java/redelm/schema/PrimitiveType.java": 92,
                "redelm-column/src/main/java/redelm/schema/Type.java": 62,
                "redelm-column/src/test/java/redelm/column/mem/TestMemColumn.java": 2,
                "redelm-column/src/test/java/redelm/io/PerfTest.java": 124,
                "redelm-column/src/test/java/redelm/io/TestColumnIO.java": 72,
                "redelm-column/src/test/java/redelm/schema/TestMessageType.java": 29,
                "redelm-pig/src/main/java/redelm/pig/BlockData.java": 38,
                "redelm-pig/src/main/java/redelm/pig/BlockMetaData.java": 15,
                "redelm-pig/src/main/java/redelm/pig/ColumnData.java": 35,
                "redelm-pig/src/main/java/redelm/pig/ColumnMetaData.java": 121,
                "redelm-pig/src/main/java/redelm/pig/Footer.java": 15,
                "redelm-pig/src/main/java/redelm/pig/PigSchemaConverter.java": 34,
                "redelm-pig/src/main/java/redelm/pig/PrintFooter.java": 15,
                "redelm-pig/src/main/java/redelm/pig/RedelmFileReader.java": 44,
                "redelm-pig/src/main/java/redelm/pig/RedelmFileWriter.java": 121,
                "redelm-pig/src/main/java/redelm/pig/RedelmInputFormat.java": 250,
                "redelm-pig/src/main/java/redelm/pig/RedelmInputSplit.java": 15,
                "redelm-pig/src/main/java/redelm/pig/RedelmOutputFormat.java": 35,
                "redelm-pig/src/main/java/redelm/pig/RedelmStorer.java": 15,
                "redelm-pig/src/main/java/redelm/pig/TupleRecordConsumer.java": 11,
                "redelm-pig/src/main/java/redelm/pig/summary/BagSummaryData.java": 15,
                "redelm-pig/src/main/java/redelm/pig/summary/EnumStat.java": 15,
                "redelm-pig/src/main/java/redelm/pig/summary/FieldSummaryData.java": 15,
                "redelm-pig/src/main/java/redelm/pig/summary/MapSummaryData.java": 15,
                "redelm-pig/src/main/java/redelm/pig/summary/NumberSummaryData.java": 15,
                "redelm-pig/src/main/java/redelm/pig/summary/StringSummaryData.java": 15,
                "redelm-pig/src/main/java/redelm/pig/summary/Summary.java": 15,
                "redelm-pig/src/main/java/redelm/pig/summary/SummaryData.java": 15,
                "redelm-pig/src/main/java/redelm/pig/summary/TupleSummaryData.java": 15,
                "redelm-pig/src/main/java/redelm/pig/summary/ValueStat.java": 15,
                "redelm-pig/src/test/java/redelm/pig/PerfTest.java": 98,
                "redelm-pig/src/test/java/redelm/pig/PerfTest2.java": 161,
                "redelm-pig/src/test/java/redelm/pig/TestPigSchemaConverter.java": 44,
                "redelm-pig/src/test/java/redelm/pig/TestRedelmFileWriter.java": 113,
                "redelm-pig/src/test/java/redelm/pig/TestRedelmStorer.java": 74,
                "redelm-pig/src/test/java/redelm/pig/summary/TestSummary.java": 15
            },
            "is_test": true,
            "is_fix": false
        },
        "71b7b11456f677e17a6fb7ca5bce862257c12048": {
            "datetime": "2012-10-18T11:54:11-07:00",
            "summary": "work",
            "message": "work\n",
            "diff": {
                "redelm-column/src/main/java/redelm/column/mem/MemColumn.java": 24,
                "redelm-column/src/main/java/redelm/schema/MessageType.java": 66
            },
            "is_test": false,
            "is_fix": false
        },
        "02b40db07adcb0c382de4b7bfa4fc019d4a06fa0": {
            "datetime": "2012-10-18T14:10:11-07:00",
            "summary": "work",
            "message": "work\n",
            "diff": {
                "redelm-column/src/main/java/redelm/parser/RedelmParser.java": 32,
                "redelm-column/src/main/java/redelm/schema/GroupType.java": 41,
                "redelm-column/src/main/java/redelm/schema/MessageType.java": 9,
                "redelm-column/src/main/java/redelm/schema/PrimitiveType.java": 79,
                "redelm-column/src/main/java/redelm/schema/Type.java": 18,
                "redelm-column/src/test/java/redelm/io/TestColumnIO.java": 8,
                "redelm-column/src/test/java/redelm/schema/TestMessageType.java": 28,
                "redelm-pig/src/main/java/redelm/pig/PigSchemaConverter.java": 4,
                "redelm-pig/src/main/java/redelm/pig/RedelmInputFormat.java": 28,
                "redelm-pig/src/test/java/redelm/pig/TestPigSchemaConverter.java": 25,
                "redelm-pig/src/test/java/redelm/pig/TestRedelmFileWriter.java": 10,
                "redelm-pig/src/test/java/redelm/pig/TestRedelmStorer.java": 76
            },
            "is_test": true,
            "is_fix": false
        },
        "38434c66f24ddd47d7a0b3683e3fcfefcadbfedd": {
            "datetime": "2012-10-18T14:23:20-07:00",
            "summary": "work",
            "message": "work\n",
            "diff": {
                "redelm-column/src/test/java/redelm/io/PerfTest.java": 6,
                "redelm-pig/src/test/java/redelm/pig/PerfTest2.java": 7,
                "redelm-pig/src/test/java/redelm/pig/TestRedelmFileWriter.java": 37,
                "redelm-pig/src/test/java/redelm/pig/TestRedelmStorer.java": 22,
                "redelm-pig/src/test/java/redelm/pig/summary/TestSummary.java": 20
            },
            "is_test": true,
            "is_fix": false
        },
        "f84fa2786b1951b81ab39f62a42b194bccee0dca": {
            "datetime": "2012-10-23T18:11:02-07:00",
            "summary": "work",
            "message": "work\n",
            "diff": {
                "redelm-column/src/main/java/redelm/parser/RedelmParser.java": 38,
                "redelm-column/src/test/java/redelm/parser/TestRedelmParser.java": 8,
                "redelm-column/src/test/java/redelm/schema/TestMessageType.java": 2,
                "redelm-pig/src/main/java/redelm/pig/RedelmInputFormat.java": 12,
                "redelm-pig/src/main/java/redelm/pig/TupleWriter.java": 5,
                "redelm-pig/src/test/java/redelm/pig/PerfTest.java": 6,
                "redelm-pig/src/test/java/redelm/pig/TestPigSchemaConverter.java": 2,
                "redelm-pig/src/test/java/redelm/pig/TestRedelmFileWriter.java": 2
            },
            "is_test": true,
            "is_fix": false
        },
        "30e3849451d4734bc776116316ecd547612743d7": {
            "datetime": "2012-10-23T18:36:31-07:00",
            "summary": "work",
            "message": "work\n",
            "diff": {
                "redelm-column/src/main/java/redelm/column/ColumnReader.java": 4,
                "redelm-column/src/main/java/redelm/column/mem/MemColumn.java": 6,
                "redelm-column/src/main/java/redelm/column/mem/MemColumnReader.java": 4,
                "redelm-column/src/main/java/redelm/data/GroupRecordConsumer.java": 2,
                "redelm-column/src/main/java/redelm/data/simple/IntValue.java": 2,
                "redelm-column/src/main/java/redelm/io/MessageColumnIO.java": 2,
                "redelm-column/src/main/java/redelm/io/RecordConsumer.java": 2,
                "redelm-column/src/main/java/redelm/io/RecordConsumerWrapper.java": 4,
                "redelm-column/src/main/java/redelm/parser/RedelmParser.java": 15,
                "redelm-column/src/main/java/redelm/schema/PrimitiveType.java": 10,
                "redelm-column/src/test/java/redelm/column/mem/TestMemColumn.java": 4,
                "redelm-column/src/test/java/redelm/io/PerfTest.java": 2,
                "redelm-column/src/test/java/redelm/io/TestColumnIO.java": 2,
                "redelm-column/src/test/java/redelm/parser/TestRedelmParser.java": 15,
                "redelm-column/src/test/java/redelm/schema/TestMessageType.java": 15,
                "redelm-pig/src/main/java/redelm/pig/PigSchemaConverter.java": 2,
                "redelm-pig/src/main/java/redelm/pig/TupleRecordConsumer.java": 2,
                "redelm-pig/src/main/java/redelm/pig/TupleWriter.java": 4,
                "redelm-pig/src/test/java/redelm/pig/TestRedelmStorer.java": 15
            },
            "is_test": true,
            "is_fix": false
        },
        "e12b27f08595a0696ac182a81623c78fd8deb8d7": {
            "datetime": "2012-10-24T16:47:13-07:00",
            "summary": "fix support for int/long and map",
            "message": "fix support for int/long and map\n",
            "diff": {
                "redelm-column/src/main/java/redelm/column/ColumnReader.java": 2,
                "redelm-column/src/main/java/redelm/column/ColumnWriter.java": 3,
                "redelm-column/src/main/java/redelm/column/mem/MemColumn.java": 31,
                "redelm-column/src/main/java/redelm/column/mem/MemColumnReader.java": 5,
                "redelm-column/src/main/java/redelm/column/mem/MemColumnWriter.java": 8,
                "redelm-column/src/main/java/redelm/column/primitive/PrimitiveColumnReader.java": 4,
                "redelm-column/src/main/java/redelm/column/primitive/SimplePrimitiveColumnReader.java": 9,
                "redelm-column/src/main/java/redelm/data/Group.java": 11,
                "redelm-column/src/main/java/redelm/data/GroupRecordConsumer.java": 5,
                "redelm-column/src/main/java/redelm/data/simple/Primitive.java": 4,
                "redelm-column/src/main/java/redelm/data/simple/SimpleGroup.java": 5,
                "redelm-column/src/main/java/redelm/data/simple/example/Paper.java": 20,
                "redelm-column/src/main/java/redelm/io/GroupColumnIO.java": 6,
                "redelm-column/src/main/java/redelm/io/MessageColumnIO.java": 41,
                "redelm-column/src/main/java/redelm/io/RecordConsumer.java": 1,
                "redelm-column/src/main/java/redelm/io/RecordConsumerWrapper.java": 6,
                "redelm-column/src/main/java/redelm/schema/PrimitiveType.java": 11,
                "redelm-column/src/test/java/redelm/column/mem/TestMemColumn.java": 6,
                "redelm-column/src/test/java/redelm/io/PerfTest.java": 1,
                "redelm-column/src/test/java/redelm/io/TestColumnIO.java": 18,
                "redelm-pig/src/main/java/redelm/pig/Footer.java": 9,
                "redelm-pig/src/main/java/redelm/pig/PigSchemaConverter.java": 4,
                "redelm-pig/src/main/java/redelm/pig/RedelmFileWriter.java": 6,
                "redelm-pig/src/main/java/redelm/pig/RedelmInputFormat.java": 10,
                "redelm-pig/src/main/java/redelm/pig/RedelmInputSplit.java": 25,
                "redelm-pig/src/main/java/redelm/pig/RedelmOutputFormat.java": 6,
                "redelm-pig/src/main/java/redelm/pig/RedelmStorer.java": 6,
                "redelm-pig/src/main/java/redelm/pig/TupleRecordConsumer.java": 111,
                "redelm-pig/src/main/java/redelm/pig/TupleWriter.java": 72,
                "redelm-pig/src/test/java/redelm/pig/TestRedelmFileWriter.java": 2,
                "redelm-pig/src/test/java/redelm/pig/TestTupleRecordConsumer.java": 43
            },
            "is_test": true,
            "is_fix": false
        },
        "d0806980aaed917ab5139533446449af33602a30": {
            "datetime": "2012-10-25T14:31:21-07:00",
            "summary": "adding schema validation",
            "message": "adding schema validation\n",
            "diff": {
                "redelm-column/src/main/java/redelm/RedelmRuntimeException.java": 22,
                "redelm-column/src/main/java/redelm/data/simple/LongValue.java": 42,
                "redelm-column/src/main/java/redelm/io/InvalidRecordException.java": 24,
                "redelm-column/src/main/java/redelm/io/ValidatingRecordConsumer.java": 134,
                "redelm-column/src/test/java/redelm/io/TestColumnIO.java": 5
            },
            "is_test": true,
            "is_fix": false
        },
        "da419bfe8ddb40261da15a88d5dad6520ed91ec2": {
            "datetime": "2012-10-29T16:19:14-07:00",
            "summary": "fix bug regarding null values in message",
            "message": "fix bug regarding null values in message\n",
            "diff": {
                "redelm-column/src/main/java/redelm/io/MessageColumnIO.java": 1,
                "redelm-column/src/main/java/redelm/io/RecordConsumerWrapper.java": 4
            },
            "is_test": false,
            "is_fix": false
        },
        "9f9b23d3855518e54e88567b88a2998d67247df9": {
            "datetime": "2012-10-30T16:18:26-07:00",
            "summary": "work",
            "message": "work\n",
            "diff": {
                "redelm-column/src/main/java/redelm/RedelmRuntimeException.java": 22,
                "redelm-column/src/main/java/redelm/column/ColumnReader.java": 6,
                "redelm-column/src/main/java/redelm/column/ColumnWriter.java": 3,
                "redelm-column/src/main/java/redelm/column/mem/MemColumn.java": 31,
                "redelm-column/src/main/java/redelm/column/mem/MemColumnReader.java": 4,
                "redelm-column/src/main/java/redelm/column/mem/MemColumnWriter.java": 8,
                "redelm-column/src/main/java/redelm/column/primitive/PrimitiveColumnReader.java": 4,
                "redelm-column/src/main/java/redelm/column/primitive/SimplePrimitiveColumnReader.java": 9,
                "redelm-column/src/main/java/redelm/data/Group.java": 11,
                "redelm-column/src/main/java/redelm/data/GroupRecordConsumer.java": 5,
                "redelm-column/src/main/java/redelm/data/simple/LongValue.java": 42,
                "redelm-column/src/main/java/redelm/data/simple/Primitive.java": 4,
                "redelm-column/src/main/java/redelm/data/simple/SimpleGroup.java": 5,
                "redelm-column/src/main/java/redelm/data/simple/example/Paper.java": 20,
                "redelm-column/src/main/java/redelm/io/GroupColumnIO.java": 6,
                "redelm-column/src/main/java/redelm/io/InvalidRecordException.java": 24,
                "redelm-column/src/main/java/redelm/io/MessageColumnIO.java": 42,
                "redelm-column/src/main/java/redelm/io/RecordConsumer.java": 1,
                "redelm-column/src/main/java/redelm/io/RecordConsumerWrapper.java": 10,
                "redelm-column/src/main/java/redelm/io/ValidatingRecordConsumer.java": 134,
                "redelm-column/src/main/java/redelm/schema/PrimitiveType.java": 11,
                "redelm-column/src/test/java/redelm/column/mem/TestMemColumn.java": 6,
                "redelm-column/src/test/java/redelm/io/PerfTest.java": 1,
                "redelm-column/src/test/java/redelm/io/TestColumnIO.java": 23,
                "redelm-pig/src/main/java/redelm/pig/Footer.java": 9,
                "redelm-pig/src/main/java/redelm/pig/PigSchemaConverter.java": 4,
                "redelm-pig/src/main/java/redelm/pig/RedelmFileWriter.java": 6,
                "redelm-pig/src/main/java/redelm/pig/RedelmInputFormat.java": 9,
                "redelm-pig/src/main/java/redelm/pig/RedelmInputSplit.java": 25,
                "redelm-pig/src/main/java/redelm/pig/RedelmOutputFormat.java": 6,
                "redelm-pig/src/main/java/redelm/pig/RedelmStorer.java": 6,
                "redelm-pig/src/main/java/redelm/pig/TupleRecordConsumer.java": 111,
                "redelm-pig/src/main/java/redelm/pig/TupleWriter.java": 72,
                "redelm-pig/src/test/java/redelm/pig/TestRedelmFileWriter.java": 2,
                "redelm-pig/src/test/java/redelm/pig/TestTupleRecordConsumer.java": 47
            },
            "is_test": true,
            "is_fix": false
        },
        "9c34678e5cfd2e228664261b25dcce8033ea22bb": {
            "datetime": "2012-10-30T16:52:36-07:00",
            "summary": "work",
            "message": "work\n",
            "diff": {
                "redelm-column/src/main/java/redelm/column/ColumnReader.java": 6,
                "redelm-column/src/main/java/redelm/data/GroupValueSource.java": 12,
                "redelm-column/src/main/java/redelm/data/simple/BoolValue.java": 41,
                "redelm-column/src/main/java/redelm/data/simple/Primitive.java": 2,
                "redelm-column/src/main/java/redelm/data/simple/SimpleGroup.java": 8,
                "redelm-column/src/main/java/redelm/io/ValidatingRecordConsumer.java": 6,
                "redelm-pig/src/main/java/redelm/pig/TupleWriter.java": 2,
                "redelm-pig/src/test/java/redelm/pig/TestTupleRecordConsumer.java": 2
            },
            "is_test": true,
            "is_fix": false
        },
        "525d3aece83ed9a0d46ab2c0568277f6345bba91": {
            "datetime": "2012-10-31T12:57:44-07:00",
            "summary": "work",
            "message": "work\n",
            "diff": {
                "redelm-column/src/main/java/redelm/parser/RedelmParser.java": 73,
                "redelm-pig/src/main/java/redelm/pig/RedelmInputFormat.java": 13
            },
            "is_test": false,
            "is_fix": false
        },
        "4cd5bc1d011e44d43b3d25d3ab20c3f7d4b7ca83": {
            "datetime": "2012-10-31T12:57:55-07:00",
            "summary": "work",
            "message": "work\n",
            "diff": {
                "redelm-column/src/main/java/redelm/data/simple/BooleanValue.java": 41
            },
            "is_test": false,
            "is_fix": false
        },
        "063486db8c7112f8790527b6c24e98198760d5ba": {
            "datetime": "2012-10-31T13:07:49-07:00",
            "summary": "work",
            "message": "work\n",
            "diff": {
                "redelm-column/src/main/java/redelm/data/simple/IntValue.java": 6,
                "redelm-column/src/main/java/redelm/data/simple/Primitive.java": 2,
                "redelm-column/src/main/java/redelm/data/simple/SimpleGroup.java": 4
            },
            "is_test": false,
            "is_fix": false
        },
        "ba06716ed8eecd9ec7d2ac7d8afb3d3f4517533c": {
            "datetime": "2012-10-31T13:38:44-07:00",
            "summary": "remove a use of StringBuffer",
            "message": "remove a use of StringBuffer\n",
            "diff": {
                "redelm-column/src/main/java/redelm/column/mem/MemColumnsStore.java": 2
            },
            "is_test": false,
            "is_fix": false
        },
        "46a3458add4df4a325d804c37f60f8866041fb4d": {
            "datetime": "2012-10-31T16:37:34-07:00",
            "summary": "first pass at adding compression",
            "message": "first pass at adding compression\n",
            "diff": {
                "redelm-pig/src/main/java/redelm/pig/RedelmFileReader.java": 33,
                "redelm-pig/src/main/java/redelm/pig/RedelmFileWriter.java": 58
            },
            "is_test": false,
            "is_fix": false
        },
        "4bfca1f14f549a6b116d25fd7aadf257b746296e": {
            "datetime": "2012-11-01T16:47:08-07:00",
            "summary": "make Codec configurable",
            "message": "make Codec configurable\n",
            "diff": {
                "redelm-column/src/main/java/redelm/column/primitive/SimplePrimitiveColumnReader.java": 14,
                "redelm-column/src/main/java/redelm/column/primitive/SimplePrimitiveColumnWriter.java": 8,
                "redelm-pig/src/main/java/redelm/pig/Footer.java": 11,
                "redelm-pig/src/main/java/redelm/pig/RedelmFileReader.java": 5,
                "redelm-pig/src/main/java/redelm/pig/RedelmFileWriter.java": 9,
                "redelm-pig/src/main/java/redelm/pig/RedelmInputFormat.java": 5,
                "redelm-pig/src/main/java/redelm/pig/RedelmInputSplit.java": 13,
                "redelm-pig/src/main/java/redelm/pig/RedelmOutputFormat.java": 6,
                "redelm-pig/src/main/java/redelm/pig/RedelmStorer.java": 12,
                "redelm-pig/src/test/java/redelm/pig/TestRedelmFileWriter.java": 9
            },
            "is_test": true,
            "is_fix": false
        },
        "1a0284da7ab5fb84644d4066b376bec6f3f582bc": {
            "datetime": "2012-11-01T16:57:16-07:00",
            "summary": "fix empty string bug",
            "message": "fix empty string bug\n",
            "diff": {
                "redelm-column/src/main/java/redelm/column/primitive/SimplePrimitiveColumnReader.java": 24
            },
            "is_test": false,
            "is_fix": false
        },
        "94781b0e7b3c0e7d8c3e1b642f1fe6cc45fe9628": {
            "datetime": "2012-11-02T16:06:08-07:00",
            "summary": "VarInt for String length",
            "message": "VarInt for String length\n",
            "diff": {
                "redelm-column/src/main/java/redelm/column/primitive/SimplePrimitiveColumnReader.java": 13,
                "redelm-column/src/main/java/redelm/column/primitive/SimplePrimitiveColumnWriter.java": 9
            },
            "is_test": false,
            "is_fix": false
        },
        "1d40ac2d53558a5306b9fb9425db70dd4c3e6313": {
            "datetime": "2012-11-02T17:28:07-07:00",
            "summary": "add javadoc",
            "message": "add javadoc\n",
            "diff": {
                "redelm-column/src/main/java/redelm/io/RecordConsumer.java": 93
            },
            "is_test": false,
            "is_fix": false
        },
        "c2ed3ee089da179c16fc49be0078f564a81d973d": {
            "datetime": "2012-11-05T14:44:12-08:00",
            "summary": "work",
            "message": "work\n",
            "diff": {
                "redelm-column/src/main/java/redelm/parser/RedelmParser.java": 135,
                "redelm-column/src/main/java/redelm/schema/GroupType.java": 68,
                "redelm-column/src/main/java/redelm/schema/MessageType.java": 14,
                "redelm-column/src/main/java/redelm/schema/PrimitiveType.java": 40,
                "redelm-column/src/main/java/redelm/schema/Type.java": 4,
                "redelm-column/src/test/java/redelm/parser/TestRedelmParser.java": 8,
                "redelm-column/src/test/java/redelm/schema/TestMessageType.java": 4,
                "redelm-pig/src/main/java/redelm/pig/RedelmInputFormat.java": 6,
                "redelm-pig/src/test/java/redelm/pig/TestPigSchemaConverter.java": 4,
                "redelm-pig/src/test/java/redelm/pig/TestRedelmFileWriter.java": 4
            },
            "is_test": true,
            "is_fix": false
        },
        "3b447a60e1ba41f06d469dc24979479619bd3d7e": {
            "datetime": "2012-11-06T11:53:27-08:00",
            "summary": "Merge pull request #8 from julienledem/add_column_compression",
            "message": "Merge pull request #8 from julienledem/add_column_compression\n\nfirst pass at adding compression",
            "diff": {
                "redelm-column/src/main/java/redelm/column/primitive/SimplePrimitiveColumnReader.java": 29,
                "redelm-column/src/main/java/redelm/column/primitive/SimplePrimitiveColumnWriter.java": 15,
                "redelm-column/src/main/java/redelm/io/RecordConsumer.java": 93,
                "redelm-pig/src/main/java/redelm/pig/Footer.java": 11,
                "redelm-pig/src/main/java/redelm/pig/RedelmFileReader.java": 34,
                "redelm-pig/src/main/java/redelm/pig/RedelmFileWriter.java": 63,
                "redelm-pig/src/main/java/redelm/pig/RedelmInputFormat.java": 5,
                "redelm-pig/src/main/java/redelm/pig/RedelmInputSplit.java": 13,
                "redelm-pig/src/main/java/redelm/pig/RedelmOutputFormat.java": 6,
                "redelm-pig/src/main/java/redelm/pig/RedelmStorer.java": 12,
                "redelm-pig/src/test/java/redelm/pig/TestRedelmFileWriter.java": 9
            },
            "is_test": true,
            "is_fix": false
        },
        "32bb525182f3e847ad9714d10f5788b214d7e9bd": {
            "datetime": "2012-11-06T12:05:00-08:00",
            "summary": "work",
            "message": "work\n",
            "diff": {
                "redelm-column/src/main/java/redelm/parser/MessageTypeParser.java": 92
            },
            "is_test": false,
            "is_fix": false
        },
        "94c10a25b4a72de745b314e6f5655de53f5be6cf": {
            "datetime": "2012-11-06T15:11:07-08:00",
            "summary": "Merge branch 'hack_week_jco' of https://github.com/jcoveney/redelm",
            "message": "Merge branch 'hack_week_jco' of https://github.com/jcoveney/redelm\n\nFixed Conflicts:\n\tredelm-column/src/main/java/redelm/io/RecordConsumer.java\n\tredelm-pig/src/test/java/redelm/pig/TestRedelmFileWriter.java\n",
            "diff": {
                "redelm-column/src/main/java/redelm/column/ColumnReader.java": 6,
                "redelm-column/src/main/java/redelm/column/mem/MemColumn.java": 6,
                "redelm-column/src/main/java/redelm/column/mem/MemColumnReader.java": 7,
                "redelm-column/src/main/java/redelm/column/mem/MemColumnsStore.java": 2,
                "redelm-column/src/main/java/redelm/data/GroupRecordConsumer.java": 2,
                "redelm-column/src/main/java/redelm/data/GroupValueSource.java": 12,
                "redelm-column/src/main/java/redelm/data/simple/BoolValue.java": 6,
                "redelm-column/src/main/java/redelm/data/simple/IntValue.java": 8,
                "redelm-column/src/main/java/redelm/data/simple/Primitive.java": 4,
                "redelm-column/src/main/java/redelm/data/simple/SimpleGroup.java": 12,
                "redelm-column/src/main/java/redelm/io/MessageColumnIO.java": 2,
                "redelm-column/src/main/java/redelm/io/RecordConsumer.java": 2,
                "redelm-column/src/main/java/redelm/io/RecordConsumerWrapper.java": 4,
                "redelm-column/src/main/java/redelm/io/ValidatingRecordConsumer.java": 6,
                "redelm-column/src/main/java/redelm/parser/MessageTypeParser.java": 100,
                "redelm-column/src/main/java/redelm/schema/GroupType.java": 53,
                "redelm-column/src/main/java/redelm/schema/MessageType.java": 76,
                "redelm-column/src/main/java/redelm/schema/PrimitiveType.java": 64,
                "redelm-column/src/main/java/redelm/schema/Type.java": 24,
                "redelm-column/src/test/java/redelm/io/PerfTest.java": 8,
                "redelm-column/src/test/java/redelm/io/TestColumnIO.java": 43,
                "redelm-column/src/test/java/redelm/parser/TestRedelmParser.java": 76,
                "redelm-column/src/test/java/redelm/schema/TestMessageType.java": 13,
                "redelm-pig/src/main/java/redelm/pig/PigSchemaConverter.java": 6,
                "redelm-pig/src/main/java/redelm/pig/RedelmInputFormat.java": 20,
                "redelm-pig/src/main/java/redelm/pig/TupleRecordConsumer.java": 2,
                "redelm-pig/src/main/java/redelm/pig/TupleWriter.java": 4,
                "redelm-pig/src/test/java/redelm/pig/PerfTest.java": 6,
                "redelm-pig/src/test/java/redelm/pig/PerfTest2.java": 7,
                "redelm-pig/src/test/java/redelm/pig/TestPigSchemaConverter.java": 25,
                "redelm-pig/src/test/java/redelm/pig/TestRedelmFileWriter.java": 47,
                "redelm-pig/src/test/java/redelm/pig/TestRedelmStorer.java": 59,
                "redelm-pig/src/test/java/redelm/pig/TestTupleRecordConsumer.java": 12,
                "redelm-pig/src/test/java/redelm/pig/summary/TestSummary.java": 20
            },
            "is_test": true,
            "is_fix": false
        },
        "fd5bd4a8734b9b7bb1ab983ad1d3e61b87069b93": {
            "datetime": "2012-11-07T14:44:32-08:00",
            "summary": "record uncompressed size in footer; add detailed report of size and compression per column",
            "message": "record uncompressed size in footer; add detailed report of size and compression per column\n",
            "diff": {
                "redelm-pig/src/main/java/redelm/pig/ColumnMetaData.java": 42,
                "redelm-pig/src/main/java/redelm/pig/PrintFooter.java": 189,
                "redelm-pig/src/main/java/redelm/pig/RedelmFileReader.java": 7,
                "redelm-pig/src/main/java/redelm/pig/RedelmFileWriter.java": 7,
                "redelm-pig/src/main/java/redelm/pig/RedelmInputFormat.java": 4,
                "redelm-pig/src/test/java/redelm/pig/TestRedelmFileWriter.java": 1
            },
            "is_test": true,
            "is_fix": false
        },
        "3b8ad08b3c0b40221096f5db00e2b1524dbf9315": {
            "datetime": "2012-11-08T08:16:26-08:00",
            "summary": "cleanup logs",
            "message": "cleanup logs\n",
            "diff": {
                "redelm-pig/src/main/java/redelm/pig/RedelmFileReader.java": 4,
                "redelm-pig/src/main/java/redelm/pig/RedelmInputFormat.java": 7
            },
            "is_test": false,
            "is_fix": false
        },
        "df97795af630d28c0d884dc21d40a731e9e20d00": {
            "datetime": "2012-11-09T09:51:55-08:00",
            "summary": "javadoc",
            "message": "javadoc\n",
            "diff": {
                "redelm-column/src/main/java/redelm/data/simple/example/Paper.java": 6,
                "redelm-column/src/main/java/redelm/io/RecordConsumerWrapper.java": 50,
                "redelm-column/src/main/java/redelm/io/RecordReader.java": 14,
                "redelm-column/src/main/java/redelm/io/ValidatingRecordConsumer.java": 51,
                "redelm-column/src/main/java/redelm/parser/MessageTypeParser.java": 12,
                "redelm-column/src/main/java/redelm/schema/GroupType.java": 75,
                "redelm-column/src/main/java/redelm/schema/MessageType.java": 18,
                "redelm-column/src/main/java/redelm/schema/PrimitiveType.java": 47,
                "redelm-column/src/main/java/redelm/schema/Type.java": 19,
                "redelm-column/src/main/java/redelm/schema/TypeVisitor.java": 21,
                "redelm-pig/src/main/java/redelm/pig/PigSchemaConverter.java": 17,
                "redelm-pig/src/main/java/redelm/pig/summary/Summary.java": 2
            },
            "is_test": false,
            "is_fix": false
        },
        "e2e3eeb5c02895d5737556bf96c775e86b740a41": {
            "datetime": "2012-11-12T09:54:41-08:00",
            "summary": "first stab a decoupling the Input/OutputFormat from Pig",
            "message": "first stab a decoupling the Input/OutputFormat from Pig\n",
            "diff": {
                "redelm-pig/src/main/java/redelm/pig/Footer.java": 30,
                "redelm-pig/src/main/java/redelm/pig/MetaDataBlock.java": 22,
                "redelm-pig/src/main/java/redelm/pig/PigMetaData.java": 89,
                "redelm-pig/src/main/java/redelm/pig/PrintFooter.java": 2,
                "redelm-pig/src/main/java/redelm/pig/ReadSupport.java": 14,
                "redelm-pig/src/main/java/redelm/pig/RedelmFileReader.java": 22,
                "redelm-pig/src/main/java/redelm/pig/RedelmFileWriter.java": 24,
                "redelm-pig/src/main/java/redelm/pig/RedelmInputFormat.java": 56,
                "redelm-pig/src/main/java/redelm/pig/RedelmLoader.java": 7,
                "redelm-pig/src/main/java/redelm/pig/RedelmOutputFormat.java": 32,
                "redelm-pig/src/main/java/redelm/pig/RedelmStorer.java": 2,
                "redelm-pig/src/main/java/redelm/pig/TupleReadSupport.java": 34,
                "redelm-pig/src/main/java/redelm/pig/TupleWriter.java": 20,
                "redelm-pig/src/main/java/redelm/pig/WriteSupport.java": 12,
                "redelm-pig/src/test/java/redelm/pig/TestRedelmFileWriter.java": 7,
                "redelm-pig/src/test/java/redelm/pig/TestTupleRecordConsumer.java": 6
            },
            "is_test": true,
            "is_fix": false
        },
        "76ded4f933f058c4299384cea192dda0677fa18c": {
            "datetime": "2012-11-13T08:20:31-08:00",
            "summary": "store count of metadatablocks in footer",
            "message": "store count of metadatablocks in footer\n",
            "diff": {
                "redelm-pig/src/main/java/redelm/pig/RedelmFileReader.java": 7,
                "redelm-pig/src/main/java/redelm/pig/RedelmFileWriter.java": 4
            },
            "is_test": false,
            "is_fix": false
        },
        "f9be51e8f8615d5e1b59c3d025cd8b12365c6bed": {
            "datetime": "2012-11-13T10:45:04-08:00",
            "summary": "Merge pull request #9 from julienledem/javadoc",
            "message": "Merge pull request #9 from julienledem/javadoc\n\njavadoc",
            "diff": {
                "redelm-column/src/main/java/redelm/data/simple/example/Paper.java": 6,
                "redelm-column/src/main/java/redelm/io/RecordConsumerWrapper.java": 50,
                "redelm-column/src/main/java/redelm/io/RecordReader.java": 14,
                "redelm-column/src/main/java/redelm/io/ValidatingRecordConsumer.java": 51,
                "redelm-column/src/main/java/redelm/parser/MessageTypeParser.java": 12,
                "redelm-column/src/main/java/redelm/schema/GroupType.java": 75,
                "redelm-column/src/main/java/redelm/schema/MessageType.java": 18,
                "redelm-column/src/main/java/redelm/schema/PrimitiveType.java": 47,
                "redelm-column/src/main/java/redelm/schema/Type.java": 19,
                "redelm-column/src/main/java/redelm/schema/TypeVisitor.java": 21,
                "redelm-pig/src/main/java/redelm/pig/PigSchemaConverter.java": 17,
                "redelm-pig/src/main/java/redelm/pig/summary/Summary.java": 2
            },
            "is_test": false,
            "is_fix": false
        },
        "f070939c111b00a6dd7178e4d03935ab58caa562": {
            "datetime": "2012-11-13T10:45:22-08:00",
            "summary": "Merge pull request #10 from julienledem/decoupling_InputOutputFormat_from_Pig",
            "message": "Merge pull request #10 from julienledem/decoupling_InputOutputFormat_from_Pig\n\nfirst stab a decoupling the Input/OutputFormat from Pig",
            "diff": {
                "redelm-pig/src/main/java/redelm/pig/Footer.java": 30,
                "redelm-pig/src/main/java/redelm/pig/MetaDataBlock.java": 22,
                "redelm-pig/src/main/java/redelm/pig/PigMetaData.java": 89,
                "redelm-pig/src/main/java/redelm/pig/PrintFooter.java": 2,
                "redelm-pig/src/main/java/redelm/pig/ReadSupport.java": 14,
                "redelm-pig/src/main/java/redelm/pig/RedelmFileReader.java": 23,
                "redelm-pig/src/main/java/redelm/pig/RedelmFileWriter.java": 28,
                "redelm-pig/src/main/java/redelm/pig/RedelmInputFormat.java": 56,
                "redelm-pig/src/main/java/redelm/pig/RedelmLoader.java": 7,
                "redelm-pig/src/main/java/redelm/pig/RedelmOutputFormat.java": 32,
                "redelm-pig/src/main/java/redelm/pig/RedelmStorer.java": 2,
                "redelm-pig/src/main/java/redelm/pig/TupleReadSupport.java": 34,
                "redelm-pig/src/main/java/redelm/pig/TupleWriter.java": 20,
                "redelm-pig/src/main/java/redelm/pig/WriteSupport.java": 12,
                "redelm-pig/src/test/java/redelm/pig/TestRedelmFileWriter.java": 7,
                "redelm-pig/src/test/java/redelm/pig/TestTupleRecordConsumer.java": 6
            },
            "is_test": true,
            "is_fix": false
        },
        "130e213b8bec04b7691e100450a5bc1d7be169f2": {
            "datetime": "2012-11-13T18:08:52-08:00",
            "summary": "better hadoop layer decoupling",
            "message": "better hadoop layer decoupling\n",
            "diff": {
                "redelm-pig/src/main/java/redelm/hadoop/ReadSupport.java": 15,
                "redelm-pig/src/main/java/redelm/hadoop/RedelmInputFormat.java": 109,
                "redelm-pig/src/main/java/redelm/hadoop/RedelmRecordReader.java": 145,
                "redelm-pig/src/main/java/redelm/pig/BlockData.java": 2,
                "redelm-pig/src/main/java/redelm/pig/BlockMetaData.java": 2,
                "redelm-pig/src/main/java/redelm/pig/ColumnData.java": 2,
                "redelm-pig/src/main/java/redelm/pig/ColumnMetaData.java": 2,
                "redelm-pig/src/main/java/redelm/pig/Footer.java": 63,
                "redelm-pig/src/main/java/redelm/pig/MetaDataBlock.java": 2,
                "redelm-pig/src/main/java/redelm/pig/PigMetaData.java": 3,
                "redelm-pig/src/main/java/redelm/pig/PrintFooter.java": 14,
                "redelm-pig/src/main/java/redelm/pig/ReadSupport.java": 14,
                "redelm-pig/src/main/java/redelm/pig/RedelmFileReader.java": 8,
                "redelm-pig/src/main/java/redelm/pig/RedelmFileWriter.java": 4,
                "redelm-pig/src/main/java/redelm/pig/RedelmInputFormat.java": 227,
                "redelm-pig/src/main/java/redelm/pig/RedelmInputSplit.java": 61,
                "redelm-pig/src/main/java/redelm/pig/RedelmLoader.java": 2,
                "redelm-pig/src/main/java/redelm/pig/RedelmOutputFormat.java": 15,
                "redelm-pig/src/main/java/redelm/pig/RedelmStorer.java": 15,
                "redelm-pig/src/main/java/redelm/pig/TupleReadSupport.java": 24,
                "redelm-pig/src/main/java/redelm/pig/TupleRecordConsumer.java": 7,
                "redelm-pig/src/main/java/redelm/pig/TupleWriteSupport.java": 2,
                "redelm-pig/src/main/java/redelm/pig/WriteSupport.java": 2,
                "redelm-pig/src/main/java/redelm/pig/summary/BagSummaryData.java": 4,
                "redelm-pig/src/main/java/redelm/pig/summary/FieldSummaryData.java": 2,
                "redelm-pig/src/main/java/redelm/pig/summary/MapSummaryData.java": 3,
                "redelm-pig/src/main/java/redelm/pig/summary/NumberSummaryData.java": 2,
                "redelm-pig/src/main/java/redelm/pig/summary/StringSummaryData.java": 2,
                "redelm-pig/src/main/java/redelm/pig/summary/SummaryData.java": 2,
                "redelm-pig/src/main/java/redelm/pig/summary/TupleSummaryData.java": 3,
                "redelm-pig/src/test/java/redelm/pig/PerfTest2.java": 16,
                "redelm-pig/src/test/java/redelm/pig/TestRedelmFileWriter.java": 9,
                "redelm-pig/src/test/java/redelm/pig/TestTupleRecordConsumer.java": 4,
                "redelm-pig/src/test/java/redelm/pig/summary/TestSummary.java": 2
            },
            "is_test": true,
            "is_fix": false
        },
        "4fb9a480910ab56af1de975e2b48aa4dd0431866": {
            "datetime": "2012-11-14T10:48:30-08:00",
            "summary": "moved hadoop implementation into its own hadoop package without dependencies on pig packages",
            "message": "moved hadoop implementation into its own hadoop package without dependencies on pig packages\n",
            "diff": {
                "redelm-pig/src/main/java/redelm/hadoop/BlockData.java": 16,
                "redelm-pig/src/main/java/redelm/hadoop/BlockMetaData.java": 38,
                "redelm-pig/src/main/java/redelm/hadoop/ColumnData.java": 29,
                "redelm-pig/src/main/java/redelm/hadoop/ColumnMetaData.java": 117,
                "redelm-pig/src/main/java/redelm/hadoop/MetaDataBlock.java": 20,
                "redelm-pig/src/main/java/redelm/hadoop/PrintFooter.java": 17,
                "redelm-pig/src/main/java/redelm/hadoop/ReadSupport.java": 20,
                "redelm-pig/src/main/java/redelm/hadoop/RedElmMetaData.java": 64,
                "redelm-pig/src/main/java/redelm/hadoop/RedelmFileReader.java": 25,
                "redelm-pig/src/main/java/redelm/hadoop/RedelmFileWriter.java": 61,
                "redelm-pig/src/main/java/redelm/hadoop/RedelmInputFormat.java": 32,
                "redelm-pig/src/main/java/redelm/hadoop/RedelmInputSplit.java": 57,
                "redelm-pig/src/main/java/redelm/hadoop/RedelmOutputFormat.java": 104,
                "redelm-pig/src/main/java/redelm/hadoop/RedelmRecordReader.java": 35,
                "redelm-pig/src/main/java/redelm/hadoop/RedelmRecordWriter.java": 110,
                "redelm-pig/src/main/java/redelm/hadoop/WriteSupport.java": 20,
                "redelm-pig/src/main/java/redelm/pig/TupleRecordConsumer.java": 9,
                "redelm-pig/src/main/java/redelm/pig/TupleWriteSupport.java": 3,
                "redelm-pig/src/test/java/redelm/pig/PerfTest.java": 7,
                "redelm-pig/src/test/java/redelm/pig/PerfTest2.java": 14,
                "redelm-pig/src/test/java/redelm/pig/TestRedelmFileWriter.java": 6,
                "redelm-pig/src/test/java/redelm/pig/TestTupleRecordConsumer.java": 7
            },
            "is_test": true,
            "is_fix": false
        },
        "fe6066bd2defd83af96c6416e1d06273278e1b6c": {
            "datetime": "2012-11-15T10:43:56-08:00",
            "summary": "get the compression codec from Configuration properties",
            "message": "get the compression codec from Configuration properties\n",
            "diff": {
                "redelm-pig/src/main/java/redelm/hadoop/RedelmFileReader.java": 42,
                "redelm-pig/src/main/java/redelm/hadoop/RedelmFileWriter.java": 46,
                "redelm-pig/src/main/java/redelm/hadoop/RedelmOutputFormat.java": 24,
                "redelm-pig/src/main/java/redelm/pig/RedelmStorer.java": 11,
                "redelm-pig/src/test/java/redelm/hadoop/TestRedelmFileWriter.java": 3,
                "redelm-pig/src/test/java/redelm/pig/PerfTest2.java": 10
            },
            "is_test": true,
            "is_fix": false
        },
        "b507f7dd6f56971f3ba6cbfab786a255e47451c1": {
            "datetime": "2012-11-15T11:56:05-08:00",
            "summary": "make block size configurable",
            "message": "make block size configurable\n",
            "diff": {
                "redelm-pig/src/main/java/redelm/hadoop/RedelmOutputFormat.java": 25,
                "redelm-pig/src/main/java/redelm/hadoop/RedelmRecordWriter.java": 7
            },
            "is_test": false,
            "is_fix": false
        },
        "5271080cd7c045a0693e5358bdc90d4f34cddd6f": {
            "datetime": "2012-11-15T13:42:53-08:00",
            "summary": "Merge pull request #11 from julienledem/move_hadoop_stuff_into_hadoop_package",
            "message": "Merge pull request #11 from julienledem/move_hadoop_stuff_into_hadoop_package\n\nMove hadoop stuff into hadoop package\r\nreviewed by jcoveney",
            "diff": {
                "redelm-pig/src/main/java/redelm/hadoop/MetaDataBlock.java": 40,
                "redelm-pig/src/main/java/redelm/hadoop/ReadSupport.java": 35,
                "redelm-pig/src/main/java/redelm/hadoop/RedelmInputFormat.java": 133,
                "redelm-pig/src/main/java/redelm/hadoop/RedelmOutputFormat.java": 117,
                "redelm-pig/src/main/java/redelm/hadoop/RedelmRecordReader.java": 176,
                "redelm-pig/src/main/java/redelm/hadoop/RedelmRecordWriter.java": 113,
                "redelm-pig/src/main/java/redelm/hadoop/WriteSupport.java": 30,
                "redelm-pig/src/main/java/redelm/pig/BlockData.java": 18,
                "redelm-pig/src/main/java/redelm/pig/BlockMetaData.java": 40,
                "redelm-pig/src/main/java/redelm/pig/ColumnData.java": 31,
                "redelm-pig/src/main/java/redelm/pig/ColumnMetaData.java": 119,
                "redelm-pig/src/main/java/redelm/pig/Footer.java": 109,
                "redelm-pig/src/main/java/redelm/pig/MetaDataBlock.java": 22,
                "redelm-pig/src/main/java/redelm/pig/PigMetaData.java": 3,
                "redelm-pig/src/main/java/redelm/pig/PrintFooter.java": 19,
                "redelm-pig/src/main/java/redelm/pig/ReadSupport.java": 14,
                "redelm-pig/src/main/java/redelm/pig/RedelmFileReader.java": 75,
                "redelm-pig/src/main/java/redelm/pig/RedelmFileWriter.java": 109,
                "redelm-pig/src/main/java/redelm/pig/RedelmInputFormat.java": 227,
                "redelm-pig/src/main/java/redelm/pig/RedelmInputSplit.java": 114,
                "redelm-pig/src/main/java/redelm/pig/RedelmLoader.java": 2,
                "redelm-pig/src/main/java/redelm/pig/RedelmOutputFormat.java": 125,
                "redelm-pig/src/main/java/redelm/pig/RedelmStorer.java": 22,
                "redelm-pig/src/main/java/redelm/pig/TupleReadSupport.java": 24,
                "redelm-pig/src/main/java/redelm/pig/TupleRecordConsumer.java": 16,
                "redelm-pig/src/main/java/redelm/pig/TupleWriteSupport.java": 5,
                "redelm-pig/src/main/java/redelm/pig/WriteSupport.java": 12,
                "redelm-pig/src/main/java/redelm/pig/summary/BagSummaryData.java": 4,
                "redelm-pig/src/main/java/redelm/pig/summary/FieldSummaryData.java": 2,
                "redelm-pig/src/main/java/redelm/pig/summary/MapSummaryData.java": 3,
                "redelm-pig/src/main/java/redelm/pig/summary/NumberSummaryData.java": 2,
                "redelm-pig/src/main/java/redelm/pig/summary/StringSummaryData.java": 2,
                "redelm-pig/src/main/java/redelm/pig/summary/SummaryData.java": 2,
                "redelm-pig/src/main/java/redelm/pig/summary/TupleSummaryData.java": 3,
                "redelm-pig/src/test/java/redelm/pig/PerfTest.java": 7,
                "redelm-pig/src/test/java/redelm/pig/PerfTest2.java": 40,
                "redelm-pig/src/test/java/redelm/pig/TestRedelmFileWriter.java": 14,
                "redelm-pig/src/test/java/redelm/pig/TestTupleRecordConsumer.java": 9,
                "redelm-pig/src/test/java/redelm/pig/summary/TestSummary.java": 2
            },
            "is_test": true,
            "is_fix": false
        },
        "1243fcc58e31131e6b13491f9fa1d126d6422e6b": {
            "datetime": "2012-11-15T15:58:51-08:00",
            "summary": "add status header",
            "message": "add status header\n",
            "diff": {
                "redelm-column/src/main/java/redelm/RedelmRuntimeException.java": 15,
                "redelm-column/src/main/java/redelm/io/InvalidRecordException.java": 15,
                "redelm-column/src/main/java/redelm/io/ValidatingRecordConsumer.java": 15,
                "redelm-pig/src/main/java/redelm/hadoop/MetaDataBlock.java": 15,
                "redelm-pig/src/main/java/redelm/hadoop/ReadSupport.java": 15,
                "redelm-pig/src/main/java/redelm/hadoop/RedelmRecordReader.java": 15,
                "redelm-pig/src/main/java/redelm/hadoop/RedelmRecordWriter.java": 15,
                "redelm-pig/src/main/java/redelm/hadoop/WriteSupport.java": 15,
                "redelm-pig/src/main/java/redelm/pig/PigMetaData.java": 15,
                "redelm-pig/src/main/java/redelm/pig/TupleReadSupport.java": 15
            },
            "is_test": false,
            "is_fix": false
        },
        "06ab2ed602ab7172a7dd55b35830b785ba737eca": {
            "datetime": "2012-11-18T15:57:42-08:00",
            "summary": "implement empty bag != null bag",
            "message": "implement empty bag != null bag\n",
            "diff": {
                "redelm-column/src/main/java/redelm/Log.java": 4,
                "redelm-pig/src/main/java/redelm/pig/PigSchemaConverter.java": 94,
                "redelm-pig/src/main/java/redelm/pig/TupleRecordConsumer.java": 92,
                "redelm-pig/src/main/java/redelm/pig/TupleWriteSupport.java": 129,
                "redelm-pig/src/test/java/redelm/pig/TestPigSchemaConverter.java": 75,
                "redelm-pig/src/test/java/redelm/pig/TestTupleRecordConsumer.java": 169
            },
            "is_test": true,
            "is_fix": false
        },
        "fbf8333a47d71e054db84334d18747f565ff9731": {
            "datetime": "2012-11-18T16:02:53-08:00",
            "summary": "cleanup unnecessary variables",
            "message": "cleanup unnecessary variables\n",
            "diff": {
                "redelm-pig/src/main/java/redelm/pig/TupleRecordConsumer.java": 5
            },
            "is_test": false,
            "is_fix": false
        },
        "87744511868c1c68c4ac6468f9eda84bd319d37a": {
            "datetime": "2012-11-19T09:40:04-08:00",
            "summary": "first stab at pregenerated Pig consumer",
            "message": "first stab at pregenerated Pig consumer\n",
            "diff": {
                "redelm-pig/src/main/java/redelm/pig/TupleReadSupport.java": 18,
                "redelm-pig/src/main/java/redelm/pig/converter/BagConverter.java": 53,
                "redelm-pig/src/main/java/redelm/pig/converter/Converter.java": 27,
                "redelm-pig/src/main/java/redelm/pig/converter/MapConverter.java": 53,
                "redelm-pig/src/main/java/redelm/pig/converter/MessageConverter.java": 93,
                "redelm-pig/src/main/java/redelm/pig/converter/TupleConverter.java": 69
            },
            "is_test": false,
            "is_fix": false
        },
        "0094892b0c7b8466afb50f4296309a83449fb359": {
            "datetime": "2012-11-19T09:46:02-08:00",
            "summary": "use non spillable databag for records",
            "message": "use non spillable databag for records\n",
            "diff": {
                "redelm-pig/src/main/java/redelm/pig/TupleRecordConsumer.java": 10
            },
            "is_test": false,
            "is_fix": false
        },
        "27c02555d97e41eb635b2441da69a36b940730b4": {
            "datetime": "2012-11-20T09:02:19-08:00",
            "summary": "make Map work",
            "message": "make Map work\n",
            "diff": {
                "redelm-pig/src/main/java/redelm/pig/TupleReadSupport.java": 21,
                "redelm-pig/src/main/java/redelm/pig/converter/BagConverter.java": 24,
                "redelm-pig/src/main/java/redelm/pig/converter/Converter.java": 9,
                "redelm-pig/src/main/java/redelm/pig/converter/MapConverter.java": 42,
                "redelm-pig/src/main/java/redelm/pig/converter/MapKeyValueConverter.java": 63,
                "redelm-pig/src/main/java/redelm/pig/converter/MessageConverter.java": 40,
                "redelm-pig/src/main/java/redelm/pig/converter/TupleConverter.java": 42,
                "redelm-pig/src/test/java/redelm/pig/TestTupleRecordConsumer.java": 21
            },
            "is_test": true,
            "is_fix": false
        },
        "ffe80dde0f3eb13cc40ec5c3efbe6ee8cb556b84": {
            "datetime": "2012-11-20T09:46:47-08:00",
            "summary": "add summary file",
            "message": "add summary file\n",
            "diff": {
                "redelm-column/src/main/java/redelm/RedelmRuntimeException.java": 15,
                "redelm-column/src/main/java/redelm/io/InvalidRecordException.java": 15,
                "redelm-column/src/main/java/redelm/io/ValidatingRecordConsumer.java": 15,
                "redelm-pig/src/main/java/redelm/hadoop/Footer.java": 50,
                "redelm-pig/src/main/java/redelm/hadoop/MetaDataBlock.java": 15,
                "redelm-pig/src/main/java/redelm/hadoop/ReadSupport.java": 15,
                "redelm-pig/src/main/java/redelm/hadoop/RedelmFileReader.java": 107,
                "redelm-pig/src/main/java/redelm/hadoop/RedelmFileWriter.java": 20,
                "redelm-pig/src/main/java/redelm/hadoop/RedelmInputFormat.java": 17,
                "redelm-pig/src/main/java/redelm/hadoop/RedelmOutputCommitter.java": 52,
                "redelm-pig/src/main/java/redelm/hadoop/RedelmOutputFormat.java": 21,
                "redelm-pig/src/main/java/redelm/hadoop/RedelmRecordReader.java": 21,
                "redelm-pig/src/main/java/redelm/hadoop/RedelmRecordWriter.java": 15,
                "redelm-pig/src/main/java/redelm/hadoop/WriteSupport.java": 15,
                "redelm-pig/src/main/java/redelm/pig/PigMetaData.java": 15,
                "redelm-pig/src/main/java/redelm/pig/TupleReadSupport.java": 15,
                "redelm-pig/src/test/java/redelm/hadoop/TestRedelmFileWriter.java": 7
            },
            "is_test": true,
            "is_fix": false
        },
        "88ed7fe5cebbef0dd1cafab50fe72354a73e5e86": {
            "datetime": "2012-11-20T09:54:59-08:00",
            "summary": "Support for short int columns by JCoveney  https://github.com/jcoveney/redelm rep_def_column",
            "message": "Support for short int columns by JCoveney  https://github.com/jcoveney/redelm rep_def_column\nadd pig snapshot\n",
            "diff": {
                "redelm-column/src/main/java/redelm/column/BytesOutput.java": 14,
                "redelm-column/src/main/java/redelm/column/ColumnDescriptor.java": 15,
                "redelm-column/src/main/java/redelm/column/ColumnWriter.java": 9,
                "redelm-column/src/main/java/redelm/column/RedelmByteArrayOutputStream.java": 5,
                "redelm-column/src/main/java/redelm/column/mem/MemColumn.java": 44,
                "redelm-column/src/main/java/redelm/column/mem/MemColumnReader.java": 29,
                "redelm-column/src/main/java/redelm/column/mem/MemColumnWriter.java": 49,
                "redelm-column/src/main/java/redelm/column/mem/MemColumnsStore.java": 14,
                "redelm-column/src/main/java/redelm/column/primitive/BitReader.java": 102,
                "redelm-column/src/main/java/redelm/column/primitive/BitWriter.java": 115,
                "redelm-column/src/main/java/redelm/column/primitive/BoundedIntColumnReader.java": 66,
                "redelm-column/src/main/java/redelm/column/primitive/BoundedIntColumnWriter.java": 130,
                "redelm-column/src/main/java/redelm/column/primitive/DevNullColumnReader.java": 98,
                "redelm-column/src/main/java/redelm/column/primitive/DevNullColumnWriter.java": 71,
                "redelm-column/src/main/java/redelm/column/primitive/PrimitiveColumnReader.java": 7,
                "redelm-column/src/main/java/redelm/column/primitive/PrimitiveColumnWriter.java": 9,
                "redelm-column/src/main/java/redelm/column/primitive/SimplePrimitiveColumnReader.java": 15,
                "redelm-column/src/main/java/redelm/column/primitive/SimplePrimitiveColumnWriter.java": 6,
                "redelm-column/src/main/java/redelm/data/GroupWriter.java": 2,
                "redelm-column/src/main/java/redelm/io/MessageColumnIO.java": 277,
                "redelm-column/src/main/java/redelm/io/PrimitiveColumnIO.java": 2,
                "redelm-column/src/main/java/redelm/schema/GroupType.java": 26,
                "redelm-column/src/main/java/redelm/schema/MessageType.java": 22,
                "redelm-column/src/main/java/redelm/schema/PrimitiveType.java": 24,
                "redelm-column/src/main/java/redelm/schema/Type.java": 6,
                "redelm-column/src/main/java/redelm/utils/Varint.java": 167,
                "redelm-column/src/test/java/redelm/column/mem/TestMemColumn.java": 32,
                "redelm-column/src/test/java/redelm/column/primitive/TestBoundedColumns.java": 90,
                "redelm-column/src/test/java/redelm/io/PerfTest.java": 2,
                "redelm-column/src/test/java/redelm/io/TestColumnIO.java": 17,
                "redelm-pig/src/main/java/redelm/hadoop/ColumnData.java": 6,
                "redelm-pig/src/main/java/redelm/hadoop/RedelmFileWriter.java": 13,
                "redelm-pig/src/main/java/redelm/hadoop/RedelmRecordReader.java": 16,
                "redelm-pig/src/main/java/redelm/hadoop/RedelmRecordWriter.java": 25,
                "redelm-pig/src/test/java/redelm/hadoop/TestRedelmFileWriter.java": 13
            },
            "is_test": true,
            "is_fix": false
        },
        "af992f3673cd06e4353354230f78deb674161322": {
            "datetime": "2012-11-20T10:00:41-08:00",
            "summary": "fixed doc based on jco's comments",
            "message": "fixed doc based on jco's comments\n",
            "diff": {
                "redelm-column/src/main/java/redelm/Log.java": 2,
                "redelm-pig/src/main/java/redelm/pig/PigSchemaConverter.java": 2
            },
            "is_test": false,
            "is_fix": false
        },
        "4a372bce138cce95a72f9d4b69ae37e434d5e27e": {
            "datetime": "2012-11-20T10:13:45-08:00",
            "summary": "Merge branch 'master' into summary_file",
            "message": "Merge branch 'master' into summary_file\n\nConflicts:\n\tredelm-pig/src/main/java/redelm/hadoop/RedelmFileWriter.java\n\tredelm-pig/src/main/java/redelm/hadoop/RedelmRecordReader.java\n",
            "diff": {
                "redelm-column/src/main/java/redelm/column/BytesOutput.java": 14,
                "redelm-column/src/main/java/redelm/column/ColumnDescriptor.java": 15,
                "redelm-column/src/main/java/redelm/column/ColumnWriter.java": 9,
                "redelm-column/src/main/java/redelm/column/RedelmByteArrayOutputStream.java": 5,
                "redelm-column/src/main/java/redelm/column/mem/MemColumn.java": 44,
                "redelm-column/src/main/java/redelm/column/mem/MemColumnReader.java": 29,
                "redelm-column/src/main/java/redelm/column/mem/MemColumnWriter.java": 49,
                "redelm-column/src/main/java/redelm/column/mem/MemColumnsStore.java": 14,
                "redelm-column/src/main/java/redelm/column/primitive/BitReader.java": 102,
                "redelm-column/src/main/java/redelm/column/primitive/BitWriter.java": 115,
                "redelm-column/src/main/java/redelm/column/primitive/BoundedIntColumnReader.java": 66,
                "redelm-column/src/main/java/redelm/column/primitive/BoundedIntColumnWriter.java": 130,
                "redelm-column/src/main/java/redelm/column/primitive/DevNullColumnReader.java": 98,
                "redelm-column/src/main/java/redelm/column/primitive/DevNullColumnWriter.java": 71,
                "redelm-column/src/main/java/redelm/column/primitive/PrimitiveColumnReader.java": 7,
                "redelm-column/src/main/java/redelm/column/primitive/PrimitiveColumnWriter.java": 9,
                "redelm-column/src/main/java/redelm/column/primitive/SimplePrimitiveColumnReader.java": 15,
                "redelm-column/src/main/java/redelm/column/primitive/SimplePrimitiveColumnWriter.java": 6,
                "redelm-column/src/main/java/redelm/data/GroupWriter.java": 2,
                "redelm-column/src/main/java/redelm/io/MessageColumnIO.java": 277,
                "redelm-column/src/main/java/redelm/io/PrimitiveColumnIO.java": 2,
                "redelm-column/src/main/java/redelm/schema/GroupType.java": 26,
                "redelm-column/src/main/java/redelm/schema/MessageType.java": 22,
                "redelm-column/src/main/java/redelm/schema/PrimitiveType.java": 24,
                "redelm-column/src/main/java/redelm/schema/Type.java": 6,
                "redelm-column/src/main/java/redelm/utils/Varint.java": 167,
                "redelm-column/src/test/java/redelm/column/mem/TestMemColumn.java": 32,
                "redelm-column/src/test/java/redelm/column/primitive/TestBoundedColumns.java": 90,
                "redelm-column/src/test/java/redelm/io/PerfTest.java": 2,
                "redelm-column/src/test/java/redelm/io/TestColumnIO.java": 17,
                "redelm-pig/src/main/java/redelm/hadoop/ColumnData.java": 6,
                "redelm-pig/src/main/java/redelm/hadoop/RedelmFileWriter.java": 12,
                "redelm-pig/src/main/java/redelm/hadoop/RedelmRecordReader.java": 2,
                "redelm-pig/src/main/java/redelm/hadoop/RedelmRecordWriter.java": 25,
                "redelm-pig/src/test/java/redelm/hadoop/TestRedelmFileWriter.java": 13
            },
            "is_test": true,
            "is_fix": false
        },
        "ad3b4596d0b84885f0377a0cd9ea6e8d983b3177": {
            "datetime": "2012-11-20T10:15:21-08:00",
            "summary": "Merge branch 'master' into preprocess_pig_schema",
            "message": "Merge branch 'master' into preprocess_pig_schema\n",
            "diff": {
                "redelm-column/src/main/java/redelm/column/BytesOutput.java": 14,
                "redelm-column/src/main/java/redelm/column/ColumnDescriptor.java": 15,
                "redelm-column/src/main/java/redelm/column/ColumnWriter.java": 9,
                "redelm-column/src/main/java/redelm/column/RedelmByteArrayOutputStream.java": 5,
                "redelm-column/src/main/java/redelm/column/mem/MemColumn.java": 44,
                "redelm-column/src/main/java/redelm/column/mem/MemColumnReader.java": 29,
                "redelm-column/src/main/java/redelm/column/mem/MemColumnWriter.java": 49,
                "redelm-column/src/main/java/redelm/column/mem/MemColumnsStore.java": 14,
                "redelm-column/src/main/java/redelm/column/primitive/BitReader.java": 102,
                "redelm-column/src/main/java/redelm/column/primitive/BitWriter.java": 115,
                "redelm-column/src/main/java/redelm/column/primitive/BoundedIntColumnReader.java": 66,
                "redelm-column/src/main/java/redelm/column/primitive/BoundedIntColumnWriter.java": 130,
                "redelm-column/src/main/java/redelm/column/primitive/DevNullColumnReader.java": 98,
                "redelm-column/src/main/java/redelm/column/primitive/DevNullColumnWriter.java": 71,
                "redelm-column/src/main/java/redelm/column/primitive/PrimitiveColumnReader.java": 7,
                "redelm-column/src/main/java/redelm/column/primitive/PrimitiveColumnWriter.java": 9,
                "redelm-column/src/main/java/redelm/column/primitive/SimplePrimitiveColumnReader.java": 15,
                "redelm-column/src/main/java/redelm/column/primitive/SimplePrimitiveColumnWriter.java": 6,
                "redelm-column/src/main/java/redelm/data/GroupWriter.java": 2,
                "redelm-column/src/main/java/redelm/io/MessageColumnIO.java": 277,
                "redelm-column/src/main/java/redelm/io/PrimitiveColumnIO.java": 2,
                "redelm-column/src/main/java/redelm/schema/GroupType.java": 26,
                "redelm-column/src/main/java/redelm/schema/MessageType.java": 22,
                "redelm-column/src/main/java/redelm/schema/PrimitiveType.java": 24,
                "redelm-column/src/main/java/redelm/schema/Type.java": 6,
                "redelm-column/src/main/java/redelm/utils/Varint.java": 167,
                "redelm-column/src/test/java/redelm/column/mem/TestMemColumn.java": 32,
                "redelm-column/src/test/java/redelm/column/primitive/TestBoundedColumns.java": 90,
                "redelm-column/src/test/java/redelm/io/PerfTest.java": 2,
                "redelm-column/src/test/java/redelm/io/TestColumnIO.java": 17,
                "redelm-pig/src/main/java/redelm/hadoop/ColumnData.java": 6,
                "redelm-pig/src/main/java/redelm/hadoop/RedelmFileWriter.java": 13,
                "redelm-pig/src/main/java/redelm/hadoop/RedelmRecordReader.java": 16,
                "redelm-pig/src/main/java/redelm/hadoop/RedelmRecordWriter.java": 25,
                "redelm-pig/src/test/java/redelm/hadoop/TestRedelmFileWriter.java": 13
            },
            "is_test": true,
            "is_fix": false
        },
        "40b0cb333cfff0fd46c0c54cef0723f6acc87277": {
            "datetime": "2012-11-20T10:27:03-08:00",
            "summary": "Merge pull request #13 from julienledem/fix_empty_bag_equals_null_bag",
            "message": "Merge pull request #13 from julienledem/fix_empty_bag_equals_null_bag\n\nFix empty bag equals null bag",
            "diff": {
                "redelm-column/src/main/java/redelm/Log.java": 4,
                "redelm-pig/src/main/java/redelm/pig/PigSchemaConverter.java": 94,
                "redelm-pig/src/main/java/redelm/pig/TupleRecordConsumer.java": 99,
                "redelm-pig/src/main/java/redelm/pig/TupleWriteSupport.java": 129,
                "redelm-pig/src/test/java/redelm/pig/TestPigSchemaConverter.java": 75,
                "redelm-pig/src/test/java/redelm/pig/TestTupleRecordConsumer.java": 169
            },
            "is_test": true,
            "is_fix": false
        },
        "bdc5a6e184f02ae130bbd345e8fd69b287a42957": {
            "datetime": "2012-11-21T11:13:44-08:00",
            "summary": "fix compression javadoc",
            "message": "fix compression javadoc\n",
            "diff": {
                "redelm-pig/src/main/java/redelm/hadoop/RedelmFileWriter.java": 11,
                "redelm-pig/src/main/java/redelm/hadoop/RedelmOutputFormat.java": 9
            },
            "is_test": false,
            "is_fix": false
        },
        "bce0f0d01c5ca92ac1f76d741e60701ef87bb12d": {
            "datetime": "2012-11-21T13:19:32-08:00",
            "summary": "fix Codec Logging",
            "message": "fix Codec Logging\n",
            "diff": {
                "redelm-column/src/main/java/redelm/Log.java": 2,
                "redelm-column/src/main/java/redelm/column/mem/MemColumnWriter.java": 2,
                "redelm-column/src/main/java/redelm/data/GroupRecordConsumer.java": 6,
                "redelm-pig/src/main/java/redelm/hadoop/RedelmOutputFormat.java": 9
            },
            "is_test": false,
            "is_fix": false
        },
        "6f4650ad2149facd860ed6977cdd095f42941159": {
            "datetime": "2012-11-21T14:17:05-08:00",
            "summary": "Merge branch 'master' into preprocess_pig_schema",
            "message": "Merge branch 'master' into preprocess_pig_schema\n",
            "diff": {
                "redelm-column/src/main/java/redelm/Log.java": 2,
                "redelm-pig/src/main/java/redelm/hadoop/RedelmFileWriter.java": 11,
                "redelm-pig/src/main/java/redelm/hadoop/RedelmOutputFormat.java": 9,
                "redelm-pig/src/main/java/redelm/pig/PigSchemaConverter.java": 2,
                "redelm-pig/src/main/java/redelm/pig/TupleRecordConsumer.java": 10
            },
            "is_test": false,
            "is_fix": false
        },
        "48ef66b4dfbdae93218f3886894f3ce4ccb7fc99": {
            "datetime": "2012-11-21T14:25:20-08:00",
            "summary": "fix exception handling",
            "message": "fix exception handling\n",
            "diff": {
                "redelm-pig/src/main/java/redelm/pig/TupleRecordConsumer.java": 14
            },
            "is_test": false,
            "is_fix": false
        },
        "c73105c4c37bef5618c255b5988ebc29166c7737": {
            "datetime": "2012-11-21T14:33:55-08:00",
            "summary": "fix exceptions in Converters",
            "message": "fix exceptions in Converters\n",
            "diff": {
                "redelm-pig/src/main/java/redelm/pig/TupleConversionException.java": 24,
                "redelm-pig/src/main/java/redelm/pig/TupleRecordConsumer.java": 12,
                "redelm-pig/src/main/java/redelm/pig/converter/BagConverter.java": 3,
                "redelm-pig/src/main/java/redelm/pig/converter/MapConverter.java": 3,
                "redelm-pig/src/main/java/redelm/pig/converter/TupleConverter.java": 9
            },
            "is_test": false,
            "is_fix": false
        },
        "4c0a1f764024574380636bb612b65e3f6ac9fd12": {
            "datetime": "2012-11-21T16:14:50-08:00",
            "summary": "Merge pull request #14 from julienledem/preprocess_pig_schema",
            "message": "Merge pull request #14 from julienledem/preprocess_pig_schema\n\nPreprocess pig schema",
            "diff": {
                "redelm-pig/src/main/java/redelm/pig/TupleConversionException.java": 24,
                "redelm-pig/src/main/java/redelm/pig/TupleReadSupport.java": 35,
                "redelm-pig/src/main/java/redelm/pig/TupleRecordConsumer.java": 14,
                "redelm-pig/src/main/java/redelm/pig/converter/BagConverter.java": 56,
                "redelm-pig/src/main/java/redelm/pig/converter/Converter.java": 34,
                "redelm-pig/src/main/java/redelm/pig/converter/MapConverter.java": 58,
                "redelm-pig/src/main/java/redelm/pig/converter/MapKeyValueConverter.java": 63,
                "redelm-pig/src/main/java/redelm/pig/converter/MessageConverter.java": 99,
                "redelm-pig/src/main/java/redelm/pig/converter/TupleConverter.java": 94,
                "redelm-pig/src/test/java/redelm/pig/TestTupleRecordConsumer.java": 21
            },
            "is_test": true,
            "is_fix": false
        },
        "0549961a0e4740d628a493dfeaaad37f6531c73f": {
            "datetime": "2012-11-21T16:15:30-08:00",
            "summary": "Merge pull request #16 from julienledem/fix_Codec_Logging",
            "message": "Merge pull request #16 from julienledem/fix_Codec_Logging\n\nfix Codec Logging",
            "diff": {
                "redelm-column/src/main/java/redelm/Log.java": 2,
                "redelm-column/src/main/java/redelm/column/mem/MemColumnWriter.java": 2,
                "redelm-column/src/main/java/redelm/data/GroupRecordConsumer.java": 6,
                "redelm-pig/src/main/java/redelm/hadoop/RedelmOutputFormat.java": 9
            },
            "is_test": false,
            "is_fix": false
        },
        "9385a2fca031b0c5dcf681172e151f6aea8e1ac1": {
            "datetime": "2012-11-26T10:37:19-08:00",
            "summary": "Merge branch 'master' of github.com:julienledem/redelm",
            "message": "Merge branch 'master' of github.com:julienledem/redelm\n",
            "diff": {
                "redelm-column/src/main/java/redelm/Log.java": 2,
                "redelm-column/src/main/java/redelm/column/mem/MemColumnWriter.java": 2,
                "redelm-column/src/main/java/redelm/data/GroupRecordConsumer.java": 6,
                "redelm-pig/src/main/java/redelm/hadoop/RedelmOutputFormat.java": 9,
                "redelm-pig/src/main/java/redelm/pig/TupleConversionException.java": 24,
                "redelm-pig/src/main/java/redelm/pig/TupleReadSupport.java": 35,
                "redelm-pig/src/main/java/redelm/pig/TupleRecordConsumer.java": 14,
                "redelm-pig/src/main/java/redelm/pig/converter/BagConverter.java": 56,
                "redelm-pig/src/main/java/redelm/pig/converter/Converter.java": 34,
                "redelm-pig/src/main/java/redelm/pig/converter/MapConverter.java": 58,
                "redelm-pig/src/main/java/redelm/pig/converter/MapKeyValueConverter.java": 63,
                "redelm-pig/src/main/java/redelm/pig/converter/MessageConverter.java": 99,
                "redelm-pig/src/main/java/redelm/pig/converter/TupleConverter.java": 94,
                "redelm-pig/src/test/java/redelm/pig/TestTupleRecordConsumer.java": 21
            },
            "is_test": true,
            "is_fix": false
        },
        "ee02094ff08af675b619412686ef55dee6c7e09c": {
            "datetime": "2012-11-28T13:59:42-08:00",
            "summary": "better logging and perf tests",
            "message": "better logging and perf tests\n",
            "diff": {
                "redelm-column/src/test/java/redelm/io/PerfTest.java": 7,
                "redelm-pig/src/main/java/redelm/hadoop/RedelmFileReader.java": 7,
                "redelm-pig/src/main/java/redelm/hadoop/RedelmInputSplit.java": 3,
                "redelm-pig/src/main/java/redelm/hadoop/RedelmMetaData.java": 8,
                "redelm-pig/src/main/java/redelm/hadoop/RedelmRecordReader.java": 31,
                "redelm-pig/src/test/java/redelm/pig/PerfTest2.java": 52,
                "redelm-pig/src/test/java/redelm/pig/PerfTestReadAllCols.java": 48,
                "redelm-pig/src/test/java/redelm/pig/TupleConsumerPerfTest.java": 261
            },
            "is_test": true,
            "is_fix": false
        },
        "9223ad517e9d42434b9ceb388154afb472c325c2": {
            "datetime": "2012-11-28T14:10:21-08:00",
            "summary": "Merge branch 'master' into summary_file",
            "message": "Merge branch 'master' into summary_file\n\nConflicts:\n\tredelm-pig/src/main/java/redelm/hadoop/RedelmFileWriter.java\n\tredelm-pig/src/main/java/redelm/hadoop/RedelmOutputFormat.java\n",
            "diff": {
                "redelm-column/src/main/java/redelm/Log.java": 6,
                "redelm-column/src/main/java/redelm/column/mem/MemColumnWriter.java": 2,
                "redelm-column/src/main/java/redelm/data/GroupRecordConsumer.java": 6,
                "redelm-pig/src/main/java/redelm/hadoop/RedelmFileWriter.java": 11,
                "redelm-pig/src/main/java/redelm/hadoop/RedelmOutputFormat.java": 14,
                "redelm-pig/src/main/java/redelm/pig/PigSchemaConverter.java": 94,
                "redelm-pig/src/main/java/redelm/pig/TupleConversionException.java": 24,
                "redelm-pig/src/main/java/redelm/pig/TupleReadSupport.java": 35,
                "redelm-pig/src/main/java/redelm/pig/TupleRecordConsumer.java": 109,
                "redelm-pig/src/main/java/redelm/pig/TupleWriteSupport.java": 129,
                "redelm-pig/src/main/java/redelm/pig/converter/BagConverter.java": 56,
                "redelm-pig/src/main/java/redelm/pig/converter/Converter.java": 34,
                "redelm-pig/src/main/java/redelm/pig/converter/MapConverter.java": 58,
                "redelm-pig/src/main/java/redelm/pig/converter/MapKeyValueConverter.java": 63,
                "redelm-pig/src/main/java/redelm/pig/converter/MessageConverter.java": 99,
                "redelm-pig/src/main/java/redelm/pig/converter/TupleConverter.java": 94,
                "redelm-pig/src/test/java/redelm/pig/TestPigSchemaConverter.java": 75,
                "redelm-pig/src/test/java/redelm/pig/TestTupleRecordConsumer.java": 172
            },
            "is_test": true,
            "is_fix": false
        },
        "817b54b4cb6bd96e77df5879fdc02fc2f0e73d10": {
            "datetime": "2012-11-28T14:13:41-08:00",
            "summary": "Merge pull request #17 from julienledem/summary_file",
            "message": "Merge pull request #17 from julienledem/summary_file\n\nSummary file",
            "diff": {
                "redelm-pig/src/main/java/redelm/hadoop/Footer.java": 50,
                "redelm-pig/src/main/java/redelm/hadoop/RedelmFileReader.java": 107,
                "redelm-pig/src/main/java/redelm/hadoop/RedelmFileWriter.java": 21,
                "redelm-pig/src/main/java/redelm/hadoop/RedelmInputFormat.java": 17,
                "redelm-pig/src/main/java/redelm/hadoop/RedelmOutputCommitter.java": 52,
                "redelm-pig/src/main/java/redelm/hadoop/RedelmOutputFormat.java": 13,
                "redelm-pig/src/main/java/redelm/hadoop/RedelmRecordReader.java": 20,
                "redelm-pig/src/test/java/redelm/hadoop/TestRedelmFileWriter.java": 7
            },
            "is_test": true,
            "is_fix": false
        },
        "615c23c3c573109646ffcc5e244e3cb4ff551328": {
            "datetime": "2012-11-29T22:40:42-08:00",
            "summary": "make splits contain all data blocks starting in the same HDFS block",
            "message": "make splits contain all data blocks starting in the same HDFS block\n",
            "diff": {
                "redelm-column/src/main/java/redelm/column/mem/MemColumnWriter.java": 4,
                "redelm-pig/src/main/java/redelm/hadoop/RedelmInputFormat.java": 64,
                "redelm-pig/src/main/java/redelm/hadoop/RedelmInputSplit.java": 17,
                "redelm-pig/src/main/java/redelm/hadoop/RedelmRecordReader.java": 22,
                "redelm-pig/src/main/java/redelm/hadoop/RedelmRecordWriter.java": 2,
                "redelm-pig/src/test/java/redelm/hadoop/TestInputFormat.java": 60
            },
            "is_test": true,
            "is_fix": false
        },
        "b23e1f64bb362c838dafd18f324e23425e2b25d0": {
            "datetime": "2012-11-29T22:43:18-08:00",
            "summary": "add missing license headers",
            "message": "add missing license headers\n",
            "diff": {
                "redelm-pig/src/main/java/redelm/pig/TupleConversionException.java": 15,
                "redelm-pig/src/main/java/redelm/pig/converter/BagConverter.java": 15,
                "redelm-pig/src/main/java/redelm/pig/converter/Converter.java": 15,
                "redelm-pig/src/main/java/redelm/pig/converter/MapConverter.java": 15,
                "redelm-pig/src/main/java/redelm/pig/converter/MapKeyValueConverter.java": 15,
                "redelm-pig/src/main/java/redelm/pig/converter/MessageConverter.java": 15,
                "redelm-pig/src/main/java/redelm/pig/converter/TupleConverter.java": 15,
                "redelm-pig/src/test/java/redelm/hadoop/TestInputFormat.java": 15
            },
            "is_test": true,
            "is_fix": false
        },
        "e186b7dcde95264a2dfdd2b179a23e1e2e4861f5": {
            "datetime": "2012-11-30T09:20:57-08:00",
            "summary": "fix UDFContext collision when multiple stores",
            "message": "fix UDFContext collision when multiple stores\n",
            "diff": {
                "redelm-pig/src/main/java/redelm/pig/RedelmStorer.java": 75
            },
            "is_test": false,
            "is_fix": false
        },
        "73d4fde0e069b31efc63e2a91a1d7c10984d9db1": {
            "datetime": "2012-12-02T22:02:44-08:00",
            "summary": "first stab at record reader compiler",
            "message": "first stab at record reader compiler\n",
            "diff": {
                "redelm-column/src/main/java/redelm/column/mem/MemColumnReader.java": 3,
                "redelm-column/src/main/java/redelm/io/RecordReader.java": 30,
                "redelm-column/src/main/java/redelm/io/RecordReaderCompiler.java": 92,
                "redelm-column/src/test/java/redelm/io/ExpectationValidatingRecordConsumer.java": 86,
                "redelm-column/src/test/java/redelm/io/TestColumnIO.java": 188,
                "redelm-column/src/test/java/redelm/io/TestRecordReaderCompiler.java": 35,
                "redelm-pig/src/test/java/redelm/pig/TupleConsumerPerfTest.java": 3
            },
            "is_test": true,
            "is_fix": false
        },
        "0f88e2922f930a1c4486dbe8a7aea80df5a4dd7f": {
            "datetime": "2012-12-03T14:57:39-08:00",
            "summary": "simplified record reader; a little more of reader compiler",
            "message": "simplified record reader; a little more of reader compiler\n",
            "diff": {
                "redelm-column/src/main/java/redelm/io/RecordReader.java": 23,
                "redelm-column/src/main/java/redelm/io/RecordReaderCompiler.java": 70
            },
            "is_test": false,
            "is_fix": false
        },
        "104b21971a95cc16042f7af2df55321ec45d63af": {
            "datetime": "2012-12-03T15:03:15-08:00",
            "summary": "remove currentNodePath from reader and improve perf a lot",
            "message": "remove currentNodePath from reader and improve perf a lot\n",
            "diff": {
                "redelm-column/src/main/java/redelm/io/RecordReader.java": 10,
                "redelm-column/src/test/java/redelm/io/PerfTest.java": 1
            },
            "is_test": true,
            "is_fix": false
        },
        "7133e58f53697bd544e647de24ba6c2c63a20a68": {
            "datetime": "2012-12-03T15:42:57-08:00",
            "summary": "Merge pull request #19 from julienledem/remove_currentNodePath_from_reader",
            "message": "Merge pull request #19 from julienledem/remove_currentNodePath_from_reader\n\nremove currentNodePath from reader and improve perf a lot",
            "diff": {
                "redelm-column/src/main/java/redelm/io/RecordReader.java": 10,
                "redelm-column/src/test/java/redelm/io/PerfTest.java": 1
            },
            "is_test": true,
            "is_fix": false
        },
        "c4a41dd9e06334829a3d0ddd8535a8a7fa7ad0e1": {
            "datetime": "2012-12-14T07:58:38-08:00",
            "summary": "more fsa codegen",
            "message": "more fsa codegen\n",
            "diff": {
                "redelm-column/src/main/java/redelm/io/ColumnIO.java": 8,
                "redelm-column/src/main/java/redelm/io/PrimitiveColumnIO.java": 5,
                "redelm-column/src/main/java/redelm/io/RecordReader.java": 13,
                "redelm-column/src/main/java/redelm/io/RecordReaderCompiler.java": 113,
                "redelm-column/src/test/java/redelm/io/TestRecordReaderCompiler.java": 18
            },
            "is_test": true,
            "is_fix": false
        },
        "072db3ed0a02e5f5476f5366eb4b654e837c3d62": {
            "datetime": "2012-12-14T18:02:20-08:00",
            "summary": "change record reader init lifecycle",
            "message": "change record reader init lifecycle\n",
            "diff": {
                "redelm-column/src/main/java/redelm/data/GroupRecordConsumer.java": 16,
                "redelm-column/src/main/java/redelm/io/MessageColumnIO.java": 16,
                "redelm-column/src/main/java/redelm/io/RecordConsumer.java": 9,
                "redelm-column/src/main/java/redelm/io/RecordConsumerWrapper.java": 12,
                "redelm-column/src/main/java/redelm/io/RecordReader.java": 42,
                "redelm-column/src/main/java/redelm/io/ValidatingRecordConsumer.java": 12,
                "redelm-column/src/test/java/redelm/io/PerfTest.java": 88,
                "redelm-column/src/test/java/redelm/io/TestColumnIO.java": 39,
                "redelm-pig/src/main/java/redelm/hadoop/ReadSupport.java": 3,
                "redelm-pig/src/main/java/redelm/hadoop/RedelmRecordReader.java": 39,
                "redelm-pig/src/main/java/redelm/pig/TupleReadSupport.java": 4,
                "redelm-pig/src/main/java/redelm/pig/TupleRecordConsumer.java": 16,
                "redelm-pig/src/main/java/redelm/pig/converter/MessageConverter.java": 24,
                "redelm-pig/src/test/java/redelm/pig/TestTupleRecordConsumer.java": 21
            },
            "is_test": true,
            "is_fix": false
        },
        "48f0e8f83705dff3bf85bd4be91309144c7fa0ae": {
            "datetime": "2012-12-14T18:46:46-08:00",
            "summary": "refactor record consumer materializer",
            "message": "refactor record consumer materializer\n",
            "diff": {
                "redelm-column/src/main/java/redelm/data/GroupRecordConsumer.java": 4,
                "redelm-column/src/main/java/redelm/io/ColumnIOFactory.java": 16,
                "redelm-column/src/main/java/redelm/io/MessageColumnIO.java": 24,
                "redelm-column/src/main/java/redelm/io/RecordConsumer.java": 9,
                "redelm-column/src/main/java/redelm/io/RecordConsumerWrapper.java": 12,
                "redelm-column/src/main/java/redelm/io/RecordMaterializer.java": 19,
                "redelm-column/src/main/java/redelm/io/RecordReader.java": 26,
                "redelm-column/src/main/java/redelm/io/ValidatingRecordConsumer.java": 12,
                "redelm-column/src/test/java/redelm/io/PerfTest.java": 5,
                "redelm-column/src/test/java/redelm/io/TestColumnIO.java": 13,
                "redelm-pig/src/main/java/redelm/hadoop/ReadSupport.java": 6,
                "redelm-pig/src/main/java/redelm/pig/TupleReadSupport.java": 4,
                "redelm-pig/src/main/java/redelm/pig/TupleRecordConsumer.java": 4,
                "redelm-pig/src/main/java/redelm/pig/converter/MessageConverter.java": 6,
                "redelm-pig/src/test/java/redelm/pig/TestTupleRecordConsumer.java": 20
            },
            "is_test": true,
            "is_fix": false
        },
        "b6f0ca6b2b764a5697f05659626206fcdee10954": {
            "datetime": "2012-12-17T08:09:02-08:00",
            "summary": "remove unnecessary constructor param",
            "message": "remove unnecessary constructor param\n",
            "diff": {
                "redelm-column/src/main/java/redelm/io/MessageColumnIO.java": 2,
                "redelm-column/src/main/java/redelm/io/RecordReader.java": 10
            },
            "is_test": false,
            "is_fix": false
        },
        "eaf317134352cf0c3309f9b747184ebf1400077b": {
            "datetime": "2012-12-17T08:15:35-08:00",
            "summary": "Merge branch 'master' into improve_record_consumer_interface",
            "message": "Merge branch 'master' into improve_record_consumer_interface\n\nConflicts:\n\tredelm-column/src/main/java/redelm/io/RecordReader.java\n\tredelm-pig/src/main/java/redelm/hadoop/RedelmRecordReader.java\n",
            "diff": {
                "redelm-column/src/main/java/redelm/io/RecordReader.java": 13,
                "redelm-pig/src/main/java/redelm/hadoop/Footer.java": 50,
                "redelm-pig/src/main/java/redelm/hadoop/RedelmFileReader.java": 107,
                "redelm-pig/src/main/java/redelm/hadoop/RedelmFileWriter.java": 21,
                "redelm-pig/src/main/java/redelm/hadoop/RedelmInputFormat.java": 17,
                "redelm-pig/src/main/java/redelm/hadoop/RedelmOutputCommitter.java": 52,
                "redelm-pig/src/main/java/redelm/hadoop/RedelmOutputFormat.java": 13,
                "redelm-pig/src/main/java/redelm/hadoop/RedelmRecordReader.java": 6,
                "redelm-pig/src/test/java/redelm/hadoop/TestRedelmFileWriter.java": 7
            },
            "is_test": true,
            "is_fix": false
        },
        "4e5da20979304e9005f67bb93cca165ef9ed6f56": {
            "datetime": "2012-12-17T15:24:08-08:00",
            "summary": "introduce state object",
            "message": "introduce state object\n",
            "diff": {
                "redelm-column/src/main/java/redelm/io/RecordReader.java": 43
            },
            "is_test": false,
            "is_fix": false
        },
        "27c93d0622e49ad44d4d1c2a10a0a11c4ae1b241": {
            "datetime": "2012-12-18T09:34:11-08:00",
            "summary": "more use of the state class",
            "message": "more use of the state class\n",
            "diff": {
                "redelm-column/src/main/java/redelm/io/RecordReader.java": 130
            },
            "is_test": false,
            "is_fix": false
        },
        "8f2c7e598dde293312f6d1894affb7630bb62591": {
            "datetime": "2012-12-19T17:57:14-08:00",
            "summary": "slight improvement to the record reader",
            "message": "slight improvement to the record reader\n",
            "diff": {
                "redelm-column/src/main/java/redelm/io/RecordReader.java": 70,
                "redelm-column/src/test/java/redelm/io/PerfTest.java": 7
            },
            "is_test": true,
            "is_fix": false
        },
        "7dd9300aa63c3abf783ae5d8046c4bad8f1ccde3": {
            "datetime": "2012-12-19T22:04:41-08:00",
            "summary": "remove dependency of column io on column store",
            "message": "remove dependency of column io on column store\n",
            "diff": {
                "redelm-column/src/main/java/redelm/io/ColumnIO.java": 5,
                "redelm-column/src/main/java/redelm/io/ColumnIOFactory.java": 13,
                "redelm-column/src/main/java/redelm/io/GroupColumnIO.java": 15,
                "redelm-column/src/main/java/redelm/io/MessageColumnIO.java": 63,
                "redelm-column/src/main/java/redelm/io/PrimitiveColumnIO.java": 32,
                "redelm-column/src/main/java/redelm/io/RecordReader.java": 6,
                "redelm-column/src/test/java/redelm/io/PerfTest.java": 13,
                "redelm-column/src/test/java/redelm/io/TestColumnIO.java": 24,
                "redelm-pig/src/main/java/redelm/hadoop/RedelmRecordReader.java": 4,
                "redelm-pig/src/main/java/redelm/hadoop/RedelmRecordWriter.java": 4
            },
            "is_test": true,
            "is_fix": false
        },
        "e7354598b543a3f86ca304e07596d08c27d1660b": {
            "datetime": "2012-12-19T22:15:56-08:00",
            "summary": "remove unecessary class parameter",
            "message": "remove unecessary class parameter\n",
            "diff": {
                "redelm-column/src/main/java/redelm/io/RecordReader.java": 3,
                "redelm-column/src/main/java/redelm/io/ValidatingRecordConsumer.java": 2
            },
            "is_test": false,
            "is_fix": false
        },
        "5334a2d7933483d032c914fa2dfeb269513b574e": {
            "datetime": "2012-12-19T22:27:35-08:00",
            "summary": "add missing license headers",
            "message": "add missing license headers\n",
            "diff": {
                "redelm-column/src/main/java/redelm/io/RecordMaterializer.java": 15,
                "redelm-pig/src/main/java/redelm/pig/TupleConversionException.java": 15,
                "redelm-pig/src/main/java/redelm/pig/converter/BagConverter.java": 15,
                "redelm-pig/src/main/java/redelm/pig/converter/Converter.java": 15,
                "redelm-pig/src/main/java/redelm/pig/converter/MapConverter.java": 15,
                "redelm-pig/src/main/java/redelm/pig/converter/MapKeyValueConverter.java": 15,
                "redelm-pig/src/main/java/redelm/pig/converter/MessageConverter.java": 15,
                "redelm-pig/src/main/java/redelm/pig/converter/TupleConverter.java": 15
            },
            "is_test": false,
            "is_fix": false
        },
        "11b6a8f09923617cd54bb55ad3216972dca00d8e": {
            "datetime": "2012-12-22T17:48:22-08:00",
            "summary": "Merge branch 'improve_record_consumer_interface' into FSA_codegen",
            "message": "Merge branch 'improve_record_consumer_interface' into FSA_codegen\n\nConflicts:\n\tredelm-column/src/main/java/redelm/io/PrimitiveColumnIO.java\n\tredelm-column/src/main/java/redelm/io/RecordReader.java\n\tredelm-column/src/test/java/redelm/io/PerfTest.java\n\tredelm-column/src/test/java/redelm/io/TestColumnIO.java\n\tredelm-pig/src/main/java/redelm/hadoop/RedelmRecordReader.java\n",
            "diff": {
                "redelm-column/src/main/java/redelm/data/GroupRecordConsumer.java": 18,
                "redelm-column/src/main/java/redelm/io/ColumnIO.java": 5,
                "redelm-column/src/main/java/redelm/io/ColumnIOFactory.java": 25,
                "redelm-column/src/main/java/redelm/io/GroupColumnIO.java": 15,
                "redelm-column/src/main/java/redelm/io/MessageColumnIO.java": 71,
                "redelm-column/src/main/java/redelm/io/PrimitiveColumnIO.java": 32,
                "redelm-column/src/main/java/redelm/io/RecordMaterializer.java": 34,
                "redelm-column/src/main/java/redelm/io/RecordReader.java": 253,
                "redelm-column/src/main/java/redelm/io/RecordReaderCompiler.java": 274,
                "redelm-column/src/test/java/redelm/io/ExpectationValidatingRecordConsumer.java": 7,
                "redelm-column/src/test/java/redelm/io/PerfTest.java": 128,
                "redelm-column/src/test/java/redelm/io/TestColumnIO.java": 46,
                "redelm-column/src/test/java/redelm/io/TestRecordReaderCompiler.java": 15,
                "redelm-pig/src/main/java/redelm/hadoop/Footer.java": 50,
                "redelm-pig/src/main/java/redelm/hadoop/ReadSupport.java": 7,
                "redelm-pig/src/main/java/redelm/hadoop/RedelmFileReader.java": 107,
                "redelm-pig/src/main/java/redelm/hadoop/RedelmFileWriter.java": 21,
                "redelm-pig/src/main/java/redelm/hadoop/RedelmInputFormat.java": 17,
                "redelm-pig/src/main/java/redelm/hadoop/RedelmOutputCommitter.java": 52,
                "redelm-pig/src/main/java/redelm/hadoop/RedelmOutputFormat.java": 13,
                "redelm-pig/src/main/java/redelm/hadoop/RedelmRecordReader.java": 49,
                "redelm-pig/src/main/java/redelm/hadoop/RedelmRecordWriter.java": 4,
                "redelm-pig/src/main/java/redelm/pig/TupleReadSupport.java": 6,
                "redelm-pig/src/main/java/redelm/pig/TupleRecordConsumer.java": 18,
                "redelm-pig/src/main/java/redelm/pig/converter/MessageConverter.java": 24,
                "redelm-pig/src/test/java/redelm/hadoop/TestInputFormat.java": 3,
                "redelm-pig/src/test/java/redelm/hadoop/TestRedelmFileWriter.java": 7,
                "redelm-pig/src/test/java/redelm/pig/TestTupleRecordConsumer.java": 27,
                "redelm-pig/src/test/java/redelm/pig/TupleConsumerPerfTest.java": 16
            },
            "is_test": true,
            "is_fix": false
        },
        "eaeff045457b3e31fd556744b2c134fc9cfaae61": {
            "datetime": "2013-01-02T11:24:40-08:00",
            "summary": "refactor reader",
            "message": "refactor reader\n",
            "diff": {
                "redelm-column/src/main/java/redelm/io/MessageColumnIO.java": 2,
                "redelm-column/src/main/java/redelm/io/RecordReader.java": 307,
                "redelm-column/src/main/java/redelm/io/RecordReaderCompiler.java": 71,
                "redelm-column/src/main/java/redelm/io/RecordReaderImplementation.java": 325,
                "redelm-column/src/test/java/redelm/io/TestColumnIO.java": 8,
                "redelm-column/src/test/java/redelm/io/TestRecordReaderCompiler.java": 2
            },
            "is_test": true,
            "is_fix": false
        },
        "c4c6991f1afe6b252a96794cb951d66c7890d656": {
            "datetime": "2013-01-05T14:57:43-08:00",
            "summary": "rewrite of the code generation bit (work in progress)",
            "message": "rewrite of the code generation bit (work in progress)\n",
            "diff": {
                "redelm-column/src/main/java/redelm/io/RecordReaderCompiler.java": 278,
                "redelm-column/src/main/java/redelm/io/RecordReaderImplementation.java": 174,
                "redelm-column/src/main/java/redelm/schema/PrimitiveType.java": 23,
                "redelm-column/src/test/java/redelm/io/TestColumnIO.java": 2,
                "redelm-column/src/test/java/redelm/io/TestRecordReaderCompiler.java": 2
            },
            "is_test": true,
            "is_fix": false
        },
        "180222e874d74fd26322786d612a418866fa020d": {
            "datetime": "2013-01-05T15:12:44-08:00",
            "summary": "rename RecordConsumerWrapper",
            "message": "rename RecordConsumerWrapper\n",
            "diff": {
                "redelm-column/src/main/java/redelm/io/RecordConsumerWrapper.java": 6,
                "redelm-column/src/test/java/redelm/io/PerfTest.java": 2,
                "redelm-column/src/test/java/redelm/io/TestColumnIO.java": 4,
                "redelm-pig/src/test/java/redelm/pig/TestTupleRecordConsumer.java": 4,
                "redelm-pig/src/test/java/redelm/pig/TupleConsumerPerfTest.java": 4
            },
            "is_test": true,
            "is_fix": false
        },
        "eba3e211269dd85265afcfb9af7d1f753b88b37b": {
            "datetime": "2013-01-05T15:28:00-08:00",
            "summary": "Merge branch 'master' of github.com:julienledem/redelm into better_InputFormat_logs",
            "message": "Merge branch 'master' of github.com:julienledem/redelm into better_InputFormat_logs\n\nConflicts:\n\tredelm-pig/src/main/java/redelm/hadoop/RedelmRecordReader.java\n",
            "diff": {
                "redelm-column/src/main/java/redelm/io/RecordReader.java": 10,
                "redelm-pig/src/main/java/redelm/hadoop/Footer.java": 50,
                "redelm-pig/src/main/java/redelm/hadoop/RedelmFileReader.java": 107,
                "redelm-pig/src/main/java/redelm/hadoop/RedelmFileWriter.java": 21,
                "redelm-pig/src/main/java/redelm/hadoop/RedelmInputFormat.java": 17,
                "redelm-pig/src/main/java/redelm/hadoop/RedelmOutputCommitter.java": 52,
                "redelm-pig/src/main/java/redelm/hadoop/RedelmOutputFormat.java": 13,
                "redelm-pig/src/main/java/redelm/hadoop/RedelmRecordReader.java": 14,
                "redelm-pig/src/test/java/redelm/hadoop/TestRedelmFileWriter.java": 7
            },
            "is_test": true,
            "is_fix": false
        },
        "f3f02f5bd5b0e36c81ee99ba04fc74a74cd0ba6a": {
            "datetime": "2013-01-05T15:33:41-08:00",
            "summary": "Merge pull request #18 from julienledem/better_InputFormat_logs",
            "message": "Merge pull request #18 from julienledem/better_InputFormat_logs\n\nBetter input format logs and one split per hdfs block",
            "diff": {
                "redelm-column/src/main/java/redelm/column/mem/MemColumnWriter.java": 4,
                "redelm-column/src/main/java/redelm/io/RecordConsumerWrapper.java": 6,
                "redelm-column/src/test/java/redelm/io/PerfTest.java": 8,
                "redelm-column/src/test/java/redelm/io/TestColumnIO.java": 4,
                "redelm-pig/src/main/java/redelm/hadoop/RedelmFileReader.java": 7,
                "redelm-pig/src/main/java/redelm/hadoop/RedelmInputFormat.java": 64,
                "redelm-pig/src/main/java/redelm/hadoop/RedelmInputSplit.java": 20,
                "redelm-pig/src/main/java/redelm/hadoop/RedelmMetaData.java": 8,
                "redelm-pig/src/main/java/redelm/hadoop/RedelmRecordReader.java": 51,
                "redelm-pig/src/main/java/redelm/hadoop/RedelmRecordWriter.java": 2,
                "redelm-pig/src/main/java/redelm/pig/TupleConversionException.java": 15,
                "redelm-pig/src/main/java/redelm/pig/converter/BagConverter.java": 15,
                "redelm-pig/src/main/java/redelm/pig/converter/Converter.java": 15,
                "redelm-pig/src/main/java/redelm/pig/converter/MapConverter.java": 15,
                "redelm-pig/src/main/java/redelm/pig/converter/MapKeyValueConverter.java": 15,
                "redelm-pig/src/main/java/redelm/pig/converter/MessageConverter.java": 15,
                "redelm-pig/src/main/java/redelm/pig/converter/TupleConverter.java": 15,
                "redelm-pig/src/test/java/redelm/hadoop/TestInputFormat.java": 75,
                "redelm-pig/src/test/java/redelm/pig/PerfTest2.java": 52,
                "redelm-pig/src/test/java/redelm/pig/PerfTestReadAllCols.java": 48,
                "redelm-pig/src/test/java/redelm/pig/TestTupleRecordConsumer.java": 4,
                "redelm-pig/src/test/java/redelm/pig/TupleConsumerPerfTest.java": 261
            },
            "is_test": true,
            "is_fix": false
        },
        "0c3a1d852c60d52073aff296f39f8ad0cd87ec84": {
            "datetime": "2013-01-06T16:34:34-08:00",
            "summary": "Merge branch 'master' of github.com:julienledem/redelm into improve_record_consumer_interface",
            "message": "Merge branch 'master' of github.com:julienledem/redelm into improve_record_consumer_interface\n\nConflicts:\n\tredelm-column/src/test/java/redelm/io/PerfTest.java\n\tredelm-column/src/test/java/redelm/io/TestColumnIO.java\n\tredelm-pig/src/main/java/redelm/hadoop/RedelmRecordReader.java\n\tredelm-pig/src/test/java/redelm/pig/TestTupleRecordConsumer.java\n",
            "diff": {
                "redelm-column/src/main/java/redelm/column/mem/MemColumnWriter.java": 4,
                "redelm-column/src/main/java/redelm/io/RecordConsumerWrapper.java": 6,
                "redelm-column/src/main/java/redelm/io/RecordReader.java": 2,
                "redelm-column/src/test/java/redelm/io/PerfTest.java": 4,
                "redelm-column/src/test/java/redelm/io/TestColumnIO.java": 3,
                "redelm-pig/src/main/java/redelm/hadoop/RedelmFileReader.java": 7,
                "redelm-pig/src/main/java/redelm/hadoop/RedelmInputFormat.java": 64,
                "redelm-pig/src/main/java/redelm/hadoop/RedelmInputSplit.java": 20,
                "redelm-pig/src/main/java/redelm/hadoop/RedelmMetaData.java": 8,
                "redelm-pig/src/main/java/redelm/hadoop/RedelmRecordReader.java": 44,
                "redelm-pig/src/main/java/redelm/hadoop/RedelmRecordWriter.java": 2,
                "redelm-pig/src/test/java/redelm/hadoop/TestInputFormat.java": 76,
                "redelm-pig/src/test/java/redelm/pig/PerfTest2.java": 52,
                "redelm-pig/src/test/java/redelm/pig/PerfTestReadAllCols.java": 48,
                "redelm-pig/src/test/java/redelm/pig/TupleConsumerPerfTest.java": 210
            },
            "is_test": true,
            "is_fix": false
        },
        "1954277c4ea81c9a748131b206f9df8ba69b9382": {
            "datetime": "2013-01-06T17:11:55-08:00",
            "summary": "removed cheesy comment and hardcoded max depth based on jco's comment",
            "message": "removed cheesy comment and hardcoded max depth based on jco's comment\n",
            "diff": {
                "redelm-column/src/main/java/redelm/io/MessageColumnIO.java": 16
            },
            "is_test": false,
            "is_fix": false
        },
        "fa4c4ba7f075586b7eed9152bd7ea231c873cfca": {
            "datetime": "2013-01-06T17:12:54-08:00",
            "summary": "removed unnecessary whitespace",
            "message": "removed unnecessary whitespace\n",
            "diff": {
                "redelm-column/src/test/java/redelm/io/TestColumnIO.java": 2
            },
            "is_test": true,
            "is_fix": false
        },
        "d68307e877b95dd613fd1a6fe4479b87ea86aa90": {
            "datetime": "2013-01-06T17:17:43-08:00",
            "summary": "Merge branch 'master' into fix_schema_passing_when_multiple_stores",
            "message": "Merge branch 'master' into fix_schema_passing_when_multiple_stores\n",
            "diff": {
                "redelm-column/src/main/java/redelm/io/RecordConsumerWrapper.java": 6,
                "redelm-column/src/main/java/redelm/io/RecordReader.java": 10,
                "redelm-column/src/test/java/redelm/io/PerfTest.java": 2,
                "redelm-column/src/test/java/redelm/io/TestColumnIO.java": 4,
                "redelm-pig/src/main/java/redelm/hadoop/Footer.java": 50,
                "redelm-pig/src/main/java/redelm/hadoop/RedelmFileReader.java": 107,
                "redelm-pig/src/main/java/redelm/hadoop/RedelmFileWriter.java": 21,
                "redelm-pig/src/main/java/redelm/hadoop/RedelmInputFormat.java": 17,
                "redelm-pig/src/main/java/redelm/hadoop/RedelmOutputCommitter.java": 52,
                "redelm-pig/src/main/java/redelm/hadoop/RedelmOutputFormat.java": 13,
                "redelm-pig/src/main/java/redelm/hadoop/RedelmRecordReader.java": 14,
                "redelm-pig/src/test/java/redelm/hadoop/TestRedelmFileWriter.java": 7,
                "redelm-pig/src/test/java/redelm/pig/TestTupleRecordConsumer.java": 4,
                "redelm-pig/src/test/java/redelm/pig/TupleConsumerPerfTest.java": 4
            },
            "is_test": true,
            "is_fix": false
        },
        "448e8c8d09c1b7a01185fa83526c071d2348c564": {
            "datetime": "2013-01-07T08:34:06-08:00",
            "summary": "Merge branch 'master' into FSA_codegen",
            "message": "Merge branch 'master' into FSA_codegen\n\nConflicts:\n\tredelm-column/src/test/java/redelm/io/PerfTest.java\n\tredelm-column/src/test/java/redelm/io/TestColumnIO.java\n\tredelm-pig/src/main/java/redelm/hadoop/RedelmRecordReader.java\n\tredelm-pig/src/test/java/redelm/pig/TestTupleRecordConsumer.java\n",
            "diff": {
                "redelm-column/src/main/java/redelm/io/RecordConsumerWrapper.java": 6,
                "redelm-column/src/main/java/redelm/io/RecordReaderImplementation.java": 2,
                "redelm-column/src/test/java/redelm/io/PerfTest.java": 5,
                "redelm-column/src/test/java/redelm/io/TestColumnIO.java": 7,
                "redelm-pig/src/main/java/redelm/hadoop/RedelmRecordReader.java": 1,
                "redelm-pig/src/test/java/redelm/hadoop/TestInputFormat.java": 1,
                "redelm-pig/src/test/java/redelm/pig/TestTupleRecordConsumer.java": 1,
                "redelm-pig/src/test/java/redelm/pig/TupleConsumerPerfTest.java": 83
            },
            "is_test": true,
            "is_fix": false
        },
        "faf756e88f6faef5526f8b2bf736ec0ba8d0b488": {
            "datetime": "2013-01-07T11:51:12-08:00",
            "summary": "fixed visibility",
            "message": "fixed visibility\n",
            "diff": {
                "redelm-column/src/main/java/redelm/io/RecordReaderCompiler.java": 2
            },
            "is_test": false,
            "is_fix": false
        },
        "758bb8bb614c5efbbdba87574d23918c93fe01fa": {
            "datetime": "2013-01-07T15:50:39-08:00",
            "summary": "Merge pull request #21 from julienledem/fix_schema_passing_when_multiple_stores",
            "message": "Merge pull request #21 from julienledem/fix_schema_passing_when_multiple_stores\n\nFix schema passing when multiple stores",
            "diff": {
                "redelm-pig/src/main/java/redelm/pig/RedelmStorer.java": 75
            },
            "is_test": false,
            "is_fix": false
        },
        "d71d754eee3773b072af89330b440bb8dbca01f8": {
            "datetime": "2013-01-07T15:59:57-08:00",
            "summary": "Make PigSchemaConverter Static",
            "message": "Make PigSchemaConverter Static\n",
            "diff": {
                "redelm-pig/src/main/java/redelm/pig/PigSchemaConverter.java": 19,
                "redelm-pig/src/main/java/redelm/pig/RedelmLoader.java": 6,
                "redelm-pig/src/main/java/redelm/pig/RedelmStorer.java": 8,
                "redelm-pig/src/test/java/redelm/pig/TestPigSchemaConverter.java": 3,
                "redelm-pig/src/test/java/redelm/pig/TestTupleRecordConsumer.java": 16,
                "redelm-pig/src/test/java/redelm/pig/TupleConsumerPerfTest.java": 23
            },
            "is_test": true,
            "is_fix": false
        },
        "19106d078bf2ceaa5217c15fd08e777111f9ec40": {
            "datetime": "2013-01-07T16:13:27-08:00",
            "summary": "Fix merge conflict",
            "message": "Fix merge conflict\n",
            "diff": {
                "redelm-pig/src/main/java/redelm/pig/RedelmStorer.java": 75
            },
            "is_test": false,
            "is_fix": false
        },
        "676c471db22d895f08c04c240d3eb9616e48b0e2": {
            "datetime": "2013-01-07T17:59:19-08:00",
            "summary": "Make maps work with sigle column case",
            "message": "Make maps work with sigle column case\n",
            "diff": {
                "redelm-pig/src/main/java/redelm/pig/PigSchemaConverter.java": 48,
                "redelm-pig/src/test/java/redelm/pig/TestPigSchemaConverter.java": 48
            },
            "is_test": true,
            "is_fix": false
        },
        "db75e0be88ce935f290b71ea6198c75c4a6a341a": {
            "datetime": "2013-01-07T21:38:15-08:00",
            "summary": "add missing base implementations",
            "message": "add missing base implementations\n",
            "diff": {
                "redelm-column/src/main/java/redelm/Log.java": 2,
                "redelm-column/src/main/java/redelm/io/RecordReaderCompiler.java": 66,
                "redelm-column/src/main/java/redelm/io/RecordReaderImplementation.java": 7,
                "redelm-column/src/test/java/redelm/io/TestRecordReaderCompiler.java": 16
            },
            "is_test": true,
            "is_fix": false
        },
        "7aaf6f95908add6f9a0ef0f41290ed82fcee6b9b": {
            "datetime": "2013-01-07T21:44:13-08:00",
            "summary": "removed unecessary readOneRecord() method and commented out old code",
            "message": "removed unecessary readOneRecord() method and commented out old code\n",
            "diff": {
                "redelm-column/src/main/java/redelm/io/RecordReader.java": 23,
                "redelm-column/src/test/java/redelm/io/PerfTest.java": 3
            },
            "is_test": true,
            "is_fix": false
        },
        "770cf4d97a1cc27f9f07171c3a99bfff547904e8": {
            "datetime": "2013-01-08T16:56:29-08:00",
            "summary": "more optimizations",
            "message": "more optimizations\n",
            "diff": {
                "redelm-column/src/main/java/redelm/Log.java": 2,
                "redelm-column/src/main/java/redelm/io/RecordReaderCompiler.java": 321,
                "redelm-column/src/main/java/redelm/io/RecordReaderImplementation.java": 65,
                "redelm-column/src/test/java/redelm/io/PerfTest.java": 40,
                "redelm-column/src/test/java/redelm/io/TestRecordReaderCompiler.java": 10
            },
            "is_test": true,
            "is_fix": false
        },
        "e5dec2bf0ca372aa7d4053482cf29c79ed23df7e": {
            "datetime": "2013-01-08T23:48:35-08:00",
            "summary": "optimizations;fix some bugs",
            "message": "optimizations;fix some bugs\n",
            "diff": {
                "redelm-column/src/main/java/redelm/column/mem/MemColumnReader.java": 6,
                "redelm-column/src/main/java/redelm/io/RecordReaderCompiler.java": 37,
                "redelm-column/src/main/java/redelm/io/RecordReaderImplementation.java": 18,
                "redelm-column/src/test/java/redelm/io/PerfTest.java": 26
            },
            "is_test": true,
            "is_fix": false
        },
        "b896112db485fadc5ca86ee441c7357ed1ef3931": {
            "datetime": "2013-01-09T00:03:23-08:00",
            "summary": "trigger full gc before starting",
            "message": "trigger full gc before starting\n",
            "diff": {
                "redelm-column/src/test/java/redelm/io/PerfTest.java": 2
            },
            "is_test": true,
            "is_fix": false
        },
        "48d9105d1b5e845a1af037968c88dad6aa374b4c": {
            "datetime": "2013-01-09T09:57:47-08:00",
            "summary": "Revert PigSchemaConverter to static",
            "message": "Revert PigSchemaConverter to static\n",
            "diff": {
                "redelm-pig/src/main/java/redelm/pig/PigSchemaConverter.java": 19,
                "redelm-pig/src/main/java/redelm/pig/RedelmLoader.java": 6,
                "redelm-pig/src/main/java/redelm/pig/RedelmStorer.java": 8,
                "redelm-pig/src/test/java/redelm/pig/TestPigSchemaConverter.java": 3,
                "redelm-pig/src/test/java/redelm/pig/TestTupleRecordConsumer.java": 16,
                "redelm-pig/src/test/java/redelm/pig/TupleConsumerPerfTest.java": 23
            },
            "is_test": true,
            "is_fix": false
        },
        "d2025609870d1fb68c0e75ded650906dbde00c29": {
            "datetime": "2013-01-09T13:38:26-08:00",
            "summary": "Incorporate Julien's comments",
            "message": "Incorporate Julien's comments\n",
            "diff": {
                "redelm-pig/src/main/java/redelm/pig/PigSchemaConverter.java": 63
            },
            "is_test": false,
            "is_fix": false
        },
        "d18ec37597717e0d50fa1ffb9a57b5be3875ab7f": {
            "datetime": "2013-01-09T13:38:53-08:00",
            "summary": "Merge pull request #23 from jcoveney/fix_simple_maps",
            "message": "Merge pull request #23 from jcoveney/fix_simple_maps\n\nFix simple maps",
            "diff": {
                "redelm-pig/src/main/java/redelm/pig/PigSchemaConverter.java": 65,
                "redelm-pig/src/test/java/redelm/pig/TestPigSchemaConverter.java": 48
            },
            "is_test": true,
            "is_fix": false
        },
        "78cff39a42d414c1cd6b5b04cda6a92296b9f6fc": {
            "datetime": "2013-01-09T14:49:33-08:00",
            "summary": "Merge pull request #20 from julienledem/improve_record_consumer_interface",
            "message": "Merge pull request #20 from julienledem/improve_record_consumer_interface\n\nImprove record consumer interface",
            "diff": {
                "redelm-column/src/main/java/redelm/data/GroupRecordConsumer.java": 18,
                "redelm-column/src/main/java/redelm/io/ColumnIO.java": 5,
                "redelm-column/src/main/java/redelm/io/ColumnIOFactory.java": 25,
                "redelm-column/src/main/java/redelm/io/GroupColumnIO.java": 15,
                "redelm-column/src/main/java/redelm/io/MessageColumnIO.java": 79,
                "redelm-column/src/main/java/redelm/io/PrimitiveColumnIO.java": 32,
                "redelm-column/src/main/java/redelm/io/RecordMaterializer.java": 34,
                "redelm-column/src/main/java/redelm/io/RecordReader.java": 222,
                "redelm-column/src/test/java/redelm/io/PerfTest.java": 125,
                "redelm-column/src/test/java/redelm/io/TestColumnIO.java": 51,
                "redelm-pig/src/main/java/redelm/hadoop/Footer.java": 4,
                "redelm-pig/src/main/java/redelm/hadoop/ReadSupport.java": 7,
                "redelm-pig/src/main/java/redelm/hadoop/RedelmRecordReader.java": 32,
                "redelm-pig/src/main/java/redelm/hadoop/RedelmRecordWriter.java": 4,
                "redelm-pig/src/main/java/redelm/pig/TupleReadSupport.java": 6,
                "redelm-pig/src/main/java/redelm/pig/TupleRecordConsumer.java": 18,
                "redelm-pig/src/main/java/redelm/pig/converter/MessageConverter.java": 24,
                "redelm-pig/src/test/java/redelm/hadoop/TestInputFormat.java": 3,
                "redelm-pig/src/test/java/redelm/pig/TestTupleRecordConsumer.java": 27,
                "redelm-pig/src/test/java/redelm/pig/TupleConsumerPerfTest.java": 103
            },
            "is_test": true,
            "is_fix": false
        },
        "cd7117b691ab04ce75b5ac0835ab278ae6bf7766": {
            "datetime": "2013-01-09T14:50:58-08:00",
            "summary": "some modification to understand better impact of gc",
            "message": "some modification to understand better impact of gc\n",
            "diff": {
                "redelm-column/src/test/java/redelm/io/PerfTest.java": 6
            },
            "is_test": true,
            "is_fix": false
        },
        "fd93ec2d73451333100e1f06714daf76945e38ab": {
            "datetime": "2013-01-09T15:52:43-08:00",
            "summary": "Merge branch 'master' into FSA_codegen",
            "message": "Merge branch 'master' into FSA_codegen\n\nConflicts:\n\tredelm-column/src/main/java/redelm/io/RecordReader.java\n\tredelm-column/src/test/java/redelm/io/PerfTest.java\n\tredelm-column/src/test/java/redelm/io/TestColumnIO.java\n\tredelm-pig/src/test/java/redelm/hadoop/TestInputFormat.java\n\tredelm-pig/src/test/java/redelm/pig/TestTupleRecordConsumer.java\n\tredelm-pig/src/test/java/redelm/pig/TupleConsumerPerfTest.java\n",
            "diff": {
                "redelm-column/src/main/java/redelm/io/MessageColumnIO.java": 16,
                "redelm-column/src/main/java/redelm/io/RecordReader.java": 0,
                "redelm-column/src/main/java/redelm/io/RecordReaderImplementation.java": 25,
                "redelm-column/src/test/java/redelm/io/PerfTest.java": 1,
                "redelm-column/src/test/java/redelm/io/TestColumnIO.java": 1,
                "redelm-pig/src/main/java/redelm/pig/PigSchemaConverter.java": 65,
                "redelm-pig/src/test/java/redelm/pig/TestPigSchemaConverter.java": 48,
                "redelm-pig/src/test/java/redelm/pig/TestTupleRecordConsumer.java": 1,
                "redelm-pig/src/test/java/redelm/pig/TupleConsumerPerfTest.java": 24
            },
            "is_test": true,
            "is_fix": false
        },
        "d5ea0450fa81f6f5950d3924c5282d55ddace35b": {
            "datetime": "2013-01-09T16:01:18-08:00",
            "summary": "cleanup unused import",
            "message": "cleanup unused import\n",
            "diff": {
                "redelm-column/src/test/java/redelm/io/TestRecordReaderCompiler.java": 1
            },
            "is_test": true,
            "is_fix": false
        },
        "da4b03430c42cd6148006a1fa68b979f36d0789b": {
            "datetime": "2013-01-10T08:08:16-08:00",
            "summary": "add license headers",
            "message": "add license headers\n",
            "diff": {
                "redelm-column/src/main/java/redelm/io/RecordReader.java": 15,
                "redelm-column/src/main/java/redelm/io/RecordReaderCompiler.java": 15,
                "redelm-column/src/test/java/redelm/io/ExpectationValidatingRecordConsumer.java": 15,
                "redelm-column/src/test/java/redelm/io/TestRecordReaderCompiler.java": 15
            },
            "is_test": true,
            "is_fix": false
        },
        "2a3d6af012ffcb649704e5d1b177322e261f5e05": {
            "datetime": "2013-01-10T08:19:38-08:00",
            "summary": "make BaseRecordReader its own class",
            "message": "make BaseRecordReader its own class\n",
            "diff": {
                "redelm-column/src/main/java/redelm/io/BaseRecordReader.java": 151,
                "redelm-column/src/main/java/redelm/io/RecordReaderCompiler.java": 134
            },
            "is_test": false,
            "is_fix": false
        },
        "2883f89341e2d29b33fc1687d07d6f965eaee796": {
            "datetime": "2013-01-14T18:24:29-08:00",
            "summary": "merge both switch statements to optimize",
            "message": "merge both switch statements to optimize\n",
            "diff": {
                "redelm-column/src/main/java/redelm/io/RecordReaderCompiler.java": 72,
                "redelm-column/src/main/java/redelm/io/RecordReaderImplementation.java": 44
            },
            "is_test": false,
            "is_fix": false
        },
        "b89750bfe652dd83c8feed49cb55e0e6b47c31dd": {
            "datetime": "2013-01-17T14:24:38-08:00",
            "summary": "some cleanup based on Jco's comments",
            "message": "some cleanup based on Jco's comments\n",
            "diff": {
                "redelm-column/src/main/java/redelm/column/mem/MemColumnReader.java": 9,
                "redelm-column/src/main/java/redelm/io/BaseRecordReader.java": 2,
                "redelm-column/src/main/java/redelm/io/RecordReaderCompiler.java": 60,
                "redelm-column/src/main/java/redelm/io/RecordReaderImplementation.java": 37,
                "redelm-column/src/test/java/redelm/io/PerfTest.java": 1
            },
            "is_test": true,
            "is_fix": false
        },
        "17271e7299de20b95b88140753b6e6685ecf7c6e": {
            "datetime": "2013-02-01T18:21:11-08:00",
            "summary": "initial integration with the new metadata",
            "message": "initial integration with the new metadata\n",
            "diff": {
                "redelm-column/src/main/java/redelm/Log.java": 2,
                "redelm-column/src/main/java/redelm/bytes/BytesInput.java": 213,
                "redelm-column/src/main/java/redelm/bytes/BytesUtils.java": 37,
                "redelm-column/src/main/java/redelm/column/ColumnWriter.java": 12,
                "redelm-column/src/main/java/redelm/column/ColumnsStore.java": 2,
                "redelm-column/src/main/java/redelm/column/RedelmByteArrayOutputStream.java": 16,
                "redelm-column/src/main/java/redelm/column/mem/MemColumn.java": 110,
                "redelm-column/src/main/java/redelm/column/mem/MemColumnReader.java": 101,
                "redelm-column/src/main/java/redelm/column/mem/MemColumnWriter.java": 81,
                "redelm-column/src/main/java/redelm/column/mem/MemColumnsStore.java": 61,
                "redelm-column/src/main/java/redelm/column/mem/MemPageReader.java": 52,
                "redelm-column/src/main/java/redelm/column/mem/MemPageStore.java": 52,
                "redelm-column/src/main/java/redelm/column/mem/MemPageWriter.java": 55,
                "redelm-column/src/main/java/redelm/column/mem/Page.java": 51,
                "redelm-column/src/main/java/redelm/column/mem/PageStore.java": 27,
                "redelm-column/src/main/java/redelm/column/mem/PageWriter.java": 26,
                "redelm-column/src/main/java/redelm/column/primitive/BitPacking.java": 615,
                "redelm-column/src/main/java/redelm/column/primitive/BitReader.java": 9,
                "redelm-column/src/main/java/redelm/column/primitive/BitWriter.java": 34,
                "redelm-column/src/main/java/redelm/column/primitive/BoundedIntColumnReader.java": 23,
                "redelm-column/src/main/java/redelm/column/primitive/BoundedIntColumnWriter.java": 34,
                "redelm-column/src/main/java/redelm/column/primitive/DevNullColumnReader.java": 7,
                "redelm-column/src/main/java/redelm/column/primitive/DevNullColumnWriter.java": 13,
                "redelm-column/src/main/java/redelm/column/primitive/PrimitiveColumnReader.java": 12,
                "redelm-column/src/main/java/redelm/column/primitive/PrimitiveColumnWriter.java": 7,
                "redelm-column/src/main/java/redelm/column/primitive/SimplePrimitiveColumnReader.java": 16,
                "redelm-column/src/main/java/redelm/column/primitive/SimplePrimitiveColumnWriter.java": 23,
                "redelm-column/src/main/java/redelm/schema/GroupType.java": 15,
                "redelm-column/src/main/java/redelm/schema/MessageType.java": 13,
                "redelm-column/src/main/java/redelm/schema/PrimitiveType.java": 10,
                "redelm-column/src/main/java/redelm/schema/Type.java": 4,
                "redelm-column/src/test/java/redelm/bytes/TestBytesUtil.java": 54,
                "redelm-column/src/test/java/redelm/column/mem/TestMemColumn.java": 108,
                "redelm-column/src/test/java/redelm/column/mem/TestMemPageStore.java": 48,
                "redelm-column/src/test/java/redelm/column/primitive/TestBitPacking.java": 215,
                "redelm-column/src/test/java/redelm/column/primitive/TestBoundedColumns.java": 102,
                "redelm-column/src/test/java/redelm/io/PerfTest.java": 4,
                "redelm-column/src/test/java/redelm/io/TestColumnIO.java": 76,
                "redelm-pig/src/main/java/redelm/hadoop/BlockData.java": 6,
                "redelm-pig/src/main/java/redelm/hadoop/BlockMetaData.java": 82,
                "redelm-pig/src/main/java/redelm/hadoop/CodecFactory.java": 52,
                "redelm-pig/src/main/java/redelm/hadoop/ColumnMetaData.java": 264,
                "redelm-pig/src/main/java/redelm/hadoop/Footer.java": 15,
                "redelm-pig/src/main/java/redelm/hadoop/MetaDataBlock.java": 39,
                "redelm-pig/src/main/java/redelm/hadoop/PageConsumer.java": 24,
                "redelm-pig/src/main/java/redelm/hadoop/PrintFooter.java": 95,
                "redelm-pig/src/main/java/redelm/hadoop/ReadSupport.java": 3,
                "redelm-pig/src/main/java/redelm/hadoop/RedelmFileReader.java": 155,
                "redelm-pig/src/main/java/redelm/hadoop/RedelmFileWriter.java": 208,
                "redelm-pig/src/main/java/redelm/hadoop/RedelmInputFormat.java": 25,
                "redelm-pig/src/main/java/redelm/hadoop/RedelmInputSplit.java": 3,
                "redelm-pig/src/main/java/redelm/hadoop/RedelmMetaData.java": 76,
                "redelm-pig/src/main/java/redelm/hadoop/RedelmOutputFormat.java": 21,
                "redelm-pig/src/main/java/redelm/hadoop/RedelmRecordReader.java": 49,
                "redelm-pig/src/main/java/redelm/hadoop/RedelmRecordWriter.java": 55,
                "redelm-pig/src/main/java/redelm/hadoop/WriteSupport.java": 4,
                "redelm-pig/src/main/java/redelm/hadoop/metadata/ColumnChunkMetaData.java": 138,
                "redelm-pig/src/main/java/redelm/hadoop/metadata/ColumnMetaData.java": 37,
                "redelm-pig/src/main/java/redelm/hadoop/metadata/CompressionCodecName.java": 69,
                "redelm-pig/src/main/java/redelm/hadoop/metadata/FileMetaData.java": 49,
                "redelm-pig/src/main/java/redelm/pig/PigMetaData.java": 17,
                "redelm-pig/src/main/java/redelm/pig/RedelmStorer.java": 6,
                "redelm-pig/src/main/java/redelm/pig/TupleReadSupport.java": 7,
                "redelm-pig/src/main/java/redelm/pig/TupleWriteSupport.java": 5,
                "redelm-pig/src/main/java/redelm/redfile/RedFileMetadataConverter.java": 220,
                "redelm-pig/src/test/java/redelm/hadoop/TestInputFormat.java": 23,
                "redelm-pig/src/test/java/redelm/hadoop/TestRedelmFileWriter.java": 177,
                "redelm-pig/src/test/java/redelm/pig/TestTupleRecordConsumer.java": 10,
                "redelm-pig/src/test/java/redelm/pig/TupleConsumerPerfTest.java": 22,
                "redelm-pig/src/test/java/redelm/redfile/TestRedFileMetadataConverter.java": 44
            },
            "is_test": true,
            "is_fix": false
        },
        "f25dfdcc0302f29349e6ad85ea4341320268b86d": {
            "datetime": "2013-02-04T10:48:25-08:00",
            "summary": "fix row count per rowgroup persistence",
            "message": "fix row count per rowgroup persistence\n",
            "diff": {
                "redelm-pig/src/main/java/redelm/redfile/RedFileMetadataConverter.java": 5
            },
            "is_test": false,
            "is_fix": false
        },
        "8ec8a9dae12484273453a57defba7cac80b82f58": {
            "datetime": "2013-02-04T15:19:28-08:00",
            "summary": "fix storer problem with page storage",
            "message": "fix storer problem with page storage\n",
            "diff": {
                "redelm-column/src/main/java/redelm/column/mem/MemColumnReader.java": 9,
                "redelm-column/src/main/java/redelm/column/mem/MemPageReader.java": 3,
                "redelm-column/src/main/java/redelm/column/mem/MemPageStore.java": 5,
                "redelm-column/src/main/java/redelm/column/mem/MemPageWriter.java": 3,
                "redelm-pig/src/main/java/redelm/hadoop/RedelmFileReader.java": 5,
                "redelm-pig/src/main/java/redelm/hadoop/RedelmRecordReader.java": 9,
                "redelm-pig/src/test/java/redelm/pig/TestRedelmStorer.java": 5
            },
            "is_test": true,
            "is_fix": false
        },
        "d63ded4da366c4d81f5044c07f087ada719055f4": {
            "datetime": "2013-02-05T17:18:25-08:00",
            "summary": "remove string type; make schema in footer use object model; make ints little endian",
            "message": "remove string type; make schema in footer use object model; make ints little endian\n",
            "diff": {
                "redelm-column/src/main/java/redelm/Log.java": 2,
                "redelm-column/src/main/java/redelm/bytes/BytesInput.java": 2,
                "redelm-column/src/main/java/redelm/bytes/BytesUtils.java": 30,
                "redelm-column/src/main/java/redelm/column/ColumnWriter.java": 2,
                "redelm-column/src/main/java/redelm/column/mem/MemColumn.java": 4,
                "redelm-column/src/main/java/redelm/column/mem/MemColumnWriter.java": 16,
                "redelm-column/src/main/java/redelm/column/primitive/BoundedIntColumnReader.java": 2,
                "redelm-column/src/main/java/redelm/data/Group.java": 2,
                "redelm-column/src/main/java/redelm/data/GroupRecordConsumer.java": 10,
                "redelm-column/src/main/java/redelm/data/simple/BinaryValue.java": 5,
                "redelm-column/src/main/java/redelm/data/simple/SimpleGroup.java": 2,
                "redelm-column/src/main/java/redelm/data/simple/StringValue.java": 8,
                "redelm-column/src/main/java/redelm/data/simple/example/Paper.java": 10,
                "redelm-column/src/main/java/redelm/io/MessageColumnIO.java": 18,
                "redelm-column/src/main/java/redelm/io/RecordConsumer.java": 10,
                "redelm-column/src/main/java/redelm/io/RecordConsumerLoggingWrapper.java": 16,
                "redelm-column/src/main/java/redelm/io/ValidatingRecordConsumer.java": 16,
                "redelm-column/src/main/java/redelm/schema/MessageType.java": 4,
                "redelm-column/src/main/java/redelm/schema/PrimitiveType.java": 24,
                "redelm-column/src/test/java/redelm/bytes/TestBytesUtil.java": 8,
                "redelm-column/src/test/java/redelm/column/mem/TestMemColumn.java": 8,
                "redelm-column/src/test/java/redelm/io/PerfTest.java": 2,
                "redelm-column/src/test/java/redelm/io/TestColumnIO.java": 46,
                "redelm-column/src/test/java/redelm/parser/TestRedelmParser.java": 23,
                "redelm-pig/src/main/java/redelm/hadoop/RedelmFileReader.java": 36,
                "redelm-pig/src/main/java/redelm/hadoop/RedelmFileWriter.java": 11,
                "redelm-pig/src/main/java/redelm/hadoop/RedelmInputFormat.java": 10,
                "redelm-pig/src/main/java/redelm/hadoop/RedelmInputSplit.java": 17,
                "redelm-pig/src/main/java/redelm/hadoop/metadata/FileMetaData.java": 8,
                "redelm-pig/src/main/java/redelm/pig/PigSchemaConverter.java": 4,
                "redelm-pig/src/main/java/redelm/pig/TupleRecordConsumer.java": 10,
                "redelm-pig/src/main/java/redelm/pig/TupleWriteSupport.java": 13,
                "redelm-pig/src/main/java/redelm/pig/converter/MapKeyValueConverter.java": 8,
                "redelm-pig/src/main/java/redelm/pig/converter/MessageConverter.java": 8,
                "redelm-pig/src/main/java/redelm/pig/converter/TupleConverter.java": 18,
                "redelm-pig/src/main/java/redelm/redfile/RedFileMetadataConverter.java": 135,
                "redelm-pig/src/test/java/redelm/hadoop/TestInputFormat.java": 5,
                "redelm-pig/src/test/java/redelm/hadoop/TestRedelmFileWriter.java": 2,
                "redelm-pig/src/test/java/redelm/pig/TestPigSchemaConverter.java": 30,
                "redelm-pig/src/test/java/redelm/redfile/TestRedFileMetadataConverter.java": 12
            },
            "is_test": true,
            "is_fix": false
        },
        "cd9e8fe1b7aa65b65f71b0b2c297c49e6ad45321": {
            "datetime": "2013-02-05T18:00:01-08:00",
            "summary": "integrate the schema change from children to parent",
            "message": "integrate the schema change from children to parent\n",
            "diff": {
                "redelm-column/src/main/java/redelm/schema/MessageType.java": 9,
                "redelm-pig/src/main/java/redelm/redfile/RedFileMetadataConverter.java": 103
            },
            "is_test": false,
            "is_fix": false
        },
        "3043e759f82d447ffe236f07722ae9800259bdd9": {
            "datetime": "2013-02-06T16:59:21-08:00",
            "summary": "optimize buffer copy; revert parent",
            "message": "optimize buffer copy; revert parent\n",
            "diff": {
                "redelm-column/src/main/java/redelm/bytes/BytesInput.java": 14,
                "redelm-pig/src/main/java/redelm/redfile/RedFileMetadataConverter.java": 99
            },
            "is_test": false,
            "is_fix": false
        },
        "2e09b42cbdbc2a4a903c7fdf4989b6635f4bc9eb": {
            "datetime": "2013-02-06T18:12:15-08:00",
            "summary": "cleanup string type",
            "message": "cleanup string type\n",
            "diff": {
                "redelm-column/src/main/java/redelm/column/ColumnWriter.java": 2,
                "redelm-column/src/main/java/redelm/column/mem/MemColumn.java": 28,
                "redelm-column/src/main/java/redelm/column/mem/MemColumnWriter.java": 9,
                "redelm-column/src/main/java/redelm/column/primitive/DevNullColumnReader.java": 11,
                "redelm-column/src/main/java/redelm/column/primitive/DevNullColumnWriter.java": 7,
                "redelm-column/src/main/java/redelm/column/primitive/PrimitiveColumnReader.java": 4,
                "redelm-column/src/main/java/redelm/column/primitive/PrimitiveColumnWriter.java": 4,
                "redelm-column/src/main/java/redelm/column/primitive/SimplePrimitiveColumnReader.java": 23,
                "redelm-column/src/main/java/redelm/column/primitive/SimplePrimitiveColumnWriter.java": 12,
                "redelm-column/src/main/java/redelm/data/GroupRecordConsumer.java": 5,
                "redelm-column/src/main/java/redelm/data/simple/BinaryValue.java": 5,
                "redelm-column/src/main/java/redelm/data/simple/SimpleGroup.java": 2,
                "redelm-column/src/main/java/redelm/data/simple/StringValue.java": 49,
                "redelm-column/src/main/java/redelm/io/MessageColumnIO.java": 10,
                "redelm-column/src/main/java/redelm/io/RecordConsumer.java": 6,
                "redelm-column/src/main/java/redelm/io/RecordConsumerLoggingWrapper.java": 9,
                "redelm-column/src/main/java/redelm/io/ValidatingRecordConsumer.java": 8,
                "redelm-column/src/main/java/redelm/schema/PrimitiveType.java": 12,
                "redelm-column/src/test/java/redelm/io/TestColumnIO.java": 10,
                "redelm-pig/src/main/java/redelm/pig/TupleRecordConsumer.java": 5,
                "redelm-pig/src/main/java/redelm/pig/converter/MessageConverter.java": 5,
                "redelm-pig/src/main/java/redelm/redfile/RedFileMetadataConverter.java": 1
            },
            "is_test": true,
            "is_fix": false
        },
        "be0088631c6253e2f8ee7ba3715f3ea8d6dd001f": {
            "datetime": "2013-02-08T11:30:34-08:00",
            "summary": "better support for plain encoding",
            "message": "better support for plain encoding\n",
            "diff": {
                "redelm-column/src/main/java/redelm/bytes/BytesUtils.java": 23,
                "redelm-column/src/main/java/redelm/bytes/LittleEndianDataInputStream.java": 400,
                "redelm-column/src/main/java/redelm/bytes/LittleEndianDataOutputStream.java": 192,
                "redelm-column/src/main/java/redelm/column/mem/MemColumnReader.java": 20,
                "redelm-column/src/main/java/redelm/column/mem/MemColumnWriter.java": 12,
                "redelm-column/src/main/java/redelm/column/primitive/BitPacking.java": 7,
                "redelm-column/src/main/java/redelm/column/primitive/BitPackingColumnReader.java": 39,
                "redelm-column/src/main/java/redelm/column/primitive/BitPackingColumnWriter.java": 58,
                "redelm-column/src/main/java/redelm/column/primitive/BooleanPlainColumnReader.java": 53,
                "redelm-column/src/main/java/redelm/column/primitive/BooleanPlainColumnWriter.java": 75,
                "redelm-column/src/main/java/redelm/column/primitive/BoundedIntColumnReader.java": 2,
                "redelm-column/src/main/java/redelm/column/primitive/DevNullColumnReader.java": 2,
                "redelm-column/src/main/java/redelm/column/primitive/PrimitiveColumnReader.java": 2,
                "redelm-column/src/main/java/redelm/column/primitive/SimplePrimitiveColumnReader.java": 23,
                "redelm-column/src/main/java/redelm/column/primitive/SimplePrimitiveColumnWriter.java": 17,
                "redelm-column/src/test/java/redelm/column/primitive/TestBitPacking.java": 6,
                "redelm-column/src/test/java/redelm/column/primitive/TestBoundedColumns.java": 10,
                "redelm-pig/src/main/java/redelm/hadoop/RedelmFileReader.java": 7,
                "redelm-pig/src/main/java/redelm/redfile/RedFileMetadataConverter.java": 15
            },
            "is_test": true,
            "is_fix": false
        },
        "6cdf6aaabbc05e2b693dbb7a1688e908ffe98e09": {
            "datetime": "2013-02-08T11:31:02-08:00",
            "summary": "generator for the int_test_file",
            "message": "generator for the int_test_file\n",
            "diff": {
                "redelm-pig/src/test/java/redelm/pig/GenerateIntTestFile.java": 104
            },
            "is_test": false,
            "is_fix": false
        },
        "f3adb6e39ada1ee15879295d1379e890045d37f1": {
            "datetime": "2013-02-08T11:32:45-08:00",
            "summary": "renamed to Plain to match the Encoding name",
            "message": "renamed to Plain to match the Encoding name\n",
            "diff": {
                "redelm-column/src/main/java/redelm/column/mem/MemColumnReader.java": 6,
                "redelm-column/src/main/java/redelm/column/mem/MemColumnWriter.java": 4,
                "redelm-column/src/main/java/redelm/column/primitive/SimplePrimitiveColumnReader.java": 4,
                "redelm-column/src/main/java/redelm/column/primitive/SimplePrimitiveColumnWriter.java": 6
            },
            "is_test": false,
            "is_fix": false
        },
        "781f40f97c09807ed21be2c00dbd708708d5ad43": {
            "datetime": "2013-02-08T11:37:07-08:00",
            "summary": "PLAIN encoding comformance",
            "message": "PLAIN encoding comformance\n",
            "diff": {
                "redelm-column/src/main/java/redelm/column/primitive/PlainColumnReader.java": 18,
                "redelm-column/src/main/java/redelm/column/primitive/PlainColumnWriter.java": 14
            },
            "is_test": false,
            "is_fix": false
        },
        "1bd47c349d5416bd2fdfd62ad603ea581622de09": {
            "datetime": "2013-02-08T15:47:53-08:00",
            "summary": "generate TPCH customer",
            "message": "generate TPCH customer\n",
            "diff": {
                "redelm-column/src/main/java/redelm/Log.java": 14,
                "redelm-column/src/main/java/redelm/bytes/BytesInput.java": 2,
                "redelm-column/src/main/java/redelm/column/ColumnDescriptor.java": 8,
                "redelm-column/src/main/java/redelm/data/simple/example/Paper.java": 4,
                "redelm-column/src/main/java/redelm/io/MessageColumnIO.java": 4,
                "redelm-column/src/main/java/redelm/io/PrimitiveColumnIO.java": 2,
                "redelm-column/src/main/java/redelm/io/RecordReader.java": 8,
                "redelm-column/src/main/java/redelm/io/ValidatingRecordConsumer.java": 18,
                "redelm-column/src/main/java/redelm/parser/MessageTypeParser.java": 4,
                "redelm-column/src/main/java/redelm/schema/MessageType.java": 6,
                "redelm-column/src/main/java/redelm/schema/PrimitiveType.java": 12,
                "redelm-column/src/test/java/redelm/column/mem/TestMemPageStore.java": 4,
                "redelm-column/src/test/java/redelm/parser/TestRedelmParser.java": 4,
                "redelm-pig/src/main/java/redelm/hadoop/RedelmFileReader.java": 4,
                "redelm-pig/src/main/java/redelm/hadoop/RedelmFileWriter.java": 2,
                "redelm-pig/src/main/java/redelm/hadoop/metadata/ColumnChunkMetaData.java": 8,
                "redelm-pig/src/main/java/redelm/pig/PigSchemaConverter.java": 20,
                "redelm-pig/src/main/java/redelm/pig/TupleWriteSupport.java": 4,
                "redelm-pig/src/main/java/redelm/redfile/RedFileMetadataConverter.java": 22,
                "redelm-pig/src/test/java/redelm/hadoop/TestInputFormat.java": 4,
                "redelm-pig/src/test/java/redelm/pig/GenerateIntTestFile.java": 99,
                "redelm-pig/src/test/java/redelm/pig/GenerateTPCH.java": 93
            },
            "is_test": true,
            "is_fix": false
        },
        "07d7aa0f26044e95cef3749454e6f16fcf6c2bf7": {
            "datetime": "2013-02-08T15:56:58-08:00",
            "summary": "change children_indices for children_count in schema representation",
            "message": "change children_indices for children_count in schema representation\n",
            "diff": {
                "redelm-pig/src/main/java/redelm/redfile/RedFileMetadataConverter.java": 24
            },
            "is_test": false,
            "is_fix": false
        },
        "867e24b84c57f768949aa385553c76f442993dda": {
            "datetime": "2013-02-08T16:06:09-08:00",
            "summary": "fix repetition for root",
            "message": "fix repetition for root\n",
            "diff": {
                "redelm-pig/src/main/java/redelm/redfile/RedFileMetadataConverter.java": 13
            },
            "is_test": false,
            "is_fix": false
        },
        "9c7e5f57e92419cc255e4597444afe7acb2c92aa": {
            "datetime": "2013-02-11T14:45:28-08:00",
            "summary": "add compression back; make page size configurable; rename children_count to num_children",
            "message": "add compression back; make page size configurable; rename children_count to num_children\n",
            "diff": {
                "redelm-column/src/main/java/redelm/Log.java": 2,
                "redelm-pig/src/main/java/redelm/hadoop/CodecFactory.java": 5,
                "redelm-pig/src/main/java/redelm/hadoop/RedelmFileWriter.java": 24,
                "redelm-pig/src/main/java/redelm/hadoop/RedelmOutputFormat.java": 50,
                "redelm-pig/src/main/java/redelm/hadoop/RedelmRecordWriter.java": 59,
                "redelm-pig/src/main/java/redelm/hadoop/metadata/CompressionCodecName.java": 7,
                "redelm-pig/src/main/java/redelm/redfile/RedFileMetadataConverter.java": 13,
                "redelm-pig/src/test/java/redelm/hadoop/TestRedelmFileWriter.java": 19,
                "redelm-pig/src/test/java/redelm/pig/GenerateIntTestFile.java": 2
            },
            "is_test": true,
            "is_fix": false
        },
        "18d5082bb927a3f55717a2ffeafa304e0d921386": {
            "datetime": "2013-02-11T16:59:03-08:00",
            "summary": "fix decompression",
            "message": "fix decompression\n",
            "diff": {
                "redelm-column/src/main/java/redelm/bytes/BytesInput.java": 10,
                "redelm-column/src/main/java/redelm/column/mem/MemColumnReader.java": 4,
                "redelm-column/src/main/java/redelm/column/mem/MemColumnWriter.java": 9,
                "redelm-column/src/main/java/redelm/column/mem/MemPageWriter.java": 3,
                "redelm-column/src/main/java/redelm/column/mem/PageWriter.java": 4,
                "redelm-column/src/test/java/redelm/column/mem/TestMemPageStore.java": 4,
                "redelm-pig/src/main/java/redelm/hadoop/PageConsumer.java": 2,
                "redelm-pig/src/main/java/redelm/hadoop/RedelmFileReader.java": 21,
                "redelm-pig/src/main/java/redelm/hadoop/RedelmOutputFormat.java": 5,
                "redelm-pig/src/main/java/redelm/hadoop/RedelmRecordReader.java": 7,
                "redelm-pig/src/main/java/redelm/hadoop/RedelmRecordWriter.java": 5,
                "redelm-pig/src/main/java/redelm/hadoop/metadata/CompressionCodecName.java": 2,
                "redelm-pig/src/test/java/redelm/hadoop/TestRedelmFileWriter.java": 25,
                "redelm-pig/src/test/java/redelm/pig/GenerateIntTestFile.java": 6,
                "redelm-pig/src/test/java/redelm/pig/TestRedelmStorer.java": 38
            },
            "is_test": true,
            "is_fix": false
        },
        "04b60eebb2be71b8253b011d64dbc0601ca85de3": {
            "datetime": "2013-02-12T11:45:50-08:00",
            "summary": "rework compression",
            "message": "rework compression\n",
            "diff": {
                "redelm-column/src/main/java/redelm/column/mem/MemColumn.java": 4,
                "redelm-column/src/main/java/redelm/column/mem/MemColumnWriter.java": 6,
                "redelm-column/src/main/java/redelm/column/mem/MemColumnsStore.java": 6,
                "redelm-column/src/test/java/redelm/column/mem/TestMemColumn.java": 2,
                "redelm-column/src/test/java/redelm/io/PerfTest.java": 2,
                "redelm-column/src/test/java/redelm/io/TestColumnIO.java": 4,
                "redelm-pig/src/main/java/redelm/hadoop/CodecFactory.java": 103,
                "redelm-pig/src/main/java/redelm/hadoop/ColumnChunkPageStore.java": 96,
                "redelm-pig/src/main/java/redelm/hadoop/PageConsumer.java": 4,
                "redelm-pig/src/main/java/redelm/hadoop/RedelmFileReader.java": 48,
                "redelm-pig/src/main/java/redelm/hadoop/RedelmFileWriter.java": 29,
                "redelm-pig/src/main/java/redelm/hadoop/RedelmOutputFormat.java": 2,
                "redelm-pig/src/main/java/redelm/hadoop/RedelmRecordReader.java": 8,
                "redelm-pig/src/main/java/redelm/hadoop/RedelmRecordWriter.java": 47,
                "redelm-pig/src/test/java/redelm/hadoop/TestRedelmFileWriter.java": 6,
                "redelm-pig/src/test/java/redelm/pig/GenerateIntTestFile.java": 16,
                "redelm-pig/src/test/java/redelm/pig/GenerateTPCH.java": 2,
                "redelm-pig/src/test/java/redelm/pig/TestRedelmStorer.java": 12,
                "redelm-pig/src/test/java/redelm/pig/TupleConsumerPerfTest.java": 2
            },
            "is_test": true,
            "is_fix": false
        },
        "d8a18ce3cf48509ffda49f4838603037118894ba": {
            "datetime": "2013-02-12T18:24:54-08:00",
            "summary": "fix PrintFooter; fix string encoding; rewrite split generation; fix block reading logic",
            "message": "fix PrintFooter; fix string encoding; rewrite split generation; fix block reading logic\n",
            "diff": {
                "redelm-pig/src/main/java/redelm/hadoop/PrintFooter.java": 172,
                "redelm-pig/src/main/java/redelm/hadoop/RedelmFileReader.java": 4,
                "redelm-pig/src/main/java/redelm/hadoop/RedelmFileWriter.java": 6,
                "redelm-pig/src/main/java/redelm/hadoop/RedelmInputFormat.java": 67,
                "redelm-pig/src/main/java/redelm/hadoop/RedelmRecordReader.java": 27,
                "redelm-pig/src/main/java/redelm/hadoop/metadata/CompressionCodecName.java": 7,
                "redelm-pig/src/main/java/redelm/pig/TupleWriteSupport.java": 2,
                "redelm-pig/src/main/java/redelm/pig/converter/MessageConverter.java": 6
            },
            "is_test": false,
            "is_fix": false
        },
        "2ea29543f34e957cbdbee77ce1795c9ecf2150a3": {
            "datetime": "2013-02-13T15:18:38-08:00",
            "summary": "split stores",
            "message": "split stores\n",
            "diff": {
                "redelm-column/src/main/java/redelm/column/ColumnReadStore.java": 22,
                "redelm-column/src/main/java/redelm/column/ColumnsStore.java": 4,
                "redelm-column/src/main/java/redelm/column/mem/MemColumn.java": 37,
                "redelm-column/src/main/java/redelm/column/mem/MemColumnsStore.java": 52,
                "redelm-column/src/main/java/redelm/column/mem/MemPageStore.java": 2,
                "redelm-column/src/main/java/redelm/column/mem/PageStore.java": 7,
                "redelm-column/src/main/java/redelm/column/mem/PageWriteStore.java": 24,
                "redelm-column/src/main/java/redelm/io/MessageColumnIO.java": 13,
                "redelm-column/src/main/java/redelm/io/RecordReader.java": 7,
                "redelm-column/src/test/java/redelm/column/mem/TestMemColumn.java": 24,
                "redelm-column/src/test/java/redelm/io/PerfTest.java": 30,
                "redelm-column/src/test/java/redelm/io/TestColumnIO.java": 29,
                "redelm-pig/src/main/java/redelm/hadoop/ColumnChunkPageReadStore.java": 94,
                "redelm-pig/src/main/java/redelm/hadoop/ColumnChunkPageStore.java": 27,
                "redelm-pig/src/main/java/redelm/hadoop/RedelmRecordReader.java": 12,
                "redelm-pig/src/main/java/redelm/hadoop/RedelmRecordWriter.java": 6,
                "redelm-pig/src/test/java/redelm/pig/GenerateIntTestFile.java": 4,
                "redelm-pig/src/test/java/redelm/pig/GenerateTPCH.java": 7,
                "redelm-pig/src/test/java/redelm/pig/TupleConsumerPerfTest.java": 15
            },
            "is_test": true,
            "is_fix": false
        },
        "4b060586ee79815e4cec5923ec211db9dda3e8bb": {
            "datetime": "2013-02-14T08:26:24-08:00",
            "summary": "move compression to decode time and fix compressor init overhead",
            "message": "move compression to decode time and fix compressor init overhead\n",
            "diff": {
                "redelm-column/src/main/java/redelm/column/mem/MemPageReader.java": 6,
                "redelm-column/src/main/java/redelm/column/mem/MemPageStore.java": 5,
                "redelm-column/src/main/java/redelm/column/mem/MemPageWriter.java": 6,
                "redelm-column/src/main/java/redelm/column/mem/Page.java": 8,
                "redelm-column/src/main/java/redelm/column/mem/PageReadStore.java": 2,
                "redelm-column/src/main/java/redelm/column/mem/PageReader.java": 2,
                "redelm-column/src/test/java/redelm/column/mem/TestMemPageStore.java": 2,
                "redelm-pig/src/main/java/redelm/hadoop/CodecFactory.java": 41,
                "redelm-pig/src/main/java/redelm/hadoop/ColumnChunkPageReadStore.java": 85,
                "redelm-pig/src/main/java/redelm/hadoop/ColumnChunkPageWriteStore.java": 11,
                "redelm-pig/src/main/java/redelm/hadoop/RedelmFileReader.java": 59,
                "redelm-pig/src/main/java/redelm/hadoop/RedelmFileWriter.java": 4,
                "redelm-pig/src/main/java/redelm/hadoop/RedelmOutputFormat.java": 2,
                "redelm-pig/src/main/java/redelm/hadoop/RedelmRecordReader.java": 51,
                "redelm-pig/src/main/java/redelm/hadoop/RedelmRecordWriter.java": 31,
                "redelm-pig/src/test/java/redelm/hadoop/TestRedelmFileWriter.java": 86,
                "redelm-pig/src/test/java/redelm/pig/GenerateIntTestFile.java": 18
            },
            "is_test": true,
            "is_fix": false
        },
        "113f8b8509072ebf978cf3934ebafa2239503530": {
            "datetime": "2013-02-14T12:00:11-08:00",
            "summary": "reworked converter framework",
            "message": "reworked converter framework\n",
            "diff": {
                "redelm-column/src/main/java/redelm/bytes/BytesUtils.java": 3,
                "redelm-column/src/main/java/redelm/io/convert/GroupConverter.java": 39,
                "redelm-column/src/main/java/redelm/io/convert/PrimitiveConverter.java": 48,
                "redelm-pig/src/main/java/redelm/pig/convert/MapConverter.java": 152,
                "redelm-pig/src/main/java/redelm/pig/convert/TupleConverter.java": 223
            },
            "is_test": false,
            "is_fix": false
        },
        "372b9f3e6a61054528393bb4c4e7630fb17abeab": {
            "datetime": "2013-02-14T16:24:19-08:00",
            "summary": "fix projection using pig schema",
            "message": "fix projection using pig schema\n",
            "diff": {
                "redelm-column/src/main/java/redelm/io/MessageColumnIO.java": 2,
                "redelm-column/src/main/java/redelm/schema/GroupType.java": 13,
                "redelm-column/src/main/java/redelm/schema/MessageType.java": 8,
                "redelm-column/src/main/java/redelm/schema/PrimitiveType.java": 13,
                "redelm-column/src/main/java/redelm/schema/Type.java": 7,
                "redelm-pig/src/main/java/redelm/hadoop/PrintFooter.java": 22,
                "redelm-pig/src/main/java/redelm/hadoop/RedelmFileReader.java": 52,
                "redelm-pig/src/main/java/redelm/hadoop/RedelmInputFormat.java": 15,
                "redelm-pig/src/main/java/redelm/hadoop/RedelmRecordReader.java": 1,
                "redelm-pig/src/main/java/redelm/pig/PigSchemaConverter.java": 109,
                "redelm-pig/src/main/java/redelm/pig/TupleReadSupport.java": 14,
                "redelm-pig/src/main/java/redelm/pig/converter/BagConverter.java": 9,
                "redelm-pig/src/main/java/redelm/pig/converter/Converter.java": 8,
                "redelm-pig/src/main/java/redelm/pig/converter/MapConverter.java": 7,
                "redelm-pig/src/main/java/redelm/pig/converter/MapKeyValueConverter.java": 6,
                "redelm-pig/src/main/java/redelm/pig/converter/MessageConverter.java": 1,
                "redelm-pig/src/main/java/redelm/pig/converter/TupleConverter.java": 13,
                "redelm-pig/src/test/java/redelm/pig/TestPigSchemaConverter.java": 3
            },
            "is_test": true,
            "is_fix": false
        },
        "b38de8abc55fb2ee9068760c38d7e0e809c1c8bd": {
            "datetime": "2013-02-19T07:57:17-08:00",
            "summary": "add allocated usage monitoring",
            "message": "add allocated usage monitoring\n",
            "diff": {
                "redelm-column/src/main/java/redelm/bytes/CapacityByteArrayOutputStream.java": 21,
                "redelm-column/src/main/java/redelm/column/mem/MemColumnWriteStore.java": 13,
                "redelm-column/src/main/java/redelm/column/mem/MemColumnWriter.java": 7,
                "redelm-column/src/main/java/redelm/column/mem/MemPageWriter.java": 6,
                "redelm-column/src/main/java/redelm/column/mem/PageWriter.java": 2,
                "redelm-column/src/main/java/redelm/column/primitive/BitPackingColumnWriter.java": 11,
                "redelm-column/src/main/java/redelm/column/primitive/BitWriter.java": 11,
                "redelm-column/src/main/java/redelm/column/primitive/BooleanPlainColumnWriter.java": 10,
                "redelm-column/src/main/java/redelm/column/primitive/BoundedIntColumnWriter.java": 5,
                "redelm-column/src/main/java/redelm/column/primitive/DevNullColumnWriter.java": 5,
                "redelm-column/src/main/java/redelm/column/primitive/PlainColumnWriter.java": 12,
                "redelm-column/src/main/java/redelm/column/primitive/PrimitiveColumnWriter.java": 3,
                "redelm-pig/src/main/java/redelm/hadoop/ColumnChunkPageWriteStore.java": 22,
                "redelm-pig/src/main/java/redelm/hadoop/RedelmFileReader.java": 9,
                "redelm-pig/src/main/java/redelm/hadoop/RedelmFileWriter.java": 4,
                "redelm-pig/src/main/java/redelm/hadoop/RedelmRecordReader.java": 17,
                "redelm-pig/src/main/java/redelm/hadoop/RedelmRecordWriter.java": 19,
                "redelm-pig/src/main/java/redelm/pig/TupleReadSupport.java": 2,
                "redelm-pig/src/main/java/redelm/pig/converter/TupleConverter.java": 3,
                "redelm-pig/src/test/java/redelm/pig/GenerateIntTestFile.java": 2
            },
            "is_test": false,
            "is_fix": false
        },
        "a62af63205961bffb3d9559454b9c289808333e6": {
            "datetime": "2013-02-19T16:20:30-08:00",
            "summary": "fix bit packing",
            "message": "fix bit packing\n",
            "diff": {
                "redelm-column/src/main/java/redelm/column/primitive/BitPacking.java": 240,
                "redelm-column/src/main/java/redelm/column/primitive/BitPackingColumnReader.java": 2,
                "redelm-column/src/main/java/redelm/column/primitive/BooleanPlainColumnReader.java": 2,
                "redelm-column/src/test/java/redelm/column/primitive/TestBitPacking.java": 14,
                "redelm-column/src/test/java/redelm/column/primitive/TestBitPackingColumn.java": 159
            },
            "is_test": true,
            "is_fix": false
        },
        "15f6bebccc09b2af0908b34eb8769ddfd25b3795": {
            "datetime": "2013-02-19T17:17:18-08:00",
            "summary": "expose schema to pig",
            "message": "expose schema to pig\n",
            "diff": {
                "redelm-pig/src/main/java/redelm/hadoop/RedelmInputFormat.java": 19,
                "redelm-pig/src/main/java/redelm/pig/RedelmLoader.java": 87,
                "redelm-pig/src/test/java/redelm/pig/TestRedelmStorer.java": 4
            },
            "is_test": true,
            "is_fix": false
        },
        "1823220da70a749b88f97d7fc7f06eb7c1d67176": {
            "datetime": "2013-02-20T10:44:16-08:00",
            "summary": "rename the metadata package",
            "message": "rename the metadata package\n",
            "diff": {
                "redelm-pig/src/main/java/redelm/hadoop/ColumnChunkPageWriteStore.java": 8,
                "redelm-pig/src/main/java/redelm/hadoop/RedelmFileReader.java": 6,
                "redelm-pig/src/main/java/redelm/hadoop/RedelmFileWriter.java": 13,
                "redelm-pig/src/main/java/redelm/hadoop/metadata/CompressionCodecName.java": 2,
                "redelm-pig/src/main/java/redelm/redfile/RedFileMetadataConverter.java": 37,
                "redelm-pig/src/test/java/redelm/redfile/TestRedFileMetadataConverter.java": 7
            },
            "is_test": true,
            "is_fix": false
        },
        "b598378e02af0d862bf27b985bc62ebd2d24b9e0": {
            "datetime": "2013-02-20T10:56:20-08:00",
            "summary": "removed reference to red file",
            "message": "removed reference to red file\n",
            "diff": {
                "redelm-pig/src/main/java/redelm/hadoop/ColumnChunkPageWriteStore.java": 6,
                "redelm-pig/src/main/java/redelm/hadoop/RedelmFileReader.java": 14,
                "redelm-pig/src/main/java/redelm/hadoop/RedelmFileWriter.java": 14,
                "redelm-pig/src/main/java/redelm/hadoop/metadata/CompressionCodecName.java": 14,
                "redelm-pig/src/main/java/redelm/redfile/RedFileMetadataConverter.java": 40,
                "redelm-pig/src/test/java/redelm/redfile/TestRedFileMetadataConverter.java": 17
            },
            "is_test": true,
            "is_fix": false
        },
        "90f027efe123343a663e51e12d485ef7b302b093": {
            "datetime": "2013-02-20T11:04:53-08:00",
            "summary": "change magic number to PAR1",
            "message": "change magic number to PAR1\n",
            "diff": {
                "redelm-pig/src/main/java/redelm/hadoop/RedelmFileWriter.java": 4
            },
            "is_test": false,
            "is_fix": false
        },
        "e6ca25c0fec5fbf85a190092ea5094b0b10c0f13": {
            "datetime": "2013-02-20T11:10:11-08:00",
            "summary": "adding license header",
            "message": "adding license header\n",
            "diff": {
                "redelm-column/src/main/java/redelm/bytes/CapacityByteArrayOutputStream.java": 15,
                "redelm-column/src/main/java/redelm/bytes/LittleEndianDataInputStream.java": 15,
                "redelm-column/src/main/java/redelm/bytes/LittleEndianDataOutputStream.java": 15,
                "redelm-column/src/main/java/redelm/column/primitive/BitPackingColumnReader.java": 15,
                "redelm-column/src/main/java/redelm/column/primitive/BitPackingColumnWriter.java": 15,
                "redelm-column/src/main/java/redelm/io/convert/GroupConverter.java": 15,
                "redelm-column/src/main/java/redelm/io/convert/PrimitiveConverter.java": 15,
                "redelm-column/src/test/java/redelm/column/primitive/TestBitPackingColumn.java": 15,
                "redelm-pig/src/main/java/redelm/hadoop/ColumnChunkPageReadStore.java": 15,
                "redelm-pig/src/main/java/redelm/hadoop/ColumnChunkPageWriteStore.java": 15,
                "redelm-pig/src/main/java/redelm/pig/convert/MapConverter.java": 15,
                "redelm-pig/src/main/java/redelm/pig/convert/TupleConverter.java": 15,
                "redelm-pig/src/test/java/redelm/pig/GenerateIntTestFile.java": 15,
                "redelm-pig/src/test/java/redelm/pig/GenerateTPCH.java": 15
            },
            "is_test": true,
            "is_fix": false
        },
        "08df187f82f3b3c0863c1bfb1096f0fb45ec599b": {
            "datetime": "2013-02-20T11:10:54-08:00",
            "summary": "Merge pull request #25 from julienledem/integrate_format_changes",
            "message": "Merge pull request #25 from julienledem/integrate_format_changes\n\nIntegrate format changes for Parquet",
            "diff": {
                "redelm-column/src/main/java/redelm/Log.java": 12,
                "redelm-column/src/main/java/redelm/bytes/BytesInput.java": 219,
                "redelm-column/src/main/java/redelm/bytes/BytesUtils.java": 87,
                "redelm-column/src/main/java/redelm/bytes/LittleEndianDataInputStream.java": 415,
                "redelm-column/src/main/java/redelm/bytes/LittleEndianDataOutputStream.java": 207,
                "redelm-column/src/main/java/redelm/column/ColumnDescriptor.java": 8,
                "redelm-column/src/main/java/redelm/column/ColumnReadStore.java": 22,
                "redelm-column/src/main/java/redelm/column/ColumnWriter.java": 14,
                "redelm-column/src/main/java/redelm/column/ColumnsStore.java": 6,
                "redelm-column/src/main/java/redelm/column/RedelmByteArrayOutputStream.java": 20,
                "redelm-column/src/main/java/redelm/column/mem/MemColumn.java": 299,
                "redelm-column/src/main/java/redelm/column/mem/MemColumnReadStore.java": 204,
                "redelm-column/src/main/java/redelm/column/mem/MemColumnReader.java": 120,
                "redelm-column/src/main/java/redelm/column/mem/MemColumnWriteStore.java": 100,
                "redelm-column/src/main/java/redelm/column/mem/MemColumnWriter.java": 108,
                "redelm-column/src/main/java/redelm/column/mem/MemColumnsStore.java": 122,
                "redelm-column/src/main/java/redelm/column/mem/MemPageReader.java": 55,
                "redelm-column/src/main/java/redelm/column/mem/MemPageStore.java": 60,
                "redelm-column/src/main/java/redelm/column/mem/MemPageWriter.java": 65,
                "redelm-column/src/main/java/redelm/column/mem/Page.java": 57,
                "redelm-column/src/main/java/redelm/column/mem/PageReadStore.java": 26,
                "redelm-column/src/main/java/redelm/column/mem/PageReader.java": 24,
                "redelm-column/src/main/java/redelm/column/mem/PageWriteStore.java": 24,
                "redelm-column/src/main/java/redelm/column/mem/PageWriter.java": 30,
                "redelm-column/src/main/java/redelm/column/primitive/BitPacking.java": 720,
                "redelm-column/src/main/java/redelm/column/primitive/BitPackingColumnReader.java": 54,
                "redelm-column/src/main/java/redelm/column/primitive/BitPackingColumnWriter.java": 78,
                "redelm-column/src/main/java/redelm/column/primitive/BitReader.java": 9,
                "redelm-column/src/main/java/redelm/column/primitive/BitWriter.java": 43,
                "redelm-column/src/main/java/redelm/column/primitive/BooleanPlainColumnReader.java": 53,
                "redelm-column/src/main/java/redelm/column/primitive/BooleanPlainColumnWriter.java": 81,
                "redelm-column/src/main/java/redelm/column/primitive/BoundedIntColumnReader.java": 23,
                "redelm-column/src/main/java/redelm/column/primitive/BoundedIntColumnWriter.java": 39,
                "redelm-column/src/main/java/redelm/column/primitive/DevNullColumnReader.java": 14,
                "redelm-column/src/main/java/redelm/column/primitive/DevNullColumnWriter.java": 19,
                "redelm-column/src/main/java/redelm/column/primitive/PrimitiveColumnReader.java": 16,
                "redelm-column/src/main/java/redelm/column/primitive/PrimitiveColumnWriter.java": 14,
                "redelm-column/src/main/java/redelm/column/primitive/SimplePrimitiveColumnReader.java": 74,
                "redelm-column/src/main/java/redelm/column/primitive/SimplePrimitiveColumnWriter.java": 66,
                "redelm-column/src/main/java/redelm/data/Group.java": 2,
                "redelm-column/src/main/java/redelm/data/GroupRecordConsumer.java": 5,
                "redelm-column/src/main/java/redelm/data/simple/BinaryValue.java": 10,
                "redelm-column/src/main/java/redelm/data/simple/SimpleGroup.java": 4,
                "redelm-column/src/main/java/redelm/data/simple/StringValue.java": 34,
                "redelm-column/src/main/java/redelm/data/simple/example/Paper.java": 12,
                "redelm-column/src/main/java/redelm/io/MessageColumnIO.java": 25,
                "redelm-column/src/main/java/redelm/io/PrimitiveColumnIO.java": 2,
                "redelm-column/src/main/java/redelm/io/RecordConsumer.java": 6,
                "redelm-column/src/main/java/redelm/io/RecordConsumerLoggingWrapper.java": 9,
                "redelm-column/src/main/java/redelm/io/RecordReader.java": 15,
                "redelm-column/src/main/java/redelm/io/ValidatingRecordConsumer.java": 26,
                "redelm-column/src/main/java/redelm/io/convert/GroupConverter.java": 54,
                "redelm-column/src/main/java/redelm/io/convert/PrimitiveConverter.java": 63,
                "redelm-column/src/main/java/redelm/parser/MessageTypeParser.java": 4,
                "redelm-column/src/main/java/redelm/schema/GroupType.java": 28,
                "redelm-column/src/main/java/redelm/schema/MessageType.java": 38,
                "redelm-column/src/main/java/redelm/schema/PrimitiveType.java": 47,
                "redelm-column/src/main/java/redelm/schema/Type.java": 11,
                "redelm-column/src/test/java/redelm/bytes/TestBytesUtil.java": 54,
                "redelm-column/src/test/java/redelm/column/mem/TestMemColumn.java": 118,
                "redelm-column/src/test/java/redelm/column/mem/TestMemPageStore.java": 50,
                "redelm-column/src/test/java/redelm/column/primitive/TestBitPacking.java": 213,
                "redelm-column/src/test/java/redelm/column/primitive/TestBitPackingColumn.java": 174,
                "redelm-column/src/test/java/redelm/column/primitive/TestBoundedColumns.java": 104,
                "redelm-column/src/test/java/redelm/io/PerfTest.java": 32,
                "redelm-column/src/test/java/redelm/io/TestColumnIO.java": 137,
                "redelm-column/src/test/java/redelm/parser/TestRedelmParser.java": 25,
                "redelm-pig/src/main/java/redelm/format/converter/ParquetMetadataConverter.java": 347,
                "redelm-pig/src/main/java/redelm/hadoop/BlockData.java": 6,
                "redelm-pig/src/main/java/redelm/hadoop/BlockMetaData.java": 82,
                "redelm-pig/src/main/java/redelm/hadoop/CodecFactory.java": 185,
                "redelm-pig/src/main/java/redelm/hadoop/ColumnChunkPageReadStore.java": 100,
                "redelm-pig/src/main/java/redelm/hadoop/ColumnChunkPageWriteStore.java": 115,
                "redelm-pig/src/main/java/redelm/hadoop/ColumnMetaData.java": 264,
                "redelm-pig/src/main/java/redelm/hadoop/Footer.java": 15,
                "redelm-pig/src/main/java/redelm/hadoop/MetaDataBlock.java": 39,
                "redelm-pig/src/main/java/redelm/hadoop/PageConsumer.java": 24,
                "redelm-pig/src/main/java/redelm/hadoop/PrintFooter.java": 239,
                "redelm-pig/src/main/java/redelm/hadoop/ReadSupport.java": 3,
                "redelm-pig/src/main/java/redelm/hadoop/RedelmFileReader.java": 294,
                "redelm-pig/src/main/java/redelm/hadoop/RedelmFileWriter.java": 253,
                "redelm-pig/src/main/java/redelm/hadoop/RedelmInputFormat.java": 112,
                "redelm-pig/src/main/java/redelm/hadoop/RedelmInputSplit.java": 20,
                "redelm-pig/src/main/java/redelm/hadoop/RedelmMetaData.java": 76,
                "redelm-pig/src/main/java/redelm/hadoop/RedelmOutputFormat.java": 70,
                "redelm-pig/src/main/java/redelm/hadoop/RedelmRecordReader.java": 107,
                "redelm-pig/src/main/java/redelm/hadoop/RedelmRecordWriter.java": 88,
                "redelm-pig/src/main/java/redelm/hadoop/WriteSupport.java": 4,
                "redelm-pig/src/main/java/redelm/hadoop/metadata/ColumnChunkMetaData.java": 138,
                "redelm-pig/src/main/java/redelm/hadoop/metadata/CompressionCodecName.java": 77,
                "redelm-pig/src/main/java/redelm/hadoop/metadata/FileMetaData.java": 51,
                "redelm-pig/src/main/java/redelm/pig/PigMetaData.java": 17,
                "redelm-pig/src/main/java/redelm/pig/PigSchemaConverter.java": 115,
                "redelm-pig/src/main/java/redelm/pig/RedelmLoader.java": 87,
                "redelm-pig/src/main/java/redelm/pig/RedelmStorer.java": 6,
                "redelm-pig/src/main/java/redelm/pig/TupleReadSupport.java": 21,
                "redelm-pig/src/main/java/redelm/pig/TupleRecordConsumer.java": 5,
                "redelm-pig/src/main/java/redelm/pig/TupleWriteSupport.java": 22,
                "redelm-pig/src/main/java/redelm/pig/convert/MapConverter.java": 167,
                "redelm-pig/src/main/java/redelm/pig/convert/TupleConverter.java": 238,
                "redelm-pig/src/main/java/redelm/pig/converter/BagConverter.java": 9,
                "redelm-pig/src/main/java/redelm/pig/converter/Converter.java": 8,
                "redelm-pig/src/main/java/redelm/pig/converter/MapConverter.java": 7,
                "redelm-pig/src/main/java/redelm/pig/converter/MapKeyValueConverter.java": 14,
                "redelm-pig/src/main/java/redelm/pig/converter/MessageConverter.java": 12,
                "redelm-pig/src/main/java/redelm/pig/converter/TupleConverter.java": 32,
                "redelm-pig/src/test/java/redelm/format/converter/TestParquetMetadataConverter.java": 58,
                "redelm-pig/src/test/java/redelm/hadoop/TestInputFormat.java": 24,
                "redelm-pig/src/test/java/redelm/hadoop/TestRedelmFileWriter.java": 153,
                "redelm-pig/src/test/java/redelm/pig/GenerateIntTestFile.java": 136,
                "redelm-pig/src/test/java/redelm/pig/GenerateTPCH.java": 109,
                "redelm-pig/src/test/java/redelm/pig/TestPigSchemaConverter.java": 33,
                "redelm-pig/src/test/java/redelm/pig/TestRedelmStorer.java": 53,
                "redelm-pig/src/test/java/redelm/pig/TestTupleRecordConsumer.java": 10,
                "redelm-pig/src/test/java/redelm/pig/TupleConsumerPerfTest.java": 35
            },
            "is_test": true,
            "is_fix": false
        },
        "951cd2f95aee57fff6ab84594669aad12e8f4e8e": {
            "datetime": "2013-02-20T12:01:44-08:00",
            "summary": "Merge branch 'master' into FSA_codegen",
            "message": "Merge branch 'master' into FSA_codegen\n\nConflicts:\n\tredelm-column/src/main/java/redelm/io/MessageColumnIO.java\n\tredelm-column/src/main/java/redelm/io/RecordReader.java\n\tredelm-column/src/main/java/redelm/schema/PrimitiveType.java\n\tredelm-column/src/test/java/redelm/io/PerfTest.java\n\tredelm-column/src/test/java/redelm/io/TestColumnIO.java\n\tredelm-pig/src/test/java/redelm/hadoop/TestInputFormat.java\n\tredelm-pig/src/test/java/redelm/pig/TupleConsumerPerfTest.java\n",
            "diff": {
                "redelm-column/src/main/java/redelm/Log.java": 12,
                "redelm-column/src/main/java/redelm/bytes/BytesInput.java": 219,
                "redelm-column/src/main/java/redelm/bytes/BytesUtils.java": 87,
                "redelm-column/src/main/java/redelm/bytes/LittleEndianDataInputStream.java": 415,
                "redelm-column/src/main/java/redelm/bytes/LittleEndianDataOutputStream.java": 207,
                "redelm-column/src/main/java/redelm/column/ColumnDescriptor.java": 8,
                "redelm-column/src/main/java/redelm/column/ColumnReadStore.java": 22,
                "redelm-column/src/main/java/redelm/column/ColumnWriter.java": 14,
                "redelm-column/src/main/java/redelm/column/ColumnsStore.java": 6,
                "redelm-column/src/main/java/redelm/column/RedelmByteArrayOutputStream.java": 20,
                "redelm-column/src/main/java/redelm/column/mem/MemColumn.java": 299,
                "redelm-column/src/main/java/redelm/column/mem/MemColumnReadStore.java": 204,
                "redelm-column/src/main/java/redelm/column/mem/MemColumnReader.java": 120,
                "redelm-column/src/main/java/redelm/column/mem/MemColumnWriteStore.java": 100,
                "redelm-column/src/main/java/redelm/column/mem/MemColumnWriter.java": 108,
                "redelm-column/src/main/java/redelm/column/mem/MemColumnsStore.java": 122,
                "redelm-column/src/main/java/redelm/column/mem/MemPageReader.java": 55,
                "redelm-column/src/main/java/redelm/column/mem/MemPageStore.java": 60,
                "redelm-column/src/main/java/redelm/column/mem/MemPageWriter.java": 65,
                "redelm-column/src/main/java/redelm/column/mem/Page.java": 57,
                "redelm-column/src/main/java/redelm/column/mem/PageReadStore.java": 26,
                "redelm-column/src/main/java/redelm/column/mem/PageReader.java": 24,
                "redelm-column/src/main/java/redelm/column/mem/PageWriteStore.java": 24,
                "redelm-column/src/main/java/redelm/column/mem/PageWriter.java": 30,
                "redelm-column/src/main/java/redelm/column/primitive/BitPacking.java": 720,
                "redelm-column/src/main/java/redelm/column/primitive/BitPackingColumnReader.java": 54,
                "redelm-column/src/main/java/redelm/column/primitive/BitPackingColumnWriter.java": 78,
                "redelm-column/src/main/java/redelm/column/primitive/BitReader.java": 9,
                "redelm-column/src/main/java/redelm/column/primitive/BitWriter.java": 43,
                "redelm-column/src/main/java/redelm/column/primitive/BooleanPlainColumnReader.java": 53,
                "redelm-column/src/main/java/redelm/column/primitive/BooleanPlainColumnWriter.java": 81,
                "redelm-column/src/main/java/redelm/column/primitive/BoundedIntColumnReader.java": 23,
                "redelm-column/src/main/java/redelm/column/primitive/BoundedIntColumnWriter.java": 39,
                "redelm-column/src/main/java/redelm/column/primitive/DevNullColumnReader.java": 14,
                "redelm-column/src/main/java/redelm/column/primitive/DevNullColumnWriter.java": 19,
                "redelm-column/src/main/java/redelm/column/primitive/PrimitiveColumnReader.java": 16,
                "redelm-column/src/main/java/redelm/column/primitive/PrimitiveColumnWriter.java": 14,
                "redelm-column/src/main/java/redelm/column/primitive/SimplePrimitiveColumnReader.java": 74,
                "redelm-column/src/main/java/redelm/column/primitive/SimplePrimitiveColumnWriter.java": 66,
                "redelm-column/src/main/java/redelm/data/Group.java": 2,
                "redelm-column/src/main/java/redelm/data/GroupRecordConsumer.java": 5,
                "redelm-column/src/main/java/redelm/data/simple/BinaryValue.java": 10,
                "redelm-column/src/main/java/redelm/data/simple/SimpleGroup.java": 4,
                "redelm-column/src/main/java/redelm/data/simple/StringValue.java": 34,
                "redelm-column/src/main/java/redelm/data/simple/example/Paper.java": 12,
                "redelm-column/src/main/java/redelm/io/BaseRecordReader.java": 24,
                "redelm-column/src/main/java/redelm/io/MessageColumnIO.java": 25,
                "redelm-column/src/main/java/redelm/io/PrimitiveColumnIO.java": 8,
                "redelm-column/src/main/java/redelm/io/RecordConsumer.java": 6,
                "redelm-column/src/main/java/redelm/io/RecordConsumerLoggingWrapper.java": 9,
                "redelm-column/src/main/java/redelm/io/RecordReader.java": 14,
                "redelm-column/src/main/java/redelm/io/RecordReaderImplementation.java": 25,
                "redelm-column/src/main/java/redelm/io/ValidatingRecordConsumer.java": 26,
                "redelm-column/src/main/java/redelm/io/convert/GroupConverter.java": 54,
                "redelm-column/src/main/java/redelm/io/convert/PrimitiveConverter.java": 63,
                "redelm-column/src/main/java/redelm/parser/MessageTypeParser.java": 4,
                "redelm-column/src/main/java/redelm/schema/GroupType.java": 28,
                "redelm-column/src/main/java/redelm/schema/MessageType.java": 38,
                "redelm-column/src/main/java/redelm/schema/PrimitiveType.java": 52,
                "redelm-column/src/main/java/redelm/schema/Type.java": 11,
                "redelm-column/src/test/java/redelm/bytes/TestBytesUtil.java": 54,
                "redelm-column/src/test/java/redelm/column/mem/TestMemColumn.java": 118,
                "redelm-column/src/test/java/redelm/column/mem/TestMemPageStore.java": 50,
                "redelm-column/src/test/java/redelm/column/primitive/TestBitPacking.java": 213,
                "redelm-column/src/test/java/redelm/column/primitive/TestBitPackingColumn.java": 174,
                "redelm-column/src/test/java/redelm/column/primitive/TestBoundedColumns.java": 104,
                "redelm-column/src/test/java/redelm/io/ExpectationValidatingRecordConsumer.java": 7,
                "redelm-column/src/test/java/redelm/io/PerfTest.java": 48,
                "redelm-column/src/test/java/redelm/io/TestColumnIO.java": 133,
                "redelm-column/src/test/java/redelm/io/TestRecordReaderCompiler.java": 37,
                "redelm-column/src/test/java/redelm/parser/TestRedelmParser.java": 25,
                "redelm-pig/src/main/java/redelm/format/converter/ParquetMetadataConverter.java": 347,
                "redelm-pig/src/main/java/redelm/hadoop/BlockData.java": 6,
                "redelm-pig/src/main/java/redelm/hadoop/BlockMetaData.java": 82,
                "redelm-pig/src/main/java/redelm/hadoop/CodecFactory.java": 185,
                "redelm-pig/src/main/java/redelm/hadoop/ColumnChunkPageReadStore.java": 100,
                "redelm-pig/src/main/java/redelm/hadoop/ColumnChunkPageWriteStore.java": 115,
                "redelm-pig/src/main/java/redelm/hadoop/ColumnMetaData.java": 264,
                "redelm-pig/src/main/java/redelm/hadoop/Footer.java": 15,
                "redelm-pig/src/main/java/redelm/hadoop/MetaDataBlock.java": 39,
                "redelm-pig/src/main/java/redelm/hadoop/PageConsumer.java": 24,
                "redelm-pig/src/main/java/redelm/hadoop/PrintFooter.java": 239,
                "redelm-pig/src/main/java/redelm/hadoop/ReadSupport.java": 3,
                "redelm-pig/src/main/java/redelm/hadoop/RedelmFileReader.java": 294,
                "redelm-pig/src/main/java/redelm/hadoop/RedelmFileWriter.java": 253,
                "redelm-pig/src/main/java/redelm/hadoop/RedelmInputFormat.java": 112,
                "redelm-pig/src/main/java/redelm/hadoop/RedelmInputSplit.java": 20,
                "redelm-pig/src/main/java/redelm/hadoop/RedelmMetaData.java": 76,
                "redelm-pig/src/main/java/redelm/hadoop/RedelmOutputFormat.java": 70,
                "redelm-pig/src/main/java/redelm/hadoop/RedelmRecordReader.java": 107,
                "redelm-pig/src/main/java/redelm/hadoop/RedelmRecordWriter.java": 88,
                "redelm-pig/src/main/java/redelm/hadoop/WriteSupport.java": 4,
                "redelm-pig/src/main/java/redelm/hadoop/metadata/ColumnChunkMetaData.java": 138,
                "redelm-pig/src/main/java/redelm/hadoop/metadata/CompressionCodecName.java": 77,
                "redelm-pig/src/main/java/redelm/hadoop/metadata/FileMetaData.java": 51,
                "redelm-pig/src/main/java/redelm/pig/PigMetaData.java": 17,
                "redelm-pig/src/main/java/redelm/pig/PigSchemaConverter.java": 115,
                "redelm-pig/src/main/java/redelm/pig/RedelmLoader.java": 87,
                "redelm-pig/src/main/java/redelm/pig/RedelmStorer.java": 6,
                "redelm-pig/src/main/java/redelm/pig/TupleReadSupport.java": 21,
                "redelm-pig/src/main/java/redelm/pig/TupleRecordConsumer.java": 5,
                "redelm-pig/src/main/java/redelm/pig/TupleWriteSupport.java": 22,
                "redelm-pig/src/main/java/redelm/pig/convert/MapConverter.java": 167,
                "redelm-pig/src/main/java/redelm/pig/convert/TupleConverter.java": 238,
                "redelm-pig/src/main/java/redelm/pig/converter/BagConverter.java": 9,
                "redelm-pig/src/main/java/redelm/pig/converter/Converter.java": 8,
                "redelm-pig/src/main/java/redelm/pig/converter/MapConverter.java": 7,
                "redelm-pig/src/main/java/redelm/pig/converter/MapKeyValueConverter.java": 14,
                "redelm-pig/src/main/java/redelm/pig/converter/MessageConverter.java": 12,
                "redelm-pig/src/main/java/redelm/pig/converter/TupleConverter.java": 32,
                "redelm-pig/src/test/java/redelm/format/converter/TestParquetMetadataConverter.java": 58,
                "redelm-pig/src/test/java/redelm/hadoop/TestInputFormat.java": 23,
                "redelm-pig/src/test/java/redelm/hadoop/TestRedelmFileWriter.java": 153,
                "redelm-pig/src/test/java/redelm/pig/GenerateIntTestFile.java": 136,
                "redelm-pig/src/test/java/redelm/pig/GenerateTPCH.java": 109,
                "redelm-pig/src/test/java/redelm/pig/TestPigSchemaConverter.java": 33,
                "redelm-pig/src/test/java/redelm/pig/TestRedelmStorer.java": 53,
                "redelm-pig/src/test/java/redelm/pig/TestTupleRecordConsumer.java": 10,
                "redelm-pig/src/test/java/redelm/pig/TupleConsumerPerfTest.java": 31
            },
            "is_test": true,
            "is_fix": false
        },
        "adcab26d8a80a6fcb6a069efa774b141e3eb19bf": {
            "datetime": "2013-02-20T12:06:16-08:00",
            "summary": "Merge pull request #24 from julienledem/FSA_codegen",
            "message": "Merge pull request #24 from julienledem/FSA_codegen\n\nFirst stab at doing codegen for the FSA",
            "diff": {
                "redelm-column/src/main/java/redelm/column/mem/MemColumnReader.java": 2,
                "redelm-column/src/main/java/redelm/io/BaseRecordReader.java": 137,
                "redelm-column/src/main/java/redelm/io/ColumnIO.java": 8,
                "redelm-column/src/main/java/redelm/io/MessageColumnIO.java": 2,
                "redelm-column/src/main/java/redelm/io/PrimitiveColumnIO.java": 5,
                "redelm-column/src/main/java/redelm/io/RecordReader.java": 276,
                "redelm-column/src/main/java/redelm/io/RecordReaderCompiler.java": 273,
                "redelm-column/src/main/java/redelm/io/RecordReaderImplementation.java": 508,
                "redelm-column/src/main/java/redelm/schema/PrimitiveType.java": 22,
                "redelm-column/src/test/java/redelm/io/ExpectationValidatingRecordConsumer.java": 101,
                "redelm-column/src/test/java/redelm/io/PerfTest.java": 66,
                "redelm-column/src/test/java/redelm/io/TestColumnIO.java": 211,
                "redelm-column/src/test/java/redelm/io/TestRecordReaderCompiler.java": 73,
                "redelm-pig/src/test/java/redelm/pig/TupleConsumerPerfTest.java": 5
            },
            "is_test": true,
            "is_fix": false
        },
        "33aad25b805a927f4ead3c7cbcfad39a518a87a0": {
            "datetime": "2013-02-20T12:16:33-08:00",
            "summary": "rename package to parquet",
            "message": "rename package to parquet\n",
            "diff": {
                "redelm-pig/src/main/java/redelm/format/converter/ParquetMetadataConverter.java": 12,
                "redelm-pig/src/main/java/redelm/hadoop/BlockData.java": 2,
                "redelm-pig/src/main/java/redelm/hadoop/CodecFactory.java": 5,
                "redelm-pig/src/main/java/redelm/hadoop/ColumnChunkPageReadStore.java": 5,
                "redelm-pig/src/main/java/redelm/hadoop/ColumnChunkPageWriteStore.java": 6,
                "redelm-pig/src/main/java/redelm/hadoop/ColumnData.java": 2,
                "redelm-pig/src/main/java/redelm/hadoop/Footer.java": 5,
                "redelm-pig/src/main/java/redelm/hadoop/PageConsumer.java": 2,
                "redelm-pig/src/main/java/redelm/hadoop/PrintFooter.java": 11,
                "redelm-pig/src/main/java/redelm/hadoop/ReadSupport.java": 2,
                "redelm-pig/src/main/java/redelm/hadoop/RedelmFileReader.java": 18,
                "redelm-pig/src/main/java/redelm/hadoop/RedelmFileWriter.java": 14,
                "redelm-pig/src/main/java/redelm/hadoop/RedelmInputFormat.java": 11,
                "redelm-pig/src/main/java/redelm/hadoop/RedelmInputSplit.java": 7,
                "redelm-pig/src/main/java/redelm/hadoop/RedelmOutputCommitter.java": 2,
                "redelm-pig/src/main/java/redelm/hadoop/RedelmOutputFormat.java": 5,
                "redelm-pig/src/main/java/redelm/hadoop/RedelmRecordReader.java": 7,
                "redelm-pig/src/main/java/redelm/hadoop/RedelmRecordWriter.java": 5,
                "redelm-pig/src/main/java/redelm/hadoop/WriteSupport.java": 2,
                "redelm-pig/src/main/java/redelm/hadoop/metadata/BlockMetaData.java": 2,
                "redelm-pig/src/main/java/redelm/hadoop/metadata/ColumnChunkMetaData.java": 2,
                "redelm-pig/src/main/java/redelm/hadoop/metadata/ColumnMetaData.java": 2,
                "redelm-pig/src/main/java/redelm/hadoop/metadata/CompressionCodecName.java": 2,
                "redelm-pig/src/main/java/redelm/hadoop/metadata/FileMetaData.java": 2,
                "redelm-pig/src/main/java/redelm/hadoop/metadata/RedelmMetaData.java": 2,
                "redelm-pig/src/main/java/redelm/pig/PigMetaData.java": 2,
                "redelm-pig/src/main/java/redelm/pig/PigSchemaConverter.java": 2,
                "redelm-pig/src/main/java/redelm/pig/RedelmLoader.java": 9,
                "redelm-pig/src/main/java/redelm/pig/RedelmStorer.java": 5,
                "redelm-pig/src/main/java/redelm/pig/TupleConversionException.java": 2,
                "redelm-pig/src/main/java/redelm/pig/TupleReadSupport.java": 7,
                "redelm-pig/src/main/java/redelm/pig/TupleRecordConsumer.java": 2,
                "redelm-pig/src/main/java/redelm/pig/TupleWriteSupport.java": 5,
                "redelm-pig/src/main/java/redelm/pig/convert/MapConverter.java": 2,
                "redelm-pig/src/main/java/redelm/pig/convert/TupleConverter.java": 5,
                "redelm-pig/src/main/java/redelm/pig/converter/BagConverter.java": 5,
                "redelm-pig/src/main/java/redelm/pig/converter/Converter.java": 2,
                "redelm-pig/src/main/java/redelm/pig/converter/MapConverter.java": 5,
                "redelm-pig/src/main/java/redelm/pig/converter/MapKeyValueConverter.java": 2,
                "redelm-pig/src/main/java/redelm/pig/converter/MessageConverter.java": 2,
                "redelm-pig/src/main/java/redelm/pig/converter/TupleConverter.java": 5,
                "redelm-pig/src/main/java/redelm/pig/summary/BagSummaryData.java": 2,
                "redelm-pig/src/main/java/redelm/pig/summary/EnumStat.java": 2,
                "redelm-pig/src/main/java/redelm/pig/summary/FieldSummaryData.java": 2,
                "redelm-pig/src/main/java/redelm/pig/summary/MapSummaryData.java": 2,
                "redelm-pig/src/main/java/redelm/pig/summary/NumberSummaryData.java": 2,
                "redelm-pig/src/main/java/redelm/pig/summary/StringSummaryData.java": 5,
                "redelm-pig/src/main/java/redelm/pig/summary/Summary.java": 2,
                "redelm-pig/src/main/java/redelm/pig/summary/SummaryData.java": 2,
                "redelm-pig/src/main/java/redelm/pig/summary/TupleSummaryData.java": 2,
                "redelm-pig/src/main/java/redelm/pig/summary/ValueStat.java": 2,
                "redelm-pig/src/test/java/redelm/format/converter/TestParquetMetadataConverter.java": 4,
                "redelm-pig/src/test/java/redelm/hadoop/TestInputFormat.java": 14,
                "redelm-pig/src/test/java/redelm/hadoop/TestRedelmFileWriter.java": 10,
                "redelm-pig/src/test/java/redelm/pig/GenerateIntTestFile.java": 11,
                "redelm-pig/src/test/java/redelm/pig/GenerateTPCH.java": 6,
                "redelm-pig/src/test/java/redelm/pig/PerfTest.java": 5,
                "redelm-pig/src/test/java/redelm/pig/PerfTest2.java": 5,
                "redelm-pig/src/test/java/redelm/pig/PerfTestReadAllCols.java": 2,
                "redelm-pig/src/test/java/redelm/pig/TestPigSchemaConverter.java": 4,
                "redelm-pig/src/test/java/redelm/pig/TestRedelmStorer.java": 5,
                "redelm-pig/src/test/java/redelm/pig/TestTupleRecordConsumer.java": 7,
                "redelm-pig/src/test/java/redelm/pig/TupleConsumerPerfTest.java": 7,
                "redelm-pig/src/test/java/redelm/pig/summary/TestSummary.java": 7
            },
            "is_test": true,
            "is_fix": false
        },
        "73f69973d78bf1fae7c1aad661421b8bc955d20f": {
            "datetime": "2013-02-20T12:21:09-08:00",
            "summary": "rename package to parquet",
            "message": "rename package to parquet\n",
            "diff": {
                "redelm-column/src/main/java/redelm/Log.java": 2,
                "redelm-column/src/main/java/redelm/RedelmRuntimeException.java": 2,
                "redelm-column/src/main/java/redelm/bytes/BytesInput.java": 5,
                "redelm-column/src/main/java/redelm/bytes/BytesUtils.java": 5,
                "redelm-column/src/main/java/redelm/bytes/CapacityByteArrayOutputStream.java": 2,
                "redelm-column/src/main/java/redelm/bytes/LittleEndianDataInputStream.java": 2,
                "redelm-column/src/main/java/redelm/bytes/LittleEndianDataOutputStream.java": 2,
                "redelm-column/src/main/java/redelm/column/ColumnDescriptor.java": 5,
                "redelm-column/src/main/java/redelm/column/ColumnReadStore.java": 2,
                "redelm-column/src/main/java/redelm/column/ColumnReader.java": 2,
                "redelm-column/src/main/java/redelm/column/ColumnWriteStore.java": 2,
                "redelm-column/src/main/java/redelm/column/ColumnWriter.java": 2,
                "redelm-column/src/main/java/redelm/column/UnknownColumnException.java": 4,
                "redelm-column/src/main/java/redelm/column/mem/MemColumnReadStore.java": 9,
                "redelm-column/src/main/java/redelm/column/mem/MemColumnReader.java": 27,
                "redelm-column/src/main/java/redelm/column/mem/MemColumnWriteStore.java": 9,
                "redelm-column/src/main/java/redelm/column/mem/MemColumnWriter.java": 23,
                "redelm-column/src/main/java/redelm/column/mem/MemPageReader.java": 7,
                "redelm-column/src/main/java/redelm/column/mem/MemPageStore.java": 9,
                "redelm-column/src/main/java/redelm/column/mem/MemPageWriter.java": 9,
                "redelm-column/src/main/java/redelm/column/mem/Page.java": 6,
                "redelm-column/src/main/java/redelm/column/mem/PageReadStore.java": 4,
                "redelm-column/src/main/java/redelm/column/mem/PageReader.java": 2,
                "redelm-column/src/main/java/redelm/column/mem/PageWriteStore.java": 4,
                "redelm-column/src/main/java/redelm/column/mem/PageWriter.java": 5,
                "redelm-column/src/main/java/redelm/column/primitive/BitPacking.java": 7,
                "redelm-column/src/main/java/redelm/column/primitive/BitPackingColumnReader.java": 9,
                "redelm-column/src/main/java/redelm/column/primitive/BitPackingColumnWriter.java": 13,
                "redelm-column/src/main/java/redelm/column/primitive/BitReader.java": 2,
                "redelm-column/src/main/java/redelm/column/primitive/BitWriter.java": 6,
                "redelm-column/src/main/java/redelm/column/primitive/BooleanPlainColumnReader.java": 13,
                "redelm-column/src/main/java/redelm/column/primitive/BooleanPlainColumnWriter.java": 13,
                "redelm-column/src/main/java/redelm/column/primitive/BoundedColumnFactory.java": 2,
                "redelm-column/src/main/java/redelm/column/primitive/BoundedIntColumnReader.java": 9,
                "redelm-column/src/main/java/redelm/column/primitive/BoundedIntColumnWriter.java": 6,
                "redelm-column/src/main/java/redelm/column/primitive/DevNullColumnReader.java": 2,
                "redelm-column/src/main/java/redelm/column/primitive/DevNullColumnWriter.java": 4,
                "redelm-column/src/main/java/redelm/column/primitive/PlainColumnReader.java": 13,
                "redelm-column/src/main/java/redelm/column/primitive/PlainColumnWriter.java": 11,
                "redelm-column/src/main/java/redelm/column/primitive/PrimitiveColumnReader.java": 2,
                "redelm-column/src/main/java/redelm/column/primitive/PrimitiveColumnWriter.java": 4,
                "redelm-column/src/main/java/redelm/data/Group.java": 6,
                "redelm-column/src/main/java/redelm/data/GroupFactory.java": 2,
                "redelm-column/src/main/java/redelm/data/GroupRecordConsumer.java": 7,
                "redelm-column/src/main/java/redelm/data/GroupValueSource.java": 4,
                "redelm-column/src/main/java/redelm/data/GroupWriter.java": 8,
                "redelm-column/src/main/java/redelm/data/simple/BinaryValue.java": 4,
                "redelm-column/src/main/java/redelm/data/simple/BooleanValue.java": 4,
                "redelm-column/src/main/java/redelm/data/simple/DoubleValue.java": 4,
                "redelm-column/src/main/java/redelm/data/simple/FloatValue.java": 4,
                "redelm-column/src/main/java/redelm/data/simple/IntegerValue.java": 4,
                "redelm-column/src/main/java/redelm/data/simple/LongValue.java": 4,
                "redelm-column/src/main/java/redelm/data/simple/Primitive.java": 4,
                "redelm-column/src/main/java/redelm/data/simple/SimpleGroup.java": 11,
                "redelm-column/src/main/java/redelm/data/simple/SimpleGroupFactory.java": 8,
                "redelm-column/src/main/java/redelm/data/simple/example/Paper.java": 22,
                "redelm-column/src/main/java/redelm/io/BaseRecordReader.java": 10,
                "redelm-column/src/main/java/redelm/io/ColumnIO.java": 9,
                "redelm-column/src/main/java/redelm/io/ColumnIOFactory.java": 15,
                "redelm-column/src/main/java/redelm/io/GroupColumnIO.java": 11,
                "redelm-column/src/main/java/redelm/io/InvalidRecordException.java": 4,
                "redelm-column/src/main/java/redelm/io/MessageColumnIO.java": 17,
                "redelm-column/src/main/java/redelm/io/PrimitiveColumnIO.java": 9,
                "redelm-column/src/main/java/redelm/io/RecordConsumer.java": 2,
                "redelm-column/src/main/java/redelm/io/RecordConsumerLoggingWrapper.java": 4,
                "redelm-column/src/main/java/redelm/io/RecordMaterializer.java": 2,
                "redelm-column/src/main/java/redelm/io/RecordReader.java": 2,
                "redelm-column/src/main/java/redelm/io/RecordReaderCompiler.java": 11,
                "redelm-column/src/main/java/redelm/io/RecordReaderImplementation.java": 15,
                "redelm-column/src/main/java/redelm/io/ValidatingRecordConsumer.java": 13,
                "redelm-column/src/main/java/redelm/io/convert/GroupConverter.java": 2,
                "redelm-column/src/main/java/redelm/io/convert/PrimitiveConverter.java": 2,
                "redelm-column/src/main/java/redelm/parser/MessageTypeParser.java": 17,
                "redelm-column/src/main/java/redelm/schema/GroupType.java": 2,
                "redelm-column/src/main/java/redelm/schema/MessageType.java": 7,
                "redelm-column/src/main/java/redelm/schema/PrimitiveType.java": 7,
                "redelm-column/src/main/java/redelm/schema/Type.java": 2,
                "redelm-column/src/main/java/redelm/schema/TypeVisitor.java": 2,
                "redelm-column/src/main/java/redelm/utils/Varint.java": 2,
                "redelm-column/src/test/java/redelm/bytes/TestBytesUtil.java": 4,
                "redelm-column/src/test/java/redelm/column/mem/TestMemColumn.java": 18,
                "redelm-column/src/test/java/redelm/column/mem/TestMemPageStore.java": 13,
                "redelm-column/src/test/java/redelm/column/primitive/TestBitPacking.java": 8,
                "redelm-column/src/test/java/redelm/column/primitive/TestBitPackingColumn.java": 5,
                "redelm-column/src/test/java/redelm/column/primitive/TestBoundedColumns.java": 5,
                "redelm-column/src/test/java/redelm/io/ExpectationValidatingRecordConsumer.java": 4,
                "redelm-column/src/test/java/redelm/io/PerfTest.java": 31,
                "redelm-column/src/test/java/redelm/io/TestColumnIO.java": 52,
                "redelm-column/src/test/java/redelm/io/TestRecordReaderCompiler.java": 20,
                "redelm-column/src/test/java/redelm/parser/TestRedelmParser.java": 20,
                "redelm-column/src/test/java/redelm/schema/TestMessageType.java": 8,
                "redelm-pig/src/main/java/parquet/format/converter/ParquetMetadataConverter.java": 20,
                "redelm-pig/src/main/java/parquet/hadoop/CodecFactory.java": 2,
                "redelm-pig/src/main/java/parquet/hadoop/ColumnChunkPageReadStore.java": 10,
                "redelm-pig/src/main/java/parquet/hadoop/ColumnChunkPageWriteStore.java": 12,
                "redelm-pig/src/main/java/parquet/hadoop/PageConsumer.java": 2,
                "redelm-pig/src/main/java/parquet/hadoop/PrintFooter.java": 4,
                "redelm-pig/src/main/java/parquet/hadoop/ReadSupport.java": 3,
                "redelm-pig/src/main/java/parquet/hadoop/RedelmFileReader.java": 14,
                "redelm-pig/src/main/java/parquet/hadoop/RedelmFileWriter.java": 14,
                "redelm-pig/src/main/java/parquet/hadoop/RedelmInputFormat.java": 6,
                "redelm-pig/src/main/java/parquet/hadoop/RedelmOutputCommitter.java": 3,
                "redelm-pig/src/main/java/parquet/hadoop/RedelmOutputFormat.java": 6,
                "redelm-pig/src/main/java/parquet/hadoop/RedelmRecordReader.java": 30,
                "redelm-pig/src/main/java/parquet/hadoop/RedelmRecordWriter.java": 10,
                "redelm-pig/src/main/java/parquet/hadoop/WriteSupport.java": 5,
                "redelm-pig/src/main/java/parquet/hadoop/metadata/ColumnChunkMetaData.java": 3,
                "redelm-pig/src/main/java/parquet/hadoop/metadata/FileMetaData.java": 3,
                "redelm-pig/src/main/java/parquet/pig/PigSchemaConverter.java": 17,
                "redelm-pig/src/main/java/parquet/pig/RedelmLoader.java": 2,
                "redelm-pig/src/main/java/parquet/pig/RedelmStorer.java": 2,
                "redelm-pig/src/main/java/parquet/pig/TupleConversionException.java": 2,
                "redelm-pig/src/main/java/parquet/pig/TupleReadSupport.java": 8,
                "redelm-pig/src/main/java/parquet/pig/TupleRecordConsumer.java": 13,
                "redelm-pig/src/main/java/parquet/pig/TupleWriteSupport.java": 8,
                "redelm-pig/src/main/java/parquet/pig/convert/MapConverter.java": 9,
                "redelm-pig/src/main/java/parquet/pig/convert/TupleConverter.java": 10,
                "redelm-pig/src/main/java/parquet/pig/converter/BagConverter.java": 2,
                "redelm-pig/src/main/java/parquet/pig/converter/MapConverter.java": 2,
                "redelm-pig/src/main/java/parquet/pig/converter/MapKeyValueConverter.java": 3,
                "redelm-pig/src/main/java/parquet/pig/converter/MessageConverter.java": 5,
                "redelm-pig/src/main/java/parquet/pig/converter/TupleConverter.java": 4,
                "redelm-pig/src/test/java/parquet/format/converter/TestParquetMetadataConverter.java": 4,
                "redelm-pig/src/test/java/parquet/hadoop/TestInputFormat.java": 6,
                "redelm-pig/src/test/java/parquet/hadoop/TestRedelmFileWriter.java": 16,
                "redelm-pig/src/test/java/parquet/pig/GenerateIntTestFile.java": 30,
                "redelm-pig/src/test/java/parquet/pig/GenerateTPCH.java": 21,
                "redelm-pig/src/test/java/parquet/pig/PerfTest2.java": 2,
                "redelm-pig/src/test/java/parquet/pig/TestPigSchemaConverter.java": 4,
                "redelm-pig/src/test/java/parquet/pig/TestTupleRecordConsumer.java": 16,
                "redelm-pig/src/test/java/parquet/pig/TupleConsumerPerfTest.java": 24
            },
            "is_test": true,
            "is_fix": false
        },
        "24c85c7746f26aceb17ffdf7394e620a079523e3": {
            "datetime": "2013-02-20T12:33:45-08:00",
            "summary": "renaming maven artifacts",
            "message": "renaming maven artifacts\n",
            "diff": {
                "redelm-column/src/main/java/parquet/Log.java": 0,
                "redelm-column/src/main/java/parquet/RedelmRuntimeException.java": 0,
                "redelm-column/src/main/java/parquet/bytes/BytesInput.java": 0,
                "redelm-column/src/main/java/parquet/bytes/BytesUtils.java": 0,
                "redelm-column/src/main/java/parquet/bytes/CapacityByteArrayOutputStream.java": 0,
                "redelm-column/src/main/java/parquet/bytes/LittleEndianDataInputStream.java": 0,
                "redelm-column/src/main/java/parquet/bytes/LittleEndianDataOutputStream.java": 0,
                "redelm-column/src/main/java/parquet/column/ColumnDescriptor.java": 0,
                "redelm-column/src/main/java/parquet/column/ColumnReadStore.java": 0,
                "redelm-column/src/main/java/parquet/column/ColumnReader.java": 0,
                "redelm-column/src/main/java/parquet/column/ColumnWriteStore.java": 0,
                "redelm-column/src/main/java/parquet/column/ColumnWriter.java": 0,
                "redelm-column/src/main/java/parquet/column/UnknownColumnException.java": 0,
                "redelm-column/src/main/java/parquet/column/mem/MemColumnReadStore.java": 0,
                "redelm-column/src/main/java/parquet/column/mem/MemColumnReader.java": 0,
                "redelm-column/src/main/java/parquet/column/mem/MemColumnWriteStore.java": 0,
                "redelm-column/src/main/java/parquet/column/mem/MemColumnWriter.java": 0,
                "redelm-column/src/main/java/parquet/column/mem/MemPageReader.java": 0,
                "redelm-column/src/main/java/parquet/column/mem/MemPageStore.java": 0,
                "redelm-column/src/main/java/parquet/column/mem/MemPageWriter.java": 0,
                "redelm-column/src/main/java/parquet/column/mem/Page.java": 0,
                "redelm-column/src/main/java/parquet/column/mem/PageReadStore.java": 0,
                "redelm-column/src/main/java/parquet/column/mem/PageReader.java": 0,
                "redelm-column/src/main/java/parquet/column/mem/PageWriteStore.java": 0,
                "redelm-column/src/main/java/parquet/column/mem/PageWriter.java": 0,
                "redelm-column/src/main/java/parquet/column/primitive/BitPacking.java": 0,
                "redelm-column/src/main/java/parquet/column/primitive/BitPackingColumnReader.java": 0,
                "redelm-column/src/main/java/parquet/column/primitive/BitPackingColumnWriter.java": 0,
                "redelm-column/src/main/java/parquet/column/primitive/BitReader.java": 0,
                "redelm-column/src/main/java/parquet/column/primitive/BitWriter.java": 0,
                "redelm-column/src/main/java/parquet/column/primitive/BooleanPlainColumnReader.java": 0,
                "redelm-column/src/main/java/parquet/column/primitive/BooleanPlainColumnWriter.java": 0,
                "redelm-column/src/main/java/parquet/column/primitive/BoundedColumnFactory.java": 0,
                "redelm-column/src/main/java/parquet/column/primitive/BoundedIntColumnReader.java": 0,
                "redelm-column/src/main/java/parquet/column/primitive/BoundedIntColumnWriter.java": 0,
                "redelm-column/src/main/java/parquet/column/primitive/DevNullColumnReader.java": 0,
                "redelm-column/src/main/java/parquet/column/primitive/DevNullColumnWriter.java": 0,
                "redelm-column/src/main/java/parquet/column/primitive/PlainColumnReader.java": 0,
                "redelm-column/src/main/java/parquet/column/primitive/PlainColumnWriter.java": 0,
                "redelm-column/src/main/java/parquet/column/primitive/PrimitiveColumnReader.java": 0,
                "redelm-column/src/main/java/parquet/column/primitive/PrimitiveColumnWriter.java": 0,
                "redelm-column/src/main/java/parquet/data/Group.java": 0,
                "redelm-column/src/main/java/parquet/data/GroupFactory.java": 0,
                "redelm-column/src/main/java/parquet/data/GroupRecordConsumer.java": 0,
                "redelm-column/src/main/java/parquet/data/GroupValueSource.java": 0,
                "redelm-column/src/main/java/parquet/data/GroupWriter.java": 0,
                "redelm-column/src/main/java/parquet/data/simple/BinaryValue.java": 0,
                "redelm-column/src/main/java/parquet/data/simple/BooleanValue.java": 0,
                "redelm-column/src/main/java/parquet/data/simple/DoubleValue.java": 0,
                "redelm-column/src/main/java/parquet/data/simple/FloatValue.java": 0,
                "redelm-column/src/main/java/parquet/data/simple/IntegerValue.java": 0,
                "redelm-column/src/main/java/parquet/data/simple/LongValue.java": 0,
                "redelm-column/src/main/java/parquet/data/simple/Primitive.java": 0,
                "redelm-column/src/main/java/parquet/data/simple/SimpleGroup.java": 0,
                "redelm-column/src/main/java/parquet/data/simple/SimpleGroupFactory.java": 0,
                "redelm-column/src/main/java/parquet/data/simple/example/Paper.java": 0,
                "redelm-column/src/main/java/parquet/io/BaseRecordReader.java": 0,
                "redelm-column/src/main/java/parquet/io/ColumnIO.java": 0,
                "redelm-column/src/main/java/parquet/io/ColumnIOFactory.java": 0,
                "redelm-column/src/main/java/parquet/io/GroupColumnIO.java": 0,
                "redelm-column/src/main/java/parquet/io/InvalidRecordException.java": 0,
                "redelm-column/src/main/java/parquet/io/MessageColumnIO.java": 0,
                "redelm-column/src/main/java/parquet/io/PrimitiveColumnIO.java": 0,
                "redelm-column/src/main/java/parquet/io/RecordConsumer.java": 0,
                "redelm-column/src/main/java/parquet/io/RecordConsumerLoggingWrapper.java": 0,
                "redelm-column/src/main/java/parquet/io/RecordMaterializer.java": 0,
                "redelm-column/src/main/java/parquet/io/RecordReader.java": 0,
                "redelm-column/src/main/java/parquet/io/RecordReaderCompiler.java": 0,
                "redelm-column/src/main/java/parquet/io/RecordReaderImplementation.java": 0,
                "redelm-column/src/main/java/parquet/io/ValidatingRecordConsumer.java": 0,
                "redelm-column/src/main/java/parquet/io/convert/GroupConverter.java": 0,
                "redelm-column/src/main/java/parquet/io/convert/PrimitiveConverter.java": 0,
                "redelm-column/src/main/java/parquet/parser/MessageTypeParser.java": 0,
                "redelm-column/src/main/java/parquet/schema/GroupType.java": 0,
                "redelm-column/src/main/java/parquet/schema/MessageType.java": 0,
                "redelm-column/src/main/java/parquet/schema/PrimitiveType.java": 0,
                "redelm-column/src/main/java/parquet/schema/Type.java": 0,
                "redelm-column/src/main/java/parquet/schema/TypeVisitor.java": 0,
                "redelm-column/src/main/java/parquet/utils/Varint.java": 0,
                "redelm-column/src/test/java/parquet/bytes/TestBytesUtil.java": 0,
                "redelm-column/src/test/java/parquet/column/mem/TestMemColumn.java": 0,
                "redelm-column/src/test/java/parquet/column/mem/TestMemPageStore.java": 0,
                "redelm-column/src/test/java/parquet/column/primitive/TestBitPacking.java": 0,
                "redelm-column/src/test/java/parquet/column/primitive/TestBitPackingColumn.java": 0,
                "redelm-column/src/test/java/parquet/column/primitive/TestBoundedColumns.java": 0,
                "redelm-column/src/test/java/parquet/io/ExpectationValidatingRecordConsumer.java": 0,
                "redelm-column/src/test/java/parquet/io/PerfTest.java": 0,
                "redelm-column/src/test/java/parquet/io/TestColumnIO.java": 0,
                "redelm-column/src/test/java/parquet/io/TestRecordReaderCompiler.java": 0,
                "redelm-column/src/test/java/parquet/parser/TestRedelmParser.java": 0,
                "redelm-column/src/test/java/parquet/schema/TestMessageType.java": 0,
                "redelm-pig/src/main/java/parquet/format/converter/ParquetMetadataConverter.java": 0,
                "redelm-pig/src/main/java/parquet/hadoop/BlockData.java": 0,
                "redelm-pig/src/main/java/parquet/hadoop/CodecFactory.java": 0,
                "redelm-pig/src/main/java/parquet/hadoop/ColumnChunkPageReadStore.java": 0,
                "redelm-pig/src/main/java/parquet/hadoop/ColumnChunkPageWriteStore.java": 0,
                "redelm-pig/src/main/java/parquet/hadoop/ColumnData.java": 0,
                "redelm-pig/src/main/java/parquet/hadoop/Footer.java": 0,
                "redelm-pig/src/main/java/parquet/hadoop/PageConsumer.java": 0,
                "redelm-pig/src/main/java/parquet/hadoop/PrintFooter.java": 0,
                "redelm-pig/src/main/java/parquet/hadoop/ReadSupport.java": 0,
                "redelm-pig/src/main/java/parquet/hadoop/RedelmFileReader.java": 0,
                "redelm-pig/src/main/java/parquet/hadoop/RedelmFileWriter.java": 0,
                "redelm-pig/src/main/java/parquet/hadoop/RedelmInputFormat.java": 0,
                "redelm-pig/src/main/java/parquet/hadoop/RedelmInputSplit.java": 0,
                "redelm-pig/src/main/java/parquet/hadoop/RedelmOutputCommitter.java": 0,
                "redelm-pig/src/main/java/parquet/hadoop/RedelmOutputFormat.java": 0,
                "redelm-pig/src/main/java/parquet/hadoop/RedelmRecordReader.java": 0,
                "redelm-pig/src/main/java/parquet/hadoop/RedelmRecordWriter.java": 0,
                "redelm-pig/src/main/java/parquet/hadoop/WriteSupport.java": 0,
                "redelm-pig/src/main/java/parquet/hadoop/metadata/BlockMetaData.java": 0,
                "redelm-pig/src/main/java/parquet/hadoop/metadata/ColumnChunkMetaData.java": 0,
                "redelm-pig/src/main/java/parquet/hadoop/metadata/ColumnMetaData.java": 0,
                "redelm-pig/src/main/java/parquet/hadoop/metadata/CompressionCodecName.java": 0,
                "redelm-pig/src/main/java/parquet/hadoop/metadata/FileMetaData.java": 0,
                "redelm-pig/src/main/java/parquet/hadoop/metadata/RedelmMetaData.java": 0,
                "redelm-pig/src/main/java/parquet/pig/PigMetaData.java": 0,
                "redelm-pig/src/main/java/parquet/pig/PigSchemaConverter.java": 0,
                "redelm-pig/src/main/java/parquet/pig/RedelmLoader.java": 0,
                "redelm-pig/src/main/java/parquet/pig/RedelmStorer.java": 0,
                "redelm-pig/src/main/java/parquet/pig/TupleConversionException.java": 0,
                "redelm-pig/src/main/java/parquet/pig/TupleReadSupport.java": 0,
                "redelm-pig/src/main/java/parquet/pig/TupleRecordConsumer.java": 0,
                "redelm-pig/src/main/java/parquet/pig/TupleWriteSupport.java": 0,
                "redelm-pig/src/main/java/parquet/pig/convert/MapConverter.java": 0,
                "redelm-pig/src/main/java/parquet/pig/convert/TupleConverter.java": 0,
                "redelm-pig/src/main/java/parquet/pig/converter/BagConverter.java": 0,
                "redelm-pig/src/main/java/parquet/pig/converter/Converter.java": 0,
                "redelm-pig/src/main/java/parquet/pig/converter/MapConverter.java": 0,
                "redelm-pig/src/main/java/parquet/pig/converter/MapKeyValueConverter.java": 0,
                "redelm-pig/src/main/java/parquet/pig/converter/MessageConverter.java": 0,
                "redelm-pig/src/main/java/parquet/pig/converter/TupleConverter.java": 0,
                "redelm-pig/src/main/java/parquet/pig/summary/BagSummaryData.java": 0,
                "redelm-pig/src/main/java/parquet/pig/summary/EnumStat.java": 0,
                "redelm-pig/src/main/java/parquet/pig/summary/FieldSummaryData.java": 0,
                "redelm-pig/src/main/java/parquet/pig/summary/MapSummaryData.java": 0,
                "redelm-pig/src/main/java/parquet/pig/summary/NumberSummaryData.java": 0,
                "redelm-pig/src/main/java/parquet/pig/summary/StringSummaryData.java": 0,
                "redelm-pig/src/main/java/parquet/pig/summary/Summary.java": 0,
                "redelm-pig/src/main/java/parquet/pig/summary/SummaryData.java": 0,
                "redelm-pig/src/main/java/parquet/pig/summary/TupleSummaryData.java": 0,
                "redelm-pig/src/main/java/parquet/pig/summary/ValueStat.java": 0,
                "redelm-pig/src/test/java/parquet/format/converter/TestParquetMetadataConverter.java": 0,
                "redelm-pig/src/test/java/parquet/hadoop/TestInputFormat.java": 0,
                "redelm-pig/src/test/java/parquet/hadoop/TestRedelmFileWriter.java": 0,
                "redelm-pig/src/test/java/parquet/pig/GenerateIntTestFile.java": 0,
                "redelm-pig/src/test/java/parquet/pig/GenerateTPCH.java": 0,
                "redelm-pig/src/test/java/parquet/pig/PerfTest.java": 0,
                "redelm-pig/src/test/java/parquet/pig/PerfTest2.java": 0,
                "redelm-pig/src/test/java/parquet/pig/PerfTestReadAllCols.java": 0,
                "redelm-pig/src/test/java/parquet/pig/TestPigSchemaConverter.java": 0,
                "redelm-pig/src/test/java/parquet/pig/TestRedelmStorer.java": 0,
                "redelm-pig/src/test/java/parquet/pig/TestTupleRecordConsumer.java": 0,
                "redelm-pig/src/test/java/parquet/pig/TupleConsumerPerfTest.java": 0,
                "redelm-pig/src/test/java/parquet/pig/summary/TestSummary.java": 0
            },
            "is_test": true,
            "is_fix": false
        },
        "ac3a80616248e6facf9c756ac8d831bcf5e978a1": {
            "datetime": "2013-02-20T14:22:16-08:00",
            "summary": "renamed to parquet",
            "message": "renamed to parquet\n",
            "diff": {
                "parquet-column/src/main/java/parquet/RedelmRuntimeException.java": 10,
                "parquet-column/src/main/java/parquet/column/UnknownColumnException.java": 4,
                "parquet-column/src/main/java/parquet/io/InvalidRecordException.java": 4,
                "parquet-column/src/main/java/parquet/io/RecordReaderCompiler.java": 2,
                "parquet-column/src/test/java/parquet/parser/TestRedelmParser.java": 2,
                "parquet-pig/src/main/java/parquet/format/converter/ParquetMetadataConverter.java": 18,
                "parquet-pig/src/main/java/parquet/hadoop/ColumnChunkPageWriteStore.java": 4,
                "parquet-pig/src/main/java/parquet/hadoop/Footer.java": 12,
                "parquet-pig/src/main/java/parquet/hadoop/PrintFooter.java": 26,
                "parquet-pig/src/main/java/parquet/hadoop/ReadSupport.java": 4,
                "parquet-pig/src/main/java/parquet/hadoop/RedelmFileReader.java": 48,
                "parquet-pig/src/main/java/parquet/hadoop/RedelmFileWriter.java": 20,
                "parquet-pig/src/main/java/parquet/hadoop/RedelmInputFormat.java": 31,
                "parquet-pig/src/main/java/parquet/hadoop/RedelmInputSplit.java": 15,
                "parquet-pig/src/main/java/parquet/hadoop/RedelmOutputCommitter.java": 10,
                "parquet-pig/src/main/java/parquet/hadoop/RedelmOutputFormat.java": 38,
                "parquet-pig/src/main/java/parquet/hadoop/RedelmRecordReader.java": 31,
                "parquet-pig/src/main/java/parquet/hadoop/RedelmRecordWriter.java": 12,
                "parquet-pig/src/main/java/parquet/hadoop/WriteSupport.java": 2,
                "parquet-pig/src/main/java/parquet/hadoop/metadata/RedelmMetaData.java": 26,
                "parquet-pig/src/main/java/parquet/pig/PigSchemaConverter.java": 6,
                "parquet-pig/src/main/java/parquet/pig/RedelmLoader.java": 29,
                "parquet-pig/src/main/java/parquet/pig/RedelmStorer.java": 16,
                "parquet-pig/src/main/java/parquet/pig/TupleConversionException.java": 4,
                "parquet-pig/src/main/java/parquet/pig/TupleReadSupport.java": 10,
                "parquet-pig/src/main/java/parquet/pig/convert/MapConverter.java": 20,
                "parquet-pig/src/main/java/parquet/pig/convert/TupleConverter.java": 24,
                "parquet-pig/src/main/java/parquet/pig/converter/BagConverter.java": 7,
                "parquet-pig/src/main/java/parquet/pig/converter/MapConverter.java": 4,
                "parquet-pig/src/main/java/parquet/pig/converter/MapKeyValueConverter.java": 10,
                "parquet-pig/src/main/java/parquet/pig/converter/MessageConverter.java": 4,
                "parquet-pig/src/main/java/parquet/pig/converter/TupleConverter.java": 10,
                "parquet-pig/src/test/java/parquet/hadoop/TestInputFormat.java": 16,
                "parquet-pig/src/test/java/parquet/hadoop/TestReadIntTestFile.java": 59,
                "parquet-pig/src/test/java/parquet/hadoop/TestRedelmFileWriter.java": 20,
                "parquet-pig/src/test/java/parquet/pig/GenerateIntTestFile.java": 22,
                "parquet-pig/src/test/java/parquet/pig/PerfTest.java": 8,
                "parquet-pig/src/test/java/parquet/pig/PerfTest2.java": 8,
                "parquet-pig/src/test/java/parquet/pig/TestPigSchemaConverter.java": 8,
                "parquet-pig/src/test/java/parquet/pig/TestRedelmStorer.java": 28,
                "parquet-pig/src/test/java/parquet/pig/TestTupleRecordConsumer.java": 14
            },
            "is_test": true,
            "is_fix": false
        },
        "bd1fde90f05a3aec05f7cad24d90633ea680d9f9": {
            "datetime": "2013-02-20T14:42:54-08:00",
            "summary": "cleanup",
            "message": "cleanup\n",
            "diff": {
                "parquet-column/src/main/java/parquet/column/ColumnDescriptor.java": 1,
                "parquet-column/src/main/java/parquet/column/mem/MemColumnReader.java": 6,
                "parquet-column/src/main/java/parquet/column/mem/MemColumnWriter.java": 4,
                "parquet-column/src/main/java/parquet/column/mem/ParquetDecodingException.java": 23,
                "parquet-column/src/main/java/parquet/column/mem/ParquetEncodingException.java": 23,
                "parquet-column/src/main/java/parquet/column/primitive/BooleanPlainColumnWriter.java": 1,
                "parquet-column/src/main/java/parquet/column/primitive/PlainColumnReader.java": 2,
                "parquet-column/src/main/java/parquet/io/MessageColumnIO.java": 4,
                "parquet-column/src/test/java/parquet/column/primitive/TestBitPackingColumn.java": 4,
                "parquet-column/src/test/java/parquet/io/ExpectationValidatingRecordConsumer.java": 3,
                "parquet-column/src/test/java/parquet/io/PerfTest.java": 7,
                "parquet-column/src/test/java/parquet/io/TestColumnIO.java": 16,
                "parquet-pig/src/main/java/parquet/hadoop/metadata/FileMetaData.java": 5,
                "parquet-pig/src/main/java/parquet/hadoop/metadata/ParquetMetadata.java": 1,
                "parquet-pig/src/main/java/parquet/pig/ParquetStorer.java": 2,
                "parquet-pig/src/main/java/parquet/pig/PigSchemaConverter.java": 4,
                "parquet-pig/src/test/java/parquet/hadoop/TestParquetFileWriter.java": 10,
                "parquet-pig/src/test/java/parquet/hadoop/TestReadIntTestFile.java": 3,
                "parquet-pig/src/test/java/parquet/pig/TestTupleRecordConsumer.java": 5
            },
            "is_test": true,
            "is_fix": false
        },
        "51649183bf4c40f40b46bbcf04adb379094d7fda": {
            "datetime": "2013-02-20T16:11:05-08:00",
            "summary": "Merge pull request #26 from julienledem/rename_to_parquet",
            "message": "Merge pull request #26 from julienledem/rename_to_parquet\n\nRename to parquet",
            "diff": {
                "parquet-column/src/main/java/parquet/column/mem/ParquetDecodingException.java": 23,
                "parquet-column/src/main/java/parquet/column/mem/ParquetEncodingException.java": 23,
                "parquet-pig/src/test/java/parquet/hadoop/TestReadIntTestFile.java": 56,
                "redelm-column/src/main/java/redelm/Log.java": 2,
                "redelm-column/src/main/java/redelm/RedelmRuntimeException.java": 12,
                "redelm-column/src/main/java/redelm/bytes/BytesInput.java": 5,
                "redelm-column/src/main/java/redelm/bytes/BytesUtils.java": 5,
                "redelm-column/src/main/java/redelm/bytes/CapacityByteArrayOutputStream.java": 2,
                "redelm-column/src/main/java/redelm/bytes/LittleEndianDataInputStream.java": 2,
                "redelm-column/src/main/java/redelm/bytes/LittleEndianDataOutputStream.java": 2,
                "redelm-column/src/main/java/redelm/column/ColumnDescriptor.java": 6,
                "redelm-column/src/main/java/redelm/column/ColumnReadStore.java": 2,
                "redelm-column/src/main/java/redelm/column/ColumnReader.java": 2,
                "redelm-column/src/main/java/redelm/column/ColumnWriteStore.java": 2,
                "redelm-column/src/main/java/redelm/column/ColumnWriter.java": 2,
                "redelm-column/src/main/java/redelm/column/UnknownColumnException.java": 6,
                "redelm-column/src/main/java/redelm/column/mem/MemColumnReadStore.java": 9,
                "redelm-column/src/main/java/redelm/column/mem/MemColumnReader.java": 27,
                "redelm-column/src/main/java/redelm/column/mem/MemColumnWriteStore.java": 9,
                "redelm-column/src/main/java/redelm/column/mem/MemColumnWriter.java": 25,
                "redelm-column/src/main/java/redelm/column/mem/MemPageReader.java": 7,
                "redelm-column/src/main/java/redelm/column/mem/MemPageStore.java": 9,
                "redelm-column/src/main/java/redelm/column/mem/MemPageWriter.java": 9,
                "redelm-column/src/main/java/redelm/column/mem/Page.java": 6,
                "redelm-column/src/main/java/redelm/column/mem/PageReadStore.java": 4,
                "redelm-column/src/main/java/redelm/column/mem/PageReader.java": 2,
                "redelm-column/src/main/java/redelm/column/mem/PageWriteStore.java": 4,
                "redelm-column/src/main/java/redelm/column/mem/PageWriter.java": 5,
                "redelm-column/src/main/java/redelm/column/primitive/BitPacking.java": 7,
                "redelm-column/src/main/java/redelm/column/primitive/BitPackingColumnReader.java": 9,
                "redelm-column/src/main/java/redelm/column/primitive/BitPackingColumnWriter.java": 13,
                "redelm-column/src/main/java/redelm/column/primitive/BitReader.java": 2,
                "redelm-column/src/main/java/redelm/column/primitive/BitWriter.java": 6,
                "redelm-column/src/main/java/redelm/column/primitive/BooleanPlainColumnReader.java": 13,
                "redelm-column/src/main/java/redelm/column/primitive/BooleanPlainColumnWriter.java": 14,
                "redelm-column/src/main/java/redelm/column/primitive/BoundedColumnFactory.java": 2,
                "redelm-column/src/main/java/redelm/column/primitive/BoundedIntColumnReader.java": 9,
                "redelm-column/src/main/java/redelm/column/primitive/BoundedIntColumnWriter.java": 6,
                "redelm-column/src/main/java/redelm/column/primitive/DevNullColumnReader.java": 2,
                "redelm-column/src/main/java/redelm/column/primitive/DevNullColumnWriter.java": 4,
                "redelm-column/src/main/java/redelm/column/primitive/PlainColumnReader.java": 13,
                "redelm-column/src/main/java/redelm/column/primitive/PlainColumnWriter.java": 11,
                "redelm-column/src/main/java/redelm/column/primitive/PrimitiveColumnReader.java": 2,
                "redelm-column/src/main/java/redelm/column/primitive/PrimitiveColumnWriter.java": 4,
                "redelm-column/src/main/java/redelm/data/Group.java": 6,
                "redelm-column/src/main/java/redelm/data/GroupFactory.java": 2,
                "redelm-column/src/main/java/redelm/data/GroupRecordConsumer.java": 7,
                "redelm-column/src/main/java/redelm/data/GroupValueSource.java": 4,
                "redelm-column/src/main/java/redelm/data/GroupWriter.java": 8,
                "redelm-column/src/main/java/redelm/data/simple/BinaryValue.java": 4,
                "redelm-column/src/main/java/redelm/data/simple/BooleanValue.java": 4,
                "redelm-column/src/main/java/redelm/data/simple/DoubleValue.java": 4,
                "redelm-column/src/main/java/redelm/data/simple/FloatValue.java": 4,
                "redelm-column/src/main/java/redelm/data/simple/IntegerValue.java": 4,
                "redelm-column/src/main/java/redelm/data/simple/LongValue.java": 4,
                "redelm-column/src/main/java/redelm/data/simple/Primitive.java": 4,
                "redelm-column/src/main/java/redelm/data/simple/SimpleGroup.java": 11,
                "redelm-column/src/main/java/redelm/data/simple/SimpleGroupFactory.java": 8,
                "redelm-column/src/main/java/redelm/data/simple/example/Paper.java": 22,
                "redelm-column/src/main/java/redelm/io/BaseRecordReader.java": 10,
                "redelm-column/src/main/java/redelm/io/ColumnIO.java": 9,
                "redelm-column/src/main/java/redelm/io/ColumnIOFactory.java": 15,
                "redelm-column/src/main/java/redelm/io/GroupColumnIO.java": 11,
                "redelm-column/src/main/java/redelm/io/InvalidRecordException.java": 6,
                "redelm-column/src/main/java/redelm/io/MessageColumnIO.java": 17,
                "redelm-column/src/main/java/redelm/io/PrimitiveColumnIO.java": 9,
                "redelm-column/src/main/java/redelm/io/RecordConsumer.java": 2,
                "redelm-column/src/main/java/redelm/io/RecordConsumerLoggingWrapper.java": 4,
                "redelm-column/src/main/java/redelm/io/RecordMaterializer.java": 2,
                "redelm-column/src/main/java/redelm/io/RecordReader.java": 2,
                "redelm-column/src/main/java/redelm/io/RecordReaderCompiler.java": 13,
                "redelm-column/src/main/java/redelm/io/RecordReaderImplementation.java": 15,
                "redelm-column/src/main/java/redelm/io/ValidatingRecordConsumer.java": 13,
                "redelm-column/src/main/java/redelm/io/convert/GroupConverter.java": 2,
                "redelm-column/src/main/java/redelm/io/convert/PrimitiveConverter.java": 2,
                "redelm-column/src/main/java/redelm/parser/MessageTypeParser.java": 17,
                "redelm-column/src/main/java/redelm/schema/GroupType.java": 2,
                "redelm-column/src/main/java/redelm/schema/MessageType.java": 7,
                "redelm-column/src/main/java/redelm/schema/PrimitiveType.java": 7,
                "redelm-column/src/main/java/redelm/schema/Type.java": 2,
                "redelm-column/src/main/java/redelm/schema/TypeVisitor.java": 2,
                "redelm-column/src/main/java/redelm/utils/Varint.java": 2,
                "redelm-column/src/test/java/redelm/bytes/TestBytesUtil.java": 4,
                "redelm-column/src/test/java/redelm/column/mem/TestMemColumn.java": 18,
                "redelm-column/src/test/java/redelm/column/mem/TestMemPageStore.java": 13,
                "redelm-column/src/test/java/redelm/column/primitive/TestBitPacking.java": 8,
                "redelm-column/src/test/java/redelm/column/primitive/TestBitPackingColumn.java": 3,
                "redelm-column/src/test/java/redelm/column/primitive/TestBoundedColumns.java": 5,
                "redelm-column/src/test/java/redelm/io/ExpectationValidatingRecordConsumer.java": 3,
                "redelm-column/src/test/java/redelm/io/PerfTest.java": 24,
                "redelm-column/src/test/java/redelm/io/TestColumnIO.java": 48,
                "redelm-column/src/test/java/redelm/io/TestRecordReaderCompiler.java": 20,
                "redelm-column/src/test/java/redelm/parser/TestRedelmParser.java": 22,
                "redelm-column/src/test/java/redelm/schema/TestMessageType.java": 8,
                "redelm-pig/src/main/java/redelm/format/converter/ParquetMetadataConverter.java": 48,
                "redelm-pig/src/main/java/redelm/hadoop/BlockData.java": 2,
                "redelm-pig/src/main/java/redelm/hadoop/CodecFactory.java": 7,
                "redelm-pig/src/main/java/redelm/hadoop/ColumnChunkPageReadStore.java": 15,
                "redelm-pig/src/main/java/redelm/hadoop/ColumnChunkPageWriteStore.java": 22,
                "redelm-pig/src/main/java/redelm/hadoop/ColumnData.java": 2,
                "redelm-pig/src/main/java/redelm/hadoop/Footer.java": 15,
                "redelm-pig/src/main/java/redelm/hadoop/PageConsumer.java": 4,
                "redelm-pig/src/main/java/redelm/hadoop/PrintFooter.java": 37,
                "redelm-pig/src/main/java/redelm/hadoop/ReadSupport.java": 9,
                "redelm-pig/src/main/java/redelm/hadoop/RedelmFileReader.java": 74,
                "redelm-pig/src/main/java/redelm/hadoop/RedelmFileWriter.java": 46,
                "redelm-pig/src/main/java/redelm/hadoop/RedelmInputFormat.java": 44,
                "redelm-pig/src/main/java/redelm/hadoop/RedelmInputSplit.java": 20,
                "redelm-pig/src/main/java/redelm/hadoop/RedelmOutputCommitter.java": 15,
                "redelm-pig/src/main/java/redelm/hadoop/RedelmOutputFormat.java": 49,
                "redelm-pig/src/main/java/redelm/hadoop/RedelmRecordReader.java": 58,
                "redelm-pig/src/main/java/redelm/hadoop/RedelmRecordWriter.java": 27,
                "redelm-pig/src/main/java/redelm/hadoop/WriteSupport.java": 9,
                "redelm-pig/src/main/java/redelm/hadoop/metadata/BlockMetaData.java": 2,
                "redelm-pig/src/main/java/redelm/hadoop/metadata/ColumnChunkMetaData.java": 5,
                "redelm-pig/src/main/java/redelm/hadoop/metadata/ColumnMetaData.java": 2,
                "redelm-pig/src/main/java/redelm/hadoop/metadata/CompressionCodecName.java": 2,
                "redelm-pig/src/main/java/redelm/hadoop/metadata/FileMetaData.java": 10,
                "redelm-pig/src/main/java/redelm/hadoop/metadata/RedelmMetaData.java": 29,
                "redelm-pig/src/main/java/redelm/pig/PigMetaData.java": 2,
                "redelm-pig/src/main/java/redelm/pig/PigSchemaConverter.java": 27,
                "redelm-pig/src/main/java/redelm/pig/RedelmLoader.java": 36,
                "redelm-pig/src/main/java/redelm/pig/RedelmStorer.java": 23,
                "redelm-pig/src/main/java/redelm/pig/TupleConversionException.java": 6,
                "redelm-pig/src/main/java/redelm/pig/TupleReadSupport.java": 25,
                "redelm-pig/src/main/java/redelm/pig/TupleRecordConsumer.java": 15,
                "redelm-pig/src/main/java/redelm/pig/TupleWriteSupport.java": 13,
                "redelm-pig/src/main/java/redelm/pig/convert/MapConverter.java": 31,
                "redelm-pig/src/main/java/redelm/pig/convert/TupleConverter.java": 39,
                "redelm-pig/src/main/java/redelm/pig/converter/BagConverter.java": 14,
                "redelm-pig/src/main/java/redelm/pig/converter/Converter.java": 2,
                "redelm-pig/src/main/java/redelm/pig/converter/MapConverter.java": 11,
                "redelm-pig/src/main/java/redelm/pig/converter/MapKeyValueConverter.java": 15,
                "redelm-pig/src/main/java/redelm/pig/converter/MessageConverter.java": 11,
                "redelm-pig/src/main/java/redelm/pig/converter/TupleConverter.java": 19,
                "redelm-pig/src/main/java/redelm/pig/summary/BagSummaryData.java": 2,
                "redelm-pig/src/main/java/redelm/pig/summary/EnumStat.java": 2,
                "redelm-pig/src/main/java/redelm/pig/summary/FieldSummaryData.java": 2,
                "redelm-pig/src/main/java/redelm/pig/summary/MapSummaryData.java": 2,
                "redelm-pig/src/main/java/redelm/pig/summary/NumberSummaryData.java": 2,
                "redelm-pig/src/main/java/redelm/pig/summary/StringSummaryData.java": 5,
                "redelm-pig/src/main/java/redelm/pig/summary/Summary.java": 2,
                "redelm-pig/src/main/java/redelm/pig/summary/SummaryData.java": 2,
                "redelm-pig/src/main/java/redelm/pig/summary/TupleSummaryData.java": 2,
                "redelm-pig/src/main/java/redelm/pig/summary/ValueStat.java": 2,
                "redelm-pig/src/test/java/redelm/format/converter/TestParquetMetadataConverter.java": 8,
                "redelm-pig/src/test/java/redelm/hadoop/TestInputFormat.java": 32,
                "redelm-pig/src/test/java/redelm/hadoop/TestRedelmFileWriter.java": 44,
                "redelm-pig/src/test/java/redelm/pig/GenerateIntTestFile.java": 57,
                "redelm-pig/src/test/java/redelm/pig/GenerateTPCH.java": 27,
                "redelm-pig/src/test/java/redelm/pig/PerfTest.java": 9,
                "redelm-pig/src/test/java/redelm/pig/PerfTest2.java": 11,
                "redelm-pig/src/test/java/redelm/pig/PerfTestReadAllCols.java": 2,
                "redelm-pig/src/test/java/redelm/pig/TestPigSchemaConverter.java": 16,
                "redelm-pig/src/test/java/redelm/pig/TestRedelmStorer.java": 29,
                "redelm-pig/src/test/java/redelm/pig/TestTupleRecordConsumer.java": 34,
                "redelm-pig/src/test/java/redelm/pig/TupleConsumerPerfTest.java": 31,
                "redelm-pig/src/test/java/redelm/pig/summary/TestSummary.java": 7
            },
            "is_test": true,
            "is_fix": false
        },
        "4a0bb74123d353df85e4a29a26e5d439bd1a5993": {
            "datetime": "2013-02-20T16:39:47-08:00",
            "summary": "cleanup exceptions",
            "message": "cleanup exceptions\n",
            "diff": {
                "parquet-column/src/main/java/parquet/column/mem/MemColumnReadStore.java": 2,
                "parquet-column/src/main/java/parquet/column/mem/MemColumnReader.java": 2,
                "parquet-column/src/main/java/parquet/column/mem/MemPageReader.java": 2,
                "parquet-column/src/main/java/parquet/column/mem/MemPageWriter.java": 2,
                "parquet-column/src/main/java/parquet/column/primitive/BitPackingColumnReader.java": 3,
                "parquet-column/src/main/java/parquet/column/primitive/BitPackingColumnWriter.java": 5,
                "parquet-column/src/main/java/parquet/column/primitive/BitReader.java": 4,
                "parquet-column/src/main/java/parquet/column/primitive/BooleanPlainColumnReader.java": 3,
                "parquet-column/src/main/java/parquet/column/primitive/BooleanPlainColumnWriter.java": 5,
                "parquet-column/src/main/java/parquet/column/primitive/BoundedIntColumnReader.java": 5,
                "parquet-column/src/main/java/parquet/column/primitive/BoundedIntColumnWriter.java": 3,
                "parquet-column/src/main/java/parquet/column/primitive/PlainColumnReader.java": 13,
                "parquet-column/src/main/java/parquet/column/primitive/PlainColumnWriter.java": 16,
                "parquet-column/src/main/java/parquet/io/BaseRecordReader.java": 3,
                "parquet-column/src/main/java/parquet/io/ColumnIO.java": 2,
                "parquet-column/src/main/java/parquet/io/CompilationException.java": 23,
                "parquet-column/src/main/java/parquet/io/GroupColumnIO.java": 2,
                "parquet-column/src/main/java/parquet/io/MessageColumnIO.java": 7,
                "parquet-column/src/main/java/parquet/io/RecordReaderCompiler.java": 16,
                "parquet-column/src/main/java/parquet/io/RecordReaderImplementation.java": 3,
                "parquet-column/src/main/java/parquet/schema/GroupType.java": 6,
                "parquet-column/src/main/java/parquet/schema/MessageType.java": 3,
                "parquet-column/src/main/java/parquet/schema/PrimitiveType.java": 11,
                "parquet-column/src/main/java/parquet/schema/Type.java": 4
            },
            "is_test": false,
            "is_fix": false
        },
        "85d8f09fa96ec16d413bd5bc01269fff6ed595f4": {
            "datetime": "2013-02-20T16:51:00-08:00",
            "summary": "removed brennus dependency (for now)",
            "message": "removed brennus dependency (for now)\n",
            "diff": {
                "parquet-column/src/main/java/parquet/io/RecordReaderCompiler.java": 274,
                "parquet-column/src/test/java/parquet/io/PerfTest.java": 18,
                "parquet-column/src/test/java/parquet/io/TestRecordReaderCompiler.java": 79
            },
            "is_test": true,
            "is_fix": false
        },
        "5141722756ae6a9f10924242f5d89cd9afebedad": {
            "datetime": "2013-02-20T17:30:11-08:00",
            "summary": "integrate thrift changes",
            "message": "integrate thrift changes\n",
            "diff": {
                "parquet-pig/src/main/java/parquet/hadoop/ColumnChunkPageWriteStore.java": 2,
                "parquet-pig/src/main/java/parquet/hadoop/ParquetFileReader.java": 4,
                "parquet-pig/src/main/java/parquet/hadoop/ParquetFileWriter.java": 2
            },
            "is_test": false,
            "is_fix": false
        },
        "cfdcdffee41711ba91109378605265200b2d9a25": {
            "datetime": "2013-02-20T17:32:39-08:00",
            "summary": "turn off customer test",
            "message": "turn off customer test\n",
            "diff": {
                "parquet-pig/src/test/java/parquet/hadoop/TestReadIntTestFile.java": 4
            },
            "is_test": true,
            "is_fix": false
        },
        "c5a894a12d326350c7b169b85704d3b183283057": {
            "datetime": "2013-02-20T18:03:22-08:00",
            "summary": "split hadoop; add thrift",
            "message": "split hadoop; add thrift\n",
            "diff": {
                "parquet-pig/src/main/java/parquet/format/converter/ParquetMetadataConverter.java": 0,
                "parquet-pig/src/main/java/parquet/hadoop/BlockData.java": 0,
                "parquet-pig/src/main/java/parquet/hadoop/CodecFactory.java": 0,
                "parquet-pig/src/main/java/parquet/hadoop/ColumnChunkPageReadStore.java": 0,
                "parquet-pig/src/main/java/parquet/hadoop/ColumnChunkPageWriteStore.java": 0,
                "parquet-pig/src/main/java/parquet/hadoop/ColumnData.java": 0,
                "parquet-pig/src/main/java/parquet/hadoop/Footer.java": 0,
                "parquet-pig/src/main/java/parquet/hadoop/PageConsumer.java": 0,
                "parquet-pig/src/main/java/parquet/hadoop/ParquetFileReader.java": 0,
                "parquet-pig/src/main/java/parquet/hadoop/ParquetFileWriter.java": 0,
                "parquet-pig/src/main/java/parquet/hadoop/ParquetInputFormat.java": 0,
                "parquet-pig/src/main/java/parquet/hadoop/ParquetInputSplit.java": 0,
                "parquet-pig/src/main/java/parquet/hadoop/ParquetOutputCommitter.java": 0,
                "parquet-pig/src/main/java/parquet/hadoop/ParquetOutputFormat.java": 0,
                "parquet-pig/src/main/java/parquet/hadoop/ParquetRecordReader.java": 0,
                "parquet-pig/src/main/java/parquet/hadoop/ParquetRecordWriter.java": 0,
                "parquet-pig/src/main/java/parquet/hadoop/PrintFooter.java": 0,
                "parquet-pig/src/main/java/parquet/hadoop/ReadSupport.java": 0,
                "parquet-pig/src/main/java/parquet/hadoop/WriteSupport.java": 0,
                "parquet-pig/src/main/java/parquet/hadoop/metadata/BlockMetaData.java": 0,
                "parquet-pig/src/main/java/parquet/hadoop/metadata/ColumnChunkMetaData.java": 0,
                "parquet-pig/src/main/java/parquet/hadoop/metadata/ColumnMetaData.java": 0,
                "parquet-pig/src/main/java/parquet/hadoop/metadata/CompressionCodecName.java": 0,
                "parquet-pig/src/main/java/parquet/hadoop/metadata/FileMetaData.java": 0,
                "parquet-pig/src/main/java/parquet/hadoop/metadata/ParquetMetadata.java": 0,
                "parquet-pig/src/test/java/parquet/format/converter/TestParquetMetadataConverter.java": 0,
                "parquet-pig/src/test/java/parquet/hadoop/TestInputFormat.java": 0,
                "parquet-pig/src/test/java/parquet/hadoop/TestParquetFileWriter.java": 0,
                "parquet-pig/src/test/java/parquet/hadoop/TestReadIntTestFile.java": 0
            },
            "is_test": true,
            "is_fix": false
        },
        "f6adf0b5e678b5aff29cc3eeef9b3e9b240c0385": {
            "datetime": "2013-02-21T12:18:11-08:00",
            "summary": "integrate new converter; cleanup",
            "message": "integrate new converter; cleanup\n",
            "diff": {
                "parquet-column/src/main/java/parquet/column/mem/MemColumnReadStore.java": 1,
                "parquet-column/src/main/java/parquet/column/mem/MemColumnReader.java": 1,
                "parquet-column/src/main/java/parquet/column/mem/MemColumnWriter.java": 1,
                "parquet-column/src/main/java/parquet/column/mem/MemPageReader.java": 1,
                "parquet-column/src/main/java/parquet/column/mem/MemPageWriter.java": 1,
                "parquet-column/src/main/java/parquet/column/mem/ParquetDecodingException.java": 2,
                "parquet-column/src/main/java/parquet/column/mem/ParquetEncodingException.java": 2,
                "parquet-column/src/main/java/parquet/column/primitive/BitPackingColumnReader.java": 2,
                "parquet-column/src/main/java/parquet/column/primitive/BitPackingColumnWriter.java": 2,
                "parquet-column/src/main/java/parquet/column/primitive/BitReader.java": 2,
                "parquet-column/src/main/java/parquet/column/primitive/BooleanPlainColumnReader.java": 2,
                "parquet-column/src/main/java/parquet/column/primitive/BooleanPlainColumnWriter.java": 2,
                "parquet-column/src/main/java/parquet/column/primitive/BoundedIntColumnReader.java": 2,
                "parquet-column/src/main/java/parquet/column/primitive/BoundedIntColumnWriter.java": 2,
                "parquet-column/src/main/java/parquet/column/primitive/PlainColumnReader.java": 2,
                "parquet-column/src/main/java/parquet/column/primitive/PlainColumnWriter.java": 2,
                "parquet-column/src/main/java/parquet/data/Group.java": 2,
                "parquet-column/src/main/java/parquet/data/GroupFactory.java": 2,
                "parquet-column/src/main/java/parquet/data/GroupRecordConsumer.java": 2,
                "parquet-column/src/main/java/parquet/data/GroupValueSource.java": 2,
                "parquet-column/src/main/java/parquet/data/GroupWriter.java": 2,
                "parquet-column/src/main/java/parquet/data/simple/BinaryValue.java": 2,
                "parquet-column/src/main/java/parquet/data/simple/BooleanValue.java": 2,
                "parquet-column/src/main/java/parquet/data/simple/DoubleValue.java": 2,
                "parquet-column/src/main/java/parquet/data/simple/FloatValue.java": 2,
                "parquet-column/src/main/java/parquet/data/simple/IntegerValue.java": 2,
                "parquet-column/src/main/java/parquet/data/simple/LongValue.java": 2,
                "parquet-column/src/main/java/parquet/data/simple/Primitive.java": 2,
                "parquet-column/src/main/java/parquet/data/simple/SimpleGroup.java": 4,
                "parquet-column/src/main/java/parquet/data/simple/SimpleGroupFactory.java": 6,
                "parquet-column/src/main/java/parquet/data/simple/example/Paper.java": 6,
                "parquet-column/src/main/java/parquet/example/DummyRecordConverter.java": 55,
                "parquet-column/src/main/java/parquet/example/data/simple/convert/GroupRecordConverter.java": 32,
                "parquet-column/src/main/java/parquet/example/data/simple/convert/SimpleGroupConverter.java": 58,
                "parquet-column/src/main/java/parquet/example/data/simple/convert/SimplePrimitiveConverter.java": 70,
                "parquet-column/src/main/java/parquet/io/BaseRecordReader.java": 4,
                "parquet-column/src/main/java/parquet/io/GroupColumnIO.java": 2,
                "parquet-column/src/main/java/parquet/io/MessageColumnIO.java": 4,
                "parquet-column/src/main/java/parquet/io/RecordConsumerLoggingWrapper.java": 2,
                "parquet-column/src/main/java/parquet/io/RecordReaderImplementation.java": 122,
                "parquet-column/src/main/java/parquet/io/convert/RecordConverter.java": 7,
                "parquet-column/src/main/java/parquet/schema/PrimitiveType.java": 40,
                "parquet-column/src/main/java/parquet/utils/Varint.java": 167,
                "parquet-column/src/test/java/parquet/io/ExpectationValidatingConverter.java": 135,
                "parquet-column/src/test/java/parquet/io/PerfTest.java": 35,
                "parquet-column/src/test/java/parquet/io/TestColumnIO.java": 111,
                "parquet-column/src/test/java/parquet/schema/TestMessageType.java": 2,
                "parquet-hadoop/src/main/java/parquet/hadoop/ReadSupport.java": 4,
                "parquet-hadoop/src/test/java/parquet/format/converter/TestParquetMetadataConverter.java": 2,
                "parquet-hadoop/src/test/java/parquet/hadoop/TestInputFormat.java": 3,
                "parquet-hadoop/src/test/java/parquet/hadoop/TestReadIntTestFile.java": 9,
                "parquet-pig/src/main/java/parquet/pig/TupleReadSupport.java": 18,
                "parquet-pig/src/main/java/parquet/pig/convert/MapConverter.java": 6,
                "parquet-pig/src/main/java/parquet/pig/convert/TupleConverter.java": 93,
                "parquet-pig/src/test/java/parquet/pig/ConverterConsumer.java": 98,
                "parquet-pig/src/test/java/parquet/pig/TestTupleRecordConsumer.java": 31,
                "parquet-pig/src/test/java/parquet/pig/TupleConsumerPerfTest.java": 48
            },
            "is_test": true,
            "is_fix": false
        },
        "78ff38c7e17cd5349bc92ccda18e7310c8e0274c": {
            "datetime": "2013-02-21T14:37:36-08:00",
            "summary": "improve logs",
            "message": "improve logs\n",
            "diff": {
                "parquet-hadoop/src/main/java/parquet/hadoop/ParquetFileReader.java": 2,
                "parquet-pig/src/main/java/parquet/pig/ParquetLoader.java": 10
            },
            "is_test": false,
            "is_fix": false
        },
        "9058bae13942bb17e96ee5ba371b0013a58d473f": {
            "datetime": "2013-02-21T16:23:12-08:00",
            "summary": "improve use of summary file",
            "message": "improve use of summary file\n",
            "diff": {
                "parquet-hadoop/src/main/java/parquet/hadoop/ParquetFileReader.java": 24,
                "parquet-pig/src/main/java/parquet/pig/ParquetLoader.java": 58
            },
            "is_test": false,
            "is_fix": false
        },
        "b2efb50d011d65644ad00fbbc7511731d9f8c47d": {
            "datetime": "2013-02-22T14:50:10-08:00",
            "summary": "refactor the read/write support",
            "message": "refactor the read/write support\n",
            "diff": {
                "parquet-hadoop/src/main/java/parquet/hadoop/BadConfigurationException.java": 29,
                "parquet-hadoop/src/main/java/parquet/hadoop/ParquetInputFormat.java": 78,
                "parquet-hadoop/src/main/java/parquet/hadoop/ParquetInputSplit.java": 58,
                "parquet-hadoop/src/main/java/parquet/hadoop/ParquetOutputFormat.java": 73,
                "parquet-hadoop/src/main/java/parquet/hadoop/ParquetRecordReader.java": 26,
                "parquet-hadoop/src/main/java/parquet/hadoop/ParquetRecordWriter.java": 2,
                "parquet-hadoop/src/main/java/parquet/hadoop/ReadSupport.java": 27,
                "parquet-hadoop/src/main/java/parquet/hadoop/WriteSupport.java": 51,
                "parquet-hadoop/src/test/java/parquet/hadoop/TestInputFormat.java": 20,
                "parquet-pig/src/main/java/parquet/pig/ParquetLoader.java": 2,
                "parquet-pig/src/main/java/parquet/pig/ParquetStorer.java": 11,
                "parquet-pig/src/main/java/parquet/pig/PigMetaData.java": 52,
                "parquet-pig/src/main/java/parquet/pig/TupleReadSupport.java": 32,
                "parquet-pig/src/main/java/parquet/pig/TupleWriteSupport.java": 24,
                "parquet-pig/src/test/java/parquet/pig/TestTupleRecordConsumer.java": 14,
                "parquet-pig/src/test/java/parquet/pig/TupleConsumerPerfTest.java": 8
            },
            "is_test": true,
            "is_fix": false
        },
        "ad9dcbe0a0dcf3b94de5e7be868a273c076c52ba": {
            "datetime": "2013-02-26T13:57:52-08:00",
            "summary": "javadoc; original type support",
            "message": "javadoc; original type support\n",
            "diff": {
                "parquet-column/src/main/java/parquet/Log.java": 41,
                "parquet-column/src/main/java/parquet/ParquetRuntimeException.java": 6,
                "parquet-column/src/main/java/parquet/bytes/BytesInput.java": 48,
                "parquet-column/src/main/java/parquet/bytes/CapacityByteArrayOutputStream.java": 4,
                "parquet-column/src/main/java/parquet/column/ColumnDescriptor.java": 51,
                "parquet-column/src/main/java/parquet/column/ColumnReadStore.java": 10,
                "parquet-column/src/main/java/parquet/column/ColumnReader.java": 49,
                "parquet-column/src/main/java/parquet/column/ColumnWriteStore.java": 14,
                "parquet-column/src/main/java/parquet/column/ColumnWriter.java": 55,
                "parquet-column/src/main/java/parquet/column/mem/MemColumnReader.java": 75,
                "parquet-column/src/main/java/parquet/column/mem/Page.java": 18,
                "parquet-column/src/main/java/parquet/column/mem/PageReadStore.java": 15,
                "parquet-column/src/main/java/parquet/column/mem/PageReader.java": 15,
                "parquet-column/src/main/java/parquet/column/mem/PageWriteStore.java": 11,
                "parquet-column/src/main/java/parquet/column/mem/PageWriter.java": 21,
                "parquet-column/src/main/java/parquet/column/primitive/BitPackingColumnReader.java": 22,
                "parquet-column/src/main/java/parquet/column/primitive/BitPackingColumnWriter.java": 37,
                "parquet-column/src/main/java/parquet/column/primitive/BooleanPlainColumnReader.java": 12,
                "parquet-column/src/main/java/parquet/column/primitive/PrimitiveColumnReader.java": 6,
                "parquet-column/src/main/java/parquet/column/primitive/PrimitiveColumnWriter.java": 42,
                "parquet-column/src/main/java/parquet/example/DummyRecordConverter.java": 15,
                "parquet-column/src/main/java/parquet/example/data/simple/convert/GroupRecordConverter.java": 15,
                "parquet-column/src/main/java/parquet/example/data/simple/convert/SimpleGroupConverter.java": 15,
                "parquet-column/src/main/java/parquet/example/data/simple/convert/SimplePrimitiveConverter.java": 15,
                "parquet-column/src/main/java/parquet/io/ColumnIOFactory.java": 18,
                "parquet-column/src/main/java/parquet/io/CompilationException.java": 21,
                "parquet-column/src/main/java/parquet/io/GroupColumnIO.java": 8,
                "parquet-column/src/main/java/parquet/io/InvalidRecordException.java": 6,
                "parquet-column/src/main/java/parquet/io/MessageColumnIO.java": 7,
                "parquet-column/src/main/java/parquet/io/ParquetDecodingException.java": 21,
                "parquet-column/src/main/java/parquet/io/ParquetEncodingException.java": 21,
                "parquet-column/src/main/java/parquet/io/PrimitiveColumnIO.java": 8,
                "parquet-column/src/main/java/parquet/io/convert/RecordConverter.java": 28,
                "parquet-column/src/main/java/parquet/parser/MessageTypeParser.java": 115,
                "parquet-column/src/main/java/parquet/schema/ConversionPatterns.java": 72,
                "parquet-column/src/main/java/parquet/schema/GroupType.java": 25,
                "parquet-column/src/main/java/parquet/schema/MessageType.java": 4,
                "parquet-column/src/main/java/parquet/schema/OriginalType.java": 24,
                "parquet-column/src/main/java/parquet/schema/PrimitiveType.java": 9,
                "parquet-column/src/main/java/parquet/schema/Type.java": 10,
                "parquet-column/src/test/java/parquet/io/ExpectationValidatingConverter.java": 15,
                "parquet-hadoop/src/main/java/parquet/hadoop/BadConfigurationException.java": 15,
                "parquet-pig/src/main/java/parquet/pig/PigSchemaConverter.java": 19,
                "parquet-pig/src/test/java/parquet/pig/ConverterConsumer.java": 15
            },
            "is_test": false,
            "is_fix": false
        },
        "42c418c56fcea3a6da2471fbadabdb77f085b6a7": {
            "datetime": "2013-02-26T15:35:15-08:00",
            "summary": "javadoc",
            "message": "javadoc\n",
            "diff": {
                "parquet-column/src/main/java/parquet/bytes/BytesUtils.java": 19,
                "parquet-column/src/main/java/parquet/io/ColumnIO.java": 7
            },
            "is_test": false,
            "is_fix": false
        }
    },
    "2013-02-27T15:17:05-07:00": {
        "f2746e71fa579f5b56e055e8304ca292392e1ebb": {
            "datetime": "2013-02-28T10:27:23-08:00",
            "summary": "adding example output/input formats",
            "message": "adding example output/input formats\n",
            "diff": {
                "parquet-column/src/main/java/parquet/Log.java": 1,
                "parquet-column/src/main/java/parquet/io/ColumnIO.java": 17,
                "parquet-column/src/main/java/parquet/io/ColumnIOFactory.java": 6,
                "parquet-column/src/main/java/parquet/io/GroupColumnIO.java": 4,
                "parquet-column/src/main/java/parquet/io/MessageColumnIO.java": 4,
                "parquet-column/src/main/java/parquet/io/PrimitiveColumnIO.java": 4,
                "parquet-column/src/test/java/parquet/io/ExpectationValidatingRecordConsumer.java": 5,
                "parquet-hadoop/src/main/java/parquet/hadoop/ReadSupport.java": 2,
                "parquet-hadoop/src/main/java/parquet/hadoop/example/ExampleInputFormat.java": 20,
                "parquet-hadoop/src/main/java/parquet/hadoop/example/ExampleOutputFormat.java": 43,
                "parquet-hadoop/src/main/java/parquet/hadoop/example/GroupReadSupport.java": 24,
                "parquet-hadoop/src/main/java/parquet/hadoop/example/GroupWriteSupport.java": 45,
                "parquet-hadoop/src/test/java/parquet/hadoop/example/TestInputOutputFormat.java": 119,
                "parquet-pig/src/main/java/parquet/pig/TupleWriteSupport.java": 4
            },
            "is_test": true,
            "is_fix": false
        },
        "77097b63b08eb366a2d667b41a73e87b401dccdd": {
            "datetime": "2013-02-28T10:30:20-08:00",
            "summary": "ThriftParquetOutputFormat",
            "message": "ThriftParquetOutputFormat\n",
            "diff": {
                "parquet-thrift/src/main/java/parquet/hadoop/thrift/ParquetProtocol.java": 244,
                "parquet-thrift/src/main/java/parquet/hadoop/thrift/ParquetReadProtocol.java": 210,
                "parquet-thrift/src/main/java/parquet/hadoop/thrift/ParquetThriftInputFormat.java": 25,
                "parquet-thrift/src/main/java/parquet/hadoop/thrift/ParquetThriftOutputFormat.java": 33,
                "parquet-thrift/src/main/java/parquet/hadoop/thrift/ParquetWriteProtocol.java": 652,
                "parquet-thrift/src/main/java/parquet/hadoop/thrift/ThriftMetaData.java": 62,
                "parquet-thrift/src/main/java/parquet/hadoop/thrift/ThriftReadSupport.java": 38,
                "parquet-thrift/src/main/java/parquet/hadoop/thrift/ThriftSchemaConverter.java": 235,
                "parquet-thrift/src/main/java/parquet/hadoop/thrift/ThriftWriteSupport.java": 73,
                "parquet-thrift/src/main/java/parquet/hadoop/thrift/struct/JSON.java": 33,
                "parquet-thrift/src/main/java/parquet/hadoop/thrift/struct/ThriftField.java": 86,
                "parquet-thrift/src/main/java/parquet/hadoop/thrift/struct/ThriftType.java": 372,
                "parquet-thrift/src/main/java/parquet/hadoop/thrift/struct/ThriftTypeID.java": 89,
                "parquet-thrift/src/test/java/parquet/hadoop/thrift/TestParquetProtocol.java": 264,
                "parquet-thrift/src/test/java/parquet/hadoop/thrift/TestThriftSchemaConverter.java": 67
            },
            "is_test": true,
            "is_fix": false
        },
        "92e93b16aefa348eebbcce6869746271d7b8b716": {
            "datetime": "2013-02-28T10:32:09-08:00",
            "summary": "license header",
            "message": "license header\n",
            "diff": {
                "parquet-hadoop/src/main/java/parquet/hadoop/example/ExampleInputFormat.java": 15,
                "parquet-hadoop/src/main/java/parquet/hadoop/example/ExampleOutputFormat.java": 15,
                "parquet-hadoop/src/main/java/parquet/hadoop/example/GroupReadSupport.java": 15,
                "parquet-hadoop/src/main/java/parquet/hadoop/example/GroupWriteSupport.java": 15,
                "parquet-hadoop/src/test/java/parquet/hadoop/example/TestInputOutputFormat.java": 15,
                "parquet-thrift/src/main/java/parquet/hadoop/thrift/struct/JSON.java": 15,
                "parquet-thrift/src/main/java/parquet/hadoop/thrift/struct/ThriftType.java": 15,
                "parquet-thrift/src/test/java/parquet/hadoop/thrift/TestParquetProtocol.java": 15
            },
            "is_test": true,
            "is_fix": false
        },
        "c5ce15e0a29b83566fc445d0d17dc40163949b62": {
            "datetime": "2013-02-28T10:32:38-08:00",
            "summary": "license header",
            "message": "license header\n",
            "diff": {
                "parquet-hadoop/src/main/java/parquet/hadoop/example/ExampleInputFormat.java": 15,
                "parquet-hadoop/src/main/java/parquet/hadoop/example/ExampleOutputFormat.java": 15,
                "parquet-hadoop/src/main/java/parquet/hadoop/example/GroupReadSupport.java": 15,
                "parquet-hadoop/src/main/java/parquet/hadoop/example/GroupWriteSupport.java": 15,
                "parquet-hadoop/src/test/java/parquet/hadoop/example/TestInputOutputFormat.java": 15
            },
            "is_test": true,
            "is_fix": false
        },
        "af20471a423684375533774320b874a49195d4f8": {
            "datetime": "2013-03-01T16:32:46-08:00",
            "summary": "javadoc; bug fixes; thrift support; refactoring",
            "message": "javadoc; bug fixes; thrift support; refactoring\n",
            "diff": {
                "parquet-column/src/main/java/parquet/Log.java": 2,
                "parquet-column/src/main/java/parquet/bytes/BytesUtils.java": 2,
                "parquet-column/src/main/java/parquet/column/primitive/PrimitiveColumnReader.java": 43,
                "parquet-column/src/main/java/parquet/example/DummyRecordConverter.java": 104,
                "parquet-column/src/main/java/parquet/example/data/simple/convert/GroupRecordConverter.java": 25,
                "parquet-column/src/main/java/parquet/example/data/simple/convert/SimpleGroupConverter.java": 27,
                "parquet-column/src/main/java/parquet/io/RecordReaderImplementation.java": 11,
                "parquet-column/src/main/java/parquet/io/convert/Converter.java": 37,
                "parquet-column/src/main/java/parquet/io/convert/GroupConverter.java": 45,
                "parquet-column/src/main/java/parquet/io/convert/PrimitiveConverter.java": 50,
                "parquet-column/src/main/java/parquet/io/convert/RecordConverter.java": 8,
                "parquet-column/src/main/java/parquet/schema/GroupType.java": 15,
                "parquet-column/src/main/java/parquet/schema/MessageType.java": 6,
                "parquet-column/src/main/java/parquet/schema/PrimitiveType.java": 5,
                "parquet-column/src/main/java/parquet/schema/Type.java": 8,
                "parquet-column/src/main/java/parquet/schema/TypeConverter.java": 37,
                "parquet-column/src/test/java/parquet/io/ExpectationValidatingConverter.java": 229,
                "parquet-column/src/test/java/parquet/io/PerfTest.java": 2,
                "parquet-column/src/test/java/parquet/io/TestColumnIO.java": 2,
                "parquet-pig/src/main/java/parquet/pig/TupleReadSupport.java": 3,
                "parquet-pig/src/main/java/parquet/pig/convert/MapConverter.java": 28,
                "parquet-pig/src/main/java/parquet/pig/convert/TupleConverter.java": 50,
                "parquet-pig/src/main/java/parquet/pig/convert/TupleRecordConverter.java": 28,
                "parquet-pig/src/main/java/parquet/pig/converter/BagConverter.java": 78,
                "parquet-pig/src/main/java/parquet/pig/converter/Converter.java": 57,
                "parquet-pig/src/main/java/parquet/pig/converter/MapConverter.java": 81,
                "parquet-pig/src/main/java/parquet/pig/converter/MapKeyValueConverter.java": 91,
                "parquet-pig/src/main/java/parquet/pig/converter/MessageConverter.java": 117,
                "parquet-pig/src/main/java/parquet/pig/converter/TupleConverter.java": 136,
                "parquet-pig/src/test/java/parquet/pig/ConverterConsumer.java": 7,
                "parquet-pig/src/test/java/parquet/pig/TestTupleRecordConsumer.java": 5,
                "parquet-thrift/src/main/java/parquet/hadoop/thrift/ParquetProtocol.java": 92,
                "parquet-thrift/src/main/java/parquet/hadoop/thrift/ParquetReadProtocol.java": 210,
                "parquet-thrift/src/main/java/parquet/hadoop/thrift/ParquetThriftOutputFormat.java": 13,
                "parquet-thrift/src/main/java/parquet/hadoop/thrift/ParquetWriteProtocol.java": 58,
                "parquet-thrift/src/main/java/parquet/hadoop/thrift/ThriftMetaData.java": 2,
                "parquet-thrift/src/main/java/parquet/hadoop/thrift/ThriftSchemaConverter.java": 10,
                "parquet-thrift/src/main/java/parquet/hadoop/thrift/ThriftWriteSupport.java": 35,
                "parquet-thrift/src/main/java/parquet/hadoop/thrift/struct/JSON.java": 2,
                "parquet-thrift/src/main/java/parquet/hadoop/thrift/struct/ThriftField.java": 2,
                "parquet-thrift/src/main/java/parquet/hadoop/thrift/struct/ThriftType.java": 26,
                "parquet-thrift/src/main/java/parquet/hadoop/thrift/struct/ThriftTypeID.java": 26,
                "parquet-thrift/src/main/java/parquet/thrift/ParquetReadProtocol.java": 159,
                "parquet-thrift/src/main/java/parquet/thrift/ThriftReader.java": 10,
                "parquet-thrift/src/main/java/parquet/thrift/ThriftRecordConverter.java": 441,
                "parquet-thrift/src/test/java/parquet/hadoop/thrift/TestInputOutputFormat.java": 134,
                "parquet-thrift/src/test/java/parquet/hadoop/thrift/TestParquetProtocol.java": 6,
                "parquet-thrift/src/test/java/parquet/hadoop/thrift/TestParquetReadProtocol.java": 91,
                "parquet-thrift/src/test/java/parquet/hadoop/thrift/TestThriftSchemaConverter.java": 5
            },
            "is_test": true,
            "is_fix": false
        },
        "25b755958b1906dd3d4f6767a2008d8566746062": {
            "datetime": "2013-03-04T11:02:05-08:00",
            "summary": "thrift read protocol; fix repetition level size in little endian",
            "message": "thrift read protocol; fix repetition level size in little endian\n",
            "diff": {
                "parquet-column/src/main/java/parquet/Log.java": 2,
                "parquet-column/src/main/java/parquet/bytes/BytesInput.java": 4,
                "parquet-column/src/main/java/parquet/bytes/BytesUtils.java": 19,
                "parquet-column/src/main/java/parquet/column/mem/MemColumnReader.java": 3,
                "parquet-column/src/main/java/parquet/column/primitive/BitPackingColumnReader.java": 3,
                "parquet-column/src/main/java/parquet/column/primitive/BoundedIntColumnReader.java": 5,
                "parquet-column/src/main/java/parquet/example/data/GroupValueSource.java": 2,
                "parquet-column/src/main/java/parquet/example/data/simple/BinaryValue.java": 3,
                "parquet-column/src/main/java/parquet/example/data/simple/DoubleValue.java": 4,
                "parquet-column/src/main/java/parquet/example/data/simple/FloatValue.java": 4,
                "parquet-column/src/main/java/parquet/example/data/simple/SimpleGroup.java": 5,
                "parquet-column/src/main/java/parquet/example/data/simple/convert/GroupRecordConverter.java": 8,
                "parquet-column/src/main/java/parquet/example/data/simple/convert/SimpleGroupConverter.java": 2,
                "parquet-column/src/main/java/parquet/schema/GroupType.java": 6,
                "parquet-column/src/test/java/parquet/bytes/TestBytesUtil.java": 52,
                "parquet-column/src/test/java/parquet/io/ExpectationValidatingConverter.java": 8,
                "parquet-column/src/test/java/parquet/io/TestColumnIO.java": 50,
                "parquet-hadoop/src/main/java/parquet/format/converter/ParquetMetadataConverter.java": 1,
                "parquet-hadoop/src/main/java/parquet/hadoop/ParquetFileWriter.java": 1,
                "parquet-hadoop/src/test/java/parquet/hadoop/TestReadIntTestFile.java": 37,
                "parquet-thrift/src/main/java/parquet/thrift/TBaseRecordConverter.java": 29,
                "parquet-thrift/src/main/java/parquet/thrift/ThriftRecordConverter.java": 572,
                "parquet-thrift/src/test/java/parquet/hadoop/thrift/TestParquetReadProtocol.java": 44
            },
            "is_test": true,
            "is_fix": false
        },
        "9c79b0876401264707d3bfae37362afc72445df5": {
            "datetime": "2013-03-04T11:37:30-08:00",
            "summary": "thrift input/output format support",
            "message": "thrift input/output format support\n",
            "diff": {
                "parquet-thrift/src/main/java/parquet/hadoop/thrift/ThriftReadSupport.java": 11,
                "parquet-thrift/src/main/java/parquet/hadoop/thrift/ThriftWriteSupport.java": 2,
                "parquet-thrift/src/main/java/parquet/thrift/ThriftMetaData.java": 23,
                "parquet-thrift/src/main/java/parquet/thrift/struct/ThriftType.java": 12,
                "parquet-thrift/src/test/java/parquet/hadoop/thrift/TestInputOutputFormat.java": 34
            },
            "is_test": true,
            "is_fix": false
        },
        "ecf19dc3d917d124c33d463d662a1fb885bfb243": {
            "datetime": "2013-03-04T12:09:31-08:00",
            "summary": "add encoding information for the column reader; allow column writer to specify the encoding",
            "message": "add encoding information for the column reader; allow column writer to specify the encoding\n",
            "diff": {
                "parquet-column/src/main/java/parquet/column/Encoding.java": 20,
                "parquet-column/src/main/java/parquet/column/mem/MemColumnReader.java": 8,
                "parquet-column/src/main/java/parquet/column/mem/MemColumnWriter.java": 5,
                "parquet-column/src/main/java/parquet/column/mem/MemPageWriter.java": 5,
                "parquet-column/src/main/java/parquet/column/mem/Page.java": 21,
                "parquet-column/src/main/java/parquet/column/mem/PageWriter.java": 3,
                "parquet-column/src/main/java/parquet/column/primitive/BooleanPlainColumnWriter.java": 9,
                "parquet-column/src/main/java/parquet/column/primitive/DataColumnWriter.java": 33,
                "parquet-column/src/main/java/parquet/column/primitive/PlainColumnWriter.java": 8,
                "parquet-column/src/main/java/parquet/column/primitive/PrimitiveColumnWriter.java": 1,
                "parquet-column/src/main/java/parquet/io/convert/GroupConverter.java": 15,
                "parquet-column/src/main/java/parquet/io/convert/PrimitiveConverter.java": 15,
                "parquet-column/src/main/java/parquet/schema/TypeConverter.java": 15,
                "parquet-column/src/test/java/parquet/column/mem/TestMemPageStore.java": 15,
                "parquet-hadoop/src/main/java/parquet/format/converter/ParquetMetadataConverter.java": 19,
                "parquet-hadoop/src/main/java/parquet/hadoop/ColumnChunkPageReadStore.java": 3,
                "parquet-hadoop/src/main/java/parquet/hadoop/ColumnChunkPageWriteStore.java": 5,
                "parquet-hadoop/src/main/java/parquet/hadoop/ParquetFileReader.java": 3,
                "parquet-pig/src/main/java/parquet/pig/convert/TupleRecordConverter.java": 15,
                "parquet-thrift/src/main/java/parquet/thrift/TBaseRecordConverter.java": 15,
                "parquet-thrift/src/main/java/parquet/thrift/ThriftReader.java": 15,
                "parquet-thrift/src/main/java/parquet/thrift/ThriftRecordConverter.java": 15,
                "parquet-thrift/src/test/java/parquet/hadoop/thrift/TestParquetReadProtocol.java": 15
            },
            "is_test": true,
            "is_fix": false
        },
        "e8f8429e11372c04afffdcd133199ff87872eebf": {
            "datetime": "2013-03-04T16:15:54-08:00",
            "summary": "populate encodings in column metadata",
            "message": "populate encodings in column metadata\n",
            "diff": {
                "parquet-hadoop/src/main/java/parquet/format/converter/ParquetMetadataConverter.java": 25,
                "parquet-hadoop/src/main/java/parquet/hadoop/ColumnChunkPageWriteStore.java": 13,
                "parquet-hadoop/src/main/java/parquet/hadoop/ParquetFileWriter.java": 17,
                "parquet-hadoop/src/main/java/parquet/hadoop/metadata/ColumnChunkMetaData.java": 16,
                "parquet-hadoop/src/test/java/parquet/hadoop/TestInputFormat.java": 5,
                "parquet-hadoop/src/test/java/parquet/hadoop/TestParquetFileWriter.java": 15,
                "parquet-pig/src/test/java/parquet/pig/GenerateIntTestFile.java": 5
            },
            "is_test": true,
            "is_fix": false
        },
        "d35c264e8f922667d9d04263df2e3b18ec9205cc": {
            "datetime": "2013-03-05T10:15:13-08:00",
            "summary": "turn byte[] into Binary object in the api",
            "message": "turn byte[] into Binary object in the api\n",
            "diff": {
                "parquet-column/src/main/java/parquet/column/ColumnReader.java": 4,
                "parquet-column/src/main/java/parquet/column/ColumnWriter.java": 4,
                "parquet-column/src/main/java/parquet/column/mem/MemColumnReadStore.java": 5,
                "parquet-column/src/main/java/parquet/column/mem/MemColumnReader.java": 3,
                "parquet-column/src/main/java/parquet/column/mem/MemColumnWriter.java": 3,
                "parquet-column/src/main/java/parquet/column/primitive/DevNullColumnReader.java": 8,
                "parquet-column/src/main/java/parquet/column/primitive/DevNullColumnWriter.java": 3,
                "parquet-column/src/main/java/parquet/column/primitive/PlainColumnReader.java": 6,
                "parquet-column/src/main/java/parquet/column/primitive/PlainColumnWriter.java": 7,
                "parquet-column/src/main/java/parquet/column/primitive/PrimitiveColumnReader.java": 4,
                "parquet-column/src/main/java/parquet/column/primitive/PrimitiveColumnWriter.java": 3,
                "parquet-column/src/main/java/parquet/example/data/Group.java": 9,
                "parquet-column/src/main/java/parquet/example/data/GroupRecordConsumer.java": 3,
                "parquet-column/src/main/java/parquet/example/data/GroupValueSource.java": 5,
                "parquet-column/src/main/java/parquet/example/data/simple/BinaryValue.java": 11,
                "parquet-column/src/main/java/parquet/example/data/simple/Primitive.java": 3,
                "parquet-column/src/main/java/parquet/example/data/simple/SimpleGroup.java": 7,
                "parquet-column/src/main/java/parquet/example/data/simple/convert/SimplePrimitiveConverter.java": 3,
                "parquet-column/src/main/java/parquet/io/BaseRecordReader.java": 2,
                "parquet-column/src/main/java/parquet/io/Binary.java": 99,
                "parquet-column/src/main/java/parquet/io/ConverterConsumer.java": 2,
                "parquet-column/src/main/java/parquet/io/MessageColumnIO.java": 4,
                "parquet-column/src/main/java/parquet/io/RecordConsumer.java": 2,
                "parquet-column/src/main/java/parquet/io/RecordConsumerLoggingWrapper.java": 4,
                "parquet-column/src/main/java/parquet/io/ValidatingRecordConsumer.java": 2,
                "parquet-column/src/main/java/parquet/io/convert/PrimitiveConverter.java": 4,
                "parquet-column/src/test/java/parquet/column/mem/TestMemColumn.java": 5,
                "parquet-column/src/test/java/parquet/io/ExpectationValidatingConverter.java": 4,
                "parquet-column/src/test/java/parquet/io/ExpectationValidatingRecordConsumer.java": 4,
                "parquet-column/src/test/java/parquet/io/TestColumnIO.java": 4,
                "parquet-pig/src/main/java/parquet/pig/TupleRecordConsumer.java": 5,
                "parquet-pig/src/main/java/parquet/pig/TupleWriteSupport.java": 3,
                "parquet-pig/src/main/java/parquet/pig/convert/MapConverter.java": 5,
                "parquet-pig/src/main/java/parquet/pig/convert/TupleConverter.java": 9,
                "parquet-pig/src/test/java/parquet/pig/GenerateTPCH.java": 3,
                "parquet-thrift/src/main/java/parquet/thrift/ParquetWriteProtocol.java": 7,
                "parquet-thrift/src/main/java/parquet/thrift/ThriftRecordConverter.java": 24
            },
            "is_test": true,
            "is_fix": false
        },
        "07ea133db57bdfa32fdcc03b370f0ac89d35fd0d": {
            "datetime": "2013-03-05T10:16:54-08:00",
            "summary": "license headers",
            "message": "license headers\n",
            "diff": {
                "parquet-column/src/main/java/parquet/io/Binary.java": 15,
                "parquet-thrift/src/main/java/parquet/thrift/ThriftRecordConverter.java": 15
            },
            "is_test": false,
            "is_fix": false
        },
        "ee8ec11a25ede3279df609ee1e402476d8b6d028": {
            "datetime": "2013-03-05T11:41:50-08:00",
            "summary": "javadoc; turn off the compatibility test for now",
            "message": "javadoc; turn off the compatibility test for now\n",
            "diff": {
                "parquet-hadoop/src/test/java/parquet/hadoop/TestReadIntTestFile.java": 57,
                "parquet-thrift/src/main/java/parquet/thrift/ThriftRecordConverter.java": 127
            },
            "is_test": true,
            "is_fix": false
        },
        "54dd652ef68572c3796efbbe636699bf00d3fc6c": {
            "datetime": "2013-03-05T13:47:25-08:00",
            "summary": "integrate the thrift changes",
            "message": "integrate the thrift changes\n",
            "diff": {
                "parquet-hadoop/src/main/java/parquet/format/converter/ParquetMetadataConverter.java": 42,
                "parquet-hadoop/src/main/java/parquet/hadoop/ColumnChunkPageWriteStore.java": 13,
                "parquet-hadoop/src/main/java/parquet/hadoop/ParquetFileWriter.java": 14,
                "parquet-hadoop/src/main/java/parquet/hadoop/metadata/ParquetMetadata.java": 2,
                "parquet-hadoop/src/test/java/parquet/hadoop/TestReadIntTestFile.java": 1
            },
            "is_test": true,
            "is_fix": false
        },
        "0973e7dd05799d75a3907c0e27415b68310c90ea": {
            "datetime": "2013-03-05T14:56:57-08:00",
            "summary": "removed outdated comment",
            "message": "removed outdated comment\n",
            "diff": {
                "parquet-thrift/src/main/java/parquet/thrift/ThriftSchemaConverter.java": 2
            },
            "is_test": false,
            "is_fix": false
        },
        "c3c22a050d91af4b80974a6290f055d8ff49b401": {
            "datetime": "2013-03-05T14:58:15-08:00",
            "summary": "Merge pull request #1 from Parquet/parquet_thrift",
            "message": "Merge pull request #1 from Parquet/parquet_thrift\n\nParquet thrift support and some related refactoring",
            "diff": {
                "parquet-column/src/main/java/parquet/bytes/BytesInput.java": 4,
                "parquet-column/src/main/java/parquet/bytes/BytesUtils.java": 21,
                "parquet-column/src/main/java/parquet/column/ColumnReader.java": 4,
                "parquet-column/src/main/java/parquet/column/ColumnWriter.java": 4,
                "parquet-column/src/main/java/parquet/column/Encoding.java": 20,
                "parquet-column/src/main/java/parquet/column/mem/MemColumnReadStore.java": 5,
                "parquet-column/src/main/java/parquet/column/mem/MemColumnReader.java": 14,
                "parquet-column/src/main/java/parquet/column/mem/MemColumnWriter.java": 8,
                "parquet-column/src/main/java/parquet/column/mem/MemPageWriter.java": 5,
                "parquet-column/src/main/java/parquet/column/mem/Page.java": 21,
                "parquet-column/src/main/java/parquet/column/mem/PageWriter.java": 3,
                "parquet-column/src/main/java/parquet/column/primitive/BitPackingColumnReader.java": 3,
                "parquet-column/src/main/java/parquet/column/primitive/BooleanPlainColumnWriter.java": 9,
                "parquet-column/src/main/java/parquet/column/primitive/BoundedIntColumnReader.java": 5,
                "parquet-column/src/main/java/parquet/column/primitive/DataColumnWriter.java": 33,
                "parquet-column/src/main/java/parquet/column/primitive/DevNullColumnReader.java": 8,
                "parquet-column/src/main/java/parquet/column/primitive/DevNullColumnWriter.java": 3,
                "parquet-column/src/main/java/parquet/column/primitive/PlainColumnReader.java": 6,
                "parquet-column/src/main/java/parquet/column/primitive/PlainColumnWriter.java": 15,
                "parquet-column/src/main/java/parquet/column/primitive/PrimitiveColumnReader.java": 47,
                "parquet-column/src/main/java/parquet/column/primitive/PrimitiveColumnWriter.java": 4,
                "parquet-column/src/main/java/parquet/example/DummyRecordConverter.java": 104,
                "parquet-column/src/main/java/parquet/example/data/Group.java": 9,
                "parquet-column/src/main/java/parquet/example/data/GroupRecordConsumer.java": 3,
                "parquet-column/src/main/java/parquet/example/data/GroupValueSource.java": 7,
                "parquet-column/src/main/java/parquet/example/data/simple/BinaryValue.java": 12,
                "parquet-column/src/main/java/parquet/example/data/simple/DoubleValue.java": 4,
                "parquet-column/src/main/java/parquet/example/data/simple/FloatValue.java": 4,
                "parquet-column/src/main/java/parquet/example/data/simple/Primitive.java": 3,
                "parquet-column/src/main/java/parquet/example/data/simple/SimpleGroup.java": 12,
                "parquet-column/src/main/java/parquet/example/data/simple/convert/GroupRecordConverter.java": 27,
                "parquet-column/src/main/java/parquet/example/data/simple/convert/SimpleGroupConverter.java": 29,
                "parquet-column/src/main/java/parquet/example/data/simple/convert/SimplePrimitiveConverter.java": 3,
                "parquet-column/src/main/java/parquet/io/BaseRecordReader.java": 2,
                "parquet-column/src/main/java/parquet/io/Binary.java": 114,
                "parquet-column/src/main/java/parquet/io/MessageColumnIO.java": 4,
                "parquet-column/src/main/java/parquet/io/RecordConsumer.java": 2,
                "parquet-column/src/main/java/parquet/io/RecordConsumerLoggingWrapper.java": 4,
                "parquet-column/src/main/java/parquet/io/RecordReaderImplementation.java": 11,
                "parquet-column/src/main/java/parquet/io/ValidatingRecordConsumer.java": 2,
                "parquet-column/src/main/java/parquet/io/convert/Converter.java": 37,
                "parquet-column/src/main/java/parquet/io/convert/GroupConverter.java": 30,
                "parquet-column/src/main/java/parquet/io/convert/PrimitiveConverter.java": 39,
                "parquet-column/src/main/java/parquet/io/convert/RecordConverter.java": 8,
                "parquet-column/src/main/java/parquet/schema/GroupType.java": 15,
                "parquet-column/src/main/java/parquet/schema/MessageType.java": 6,
                "parquet-column/src/main/java/parquet/schema/PrimitiveType.java": 5,
                "parquet-column/src/main/java/parquet/schema/Type.java": 8,
                "parquet-column/src/main/java/parquet/schema/TypeConverter.java": 52,
                "parquet-column/src/test/java/parquet/bytes/TestBytesUtil.java": 52,
                "parquet-column/src/test/java/parquet/column/mem/TestMemColumn.java": 5,
                "parquet-column/src/test/java/parquet/column/mem/TestMemPageStore.java": 15,
                "parquet-column/src/test/java/parquet/io/ExpectationValidatingConverter.java": 231,
                "parquet-column/src/test/java/parquet/io/ExpectationValidatingRecordConsumer.java": 4,
                "parquet-column/src/test/java/parquet/io/PerfTest.java": 2,
                "parquet-column/src/test/java/parquet/io/TestColumnIO.java": 56,
                "parquet-hadoop/src/main/java/parquet/format/converter/ParquetMetadataConverter.java": 81,
                "parquet-hadoop/src/main/java/parquet/hadoop/ColumnChunkPageReadStore.java": 3,
                "parquet-hadoop/src/main/java/parquet/hadoop/ColumnChunkPageWriteStore.java": 27,
                "parquet-hadoop/src/main/java/parquet/hadoop/ParquetFileReader.java": 3,
                "parquet-hadoop/src/main/java/parquet/hadoop/ParquetFileWriter.java": 28,
                "parquet-hadoop/src/main/java/parquet/hadoop/metadata/ColumnChunkMetaData.java": 16,
                "parquet-hadoop/src/main/java/parquet/hadoop/metadata/ParquetMetadata.java": 2,
                "parquet-hadoop/src/test/java/parquet/hadoop/TestInputFormat.java": 5,
                "parquet-hadoop/src/test/java/parquet/hadoop/TestParquetFileWriter.java": 15,
                "parquet-hadoop/src/test/java/parquet/hadoop/TestReadIntTestFile.java": 87,
                "parquet-pig/src/main/java/parquet/pig/TupleReadSupport.java": 3,
                "parquet-pig/src/main/java/parquet/pig/TupleRecordConsumer.java": 5,
                "parquet-pig/src/main/java/parquet/pig/TupleWriteSupport.java": 3,
                "parquet-pig/src/main/java/parquet/pig/convert/MapConverter.java": 33,
                "parquet-pig/src/main/java/parquet/pig/convert/TupleConverter.java": 59,
                "parquet-pig/src/main/java/parquet/pig/convert/TupleRecordConverter.java": 43,
                "parquet-pig/src/main/java/parquet/pig/converter/BagConverter.java": 78,
                "parquet-pig/src/main/java/parquet/pig/converter/Converter.java": 57,
                "parquet-pig/src/main/java/parquet/pig/converter/MapConverter.java": 81,
                "parquet-pig/src/main/java/parquet/pig/converter/MapKeyValueConverter.java": 91,
                "parquet-pig/src/main/java/parquet/pig/converter/MessageConverter.java": 117,
                "parquet-pig/src/main/java/parquet/pig/converter/TupleConverter.java": 136,
                "parquet-pig/src/test/java/parquet/pig/ConverterConsumer.java": 9,
                "parquet-pig/src/test/java/parquet/pig/GenerateIntTestFile.java": 5,
                "parquet-pig/src/test/java/parquet/pig/GenerateTPCH.java": 3,
                "parquet-pig/src/test/java/parquet/pig/TestTupleRecordConsumer.java": 5,
                "parquet-thrift/src/main/java/parquet/hadoop/thrift/ParquetThriftInputFormat.java": 25,
                "parquet-thrift/src/main/java/parquet/hadoop/thrift/ParquetThriftOutputFormat.java": 42,
                "parquet-thrift/src/main/java/parquet/hadoop/thrift/ThriftReadSupport.java": 45,
                "parquet-thrift/src/main/java/parquet/hadoop/thrift/ThriftWriteSupport.java": 84,
                "parquet-thrift/src/main/java/parquet/thrift/ParquetProtocol.java": 252,
                "parquet-thrift/src/main/java/parquet/thrift/ParquetReadProtocol.java": 159,
                "parquet-thrift/src/main/java/parquet/thrift/ParquetWriteProtocol.java": 653,
                "parquet-thrift/src/main/java/parquet/thrift/TBaseRecordConverter.java": 44,
                "parquet-thrift/src/main/java/parquet/thrift/ThriftMetaData.java": 79,
                "parquet-thrift/src/main/java/parquet/thrift/ThriftReader.java": 25,
                "parquet-thrift/src/main/java/parquet/thrift/ThriftRecordConverter.java": 754,
                "parquet-thrift/src/main/java/parquet/thrift/ThriftSchemaConverter.java": 235,
                "parquet-thrift/src/main/java/parquet/thrift/struct/JSON.java": 48,
                "parquet-thrift/src/main/java/parquet/thrift/struct/ThriftField.java": 86,
                "parquet-thrift/src/main/java/parquet/thrift/struct/ThriftType.java": 375,
                "parquet-thrift/src/main/java/parquet/thrift/struct/ThriftTypeID.java": 89,
                "parquet-thrift/src/test/java/parquet/hadoop/thrift/TestInputOutputFormat.java": 146,
                "parquet-thrift/src/test/java/parquet/hadoop/thrift/TestParquetReadProtocol.java": 122,
                "parquet-thrift/src/test/java/parquet/hadoop/thrift/TestParquetWriteProtocol.java": 281,
                "parquet-thrift/src/test/java/parquet/hadoop/thrift/TestThriftSchemaConverter.java": 68
            },
            "is_test": true,
            "is_fix": false
        },
        "003299e4240a1f131c4d1b9d3fe5f3b4ff9fd0e6": {
            "datetime": "2013-03-05T15:24:20-08:00",
            "summary": "Style cleanup and other miscellanea (javadoc, etc)",
            "message": "Style cleanup and other miscellanea (javadoc, etc)\n\nAdded other review comments as TODOs\n",
            "diff": {
                "parquet-column/src/main/java/parquet/bytes/BytesUtils.java": 4,
                "parquet-column/src/main/java/parquet/bytes/LittleEndianDataInputStream.java": 6,
                "parquet-column/src/main/java/parquet/bytes/LittleEndianDataOutputStream.java": 3,
                "parquet-column/src/main/java/parquet/column/ColumnDescriptor.java": 32,
                "parquet-column/src/main/java/parquet/column/ColumnReadStore.java": 5,
                "parquet-column/src/main/java/parquet/column/ColumnReader.java": 25,
                "parquet-column/src/main/java/parquet/column/ColumnWriteStore.java": 8,
                "parquet-column/src/main/java/parquet/column/ColumnWriter.java": 7,
                "parquet-column/src/main/java/parquet/column/UnknownColumnException.java": 5,
                "parquet-column/src/main/java/parquet/column/mem/MemColumnReader.java": 7,
                "parquet-column/src/main/java/parquet/column/mem/MemColumnWriteStore.java": 6,
                "parquet-column/src/main/java/parquet/column/mem/MemColumnWriter.java": 24,
                "parquet-column/src/main/java/parquet/column/mem/MemPageStore.java": 6,
                "parquet-column/src/main/java/parquet/column/primitive/BitPacking.java": 2,
                "parquet-column/src/main/java/parquet/column/primitive/BitPackingColumnReader.java": 5,
                "parquet-column/src/main/java/parquet/column/primitive/BitPackingColumnWriter.java": 8,
                "parquet-column/src/main/java/parquet/column/primitive/BitReader.java": 23,
                "parquet-column/src/main/java/parquet/column/primitive/BitWriter.java": 26,
                "parquet-column/src/main/java/parquet/column/primitive/BooleanPlainColumnReader.java": 4,
                "parquet-column/src/main/java/parquet/column/primitive/BooleanPlainColumnWriter.java": 4,
                "parquet-column/src/main/java/parquet/column/primitive/BoundedColumnFactory.java": 2,
                "parquet-column/src/main/java/parquet/column/primitive/BoundedIntColumnReader.java": 10,
                "parquet-column/src/main/java/parquet/column/primitive/BoundedIntColumnWriter.java": 14,
                "parquet-column/src/main/java/parquet/column/primitive/DevNullColumnReader.java": 7,
                "parquet-column/src/main/java/parquet/column/primitive/DevNullColumnWriter.java": 6,
                "parquet-column/src/main/java/parquet/column/primitive/PlainColumnReader.java": 1,
                "parquet-column/src/main/java/parquet/column/primitive/PlainColumnWriter.java": 4,
                "parquet-column/src/main/java/parquet/column/primitive/PrimitiveColumnReader.java": 27,
                "parquet-column/src/main/java/parquet/column/primitive/PrimitiveColumnWriter.java": 8,
                "parquet-column/src/main/java/parquet/io/BaseRecordReader.java": 1,
                "parquet-column/src/main/java/parquet/io/RecordReaderImplementation.java": 10,
                "parquet-column/src/main/java/parquet/io/convert/RecordConverter.java": 9,
                "parquet-column/src/main/java/parquet/parser/MessageTypeParser.java": 5,
                "parquet-column/src/main/java/parquet/schema/ConversionPatterns.java": 8,
                "parquet-column/src/main/java/parquet/schema/GroupType.java": 18,
                "parquet-column/src/main/java/parquet/schema/MessageType.java": 24,
                "parquet-column/src/main/java/parquet/schema/PrimitiveType.java": 9,
                "parquet-column/src/main/java/parquet/schema/Type.java": 16,
                "parquet-column/src/test/java/parquet/column/primitive/TestBitPacking.java": 2,
                "parquet-column/src/test/java/parquet/io/TestColumnIO.java": 2,
                "parquet-column/src/test/java/parquet/schema/TestMessageType.java": 15,
                "parquet-hadoop/src/main/java/parquet/hadoop/ParquetInputFormat.java": 4
            },
            "is_test": true,
            "is_fix": false
        },
        "591c2b9d2bb8c428597091698f762155d6fdee4f": {
            "datetime": "2013-03-05T15:27:37-08:00",
            "summary": "move compatibility test to the appropriate repo",
            "message": "move compatibility test to the appropriate repo\n",
            "diff": {
                "parquet-hadoop/src/test/java/parquet/hadoop/TestReadIntTestFile.java": 130
            },
            "is_test": true,
            "is_fix": false
        },
        "76fd1d8011bf4f125118e28f11f5aa5539f06fbd": {
            "datetime": "2013-03-05T16:09:59-08:00",
            "summary": "cleanup",
            "message": "cleanup\n",
            "diff": {
                "parquet-hadoop/src/main/java/parquet/hadoop/BlockData.java": 52,
                "parquet-hadoop/src/main/java/parquet/hadoop/ColumnData.java": 88,
                "parquet-hadoop/src/main/java/parquet/hadoop/PageConsumer.java": 24,
                "parquet-hadoop/src/main/java/parquet/hadoop/metadata/ColumnMetaData.java": 37
            },
            "is_test": false,
            "is_fix": false
        },
        "962dd9e8bbacab7f86159da53f165fe8c569fd3b": {
            "datetime": "2013-03-05T16:15:31-08:00",
            "summary": "More cleanup/renames",
            "message": "More cleanup/renames\n",
            "diff": {
                "parquet-column/src/main/java/parquet/column/mem/PageReadStore.java": 2,
                "parquet-hadoop/src/main/java/parquet/format/converter/ParquetMetadataConverter.java": 6,
                "parquet-hadoop/src/main/java/parquet/hadoop/CodecFactory.java": 42,
                "parquet-hadoop/src/main/java/parquet/hadoop/ColumnChunkPageReadStore.java": 57,
                "parquet-hadoop/src/main/java/parquet/hadoop/ColumnChunkPageWriteStore.java": 2,
                "parquet-hadoop/src/main/java/parquet/hadoop/ColumnData.java": 2,
                "parquet-hadoop/src/main/java/parquet/hadoop/Footer.java": 2,
                "parquet-hadoop/src/main/java/parquet/hadoop/PageConsumer.java": 2,
                "parquet-hadoop/src/main/java/parquet/hadoop/ParquetFileReader.java": 71,
                "parquet-hadoop/src/main/java/parquet/hadoop/ParquetFileWriter.java": 2,
                "parquet-hadoop/src/main/java/parquet/hadoop/ParquetInputFormat.java": 2,
                "parquet-hadoop/src/main/java/parquet/hadoop/ParquetRecordReader.java": 2,
                "parquet-hadoop/src/main/java/parquet/hadoop/metadata/ColumnChunkMetaData.java": 4,
                "parquet-hadoop/src/test/java/parquet/hadoop/TestInputFormat.java": 2,
                "parquet-hadoop/src/test/java/parquet/hadoop/TestParquetFileWriter.java": 10,
                "parquet-hadoop/src/test/java/parquet/hadoop/TestReadIntTestFile.java": 2,
                "parquet-pig/src/test/java/parquet/pig/GenerateIntTestFile.java": 2
            },
            "is_test": true,
            "is_fix": false
        },
        "7ea3721c8559b96683854edf1594059eb6deda35": {
            "datetime": "2013-03-05T17:40:04-08:00",
            "summary": "Merge remote-tracking branch 'origin/master'",
            "message": "Merge remote-tracking branch 'origin/master'\n\nConflicts:\n\tparquet-column/src/main/java/parquet/column/primitive/DevNullColumnReader.java\n\tparquet-column/src/main/java/parquet/column/primitive/PrimitiveColumnWriter.java\n\tparquet-hadoop/src/main/java/parquet/format/converter/ParquetMetadataConverter.java\n\tparquet-hadoop/src/main/java/parquet/hadoop/ColumnData.java\n\tparquet-hadoop/src/main/java/parquet/hadoop/PageConsumer.java\n\tparquet-hadoop/src/test/java/parquet/hadoop/TestInputFormat.java\n\tparquet-hadoop/src/test/java/parquet/hadoop/TestReadIntTestFile.java\n",
            "diff": {
                "parquet-column/src/main/java/parquet/column/ColumnReader.java": 4,
                "parquet-column/src/main/java/parquet/column/ColumnWriter.java": 4,
                "parquet-column/src/main/java/parquet/column/mem/MemColumnReadStore.java": 5,
                "parquet-column/src/main/java/parquet/column/mem/MemColumnReader.java": 3,
                "parquet-column/src/main/java/parquet/column/mem/MemColumnWriter.java": 3,
                "parquet-column/src/main/java/parquet/column/primitive/DevNullColumnReader.java": 7,
                "parquet-column/src/main/java/parquet/column/primitive/DevNullColumnWriter.java": 3,
                "parquet-column/src/main/java/parquet/column/primitive/PlainColumnReader.java": 6,
                "parquet-column/src/main/java/parquet/column/primitive/PlainColumnWriter.java": 7,
                "parquet-column/src/main/java/parquet/column/primitive/PrimitiveColumnReader.java": 4,
                "parquet-column/src/main/java/parquet/column/primitive/PrimitiveColumnWriter.java": 4,
                "parquet-column/src/main/java/parquet/example/data/Group.java": 9,
                "parquet-column/src/main/java/parquet/example/data/GroupRecordConsumer.java": 3,
                "parquet-column/src/main/java/parquet/example/data/GroupValueSource.java": 5,
                "parquet-column/src/main/java/parquet/example/data/simple/BinaryValue.java": 11,
                "parquet-column/src/main/java/parquet/example/data/simple/Primitive.java": 3,
                "parquet-column/src/main/java/parquet/example/data/simple/SimpleGroup.java": 7,
                "parquet-column/src/main/java/parquet/example/data/simple/convert/SimplePrimitiveConverter.java": 3,
                "parquet-column/src/main/java/parquet/io/BaseRecordReader.java": 2,
                "parquet-column/src/main/java/parquet/io/Binary.java": 114,
                "parquet-column/src/main/java/parquet/io/ConverterConsumer.java": 2,
                "parquet-column/src/main/java/parquet/io/MessageColumnIO.java": 4,
                "parquet-column/src/main/java/parquet/io/RecordConsumer.java": 2,
                "parquet-column/src/main/java/parquet/io/RecordConsumerLoggingWrapper.java": 4,
                "parquet-column/src/main/java/parquet/io/ValidatingRecordConsumer.java": 2,
                "parquet-column/src/main/java/parquet/io/convert/PrimitiveConverter.java": 4,
                "parquet-column/src/test/java/parquet/column/mem/TestMemColumn.java": 5,
                "parquet-column/src/test/java/parquet/io/ExpectationValidatingConverter.java": 4,
                "parquet-column/src/test/java/parquet/io/ExpectationValidatingRecordConsumer.java": 4,
                "parquet-column/src/test/java/parquet/io/TestColumnIO.java": 4,
                "parquet-hadoop/src/main/java/parquet/format/converter/ParquetMetadataConverter.java": 67,
                "parquet-hadoop/src/main/java/parquet/hadoop/BlockData.java": 52,
                "parquet-hadoop/src/main/java/parquet/hadoop/ColumnChunkPageWriteStore.java": 26,
                "parquet-hadoop/src/main/java/parquet/hadoop/ColumnData.java": 88,
                "parquet-hadoop/src/main/java/parquet/hadoop/Footer.java": 2,
                "parquet-hadoop/src/main/java/parquet/hadoop/PageConsumer.java": 24,
                "parquet-hadoop/src/main/java/parquet/hadoop/ParquetFileWriter.java": 29,
                "parquet-hadoop/src/main/java/parquet/hadoop/metadata/ColumnChunkMetaData.java": 16,
                "parquet-hadoop/src/main/java/parquet/hadoop/metadata/ColumnMetaData.java": 37,
                "parquet-hadoop/src/main/java/parquet/hadoop/metadata/ParquetMetadata.java": 2,
                "parquet-hadoop/src/test/java/parquet/hadoop/TestInputFormat.java": 5,
                "parquet-hadoop/src/test/java/parquet/hadoop/TestParquetFileWriter.java": 15,
                "parquet-hadoop/src/test/java/parquet/hadoop/TestReadIntTestFile.java": 84,
                "parquet-pig/src/main/java/parquet/pig/TupleRecordConsumer.java": 5,
                "parquet-pig/src/main/java/parquet/pig/TupleWriteSupport.java": 3,
                "parquet-pig/src/main/java/parquet/pig/convert/MapConverter.java": 5,
                "parquet-pig/src/main/java/parquet/pig/convert/TupleConverter.java": 9,
                "parquet-pig/src/test/java/parquet/pig/GenerateIntTestFile.java": 5,
                "parquet-pig/src/test/java/parquet/pig/GenerateTPCH.java": 3,
                "parquet-thrift/src/main/java/parquet/thrift/ParquetWriteProtocol.java": 7,
                "parquet-thrift/src/main/java/parquet/thrift/ThriftRecordConverter.java": 146,
                "parquet-thrift/src/main/java/parquet/thrift/ThriftSchemaConverter.java": 2
            },
            "is_test": true,
            "is_fix": false
        },
        "d4a7da550acff516086cf0984fb4b3a3edde1b24": {
            "datetime": "2013-03-05T17:55:18-08:00",
            "summary": "Merge pull request #3 from toddlipcon/master",
            "message": "Merge pull request #3 from toddlipcon/master\n\nSome misc cleanups, review comments for Julien",
            "diff": {
                "parquet-column/src/main/java/parquet/bytes/BytesUtils.java": 4,
                "parquet-column/src/main/java/parquet/bytes/LittleEndianDataInputStream.java": 6,
                "parquet-column/src/main/java/parquet/bytes/LittleEndianDataOutputStream.java": 3,
                "parquet-column/src/main/java/parquet/column/ColumnDescriptor.java": 32,
                "parquet-column/src/main/java/parquet/column/ColumnReadStore.java": 5,
                "parquet-column/src/main/java/parquet/column/ColumnReader.java": 25,
                "parquet-column/src/main/java/parquet/column/ColumnWriteStore.java": 8,
                "parquet-column/src/main/java/parquet/column/ColumnWriter.java": 7,
                "parquet-column/src/main/java/parquet/column/UnknownColumnException.java": 5,
                "parquet-column/src/main/java/parquet/column/mem/MemColumnReader.java": 7,
                "parquet-column/src/main/java/parquet/column/mem/MemColumnWriteStore.java": 6,
                "parquet-column/src/main/java/parquet/column/mem/MemColumnWriter.java": 24,
                "parquet-column/src/main/java/parquet/column/mem/MemPageStore.java": 6,
                "parquet-column/src/main/java/parquet/column/mem/PageReadStore.java": 2,
                "parquet-column/src/main/java/parquet/column/primitive/BitPacking.java": 2,
                "parquet-column/src/main/java/parquet/column/primitive/BitPackingColumnReader.java": 5,
                "parquet-column/src/main/java/parquet/column/primitive/BitPackingColumnWriter.java": 8,
                "parquet-column/src/main/java/parquet/column/primitive/BitReader.java": 23,
                "parquet-column/src/main/java/parquet/column/primitive/BitWriter.java": 26,
                "parquet-column/src/main/java/parquet/column/primitive/BooleanPlainColumnReader.java": 4,
                "parquet-column/src/main/java/parquet/column/primitive/BooleanPlainColumnWriter.java": 4,
                "parquet-column/src/main/java/parquet/column/primitive/BoundedColumnFactory.java": 2,
                "parquet-column/src/main/java/parquet/column/primitive/BoundedIntColumnReader.java": 10,
                "parquet-column/src/main/java/parquet/column/primitive/BoundedIntColumnWriter.java": 14,
                "parquet-column/src/main/java/parquet/column/primitive/DevNullColumnReader.java": 8,
                "parquet-column/src/main/java/parquet/column/primitive/DevNullColumnWriter.java": 6,
                "parquet-column/src/main/java/parquet/column/primitive/PlainColumnReader.java": 1,
                "parquet-column/src/main/java/parquet/column/primitive/PlainColumnWriter.java": 4,
                "parquet-column/src/main/java/parquet/column/primitive/PrimitiveColumnReader.java": 27,
                "parquet-column/src/main/java/parquet/column/primitive/PrimitiveColumnWriter.java": 7,
                "parquet-column/src/main/java/parquet/io/BaseRecordReader.java": 1,
                "parquet-column/src/main/java/parquet/io/RecordReaderImplementation.java": 10,
                "parquet-column/src/main/java/parquet/io/convert/RecordConverter.java": 9,
                "parquet-column/src/main/java/parquet/parser/MessageTypeParser.java": 5,
                "parquet-column/src/main/java/parquet/schema/ConversionPatterns.java": 8,
                "parquet-column/src/main/java/parquet/schema/GroupType.java": 18,
                "parquet-column/src/main/java/parquet/schema/MessageType.java": 24,
                "parquet-column/src/main/java/parquet/schema/PrimitiveType.java": 9,
                "parquet-column/src/main/java/parquet/schema/Type.java": 16,
                "parquet-column/src/test/java/parquet/column/primitive/TestBitPacking.java": 2,
                "parquet-column/src/test/java/parquet/io/TestColumnIO.java": 2,
                "parquet-column/src/test/java/parquet/schema/TestMessageType.java": 15,
                "parquet-hadoop/src/main/java/parquet/format/converter/ParquetMetadataConverter.java": 6,
                "parquet-hadoop/src/main/java/parquet/hadoop/CodecFactory.java": 42,
                "parquet-hadoop/src/main/java/parquet/hadoop/ColumnChunkPageReadStore.java": 57,
                "parquet-hadoop/src/main/java/parquet/hadoop/ColumnChunkPageWriteStore.java": 2,
                "parquet-hadoop/src/main/java/parquet/hadoop/ParquetFileReader.java": 71,
                "parquet-hadoop/src/main/java/parquet/hadoop/ParquetFileWriter.java": 2,
                "parquet-hadoop/src/main/java/parquet/hadoop/ParquetInputFormat.java": 6,
                "parquet-hadoop/src/main/java/parquet/hadoop/ParquetRecordReader.java": 2,
                "parquet-hadoop/src/main/java/parquet/hadoop/metadata/ColumnChunkMetaData.java": 4,
                "parquet-hadoop/src/test/java/parquet/hadoop/TestInputFormat.java": 2,
                "parquet-hadoop/src/test/java/parquet/hadoop/TestParquetFileWriter.java": 10,
                "parquet-pig/src/test/java/parquet/pig/GenerateIntTestFile.java": 2
            },
            "is_test": true,
            "is_fix": false
        },
        "25608ae6eb4088a81a7fe4969409c30ecc81a7a1": {
            "datetime": "2013-03-05T18:04:19-08:00",
            "summary": "cleanup",
            "message": "cleanup\n",
            "diff": {
                "parquet-column/src/main/java/parquet/io/ConverterConsumer.java": 0,
                "parquet-column/src/main/java/parquet/io/MessageColumnIO.java": 4,
                "parquet-column/src/main/java/parquet/io/RecordReaderImplementation.java": 3
            },
            "is_test": false,
            "is_fix": false
        },
        "ca1f11a04355eb7ea268492e9b9508e97f8aaf33": {
            "datetime": "2013-03-05T18:04:31-08:00",
            "summary": "Merge branch 'master' of github.com:Parquet/parquet-mr",
            "message": "Merge branch 'master' of github.com:Parquet/parquet-mr\n",
            "diff": {
                "parquet-column/src/main/java/parquet/bytes/BytesUtils.java": 4,
                "parquet-column/src/main/java/parquet/bytes/LittleEndianDataInputStream.java": 6,
                "parquet-column/src/main/java/parquet/bytes/LittleEndianDataOutputStream.java": 3,
                "parquet-column/src/main/java/parquet/column/ColumnDescriptor.java": 32,
                "parquet-column/src/main/java/parquet/column/ColumnReadStore.java": 5,
                "parquet-column/src/main/java/parquet/column/ColumnReader.java": 25,
                "parquet-column/src/main/java/parquet/column/ColumnWriteStore.java": 8,
                "parquet-column/src/main/java/parquet/column/ColumnWriter.java": 7,
                "parquet-column/src/main/java/parquet/column/UnknownColumnException.java": 5,
                "parquet-column/src/main/java/parquet/column/mem/MemColumnReader.java": 7,
                "parquet-column/src/main/java/parquet/column/mem/MemColumnWriteStore.java": 6,
                "parquet-column/src/main/java/parquet/column/mem/MemColumnWriter.java": 24,
                "parquet-column/src/main/java/parquet/column/mem/MemPageStore.java": 6,
                "parquet-column/src/main/java/parquet/column/mem/PageReadStore.java": 2,
                "parquet-column/src/main/java/parquet/column/primitive/BitPacking.java": 2,
                "parquet-column/src/main/java/parquet/column/primitive/BitPackingColumnReader.java": 5,
                "parquet-column/src/main/java/parquet/column/primitive/BitPackingColumnWriter.java": 8,
                "parquet-column/src/main/java/parquet/column/primitive/BitReader.java": 23,
                "parquet-column/src/main/java/parquet/column/primitive/BitWriter.java": 26,
                "parquet-column/src/main/java/parquet/column/primitive/BooleanPlainColumnReader.java": 4,
                "parquet-column/src/main/java/parquet/column/primitive/BooleanPlainColumnWriter.java": 4,
                "parquet-column/src/main/java/parquet/column/primitive/BoundedColumnFactory.java": 2,
                "parquet-column/src/main/java/parquet/column/primitive/BoundedIntColumnReader.java": 10,
                "parquet-column/src/main/java/parquet/column/primitive/BoundedIntColumnWriter.java": 14,
                "parquet-column/src/main/java/parquet/column/primitive/DevNullColumnReader.java": 8,
                "parquet-column/src/main/java/parquet/column/primitive/DevNullColumnWriter.java": 6,
                "parquet-column/src/main/java/parquet/column/primitive/PlainColumnReader.java": 1,
                "parquet-column/src/main/java/parquet/column/primitive/PlainColumnWriter.java": 4,
                "parquet-column/src/main/java/parquet/column/primitive/PrimitiveColumnReader.java": 27,
                "parquet-column/src/main/java/parquet/column/primitive/PrimitiveColumnWriter.java": 7,
                "parquet-column/src/main/java/parquet/io/BaseRecordReader.java": 1,
                "parquet-column/src/main/java/parquet/io/RecordReaderImplementation.java": 10,
                "parquet-column/src/main/java/parquet/io/convert/RecordConverter.java": 9,
                "parquet-column/src/main/java/parquet/parser/MessageTypeParser.java": 5,
                "parquet-column/src/main/java/parquet/schema/ConversionPatterns.java": 8,
                "parquet-column/src/main/java/parquet/schema/GroupType.java": 18,
                "parquet-column/src/main/java/parquet/schema/MessageType.java": 24,
                "parquet-column/src/main/java/parquet/schema/PrimitiveType.java": 9,
                "parquet-column/src/main/java/parquet/schema/Type.java": 16,
                "parquet-column/src/test/java/parquet/column/primitive/TestBitPacking.java": 2,
                "parquet-column/src/test/java/parquet/io/TestColumnIO.java": 2,
                "parquet-column/src/test/java/parquet/schema/TestMessageType.java": 15,
                "parquet-hadoop/src/main/java/parquet/format/converter/ParquetMetadataConverter.java": 6,
                "parquet-hadoop/src/main/java/parquet/hadoop/CodecFactory.java": 42,
                "parquet-hadoop/src/main/java/parquet/hadoop/ColumnChunkPageReadStore.java": 57,
                "parquet-hadoop/src/main/java/parquet/hadoop/ColumnChunkPageWriteStore.java": 2,
                "parquet-hadoop/src/main/java/parquet/hadoop/ParquetFileReader.java": 71,
                "parquet-hadoop/src/main/java/parquet/hadoop/ParquetFileWriter.java": 2,
                "parquet-hadoop/src/main/java/parquet/hadoop/ParquetInputFormat.java": 6,
                "parquet-hadoop/src/main/java/parquet/hadoop/ParquetRecordReader.java": 2,
                "parquet-hadoop/src/main/java/parquet/hadoop/metadata/ColumnChunkMetaData.java": 4,
                "parquet-hadoop/src/test/java/parquet/hadoop/TestInputFormat.java": 2,
                "parquet-hadoop/src/test/java/parquet/hadoop/TestParquetFileWriter.java": 10,
                "parquet-pig/src/test/java/parquet/pig/GenerateIntTestFile.java": 2
            },
            "is_test": true,
            "is_fix": false
        },
        "b9463550d01f4b0118f725ed957e6e4354b0e4ba": {
            "datetime": "2013-03-06T15:32:07-08:00",
            "summary": "thrift enum and list fixes; ParquetReadToWrite",
            "message": "thrift enum and list fixes; ParquetReadToWrite\n",
            "diff": {
                "parquet-column/src/main/java/parquet/io/Binary.java": 104,
                "parquet-column/src/main/java/parquet/schema/ConversionPatterns.java": 40,
                "parquet-pig/src/main/java/parquet/pig/PigSchemaConverter.java": 43,
                "parquet-thrift/src/main/java/parquet/thrift/ParquetReadToWriteProtocol.java": 122,
                "parquet-thrift/src/main/java/parquet/thrift/ParquetWriteProtocol.java": 22,
                "parquet-thrift/src/main/java/parquet/thrift/ThriftRecordConverter.java": 56,
                "parquet-thrift/src/main/java/parquet/thrift/ThriftSchemaConverter.java": 4,
                "parquet-thrift/src/test/java/parquet/hadoop/thrift/TestParquetReadProtocol.java": 8,
                "parquet-thrift/src/test/java/parquet/hadoop/thrift/TestParquetWriteProtocol.java": 281,
                "parquet-thrift/src/test/java/parquet/hadoop/thrift/TestThriftSchemaConverter.java": 2,
                "parquet-thrift/src/test/java/parquet/thrift/TestParquetReadWriteProtocol.java": 64,
                "parquet-thrift/src/test/java/parquet/thrift/TestParquetWriteProtocol.java": 424
            },
            "is_test": true,
            "is_fix": false
        },
        "5daf06892b533a06fa0d80c83006f84b74e429f8": {
            "datetime": "2013-03-06T17:29:16-08:00",
            "summary": "more thrift bug fixes",
            "message": "more thrift bug fixes\n",
            "diff": {
                "parquet-column/src/main/java/parquet/column/mem/MemColumnReader.java": 3,
                "parquet-column/src/main/java/parquet/column/mem/MemColumnWriter.java": 1,
                "parquet-column/src/main/java/parquet/column/primitive/PrimitiveColumnWriter.java": 14,
                "parquet-column/src/main/java/parquet/io/Binary.java": 13,
                "parquet-thrift/src/main/java/parquet/thrift/ParquetReadToWriteProtocol.java": 4,
                "parquet-thrift/src/main/java/parquet/thrift/ParquetWriteProtocol.java": 4,
                "parquet-thrift/src/main/java/parquet/thrift/ThriftRecordConverter.java": 46,
                "parquet-thrift/src/test/java/parquet/thrift/TestParquetReadProtocol.java": 49,
                "parquet-thrift/src/test/java/parquet/thrift/TestParquetReadWriteProtocol.java": 41,
                "parquet-thrift/src/test/java/parquet/thrift/TestParquetWriteProtocol.java": 65
            },
            "is_test": true,
            "is_fix": false
        },
        "668d74df8addad24ad0bd2e53a23a4ad07e5ad47": {
            "datetime": "2013-03-07T16:55:07-08:00",
            "summary": "exception cleanup; creation of parquet.hadoop.api package; thrift from bytes support; bug fixes",
            "message": "exception cleanup; creation of parquet.hadoop.api package; thrift from bytes support; bug fixes\n",
            "diff": {
                "parquet-hadoop/src/main/java/parquet/hadoop/CodecFactory.java": 4,
                "parquet-hadoop/src/main/java/parquet/hadoop/ColumnChunkPageReadStore.java": 7,
                "parquet-hadoop/src/main/java/parquet/hadoop/ParquetFileWriter.java": 5,
                "parquet-hadoop/src/main/java/parquet/hadoop/ParquetInputFormat.java": 1,
                "parquet-hadoop/src/main/java/parquet/hadoop/ParquetOutputFormat.java": 18,
                "parquet-hadoop/src/main/java/parquet/hadoop/ParquetRecordReader.java": 1,
                "parquet-hadoop/src/main/java/parquet/hadoop/ParquetRecordWriter.java": 3,
                "parquet-hadoop/src/main/java/parquet/hadoop/PrintFooter.java": 3,
                "parquet-hadoop/src/main/java/parquet/hadoop/ReadSupport.java": 7,
                "parquet-hadoop/src/main/java/parquet/hadoop/WriteSupport.java": 4,
                "parquet-hadoop/src/main/java/parquet/hadoop/example/GroupReadSupport.java": 2,
                "parquet-hadoop/src/main/java/parquet/hadoop/example/GroupWriteSupport.java": 4,
                "parquet-hadoop/src/test/java/parquet/hadoop/TestInputFormat.java": 1,
                "parquet-pig/src/main/java/parquet/pig/ParquetLoader.java": 3,
                "parquet-pig/src/main/java/parquet/pig/ParquetStorer.java": 5,
                "parquet-pig/src/main/java/parquet/pig/PigSchemaConverter.java": 6,
                "parquet-pig/src/main/java/parquet/pig/SchemaConversionException.java": 44,
                "parquet-pig/src/main/java/parquet/pig/TupleReadSupport.java": 4,
                "parquet-pig/src/main/java/parquet/pig/TupleWriteSupport.java": 5,
                "parquet-thrift/src/main/java/parquet/hadoop/thrift/ParquetThriftBytesOutputFormat.java": 48,
                "parquet-thrift/src/main/java/parquet/hadoop/thrift/ParquetThriftInputFormat.java": 1,
                "parquet-thrift/src/main/java/parquet/hadoop/thrift/ParquetThriftOutputFormat.java": 4,
                "parquet-thrift/src/main/java/parquet/hadoop/thrift/ThriftBytesWriteSupport.java": 122,
                "parquet-thrift/src/main/java/parquet/hadoop/thrift/ThriftReadSupport.java": 2,
                "parquet-thrift/src/main/java/parquet/hadoop/thrift/ThriftToParquetFileWriter.java": 58,
                "parquet-thrift/src/main/java/parquet/hadoop/thrift/ThriftWriteSupport.java": 10,
                "parquet-thrift/src/main/java/parquet/thrift/ParquetProtocol.java": 9,
                "parquet-thrift/src/main/java/parquet/thrift/ParquetReadProtocol.java": 3,
                "parquet-thrift/src/main/java/parquet/thrift/ParquetReadToWriteProtocol.java": 46,
                "parquet-thrift/src/main/java/parquet/thrift/ParquetWriteProtocol.java": 56,
                "parquet-thrift/src/main/java/parquet/thrift/ThriftSchemaConverter.java": 21,
                "parquet-thrift/src/main/java/parquet/thrift/struct/ThriftType.java": 18,
                "parquet-thrift/src/main/java/parquet/thrift/struct/ThriftTypeID.java": 7,
                "parquet-thrift/src/test/java/parquet/hadoop/thrift/TestThriftToParquetFileWriter.java": 109,
                "parquet-thrift/src/test/java/parquet/thrift/TestParquetReadWriteProtocol.java": 46
            },
            "is_test": true,
            "is_fix": false
        },
        "0703f014894119c2f6b488d821c4409c8c0519e2": {
            "datetime": "2013-03-08T10:36:31-08:00",
            "summary": "Merge pull request #4 from Parquet/thrift_fixes",
            "message": "Merge pull request #4 from Parquet/thrift_fixes\n\nThrift fixes",
            "diff": {
                "parquet-column/src/main/java/parquet/column/mem/MemColumnReader.java": 3,
                "parquet-column/src/main/java/parquet/column/mem/MemColumnWriter.java": 1,
                "parquet-column/src/main/java/parquet/column/primitive/PrimitiveColumnWriter.java": 14,
                "parquet-column/src/main/java/parquet/io/Binary.java": 117,
                "parquet-column/src/main/java/parquet/io/ConverterConsumer.java": 0,
                "parquet-column/src/main/java/parquet/io/MessageColumnIO.java": 4,
                "parquet-column/src/main/java/parquet/io/RecordReaderImplementation.java": 3,
                "parquet-column/src/main/java/parquet/schema/ConversionPatterns.java": 40,
                "parquet-hadoop/src/main/java/parquet/hadoop/CodecFactory.java": 4,
                "parquet-hadoop/src/main/java/parquet/hadoop/ColumnChunkPageReadStore.java": 7,
                "parquet-hadoop/src/main/java/parquet/hadoop/ParquetFileWriter.java": 5,
                "parquet-hadoop/src/main/java/parquet/hadoop/ParquetInputFormat.java": 1,
                "parquet-hadoop/src/main/java/parquet/hadoop/ParquetOutputFormat.java": 18,
                "parquet-hadoop/src/main/java/parquet/hadoop/ParquetRecordReader.java": 1,
                "parquet-hadoop/src/main/java/parquet/hadoop/ParquetRecordWriter.java": 3,
                "parquet-hadoop/src/main/java/parquet/hadoop/PrintFooter.java": 3,
                "parquet-hadoop/src/main/java/parquet/hadoop/ReadSupport.java": 7,
                "parquet-hadoop/src/main/java/parquet/hadoop/WriteSupport.java": 4,
                "parquet-hadoop/src/main/java/parquet/hadoop/example/GroupReadSupport.java": 2,
                "parquet-hadoop/src/main/java/parquet/hadoop/example/GroupWriteSupport.java": 4,
                "parquet-hadoop/src/test/java/parquet/hadoop/TestInputFormat.java": 1,
                "parquet-pig/src/main/java/parquet/pig/ParquetLoader.java": 3,
                "parquet-pig/src/main/java/parquet/pig/ParquetStorer.java": 5,
                "parquet-pig/src/main/java/parquet/pig/PigSchemaConverter.java": 47,
                "parquet-pig/src/main/java/parquet/pig/SchemaConversionException.java": 44,
                "parquet-pig/src/main/java/parquet/pig/TupleReadSupport.java": 4,
                "parquet-pig/src/main/java/parquet/pig/TupleWriteSupport.java": 5,
                "parquet-thrift/src/main/java/parquet/hadoop/thrift/ParquetThriftBytesOutputFormat.java": 48,
                "parquet-thrift/src/main/java/parquet/hadoop/thrift/ParquetThriftInputFormat.java": 1,
                "parquet-thrift/src/main/java/parquet/hadoop/thrift/ParquetThriftOutputFormat.java": 4,
                "parquet-thrift/src/main/java/parquet/hadoop/thrift/ThriftBytesWriteSupport.java": 122,
                "parquet-thrift/src/main/java/parquet/hadoop/thrift/ThriftReadSupport.java": 2,
                "parquet-thrift/src/main/java/parquet/hadoop/thrift/ThriftToParquetFileWriter.java": 58,
                "parquet-thrift/src/main/java/parquet/hadoop/thrift/ThriftWriteSupport.java": 10,
                "parquet-thrift/src/main/java/parquet/thrift/ParquetProtocol.java": 9,
                "parquet-thrift/src/main/java/parquet/thrift/ParquetReadProtocol.java": 3,
                "parquet-thrift/src/main/java/parquet/thrift/ParquetWriteProtocol.java": 86,
                "parquet-thrift/src/main/java/parquet/thrift/ProtocolReadToWrite.java": 140,
                "parquet-thrift/src/main/java/parquet/thrift/ThriftRecordConverter.java": 100,
                "parquet-thrift/src/main/java/parquet/thrift/ThriftSchemaConverter.java": 25,
                "parquet-thrift/src/main/java/parquet/thrift/struct/ThriftType.java": 18,
                "parquet-thrift/src/main/java/parquet/thrift/struct/ThriftTypeID.java": 7,
                "parquet-thrift/src/test/java/parquet/hadoop/thrift/TestParquetReadProtocol.java": 55,
                "parquet-thrift/src/test/java/parquet/hadoop/thrift/TestParquetWriteProtocol.java": 281,
                "parquet-thrift/src/test/java/parquet/hadoop/thrift/TestThriftSchemaConverter.java": 2,
                "parquet-thrift/src/test/java/parquet/hadoop/thrift/TestThriftToParquetFileWriter.java": 109,
                "parquet-thrift/src/test/java/parquet/thrift/TestParquetWriteProtocol.java": 489,
                "parquet-thrift/src/test/java/parquet/thrift/TestProtocolReadToWrite.java": 115
            },
            "is_test": true,
            "is_fix": false
        },
        "45138bb6736ef986f493b2c72fb0e9a61531bee7": {
            "datetime": "2013-03-08T11:22:50-08:00",
            "summary": "integrating feedback from Todd; renaming PrimitiveColumnW/R to ValuesW/R",
            "message": "integrating feedback from Todd; renaming PrimitiveColumnW/R to ValuesW/R\n",
            "diff": {
                "parquet-column/src/main/java/parquet/column/mem/MemColumnReadStore.java": 7,
                "parquet-column/src/main/java/parquet/column/mem/MemColumnReader.java": 26,
                "parquet-column/src/main/java/parquet/column/mem/MemColumnWriteStore.java": 7,
                "parquet-column/src/main/java/parquet/column/mem/MemColumnWriter.java": 27,
                "parquet-column/src/main/java/parquet/column/mem/MemPageReader.java": 4,
                "parquet-column/src/main/java/parquet/column/mem/MemPageStore.java": 7,
                "parquet-column/src/main/java/parquet/column/mem/MemPageWriter.java": 4,
                "parquet-column/src/main/java/parquet/column/mem/Page.java": 2,
                "parquet-column/src/main/java/parquet/column/mem/PageReadStore.java": 2,
                "parquet-column/src/main/java/parquet/column/mem/PageReader.java": 2,
                "parquet-column/src/main/java/parquet/column/mem/PageWriteStore.java": 2,
                "parquet-column/src/main/java/parquet/column/mem/PageWriter.java": 2,
                "parquet-column/src/main/java/parquet/column/primitive/BitPackingColumnReader.java": 10,
                "parquet-column/src/main/java/parquet/column/primitive/BitPackingColumnWriter.java": 14,
                "parquet-column/src/main/java/parquet/column/primitive/BooleanPlainColumnReader.java": 6,
                "parquet-column/src/main/java/parquet/column/primitive/BooleanPlainColumnWriter.java": 2,
                "parquet-column/src/main/java/parquet/column/primitive/BoundedColumnFactory.java": 10,
                "parquet-column/src/main/java/parquet/column/primitive/BoundedIntColumnReader.java": 8,
                "parquet-column/src/main/java/parquet/column/primitive/BoundedIntColumnWriter.java": 8,
                "parquet-column/src/main/java/parquet/column/primitive/DataColumnWriter.java": 2,
                "parquet-column/src/main/java/parquet/column/primitive/DevNullColumnReader.java": 98,
                "parquet-column/src/main/java/parquet/column/primitive/DevNullColumnWriter.java": 2,
                "parquet-column/src/main/java/parquet/column/primitive/PlainColumnReader.java": 6,
                "parquet-column/src/main/java/parquet/column/primitive/PlainColumnWriter.java": 6,
                "parquet-column/src/main/java/parquet/column/primitive/PrimitiveColumnReader.java": 2,
                "parquet-column/src/main/java/parquet/column/primitive/PrimitiveColumnWriter.java": 3,
                "parquet-column/src/main/java/parquet/column/primitive/ZeroIntegerValuesReader.java": 36,
                "parquet-column/src/main/java/parquet/io/MessageColumnIO.java": 4,
                "parquet-column/src/main/java/parquet/io/RecordReaderImplementation.java": 2,
                "parquet-column/src/test/java/parquet/column/mem/TestMemColumn.java": 6,
                "parquet-column/src/test/java/parquet/column/mem/TestMemPageStore.java": 4,
                "parquet-column/src/test/java/parquet/column/primitive/TestBitPackingColumn.java": 4,
                "parquet-column/src/test/java/parquet/column/primitive/TestBoundedColumns.java": 12,
                "parquet-column/src/test/java/parquet/io/PerfTest.java": 4,
                "parquet-column/src/test/java/parquet/io/TestColumnIO.java": 6,
                "parquet-hadoop/src/main/java/parquet/hadoop/ColumnChunkPageReadStore.java": 6,
                "parquet-hadoop/src/main/java/parquet/hadoop/ColumnChunkPageWriteStore.java": 4,
                "parquet-hadoop/src/main/java/parquet/hadoop/ParquetFileReader.java": 4,
                "parquet-hadoop/src/main/java/parquet/hadoop/ParquetRecordReader.java": 2,
                "parquet-hadoop/src/main/java/parquet/hadoop/ParquetRecordWriter.java": 2,
                "parquet-hadoop/src/test/java/parquet/hadoop/TestParquetFileWriter.java": 6,
                "parquet-pig/src/test/java/parquet/pig/GenerateIntTestFile.java": 10,
                "parquet-pig/src/test/java/parquet/pig/GenerateTPCH.java": 4,
                "parquet-pig/src/test/java/parquet/pig/TupleConsumerPerfTest.java": 6,
                "parquet-thrift/src/test/java/parquet/thrift/TestParquetReadProtocol.java": 4
            },
            "is_test": true,
            "is_fix": false
        },
        "6b9366b1978f236f68e8bd8bf555fbdb5c82c8a9": {
            "datetime": "2013-03-08T11:51:25-08:00",
            "summary": "renaming classes and packages based on feedback",
            "message": "renaming classes and packages based on feedback\n",
            "diff": {
                "parquet-column/src/main/java/parquet/column/Encoding.java": 6,
                "parquet-column/src/main/java/parquet/column/MemColumnReadStore.java": 23,
                "parquet-column/src/main/java/parquet/column/MemColumnReader.java": 22,
                "parquet-column/src/main/java/parquet/column/MemColumnWriteStore.java": 35,
                "parquet-column/src/main/java/parquet/column/MemColumnWriter.java": 24,
                "parquet-column/src/main/java/parquet/column/page/mem/MemPageReader.java": 0,
                "parquet-column/src/main/java/parquet/column/page/mem/MemPageStore.java": 0,
                "parquet-column/src/main/java/parquet/column/page/mem/MemPageWriter.java": 0,
                "parquet-column/src/main/java/parquet/column/primitive/BitPacking.java": 6,
                "parquet-column/src/main/java/parquet/column/primitive/BitPackingValuesReader.java": 11,
                "parquet-column/src/main/java/parquet/column/primitive/BitPackingValuesWriter.java": 17,
                "parquet-column/src/main/java/parquet/column/primitive/BitReader.java": 2,
                "parquet-column/src/main/java/parquet/column/primitive/BitWriter.java": 2,
                "parquet-column/src/main/java/parquet/column/primitive/BooleanPlainColumnReader.java": 15,
                "parquet-column/src/main/java/parquet/column/primitive/BooleanPlainColumnWriter.java": 13,
                "parquet-column/src/main/java/parquet/column/primitive/BoundedIntValuesFactory.java": 5,
                "parquet-column/src/main/java/parquet/column/primitive/BoundedIntValuesReader.java": 3,
                "parquet-column/src/main/java/parquet/column/primitive/BoundedIntValuesWriter.java": 4,
                "parquet-column/src/main/java/parquet/column/primitive/DataValuesWriter.java": 2,
                "parquet-column/src/main/java/parquet/column/primitive/DevNullValuesWriter.java": 3,
                "parquet-column/src/main/java/parquet/column/primitive/PlainValuesReader.java": 5,
                "parquet-column/src/main/java/parquet/column/primitive/PlainValuesWriter.java": 3,
                "parquet-column/src/main/java/parquet/column/primitive/ValuesReader.java": 2,
                "parquet-column/src/main/java/parquet/column/primitive/ValuesWriter.java": 2,
                "parquet-column/src/main/java/parquet/column/primitive/ZeroIntegerValuesReader.java": 4,
                "parquet-column/src/main/java/parquet/io/MessageColumnIO.java": 4,
                "parquet-column/src/main/java/parquet/io/RecordReaderImplementation.java": 4,
                "parquet-column/src/test/java/parquet/column/mem/TestMemColumn.java": 20,
                "parquet-column/src/test/java/parquet/column/primitive/TestBitPacking.java": 6,
                "parquet-column/src/test/java/parquet/column/primitive/TestBitPackingColumn.java": 3,
                "parquet-column/src/test/java/parquet/column/primitive/TestBoundedColumns.java": 6,
                "parquet-column/src/test/java/parquet/io/PerfTest.java": 4,
                "parquet-column/src/test/java/parquet/io/TestColumnIO.java": 6,
                "parquet-hadoop/src/main/java/parquet/hadoop/ParquetRecordWriter.java": 6,
                "parquet-pig/src/test/java/parquet/pig/GenerateIntTestFile.java": 4,
                "parquet-pig/src/test/java/parquet/pig/GenerateTPCH.java": 4,
                "parquet-pig/src/test/java/parquet/pig/TupleConsumerPerfTest.java": 6,
                "parquet-thrift/src/test/java/parquet/thrift/TestParquetReadProtocol.java": 4
            },
            "is_test": true,
            "is_fix": false
        },
        "e0dc2f324e555d3fe46665f2c02530b55a3d0060": {
            "datetime": "2013-03-08T12:14:18-08:00",
            "summary": "reorganizing packages and deleting old classes",
            "message": "reorganizing packages and deleting old classes\n",
            "diff": {
                "parquet-column/src/main/java/parquet/column/ColumnReader.java": 2,
                "parquet-column/src/main/java/parquet/column/ColumnWriter.java": 2,
                "parquet-column/src/main/java/parquet/column/impl/ColumnReadStoreImpl.java": 2,
                "parquet-column/src/main/java/parquet/column/impl/ColumnReaderImpl.java": 2,
                "parquet-column/src/main/java/parquet/column/impl/ColumnWriterImpl.java": 2,
                "parquet-column/src/main/java/parquet/column/values/ValuesReader.java": 2,
                "parquet-column/src/main/java/parquet/column/values/ValuesWriter.java": 2,
                "parquet-column/src/main/java/parquet/column/values/boundedint/DevNullValuesWriter.java": 2,
                "parquet-column/src/main/java/parquet/column/values/plain/PlainValuesReader.java": 2,
                "parquet-column/src/main/java/parquet/column/values/plain/PlainValuesWriter.java": 2,
                "parquet-column/src/main/java/parquet/example/DummyRecordConverter.java": 10,
                "parquet-column/src/main/java/parquet/example/data/Group.java": 4,
                "parquet-column/src/main/java/parquet/example/data/GroupRecordConsumer.java": 105,
                "parquet-column/src/main/java/parquet/example/data/GroupValueSource.java": 2,
                "parquet-column/src/main/java/parquet/example/data/GroupWriter.java": 2,
                "parquet-column/src/main/java/parquet/example/data/simple/BinaryValue.java": 4,
                "parquet-column/src/main/java/parquet/example/data/simple/BooleanValue.java": 2,
                "parquet-column/src/main/java/parquet/example/data/simple/DoubleValue.java": 2,
                "parquet-column/src/main/java/parquet/example/data/simple/FloatValue.java": 2,
                "parquet-column/src/main/java/parquet/example/data/simple/IntegerValue.java": 2,
                "parquet-column/src/main/java/parquet/example/data/simple/LongValue.java": 2,
                "parquet-column/src/main/java/parquet/example/data/simple/Primitive.java": 4,
                "parquet-column/src/main/java/parquet/example/data/simple/SimpleGroup.java": 4,
                "parquet-column/src/main/java/parquet/example/data/simple/convert/GroupRecordConverter.java": 6,
                "parquet-column/src/main/java/parquet/example/data/simple/convert/SimpleGroupConverter.java": 4,
                "parquet-column/src/main/java/parquet/example/data/simple/convert/SimplePrimitiveConverter.java": 16,
                "parquet-column/src/main/java/parquet/io/BaseRecordReader.java": 6,
                "parquet-column/src/main/java/parquet/io/Binary.java": 2,
                "parquet-column/src/main/java/parquet/io/MessageColumnIO.java": 6,
                "parquet-column/src/main/java/parquet/io/RecordConsumer.java": 7,
                "parquet-column/src/main/java/parquet/io/RecordConsumerLoggingWrapper.java": 2,
                "parquet-column/src/main/java/parquet/io/RecordMaterializer.java": 34,
                "parquet-column/src/main/java/parquet/io/RecordReaderImplementation.java": 20,
                "parquet-column/src/main/java/parquet/io/ValidatingRecordConsumer.java": 4,
                "parquet-column/src/main/java/parquet/io/convert/Converter.java": 2,
                "parquet-column/src/main/java/parquet/io/convert/GroupConverter.java": 22,
                "parquet-column/src/main/java/parquet/io/convert/PrimitiveConverter.java": 25,
                "parquet-column/src/main/java/parquet/io/convert/RecordConverter.java": 4,
                "parquet-column/src/main/java/parquet/parser/MessageTypeParser.java": 7,
                "parquet-column/src/main/java/parquet/schema/PrimitiveType.java": 4,
                "parquet-column/src/test/java/parquet/column/mem/TestMemColumn.java": 4,
                "parquet-column/src/test/java/parquet/io/ConverterConsumer.java": 6,
                "parquet-column/src/test/java/parquet/io/ExpectationValidatingConverter.java": 11,
                "parquet-column/src/test/java/parquet/io/ExpectationValidatingRecordConsumer.java": 9,
                "parquet-column/src/test/java/parquet/io/PerfTest.java": 4,
                "parquet-column/src/test/java/parquet/io/TestColumnIO.java": 15,
                "parquet-column/src/test/java/parquet/parser/TestParquetParser.java": 2,
                "parquet-column/src/test/java/parquet/schema/TestMessageType.java": 1,
                "parquet-hadoop/src/main/java/parquet/hadoop/ParquetInputFormat.java": 2,
                "parquet-hadoop/src/main/java/parquet/hadoop/ParquetRecordReader.java": 6,
                "parquet-hadoop/src/main/java/parquet/hadoop/api/ReadSupport.java": 4,
                "parquet-hadoop/src/main/java/parquet/hadoop/api/WriteSupport.java": 2,
                "parquet-hadoop/src/main/java/parquet/hadoop/example/GroupReadSupport.java": 4,
                "parquet-hadoop/src/main/java/parquet/hadoop/example/GroupWriteSupport.java": 4,
                "parquet-hadoop/src/test/java/parquet/hadoop/TestParquetFileWriter.java": 2,
                "parquet-hadoop/src/test/java/parquet/hadoop/example/TestInputOutputFormat.java": 2,
                "parquet-pig/src/main/java/parquet/pig/PigMetaData.java": 9,
                "parquet-pig/src/main/java/parquet/pig/TupleReadSupport.java": 5,
                "parquet-pig/src/main/java/parquet/pig/TupleRecordConsumer.java": 234,
                "parquet-pig/src/main/java/parquet/pig/TupleWriteSupport.java": 7,
                "parquet-pig/src/main/java/parquet/pig/convert/MapConverter.java": 8,
                "parquet-pig/src/main/java/parquet/pig/convert/TupleConverter.java": 8,
                "parquet-pig/src/main/java/parquet/pig/convert/TupleRecordConverter.java": 6,
                "parquet-pig/src/test/java/parquet/pig/GenerateIntTestFile.java": 2,
                "parquet-pig/src/test/java/parquet/pig/GenerateTPCH.java": 4,
                "parquet-pig/src/test/java/parquet/pig/TestPigSchemaConverter.java": 2,
                "parquet-pig/src/test/java/parquet/pig/TestTupleRecordConsumer.java": 10,
                "parquet-pig/src/test/java/parquet/pig/TupleConsumerPerfTest.java": 15,
                "parquet-thrift/src/main/java/parquet/hadoop/thrift/ThriftBytesWriteSupport.java": 2,
                "parquet-thrift/src/main/java/parquet/hadoop/thrift/ThriftReadSupport.java": 4,
                "parquet-thrift/src/main/java/parquet/hadoop/thrift/ThriftWriteSupport.java": 2,
                "parquet-thrift/src/main/java/parquet/thrift/ParquetWriteProtocol.java": 4,
                "parquet-thrift/src/main/java/parquet/thrift/ThriftRecordConverter.java": 16,
                "parquet-thrift/src/test/java/parquet/thrift/TestParquetReadProtocol.java": 2,
                "parquet-thrift/src/test/java/parquet/thrift/TestThriftSchemaConverter.java": 2
            },
            "is_test": true,
            "is_fix": false
        },
        "63949a321cda2c03f3b54ae74589c4b43d439ffa": {
            "datetime": "2013-03-08T13:35:22-08:00",
            "summary": "Merge pull request #7 from Parquet/renaming_classes",
            "message": "Merge pull request #7 from Parquet/renaming_classes\n\nRenaming and moving classes",
            "diff": {
                "parquet-column/src/main/java/parquet/column/ColumnReader.java": 2,
                "parquet-column/src/main/java/parquet/column/ColumnWriter.java": 2,
                "parquet-column/src/main/java/parquet/column/Encoding.java": 6,
                "parquet-column/src/main/java/parquet/column/mem/MemColumnReadStore.java": 24,
                "parquet-column/src/main/java/parquet/column/mem/MemColumnReader.java": 36,
                "parquet-column/src/main/java/parquet/column/mem/MemColumnWriteStore.java": 34,
                "parquet-column/src/main/java/parquet/column/mem/MemColumnWriter.java": 37,
                "parquet-column/src/main/java/parquet/column/mem/MemPageReader.java": 4,
                "parquet-column/src/main/java/parquet/column/mem/MemPageStore.java": 7,
                "parquet-column/src/main/java/parquet/column/mem/MemPageWriter.java": 4,
                "parquet-column/src/main/java/parquet/column/mem/Page.java": 2,
                "parquet-column/src/main/java/parquet/column/mem/PageReadStore.java": 2,
                "parquet-column/src/main/java/parquet/column/mem/PageReader.java": 2,
                "parquet-column/src/main/java/parquet/column/mem/PageWriteStore.java": 2,
                "parquet-column/src/main/java/parquet/column/mem/PageWriter.java": 2,
                "parquet-column/src/main/java/parquet/column/primitive/BitPacking.java": 6,
                "parquet-column/src/main/java/parquet/column/primitive/BitPackingColumnReader.java": 17,
                "parquet-column/src/main/java/parquet/column/primitive/BitPackingColumnWriter.java": 21,
                "parquet-column/src/main/java/parquet/column/primitive/BitReader.java": 2,
                "parquet-column/src/main/java/parquet/column/primitive/BitWriter.java": 2,
                "parquet-column/src/main/java/parquet/column/primitive/BooleanPlainColumnReader.java": 15,
                "parquet-column/src/main/java/parquet/column/primitive/BooleanPlainColumnWriter.java": 13,
                "parquet-column/src/main/java/parquet/column/primitive/BoundedColumnFactory.java": 26,
                "parquet-column/src/main/java/parquet/column/primitive/BoundedIntColumnReader.java": 11,
                "parquet-column/src/main/java/parquet/column/primitive/BoundedIntColumnWriter.java": 12,
                "parquet-column/src/main/java/parquet/column/primitive/DataColumnWriter.java": 4,
                "parquet-column/src/main/java/parquet/column/primitive/DevNullColumnReader.java": 98,
                "parquet-column/src/main/java/parquet/column/primitive/DevNullColumnWriter.java": 7,
                "parquet-column/src/main/java/parquet/column/primitive/PlainColumnReader.java": 11,
                "parquet-column/src/main/java/parquet/column/primitive/PlainColumnWriter.java": 11,
                "parquet-column/src/main/java/parquet/column/primitive/PrimitiveColumnReader.java": 6,
                "parquet-column/src/main/java/parquet/column/primitive/PrimitiveColumnWriter.java": 7,
                "parquet-column/src/main/java/parquet/column/values/boundedint/BoundedIntValuesFactory.java": 29,
                "parquet-column/src/main/java/parquet/column/values/boundedint/ZeroIntegerValuesReader.java": 38,
                "parquet-column/src/main/java/parquet/example/DummyRecordConverter.java": 10,
                "parquet-column/src/main/java/parquet/example/data/Group.java": 4,
                "parquet-column/src/main/java/parquet/example/data/GroupRecordConsumer.java": 105,
                "parquet-column/src/main/java/parquet/example/data/GroupValueSource.java": 2,
                "parquet-column/src/main/java/parquet/example/data/GroupWriter.java": 2,
                "parquet-column/src/main/java/parquet/example/data/simple/BinaryValue.java": 4,
                "parquet-column/src/main/java/parquet/example/data/simple/BooleanValue.java": 2,
                "parquet-column/src/main/java/parquet/example/data/simple/DoubleValue.java": 2,
                "parquet-column/src/main/java/parquet/example/data/simple/FloatValue.java": 2,
                "parquet-column/src/main/java/parquet/example/data/simple/IntegerValue.java": 2,
                "parquet-column/src/main/java/parquet/example/data/simple/LongValue.java": 2,
                "parquet-column/src/main/java/parquet/example/data/simple/Primitive.java": 4,
                "parquet-column/src/main/java/parquet/example/data/simple/SimpleGroup.java": 4,
                "parquet-column/src/main/java/parquet/example/data/simple/convert/GroupRecordConverter.java": 6,
                "parquet-column/src/main/java/parquet/example/data/simple/convert/SimpleGroupConverter.java": 4,
                "parquet-column/src/main/java/parquet/example/data/simple/convert/SimplePrimitiveConverter.java": 16,
                "parquet-column/src/main/java/parquet/io/BaseRecordReader.java": 6,
                "parquet-column/src/main/java/parquet/io/Binary.java": 2,
                "parquet-column/src/main/java/parquet/io/MessageColumnIO.java": 12,
                "parquet-column/src/main/java/parquet/io/RecordConsumer.java": 7,
                "parquet-column/src/main/java/parquet/io/RecordConsumerLoggingWrapper.java": 2,
                "parquet-column/src/main/java/parquet/io/RecordMaterializer.java": 34,
                "parquet-column/src/main/java/parquet/io/RecordReaderImplementation.java": 22,
                "parquet-column/src/main/java/parquet/io/ValidatingRecordConsumer.java": 4,
                "parquet-column/src/main/java/parquet/io/convert/Converter.java": 2,
                "parquet-column/src/main/java/parquet/io/convert/GroupConverter.java": 22,
                "parquet-column/src/main/java/parquet/io/convert/PrimitiveConverter.java": 25,
                "parquet-column/src/main/java/parquet/io/convert/RecordConverter.java": 4,
                "parquet-column/src/main/java/parquet/parser/MessageTypeParser.java": 7,
                "parquet-column/src/main/java/parquet/schema/PrimitiveType.java": 4,
                "parquet-column/src/test/java/parquet/column/mem/TestMemColumn.java": 26,
                "parquet-column/src/test/java/parquet/column/mem/TestMemPageStore.java": 4,
                "parquet-column/src/test/java/parquet/column/primitive/TestBitPacking.java": 6,
                "parquet-column/src/test/java/parquet/column/primitive/TestBitPackingColumn.java": 7,
                "parquet-column/src/test/java/parquet/column/primitive/TestBoundedColumns.java": 14,
                "parquet-column/src/test/java/parquet/io/ConverterConsumer.java": 6,
                "parquet-column/src/test/java/parquet/io/ExpectationValidatingConverter.java": 11,
                "parquet-column/src/test/java/parquet/io/ExpectationValidatingRecordConsumer.java": 9,
                "parquet-column/src/test/java/parquet/io/PerfTest.java": 10,
                "parquet-column/src/test/java/parquet/io/TestColumnIO.java": 25,
                "parquet-column/src/test/java/parquet/parser/TestParquetParser.java": 2,
                "parquet-column/src/test/java/parquet/schema/TestMessageType.java": 1,
                "parquet-hadoop/src/main/java/parquet/hadoop/ColumnChunkPageReadStore.java": 6,
                "parquet-hadoop/src/main/java/parquet/hadoop/ColumnChunkPageWriteStore.java": 4,
                "parquet-hadoop/src/main/java/parquet/hadoop/ParquetFileReader.java": 4,
                "parquet-hadoop/src/main/java/parquet/hadoop/ParquetInputFormat.java": 2,
                "parquet-hadoop/src/main/java/parquet/hadoop/ParquetRecordReader.java": 8,
                "parquet-hadoop/src/main/java/parquet/hadoop/ParquetRecordWriter.java": 6,
                "parquet-hadoop/src/main/java/parquet/hadoop/api/ReadSupport.java": 4,
                "parquet-hadoop/src/main/java/parquet/hadoop/api/WriteSupport.java": 2,
                "parquet-hadoop/src/main/java/parquet/hadoop/example/GroupReadSupport.java": 4,
                "parquet-hadoop/src/main/java/parquet/hadoop/example/GroupWriteSupport.java": 4,
                "parquet-hadoop/src/test/java/parquet/hadoop/TestParquetFileWriter.java": 8,
                "parquet-hadoop/src/test/java/parquet/hadoop/example/TestInputOutputFormat.java": 2,
                "parquet-pig/src/main/java/parquet/pig/PigMetaData.java": 9,
                "parquet-pig/src/main/java/parquet/pig/TupleReadSupport.java": 5,
                "parquet-pig/src/main/java/parquet/pig/TupleRecordConsumer.java": 234,
                "parquet-pig/src/main/java/parquet/pig/TupleWriteSupport.java": 7,
                "parquet-pig/src/main/java/parquet/pig/convert/MapConverter.java": 8,
                "parquet-pig/src/main/java/parquet/pig/convert/TupleConverter.java": 8,
                "parquet-pig/src/main/java/parquet/pig/convert/TupleRecordConverter.java": 6,
                "parquet-pig/src/test/java/parquet/pig/GenerateIntTestFile.java": 14,
                "parquet-pig/src/test/java/parquet/pig/GenerateTPCH.java": 10,
                "parquet-pig/src/test/java/parquet/pig/TestPigSchemaConverter.java": 2,
                "parquet-pig/src/test/java/parquet/pig/TestTupleRecordConsumer.java": 10,
                "parquet-pig/src/test/java/parquet/pig/TupleConsumerPerfTest.java": 25,
                "parquet-thrift/src/main/java/parquet/hadoop/thrift/ThriftBytesWriteSupport.java": 2,
                "parquet-thrift/src/main/java/parquet/hadoop/thrift/ThriftReadSupport.java": 4,
                "parquet-thrift/src/main/java/parquet/hadoop/thrift/ThriftWriteSupport.java": 2,
                "parquet-thrift/src/main/java/parquet/thrift/ParquetWriteProtocol.java": 4,
                "parquet-thrift/src/main/java/parquet/thrift/ThriftRecordConverter.java": 16,
                "parquet-thrift/src/test/java/parquet/thrift/TestParquetReadProtocol.java": 8,
                "parquet-thrift/src/test/java/parquet/thrift/TestThriftSchemaConverter.java": 2
            },
            "is_test": true,
            "is_fix": false
        },
        "6e33c3d317965c8a26a98b79e6595a6b2062beb4": {
            "datetime": "2013-03-08T14:35:12-08:00",
            "summary": "fix Filesystem access issues mentioned by Dmitriy",
            "message": "fix Filesystem access issues mentioned by Dmitriy\n",
            "diff": {
                "parquet-hadoop/src/main/java/parquet/hadoop/ParquetFileReader.java": 6
            },
            "is_test": false,
            "is_fix": false
        },
        "5a52fe124ab877876f5c884ee295d14d6573bd7d": {
            "datetime": "2013-03-08T17:56:43-08:00",
            "summary": "fix Filesystem access issues mentioned by Dmitriy",
            "message": "fix Filesystem access issues mentioned by Dmitriy\n",
            "diff": {
                "parquet-hadoop/src/main/java/parquet/hadoop/ParquetInputFormat.java": 8
            },
            "is_test": false,
            "is_fix": false
        },
        "12b99b1a78478999ef8da2c5617d65a5b0e687ac": {
            "datetime": "2013-03-11T08:25:52-07:00",
            "summary": "metadata file in parquet format",
            "message": "metadata file in parquet format\n",
            "diff": {
                "parquet-hadoop/src/main/java/parquet/format/converter/ParquetMetadataConverter.java": 9,
                "parquet-hadoop/src/main/java/parquet/hadoop/ParquetFileReader.java": 33,
                "parquet-hadoop/src/main/java/parquet/hadoop/ParquetFileWriter.java": 72,
                "parquet-hadoop/src/main/java/parquet/hadoop/PrintFooter.java": 4,
                "parquet-hadoop/src/main/java/parquet/hadoop/metadata/BlockMetaData.java": 16,
                "parquet-hadoop/src/main/java/parquet/hadoop/metadata/FileMetaData.java": 8
            },
            "is_test": false,
            "is_fix": false
        },
        "251855be5bf1000d00371f4be7a04f3c83b438e4": {
            "datetime": "2013-03-11T09:49:42-07:00",
            "summary": "better metadata file tests",
            "message": "better metadata file tests\n",
            "diff": {
                "parquet-hadoop/src/test/java/parquet/hadoop/TestParquetFileWriter.java": 63,
                "parquet-hadoop/src/test/java/parquet/hadoop/example/TestInputOutputFormat.java": 9
            },
            "is_test": true,
            "is_fix": false
        },
        "dfd872b669c80ee2954ca77dbb95a019667d4f55": {
            "datetime": "2013-03-11T10:14:56-07:00",
            "summary": "javadoc",
            "message": "javadoc\n",
            "diff": {
                "parquet-pig/src/main/java/parquet/pig/ParquetLoader.java": 15
            },
            "is_test": false,
            "is_fix": false
        },
        "a4c107e78e24455702e73ff431a72d24f4402d12": {
            "datetime": "2013-03-11T12:17:32-07:00",
            "summary": "Updated file description.",
            "message": "Updated file description.\n",
            "diff": {
                "dev/merge_parquet_pr.py": 393,
                "parquet-arrow/src/main/java/org/apache/parquet/arrow/schema/List3Levels.java": 77,
                "parquet-arrow/src/main/java/org/apache/parquet/arrow/schema/SchemaConverter.java": 705,
                "parquet-arrow/src/main/java/org/apache/parquet/arrow/schema/SchemaMapping.java": 201,
                "parquet-arrow/src/test/java/org/apache/parquet/arrow/schema/TestSchemaConverter.java": 530,
                "parquet-avro/src/main/java/org/apache/parquet/avro/AvroCompatRecordMaterializer.java": 46,
                "parquet-avro/src/main/java/org/apache/parquet/avro/AvroConverters.java": 333,
                "parquet-avro/src/main/java/org/apache/parquet/avro/AvroDataSupplier.java": 31,
                "parquet-avro/src/main/java/org/apache/parquet/avro/AvroIndexedRecordConverter.java": 535,
                "parquet-avro/src/main/java/org/apache/parquet/avro/AvroParquetInputFormat.java": 86,
                "parquet-avro/src/main/java/org/apache/parquet/avro/AvroParquetOutputFormat.java": 63,
                "parquet-avro/src/main/java/org/apache/parquet/avro/AvroParquetReader.java": 178,
                "parquet-avro/src/main/java/org/apache/parquet/avro/AvroParquetWriter.java": 193,
                "parquet-avro/src/main/java/org/apache/parquet/avro/AvroReadSupport.java": 180,
                "parquet-avro/src/main/java/org/apache/parquet/avro/AvroRecordConverter.java": 1093,
                "parquet-avro/src/main/java/org/apache/parquet/avro/AvroRecordMaterializer.java": 45,
                "parquet-avro/src/main/java/org/apache/parquet/avro/AvroSchemaConverter.java": 565,
                "parquet-avro/src/main/java/org/apache/parquet/avro/AvroWriteSupport.java": 711,
                "parquet-avro/src/main/java/org/apache/parquet/avro/GenericDataSupplier.java": 28,
                "parquet-avro/src/main/java/org/apache/parquet/avro/ParentValueContainer.java": 238,
                "parquet-avro/src/main/java/org/apache/parquet/avro/ReflectDataSupplier.java": 29,
                "parquet-avro/src/main/java/org/apache/parquet/avro/SpecificDataSupplier.java": 29,
                "parquet-avro/src/main/java/org/apache/parquet/avro/package-info.java": 174,
                "parquet-avro/src/test/java/org/apache/parquet/avro/AvroTestUtil.java": 136,
                "parquet-avro/src/test/java/org/apache/parquet/avro/TestArrayCompatibility.java": 1164,
                "parquet-avro/src/test/java/org/apache/parquet/avro/TestAvroDataSupplier.java": 43,
                "parquet-avro/src/test/java/org/apache/parquet/avro/TestAvroRecordConverter.java": 202,
                "parquet-avro/src/test/java/org/apache/parquet/avro/TestAvroSchemaConverter.java": 942,
                "parquet-avro/src/test/java/org/apache/parquet/avro/TestAvroWriteSupport.java": 61,
                "parquet-avro/src/test/java/org/apache/parquet/avro/TestBackwardCompatibility.java": 68,
                "parquet-avro/src/test/java/org/apache/parquet/avro/TestByteStreamSplitE2E.java": 114,
                "parquet-avro/src/test/java/org/apache/parquet/avro/TestCircularReferences.java": 387,
                "parquet-avro/src/test/java/org/apache/parquet/avro/TestGenericLogicalTypes.java": 296,
                "parquet-avro/src/test/java/org/apache/parquet/avro/TestInputOutputFormat.java": 145,
                "parquet-avro/src/test/java/org/apache/parquet/avro/TestReadWrite.java": 900,
                "parquet-avro/src/test/java/org/apache/parquet/avro/TestReadWriteOldListBehavior.java": 584,
                "parquet-avro/src/test/java/org/apache/parquet/avro/TestReflectInputOutputFormat.java": 496,
                "parquet-avro/src/test/java/org/apache/parquet/avro/TestReflectLogicalTypes.java": 999,
                "parquet-avro/src/test/java/org/apache/parquet/avro/TestReflectReadWrite.java": 240,
                "parquet-avro/src/test/java/org/apache/parquet/avro/TestSpecificInputOutputFormat.java": 287,
                "parquet-avro/src/test/java/org/apache/parquet/avro/TestSpecificReadWrite.java": 360,
                "parquet-avro/src/test/java/org/apache/parquet/avro/TestStringBehavior.java": 330,
                "parquet-benchmarks/src/main/java/org/apache/parquet/benchmarks/BenchmarkConstants.java": 42,
                "parquet-benchmarks/src/main/java/org/apache/parquet/benchmarks/BenchmarkFiles.java": 64,
                "parquet-benchmarks/src/main/java/org/apache/parquet/benchmarks/BenchmarkUtils.java": 46,
                "parquet-benchmarks/src/main/java/org/apache/parquet/benchmarks/DataGenerator.java": 137,
                "parquet-benchmarks/src/main/java/org/apache/parquet/benchmarks/FilteringBenchmarks.java": 430,
                "parquet-benchmarks/src/main/java/org/apache/parquet/benchmarks/NestedNullWritingBenchmarks.java": 156,
                "parquet-benchmarks/src/main/java/org/apache/parquet/benchmarks/PageChecksumDataGenerator.java": 106,
                "parquet-benchmarks/src/main/java/org/apache/parquet/benchmarks/PageChecksumReadBenchmarks.java": 196,
                "parquet-benchmarks/src/main/java/org/apache/parquet/benchmarks/PageChecksumWriteBenchmarks.java": 178,
                "parquet-benchmarks/src/main/java/org/apache/parquet/benchmarks/ReadBenchmarks.java": 131,
                "parquet-benchmarks/src/main/java/org/apache/parquet/benchmarks/WriteBenchmarks.java": 168,
                "parquet-cli/src/main/java/org/apache/parquet/cli/BaseCommand.java": 428,
                "parquet-cli/src/main/java/org/apache/parquet/cli/Command.java": 40,
                "parquet-cli/src/main/java/org/apache/parquet/cli/HadoopFileSystemURLStreamHandler.java": 79,
                "parquet-cli/src/main/java/org/apache/parquet/cli/Help.java": 153,
                "parquet-cli/src/main/java/org/apache/parquet/cli/Main.java": 196,
                "parquet-cli/src/main/java/org/apache/parquet/cli/Util.java": 272,
                "parquet-cli/src/main/java/org/apache/parquet/cli/commands/CSVSchemaCommand.java": 131,
                "parquet-cli/src/main/java/org/apache/parquet/cli/commands/CatCommand.java": 106,
                "parquet-cli/src/main/java/org/apache/parquet/cli/commands/CheckParquet251Command.java": 352,
                "parquet-cli/src/main/java/org/apache/parquet/cli/commands/ColumnMaskingCommand.java": 115,
                "parquet-cli/src/main/java/org/apache/parquet/cli/commands/ColumnSizeCommand.java": 137,
                "parquet-cli/src/main/java/org/apache/parquet/cli/commands/ConvertCSVCommand.java": 204,
                "parquet-cli/src/main/java/org/apache/parquet/cli/commands/ConvertCommand.java": 165,
                "parquet-cli/src/main/java/org/apache/parquet/cli/commands/ParquetMetadataCommand.java": 183,
                "parquet-cli/src/main/java/org/apache/parquet/cli/commands/PruneColumnsCommand.java": 82,
                "parquet-cli/src/main/java/org/apache/parquet/cli/commands/RewriteCommand.java": 131,
                "parquet-cli/src/main/java/org/apache/parquet/cli/commands/ScanCommand.java": 91,
                "parquet-cli/src/main/java/org/apache/parquet/cli/commands/SchemaCommand.java": 132,
                "parquet-cli/src/main/java/org/apache/parquet/cli/commands/ShowBloomFilterCommand.java": 133,
                "parquet-cli/src/main/java/org/apache/parquet/cli/commands/ShowColumnIndexCommand.java": 157,
                "parquet-cli/src/main/java/org/apache/parquet/cli/commands/ShowDictionaryCommand.java": 139,
                "parquet-cli/src/main/java/org/apache/parquet/cli/commands/ShowFooterCommand.java": 101,
                "parquet-cli/src/main/java/org/apache/parquet/cli/commands/ShowPagesCommand.java": 234,
                "parquet-cli/src/main/java/org/apache/parquet/cli/commands/ToAvroCommand.java": 134,
                "parquet-cli/src/main/java/org/apache/parquet/cli/commands/TransCompressionCommand.java": 101,
                "parquet-cli/src/main/java/org/apache/parquet/cli/csv/AvroCSV.java": 258,
                "parquet-cli/src/main/java/org/apache/parquet/cli/csv/AvroCSVReader.java": 121,
                "parquet-cli/src/main/java/org/apache/parquet/cli/csv/CSVProperties.java": 120,
                "parquet-cli/src/main/java/org/apache/parquet/cli/csv/RecordBuilder.java": 200,
                "parquet-cli/src/main/java/org/apache/parquet/cli/json/AvroJson.java": 631,
                "parquet-cli/src/main/java/org/apache/parquet/cli/json/AvroJsonReader.java": 77,
                "parquet-cli/src/main/java/org/apache/parquet/cli/rawpages/RawPagesReader.java": 92,
                "parquet-cli/src/main/java/org/apache/parquet/cli/util/Codecs.java": 52,
                "parquet-cli/src/main/java/org/apache/parquet/cli/util/Expressions.java": 395,
                "parquet-cli/src/main/java/org/apache/parquet/cli/util/Formats.java": 47,
                "parquet-cli/src/main/java/org/apache/parquet/cli/util/GetClassLoader.java": 39,
                "parquet-cli/src/main/java/org/apache/parquet/cli/util/RawUtils.java": 85,
                "parquet-cli/src/main/java/org/apache/parquet/cli/util/RecordException.java": 55,
                "parquet-cli/src/main/java/org/apache/parquet/cli/util/RuntimeIOException.java": 31,
                "parquet-cli/src/main/java/org/apache/parquet/cli/util/Schemas.java": 501,
                "parquet-cli/src/main/java/org/apache/parquet/cli/util/SeekableFSDataInputStream.java": 76,
                "parquet-cli/src/test/java/org/apache/parquet/cli/BaseCommandTest.java": 100,
                "parquet-cli/src/test/java/org/apache/parquet/cli/MainTest.java": 34,
                "parquet-cli/src/test/java/org/apache/parquet/cli/commands/AvroFileTest.java": 53,
                "parquet-cli/src/test/java/org/apache/parquet/cli/commands/CSVFileTest.java": 51,
                "parquet-cli/src/test/java/org/apache/parquet/cli/commands/CSVSchemaCommandTest.java": 39,
                "parquet-cli/src/test/java/org/apache/parquet/cli/commands/CatCommandTest.java": 38,
                "parquet-cli/src/test/java/org/apache/parquet/cli/commands/CheckParquet251CommandTest.java": 38,
                "parquet-cli/src/test/java/org/apache/parquet/cli/commands/ColumnSizeCommandTest.java": 91,
                "parquet-cli/src/test/java/org/apache/parquet/cli/commands/ConvertCSVCommandTest.java": 41,
                "parquet-cli/src/test/java/org/apache/parquet/cli/commands/ConvertCommandTest.java": 41,
                "parquet-cli/src/test/java/org/apache/parquet/cli/commands/FileTest.java": 58,
                "parquet-cli/src/test/java/org/apache/parquet/cli/commands/ParquetFileTest.java": 117,
                "parquet-cli/src/test/java/org/apache/parquet/cli/commands/ParquetMetadataCommandTest.java": 38,
                "parquet-cli/src/test/java/org/apache/parquet/cli/commands/RewriteCommandTest.java": 41,
                "parquet-cli/src/test/java/org/apache/parquet/cli/commands/ScanCommandTest.java": 38,
                "parquet-cli/src/test/java/org/apache/parquet/cli/commands/SchemaCommandTest.java": 68,
                "parquet-cli/src/test/java/org/apache/parquet/cli/commands/ShowBloomFilterCommandTest.java": 41,
                "parquet-cli/src/test/java/org/apache/parquet/cli/commands/ShowColumnIndexTest.java": 38,
                "parquet-cli/src/test/java/org/apache/parquet/cli/commands/ShowDictionaryCommandTest.java": 50,
                "parquet-cli/src/test/java/org/apache/parquet/cli/commands/ShowFooterCommandTest.java": 43,
                "parquet-cli/src/test/java/org/apache/parquet/cli/commands/ShowPagesCommandTest.java": 38,
                "parquet-cli/src/test/java/org/apache/parquet/cli/commands/ToAvroCommandTest.java": 113,
                "parquet-cli/src/test/java/org/apache/parquet/cli/commands/TransCompressionCommandTest.java": 45,
                "parquet-column/src/main/java/org/apache/parquet/CorruptDeltaByteArrays.java": 97,
                "parquet-column/src/main/java/org/apache/parquet/CorruptStatistics.java": 116,
                "parquet-column/src/main/java/org/apache/parquet/column/ColumnDescriptor.java": 156,
                "parquet-column/src/main/java/org/apache/parquet/column/ColumnProperty.java": 137,
                "parquet-column/src/main/java/org/apache/parquet/column/ColumnReadStore.java": 32,
                "parquet-column/src/main/java/org/apache/parquet/column/ColumnReader.java": 117,
                "parquet-column/src/main/java/org/apache/parquet/column/ColumnWriteStore.java": 75,
                "parquet-column/src/main/java/org/apache/parquet/column/ColumnWriter.java": 96,
                "parquet-column/src/main/java/org/apache/parquet/column/Dictionary.java": 63,
                "parquet-column/src/main/java/org/apache/parquet/column/Encoding.java": 309,
                "parquet-column/src/main/java/org/apache/parquet/column/EncodingStats.java": 157,
                "parquet-column/src/main/java/org/apache/parquet/column/MinMax.java": 56,
                "parquet-column/src/main/java/org/apache/parquet/column/ParquetProperties.java": 589,
                "parquet-column/src/main/java/org/apache/parquet/column/UnknownColumnException.java": 40,
                "parquet-column/src/main/java/org/apache/parquet/column/UnknownColumnTypeException.java": 41,
                "parquet-column/src/main/java/org/apache/parquet/column/ValuesType.java": 26,
                "parquet-column/src/main/java/org/apache/parquet/column/impl/ColumnReadStoreImpl.java": 104,
                "parquet-column/src/main/java/org/apache/parquet/column/impl/ColumnReaderBase.java": 790,
                "parquet-column/src/main/java/org/apache/parquet/column/impl/ColumnReaderImpl.java": 58,
                "parquet-column/src/main/java/org/apache/parquet/column/impl/ColumnWriteStoreBase.java": 273,
                "parquet-column/src/main/java/org/apache/parquet/column/impl/ColumnWriteStoreV1.java": 52,
                "parquet-column/src/main/java/org/apache/parquet/column/impl/ColumnWriteStoreV2.java": 46,
                "parquet-column/src/main/java/org/apache/parquet/column/impl/ColumnWriterBase.java": 408,
                "parquet-column/src/main/java/org/apache/parquet/column/impl/ColumnWriterV1.java": 68,
                "parquet-column/src/main/java/org/apache/parquet/column/impl/ColumnWriterV2.java": 94,
                "parquet-column/src/main/java/org/apache/parquet/column/impl/SynchronizingColumnReader.java": 111,
                "parquet-column/src/main/java/org/apache/parquet/column/page/DataPage.java": 72,
                "parquet-column/src/main/java/org/apache/parquet/column/page/DataPageV1.java": 127,
                "parquet-column/src/main/java/org/apache/parquet/column/page/DataPageV2.java": 207,
                "parquet-column/src/main/java/org/apache/parquet/column/page/DictionaryPage.java": 83,
                "parquet-column/src/main/java/org/apache/parquet/column/page/DictionaryPageReadStore.java": 36,
                "parquet-column/src/main/java/org/apache/parquet/column/page/Page.java": 62,
                "parquet-column/src/main/java/org/apache/parquet/column/page/PageReadStore.java": 64,
                "parquet-column/src/main/java/org/apache/parquet/column/page/PageReader.java": 40,
                "parquet-column/src/main/java/org/apache/parquet/column/page/PageWriteStore.java": 35,
                "parquet-column/src/main/java/org/apache/parquet/column/page/PageWriter.java": 102,
                "parquet-column/src/main/java/org/apache/parquet/column/statistics/BinaryStatistics.java": 188,
                "parquet-column/src/main/java/org/apache/parquet/column/statistics/BooleanStatistics.java": 147,
                "parquet-column/src/main/java/org/apache/parquet/column/statistics/DoubleStatistics.java": 147,
                "parquet-column/src/main/java/org/apache/parquet/column/statistics/FloatStatistics.java": 148,
                "parquet-column/src/main/java/org/apache/parquet/column/statistics/IntStatistics.java": 147,
                "parquet-column/src/main/java/org/apache/parquet/column/statistics/LongStatistics.java": 147,
                "parquet-column/src/main/java/org/apache/parquet/column/statistics/Statistics.java": 539,
                "parquet-column/src/main/java/org/apache/parquet/column/statistics/StatisticsClassException.java": 44,
                "parquet-column/src/main/java/org/apache/parquet/column/values/RequiresFallback.java": 51,
                "parquet-column/src/main/java/org/apache/parquet/column/values/RequiresPreviousReader.java": 23,
                "parquet-column/src/main/java/org/apache/parquet/column/values/ValuesReader.java": 205,
                "parquet-column/src/main/java/org/apache/parquet/column/values/ValuesWriter.java": 136,
                "parquet-column/src/main/java/org/apache/parquet/column/values/bitpacking/BitPackingValuesReader.java": 84,
                "parquet-column/src/main/java/org/apache/parquet/column/values/bitpacking/BitPackingValuesWriter.java": 130,
                "parquet-column/src/main/java/org/apache/parquet/column/values/bitpacking/ByteBitPackingValuesReader.java": 99,
                "parquet-column/src/main/java/org/apache/parquet/column/values/bitpacking/ByteBitPackingValuesWriter.java": 86,
                "parquet-column/src/main/java/org/apache/parquet/column/values/bitpacking/DevNullValuesWriter.java": 89,
                "parquet-column/src/main/java/org/apache/parquet/column/values/bloomfilter/AdaptiveBlockSplitBloomFilter.java": 305,
                "parquet-column/src/main/java/org/apache/parquet/column/values/bloomfilter/BlockSplitBloomFilter.java": 424,
                "parquet-column/src/main/java/org/apache/parquet/column/values/bloomfilter/BloomFilter.java": 203,
                "parquet-column/src/main/java/org/apache/parquet/column/values/bloomfilter/BloomFilterWriteStore.java": 35,
                "parquet-column/src/main/java/org/apache/parquet/column/values/bloomfilter/BloomFilterWriter.java": 31,
                "parquet-column/src/main/java/org/apache/parquet/column/values/bloomfilter/HashFunction.java": 41,
                "parquet-column/src/main/java/org/apache/parquet/column/values/bloomfilter/XxHash.java": 40,
                "parquet-column/src/main/java/org/apache/parquet/column/values/bytestreamsplit/ByteStreamSplitValuesReader.java": 111,
                "parquet-column/src/main/java/org/apache/parquet/column/values/bytestreamsplit/ByteStreamSplitValuesReaderForDouble.java": 37,
                "parquet-column/src/main/java/org/apache/parquet/column/values/bytestreamsplit/ByteStreamSplitValuesReaderForFloat.java": 37,
                "parquet-column/src/main/java/org/apache/parquet/column/values/bytestreamsplit/ByteStreamSplitValuesWriter.java": 142,
                "parquet-column/src/main/java/org/apache/parquet/column/values/delta/DeltaBinaryPackingConfig.java": 55,
                "parquet-column/src/main/java/org/apache/parquet/column/values/delta/DeltaBinaryPackingValuesReader.java": 171,
                "parquet-column/src/main/java/org/apache/parquet/column/values/delta/DeltaBinaryPackingValuesWriter.java": 136,
                "parquet-column/src/main/java/org/apache/parquet/column/values/delta/DeltaBinaryPackingValuesWriterForInteger.java": 196,
                "parquet-column/src/main/java/org/apache/parquet/column/values/delta/DeltaBinaryPackingValuesWriterForLong.java": 198,
                "parquet-column/src/main/java/org/apache/parquet/column/values/deltalengthbytearray/DeltaLengthByteArrayValuesReader.java": 80,
                "parquet-column/src/main/java/org/apache/parquet/column/values/deltalengthbytearray/DeltaLengthByteArrayValuesWriter.java": 115,
                "parquet-column/src/main/java/org/apache/parquet/column/values/deltastrings/DeltaByteArrayReader.java": 96,
                "parquet-column/src/main/java/org/apache/parquet/column/values/deltastrings/DeltaByteArrayWriter.java": 100,
                "parquet-column/src/main/java/org/apache/parquet/column/values/dictionary/DictionaryValuesReader.java": 131,
                "parquet-column/src/main/java/org/apache/parquet/column/values/dictionary/DictionaryValuesWriter.java": 597,
                "parquet-column/src/main/java/org/apache/parquet/column/values/dictionary/IntList.java": 159,
                "parquet-column/src/main/java/org/apache/parquet/column/values/dictionary/PlainValuesDictionary.java": 313,
                "parquet-column/src/main/java/org/apache/parquet/column/values/factory/DefaultV1ValuesWriterFactory.java": 122,
                "parquet-column/src/main/java/org/apache/parquet/column/values/factory/DefaultV2ValuesWriterFactory.java": 126,
                "parquet-column/src/main/java/org/apache/parquet/column/values/factory/DefaultValuesWriterFactory.java": 87,
                "parquet-column/src/main/java/org/apache/parquet/column/values/factory/ValuesWriterFactory.java": 52,
                "parquet-column/src/main/java/org/apache/parquet/column/values/fallback/FallbackValuesWriter.java": 204,
                "parquet-column/src/main/java/org/apache/parquet/column/values/plain/BinaryPlainValuesReader.java": 63,
                "parquet-column/src/main/java/org/apache/parquet/column/values/plain/BooleanPlainValuesReader.java": 73,
                "parquet-column/src/main/java/org/apache/parquet/column/values/plain/BooleanPlainValuesWriter.java": 81,
                "parquet-column/src/main/java/org/apache/parquet/column/values/plain/FixedLenByteArrayPlainValuesReader.java": 72,
                "parquet-column/src/main/java/org/apache/parquet/column/values/plain/FixedLenByteArrayPlainValuesWriter.java": 106,
                "parquet-column/src/main/java/org/apache/parquet/column/values/plain/PlainValuesReader.java": 139,
                "parquet-column/src/main/java/org/apache/parquet/column/values/plain/PlainValuesWriter.java": 148,
                "parquet-column/src/main/java/org/apache/parquet/column/values/rle/RunLengthBitPackingHybridDecoder.java": 107,
                "parquet-column/src/main/java/org/apache/parquet/column/values/rle/RunLengthBitPackingHybridEncoder.java": 293,
                "parquet-column/src/main/java/org/apache/parquet/column/values/rle/RunLengthBitPackingHybridValuesReader.java": 68,
                "parquet-column/src/main/java/org/apache/parquet/column/values/rle/RunLengthBitPackingHybridValuesWriter.java": 95,
                "parquet-column/src/main/java/org/apache/parquet/column/values/rle/ZeroIntegerValuesReader.java": 50,
                "parquet-column/src/main/java/org/apache/parquet/example/DummyRecordConverter.java": 114,
                "parquet-column/src/main/java/org/apache/parquet/example/Paper.java": 164,
                "parquet-column/src/main/java/org/apache/parquet/example/data/Group.java": 147,
                "parquet-column/src/main/java/org/apache/parquet/example/data/GroupFactory.java": 25,
                "parquet-column/src/main/java/org/apache/parquet/example/data/GroupValueSource.java": 89,
                "parquet-column/src/main/java/org/apache/parquet/example/data/GroupWriter.java": 62,
                "parquet-column/src/main/java/org/apache/parquet/example/data/simple/BinaryValue.java": 52,
                "parquet-column/src/main/java/org/apache/parquet/example/data/simple/BooleanValue.java": 44,
                "parquet-column/src/main/java/org/apache/parquet/example/data/simple/DoubleValue.java": 45,
                "parquet-column/src/main/java/org/apache/parquet/example/data/simple/FloatValue.java": 45,
                "parquet-column/src/main/java/org/apache/parquet/example/data/simple/Int96Value.java": 46,
                "parquet-column/src/main/java/org/apache/parquet/example/data/simple/IntegerValue.java": 46,
                "parquet-column/src/main/java/org/apache/parquet/example/data/simple/LongValue.java": 45,
                "parquet-column/src/main/java/org/apache/parquet/example/data/simple/NanoTime.java": 80,
                "parquet-column/src/main/java/org/apache/parquet/example/data/simple/Primitive.java": 60,
                "parquet-column/src/main/java/org/apache/parquet/example/data/simple/SimpleGroup.java": 236,
                "parquet-column/src/main/java/org/apache/parquet/example/data/simple/SimpleGroupFactory.java": 38,
                "parquet-column/src/main/java/org/apache/parquet/example/data/simple/convert/GroupRecordConverter.java": 57,
                "parquet-column/src/main/java/org/apache/parquet/example/data/simple/convert/SimpleGroupConverter.java": 67,
                "parquet-column/src/main/java/org/apache/parquet/example/data/simple/convert/SimplePrimitiveConverter.java": 88,
                "parquet-column/src/main/java/org/apache/parquet/filter/AndRecordFilter.java": 65,
                "parquet-column/src/main/java/org/apache/parquet/filter/ColumnPredicates.java": 191,
                "parquet-column/src/main/java/org/apache/parquet/filter/ColumnRecordFilter.java": 76,
                "parquet-column/src/main/java/org/apache/parquet/filter/NotRecordFilter.java": 60,
                "parquet-column/src/main/java/org/apache/parquet/filter/OrRecordFilter.java": 62,
                "parquet-column/src/main/java/org/apache/parquet/filter/PagedRecordFilter.java": 65,
                "parquet-column/src/main/java/org/apache/parquet/filter/RecordFilter.java": 33,
                "parquet-column/src/main/java/org/apache/parquet/filter/UnboundRecordFilter.java": 37,
                "parquet-column/src/main/java/org/apache/parquet/filter2/compat/FilterCompat.java": 181,
                "parquet-column/src/main/java/org/apache/parquet/filter2/predicate/FilterApi.java": 328,
                "parquet-column/src/main/java/org/apache/parquet/filter2/predicate/FilterPredicate.java": 84,
                "parquet-column/src/main/java/org/apache/parquet/filter2/predicate/LogicalInverseRewriter.java": 126,
                "parquet-column/src/main/java/org/apache/parquet/filter2/predicate/LogicalInverter.java": 120,
                "parquet-column/src/main/java/org/apache/parquet/filter2/predicate/Operators.java": 587,
                "parquet-column/src/main/java/org/apache/parquet/filter2/predicate/PrimitiveToBoxedClass.java": 50,
                "parquet-column/src/main/java/org/apache/parquet/filter2/predicate/SchemaCompatibilityValidator.java": 204,
                "parquet-column/src/main/java/org/apache/parquet/filter2/predicate/Statistics.java": 93,
                "parquet-column/src/main/java/org/apache/parquet/filter2/predicate/UserDefinedPredicate.java": 131,
                "parquet-column/src/main/java/org/apache/parquet/filter2/predicate/ValidTypeMap.java": 128,
                "parquet-column/src/main/java/org/apache/parquet/filter2/recordlevel/FilteringGroupConverter.java": 112,
                "parquet-column/src/main/java/org/apache/parquet/filter2/recordlevel/FilteringPrimitiveConverter.java": 109,
                "parquet-column/src/main/java/org/apache/parquet/filter2/recordlevel/FilteringRecordMaterializer.java": 116,
                "parquet-column/src/main/java/org/apache/parquet/filter2/recordlevel/IncrementallyUpdatedFilterPredicate.java": 166,
                "parquet-column/src/main/java/org/apache/parquet/filter2/recordlevel/IncrementallyUpdatedFilterPredicateBuilderBase.java": 116,
                "parquet-column/src/main/java/org/apache/parquet/filter2/recordlevel/IncrementallyUpdatedFilterPredicateEvaluator.java": 62,
                "parquet-column/src/main/java/org/apache/parquet/filter2/recordlevel/IncrementallyUpdatedFilterPredicateResetter.java": 59,
                "parquet-column/src/main/java/org/apache/parquet/internal/column/columnindex/BinaryColumnIndexBuilder.java": 140,
                "parquet-column/src/main/java/org/apache/parquet/internal/column/columnindex/BinaryTruncator.java": 221,
                "parquet-column/src/main/java/org/apache/parquet/internal/column/columnindex/BooleanColumnIndexBuilder.java": 133,
                "parquet-column/src/main/java/org/apache/parquet/internal/column/columnindex/BoundaryOrder.java": 384,
                "parquet-column/src/main/java/org/apache/parquet/internal/column/columnindex/ColumnIndex.java": 60,
                "parquet-column/src/main/java/org/apache/parquet/internal/column/columnindex/ColumnIndexBuilder.java": 686,
                "parquet-column/src/main/java/org/apache/parquet/internal/column/columnindex/DoubleColumnIndexBuilder.java": 155,
                "parquet-column/src/main/java/org/apache/parquet/internal/column/columnindex/FloatColumnIndexBuilder.java": 155,
                "parquet-column/src/main/java/org/apache/parquet/internal/column/columnindex/IndexIterator.java": 89,
                "parquet-column/src/main/java/org/apache/parquet/internal/column/columnindex/IntColumnIndexBuilder.java": 136,
                "parquet-column/src/main/java/org/apache/parquet/internal/column/columnindex/LongColumnIndexBuilder.java": 136,
                "parquet-column/src/main/java/org/apache/parquet/internal/column/columnindex/OffsetIndex.java": 73,
                "parquet-column/src/main/java/org/apache/parquet/internal/column/columnindex/OffsetIndexBuilder.java": 193,
                "parquet-column/src/main/java/org/apache/parquet/internal/filter2/columnindex/ColumnIndexFilter.java": 217,
                "parquet-column/src/main/java/org/apache/parquet/internal/filter2/columnindex/ColumnIndexStore.java": 55,
                "parquet-column/src/main/java/org/apache/parquet/internal/filter2/columnindex/RowRanges.java": 318,
                "parquet-column/src/main/java/org/apache/parquet/io/BaseRecordReader.java": 149,
                "parquet-column/src/main/java/org/apache/parquet/io/ColumnIO.java": 138,
                "parquet-column/src/main/java/org/apache/parquet/io/ColumnIOFactory.java": 174,
                "parquet-column/src/main/java/org/apache/parquet/io/CompilationException.java": 44,
                "parquet-column/src/main/java/org/apache/parquet/io/EmptyRecordReader.java": 48,
                "parquet-column/src/main/java/org/apache/parquet/io/FilteredRecordReader.java": 97,
                "parquet-column/src/main/java/org/apache/parquet/io/GroupColumnIO.java": 121,
                "parquet-column/src/main/java/org/apache/parquet/io/InvalidFileOffsetException.java": 29,
                "parquet-column/src/main/java/org/apache/parquet/io/InvalidRecordException.java": 45,
                "parquet-column/src/main/java/org/apache/parquet/io/MessageColumnIO.java": 534,
                "parquet-column/src/main/java/org/apache/parquet/io/ParquetDecodingException.java": 44,
                "parquet-column/src/main/java/org/apache/parquet/io/ParquetEncodingException.java": 44,
                "parquet-column/src/main/java/org/apache/parquet/io/PrimitiveColumnIO.java": 108,
                "parquet-column/src/main/java/org/apache/parquet/io/RecordConsumerLoggingWrapper.java": 187,
                "parquet-column/src/main/java/org/apache/parquet/io/RecordReader.java": 43,
                "parquet-column/src/main/java/org/apache/parquet/io/RecordReaderImplementation.java": 474,
                "parquet-column/src/main/java/org/apache/parquet/io/ValidatingRecordConsumer.java": 247,
                "parquet-column/src/main/java/org/apache/parquet/io/api/Binary.java": 737,
                "parquet-column/src/main/java/org/apache/parquet/io/api/Converter.java": 37,
                "parquet-column/src/main/java/org/apache/parquet/io/api/GroupConverter.java": 55,
                "parquet-column/src/main/java/org/apache/parquet/io/api/PrimitiveConverter.java": 108,
                "parquet-column/src/main/java/org/apache/parquet/io/api/RecordConsumer.java": 134,
                "parquet-column/src/main/java/org/apache/parquet/io/api/RecordMaterializer.java": 73,
                "parquet-column/src/main/java/org/apache/parquet/schema/ColumnOrder.java": 97,
                "parquet-column/src/main/java/org/apache/parquet/schema/ConversionPatterns.java": 133,
                "parquet-column/src/main/java/org/apache/parquet/schema/DecimalMetadata.java": 62,
                "parquet-column/src/main/java/org/apache/parquet/schema/GroupType.java": 421,
                "parquet-column/src/main/java/org/apache/parquet/schema/IncompatibleSchemaModificationException.java": 46,
                "parquet-column/src/main/java/org/apache/parquet/schema/InvalidSchemaException.java": 31,
                "parquet-column/src/main/java/org/apache/parquet/schema/LogicalTypeAnnotation.java": 1064,
                "parquet-column/src/main/java/org/apache/parquet/schema/MessageType.java": 145,
                "parquet-column/src/main/java/org/apache/parquet/schema/MessageTypeParser.java": 243,
                "parquet-column/src/main/java/org/apache/parquet/schema/OriginalType.java": 48,
                "parquet-column/src/main/java/org/apache/parquet/schema/PrimitiveComparator.java": 279,
                "parquet-column/src/main/java/org/apache/parquet/schema/PrimitiveStringifier.java": 451,
                "parquet-column/src/main/java/org/apache/parquet/schema/PrimitiveType.java": 797,
                "parquet-column/src/main/java/org/apache/parquet/schema/Type.java": 366,
                "parquet-column/src/main/java/org/apache/parquet/schema/TypeConverter.java": 53,
                "parquet-column/src/main/java/org/apache/parquet/schema/TypeUtil.java": 45,
                "parquet-column/src/main/java/org/apache/parquet/schema/TypeVisitor.java": 43,
                "parquet-column/src/main/java/org/apache/parquet/schema/Types.java": 1542,
                "parquet-column/src/test/java/org/apache/parquet/CorruptStatisticsTest.java": 92,
                "parquet-column/src/test/java/org/apache/parquet/FixedBinaryTestUtils.java": 96,
                "parquet-column/src/test/java/org/apache/parquet/ResourceIntensiveTestRule.java": 58,
                "parquet-column/src/test/java/org/apache/parquet/column/TestColumnDescriptor.java": 52,
                "parquet-column/src/test/java/org/apache/parquet/column/TestEncodingStats.java": 202,
                "parquet-column/src/test/java/org/apache/parquet/column/impl/TestColumnReaderImpl.java": 131,
                "parquet-column/src/test/java/org/apache/parquet/column/impl/TestCorruptDeltaByteArrays.java": 269,
                "parquet-column/src/test/java/org/apache/parquet/column/mem/TestMemColumn.java": 246,
                "parquet-column/src/test/java/org/apache/parquet/column/mem/TestMemPageStore.java": 61,
                "parquet-column/src/test/java/org/apache/parquet/column/page/mem/MemPageReader.java": 67,
                "parquet-column/src/test/java/org/apache/parquet/column/page/mem/MemPageStore.java": 78,
                "parquet-column/src/test/java/org/apache/parquet/column/page/mem/MemPageWriter.java": 117,
                "parquet-column/src/test/java/org/apache/parquet/column/statistics/TestStatistics.java": 789,
                "parquet-column/src/test/java/org/apache/parquet/column/values/TestValuesReaderImpl.java": 148,
                "parquet-column/src/test/java/org/apache/parquet/column/values/Utils.java": 76,
                "parquet-column/src/test/java/org/apache/parquet/column/values/bitpacking/BitPackingPerfTest.java": 103,
                "parquet-column/src/test/java/org/apache/parquet/column/values/bitpacking/TestBitPackingColumn.java": 232,
                "parquet-column/src/test/java/org/apache/parquet/column/values/bloomfilter/TestBlockSplitBloomFilter.java": 325,
                "parquet-column/src/test/java/org/apache/parquet/column/values/bytestreamsplit/ByteStreamSplitValuesEndToEndTest.java": 111,
                "parquet-column/src/test/java/org/apache/parquet/column/values/bytestreamsplit/ByteStreamSplitValuesReaderTest.java": 193,
                "parquet-column/src/test/java/org/apache/parquet/column/values/bytestreamsplit/ByteStreamSplitValuesWriterTest.java": 189,
                "parquet-column/src/test/java/org/apache/parquet/column/values/delta/DeltaBinaryPackingValuesWriterForIntegerTest.java": 294,
                "parquet-column/src/test/java/org/apache/parquet/column/values/delta/DeltaBinaryPackingValuesWriterForLongTest.java": 291,
                "parquet-column/src/test/java/org/apache/parquet/column/values/delta/benchmark/BenchMarkTest.java": 41,
                "parquet-column/src/test/java/org/apache/parquet/column/values/delta/benchmark/BenchmarkIntegerOutputSize.java": 107,
                "parquet-column/src/test/java/org/apache/parquet/column/values/delta/benchmark/BenchmarkReadingRandomIntegers.java": 102,
                "parquet-column/src/test/java/org/apache/parquet/column/values/delta/benchmark/RandomWritingBenchmarkTest.java": 76,
                "parquet-column/src/test/java/org/apache/parquet/column/values/delta/benchmark/SmallRangeWritingBenchmarkTest.java": 49,
                "parquet-column/src/test/java/org/apache/parquet/column/values/deltalengthbytearray/TestDeltaLengthByteArray.java": 103,
                "parquet-column/src/test/java/org/apache/parquet/column/values/deltalengthbytearray/benchmark/BenchmarkDeltaLengthByteArray.java": 73,
                "parquet-column/src/test/java/org/apache/parquet/column/values/deltastrings/TestDeltaByteArray.java": 130,
                "parquet-column/src/test/java/org/apache/parquet/column/values/deltastrings/benchmark/BenchmarkDeltaByteArray.java": 103,
                "parquet-column/src/test/java/org/apache/parquet/column/values/dictionary/IntListTest.java": 84,
                "parquet-column/src/test/java/org/apache/parquet/column/values/dictionary/TestDictionary.java": 661,
                "parquet-column/src/test/java/org/apache/parquet/column/values/factory/DefaultValuesWriterFactoryTest.java": 546,
                "parquet-column/src/test/java/org/apache/parquet/column/values/rle/RunLengthBitPackingHybridIntegrationTest.java": 86,
                "parquet-column/src/test/java/org/apache/parquet/column/values/rle/TestRunLengthBitPackingHybridEncoder.java": 329,
                "parquet-column/src/test/java/org/apache/parquet/filter2/predicate/DummyUdp.java": 37,
                "parquet-column/src/test/java/org/apache/parquet/filter2/predicate/TestFilterApiMethods.java": 172,
                "parquet-column/src/test/java/org/apache/parquet/filter2/predicate/TestLogicalInverseRewriter.java": 103,
                "parquet-column/src/test/java/org/apache/parquet/filter2/predicate/TestLogicalInverter.java": 94,
                "parquet-column/src/test/java/org/apache/parquet/filter2/predicate/TestSchemaCompatibilityValidator.java": 142,
                "parquet-column/src/test/java/org/apache/parquet/filter2/predicate/TestValidTypeMap.java": 98,
                "parquet-column/src/test/java/org/apache/parquet/filter2/recordlevel/TestIncrementallyUpdatedFilterPredicateEvaluator.java": 209,
                "parquet-column/src/test/java/org/apache/parquet/filter2/recordlevel/TestIncrementallyUpdatedFilterPredicateResetter.java": 69,
                "parquet-column/src/test/java/org/apache/parquet/filter2/recordlevel/TestValueInspector.java": 97,
                "parquet-column/src/test/java/org/apache/parquet/internal/column/columnindex/TestBinaryTruncator.java": 285,
                "parquet-column/src/test/java/org/apache/parquet/internal/column/columnindex/TestBoundaryOrder.java": 543,
                "parquet-column/src/test/java/org/apache/parquet/internal/column/columnindex/TestColumnIndexBuilder.java": 1728,
                "parquet-column/src/test/java/org/apache/parquet/internal/column/columnindex/TestIndexIterator.java": 63,
                "parquet-column/src/test/java/org/apache/parquet/internal/column/columnindex/TestOffsetIndexBuilder.java": 111,
                "parquet-column/src/test/java/org/apache/parquet/internal/filter2/columnindex/TestColumnIndexFilter.java": 555,
                "parquet-column/src/test/java/org/apache/parquet/internal/filter2/columnindex/TestRowRanges.java": 155,
                "parquet-column/src/test/java/org/apache/parquet/io/ConverterConsumer.java": 125,
                "parquet-column/src/test/java/org/apache/parquet/io/ExpectationValidatingConverter.java": 169,
                "parquet-column/src/test/java/org/apache/parquet/io/ExpectationValidatingRecordConsumer.java": 112,
                "parquet-column/src/test/java/org/apache/parquet/io/PerfTest.java": 128,
                "parquet-column/src/test/java/org/apache/parquet/io/TestColumnIO.java": 709,
                "parquet-column/src/test/java/org/apache/parquet/io/TestFiltered.java": 278,
                "parquet-column/src/test/java/org/apache/parquet/io/api/TestBinary.java": 271,
                "parquet-column/src/test/java/org/apache/parquet/parser/TestParquetParser.java": 374,
                "parquet-column/src/test/java/org/apache/parquet/schema/TestMessageType.java": 247,
                "parquet-column/src/test/java/org/apache/parquet/schema/TestPrimitiveComparator.java": 330,
                "parquet-column/src/test/java/org/apache/parquet/schema/TestPrimitiveStringifier.java": 391,
                "parquet-column/src/test/java/org/apache/parquet/schema/TestRepetitionType.java": 36,
                "parquet-column/src/test/java/org/apache/parquet/schema/TestTypeBuilders.java": 1372,
                "parquet-column/src/test/java/org/apache/parquet/schema/TestTypeBuildersWithLogicalTypes.java": 422,
                "parquet-column/src/test/java/org/apache/parquet/schema/TestTypeUtil.java": 80,
                "parquet-common/src/main/java/org/apache/parquet/Closeables.java": 60,
                "parquet-common/src/main/java/org/apache/parquet/Exceptions.java": 39,
                "parquet-common/src/main/java/org/apache/parquet/Files.java": 54,
                "parquet-common/src/main/java/org/apache/parquet/IOExceptionUtils.java": 45,
                "parquet-common/src/main/java/org/apache/parquet/Ints.java": 44,
                "parquet-common/src/main/java/org/apache/parquet/Log.java": 146,
                "parquet-common/src/main/java/org/apache/parquet/OutputStreamCloseException.java": 46,
                "parquet-common/src/main/java/org/apache/parquet/ParquetRuntimeException.java": 42,
                "parquet-common/src/main/java/org/apache/parquet/Preconditions.java": 251,
                "parquet-common/src/main/java/org/apache/parquet/SemanticVersion.java": 293,
                "parquet-common/src/main/java/org/apache/parquet/ShouldNeverHappenException.java": 40,
                "parquet-common/src/main/java/org/apache/parquet/Strings.java": 132,
                "parquet-common/src/main/java/org/apache/parquet/VersionParser.java": 129,
                "parquet-common/src/main/java/org/apache/parquet/bytes/ByteBufferAllocator.java": 40,
                "parquet-common/src/main/java/org/apache/parquet/bytes/ByteBufferInputStream.java": 160,
                "parquet-common/src/main/java/org/apache/parquet/bytes/BytesInput.java": 545,
                "parquet-common/src/main/java/org/apache/parquet/bytes/BytesUtils.java": 335,
                "parquet-common/src/main/java/org/apache/parquet/bytes/CapacityByteArrayOutputStream.java": 352,
                "parquet-common/src/main/java/org/apache/parquet/bytes/ConcatenatingByteArrayCollector.java": 63,
                "parquet-common/src/main/java/org/apache/parquet/bytes/DirectByteBufferAllocator.java": 43,
                "parquet-common/src/main/java/org/apache/parquet/bytes/HeapByteBufferAllocator.java": 44,
                "parquet-common/src/main/java/org/apache/parquet/bytes/LittleEndianDataInputStream.java": 421,
                "parquet-common/src/main/java/org/apache/parquet/bytes/LittleEndianDataOutputStream.java": 218,
                "parquet-common/src/main/java/org/apache/parquet/bytes/MultiBufferInputStream.java": 382,
                "parquet-common/src/main/java/org/apache/parquet/bytes/SingleBufferInputStream.java": 177,
                "parquet-common/src/main/java/org/apache/parquet/compression/CompressionCodecFactory.java": 47,
                "parquet-common/src/main/java/org/apache/parquet/glob/GlobExpander.java": 129,
                "parquet-common/src/main/java/org/apache/parquet/glob/GlobNode.java": 157,
                "parquet-common/src/main/java/org/apache/parquet/glob/GlobParser.java": 224,
                "parquet-common/src/main/java/org/apache/parquet/glob/WildcardPath.java": 121,
                "parquet-common/src/main/java/org/apache/parquet/hadoop/codec/CompressionCodecNotSupportedException.java": 38,
                "parquet-common/src/main/java/org/apache/parquet/hadoop/metadata/Canonicalizer.java": 61,
                "parquet-common/src/main/java/org/apache/parquet/hadoop/metadata/ColumnPath.java": 88,
                "parquet-common/src/main/java/org/apache/parquet/hadoop/metadata/CompressionCodecName.java": 99,
                "parquet-common/src/main/java/org/apache/parquet/io/DelegatingPositionOutputStream.java": 63,
                "parquet-common/src/main/java/org/apache/parquet/io/DelegatingSeekableInputStream.java": 171,
                "parquet-common/src/main/java/org/apache/parquet/io/InputFile.java": 44,
                "parquet-common/src/main/java/org/apache/parquet/io/LocalInputFile.java": 102,
                "parquet-common/src/main/java/org/apache/parquet/io/LocalOutputFile.java": 107,
                "parquet-common/src/main/java/org/apache/parquet/io/OutputFile.java": 62,
                "parquet-common/src/main/java/org/apache/parquet/io/PositionOutputStream.java": 39,
                "parquet-common/src/main/java/org/apache/parquet/io/SeekableInputStream.java": 108,
                "parquet-common/src/main/java/org/apache/parquet/util/DynConstructors.java": 263,
                "parquet-common/src/main/java/org/apache/parquet/util/DynMethods.java": 506,
                "parquet-common/src/test/java/org/apache/parquet/SemanticVersionTest.java": 114,
                "parquet-common/src/test/java/org/apache/parquet/TestPreconditions.java": 246,
                "parquet-common/src/test/java/org/apache/parquet/TestUtils.java": 70,
                "parquet-common/src/test/java/org/apache/parquet/VersionTest.java": 100,
                "parquet-common/src/test/java/org/apache/parquet/bytes/TestByteBufferInputStreams.java": 589,
                "parquet-common/src/test/java/org/apache/parquet/bytes/TestBytesUtil.java": 49,
                "parquet-common/src/test/java/org/apache/parquet/bytes/TestDeprecatedBufferInputStream.java": 152,
                "parquet-common/src/test/java/org/apache/parquet/bytes/TestMultiBufferInputStream.java": 141,
                "parquet-common/src/test/java/org/apache/parquet/bytes/TestSingleBufferInputStream.java": 130,
                "parquet-common/src/test/java/org/apache/parquet/glob/TestGlob.java": 144,
                "parquet-common/src/test/java/org/apache/parquet/glob/TestWildcardPath.java": 125,
                "parquet-common/src/test/java/org/apache/parquet/io/MockInputStream.java": 56,
                "parquet-common/src/test/java/org/apache/parquet/io/TestDelegatingSeekableInputStream.java": 844,
                "parquet-common/src/test/java/org/apache/parquet/io/TestLocalInputOutput.java": 92,
                "parquet-common/src/test/java/org/apache/parquet/util/Concatenator.java": 82,
                "parquet-common/src/test/java/org/apache/parquet/util/TestDynConstructors.java": 165,
                "parquet-common/src/test/java/org/apache/parquet/util/TestDynMethods.java": 315,
                "parquet-encoding/src/main/java/org/apache/parquet/column/values/bitpacking/BitPacking.java": 717,
                "parquet-encoding/src/main/java/org/apache/parquet/column/values/bitpacking/ByteBasedBitPackingEncoder.java": 142,
                "parquet-encoding/src/main/java/org/apache/parquet/column/values/bitpacking/BytePacker.java": 141,
                "parquet-encoding/src/main/java/org/apache/parquet/column/values/bitpacking/BytePackerFactory.java": 25,
                "parquet-encoding/src/main/java/org/apache/parquet/column/values/bitpacking/BytePackerForLong.java": 109,
                "parquet-encoding/src/main/java/org/apache/parquet/column/values/bitpacking/BytePackerForLongFactory.java": 25,
                "parquet-encoding/src/main/java/org/apache/parquet/column/values/bitpacking/IntPacker.java": 63,
                "parquet-encoding/src/main/java/org/apache/parquet/column/values/bitpacking/IntPackerFactory.java": 25,
                "parquet-encoding/src/main/java/org/apache/parquet/column/values/bitpacking/Packer.java": 137,
                "parquet-encoding/src/test/java/org/apache/parquet/bytes/TestBytesInput.java": 42,
                "parquet-encoding/src/test/java/org/apache/parquet/bytes/TestCapacityByteArrayOutputStream.java": 242,
                "parquet-encoding/src/test/java/org/apache/parquet/column/values/bitpacking/TestBitPacking.java": 233,
                "parquet-encoding/src/test/java/org/apache/parquet/column/values/bitpacking/TestByteBasedBitPackingEncoder.java": 46,
                "parquet-encoding/src/test/java/org/apache/parquet/column/values/bitpacking/TestByteBitPacking.java": 198,
                "parquet-encoding/src/test/java/org/apache/parquet/column/values/bitpacking/TestLemireBitPacking.java": 125,
                "parquet-format-structures/src/main/java/org/apache/parquet/format/BlockCipher.java": 76,
                "parquet-format-structures/src/main/java/org/apache/parquet/format/CliUtils.java": 55,
                "parquet-format-structures/src/main/java/org/apache/parquet/format/InterningProtocol.java": 236,
                "parquet-format-structures/src/main/java/org/apache/parquet/format/InvalidParquetMetadataException.java": 30,
                "parquet-format-structures/src/main/java/org/apache/parquet/format/LogicalTypes.java": 55,
                "parquet-format-structures/src/main/java/org/apache/parquet/format/MetadataValidator.java": 44,
                "parquet-format-structures/src/main/java/org/apache/parquet/format/Util.java": 389,
                "parquet-format-structures/src/main/java/org/apache/parquet/format/event/Consumers.java": 191,
                "parquet-format-structures/src/main/java/org/apache/parquet/format/event/EventBasedThriftReader.java": 126,
                "parquet-format-structures/src/main/java/org/apache/parquet/format/event/FieldConsumer.java": 39,
                "parquet-format-structures/src/main/java/org/apache/parquet/format/event/TypedConsumer.java": 205,
                "parquet-format-structures/src/test/java/org/apache/parquet/format/TestUtil.java": 101,
                "parquet-generator/src/main/java/org/apache/parquet/encoding/Generator.java": 34,
                "parquet-generator/src/main/java/org/apache/parquet/encoding/bitpacking/ByteBasedBitPackingGenerator.java": 319,
                "parquet-generator/src/main/java/org/apache/parquet/encoding/bitpacking/IntBasedBitPackingGenerator.java": 208,
                "parquet-generator/src/main/java/org/apache/parquet/filter2/Generator.java": 28,
                "parquet-generator/src/main/java/org/apache/parquet/filter2/IncrementallyUpdatedFilterPredicateGenerator.java": 335,
                "parquet-generator/src/main/java/org/apache/parquet/version/Generator.java": 28,
                "parquet-generator/src/main/java/org/apache/parquet/version/VersionGenerator.java": 87,
                "parquet-hadoop/src/main/java/org/apache/parquet/HadoopReadOptions.java": 143,
                "parquet-hadoop/src/main/java/org/apache/parquet/ParquetReadOptions.java": 345,
                "parquet-hadoop/src/main/java/org/apache/parquet/crypto/AADPrefixVerifier.java": 32,
                "parquet-hadoop/src/main/java/org/apache/parquet/crypto/AesCipher.java": 164,
                "parquet-hadoop/src/main/java/org/apache/parquet/crypto/AesCtrDecryptor.java": 170,
                "parquet-hadoop/src/main/java/org/apache/parquet/crypto/AesCtrEncryptor.java": 104,
                "parquet-hadoop/src/main/java/org/apache/parquet/crypto/AesGcmDecryptor.java": 151,
                "parquet-hadoop/src/main/java/org/apache/parquet/crypto/AesGcmEncryptor.java": 91,
                "parquet-hadoop/src/main/java/org/apache/parquet/crypto/AesMode.java": 35,
                "parquet-hadoop/src/main/java/org/apache/parquet/crypto/ColumnDecryptionProperties.java": 104,
                "parquet-hadoop/src/main/java/org/apache/parquet/crypto/ColumnEncryptionProperties.java": 195,
                "parquet-hadoop/src/main/java/org/apache/parquet/crypto/DecryptionKeyRetriever.java": 39,
                "parquet-hadoop/src/main/java/org/apache/parquet/crypto/DecryptionPropertiesFactory.java": 88,
                "parquet-hadoop/src/main/java/org/apache/parquet/crypto/EncryptionPropertiesFactory.java": 93,
                "parquet-hadoop/src/main/java/org/apache/parquet/crypto/FileDecryptionProperties.java": 254,
                "parquet-hadoop/src/main/java/org/apache/parquet/crypto/FileEncryptionProperties.java": 278,
                "parquet-hadoop/src/main/java/org/apache/parquet/crypto/InternalColumnDecryptionSetup.java": 74,
                "parquet-hadoop/src/main/java/org/apache/parquet/crypto/InternalColumnEncryptionSetup.java": 82,
                "parquet-hadoop/src/main/java/org/apache/parquet/crypto/InternalFileDecryptor.java": 312,
                "parquet-hadoop/src/main/java/org/apache/parquet/crypto/InternalFileEncryptor.java": 200,
                "parquet-hadoop/src/main/java/org/apache/parquet/crypto/KeyAccessDeniedException.java": 39,
                "parquet-hadoop/src/main/java/org/apache/parquet/crypto/ModuleCipherFactory.java": 73,
                "parquet-hadoop/src/main/java/org/apache/parquet/crypto/ParquetCipher.java": 42,
                "parquet-hadoop/src/main/java/org/apache/parquet/crypto/ParquetCryptoRuntimeException.java": 42,
                "parquet-hadoop/src/main/java/org/apache/parquet/crypto/TagVerificationException.java": 39,
                "parquet-hadoop/src/main/java/org/apache/parquet/crypto/keytools/FileKeyMaterialStore.java": 72,
                "parquet-hadoop/src/main/java/org/apache/parquet/crypto/keytools/FileKeyUnwrapper.java": 178,
                "parquet-hadoop/src/main/java/org/apache/parquet/crypto/keytools/FileKeyWrapper.java": 177,
                "parquet-hadoop/src/main/java/org/apache/parquet/crypto/keytools/HadoopFSKeyMaterialStore.java": 136,
                "parquet-hadoop/src/main/java/org/apache/parquet/crypto/keytools/KeyMaterial.java": 210,
                "parquet-hadoop/src/main/java/org/apache/parquet/crypto/keytools/KeyMetadata.java": 130,
                "parquet-hadoop/src/main/java/org/apache/parquet/crypto/keytools/KeyToolkit.java": 394,
                "parquet-hadoop/src/main/java/org/apache/parquet/crypto/keytools/KmsClient.java": 72,
                "parquet-hadoop/src/main/java/org/apache/parquet/crypto/keytools/LocalWrapKmsClient.java": 181,
                "parquet-hadoop/src/main/java/org/apache/parquet/crypto/keytools/PropertiesDrivenCryptoFactory.java": 258,
                "parquet-hadoop/src/main/java/org/apache/parquet/crypto/keytools/TwoLevelCacheWithExpiration.java": 105,
                "parquet-hadoop/src/main/java/org/apache/parquet/filter2/bloomfilterlevel/BloomFilterImpl.java": 187,
                "parquet-hadoop/src/main/java/org/apache/parquet/filter2/compat/RowGroupFilter.java": 131,
                "parquet-hadoop/src/main/java/org/apache/parquet/filter2/dictionarylevel/DictionaryFilter.java": 570,
                "parquet-hadoop/src/main/java/org/apache/parquet/filter2/statisticslevel/StatisticsFilter.java": 485,
                "parquet-hadoop/src/main/java/org/apache/parquet/format/converter/ParquetMetadataConverter.java": 2080,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/BadConfigurationException.java": 44,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/BloomFilterReader.java": 70,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/CodecFactory.java": 289,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ColumnChunkPageReadStore.java": 364,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ColumnChunkPageWriteStore.java": 462,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ColumnConfigParser.java": 72,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ColumnIndexFilterUtils.java": 162,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ColumnIndexStoreImpl.java": 155,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ColumnIndexValidator.java": 613,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/DictionaryPageReader.java": 115,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/DirectCodecFactory.java": 528,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/DirectZstd.java": 144,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/Footer.java": 53,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/InternalParquetRecordReader.java": 321,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/InternalParquetRecordWriter.java": 209,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/LruCache.java": 195,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/MemoryManager.java": 199,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/Offsets.java": 94,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ParquetEmptyBlockException.java": 41,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ParquetFileReader.java": 1869,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ParquetFileWriter.java": 1731,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ParquetInputFormat.java": 837,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ParquetInputSplit.java": 295,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ParquetMemoryManagerRuntimeException.java": 38,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ParquetOutputCommitter.java": 112,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ParquetOutputFormat.java": 570,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ParquetReader.java": 379,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ParquetRecordReader.java": 233,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ParquetRecordWriter.java": 184,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ParquetWriter.java": 744,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/PrintFooter.java": 265,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/UnmaterializableRecordCounter.java": 103,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/api/DelegatingReadSupport.java": 60,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/api/DelegatingWriteSupport.java": 69,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/api/InitContext.java": 99,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/api/ReadSupport.java": 145,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/api/WriteSupport.java": 140,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/api/package-info.java": 27,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/codec/CleanUtil.java": 111,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/codec/CodecConfig.java": 167,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/codec/Lz4RawCodec.java": 112,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/codec/Lz4RawCompressor.java": 44,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/codec/Lz4RawDecompressor.java": 46,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/codec/NonBlockedCompressor.java": 192,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/codec/NonBlockedCompressorStream.java": 50,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/codec/NonBlockedDecompressor.java": 180,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/codec/NonBlockedDecompressorStream.java": 57,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/codec/SnappyCodec.java": 105,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/codec/SnappyCompressor.java": 38,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/codec/SnappyDecompressor.java": 38,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/codec/SnappyUtil.java": 33,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/codec/ZstandardCodec.java": 130,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/codec/ZstdCompressorStream.java": 70,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/codec/ZstdDecompressorStream.java": 62,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/example/ExampleInputFormat.java": 35,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/example/ExampleOutputFormat.java": 58,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/example/ExampleParquetWriter.java": 118,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/example/GroupReadSupport.java": 49,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/example/GroupWriteSupport.java": 88,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/mapred/Container.java": 37,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/mapred/DeprecatedParquetInputFormat.java": 209,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/mapred/DeprecatedParquetOutputFormat.java": 119,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/mapred/MapredParquetOutputCommitter.java": 42,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/metadata/BlockMetaData.java": 153,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/metadata/ColumnChunkMetaData.java": 683,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/metadata/ColumnChunkProperties.java": 118,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/metadata/ConcatenatingKeyValueMetadataMergeStrategy.java": 61,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/metadata/EncodingList.java": 81,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/metadata/FileMetaData.java": 108,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/metadata/GlobalMetaData.java": 110,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/metadata/KeyValueMetadataMergeStrategy.java": 42,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/metadata/ParquetMetadata.java": 134,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/metadata/StrictKeyValueMetadataMergeStrategy.java": 42,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/package-info.java": 33,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/rewrite/MaskMode.java": 38,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/rewrite/ParquetRewriter.java": 819,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/rewrite/RewriteOptions.java": 262,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/util/ColumnEncryptor.java": 90,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/util/ColumnMasker.java": 98,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/util/ColumnPruner.java": 42,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/util/CompressionConverter.java": 81,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/util/ConfigurationUtil.java": 44,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/util/ContextUtil.java": 315,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/util/H1SeekableInputStream.java": 59,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/util/H2SeekableInputStream.java": 99,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/util/HadoopCodecs.java": 39,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/util/HadoopInputFile.java": 76,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/util/HadoopOutputFile.java": 105,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/util/HadoopPositionOutputStream.java": 66,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/util/HadoopStreams.java": 148,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/util/HiddenFileFilter.java": 39,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/util/SerializationUtil.java": 93,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/util/counters/BenchmarkCounter.java": 112,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/util/counters/CounterLoader.java": 27,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/util/counters/ICounter.java": 28,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/util/counters/mapred/MapRedCounterAdapter.java": 43,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/util/counters/mapred/MapRedCounterLoader.java": 51,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/util/counters/mapreduce/MapReduceCounterAdapter.java": 44,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/util/counters/mapreduce/MapReduceCounterLoader.java": 47,
                "parquet-hadoop/src/main/java/org/apache/parquet/internal/hadoop/metadata/IndexReference.java": 41,
                "parquet-hadoop/src/test/java/org/apache/parquet/DirectWriterTest.java": 102,
                "parquet-hadoop/src/test/java/org/apache/parquet/crypto/DecryptionKeyRetrieverMock.java": 41,
                "parquet-hadoop/src/test/java/org/apache/parquet/crypto/DecryptionPropertiesFactoryTest.java": 43,
                "parquet-hadoop/src/test/java/org/apache/parquet/crypto/EncryptionPropertiesFactoryTest.java": 45,
                "parquet-hadoop/src/test/java/org/apache/parquet/crypto/SampleDecryptionPropertiesFactory.java": 57,
                "parquet-hadoop/src/test/java/org/apache/parquet/crypto/SampleEncryptionPropertiesFactory.java": 58,
                "parquet-hadoop/src/test/java/org/apache/parquet/crypto/SingleRow.java": 139,
                "parquet-hadoop/src/test/java/org/apache/parquet/crypto/TestPropertiesDrivenEncryption.java": 705,
                "parquet-hadoop/src/test/java/org/apache/parquet/crypto/keytools/mocks/InMemoryKMS.java": 116,
                "parquet-hadoop/src/test/java/org/apache/parquet/crypto/keytools/mocks/LocalWrapInMemoryKMS.java": 79,
                "parquet-hadoop/src/test/java/org/apache/parquet/crypto/keytools/samples/VaultClient.java": 184,
                "parquet-hadoop/src/test/java/org/apache/parquet/crypto/propertiesfactory/SchemaControlEncryptionTest.java": 250,
                "parquet-hadoop/src/test/java/org/apache/parquet/crypto/propertiesfactory/SchemaCryptoPropertiesFactory.java": 137,
                "parquet-hadoop/src/test/java/org/apache/parquet/encodings/FileEncodingsIT.java": 564,
                "parquet-hadoop/src/test/java/org/apache/parquet/filter2/TestFiltersWithMissingColumns.java": 275,
                "parquet-hadoop/src/test/java/org/apache/parquet/filter2/compat/TestRowGroupFilter.java": 128,
                "parquet-hadoop/src/test/java/org/apache/parquet/filter2/dictionarylevel/DictionaryFilterTest.java": 839,
                "parquet-hadoop/src/test/java/org/apache/parquet/filter2/recordlevel/PhoneBookWriter.java": 373,
                "parquet-hadoop/src/test/java/org/apache/parquet/filter2/recordlevel/TestRecordLevelFilters.java": 310,
                "parquet-hadoop/src/test/java/org/apache/parquet/filter2/statisticslevel/TestStatisticsFilter.java": 561,
                "parquet-hadoop/src/test/java/org/apache/parquet/format/converter/TestParquetMetadataConverter.java": 1389,
                "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/DeprecatedInputFormatTest.java": 346,
                "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/DeprecatedOutputFormatTest.java": 108,
                "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/ITTestEncryptionOptions.java": 50,
                "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/TestAdaptiveBlockSplitBloomFiltering.java": 78,
                "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/TestBloomFiltering.java": 421,
                "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/TestColumnChunkPageWriteStore.java": 288,
                "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/TestColumnIndexFiltering.java": 617,
                "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/TestDataPageV1Checksums.java": 563,
                "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/TestDirectCodecFactory.java": 178,
                "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/TestEncryptionOptions.java": 752,
                "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/TestInputFormat.java": 555,
                "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/TestInputFormatColumnProjection.java": 180,
                "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/TestInputOutputFormatWithPadding.java": 214,
                "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/TestLargeColumnChunk.java": 145,
                "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/TestLruCache.java": 162,
                "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/TestMemoryManager.java": 189,
                "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/TestMergeMetadataFiles.java": 221,
                "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/TestMultipleWriteRead.java": 250,
                "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/TestParquetFileWriter.java": 1218,
                "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/TestParquetOutputFormatJobSummaryLevel.java": 69,
                "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/TestParquetReader.java": 198,
                "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/TestParquetReaderEmptyBlock.java": 170,
                "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/TestParquetReaderRandomAccess.java": 387,
                "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/TestParquetWriter.java": 431,
                "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/TestParquetWriterAppendBlocks.java": 361,
                "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/TestParquetWriterNewPage.java": 136,
                "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/TestParquetWriterTruncation.java": 125,
                "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/TestReadWriteEncodingStats.java": 122,
                "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/TestSnappyCodec.java": 140,
                "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/TestStoreBloomFilter.java": 132,
                "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/TestUtils.java": 85,
                "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/TestZstandardCodec.java": 173,
                "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/codec/CodecConfigTest.java": 77,
                "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/codec/TestCompressionCodec.java": 177,
                "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/codec/TestInteropReadLz4RawCodec.java": 129,
                "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/example/GroupReadSupportTest.java": 65,
                "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/example/TestInputOutputFormat.java": 364,
                "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/metadata/TestColumnChunkMetaData.java": 83,
                "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/rewrite/ParquetRewriterTest.java": 772,
                "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/util/ColumnEncryptorTest.java": 315,
                "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/util/ColumnMaskerTest.java": 223,
                "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/util/ColumnPrunerTest.java": 246,
                "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/util/CompressionConverterTest.java": 312,
                "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/util/EncDecProperties.java": 94,
                "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/util/EncryptionTestFile.java": 38,
                "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/util/MockHadoopInputStream.java": 87,
                "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/util/TestFileBuilder.java": 198,
                "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/util/TestHadoop2ByteBufferReads.java": 446,
                "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/util/TestSerializationUtil.java": 71,
                "parquet-hadoop/src/test/java/org/apache/parquet/statistics/DataGenerationContext.java": 85,
                "parquet-hadoop/src/test/java/org/apache/parquet/statistics/RandomValues.java": 383,
                "parquet-hadoop/src/test/java/org/apache/parquet/statistics/TestColumnIndexes.java": 304,
                "parquet-hadoop/src/test/java/org/apache/parquet/statistics/TestStatistics.java": 459,
                "parquet-pig/src/main/java/org/apache/parquet/pig/ParquetLoader.java": 575,
                "parquet-pig/src/main/java/org/apache/parquet/pig/ParquetStorer.java": 152,
                "parquet-pig/src/main/java/org/apache/parquet/pig/PigMetaData.java": 91,
                "parquet-pig/src/main/java/org/apache/parquet/pig/PigSchemaConverter.java": 551,
                "parquet-pig/src/main/java/org/apache/parquet/pig/SchemaConversionException.java": 44,
                "parquet-pig/src/main/java/org/apache/parquet/pig/TupleConversionException.java": 42,
                "parquet-pig/src/main/java/org/apache/parquet/pig/TupleReadSupport.java": 191,
                "parquet-pig/src/main/java/org/apache/parquet/pig/TupleWriteSupport.java": 209,
                "parquet-pig/src/main/java/org/apache/parquet/pig/convert/DecimalUtils.java": 65,
                "parquet-pig/src/main/java/org/apache/parquet/pig/convert/MapConverter.java": 190,
                "parquet-pig/src/main/java/org/apache/parquet/pig/convert/ParentValueContainer.java": 32,
                "parquet-pig/src/main/java/org/apache/parquet/pig/convert/TupleConverter.java": 592,
                "parquet-pig/src/main/java/org/apache/parquet/pig/convert/TupleRecordMaterializer.java": 50,
                "parquet-pig/src/main/java/org/apache/parquet/pig/summary/BagSummaryData.java": 72,
                "parquet-pig/src/main/java/org/apache/parquet/pig/summary/EnumStat.java": 115,
                "parquet-pig/src/main/java/org/apache/parquet/pig/summary/FieldSummaryData.java": 178,
                "parquet-pig/src/main/java/org/apache/parquet/pig/summary/MapSummaryData.java": 85,
                "parquet-pig/src/main/java/org/apache/parquet/pig/summary/NumberSummaryData.java": 47,
                "parquet-pig/src/main/java/org/apache/parquet/pig/summary/StringSummaryData.java": 82,
                "parquet-pig/src/main/java/org/apache/parquet/pig/summary/Summary.java": 224,
                "parquet-pig/src/main/java/org/apache/parquet/pig/summary/SummaryData.java": 135,
                "parquet-pig/src/main/java/org/apache/parquet/pig/summary/TupleSummaryData.java": 98,
                "parquet-pig/src/main/java/org/apache/parquet/pig/summary/ValueStat.java": 64,
                "parquet-pig/src/test/java/org/apache/parquet/pig/PerfTest.java": 104,
                "parquet-pig/src/test/java/org/apache/parquet/pig/PerfTest2.java": 185,
                "parquet-pig/src/test/java/org/apache/parquet/pig/PerfTestReadAllCols.java": 47,
                "parquet-pig/src/test/java/org/apache/parquet/pig/TestDecimalUtils.java": 79,
                "parquet-pig/src/test/java/org/apache/parquet/pig/TestParquetLoader.java": 367,
                "parquet-pig/src/test/java/org/apache/parquet/pig/TestParquetStorer.java": 264,
                "parquet-pig/src/test/java/org/apache/parquet/pig/TestPigSchemaConverter.java": 291,
                "parquet-pig/src/test/java/org/apache/parquet/pig/TestTupleRecordConsumer.java": 210,
                "parquet-pig/src/test/java/org/apache/parquet/pig/TupleConsumerPerfTest.java": 206,
                "parquet-pig/src/test/java/org/apache/parquet/pig/summary/TestSummary.java": 158,
                "parquet-plugins/parquet-encoding-vector/src/main/java/org/apache/parquet/column/values/bitpacking/ByteBitPacking512VectorLE.java": 3010,
                "parquet-plugins/parquet-encoding-vector/src/main/java/org/apache/parquet/column/values/bitpacking/ParquetReadRouter.java": 133,
                "parquet-plugins/parquet-encoding-vector/src/main/java/org/apache/parquet/column/values/bitpacking/VectorSupport.java": 27,
                "parquet-plugins/parquet-encoding-vector/src/test/java/org/apache/parquet/column/values/bitpacking/TestByteBitPacking512VectorLE.java": 169,
                "parquet-plugins/parquet-encoding-vector/src/test/java/org/apache/parquet/column/values/bitpacking/TestParquetReadRouter.java": 59,
                "parquet-plugins/parquet-plugins-benchmarks/src/main/java/org/apache/parquet/plugins/benchmarks/ByteBitPackingVectorBenchmarks.java": 92,
                "parquet-protobuf/src/main/java/org/apache/parquet/proto/ProtoConstants.java": 46,
                "parquet-protobuf/src/main/java/org/apache/parquet/proto/ProtoMessageConverter.java": 599,
                "parquet-protobuf/src/main/java/org/apache/parquet/proto/ProtoParquetInputFormat.java": 38,
                "parquet-protobuf/src/main/java/org/apache/parquet/proto/ProtoParquetOutputFormat.java": 52,
                "parquet-protobuf/src/main/java/org/apache/parquet/proto/ProtoParquetReader.java": 101,
                "parquet-protobuf/src/main/java/org/apache/parquet/proto/ProtoParquetWriter.java": 127,
                "parquet-protobuf/src/main/java/org/apache/parquet/proto/ProtoReadSupport.java": 97,
                "parquet-protobuf/src/main/java/org/apache/parquet/proto/ProtoRecordConverter.java": 100,
                "parquet-protobuf/src/main/java/org/apache/parquet/proto/ProtoRecordMaterializer.java": 47,
                "parquet-protobuf/src/main/java/org/apache/parquet/proto/ProtoSchemaConverter.java": 297,
                "parquet-protobuf/src/main/java/org/apache/parquet/proto/ProtoWriteSupport.java": 586,
                "parquet-protobuf/src/test/java/org/apache/parquet/proto/ProtoInputOutputFormatTest.java": 618,
                "parquet-protobuf/src/test/java/org/apache/parquet/proto/ProtoRecordConverterTest.java": 363,
                "parquet-protobuf/src/test/java/org/apache/parquet/proto/ProtoSchemaConverterTest.java": 539,
                "parquet-protobuf/src/test/java/org/apache/parquet/proto/ProtoSchemaEvolutionTest.java": 133,
                "parquet-protobuf/src/test/java/org/apache/parquet/proto/ProtoWriteSupportTest.java": 1204,
                "parquet-protobuf/src/test/java/org/apache/parquet/proto/TestUtils.java": 232,
                "parquet-protobuf/src/test/java/org/apache/parquet/proto/utils/ReadUsingMR.java": 94,
                "parquet-protobuf/src/test/java/org/apache/parquet/proto/utils/WriteUsingMR.java": 121,
                "parquet-thrift/src/main/java/org/apache/parquet/hadoop/thrift/AbstractThriftWriteSupport.java": 129,
                "parquet-thrift/src/main/java/org/apache/parquet/hadoop/thrift/ParquetThriftBytesOutputFormat.java": 96,
                "parquet-thrift/src/main/java/org/apache/parquet/hadoop/thrift/ParquetThriftInputFormat.java": 66,
                "parquet-thrift/src/main/java/org/apache/parquet/hadoop/thrift/ParquetThriftOutputFormat.java": 43,
                "parquet-thrift/src/main/java/org/apache/parquet/hadoop/thrift/TBaseWriteSupport.java": 70,
                "parquet-thrift/src/main/java/org/apache/parquet/hadoop/thrift/ThriftBytesWriteSupport.java": 196,
                "parquet-thrift/src/main/java/org/apache/parquet/hadoop/thrift/ThriftReadSupport.java": 289,
                "parquet-thrift/src/main/java/org/apache/parquet/hadoop/thrift/ThriftToParquetFileWriter.java": 125,
                "parquet-thrift/src/main/java/org/apache/parquet/hadoop/thrift/ThriftWriteSupport.java": 80,
                "parquet-thrift/src/main/java/org/apache/parquet/thrift/BufferedProtocolReadToWrite.java": 738,
                "parquet-thrift/src/main/java/org/apache/parquet/thrift/ConvertedField.java": 169,
                "parquet-thrift/src/main/java/org/apache/parquet/thrift/DecodingSchemaMismatchException.java": 30,
                "parquet-thrift/src/main/java/org/apache/parquet/thrift/FieldIgnoredHandler.java": 45,
                "parquet-thrift/src/main/java/org/apache/parquet/thrift/KeepOnlyFirstPrimitiveFilter.java": 44,
                "parquet-thrift/src/main/java/org/apache/parquet/thrift/ParquetProtocol.java": 282,
                "parquet-thrift/src/main/java/org/apache/parquet/thrift/ParquetReadProtocol.java": 164,
                "parquet-thrift/src/main/java/org/apache/parquet/thrift/ParquetWriteProtocol.java": 778,
                "parquet-thrift/src/main/java/org/apache/parquet/thrift/ProtocolPipe.java": 29,
                "parquet-thrift/src/main/java/org/apache/parquet/thrift/ProtocolReadToWrite.java": 142,
                "parquet-thrift/src/main/java/org/apache/parquet/thrift/SkippableException.java": 47,
                "parquet-thrift/src/main/java/org/apache/parquet/thrift/TBaseRecordConverter.java": 61,
                "parquet-thrift/src/main/java/org/apache/parquet/thrift/ThriftMetaData.java": 147,
                "parquet-thrift/src/main/java/org/apache/parquet/thrift/ThriftParquetReader.java": 139,
                "parquet-thrift/src/main/java/org/apache/parquet/thrift/ThriftParquetWriter.java": 52,
                "parquet-thrift/src/main/java/org/apache/parquet/thrift/ThriftReader.java": 28,
                "parquet-thrift/src/main/java/org/apache/parquet/thrift/ThriftRecordConverter.java": 954,
                "parquet-thrift/src/main/java/org/apache/parquet/thrift/ThriftSchemaConvertVisitor.java": 409,
                "parquet-thrift/src/main/java/org/apache/parquet/thrift/ThriftSchemaConverter.java": 226,
                "parquet-thrift/src/main/java/org/apache/parquet/thrift/pig/ParquetThriftStorer.java": 90,
                "parquet-thrift/src/main/java/org/apache/parquet/thrift/pig/TupleToThriftWriteSupport.java": 79,
                "parquet-thrift/src/main/java/org/apache/parquet/thrift/projection/FieldProjectionFilter.java": 62,
                "parquet-thrift/src/main/java/org/apache/parquet/thrift/projection/FieldsPath.java": 87,
                "parquet-thrift/src/main/java/org/apache/parquet/thrift/projection/StrictFieldProjectionFilter.java": 187,
                "parquet-thrift/src/main/java/org/apache/parquet/thrift/projection/ThriftProjectionException.java": 45,
                "parquet-thrift/src/main/java/org/apache/parquet/thrift/projection/amend/DefaultEventsVisitor.java": 228,
                "parquet-thrift/src/main/java/org/apache/parquet/thrift/projection/amend/DefaultProtocolEventsGenerator.java": 68,
                "parquet-thrift/src/main/java/org/apache/parquet/thrift/projection/amend/ProtocolEventsAmender.java": 171,
                "parquet-thrift/src/main/java/org/apache/parquet/thrift/projection/amend/ReadFieldBeginProtocol.java": 44,
                "parquet-thrift/src/main/java/org/apache/parquet/thrift/projection/deprecated/DeprecatedFieldProjectionFilter.java": 106,
                "parquet-thrift/src/main/java/org/apache/parquet/thrift/projection/deprecated/PathGlobPattern.java": 173,
                "parquet-thrift/src/main/java/org/apache/parquet/thrift/struct/CompatibilityChecker.java": 265,
                "parquet-thrift/src/main/java/org/apache/parquet/thrift/struct/CompatibilityRunner.java": 104,
                "parquet-thrift/src/main/java/org/apache/parquet/thrift/struct/JSON.java": 50,
                "parquet-thrift/src/main/java/org/apache/parquet/thrift/struct/ThriftField.java": 121,
                "parquet-thrift/src/main/java/org/apache/parquet/thrift/struct/ThriftType.java": 698,
                "parquet-thrift/src/main/java/org/apache/parquet/thrift/struct/ThriftTypeID.java": 108,
                "parquet-thrift/src/test/java/org/apache/parquet/hadoop/thrift/TestArrayCompatibility.java": 779,
                "parquet-thrift/src/test/java/org/apache/parquet/hadoop/thrift/TestBinary.java": 86,
                "parquet-thrift/src/test/java/org/apache/parquet/hadoop/thrift/TestCorruptThriftRecords.java": 213,
                "parquet-thrift/src/test/java/org/apache/parquet/hadoop/thrift/TestInputOutputFormat.java": 258,
                "parquet-thrift/src/test/java/org/apache/parquet/hadoop/thrift/TestParquetToThriftReadWriteAndProjection.java": 385,
                "parquet-thrift/src/test/java/org/apache/parquet/hadoop/thrift/TestThriftToParquetFileWriter.java": 360,
                "parquet-thrift/src/test/java/org/apache/parquet/thrift/TestParquetReadProtocol.java": 173,
                "parquet-thrift/src/test/java/org/apache/parquet/thrift/TestParquetWriteProtocol.java": 719,
                "parquet-thrift/src/test/java/org/apache/parquet/thrift/TestProtocolReadToWrite.java": 384,
                "parquet-thrift/src/test/java/org/apache/parquet/thrift/TestThriftMetaData.java": 56,
                "parquet-thrift/src/test/java/org/apache/parquet/thrift/TestThriftParquetReaderWriter.java": 83,
                "parquet-thrift/src/test/java/org/apache/parquet/thrift/TestThriftRecordConverter.java": 101,
                "parquet-thrift/src/test/java/org/apache/parquet/thrift/TestThriftSchemaConvertVisitor.java": 178,
                "parquet-thrift/src/test/java/org/apache/parquet/thrift/TestThriftSchemaConverter.java": 353,
                "parquet-thrift/src/test/java/org/apache/parquet/thrift/TestThriftSchemaConverterProjectUnion.java": 480,
                "parquet-thrift/src/test/java/org/apache/parquet/thrift/TestThriftToPigCompatibility.java": 171,
                "parquet-thrift/src/test/java/org/apache/parquet/thrift/pig/TestParquetThriftStorer.java": 82,
                "parquet-thrift/src/test/java/org/apache/parquet/thrift/projection/TestFieldsPath.java": 162,
                "parquet-thrift/src/test/java/org/apache/parquet/thrift/projection/TestStrictFieldProjectionFilter.java": 119,
                "parquet-thrift/src/test/java/org/apache/parquet/thrift/projection/deprecated/PathGlobPatternTest.java": 59,
                "parquet-thrift/src/test/java/org/apache/parquet/thrift/struct/CompatibilityCheckerTest.java": 132,
                "parquet-thrift/src/test/java/org/apache/parquet/thrift/struct/TestThriftType.java": 70
            },
            "is_test": true,
            "is_fix": false
        },
        "37b704153bc2bf50129b9e0a6ada3e2530876114": {
            "datetime": "2013-03-11T13:53:01-07:00",
            "summary": "better tests for new summary file",
            "message": "better tests for new summary file\n",
            "diff": {
                "parquet-hadoop/src/main/java/parquet/hadoop/Footer.java": 4,
                "parquet-hadoop/src/main/java/parquet/hadoop/ParquetFileReader.java": 5,
                "parquet-hadoop/src/test/java/parquet/hadoop/TestParquetFileWriter.java": 69
            },
            "is_test": true,
            "is_fix": false
        },
        "aa6dca8666b7f05e02c09f424e29f6f964c5a273": {
            "datetime": "2013-03-11T14:19:02-07:00",
            "summary": "integrate thrift format changes",
            "message": "integrate thrift format changes\n",
            "diff": {
                "parquet-hadoop/src/main/java/parquet/format/converter/ParquetMetadataConverter.java": 9,
                "parquet-hadoop/src/test/java/parquet/hadoop/example/TestInputOutputFormat.java": 4
            },
            "is_test": true,
            "is_fix": false
        },
        "dabb797e22c21f49f58fce64ad536d45b529efb1": {
            "datetime": "2013-03-11T14:19:47-07:00",
            "summary": "Merge pull request #8 from Parquet/metadata_file",
            "message": "Merge pull request #8 from Parquet/metadata_file\n\nMetadata file in parquet format",
            "diff": {
                "parquet-hadoop/src/main/java/parquet/format/converter/ParquetMetadataConverter.java": 18,
                "parquet-hadoop/src/main/java/parquet/hadoop/Footer.java": 4,
                "parquet-hadoop/src/main/java/parquet/hadoop/ParquetFileReader.java": 34,
                "parquet-hadoop/src/main/java/parquet/hadoop/ParquetFileWriter.java": 72,
                "parquet-hadoop/src/main/java/parquet/hadoop/PrintFooter.java": 4,
                "parquet-hadoop/src/main/java/parquet/hadoop/metadata/BlockMetaData.java": 16,
                "parquet-hadoop/src/main/java/parquet/hadoop/metadata/FileMetaData.java": 8,
                "parquet-hadoop/src/test/java/parquet/hadoop/TestParquetFileWriter.java": 110,
                "parquet-hadoop/src/test/java/parquet/hadoop/example/TestInputOutputFormat.java": 5
            },
            "is_test": true,
            "is_fix": false
        },
        "11c34bf287a5eb78b5878355c6d5ad2dfe1689fe": {
            "datetime": "2013-03-11T14:21:04-07:00",
            "summary": "Merge branch 'master' of github.com:Parquet/parquet-mr",
            "message": "Merge branch 'master' of github.com:Parquet/parquet-mr\n",
            "diff": {
                "parquet-hadoop/src/main/java/parquet/format/converter/ParquetMetadataConverter.java": 18,
                "parquet-hadoop/src/main/java/parquet/hadoop/Footer.java": 4,
                "parquet-hadoop/src/main/java/parquet/hadoop/ParquetFileReader.java": 34,
                "parquet-hadoop/src/main/java/parquet/hadoop/ParquetFileWriter.java": 72,
                "parquet-hadoop/src/main/java/parquet/hadoop/PrintFooter.java": 4,
                "parquet-hadoop/src/main/java/parquet/hadoop/metadata/BlockMetaData.java": 16,
                "parquet-hadoop/src/main/java/parquet/hadoop/metadata/FileMetaData.java": 8,
                "parquet-hadoop/src/test/java/parquet/hadoop/TestParquetFileWriter.java": 110,
                "parquet-hadoop/src/test/java/parquet/hadoop/example/TestInputOutputFormat.java": 5
            },
            "is_test": true,
            "is_fix": false
        },
        "bdec17ea2af932e60db3133d3d13cad7fa6e74f6": {
            "datetime": "2013-03-11T15:01:50-07:00",
            "summary": "integrate Todd's feedback",
            "message": "integrate Todd's feedback\n",
            "diff": {
                "parquet-column/src/main/java/parquet/bytes/BytesUtils.java": 4
            },
            "is_test": false,
            "is_fix": false
        },
        "7bd223aba6584ea4caa3b40180c2c414be9e185f": {
            "datetime": "2013-03-12T08:15:51-07:00",
            "summary": "improved OutputFormat javadoc and defaults",
            "message": "improved OutputFormat javadoc and defaults\n",
            "diff": {
                "parquet-hadoop/src/main/java/parquet/hadoop/ParquetOutputFormat.java": 30
            },
            "is_test": false,
            "is_fix": false
        },
        "241634e6990bb929236863b985d362e6cc8698a7": {
            "datetime": "2013-03-12T18:14:34-07:00",
            "summary": "better exception when reading unknown field",
            "message": "better exception when reading unknown field\n",
            "diff": {
                "parquet-thrift/src/main/java/parquet/thrift/ParquetWriteProtocol.java": 15
            },
            "is_test": false,
            "is_fix": false
        },
        "de8bc0d11b0834aca31f65159c641e4051844ac1": {
            "datetime": "2013-03-12T21:19:18-07:00",
            "summary": "fix java 6 compiler compatibility",
            "message": "fix java 6 compiler compatibility\n",
            "diff": {
                "parquet-column/src/main/java/parquet/io/api/Binary.java": 4
            },
            "is_test": false,
            "is_fix": false
        },
        "5fe97c8b3a293cd37e7dfc2f611a370bab6a9b0f": {
            "datetime": "2013-03-12T21:20:07-07:00",
            "summary": "add pig schema in thrift metadata",
            "message": "add pig schema in thrift metadata\n",
            "diff": {
                "parquet-pig/src/main/java/parquet/pig/PigMetaData.java": 7,
                "parquet-pig/src/main/java/parquet/pig/TupleWriteSupport.java": 3,
                "parquet-thrift/src/main/java/parquet/hadoop/thrift/ThriftWriteSupport.java": 10
            },
            "is_test": false,
            "is_fix": false
        },
        "65364a46bc72bb99fbdc4f19cb51a0db2ab8030e": {
            "datetime": "2013-03-14T11:12:18-07:00",
            "summary": "fix map of primitive; add thrift to pig compat",
            "message": "fix map of primitive; add thrift to pig compat\n",
            "diff": {
                "parquet-pig/src/main/java/parquet/pig/PigSchemaConverter.java": 2,
                "parquet-pig/src/main/java/parquet/pig/TupleReadSupport.java": 4,
                "parquet-pig/src/main/java/parquet/pig/convert/MapConverter.java": 47,
                "parquet-pig/src/main/java/parquet/pig/convert/TupleConverter.java": 238,
                "parquet-pig/src/main/java/parquet/pig/convert/TupleRecordConverter.java": 4,
                "parquet-pig/src/main/java/parquet/pig/convert/ValueContainer.java": 28,
                "parquet-thrift/src/test/java/parquet/thrift/TestParquetWriteProtocol.java": 13,
                "parquet-thrift/src/test/java/parquet/thrift/TestThriftToPigCompatibility.java": 165
            },
            "is_test": true,
            "is_fix": false
        },
        "c44ff2de4cb9ddc8d8ae42f4cf8336902d7208a3": {
            "datetime": "2013-03-14T11:23:55-07:00",
            "summary": "cleanup",
            "message": "cleanup\n",
            "diff": {
                "parquet-pig/src/main/java/parquet/pig/convert/MapConverter.java": 2,
                "parquet-pig/src/main/java/parquet/pig/convert/TupleConverter.java": 3,
                "parquet-thrift/src/test/java/parquet/thrift/TestThriftToPigCompatibility.java": 2
            },
            "is_test": true,
            "is_fix": false
        },
        "ef0069eecb6448270b5ca60fb82caf8ab77811b0": {
            "datetime": "2013-03-14T15:58:32-07:00",
            "summary": "incorporate feddback; more tests",
            "message": "incorporate feddback; more tests\n",
            "diff": {
                "parquet-column/src/main/java/parquet/example/data/Group.java": 18,
                "parquet-column/src/test/java/parquet/io/TestColumnIO.java": 41,
                "parquet-pig/src/main/java/parquet/pig/convert/MapConverter.java": 29,
                "parquet-pig/src/main/java/parquet/pig/convert/TupleConverter.java": 92,
                "parquet-pig/src/main/java/parquet/pig/convert/ValueContainer.java": 6
            },
            "is_test": true,
            "is_fix": false
        },
        "82d5d85e9c5483a124c8436ae403219262006878": {
            "datetime": "2013-03-14T16:00:01-07:00",
            "summary": "Merge pull request #13 from Parquet/thrift_to_pig_compat",
            "message": "Merge pull request #13 from Parquet/thrift_to_pig_compat\n\nfix map of primitive; add thrift to pig compat",
            "diff": {
                "parquet-column/src/main/java/parquet/example/data/Group.java": 18,
                "parquet-column/src/test/java/parquet/io/TestColumnIO.java": 41,
                "parquet-pig/src/main/java/parquet/pig/PigSchemaConverter.java": 2,
                "parquet-pig/src/main/java/parquet/pig/TupleReadSupport.java": 4,
                "parquet-pig/src/main/java/parquet/pig/convert/MapConverter.java": 70,
                "parquet-pig/src/main/java/parquet/pig/convert/ParentValueContainer.java": 32,
                "parquet-pig/src/main/java/parquet/pig/convert/TupleConverter.java": 287,
                "parquet-pig/src/main/java/parquet/pig/convert/TupleRecordConverter.java": 4,
                "parquet-thrift/src/test/java/parquet/thrift/TestParquetWriteProtocol.java": 13,
                "parquet-thrift/src/test/java/parquet/thrift/TestThriftToPigCompatibility.java": 163
            },
            "is_test": true,
            "is_fix": false
        },
        "e93e35cfe4e102b9b98deb171065509fe6668ba9": {
            "datetime": "2013-03-15T13:26:45-07:00",
            "summary": "fix metadata file in mr mode",
            "message": "fix metadata file in mr mode\n",
            "diff": {
                "parquet-hadoop/src/main/java/parquet/hadoop/ParquetFileReader.java": 2,
                "parquet-hadoop/src/main/java/parquet/hadoop/ParquetFileWriter.java": 1,
                "parquet-hadoop/src/main/java/parquet/hadoop/ParquetOutputCommitter.java": 14,
                "parquet-hadoop/src/main/java/parquet/hadoop/ParquetRecordWriter.java": 10
            },
            "is_test": false,
            "is_fix": false
        },
        "df3e94ad9e4d6cd87f487087616d220e90cf192e": {
            "datetime": "2013-03-15T15:36:45-07:00",
            "summary": "change default level encoding to bit packed; instanciate reader from page header encoding",
            "message": "change default level encoding to bit packed; instanciate reader from page header encoding\n",
            "diff": {
                "parquet-column/src/main/java/parquet/column/Encoding.java": 57,
                "parquet-column/src/main/java/parquet/column/impl/ColumnReaderImpl.java": 22,
                "parquet-column/src/main/java/parquet/column/impl/ColumnWriterImpl.java": 13,
                "parquet-column/src/main/java/parquet/column/page/Page.java": 38,
                "parquet-column/src/main/java/parquet/column/page/PageWriter.java": 5,
                "parquet-column/src/main/java/parquet/column/values/DataValuesWriter.java": 13,
                "parquet-column/src/main/java/parquet/column/values/ValuesWriter.java": 7,
                "parquet-column/src/main/java/parquet/column/values/bitpacking/BitPackingValuesWriter.java": 7,
                "parquet-column/src/main/java/parquet/column/values/boundedint/BoundedIntValuesWriter.java": 9,
                "parquet-column/src/main/java/parquet/column/values/boundedint/DevNullValuesWriter.java": 7,
                "parquet-column/src/main/java/parquet/column/values/plain/BooleanPlainValuesWriter.java": 4,
                "parquet-column/src/main/java/parquet/column/values/plain/PlainValuesWriter.java": 4,
                "parquet-column/src/test/java/parquet/column/mem/TestMemPageStore.java": 10,
                "parquet-column/src/test/java/parquet/column/page/mem/MemPageWriter.java": 5,
                "parquet-hadoop/src/main/java/parquet/format/converter/ParquetMetadataConverter.java": 24,
                "parquet-hadoop/src/main/java/parquet/hadoop/ColumnChunkPageReadStore.java": 4,
                "parquet-hadoop/src/main/java/parquet/hadoop/ColumnChunkPageWriteStore.java": 10,
                "parquet-hadoop/src/main/java/parquet/hadoop/ParquetFileReader.java": 3,
                "parquet-hadoop/src/main/java/parquet/hadoop/ParquetFileWriter.java": 14,
                "parquet-hadoop/src/test/java/parquet/hadoop/TestParquetFileWriter.java": 32,
                "parquet-pig/src/test/java/parquet/pig/GenerateIntTestFile.java": 9
            },
            "is_test": true,
            "is_fix": false
        },
        "4828f1dcf1dc1fa2d1b33617469885acf632af69": {
            "datetime": "2013-03-18T08:33:56-07:00",
            "summary": "fix metadata conversion",
            "message": "fix metadata conversion\n",
            "diff": {
                "parquet-hadoop/src/main/java/parquet/format/converter/ParquetMetadataConverter.java": 39
            },
            "is_test": false,
            "is_fix": false
        },
        "d81380a358cbb8100d99ac0e0f9ea1fdcd144738": {
            "datetime": "2013-03-18T10:13:54-07:00",
            "summary": "add test to ensure enums are equivalent",
            "message": "add test to ensure enums are equivalent\n",
            "diff": {
                "parquet-column/src/main/java/parquet/column/Encoding.java": 20,
                "parquet-column/src/main/java/parquet/schema/PrimitiveType.java": 42,
                "parquet-hadoop/src/main/java/parquet/format/converter/ParquetMetadataConverter.java": 22,
                "parquet-hadoop/src/test/java/parquet/format/converter/TestParquetMetadataConverter.java": 31
            },
            "is_test": true,
            "is_fix": false
        },
        "e0879089422d33387d25acce29d5cc39e29cfcfd": {
            "datetime": "2013-03-18T10:50:34-07:00",
            "summary": "integrate elaphantbird 3.0.8",
            "message": "integrate elaphantbird 3.0.8\n",
            "diff": {
                "parquet-thrift/src/main/java/parquet/thrift/ThriftSchemaConverter.java": 80,
                "parquet-thrift/src/main/java/parquet/thrift/struct/ThriftField.java": 9,
                "parquet-thrift/src/test/java/parquet/thrift/TestParquetReadProtocol.java": 2,
                "parquet-thrift/src/test/java/parquet/thrift/TestProtocolReadToWrite.java": 3,
                "parquet-thrift/src/test/java/parquet/thrift/TestThriftSchemaConverter.java": 5
            },
            "is_test": true,
            "is_fix": false
        },
        "071b8f4626f125c81a01a5c07111d4d52102dbdf": {
            "datetime": "2013-03-19T11:14:56-07:00",
            "summary": "change ReadSupport api to fix projection support",
            "message": "change ReadSupport api to fix projection support\n",
            "diff": {
                "parquet-column/src/main/java/parquet/schema/MessageType.java": 6,
                "parquet-column/src/main/java/parquet/schema/PrimitiveType.java": 2,
                "parquet-column/src/main/java/parquet/schema/Type.java": 4,
                "parquet-hadoop/src/main/java/parquet/format/converter/ParquetMetadataConverter.java": 7,
                "parquet-hadoop/src/main/java/parquet/hadoop/ParquetFileReader.java": 2,
                "parquet-hadoop/src/main/java/parquet/hadoop/ParquetFileWriter.java": 46,
                "parquet-hadoop/src/main/java/parquet/hadoop/ParquetInputFormat.java": 76,
                "parquet-hadoop/src/main/java/parquet/hadoop/ParquetInputSplit.java": 28,
                "parquet-hadoop/src/main/java/parquet/hadoop/ParquetOutputCommitter.java": 2,
                "parquet-hadoop/src/main/java/parquet/hadoop/ParquetRecordReader.java": 36,
                "parquet-hadoop/src/main/java/parquet/hadoop/api/ReadSupport.java": 46,
                "parquet-hadoop/src/main/java/parquet/hadoop/api/WriteSupport.java": 8,
                "parquet-hadoop/src/main/java/parquet/hadoop/example/GroupReadSupport.java": 18,
                "parquet-hadoop/src/main/java/parquet/hadoop/metadata/FileMetaData.java": 33,
                "parquet-hadoop/src/main/java/parquet/hadoop/metadata/ParquetMetadata.java": 12,
                "parquet-hadoop/src/test/java/parquet/hadoop/TestInputFormat.java": 6,
                "parquet-hadoop/src/test/java/parquet/hadoop/TestParquetFileWriter.java": 18,
                "parquet-pig/src/main/java/parquet/pig/ParquetLoader.java": 35,
                "parquet-pig/src/main/java/parquet/pig/PigSchemaConverter.java": 162,
                "parquet-pig/src/main/java/parquet/pig/TupleReadSupport.java": 63,
                "parquet-pig/src/main/java/parquet/pig/convert/TupleConverter.java": 2,
                "parquet-pig/src/test/java/parquet/pig/TestPigSchemaConverter.java": 4,
                "parquet-pig/src/test/java/parquet/pig/TestTupleRecordConsumer.java": 7,
                "parquet-pig/src/test/java/parquet/pig/TupleConsumerPerfTest.java": 5,
                "parquet-thrift/src/main/java/parquet/hadoop/thrift/ThriftReadSupport.java": 16,
                "parquet-thrift/src/test/java/parquet/thrift/TestThriftToPigCompatibility.java": 3
            },
            "is_test": true,
            "is_fix": false
        },
        "cf6dbc38f4f2aa7756bd393e3607d05d32c53912": {
            "datetime": "2013-03-19T11:25:55-07:00",
            "summary": "Merge pull request #16 from Parquet/update_encodings",
            "message": "Merge pull request #16 from Parquet/update_encodings\n\nUpdate encodings",
            "diff": {
                "parquet-column/src/main/java/parquet/column/Encoding.java": 77,
                "parquet-column/src/main/java/parquet/column/impl/ColumnReaderImpl.java": 22,
                "parquet-column/src/main/java/parquet/column/impl/ColumnWriterImpl.java": 13,
                "parquet-column/src/main/java/parquet/column/page/Page.java": 38,
                "parquet-column/src/main/java/parquet/column/page/PageWriter.java": 5,
                "parquet-column/src/main/java/parquet/column/values/DataValuesWriter.java": 13,
                "parquet-column/src/main/java/parquet/column/values/ValuesWriter.java": 7,
                "parquet-column/src/main/java/parquet/column/values/bitpacking/BitPackingValuesWriter.java": 7,
                "parquet-column/src/main/java/parquet/column/values/boundedint/BoundedIntValuesWriter.java": 9,
                "parquet-column/src/main/java/parquet/column/values/boundedint/DevNullValuesWriter.java": 7,
                "parquet-column/src/main/java/parquet/column/values/plain/BooleanPlainValuesWriter.java": 4,
                "parquet-column/src/main/java/parquet/column/values/plain/PlainValuesWriter.java": 4,
                "parquet-column/src/main/java/parquet/schema/PrimitiveType.java": 42,
                "parquet-column/src/test/java/parquet/column/mem/TestMemPageStore.java": 10,
                "parquet-column/src/test/java/parquet/column/page/mem/MemPageWriter.java": 5,
                "parquet-hadoop/src/main/java/parquet/format/converter/ParquetMetadataConverter.java": 69,
                "parquet-hadoop/src/main/java/parquet/hadoop/ColumnChunkPageReadStore.java": 4,
                "parquet-hadoop/src/main/java/parquet/hadoop/ColumnChunkPageWriteStore.java": 10,
                "parquet-hadoop/src/main/java/parquet/hadoop/ParquetFileReader.java": 5,
                "parquet-hadoop/src/main/java/parquet/hadoop/ParquetFileWriter.java": 15,
                "parquet-hadoop/src/main/java/parquet/hadoop/ParquetOutputCommitter.java": 14,
                "parquet-hadoop/src/main/java/parquet/hadoop/ParquetRecordWriter.java": 10,
                "parquet-hadoop/src/test/java/parquet/format/converter/TestParquetMetadataConverter.java": 31,
                "parquet-hadoop/src/test/java/parquet/hadoop/TestParquetFileWriter.java": 32,
                "parquet-pig/src/test/java/parquet/pig/GenerateIntTestFile.java": 9,
                "parquet-thrift/src/main/java/parquet/thrift/ThriftSchemaConverter.java": 80,
                "parquet-thrift/src/main/java/parquet/thrift/struct/ThriftField.java": 9,
                "parquet-thrift/src/test/java/parquet/thrift/TestParquetReadProtocol.java": 2,
                "parquet-thrift/src/test/java/parquet/thrift/TestProtocolReadToWrite.java": 3,
                "parquet-thrift/src/test/java/parquet/thrift/TestThriftSchemaConverter.java": 5
            },
            "is_test": true,
            "is_fix": false
        },
        "5dfa1b22e5eb7f07c64f3d78bdee67fa07e5980e": {
            "datetime": "2013-03-19T15:06:41-07:00",
            "summary": "deal with elephantbird handling of numbers",
            "message": "deal with elephantbird handling of numbers\n",
            "diff": {
                "parquet-pig/src/main/java/parquet/pig/TupleReadSupport.java": 16,
                "parquet-pig/src/main/java/parquet/pig/convert/MapConverter.java": 8,
                "parquet-pig/src/main/java/parquet/pig/convert/TupleConverter.java": 57,
                "parquet-pig/src/main/java/parquet/pig/convert/TupleRecordMaterializer.java": 4,
                "parquet-thrift/src/test/java/parquet/thrift/TestThriftToPigCompatibility.java": 4
            },
            "is_test": true,
            "is_fix": false
        },
        "696bce4436dcfbe5bb6aec164932bd2195f69128": {
            "datetime": "2013-03-19T15:13:40-07:00",
            "summary": "use constant for settings",
            "message": "use constant for settings\n",
            "diff": {
                "parquet-pig/src/main/java/parquet/pig/ParquetLoader.java": 4
            },
            "is_test": false,
            "is_fix": false
        },
        "f9c25b690457cc5788142feba2c31ee169b1736e": {
            "datetime": "2013-03-21T09:10:37-07:00",
            "summary": "Merge pull request #17 from Parquet/thrift_to_pig_compat2",
            "message": "Merge pull request #17 from Parquet/thrift_to_pig_compat2\n\nSlight change in ReadSupport API",
            "diff": {
                "parquet-column/src/main/java/parquet/schema/MessageType.java": 6,
                "parquet-column/src/main/java/parquet/schema/PrimitiveType.java": 2,
                "parquet-column/src/main/java/parquet/schema/Type.java": 4,
                "parquet-hadoop/src/main/java/parquet/format/converter/ParquetMetadataConverter.java": 7,
                "parquet-hadoop/src/main/java/parquet/hadoop/ParquetFileReader.java": 2,
                "parquet-hadoop/src/main/java/parquet/hadoop/ParquetFileWriter.java": 46,
                "parquet-hadoop/src/main/java/parquet/hadoop/ParquetInputFormat.java": 76,
                "parquet-hadoop/src/main/java/parquet/hadoop/ParquetInputSplit.java": 28,
                "parquet-hadoop/src/main/java/parquet/hadoop/ParquetOutputCommitter.java": 2,
                "parquet-hadoop/src/main/java/parquet/hadoop/ParquetRecordReader.java": 36,
                "parquet-hadoop/src/main/java/parquet/hadoop/api/ReadSupport.java": 46,
                "parquet-hadoop/src/main/java/parquet/hadoop/api/WriteSupport.java": 8,
                "parquet-hadoop/src/main/java/parquet/hadoop/example/GroupReadSupport.java": 18,
                "parquet-hadoop/src/main/java/parquet/hadoop/metadata/FileMetaData.java": 33,
                "parquet-hadoop/src/main/java/parquet/hadoop/metadata/ParquetMetadata.java": 12,
                "parquet-hadoop/src/test/java/parquet/hadoop/TestInputFormat.java": 6,
                "parquet-hadoop/src/test/java/parquet/hadoop/TestParquetFileWriter.java": 18,
                "parquet-pig/src/main/java/parquet/pig/ParquetLoader.java": 37,
                "parquet-pig/src/main/java/parquet/pig/PigSchemaConverter.java": 162,
                "parquet-pig/src/main/java/parquet/pig/TupleReadSupport.java": 71,
                "parquet-pig/src/main/java/parquet/pig/convert/MapConverter.java": 8,
                "parquet-pig/src/main/java/parquet/pig/convert/TupleConverter.java": 59,
                "parquet-pig/src/main/java/parquet/pig/convert/TupleRecordMaterializer.java": 4,
                "parquet-pig/src/test/java/parquet/pig/TestPigSchemaConverter.java": 4,
                "parquet-pig/src/test/java/parquet/pig/TestTupleRecordConsumer.java": 7,
                "parquet-pig/src/test/java/parquet/pig/TupleConsumerPerfTest.java": 5,
                "parquet-thrift/src/main/java/parquet/hadoop/thrift/ThriftReadSupport.java": 16,
                "parquet-thrift/src/test/java/parquet/thrift/TestThriftToPigCompatibility.java": 7
            },
            "is_test": true,
            "is_fix": false
        },
        "fce6998edbebee642c8194d8d74f90e6ab887fca": {
            "datetime": "2013-03-21T16:43:00-07:00",
            "summary": "avoid string decoding recoding",
            "message": "avoid string decoding recoding\n",
            "diff": {
                "parquet-thrift/src/main/java/parquet/thrift/ProtocolReadToWrite.java": 2
            },
            "is_test": false,
            "is_fix": false
        },
        "c625aa6a83800bf4cd648edca2ffc3c8271a2a6a": {
            "datetime": "2013-03-27T13:48:43-07:00",
            "summary": "Merge pull request #19 from Parquet/improve_thrift_perf",
            "message": "Merge pull request #19 from Parquet/improve_thrift_perf\n\navoid string decoding recoding",
            "diff": {
                "parquet-thrift/src/main/java/parquet/thrift/ProtocolReadToWrite.java": 2
            },
            "is_test": false,
            "is_fix": false
        },
        "f5b2cb8e8bfd75f65b31b8dcb153f3cd094e762c": {
            "datetime": "2013-03-27T17:58:03-07:00",
            "summary": "add better Bytes plain decoder",
            "message": "add better Bytes plain decoder\n",
            "diff": {
                "parquet-column/src/main/java/parquet/column/Encoding.java": 3,
                "parquet-column/src/main/java/parquet/column/values/plain/BinaryPlainValuesReader.java": 38,
                "parquet-column/src/main/java/parquet/column/values/plain/PlainValuesReader.java": 12
            },
            "is_test": false,
            "is_fix": false
        },
        "56faa1be0d3334fab7366c454c08da300d726e25": {
            "datetime": "2013-03-27T17:59:08-07:00",
            "summary": "first stab at dict encoding",
            "message": "first stab at dict encoding\n",
            "diff": {
                "parquet-column/src/main/java/parquet/column/values/dictionary/DictionaryColumnWriter.java": 58,
                "parquet-column/src/test/java/parquet/column/values/dictionary/TestDictionary.java": 11
            },
            "is_test": true,
            "is_fix": false
        },
        "cf5ba492d2c4acc00305c880dddc661909e66ff4": {
            "datetime": "2013-03-27T18:09:01-07:00",
            "summary": "fix perf test",
            "message": "fix perf test\n",
            "diff": {
                "parquet-column/src/main/java/parquet/example/DummyRecordConverter.java": 9,
                "parquet-column/src/test/java/parquet/io/PerfTest.java": 6
            },
            "is_test": true,
            "is_fix": false
        },
        "1b2694e462abaff27a134a2ebaed837f8a306aef": {
            "datetime": "2013-03-27T18:16:55-07:00",
            "summary": "fix offset",
            "message": "fix offset\n",
            "diff": {
                "parquet-column/src/main/java/parquet/column/values/plain/BinaryPlainValuesReader.java": 5
            },
            "is_test": false,
            "is_fix": false
        },
        "8246e0bbb229f54bf8fcb03f6133d7c5f8f4036c": {
            "datetime": "2013-03-28T11:26:13-07:00",
            "summary": "fix perf problem with new String(bytes, offset, length, encoding)",
            "message": "fix perf problem with new String(bytes, offset, length, encoding)\n",
            "diff": {
                "parquet-column/src/main/java/parquet/io/api/Binary.java": 6
            },
            "is_test": false,
            "is_fix": false
        },
        "5c60ed8459b88d44eb6c555fff8c3cd1b3e26d17": {
            "datetime": "2013-03-28T13:06:05-07:00",
            "summary": "remove one array copy",
            "message": "remove one array copy\n",
            "diff": {
                "parquet-column/src/main/java/parquet/bytes/BytesInput.java": 7,
                "parquet-column/src/main/java/parquet/column/values/plain/PlainValuesReader.java": 1
            },
            "is_test": false,
            "is_fix": false
        },
        "60a2925533d852627cdc1de26c4e973acbfbf407": {
            "datetime": "2013-03-29T17:40:38-07:00",
            "summary": "Merge pull request #20 from Parquet/perf_improvement",
            "message": "Merge pull request #20 from Parquet/perf_improvement\n\nPerf improvement",
            "diff": {
                "parquet-column/src/main/java/parquet/bytes/BytesInput.java": 7,
                "parquet-column/src/main/java/parquet/column/Encoding.java": 3,
                "parquet-column/src/main/java/parquet/column/values/plain/BinaryPlainValuesReader.java": 39,
                "parquet-column/src/main/java/parquet/column/values/plain/PlainValuesReader.java": 13,
                "parquet-column/src/main/java/parquet/example/DummyRecordConverter.java": 9,
                "parquet-column/src/main/java/parquet/io/api/Binary.java": 6,
                "parquet-column/src/test/java/parquet/io/PerfTest.java": 6
            },
            "is_test": true,
            "is_fix": false
        },
        "e18d38bc1d6527439919e61fb19c429921acdadc": {
            "datetime": "2013-04-02T18:30:35-07:00",
            "summary": "dictionary encoding",
            "message": "dictionary encoding\n",
            "diff": {
                "parquet-column/src/main/java/parquet/bytes/BytesInput.java": 8,
                "parquet-column/src/main/java/parquet/column/Dictionary.java": 25,
                "parquet-column/src/main/java/parquet/column/Encoding.java": 42,
                "parquet-column/src/main/java/parquet/column/impl/ColumnReaderImpl.java": 33,
                "parquet-column/src/main/java/parquet/column/impl/ColumnWriterImpl.java": 24,
                "parquet-column/src/main/java/parquet/column/page/DictionaryPage.java": 54,
                "parquet-column/src/main/java/parquet/column/page/PageReader.java": 7,
                "parquet-column/src/main/java/parquet/column/page/PageWriter.java": 8,
                "parquet-column/src/main/java/parquet/column/values/ValuesReader.java": 16,
                "parquet-column/src/main/java/parquet/column/values/ValuesWriter.java": 14,
                "parquet-column/src/main/java/parquet/column/values/dictionary/DictionaryColumnWriter.java": 58,
                "parquet-column/src/main/java/parquet/column/values/dictionary/DictionaryValuesReader.java": 44,
                "parquet-column/src/main/java/parquet/column/values/dictionary/DictionaryValuesWriter.java": 82,
                "parquet-column/src/main/java/parquet/column/values/dictionary/PlainDictionary.java": 42,
                "parquet-column/src/test/java/parquet/column/page/mem/MemPageReader.java": 16,
                "parquet-column/src/test/java/parquet/column/page/mem/MemPageStore.java": 2,
                "parquet-column/src/test/java/parquet/column/page/mem/MemPageWriter.java": 13,
                "parquet-column/src/test/java/parquet/column/values/dictionary/TestDictionary.java": 45,
                "parquet-hadoop/src/main/java/parquet/format/converter/ParquetMetadataConverter.java": 11,
                "parquet-hadoop/src/main/java/parquet/hadoop/ColumnChunkPageReadStore.java": 22,
                "parquet-hadoop/src/main/java/parquet/hadoop/ColumnChunkPageWriteStore.java": 14,
                "parquet-hadoop/src/main/java/parquet/hadoop/ParquetFileReader.java": 69,
                "parquet-hadoop/src/main/java/parquet/hadoop/ParquetFileWriter.java": 26
            },
            "is_test": true,
            "is_fix": false
        },
        "827a5bc4a7a00c624dd6062804ae7f4f42be16a8": {
            "datetime": "2013-04-03T08:21:08-07:00",
            "summary": "fix dictionary encoding",
            "message": "fix dictionary encoding\n",
            "diff": {
                "parquet-column/src/main/java/parquet/column/impl/ColumnWriterImpl.java": 1,
                "parquet-column/src/main/java/parquet/column/page/DictionaryPage.java": 17,
                "parquet-column/src/main/java/parquet/column/values/ValuesReader.java": 2,
                "parquet-column/src/test/java/parquet/column/page/mem/MemPageReader.java": 9,
                "parquet-column/src/test/java/parquet/column/values/dictionary/TestDictionary.java": 2,
                "parquet-hadoop/src/main/java/parquet/hadoop/ColumnChunkPageReadStore.java": 1,
                "parquet-hadoop/src/main/java/parquet/hadoop/ParquetFileWriter.java": 8
            },
            "is_test": true,
            "is_fix": false
        },
        "4a69511fea03a2f4051df3f90e1fd0f982d7def0": {
            "datetime": "2013-04-03T14:52:27-07:00",
            "summary": "dictionary encoding",
            "message": "dictionary encoding\n",
            "diff": {
                "parquet-column/src/main/java/parquet/column/impl/ColumnWriterImpl.java": 5,
                "parquet-column/src/main/java/parquet/column/values/BinaryEncodingPickerValuesWriter.java": 95,
                "parquet-column/src/main/java/parquet/column/values/ValuesWriter.java": 11,
                "parquet-column/src/main/java/parquet/column/values/dictionary/DictionaryValuesWriter.java": 4,
                "parquet-column/src/test/java/parquet/column/values/dictionary/TestDictionary.java": 41,
                "parquet-hadoop/src/main/java/parquet/format/converter/ParquetMetadataConverter.java": 2,
                "parquet-hadoop/src/main/java/parquet/hadoop/ColumnChunkPageWriteStore.java": 8,
                "parquet-hadoop/src/main/java/parquet/hadoop/ParquetFileReader.java": 7,
                "parquet-hadoop/src/main/java/parquet/hadoop/ParquetFileWriter.java": 3,
                "parquet-hadoop/src/main/java/parquet/hadoop/ParquetRecordWriter.java": 2,
                "parquet-hadoop/src/main/java/parquet/hadoop/metadata/ColumnChunkMetaData.java": 23,
                "parquet-thrift/src/test/java/parquet/thrift/TestThriftSchemaConverter.java": 1
            },
            "is_test": true,
            "is_fix": false
        },
        "90b5eae8ba0e7230dc5c379c14ebda076b4dd283": {
            "datetime": "2013-04-03T16:01:41-07:00",
            "summary": "add scrooge and cascading support",
            "message": "add scrooge and cascading support\n",
            "diff": {
                "parquet-cascading/src/main/java/parquet/cascading/ParquetTBaseScheme.java": 53,
                "parquet-cascading/src/main/java/parquet/cascading/ParquetValueScheme.java": 41,
                "parquet-hadoop/src/main/java/parquet/hadoop/ParquetInputFormat.java": 5,
                "parquet-scrooge/src/main/java/parquet/scrooge/ParquetScroogeScheme.java": 61,
                "parquet-scrooge/src/main/java/parquet/scrooge/ScroogeRecordConverter.java": 38,
                "parquet-scrooge/src/test/java/parquet/scrooge/TestScroogeIOFormats.java": 5,
                "parquet-thrift/src/main/java/parquet/hadoop/thrift/ParquetThriftInputFormat.java": 27,
                "parquet-thrift/src/main/java/parquet/hadoop/thrift/ThriftReadSupport.java": 56,
                "parquet-thrift/src/main/java/parquet/thrift/TBaseRecordConverter.java": 4,
                "parquet-thrift/src/main/java/parquet/thrift/ThriftMetaData.java": 43
            },
            "is_test": true,
            "is_fix": false
        },
        "dd057cf9fb15ec964efdc7594808850f6e397393": {
            "datetime": "2013-04-03T16:07:56-07:00",
            "summary": "merge shade_jackson, fix compilation errors",
            "message": "merge shade_jackson, fix compilation errors\n",
            "diff": {
                "parquet-thrift/src/main/java/parquet/hadoop/thrift/ThriftWriteSupport.java": 2
            },
            "is_test": false,
            "is_fix": false
        },
        "dd8077e57ea2ac96ba23a31e569ef66104a79689": {
            "datetime": "2013-04-03T16:49:30-07:00",
            "summary": "adding utility classe to completely hide Thrift",
            "message": "adding utility classe to completely hide Thrift\n",
            "diff": {
                "src/main/java/parquet/format/Util.java": 61
            },
            "is_test": false,
            "is_fix": false
        },
        "efb93bf0ed82a625e1a893bacfbe27a440a84100": {
            "datetime": "2013-04-03T17:11:37-07:00",
            "summary": "Merge pull request #35 from Parquet/shading_jar",
            "message": "Merge pull request #35 from Parquet/shading_jar\n\nthis embeds and renames the thrift dependency in the jar, allowing people to use a different version of thrift in parallel",
            "diff": {
                "src/main/java/parquet/format/Util.java": 61
            },
            "is_test": false,
            "is_fix": false
        },
        "8f9f0c77ab4e2972192ca76a6ee7b5228fe10b7b": {
            "datetime": "2013-04-03T17:48:04-07:00",
            "summary": "integrate thrift change in format",
            "message": "integrate thrift change in format\n",
            "diff": {
                "parquet-hadoop/src/main/java/parquet/format/converter/ParquetMetadataConverter.java": 77,
                "parquet-hadoop/src/main/java/parquet/hadoop/ParquetFileReader.java": 2
            },
            "is_test": false,
            "is_fix": false
        },
        "a4f133aab1e6908f9c7244d755df0b90a9d12a38": {
            "datetime": "2013-04-03T18:03:19-07:00",
            "summary": "cleaning methods",
            "message": "cleaning methods\n",
            "diff": {
                "parquet-hadoop/src/main/java/parquet/format/converter/ParquetMetadataConverter.java": 30,
                "parquet-hadoop/src/main/java/parquet/hadoop/ParquetFileReader.java": 14,
                "parquet-hadoop/src/main/java/parquet/hadoop/ParquetFileWriter.java": 3,
                "parquet-hadoop/src/test/java/parquet/format/converter/TestParquetMetadataConverter.java": 10,
                "parquet-hadoop/src/test/java/parquet/hadoop/example/TestInputOutputFormat.java": 5,
                "parquet-pig/src/main/java/parquet/pig/ParquetLoader.java": 3,
                "parquet-pig/src/main/java/parquet/pig/convert/TupleConverter.java": 1
            },
            "is_test": true,
            "is_fix": false
        },
        "7025ede295ff4960b9ae72f1cb6ca0d0140a490c": {
            "datetime": "2013-04-03T18:09:51-07:00",
            "summary": "Merge branch 'integrate_format_changes' into dictionary_encoding",
            "message": "Merge branch 'integrate_format_changes' into dictionary_encoding\n\nConflicts:\n\tparquet-column/src/main/java/parquet/column/Encoding.java\n\tparquet-hadoop/src/main/java/parquet/hadoop/ParquetFileReader.java\n",
            "diff": {
                "parquet-column/src/main/java/parquet/bytes/BytesInput.java": 7,
                "parquet-column/src/main/java/parquet/column/Encoding.java": 3,
                "parquet-column/src/main/java/parquet/column/values/plain/BinaryPlainValuesReader.java": 39,
                "parquet-column/src/main/java/parquet/column/values/plain/PlainValuesReader.java": 13,
                "parquet-column/src/main/java/parquet/example/DummyRecordConverter.java": 9,
                "parquet-column/src/main/java/parquet/io/api/Binary.java": 6,
                "parquet-column/src/test/java/parquet/io/PerfTest.java": 6,
                "parquet-hadoop/src/main/java/parquet/format/converter/ParquetMetadataConverter.java": 73,
                "parquet-hadoop/src/main/java/parquet/hadoop/ParquetFileReader.java": 14,
                "parquet-hadoop/src/main/java/parquet/hadoop/ParquetFileWriter.java": 3,
                "parquet-hadoop/src/test/java/parquet/format/converter/TestParquetMetadataConverter.java": 10,
                "parquet-hadoop/src/test/java/parquet/hadoop/example/TestInputOutputFormat.java": 5,
                "parquet-pig/src/main/java/parquet/pig/ParquetLoader.java": 3,
                "parquet-pig/src/main/java/parquet/pig/convert/TupleConverter.java": 1,
                "parquet-thrift/src/main/java/parquet/thrift/ProtocolReadToWrite.java": 2
            },
            "is_test": true,
            "is_fix": false
        },
        "8fc53c49b9c0ea287e131b30a975e1ecbb8cc3ff": {
            "datetime": "2013-04-04T11:21:28-07:00",
            "summary": "improve logging",
            "message": "improve logging\n",
            "diff": {
                "parquet-column/src/test/java/parquet/column/values/dictionary/TestDictionary.java": 2,
                "parquet-hadoop/src/main/java/parquet/hadoop/ColumnChunkPageWriteStore.java": 14
            },
            "is_test": true,
            "is_fix": false
        },
        "e9aa5d5591590b17dc592f7349ad5bd9a8bf4ed4": {
            "datetime": "2013-04-04T13:07:06-07:00",
            "summary": "Merge pull request #22 from Parquet/integrate_format_changes",
            "message": "Merge pull request #22 from Parquet/integrate_format_changes\n\nIntegrate format changes",
            "diff": {
                "parquet-hadoop/src/main/java/parquet/format/converter/ParquetMetadataConverter.java": 73,
                "parquet-hadoop/src/main/java/parquet/hadoop/ParquetFileReader.java": 14,
                "parquet-hadoop/src/main/java/parquet/hadoop/ParquetFileWriter.java": 3,
                "parquet-hadoop/src/test/java/parquet/format/converter/TestParquetMetadataConverter.java": 10,
                "parquet-hadoop/src/test/java/parquet/hadoop/example/TestInputOutputFormat.java": 5,
                "parquet-pig/src/main/java/parquet/pig/ParquetLoader.java": 3,
                "parquet-pig/src/main/java/parquet/pig/convert/TupleConverter.java": 1
            },
            "is_test": true,
            "is_fix": false
        },
        "dc585ac131d8a276d81152415b269fdedbc3f882": {
            "datetime": "2013-04-04T22:11:30-07:00",
            "summary": "Merge branch 'master' of github.com:Parquet/parquet-mr into scrooge_scalding",
            "message": "Merge branch 'master' of github.com:Parquet/parquet-mr into scrooge_scalding\n",
            "diff": {
                "parquet-hadoop/src/main/java/parquet/format/converter/ParquetMetadataConverter.java": 73,
                "parquet-hadoop/src/main/java/parquet/hadoop/ParquetFileReader.java": 14,
                "parquet-hadoop/src/main/java/parquet/hadoop/ParquetFileWriter.java": 3,
                "parquet-hadoop/src/test/java/parquet/format/converter/TestParquetMetadataConverter.java": 10,
                "parquet-hadoop/src/test/java/parquet/hadoop/example/TestInputOutputFormat.java": 5,
                "parquet-pig/src/main/java/parquet/pig/ParquetLoader.java": 3,
                "parquet-pig/src/main/java/parquet/pig/convert/TupleConverter.java": 1
            },
            "is_test": true,
            "is_fix": false
        },
        "9c62f41d3b4e4294d3d7a009e2bceda19d854c75": {
            "datetime": "2013-04-04T22:15:53-07:00",
            "summary": "improve dictionary",
            "message": "improve dictionary\n",
            "diff": {
                "parquet-column/src/main/java/parquet/column/impl/ColumnWriterImpl.java": 17,
                "parquet-column/src/main/java/parquet/column/values/BinaryEncodingPickerValuesWriter.java": 95,
                "parquet-column/src/main/java/parquet/column/values/ValuesWriter.java": 20,
                "parquet-column/src/main/java/parquet/column/values/dictionary/DictionaryValuesReader.java": 14,
                "parquet-column/src/main/java/parquet/column/values/dictionary/DictionaryValuesWriter.java": 180,
                "parquet-column/src/test/java/parquet/column/values/dictionary/TestDictionary.java": 55,
                "parquet-hadoop/src/main/java/parquet/hadoop/ColumnChunkPageWriteStore.java": 19
            },
            "is_test": true,
            "is_fix": false
        },
        "073421762e172b68af81c97374b5c45234ce4f17": {
            "datetime": "2013-04-04T23:09:54-07:00",
            "summary": "add license headers",
            "message": "add license headers\n",
            "diff": {
                "parquet-cascading/src/main/java/parquet/cascading/ParquetTBaseScheme.java": 20,
                "parquet-cascading/src/main/java/parquet/cascading/ParquetValueScheme.java": 24,
                "parquet-scrooge/src/main/java/parquet/scrooge/ParquetScroogeScheme.java": 24,
                "parquet-scrooge/src/main/java/parquet/scrooge/ScroogeRecordConverter.java": 15,
                "parquet-thrift/src/main/java/parquet/hadoop/thrift/Container.java": 34,
                "parquet-thrift/src/main/java/parquet/hadoop/thrift/DeprecatedContainerInputFormat.java": 367
            },
            "is_test": false,
            "is_fix": false
        },
        "9656ef2806fc4a35e7754eee8b1a742e921bf9eb": {
            "datetime": "2013-04-05T09:58:27-07:00",
            "summary": "improve api; improve logs;improve PrintFooter",
            "message": "improve api; improve logs;improve PrintFooter\n",
            "diff": {
                "parquet-column/src/main/java/parquet/column/values/ValuesWriter.java": 29,
                "parquet-column/src/main/java/parquet/column/values/dictionary/DictionaryValuesWriter.java": 2,
                "parquet-hadoop/src/main/java/parquet/hadoop/ColumnChunkPageWriteStore.java": 20,
                "parquet-hadoop/src/main/java/parquet/hadoop/PrintFooter.java": 15
            },
            "is_test": false,
            "is_fix": false
        },
        "08c8f82011925d3ba083f8b23b8f1c0af29c0d7e": {
            "datetime": "2013-04-08T15:36:50-07:00",
            "summary": "use published EB, fix NPE in ThriftMetaData",
            "message": "use published EB, fix NPE in ThriftMetaData\n",
            "diff": {
                "parquet-thrift/src/main/java/parquet/thrift/ThriftMetaData.java": 2
            },
            "is_test": false,
            "is_fix": false
        },
        "d5b3b7d836638a9f29f7798aee5da3c289a5cad4": {
            "datetime": "2013-04-09T15:20:57-07:00",
            "summary": "better logging",
            "message": "better logging\n",
            "diff": {
                "parquet-hadoop/src/main/java/parquet/hadoop/ColumnChunkPageWriteStore.java": 2
            },
            "is_test": false,
            "is_fix": false
        },
        "0bb5e93507c0725f3f938b38605c67bcaa507b1a": {
            "datetime": "2013-04-10T11:10:25-07:00",
            "summary": "first stab at rle encoding",
            "message": "first stab at rle encoding\n",
            "diff": {
                "parquet-column/src/main/java/parquet/column/values/rle/RLEDecoder.java": 70,
                "parquet-column/src/main/java/parquet/column/values/rle/RLESimpleEncoder.java": 41,
                "parquet-column/src/test/java/parquet/column/values/rle/TestRLE.java": 33
            },
            "is_test": true,
            "is_fix": false
        },
        "4fe082c513d9388a3eddd6a857ba576b908b54da": {
            "datetime": "2013-04-11T15:06:22-07:00",
            "summary": "BitPacking up to 31 bits",
            "message": "BitPacking up to 31 bits\n",
            "diff": {
                "parquet-column/src/main/java/parquet/bytes/BytesUtils.java": 25,
                "parquet-column/src/main/java/parquet/column/values/bitpacking/BitPackingGenerator.java": 119,
                "parquet-column/src/main/java/parquet/column/values/bitpacking/LemireBitPacking.java": 3176,
                "parquet-column/src/main/java/parquet/column/values/rle/RLEDecoder.java": 24,
                "parquet-column/src/test/java/parquet/column/values/bitpacking/TestLemireBitPacking.java": 87,
                "parquet-column/src/test/java/parquet/column/values/rle/TestRLE.java": 6
            },
            "is_test": true,
            "is_fix": false
        },
        "f7a47d3572ccae6467a27503dda2664bb7bd424f": {
            "datetime": "2013-04-12T11:20:52-07:00",
            "summary": "adapt Lemire's scheme to our value ordering",
            "message": "adapt Lemire's scheme to our value ordering\n",
            "diff": {
                "parquet-column/src/main/java/parquet/column/values/bitpacking/BitPackingGenerator.java": 37,
                "parquet-column/src/main/java/parquet/column/values/bitpacking/LemireBitPacking.java": 4800,
                "parquet-column/src/test/java/parquet/column/values/bitpacking/TestLemireBitPacking.java": 2
            },
            "is_test": true,
            "is_fix": false
        },
        "f2ff9e854bb8d787203a85fb311c3ae0a9af52c5": {
            "datetime": "2013-04-12T11:22:17-07:00",
            "summary": "add license headers",
            "message": "add license headers\n",
            "diff": {
                "parquet-column/src/main/java/parquet/column/values/bitpacking/BitPackingGenerator.java": 15,
                "parquet-column/src/main/java/parquet/column/values/bitpacking/LemireBitPacking.java": 15,
                "parquet-column/src/main/java/parquet/column/values/plain/BinaryPlainValuesReader.java": 15,
                "parquet-column/src/main/java/parquet/column/values/rle/RLEDecoder.java": 15,
                "parquet-column/src/main/java/parquet/column/values/rle/RLESimpleEncoder.java": 15,
                "parquet-column/src/test/java/parquet/column/values/bitpacking/TestLemireBitPacking.java": 15,
                "parquet-column/src/test/java/parquet/column/values/rle/TestRLE.java": 15
            },
            "is_test": true,
            "is_fix": false
        },
        "07c56fcb2c8448701d1542c25c9ac2afa28aba5c": {
            "datetime": "2013-04-12T13:31:02-07:00",
            "summary": "add notice",
            "message": "add notice\n",
            "diff": {
                "parquet-column/src/main/java/parquet/column/values/bitpacking/BitPackingGenerator.java": 6,
                "parquet-column/src/main/java/parquet/column/values/bitpacking/LemireBitPacking.java": 6
            },
            "is_test": false,
            "is_fix": false
        },
        "4611c4778027a167f474c777573bbf30aa4a08fa": {
            "datetime": "2013-04-15T11:27:52-07:00",
            "summary": "writer readers for int based packing",
            "message": "writer readers for int based packing\n",
            "diff": {
                "parquet-column/src/main/java/parquet/bytes/BytesInput.java": 20,
                "parquet-column/src/main/java/parquet/column/values/bitpacking/BitPackingGenerator.java": 32,
                "parquet-column/src/main/java/parquet/column/values/bitpacking/BitPackingValuesReader.java": 3,
                "parquet-column/src/main/java/parquet/column/values/bitpacking/BitPackingValuesWriter.java": 8,
                "parquet-column/src/main/java/parquet/column/values/bitpacking/IntBasedBitPackingValuesReader.java": 63,
                "parquet-column/src/main/java/parquet/column/values/bitpacking/IntBasedBitPackingValuesWriter.java": 91,
                "parquet-column/src/main/java/parquet/column/values/bitpacking/IntPacker.java": 19,
                "parquet-column/src/main/java/parquet/column/values/bitpacking/LemireBitPacking.java": 250,
                "parquet-column/src/test/java/parquet/column/values/bitpacking/TestLemireBitPacking.java": 6
            },
            "is_test": true,
            "is_fix": false
        },
        "a0926f380bacc3eca8afcaa208b8c4734a1e2d45": {
            "datetime": "2013-04-15T12:02:40-07:00",
            "summary": "add both orders as we might want to change our encoding in the future",
            "message": "add both orders as we might want to change our encoding in the future\n",
            "diff": {
                "parquet-column/src/main/java/parquet/column/values/bitpacking/BitPackingGenerator.java": 83,
                "parquet-column/src/main/java/parquet/column/values/bitpacking/IntBasedBitPackingValuesReader.java": 15,
                "parquet-column/src/main/java/parquet/column/values/bitpacking/IntBasedBitPackingValuesWriter.java": 15,
                "parquet-column/src/main/java/parquet/column/values/bitpacking/IntPacker.java": 48,
                "parquet-column/src/main/java/parquet/column/values/bitpacking/LemireBitPackingBE.java": 15,
                "parquet-column/src/main/java/parquet/column/values/bitpacking/LemireBitPackingLE.java": 3353,
                "parquet-column/src/test/java/parquet/column/values/bitpacking/TestLemireBitPacking.java": 19
            },
            "is_test": true,
            "is_fix": false
        },
        "b0e9609e4850fcf8e0e79a427aa0f079aaf04b10": {
            "datetime": "2013-04-16T10:31:06-07:00",
            "summary": "more tests and bug fixing the Bit packing",
            "message": "more tests and bug fixing the Bit packing\n",
            "diff": {
                "parquet-column/src/main/java/parquet/bytes/BytesInput.java": 17,
                "parquet-column/src/main/java/parquet/column/values/bitpacking/IntBasedBitPackingValuesReader.java": 33,
                "parquet-column/src/main/java/parquet/column/values/bitpacking/IntBasedBitPackingValuesWriter.java": 40,
                "parquet-column/src/main/java/parquet/column/values/bitpacking/LemireBitPackingBE.java": 15,
                "parquet-column/src/main/java/parquet/column/values/bitpacking/LemireBitPackingLE.java": 15,
                "parquet-column/src/test/java/parquet/column/primitive/TestBitPacking.java": 4,
                "parquet-column/src/test/java/parquet/column/primitive/TestBitPackingColumn.java": 62,
                "parquet-column/src/test/java/parquet/column/values/bitpacking/TestLemireBitPacking.java": 37
            },
            "is_test": true,
            "is_fix": false
        },
        "e3e81597fc03c12515adabfe9c69419024b9403f": {
            "datetime": "2013-04-16T14:40:39-07:00",
            "summary": "make things that look like closeables implement Closeable",
            "message": "make things that look like closeables implement Closeable\n",
            "diff": {
                "parquet-hadoop/src/main/java/parquet/hadoop/ParquetFileReader.java": 4,
                "parquet-thrift/src/main/java/parquet/hadoop/thrift/ThriftToParquetFileWriter.java": 13
            },
            "is_test": false,
            "is_fix": false
        },
        "ee8c25ea3a73b068c7523bdfd1c4cdddf156e26c": {
            "datetime": "2013-04-16T14:55:50-07:00",
            "summary": "Merge pull request #27 from Parquet/make_closeable",
            "message": "Merge pull request #27 from Parquet/make_closeable\n\nmake things that look like closeables implement Closeable",
            "diff": {
                "parquet-hadoop/src/main/java/parquet/hadoop/ParquetFileReader.java": 4,
                "parquet-thrift/src/main/java/parquet/hadoop/thrift/ThriftToParquetFileWriter.java": 13
            },
            "is_test": false,
            "is_fix": false
        },
        "bca0411428def0c2abe792d882e8d23461c6a097": {
            "datetime": "2013-04-18T09:21:31-07:00",
            "summary": "Merge branch 'master' of github.com:Parquet/parquet-mr into scrooge_scalding",
            "message": "Merge branch 'master' of github.com:Parquet/parquet-mr into scrooge_scalding\n",
            "diff": {
                "parquet-hadoop/src/main/java/parquet/hadoop/ParquetFileReader.java": 4,
                "parquet-thrift/src/main/java/parquet/hadoop/thrift/ThriftToParquetFileWriter.java": 13
            },
            "is_test": false,
            "is_fix": false
        },
        "bcdddf76bb16436a62167e82664b1e8bc4f2e0ed": {
            "datetime": "2013-04-19T11:24:23-07:00",
            "summary": "implement byte based batch bit packing",
            "message": "implement byte based batch bit packing\n",
            "diff": {
                "parquet-column/src/main/java/parquet/column/values/bitpacking/BitPackingGenerator.java": 4,
                "parquet-column/src/main/java/parquet/column/values/bitpacking/ByteBasedBitPackingGenerator.java": 229,
                "parquet-column/src/main/java/parquet/column/values/bitpacking/ByteBitPacking.java": 25636,
                "parquet-column/src/main/java/parquet/column/values/bitpacking/BytePacker.java": 83,
                "parquet-column/src/main/java/parquet/column/values/bitpacking/LemireBitPackingBE.java": 17,
                "parquet-column/src/main/java/parquet/column/values/bitpacking/LemireBitPackingLE.java": 17,
                "parquet-column/src/test/java/parquet/column/values/bitpacking/TestByteBitPacking.java": 134
            },
            "is_test": true,
            "is_fix": false
        },
        "c2bdea0d004103fe74585d42abe3643a62d3da0a": {
            "datetime": "2013-04-19T14:22:09-07:00",
            "summary": "address comments from alex l.",
            "message": "address comments from alex l.\n",
            "diff": {
                "parquet-cascading/src/main/java/parquet/cascading/ParquetTBaseScheme.java": 8,
                "parquet-hadoop/src/main/java/parquet/hadoop/ParquetInputFormat.java": 11,
                "parquet-scrooge/src/main/java/parquet/scrooge/ParquetScroogeScheme.java": 11,
                "parquet-scrooge/src/main/java/parquet/scrooge/ScroogeRecordConverter.java": 2,
                "parquet-scrooge/src/test/java/parquet/scrooge/TestScroogeIOFormats.java": 5,
                "parquet-thrift/src/main/java/parquet/hadoop/thrift/ThriftReadSupport.java": 2,
                "parquet-thrift/src/main/java/parquet/thrift/TBaseRecordConverter.java": 2
            },
            "is_test": true,
            "is_fix": false
        },
        "9942ce175d35708cc7f0586b075bc3467a6a5224": {
            "datetime": "2013-04-19T14:29:42-07:00",
            "summary": "move simple RLE to generated bit packing",
            "message": "move simple RLE to generated bit packing\n",
            "diff": {
                "parquet-column/src/main/java/parquet/column/values/bitpacking/ByteBasedBitPackingEncoder.java": 84,
                "parquet-column/src/main/java/parquet/column/values/bitpacking/ByteBasedBitPackingGenerator.java": 2,
                "parquet-column/src/main/java/parquet/column/values/bitpacking/ByteBitPacking.java": 2,
                "parquet-column/src/main/java/parquet/column/values/rle/RLEDecoder.java": 39,
                "parquet-column/src/main/java/parquet/column/values/rle/RLESimpleEncoder.java": 24,
                "parquet-column/src/test/java/parquet/column/values/bitpacking/TestBitPackingColumn.java": 22,
                "parquet-column/src/test/java/parquet/column/values/rle/TestRLE.java": 12
            },
            "is_test": true,
            "is_fix": false
        },
        "aa851eb7ca9edd0c364bfe39ec2c2f99c4914d01": {
            "datetime": "2013-04-19T14:35:01-07:00",
            "summary": "remove broken reader/writer",
            "message": "remove broken reader/writer\n",
            "diff": {
                "parquet-column/src/main/java/parquet/column/values/bitpacking/IntBasedBitPackingValuesReader.java": 103,
                "parquet-column/src/main/java/parquet/column/values/bitpacking/IntBasedBitPackingValuesWriter.java": 118,
                "parquet-column/src/test/java/parquet/column/values/bitpacking/TestBitPackingColumn.java": 11
            },
            "is_test": true,
            "is_fix": false
        },
        "61d5170844aaf611555a0dd63c5e24af08acf1c8": {
            "datetime": "2013-04-19T16:47:58-07:00",
            "summary": "fix bug where a required field would not be created at the right level",
            "message": "fix bug where a required field would not be created at the right level\n",
            "diff": {
                "parquet-column/src/main/java/parquet/io/RecordReaderImplementation.java": 7,
                "parquet-column/src/test/java/parquet/io/TestColumnIO.java": 34
            },
            "is_test": true,
            "is_fix": false
        },
        "8b69ad5d107946d0a52a30f879ef3f932ba72a32": {
            "datetime": "2013-04-19T23:08:53-07:00",
            "summary": "address comments from @J_",
            "message": "address comments from @J_\n",
            "diff": {
                "parquet-scrooge/src/main/java/parquet/scrooge/ScroogeRecordConverter.java": 1,
                "parquet-thrift/src/main/java/parquet/hadoop/thrift/DeprecatedContainerInputFormat.java": 5,
                "parquet-thrift/src/main/java/parquet/hadoop/thrift/ThriftReadSupport.java": 2
            },
            "is_test": false,
            "is_fix": false
        },
        "1d2164671889e4af8a0a73c36e0290ab75ea7e3e": {
            "datetime": "2013-04-20T01:19:18-07:00",
            "summary": "Merge pull request #29 from Parquet/fix_definition_level_for_nested_required",
            "message": "Merge pull request #29 from Parquet/fix_definition_level_for_nested_required\n\nfix bug where a required field would not be created at the right level",
            "diff": {
                "parquet-column/src/main/java/parquet/io/RecordReaderImplementation.java": 7,
                "parquet-column/src/test/java/parquet/io/TestColumnIO.java": 34
            },
            "is_test": true,
            "is_fix": false
        },
        "f866bb844c8534c3c14975c185c3df627f640b24": {
            "datetime": "2013-04-22T14:48:01-07:00",
            "summary": "more tests for optional vs required",
            "message": "more tests for optional vs required\n",
            "diff": {
                "parquet-column/src/test/java/parquet/io/TestColumnIO.java": 133
            },
            "is_test": true,
            "is_fix": false
        },
        "ee4a1b84351ea152a90a5075e29834bbd78521e8": {
            "datetime": "2013-04-22T15:11:55-07:00",
            "summary": "Merge pull request #30 from Parquet/fix_definition_level_for_nested_required",
            "message": "Merge pull request #30 from Parquet/fix_definition_level_for_nested_required\n\nmore tests for optional vs required",
            "diff": {
                "parquet-column/src/test/java/parquet/io/TestColumnIO.java": 133
            },
            "is_test": true,
            "is_fix": false
        },
        "9d2df1361fb131c21ed5ec7c2a33eb098ae2d5ce": {
            "datetime": "2013-04-22T16:22:56-07:00",
            "summary": "Merge branch 'master' into dictionary_encoding",
            "message": "Merge branch 'master' into dictionary_encoding\n\nConflicts:\n\tparquet-hadoop/src/main/java/parquet/hadoop/ParquetFileReader.java\n",
            "diff": {
                "parquet-column/src/main/java/parquet/io/RecordReaderImplementation.java": 7,
                "parquet-column/src/test/java/parquet/io/TestColumnIO.java": 34,
                "parquet-hadoop/src/main/java/parquet/hadoop/ParquetFileReader.java": 4,
                "parquet-thrift/src/main/java/parquet/hadoop/thrift/ThriftToParquetFileWriter.java": 13
            },
            "is_test": true,
            "is_fix": false
        },
        "d64c883beb9197500ce0922b60462a686435916d": {
            "datetime": "2013-04-23T08:52:31-07:00",
            "summary": "mae dictionary more generic; allow converters to understand dictionaries",
            "message": "mae dictionary more generic; allow converters to understand dictionaries\n",
            "diff": {
                "parquet-column/src/main/java/parquet/column/Dictionary.java": 25,
                "parquet-column/src/main/java/parquet/column/Encoding.java": 12,
                "parquet-column/src/main/java/parquet/column/impl/ColumnReadStoreImpl.java": 92,
                "parquet-column/src/main/java/parquet/column/impl/ColumnReaderImpl.java": 10,
                "parquet-column/src/main/java/parquet/column/values/ValuesReader.java": 29,
                "parquet-column/src/main/java/parquet/column/values/dictionary/DictionaryValuesReader.java": 2,
                "parquet-column/src/main/java/parquet/column/values/dictionary/PlainDictionary.java": 11,
                "parquet-column/src/main/java/parquet/column/values/plain/PlainValuesReader.java": 9,
                "parquet-column/src/main/java/parquet/io/MessageColumnIO.java": 7,
                "parquet-column/src/main/java/parquet/io/api/GroupConverter.java": 23,
                "parquet-column/src/main/java/parquet/io/api/PrimitiveConverter.java": 1,
                "parquet-column/src/test/java/parquet/column/mem/TestMemColumn.java": 49,
                "parquet-column/src/test/java/parquet/column/values/dictionary/TestDictionary.java": 8
            },
            "is_test": true,
            "is_fix": false
        },
        "feadc9effe3e2814774f128177817f7ffa4f031b": {
            "datetime": "2013-04-23T14:13:56-07:00",
            "summary": "Merge pull request #24 from Parquet/scrooge_scalding",
            "message": "Merge pull request #24 from Parquet/scrooge_scalding\n\nCascading Thrift and Scrooge support",
            "diff": {
                "parquet-cascading/src/main/java/parquet/cascading/ParquetTBaseScheme.java": 67,
                "parquet-cascading/src/main/java/parquet/cascading/ParquetValueScheme.java": 57,
                "parquet-hadoop/src/main/java/parquet/hadoop/ParquetInputFormat.java": 14,
                "parquet-scrooge/src/main/java/parquet/scrooge/ParquetScroogeScheme.java": 74,
                "parquet-scrooge/src/main/java/parquet/scrooge/ScroogeRecordConverter.java": 54,
                "parquet-thrift/src/main/java/parquet/hadoop/thrift/Container.java": 34,
                "parquet-thrift/src/main/java/parquet/hadoop/thrift/DeprecatedContainerInputFormat.java": 372,
                "parquet-thrift/src/main/java/parquet/hadoop/thrift/ParquetThriftInputFormat.java": 27,
                "parquet-thrift/src/main/java/parquet/hadoop/thrift/ThriftReadSupport.java": 56,
                "parquet-thrift/src/main/java/parquet/hadoop/thrift/ThriftWriteSupport.java": 2,
                "parquet-thrift/src/main/java/parquet/thrift/TBaseRecordConverter.java": 4,
                "parquet-thrift/src/main/java/parquet/thrift/ThriftMetaData.java": 45
            },
            "is_test": false,
            "is_fix": false
        },
        "31b91eec339fccb0d041b80ac6b0a260a0e054c7": {
            "datetime": "2013-04-23T16:55:27-07:00",
            "summary": "address review comments by @squarecog",
            "message": "address review comments by @squarecog\n",
            "diff": {
                "parquet-column/src/main/java/parquet/column/values/bitpacking/IntBasedBitPackingGenerator.java": 31,
                "parquet-column/src/main/java/parquet/column/values/bitpacking/LemireBitPackingBE.java": 139,
                "parquet-column/src/main/java/parquet/column/values/bitpacking/LemireBitPackingLE.java": 139
            },
            "is_test": false,
            "is_fix": false
        },
        "64c45cbe585d6be1fdc0c4f87e4ac977b5df5eb7": {
            "datetime": "2013-04-24T10:03:03+01:00",
            "summary": "Add test for nested records following fix in 61d5170844aaf611555a0dd63c5e24af08acf1c8",
            "message": "Add test for nested records following fix in 61d5170844aaf611555a0dd63c5e24af08acf1c8\n",
            "diff": {
                "parquet-avro/src/test/java/parquet/avro/TestReadWrite.java": 11
            },
            "is_test": true,
            "is_fix": false
        },
        "5121cd599c259d9eda51585a66ca680591398c65": {
            "datetime": "2013-04-24T10:03:03+01:00",
            "summary": "Avoid double conversion of bytes for Avro Utf8 instances.",
            "message": "Avoid double conversion of bytes for Avro Utf8 instances.\n",
            "diff": {
                "parquet-avro/src/main/java/parquet/avro/AvroWriteSupport.java": 11
            },
            "is_test": false,
            "is_fix": false
        },
        "1605cda914e596b90cd95d1adbc7001ad0557da8": {
            "datetime": "2013-04-24T10:03:03+01:00",
            "summary": "Avoid copying bytes if ByteBuffer is array-based.",
            "message": "Avoid copying bytes if ByteBuffer is array-based.\n",
            "diff": {
                "parquet-column/src/main/java/parquet/io/api/Binary.java": 12
            },
            "is_test": false,
            "is_fix": false
        },
        "e365840ea62f29a6cca472772bf96bee8b1a4e3c": {
            "datetime": "2013-04-24T10:03:03+01:00",
            "summary": "Create generic Parquet reader and writer for object records.",
            "message": "Create generic Parquet reader and writer for object records.\n",
            "diff": {
                "parquet-avro/src/main/java/parquet/avro/AvroParquetReader.java": 70,
                "parquet-avro/src/main/java/parquet/avro/AvroParquetWriter.java": 61,
                "parquet-hadoop/src/main/java/parquet/hadoop/CodecFactory.java": 2,
                "parquet-hadoop/src/main/java/parquet/hadoop/ParquetReader.java": 75,
                "parquet-hadoop/src/main/java/parquet/hadoop/ParquetWriter.java": 66
            },
            "is_test": false,
            "is_fix": false
        },
        "58d8c52e91ae45252e388747f0bf17ebc859930e": {
            "datetime": "2013-04-24T10:03:03+01:00",
            "summary": "Remove incorrect record initialization to compensate for broken support for nested records (not yet fixed).",
            "message": "Remove incorrect record initialization to compensate for broken support for nested records (not yet fixed).\n",
            "diff": {
                "parquet-avro/src/main/java/parquet/avro/AvroGenericRecordConverter.java": 1,
                "parquet-avro/src/test/java/parquet/avro/TestReadWrite.java": 10
            },
            "is_test": true,
            "is_fix": false
        },
        "e47f3b13a69672bebecb6928360dcd38aa8657b6": {
            "datetime": "2013-04-24T10:03:03+01:00",
            "summary": "Fix creation of arrays and maps in converters.",
            "message": "Fix creation of arrays and maps in converters.\n",
            "diff": {
                "parquet-avro/src/main/java/parquet/avro/AvroGenericRecordConverter.java": 21
            },
            "is_test": false,
            "is_fix": false
        },
        "11bb824716f757ed1d69405fb0c5821975a606fd": {
            "datetime": "2013-04-24T10:03:03+01:00",
            "summary": "Remove unnecessary level of grouping for array.",
            "message": "Remove unnecessary level of grouping for array.\n",
            "diff": {
                "parquet-avro/src/main/java/parquet/avro/AvroGenericRecordConverter.java": 12,
                "parquet-avro/src/main/java/parquet/avro/AvroSchemaConverter.java": 3,
                "parquet-avro/src/main/java/parquet/avro/AvroWriteSupport.java": 9,
                "parquet-avro/src/test/java/parquet/avro/TestAvroSchemaConverter.java": 4
            },
            "is_test": true,
            "is_fix": false
        },
        "568bd7f60ffa0fa75071c4ac1675bcc1519c0c00": {
            "datetime": "2013-04-24T10:03:03+01:00",
            "summary": "Add Binary.fromByteBuffer method.",
            "message": "Add Binary.fromByteBuffer method.\n",
            "diff": {
                "parquet-avro/src/main/java/parquet/avro/AvroWriteSupport.java": 5,
                "parquet-column/src/main/java/parquet/io/api/Binary.java": 49
            },
            "is_test": false,
            "is_fix": false
        },
        "61a163d31b1fd9aac7443fc547aeb6cc73089e62": {
            "datetime": "2013-04-24T10:03:03+01:00",
            "summary": "Honor repetitions correctly.",
            "message": "Honor repetitions correctly.\n",
            "diff": {
                "parquet-avro/src/main/java/parquet/avro/AvroSchemaConverter.java": 33
            },
            "is_test": false,
            "is_fix": false
        },
        "42c38a1e016b9fc7d280012a237101a1a2d5a0be": {
            "datetime": "2013-04-24T10:03:03+01:00",
            "summary": "Remove unchecked generics warnings.",
            "message": "Remove unchecked generics warnings.\n",
            "diff": {
                "parquet-avro/src/main/java/parquet/avro/AvroGenericRecordConverter.java": 23,
                "parquet-avro/src/main/java/parquet/avro/AvroWriteSupport.java": 14,
                "parquet-avro/src/test/java/parquet/avro/TestReadWrite.java": 4
            },
            "is_test": true,
            "is_fix": false
        },
        "02b283dbd3c44206ca31e2fcd0bfebe6949ef4be": {
            "datetime": "2013-04-24T10:03:03+01:00",
            "summary": "Initial support for Avro.",
            "message": "Initial support for Avro.\n",
            "diff": {
                "parquet-avro/src/main/java/parquet/avro/AvroGenericRecordConverter.java": 358,
                "parquet-avro/src/main/java/parquet/avro/AvroParquetInputFormat.java": 14,
                "parquet-avro/src/main/java/parquet/avro/AvroParquetOutputFormat.java": 22,
                "parquet-avro/src/main/java/parquet/avro/AvroParquetReader.java": 65,
                "parquet-avro/src/main/java/parquet/avro/AvroParquetWriter.java": 57,
                "parquet-avro/src/main/java/parquet/avro/AvroReadSupport.java": 28,
                "parquet-avro/src/main/java/parquet/avro/AvroRecordMaterializer.java": 26,
                "parquet-avro/src/main/java/parquet/avro/AvroSchemaConverter.java": 136,
                "parquet-avro/src/main/java/parquet/avro/AvroWriteSupport.java": 163,
                "parquet-avro/src/main/java/parquet/avro/package-info.java": 74,
                "parquet-avro/src/test/java/parquet/avro/TestAvroSchemaConverter.java": 89,
                "parquet-avro/src/test/java/parquet/avro/TestInputOutputFormat.java": 137,
                "parquet-avro/src/test/java/parquet/avro/TestReadWrite.java": 78,
                "parquet-hadoop/src/main/java/parquet/hadoop/CodecFactory.java": 2,
                "parquet-hadoop/src/main/java/parquet/hadoop/ParquetRecordReader.java": 2
            },
            "is_test": true,
            "is_fix": false
        },
        "d3c1a34f3297146695c6cf30a67e56e8b8fbdbc7": {
            "datetime": "2013-04-24T10:39:21+01:00",
            "summary": "Fix compilation with Java 6.",
            "message": "Fix compilation with Java 6.\n",
            "diff": {
                "parquet-cascading/src/main/java/parquet/cascading/ParquetTBaseScheme.java": 2,
                "parquet-hadoop/src/main/java/parquet/hadoop/ParquetInputFormat.java": 9,
                "parquet-scrooge/src/main/java/parquet/scrooge/ParquetScroogeScheme.java": 2
            },
            "is_test": false,
            "is_fix": false
        },
        "34ce9248f9db1f2fb819b66927acfddd138b0626": {
            "datetime": "2013-04-24T09:55:26-07:00",
            "summary": "Merge pull request #26 from tomwhite/avro",
            "message": "Merge pull request #26 from tomwhite/avro\n\nInitial support for Avro.\r\nThanks @tomwhite ",
            "diff": {
                "parquet-avro/src/main/java/parquet/avro/AvroGenericRecordConverter.java": 357,
                "parquet-avro/src/main/java/parquet/avro/AvroParquetInputFormat.java": 14,
                "parquet-avro/src/main/java/parquet/avro/AvroParquetOutputFormat.java": 22,
                "parquet-avro/src/main/java/parquet/avro/AvroParquetReader.java": 31,
                "parquet-avro/src/main/java/parquet/avro/AvroParquetWriter.java": 34,
                "parquet-avro/src/main/java/parquet/avro/AvroReadSupport.java": 28,
                "parquet-avro/src/main/java/parquet/avro/AvroRecordMaterializer.java": 26,
                "parquet-avro/src/main/java/parquet/avro/AvroSchemaConverter.java": 118,
                "parquet-avro/src/main/java/parquet/avro/AvroWriteSupport.java": 164,
                "parquet-avro/src/main/java/parquet/avro/package-info.java": 74,
                "parquet-avro/src/test/java/parquet/avro/TestAvroSchemaConverter.java": 87,
                "parquet-avro/src/test/java/parquet/avro/TestInputOutputFormat.java": 137,
                "parquet-avro/src/test/java/parquet/avro/TestReadWrite.java": 77,
                "parquet-column/src/main/java/parquet/io/api/Binary.java": 61,
                "parquet-hadoop/src/main/java/parquet/hadoop/ParquetReader.java": 75,
                "parquet-hadoop/src/main/java/parquet/hadoop/ParquetRecordReader.java": 2,
                "parquet-hadoop/src/main/java/parquet/hadoop/ParquetWriter.java": 66
            },
            "is_test": true,
            "is_fix": false
        },
        "a5d72a44117e7263c0e39be8ffcf5992f4e45b89": {
            "datetime": "2013-04-24T09:55:54-07:00",
            "summary": "Merge pull request #31 from tomwhite/java6-compilation-fixes",
            "message": "Merge pull request #31 from tomwhite/java6-compilation-fixes\n\nFix compilation with Java 6.\r\nThanks @tomwhite",
            "diff": {
                "parquet-cascading/src/main/java/parquet/cascading/ParquetTBaseScheme.java": 2,
                "parquet-hadoop/src/main/java/parquet/hadoop/ParquetInputFormat.java": 9,
                "parquet-scrooge/src/main/java/parquet/scrooge/ParquetScroogeScheme.java": 2
            },
            "is_test": false,
            "is_fix": false
        },
        "19e0902b3c17ef1e163b429d114f8541139863ac": {
            "datetime": "2013-04-25T12:44:41-07:00",
            "summary": "make converters dictionary aware",
            "message": "make converters dictionary aware\n",
            "diff": {
                "parquet-column/src/main/java/parquet/Log.java": 2,
                "parquet-column/src/main/java/parquet/column/ColumnReader.java": 11,
                "parquet-column/src/main/java/parquet/column/Dictionary.java": 2,
                "parquet-column/src/main/java/parquet/column/Encoding.java": 24,
                "parquet-column/src/main/java/parquet/column/impl/ColumnReadStoreImpl.java": 195,
                "parquet-column/src/main/java/parquet/column/impl/ColumnReaderImpl.java": 261,
                "parquet-column/src/main/java/parquet/column/page/DictionaryPage.java": 7,
                "parquet-column/src/main/java/parquet/column/page/PageReader.java": 2,
                "parquet-column/src/main/java/parquet/column/values/ValuesReader.java": 13,
                "parquet-column/src/main/java/parquet/column/values/ValuesWriter.java": 1,
                "parquet-column/src/main/java/parquet/column/values/dictionary/DictionaryValuesReader.java": 21,
                "parquet-column/src/main/java/parquet/column/values/dictionary/DictionaryValuesWriter.java": 10,
                "parquet-column/src/main/java/parquet/io/RecordReaderImplementation.java": 2,
                "parquet-column/src/main/java/parquet/io/api/GroupConverter.java": 20,
                "parquet-column/src/main/java/parquet/io/api/PrimitiveConverter.java": 34,
                "parquet-column/src/main/java/parquet/schema/PrimitiveType.java": 75,
                "parquet-column/src/test/java/parquet/column/page/mem/MemPageReader.java": 19,
                "parquet-column/src/test/java/parquet/column/page/mem/MemPageStore.java": 2,
                "parquet-column/src/test/java/parquet/column/page/mem/MemPageWriter.java": 13,
                "parquet-column/src/test/java/parquet/column/values/dictionary/TestDictionary.java": 20,
                "parquet-hadoop/src/main/java/parquet/hadoop/ColumnChunkPageReadStore.java": 15,
                "parquet-hadoop/src/main/java/parquet/hadoop/ColumnChunkPageWriteStore.java": 23,
                "parquet-hadoop/src/main/java/parquet/hadoop/ParquetFileReader.java": 9,
                "parquet-pig/src/main/java/parquet/pig/convert/TupleConverter.java": 26
            },
            "is_test": true,
            "is_fix": false
        },
        "aed56c954fba19095fd622cfaa39341b9a22c9c6": {
            "datetime": "2013-04-25T14:30:47-07:00",
            "summary": "integrate the new bit packing for perf",
            "message": "integrate the new bit packing for perf\n",
            "diff": {
                "parquet-column/src/main/java/parquet/bytes/BytesUtils.java": 8,
                "parquet-column/src/main/java/parquet/column/Encoding.java": 4,
                "parquet-column/src/main/java/parquet/column/impl/ColumnWriterImpl.java": 6,
                "parquet-column/src/main/java/parquet/column/values/bitpacking/BitPackingValuesReader.java": 3,
                "parquet-column/src/main/java/parquet/column/values/bitpacking/ByteBasedBitPackingEncoder.java": 37,
                "parquet-column/src/main/java/parquet/column/values/bitpacking/ByteBasedBitPackingGenerator.java": 3,
                "parquet-column/src/main/java/parquet/column/values/bitpacking/ByteBitPackingValuesReader.java": 54,
                "parquet-column/src/main/java/parquet/column/values/bitpacking/ByteBitPackingValuesWriter.java": 61,
                "parquet-column/src/main/java/parquet/column/values/bitpacking/BytePacker.java": 2,
                "parquet-column/src/main/java/parquet/column/values/bitpacking/IntBasedBitPackingGenerator.java": 1,
                "parquet-column/src/main/java/parquet/column/values/bitpacking/IntPacker.java": 0,
                "parquet-column/src/test/java/parquet/TestLog.java": 13,
                "parquet-column/src/test/java/parquet/column/values/bitpacking/BitPackingPerfTest.java": 85,
                "parquet-column/src/test/java/parquet/column/values/bitpacking/TestBitPackingColumn.java": 19
            },
            "is_test": true,
            "is_fix": false
        },
        "133d845b497c6b9cc662a06405128c7ccf06a110": {
            "datetime": "2013-04-25T14:54:52-07:00",
            "summary": "Merge branch 'master' into rle",
            "message": "Merge branch 'master' into rle\n",
            "diff": {
                "parquet-cascading/src/main/java/parquet/cascading/ParquetTBaseScheme.java": 67,
                "parquet-cascading/src/main/java/parquet/cascading/ParquetValueScheme.java": 57,
                "parquet-column/src/main/java/parquet/io/RecordReaderImplementation.java": 7,
                "parquet-column/src/test/java/parquet/io/TestColumnIO.java": 131,
                "parquet-hadoop/src/main/java/parquet/hadoop/ParquetFileReader.java": 4,
                "parquet-hadoop/src/main/java/parquet/hadoop/ParquetInputFormat.java": 14,
                "parquet-scrooge/src/main/java/parquet/scrooge/ParquetScroogeScheme.java": 74,
                "parquet-scrooge/src/main/java/parquet/scrooge/ScroogeRecordConverter.java": 54,
                "parquet-thrift/src/main/java/parquet/hadoop/thrift/Container.java": 34,
                "parquet-thrift/src/main/java/parquet/hadoop/thrift/DeprecatedContainerInputFormat.java": 372,
                "parquet-thrift/src/main/java/parquet/hadoop/thrift/ParquetThriftInputFormat.java": 27,
                "parquet-thrift/src/main/java/parquet/hadoop/thrift/ThriftReadSupport.java": 56,
                "parquet-thrift/src/main/java/parquet/hadoop/thrift/ThriftToParquetFileWriter.java": 13,
                "parquet-thrift/src/main/java/parquet/hadoop/thrift/ThriftWriteSupport.java": 2,
                "parquet-thrift/src/main/java/parquet/thrift/TBaseRecordConverter.java": 4,
                "parquet-thrift/src/main/java/parquet/thrift/ThriftMetaData.java": 45
            },
            "is_test": true,
            "is_fix": false
        },
        "a3e8963cb4ea88523a74105491a7db59f30b034c": {
            "datetime": "2013-04-25T14:56:14-07:00",
            "summary": "Merge branch 'rle' into dictionary_encoding",
            "message": "Merge branch 'rle' into dictionary_encoding\n\nConflicts:\n\tparquet-column/src/main/java/parquet/column/impl/ColumnWriterImpl.java\n",
            "diff": {
                "parquet-cascading/src/main/java/parquet/cascading/ParquetTBaseScheme.java": 67,
                "parquet-cascading/src/main/java/parquet/cascading/ParquetValueScheme.java": 57,
                "parquet-column/src/main/java/parquet/bytes/BytesInput.java": 41,
                "parquet-column/src/main/java/parquet/bytes/BytesUtils.java": 33,
                "parquet-column/src/main/java/parquet/column/Encoding.java": 4,
                "parquet-column/src/main/java/parquet/column/impl/ColumnWriterImpl.java": 6,
                "parquet-column/src/main/java/parquet/column/values/bitpacking/BitPackingValuesReader.java": 6,
                "parquet-column/src/main/java/parquet/column/values/bitpacking/BitPackingValuesWriter.java": 8,
                "parquet-column/src/main/java/parquet/column/values/bitpacking/ByteBasedBitPackingEncoder.java": 117,
                "parquet-column/src/main/java/parquet/column/values/bitpacking/ByteBasedBitPackingGenerator.java": 230,
                "parquet-column/src/main/java/parquet/column/values/bitpacking/ByteBitPacking.java": 25636,
                "parquet-column/src/main/java/parquet/column/values/bitpacking/ByteBitPackingValuesReader.java": 54,
                "parquet-column/src/main/java/parquet/column/values/bitpacking/ByteBitPackingValuesWriter.java": 61,
                "parquet-column/src/main/java/parquet/column/values/bitpacking/BytePacker.java": 83,
                "parquet-column/src/main/java/parquet/column/values/bitpacking/IntBasedBitPackingGenerator.java": 202,
                "parquet-column/src/main/java/parquet/column/values/bitpacking/IntPacker.java": 63,
                "parquet-column/src/main/java/parquet/column/values/bitpacking/LemireBitPackingBE.java": 3353,
                "parquet-column/src/main/java/parquet/column/values/bitpacking/LemireBitPackingLE.java": 3352,
                "parquet-column/src/main/java/parquet/column/values/plain/BinaryPlainValuesReader.java": 15,
                "parquet-column/src/main/java/parquet/column/values/rle/RLEDecoder.java": 104,
                "parquet-column/src/main/java/parquet/column/values/rle/RLESimpleEncoder.java": 54,
                "parquet-column/src/test/java/parquet/TestLog.java": 13,
                "parquet-column/src/test/java/parquet/column/primitive/TestBitPacking.java": 4,
                "parquet-column/src/test/java/parquet/column/primitive/TestBitPackingColumn.java": 62,
                "parquet-column/src/test/java/parquet/column/values/bitpacking/BitPackingPerfTest.java": 85,
                "parquet-column/src/test/java/parquet/column/values/bitpacking/TestByteBitPacking.java": 134,
                "parquet-column/src/test/java/parquet/column/values/bitpacking/TestLemireBitPacking.java": 110,
                "parquet-column/src/test/java/parquet/column/values/rle/TestRLE.java": 62,
                "parquet-column/src/test/java/parquet/io/TestColumnIO.java": 133,
                "parquet-hadoop/src/main/java/parquet/hadoop/ParquetInputFormat.java": 14,
                "parquet-scrooge/src/main/java/parquet/scrooge/ParquetScroogeScheme.java": 74,
                "parquet-scrooge/src/main/java/parquet/scrooge/ScroogeRecordConverter.java": 54,
                "parquet-thrift/src/main/java/parquet/hadoop/thrift/Container.java": 34,
                "parquet-thrift/src/main/java/parquet/hadoop/thrift/DeprecatedContainerInputFormat.java": 372,
                "parquet-thrift/src/main/java/parquet/hadoop/thrift/ParquetThriftInputFormat.java": 27,
                "parquet-thrift/src/main/java/parquet/hadoop/thrift/ThriftReadSupport.java": 56,
                "parquet-thrift/src/main/java/parquet/hadoop/thrift/ThriftWriteSupport.java": 2,
                "parquet-thrift/src/main/java/parquet/thrift/TBaseRecordConverter.java": 4,
                "parquet-thrift/src/main/java/parquet/thrift/ThriftMetaData.java": 45
            },
            "is_test": true,
            "is_fix": false
        },
        "67a357741b65cd087836cc2230ded57c1f4850d7": {
            "datetime": "2013-04-25T15:07:38-07:00",
            "summary": "make field private; add braces for one line if statements",
            "message": "make field private; add braces for one line if statements\n",
            "diff": {
                "parquet-column/src/main/java/parquet/bytes/BytesInput.java": 2,
                "parquet-column/src/main/java/parquet/bytes/BytesUtils.java": 12
            },
            "is_test": false,
            "is_fix": false
        },
        "999b214297a9ce4cb7558fe598de04b5a2e9bb16": {
            "datetime": "2013-04-25T15:23:23-07:00",
            "summary": "use BytesUtils.paddedByteCountFromBits everywhere",
            "message": "use BytesUtils.paddedByteCountFromBits everywhere\n",
            "diff": {
                "parquet-column/src/main/java/parquet/column/values/bitpacking/BitPacking.java": 3,
                "parquet-column/src/main/java/parquet/column/values/bitpacking/BitPackingValuesReader.java": 3,
                "parquet-column/src/main/java/parquet/column/values/bitpacking/ByteBasedBitPackingEncoder.java": 5,
                "parquet-column/src/main/java/parquet/column/values/bitpacking/ByteBasedBitPackingGenerator.java": 4,
                "parquet-column/src/main/java/parquet/column/values/bitpacking/ByteBitPackingValuesReader.java": 15,
                "parquet-column/src/main/java/parquet/column/values/bitpacking/ByteBitPackingValuesWriter.java": 15,
                "parquet-column/src/main/java/parquet/column/values/rle/RLEDecoder.java": 2,
                "parquet-column/src/main/java/parquet/column/values/rle/RLESimpleEncoder.java": 2,
                "parquet-column/src/test/java/parquet/TestLog.java": 15,
                "parquet-column/src/test/java/parquet/column/values/bitpacking/BitPackingPerfTest.java": 15
            },
            "is_test": true,
            "is_fix": false
        },
        "b125deea4849d3001616f426e4fa770e7e8d020e": {
            "datetime": "2013-04-25T15:27:58-07:00",
            "summary": "make initial capacity a constant",
            "message": "make initial capacity a constant\n",
            "diff": {
                "parquet-column/src/main/java/parquet/column/values/bitpacking/BitPackingValuesWriter.java": 4
            },
            "is_test": false,
            "is_fix": false
        },
        "7cb782c35ea463da541f94576634850c58a50f34": {
            "datetime": "2013-04-25T16:33:31-07:00",
            "summary": "make a constant for constant value; remove outragous System.out.println()",
            "message": "make a constant for constant value; remove outragous System.out.println()\n",
            "diff": {
                "parquet-column/src/main/java/parquet/column/values/bitpacking/ByteBitPackingValuesReader.java": 9
            },
            "is_test": false,
            "is_fix": false
        },
        "e5484323922826f66c22e5d5d4b2dae0fe521b42": {
            "datetime": "2013-04-25T16:38:35-07:00",
            "summary": "add new line",
            "message": "add new line\n",
            "diff": {
                "parquet-column/src/main/java/parquet/column/values/bitpacking/BytePacker.java": 0
            },
            "is_test": false,
            "is_fix": false
        },
        "4c11b6625d1098345f2180aaba0efaa9cec6c69d": {
            "datetime": "2013-04-26T08:27:06-07:00",
            "summary": "typo",
            "message": "typo\n",
            "diff": {
                "parquet-column/src/main/java/parquet/column/values/dictionary/DictionaryValuesWriter.java": 2
            },
            "is_test": false,
            "is_fix": false
        },
        "280cea3b157181f4cad8cef9ddb69618caa3f5a8": {
            "datetime": "2013-04-26T10:57:30-07:00",
            "summary": "make the API treat empty fields the same as missing fields to avoid confusion",
            "message": "make the API treat empty fields the same as missing fields to avoid confusion\n",
            "diff": {
                "parquet-column/src/main/java/parquet/io/MessageColumnIO.java": 52,
                "parquet-column/src/test/java/parquet/io/ExpectationValidatingConverter.java": 6,
                "parquet-column/src/test/java/parquet/io/TestColumnIO.java": 38
            },
            "is_test": true,
            "is_fix": false
        },
        "1db1018e696a3be8ea4167b966b774ae87386578": {
            "datetime": "2013-04-26T11:01:06-07:00",
            "summary": "turn on validation for generate TPCH",
            "message": "turn on validation for generate TPCH\n",
            "diff": {
                "parquet-pig/src/test/java/parquet/pig/GenerateTPCH.java": 2
            },
            "is_test": false,
            "is_fix": false
        },
        "3f0975142a81b681e61195b4df7aa372d8c16ee9": {
            "datetime": "2013-04-26T14:21:13-07:00",
            "summary": "making empty fields illegal",
            "message": "making empty fields illegal\n",
            "diff": {
                "parquet-column/src/main/java/parquet/io/MessageColumnIO.java": 4,
                "parquet-column/src/test/java/parquet/io/TestColumnIO.java": 22,
                "parquet-pig/src/test/java/parquet/pig/GenerateTPCH.java": 4,
                "parquet-thrift/src/main/java/parquet/thrift/ParquetProtocol.java": 98,
                "parquet-thrift/src/main/java/parquet/thrift/TBaseRecordConverter.java": 17,
                "parquet-thrift/src/test/java/parquet/hadoop/thrift/TestInputOutputFormat.java": 2,
                "parquet-thrift/src/test/java/parquet/thrift/TestParquetReadProtocol.java": 2
            },
            "is_test": true,
            "is_fix": false
        },
        "7c0f1a6779e49166d2925b6afebabb58cb81bb9e": {
            "datetime": "2013-04-26T14:41:19-07:00",
            "summary": "rename fromSequence to concat",
            "message": "rename fromSequence to concat\n",
            "diff": {
                "parquet-column/src/main/java/parquet/bytes/BytesInput.java": 4,
                "parquet-column/src/main/java/parquet/column/impl/ColumnWriterImpl.java": 4,
                "parquet-column/src/main/java/parquet/column/values/bitpacking/ByteBasedBitPackingEncoder.java": 7,
                "parquet-column/src/main/java/parquet/column/values/boundedint/BoundedIntValuesWriter.java": 3,
                "parquet-column/src/main/java/parquet/column/values/rle/RLESimpleEncoder.java": 7
            },
            "is_test": false,
            "is_fix": false
        },
        "5db276f1a6b5132b9c19936bc17f9aa73c36012e": {
            "datetime": "2013-04-26T14:43:39-07:00",
            "summary": "cleanup import",
            "message": "cleanup import\n",
            "diff": {
                "parquet-column/src/main/java/parquet/column/impl/ColumnWriterImpl.java": 1
            },
            "is_test": false,
            "is_fix": false
        },
        "05505456e6db07603559c2d02233077889a249cf": {
            "datetime": "2013-04-26T14:43:44-07:00",
            "summary": "Merge branch 'master' into rle",
            "message": "Merge branch 'master' into rle\n",
            "diff": {
                "parquet-avro/src/main/java/parquet/avro/AvroGenericRecordConverter.java": 357,
                "parquet-avro/src/main/java/parquet/avro/AvroParquetInputFormat.java": 14,
                "parquet-avro/src/main/java/parquet/avro/AvroParquetOutputFormat.java": 22,
                "parquet-avro/src/main/java/parquet/avro/AvroParquetReader.java": 31,
                "parquet-avro/src/main/java/parquet/avro/AvroParquetWriter.java": 34,
                "parquet-avro/src/main/java/parquet/avro/AvroReadSupport.java": 28,
                "parquet-avro/src/main/java/parquet/avro/AvroRecordMaterializer.java": 26,
                "parquet-avro/src/main/java/parquet/avro/AvroSchemaConverter.java": 118,
                "parquet-avro/src/main/java/parquet/avro/AvroWriteSupport.java": 164,
                "parquet-avro/src/main/java/parquet/avro/package-info.java": 74,
                "parquet-avro/src/test/java/parquet/avro/TestAvroSchemaConverter.java": 87,
                "parquet-avro/src/test/java/parquet/avro/TestInputOutputFormat.java": 137,
                "parquet-avro/src/test/java/parquet/avro/TestReadWrite.java": 77,
                "parquet-cascading/src/main/java/parquet/cascading/ParquetTBaseScheme.java": 2,
                "parquet-column/src/main/java/parquet/io/api/Binary.java": 61,
                "parquet-hadoop/src/main/java/parquet/hadoop/ParquetInputFormat.java": 9,
                "parquet-hadoop/src/main/java/parquet/hadoop/ParquetReader.java": 75,
                "parquet-hadoop/src/main/java/parquet/hadoop/ParquetRecordReader.java": 2,
                "parquet-hadoop/src/main/java/parquet/hadoop/ParquetWriter.java": 66,
                "parquet-scrooge/src/main/java/parquet/scrooge/ParquetScroogeScheme.java": 2
            },
            "is_test": true,
            "is_fix": false
        },
        "43dcb039476577743c62a0cb8f1ba18b0fff225c": {
            "datetime": "2013-04-26T15:49:17-07:00",
            "summary": "Merge branch 'master' into dictionary_encoding",
            "message": "Merge branch 'master' into dictionary_encoding\n",
            "diff": {
                "parquet-avro/src/main/java/parquet/avro/AvroGenericRecordConverter.java": 357,
                "parquet-avro/src/main/java/parquet/avro/AvroParquetInputFormat.java": 14,
                "parquet-avro/src/main/java/parquet/avro/AvroParquetOutputFormat.java": 22,
                "parquet-avro/src/main/java/parquet/avro/AvroParquetReader.java": 31,
                "parquet-avro/src/main/java/parquet/avro/AvroParquetWriter.java": 34,
                "parquet-avro/src/main/java/parquet/avro/AvroReadSupport.java": 28,
                "parquet-avro/src/main/java/parquet/avro/AvroRecordMaterializer.java": 26,
                "parquet-avro/src/main/java/parquet/avro/AvroSchemaConverter.java": 118,
                "parquet-avro/src/main/java/parquet/avro/AvroWriteSupport.java": 164,
                "parquet-avro/src/main/java/parquet/avro/package-info.java": 74,
                "parquet-avro/src/test/java/parquet/avro/TestAvroSchemaConverter.java": 87,
                "parquet-avro/src/test/java/parquet/avro/TestInputOutputFormat.java": 137,
                "parquet-avro/src/test/java/parquet/avro/TestReadWrite.java": 77,
                "parquet-cascading/src/main/java/parquet/cascading/ParquetTBaseScheme.java": 2,
                "parquet-column/src/main/java/parquet/io/api/Binary.java": 61,
                "parquet-hadoop/src/main/java/parquet/hadoop/ParquetInputFormat.java": 9,
                "parquet-hadoop/src/main/java/parquet/hadoop/ParquetReader.java": 75,
                "parquet-hadoop/src/main/java/parquet/hadoop/ParquetRecordReader.java": 2,
                "parquet-hadoop/src/main/java/parquet/hadoop/ParquetWriter.java": 66,
                "parquet-scrooge/src/main/java/parquet/scrooge/ParquetScroogeScheme.java": 2
            },
            "is_test": true,
            "is_fix": false
        },
        "6b867e502c1b9cfe6b10e1e7387d93ef2969e7e4": {
            "datetime": "2013-04-27T17:08:48-07:00",
            "summary": "skeleton for an efficient converter from groups to cascading tuples",
            "message": "skeleton for an efficient converter from groups to cascading tuples\n",
            "diff": {
                "parquet-cascading/src/main/java/parquet/cascading/FilterSchema.java": 16,
                "parquet-cascading/src/main/java/parquet/cascading/ParquetTupleScheme.java": 95,
                "parquet-cascading/src/main/java/parquet/cascading/TupleReadSupport.java": 58,
                "parquet-cascading/src/main/java/parquet/cascading/convert/TupleConverter.java": 97,
                "parquet-cascading/src/main/java/parquet/cascading/convert/TupleRecordMaterializer.java": 28
            },
            "is_test": false,
            "is_fix": false
        },
        "065a3c90673a7b3eae9165db0c4f0786372153dd": {
            "datetime": "2013-04-27T22:06:25-07:00",
            "summary": "working selective tuple materialization for cascading",
            "message": "working selective tuple materialization for cascading\n",
            "diff": {
                "parquet-cascading/src/main/java/parquet/cascading/FilterSchema.java": 16,
                "parquet-cascading/src/main/java/parquet/cascading/ParquetTupleScheme.java": 27,
                "parquet-cascading/src/main/java/parquet/cascading/SchemaIntersection.java": 42,
                "parquet-cascading/src/main/java/parquet/cascading/TupleReadSupport.java": 36,
                "parquet-cascading/src/main/java/parquet/cascading/convert/TupleConverter.java": 2,
                "parquet-hadoop/src/main/java/parquet/hadoop/ParquetFileReader.java": 14
            },
            "is_test": false,
            "is_fix": false
        },
        "593a105cea2faa01849240e140a6f9fd03bd31f7": {
            "datetime": "2013-04-27T22:14:34-07:00",
            "summary": "short class comment for the TupleScheme",
            "message": "short class comment for the TupleScheme\n",
            "diff": {
                "parquet-cascading/src/main/java/parquet/cascading/ParquetTupleScheme.java": 15
            },
            "is_test": false,
            "is_fix": false
        },
        "1f0a8a25ad7d3b2683f0f8b10449db3ff1c2de13": {
            "datetime": "2013-04-28T16:05:04-07:00",
            "summary": "replace DeprecatedContainerInputFormat with DeprecatedParquetInputFormat, should build under MR2",
            "message": "replace DeprecatedContainerInputFormat with DeprecatedParquetInputFormat, should build under MR2\n",
            "diff": {
                "parquet-hadoop/src/main/java/parquet/hadoop/ParquetInputFormat.java": 34,
                "parquet-hadoop/src/main/java/parquet/hadoop/ParquetRecordReader.java": 8,
                "parquet-hadoop/src/main/java/parquet/hadoop/mapred/DeprecatedParquetInputFormat.java": 204,
                "parquet-hadoop/src/test/java/parquet/hadoop/TestInputFormat.java": 4,
                "parquet-thrift/src/main/java/parquet/hadoop/thrift/Container.java": 2,
                "parquet-thrift/src/main/java/parquet/hadoop/thrift/DeprecatedContainerInputFormat.java": 372
            },
            "is_test": true,
            "is_fix": false
        },
        "5e82439eb8f99d20a5bbc55fdeaa0840b0cac90f": {
            "datetime": "2013-04-28T16:20:06-07:00",
            "summary": "fix up cascading and scrooge to use DeprecatedParquetInputFormat",
            "message": "fix up cascading and scrooge to use DeprecatedParquetInputFormat\n",
            "diff": {
                "parquet-cascading/src/main/java/parquet/cascading/ParquetTBaseScheme.java": 9,
                "parquet-cascading/src/main/java/parquet/cascading/ParquetValueScheme.java": 2,
                "parquet-scrooge/src/main/java/parquet/scrooge/ParquetScroogeScheme.java": 8
            },
            "is_test": false,
            "is_fix": false
        },
        "20a4bf72e9e64e317c9167eea88303b4f4e16f31": {
            "datetime": "2013-04-28T21:20:13-07:00",
            "summary": "DeprecatedParquetInputFormat is not abstract",
            "message": "DeprecatedParquetInputFormat is not abstract\n",
            "diff": {
                "parquet-hadoop/src/main/java/parquet/hadoop/mapred/DeprecatedParquetInputFormat.java": 2
            },
            "is_test": false,
            "is_fix": false
        },
        "2676de9bf340c2b97d1df6ac4208eba8e1cc28dd": {
            "datetime": "2013-04-28T21:35:31-07:00",
            "summary": "Treat Fields.UNKNOWN as Fields.ALL",
            "message": "Treat Fields.UNKNOWN as Fields.ALL\n",
            "diff": {
                "parquet-cascading/src/main/java/parquet/cascading/SchemaIntersection.java": 3
            },
            "is_test": false,
            "is_fix": false
        },
        "a49a0e929d6404d2291bc8959682ac6f8eadefa4": {
            "datetime": "2013-04-28T21:47:42-07:00",
            "summary": "don't create a TaskAttemptContext in ParquetReader",
            "message": "don't create a TaskAttemptContext in ParquetReader\n",
            "diff": {
                "parquet-hadoop/src/main/java/parquet/hadoop/ParquetReader.java": 7,
                "parquet-hadoop/src/main/java/parquet/hadoop/ParquetRecordReader.java": 2
            },
            "is_test": false,
            "is_fix": false
        },
        "74157a052de90b429000a16809db73f1edaa82b1": {
            "datetime": "2013-04-29T15:50:27+04:00",
            "summary": "Fixed potential Integer overflow.",
            "message": "Fixed potential Integer overflow.\n",
            "diff": {
                "parquet-column/src/main/java/parquet/column/impl/ColumnWriterImpl.java": 4
            },
            "is_test": false,
            "is_fix": false
        },
        "fc0c7cdd92c703784b9dfa4f891ee2be59f4d7b0": {
            "datetime": "2013-04-29T08:23:47-07:00",
            "summary": "integrate RLE into dictionary encoding",
            "message": "integrate RLE into dictionary encoding\n",
            "diff": {
                "parquet-column/src/main/java/parquet/bytes/BytesInput.java": 2,
                "parquet-column/src/main/java/parquet/column/values/bitpacking/ByteBasedBitPackingEncoder.java": 5,
                "parquet-column/src/main/java/parquet/column/values/dictionary/DictionaryValuesReader.java": 27,
                "parquet-column/src/main/java/parquet/column/values/dictionary/DictionaryValuesWriter.java": 35,
                "parquet-column/src/main/java/parquet/column/values/dictionary/IntList.java": 68,
                "parquet-column/src/main/java/parquet/column/values/rle/RLEDecoder.java": 7,
                "parquet-column/src/main/java/parquet/column/values/rle/RLESimpleEncoder.java": 21,
                "parquet-pig/src/test/java/parquet/pig/GenerateIntTestFile.java": 5
            },
            "is_test": false,
            "is_fix": false
        },
        "7cb711c27df1b4c0b1fdc7ae28837f4051c814da": {
            "datetime": "2013-04-29T08:32:59-07:00",
            "summary": "Merge branch 'rle' into dictionary_encoding",
            "message": "Merge branch 'rle' into dictionary_encoding\n\nConflicts:\n\tparquet-column/src/main/java/parquet/column/values/bitpacking/ByteBasedBitPackingEncoder.java\n\tparquet-column/src/main/java/parquet/column/values/rle/RLESimpleEncoder.java\n",
            "diff": {
                "parquet-column/src/main/java/parquet/bytes/BytesInput.java": 6,
                "parquet-column/src/main/java/parquet/bytes/BytesUtils.java": 12,
                "parquet-column/src/main/java/parquet/column/impl/ColumnWriterImpl.java": 5,
                "parquet-column/src/main/java/parquet/column/values/bitpacking/BitPacking.java": 3,
                "parquet-column/src/main/java/parquet/column/values/bitpacking/BitPackingValuesReader.java": 3,
                "parquet-column/src/main/java/parquet/column/values/bitpacking/BitPackingValuesWriter.java": 4,
                "parquet-column/src/main/java/parquet/column/values/bitpacking/ByteBasedBitPackingEncoder.java": 12,
                "parquet-column/src/main/java/parquet/column/values/bitpacking/ByteBasedBitPackingGenerator.java": 4,
                "parquet-column/src/main/java/parquet/column/values/bitpacking/ByteBitPackingValuesReader.java": 24,
                "parquet-column/src/main/java/parquet/column/values/bitpacking/ByteBitPackingValuesWriter.java": 15,
                "parquet-column/src/main/java/parquet/column/values/bitpacking/BytePacker.java": 0,
                "parquet-column/src/main/java/parquet/column/values/boundedint/BoundedIntValuesWriter.java": 3,
                "parquet-column/src/main/java/parquet/column/values/dictionary/DictionaryValuesWriter.java": 3,
                "parquet-column/src/main/java/parquet/column/values/rle/RLEDecoder.java": 2,
                "parquet-column/src/main/java/parquet/column/values/rle/RLESimpleEncoder.java": 9,
                "parquet-column/src/test/java/parquet/TestLog.java": 15,
                "parquet-column/src/test/java/parquet/column/values/bitpacking/BitPackingPerfTest.java": 15
            },
            "is_test": true,
            "is_fix": false
        },
        "249e88935a203cda47483f7c73696000abd615e8": {
            "datetime": "2013-04-29T10:01:49-07:00",
            "summary": "Use a simpler serialization for cascading Fields to be compatible with older cascading versions",
            "message": "Use a simpler serialization for cascading Fields to be compatible with older cascading versions\n",
            "diff": {
                "parquet-cascading/src/main/java/parquet/cascading/TupleReadSupport.java": 22
            },
            "is_test": false,
            "is_fix": false
        },
        "8cb82ee8c8bc9f558fc16a0f8f41f1334e5c5dc0": {
            "datetime": "2013-04-29T10:06:38-07:00",
            "summary": "javadoc",
            "message": "javadoc\n",
            "diff": {
                "parquet-column/src/main/java/parquet/column/ColumnReader.java": 1
            },
            "is_test": false,
            "is_fix": false
        },
        "c96e7949a85b5327b348c587dfc9906707e18d4b": {
            "datetime": "2013-04-29T10:11:05-07:00",
            "summary": "+ needs space",
            "message": "+ needs space\n",
            "diff": {
                "parquet-column/src/main/java/parquet/io/MessageColumnIO.java": 26
            },
            "is_test": false,
            "is_fix": false
        },
        "d6e3866964a91a7c8d2b809215a2a4cf27fd308a": {
            "datetime": "2013-04-29T10:13:16-07:00",
            "summary": "Merge pull request #36 from 0xh3x/master",
            "message": "Merge pull request #36 from 0xh3x/master\n\nPotential Integer overflow in ColumnWriterImpl",
            "diff": {
                "parquet-column/src/main/java/parquet/column/impl/ColumnWriterImpl.java": 4
            },
            "is_test": false,
            "is_fix": false
        },
        "d822ef5a75567f75d7c5ceeb2958166bb5e99e92": {
            "datetime": "2013-04-29T10:19:55-07:00",
            "summary": "Merge pull request #35 from avibryant/deprecated-mr2",
            "message": "Merge pull request #35 from avibryant/deprecated-mr2\n\nHadoop 2 compatible DeprecatedParquetInputFormat",
            "diff": {
                "parquet-cascading/src/main/java/parquet/cascading/ParquetTBaseScheme.java": 9,
                "parquet-cascading/src/main/java/parquet/cascading/ParquetValueScheme.java": 2,
                "parquet-hadoop/src/main/java/parquet/hadoop/ParquetInputFormat.java": 34,
                "parquet-hadoop/src/main/java/parquet/hadoop/ParquetReader.java": 7,
                "parquet-hadoop/src/main/java/parquet/hadoop/ParquetRecordReader.java": 8,
                "parquet-hadoop/src/main/java/parquet/hadoop/mapred/DeprecatedParquetInputFormat.java": 204,
                "parquet-hadoop/src/test/java/parquet/hadoop/TestInputFormat.java": 4,
                "parquet-scrooge/src/main/java/parquet/scrooge/ParquetScroogeScheme.java": 8,
                "parquet-thrift/src/main/java/parquet/hadoop/thrift/Container.java": 2,
                "parquet-thrift/src/main/java/parquet/hadoop/thrift/DeprecatedContainerInputFormat.java": 372
            },
            "is_test": true,
            "is_fix": false
        },
        "f2ab7a27d9dbe8ec9cfa407bcaee4d4f99d3ea83": {
            "datetime": "2013-04-29T10:35:04-07:00",
            "summary": "Use a simpler serialization for cascading Fields to be compatible with older cascading versions",
            "message": "Use a simpler serialization for cascading Fields to be compatible with older cascading versions\n",
            "diff": {
                "parquet-cascading/src/main/java/parquet/cascading/TupleReadSupport.java": 22
            },
            "is_test": false,
            "is_fix": false
        },
        "1ee87d8ff65e58396a14b407e96c140fde030f77": {
            "datetime": "2013-04-29T10:35:04-07:00",
            "summary": "Treat Fields.UNKNOWN as Fields.ALL",
            "message": "Treat Fields.UNKNOWN as Fields.ALL\n",
            "diff": {
                "parquet-cascading/src/main/java/parquet/cascading/SchemaIntersection.java": 3
            },
            "is_test": false,
            "is_fix": false
        },
        "2f0a779ba2db69649591ab2663cafe6bc0ce09f5": {
            "datetime": "2013-04-29T10:35:04-07:00",
            "summary": "short class comment for the TupleScheme",
            "message": "short class comment for the TupleScheme\n",
            "diff": {
                "parquet-cascading/src/main/java/parquet/cascading/ParquetTupleScheme.java": 15
            },
            "is_test": false,
            "is_fix": false
        },
        "62df1234e87094cc0965f04fa7444fd3ea136938": {
            "datetime": "2013-04-29T10:35:04-07:00",
            "summary": "working selective tuple materialization for cascading",
            "message": "working selective tuple materialization for cascading\n",
            "diff": {
                "parquet-cascading/src/main/java/parquet/cascading/FilterSchema.java": 16,
                "parquet-cascading/src/main/java/parquet/cascading/ParquetTupleScheme.java": 27,
                "parquet-cascading/src/main/java/parquet/cascading/SchemaIntersection.java": 42,
                "parquet-cascading/src/main/java/parquet/cascading/TupleReadSupport.java": 36,
                "parquet-cascading/src/main/java/parquet/cascading/convert/TupleConverter.java": 2,
                "parquet-hadoop/src/main/java/parquet/hadoop/ParquetFileReader.java": 14
            },
            "is_test": false,
            "is_fix": false
        },
        "30b461eabcdcb19708468159db8edba18ff31047": {
            "datetime": "2013-04-29T10:35:04-07:00",
            "summary": "skeleton for an efficient converter from groups to cascading tuples",
            "message": "skeleton for an efficient converter from groups to cascading tuples\n",
            "diff": {
                "parquet-cascading/src/main/java/parquet/cascading/FilterSchema.java": 16,
                "parquet-cascading/src/main/java/parquet/cascading/ParquetTupleScheme.java": 95,
                "parquet-cascading/src/main/java/parquet/cascading/TupleReadSupport.java": 58,
                "parquet-cascading/src/main/java/parquet/cascading/convert/TupleConverter.java": 97,
                "parquet-cascading/src/main/java/parquet/cascading/convert/TupleRecordMaterializer.java": 28
            },
            "is_test": false,
            "is_fix": false
        },
        "ffebada1455a96e22fd24dc961ba432087ded7ba": {
            "datetime": "2013-04-29T10:40:11-07:00",
            "summary": "update ParquetTupleScheme to use DeprecatedParquetInputFormat",
            "message": "update ParquetTupleScheme to use DeprecatedParquetInputFormat\n",
            "diff": {
                "parquet-cascading/src/main/java/parquet/cascading/ParquetTupleScheme.java": 6
            },
            "is_test": false,
            "is_fix": false
        },
        "3c96e97867b406411b7152d0ddd4374729b3f5d1": {
            "datetime": "2013-04-29T14:35:38-07:00",
            "summary": "Merge pull request #33 from Parquet/handle_empty_fields_as_nulls",
            "message": "Merge pull request #33 from Parquet/handle_empty_fields_as_nulls\n\nmake the API refuse empty fields and require missing fields",
            "diff": {
                "parquet-column/src/main/java/parquet/io/MessageColumnIO.java": 76,
                "parquet-column/src/test/java/parquet/io/ExpectationValidatingConverter.java": 6,
                "parquet-column/src/test/java/parquet/io/TestColumnIO.java": 32,
                "parquet-pig/src/test/java/parquet/pig/GenerateTPCH.java": 6,
                "parquet-thrift/src/main/java/parquet/thrift/ParquetProtocol.java": 98,
                "parquet-thrift/src/main/java/parquet/thrift/TBaseRecordConverter.java": 17,
                "parquet-thrift/src/test/java/parquet/hadoop/thrift/TestInputOutputFormat.java": 2,
                "parquet-thrift/src/test/java/parquet/thrift/TestParquetReadProtocol.java": 2
            },
            "is_test": true,
            "is_fix": false
        },
        "634cb777c22ee7d4b03b3c35c85f3d198e7c1691": {
            "datetime": "2013-04-30T08:08:08-07:00",
            "summary": "fix bug when printing a ByteBuffer based binary would consume the buffer",
            "message": "fix bug when printing a ByteBuffer based binary would consume the buffer\n",
            "diff": {
                "parquet-column/src/main/java/parquet/io/api/Binary.java": 7
            },
            "is_test": false,
            "is_fix": false
        },
        "aaa58d36317c6242fb086efd3a161d5aee0c85db": {
            "datetime": "2013-04-30T13:38:16-07:00",
            "summary": "code formating and license headers",
            "message": "code formating and license headers\n",
            "diff": {
                "parquet-avro/src/main/java/parquet/avro/AvroGenericRecordConverter.java": 15,
                "parquet-avro/src/main/java/parquet/avro/AvroParquetInputFormat.java": 15,
                "parquet-avro/src/main/java/parquet/avro/AvroParquetOutputFormat.java": 15,
                "parquet-avro/src/main/java/parquet/avro/AvroReadSupport.java": 15,
                "parquet-avro/src/main/java/parquet/avro/AvroRecordMaterializer.java": 15,
                "parquet-avro/src/main/java/parquet/avro/AvroWriteSupport.java": 15,
                "parquet-avro/src/main/java/parquet/avro/package-info.java": 15,
                "parquet-avro/src/test/java/parquet/avro/TestAvroSchemaConverter.java": 15,
                "parquet-avro/src/test/java/parquet/avro/TestReadWrite.java": 15,
                "parquet-column/src/main/java/parquet/column/values/bitpacking/ByteBasedBitPackingGenerator.java": 4,
                "parquet-column/src/main/java/parquet/column/values/bitpacking/ByteBitPacking.java": 264
            },
            "is_test": true,
            "is_fix": false
        },
        "2d4be4391e17612fbfec132adf6b5b1dc1b40802": {
            "datetime": "2013-04-30T18:13:09-07:00",
            "summary": "Merge pull request #25 from Parquet/rle",
            "message": "Merge pull request #25 from Parquet/rle\n\nRLE and Bitpacking improvement",
            "diff": {
                "parquet-avro/src/main/java/parquet/avro/AvroGenericRecordConverter.java": 15,
                "parquet-avro/src/main/java/parquet/avro/AvroParquetInputFormat.java": 15,
                "parquet-avro/src/main/java/parquet/avro/AvroParquetOutputFormat.java": 15,
                "parquet-avro/src/main/java/parquet/avro/AvroReadSupport.java": 15,
                "parquet-avro/src/main/java/parquet/avro/AvroRecordMaterializer.java": 15,
                "parquet-avro/src/main/java/parquet/avro/AvroWriteSupport.java": 15,
                "parquet-avro/src/main/java/parquet/avro/package-info.java": 15,
                "parquet-avro/src/test/java/parquet/avro/TestAvroSchemaConverter.java": 15,
                "parquet-avro/src/test/java/parquet/avro/TestReadWrite.java": 15,
                "parquet-column/src/main/java/parquet/bytes/BytesInput.java": 43,
                "parquet-column/src/main/java/parquet/bytes/BytesUtils.java": 39,
                "parquet-column/src/main/java/parquet/column/Encoding.java": 4,
                "parquet-column/src/main/java/parquet/column/impl/ColumnWriterImpl.java": 11,
                "parquet-column/src/main/java/parquet/column/values/bitpacking/BitPacking.java": 3,
                "parquet-column/src/main/java/parquet/column/values/bitpacking/BitPackingValuesReader.java": 7,
                "parquet-column/src/main/java/parquet/column/values/bitpacking/BitPackingValuesWriter.java": 10,
                "parquet-column/src/main/java/parquet/column/values/bitpacking/ByteBasedBitPackingEncoder.java": 117,
                "parquet-column/src/main/java/parquet/column/values/bitpacking/ByteBasedBitPackingGenerator.java": 232,
                "parquet-column/src/main/java/parquet/column/values/bitpacking/ByteBitPacking.java": 25636,
                "parquet-column/src/main/java/parquet/column/values/bitpacking/ByteBitPackingValuesReader.java": 70,
                "parquet-column/src/main/java/parquet/column/values/bitpacking/ByteBitPackingValuesWriter.java": 76,
                "parquet-column/src/main/java/parquet/column/values/bitpacking/BytePacker.java": 83,
                "parquet-column/src/main/java/parquet/column/values/bitpacking/IntBasedBitPackingGenerator.java": 202,
                "parquet-column/src/main/java/parquet/column/values/bitpacking/IntPacker.java": 63,
                "parquet-column/src/main/java/parquet/column/values/bitpacking/LemireBitPackingBE.java": 3353,
                "parquet-column/src/main/java/parquet/column/values/bitpacking/LemireBitPackingLE.java": 3352,
                "parquet-column/src/main/java/parquet/column/values/boundedint/BoundedIntValuesWriter.java": 3,
                "parquet-column/src/main/java/parquet/column/values/plain/BinaryPlainValuesReader.java": 15,
                "parquet-column/src/main/java/parquet/column/values/rle/RLEDecoder.java": 104,
                "parquet-column/src/main/java/parquet/column/values/rle/RLESimpleEncoder.java": 53,
                "parquet-column/src/test/java/parquet/TestLog.java": 28,
                "parquet-column/src/test/java/parquet/column/primitive/TestBitPacking.java": 4,
                "parquet-column/src/test/java/parquet/column/primitive/TestBitPackingColumn.java": 62,
                "parquet-column/src/test/java/parquet/column/values/bitpacking/BitPackingPerfTest.java": 100,
                "parquet-column/src/test/java/parquet/column/values/bitpacking/TestByteBitPacking.java": 134,
                "parquet-column/src/test/java/parquet/column/values/bitpacking/TestLemireBitPacking.java": 110,
                "parquet-column/src/test/java/parquet/column/values/rle/TestRLE.java": 62
            },
            "is_test": true,
            "is_fix": false
        },
        "59f4b102517c472f26ea2138d353b33ee8146380": {
            "datetime": "2013-05-01T09:45:04-07:00",
            "summary": "Use the standard readFooters in ParquetTupleScheme",
            "message": "Use the standard readFooters in ParquetTupleScheme\n",
            "diff": {
                "parquet-cascading/src/main/java/parquet/cascading/ParquetTupleScheme.java": 14,
                "parquet-cascading/src/main/java/parquet/cascading/TupleReadSupport.java": 4,
                "parquet-hadoop/src/main/java/parquet/hadoop/ParquetFileReader.java": 12
            },
            "is_test": false,
            "is_fix": false
        },
        "88690f97f3aba9112b25337512d1e82e9034793d": {
            "datetime": "2013-05-01T09:58:33-07:00",
            "summary": "Fix Avro Read/Write support to work with the union-null optional value pattern",
            "message": "Fix Avro Read/Write support to work with the union-null optional value pattern\n",
            "diff": {
                "parquet-avro/src/main/java/parquet/avro/AvroGenericRecordConverter.java": 3,
                "parquet-avro/src/main/java/parquet/avro/AvroSchemaHelper.java": 51,
                "parquet-avro/src/main/java/parquet/avro/AvroWriteSupport.java": 15,
                "parquet-avro/src/test/java/parquet/avro/TestInputOutputFormat.java": 12
            },
            "is_test": true,
            "is_fix": false
        },
        "5ed616243b81f61e12e45d4e4b67f312f85d5289": {
            "datetime": "2013-05-01T11:29:10-07:00",
            "summary": "mvn license:headers",
            "message": "mvn license:headers\n",
            "diff": {
                "parquet-cascading/src/main/java/parquet/cascading/ParquetTupleScheme.java": 15,
                "parquet-cascading/src/main/java/parquet/cascading/SchemaIntersection.java": 15,
                "parquet-cascading/src/main/java/parquet/cascading/TupleReadSupport.java": 15,
                "parquet-cascading/src/main/java/parquet/cascading/convert/TupleConverter.java": 15,
                "parquet-cascading/src/main/java/parquet/cascading/convert/TupleRecordMaterializer.java": 15
            },
            "is_test": false,
            "is_fix": false
        },
        "c7ebfbb14a1147b8c34d176821000140d2ec8bfc": {
            "datetime": "2013-05-01T11:35:40-07:00",
            "summary": "Fixes based on Julian's feedback",
            "message": "Fixes based on Julian's feedback\n",
            "diff": {
                "parquet-avro/src/main/java/parquet/avro/AvroGenericRecordConverter.java": 2,
                "parquet-avro/src/main/java/parquet/avro/AvroSchemaConverter.java": 26,
                "parquet-avro/src/main/java/parquet/avro/AvroSchemaHelper.java": 51,
                "parquet-avro/src/main/java/parquet/avro/AvroWriteSupport.java": 6
            },
            "is_test": false,
            "is_fix": false
        },
        "f3ee0c9b2380aefc2b9d861a9e721bfce755bde0": {
            "datetime": "2013-05-01T11:51:58-07:00",
            "summary": "Merge pull request #37 from avibryant/cascading-tuples",
            "message": "Merge pull request #37 from avibryant/cascading-tuples\n\nCascading tuple support",
            "diff": {
                "parquet-cascading/src/main/java/parquet/cascading/ParquetTupleScheme.java": 140,
                "parquet-cascading/src/main/java/parquet/cascading/SchemaIntersection.java": 60,
                "parquet-cascading/src/main/java/parquet/cascading/TupleReadSupport.java": 77,
                "parquet-cascading/src/main/java/parquet/cascading/convert/TupleConverter.java": 112,
                "parquet-cascading/src/main/java/parquet/cascading/convert/TupleRecordMaterializer.java": 43,
                "parquet-hadoop/src/main/java/parquet/hadoop/ParquetFileReader.java": 6
            },
            "is_test": false,
            "is_fix": false
        },
        "cec7b39ea182757d43e247241c2a4f64e1b04a24": {
            "datetime": "2013-05-01T11:56:10-07:00",
            "summary": "Merge pull request #41 from jwills/avro-null-unions",
            "message": "Merge pull request #41 from jwills/avro-null-unions\n\nFix Avro Read/Write support to work with union-null optional values",
            "diff": {
                "parquet-avro/src/main/java/parquet/avro/AvroGenericRecordConverter.java": 3,
                "parquet-avro/src/main/java/parquet/avro/AvroSchemaConverter.java": 26,
                "parquet-avro/src/main/java/parquet/avro/AvroWriteSupport.java": 15,
                "parquet-avro/src/test/java/parquet/avro/TestInputOutputFormat.java": 12
            },
            "is_test": true,
            "is_fix": false
        },
        "a1fbcfb1fd229f77222fabae54a97f3b161f4d26": {
            "datetime": "2013-05-01T16:05:25-07:00",
            "summary": "make total size include header size",
            "message": "make total size include header size\n",
            "diff": {
                "parquet-column/src/main/java/parquet/Log.java": 2,
                "parquet-hadoop/src/main/java/parquet/hadoop/ParquetFileWriter.java": 21,
                "parquet-hadoop/src/test/java/parquet/hadoop/TestParquetFileWriter.java": 7
            },
            "is_test": true,
            "is_fix": false
        },
        "75ead0a3ed59c4b821fc2973b8917a856d3067dc": {
            "datetime": "2013-05-01T16:08:06-07:00",
            "summary": "turn LOGs back to INFO",
            "message": "turn LOGs back to INFO\n",
            "diff": {
                "parquet-column/src/main/java/parquet/Log.java": 2
            },
            "is_test": false,
            "is_fix": false
        },
        "6c26ece97fc5d13a0ea68c23f52ca7ee6f671516": {
            "datetime": "2013-05-01T17:35:59-07:00",
            "summary": "Merge pull request #42 from Parquet/make_total_size_include_headers",
            "message": "Merge pull request #42 from Parquet/make_total_size_include_headers\n\nmake total size include header size",
            "diff": {
                "parquet-hadoop/src/main/java/parquet/hadoop/ParquetFileWriter.java": 21,
                "parquet-hadoop/src/test/java/parquet/hadoop/TestParquetFileWriter.java": 7
            },
            "is_test": true,
            "is_fix": false
        },
        "f5ab5ebd5e3c9e3a63f2dcc124b60fb3349679b3": {
            "datetime": "2013-05-03T09:45:03-07:00",
            "summary": "better error message when schema is unknown",
            "message": "better error message when schema is unknown\n",
            "diff": {
                "parquet-pig/src/main/java/parquet/pig/ParquetStorer.java": 6
            },
            "is_test": false,
            "is_fix": false
        },
        "6c1ccb7e155319faa58ff7add19f87315ab5a3d1": {
            "datetime": "2013-05-03T14:37:51-07:00",
            "summary": "Merge pull request #45 from Parquet/no_schema_error",
            "message": "Merge pull request #45 from Parquet/no_schema_error\n\nbetter error message when schema is unknown",
            "diff": {
                "parquet-pig/src/main/java/parquet/pig/ParquetStorer.java": 6
            },
            "is_test": false,
            "is_fix": false
        },
        "0c250380bd15e6491857108b9463e4b9ba3c00c9": {
            "datetime": "2013-05-03T18:30:57-07:00",
            "summary": "read version information from META-INF",
            "message": "read version information from META-INF\n",
            "diff": {
                "parquet-column/src/main/java/parquet/Version.java": 66
            },
            "is_test": false,
            "is_fix": false
        },
        "a20750a87d69823e4048d954627494505d508e2e": {
            "datetime": "2013-05-07T16:03:16+01:00",
            "summary": "Replace JobContext#getConfiguration calls with reflective call.",
            "message": "Replace JobContext#getConfiguration calls with reflective call.\n",
            "diff": {
                "parquet-avro/src/main/java/parquet/avro/AvroParquetOutputFormat.java": 3,
                "parquet-hadoop/src/main/java/parquet/hadoop/ParquetInputFormat.java": 9,
                "parquet-hadoop/src/main/java/parquet/hadoop/ParquetOutputCommitter.java": 3,
                "parquet-hadoop/src/main/java/parquet/hadoop/ParquetOutputFormat.java": 21,
                "parquet-hadoop/src/main/java/parquet/hadoop/ParquetRecordReader.java": 3,
                "parquet-hadoop/src/main/java/parquet/hadoop/example/ExampleOutputFormat.java": 5,
                "parquet-hadoop/src/main/java/parquet/hadoop/util/ContextUtil.java": 245,
                "parquet-hadoop/src/test/java/parquet/hadoop/example/TestInputOutputFormat.java": 3,
                "parquet-pig/src/main/java/parquet/pig/ParquetLoader.java": 3,
                "parquet-pig/src/test/java/parquet/pig/PerfTest2.java": 11,
                "parquet-thrift/src/main/java/parquet/hadoop/thrift/ParquetThriftBytesOutputFormat.java": 7,
                "parquet-thrift/src/main/java/parquet/hadoop/thrift/ParquetThriftOutputFormat.java": 5,
                "parquet-thrift/src/test/java/parquet/hadoop/thrift/TestThriftToParquetFileWriter.java": 5
            },
            "is_test": true,
            "is_fix": false
        },
        "a67ea4ea283481abd324a0a799d6a09cc8002545": {
            "datetime": "2013-05-07T16:03:49+01:00",
            "summary": "add test for hadoop2",
            "message": "add test for hadoop2\n",
            "diff": {
                "parquet-test-hadoop2/src/test/java/parquet/hadoop2/TestInputOutputFormat.java": 137
            },
            "is_test": true,
            "is_fix": false
        },
        "5ab09189cf32c76a3bdd8fecedaf337735c1ea24": {
            "datetime": "2013-05-07T21:30:47+01:00",
            "summary": "update dependencies to hadoop-client",
            "message": "update dependencies to hadoop-client\n",
            "diff": {
                "parquet-test-hadoop2/src/test/java/parquet/hadoop2/TestInputOutputFormat.java": 6
            },
            "is_test": true,
            "is_fix": false
        },
        "fae4c56c0526db232d5d4e98f9587c549ed50e27": {
            "datetime": "2013-05-07T17:22:47-07:00",
            "summary": "Merge pull request #32 from tomwhite/hadoop2",
            "message": "Merge pull request #32 from tomwhite/hadoop2\n\nAdd a build profile for Hadoop 2.",
            "diff": {
                "parquet-avro/src/main/java/parquet/avro/AvroParquetOutputFormat.java": 3,
                "parquet-hadoop/src/main/java/parquet/hadoop/ParquetInputFormat.java": 9,
                "parquet-hadoop/src/main/java/parquet/hadoop/ParquetOutputCommitter.java": 3,
                "parquet-hadoop/src/main/java/parquet/hadoop/ParquetOutputFormat.java": 21,
                "parquet-hadoop/src/main/java/parquet/hadoop/ParquetRecordReader.java": 3,
                "parquet-hadoop/src/main/java/parquet/hadoop/example/ExampleOutputFormat.java": 5,
                "parquet-hadoop/src/main/java/parquet/hadoop/util/ContextUtil.java": 245,
                "parquet-hadoop/src/test/java/parquet/hadoop/example/TestInputOutputFormat.java": 3,
                "parquet-pig/src/main/java/parquet/pig/ParquetLoader.java": 3,
                "parquet-pig/src/test/java/parquet/pig/PerfTest2.java": 11,
                "parquet-test-hadoop2/src/test/java/parquet/hadoop2/TestInputOutputFormat.java": 139,
                "parquet-thrift/src/main/java/parquet/hadoop/thrift/ParquetThriftBytesOutputFormat.java": 7,
                "parquet-thrift/src/main/java/parquet/hadoop/thrift/ParquetThriftOutputFormat.java": 5,
                "parquet-thrift/src/test/java/parquet/hadoop/thrift/TestThriftToParquetFileWriter.java": 5
            },
            "is_test": true,
            "is_fix": false
        },
        "647825b5a7b317dfb6d1a6ef61eca87c75e6bfd2": {
            "datetime": "2013-05-07T18:55:15-07:00",
            "summary": "Changed two utility classes to public",
            "message": "Changed two utility classes to public\n\nAvroSchemaConverter\nCodecFactory\n",
            "diff": {
                "parquet-avro/src/main/java/parquet/avro/AvroSchemaConverter.java": 2,
                "parquet-hadoop/src/main/java/parquet/hadoop/CodecFactory.java": 2
            },
            "is_test": false,
            "is_fix": false
        },
        "09a54d6c786d7258cb1baf03f821882058ea62c6": {
            "datetime": "2013-05-08T18:12:20-07:00",
            "summary": "Rolled back one of the public classes",
            "message": "Rolled back one of the public classes\n",
            "diff": {
                "parquet-hadoop/src/main/java/parquet/hadoop/CodecFactory.java": 2
            },
            "is_test": false,
            "is_fix": false
        },
        "3e4561b5a15d234d9a9f2331ef55dba7eb44773c": {
            "datetime": "2013-05-08T21:25:56-07:00",
            "summary": "Merge pull request #46 from laserson/public_utils",
            "message": "Merge pull request #46 from laserson/public_utils\n\nChanged `AvroSchemaConverter` to `public`",
            "diff": {
                "parquet-avro/src/main/java/parquet/avro/AvroSchemaConverter.java": 2
            },
            "is_test": false,
            "is_fix": false
        },
        "306868de79ff9d092aeedcbcf0a358f95826675f": {
            "datetime": "2013-05-08T21:36:24-07:00",
            "summary": "Merge branch 'master' into version",
            "message": "Merge branch 'master' into version\n",
            "diff": {
                "parquet-avro/src/main/java/parquet/avro/AvroParquetOutputFormat.java": 3,
                "parquet-avro/src/main/java/parquet/avro/AvroSchemaConverter.java": 2,
                "parquet-hadoop/src/main/java/parquet/hadoop/ParquetFileWriter.java": 21,
                "parquet-hadoop/src/main/java/parquet/hadoop/ParquetInputFormat.java": 9,
                "parquet-hadoop/src/main/java/parquet/hadoop/ParquetOutputCommitter.java": 3,
                "parquet-hadoop/src/main/java/parquet/hadoop/ParquetOutputFormat.java": 21,
                "parquet-hadoop/src/main/java/parquet/hadoop/ParquetRecordReader.java": 3,
                "parquet-hadoop/src/main/java/parquet/hadoop/example/ExampleOutputFormat.java": 5,
                "parquet-hadoop/src/main/java/parquet/hadoop/util/ContextUtil.java": 245,
                "parquet-hadoop/src/test/java/parquet/hadoop/TestParquetFileWriter.java": 7,
                "parquet-hadoop/src/test/java/parquet/hadoop/example/TestInputOutputFormat.java": 3,
                "parquet-pig/src/main/java/parquet/pig/ParquetLoader.java": 3,
                "parquet-pig/src/main/java/parquet/pig/ParquetStorer.java": 6,
                "parquet-pig/src/test/java/parquet/pig/PerfTest2.java": 11,
                "parquet-test-hadoop2/src/test/java/parquet/hadoop2/TestInputOutputFormat.java": 139,
                "parquet-thrift/src/main/java/parquet/hadoop/thrift/ParquetThriftBytesOutputFormat.java": 7,
                "parquet-thrift/src/main/java/parquet/hadoop/thrift/ParquetThriftOutputFormat.java": 5,
                "parquet-thrift/src/test/java/parquet/hadoop/thrift/TestThriftToParquetFileWriter.java": 5
            },
            "is_test": true,
            "is_fix": false
        },
        "cd2535980e715b00d43ee47b2aa138167016aed3": {
            "datetime": "2013-05-08T21:48:35-07:00",
            "summary": "add library version to metadata",
            "message": "add library version to metadata\n",
            "diff": {
                "parquet-column/src/main/java/parquet/Version.java": 11,
                "parquet-hadoop/src/main/java/parquet/format/converter/ParquetMetadataConverter.java": 4,
                "parquet-hadoop/src/main/java/parquet/hadoop/ParquetFileWriter.java": 6,
                "parquet-hadoop/src/main/java/parquet/hadoop/metadata/FileMetaData.java": 13,
                "parquet-hadoop/src/test/java/parquet/hadoop/TestInputFormat.java": 3
            },
            "is_test": true,
            "is_fix": false
        },
        "f0c42cac547243950fb1a47f8bdf9c5aefd69fbb": {
            "datetime": "2013-05-09T14:15:51-07:00",
            "summary": "Merge pull request #49 from Parquet/version",
            "message": "Merge pull request #49 from Parquet/version\n\nadd Version in footer",
            "diff": {
                "parquet-column/src/main/java/parquet/Version.java": 73,
                "parquet-hadoop/src/main/java/parquet/format/converter/ParquetMetadataConverter.java": 4,
                "parquet-hadoop/src/main/java/parquet/hadoop/ParquetFileWriter.java": 6,
                "parquet-hadoop/src/main/java/parquet/hadoop/metadata/FileMetaData.java": 13,
                "parquet-hadoop/src/test/java/parquet/hadoop/TestInputFormat.java": 3
            },
            "is_test": true,
            "is_fix": false
        },
        "e1aa79849714d189727155ad9937436b66595256": {
            "datetime": "2013-05-10T15:07:35-07:00",
            "summary": "improve memory consumption in write",
            "message": "improve memory consumption in write\n",
            "diff": {
                "parquet-column/src/main/java/parquet/bytes/BytesInput.java": 32,
                "parquet-column/src/main/java/parquet/bytes/CapacityByteArrayOutputStream.java": 147,
                "parquet-column/src/main/java/parquet/column/impl/ColumnWriteStoreImpl.java": 16,
                "parquet-column/src/main/java/parquet/column/impl/ColumnWriterImpl.java": 36,
                "parquet-column/src/main/java/parquet/column/page/PageWriter.java": 2,
                "parquet-column/src/main/java/parquet/column/values/ValuesWriter.java": 2,
                "parquet-column/src/main/java/parquet/column/values/bitpacking/BitPackingValuesWriter.java": 12,
                "parquet-column/src/main/java/parquet/column/values/bitpacking/ByteBasedBitPackingEncoder.java": 6,
                "parquet-column/src/main/java/parquet/column/values/bitpacking/ByteBitPackingValuesWriter.java": 5,
                "parquet-column/src/main/java/parquet/column/values/boundedint/BitWriter.java": 18,
                "parquet-column/src/main/java/parquet/column/values/boundedint/BoundedIntValuesFactory.java": 4,
                "parquet-column/src/main/java/parquet/column/values/boundedint/BoundedIntValuesWriter.java": 16,
                "parquet-column/src/main/java/parquet/column/values/boundedint/DevNullValuesWriter.java": 5,
                "parquet-column/src/main/java/parquet/column/values/plain/BooleanPlainValuesWriter.java": 5,
                "parquet-column/src/main/java/parquet/column/values/plain/PlainValuesWriter.java": 5,
                "parquet-column/src/test/java/parquet/bytes/TestCapacityByteArrayOutputStream.java": 78,
                "parquet-column/src/test/java/parquet/column/mem/TestMemColumn.java": 8,
                "parquet-column/src/test/java/parquet/column/page/mem/MemPageWriter.java": 5,
                "parquet-column/src/test/java/parquet/column/values/bitpacking/TestBitPackingColumn.java": 2,
                "parquet-column/src/test/java/parquet/column/values/boundedint/TestBoundedColumns.java": 4,
                "parquet-column/src/test/java/parquet/io/PerfTest.java": 2,
                "parquet-column/src/test/java/parquet/io/TestColumnIO.java": 8,
                "parquet-hadoop/src/main/java/parquet/hadoop/ParquetRecordWriter.java": 11,
                "parquet-pig/src/test/java/parquet/pig/GenerateIntTestFile.java": 2,
                "parquet-pig/src/test/java/parquet/pig/GenerateTPCH.java": 5,
                "parquet-pig/src/test/java/parquet/pig/TupleConsumerPerfTest.java": 2,
                "parquet-thrift/src/test/java/parquet/thrift/TestParquetReadProtocol.java": 2
            },
            "is_test": true,
            "is_fix": false
        },
        "b30d7fe08d26346da07c3ac873fea3f174785362": {
            "datetime": "2013-05-10T15:09:31-07:00",
            "summary": "reduce rep and def level buffer size. 8MB * 2 * #cols is way too much",
            "message": "reduce rep and def level buffer size. 8MB * 2 * #cols is way too much\n",
            "diff": {
                "parquet-column/src/main/java/parquet/column/values/bitpacking/ByteBasedBitPackingEncoder.java": 2
            },
            "is_test": false,
            "is_fix": false
        },
        "f334966c806491771eba06af44eb0abbc07ace64": {
            "datetime": "2013-05-10T15:28:18-07:00",
            "summary": "Merge pull request #50 from Parquet/scale_down_overly_enthusiastic_buffer_size",
            "message": "Merge pull request #50 from Parquet/scale_down_overly_enthusiastic_buffer_size\n\nreduce rep and def level buffer size. 8MB * 2 * #cols is way too much",
            "diff": {
                "parquet-column/src/main/java/parquet/column/values/bitpacking/ByteBasedBitPackingEncoder.java": 2
            },
            "is_test": false,
            "is_fix": false
        },
        "a0e82a878547701b0259cf9c2211f721c1fca172": {
            "datetime": "2013-05-10T16:09:36-07:00",
            "summary": "add improved memory management in hadoop layer",
            "message": "add improved memory management in hadoop layer\n",
            "diff": {
                "parquet-hadoop/src/main/java/parquet/hadoop/ColumnChunkPageWriteStore.java": 11,
                "parquet-hadoop/src/main/java/parquet/hadoop/ParquetRecordWriter.java": 14
            },
            "is_test": false,
            "is_fix": false
        },
        "922f6c5098f8d58708e79f9640ea06c73d255519": {
            "datetime": "2013-05-10T18:20:59-07:00",
            "summary": "add setting to turn dictionary on",
            "message": "add setting to turn dictionary on\n",
            "diff": {
                "parquet-column/src/main/java/parquet/column/impl/ColumnWriteStoreImpl.java": 6,
                "parquet-column/src/main/java/parquet/column/impl/ColumnWriterImpl.java": 8,
                "parquet-column/src/test/java/parquet/column/mem/TestMemColumn.java": 8,
                "parquet-column/src/test/java/parquet/io/PerfTest.java": 2,
                "parquet-column/src/test/java/parquet/io/TestColumnIO.java": 6,
                "parquet-hadoop/src/main/java/parquet/hadoop/ParquetOutputFormat.java": 22,
                "parquet-hadoop/src/main/java/parquet/hadoop/ParquetRecordWriter.java": 7,
                "parquet-hadoop/src/main/java/parquet/hadoop/ParquetWriter.java": 2
            },
            "is_test": true,
            "is_fix": false
        },
        "6a4f8d03f38cddc1d62a6fa240b601816738af33": {
            "datetime": "2013-05-10T18:36:08-07:00",
            "summary": "handle case when value is bigger than slab size",
            "message": "handle case when value is bigger than slab size\n",
            "diff": {
                "parquet-column/src/main/java/parquet/bytes/CapacityByteArrayOutputStream.java": 17
            },
            "is_test": false,
            "is_fix": false
        },
        "0347e7b2b3d722a63ade36077ef02b5e22d66f5b": {
            "datetime": "2013-05-10T21:29:34-07:00",
            "summary": "adjust initial column size",
            "message": "adjust initial column size\n",
            "diff": {
                "parquet-hadoop/src/main/java/parquet/hadoop/ParquetRecordWriter.java": 5
            },
            "is_test": false,
            "is_fix": false
        },
        "f7e7dd7685fb0e10ab3ad30201b80a995cd7b3ed": {
            "datetime": "2013-05-11T15:37:36-07:00",
            "summary": "more unit tests for CapacityByteArrayOutputStream",
            "message": "more unit tests for CapacityByteArrayOutputStream\n",
            "diff": {
                "parquet-column/src/main/java/parquet/bytes/CapacityByteArrayOutputStream.java": 6,
                "parquet-column/src/test/java/parquet/bytes/TestCapacityByteArrayOutputStream.java": 102
            },
            "is_test": true,
            "is_fix": false
        },
        "21bb59da12bf497113f3fc2ec1b60aa0c7f2d2cc": {
            "datetime": "2013-05-13T13:22:00-07:00",
            "summary": "Oops, forgot about default compression",
            "message": "Oops, forgot about default compression\n",
            "diff": {
                "parquet-avro/src/main/java/parquet/avro/AvroParquetWriter.java": 2,
                "parquet-hadoop/src/main/java/parquet/hadoop/ParquetWriter.java": 2
            },
            "is_test": false,
            "is_fix": false
        },
        "11d8e0ebf0c8c3f0f9c17217269e36152003c476": {
            "datetime": "2013-05-13T13:22:00-07:00",
            "summary": "Added javadocs",
            "message": "Added javadocs\n",
            "diff": {
                "parquet-avro/src/main/java/parquet/avro/AvroParquetWriter.java": 22,
                "parquet-hadoop/src/main/java/parquet/hadoop/ParquetWriter.java": 20
            },
            "is_test": false,
            "is_fix": false
        },
        "d636d60611371643b3ffe5c7494e9d1b315d2ac0": {
            "datetime": "2013-05-13T13:22:00-07:00",
            "summary": "Allow setting compressor, block/page size for ParquetWriter",
            "message": "Allow setting compressor, block/page size for ParquetWriter\n",
            "diff": {
                "parquet-avro/src/main/java/parquet/avro/AvroParquetWriter.java": 12,
                "parquet-hadoop/src/main/java/parquet/hadoop/ParquetWriter.java": 14
            },
            "is_test": false,
            "is_fix": false
        },
        "34a8fb00cf205de05f350496b20e721104119fdf": {
            "datetime": "2013-05-13T16:13:30-07:00",
            "summary": "Propagated default sizes to the OutputFormat",
            "message": "Propagated default sizes to the OutputFormat\n",
            "diff": {
                "parquet-avro/src/main/java/parquet/avro/AvroParquetWriter.java": 5,
                "parquet-hadoop/src/main/java/parquet/hadoop/ParquetOutputFormat.java": 4,
                "parquet-hadoop/src/main/java/parquet/hadoop/ParquetWriter.java": 5
            },
            "is_test": false,
            "is_fix": false
        },
        "0add8d86e367ec01a3e8fe5813e53151dd6aa28a": {
            "datetime": "2013-05-13T16:27:18-07:00",
            "summary": "add constant and override annotations",
            "message": "add constant and override annotations\n",
            "diff": {
                "parquet-column/src/main/java/parquet/bytes/CapacityByteArrayOutputStream.java": 21
            },
            "is_test": false,
            "is_fix": false
        },
        "7f7fa72169cfbfc15b2cee3040222a3cb6158926": {
            "datetime": "2013-05-13T16:44:39-07:00",
            "summary": "Merge pull request #48 from laserson/choose_compression",
            "message": "Merge pull request #48 from laserson/choose_compression\n\nAllow setting compressor, block/page size for ParquetWriter",
            "diff": {
                "parquet-avro/src/main/java/parquet/avro/AvroParquetWriter.java": 29,
                "parquet-hadoop/src/main/java/parquet/hadoop/ParquetOutputFormat.java": 4,
                "parquet-hadoop/src/main/java/parquet/hadoop/ParquetWriter.java": 33
            },
            "is_test": false,
            "is_fix": false
        },
        "d0cc3a96ee61e132ab109c2cacd1289d372f10ca": {
            "datetime": "2013-05-13T16:52:10-07:00",
            "summary": "check initial size",
            "message": "check initial size\n",
            "diff": {
                "parquet-column/src/main/java/parquet/bytes/CapacityByteArrayOutputStream.java": 3
            },
            "is_test": false,
            "is_fix": false
        },
        "ea3eb7b23cc36d69709824b41c8222a1c8652c68": {
            "datetime": "2013-05-14T02:07:16-07:00",
            "summary": "Removed getCounter for compatibility",
            "message": "Removed getCounter for compatibility\n",
            "diff": {
                "parquet-hadoop/src/main/java/parquet/hadoop/util/ContextUtil.java": 20
            },
            "is_test": false,
            "is_fix": false
        },
        "a53dde1c7bebc1f7242f574973afa71699076cd8": {
            "datetime": "2013-05-14T08:45:08-07:00",
            "summary": "javadoc and constants",
            "message": "javadoc and constants\n",
            "diff": {
                "parquet-column/src/main/java/parquet/bytes/CapacityByteArrayOutputStream.java": 43
            },
            "is_test": false,
            "is_fix": false
        },
        "34d0b5d32689b8ebc1ba4a6f4988bc3637f55e6c": {
            "datetime": "2013-05-14T10:12:53-07:00",
            "summary": "Merge pull request #52 from laserson/getCounter_compat",
            "message": "Merge pull request #52 from laserson/getCounter_compat\n\nRemoved getCounter for compatibility",
            "diff": {
                "parquet-hadoop/src/main/java/parquet/hadoop/util/ContextUtil.java": 20
            },
            "is_test": false,
            "is_fix": false
        },
        "5b25bb57fc1f68dbf46e6cedab67f25120aec070": {
            "datetime": "2013-05-14T11:09:23-07:00",
            "summary": "add constants and doc",
            "message": "add constants and doc\n",
            "diff": {
                "parquet-column/src/main/java/parquet/column/impl/ColumnWriterImpl.java": 23,
                "parquet-hadoop/src/main/java/parquet/hadoop/ParquetRecordWriter.java": 6
            },
            "is_test": false,
            "is_fix": false
        },
        "4f4c5c47f82ea063825bf654cc2053e5c9625810": {
            "datetime": "2013-05-14T14:33:21-07:00",
            "summary": "Merge pull request #51 from Parquet/improve_mem_usage_in_write",
            "message": "Merge pull request #51 from Parquet/improve_mem_usage_in_write\n\nimprove memory consumption in write path",
            "diff": {
                "parquet-column/src/main/java/parquet/bytes/BytesInput.java": 32,
                "parquet-column/src/main/java/parquet/bytes/CapacityByteArrayOutputStream.java": 183,
                "parquet-column/src/main/java/parquet/column/impl/ColumnWriteStoreImpl.java": 16,
                "parquet-column/src/main/java/parquet/column/impl/ColumnWriterImpl.java": 55,
                "parquet-column/src/main/java/parquet/column/page/PageWriter.java": 2,
                "parquet-column/src/main/java/parquet/column/values/ValuesWriter.java": 2,
                "parquet-column/src/main/java/parquet/column/values/bitpacking/BitPackingValuesWriter.java": 12,
                "parquet-column/src/main/java/parquet/column/values/bitpacking/ByteBasedBitPackingEncoder.java": 4,
                "parquet-column/src/main/java/parquet/column/values/bitpacking/ByteBitPackingValuesWriter.java": 5,
                "parquet-column/src/main/java/parquet/column/values/boundedint/BitWriter.java": 18,
                "parquet-column/src/main/java/parquet/column/values/boundedint/BoundedIntValuesFactory.java": 4,
                "parquet-column/src/main/java/parquet/column/values/boundedint/BoundedIntValuesWriter.java": 16,
                "parquet-column/src/main/java/parquet/column/values/boundedint/DevNullValuesWriter.java": 5,
                "parquet-column/src/main/java/parquet/column/values/plain/BooleanPlainValuesWriter.java": 5,
                "parquet-column/src/main/java/parquet/column/values/plain/PlainValuesWriter.java": 5,
                "parquet-column/src/test/java/parquet/bytes/TestCapacityByteArrayOutputStream.java": 134,
                "parquet-column/src/test/java/parquet/column/mem/TestMemColumn.java": 8,
                "parquet-column/src/test/java/parquet/column/page/mem/MemPageWriter.java": 5,
                "parquet-column/src/test/java/parquet/column/values/bitpacking/TestBitPackingColumn.java": 2,
                "parquet-column/src/test/java/parquet/column/values/boundedint/TestBoundedColumns.java": 4,
                "parquet-column/src/test/java/parquet/io/PerfTest.java": 2,
                "parquet-column/src/test/java/parquet/io/TestColumnIO.java": 8,
                "parquet-hadoop/src/main/java/parquet/hadoop/ColumnChunkPageWriteStore.java": 11,
                "parquet-hadoop/src/main/java/parquet/hadoop/ParquetRecordWriter.java": 16,
                "parquet-pig/src/test/java/parquet/pig/GenerateIntTestFile.java": 2,
                "parquet-pig/src/test/java/parquet/pig/GenerateTPCH.java": 5,
                "parquet-pig/src/test/java/parquet/pig/TupleConsumerPerfTest.java": 2,
                "parquet-thrift/src/test/java/parquet/thrift/TestParquetReadProtocol.java": 2
            },
            "is_test": true,
            "is_fix": false
        },
        "b6d1cb046418da4de3f35e5109a87df29e2cc42c": {
            "datetime": "2013-05-17T16:28:29-07:00",
            "summary": "add a validation setting to OutputFormat",
            "message": "add a validation setting to OutputFormat\n",
            "diff": {
                "parquet-column/src/main/java/parquet/column/impl/ColumnReaderImpl.java": 17,
                "parquet-column/src/main/java/parquet/column/values/plain/BinaryPlainValuesReader.java": 2,
                "parquet-hadoop/src/main/java/parquet/hadoop/ParquetOutputFormat.java": 39,
                "parquet-hadoop/src/main/java/parquet/hadoop/ParquetReader.java": 4,
                "parquet-hadoop/src/main/java/parquet/hadoop/ParquetRecordReader.java": 19,
                "parquet-hadoop/src/main/java/parquet/hadoop/ParquetRecordWriter.java": 7,
                "parquet-hadoop/src/main/java/parquet/hadoop/ParquetWriter.java": 50
            },
            "is_test": false,
            "is_fix": false
        },
        "05f103b33abc8c8191a2aeb59f688ddd5c41d319": {
            "datetime": "2013-05-18T22:42:14-07:00",
            "summary": "Fix bug that prevented writing optional Avro records, arrays or maps",
            "message": "Fix bug that prevented writing optional Avro records, arrays or maps\n\nThe writeValue method in AvroWriteSupport would correct resolve\nthe non-null type but would incorrectly try to write records,\narrays and maps with the original union schema triggering e.g.\nAvroRuntimeException: Not an array: [\"null\",{\"type\":\"array\",\"items\":\"int\"}]\n",
            "diff": {
                "parquet-avro/src/main/java/parquet/avro/AvroWriteSupport.java": 9,
                "parquet-avro/src/test/java/parquet/avro/TestReadWrite.java": 13
            },
            "is_test": true,
            "is_fix": false
        },
        "427137de9ccc343d3559a1e02a47488b7204f62b": {
            "datetime": "2013-05-20T12:09:29-07:00",
            "summary": "Merge pull request #54 from massie/master",
            "message": "Merge pull request #54 from massie/master\n\nFix bug that prevented writing optional Avro records, arrays or maps",
            "diff": {
                "parquet-avro/src/main/java/parquet/avro/AvroWriteSupport.java": 9,
                "parquet-avro/src/test/java/parquet/avro/TestReadWrite.java": 13
            },
            "is_test": true,
            "is_fix": false
        },
        "a5b478edbb89e7f168d12b7ee2b38c93cdca4a0c": {
            "datetime": "2013-05-21T10:15:28-07:00",
            "summary": "standard ordering of keywords",
            "message": "standard ordering of keywords\n",
            "diff": {
                "parquet-column/src/main/java/parquet/column/Dictionary.java": 4
            },
            "is_test": false,
            "is_fix": false
        },
        "19b369b8a7f5514c346206801773425cc333a796": {
            "datetime": "2013-05-21T11:04:30-07:00",
            "summary": "use checkNotNull",
            "message": "use checkNotNull\n",
            "diff": {
                "parquet-column/src/main/java/parquet/Preconditions.java": 23,
                "parquet-column/src/main/java/parquet/bytes/BytesInput.java": 2,
                "parquet-column/src/main/java/parquet/column/impl/ColumnReadStoreImpl.java": 4,
                "parquet-column/src/main/java/parquet/column/impl/ColumnReaderImpl.java": 19,
                "parquet-column/src/main/java/parquet/column/page/DictionaryPage.java": 12,
                "parquet-column/src/test/java/parquet/column/page/mem/MemPageReader.java": 5
            },
            "is_test": false,
            "is_fix": false
        },
        "e85b3c20ad3fd4da72cd368359f62b19dfcb078a": {
            "datetime": "2013-05-21T11:06:44-07:00",
            "summary": "interfaces have public members",
            "message": "interfaces have public members\n",
            "diff": {
                "parquet-column/src/main/java/parquet/column/page/PageReader.java": 6
            },
            "is_test": false,
            "is_fix": false
        },
        "df1ab6f8413cf9b9b1fa33e024483cde229dc4cf": {
            "datetime": "2013-05-21T11:30:19-07:00",
            "summary": "introduce contants",
            "message": "introduce contants\n",
            "diff": {
                "parquet-column/src/main/java/parquet/Preconditions.java": 1,
                "parquet-column/src/main/java/parquet/column/impl/ColumnWriterImpl.java": 19,
                "parquet-column/src/main/java/parquet/column/values/dictionary/DictionaryValuesWriter.java": 16,
                "parquet-pig/src/test/java/parquet/pig/GenerateIntTestFile.java": 2,
                "parquet-pig/src/test/java/parquet/pig/GenerateTPCH.java": 2,
                "parquet-pig/src/test/java/parquet/pig/TupleConsumerPerfTest.java": 2,
                "parquet-thrift/src/test/java/parquet/thrift/TestParquetReadProtocol.java": 2
            },
            "is_test": true,
            "is_fix": false
        },
        "70d3eeba642a103c0a1d50d70086402ecec3350f": {
            "datetime": "2013-05-21T14:43:56-07:00",
            "summary": "better javadoc",
            "message": "better javadoc\n",
            "diff": {
                "parquet-column/src/main/java/parquet/column/ColumnReader.java": 12
            },
            "is_test": false,
            "is_fix": false
        },
        "f9784bf70bae3540dca2606b83fab08b1966cc04": {
            "datetime": "2013-05-21T14:48:31-07:00",
            "summary": "remove unnecessary keywords",
            "message": "remove unnecessary keywords\n",
            "diff": {
                "parquet-column/src/main/java/parquet/column/page/PageReader.java": 6,
                "parquet-column/src/main/java/parquet/column/page/PageWriter.java": 8
            },
            "is_test": false,
            "is_fix": false
        },
        "25d8ff20756281d170ea9d26334cef0862bbac2e": {
            "datetime": "2013-05-22T18:37:51-07:00",
            "summary": "javadoc and cleanup",
            "message": "javadoc and cleanup\n",
            "diff": {
                "parquet-column/src/main/java/parquet/column/impl/ColumnReadStoreImpl.java": 15,
                "parquet-column/src/main/java/parquet/column/page/PageReader.java": 4,
                "parquet-column/src/main/java/parquet/column/values/dictionary/DictionaryValuesWriter.java": 7,
                "parquet-column/src/main/java/parquet/column/values/dictionary/IntList.java": 45,
                "parquet-column/src/main/java/parquet/column/values/dictionary/PlainBinaryDictionary.java": 23,
                "parquet-column/src/main/java/parquet/column/values/rle/RLESimpleEncoder.java": 21,
                "parquet-column/src/main/java/parquet/io/api/PrimitiveConverter.java": 6,
                "parquet-hadoop/src/main/java/parquet/hadoop/ParquetFileWriter.java": 4
            },
            "is_test": false,
            "is_fix": false
        },
        "5c2034a0601384cc93258c27f8a68d60a71babb9": {
            "datetime": "2013-05-22T18:40:36-07:00",
            "summary": "license headers",
            "message": "license headers\n",
            "diff": {
                "parquet-column/src/main/java/parquet/Preconditions.java": 15,
                "parquet-column/src/main/java/parquet/column/Dictionary.java": 15,
                "parquet-column/src/main/java/parquet/column/page/DictionaryPage.java": 15,
                "parquet-column/src/main/java/parquet/column/values/dictionary/DictionaryValuesReader.java": 15,
                "parquet-column/src/main/java/parquet/column/values/dictionary/DictionaryValuesWriter.java": 15,
                "parquet-column/src/main/java/parquet/column/values/dictionary/IntList.java": 15,
                "parquet-column/src/main/java/parquet/column/values/dictionary/PlainBinaryDictionary.java": 15,
                "parquet-column/src/test/java/parquet/column/values/dictionary/TestDictionary.java": 15
            },
            "is_test": true,
            "is_fix": false
        },
        "38d8a68beadb7335dd52dc10f872d96b635dfc2d": {
            "datetime": "2013-05-23T09:51:39-07:00",
            "summary": "Merge branch 'master' of github.com:Parquet/parquet-mr into dictionary_encoding",
            "message": "Merge branch 'master' of github.com:Parquet/parquet-mr into dictionary_encoding\n\nConflicts:\n\tparquet-column/src/main/java/parquet/column/impl/ColumnWriteStoreImpl.java\n\tparquet-column/src/main/java/parquet/column/impl/ColumnWriterImpl.java\n\tparquet-column/src/test/java/parquet/column/mem/TestMemColumn.java\n\tparquet-column/src/test/java/parquet/column/page/mem/MemPageWriter.java\n\tparquet-column/src/test/java/parquet/io/PerfTest.java\n\tparquet-column/src/test/java/parquet/io/TestColumnIO.java\n\tparquet-hadoop/src/main/java/parquet/hadoop/ColumnChunkPageWriteStore.java\n\tparquet-hadoop/src/main/java/parquet/hadoop/ParquetRecordWriter.java\n\tparquet-hadoop/src/main/java/parquet/hadoop/ParquetWriter.java\n\tparquet-pig/src/test/java/parquet/pig/GenerateIntTestFile.java\n\tparquet-pig/src/test/java/parquet/pig/GenerateTPCH.java\n\tparquet-pig/src/test/java/parquet/pig/TupleConsumerPerfTest.java\n\tparquet-thrift/src/test/java/parquet/thrift/TestParquetReadProtocol.java\n",
            "diff": {
                "parquet-avro/src/main/java/parquet/avro/AvroGenericRecordConverter.java": 18,
                "parquet-avro/src/main/java/parquet/avro/AvroParquetInputFormat.java": 15,
                "parquet-avro/src/main/java/parquet/avro/AvroParquetOutputFormat.java": 18,
                "parquet-avro/src/main/java/parquet/avro/AvroParquetWriter.java": 29,
                "parquet-avro/src/main/java/parquet/avro/AvroReadSupport.java": 15,
                "parquet-avro/src/main/java/parquet/avro/AvroRecordMaterializer.java": 15,
                "parquet-avro/src/main/java/parquet/avro/AvroSchemaConverter.java": 28,
                "parquet-avro/src/main/java/parquet/avro/AvroWriteSupport.java": 37,
                "parquet-avro/src/main/java/parquet/avro/package-info.java": 15,
                "parquet-avro/src/test/java/parquet/avro/TestAvroSchemaConverter.java": 15,
                "parquet-avro/src/test/java/parquet/avro/TestInputOutputFormat.java": 12,
                "parquet-avro/src/test/java/parquet/avro/TestReadWrite.java": 28,
                "parquet-cascading/src/main/java/parquet/cascading/ParquetTBaseScheme.java": 9,
                "parquet-cascading/src/main/java/parquet/cascading/ParquetTupleScheme.java": 140,
                "parquet-cascading/src/main/java/parquet/cascading/ParquetValueScheme.java": 2,
                "parquet-cascading/src/main/java/parquet/cascading/SchemaIntersection.java": 60,
                "parquet-cascading/src/main/java/parquet/cascading/TupleReadSupport.java": 77,
                "parquet-cascading/src/main/java/parquet/cascading/convert/TupleConverter.java": 112,
                "parquet-cascading/src/main/java/parquet/cascading/convert/TupleRecordMaterializer.java": 43,
                "parquet-column/src/main/java/parquet/Version.java": 73,
                "parquet-column/src/main/java/parquet/bytes/BytesInput.java": 32,
                "parquet-column/src/main/java/parquet/bytes/CapacityByteArrayOutputStream.java": 183,
                "parquet-column/src/main/java/parquet/column/impl/ColumnWriteStoreImpl.java": 16,
                "parquet-column/src/main/java/parquet/column/impl/ColumnWriterImpl.java": 62,
                "parquet-column/src/main/java/parquet/column/page/PageWriter.java": 2,
                "parquet-column/src/main/java/parquet/column/values/ValuesWriter.java": 2,
                "parquet-column/src/main/java/parquet/column/values/bitpacking/BitPackingValuesWriter.java": 12,
                "parquet-column/src/main/java/parquet/column/values/bitpacking/ByteBasedBitPackingEncoder.java": 6,
                "parquet-column/src/main/java/parquet/column/values/bitpacking/ByteBasedBitPackingGenerator.java": 4,
                "parquet-column/src/main/java/parquet/column/values/bitpacking/ByteBitPacking.java": 264,
                "parquet-column/src/main/java/parquet/column/values/bitpacking/ByteBitPackingValuesWriter.java": 5,
                "parquet-column/src/main/java/parquet/column/values/boundedint/BitWriter.java": 18,
                "parquet-column/src/main/java/parquet/column/values/boundedint/BoundedIntValuesFactory.java": 4,
                "parquet-column/src/main/java/parquet/column/values/boundedint/BoundedIntValuesWriter.java": 16,
                "parquet-column/src/main/java/parquet/column/values/boundedint/DevNullValuesWriter.java": 5,
                "parquet-column/src/main/java/parquet/column/values/dictionary/DictionaryValuesWriter.java": 11,
                "parquet-column/src/main/java/parquet/column/values/plain/BooleanPlainValuesWriter.java": 5,
                "parquet-column/src/main/java/parquet/column/values/plain/PlainValuesWriter.java": 5,
                "parquet-column/src/main/java/parquet/io/MessageColumnIO.java": 76,
                "parquet-column/src/test/java/parquet/bytes/TestCapacityByteArrayOutputStream.java": 134,
                "parquet-column/src/test/java/parquet/column/mem/TestMemColumn.java": 12,
                "parquet-column/src/test/java/parquet/column/page/mem/MemPageWriter.java": 6,
                "parquet-column/src/test/java/parquet/column/values/bitpacking/TestBitPackingColumn.java": 2,
                "parquet-column/src/test/java/parquet/column/values/boundedint/TestBoundedColumns.java": 4,
                "parquet-column/src/test/java/parquet/io/ExpectationValidatingConverter.java": 6,
                "parquet-column/src/test/java/parquet/io/PerfTest.java": 2,
                "parquet-column/src/test/java/parquet/io/TestColumnIO.java": 35,
                "parquet-hadoop/src/main/java/parquet/format/converter/ParquetMetadataConverter.java": 4,
                "parquet-hadoop/src/main/java/parquet/hadoop/ColumnChunkPageWriteStore.java": 12,
                "parquet-hadoop/src/main/java/parquet/hadoop/ParquetFileReader.java": 6,
                "parquet-hadoop/src/main/java/parquet/hadoop/ParquetFileWriter.java": 27,
                "parquet-hadoop/src/main/java/parquet/hadoop/ParquetInputFormat.java": 39,
                "parquet-hadoop/src/main/java/parquet/hadoop/ParquetOutputCommitter.java": 3,
                "parquet-hadoop/src/main/java/parquet/hadoop/ParquetOutputFormat.java": 25,
                "parquet-hadoop/src/main/java/parquet/hadoop/ParquetReader.java": 7,
                "parquet-hadoop/src/main/java/parquet/hadoop/ParquetRecordReader.java": 9,
                "parquet-hadoop/src/main/java/parquet/hadoop/ParquetRecordWriter.java": 16,
                "parquet-hadoop/src/main/java/parquet/hadoop/ParquetWriter.java": 46,
                "parquet-hadoop/src/main/java/parquet/hadoop/example/ExampleOutputFormat.java": 5,
                "parquet-hadoop/src/main/java/parquet/hadoop/mapred/DeprecatedParquetInputFormat.java": 204,
                "parquet-hadoop/src/main/java/parquet/hadoop/metadata/FileMetaData.java": 13,
                "parquet-hadoop/src/main/java/parquet/hadoop/util/ContextUtil.java": 221,
                "parquet-hadoop/src/test/java/parquet/hadoop/TestInputFormat.java": 7,
                "parquet-hadoop/src/test/java/parquet/hadoop/TestParquetFileWriter.java": 7,
                "parquet-hadoop/src/test/java/parquet/hadoop/example/TestInputOutputFormat.java": 3,
                "parquet-pig/src/main/java/parquet/pig/ParquetLoader.java": 3,
                "parquet-pig/src/main/java/parquet/pig/ParquetStorer.java": 6,
                "parquet-pig/src/test/java/parquet/pig/GenerateIntTestFile.java": 3,
                "parquet-pig/src/test/java/parquet/pig/GenerateTPCH.java": 12,
                "parquet-pig/src/test/java/parquet/pig/PerfTest2.java": 11,
                "parquet-pig/src/test/java/parquet/pig/TupleConsumerPerfTest.java": 2,
                "parquet-scrooge/src/main/java/parquet/scrooge/ParquetScroogeScheme.java": 8,
                "parquet-test-hadoop2/src/test/java/parquet/hadoop2/TestInputOutputFormat.java": 139,
                "parquet-thrift/src/main/java/parquet/hadoop/thrift/Container.java": 2,
                "parquet-thrift/src/main/java/parquet/hadoop/thrift/DeprecatedContainerInputFormat.java": 372,
                "parquet-thrift/src/main/java/parquet/hadoop/thrift/ParquetThriftBytesOutputFormat.java": 7,
                "parquet-thrift/src/main/java/parquet/hadoop/thrift/ParquetThriftOutputFormat.java": 5,
                "parquet-thrift/src/main/java/parquet/thrift/ParquetProtocol.java": 98,
                "parquet-thrift/src/main/java/parquet/thrift/TBaseRecordConverter.java": 17,
                "parquet-thrift/src/test/java/parquet/hadoop/thrift/TestInputOutputFormat.java": 2,
                "parquet-thrift/src/test/java/parquet/hadoop/thrift/TestThriftToParquetFileWriter.java": 5,
                "parquet-thrift/src/test/java/parquet/thrift/TestParquetReadProtocol.java": 4
            },
            "is_test": true,
            "is_fix": false
        },
        "5cedb4afb0065fe9dbf3f4bd7cf8e4c953689780": {
            "datetime": "2013-05-23T10:00:26-07:00",
            "summary": "license headers",
            "message": "license headers\n",
            "diff": {
                "parquet-column/src/main/java/parquet/Version.java": 15,
                "parquet-column/src/test/java/parquet/bytes/TestCapacityByteArrayOutputStream.java": 15,
                "parquet-hadoop/src/main/java/parquet/hadoop/util/ContextUtil.java": 15
            },
            "is_test": true,
            "is_fix": false
        },
        "9a30c8fdbe0c7850cb5cac9d5778217e7a026e36": {
            "datetime": "2013-05-23T16:12:16-07:00",
            "summary": "Merge pull request #40 from Parquet/dictionary_encoding",
            "message": "Merge pull request #40 from Parquet/dictionary_encoding\n\nDictionary encoding",
            "diff": {
                "parquet-column/src/main/java/parquet/Log.java": 2,
                "parquet-column/src/main/java/parquet/Preconditions.java": 39,
                "parquet-column/src/main/java/parquet/Version.java": 15,
                "parquet-column/src/main/java/parquet/bytes/BytesInput.java": 8,
                "parquet-column/src/main/java/parquet/column/ColumnReader.java": 24,
                "parquet-column/src/main/java/parquet/column/Dictionary.java": 63,
                "parquet-column/src/main/java/parquet/column/Encoding.java": 66,
                "parquet-column/src/main/java/parquet/column/impl/ColumnReadStoreImpl.java": 212,
                "parquet-column/src/main/java/parquet/column/impl/ColumnReaderImpl.java": 275,
                "parquet-column/src/main/java/parquet/column/impl/ColumnWriteStoreImpl.java": 6,
                "parquet-column/src/main/java/parquet/column/impl/ColumnWriterImpl.java": 29,
                "parquet-column/src/main/java/parquet/column/page/DictionaryPage.java": 89,
                "parquet-column/src/main/java/parquet/column/page/PageReader.java": 19,
                "parquet-column/src/main/java/parquet/column/page/PageWriter.java": 14,
                "parquet-column/src/main/java/parquet/column/values/ValuesReader.java": 48,
                "parquet-column/src/main/java/parquet/column/values/ValuesWriter.java": 17,
                "parquet-column/src/main/java/parquet/column/values/bitpacking/ByteBasedBitPackingEncoder.java": 5,
                "parquet-column/src/main/java/parquet/column/values/dictionary/DictionaryValuesReader.java": 81,
                "parquet-column/src/main/java/parquet/column/values/dictionary/DictionaryValuesWriter.java": 247,
                "parquet-column/src/main/java/parquet/column/values/dictionary/IntList.java": 120,
                "parquet-column/src/main/java/parquet/column/values/dictionary/PlainBinaryDictionary.java": 83,
                "parquet-column/src/main/java/parquet/column/values/plain/PlainValuesReader.java": 9,
                "parquet-column/src/main/java/parquet/column/values/rle/RLEDecoder.java": 7,
                "parquet-column/src/main/java/parquet/column/values/rle/RLESimpleEncoder.java": 32,
                "parquet-column/src/main/java/parquet/io/MessageColumnIO.java": 7,
                "parquet-column/src/main/java/parquet/io/RecordReaderImplementation.java": 2,
                "parquet-column/src/main/java/parquet/io/api/Binary.java": 7,
                "parquet-column/src/main/java/parquet/io/api/GroupConverter.java": 3,
                "parquet-column/src/main/java/parquet/io/api/PrimitiveConverter.java": 33,
                "parquet-column/src/main/java/parquet/schema/PrimitiveType.java": 75,
                "parquet-column/src/test/java/parquet/bytes/TestCapacityByteArrayOutputStream.java": 15,
                "parquet-column/src/test/java/parquet/column/mem/TestMemColumn.java": 55,
                "parquet-column/src/test/java/parquet/column/page/mem/MemPageReader.java": 19,
                "parquet-column/src/test/java/parquet/column/page/mem/MemPageStore.java": 2,
                "parquet-column/src/test/java/parquet/column/page/mem/MemPageWriter.java": 17,
                "parquet-column/src/test/java/parquet/column/values/dictionary/TestDictionary.java": 131,
                "parquet-column/src/test/java/parquet/io/PerfTest.java": 2,
                "parquet-column/src/test/java/parquet/io/TestColumnIO.java": 15,
                "parquet-hadoop/src/main/java/parquet/format/converter/ParquetMetadataConverter.java": 13,
                "parquet-hadoop/src/main/java/parquet/hadoop/ColumnChunkPageReadStore.java": 20,
                "parquet-hadoop/src/main/java/parquet/hadoop/ColumnChunkPageWriteStore.java": 35,
                "parquet-hadoop/src/main/java/parquet/hadoop/ParquetFileReader.java": 81,
                "parquet-hadoop/src/main/java/parquet/hadoop/ParquetFileWriter.java": 29,
                "parquet-hadoop/src/main/java/parquet/hadoop/ParquetOutputFormat.java": 22,
                "parquet-hadoop/src/main/java/parquet/hadoop/ParquetRecordWriter.java": 9,
                "parquet-hadoop/src/main/java/parquet/hadoop/ParquetWriter.java": 47,
                "parquet-hadoop/src/main/java/parquet/hadoop/PrintFooter.java": 15,
                "parquet-hadoop/src/main/java/parquet/hadoop/metadata/ColumnChunkMetaData.java": 23,
                "parquet-hadoop/src/main/java/parquet/hadoop/util/ContextUtil.java": 19,
                "parquet-pig/src/main/java/parquet/pig/convert/TupleConverter.java": 26,
                "parquet-pig/src/test/java/parquet/pig/GenerateIntTestFile.java": 8,
                "parquet-pig/src/test/java/parquet/pig/GenerateTPCH.java": 3,
                "parquet-pig/src/test/java/parquet/pig/TupleConsumerPerfTest.java": 2,
                "parquet-thrift/src/test/java/parquet/thrift/TestParquetReadProtocol.java": 2,
                "parquet-thrift/src/test/java/parquet/thrift/TestThriftSchemaConverter.java": 1
            },
            "is_test": true,
            "is_fix": false
        },
        "0a7c59aac0bc55999d768ffbef4d503e1282e6ca": {
            "datetime": "2013-05-29T15:48:54-07:00",
            "summary": "Speed up Avro string parsing",
            "message": "Speed up Avro string parsing\n",
            "diff": {
                "parquet-column/src/main/java/parquet/io/api/Binary.java": 8
            },
            "is_test": false,
            "is_fix": false
        },
        "b3e94326c9488270af209f0cc978b956fb2a5380": {
            "datetime": "2013-05-29T15:53:55-07:00",
            "summary": "First pass at RLE hybrid",
            "message": "First pass at RLE hybrid\n",
            "diff": {
                "parquet-column/src/main/java/parquet/Preconditions.java": 15,
                "parquet-column/src/main/java/parquet/bytes/BytesUtils.java": 38,
                "parquet-column/src/main/java/parquet/bytes/CapacityByteArrayOutputStream.java": 29,
                "parquet-column/src/main/java/parquet/column/values/rle/RunLengthBitPackingHybridEncoder.java": 260
            },
            "is_test": false,
            "is_fix": false
        },
        "0f9eee5ff50ea7475e34bea444ea0de2d877862f": {
            "datetime": "2013-05-29T16:00:47-07:00",
            "summary": "Cleanup",
            "message": "Cleanup\n",
            "diff": {
                "parquet-column/src/main/java/parquet/bytes/CapacityByteArrayOutputStream.java": 17
            },
            "is_test": false,
            "is_fix": false
        },
        "2ffdab725e039a33d2c34196bbbcd52fb4fb005c": {
            "datetime": "2013-05-29T16:25:37-07:00",
            "summary": "Add test for setByte()",
            "message": "Add test for setByte()\n",
            "diff": {
                "parquet-column/src/main/java/parquet/bytes/CapacityByteArrayOutputStream.java": 2,
                "parquet-column/src/test/java/parquet/bytes/TestCapacityByteArrayOutputStream.java": 86
            },
            "is_test": true,
            "is_fix": false
        },
        "d29eeb570d0b5e3c07cbd85152349c72a0f976dd": {
            "datetime": "2013-05-29T16:28:38-07:00",
            "summary": "cleanup preconditions",
            "message": "cleanup preconditions\n",
            "diff": {
                "parquet-column/src/main/java/parquet/Preconditions.java": 15
            },
            "is_test": false,
            "is_fix": false
        },
        "27d1c2c4fb4b0af707cae81d003bbb83e47a9382": {
            "datetime": "2013-05-29T16:31:04-07:00",
            "summary": "Add javadoc to ByteUtils",
            "message": "Add javadoc to ByteUtils\n",
            "diff": {
                "parquet-column/src/main/java/parquet/bytes/BytesUtils.java": 4
            },
            "is_test": false,
            "is_fix": false
        },
        "c71cb25c988f31893a1258faf9d5c086c03216ed": {
            "datetime": "2013-05-29T16:36:20-07:00",
            "summary": "Merge pull request #55 from laserson/fastavro",
            "message": "Merge pull request #55 from laserson/fastavro\n\nWrite Avro objects to Parquet files 30x faster",
            "diff": {
                "parquet-column/src/main/java/parquet/io/api/Binary.java": 8
            },
            "is_test": false,
            "is_fix": false
        },
        "71bd4e2ee5e64d726e6978e4f595f9d281413301": {
            "datetime": "2013-05-29T17:31:45-07:00",
            "summary": "bit packing support for LE",
            "message": "bit packing support for LE\n",
            "diff": {
                "parquet-column/src/main/java/parquet/column/Encoding.java": 5,
                "parquet-column/src/main/java/parquet/column/impl/ColumnWriterImpl.java": 7,
                "parquet-column/src/main/java/parquet/column/values/bitpacking/ByteBasedBitPackingEncoder.java": 4,
                "parquet-column/src/main/java/parquet/column/values/bitpacking/ByteBasedBitPackingGenerator.java": 174,
                "parquet-column/src/main/java/parquet/column/values/bitpacking/ByteBitPacking.java": 2,
                "parquet-column/src/main/java/parquet/column/values/bitpacking/ByteBitPackingLE.java": 25636,
                "parquet-column/src/main/java/parquet/column/values/bitpacking/ByteBitPackingValuesReader.java": 4,
                "parquet-column/src/main/java/parquet/column/values/bitpacking/ByteBitPackingValuesWriter.java": 10,
                "parquet-column/src/main/java/parquet/column/values/bitpacking/Packer.java": 67,
                "parquet-column/src/main/java/parquet/column/values/plain/BooleanPlainValuesReader.java": 17,
                "parquet-column/src/main/java/parquet/column/values/plain/BooleanPlainValuesWriter.java": 42,
                "parquet-column/src/main/java/parquet/column/values/rle/RLEDecoder.java": 4,
                "parquet-column/src/main/java/parquet/column/values/rle/RLESimpleEncoder.java": 4,
                "parquet-column/src/test/java/parquet/column/values/bitpacking/BitPackingPerfTest.java": 2,
                "parquet-column/src/test/java/parquet/column/values/bitpacking/TestBitPackingColumn.java": 5,
                "parquet-column/src/test/java/parquet/column/values/bitpacking/TestByteBitPacking.java": 76,
                "parquet-column/src/test/java/parquet/column/values/bitpacking/TestLemireBitPacking.java": 38
            },
            "is_test": true,
            "is_fix": false
        },
        "cd3a1238950c7821e1505396270335fab989d9b3": {
            "datetime": "2013-05-29T17:45:33-07:00",
            "summary": "Start tests for rle hybrid",
            "message": "Start tests for rle hybrid\n",
            "diff": {
                "parquet-column/src/main/java/parquet/column/values/rle/RunLengthBitPackingHybridEncoder.java": 6,
                "parquet-column/src/test/java/parquet/column/values/rle/TestRunLengthBitPackingHybridEncoder.java": 85
            },
            "is_test": true,
            "is_fix": false
        },
        "c9c1080bebb2173585ac55e1d118a58be80d968f": {
            "datetime": "2013-05-30T17:32:08-07:00",
            "summary": "Add bit packing overflow test",
            "message": "Add bit packing overflow test\n",
            "diff": {
                "parquet-column/src/test/java/parquet/column/values/rle/TestRunLengthBitPackingHybridEncoder.java": 54
            },
            "is_test": true,
            "is_fix": false
        },
        "24f652409db7ee67faea791e896cca4c97e184b6": {
            "datetime": "2013-05-30T20:51:57-07:00",
            "summary": "End to end test",
            "message": "End to end test\n",
            "diff": {
                "parquet-column/src/main/java/parquet/column/values/rle/RunLengthBitPackingHybridEncoder.java": 13,
                "parquet-column/src/test/java/parquet/column/values/rle/TestRunLengthBitPackingHybridEncoder.java": 152
            },
            "is_test": true,
            "is_fix": false
        },
        "65fb8d3e069b321d6b6bd551e4d1c652546d37f8": {
            "datetime": "2013-05-31T01:23:36-07:00",
            "summary": "move unpack",
            "message": "move unpack\n",
            "diff": {
                "parquet-column/src/test/java/parquet/column/values/rle/TestRunLengthBitPackingHybridEncoder.java": 49
            },
            "is_test": true,
            "is_fix": false
        },
        "63ed7191384053817b91910a428a028fe1ad0336": {
            "datetime": "2013-05-31T13:50:03-07:00",
            "summary": "Fixup / rename RLEDecoder, fix tests",
            "message": "Fixup / rename RLEDecoder, fix tests\n",
            "diff": {
                "parquet-column/src/main/java/parquet/bytes/BytesUtils.java": 19,
                "parquet-column/src/main/java/parquet/column/values/dictionary/DictionaryValuesReader.java": 7,
                "parquet-column/src/main/java/parquet/column/values/dictionary/DictionaryValuesWriter.java": 17,
                "parquet-column/src/main/java/parquet/column/values/rle/RLEDecoder.java": 44,
                "parquet-column/src/main/java/parquet/column/values/rle/RLESimpleEncoder.java": 73,
                "parquet-column/src/main/java/parquet/column/values/rle/RunLengthBitPackingHybridEncoder.java": 10,
                "parquet-column/src/test/java/parquet/column/values/rle/RunLengthBitPackingHybridIntegrationTest.java": 75,
                "parquet-column/src/test/java/parquet/column/values/rle/TestRLE.java": 62
            },
            "is_test": true,
            "is_fix": false
        },
        "99853be93af6457b2989f57b063e7b6c053aeb0a": {
            "datetime": "2013-05-31T13:50:46-07:00",
            "summary": "Merge branch 'master' into alexlevenson/RLE-bit-packing-hybrid",
            "message": "Merge branch 'master' into alexlevenson/RLE-bit-packing-hybrid\n",
            "diff": {
                "parquet-column/src/main/java/parquet/io/api/Binary.java": 8
            },
            "is_test": false,
            "is_fix": false
        },
        "ded5bec1da026c6f994238d3ff72cdb5383cb9e7": {
            "datetime": "2013-05-31T14:01:03-07:00",
            "summary": "cleanup comments",
            "message": "cleanup comments\n",
            "diff": {
                "parquet-column/src/main/java/parquet/column/values/rle/RunLengthBitPackingHybridEncoder.java": 7
            },
            "is_test": false,
            "is_fix": false
        },
        "14e05746ee12bcc484feab28a65e128763980b69": {
            "datetime": "2013-06-03T01:15:30-07:00",
            "summary": "Merge pull request #57 from Parquet/bit_packing_lsb_first",
            "message": "Merge pull request #57 from Parquet/bit_packing_lsb_first\n\nbit packing support for LE",
            "diff": {
                "parquet-column/src/main/java/parquet/column/Encoding.java": 5,
                "parquet-column/src/main/java/parquet/column/impl/ColumnWriterImpl.java": 7,
                "parquet-column/src/main/java/parquet/column/values/bitpacking/ByteBasedBitPackingEncoder.java": 4,
                "parquet-column/src/main/java/parquet/column/values/bitpacking/ByteBasedBitPackingGenerator.java": 174,
                "parquet-column/src/main/java/parquet/column/values/bitpacking/ByteBitPacking.java": 2,
                "parquet-column/src/main/java/parquet/column/values/bitpacking/ByteBitPackingLE.java": 25636,
                "parquet-column/src/main/java/parquet/column/values/bitpacking/ByteBitPackingValuesReader.java": 4,
                "parquet-column/src/main/java/parquet/column/values/bitpacking/ByteBitPackingValuesWriter.java": 10,
                "parquet-column/src/main/java/parquet/column/values/bitpacking/Packer.java": 67,
                "parquet-column/src/main/java/parquet/column/values/plain/BooleanPlainValuesReader.java": 17,
                "parquet-column/src/main/java/parquet/column/values/plain/BooleanPlainValuesWriter.java": 42,
                "parquet-column/src/main/java/parquet/column/values/rle/RLEDecoder.java": 4,
                "parquet-column/src/main/java/parquet/column/values/rle/RLESimpleEncoder.java": 4,
                "parquet-column/src/test/java/parquet/column/values/bitpacking/BitPackingPerfTest.java": 2,
                "parquet-column/src/test/java/parquet/column/values/bitpacking/TestBitPackingColumn.java": 5,
                "parquet-column/src/test/java/parquet/column/values/bitpacking/TestByteBitPacking.java": 76,
                "parquet-column/src/test/java/parquet/column/values/bitpacking/TestLemireBitPacking.java": 38
            },
            "is_test": true,
            "is_fix": false
        },
        "abb6e3644ad6104980831ecd12815d8fcff4acfd": {
            "datetime": "2013-06-03T08:22:08-07:00",
            "summary": "Address first round of comments",
            "message": "Address first round of comments\n",
            "diff": {
                "parquet-column/src/main/java/parquet/Preconditions.java": 11,
                "parquet-column/src/main/java/parquet/bytes/BytesUtils.java": 6,
                "parquet-column/src/main/java/parquet/column/Encoding.java": 15,
                "parquet-column/src/main/java/parquet/column/values/dictionary/DictionaryValuesWriter.java": 3,
                "parquet-column/src/main/java/parquet/column/values/rle/RunLengthBitPackingHybridDecoder.java": 4,
                "parquet-column/src/main/java/parquet/column/values/rle/RunLengthBitPackingHybridEncoder.java": 9,
                "parquet-column/src/main/java/parquet/column/values/rle/RunLengthBitPackingHybridValuesReader.java": 36,
                "parquet-column/src/test/java/parquet/column/values/rle/RunLengthBitPackingHybridIntegrationTest.java": 2,
                "parquet-column/src/test/java/parquet/column/values/rle/TestRunLengthBitPackingHybridEncoder.java": 16
            },
            "is_test": true,
            "is_fix": false
        },
        "cd6a02d27bf20f601d8109ddbd756d7f665f2281": {
            "datetime": "2013-06-03T08:27:00-07:00",
            "summary": "Merge branch 'master' into alexlevenson/RLE-bit-packing-hybrid",
            "message": "Merge branch 'master' into alexlevenson/RLE-bit-packing-hybrid\n\nConflicts:\n\tparquet-column/src/main/java/parquet/column/Encoding.java\n\tparquet-column/src/main/java/parquet/column/values/rle/RLESimpleEncoder.java\n\tparquet-column/src/main/java/parquet/column/values/rle/RunLengthBitPackingHybridDecoder.java\n",
            "diff": {
                "parquet-column/src/main/java/parquet/column/Encoding.java": 4,
                "parquet-column/src/main/java/parquet/column/impl/ColumnWriterImpl.java": 7,
                "parquet-column/src/main/java/parquet/column/values/bitpacking/ByteBasedBitPackingEncoder.java": 4,
                "parquet-column/src/main/java/parquet/column/values/bitpacking/ByteBasedBitPackingGenerator.java": 174,
                "parquet-column/src/main/java/parquet/column/values/bitpacking/ByteBitPacking.java": 2,
                "parquet-column/src/main/java/parquet/column/values/bitpacking/ByteBitPackingLE.java": 25636,
                "parquet-column/src/main/java/parquet/column/values/bitpacking/ByteBitPackingValuesReader.java": 4,
                "parquet-column/src/main/java/parquet/column/values/bitpacking/ByteBitPackingValuesWriter.java": 10,
                "parquet-column/src/main/java/parquet/column/values/bitpacking/Packer.java": 67,
                "parquet-column/src/main/java/parquet/column/values/plain/BooleanPlainValuesReader.java": 17,
                "parquet-column/src/main/java/parquet/column/values/plain/BooleanPlainValuesWriter.java": 42,
                "parquet-column/src/main/java/parquet/column/values/rle/RunLengthBitPackingHybridDecoder.java": 4,
                "parquet-column/src/test/java/parquet/column/values/bitpacking/BitPackingPerfTest.java": 2,
                "parquet-column/src/test/java/parquet/column/values/bitpacking/TestBitPackingColumn.java": 5,
                "parquet-column/src/test/java/parquet/column/values/bitpacking/TestByteBitPacking.java": 76,
                "parquet-column/src/test/java/parquet/column/values/bitpacking/TestLemireBitPacking.java": 38
            },
            "is_test": true,
            "is_fix": false
        },
        "d7fe1a5d2b2129c53a5d8425f9e3ca14f42522f9": {
            "datetime": "2013-06-03T08:50:41-07:00",
            "summary": "Use RLE for repetition / definition levels",
            "message": "Use RLE for repetition / definition levels\n",
            "diff": {
                "parquet-column/src/main/java/parquet/column/impl/ColumnWriterImpl.java": 21,
                "parquet-column/src/main/java/parquet/column/values/ValuesReader.java": 2,
                "parquet-column/src/main/java/parquet/column/values/ValuesWriter.java": 2,
                "parquet-column/src/main/java/parquet/column/values/rle/RunLengthBitPackingHybridEncoder.java": 12,
                "parquet-column/src/main/java/parquet/column/values/rle/RunLengthBitPackingHybridValuesWriter.java": 62,
                "parquet-column/src/test/java/parquet/column/values/rle/TestRunLengthBitPackingHybridEncoder.java": 4
            },
            "is_test": true,
            "is_fix": false
        },
        "47824efda9cb7d027138981672d569a042b4af06": {
            "datetime": "2013-06-03T12:21:39-07:00",
            "summary": "Merge branch 'master' of github.com:Parquet/parquet-mr into add_validation_setting",
            "message": "Merge branch 'master' of github.com:Parquet/parquet-mr into add_validation_setting\n\nConflicts:\n\tparquet-hadoop/src/main/java/parquet/hadoop/ParquetOutputFormat.java\n\tparquet-hadoop/src/main/java/parquet/hadoop/ParquetRecordWriter.java\n\tparquet-hadoop/src/main/java/parquet/hadoop/ParquetWriter.java\n",
            "diff": {
                "parquet-avro/src/main/java/parquet/avro/AvroWriteSupport.java": 9,
                "parquet-avro/src/test/java/parquet/avro/TestReadWrite.java": 13,
                "parquet-column/src/main/java/parquet/Log.java": 2,
                "parquet-column/src/main/java/parquet/Preconditions.java": 39,
                "parquet-column/src/main/java/parquet/Version.java": 15,
                "parquet-column/src/main/java/parquet/bytes/BytesInput.java": 8,
                "parquet-column/src/main/java/parquet/column/ColumnReader.java": 24,
                "parquet-column/src/main/java/parquet/column/Dictionary.java": 63,
                "parquet-column/src/main/java/parquet/column/Encoding.java": 71,
                "parquet-column/src/main/java/parquet/column/impl/ColumnReadStoreImpl.java": 212,
                "parquet-column/src/main/java/parquet/column/impl/ColumnReaderImpl.java": 275,
                "parquet-column/src/main/java/parquet/column/impl/ColumnWriteStoreImpl.java": 6,
                "parquet-column/src/main/java/parquet/column/impl/ColumnWriterImpl.java": 36,
                "parquet-column/src/main/java/parquet/column/page/DictionaryPage.java": 89,
                "parquet-column/src/main/java/parquet/column/page/PageReader.java": 19,
                "parquet-column/src/main/java/parquet/column/page/PageWriter.java": 14,
                "parquet-column/src/main/java/parquet/column/values/ValuesReader.java": 48,
                "parquet-column/src/main/java/parquet/column/values/ValuesWriter.java": 17,
                "parquet-column/src/main/java/parquet/column/values/bitpacking/ByteBasedBitPackingEncoder.java": 9,
                "parquet-column/src/main/java/parquet/column/values/bitpacking/ByteBasedBitPackingGenerator.java": 174,
                "parquet-column/src/main/java/parquet/column/values/bitpacking/ByteBitPacking.java": 2,
                "parquet-column/src/main/java/parquet/column/values/bitpacking/ByteBitPackingLE.java": 25636,
                "parquet-column/src/main/java/parquet/column/values/bitpacking/ByteBitPackingValuesReader.java": 4,
                "parquet-column/src/main/java/parquet/column/values/bitpacking/ByteBitPackingValuesWriter.java": 10,
                "parquet-column/src/main/java/parquet/column/values/bitpacking/Packer.java": 67,
                "parquet-column/src/main/java/parquet/column/values/dictionary/DictionaryValuesReader.java": 81,
                "parquet-column/src/main/java/parquet/column/values/dictionary/DictionaryValuesWriter.java": 247,
                "parquet-column/src/main/java/parquet/column/values/dictionary/IntList.java": 120,
                "parquet-column/src/main/java/parquet/column/values/dictionary/PlainBinaryDictionary.java": 83,
                "parquet-column/src/main/java/parquet/column/values/plain/BooleanPlainValuesReader.java": 17,
                "parquet-column/src/main/java/parquet/column/values/plain/BooleanPlainValuesWriter.java": 42,
                "parquet-column/src/main/java/parquet/column/values/plain/PlainValuesReader.java": 9,
                "parquet-column/src/main/java/parquet/column/values/rle/RLEDecoder.java": 11,
                "parquet-column/src/main/java/parquet/column/values/rle/RLESimpleEncoder.java": 34,
                "parquet-column/src/main/java/parquet/io/MessageColumnIO.java": 7,
                "parquet-column/src/main/java/parquet/io/RecordReaderImplementation.java": 2,
                "parquet-column/src/main/java/parquet/io/api/Binary.java": 15,
                "parquet-column/src/main/java/parquet/io/api/GroupConverter.java": 3,
                "parquet-column/src/main/java/parquet/io/api/PrimitiveConverter.java": 33,
                "parquet-column/src/main/java/parquet/schema/PrimitiveType.java": 75,
                "parquet-column/src/test/java/parquet/bytes/TestCapacityByteArrayOutputStream.java": 15,
                "parquet-column/src/test/java/parquet/column/mem/TestMemColumn.java": 55,
                "parquet-column/src/test/java/parquet/column/page/mem/MemPageReader.java": 19,
                "parquet-column/src/test/java/parquet/column/page/mem/MemPageStore.java": 2,
                "parquet-column/src/test/java/parquet/column/page/mem/MemPageWriter.java": 17,
                "parquet-column/src/test/java/parquet/column/values/bitpacking/BitPackingPerfTest.java": 2,
                "parquet-column/src/test/java/parquet/column/values/bitpacking/TestBitPackingColumn.java": 5,
                "parquet-column/src/test/java/parquet/column/values/bitpacking/TestByteBitPacking.java": 76,
                "parquet-column/src/test/java/parquet/column/values/bitpacking/TestLemireBitPacking.java": 38,
                "parquet-column/src/test/java/parquet/column/values/dictionary/TestDictionary.java": 131,
                "parquet-column/src/test/java/parquet/io/PerfTest.java": 2,
                "parquet-column/src/test/java/parquet/io/TestColumnIO.java": 15,
                "parquet-hadoop/src/main/java/parquet/format/converter/ParquetMetadataConverter.java": 13,
                "parquet-hadoop/src/main/java/parquet/hadoop/ColumnChunkPageReadStore.java": 20,
                "parquet-hadoop/src/main/java/parquet/hadoop/ColumnChunkPageWriteStore.java": 35,
                "parquet-hadoop/src/main/java/parquet/hadoop/ParquetFileReader.java": 81,
                "parquet-hadoop/src/main/java/parquet/hadoop/ParquetFileWriter.java": 29,
                "parquet-hadoop/src/main/java/parquet/hadoop/ParquetOutputFormat.java": 23,
                "parquet-hadoop/src/main/java/parquet/hadoop/ParquetRecordWriter.java": 8,
                "parquet-hadoop/src/main/java/parquet/hadoop/ParquetWriter.java": 45,
                "parquet-hadoop/src/main/java/parquet/hadoop/PrintFooter.java": 15,
                "parquet-hadoop/src/main/java/parquet/hadoop/metadata/ColumnChunkMetaData.java": 23,
                "parquet-hadoop/src/main/java/parquet/hadoop/util/ContextUtil.java": 19,
                "parquet-pig/src/main/java/parquet/pig/convert/TupleConverter.java": 26,
                "parquet-pig/src/test/java/parquet/pig/GenerateIntTestFile.java": 8,
                "parquet-pig/src/test/java/parquet/pig/GenerateTPCH.java": 3,
                "parquet-pig/src/test/java/parquet/pig/TupleConsumerPerfTest.java": 2,
                "parquet-thrift/src/test/java/parquet/thrift/TestParquetReadProtocol.java": 2,
                "parquet-thrift/src/test/java/parquet/thrift/TestThriftSchemaConverter.java": 1
            },
            "is_test": true,
            "is_fix": false
        },
        "af0ccf9cd78d49436fedadd9b4dd32d1b8dc9bad": {
            "datetime": "2013-06-03T12:25:52-07:00",
            "summary": "better error message and javadoc",
            "message": "better error message and javadoc\n",
            "diff": {
                "parquet-column/src/main/java/parquet/column/impl/ColumnReaderImpl.java": 2,
                "parquet-hadoop/src/main/java/parquet/hadoop/ParquetWriter.java": 6
            },
            "is_test": false,
            "is_fix": false
        },
        "c2115825b690aba1f2cf6a48fde96c9aea489e26": {
            "datetime": "2013-06-03T14:25:21-07:00",
            "summary": "Merge pull request #53 from Parquet/add_validation_setting",
            "message": "Merge pull request #53 from Parquet/add_validation_setting\n\nadd a validation setting to OutputFormat",
            "diff": {
                "parquet-column/src/main/java/parquet/column/impl/ColumnReaderImpl.java": 17,
                "parquet-column/src/main/java/parquet/column/values/plain/BinaryPlainValuesReader.java": 2,
                "parquet-hadoop/src/main/java/parquet/hadoop/ParquetOutputFormat.java": 44,
                "parquet-hadoop/src/main/java/parquet/hadoop/ParquetReader.java": 4,
                "parquet-hadoop/src/main/java/parquet/hadoop/ParquetRecordReader.java": 19,
                "parquet-hadoop/src/main/java/parquet/hadoop/ParquetRecordWriter.java": 6,
                "parquet-hadoop/src/main/java/parquet/hadoop/ParquetWriter.java": 34
            },
            "is_test": false,
            "is_fix": false
        },
        "aed1dca4522647aa525b97cca13df75fb5feb751": {
            "datetime": "2013-06-04T13:52:09-07:00",
            "summary": "dictionary encoding header is now bitWidth instead of max dictionary entry id",
            "message": "dictionary encoding header is now bitWidth instead of max dictionary entry id\n",
            "diff": {
                "parquet-column/src/main/java/parquet/column/values/dictionary/DictionaryValuesReader.java": 6,
                "parquet-column/src/main/java/parquet/column/values/dictionary/DictionaryValuesWriter.java": 20
            },
            "is_test": false,
            "is_fix": false
        },
        "7cf85cb4e0ea7d25223b9a2773c7a8d629830ea5": {
            "datetime": "2013-06-04T15:08:40-07:00",
            "summary": "Fix RunLengthBitPackingHybridValuesReader",
            "message": "Fix RunLengthBitPackingHybridValuesReader\n",
            "diff": {
                "parquet-column/src/main/java/parquet/column/values/rle/RunLengthBitPackingHybridValuesReader.java": 98
            },
            "is_test": false,
            "is_fix": false
        },
        "e70652e22cedab7440b477970fffb058fd888d5a": {
            "datetime": "2013-06-05T13:57:10-07:00",
            "summary": "Merge pull request #59 from Parquet/dictionary_encoding_format_adjustment",
            "message": "Merge pull request #59 from Parquet/dictionary_encoding_format_adjustment\n\ndictionary encoding header is now bitWidth instead of max dictionary entry id",
            "diff": {
                "parquet-column/src/main/java/parquet/column/values/dictionary/DictionaryValuesReader.java": 6,
                "parquet-column/src/main/java/parquet/column/values/dictionary/DictionaryValuesWriter.java": 20
            },
            "is_test": false,
            "is_fix": false
        },
        "2dbd0d232e11dde8944b5cc41486aabcee6dc7d1": {
            "datetime": "2013-06-05T14:35:38-07:00",
            "summary": "Remove logic for valueCount > Integer.MAX_VALUE",
            "message": "Remove logic for valueCount > Integer.MAX_VALUE\n",
            "diff": {
                "parquet-column/src/main/java/parquet/column/values/rle/RunLengthBitPackingHybridValuesReader.java": 65
            },
            "is_test": false,
            "is_fix": false
        },
        "3ff63fd2f9de8dd0f4cfa68b7a7e40195f230a5d": {
            "datetime": "2013-06-05T15:05:09-07:00",
            "summary": "Merge branch 'master' into alexlevenson/RLE-bit-packing-hybrid",
            "message": "Merge branch 'master' into alexlevenson/RLE-bit-packing-hybrid\n\nConflicts:\n\tparquet-column/src/main/java/parquet/column/values/dictionary/DictionaryValuesReader.java\n\tparquet-column/src/main/java/parquet/column/values/dictionary/DictionaryValuesWriter.java\n",
            "diff": {
                "parquet-column/src/main/java/parquet/column/impl/ColumnReaderImpl.java": 17,
                "parquet-column/src/main/java/parquet/column/values/dictionary/DictionaryValuesReader.java": 6,
                "parquet-column/src/main/java/parquet/column/values/dictionary/DictionaryValuesWriter.java": 21,
                "parquet-column/src/main/java/parquet/column/values/plain/BinaryPlainValuesReader.java": 2,
                "parquet-hadoop/src/main/java/parquet/hadoop/ParquetOutputFormat.java": 44,
                "parquet-hadoop/src/main/java/parquet/hadoop/ParquetReader.java": 4,
                "parquet-hadoop/src/main/java/parquet/hadoop/ParquetRecordReader.java": 19,
                "parquet-hadoop/src/main/java/parquet/hadoop/ParquetRecordWriter.java": 6,
                "parquet-hadoop/src/main/java/parquet/hadoop/ParquetWriter.java": 34
            },
            "is_test": false,
            "is_fix": false
        },
        "6e6516622b26450d2030442c9a794e3d021e262f": {
            "datetime": "2013-06-06T07:55:02-07:00",
            "summary": "fix bit packing encoding bug",
            "message": "fix bit packing encoding bug\n",
            "diff": {
                "parquet-column/src/main/java/parquet/column/values/bitpacking/ByteBasedBitPackingEncoder.java": 13,
                "parquet-column/src/main/java/parquet/column/values/dictionary/DictionaryValuesReader.java": 1,
                "parquet-column/src/main/java/parquet/column/values/dictionary/DictionaryValuesWriter.java": 2,
                "parquet-column/src/test/java/parquet/column/values/bitpacking/TestByteBasedBitPackingEncoder.java": 22
            },
            "is_test": true,
            "is_fix": false
        },
        "1d13a61a1eec58e105defaa0731281f6aa8a7107": {
            "datetime": "2013-06-06T13:32:25-07:00",
            "summary": "create and use checkedCast()",
            "message": "create and use checkedCast()\n",
            "diff": {
                "parquet-column/src/main/java/parquet/Ints.java": 26,
                "parquet-column/src/main/java/parquet/column/values/rle/RunLengthBitPackingHybridValuesReader.java": 6
            },
            "is_test": false,
            "is_fix": false
        },
        "b7f694613b862710be79211f181974c9478145b5": {
            "datetime": "2013-06-06T14:22:58-07:00",
            "summary": "Merge pull request #58 from Parquet/alexlevenson/RLE-bit-packing-hybrid",
            "message": "Merge pull request #58 from Parquet/alexlevenson/RLE-bit-packing-hybrid\n\nAdds rle / bitpacking hybrid encoding",
            "diff": {
                "parquet-column/src/main/java/parquet/Ints.java": 26,
                "parquet-column/src/main/java/parquet/Preconditions.java": 15,
                "parquet-column/src/main/java/parquet/bytes/BytesUtils.java": 65,
                "parquet-column/src/main/java/parquet/bytes/CapacityByteArrayOutputStream.java": 36,
                "parquet-column/src/main/java/parquet/column/Encoding.java": 20,
                "parquet-column/src/main/java/parquet/column/impl/ColumnWriterImpl.java": 21,
                "parquet-column/src/main/java/parquet/column/values/ValuesReader.java": 2,
                "parquet-column/src/main/java/parquet/column/values/ValuesWriter.java": 2,
                "parquet-column/src/main/java/parquet/column/values/dictionary/DictionaryValuesReader.java": 7,
                "parquet-column/src/main/java/parquet/column/values/dictionary/DictionaryValuesWriter.java": 25,
                "parquet-column/src/main/java/parquet/column/values/rle/RLEDecoder.java": 46,
                "parquet-column/src/main/java/parquet/column/values/rle/RLESimpleEncoder.java": 73,
                "parquet-column/src/main/java/parquet/column/values/rle/RunLengthBitPackingHybridEncoder.java": 267,
                "parquet-column/src/main/java/parquet/column/values/rle/RunLengthBitPackingHybridValuesReader.java": 79,
                "parquet-column/src/main/java/parquet/column/values/rle/RunLengthBitPackingHybridValuesWriter.java": 62,
                "parquet-column/src/test/java/parquet/bytes/TestCapacityByteArrayOutputStream.java": 86,
                "parquet-column/src/test/java/parquet/column/values/rle/RunLengthBitPackingHybridIntegrationTest.java": 75,
                "parquet-column/src/test/java/parquet/column/values/rle/TestRLE.java": 62,
                "parquet-column/src/test/java/parquet/column/values/rle/TestRunLengthBitPackingHybridEncoder.java": 288
            },
            "is_test": true,
            "is_fix": false
        },
        "e0a5920b0e0074aa2129beda7be49dcd35c62e3e": {
            "datetime": "2013-06-07T23:51:53-07:00",
            "summary": "Merge branch 'master' of github.com:Parquet/parquet-mr into fix_bit_packing_encoding_bug",
            "message": "Merge branch 'master' of github.com:Parquet/parquet-mr into fix_bit_packing_encoding_bug\n\nConflicts:\n\tparquet-column/src/main/java/parquet/column/values/dictionary/DictionaryValuesWriter.java\n",
            "diff": {
                "parquet-column/src/main/java/parquet/Ints.java": 26,
                "parquet-column/src/main/java/parquet/Preconditions.java": 15,
                "parquet-column/src/main/java/parquet/bytes/BytesUtils.java": 65,
                "parquet-column/src/main/java/parquet/bytes/CapacityByteArrayOutputStream.java": 36,
                "parquet-column/src/main/java/parquet/column/Encoding.java": 20,
                "parquet-column/src/main/java/parquet/column/impl/ColumnWriterImpl.java": 21,
                "parquet-column/src/main/java/parquet/column/values/ValuesReader.java": 2,
                "parquet-column/src/main/java/parquet/column/values/ValuesWriter.java": 2,
                "parquet-column/src/main/java/parquet/column/values/dictionary/DictionaryValuesReader.java": 6,
                "parquet-column/src/main/java/parquet/column/values/dictionary/DictionaryValuesWriter.java": 19,
                "parquet-column/src/main/java/parquet/column/values/rle/RLEDecoder.java": 46,
                "parquet-column/src/main/java/parquet/column/values/rle/RLESimpleEncoder.java": 73,
                "parquet-column/src/main/java/parquet/column/values/rle/RunLengthBitPackingHybridEncoder.java": 267,
                "parquet-column/src/main/java/parquet/column/values/rle/RunLengthBitPackingHybridValuesReader.java": 79,
                "parquet-column/src/main/java/parquet/column/values/rle/RunLengthBitPackingHybridValuesWriter.java": 62,
                "parquet-column/src/test/java/parquet/bytes/TestCapacityByteArrayOutputStream.java": 86,
                "parquet-column/src/test/java/parquet/column/values/rle/RunLengthBitPackingHybridIntegrationTest.java": 75,
                "parquet-column/src/test/java/parquet/column/values/rle/TestRLE.java": 62,
                "parquet-column/src/test/java/parquet/column/values/rle/TestRunLengthBitPackingHybridEncoder.java": 288
            },
            "is_test": true,
            "is_fix": false
        },
        "7e3ef9febfb49d8ace1715665ba3d7ac640434a0": {
            "datetime": "2013-06-08T07:26:26-07:00",
            "summary": "Merge pull request #60 from Parquet/fix_bit_packing_encoding_bug",
            "message": "Merge pull request #60 from Parquet/fix_bit_packing_encoding_bug\n\nfix bit packing encoding bug",
            "diff": {
                "parquet-column/src/main/java/parquet/column/values/bitpacking/ByteBasedBitPackingEncoder.java": 13,
                "parquet-column/src/main/java/parquet/column/values/dictionary/DictionaryValuesWriter.java": 8,
                "parquet-column/src/test/java/parquet/column/values/bitpacking/TestByteBasedBitPackingEncoder.java": 22
            },
            "is_test": true,
            "is_fix": false
        },
        "c773446264808dc0fc50a495cfb24f8e4c6140d0": {
            "datetime": "2013-06-17T11:13:57-07:00",
            "summary": "ability to read version number from parquet jar Version utility",
            "message": "ability to read version number from parquet jar Version utility\n",
            "diff": {
                "parquet-column/src/main/java/parquet/Version.java": 24
            },
            "is_test": false,
            "is_fix": false
        },
        "a2b7a657c51d68bcea32396ed58b3fda77ba0e17": {
            "datetime": "2013-06-17T13:50:34-07:00",
            "summary": "when there is more than one row group the converter will get multiple dictionaries set",
            "message": "when there is more than one row group the converter will get multiple dictionaries set\n",
            "diff": {
                "parquet-pig/src/main/java/parquet/pig/convert/TupleConverter.java": 3
            },
            "is_test": false,
            "is_fix": false
        },
        "c3596a9ddd0093890cc39e49fb15b11996f451ff": {
            "datetime": "2013-06-17T17:44:39-07:00",
            "summary": "Add support for 4 byte length written at the beginning of rle columns",
            "message": "Add support for 4 byte length written at the beginning of rle columns\n",
            "diff": {
                "parquet-column/src/main/java/parquet/column/values/rle/RunLengthBitPackingHybridEncoder.java": 5,
                "parquet-column/src/main/java/parquet/column/values/rle/RunLengthBitPackingHybridValuesReader.java": 48,
                "parquet-column/src/main/java/parquet/column/values/rle/RunLengthBitPackingHybridValuesWriter.java": 11
            },
            "is_test": false,
            "is_fix": false
        },
        "c4c77ba08da97d4d4da656898a6f82506b240bea": {
            "datetime": "2013-06-18T09:45:36-07:00",
            "summary": "add support for ReadSupport specific info in split",
            "message": "add support for ReadSupport specific info in split\n",
            "diff": {
                "parquet-hadoop/src/main/java/parquet/hadoop/ParquetInputFormat.java": 23,
                "parquet-hadoop/src/main/java/parquet/hadoop/ParquetInputSplit.java": 17,
                "parquet-hadoop/src/main/java/parquet/hadoop/ParquetReader.java": 17,
                "parquet-hadoop/src/main/java/parquet/hadoop/ParquetRecordReader.java": 2,
                "parquet-hadoop/src/main/java/parquet/hadoop/api/ReadSupport.java": 21,
                "parquet-hadoop/src/test/java/parquet/hadoop/TestInputFormat.java": 5
            },
            "is_test": true,
            "is_fix": false
        },
        "4950149fb60a055f2e99d0a2b016d9f61d9121b7": {
            "datetime": "2013-06-18T10:59:25-07:00",
            "summary": "Merge pull request #61 from aniket486/master",
            "message": "Merge pull request #61 from aniket486/master\n\nability to read version number from parquet jar Version utility",
            "diff": {
                "parquet-column/src/main/java/parquet/Version.java": 24
            },
            "is_test": false,
            "is_fix": false
        },
        "e27f8719ec2d8f406ce47695856e271caf4cc4f1": {
            "datetime": "2013-06-18T10:59:48-07:00",
            "summary": "Merge pull request #63 from Parquet/alexlevenson/fix-rle-4byte-length",
            "message": "Merge pull request #63 from Parquet/alexlevenson/fix-rle-4byte-length\n\nAdd support for 4 byte length written at the beginning of rle columns",
            "diff": {
                "parquet-column/src/main/java/parquet/column/values/rle/RunLengthBitPackingHybridEncoder.java": 5,
                "parquet-column/src/main/java/parquet/column/values/rle/RunLengthBitPackingHybridValuesReader.java": 48,
                "parquet-column/src/main/java/parquet/column/values/rle/RunLengthBitPackingHybridValuesWriter.java": 11
            },
            "is_test": false,
            "is_fix": false
        },
        "f7fbed18312d8e39f33e156310d7e635d4c8434a": {
            "datetime": "2013-06-18T14:16:30-07:00",
            "summary": "fix comments",
            "message": "fix comments\n",
            "diff": {
                "parquet-column/src/main/java/parquet/column/values/rle/RunLengthBitPackingHybridEncoder.java": 19
            },
            "is_test": false,
            "is_fix": false
        },
        "04ac202ccb95ce27b132c3638e6838d642587072": {
            "datetime": "2013-06-18T14:28:53-07:00",
            "summary": "Merge pull request #62 from Parquet/fix_dic_decoding_bug",
            "message": "Merge pull request #62 from Parquet/fix_dic_decoding_bug\n\nwhen there is more than one row group the converter will get multiple dictionaries set",
            "diff": {
                "parquet-pig/src/main/java/parquet/pig/convert/TupleConverter.java": 3
            },
            "is_test": false,
            "is_fix": false
        },
        "1a30dcce72b45e0f3e6cb8722ed07087b9b9fb11": {
            "datetime": "2013-06-18T18:36:33-07:00",
            "summary": "Merge pull request #66 from Parquet/alexlevenson/fix-rle-comments",
            "message": "Merge pull request #66 from Parquet/alexlevenson/fix-rle-comments\n\nFix the comments in RunLengthBitPackingHybridEncoder.java",
            "diff": {
                "parquet-column/src/main/java/parquet/column/values/rle/RunLengthBitPackingHybridEncoder.java": 19
            },
            "is_test": false,
            "is_fix": false
        },
        "ff109bc92b5bd488e54249445be997a9a577e280": {
            "datetime": "2013-06-19T23:42:30-07:00",
            "summary": "Merge pull request #65 from Parquet/ReadSupport_specific_info_in_split",
            "message": "Merge pull request #65 from Parquet/ReadSupport_specific_info_in_split\n\nadd support for ReadSupport specific info in split",
            "diff": {
                "parquet-hadoop/src/main/java/parquet/hadoop/ParquetInputFormat.java": 23,
                "parquet-hadoop/src/main/java/parquet/hadoop/ParquetInputSplit.java": 17,
                "parquet-hadoop/src/main/java/parquet/hadoop/ParquetReader.java": 17,
                "parquet-hadoop/src/main/java/parquet/hadoop/ParquetRecordReader.java": 2,
                "parquet-hadoop/src/main/java/parquet/hadoop/api/ReadSupport.java": 21,
                "parquet-hadoop/src/test/java/parquet/hadoop/TestInputFormat.java": 5
            },
            "is_test": true,
            "is_fix": false
        },
        "5f0f929e42c9a0a8cf3a7bf418a252aa7e4a1168": {
            "datetime": "2013-06-22T12:48:11+01:00",
            "summary": "Added filtering functionality",
            "message": "Added filtering functionality\n",
            "diff": {
                "parquet-avro/src/main/java/parquet/avro/AvroParquetReader.java": 5,
                "parquet-column/src/main/java/parquet/column/ColumnReader.java": 10,
                "parquet-column/src/main/java/parquet/column/impl/ColumnReaderImpl.java": 18,
                "parquet-column/src/main/java/parquet/filter/AndRecordFilter.java": 51,
                "parquet-column/src/main/java/parquet/filter/ColumnRecordFilter.java": 92,
                "parquet-column/src/main/java/parquet/filter/NullRecordFilter.java": 30,
                "parquet-column/src/main/java/parquet/filter/PagedRecordFilter.java": 55,
                "parquet-column/src/main/java/parquet/filter/RecordFilter.java": 26,
                "parquet-column/src/main/java/parquet/filter/UnboundRecordFilter.java": 19,
                "parquet-column/src/main/java/parquet/io/MessageColumnIO.java": 17,
                "parquet-column/src/main/java/parquet/io/RecordReaderImplementation.java": 91,
                "parquet-column/src/test/java/parquet/io/TestFiltered.java": 122,
                "parquet-hadoop/src/main/java/parquet/hadoop/ParquetReader.java": 8,
                "parquet-hadoop/src/main/java/parquet/hadoop/ParquetRecordReader.java": 19
            },
            "is_test": true,
            "is_fix": false
        },
        "ef5c143d0ce9fc825a0ef418c584f1c3a491435d": {
            "datetime": "2013-06-22T16:05:50+01:00",
            "summary": "Added avro specific functionality",
            "message": "Added avro specific functionality\n",
            "diff": {
                "parquet-avro/src/main/java/parquet/avro/AvroGenericRecordConverter.java": 20,
                "parquet-avro/src/main/java/parquet/avro/AvroParquetInputFormat.java": 3,
                "parquet-avro/src/main/java/parquet/avro/AvroParquetOutputFormat.java": 3,
                "parquet-avro/src/main/java/parquet/avro/AvroParquetReader.java": 4,
                "parquet-avro/src/main/java/parquet/avro/AvroParquetWriter.java": 20,
                "parquet-avro/src/main/java/parquet/avro/AvroReadSupport.java": 5,
                "parquet-avro/src/main/java/parquet/avro/AvroRecordMaterializer.java": 9,
                "parquet-avro/src/main/java/parquet/avro/AvroWriteSupport.java": 9
            },
            "is_test": false,
            "is_fix": false
        },
        "61239a0aa5d41e731b6b2a53df4da2b953abe1dd": {
            "datetime": "2013-06-22T16:47:27+01:00",
            "summary": "Added avro specific functionality",
            "message": "Added avro specific functionality\n",
            "diff": {
                "parquet-avro/src/test/java/parquet/avro/TestSpecificReadWrite.java": 104
            },
            "is_test": true,
            "is_fix": false
        },
        "f3ed65beddc41314fc19fa2a237d3379d1bdf557": {
            "datetime": "2013-06-23T00:32:00+02:00",
            "summary": "fix ValueStat max value",
            "message": "fix ValueStat max value\n",
            "diff": {
                "parquet-pig/src/main/java/parquet/pig/summary/ValueStat.java": 4,
                "parquet-pig/src/test/java/parquet/pig/summary/TestSummary.java": 18
            },
            "is_test": true,
            "is_fix": false
        },
        "8285b62ceafe3fe096ebe1836142445acf0a9586": {
            "datetime": "2013-06-23T14:13:12+01:00",
            "summary": "Fixed bug querying on Name,Url",
            "message": "Fixed bug querying on Name,Url\n",
            "diff": {
                "parquet-column/src/main/java/parquet/column/impl/ColumnReaderImpl.java": 2,
                "parquet-column/src/main/java/parquet/filter/ColumnRecordFilter.java": 4,
                "parquet-column/src/main/java/parquet/io/RecordReaderImplementation.java": 87,
                "parquet-column/src/test/java/parquet/io/TestFiltered.java": 23
            },
            "is_test": true,
            "is_fix": false
        },
        "ac5cbd1a48f12a0a431af07c9867b0b0ae04eceb": {
            "datetime": "2013-06-23T16:13:48+01:00",
            "summary": "Implmented more efficient skip algorithm",
            "message": "Implmented more efficient skip algorithm\n",
            "diff": {
                "parquet-column/src/main/java/parquet/column/impl/ColumnReaderImpl.java": 77,
                "parquet-column/src/main/java/parquet/column/values/ValuesReader.java": 41,
                "parquet-column/src/main/java/parquet/column/values/dictionary/DictionaryValuesReader.java": 8,
                "parquet-column/src/main/java/parquet/column/values/plain/BinaryPlainValuesReader.java": 12,
                "parquet-column/src/main/java/parquet/column/values/plain/BooleanPlainValuesReader.java": 8,
                "parquet-column/src/main/java/parquet/column/values/plain/PlainValuesReader.java": 36
            },
            "is_test": false,
            "is_fix": false
        },
        "483dd9f3a906fc0d87fbb3652efcc90ae01e0321": {
            "datetime": "2013-06-23T19:08:21-07:00",
            "summary": "Merge pull request #67 from svzdvd/master",
            "message": "Merge pull request #67 from svzdvd/master\n\nValueStat max value",
            "diff": {
                "parquet-pig/src/main/java/parquet/pig/summary/ValueStat.java": 4,
                "parquet-pig/src/test/java/parquet/pig/summary/TestSummary.java": 18
            },
            "is_test": true,
            "is_fix": false
        },
        "e440108de57199c12d66801ca93804086e7f7632": {
            "datetime": "2013-06-28T14:37:11-07:00",
            "summary": "Add support for snappy compression.",
            "message": "Add support for snappy compression.\n",
            "diff": {
                "parquet-hadoop/src/main/java/parquet/hadoop/ParquetOutputFormat.java": 2,
                "parquet-hadoop/src/main/java/parquet/hadoop/codec/SnappyCodec.java": 89,
                "parquet-hadoop/src/main/java/parquet/hadoop/codec/SnappyCompressor.java": 141,
                "parquet-hadoop/src/main/java/parquet/hadoop/codec/SnappyDecompressor.java": 134,
                "parquet-hadoop/src/main/java/parquet/hadoop/codec/SnappyUtil.java": 14,
                "parquet-hadoop/src/main/java/parquet/hadoop/metadata/CompressionCodecName.java": 2,
                "parquet-hadoop/src/test/java/parquet/hadoop/TestSnappyCodec.java": 65,
                "parquet-hadoop/src/test/java/parquet/hadoop/example/TestInputOutputFormat.java": 13
            },
            "is_test": true,
            "is_fix": false
        },
        "7b742900d565271408c87df6b995d9157b9c4354": {
            "datetime": "2013-06-28T14:55:17-07:00",
            "summary": "Fixed test case.",
            "message": "Fixed test case.\n",
            "diff": {
                "parquet-hadoop/src/test/java/parquet/hadoop/TestSnappyCodec.java": 12
            },
            "is_test": true,
            "is_fix": false
        },
        "2519b95f9e1f458bd3b47f75b4f83eb6a4c55930": {
            "datetime": "2013-06-29T09:51:22-07:00",
            "summary": "Merge pull request #70 from Parquet/snappy",
            "message": "Merge pull request #70 from Parquet/snappy\n\nAdd support for snappy compression.",
            "diff": {
                "parquet-hadoop/src/main/java/parquet/hadoop/ParquetOutputFormat.java": 2,
                "parquet-hadoop/src/main/java/parquet/hadoop/codec/SnappyCodec.java": 89,
                "parquet-hadoop/src/main/java/parquet/hadoop/codec/SnappyCompressor.java": 141,
                "parquet-hadoop/src/main/java/parquet/hadoop/codec/SnappyDecompressor.java": 134,
                "parquet-hadoop/src/main/java/parquet/hadoop/codec/SnappyUtil.java": 14,
                "parquet-hadoop/src/main/java/parquet/hadoop/metadata/CompressionCodecName.java": 2,
                "parquet-hadoop/src/test/java/parquet/hadoop/TestSnappyCodec.java": 67,
                "parquet-hadoop/src/test/java/parquet/hadoop/example/TestInputOutputFormat.java": 13
            },
            "is_test": true,
            "is_fix": false
        },
        "be8e4e953b98400426b801793da9c66f95f68881": {
            "datetime": "2013-06-30T19:35:30+01:00",
            "summary": "Merge remote-tracking branch 'upstream/master'",
            "message": "Merge remote-tracking branch 'upstream/master'\n",
            "diff": {
                "parquet-hadoop/src/main/java/parquet/hadoop/ParquetOutputFormat.java": 2,
                "parquet-hadoop/src/main/java/parquet/hadoop/codec/SnappyCodec.java": 89,
                "parquet-hadoop/src/main/java/parquet/hadoop/codec/SnappyCompressor.java": 141,
                "parquet-hadoop/src/main/java/parquet/hadoop/codec/SnappyDecompressor.java": 134,
                "parquet-hadoop/src/main/java/parquet/hadoop/codec/SnappyUtil.java": 14,
                "parquet-hadoop/src/main/java/parquet/hadoop/metadata/CompressionCodecName.java": 2,
                "parquet-hadoop/src/test/java/parquet/hadoop/TestSnappyCodec.java": 67,
                "parquet-hadoop/src/test/java/parquet/hadoop/example/TestInputOutputFormat.java": 13,
                "parquet-pig/src/main/java/parquet/pig/summary/ValueStat.java": 4,
                "parquet-pig/src/test/java/parquet/pig/summary/TestSummary.java": 18
            },
            "is_test": true,
            "is_fix": false
        },
        "1d7a5c33c935710ac8e5fa722d77e23fe55d5c5e": {
            "datetime": "2013-07-01T01:06:05+01:00",
            "summary": "Fixing after code reviews",
            "message": "Fixing after code reviews\n",
            "diff": {
                "parquet-avro/src/main/java/parquet/avro/AvroIndexedRecordConverter.java": 83,
                "parquet-avro/src/main/java/parquet/avro/AvroParquetInputFormat.java": 1,
                "parquet-avro/src/main/java/parquet/avro/AvroParquetOutputFormat.java": 1,
                "parquet-avro/src/main/java/parquet/avro/AvroParquetWriter.java": 26,
                "parquet-avro/src/main/java/parquet/avro/AvroReadSupport.java": 5,
                "parquet-avro/src/main/java/parquet/avro/AvroRecordMaterializer.java": 1,
                "parquet-avro/src/main/java/parquet/avro/AvroSchemaConverter.java": 42,
                "parquet-avro/src/main/java/parquet/avro/AvroWriteSupport.java": 41,
                "parquet-avro/src/test/java/parquet/avro/TestAvroSchemaConverter.java": 11,
                "parquet-avro/src/test/java/parquet/avro/TestSpecificReadWrite.java": 113,
                "parquet-column/src/main/java/parquet/column/impl/ColumnReaderImpl.java": 2,
                "parquet-column/src/main/java/parquet/filter/ColumnPredicates.java": 82,
                "parquet-column/src/main/java/parquet/filter/ColumnRecordFilter.java": 43,
                "parquet-column/src/main/java/parquet/filter/NullRecordFilter.java": 30,
                "parquet-column/src/main/java/parquet/filter/PagedRecordFilter.java": 3,
                "parquet-column/src/main/java/parquet/filter/RecordFilter.java": 5,
                "parquet-column/src/main/java/parquet/filter/UnboundRecordFilter.java": 1,
                "parquet-column/src/main/java/parquet/io/FilteredRecordReader.java": 77,
                "parquet-column/src/main/java/parquet/io/MessageColumnIO.java": 12,
                "parquet-column/src/main/java/parquet/io/RecordReaderImplementation.java": 58,
                "parquet-column/src/test/java/parquet/io/TestFiltered.java": 10,
                "parquet-hadoop/src/main/java/parquet/hadoop/ParquetReader.java": 4,
                "parquet-hadoop/src/main/java/parquet/hadoop/ParquetRecordReader.java": 2
            },
            "is_test": true,
            "is_fix": false
        },
        "08b7aebb91af31cea3f143b4c464e853d97ad82e": {
            "datetime": "2013-07-01T10:27:49-07:00",
            "summary": "support for schema compatibility",
            "message": "support for schema compatibility\n",
            "diff": {
                "parquet-column/src/main/java/parquet/io/ColumnIOFactory.java": 86,
                "parquet-column/src/main/java/parquet/schema/Type.java": 25,
                "parquet-column/src/test/java/parquet/io/TestColumnIO.java": 102,
                "parquet-hadoop/src/main/java/parquet/hadoop/ParquetInputFormat.java": 1,
                "parquet-hadoop/src/main/java/parquet/hadoop/ParquetInputSplit.java": 15,
                "parquet-hadoop/src/main/java/parquet/hadoop/ParquetReader.java": 1,
                "parquet-hadoop/src/main/java/parquet/hadoop/ParquetRecordReader.java": 4
            },
            "is_test": true,
            "is_fix": false
        },
        "7b470794cde3f488f863b276721c930ab50a3c58": {
            "datetime": "2013-07-01T14:17:33-07:00",
            "summary": "Should not write data if the RL/DL is all zeroes",
            "message": "Should not write data if the RL/DL is all zeroes\n",
            "diff": {
                "parquet-column/src/main/java/parquet/column/Encoding.java": 4,
                "parquet-column/src/main/java/parquet/column/impl/ColumnWriterImpl.java": 24
            },
            "is_test": false,
            "is_fix": false
        },
        "c98f4670b8467d6e15c9ecdff4dad88331302775": {
            "datetime": "2013-07-01T14:40:12-07:00",
            "summary": "Merge pull request #73 from aniket486/write_no_data_for_no_RL_DL",
            "message": "Merge pull request #73 from aniket486/write_no_data_for_no_RL_DL\n\nShould not write data if the RL/DL is all zeroes",
            "diff": {
                "parquet-column/src/main/java/parquet/column/Encoding.java": 4,
                "parquet-column/src/main/java/parquet/column/impl/ColumnWriterImpl.java": 24
            },
            "is_test": false,
            "is_fix": false
        },
        "94afb195dfae10fc40699f3c0efc31bb8f23f51a": {
            "datetime": "2013-07-02T15:53:13-07:00",
            "summary": "fix dictionary decoding bug when more than one encoding is used",
            "message": "fix dictionary decoding bug when more than one encoding is used\n",
            "diff": {
                "parquet-column/src/main/java/parquet/column/Encoding.java": 12,
                "parquet-column/src/main/java/parquet/column/impl/ColumnReaderImpl.java": 10
            },
            "is_test": false,
            "is_fix": false
        },
        "707bdf04d31fea4174c8078ed449121899dfc01c": {
            "datetime": "2013-07-02T16:07:14-07:00",
            "summary": "add negative tests",
            "message": "add negative tests\n",
            "diff": {
                "parquet-column/src/test/java/parquet/io/TestColumnIO.java": 21
            },
            "is_test": true,
            "is_fix": false
        },
        "364b4a03e9899004399ef401e3a7b8a5174de8c0": {
            "datetime": "2013-07-02T16:13:47-07:00",
            "summary": "Merge pull request #72 from Parquet/schema_compatibility",
            "message": "Merge pull request #72 from Parquet/schema_compatibility\n\nsupport for schema compatibility",
            "diff": {
                "parquet-column/src/main/java/parquet/io/ColumnIOFactory.java": 86,
                "parquet-column/src/main/java/parquet/schema/Type.java": 25,
                "parquet-column/src/test/java/parquet/io/TestColumnIO.java": 123,
                "parquet-hadoop/src/main/java/parquet/hadoop/ParquetInputFormat.java": 1,
                "parquet-hadoop/src/main/java/parquet/hadoop/ParquetInputSplit.java": 15,
                "parquet-hadoop/src/main/java/parquet/hadoop/ParquetReader.java": 1,
                "parquet-hadoop/src/main/java/parquet/hadoop/ParquetRecordReader.java": 4
            },
            "is_test": true,
            "is_fix": false
        },
        "efc59829cfbf19de248c9fdadb39486382c2a457": {
            "datetime": "2013-07-02T18:26:08-07:00",
            "summary": "fix schema compat",
            "message": "fix schema compat\n",
            "diff": {
                "parquet-column/src/main/java/parquet/column/page/Page.java": 3,
                "parquet-column/src/main/java/parquet/io/ColumnIOFactory.java": 45,
                "parquet-column/src/test/java/parquet/io/TestColumnIO.java": 2
            },
            "is_test": true,
            "is_fix": false
        },
        "18122b433e6301d6c1ca61148102c8e964ee21f3": {
            "datetime": "2013-07-02T18:26:13-07:00",
            "summary": "Merge branch 'master' into schema_compatibility",
            "message": "Merge branch 'master' into schema_compatibility\n",
            "diff": {
                "parquet-column/src/main/java/parquet/column/Encoding.java": 4,
                "parquet-column/src/main/java/parquet/column/impl/ColumnWriterImpl.java": 24
            },
            "is_test": false,
            "is_fix": false
        },
        "3afe6477da895f394bb34f5d3195102b1cbf1e2e": {
            "datetime": "2013-07-02T18:38:06-07:00",
            "summary": "Merge pull request #75 from Parquet/schema_compatibility",
            "message": "Merge pull request #75 from Parquet/schema_compatibility\n\nSchema compatibility fix",
            "diff": {
                "parquet-column/src/main/java/parquet/column/page/Page.java": 3,
                "parquet-column/src/main/java/parquet/io/ColumnIOFactory.java": 45,
                "parquet-column/src/test/java/parquet/io/TestColumnIO.java": 2
            },
            "is_test": true,
            "is_fix": false
        },
        "992a47e512a077ac95fcb265e7ee05236a788f6e": {
            "datetime": "2013-07-03T09:31:39-07:00",
            "summary": "fix call to converter",
            "message": "fix call to converter\n",
            "diff": {
                "parquet-column/src/main/java/parquet/column/impl/ColumnReaderImpl.java": 2
            },
            "is_test": false,
            "is_fix": false
        },
        "5fc67280aa0d58a4ad1ff4c31d320d215f092695": {
            "datetime": "2013-07-03T14:18:28-07:00",
            "summary": "Merge pull request #74 from Parquet/fix_dictionary_decoding",
            "message": "Merge pull request #74 from Parquet/fix_dictionary_decoding\n\nfix dictionary decoding bug when more than one encoding is used",
            "diff": {
                "parquet-column/src/main/java/parquet/column/Encoding.java": 12,
                "parquet-column/src/main/java/parquet/column/impl/ColumnReaderImpl.java": 12
            },
            "is_test": false,
            "is_fix": false
        },
        "c4b14fbc4d20034596ad56825349976e4805f456": {
            "datetime": "2013-07-06T15:05:15+01:00",
            "summary": "Adding APL headers and test for union schema creation.",
            "message": "Adding APL headers and test for union schema creation.\n",
            "diff": {
                "parquet-avro/src/test/java/parquet/avro/TestAvroSchemaConverter.java": 22,
                "parquet-avro/src/test/java/parquet/avro/TestSpecificReadWrite.java": 15,
                "parquet-column/src/main/java/parquet/Ints.java": 15,
                "parquet-column/src/main/java/parquet/column/values/rle/RunLengthBitPackingHybridEncoder.java": 15,
                "parquet-column/src/main/java/parquet/column/values/rle/RunLengthBitPackingHybridValuesReader.java": 15,
                "parquet-column/src/main/java/parquet/column/values/rle/RunLengthBitPackingHybridValuesWriter.java": 15,
                "parquet-column/src/main/java/parquet/filter/AndRecordFilter.java": 15,
                "parquet-column/src/main/java/parquet/filter/ColumnPredicates.java": 15,
                "parquet-column/src/main/java/parquet/filter/ColumnRecordFilter.java": 15,
                "parquet-column/src/main/java/parquet/filter/PagedRecordFilter.java": 15,
                "parquet-column/src/main/java/parquet/filter/RecordFilter.java": 15,
                "parquet-column/src/main/java/parquet/filter/UnboundRecordFilter.java": 15,
                "parquet-column/src/main/java/parquet/io/FilteredRecordReader.java": 15,
                "parquet-column/src/test/java/parquet/column/values/bitpacking/TestByteBasedBitPackingEncoder.java": 15,
                "parquet-column/src/test/java/parquet/column/values/rle/RunLengthBitPackingHybridIntegrationTest.java": 15,
                "parquet-column/src/test/java/parquet/column/values/rle/TestRunLengthBitPackingHybridEncoder.java": 15,
                "parquet-column/src/test/java/parquet/io/TestFiltered.java": 15,
                "parquet-hadoop/src/main/java/parquet/hadoop/codec/SnappyCodec.java": 15,
                "parquet-hadoop/src/main/java/parquet/hadoop/codec/SnappyCompressor.java": 15,
                "parquet-hadoop/src/main/java/parquet/hadoop/codec/SnappyDecompressor.java": 15,
                "parquet-hadoop/src/main/java/parquet/hadoop/codec/SnappyUtil.java": 15,
                "parquet-hadoop/src/test/java/parquet/hadoop/TestSnappyCodec.java": 15
            },
            "is_test": true,
            "is_fix": false
        },
        "f52a26e1a32aadf4ec6713ae12ad0d5cedeca9ed": {
            "datetime": "2013-07-06T15:14:14+01:00",
            "summary": "Renamed checkValueRead.",
            "message": "Renamed checkValueRead.\n",
            "diff": {
                "parquet-column/src/main/java/parquet/column/impl/ColumnReaderImpl.java": 20
            },
            "is_test": false,
            "is_fix": false
        },
        "80a449d1c1e4212d612fdada6d1f5c6e7e622e2c": {
            "datetime": "2013-07-06T15:40:23+01:00",
            "summary": "Updated from master",
            "message": "Updated from master\n",
            "diff": {
                "parquet-avro/src/test/java/parquet/avro/TestSpecificReadWrite.java": 12,
                "parquet-column/src/main/java/parquet/column/Encoding.java": 16,
                "parquet-column/src/main/java/parquet/column/impl/ColumnReaderImpl.java": 12,
                "parquet-column/src/main/java/parquet/column/impl/ColumnWriterImpl.java": 24,
                "parquet-column/src/main/java/parquet/column/page/Page.java": 3,
                "parquet-column/src/main/java/parquet/io/ColumnIOFactory.java": 89,
                "parquet-column/src/main/java/parquet/schema/Type.java": 25,
                "parquet-column/src/test/java/parquet/io/TestColumnIO.java": 123,
                "parquet-hadoop/src/main/java/parquet/hadoop/ParquetInputFormat.java": 1,
                "parquet-hadoop/src/main/java/parquet/hadoop/ParquetInputSplit.java": 15,
                "parquet-hadoop/src/main/java/parquet/hadoop/ParquetReader.java": 1,
                "parquet-hadoop/src/main/java/parquet/hadoop/ParquetRecordReader.java": 16
            },
            "is_test": true,
            "is_fix": false
        },
        "caa8e5113f56af3e186925668da2a78dc8640380": {
            "datetime": "2013-07-08T12:44:40-07:00",
            "summary": "split Plain reader so that the reader knows what type it's reading",
            "message": "split Plain reader so that the reader knows what type it's reading\n",
            "diff": {
                "parquet-column/src/main/java/parquet/column/Encoding.java": 15,
                "parquet-column/src/main/java/parquet/column/values/plain/DoublePlainValuesReader.java": 39,
                "parquet-column/src/main/java/parquet/column/values/plain/FloatPlainValuesReader.java": 39,
                "parquet-column/src/main/java/parquet/column/values/plain/IntegerPlainValuesReader.java": 39,
                "parquet-column/src/main/java/parquet/column/values/plain/LongPlainValuesReader.java": 39,
                "parquet-column/src/main/java/parquet/column/values/plain/PlainValuesReader.java": 39
            },
            "is_test": false,
            "is_fix": false
        },
        "653a4cf53bd9ed4fd4002c8f5d87a11577747a6d": {
            "datetime": "2013-07-08T15:08:22-07:00",
            "summary": "collapse small classes into one class",
            "message": "collapse small classes into one class\n",
            "diff": {
                "parquet-column/src/main/java/parquet/column/Encoding.java": 8,
                "parquet-column/src/main/java/parquet/column/values/plain/DoublePlainValuesReader.java": 39,
                "parquet-column/src/main/java/parquet/column/values/plain/FloatPlainValuesReader.java": 39,
                "parquet-column/src/main/java/parquet/column/values/plain/IntegerPlainValuesReader.java": 39,
                "parquet-column/src/main/java/parquet/column/values/plain/LongPlainValuesReader.java": 39,
                "parquet-column/src/main/java/parquet/column/values/plain/PlainValuesReader.java": 46
            },
            "is_test": false,
            "is_fix": false
        },
        "89d6b171f1d45bac178fb638da63a85004d68086": {
            "datetime": "2013-07-09T08:54:39-07:00",
            "summary": "refactored bit packing",
            "message": "refactored bit packing\n",
            "diff": {
                "parquet-column/src/main/java/parquet/Ints.java": 15,
                "parquet-column/src/main/java/parquet/Log.java": 0,
                "parquet-column/src/main/java/parquet/ParquetRuntimeException.java": 0,
                "parquet-column/src/main/java/parquet/Preconditions.java": 0,
                "parquet-column/src/main/java/parquet/Version.java": 0,
                "parquet-column/src/main/java/parquet/bytes/BytesInput.java": 1,
                "parquet-column/src/main/java/parquet/bytes/BytesUtils.java": 0,
                "parquet-column/src/main/java/parquet/bytes/CapacityByteArrayOutputStream.java": 0,
                "parquet-column/src/main/java/parquet/bytes/LittleEndianDataInputStream.java": 0,
                "parquet-column/src/main/java/parquet/bytes/LittleEndianDataOutputStream.java": 0,
                "parquet-column/src/main/java/parquet/column/Encoding.java": 1,
                "parquet-column/src/main/java/parquet/column/impl/ColumnReaderImpl.java": 2,
                "parquet-column/src/main/java/parquet/column/impl/ColumnWriterImpl.java": 7,
                "parquet-column/src/main/java/parquet/column/page/Page.java": 3,
                "parquet-column/src/main/java/parquet/column/values/ValuesType.java": 2,
                "parquet-column/src/main/java/parquet/column/values/bitpacking/BitPacking.java": 0,
                "parquet-column/src/main/java/parquet/column/values/bitpacking/ByteBasedBitPackingEncoder.java": 0,
                "parquet-column/src/main/java/parquet/column/values/bitpacking/ByteBasedBitPackingGenerator.java": 22,
                "parquet-column/src/main/java/parquet/column/values/bitpacking/ByteBitPackingBE.java": 25636,
                "parquet-column/src/main/java/parquet/column/values/bitpacking/ByteBitPackingLE.java": 25636,
                "parquet-column/src/main/java/parquet/column/values/bitpacking/BytePacker.java": 0,
                "parquet-column/src/main/java/parquet/column/values/bitpacking/IntBasedBitPackingGenerator.java": 22,
                "parquet-column/src/main/java/parquet/column/values/bitpacking/IntPacker.java": 0,
                "parquet-column/src/main/java/parquet/column/values/bitpacking/LemireBitPackingBE.java": 3353,
                "parquet-column/src/main/java/parquet/column/values/bitpacking/LemireBitPackingLE.java": 3352,
                "parquet-column/src/main/java/parquet/column/values/bitpacking/Packer.java": 67,
                "parquet-column/src/main/java/parquet/column/values/dictionary/PlainBinaryDictionary.java": 1,
                "parquet-column/src/main/java/parquet/column/values/rle/RunLengthBitPackingHybridDecoder.java": 4,
                "parquet-column/src/main/java/parquet/column/values/rle/RunLengthBitPackingHybridEncoder.java": 19,
                "parquet-column/src/main/java/parquet/column/values/rle/RunLengthBitPackingHybridValuesReader.java": 16,
                "parquet-column/src/main/java/parquet/column/values/rle/RunLengthBitPackingHybridValuesWriter.java": 15,
                "parquet-column/src/main/java/parquet/example/data/simple/BinaryValue.java": 1,
                "parquet-column/src/main/java/parquet/schema/Type.java": 1,
                "parquet-column/src/test/java/parquet/TestLog.java": 0,
                "parquet-column/src/test/java/parquet/bytes/TestBytesUtil.java": 0,
                "parquet-column/src/test/java/parquet/bytes/TestCapacityByteArrayOutputStream.java": 0,
                "parquet-column/src/test/java/parquet/column/values/bitpacking/TestBitPacking.java": 0,
                "parquet-column/src/test/java/parquet/column/values/bitpacking/TestByteBasedBitPackingEncoder.java": 22,
                "parquet-column/src/test/java/parquet/column/values/bitpacking/TestByteBitPacking.java": 4,
                "parquet-column/src/test/java/parquet/column/values/bitpacking/TestLemireBitPacking.java": 2,
                "parquet-column/src/test/java/parquet/column/values/rle/RunLengthBitPackingHybridIntegrationTest.java": 15,
                "parquet-column/src/test/java/parquet/column/values/rle/TestRunLengthBitPackingHybridEncoder.java": 23,
                "parquet-encoding/src/main/java/parquet/column/values/bitpacking/BytePackerFactory.java": 22,
                "parquet-encoding/src/main/java/parquet/column/values/bitpacking/IntPackerFactory.java": 22,
                "parquet-encoding/src/main/java/parquet/column/values/bitpacking/Packer.java": 96,
                "parquet-encoding/src/test/java/parquet/column/values/bitpacking/TestByteBasedBitPackingEncoder.java": 37,
                "parquet-generator/src/main/java/parquet/encoding/Generator.java": 34,
                "parquet-hadoop/src/main/java/parquet/hadoop/codec/SnappyCodec.java": 15,
                "parquet-hadoop/src/main/java/parquet/hadoop/codec/SnappyCompressor.java": 15,
                "parquet-hadoop/src/main/java/parquet/hadoop/codec/SnappyDecompressor.java": 15,
                "parquet-hadoop/src/main/java/parquet/hadoop/codec/SnappyUtil.java": 15,
                "parquet-hadoop/src/test/java/parquet/hadoop/TestSnappyCodec.java": 15
            },
            "is_test": true,
            "is_fix": false
        },
        "f1da1c71ef4cb270368530a1c899c6802790a99d": {
            "datetime": "2013-07-09T11:49:54-07:00",
            "summary": "Merge pull request #79 from Parquet/split_plain_reader",
            "message": "Merge pull request #79 from Parquet/split_plain_reader\n\nsplit Plain reader so that the reader knows what type it's reading",
            "diff": {
                "parquet-column/src/main/java/parquet/column/Encoding.java": 15,
                "parquet-column/src/main/java/parquet/column/values/plain/PlainValuesReader.java": 83
            },
            "is_test": false,
            "is_fix": false
        },
        "806b548153532021d80de45741e51e0d2622f3e3": {
            "datetime": "2013-07-10T10:23:42-07:00",
            "summary": "fix for schema compatibility",
            "message": "fix for schema compatibility\n",
            "diff": {
                "parquet-column/src/main/java/parquet/io/ColumnIOFactory.java": 4,
                "parquet-column/src/main/java/parquet/io/GroupColumnIO.java": 4
            },
            "is_test": false,
            "is_fix": false
        },
        "33c8dc5d1cb56710f3e7ec2f58255ef86c39ebe9": {
            "datetime": "2013-07-10T10:30:49-07:00",
            "summary": "Merge pull request #81 from Parquet/fix_schema_compatibility",
            "message": "Merge pull request #81 from Parquet/fix_schema_compatibility\n\nfix for schema compatibility",
            "diff": {
                "parquet-column/src/main/java/parquet/io/ColumnIOFactory.java": 4,
                "parquet-column/src/main/java/parquet/io/GroupColumnIO.java": 4
            },
            "is_test": false,
            "is_fix": false
        },
        "43dc88d41e345cfd5eb2c4e62dfa0cca183bdf4e": {
            "datetime": "2013-07-11T16:10:48+01:00",
            "summary": "adding projection support for thrift types",
            "message": "adding projection support for thrift types\n",
            "diff": {
                "parquet-hadoop/src/main/java/parquet/hadoop/ParquetInputFormat.java": 12,
                "parquet-hadoop/src/main/java/parquet/hadoop/api/ReadSupport.java": 23,
                "parquet-thrift/src/main/java/parquet/hadoop/thrift/ThriftReadSupport.java": 10,
                "parquet-thrift/src/main/java/parquet/thrift/ThriftRecordConverter.java": 25,
                "parquet-thrift/src/test/java/parquet/hadoop/thrift/TestParquetToThriftReadProjection.java": 123
            },
            "is_test": true,
            "is_fix": false
        },
        "adb46b694e94dc906922591f439997e7246d36eb": {
            "datetime": "2013-07-11T09:27:02-07:00",
            "summary": "make splits report actual length",
            "message": "make splits report actual length\n",
            "diff": {
                "parquet-column/src/main/java/parquet/schema/GroupType.java": 8,
                "parquet-column/src/main/java/parquet/schema/MessageType.java": 4,
                "parquet-column/src/main/java/parquet/schema/PrimitiveType.java": 5,
                "parquet-column/src/main/java/parquet/schema/Type.java": 2,
                "parquet-hadoop/src/main/java/parquet/hadoop/ParquetInputFormat.java": 13,
                "parquet-hadoop/src/test/java/parquet/hadoop/TestInputFormat.java": 9
            },
            "is_test": true,
            "is_fix": false
        },
        "9a5d5978f6e645c2e581e0b7075978088b2595eb": {
            "datetime": "2013-07-11T09:28:40-07:00",
            "summary": "Merge pull request #83 from atkeano/thrift_read_projections",
            "message": "Merge pull request #83 from atkeano/thrift_read_projections\n\nProjection support for Thrift ",
            "diff": {
                "parquet-hadoop/src/main/java/parquet/hadoop/ParquetInputFormat.java": 12,
                "parquet-hadoop/src/main/java/parquet/hadoop/api/ReadSupport.java": 23,
                "parquet-thrift/src/main/java/parquet/hadoop/thrift/ThriftReadSupport.java": 10,
                "parquet-thrift/src/main/java/parquet/thrift/ThriftRecordConverter.java": 25,
                "parquet-thrift/src/test/java/parquet/hadoop/thrift/TestParquetToThriftReadProjection.java": 123
            },
            "is_test": true,
            "is_fix": false
        },
        "6bf0597970fd9421a98f2625c9ae2ee221d04acd": {
            "datetime": "2013-07-11T09:29:06-07:00",
            "summary": "Merge pull request #80 from Parquet/encodings",
            "message": "Merge pull request #80 from Parquet/encodings\n\ncreate an encodings module to facilitate encoding sharing",
            "diff": {
                "parquet-column/src/main/java/parquet/Ints.java": 15,
                "parquet-column/src/main/java/parquet/Log.java": 0,
                "parquet-column/src/main/java/parquet/ParquetRuntimeException.java": 0,
                "parquet-column/src/main/java/parquet/Preconditions.java": 0,
                "parquet-column/src/main/java/parquet/Version.java": 0,
                "parquet-column/src/main/java/parquet/bytes/BytesInput.java": 1,
                "parquet-column/src/main/java/parquet/bytes/BytesUtils.java": 0,
                "parquet-column/src/main/java/parquet/bytes/CapacityByteArrayOutputStream.java": 0,
                "parquet-column/src/main/java/parquet/bytes/LittleEndianDataInputStream.java": 0,
                "parquet-column/src/main/java/parquet/bytes/LittleEndianDataOutputStream.java": 0,
                "parquet-column/src/main/java/parquet/column/Encoding.java": 1,
                "parquet-column/src/main/java/parquet/column/impl/ColumnReaderImpl.java": 2,
                "parquet-column/src/main/java/parquet/column/impl/ColumnWriterImpl.java": 7,
                "parquet-column/src/main/java/parquet/column/page/Page.java": 3,
                "parquet-column/src/main/java/parquet/column/values/ValuesType.java": 2,
                "parquet-column/src/main/java/parquet/column/values/bitpacking/BitPacking.java": 0,
                "parquet-column/src/main/java/parquet/column/values/bitpacking/ByteBasedBitPackingEncoder.java": 0,
                "parquet-column/src/main/java/parquet/column/values/bitpacking/ByteBasedBitPackingGenerator.java": 22,
                "parquet-column/src/main/java/parquet/column/values/bitpacking/ByteBitPackingBE.java": 25636,
                "parquet-column/src/main/java/parquet/column/values/bitpacking/ByteBitPackingLE.java": 25636,
                "parquet-column/src/main/java/parquet/column/values/bitpacking/BytePacker.java": 0,
                "parquet-column/src/main/java/parquet/column/values/bitpacking/IntBasedBitPackingGenerator.java": 22,
                "parquet-column/src/main/java/parquet/column/values/bitpacking/IntPacker.java": 0,
                "parquet-column/src/main/java/parquet/column/values/bitpacking/LemireBitPackingBE.java": 3353,
                "parquet-column/src/main/java/parquet/column/values/bitpacking/LemireBitPackingLE.java": 3352,
                "parquet-column/src/main/java/parquet/column/values/bitpacking/Packer.java": 67,
                "parquet-column/src/main/java/parquet/column/values/dictionary/PlainBinaryDictionary.java": 1,
                "parquet-column/src/main/java/parquet/column/values/rle/RunLengthBitPackingHybridDecoder.java": 4,
                "parquet-column/src/main/java/parquet/column/values/rle/RunLengthBitPackingHybridEncoder.java": 19,
                "parquet-column/src/main/java/parquet/column/values/rle/RunLengthBitPackingHybridValuesReader.java": 16,
                "parquet-column/src/main/java/parquet/column/values/rle/RunLengthBitPackingHybridValuesWriter.java": 15,
                "parquet-column/src/main/java/parquet/example/data/simple/BinaryValue.java": 1,
                "parquet-column/src/main/java/parquet/schema/Type.java": 1,
                "parquet-column/src/test/java/parquet/TestLog.java": 0,
                "parquet-column/src/test/java/parquet/bytes/TestBytesUtil.java": 0,
                "parquet-column/src/test/java/parquet/bytes/TestCapacityByteArrayOutputStream.java": 0,
                "parquet-column/src/test/java/parquet/column/values/bitpacking/TestBitPacking.java": 0,
                "parquet-column/src/test/java/parquet/column/values/bitpacking/TestByteBasedBitPackingEncoder.java": 22,
                "parquet-column/src/test/java/parquet/column/values/bitpacking/TestByteBitPacking.java": 4,
                "parquet-column/src/test/java/parquet/column/values/bitpacking/TestLemireBitPacking.java": 2,
                "parquet-column/src/test/java/parquet/column/values/rle/RunLengthBitPackingHybridIntegrationTest.java": 15,
                "parquet-column/src/test/java/parquet/column/values/rle/TestRunLengthBitPackingHybridEncoder.java": 23,
                "parquet-encoding/src/main/java/parquet/column/values/bitpacking/BytePackerFactory.java": 22,
                "parquet-encoding/src/main/java/parquet/column/values/bitpacking/IntPackerFactory.java": 22,
                "parquet-encoding/src/main/java/parquet/column/values/bitpacking/Packer.java": 96,
                "parquet-encoding/src/test/java/parquet/column/values/bitpacking/TestByteBasedBitPackingEncoder.java": 37,
                "parquet-generator/src/main/java/parquet/encoding/Generator.java": 34,
                "parquet-hadoop/src/main/java/parquet/hadoop/codec/SnappyCodec.java": 15,
                "parquet-hadoop/src/main/java/parquet/hadoop/codec/SnappyCompressor.java": 15,
                "parquet-hadoop/src/main/java/parquet/hadoop/codec/SnappyDecompressor.java": 15,
                "parquet-hadoop/src/main/java/parquet/hadoop/codec/SnappyUtil.java": 15,
                "parquet-hadoop/src/test/java/parquet/hadoop/TestSnappyCodec.java": 15
            },
            "is_test": true,
            "is_fix": false
        },
        "6030c9ec92049c9cc883e6fe2ad54e1fda1b0ab2": {
            "datetime": "2013-07-11T10:23:54-07:00",
            "summary": "Merge pull request #84 from Parquet/splits_report_actual_length",
            "message": "Merge pull request #84 from Parquet/splits_report_actual_length\n\nmake splits report actual length",
            "diff": {
                "parquet-column/src/main/java/parquet/schema/GroupType.java": 8,
                "parquet-column/src/main/java/parquet/schema/MessageType.java": 4,
                "parquet-column/src/main/java/parquet/schema/PrimitiveType.java": 5,
                "parquet-column/src/main/java/parquet/schema/Type.java": 2,
                "parquet-hadoop/src/main/java/parquet/hadoop/ParquetInputFormat.java": 13,
                "parquet-hadoop/src/test/java/parquet/hadoop/TestInputFormat.java": 9
            },
            "is_test": true,
            "is_fix": false
        },
        "4de27444249d45f9fd4e57297f04025b66609ea1": {
            "datetime": "2013-07-11T10:54:00-07:00",
            "summary": "fix bad merge",
            "message": "fix bad merge\n",
            "diff": {
                "parquet-hadoop/src/main/java/parquet/hadoop/ParquetInputFormat.java": 2
            },
            "is_test": false,
            "is_fix": false
        },
        "79a310624f843cdcd59dd27aa41ec72c8527d8b6": {
            "datetime": "2013-07-11T11:35:25-07:00",
            "summary": "reduce memory usage of metadata",
            "message": "reduce memory usage of metadata\n",
            "diff": {
                "parquet-hadoop/src/main/java/parquet/format/converter/ParquetMetadataConverter.java": 87
            },
            "is_test": false,
            "is_fix": false
        },
        "fc56631a84c4dfe20300698153a86a53cc6af603": {
            "datetime": "2013-07-11T14:58:19-07:00",
            "summary": "Initial checkin for load pushdown",
            "message": "Initial checkin for load pushdown\n",
            "diff": {
                "parquet-hadoop/src/main/java/parquet/hadoop/ParquetInputFormat.java": 70,
                "parquet-pig/src/main/java/parquet/pig/ParquetLoader.java": 82,
                "parquet-pig/src/test/java/parquet/pig/TestParquetLoader.java": 49
            },
            "is_test": true,
            "is_fix": false
        },
        "5214a653c0aad2bd2dea023a2aaf9b5fc1295bc3": {
            "datetime": "2013-07-11T16:09:19-07:00",
            "summary": "minor fixes and refactor",
            "message": "minor fixes and refactor\n",
            "diff": {
                "parquet-pig/src/main/java/parquet/pig/ParquetLoader.java": 18,
                "parquet-pig/src/main/java/parquet/pig/TupleReadSupport.java": 17
            },
            "is_test": false,
            "is_fix": false
        },
        "64814a6e48f2f68a0f7b7bb6f3ff0deb7fe8007a": {
            "datetime": "2013-07-11T21:38:04-07:00",
            "summary": "make fields final",
            "message": "make fields final\n",
            "diff": {
                "parquet-hadoop/src/main/java/parquet/format/converter/ParquetMetadataConverter.java": 4
            },
            "is_test": false,
            "is_fix": false
        },
        "80e72a5af3ba300e4ff880c6468b29f1e08b7e5f": {
            "datetime": "2013-07-11T22:10:22-07:00",
            "summary": "Merge pull request #85 from Parquet/reduce_memory_usage_of_metadata",
            "message": "Merge pull request #85 from Parquet/reduce_memory_usage_of_metadata\n\nreduce memory usage of metadata",
            "diff": {
                "parquet-hadoop/src/main/java/parquet/format/converter/ParquetMetadataConverter.java": 87
            },
            "is_test": false,
            "is_fix": false
        },
        "feecf58ff8c992ba0ebbaad688e427de8cec93ef": {
            "datetime": "2013-07-12T15:19:03-07:00",
            "summary": "adding tests and removing comments",
            "message": "adding tests and removing comments\n",
            "diff": {
                "parquet-pig/src/main/java/parquet/pig/ParquetLoader.java": 4,
                "parquet-pig/src/main/java/parquet/pig/TupleReadSupport.java": 2,
                "parquet-pig/src/test/java/parquet/pig/TestParquetLoader.java": 179
            },
            "is_test": true,
            "is_fix": false
        },
        "ef2aa8e526bf724a8308703495dfa0b240921ed3": {
            "datetime": "2013-07-12T21:31:22-07:00",
            "summary": "Merge branch 'master' into filtered_reader",
            "message": "Merge branch 'master' into filtered_reader\n\nConflicts:\n\tparquet-column/src/main/java/parquet/column/values/plain/PlainValuesReader.java\n\tparquet-column/src/test/java/parquet/column/values/bitpacking/TestByteBasedBitPackingEncoder.java\n",
            "diff": {
                "parquet-column/src/main/java/parquet/Ints.java": 0,
                "parquet-column/src/main/java/parquet/Log.java": 0,
                "parquet-column/src/main/java/parquet/ParquetRuntimeException.java": 0,
                "parquet-column/src/main/java/parquet/Preconditions.java": 0,
                "parquet-column/src/main/java/parquet/Version.java": 0,
                "parquet-column/src/main/java/parquet/bytes/BytesInput.java": 1,
                "parquet-column/src/main/java/parquet/bytes/BytesUtils.java": 0,
                "parquet-column/src/main/java/parquet/bytes/CapacityByteArrayOutputStream.java": 0,
                "parquet-column/src/main/java/parquet/bytes/LittleEndianDataInputStream.java": 0,
                "parquet-column/src/main/java/parquet/bytes/LittleEndianDataOutputStream.java": 0,
                "parquet-column/src/main/java/parquet/column/Encoding.java": 16,
                "parquet-column/src/main/java/parquet/column/impl/ColumnReaderImpl.java": 17,
                "parquet-column/src/main/java/parquet/column/impl/ColumnWriterImpl.java": 7,
                "parquet-column/src/main/java/parquet/column/page/Page.java": 3,
                "parquet-column/src/main/java/parquet/column/values/ValuesReader.java": 41,
                "parquet-column/src/main/java/parquet/column/values/ValuesType.java": 2,
                "parquet-column/src/main/java/parquet/column/values/bitpacking/BitPacking.java": 0,
                "parquet-column/src/main/java/parquet/column/values/bitpacking/BitPackingValuesReader.java": 5,
                "parquet-column/src/main/java/parquet/column/values/bitpacking/ByteBasedBitPackingEncoder.java": 0,
                "parquet-column/src/main/java/parquet/column/values/bitpacking/ByteBasedBitPackingGenerator.java": 22,
                "parquet-column/src/main/java/parquet/column/values/bitpacking/ByteBitPackingBE.java": 25636,
                "parquet-column/src/main/java/parquet/column/values/bitpacking/ByteBitPackingLE.java": 25636,
                "parquet-column/src/main/java/parquet/column/values/bitpacking/ByteBitPackingValuesReader.java": 5,
                "parquet-column/src/main/java/parquet/column/values/bitpacking/BytePacker.java": 0,
                "parquet-column/src/main/java/parquet/column/values/bitpacking/IntBasedBitPackingGenerator.java": 22,
                "parquet-column/src/main/java/parquet/column/values/bitpacking/IntPacker.java": 0,
                "parquet-column/src/main/java/parquet/column/values/bitpacking/LemireBitPackingBE.java": 3353,
                "parquet-column/src/main/java/parquet/column/values/bitpacking/LemireBitPackingLE.java": 3352,
                "parquet-column/src/main/java/parquet/column/values/bitpacking/Packer.java": 67,
                "parquet-column/src/main/java/parquet/column/values/boundedint/BoundedIntValuesReader.java": 5,
                "parquet-column/src/main/java/parquet/column/values/boundedint/ZeroIntegerValuesReader.java": 4,
                "parquet-column/src/main/java/parquet/column/values/dictionary/DictionaryValuesReader.java": 2,
                "parquet-column/src/main/java/parquet/column/values/dictionary/PlainBinaryDictionary.java": 1,
                "parquet-column/src/main/java/parquet/column/values/plain/BinaryPlainValuesReader.java": 2,
                "parquet-column/src/main/java/parquet/column/values/plain/BooleanPlainValuesReader.java": 2,
                "parquet-column/src/main/java/parquet/column/values/plain/PlainValuesReader.java": 163,
                "parquet-column/src/main/java/parquet/column/values/rle/RunLengthBitPackingHybridDecoder.java": 4,
                "parquet-column/src/main/java/parquet/column/values/rle/RunLengthBitPackingHybridEncoder.java": 4,
                "parquet-column/src/main/java/parquet/column/values/rle/RunLengthBitPackingHybridValuesReader.java": 6,
                "parquet-column/src/main/java/parquet/example/data/simple/BinaryValue.java": 1,
                "parquet-column/src/main/java/parquet/io/ColumnIOFactory.java": 4,
                "parquet-column/src/main/java/parquet/io/GroupColumnIO.java": 4,
                "parquet-column/src/main/java/parquet/schema/GroupType.java": 8,
                "parquet-column/src/main/java/parquet/schema/MessageType.java": 4,
                "parquet-column/src/main/java/parquet/schema/PrimitiveType.java": 5,
                "parquet-column/src/main/java/parquet/schema/Type.java": 3,
                "parquet-column/src/test/java/parquet/TestLog.java": 0,
                "parquet-column/src/test/java/parquet/bytes/TestBytesUtil.java": 0,
                "parquet-column/src/test/java/parquet/bytes/TestCapacityByteArrayOutputStream.java": 0,
                "parquet-column/src/test/java/parquet/column/values/bitpacking/TestBitPacking.java": 0,
                "parquet-column/src/test/java/parquet/column/values/bitpacking/TestByteBasedBitPackingEncoder.java": 0,
                "parquet-column/src/test/java/parquet/column/values/bitpacking/TestByteBitPacking.java": 4,
                "parquet-column/src/test/java/parquet/column/values/bitpacking/TestLemireBitPacking.java": 2,
                "parquet-column/src/test/java/parquet/column/values/rle/TestRunLengthBitPackingHybridEncoder.java": 8,
                "parquet-encoding/src/main/java/parquet/column/values/bitpacking/BytePackerFactory.java": 22,
                "parquet-encoding/src/main/java/parquet/column/values/bitpacking/IntPackerFactory.java": 22,
                "parquet-encoding/src/main/java/parquet/column/values/bitpacking/Packer.java": 96,
                "parquet-generator/src/main/java/parquet/encoding/Generator.java": 34,
                "parquet-hadoop/src/main/java/parquet/format/converter/ParquetMetadataConverter.java": 87,
                "parquet-hadoop/src/main/java/parquet/hadoop/ParquetInputFormat.java": 23,
                "parquet-hadoop/src/main/java/parquet/hadoop/api/ReadSupport.java": 23,
                "parquet-hadoop/src/test/java/parquet/hadoop/TestInputFormat.java": 9,
                "parquet-thrift/src/main/java/parquet/hadoop/thrift/ThriftReadSupport.java": 10,
                "parquet-thrift/src/main/java/parquet/thrift/ThriftRecordConverter.java": 25,
                "parquet-thrift/src/test/java/parquet/hadoop/thrift/TestParquetToThriftReadProjection.java": 123
            },
            "is_test": true,
            "is_fix": false
        },
        "7e31eecc65f5328049373add2dd41def4d2caad8": {
            "datetime": "2013-07-12T21:42:58-07:00",
            "summary": "Merge pull request #89 from Parquet/filtered_reader",
            "message": "Merge pull request #89 from Parquet/filtered_reader\n\nFiltered Reader Implementation, Avro Specific Support",
            "diff": {
                "parquet-avro/src/main/java/parquet/avro/AvroGenericRecordConverter.java": 99,
                "parquet-avro/src/main/java/parquet/avro/AvroParquetInputFormat.java": 4,
                "parquet-avro/src/main/java/parquet/avro/AvroParquetOutputFormat.java": 4,
                "parquet-avro/src/main/java/parquet/avro/AvroParquetReader.java": 9,
                "parquet-avro/src/main/java/parquet/avro/AvroParquetWriter.java": 30,
                "parquet-avro/src/main/java/parquet/avro/AvroReadSupport.java": 10,
                "parquet-avro/src/main/java/parquet/avro/AvroRecordMaterializer.java": 10,
                "parquet-avro/src/main/java/parquet/avro/AvroSchemaConverter.java": 42,
                "parquet-avro/src/main/java/parquet/avro/AvroWriteSupport.java": 50,
                "parquet-avro/src/test/java/parquet/avro/TestAvroSchemaConverter.java": 25,
                "parquet-avro/src/test/java/parquet/avro/TestSpecificReadWrite.java": 180,
                "parquet-column/src/main/java/parquet/column/ColumnReader.java": 10,
                "parquet-column/src/main/java/parquet/column/impl/ColumnReaderImpl.java": 76,
                "parquet-column/src/main/java/parquet/column/values/ValuesReader.java": 4,
                "parquet-column/src/main/java/parquet/column/values/bitpacking/BitPackingValuesReader.java": 5,
                "parquet-column/src/main/java/parquet/column/values/bitpacking/ByteBitPackingValuesReader.java": 5,
                "parquet-column/src/main/java/parquet/column/values/boundedint/BoundedIntValuesReader.java": 5,
                "parquet-column/src/main/java/parquet/column/values/boundedint/ZeroIntegerValuesReader.java": 4,
                "parquet-column/src/main/java/parquet/column/values/dictionary/DictionaryValuesReader.java": 8,
                "parquet-column/src/main/java/parquet/column/values/plain/BinaryPlainValuesReader.java": 12,
                "parquet-column/src/main/java/parquet/column/values/plain/BooleanPlainValuesReader.java": 8,
                "parquet-column/src/main/java/parquet/column/values/plain/PlainValuesReader.java": 44,
                "parquet-column/src/main/java/parquet/column/values/rle/RunLengthBitPackingHybridValuesReader.java": 5,
                "parquet-column/src/main/java/parquet/filter/AndRecordFilter.java": 66,
                "parquet-column/src/main/java/parquet/filter/ColumnPredicates.java": 97,
                "parquet-column/src/main/java/parquet/filter/ColumnRecordFilter.java": 80,
                "parquet-column/src/main/java/parquet/filter/PagedRecordFilter.java": 69,
                "parquet-column/src/main/java/parquet/filter/RecordFilter.java": 36,
                "parquet-column/src/main/java/parquet/filter/UnboundRecordFilter.java": 33,
                "parquet-column/src/main/java/parquet/io/FilteredRecordReader.java": 92,
                "parquet-column/src/main/java/parquet/io/MessageColumnIO.java": 17,
                "parquet-column/src/main/java/parquet/io/RecordReaderImplementation.java": 14,
                "parquet-column/src/test/java/parquet/io/TestFiltered.java": 148,
                "parquet-hadoop/src/main/java/parquet/hadoop/ParquetReader.java": 8,
                "parquet-hadoop/src/main/java/parquet/hadoop/ParquetRecordReader.java": 17
            },
            "is_test": true,
            "is_fix": false
        },
        "d8e6ba34048a1c9eeb8613aa538b976616b3a58f": {
            "datetime": "2013-07-14T22:51:56-07:00",
            "summary": "added code review changes",
            "message": "added code review changes\n",
            "diff": {
                "parquet-pig/src/main/java/parquet/pig/ParquetLoader.java": 15,
                "parquet-pig/src/main/java/parquet/pig/TupleReadSupport.java": 5,
                "parquet-pig/src/test/java/parquet/pig/TestParquetLoader.java": 155
            },
            "is_test": true,
            "is_fix": false
        },
        "5a5bb7f26efe4a31d0de99e6b4c81199752cc118": {
            "datetime": "2013-07-15T12:11:35-07:00",
            "summary": "initial commit for recursive listing",
            "message": "initial commit for recursive listing\n",
            "diff": {
                "parquet-hadoop/src/main/java/parquet/hadoop/ParquetInputFormat.java": 60
            },
            "is_test": false,
            "is_fix": false
        },
        "39217427aefa710e4543cd6e5310b84d14246453": {
            "datetime": "2013-07-15T17:09:50-07:00",
            "summary": "small fixes for hadoop2 failure",
            "message": "small fixes for hadoop2 failure\n",
            "diff": {
                "parquet-hadoop/src/main/java/parquet/hadoop/ParquetInputFormat.java": 16
            },
            "is_test": false,
            "is_fix": false
        },
        "61f2c86a40fa9904ede235f10fc02f6818504346": {
            "datetime": "2013-07-17T11:07:16-07:00",
            "summary": "add buffer to protocol pipe",
            "message": "add buffer to protocol pipe\n",
            "diff": {
                "parquet-thrift/src/main/java/parquet/hadoop/thrift/ParquetThriftBytesOutputFormat.java": 23,
                "parquet-thrift/src/main/java/parquet/hadoop/thrift/ThriftBytesWriteSupport.java": 13,
                "parquet-thrift/src/main/java/parquet/hadoop/thrift/ThriftToParquetFileWriter.java": 41,
                "parquet-thrift/src/main/java/parquet/thrift/BufferedProtocolReadToWrite.java": 257,
                "parquet-thrift/src/main/java/parquet/thrift/ProtocolPipe.java": 29,
                "parquet-thrift/src/main/java/parquet/thrift/ProtocolReadToWrite.java": 6,
                "parquet-thrift/src/test/java/parquet/thrift/TestProtocolReadToWrite.java": 17
            },
            "is_test": true,
            "is_fix": false
        },
        "c2ad76471996bf21da7860a005acc559b7e4437d": {
            "datetime": "2013-07-17T11:14:00-07:00",
            "summary": "Merge pull request #90 from aniket486/list_recursive",
            "message": "Merge pull request #90 from aniket486/list_recursive\n\nAllow ParquetInputFormat to list files recursively in a directory",
            "diff": {
                "parquet-hadoop/src/main/java/parquet/hadoop/ParquetInputFormat.java": 50
            },
            "is_test": false,
            "is_fix": false
        },
        "9f41d31a313359c6b72b5094cb717d243edd6d00": {
            "datetime": "2013-07-17T11:16:24-07:00",
            "summary": "Merge pull request #86 from aniket486/load_pushdown",
            "message": "Merge pull request #86 from aniket486/load_pushdown\n\nAdding LoadPushdown to ParquetLoader for column pruning",
            "diff": {
                "parquet-hadoop/src/main/java/parquet/hadoop/ParquetInputFormat.java": 69,
                "parquet-pig/src/main/java/parquet/pig/ParquetLoader.java": 75,
                "parquet-pig/src/main/java/parquet/pig/TupleReadSupport.java": 12,
                "parquet-pig/src/test/java/parquet/pig/TestParquetLoader.java": 35
            },
            "is_test": true,
            "is_fix": false
        },
        "02d5ed256de093ccd8a6c3705dfae6cff9ae22c6": {
            "datetime": "2013-07-17T11:24:53-07:00",
            "summary": "fix merge conflict",
            "message": "fix merge conflict\n",
            "diff": {
                "parquet-hadoop/src/main/java/parquet/hadoop/ParquetInputFormat.java": 65
            },
            "is_test": false,
            "is_fix": false
        },
        "aa0bc1396bdbbc736f062be9a07675c021380b5b": {
            "datetime": "2013-07-17T12:10:39-07:00",
            "summary": "Add Avro specific support to AvroParquet{Input,Output}Format",
            "message": "Add Avro specific support to AvroParquet{Input,Output}Format\n\nThis commit generalizes AvroIndexedRecordConverter, AvroReadSupport and\nAvroRecordMaterializer to enable Parquet to read/write Avro specific\nobjects.\n",
            "diff": {
                "parquet-avro/src/main/java/parquet/avro/AvroIndexedRecordConverter.java": 12,
                "parquet-avro/src/main/java/parquet/avro/AvroReadSupport.java": 6,
                "parquet-avro/src/main/java/parquet/avro/AvroRecordMaterializer.java": 8,
                "parquet-avro/src/test/java/parquet/avro/TestSpecificInputOutputFormat.java": 147
            },
            "is_test": true,
            "is_fix": false
        },
        "de0d0cbe83a5310b4978549475722eb6d5485906": {
            "datetime": "2013-07-17T13:30:03-07:00",
            "summary": "Merge pull request #94 from massie/avro-specific",
            "message": "Merge pull request #94 from massie/avro-specific\n\nAdd Avro specific support to AvroParquet{Input,Output}Format",
            "diff": {
                "parquet-avro/src/main/java/parquet/avro/AvroIndexedRecordConverter.java": 12,
                "parquet-avro/src/main/java/parquet/avro/AvroReadSupport.java": 6,
                "parquet-avro/src/main/java/parquet/avro/AvroRecordMaterializer.java": 8,
                "parquet-avro/src/test/java/parquet/avro/TestSpecificInputOutputFormat.java": 147
            },
            "is_test": true,
            "is_fix": false
        },
        "3f19ce3df0f46399ae8c6fead520dd27049ca3d6": {
            "datetime": "2013-07-17T13:39:08-07:00",
            "summary": "reduce size of splits",
            "message": "reduce size of splits\n",
            "diff": {
                "parquet-hadoop/src/main/java/parquet/hadoop/ParquetInputFormat.java": 22,
                "parquet-hadoop/src/main/java/parquet/hadoop/ParquetInputSplit.java": 174,
                "parquet-hadoop/src/main/java/parquet/hadoop/ParquetReader.java": 1,
                "parquet-hadoop/src/main/java/parquet/hadoop/ParquetRecordReader.java": 2,
                "parquet-hadoop/src/main/java/parquet/hadoop/metadata/BlockMetaData.java": 4,
                "parquet-hadoop/src/main/java/parquet/hadoop/metadata/ColumnChunkMetaData.java": 4
            },
            "is_test": false,
            "is_fix": false
        },
        "dd20df13934cac620a35d7161cd24fdf66653ced": {
            "datetime": "2013-07-17T15:32:32-07:00",
            "summary": "Merge pull request #87 from Parquet/reduce_size_of_split",
            "message": "Merge pull request #87 from Parquet/reduce_size_of_split\n\nreduce size of splits",
            "diff": {
                "parquet-hadoop/src/main/java/parquet/hadoop/ParquetInputFormat.java": 22,
                "parquet-hadoop/src/main/java/parquet/hadoop/ParquetInputSplit.java": 174,
                "parquet-hadoop/src/main/java/parquet/hadoop/ParquetReader.java": 1,
                "parquet-hadoop/src/main/java/parquet/hadoop/ParquetRecordReader.java": 2,
                "parquet-hadoop/src/main/java/parquet/hadoop/metadata/BlockMetaData.java": 4,
                "parquet-hadoop/src/main/java/parquet/hadoop/metadata/ColumnChunkMetaData.java": 4
            },
            "is_test": false,
            "is_fix": false
        },
        "f46bdafe245db2f6f010ff3ff56858ada695d0f3": {
            "datetime": "2013-07-17T15:37:54-07:00",
            "summary": "Merge pull request #93 from Parquet/add_buffer_to_protocol_pipe_in_master",
            "message": "Merge pull request #93 from Parquet/add_buffer_to_protocol_pipe_in_master\n\nadd buffer to protocol pipe",
            "diff": {
                "parquet-thrift/src/main/java/parquet/hadoop/thrift/ParquetThriftBytesOutputFormat.java": 23,
                "parquet-thrift/src/main/java/parquet/hadoop/thrift/ThriftBytesWriteSupport.java": 13,
                "parquet-thrift/src/main/java/parquet/hadoop/thrift/ThriftToParquetFileWriter.java": 41,
                "parquet-thrift/src/main/java/parquet/thrift/BufferedProtocolReadToWrite.java": 257,
                "parquet-thrift/src/main/java/parquet/thrift/ProtocolPipe.java": 29,
                "parquet-thrift/src/main/java/parquet/thrift/ProtocolReadToWrite.java": 6,
                "parquet-thrift/src/test/java/parquet/thrift/TestProtocolReadToWrite.java": 17
            },
            "is_test": true,
            "is_fix": false
        },
        "6b5b8b214ebb6cc8ec3f7dd521bc072e973b5378": {
            "datetime": "2013-07-19T23:27:08-07:00",
            "summary": "improve memory usage of metadata",
            "message": "improve memory usage of metadata\n",
            "diff": {
                "parquet-hadoop/src/main/java/parquet/format/converter/ParquetMetadataConverter.java": 90,
                "parquet-hadoop/src/main/java/parquet/hadoop/ColumnChunkPageReadStore.java": 2,
                "parquet-hadoop/src/main/java/parquet/hadoop/ParquetFileReader.java": 9,
                "parquet-hadoop/src/main/java/parquet/hadoop/ParquetFileWriter.java": 34,
                "parquet-hadoop/src/main/java/parquet/hadoop/ParquetInputFormat.java": 2,
                "parquet-hadoop/src/main/java/parquet/hadoop/ParquetInputSplit.java": 16,
                "parquet-hadoop/src/main/java/parquet/hadoop/PrintFooter.java": 7,
                "parquet-hadoop/src/main/java/parquet/hadoop/metadata/ColumnChunkMetaData.java": 240,
                "parquet-hadoop/src/main/java/parquet/hadoop/metadata/ColumnChunkProperties.java": 78,
                "parquet-hadoop/src/main/java/parquet/hadoop/metadata/ColumnPath.java": 61,
                "parquet-hadoop/src/main/java/parquet/hadoop/metadata/EncodingList.java": 72,
                "parquet-hadoop/src/test/java/parquet/hadoop/TestInputFormat.java": 8,
                "parquet-pig/src/main/java/parquet/pig/ParquetLoader.java": 35
            },
            "is_test": true,
            "is_fix": false
        },
        "54ac6b4098e5afebb3e404894a423cf00ef80295": {
            "datetime": "2013-07-19T23:30:11-07:00",
            "summary": "license headers",
            "message": "license headers\n",
            "diff": {
                "parquet-hadoop/src/main/java/parquet/hadoop/metadata/ColumnChunkProperties.java": 15,
                "parquet-hadoop/src/main/java/parquet/hadoop/metadata/ColumnPath.java": 15,
                "parquet-hadoop/src/main/java/parquet/hadoop/metadata/EncodingList.java": 15,
                "parquet-pig/src/test/java/parquet/pig/TestParquetLoader.java": 15
            },
            "is_test": true,
            "is_fix": false
        },
        "f7d098778fbb7b484e1f0c20f14b2260ec625a72": {
            "datetime": "2013-07-19T23:45:47-07:00",
            "summary": "fix compilation issue with 1.6",
            "message": "fix compilation issue with 1.6\n",
            "diff": {
                "parquet-pig/src/main/java/parquet/pig/ParquetLoader.java": 30
            },
            "is_test": false,
            "is_fix": false
        },
        "964e5da655a184a939eac7770f20acd4ef565ef6": {
            "datetime": "2013-07-22T10:12:26-07:00",
            "summary": "Add support for schema projection in Avro",
            "message": "Add support for schema projection in Avro\n\nThis commit updates the AvroReadSupport and AvroParquetInputFormat\nclasses to allow users to request a schema projection.\n",
            "diff": {
                "parquet-avro/src/main/java/parquet/avro/AvroIndexedRecordConverter.java": 31,
                "parquet-avro/src/main/java/parquet/avro/AvroParquetInputFormat.java": 9,
                "parquet-avro/src/main/java/parquet/avro/AvroReadSupport.java": 16,
                "parquet-avro/src/test/java/parquet/avro/TestSpecificInputOutputFormat.java": 46
            },
            "is_test": true,
            "is_fix": false
        },
        "62c3155acf4385e907c6eb4a0bb903ae1f41fdc3": {
            "datetime": "2013-07-22T13:58:27-07:00",
            "summary": "Merge pull request #96 from massie/master",
            "message": "Merge pull request #96 from massie/master\n\nAdd support for schema projection in Avro",
            "diff": {
                "parquet-avro/src/main/java/parquet/avro/AvroIndexedRecordConverter.java": 31,
                "parquet-avro/src/main/java/parquet/avro/AvroParquetInputFormat.java": 9,
                "parquet-avro/src/main/java/parquet/avro/AvroReadSupport.java": 16,
                "parquet-avro/src/test/java/parquet/avro/TestSpecificInputOutputFormat.java": 46
            },
            "is_test": true,
            "is_fix": false
        },
        "c1d67ee581df3581882efbb875d65bd063ec6d33": {
            "datetime": "2013-07-22T14:13:21-07:00",
            "summary": "Add support for predicate pushdown in ParquetInputFormat",
            "message": "Add support for predicate pushdown in ParquetInputFormat\n\nThis commit allows users to define an UnboundRecordFilter to be\nused when reading Parquet records from the ParquetInputFormat.\n",
            "diff": {
                "parquet-avro/src/test/java/parquet/avro/TestSpecificInputOutputFormat.java": 77,
                "parquet-hadoop/src/main/java/parquet/hadoop/ParquetInputFormat.java": 56,
                "parquet-hadoop/src/main/java/parquet/hadoop/util/ConfigurationUtil.java": 40
            },
            "is_test": true,
            "is_fix": false
        },
        "435b13bc8a8871c255e7a0f7f2fe2d9ec1a89254": {
            "datetime": "2013-07-22T15:09:03-07:00",
            "summary": "Merge pull request #98 from massie/matt-pushdown",
            "message": "Merge pull request #98 from massie/matt-pushdown\n\nAdd support for predicate pushdown in ParquetInputFormat",
            "diff": {
                "parquet-avro/src/test/java/parquet/avro/TestSpecificInputOutputFormat.java": 77,
                "parquet-hadoop/src/main/java/parquet/hadoop/ParquetInputFormat.java": 56,
                "parquet-hadoop/src/main/java/parquet/hadoop/util/ConfigurationUtil.java": 40
            },
            "is_test": true,
            "is_fix": false
        },
        "8c1032d889cc332a73790c5fe08499c18e519f25": {
            "datetime": "2013-07-22T16:00:43-07:00",
            "summary": "Merge pull request #97 from Parquet/improve_memory_usage_of_metadata",
            "message": "Merge pull request #97 from Parquet/improve_memory_usage_of_metadata\n\nimprove memory usage of metadata",
            "diff": {
                "parquet-hadoop/src/main/java/parquet/format/converter/ParquetMetadataConverter.java": 90,
                "parquet-hadoop/src/main/java/parquet/hadoop/ColumnChunkPageReadStore.java": 2,
                "parquet-hadoop/src/main/java/parquet/hadoop/ParquetFileReader.java": 9,
                "parquet-hadoop/src/main/java/parquet/hadoop/ParquetFileWriter.java": 34,
                "parquet-hadoop/src/main/java/parquet/hadoop/ParquetInputFormat.java": 2,
                "parquet-hadoop/src/main/java/parquet/hadoop/ParquetInputSplit.java": 16,
                "parquet-hadoop/src/main/java/parquet/hadoop/PrintFooter.java": 7,
                "parquet-hadoop/src/main/java/parquet/hadoop/metadata/ColumnChunkMetaData.java": 240,
                "parquet-hadoop/src/main/java/parquet/hadoop/metadata/ColumnChunkProperties.java": 93,
                "parquet-hadoop/src/main/java/parquet/hadoop/metadata/ColumnPath.java": 76,
                "parquet-hadoop/src/main/java/parquet/hadoop/metadata/EncodingList.java": 87,
                "parquet-hadoop/src/test/java/parquet/hadoop/TestInputFormat.java": 8,
                "parquet-pig/src/main/java/parquet/pig/ParquetLoader.java": 45,
                "parquet-pig/src/test/java/parquet/pig/TestParquetLoader.java": 15
            },
            "is_test": true,
            "is_fix": false
        },
        "bd826ec880bc2ecda69b2bfb0b89d8dbe3c08845": {
            "datetime": "2013-07-23T11:11:44+02:00",
            "summary": "Add a simple unit test for ParquetSerDe",
            "message": "Add a simple unit test for ParquetSerDe\n",
            "diff": {
                "parquet-hive/src/test/java/parquet/hive/TestParquetSerDe.java": 130
            },
            "is_test": true,
            "is_fix": false
        },
        "6c219a5f1c5a18f1d7391db20245a1981c5587c6": {
            "datetime": "2013-07-23T11:11:44+02:00",
            "summary": "Fix Short object for Hive (use short for short instead of byte :))",
            "message": "Fix Short object for Hive (use short for short instead of byte :))\n",
            "diff": {
                "parquet-hive/src/main/java/parquet/hive/serde/MapWritableObjectInspector.java": 7,
                "parquet-hive/src/main/java/parquet/hive/serde/ParquetHiveSerDe.java": 5
            },
            "is_test": false,
            "is_fix": false
        },
        "7f534d5259ff71d8c77b9fbeb4c381b4007b188b": {
            "datetime": "2013-07-23T11:11:44+02:00",
            "summary": "Implement a basic version of the SerDeStats object for ParquetHiveSerDe",
            "message": "Implement a basic version of the SerDeStats object for ParquetHiveSerDe\n",
            "diff": {
                "parquet-hive/src/main/java/parquet/hive/serde/ParquetHiveSerDe.java": 37
            },
            "is_test": false,
            "is_fix": false
        },
        "910e7cd962f2a516e353214a32cc1e5ceb910d0a": {
            "datetime": "2013-07-23T11:11:44+02:00",
            "summary": "Add equals and hashcode methods to BinaryWritable",
            "message": "Add equals and hashcode methods to BinaryWritable\n",
            "diff": {
                "parquet-hive/src/main/java/parquet/hive/writable/BinaryWritable.java": 42
            },
            "is_test": false,
            "is_fix": false
        },
        "126da3cad286d441f6638ba94ba9d201c4081231": {
            "datetime": "2013-07-23T11:11:44+02:00",
            "summary": "Give selected columns to ParquetInputFormat : Done",
            "message": "Give selected columns to ParquetInputFormat : Done\n\n - no more hack\n - works with HiveInputFormat and HiveCombine\n",
            "diff": {
                "parquet-hive/src/main/java/parquet/hive/DeprecatedParquetInputFormat.java": 27,
                "parquet-hive/src/main/java/parquet/hive/ManageJobConfig.java": 59,
                "parquet-hive/src/main/java/parquet/hive/convert/ETypeConverter.java": 17,
                "parquet-hive/src/main/java/parquet/hive/convert/MapWritableGroupConverter.java": 7,
                "parquet-hive/src/main/java/parquet/hive/read/MapWritableReadSupport.java": 13,
                "parquet-hive/src/main/java/parquet/hive/serde/MapWritableObjectInspector.java": 4,
                "parquet-hive/src/main/java/parquet/hive/serde/ParquetHiveSerDe.java": 4
            },
            "is_test": false,
            "is_fix": false
        },
        "ebf76d4dfca1e1bf6d69f0f6c64e4860452c866e": {
            "datetime": "2013-07-23T11:11:44+02:00",
            "summary": "Indentation : retab to 2 spaces. Nothing else.",
            "message": "Indentation : retab to 2 spaces. Nothing else.\n",
            "diff": {
                "parquet-hive/src/main/java/parquet/hive/DeprecatedParquetInputFormat.java": 527,
                "parquet-hive/src/main/java/parquet/hive/DeprecatedParquetOutputFormat.java": 195,
                "parquet-hive/src/main/java/parquet/hive/ManageJobConfig.java": 222,
                "parquet-hive/src/main/java/parquet/hive/convert/ArrayWritableGroupConverter.java": 95,
                "parquet-hive/src/main/java/parquet/hive/convert/ETypeConverter.java": 464,
                "parquet-hive/src/main/java/parquet/hive/convert/HiveGroupConverter.java": 36,
                "parquet-hive/src/main/java/parquet/hive/convert/HiveSchemaConverter.java": 135,
                "parquet-hive/src/main/java/parquet/hive/convert/MapWritableGroupConverter.java": 100,
                "parquet-hive/src/main/java/parquet/hive/convert/MapWritableRecordConverter.java": 25,
                "parquet-hive/src/main/java/parquet/hive/read/MapWritableReadSupport.java": 50,
                "parquet-hive/src/main/java/parquet/hive/serde/MapWritableObjectInspector.java": 246,
                "parquet-hive/src/main/java/parquet/hive/serde/ParquetHiveArrayInspector.java": 110,
                "parquet-hive/src/main/java/parquet/hive/serde/ParquetHiveMapInspector.java": 118,
                "parquet-hive/src/main/java/parquet/hive/serde/ParquetHiveSerDe.java": 334,
                "parquet-hive/src/main/java/parquet/hive/writable/BigDecimalWritable.java": 172,
                "parquet-hive/src/main/java/parquet/hive/writable/BinaryWritable.java": 52,
                "parquet-hive/src/main/java/parquet/hive/write/MapWritableWriteSupport.java": 44,
                "parquet-hive/src/main/java/parquet/hive/write/MapWritableWriter.java": 186,
                "parquet-hive/src/test/java/parquet/hive/TestHiveInputFormat.java": 156,
                "parquet-hive/src/test/java/parquet/hive/TestHiveSchemaConverter.java": 74
            },
            "is_test": true,
            "is_fix": false
        },
        "1ada3d2b48778378763985124fe66c759e288b92": {
            "datetime": "2013-07-23T11:11:44+02:00",
            "summary": "Some improvements on the hive implementation :",
            "message": "Some improvements on the hive implementation :\n\n - start to read complex type (struct done !, other in progress)\n - start to write complex type (struct done !, other maybe done :) )\n - try to give only the requested schema to parquet objects but\nwe have some troubles with the way readsupport object is initialized. Trying few\nwork around with hive to force the jobConf to be updated (like they do for\nRCFile in HiveInputFormat). Not working when getSplits is called because\nwe have no path (in progress).\n\nUnit test :\n\n - Just a start only one very very tiny small is working to test hiveschemaconverter\n - working on the SerDe testing (trying to create a parquet file first in unit test)\n\nThe code is not clean, neither optimize. 'Make it work, Make it right, Make it fast'\nonly on the first step :p\n",
            "diff": {
                "parquet-hive/src/main/java/parquet/hive/DeprecatedParquetInputFormat.java": 38,
                "parquet-hive/src/main/java/parquet/hive/DeprecatedParquetOutputFormat.java": 2,
                "parquet-hive/src/main/java/parquet/hive/ManageJobConfig.java": 77,
                "parquet-hive/src/main/java/parquet/hive/convert/ArrayWritableGroupConverter.java": 39,
                "parquet-hive/src/main/java/parquet/hive/convert/HiveGroupConverter.java": 15,
                "parquet-hive/src/main/java/parquet/hive/read/MapWritableReadSupport.java": 30,
                "parquet-hive/src/main/java/parquet/hive/serde/MapWritableObjectInspector.java": 6,
                "parquet-hive/src/main/java/parquet/hive/serde/ParquetHiveArrayInspector.java": 15,
                "parquet-hive/src/main/java/parquet/hive/serde/ParquetHiveMapInspector.java": 15,
                "parquet-hive/src/test/java/parquet/hive/TestHiveInputFormat.java": 143,
                "parquet-hive/src/test/java/parquet/hive/TestHiveOuputFormat.java": 27,
                "parquet-hive/src/test/java/parquet/hive/TestHiveSchemaConverter.java": 87
            },
            "is_test": true,
            "is_fix": false
        },
        "07e54a534ab872191a247270f281de7bdc3f803a": {
            "datetime": "2013-07-23T11:11:44+02:00",
            "summary": "rename one parameter",
            "message": "rename one parameter\n",
            "diff": {
                "parquet-hive/src/main/java/parquet/hive/convert/MapWritableRecordConverter.java": 4
            },
            "is_test": false,
            "is_fix": false
        },
        "b4d1c7149f861377e8b776f0d82a6b0a86dfd7d0": {
            "datetime": "2013-07-23T11:11:44+02:00",
            "summary": "Can read some complex types",
            "message": "Can read some complex types\n\n- Structs should be entirely good\n- Array and maps do not seem to work correctly\n",
            "diff": {
                "parquet-hive/src/main/java/parquet/hive/DeprecatedParquetInputFormat.java": 27,
                "parquet-hive/src/main/java/parquet/hive/convert/ArrayWritableGroupConverter.java": 87,
                "parquet-hive/src/main/java/parquet/hive/convert/ETypeConverter.java": 58,
                "parquet-hive/src/main/java/parquet/hive/convert/HiveGroupConverter.java": 33,
                "parquet-hive/src/main/java/parquet/hive/convert/HiveSchemaConverter.java": 38,
                "parquet-hive/src/main/java/parquet/hive/convert/MapWritableGroupConverter.java": 64,
                "parquet-hive/src/main/java/parquet/hive/convert/MapWritableRecordConverter.java": 2,
                "parquet-hive/src/main/java/parquet/hive/serde/MapWritableObjectInspector.java": 18,
                "parquet-hive/src/main/java/parquet/hive/serde/ParquetHiveArrayInspector.java": 87,
                "parquet-hive/src/main/java/parquet/hive/serde/ParquetHiveMapInspector.java": 83,
                "parquet-hive/src/main/java/parquet/hive/serde/ParquetHiveSerDe.java": 66,
                "parquet-hive/src/main/java/parquet/hive/write/MapWritableWriter.java": 79
            },
            "is_test": false,
            "is_fix": false
        },
        "4fe18c5386af73952c7c4d090ea4c5c8b9bcf85d": {
            "datetime": "2013-07-23T11:11:44+02:00",
            "summary": "Can write complex types",
            "message": "Can write complex types\n",
            "diff": {
                "parquet-hive/src/main/java/parquet/hive/convert/HiveSchemaConverter.java": 70,
                "parquet-hive/src/main/java/parquet/hive/convert/MapWritableGroupConverter.java": 7,
                "parquet-hive/src/main/java/parquet/hive/serde/MapWritableObjectInspector.java": 52,
                "parquet-hive/src/main/java/parquet/hive/serde/ParquetHiveSerDe.java": 116,
                "parquet-hive/src/main/java/parquet/hive/write/MapWritableWriteSupport.java": 1,
                "parquet-hive/src/main/java/parquet/hive/write/MapWritableWriter.java": 99
            },
            "is_test": false,
            "is_fix": false
        },
        "f5ca27b0cef7902203035319887fbe792fe36459": {
            "datetime": "2013-07-23T11:11:44+02:00",
            "summary": "Improve column reading",
            "message": "Improve column reading\n\n - Trying to only read the right column (work in progress)\n",
            "diff": {
                "parquet-hive/src/main/java/parquet/hive/DeprecatedParquetInputFormat.java": 132,
                "parquet-hive/src/main/java/parquet/hive/DeprecatedParquetOutputFormat.java": 53,
                "parquet-hive/src/main/java/parquet/hive/ManageJobConfig.java": 165,
                "parquet-hive/src/main/java/parquet/hive/convert/ETypeConverter.java": 58,
                "parquet-hive/src/main/java/parquet/hive/convert/HiveSchemaConverter.java": 46,
                "parquet-hive/src/main/java/parquet/hive/convert/MapWritableGroupConverter.java": 50,
                "parquet-hive/src/main/java/parquet/hive/convert/MapWritableRecordConverter.java": 18,
                "parquet-hive/src/main/java/parquet/hive/read/MapWritableReadSupport.java": 67,
                "parquet-hive/src/main/java/parquet/hive/serde/MapWritableObjectInspector.java": 59,
                "parquet-hive/src/main/java/parquet/hive/serde/ParquetHiveSerDe.java": 57,
                "parquet-hive/src/main/java/parquet/hive/writable/BigDecimalWritable.java": 34,
                "parquet-hive/src/main/java/parquet/hive/writable/BinaryWritable.java": 30,
                "parquet-hive/src/main/java/parquet/hive/write/MapWritableWriteSupport.java": 26,
                "parquet-hive/src/main/java/parquet/hive/write/MapWritableWriter.java": 41
            },
            "is_test": false,
            "is_fix": false
        },
        "fcc88f3e81b9b29f0bb46772f0c8f944fe531ce3": {
            "datetime": "2013-07-23T11:11:44+02:00",
            "summary": "Add support for CombineHiveInputFormat",
            "message": "Add support for CombineHiveInputFormat\n\n- This recreates the input splits by reading each file's metadata\n- This is slower than being able to get our InputSplits directly,\nbut still faster than calling getSplits over and over again\n",
            "diff": {
                "parquet-hive/src/main/java/parquet/hive/DeprecatedParquetInputFormat.java": 39
            },
            "is_test": false,
            "is_fix": false
        },
        "2471e518729a84d6800c8b7b5abf0566f5bf8bec": {
            "datetime": "2013-07-23T11:11:44+02:00",
            "summary": "Remove any K,V from DeprecatedXXFormat",
            "message": "Remove any K,V from DeprecatedXXFormat\n",
            "diff": {
                "parquet-hive/src/main/java/parquet/hive/DeprecatedParquetInputFormat.java": 29,
                "parquet-hive/src/main/java/parquet/hive/DeprecatedParquetOutputFormat.java": 38
            },
            "is_test": false,
            "is_fix": false
        },
        "c7a8eafa62be64a12a7f6f518e43733a67e6f39f": {
            "datetime": "2013-07-23T11:11:44+02:00",
            "summary": "Start implementation parquet for hive :",
            "message": "Start implementation parquet for hive :\n\n - Read simple data (INT32, INT64, DOUBLE, FLOAT, BOOLEAN, BINARY -String)\n - Write simple data (INT32, INT64, FLOAT, DOUBLE, BOOLEAN, BINARY -String)\n - Read data works only if HiveInputFormat is set (not CombineHive)\n\nTODO :\n\n - Support complex type (struct, map, array)\n - Support CombineHive\n - Unit test :)\n",
            "diff": {
                "parquet-hive/src/main/java/parquet/hive/DeprecatedParquetInputFormat.java": 347,
                "parquet-hive/src/main/java/parquet/hive/DeprecatedParquetOutputFormat.java": 177,
                "parquet-hive/src/main/java/parquet/hive/convert/ETypeConverter.java": 277,
                "parquet-hive/src/main/java/parquet/hive/convert/HiveSchemaConverter.java": 81,
                "parquet-hive/src/main/java/parquet/hive/convert/MapWritableGroupConverter.java": 94,
                "parquet-hive/src/main/java/parquet/hive/convert/MapWritableRecordConverter.java": 54,
                "parquet-hive/src/main/java/parquet/hive/read/MapWritableReadSupport.java": 48,
                "parquet-hive/src/main/java/parquet/hive/serde/MapWritableObjectInspector.java": 185,
                "parquet-hive/src/main/java/parquet/hive/serde/ParquetHiveSerDe.java": 201,
                "parquet-hive/src/main/java/parquet/hive/writable/BigDecimalWritable.java": 147,
                "parquet-hive/src/main/java/parquet/hive/writable/BinaryWritable.java": 70,
                "parquet-hive/src/main/java/parquet/hive/write/MapWritableWriteSupport.java": 67,
                "parquet-hive/src/main/java/parquet/hive/write/MapWritableWriter.java": 81
            },
            "is_test": false,
            "is_fix": false
        },
        "543cdc2c1027a858f6d431293a496014adf53bbe": {
            "datetime": "2013-07-23T11:11:45+02:00",
            "summary": "Fix the size of the value array",
            "message": "Fix the size of the value array\n\n- Give the list of columns to the ReadSupport via the split\n- The ReadSupport then gives the GroupConverter the Hive schema\nconverted in Parquet format\n",
            "diff": {
                "parquet-hive/src/main/java/parquet/hive/DeprecatedParquetInputFormat.java": 29,
                "parquet-hive/src/main/java/parquet/hive/ManageJobConfig.java": 22,
                "parquet-hive/src/main/java/parquet/hive/convert/DataWritableGroupConverter.java": 36,
                "parquet-hive/src/main/java/parquet/hive/convert/DataWritableRecordConverter.java": 6,
                "parquet-hive/src/main/java/parquet/hive/convert/HiveSchemaConverter.java": 4,
                "parquet-hive/src/main/java/parquet/hive/read/DataWritableReadSupport.java": 27,
                "parquet-hive/src/main/java/parquet/hive/serde/ParquetHiveArrayInspector.java": 2,
                "parquet-hive/src/main/java/parquet/hive/serde/ParquetHiveMapInspector.java": 2
            },
            "is_test": false,
            "is_fix": false
        },
        "8234945c40078a911ba7a9e83fc5fd534126182b": {
            "datetime": "2013-07-23T11:11:45+02:00",
            "summary": "Remove unused parameters",
            "message": "Remove unused parameters\n",
            "diff": {
                "parquet-hive/src/main/java/parquet/hive/serde/ParquetHiveSerDe.java": 13
            },
            "is_test": false,
            "is_fix": false
        },
        "3ee49a5e6c52b374431dfdeeb7b01546625bbfdd": {
            "datetime": "2013-07-23T11:11:45+02:00",
            "summary": "Change MapWritable to ArrayWritable (perfomance improved !)",
            "message": "Change MapWritable to ArrayWritable (perfomance improved !)\n\nFix the ugly fix in case trouble while reading with combine hive\nRefactor the unit test\nAdd more unit test\nSpecify all the unsupported format (next : refactor this, because we have like 4 methods for it)\nFix the fact that we were reading twice the data ( sorry :) )\nDid some profiling with the unit test\n",
            "diff": {
                "parquet-hive/src/main/java/parquet/hive/DeprecatedParquetInputFormat.java": 70,
                "parquet-hive/src/main/java/parquet/hive/DeprecatedParquetOutputFormat.java": 35,
                "parquet-hive/src/main/java/parquet/hive/ManageJobConfig.java": 22,
                "parquet-hive/src/main/java/parquet/hive/convert/ArrayWritableGroupConverter.java": 2,
                "parquet-hive/src/main/java/parquet/hive/convert/DataWritableGroupConverter.java": 132,
                "parquet-hive/src/main/java/parquet/hive/convert/DataWritableRecordConverter.java": 46,
                "parquet-hive/src/main/java/parquet/hive/convert/HiveGroupConverter.java": 2,
                "parquet-hive/src/main/java/parquet/hive/convert/HiveSchemaConverter.java": 16,
                "parquet-hive/src/main/java/parquet/hive/convert/MapWritableGroupConverter.java": 128,
                "parquet-hive/src/main/java/parquet/hive/convert/MapWritableRecordConverter.java": 54,
                "parquet-hive/src/main/java/parquet/hive/read/MapWritableReadSupport.java": 44,
                "parquet-hive/src/main/java/parquet/hive/serde/MapWritableObjectInspector.java": 41,
                "parquet-hive/src/main/java/parquet/hive/serde/ParquetHiveArrayInspector.java": 8,
                "parquet-hive/src/main/java/parquet/hive/serde/ParquetHiveMapInspector.java": 15,
                "parquet-hive/src/main/java/parquet/hive/serde/ParquetHiveSerDe.java": 62,
                "parquet-hive/src/main/java/parquet/hive/writable/BinaryWritable.java": 19,
                "parquet-hive/src/main/java/parquet/hive/write/MapWritableWriteSupport.java": 24,
                "parquet-hive/src/main/java/parquet/hive/write/MapWritableWriter.java": 50,
                "parquet-hive/src/test/java/parquet/hive/TestDeprecatedParquetInputFormat.java": 116,
                "parquet-hive/src/test/java/parquet/hive/TestDeprecatedParquetOuputFormat.java": 34,
                "parquet-hive/src/test/java/parquet/hive/TestDeprecatedParquetOuputFormatComplexType.java": 192,
                "parquet-hive/src/test/java/parquet/hive/TestParquetSerDe.java": 42,
                "parquet-hive/src/test/java/parquet/hive/UtilitiesTestMethods.java": 84
            },
            "is_test": true,
            "is_fix": false
        },
        "174c26ae4648ca2554942008905c303be851d5b3": {
            "datetime": "2013-07-23T11:11:45+02:00",
            "summary": "Correct fix to CombineHive",
            "message": "Correct fix to CombineHive\n",
            "diff": {
                "parquet-hive/src/main/java/parquet/hive/DeprecatedParquetInputFormat.java": 59
            },
            "is_test": false,
            "is_fix": false
        },
        "cee774c357a4af5f404249eaf1681efa0f5e085e": {
            "datetime": "2013-07-23T11:11:45+02:00",
            "summary": "Fix more combine stuff",
            "message": "Fix more combine stuff\n",
            "diff": {
                "parquet-hive/src/main/java/parquet/hive/DeprecatedParquetInputFormat.java": 59
            },
            "is_test": false,
            "is_fix": false
        },
        "cc6754ceb89421859afa0e9ab8e7bc9d9ad7dd10": {
            "datetime": "2013-07-23T11:11:45+02:00",
            "summary": "Fix CombineHive bug",
            "message": "Fix CombineHive bug\n\n- When getting splits from CombineHive, recalculate all possible\nsplits for the path, and only keep the correct one, to keep only\nthe correct blocks\n",
            "diff": {
                "parquet-hive/src/main/java/parquet/hive/DeprecatedParquetInputFormat.java": 46
            },
            "is_test": false,
            "is_fix": false
        },
        "41981533138c845508fe05253f81c78d90083b03": {
            "datetime": "2013-07-23T11:11:45+02:00",
            "summary": "Fix compile with abstract methods",
            "message": "Fix compile with abstract methods\n",
            "diff": {
                "parquet-hive/src/test/java/parquet/hive/TestDeprecatedParquetOuputFormat.java": 19,
                "parquet-hive/src/test/java/parquet/hive/TestDeprecatedParquetOuputFormatComplexType.java": 19
            },
            "is_test": true,
            "is_fix": false
        },
        "f2d9e81bf69d3c0f4bbf3ff2b148ff04c1187289": {
            "datetime": "2013-07-23T11:11:45+02:00",
            "summary": "update hadoop version",
            "message": "update hadoop version\n",
            "diff": {
                "parquet-hive/src/main/java/parquet/hive/DeprecatedParquetInputFormat.java": 14,
                "parquet-hive/src/test/java/parquet/hive/TestDeprecatedParquetInputFormat.java": 5
            },
            "is_test": true,
            "is_fix": false
        },
        "d6157297fb3533139b98d5ceaf0ab6311c5ed724": {
            "datetime": "2013-07-23T11:11:45+02:00",
            "summary": "Add unit test for storage",
            "message": "Add unit test for storage\n",
            "diff": {
                "parquet-hive/src/test/java/parquet/hive/TestDeprecatedParquetOuputFormat.java": 78,
                "parquet-hive/src/test/java/parquet/hive/TestDeprecatedParquetOuputFormatComplexType.java": 187
            },
            "is_test": true,
            "is_fix": false
        },
        "74be52851bbb1d0bed6af746eb7a83d8113bb555": {
            "datetime": "2013-07-23T11:11:45+02:00",
            "summary": "Add full support for array and map reading",
            "message": "Add full support for array and map reading\n",
            "diff": {
                "parquet-hive/src/main/java/parquet/hive/DeprecatedParquetInputFormat.java": 49,
                "parquet-hive/src/main/java/parquet/hive/DeprecatedParquetOutputFormat.java": 2,
                "parquet-hive/src/main/java/parquet/hive/convert/ArrayWritableGroupConverter.java": 30,
                "parquet-hive/src/main/java/parquet/hive/convert/ETypeConverter.java": 8,
                "parquet-hive/src/main/java/parquet/hive/convert/HiveGroupConverter.java": 5,
                "parquet-hive/src/main/java/parquet/hive/convert/HiveSchemaConverter.java": 9,
                "parquet-hive/src/main/java/parquet/hive/convert/MapWritableGroupConverter.java": 42,
                "parquet-hive/src/main/java/parquet/hive/convert/MapWritableRecordConverter.java": 1,
                "parquet-hive/src/main/java/parquet/hive/read/MapWritableReadSupport.java": 6,
                "parquet-hive/src/main/java/parquet/hive/serde/MapWritableObjectInspector.java": 3,
                "parquet-hive/src/main/java/parquet/hive/serde/ParquetHiveSerDe.java": 5,
                "parquet-hive/src/main/java/parquet/hive/write/MapWritableWriter.java": 1
            },
            "is_test": false,
            "is_fix": false
        },
        "1dc42f0bf123219d03107ff64954705fe1b104d8": {
            "datetime": "2013-07-23T11:11:45+02:00",
            "summary": "Improve the pull request following advices from Julien",
            "message": "Improve the pull request following advices from Julien\n",
            "diff": {
                "parquet-hive/src/main/java/parquet/hive/convert/ArrayWritableGroupConverter.java": 4,
                "parquet-hive/src/main/java/parquet/hive/convert/HiveSchemaConverter.java": 4,
                "parquet-hive/src/main/java/parquet/hive/serde/ParquetHiveSerDe.java": 5,
                "parquet-hive/src/main/java/parquet/hive/write/MapWritableWriter.java": 3,
                "parquet-hive/src/test/java/parquet/hive/TestDeprecatedParquetInputFormat.java": 73,
                "parquet-hive/src/test/java/parquet/hive/TestDeprecatedParquetOuputFormat.java": 57
            },
            "is_test": true,
            "is_fix": false
        },
        "33e0131ff0cd7c282b6af17bc82f74155eb761a8": {
            "datetime": "2013-07-23T11:11:45+02:00",
            "summary": "Add some unit test in order to test :",
            "message": "Add some unit test in order to test :\n\n - HiveSerDe : fix some bugs about long and byte datas\n - DeprecatedParquetInputFormat : add StatsSerDe method\n - MapWritableWriter : fix bug if we start and close without adding values\n - UtilitiesTestMethods : almost everything is from parquet-pig. Very useful\n - TestDeprecated{Input,Output}Format : in order to test the hive stuff\n\nUpdate pom.xml :\n\n - Hive-* 0.10 version\n - Add column for test purpose\n",
            "diff": {
                "parquet-hive/src/main/java/parquet/hive/DeprecatedParquetInputFormat.java": 36,
                "parquet-hive/src/main/java/parquet/hive/DeprecatedParquetOutputFormat.java": 20,
                "parquet-hive/src/main/java/parquet/hive/serde/ParquetHiveSerDe.java": 3,
                "parquet-hive/src/main/java/parquet/hive/write/MapWritableWriter.java": 19,
                "parquet-hive/src/test/java/parquet/hive/TestDeprecatedParquetInputFormat.java": 207,
                "parquet-hive/src/test/java/parquet/hive/TestDeprecatedParquetOuputFormat.java": 148,
                "parquet-hive/src/test/java/parquet/hive/TestHiveInputFormat.java": 143,
                "parquet-hive/src/test/java/parquet/hive/TestHiveOuputFormat.java": 27,
                "parquet-hive/src/test/java/parquet/hive/TestParquetSerDe.java": 52,
                "parquet-hive/src/test/java/parquet/hive/UtilitiesTestMethods.java": 158
            },
            "is_test": true,
            "is_fix": false
        },
        "bb6e2ff89644690e363a31078e94b17e76b590a9": {
            "datetime": "2013-07-23T11:51:58+02:00",
            "summary": "Hadoop 2.0 compatibility, hive 0.10",
            "message": "Hadoop 2.0 compatibility, hive 0.10\n\n - Using ContextUtils to be able to launch with hadoop 2.0\n - Working with hive 0.10\n - Fix some issues with ArrayWritable to be able to reach any columns\nwith objectInspector\n",
            "diff": {
                "parquet-hive/src/main/java/parquet/hive/DeprecatedParquetInputFormat.java": 34,
                "parquet-hive/src/main/java/parquet/hive/serde/ArrayWritableObjectInspector.java": 40,
                "parquet-hive/src/main/java/parquet/hive/serde/ParquetHiveArrayInspector.java": 49,
                "parquet-hive/src/main/java/parquet/hive/writable/BinaryWritable.java": 4,
                "parquet-hive/src/test/java/parquet/hive/TestDeprecatedParquetInputFormat.java": 12,
                "parquet-hive/src/test/java/parquet/hive/TestDeprecatedParquetOuputFormat.java": 6,
                "parquet-hive/src/test/java/parquet/hive/UtilitiesTestMethods.java": 5
            },
            "is_test": true,
            "is_fix": false
        },
        "4cf6ae1b5de1293eaed6e409a7a69c1ce2aac316": {
            "datetime": "2013-07-23T11:52:05+02:00",
            "summary": "Code review",
            "message": "Code review\n\n - Add todo\n - Add javadoc\n - Rename class\n - Rename method\n - Improve tests\n",
            "diff": {
                "parquet-column/src/main/java/parquet/io/MessageColumnIO.java": 2,
                "parquet-column/src/main/java/parquet/io/RecordReaderEmpty.java": 4,
                "parquet-hive/src/main/java/parquet/hive/DeprecatedParquetOutputFormat.java": 8,
                "parquet-hive/src/main/java/parquet/hive/ManageJobConfig.java": 34,
                "parquet-hive/src/main/java/parquet/hive/convert/ETypeConverter.java": 53,
                "parquet-hive/src/main/java/parquet/hive/convert/HiveSchemaConverter.java": 6,
                "parquet-hive/src/main/java/parquet/hive/serde/ArrayWritableObjectInspector.java": 3,
                "parquet-hive/src/main/java/parquet/hive/writable/BinaryWritable.java": 87,
                "parquet-hive/src/test/java/parquet/hive/TestDeprecatedParquetInputFormat.java": 28,
                "parquet-hive/src/test/java/parquet/hive/TestDeprecatedParquetOuputFormat.java": 2,
                "parquet-hive/src/test/java/parquet/hive/UtilitiesTestMethods.java": 48
            },
            "is_test": true,
            "is_fix": false
        },
        "2525587f8290908229c4582a2c3b0ea54067428d": {
            "datetime": "2013-07-23T11:52:05+02:00",
            "summary": "Update getSplits in DeprecatedParquetInputFormat",
            "message": "Update getSplits in DeprecatedParquetInputFormat\n\n- In the case of a FileSplit, do not get the blocks, and instead\ncompute directly from the split offset/length\n- Add javadoc\n",
            "diff": {
                "parquet-hive/src/main/java/parquet/hive/DeprecatedParquetInputFormat.java": 33
            },
            "is_test": false,
            "is_fix": false
        },
        "26360f35ee52811ea5cb320813848a79aa4b8047": {
            "datetime": "2013-07-23T11:52:05+02:00",
            "summary": "Minor changes",
            "message": "Minor changes\n\n - Documentation\n - Change the name of a method\n",
            "diff": {
                "parquet-hive/src/main/java/parquet/hive/DeprecatedParquetInputFormat.java": 2,
                "parquet-hive/src/main/java/parquet/hive/ManageJobConfig.java": 5,
                "parquet-hive/src/main/java/parquet/hive/writable/BigDecimalWritable.java": 9,
                "parquet-hive/src/main/java/parquet/hive/writable/BinaryWritable.java": 6,
                "parquet-hive/src/main/java/parquet/hive/write/DataWritableWriteSupport.java": 3,
                "parquet-hive/src/main/java/parquet/hive/write/DataWritableWriter.java": 5
            },
            "is_test": false,
            "is_fix": false
        },
        "eccbba1c124d1b22553cb3ef64a883f23e7dbe84": {
            "datetime": "2013-07-23T11:52:05+02:00",
            "summary": "Improve speed for queries like count(0), in which we only need the number of lines",
            "message": "Improve speed for queries like count(0), in which we only need the number of lines\n",
            "diff": {
                "parquet-column/src/main/java/parquet/io/MessageColumnIO.java": 11,
                "parquet-column/src/main/java/parquet/io/RecordReaderEmpty.java": 47,
                "parquet-column/src/main/java/parquet/io/RecordReaderImplementation.java": 2
            },
            "is_test": false,
            "is_fix": false
        },
        "21b0d9787694f3d87e4068cfce01b51749854495": {
            "datetime": "2013-07-23T11:52:05+02:00",
            "summary": "Update with advices from Julien",
            "message": "Update with advices from Julien\n",
            "diff": {
                "parquet-hive/src/main/java/parquet/hive/DeprecatedParquetInputFormat.java": 25,
                "parquet-hive/src/main/java/parquet/hive/serde/ArrayWritableObjectInspector.java": 2,
                "parquet-hive/src/main/java/parquet/hive/serde/ParquetHiveSerDe.java": 28,
                "parquet-hive/src/test/java/parquet/hive/TestParquetSerDe.java": 10
            },
            "is_test": true,
            "is_fix": false
        },
        "3089e834ae9bfbd212a77e12c9f9b9cf8917d63d": {
            "datetime": "2013-07-23T11:52:05+02:00",
            "summary": "Manage count 0",
            "message": "Manage count 0\n",
            "diff": {
                "parquet-hive/src/main/java/parquet/hive/read/DataWritableReadSupport.java": 24
            },
            "is_test": false,
            "is_fix": false
        },
        "82fff8c856abc84159c09aff4670fc7c76489be5": {
            "datetime": "2013-07-23T11:52:05+02:00",
            "summary": "Clean up ReadSupport init",
            "message": "Clean up ReadSupport init\n",
            "diff": {
                "parquet-hive/src/main/java/parquet/hive/DeprecatedParquetInputFormat.java": 3,
                "parquet-hive/src/main/java/parquet/hive/ManageJobConfig.java": 3,
                "parquet-hive/src/main/java/parquet/hive/read/DataWritableReadSupport.java": 47,
                "parquet-hive/src/test/java/parquet/hive/TestDeprecatedParquetInputFormat.java": 15,
                "parquet-hive/src/test/java/parquet/hive/TestDeprecatedParquetOuputFormat.java": 15
            },
            "is_test": true,
            "is_fix": false
        },
        "0ec089dcaa6246e08b069a1770484e52b1e05357": {
            "datetime": "2013-07-23T11:52:05+02:00",
            "summary": "Add metadata in ReadContext instead of Split",
            "message": "Add metadata in ReadContext instead of Split\n\n- Fix TaskAttemptContext in the deprecated output format\n- Clean up a bit how we get the split in the deprecated input format\n",
            "diff": {
                "parquet-hive/src/main/java/parquet/hive/DeprecatedParquetInputFormat.java": 169,
                "parquet-hive/src/main/java/parquet/hive/DeprecatedParquetOutputFormat.java": 28,
                "parquet-hive/src/main/java/parquet/hive/read/DataWritableReadSupport.java": 22,
                "parquet-hive/src/main/java/parquet/hive/serde/ArrayWritableObjectInspector.java": 10,
                "parquet-hive/src/main/java/parquet/hive/serde/ParquetHiveArrayInspector.java": 15,
                "parquet-hive/src/test/java/parquet/hive/TestDeprecatedParquetInputFormat.java": 6,
                "parquet-hive/src/test/java/parquet/hive/TestDeprecatedParquetOuputFormat.java": 14
            },
            "is_test": true,
            "is_fix": false
        },
        "92c450a9783cfed62bc1b7bf1f99a6d641ec72a4": {
            "datetime": "2013-07-23T18:02:40-07:00",
            "summary": "Merge pull request #28 from mickaellcr/parquet-hive",
            "message": "Merge pull request #28 from mickaellcr/parquet-hive\n\nParquet hive implementation",
            "diff": {
                "parquet-column/src/main/java/parquet/io/EmptyRecordReader.java": 47,
                "parquet-column/src/main/java/parquet/io/MessageColumnIO.java": 11,
                "parquet-column/src/main/java/parquet/io/RecordReaderImplementation.java": 2,
                "parquet-hive/src/main/java/parquet/hive/DeprecatedParquetInputFormat.java": 366,
                "parquet-hive/src/main/java/parquet/hive/DeprecatedParquetOutputFormat.java": 162,
                "parquet-hive/src/main/java/parquet/hive/ManageJobConfig.java": 185,
                "parquet-hive/src/main/java/parquet/hive/convert/ArrayWritableGroupConverter.java": 83,
                "parquet-hive/src/main/java/parquet/hive/convert/DataWritableGroupConverter.java": 140,
                "parquet-hive/src/main/java/parquet/hive/convert/DataWritableRecordConverter.java": 44,
                "parquet-hive/src/main/java/parquet/hive/convert/ETypeConverter.java": 283,
                "parquet-hive/src/main/java/parquet/hive/convert/HiveGroupConverter.java": 47,
                "parquet-hive/src/main/java/parquet/hive/convert/HiveSchemaConverter.java": 139,
                "parquet-hive/src/main/java/parquet/hive/read/DataWritableReadSupport.java": 106,
                "parquet-hive/src/main/java/parquet/hive/serde/ArrayWritableObjectInspector.java": 242,
                "parquet-hive/src/main/java/parquet/hive/serde/ParquetHiveArrayInspector.java": 144,
                "parquet-hive/src/main/java/parquet/hive/serde/ParquetHiveMapInspector.java": 99,
                "parquet-hive/src/main/java/parquet/hive/serde/ParquetHiveSerDe.java": 290,
                "parquet-hive/src/main/java/parquet/hive/writable/BigDecimalWritable.java": 152,
                "parquet-hive/src/main/java/parquet/hive/writable/BinaryWritable.java": 46,
                "parquet-hive/src/main/java/parquet/hive/write/DataWritableWriteSupport.java": 61,
                "parquet-hive/src/main/java/parquet/hive/write/DataWritableWriter.java": 156,
                "parquet-hive/src/test/java/parquet/hive/TestDeprecatedParquetInputFormat.java": 260,
                "parquet-hive/src/test/java/parquet/hive/TestDeprecatedParquetOuputFormat.java": 211,
                "parquet-hive/src/test/java/parquet/hive/TestHiveSchemaConverter.java": 87,
                "parquet-hive/src/test/java/parquet/hive/TestParquetSerDe.java": 110,
                "parquet-hive/src/test/java/parquet/hive/UtilitiesTestMethods.java": 141
            },
            "is_test": true,
            "is_fix": false
        },
        "67b8423a653fbd4c191b2c886b5c5b71143698a3": {
            "datetime": "2013-07-24T09:33:26-07:00",
            "summary": "ThriftParquetReader and ThriftParquetWriter",
            "message": "ThriftParquetReader and ThriftParquetWriter\n",
            "diff": {
                "parquet-thrift/src/main/java/parquet/hadoop/thrift/ThriftReadSupport.java": 19,
                "parquet-thrift/src/main/java/parquet/hadoop/thrift/ThriftWriteSupport.java": 32,
                "parquet-thrift/src/main/java/parquet/thrift/ThriftParquetReader.java": 52,
                "parquet-thrift/src/main/java/parquet/thrift/ThriftParquetWriter.java": 44,
                "parquet-thrift/src/test/java/parquet/thrift/TestThriftParquetReaderWriter.java": 70
            },
            "is_test": true,
            "is_fix": false
        },
        "be49204476dbf293cadc35528d3eaec5ce384678": {
            "datetime": "2013-07-25T09:44:26-07:00",
            "summary": "change default page size and add some doc",
            "message": "change default page size and add some doc\n",
            "diff": {
                "parquet-hadoop/src/main/java/parquet/hadoop/ParquetFileReader.java": 2,
                "parquet-hadoop/src/main/java/parquet/hadoop/ParquetFileWriter.java": 3,
                "parquet-hadoop/src/main/java/parquet/hadoop/ParquetOutputFormat.java": 2,
                "parquet-hadoop/src/main/java/parquet/hadoop/ParquetReader.java": 1,
                "parquet-hadoop/src/main/java/parquet/hadoop/ParquetRecordReader.java": 4,
                "parquet-hadoop/src/main/java/parquet/hadoop/ParquetWriter.java": 4,
                "parquet-hadoop/src/main/java/parquet/hadoop/api/package-info.java": 31,
                "parquet-hadoop/src/main/java/parquet/hadoop/package-info.java": 31
            },
            "is_test": false,
            "is_fix": false
        },
        "0fbd026714e3f2f3e0ab8e5a2080af4da3329f84": {
            "datetime": "2013-07-25T09:46:02-07:00",
            "summary": "Merge pull request #105 from Parquet/ThriftParquetWriter",
            "message": "Merge pull request #105 from Parquet/ThriftParquetWriter\n\nThriftParquetReader and ThriftParquetWriter",
            "diff": {
                "parquet-thrift/src/main/java/parquet/hadoop/thrift/ThriftReadSupport.java": 19,
                "parquet-thrift/src/main/java/parquet/hadoop/thrift/ThriftWriteSupport.java": 32,
                "parquet-thrift/src/main/java/parquet/thrift/ThriftParquetReader.java": 52,
                "parquet-thrift/src/main/java/parquet/thrift/ThriftParquetWriter.java": 44,
                "parquet-thrift/src/test/java/parquet/thrift/TestThriftParquetReaderWriter.java": 70
            },
            "is_test": true,
            "is_fix": false
        },
        "b7fe532ff5e4e8f56fffd9d18e04d105d92c8a1f": {
            "datetime": "2013-07-25T09:46:33-07:00",
            "summary": "Merge branch 'master' of github.com:Parquet/parquet-mr into change_default_block_size",
            "message": "Merge branch 'master' of github.com:Parquet/parquet-mr into change_default_block_size\n",
            "diff": {
                "parquet-thrift/src/main/java/parquet/hadoop/thrift/ThriftReadSupport.java": 19,
                "parquet-thrift/src/main/java/parquet/hadoop/thrift/ThriftWriteSupport.java": 32,
                "parquet-thrift/src/main/java/parquet/thrift/ThriftParquetReader.java": 52,
                "parquet-thrift/src/main/java/parquet/thrift/ThriftParquetWriter.java": 44,
                "parquet-thrift/src/test/java/parquet/thrift/TestThriftParquetReaderWriter.java": 70
            },
            "is_test": true,
            "is_fix": false
        },
        "8a62bb35a5aac83340f968467c438a01563c6d79": {
            "datetime": "2013-07-25T09:47:18-07:00",
            "summary": "fix doc",
            "message": "fix doc\n",
            "diff": {
                "parquet-hadoop/src/main/java/parquet/hadoop/api/package-info.java": 10
            },
            "is_test": false,
            "is_fix": false
        },
        "4bc24334231a0565fcd6bc1126c6f1f7e16c3f3f": {
            "datetime": "2013-07-25T11:21:57-07:00",
            "summary": "[fix validation script] when boolean value is null, set it to 0 for being compatible.",
            "message": "[fix validation script] when boolean value is null, set it to 0 for being compatible.\n",
            "diff": {
                "parquet-pig/src/main/java/parquet/pig/convert/TupleConverter.java": 3
            },
            "is_test": false,
            "is_fix": false
        },
        "265ef240e67029fe94dcfffd3393344c0601dc1c": {
            "datetime": "2013-07-25T11:22:19-07:00",
            "summary": "Merge branch 'master' of https://github.com/Parquet/parquet-mr into fix_boolean_default_value_for_tuple_converter",
            "message": "Merge branch 'master' of https://github.com/Parquet/parquet-mr into fix_boolean_default_value_for_tuple_converter\n",
            "diff": {
                "parquet-column/src/main/java/parquet/io/EmptyRecordReader.java": 47,
                "parquet-column/src/main/java/parquet/io/MessageColumnIO.java": 11,
                "parquet-column/src/main/java/parquet/io/RecordReaderImplementation.java": 2,
                "parquet-hive/src/main/java/parquet/hive/DeprecatedParquetInputFormat.java": 366,
                "parquet-hive/src/main/java/parquet/hive/DeprecatedParquetOutputFormat.java": 162,
                "parquet-hive/src/main/java/parquet/hive/ManageJobConfig.java": 185,
                "parquet-hive/src/main/java/parquet/hive/convert/ArrayWritableGroupConverter.java": 83,
                "parquet-hive/src/main/java/parquet/hive/convert/DataWritableGroupConverter.java": 140,
                "parquet-hive/src/main/java/parquet/hive/convert/DataWritableRecordConverter.java": 44,
                "parquet-hive/src/main/java/parquet/hive/convert/ETypeConverter.java": 283,
                "parquet-hive/src/main/java/parquet/hive/convert/HiveGroupConverter.java": 47,
                "parquet-hive/src/main/java/parquet/hive/convert/HiveSchemaConverter.java": 139,
                "parquet-hive/src/main/java/parquet/hive/read/DataWritableReadSupport.java": 106,
                "parquet-hive/src/main/java/parquet/hive/serde/ArrayWritableObjectInspector.java": 242,
                "parquet-hive/src/main/java/parquet/hive/serde/ParquetHiveArrayInspector.java": 144,
                "parquet-hive/src/main/java/parquet/hive/serde/ParquetHiveMapInspector.java": 99,
                "parquet-hive/src/main/java/parquet/hive/serde/ParquetHiveSerDe.java": 290,
                "parquet-hive/src/main/java/parquet/hive/writable/BigDecimalWritable.java": 152,
                "parquet-hive/src/main/java/parquet/hive/writable/BinaryWritable.java": 46,
                "parquet-hive/src/main/java/parquet/hive/write/DataWritableWriteSupport.java": 61,
                "parquet-hive/src/main/java/parquet/hive/write/DataWritableWriter.java": 156,
                "parquet-hive/src/test/java/parquet/hive/TestDeprecatedParquetInputFormat.java": 260,
                "parquet-hive/src/test/java/parquet/hive/TestDeprecatedParquetOuputFormat.java": 211,
                "parquet-hive/src/test/java/parquet/hive/TestHiveSchemaConverter.java": 87,
                "parquet-hive/src/test/java/parquet/hive/TestParquetSerDe.java": 110,
                "parquet-hive/src/test/java/parquet/hive/UtilitiesTestMethods.java": 141,
                "parquet-thrift/src/main/java/parquet/hadoop/thrift/ThriftReadSupport.java": 19,
                "parquet-thrift/src/main/java/parquet/hadoop/thrift/ThriftWriteSupport.java": 32,
                "parquet-thrift/src/main/java/parquet/thrift/ThriftParquetReader.java": 52,
                "parquet-thrift/src/main/java/parquet/thrift/ThriftParquetWriter.java": 44,
                "parquet-thrift/src/test/java/parquet/thrift/TestThriftParquetReaderWriter.java": 70
            },
            "is_test": true,
            "is_fix": false
        },
        "0e8f1f7a6d33a2141c5b45a4f0518b7747678f2e": {
            "datetime": "2013-07-25T14:52:40-07:00",
            "summary": "Merge pull request #107 from Parquet/change_default_block_size",
            "message": "Merge pull request #107 from Parquet/change_default_block_size\n\nChange default block size and clarify some doc",
            "diff": {
                "parquet-hadoop/src/main/java/parquet/hadoop/ParquetFileReader.java": 2,
                "parquet-hadoop/src/main/java/parquet/hadoop/ParquetFileWriter.java": 3,
                "parquet-hadoop/src/main/java/parquet/hadoop/ParquetOutputFormat.java": 2,
                "parquet-hadoop/src/main/java/parquet/hadoop/ParquetReader.java": 1,
                "parquet-hadoop/src/main/java/parquet/hadoop/ParquetRecordReader.java": 4,
                "parquet-hadoop/src/main/java/parquet/hadoop/ParquetWriter.java": 4,
                "parquet-hadoop/src/main/java/parquet/hadoop/api/package-info.java": 23,
                "parquet-hadoop/src/main/java/parquet/hadoop/package-info.java": 31
            },
            "is_test": false,
            "is_fix": false
        },
        "eac5aecfa40273edab7645ba81eb4816ceac9d98": {
            "datetime": "2013-07-25T15:52:30-07:00",
            "summary": "1. return compatible schema when compatible flag is set. 2. tupleConverter set to return IntegerConverter when flag is set",
            "message": "1. return compatible schema when compatible flag is set. 2. tupleConverter set to return IntegerConverter when flag is set\n",
            "diff": {
                "parquet-pig/src/main/java/parquet/pig/ParquetLoader.java": 16,
                "parquet-pig/src/main/java/parquet/pig/TupleReadSupport.java": 5,
                "parquet-pig/src/main/java/parquet/pig/convert/TupleConverter.java": 21
            },
            "is_test": false,
            "is_fix": false
        },
        "c4e8d261c322aca17c8789c61b4e4289dfd3b675": {
            "datetime": "2013-07-25T16:50:09-07:00",
            "summary": "optimize code format, add log info to indicate boolean will be convert",
            "message": "optimize code format, add log info to indicate boolean will be convert\nto int when compatible mode is on\n",
            "diff": {
                "parquet-pig/src/main/java/parquet/pig/ParquetLoader.java": 8,
                "parquet-pig/src/main/java/parquet/pig/TupleReadSupport.java": 10
            },
            "is_test": false,
            "is_fix": false
        },
        "7a4b5626cbdfad9b4429e47fc4b6da37516a09b9": {
            "datetime": "2013-07-25T19:47:32-07:00",
            "summary": "add if debug statements to parquetloader",
            "message": "add if debug statements to parquetloader\n",
            "diff": {
                "parquet-pig/src/main/java/parquet/pig/ParquetLoader.java": 15
            },
            "is_test": false,
            "is_fix": false
        },
        "a7c42f93d0a2278970beaddaec26071efc4436ad": {
            "datetime": "2013-07-26T15:21:00+01:00",
            "summary": "Make writer independent",
            "message": "Make writer independent\n",
            "diff": {
                "parquet-hadoop/src/main/java/parquet/hadoop/InternalParquetRecordWriter.java": 135,
                "parquet-hadoop/src/main/java/parquet/hadoop/ParquetRecordWriter.java": 98,
                "parquet-hadoop/src/main/java/parquet/hadoop/ParquetWriter.java": 8
            },
            "is_test": false,
            "is_fix": false
        },
        "504833e34a16b58c60fd1e43e771c258b2bebeb9": {
            "datetime": "2013-07-26T16:00:13+01:00",
            "summary": "Make reader independent",
            "message": "Make reader independent\n",
            "diff": {
                "parquet-hadoop/src/main/java/parquet/hadoop/InternalParquetRecordReader.java": 178,
                "parquet-hadoop/src/main/java/parquet/hadoop/InternalParquetRecordWriter.java": 2,
                "parquet-hadoop/src/main/java/parquet/hadoop/ParquetReader.java": 14,
                "parquet-hadoop/src/main/java/parquet/hadoop/ParquetRecordReader.java": 136
            },
            "is_test": false,
            "is_fix": false
        },
        "7d1fe7846a7973cccb683ecb8201c2b03fbc7e60": {
            "datetime": "2013-07-26T09:55:21-07:00",
            "summary": "remove space, add braces for readability",
            "message": "remove space, add braces for readability\n",
            "diff": {
                "parquet-pig/src/main/java/parquet/pig/ParquetLoader.java": 4,
                "parquet-pig/src/main/java/parquet/pig/convert/TupleConverter.java": 9
            },
            "is_test": false,
            "is_fix": false
        },
        "82579c96a03a3c97812d621087f3a44e69e4ea0d": {
            "datetime": "2013-07-26T10:14:20-07:00",
            "summary": "Merge pull request #108 from Parquet/elephant_bird_compatible",
            "message": "Merge pull request #108 from Parquet/elephant_bird_compatible\n\nset elephantbird compatible flag to get compatible schema and  value converter",
            "diff": {
                "parquet-pig/src/main/java/parquet/pig/ParquetLoader.java": 16,
                "parquet-pig/src/main/java/parquet/pig/TupleReadSupport.java": 11,
                "parquet-pig/src/main/java/parquet/pig/convert/TupleConverter.java": 24
            },
            "is_test": false,
            "is_fix": false
        },
        "09ba2fb2fdccbd7f79b2b5d3fa42f80d46546581": {
            "datetime": "2013-07-26T11:30:46-07:00",
            "summary": "Merge pull request #111 from aniket486/master",
            "message": "Merge pull request #111 from aniket486/master\n\nadd if debug statements to parquetloader",
            "diff": {
                "parquet-pig/src/main/java/parquet/pig/ParquetLoader.java": 15
            },
            "is_test": false,
            "is_fix": false
        },
        "3c55f589708eb25a870c6669806b7e465446c0ae": {
            "datetime": "2013-07-26T11:31:46-07:00",
            "summary": "Merge pull request #112 from tomwhite/issue-64-mr-indept",
            "message": "Merge pull request #112 from tomwhite/issue-64-mr-indept\n\nMake Parquet{Reader,Writer} independent of MapReduce APIs",
            "diff": {
                "parquet-hadoop/src/main/java/parquet/hadoop/InternalParquetRecordReader.java": 178,
                "parquet-hadoop/src/main/java/parquet/hadoop/InternalParquetRecordWriter.java": 133,
                "parquet-hadoop/src/main/java/parquet/hadoop/ParquetReader.java": 14,
                "parquet-hadoop/src/main/java/parquet/hadoop/ParquetRecordReader.java": 136,
                "parquet-hadoop/src/main/java/parquet/hadoop/ParquetRecordWriter.java": 98,
                "parquet-hadoop/src/main/java/parquet/hadoop/ParquetWriter.java": 8
            },
            "is_test": false,
            "is_fix": false
        },
        "ecb2daca5bd6e2828e2a5079d0f2f326737415c9": {
            "datetime": "2013-08-03T10:01:03-07:00",
            "summary": "refactro column reader",
            "message": "refactro column reader\n",
            "diff": {
                "parquet-column/src/main/java/parquet/column/ColumnReader.java": 13,
                "parquet-column/src/main/java/parquet/column/impl/ColumnReaderImpl.java": 128,
                "parquet-column/src/main/java/parquet/filter/AndRecordFilter.java": 5,
                "parquet-column/src/main/java/parquet/filter/ColumnRecordFilter.java": 10,
                "parquet-column/src/main/java/parquet/filter/PagedRecordFilter.java": 8,
                "parquet-column/src/main/java/parquet/filter/RecordFilter.java": 5,
                "parquet-column/src/main/java/parquet/io/FilteredRecordReader.java": 24,
                "parquet-column/src/main/java/parquet/io/MessageColumnIO.java": 6,
                "parquet-column/src/main/java/parquet/io/RecordReaderImplementation.java": 1,
                "parquet-column/src/test/java/parquet/column/mem/TestMemColumn.java": 16,
                "parquet-column/src/test/java/parquet/column/mem/TestMemPageStore.java": 2,
                "parquet-column/src/test/java/parquet/column/page/mem/MemPageStore.java": 12,
                "parquet-column/src/test/java/parquet/io/PerfTest.java": 19,
                "parquet-column/src/test/java/parquet/io/TestColumnIO.java": 14,
                "parquet-column/src/test/java/parquet/io/TestFiltered.java": 76,
                "parquet-hive/src/test/java/parquet/hive/TestDeprecatedParquetInputFormat.java": 2,
                "parquet-pig/src/test/java/parquet/pig/GenerateIntTestFile.java": 2,
                "parquet-pig/src/test/java/parquet/pig/GenerateTPCH.java": 2,
                "parquet-pig/src/test/java/parquet/pig/TupleConsumerPerfTest.java": 23,
                "parquet-thrift/src/test/java/parquet/thrift/TestParquetReadProtocol.java": 2
            },
            "is_test": true,
            "is_fix": false
        },
        "f8dd20889316262aaf2d8c73eeca092e27faad0e": {
            "datetime": "2013-08-03T10:10:05-07:00",
            "summary": "simplify end of page count",
            "message": "simplify end of page count\n",
            "diff": {
                "parquet-column/src/main/java/parquet/column/impl/ColumnReaderImpl.java": 9
            },
            "is_test": false,
            "is_fix": false
        },
        "aa530c19c2b1c7253b1dec3d29fd7abc1762dde8": {
            "datetime": "2013-08-03T10:18:16-07:00",
            "summary": "Merge branch 'master' of github.com:Parquet/parquet-mr into refactor_column_reader",
            "message": "Merge branch 'master' of github.com:Parquet/parquet-mr into refactor_column_reader\n",
            "diff": {
                "parquet-hadoop/src/main/java/parquet/hadoop/InternalParquetRecordReader.java": 178,
                "parquet-hadoop/src/main/java/parquet/hadoop/InternalParquetRecordWriter.java": 133,
                "parquet-hadoop/src/main/java/parquet/hadoop/ParquetFileReader.java": 2,
                "parquet-hadoop/src/main/java/parquet/hadoop/ParquetFileWriter.java": 3,
                "parquet-hadoop/src/main/java/parquet/hadoop/ParquetOutputFormat.java": 2,
                "parquet-hadoop/src/main/java/parquet/hadoop/ParquetReader.java": 15,
                "parquet-hadoop/src/main/java/parquet/hadoop/ParquetRecordReader.java": 140,
                "parquet-hadoop/src/main/java/parquet/hadoop/ParquetRecordWriter.java": 98,
                "parquet-hadoop/src/main/java/parquet/hadoop/ParquetWriter.java": 12,
                "parquet-hadoop/src/main/java/parquet/hadoop/api/package-info.java": 23,
                "parquet-hadoop/src/main/java/parquet/hadoop/package-info.java": 31,
                "parquet-pig/src/main/java/parquet/pig/ParquetLoader.java": 31,
                "parquet-pig/src/main/java/parquet/pig/TupleReadSupport.java": 11,
                "parquet-pig/src/main/java/parquet/pig/convert/TupleConverter.java": 27,
                "parquet-thrift/src/main/java/parquet/hadoop/thrift/ThriftReadSupport.java": 19,
                "parquet-thrift/src/main/java/parquet/hadoop/thrift/ThriftWriteSupport.java": 32,
                "parquet-thrift/src/main/java/parquet/thrift/ThriftParquetReader.java": 52,
                "parquet-thrift/src/main/java/parquet/thrift/ThriftParquetWriter.java": 44,
                "parquet-thrift/src/test/java/parquet/thrift/TestThriftParquetReaderWriter.java": 70
            },
            "is_test": true,
            "is_fix": false
        },
        "c126179781821c1aba1140184be1e28b3d1924c9": {
            "datetime": "2013-08-06T13:16:02-07:00",
            "summary": "remove raw type for ParquetTbaseScheme to support thrift0.5; remove scalding dependency",
            "message": "remove raw type for ParquetTbaseScheme to support thrift0.5; remove scalding dependency\n",
            "diff": {
                "parquet-cascading/src/main/java/parquet/cascading/ParquetTBaseScheme.java": 2
            },
            "is_test": false,
            "is_fix": false
        },
        "2a32f349586e6d224b13089a74bdf46f36ee48ac": {
            "datetime": "2013-08-06T13:29:03-07:00",
            "summary": "Merge pull request #119 from Parquet/thrift_05_compatible",
            "message": "Merge pull request #119 from Parquet/thrift_05_compatible\n\nfix compatibility with thrift, remove unused dependency",
            "diff": {
                "parquet-cascading/src/main/java/parquet/cascading/ParquetTBaseScheme.java": 2
            },
            "is_test": false,
            "is_fix": false
        },
        "86ae4f87c4254a74006f807aed8199d3138cc4ad": {
            "datetime": "2013-08-07T15:12:48-07:00",
            "summary": "fix wrong converter: use TBaseRecordConverter for ParquetTBaseScheme; Add unit test for getting correct record converter",
            "message": "fix wrong converter: use TBaseRecordConverter for ParquetTBaseScheme; Add unit test for getting correct record converter\n",
            "diff": {
                "parquet-cascading/src/main/java/parquet/cascading/ParquetTBaseScheme.java": 4,
                "parquet-cascading/src/test/java/parquet/cascading/ParquetTBaseSchemeTest.java": 44
            },
            "is_test": true,
            "is_fix": false
        },
        "a54414c908d68125994c9d3199f95000dc53db02": {
            "datetime": "2013-08-07T15:41:48-07:00",
            "summary": "use Mockito to mock varibles in test, fix format and variable name",
            "message": "use Mockito to mock varibles in test, fix format and variable name\n",
            "diff": {
                "parquet-cascading/src/test/java/parquet/cascading/ParquetTBaseSchemeTest.java": 16
            },
            "is_test": true,
            "is_fix": false
        },
        "5a259265afa62b5117cfa969c735b5e36e416050": {
            "datetime": "2013-08-07T16:47:55-07:00",
            "summary": "Merge pull request #121 from Parquet/fix_wrong_record_converter_class",
            "message": "Merge pull request #121 from Parquet/fix_wrong_record_converter_class\n\nfix wrong RecordConverter for ParquetTBaseScheme",
            "diff": {
                "parquet-cascading/src/main/java/parquet/cascading/ParquetTBaseScheme.java": 4,
                "parquet-cascading/src/test/java/parquet/cascading/ParquetTBaseSchemeTest.java": 44
            },
            "is_test": true,
            "is_fix": false
        },
        "6232dafaeeea874433a1a735c96f856293514f20": {
            "datetime": "2013-08-07T17:32:27-07:00",
            "summary": "fix javadoc",
            "message": "fix javadoc\n",
            "diff": {
                "parquet-column/src/main/java/parquet/io/RecordReaderImplementation.java": 7
            },
            "is_test": false,
            "is_fix": false
        },
        "1fc0698ed64514c9e30de7892c3a1d142f3f5469": {
            "datetime": "2013-08-07T19:19:39-07:00",
            "summary": "Fix RLE bug with partial literal groups at end of stream.",
            "message": "Fix RLE bug with partial literal groups at end of stream.\n",
            "diff": {
                "parquet-column/src/main/java/parquet/column/values/dictionary/DictionaryValuesReader.java": 2,
                "parquet-column/src/main/java/parquet/column/values/rle/RunLengthBitPackingHybridDecoder.java": 15,
                "parquet-column/src/main/java/parquet/column/values/rle/RunLengthBitPackingHybridValuesReader.java": 2,
                "parquet-column/src/test/java/parquet/column/values/rle/RunLengthBitPackingHybridIntegrationTest.java": 8,
                "parquet-column/src/test/java/parquet/column/values/rle/TestRunLengthBitPackingHybridEncoder.java": 18
            },
            "is_test": true,
            "is_fix": false
        },
        "a9e2c7d5fc862fe422624e29b7bcb6a8dafdb2da": {
            "datetime": "2013-08-07T23:34:42-07:00",
            "summary": "Fix Short and Byte types in Hive SerDe.",
            "message": "Fix Short and Byte types in Hive SerDe.\n",
            "diff": {
                "parquet-hive/src/main/java/parquet/hive/serde/ArrayWritableObjectInspector.java": 75,
                "parquet-hive/src/main/java/parquet/hive/write/DataWritableWriter.java": 6
            },
            "is_test": false,
            "is_fix": false
        },
        "f17b83c6a6a84a5462263593bdf106804390c648": {
            "datetime": "2013-08-09T13:54:11-07:00",
            "summary": "added unit tests for parquet cascading",
            "message": "added unit tests for parquet cascading\n",
            "diff": {
                "parquet-cascading/src/test/java/parquet/cascading/ParquetTBaseSchemeTest.java": 27,
                "parquet-cascading/src/test/java/parquet/cascading/ParquetTupleSchemeTest.java": 87,
                "parquet-scrooge/src/test/parquet/scrooge/ParquetScroogeSchemeTest.java": 11
            },
            "is_test": true,
            "is_fix": false
        },
        "7e16d31a2729e06c9c9f753af2bbe47b3751fa44": {
            "datetime": "2013-08-09T13:58:58-07:00",
            "summary": "better format",
            "message": "better format\n",
            "diff": {
                "parquet-cascading/src/test/java/parquet/cascading/ParquetTupleSchemeTest.java": 59,
                "parquet-cascading/src/test/java/parquet/cascading/TestParquetTBaseScheme.java": 18
            },
            "is_test": true,
            "is_fix": false
        },
        "f327ecff9dceb2013237a89a0b0740ffea558a0c": {
            "datetime": "2013-08-09T14:11:35-07:00",
            "summary": "format",
            "message": "format\n",
            "diff": {
                "parquet-cascading/src/test/java/parquet/cascading/ParquetTupleSchemeTest.java": 2,
                "parquet-scrooge/src/test/parquet/scrooge/ParquetScroogeSchemeTest.java": 11
            },
            "is_test": true,
            "is_fix": false
        },
        "e4269e64a18f18c9fa83e39d9ca3a9c7479a8245": {
            "datetime": "2013-08-09T14:14:29-07:00",
            "summary": "remove blank lines",
            "message": "remove blank lines\n",
            "diff": {
                "parquet-cascading/src/test/java/parquet/cascading/TestParquetTupleScheme.java": 3
            },
            "is_test": true,
            "is_fix": false
        },
        "3a3b73a68d3c50e86e4d2372511b9ee99d9b9fe3": {
            "datetime": "2013-08-09T17:42:49-07:00",
            "summary": "Merge pull request #126 from Parquet/unit_tests_for_parquet_cascading",
            "message": "Merge pull request #126 from Parquet/unit_tests_for_parquet_cascading\n\nUnit tests for parquet cascading",
            "diff": {
                "parquet-cascading/src/test/java/parquet/cascading/ParquetTBaseSchemeTest.java": 29,
                "parquet-cascading/src/test/java/parquet/cascading/TestParquetTupleScheme.java": 79
            },
            "is_test": true,
            "is_fix": false
        },
        "3c869369c31f7b5111144e20eada313877fdf78e": {
            "datetime": "2013-08-09T17:44:54-07:00",
            "summary": "Merge pull request #120 from Parquet/rle_fix",
            "message": "Merge pull request #120 from Parquet/rle_fix\n\nFix RLE bug with partial literal groups at end of stream.",
            "diff": {
                "parquet-column/src/main/java/parquet/column/values/dictionary/DictionaryValuesReader.java": 2,
                "parquet-column/src/main/java/parquet/column/values/rle/RunLengthBitPackingHybridDecoder.java": 15,
                "parquet-column/src/main/java/parquet/column/values/rle/RunLengthBitPackingHybridValuesReader.java": 2,
                "parquet-column/src/test/java/parquet/column/values/rle/RunLengthBitPackingHybridIntegrationTest.java": 8,
                "parquet-column/src/test/java/parquet/column/values/rle/TestRunLengthBitPackingHybridEncoder.java": 18
            },
            "is_test": true,
            "is_fix": false
        },
        "8d6661106c2511b0b9525016278d5f2ec3947956": {
            "datetime": "2013-08-12T17:17:26+01:00",
            "summary": "adding dictionary encoding for long,double,int,float",
            "message": "adding dictionary encoding for long,double,int,float\n",
            "diff": {
                "parquet-column/src/main/java/parquet/column/Encoding.java": 24,
                "parquet-column/src/main/java/parquet/column/impl/ColumnWriterImpl.java": 8,
                "parquet-column/src/main/java/parquet/column/values/dictionary/DictionaryValuesReader.java": 36,
                "parquet-column/src/main/java/parquet/column/values/dictionary/DictionaryValuesWriter.java": 373,
                "parquet-column/src/main/java/parquet/column/values/dictionary/PlainBinaryDictionary.java": 82,
                "parquet-column/src/main/java/parquet/column/values/dictionary/PlainValuesDictionary.java": 208,
                "parquet-column/src/test/java/parquet/column/values/dictionary/TestDictionary.java": 389
            },
            "is_test": true,
            "is_fix": false
        },
        "28da58cd571f5c23397f3865333c24d434e7aa89": {
            "datetime": "2013-08-12T13:50:27-07:00",
            "summary": "Fix Snappy compressor in parquet-hadoop.",
            "message": "Fix Snappy compressor in parquet-hadoop.\n",
            "diff": {
                "parquet-hadoop/src/main/java/parquet/hadoop/codec/NonBlockedCompressorStream.java": 32,
                "parquet-hadoop/src/main/java/parquet/hadoop/codec/NonBlockedDecompressorStream.java": 39,
                "parquet-hadoop/src/main/java/parquet/hadoop/codec/SnappyCodec.java": 6,
                "parquet-hadoop/src/main/java/parquet/hadoop/codec/SnappyCompressor.java": 12,
                "parquet-hadoop/src/main/java/parquet/hadoop/codec/SnappyDecompressor.java": 30,
                "parquet-hadoop/src/main/java/parquet/hadoop/codec/SnappyUtil.java": 3,
                "parquet-hadoop/src/test/java/parquet/hadoop/TestSnappyCodec.java": 55
            },
            "is_test": true,
            "is_fix": false
        },
        "87228ebd3a778ec4abacd9288a4872d7ec2c95f0": {
            "datetime": "2013-08-13T23:33:12+01:00",
            "summary": "refactoring dictionary encoding for non string types after comments #127",
            "message": "refactoring dictionary encoding for non string types after comments #127\n",
            "diff": {
                "parquet-column/src/main/java/parquet/column/Encoding.java": 12,
                "parquet-column/src/main/java/parquet/column/impl/ColumnWriterImpl.java": 56,
                "parquet-column/src/main/java/parquet/column/values/dictionary/DictionaryValuesWriter.java": 561,
                "parquet-column/src/main/java/parquet/column/values/dictionary/PlainValuesDictionary.java": 305,
                "parquet-column/src/test/java/parquet/column/values/dictionary/TestDictionary.java": 28
            },
            "is_test": true,
            "is_fix": false
        },
        "12bc29a405b6e0bcf25c7412f1b3b6649c6819c6": {
            "datetime": "2013-08-13T15:43:15-07:00",
            "summary": "split out method to facilitate the inliner job",
            "message": "split out method to facilitate the inliner job\n",
            "diff": {
                "parquet-column/src/main/java/parquet/column/impl/ColumnReaderImpl.java": 80,
                "parquet-column/src/test/java/parquet/io/PerfTest.java": 1
            },
            "is_test": true,
            "is_fix": false
        },
        "99673f2fa7b36ad2fae41cbb2eb2cd27424e9883": {
            "datetime": "2013-08-13T16:36:05-07:00",
            "summary": "Merge pull request #127 from atkeano/dictionary_encodings",
            "message": "Merge pull request #127 from atkeano/dictionary_encodings\n\nAdding dictionary encoding for non string types.. #99",
            "diff": {
                "parquet-column/src/main/java/parquet/column/Encoding.java": 32,
                "parquet-column/src/main/java/parquet/column/impl/ColumnWriterImpl.java": 52,
                "parquet-column/src/main/java/parquet/column/values/dictionary/DictionaryValuesReader.java": 36,
                "parquet-column/src/main/java/parquet/column/values/dictionary/DictionaryValuesWriter.java": 524,
                "parquet-column/src/main/java/parquet/column/values/dictionary/PlainBinaryDictionary.java": 82,
                "parquet-column/src/main/java/parquet/column/values/dictionary/PlainValuesDictionary.java": 269,
                "parquet-column/src/test/java/parquet/column/values/dictionary/TestDictionary.java": 393
            },
            "is_test": true,
            "is_fix": false
        },
        "ce8c1a42849e3022b38807d3c597615925bf8544": {
            "datetime": "2013-08-13T16:39:18-07:00",
            "summary": "Merge pull request #118 from Parquet/refactor_column_reader",
            "message": "Merge pull request #118 from Parquet/refactor_column_reader\n\nRefactor column reader",
            "diff": {
                "parquet-column/src/main/java/parquet/column/ColumnReader.java": 13,
                "parquet-column/src/main/java/parquet/column/impl/ColumnReaderImpl.java": 215,
                "parquet-column/src/main/java/parquet/filter/AndRecordFilter.java": 5,
                "parquet-column/src/main/java/parquet/filter/ColumnRecordFilter.java": 10,
                "parquet-column/src/main/java/parquet/filter/PagedRecordFilter.java": 8,
                "parquet-column/src/main/java/parquet/filter/RecordFilter.java": 5,
                "parquet-column/src/main/java/parquet/io/FilteredRecordReader.java": 24,
                "parquet-column/src/main/java/parquet/io/MessageColumnIO.java": 6,
                "parquet-column/src/main/java/parquet/io/RecordReaderImplementation.java": 6,
                "parquet-column/src/test/java/parquet/column/mem/TestMemColumn.java": 16,
                "parquet-column/src/test/java/parquet/column/mem/TestMemPageStore.java": 2,
                "parquet-column/src/test/java/parquet/column/page/mem/MemPageStore.java": 12,
                "parquet-column/src/test/java/parquet/io/PerfTest.java": 20,
                "parquet-column/src/test/java/parquet/io/TestColumnIO.java": 14,
                "parquet-column/src/test/java/parquet/io/TestFiltered.java": 76,
                "parquet-hive/src/test/java/parquet/hive/TestDeprecatedParquetInputFormat.java": 2,
                "parquet-pig/src/test/java/parquet/pig/GenerateIntTestFile.java": 2,
                "parquet-pig/src/test/java/parquet/pig/GenerateTPCH.java": 2,
                "parquet-pig/src/test/java/parquet/pig/TupleConsumerPerfTest.java": 23,
                "parquet-thrift/src/test/java/parquet/thrift/TestParquetReadProtocol.java": 2
            },
            "is_test": true,
            "is_fix": false
        },
        "af45d9cc20d31f5fd103dac3de8b850d00b18f17": {
            "datetime": "2013-08-14T17:41:36-07:00",
            "summary": "fix bug of wrong column metadata size",
            "message": "fix bug of wrong column metadata size\n",
            "diff": {
                "parquet-hadoop/src/main/java/parquet/format/converter/ParquetMetadataConverter.java": 4
            },
            "is_test": false,
            "is_fix": false
        },
        "3fb938b9e09271c5e8919e4cdff671ba7d6a0593": {
            "datetime": "2013-08-14T18:15:39-07:00",
            "summary": "Merge pull request #138 from Parquet/fix_column_metadata_size",
            "message": "Merge pull request #138 from Parquet/fix_column_metadata_size\n\nfix bug of wrong column metadata size",
            "diff": {
                "parquet-hadoop/src/main/java/parquet/format/converter/ParquetMetadataConverter.java": 4
            },
            "is_test": false,
            "is_fix": false
        },
        "6ff02643a66b1e25ac3edca94433ac7c7e781f7d": {
            "datetime": "2013-08-15T09:23:01-07:00",
            "summary": "Implemented partial schema for GroupReadSupport",
            "message": "Implemented partial schema for GroupReadSupport\n",
            "diff": {
                "parquet-hadoop/src/main/java/parquet/hadoop/example/GroupReadSupport.java": 5
            },
            "is_test": false,
            "is_fix": false
        },
        "c9b213cfce3d7d24fdd23471ce5b9dd970f7fc3d": {
            "datetime": "2013-08-15T11:43:56-07:00",
            "summary": "Merge pull request #123 from Parquet/snappy_codec",
            "message": "Merge pull request #123 from Parquet/snappy_codec\n\nFix Snappy compressor in parquet-hadoop.",
            "diff": {
                "parquet-hadoop/src/main/java/parquet/hadoop/codec/NonBlockedCompressorStream.java": 32,
                "parquet-hadoop/src/main/java/parquet/hadoop/codec/NonBlockedDecompressorStream.java": 39,
                "parquet-hadoop/src/main/java/parquet/hadoop/codec/SnappyCodec.java": 6,
                "parquet-hadoop/src/main/java/parquet/hadoop/codec/SnappyCompressor.java": 12,
                "parquet-hadoop/src/main/java/parquet/hadoop/codec/SnappyDecompressor.java": 30,
                "parquet-hadoop/src/main/java/parquet/hadoop/codec/SnappyUtil.java": 3,
                "parquet-hadoop/src/test/java/parquet/hadoop/TestSnappyCodec.java": 55
            },
            "is_test": true,
            "is_fix": false
        },
        "a274684f2257aecb27404130a938758cd36504e9": {
            "datetime": "2013-08-15T12:03:15-07:00",
            "summary": "added 3 counters to parquet for benchmarking bytes read and time spent",
            "message": "added 3 counters to parquet for benchmarking bytes read and time spent\n",
            "diff": {
                "parquet-hadoop/src/main/java/parquet/hadoop/InternalParquetRecordReader.java": 2,
                "parquet-hadoop/src/main/java/parquet/hadoop/ParquetFileReader.java": 3,
                "parquet-hadoop/src/main/java/parquet/hadoop/ParquetRecordReader.java": 5,
                "parquet-hadoop/src/main/java/parquet/hadoop/util/BenchmarkCounter.java": 59,
                "parquet-hadoop/src/main/java/parquet/hadoop/util/ContextUtil.java": 23,
                "parquet-hadoop/src/test/java/parquet/hadoop/example/TestInputOutputFormat.java": 103
            },
            "is_test": true,
            "is_fix": false
        },
        "43ad5e5257e03e8fb6ad738d61bf1e4ae132b6fc": {
            "datetime": "2013-08-15T12:04:39-07:00",
            "summary": "fix test",
            "message": "fix test\n",
            "diff": {
                "parquet-hadoop/src/test/java/parquet/hadoop/example/TestInputOutputFormat.java": 2
            },
            "is_test": true,
            "is_fix": false
        },
        "2cc9321b41806955d55358e361d454d31f4f0627": {
            "datetime": "2013-08-15T12:13:15-07:00",
            "summary": "add test for no benchmark counters",
            "message": "add test for no benchmark counters\n",
            "diff": {
                "parquet-hadoop/src/test/java/parquet/hadoop/example/TestInputOutputFormat.java": 24
            },
            "is_test": true,
            "is_fix": false
        },
        "ccf32c7ce4cd85556336fe769389f3f257668ecb": {
            "datetime": "2013-08-15T14:54:16-07:00",
            "summary": "remove comments",
            "message": "remove comments\n",
            "diff": {
                "parquet-hadoop/src/main/java/parquet/hadoop/util/BenchmarkCounter.java": 3
            },
            "is_test": false,
            "is_fix": false
        },
        "ea62ffe142871844b605d5300bd2a07dff785f17": {
            "datetime": "2013-08-15T15:25:41-07:00",
            "summary": "add unit test",
            "message": "add unit test\n",
            "diff": {
                "parquet-hadoop/src/test/java/parquet/hadoop/example/GroupReadSupportTest.java": 47
            },
            "is_test": true,
            "is_fix": false
        },
        "9394c097b9c19070fffd8143dcdcb4c60765be2d": {
            "datetime": "2013-08-15T15:55:47-07:00",
            "summary": "fix test",
            "message": "fix test\n",
            "diff": {
                "parquet-hadoop/src/test/java/parquet/hadoop/example/GroupReadSupportTest.java": 29
            },
            "is_test": true,
            "is_fix": false
        },
        "c2697261fdd7ebc10badaf89563ec4c2ed0c4804": {
            "datetime": "2013-08-15T15:57:29-07:00",
            "summary": "formatting",
            "message": "formatting\n",
            "diff": {
                "parquet-hadoop/src/test/java/parquet/hadoop/example/GroupReadSupportTest.java": 2
            },
            "is_test": true,
            "is_fix": false
        },
        "4288aa65dc642c23dd90110209653c4033f9dbe1": {
            "datetime": "2013-08-15T15:58:45-07:00",
            "summary": "formatting",
            "message": "formatting\n",
            "diff": {
                "parquet-hadoop/src/test/java/parquet/hadoop/example/GroupReadSupportTest.java": 3
            },
            "is_test": true,
            "is_fix": false
        },
        "d4ef8d958c1a0dfbda0334d183ed5843e2fb9496": {
            "datetime": "2013-08-15T16:06:05-07:00",
            "summary": "Merge pull request #140 from Parquet/partial_schema_for_group_read_support",
            "message": "Merge pull request #140 from Parquet/partial_schema_for_group_read_support\n\nImplemented partial schema for GroupReadSupport",
            "diff": {
                "parquet-hadoop/src/main/java/parquet/hadoop/example/GroupReadSupport.java": 5,
                "parquet-hadoop/src/test/java/parquet/hadoop/example/GroupReadSupportTest.java": 47
            },
            "is_test": true,
            "is_fix": false
        },
        "1323e4f80184c79dc5bd7cee642bbf8c398c8cf0": {
            "datetime": "2013-08-15T16:07:22-07:00",
            "summary": "Merge branch 'master' of https://github.com/Parquet/parquet-mr into hraven_counters",
            "message": "Merge branch 'master' of https://github.com/Parquet/parquet-mr into hraven_counters\n",
            "diff": {
                "parquet-hadoop/src/main/java/parquet/hadoop/codec/NonBlockedCompressorStream.java": 32,
                "parquet-hadoop/src/main/java/parquet/hadoop/codec/NonBlockedDecompressorStream.java": 39,
                "parquet-hadoop/src/main/java/parquet/hadoop/codec/SnappyCodec.java": 6,
                "parquet-hadoop/src/main/java/parquet/hadoop/codec/SnappyCompressor.java": 12,
                "parquet-hadoop/src/main/java/parquet/hadoop/codec/SnappyDecompressor.java": 30,
                "parquet-hadoop/src/main/java/parquet/hadoop/codec/SnappyUtil.java": 3,
                "parquet-hadoop/src/test/java/parquet/hadoop/TestSnappyCodec.java": 55,
                "parquet-hadoop/src/test/java/parquet/hadoop/example/GroupReadSupportTest.java": 47
            },
            "is_test": true,
            "is_fix": false
        },
        "397b4c9b59855db9ef4e27f3c72df1e043340cb4": {
            "datetime": "2013-08-15T16:28:01-07:00",
            "summary": "formatting",
            "message": "formatting\n",
            "diff": {
                "parquet-hadoop/src/main/java/parquet/hadoop/util/BenchmarkCounter.java": 18,
                "parquet-hadoop/src/test/java/parquet/hadoop/example/TestInputOutputFormat.java": 60
            },
            "is_test": true,
            "is_fix": false
        },
        "f8e2658581d8291281969aac53793b921ba49476": {
            "datetime": "2013-08-16T10:14:49-07:00",
            "summary": "fix incrementCounter getConfiguration method to support 2.0",
            "message": "fix incrementCounter getConfiguration method to support 2.0\n",
            "diff": {
                "parquet-hadoop/src/main/java/parquet/hadoop/util/BenchmarkCounter.java": 8,
                "parquet-hadoop/src/main/java/parquet/hadoop/util/ContextUtil.java": 17
            },
            "is_test": false,
            "is_fix": false
        },
        "3bebb9a160a3e181445f425a0b04f01f7818c649": {
            "datetime": "2013-08-16T14:04:00-07:00",
            "summary": "fix",
            "message": "fix\n",
            "diff": {
                "parquet-hadoop/src/main/java/parquet/hadoop/ParquetFileWriter.java": 1,
                "parquet-hadoop/src/main/java/parquet/hadoop/util/BenchmarkCounter.java": 7,
                "parquet-hadoop/src/test/java/parquet/hadoop/example/TestInputOutputFormat.java": 2
            },
            "is_test": true,
            "is_fix": false
        },
        "35c419cd8346b7db368bf1dbcfa7836ed32a9544": {
            "datetime": "2013-08-16T14:41:31-07:00",
            "summary": "remove public Constants",
            "message": "remove public Constants\n",
            "diff": {
                "parquet-hadoop/src/main/java/parquet/hadoop/util/BenchmarkCounter.java": 20,
                "parquet-hadoop/src/test/java/parquet/hadoop/example/TestInputOutputFormat.java": 22
            },
            "is_test": true,
            "is_fix": false
        },
        "cb6d3d2347762f50c277d3fcfef236af7b2cee52": {
            "datetime": "2013-08-18T22:00:44-07:00",
            "summary": "Merge pull request #141 from Parquet/hraven_counters",
            "message": "Merge pull request #141 from Parquet/hraven_counters\n\nadd parquet counters for benchmark",
            "diff": {
                "parquet-hadoop/src/main/java/parquet/hadoop/InternalParquetRecordReader.java": 2,
                "parquet-hadoop/src/main/java/parquet/hadoop/ParquetFileReader.java": 3,
                "parquet-hadoop/src/main/java/parquet/hadoop/ParquetRecordReader.java": 5,
                "parquet-hadoop/src/main/java/parquet/hadoop/util/BenchmarkCounter.java": 52,
                "parquet-hadoop/src/main/java/parquet/hadoop/util/ContextUtil.java": 38,
                "parquet-hadoop/src/test/java/parquet/hadoop/example/TestInputOutputFormat.java": 137
            },
            "is_test": true,
            "is_fix": false
        },
        "9ef85a0e14279e30775f7f77754952740306bda9": {
            "datetime": "2013-08-19T09:44:49-07:00",
            "summary": "merge",
            "message": "merge\n",
            "diff": {
                "parquet-hadoop/src/main/java/parquet/hadoop/util/BenchmarkCounter.java": 20,
                "parquet-hadoop/src/test/java/parquet/hadoop/example/TestInputOutputFormat.java": 22
            },
            "is_test": true,
            "is_fix": false
        },
        "42ad7014390491ace28ac2fc3a36ed6959ee4dbc": {
            "datetime": "2013-08-19T09:46:16-07:00",
            "summary": "fix test file path",
            "message": "fix test file path\n",
            "diff": {
                "parquet-hadoop/src/test/java/parquet/hadoop/example/TestInputOutputFormat.java": 2
            },
            "is_test": true,
            "is_fix": false
        },
        "4d1b3e06819eb3e2cde75b915115ce22a6580729": {
            "datetime": "2013-08-19T09:52:32-07:00",
            "summary": "add unit test",
            "message": "add unit test\n",
            "diff": {
                "parquet-hadoop/src/test/java/parquet/hadoop/TestParquetFileWriter.java": 1
            },
            "is_test": true,
            "is_fix": false
        },
        "09bfe990ea6951a7a03e42b825ab6734c89c4c58": {
            "datetime": "2013-08-19T10:10:05-07:00",
            "summary": "Merge pull request #124 from Parquet/serde",
            "message": "Merge pull request #124 from Parquet/serde\n\nFix Short and Byte types in Hive SerDe.",
            "diff": {
                "parquet-hive/src/main/java/parquet/hive/serde/ArrayWritableObjectInspector.java": 75,
                "parquet-hive/src/main/java/parquet/hive/write/DataWritableWriter.java": 6
            },
            "is_test": false,
            "is_fix": false
        },
        "92ce68dd021242974417c385a7e7288684f5dab7": {
            "datetime": "2013-08-19T10:20:40-07:00",
            "summary": "fixed",
            "message": "fixed\n",
            "diff": {
                "parquet-hadoop/src/main/java/parquet/hadoop/ParquetFileWriter.java": 1
            },
            "is_test": false,
            "is_fix": false
        },
        "77bede5537e89d83291f90f1a181d3342bd6b463": {
            "datetime": "2013-08-19T10:30:41-07:00",
            "summary": "add test",
            "message": "add test\n",
            "diff": {
                "parquet-hadoop/src/test/java/parquet/hadoop/TestParquetFileWriter.java": 11
            },
            "is_test": true,
            "is_fix": false
        },
        "fb670693ff737e2914f47943181f97ad11a12d5f": {
            "datetime": "2013-08-19T12:08:52-07:00",
            "summary": "fix space format",
            "message": "fix space format\n",
            "diff": {
                "parquet-hadoop/src/main/java/parquet/hadoop/ParquetFileWriter.java": 2
            },
            "is_test": false,
            "is_fix": false
        },
        "37bd05d266c9dc06b4c0a6e808eed256f7f2fa09": {
            "datetime": "2013-08-19T14:12:02-07:00",
            "summary": "Merge pull request #142 from Parquet/fix_total_size_row_group",
            "message": "Merge pull request #142 from Parquet/fix_total_size_row_group\n\nFix total size row group",
            "diff": {
                "parquet-hadoop/src/main/java/parquet/hadoop/ParquetFileWriter.java": 1,
                "parquet-hadoop/src/main/java/parquet/hadoop/util/BenchmarkCounter.java": 5,
                "parquet-hadoop/src/test/java/parquet/hadoop/TestParquetFileWriter.java": 1
            },
            "is_test": true,
            "is_fix": false
        },
        "f61a123dbbe21d060f7fa21342cc402b83a81805": {
            "datetime": "2013-08-20T09:39:40-07:00",
            "summary": "Merge branch 'master' of https://github.com/Parquet/parquet-mr into fix_empty_encoding_col_metadata",
            "message": "Merge branch 'master' of https://github.com/Parquet/parquet-mr into fix_empty_encoding_col_metadata\n",
            "diff": {
                "parquet-hadoop/src/main/java/parquet/hadoop/ParquetFileWriter.java": 2,
                "parquet-hive/src/main/java/parquet/hive/serde/ArrayWritableObjectInspector.java": 75,
                "parquet-hive/src/main/java/parquet/hive/write/DataWritableWriter.java": 6
            },
            "is_test": false,
            "is_fix": false
        },
        "d2878f8b134f64afe6c6179d56e1f30df36ea958": {
            "datetime": "2013-08-20T17:57:32-07:00",
            "summary": "Merge pull request #143 from Parquet/fix_empty_encoding_col_metadata",
            "message": "Merge pull request #143 from Parquet/fix_empty_encoding_col_metadata\n\nFix empty encoding col metadata",
            "diff": {
                "parquet-hadoop/src/main/java/parquet/hadoop/ParquetFileWriter.java": 1,
                "parquet-hadoop/src/test/java/parquet/hadoop/TestParquetFileWriter.java": 11
            },
            "is_test": true,
            "is_fix": false
        },
        "8f93adfd0020939b9a58f092b88a5f62fd14b834": {
            "datetime": "2013-08-20T18:13:50-07:00",
            "summary": "Map key fields should allow other types than strings",
            "message": "Map key fields should allow other types than strings\n",
            "diff": {
                "parquet-avro/src/main/java/parquet/avro/AvroSchemaConverter.java": 11,
                "parquet-avro/src/main/java/parquet/avro/AvroWriteSupport.java": 2,
                "parquet-column/src/main/java/parquet/example/data/simple/SimpleGroup.java": 2,
                "parquet-column/src/main/java/parquet/io/ColumnIO.java": 2,
                "parquet-column/src/main/java/parquet/io/ColumnIOFactory.java": 2,
                "parquet-column/src/main/java/parquet/io/GroupColumnIO.java": 6,
                "parquet-column/src/main/java/parquet/io/ValidatingRecordConsumer.java": 2,
                "parquet-column/src/main/java/parquet/schema/ConversionPatterns.java": 22,
                "parquet-column/src/main/java/parquet/schema/GroupType.java": 4,
                "parquet-column/src/main/java/parquet/schema/PrimitiveType.java": 4,
                "parquet-column/src/main/java/parquet/schema/Type.java": 4,
                "parquet-pig/src/main/java/parquet/pig/ParquetLoader.java": 1,
                "parquet-pig/src/main/java/parquet/pig/PigSchemaConverter.java": 134,
                "parquet-pig/src/main/java/parquet/pig/TupleReadSupport.java": 15,
                "parquet-pig/src/main/java/parquet/pig/convert/MapConverter.java": 18,
                "parquet-pig/src/main/java/parquet/pig/convert/TupleConverter.java": 2,
                "parquet-pig/src/test/java/parquet/pig/TestPigSchemaConverter.java": 35,
                "parquet-pig/src/test/java/parquet/pig/TupleConsumerPerfTest.java": 3,
                "parquet-thrift/src/main/java/parquet/thrift/ThriftSchemaConverter.java": 8,
                "parquet-thrift/src/test/java/parquet/hadoop/thrift/TestThriftToParquetFileWriter.java": 155
            },
            "is_test": true,
            "is_fix": false
        },
        "9adb8e24baa3909d91691de2ee7faf2a41e6d7d6": {
            "datetime": "2013-08-21T15:23:44-07:00",
            "summary": "code review changes",
            "message": "code review changes\n",
            "diff": {
                "parquet-column/src/main/java/parquet/column/impl/ColumnReaderImpl.java": 18,
                "parquet-column/src/main/java/parquet/schema/PrimitiveType.java": 36,
                "parquet-pig/src/main/java/parquet/pig/PigSchemaConverter.java": 104
            },
            "is_test": false,
            "is_fix": false
        },
        "c22a357252cdbac4b92af8ebb72f224d6f686508": {
            "datetime": "2013-08-21T16:23:00-07:00",
            "summary": "Merge pull request #144 from aniket486/map_support",
            "message": "Merge pull request #144 from aniket486/map_support\n\nMap key fields should allow other types than strings",
            "diff": {
                "parquet-avro/src/main/java/parquet/avro/AvroSchemaConverter.java": 11,
                "parquet-avro/src/main/java/parquet/avro/AvroWriteSupport.java": 2,
                "parquet-column/src/main/java/parquet/column/impl/ColumnReaderImpl.java": 18,
                "parquet-column/src/main/java/parquet/example/data/simple/SimpleGroup.java": 2,
                "parquet-column/src/main/java/parquet/io/ColumnIO.java": 2,
                "parquet-column/src/main/java/parquet/io/ColumnIOFactory.java": 2,
                "parquet-column/src/main/java/parquet/io/GroupColumnIO.java": 6,
                "parquet-column/src/main/java/parquet/io/ValidatingRecordConsumer.java": 2,
                "parquet-column/src/main/java/parquet/schema/ConversionPatterns.java": 22,
                "parquet-column/src/main/java/parquet/schema/GroupType.java": 4,
                "parquet-column/src/main/java/parquet/schema/PrimitiveType.java": 40,
                "parquet-column/src/main/java/parquet/schema/Type.java": 4,
                "parquet-pig/src/main/java/parquet/pig/ParquetLoader.java": 1,
                "parquet-pig/src/main/java/parquet/pig/PigSchemaConverter.java": 170,
                "parquet-pig/src/main/java/parquet/pig/TupleReadSupport.java": 15,
                "parquet-pig/src/main/java/parquet/pig/convert/MapConverter.java": 18,
                "parquet-pig/src/main/java/parquet/pig/convert/TupleConverter.java": 2,
                "parquet-pig/src/test/java/parquet/pig/TestPigSchemaConverter.java": 35,
                "parquet-pig/src/test/java/parquet/pig/TupleConsumerPerfTest.java": 3,
                "parquet-thrift/src/main/java/parquet/thrift/ThriftSchemaConverter.java": 8,
                "parquet-thrift/src/test/java/parquet/hadoop/thrift/TestThriftToParquetFileWriter.java": 155
            },
            "is_test": true,
            "is_fix": false
        },
        "b500681226f4a87bed01cdbd99d69e603836cd6d": {
            "datetime": "2013-08-21T23:52:19-07:00",
            "summary": "add getStatistics method to parquetloader",
            "message": "add getStatistics method to parquetloader\n",
            "diff": {
                "parquet-pig/src/main/java/parquet/pig/ParquetLoader.java": 16
            },
            "is_test": false,
            "is_fix": false
        },
        "e5b767ab75e8cb09fe18d2e83d061a0a285f54c8": {
            "datetime": "2013-08-22T10:56:44+02:00",
            "summary": "Add some nested type tests and fix Map handling",
            "message": "Add some nested type tests and fix Map handling\n\n- Add nested type unit tests to hive-parquet schema converter\n- Add map and list to the serde unit test\n",
            "diff": {
                "parquet-hive/src/main/java/parquet/hive/DeprecatedParquetInputFormat.java": 2,
                "parquet-hive/src/main/java/parquet/hive/convert/ArrayWritableGroupConverter.java": 29,
                "parquet-hive/src/main/java/parquet/hive/serde/ParquetHiveMapInspector.java": 9,
                "parquet-hive/src/test/java/parquet/hive/TestDeprecatedParquetInputFormat.java": 7,
                "parquet-hive/src/test/java/parquet/hive/TestDeprecatedParquetOuputFormat.java": 19,
                "parquet-hive/src/test/java/parquet/hive/TestHiveSchemaConverter.java": 56,
                "parquet-hive/src/test/java/parquet/hive/TestParquetSerDe.java": 76,
                "parquet-hive/src/test/java/parquet/hive/UtilitiesTestMethods.java": 6
            },
            "is_test": true,
            "is_fix": false
        },
        "8cc147b37b85f22cd6a79d5d8508a1b34e91d679": {
            "datetime": "2013-08-22T10:56:52+02:00",
            "summary": "Add map and list to in/outputformat unit tests",
            "message": "Add map and list to in/outputformat unit tests\n",
            "diff": {
                "parquet-hive/src/test/java/parquet/hive/TestDeprecatedParquetInputFormat.java": 51,
                "parquet-hive/src/test/java/parquet/hive/TestDeprecatedParquetOuputFormat.java": 33,
                "parquet-hive/src/test/java/parquet/hive/TestParquetSerDe.java": 28,
                "parquet-hive/src/test/java/parquet/hive/UtilitiesTestMethods.java": 78
            },
            "is_test": true,
            "is_fix": false
        },
        "c76880d8d94a7666ab5456be370928e3500efa5c": {
            "datetime": "2013-08-22T11:37:58-07:00",
            "summary": "Merge pull request #146 from Parquet/hive_nested_types",
            "message": "Merge pull request #146 from Parquet/hive_nested_types\n\nFix and add unit tests for Hive nested types",
            "diff": {
                "parquet-hive/src/main/java/parquet/hive/DeprecatedParquetInputFormat.java": 2,
                "parquet-hive/src/main/java/parquet/hive/convert/ArrayWritableGroupConverter.java": 29,
                "parquet-hive/src/main/java/parquet/hive/serde/ParquetHiveMapInspector.java": 9,
                "parquet-hive/src/test/java/parquet/hive/TestDeprecatedParquetInputFormat.java": 58,
                "parquet-hive/src/test/java/parquet/hive/TestDeprecatedParquetOuputFormat.java": 52,
                "parquet-hive/src/test/java/parquet/hive/TestHiveSchemaConverter.java": 56,
                "parquet-hive/src/test/java/parquet/hive/TestParquetSerDe.java": 50,
                "parquet-hive/src/test/java/parquet/hive/UtilitiesTestMethods.java": 82
            },
            "is_test": true,
            "is_fix": false
        },
        "808a90d9a11a3f17caf3dcdbd461d5b6bfda15e7": {
            "datetime": "2013-08-25T12:59:58-07:00",
            "summary": "changing default block size to 128mb",
            "message": "changing default block size to 128mb\n",
            "diff": {
                "parquet-hadoop/src/main/java/parquet/hadoop/ParquetOutputFormat.java": 2,
                "parquet-hadoop/src/main/java/parquet/hadoop/ParquetWriter.java": 2
            },
            "is_test": false,
            "is_fix": false
        },
        "4202efbe7bf5373539f18a8b7c08ebefeda7f755": {
            "datetime": "2013-08-25T14:30:10-07:00",
            "summary": "Merge pull request #149 from aniket486/change_block_size",
            "message": "Merge pull request #149 from aniket486/change_block_size\n\nchanging default block size to 128mb",
            "diff": {
                "parquet-hadoop/src/main/java/parquet/hadoop/ParquetOutputFormat.java": 2,
                "parquet-hadoop/src/main/java/parquet/hadoop/ParquetWriter.java": 2
            },
            "is_test": false,
            "is_fix": false
        }
    },
    "2013-08-26T15:17:05-07:00": {
        "aab7b4b672915fd587bf47640b3a82873ef7aef9": {
            "datetime": "2013-08-26T16:08:23-07:00",
            "summary": "code review comments for stats",
            "message": "code review comments for stats\n",
            "diff": {
                "parquet-pig/src/main/java/parquet/pig/ParquetLoader.java": 17
            },
            "is_test": false,
            "is_fix": false
        },
        "4b4fb0e59ad2d804d8e0344a7ef695aeb2c9a175": {
            "datetime": "2013-08-26T16:26:29-07:00",
            "summary": "Merge pull request #145 from aniket486/stats_loader",
            "message": "Merge pull request #145 from aniket486/stats_loader\n\nadd getStatistics method to parquetloader",
            "diff": {
                "parquet-pig/src/main/java/parquet/pig/ParquetLoader.java": 21
            },
            "is_test": false,
            "is_fix": false
        },
        "7b2ef26003ab455bb03a696ea6583bcf73c8a9ad": {
            "datetime": "2013-08-27T15:21:27-07:00",
            "summary": "add thrift validation on read",
            "message": "add thrift validation on read\n",
            "diff": {
                "parquet-thrift/src/main/java/parquet/hadoop/thrift/ThriftBytesWriteSupport.java": 16,
                "parquet-thrift/src/main/java/parquet/thrift/BufferedProtocolReadToWrite.java": 52,
                "parquet-thrift/src/main/java/parquet/thrift/struct/ThriftType.java": 20,
                "parquet-thrift/src/main/java/parquet/thrift/struct/ThriftTypeID.java": 20,
                "parquet-thrift/src/test/java/parquet/hadoop/thrift/TestThriftToParquetFileWriter.java": 26,
                "parquet-thrift/src/test/java/parquet/thrift/TestProtocolReadToWrite.java": 2
            },
            "is_test": true,
            "is_fix": false
        },
        "8a8354b73f61e1aad5a04ced61be5d7fcb26caf5": {
            "datetime": "2013-08-27T21:23:25-07:00",
            "summary": "add better error message",
            "message": "add better error message\n",
            "diff": {
                "parquet-thrift/src/main/java/parquet/thrift/BufferedProtocolReadToWrite.java": 90
            },
            "is_test": false,
            "is_fix": false
        },
        "71a6d880fb98903240b4bf996ac9d51f9c11a663": {
            "datetime": "2013-08-27T22:20:15-07:00",
            "summary": "add better error message",
            "message": "add better error message\n",
            "diff": {
                "parquet-thrift/src/main/java/parquet/thrift/BufferedProtocolReadToWrite.java": 6
            },
            "is_test": false,
            "is_fix": false
        },
        "c8ba085bffbe0a4a9f56fdd249e0b5945cf4c832": {
            "datetime": "2013-08-27T23:16:05-07:00",
            "summary": "Merge pull request #150 from Parquet/add_thrift_validation",
            "message": "Merge pull request #150 from Parquet/add_thrift_validation\n\nadd thrift validation on read",
            "diff": {
                "parquet-thrift/src/main/java/parquet/hadoop/thrift/ThriftBytesWriteSupport.java": 16,
                "parquet-thrift/src/main/java/parquet/thrift/BufferedProtocolReadToWrite.java": 152,
                "parquet-thrift/src/main/java/parquet/thrift/struct/ThriftType.java": 20,
                "parquet-thrift/src/main/java/parquet/thrift/struct/ThriftTypeID.java": 20,
                "parquet-thrift/src/test/java/parquet/hadoop/thrift/TestThriftToParquetFileWriter.java": 26,
                "parquet-thrift/src/test/java/parquet/thrift/TestProtocolReadToWrite.java": 2
            },
            "is_test": true,
            "is_fix": false
        },
        "91c17112f18ecae914c7f670439a81dcd4041456": {
            "datetime": "2013-08-28T10:51:19-07:00",
            "summary": "fix projection on required fields and refactored unit tests for column IO",
            "message": "fix projection on required fields and refactored unit tests for column IO\n",
            "diff": {
                "parquet-column/src/main/java/parquet/io/ColumnIOFactory.java": 4,
                "parquet-column/src/test/java/parquet/io/TestColumnIO.java": 134,
                "parquet-hadoop/src/test/java/parquet/hadoop/example/TestInputOutputFormat.java": 30
            },
            "is_test": true,
            "is_fix": false
        },
        "69ef1f447b4fbebcc528eab9cb782272eff9cb30": {
            "datetime": "2013-08-28T10:52:27-07:00",
            "summary": "fix file path",
            "message": "fix file path\n",
            "diff": {
                "parquet-hadoop/src/test/java/parquet/hadoop/example/TestInputOutputFormat.java": 2
            },
            "is_test": true,
            "is_fix": false
        },
        "c023d63eaf92b4a9f35c134c81f0fee31de1f6d0": {
            "datetime": "2013-08-28T17:31:49-07:00",
            "summary": "improve thrift error message",
            "message": "improve thrift error message\n",
            "diff": {
                "parquet-thrift/src/main/java/parquet/thrift/BufferedProtocolReadToWrite.java": 19,
                "parquet-thrift/src/test/java/parquet/thrift/TestProtocolReadToWrite.java": 30
            },
            "is_test": true,
            "is_fix": false
        },
        "bde6493d920178d1966c11d7ae5a97e4413d9feb": {
            "datetime": "2013-08-29T10:46:51-07:00",
            "summary": "Merge pull request #153 from Parquet/fix_projection_required_field",
            "message": "Merge pull request #153 from Parquet/fix_projection_required_field\n\nFix projection required field",
            "diff": {
                "parquet-column/src/main/java/parquet/io/ColumnIOFactory.java": 4,
                "parquet-column/src/test/java/parquet/io/TestColumnIO.java": 134,
                "parquet-hadoop/src/test/java/parquet/hadoop/example/TestInputOutputFormat.java": 28
            },
            "is_test": true,
            "is_fix": false
        },
        "ec4632917549fe10e4cc26c2d6b9064a9b06e5cd": {
            "datetime": "2013-08-29T15:26:55-07:00",
            "summary": "use globbing syntax to specify manual pushdown in ThriftReadSupport",
            "message": "use globbing syntax to specify manual pushdown in ThriftReadSupport\n",
            "diff": {
                "parquet-hadoop/src/main/java/parquet/hadoop/api/ReadSupport.java": 95,
                "parquet-thrift/src/main/java/parquet/hadoop/thrift/ThriftReadSupport.java": 32,
                "parquet-thrift/src/main/java/parquet/thrift/TBaseRecordConverter.java": 4,
                "parquet-thrift/src/main/java/parquet/thrift/ThriftRecordConverter.java": 6,
                "parquet-thrift/src/main/java/parquet/thrift/ThriftSchemaConverter.java": 139,
                "parquet-thrift/src/main/java/parquet/thrift/projection/FieldProjectionFilter.java": 71,
                "parquet-thrift/src/main/java/parquet/thrift/projection/PathGlobPattern.java": 161,
                "parquet-thrift/src/main/java/parquet/thrift/projection/ThriftProjectionException.java": 30,
                "parquet-thrift/src/test/java/parquet/hadoop/thrift/TestParquetToThriftReadProjection.java": 64,
                "parquet-thrift/src/test/java/parquet/thrift/TestThriftSchemaConverter.java": 197,
                "parquet-thrift/src/test/java/parquet/thrift/projection/PathGlobPatternTest.java": 39
            },
            "is_test": true,
            "is_fix": false
        },
        "17e251145f9e388de73b112694fb966a2d964ee7": {
            "datetime": "2013-08-29T15:27:03-07:00",
            "summary": "Merge branch 'master' of https://github.com/Parquet/parquet-mr into manual_pushdown_for_thrift_read_support",
            "message": "Merge branch 'master' of https://github.com/Parquet/parquet-mr into manual_pushdown_for_thrift_read_support\n",
            "diff": {
                "parquet-thrift/src/main/java/parquet/hadoop/thrift/ThriftBytesWriteSupport.java": 16,
                "parquet-thrift/src/main/java/parquet/thrift/BufferedProtocolReadToWrite.java": 152,
                "parquet-thrift/src/main/java/parquet/thrift/struct/ThriftType.java": 20,
                "parquet-thrift/src/main/java/parquet/thrift/struct/ThriftTypeID.java": 20,
                "parquet-thrift/src/test/java/parquet/hadoop/thrift/TestThriftToParquetFileWriter.java": 26,
                "parquet-thrift/src/test/java/parquet/thrift/TestProtocolReadToWrite.java": 2
            },
            "is_test": true,
            "is_fix": false
        },
        "30359b46fd6873defd71d5d3a224cb8675b67339": {
            "datetime": "2013-08-29T16:19:24-07:00",
            "summary": "remove TODOs and fix format",
            "message": "remove TODOs and fix format\n",
            "diff": {
                "parquet-thrift/src/main/java/parquet/hadoop/thrift/ThriftReadSupport.java": 6,
                "parquet-thrift/src/main/java/parquet/thrift/ThriftSchemaConverter.java": 18,
                "parquet-thrift/src/test/java/parquet/hadoop/thrift/TestParquetToThriftReadProjection.java": 5
            },
            "is_test": true,
            "is_fix": false
        },
        "459a8a193f8a61e92f6fbc5dbc079b194f25ae3c": {
            "datetime": "2013-09-04T12:02:30-07:00",
            "summary": "make counter works in DeprecatedInputFormat, which is used by cascading",
            "message": "make counter works in DeprecatedInputFormat, which is used by cascading\n",
            "diff": {
                "parquet-hadoop/src/main/java/parquet/hadoop/InternalParquetRecordReader.java": 2,
                "parquet-hadoop/src/main/java/parquet/hadoop/ParquetFileReader.java": 2,
                "parquet-hadoop/src/main/java/parquet/hadoop/ParquetRecordReader.java": 17,
                "parquet-hadoop/src/main/java/parquet/hadoop/mapred/DeprecatedParquetInputFormat.java": 2,
                "parquet-hadoop/src/main/java/parquet/hadoop/util/BenchmarkCounter.java": 53,
                "parquet-hadoop/src/main/java/parquet/hadoop/util/counters/BenchmarkCounter.java": 112,
                "parquet-hadoop/src/main/java/parquet/hadoop/util/counters/CounterLoader.java": 25,
                "parquet-hadoop/src/main/java/parquet/hadoop/util/counters/ICounter.java": 11,
                "parquet-hadoop/src/main/java/parquet/hadoop/util/counters/mapred/MapRedCounterAdapter.java": 41,
                "parquet-hadoop/src/main/java/parquet/hadoop/util/counters/mapred/MapRedCounterLoader.java": 46,
                "parquet-hadoop/src/main/java/parquet/hadoop/util/counters/mapreduce/MapReduceCounterAdapter.java": 42,
                "parquet-hadoop/src/main/java/parquet/hadoop/util/counters/mapreduce/MapReduceCounterLoader.java": 44,
                "parquet-hadoop/src/test/java/parquet/hadoop/DeprecatedInputFormatTest.java": 179
            },
            "is_test": true,
            "is_fix": false
        },
        "d20e5f2c01cd770babbca030f9bec5b2549c78b2": {
            "datetime": "2013-09-04T14:03:28-07:00",
            "summary": "fix tests",
            "message": "fix tests\n",
            "diff": {
                "parquet-hadoop/src/main/java/parquet/hadoop/ParquetRecordReader.java": 5,
                "parquet-hadoop/src/main/java/parquet/hadoop/util/counters/BenchmarkCounter.java": 1,
                "parquet-hadoop/src/test/java/parquet/hadoop/DeprecatedInputFormatTest.java": 2,
                "parquet-hadoop/src/test/java/parquet/hadoop/example/TestInputOutputFormat.java": 2
            },
            "is_test": true,
            "is_fix": false
        },
        "00065cd7c76df68e0c85476880476f44e5e5e36c": {
            "datetime": "2013-09-04T15:03:35-07:00",
            "summary": "change filter key name to parquet.thrift.column.filter, remove extra filter parameter from ThriftSchemaConverter",
            "message": "change filter key name to parquet.thrift.column.filter, remove extra filter parameter from ThriftSchemaConverter\n",
            "diff": {
                "parquet-thrift/src/main/java/parquet/hadoop/thrift/ThriftReadSupport.java": 6,
                "parquet-thrift/src/main/java/parquet/thrift/ThriftSchemaConverter.java": 18,
                "parquet-thrift/src/test/java/parquet/hadoop/thrift/TestParquetToThriftReadProjection.java": 2
            },
            "is_test": true,
            "is_fix": false
        },
        "bb06859085679798bca20b8c54f20f2e9e006082": {
            "datetime": "2013-09-04T15:20:52-07:00",
            "summary": "add license and comment",
            "message": "add license and comment\n",
            "diff": {
                "parquet-thrift/src/main/java/parquet/thrift/projection/ThriftProjectionException.java": 16,
                "parquet-thrift/src/test/java/parquet/thrift/projection/PathGlobPatternTest.java": 20
            },
            "is_test": true,
            "is_fix": false
        },
        "e371fbb247bdfe462e3b7ad2fd0fb4b788e23ce4": {
            "datetime": "2013-09-04T15:49:25-07:00",
            "summary": "add comment",
            "message": "add comment\n",
            "diff": {
                "parquet-hadoop/src/main/java/parquet/hadoop/util/counters/BenchmarkCounter.java": 2
            },
            "is_test": false,
            "is_fix": false
        },
        "6dfd97551fc1b8606704dcf656b185b34ceffcd4": {
            "datetime": "2013-09-04T16:52:39-07:00",
            "summary": "Merge pull request #159 from Parquet/counter_for_mapred",
            "message": "Merge pull request #159 from Parquet/counter_for_mapred\n\nCounter for mapred",
            "diff": {
                "parquet-hadoop/src/main/java/parquet/hadoop/InternalParquetRecordReader.java": 2,
                "parquet-hadoop/src/main/java/parquet/hadoop/ParquetFileReader.java": 2,
                "parquet-hadoop/src/main/java/parquet/hadoop/ParquetRecordReader.java": 20,
                "parquet-hadoop/src/main/java/parquet/hadoop/mapred/DeprecatedParquetInputFormat.java": 2,
                "parquet-hadoop/src/main/java/parquet/hadoop/util/BenchmarkCounter.java": 53,
                "parquet-hadoop/src/main/java/parquet/hadoop/util/counters/BenchmarkCounter.java": 111,
                "parquet-hadoop/src/main/java/parquet/hadoop/util/counters/CounterLoader.java": 25,
                "parquet-hadoop/src/main/java/parquet/hadoop/util/counters/ICounter.java": 11,
                "parquet-hadoop/src/main/java/parquet/hadoop/util/counters/mapred/MapRedCounterAdapter.java": 41,
                "parquet-hadoop/src/main/java/parquet/hadoop/util/counters/mapred/MapRedCounterLoader.java": 46,
                "parquet-hadoop/src/main/java/parquet/hadoop/util/counters/mapreduce/MapReduceCounterAdapter.java": 42,
                "parquet-hadoop/src/main/java/parquet/hadoop/util/counters/mapreduce/MapReduceCounterLoader.java": 44,
                "parquet-hadoop/src/test/java/parquet/hadoop/DeprecatedInputFormatTest.java": 179,
                "parquet-hadoop/src/test/java/parquet/hadoop/example/TestInputOutputFormat.java": 2
            },
            "is_test": true,
            "is_fix": false
        },
        "6b96924e855e8b74a43c0170185cafd4a81d4df8": {
            "datetime": "2013-09-04T16:53:35-07:00",
            "summary": "Merge pull request #155 from Parquet/manual_pushdown_for_thrift_read_support",
            "message": "Merge pull request #155 from Parquet/manual_pushdown_for_thrift_read_support\n\nManual pushdown for thrift read support",
            "diff": {
                "parquet-hadoop/src/main/java/parquet/hadoop/api/ReadSupport.java": 95,
                "parquet-thrift/src/main/java/parquet/hadoop/thrift/ThriftReadSupport.java": 36,
                "parquet-thrift/src/main/java/parquet/thrift/TBaseRecordConverter.java": 4,
                "parquet-thrift/src/main/java/parquet/thrift/ThriftRecordConverter.java": 6,
                "parquet-thrift/src/main/java/parquet/thrift/ThriftSchemaConverter.java": 135,
                "parquet-thrift/src/main/java/parquet/thrift/projection/FieldProjectionFilter.java": 71,
                "parquet-thrift/src/main/java/parquet/thrift/projection/PathGlobPattern.java": 161,
                "parquet-thrift/src/main/java/parquet/thrift/projection/ThriftProjectionException.java": 46,
                "parquet-thrift/src/test/java/parquet/hadoop/thrift/TestParquetToThriftReadProjection.java": 65,
                "parquet-thrift/src/test/java/parquet/thrift/TestThriftSchemaConverter.java": 197,
                "parquet-thrift/src/test/java/parquet/thrift/projection/PathGlobPatternTest.java": 57
            },
            "is_test": true,
            "is_fix": false
        },
        "b045ac18d613e226bf14ff9e3e1b6a0f93c26bae": {
            "datetime": "2013-09-04T17:30:48-07:00",
            "summary": "Resource leak in parquet.hadoop.ParquetFileReader.readFooter(Configuration, FileStatus)",
            "message": "Resource leak in parquet.hadoop.ParquetFileReader.readFooter(Configuration, FileStatus)\n",
            "diff": {
                "parquet-hadoop/src/main/java/parquet/hadoop/ParquetFileReader.java": 49
            },
            "is_test": false,
            "is_fix": false
        },
        "848fa8e1cca99ddf38b6f9827ffa73fefcdc1929": {
            "datetime": "2013-09-05T15:41:57-07:00",
            "summary": "support schema evolution",
            "message": "support schema evolution\n",
            "diff": {
                "parquet-column/src/main/java/parquet/schema/GroupType.java": 33,
                "parquet-column/src/main/java/parquet/schema/IncompatibleSchemaModificationException.java": 31,
                "parquet-column/src/main/java/parquet/schema/MessageType.java": 5,
                "parquet-column/src/main/java/parquet/schema/PrimitiveType.java": 8,
                "parquet-column/src/main/java/parquet/schema/Type.java": 5,
                "parquet-column/src/test/java/parquet/schema/TestMessageType.java": 68,
                "parquet-hadoop/src/main/java/parquet/hadoop/ParquetFileWriter.java": 77,
                "parquet-hadoop/src/main/java/parquet/hadoop/ParquetInputFormat.java": 24,
                "parquet-hadoop/src/main/java/parquet/hadoop/ParquetReader.java": 61,
                "parquet-hadoop/src/main/java/parquet/hadoop/api/InitContext.java": 57,
                "parquet-hadoop/src/main/java/parquet/hadoop/api/ReadSupport.java": 14,
                "parquet-hadoop/src/main/java/parquet/hadoop/metadata/FileMetaData.java": 3,
                "parquet-hadoop/src/main/java/parquet/hadoop/metadata/GlobalMetaData.java": 79,
                "parquet-hadoop/src/test/java/parquet/hadoop/TestParquetFileWriter.java": 19,
                "parquet-pig/src/main/java/parquet/pig/ParquetLoader.java": 58,
                "parquet-pig/src/main/java/parquet/pig/PigMetaData.java": 10,
                "parquet-pig/src/main/java/parquet/pig/PigSchemaConverter.java": 23,
                "parquet-pig/src/main/java/parquet/pig/TupleReadSupport.java": 97,
                "parquet-pig/src/test/java/parquet/pig/TestParquetLoader.java": 12,
                "parquet-pig/src/test/java/parquet/pig/TestParquetStorer.java": 64,
                "parquet-pig/src/test/java/parquet/pig/TestTupleRecordConsumer.java": 14
            },
            "is_test": true,
            "is_fix": false
        },
        "c32be9e4ef2169be9267dc4ef17c0b7f06db4927": {
            "datetime": "2013-09-05T16:51:18-07:00",
            "summary": "thrift schema evolution support",
            "message": "thrift schema evolution support\n",
            "diff": {
                "parquet-column/src/main/java/parquet/schema/GroupType.java": 4,
                "parquet-column/src/main/java/parquet/schema/MessageType.java": 2,
                "parquet-thrift/src/main/java/parquet/hadoop/thrift/ThriftReadSupport.java": 45,
                "parquet-thrift/src/main/java/parquet/thrift/ThriftMetaData.java": 31,
                "parquet-thrift/src/main/java/parquet/thrift/ThriftRecordConverter.java": 5,
                "parquet-thrift/src/test/java/parquet/hadoop/thrift/TestInputOutputFormat.java": 97
            },
            "is_test": true,
            "is_fix": false
        },
        "f369a13e0500604a7cd7276e6290fbae70ecb08c": {
            "datetime": "2013-09-05T17:02:51-07:00",
            "summary": "validate output",
            "message": "validate output\n",
            "diff": {
                "parquet-thrift/src/test/java/parquet/hadoop/thrift/TestInputOutputFormat.java": 21
            },
            "is_test": true,
            "is_fix": false
        },
        "f0d30dfb2274ef430d805d900f53ba8252f496ad": {
            "datetime": "2013-09-06T09:34:32-07:00",
            "summary": "refactor schema converter",
            "message": "refactor schema converter\n",
            "diff": {
                "parquet-thrift/src/main/java/parquet/thrift/ThriftSchemaConverter.java": 182,
                "parquet-thrift/src/main/java/parquet/thrift/projection/FieldProjectionFilter.java": 12,
                "parquet-thrift/src/main/java/parquet/thrift/projection/FieldsPath.java": 73
            },
            "is_test": false,
            "is_fix": false
        },
        "8faaaf087ceb7c3827e1e4d0c4ff7eefd9935ed0": {
            "datetime": "2013-09-06T11:12:55-07:00",
            "summary": "support projection on only key of a map",
            "message": "support projection on only key of a map\n",
            "diff": {
                "parquet-column/src/main/java/parquet/schema/ConversionPatterns.java": 14,
                "parquet-thrift/src/main/java/parquet/thrift/ThriftSchemaConverter.java": 3,
                "parquet-thrift/src/test/java/parquet/thrift/TestThriftSchemaConverter.java": 11
            },
            "is_test": true,
            "is_fix": false
        },
        "7f08eeed1ee16d2bec0b1caa7eee8cd664f3675b": {
            "datetime": "2013-09-06T11:56:41-07:00",
            "summary": "add license headers",
            "message": "add license headers\n",
            "diff": {
                "parquet-cascading/src/test/java/parquet/cascading/TestParquetTBaseScheme.java": 15,
                "parquet-cascading/src/test/java/parquet/cascading/TestParquetTupleScheme.java": 15,
                "parquet-column/src/main/java/parquet/column/values/dictionary/PlainValuesDictionary.java": 3,
                "parquet-column/src/main/java/parquet/schema/IncompatibleSchemaModificationException.java": 15,
                "parquet-hadoop/src/main/java/parquet/hadoop/api/InitContext.java": 15,
                "parquet-hadoop/src/main/java/parquet/hadoop/codec/NonBlockedCompressorStream.java": 15,
                "parquet-hadoop/src/main/java/parquet/hadoop/codec/NonBlockedDecompressorStream.java": 15,
                "parquet-hadoop/src/main/java/parquet/hadoop/metadata/GlobalMetaData.java": 15,
                "parquet-hadoop/src/main/java/parquet/hadoop/util/counters/ICounter.java": 15,
                "parquet-hadoop/src/test/java/parquet/hadoop/example/GroupReadSupportTest.java": 15
            },
            "is_test": true,
            "is_fix": false
        },
        "1a711f05d5ba1f8579efeac5b0652b3efecf27d4": {
            "datetime": "2013-09-06T15:40:35-07:00",
            "summary": "turn off projection from scrooge",
            "message": "turn off projection from scrooge\n",
            "diff": {
                "parquet-thrift/src/main/java/parquet/hadoop/thrift/ThriftReadSupport.java": 14
            },
            "is_test": false,
            "is_fix": false
        },
        "eb156658b9514548a005561b0c4d3642be3034fa": {
            "datetime": "2013-09-06T16:33:21-07:00",
            "summary": "Add test cases for reading/writing Avro records with empty arrays and maps.",
            "message": "Add test cases for reading/writing Avro records with empty arrays and maps.\n",
            "diff": {
                "parquet-avro/src/test/java/parquet/avro/TestReadWrite.java": 55
            },
            "is_test": true,
            "is_fix": false
        },
        "50feb3363f202dabde35e749367e00348b3af3ee": {
            "datetime": "2013-09-06T16:33:51-07:00",
            "summary": "Fix tests for reading and writing Avro records with empty arrays and maps.",
            "message": "Fix tests for reading and writing Avro records with empty arrays and maps.\n",
            "diff": {
                "parquet-avro/src/test/java/parquet/avro/TestReadWrite.java": 12
            },
            "is_test": true,
            "is_fix": false
        },
        "0cedaf25e758c223ad54429c1e7bc991eb846c0a": {
            "datetime": "2013-09-06T17:51:59-07:00",
            "summary": "remove debugging code from hot path",
            "message": "remove debugging code from hot path\n",
            "diff": {
                "parquet-thrift/src/main/java/parquet/thrift/ParquetProtocol.java": 10
            },
            "is_test": false,
            "is_fix": false
        },
        "9594bba425ecd16e7a65021a4c5b0ec08921bd82": {
            "datetime": "2013-09-06T18:19:55-07:00",
            "summary": "address review comments",
            "message": "address review comments\n",
            "diff": {
                "parquet-column/src/main/java/parquet/schema/GroupType.java": 6,
                "parquet-column/src/main/java/parquet/schema/Type.java": 4,
                "parquet-column/src/test/java/parquet/schema/TestMessageType.java": 52,
                "parquet-hadoop/src/main/java/parquet/hadoop/ParquetFileWriter.java": 19,
                "parquet-hadoop/src/test/java/parquet/hadoop/TestParquetFileWriter.java": 16,
                "parquet-pig/src/main/java/parquet/pig/TupleReadSupport.java": 3
            },
            "is_test": true,
            "is_fix": false
        },
        "6f25a0f2e68adc13d8c2caaf87a864bba8fd8be5": {
            "datetime": "2013-09-07T04:41:48-07:00",
            "summary": "Correctly handle Avro records with empty maps and arrays.",
            "message": "Correctly handle Avro records with empty maps and arrays.\n",
            "diff": {
                "parquet-avro/src/main/java/parquet/avro/AvroWriteSupport.java": 74
            },
            "is_test": false,
            "is_fix": false
        },
        "26d09f4b150c49d36d7933c92651689622828f7c": {
            "datetime": "2013-09-07T11:29:20-07:00",
            "summary": "javadoc",
            "message": "javadoc\n",
            "diff": {
                "parquet-column/src/main/java/parquet/schema/GroupType.java": 29,
                "parquet-column/src/main/java/parquet/schema/PrimitiveType.java": 9,
                "parquet-column/src/main/java/parquet/schema/Type.java": 57,
                "parquet-hadoop/src/main/java/parquet/hadoop/ParquetFileWriter.java": 11,
                "parquet-hadoop/src/main/java/parquet/hadoop/ParquetInputFormat.java": 24,
                "parquet-hadoop/src/main/java/parquet/hadoop/ParquetReader.java": 15,
                "parquet-hadoop/src/main/java/parquet/hadoop/api/InitContext.java": 12
            },
            "is_test": false,
            "is_fix": false
        },
        "8c51a420a73241036ed28563c6a0ec5f905d133d": {
            "datetime": "2013-09-07T11:34:16-07:00",
            "summary": "better error message",
            "message": "better error message\n",
            "diff": {
                "parquet-hadoop/src/main/java/parquet/hadoop/InternalParquetRecordReader.java": 5
            },
            "is_test": false,
            "is_fix": false
        },
        "8fa09f0f74af3834ddceae3d36b8f2f286085d6d": {
            "datetime": "2013-09-07T11:39:18-07:00",
            "summary": "Merge pull request #163 from Parquet/thrift_perf",
            "message": "Merge pull request #163 from Parquet/thrift_perf\n\nremove debugging code from hot path",
            "diff": {
                "parquet-thrift/src/main/java/parquet/thrift/ParquetProtocol.java": 10
            },
            "is_test": false,
            "is_fix": false
        },
        "80c3a2a7c3fb4c691cbd2b66a467b6383d175e88": {
            "datetime": "2013-09-07T11:42:03-07:00",
            "summary": "Merge branch 'master' into schema_evolution",
            "message": "Merge branch 'master' into schema_evolution\n",
            "diff": {
                "parquet-thrift/src/main/java/parquet/thrift/ParquetProtocol.java": 10
            },
            "is_test": false,
            "is_fix": false
        },
        "60a3468f8266eeca965c4dd3906afca7f3001300": {
            "datetime": "2013-09-07T12:19:39-07:00",
            "summary": "fix test",
            "message": "fix test\n",
            "diff": {
                "parquet-column/src/test/java/parquet/schema/TestMessageType.java": 2
            },
            "is_test": true,
            "is_fix": false
        },
        "cfc91fc79e13bd640dcb6b6605750c92d11ccb64": {
            "datetime": "2013-09-08T18:09:40-07:00",
            "summary": "almost there... now working on not to use thrift class, so it's compatible with scrooge",
            "message": "almost there... now working on not to use thrift class, so it's compatible with scrooge\n",
            "diff": {
                "parquet-hadoop/src/test/java/parquet/hadoop/example/TestInputOutputFormat.java": 2,
                "parquet-thrift/src/main/java/parquet/hadoop/thrift/ThriftReadSupport.java": 8,
                "parquet-thrift/src/main/java/parquet/thrift/ThriftSchemaConverter.java": 131,
                "parquet-thrift/src/test/java/parquet/thrift/TestThriftSchemaConverter.java": 19
            },
            "is_test": true,
            "is_fix": false
        },
        "00a5d5b55eac3c869291a5f6359af97a880ddfd4": {
            "datetime": "2013-09-08T19:01:03-07:00",
            "summary": "migrated to using ThriftStruct for schemaConverter, do not use thriftClass",
            "message": "migrated to using ThriftStruct for schemaConverter, do not use thriftClass\n",
            "diff": {
                "parquet-thrift/src/main/java/parquet/hadoop/thrift/ThriftReadSupport.java": 2,
                "parquet-thrift/src/main/java/parquet/thrift/ThriftSchemaConverter.java": 355,
                "parquet-thrift/src/main/java/parquet/thrift/projection/FieldsPath.java": 31,
                "parquet-thrift/src/test/java/parquet/thrift/TestThriftSchemaConverter.java": 59
            },
            "is_test": true,
            "is_fix": false
        },
        "7387a615dd3b9ae89a63e052f11e36e91244728e": {
            "datetime": "2013-09-08T19:21:58-07:00",
            "summary": "passed all test, fix map, removed tests for pull in required fields",
            "message": "passed all test, fix map, removed tests for pull in required fields\n",
            "diff": {
                "parquet-thrift/src/main/java/parquet/thrift/ThriftSchemaConverter.java": 23,
                "parquet-thrift/src/test/java/parquet/thrift/TestThriftSchemaConverter.java": 42
            },
            "is_test": true,
            "is_fix": false
        },
        "147a3f023f68a321dad8fb55bc8b09d4f9b088ae": {
            "datetime": "2013-09-08T19:26:31-07:00",
            "summary": "start! do not check required field, failing test",
            "message": "start! do not check required field, failing test\n",
            "diff": {
                "parquet-thrift/src/main/java/parquet/thrift/ThriftSchemaConverter.java": 8,
                "parquet-thrift/src/test/java/parquet/hadoop/thrift/TestParquetToThriftReadProjection.java": 2
            },
            "is_test": true,
            "is_fix": false
        },
        "55c14bf93275371dbd4f4c3368dce00389be25cc": {
            "datetime": "2013-09-09T08:27:00-07:00",
            "summary": "javadoc",
            "message": "javadoc\n",
            "diff": {
                "parquet-hadoop/src/main/java/parquet/hadoop/api/InitContext.java": 19,
                "parquet-hadoop/src/main/java/parquet/hadoop/api/ReadSupport.java": 7,
                "parquet-hadoop/src/main/java/parquet/hadoop/metadata/FileMetaData.java": 14,
                "parquet-hadoop/src/main/java/parquet/hadoop/metadata/GlobalMetaData.java": 31,
                "parquet-pig/src/main/java/parquet/pig/ParquetLoader.java": 18,
                "parquet-pig/src/main/java/parquet/pig/PigMetaData.java": 29,
                "parquet-pig/src/main/java/parquet/pig/PigSchemaConverter.java": 24,
                "parquet-thrift/src/main/java/parquet/thrift/ThriftMetaData.java": 28
            },
            "is_test": false,
            "is_fix": false
        },
        "e5cb3c8fec0991942a12d3d97ef9e60329a5eba3": {
            "datetime": "2013-09-09T08:37:25-07:00",
            "summary": "fix test",
            "message": "fix test\n",
            "diff": {
                "parquet-thrift/src/test/java/parquet/thrift/TestProtocolReadToWrite.java": 2
            },
            "is_test": true,
            "is_fix": false
        },
        "e9f2550a40a51ff383283a88e1f8e847ad091d8c": {
            "datetime": "2013-09-09T15:29:10-07:00",
            "summary": "parameterize dictionary",
            "message": "parameterize dictionary\n",
            "diff": {
                "parquet-column/src/main/java/parquet/column/impl/ColumnWriteStoreImpl.java": 6,
                "parquet-column/src/main/java/parquet/column/impl/ColumnWriterImpl.java": 37,
                "parquet-column/src/main/java/parquet/column/values/dictionary/DictionaryValuesWriter.java": 28,
                "parquet-column/src/test/java/parquet/column/mem/TestMemColumn.java": 12,
                "parquet-column/src/test/java/parquet/column/values/dictionary/TestDictionary.java": 100,
                "parquet-column/src/test/java/parquet/io/PerfTest.java": 2,
                "parquet-column/src/test/java/parquet/io/TestColumnIO.java": 14,
                "parquet-column/src/test/java/parquet/io/TestFiltered.java": 30,
                "parquet-hadoop/src/main/java/parquet/hadoop/InternalParquetRecordWriter.java": 34,
                "parquet-hadoop/src/main/java/parquet/hadoop/ParquetOutputFormat.java": 34,
                "parquet-hadoop/src/main/java/parquet/hadoop/ParquetRecordWriter.java": 17,
                "parquet-hadoop/src/main/java/parquet/hadoop/ParquetWriter.java": 43,
                "parquet-thrift/src/test/java/parquet/thrift/TestParquetReadProtocol.java": 2
            },
            "is_test": true,
            "is_fix": false
        },
        "12d1ac423bc3ae4b8270c4732601262f5296c553": {
            "datetime": "2013-09-09T15:30:50-07:00",
            "summary": "fix noisy warning",
            "message": "fix noisy warning\n",
            "diff": {
                "parquet-hadoop/src/main/java/parquet/hadoop/ParquetInputFormat.java": 4
            },
            "is_test": false,
            "is_fix": false
        },
        "47116ad7ac86c001c2e68bca0e3f75f51488c462": {
            "datetime": "2013-09-09T15:55:18-07:00",
            "summary": "fix schema merging",
            "message": "fix schema merging\n",
            "diff": {
                "parquet-pig/src/main/java/parquet/pig/TupleReadSupport.java": 14,
                "parquet-pig/src/test/java/parquet/pig/TestPigSchemaConverter.java": 38
            },
            "is_test": true,
            "is_fix": false
        },
        "d4dbf0b254c19d8af81fca680ed41f7df61fe8e2": {
            "datetime": "2013-09-09T16:22:56-07:00",
            "summary": "Merge pull request #160 from adityakishore/master",
            "message": "Merge pull request #160 from adityakishore/master\n\nResource leak in parquet.hadoop.ParquetFileReader.readFooter(Configurati...",
            "diff": {
                "parquet-hadoop/src/main/java/parquet/hadoop/ParquetFileReader.java": 49
            },
            "is_test": false,
            "is_fix": false
        },
        "05a01060ffd72fca1b96e7e342cdedecc4889987": {
            "datetime": "2013-09-09T17:04:41-07:00",
            "summary": "Merge pull request #161 from Parquet/schema_evolution",
            "message": "Merge pull request #161 from Parquet/schema_evolution\n\nsupport schema evolution",
            "diff": {
                "parquet-cascading/src/test/java/parquet/cascading/TestParquetTBaseScheme.java": 15,
                "parquet-cascading/src/test/java/parquet/cascading/TestParquetTupleScheme.java": 15,
                "parquet-column/src/main/java/parquet/column/values/dictionary/PlainValuesDictionary.java": 3,
                "parquet-column/src/main/java/parquet/schema/GroupType.java": 66,
                "parquet-column/src/main/java/parquet/schema/IncompatibleSchemaModificationException.java": 46,
                "parquet-column/src/main/java/parquet/schema/MessageType.java": 7,
                "parquet-column/src/main/java/parquet/schema/PrimitiveType.java": 17,
                "parquet-column/src/main/java/parquet/schema/Type.java": 66,
                "parquet-column/src/test/java/parquet/schema/TestMessageType.java": 88,
                "parquet-hadoop/src/main/java/parquet/hadoop/InternalParquetRecordReader.java": 5,
                "parquet-hadoop/src/main/java/parquet/hadoop/ParquetFileWriter.java": 97,
                "parquet-hadoop/src/main/java/parquet/hadoop/ParquetInputFormat.java": 52,
                "parquet-hadoop/src/main/java/parquet/hadoop/ParquetReader.java": 76,
                "parquet-hadoop/src/main/java/parquet/hadoop/api/InitContext.java": 99,
                "parquet-hadoop/src/main/java/parquet/hadoop/api/ReadSupport.java": 19,
                "parquet-hadoop/src/main/java/parquet/hadoop/codec/NonBlockedCompressorStream.java": 15,
                "parquet-hadoop/src/main/java/parquet/hadoop/codec/NonBlockedDecompressorStream.java": 15,
                "parquet-hadoop/src/main/java/parquet/hadoop/metadata/FileMetaData.java": 13,
                "parquet-hadoop/src/main/java/parquet/hadoop/metadata/GlobalMetaData.java": 103,
                "parquet-hadoop/src/main/java/parquet/hadoop/util/counters/ICounter.java": 15,
                "parquet-hadoop/src/test/java/parquet/hadoop/TestParquetFileWriter.java": 29,
                "parquet-hadoop/src/test/java/parquet/hadoop/example/GroupReadSupportTest.java": 15,
                "parquet-pig/src/main/java/parquet/pig/ParquetLoader.java": 70,
                "parquet-pig/src/main/java/parquet/pig/PigMetaData.java": 45,
                "parquet-pig/src/main/java/parquet/pig/PigSchemaConverter.java": 47,
                "parquet-pig/src/main/java/parquet/pig/TupleReadSupport.java": 102,
                "parquet-pig/src/test/java/parquet/pig/TestParquetLoader.java": 12,
                "parquet-pig/src/test/java/parquet/pig/TestParquetStorer.java": 64,
                "parquet-pig/src/test/java/parquet/pig/TestPigSchemaConverter.java": 38,
                "parquet-pig/src/test/java/parquet/pig/TestTupleRecordConsumer.java": 14,
                "parquet-thrift/src/main/java/parquet/hadoop/thrift/ThriftReadSupport.java": 57,
                "parquet-thrift/src/main/java/parquet/thrift/ThriftMetaData.java": 59,
                "parquet-thrift/src/main/java/parquet/thrift/ThriftRecordConverter.java": 5,
                "parquet-thrift/src/test/java/parquet/hadoop/thrift/TestInputOutputFormat.java": 108
            },
            "is_test": true,
            "is_fix": false
        },
        "5b36d9c5d89fac4b346ad0ee4fe49805c8d9b748": {
            "datetime": "2013-09-09T17:07:30-07:00",
            "summary": "make buffered by default",
            "message": "make buffered by default\n",
            "diff": {
                "parquet-thrift/src/main/java/parquet/hadoop/thrift/ThriftBytesWriteSupport.java": 2
            },
            "is_test": false,
            "is_fix": false
        },
        "2de256778d396bec5fe4fbe73a072f72a71f6642": {
            "datetime": "2013-09-09T17:32:35-07:00",
            "summary": "Merge pull request #154 from Parquet/add_thrift_validation",
            "message": "Merge pull request #154 from Parquet/add_thrift_validation\n\nimprove thrift error message",
            "diff": {
                "parquet-thrift/src/main/java/parquet/hadoop/thrift/ThriftBytesWriteSupport.java": 2,
                "parquet-thrift/src/main/java/parquet/thrift/BufferedProtocolReadToWrite.java": 19,
                "parquet-thrift/src/test/java/parquet/thrift/TestProtocolReadToWrite.java": 30
            },
            "is_test": true,
            "is_fix": false
        },
        "b3efce20048307c7b7dd6aec2dcb08529c62320f": {
            "datetime": "2013-09-09T18:09:47-07:00",
            "summary": "fix compilation problems",
            "message": "fix compilation problems\n",
            "diff": {
                "parquet-column/src/test/java/parquet/column/values/dictionary/TestDictionary.java": 2,
                "parquet-hive/src/test/java/parquet/hive/TestDeprecatedParquetInputFormat.java": 2,
                "parquet-pig/src/test/java/parquet/pig/GenerateIntTestFile.java": 2,
                "parquet-pig/src/test/java/parquet/pig/GenerateTPCH.java": 2,
                "parquet-pig/src/test/java/parquet/pig/TupleConsumerPerfTest.java": 2
            },
            "is_test": true,
            "is_fix": false
        },
        "3c274d179ac08da51e89b0db5aecd80928031041": {
            "datetime": "2013-09-09T18:21:24-07:00",
            "summary": "Merge branch 'master' into fix_avro_empty_maps_arrays",
            "message": "Merge branch 'master' into fix_avro_empty_maps_arrays\n",
            "diff": {
                "parquet-cascading/src/test/java/parquet/cascading/TestParquetTBaseScheme.java": 15,
                "parquet-cascading/src/test/java/parquet/cascading/TestParquetTupleScheme.java": 15,
                "parquet-column/src/main/java/parquet/column/values/dictionary/PlainValuesDictionary.java": 3,
                "parquet-column/src/main/java/parquet/schema/GroupType.java": 66,
                "parquet-column/src/main/java/parquet/schema/IncompatibleSchemaModificationException.java": 46,
                "parquet-column/src/main/java/parquet/schema/MessageType.java": 7,
                "parquet-column/src/main/java/parquet/schema/PrimitiveType.java": 17,
                "parquet-column/src/main/java/parquet/schema/Type.java": 66,
                "parquet-column/src/test/java/parquet/schema/TestMessageType.java": 88,
                "parquet-hadoop/src/main/java/parquet/hadoop/InternalParquetRecordReader.java": 5,
                "parquet-hadoop/src/main/java/parquet/hadoop/ParquetFileReader.java": 49,
                "parquet-hadoop/src/main/java/parquet/hadoop/ParquetFileWriter.java": 97,
                "parquet-hadoop/src/main/java/parquet/hadoop/ParquetInputFormat.java": 52,
                "parquet-hadoop/src/main/java/parquet/hadoop/ParquetReader.java": 76,
                "parquet-hadoop/src/main/java/parquet/hadoop/api/InitContext.java": 99,
                "parquet-hadoop/src/main/java/parquet/hadoop/api/ReadSupport.java": 19,
                "parquet-hadoop/src/main/java/parquet/hadoop/codec/NonBlockedCompressorStream.java": 15,
                "parquet-hadoop/src/main/java/parquet/hadoop/codec/NonBlockedDecompressorStream.java": 15,
                "parquet-hadoop/src/main/java/parquet/hadoop/metadata/FileMetaData.java": 13,
                "parquet-hadoop/src/main/java/parquet/hadoop/metadata/GlobalMetaData.java": 103,
                "parquet-hadoop/src/main/java/parquet/hadoop/util/counters/ICounter.java": 15,
                "parquet-hadoop/src/test/java/parquet/hadoop/TestParquetFileWriter.java": 29,
                "parquet-hadoop/src/test/java/parquet/hadoop/example/GroupReadSupportTest.java": 15,
                "parquet-pig/src/main/java/parquet/pig/ParquetLoader.java": 70,
                "parquet-pig/src/main/java/parquet/pig/PigMetaData.java": 45,
                "parquet-pig/src/main/java/parquet/pig/PigSchemaConverter.java": 47,
                "parquet-pig/src/main/java/parquet/pig/TupleReadSupport.java": 102,
                "parquet-pig/src/test/java/parquet/pig/TestParquetLoader.java": 12,
                "parquet-pig/src/test/java/parquet/pig/TestParquetStorer.java": 64,
                "parquet-pig/src/test/java/parquet/pig/TestPigSchemaConverter.java": 38,
                "parquet-pig/src/test/java/parquet/pig/TestTupleRecordConsumer.java": 14,
                "parquet-thrift/src/main/java/parquet/hadoop/thrift/ThriftBytesWriteSupport.java": 2,
                "parquet-thrift/src/main/java/parquet/hadoop/thrift/ThriftReadSupport.java": 57,
                "parquet-thrift/src/main/java/parquet/thrift/BufferedProtocolReadToWrite.java": 19,
                "parquet-thrift/src/main/java/parquet/thrift/ParquetProtocol.java": 10,
                "parquet-thrift/src/main/java/parquet/thrift/ThriftMetaData.java": 59,
                "parquet-thrift/src/main/java/parquet/thrift/ThriftRecordConverter.java": 5,
                "parquet-thrift/src/test/java/parquet/hadoop/thrift/TestInputOutputFormat.java": 108,
                "parquet-thrift/src/test/java/parquet/thrift/TestProtocolReadToWrite.java": 30
            },
            "is_test": true,
            "is_fix": false
        },
        "70226b9a97dd2ade359cb76a320727e20892b881": {
            "datetime": "2013-09-10T08:37:32-07:00",
            "summary": "distinguish recoverable errors",
            "message": "distinguish recoverable errors\n",
            "diff": {
                "parquet-thrift/src/main/java/parquet/thrift/BufferedProtocolReadToWrite.java": 21
            },
            "is_test": false,
            "is_fix": false
        },
        "68fa6cd26b473d8d1592fbd51b31d5a0c5af53ad": {
            "datetime": "2013-09-10T10:08:46-07:00",
            "summary": "fill in missing fields, only for str now, will refactor to visitor pattern",
            "message": "fill in missing fields, only for str now, will refactor to visitor pattern\n",
            "diff": {
                "parquet-thrift/src/main/java/parquet/thrift/ParquetProtocol.java": 4,
                "parquet-thrift/src/main/java/parquet/thrift/ParquetReadProtocol.java": 14,
                "parquet-thrift/src/main/java/parquet/thrift/ThriftRecordConverter.java": 383,
                "parquet-thrift/src/main/java/parquet/thrift/projection/ProtocolEventsAmender.java": 184,
                "parquet-thrift/src/main/java/parquet/thrift/projection/ProtocolEventsGenerator.java": 132,
                "parquet-thrift/src/test/java/parquet/hadoop/thrift/TestParquetToThriftReadProjection.java": 2
            },
            "is_test": true,
            "is_fix": false
        },
        "7dfa864c3382f3223a9331672b0f77ef874e6ca0": {
            "datetime": "2013-09-10T10:26:11-07:00",
            "summary": "visitor pattern for string, test passed",
            "message": "visitor pattern for string, test passed\n",
            "diff": {
                "parquet-thrift/src/main/java/parquet/thrift/ThriftRecordConverter.java": 2,
                "parquet-thrift/src/main/java/parquet/thrift/projection/ProtocolEventsAmender.java": 3,
                "parquet-thrift/src/main/java/parquet/thrift/projection/ProtocolEventsGenerator.java": 132,
                "parquet-thrift/src/main/java/parquet/thrift/projection/amend/ProtocolEventsGenerator.java": 167,
                "parquet-thrift/src/main/java/parquet/thrift/projection/amend/StructBeginProtocol.java": 25
            },
            "is_test": false,
            "is_fix": false
        },
        "1bf9d5f350bba42490e40d2312f2879ee0caf82e": {
            "datetime": "2013-09-10T10:34:27-07:00",
            "summary": "extracted inner classes from ProtocolEventsGenerator",
            "message": "extracted inner classes from ProtocolEventsGenerator\n",
            "diff": {
                "parquet-thrift/src/main/java/parquet/thrift/projection/amend/DummyCreatorVisitor.java": 91,
                "parquet-thrift/src/main/java/parquet/thrift/projection/amend/ProtocolEventsGenerator.java": 120,
                "parquet-thrift/src/main/java/parquet/thrift/projection/amend/ReadFieldBeginProtocol.java": 33,
                "parquet-thrift/src/main/java/parquet/thrift/projection/amend/StringProtocol.java": 33
            },
            "is_test": false,
            "is_fix": false
        },
        "c59e82f53fde512934a3fa37bccdfa12f915c349": {
            "datetime": "2013-09-10T11:01:36-07:00",
            "summary": "implemented all dummy values",
            "message": "implemented all dummy values\n",
            "diff": {
                "parquet-thrift/src/main/java/parquet/thrift/projection/amend/DummyCreatorVisitor.java": 81,
                "parquet-thrift/src/main/java/parquet/thrift/projection/amend/ProtocolEventsGenerator.java": 1
            },
            "is_test": false,
            "is_fix": false
        },
        "9a1e2953b3234395b211481644d17857f52b803e": {
            "datetime": "2013-09-10T11:06:46-07:00",
            "summary": "merge master",
            "message": "merge master\n",
            "diff": {
                "parquet-cascading/src/test/java/parquet/cascading/TestParquetTBaseScheme.java": 15,
                "parquet-cascading/src/test/java/parquet/cascading/TestParquetTupleScheme.java": 15,
                "parquet-column/src/main/java/parquet/column/values/dictionary/PlainValuesDictionary.java": 3,
                "parquet-column/src/main/java/parquet/schema/GroupType.java": 66,
                "parquet-column/src/main/java/parquet/schema/IncompatibleSchemaModificationException.java": 46,
                "parquet-column/src/main/java/parquet/schema/MessageType.java": 7,
                "parquet-column/src/main/java/parquet/schema/PrimitiveType.java": 17,
                "parquet-column/src/main/java/parquet/schema/Type.java": 66,
                "parquet-column/src/test/java/parquet/schema/TestMessageType.java": 88,
                "parquet-hadoop/src/main/java/parquet/hadoop/InternalParquetRecordReader.java": 7,
                "parquet-hadoop/src/main/java/parquet/hadoop/ParquetFileReader.java": 51,
                "parquet-hadoop/src/main/java/parquet/hadoop/ParquetFileWriter.java": 97,
                "parquet-hadoop/src/main/java/parquet/hadoop/ParquetInputFormat.java": 52,
                "parquet-hadoop/src/main/java/parquet/hadoop/ParquetReader.java": 76,
                "parquet-hadoop/src/main/java/parquet/hadoop/ParquetRecordReader.java": 20,
                "parquet-hadoop/src/main/java/parquet/hadoop/api/InitContext.java": 99,
                "parquet-hadoop/src/main/java/parquet/hadoop/api/ReadSupport.java": 19,
                "parquet-hadoop/src/main/java/parquet/hadoop/codec/NonBlockedCompressorStream.java": 15,
                "parquet-hadoop/src/main/java/parquet/hadoop/codec/NonBlockedDecompressorStream.java": 15,
                "parquet-hadoop/src/main/java/parquet/hadoop/mapred/DeprecatedParquetInputFormat.java": 2,
                "parquet-hadoop/src/main/java/parquet/hadoop/metadata/FileMetaData.java": 13,
                "parquet-hadoop/src/main/java/parquet/hadoop/metadata/GlobalMetaData.java": 103,
                "parquet-hadoop/src/main/java/parquet/hadoop/util/BenchmarkCounter.java": 53,
                "parquet-hadoop/src/main/java/parquet/hadoop/util/counters/BenchmarkCounter.java": 111,
                "parquet-hadoop/src/main/java/parquet/hadoop/util/counters/CounterLoader.java": 25,
                "parquet-hadoop/src/main/java/parquet/hadoop/util/counters/ICounter.java": 26,
                "parquet-hadoop/src/main/java/parquet/hadoop/util/counters/mapred/MapRedCounterAdapter.java": 41,
                "parquet-hadoop/src/main/java/parquet/hadoop/util/counters/mapred/MapRedCounterLoader.java": 46,
                "parquet-hadoop/src/main/java/parquet/hadoop/util/counters/mapreduce/MapReduceCounterAdapter.java": 42,
                "parquet-hadoop/src/main/java/parquet/hadoop/util/counters/mapreduce/MapReduceCounterLoader.java": 44,
                "parquet-hadoop/src/test/java/parquet/hadoop/DeprecatedInputFormatTest.java": 179,
                "parquet-hadoop/src/test/java/parquet/hadoop/TestParquetFileWriter.java": 29,
                "parquet-hadoop/src/test/java/parquet/hadoop/example/GroupReadSupportTest.java": 15,
                "parquet-hadoop/src/test/java/parquet/hadoop/example/TestInputOutputFormat.java": 2,
                "parquet-pig/src/main/java/parquet/pig/ParquetLoader.java": 70,
                "parquet-pig/src/main/java/parquet/pig/PigMetaData.java": 45,
                "parquet-pig/src/main/java/parquet/pig/PigSchemaConverter.java": 47,
                "parquet-pig/src/main/java/parquet/pig/TupleReadSupport.java": 102,
                "parquet-pig/src/test/java/parquet/pig/TestParquetLoader.java": 12,
                "parquet-pig/src/test/java/parquet/pig/TestParquetStorer.java": 64,
                "parquet-pig/src/test/java/parquet/pig/TestPigSchemaConverter.java": 38,
                "parquet-pig/src/test/java/parquet/pig/TestTupleRecordConsumer.java": 14,
                "parquet-thrift/src/main/java/parquet/hadoop/thrift/ThriftBytesWriteSupport.java": 2,
                "parquet-thrift/src/main/java/parquet/hadoop/thrift/ThriftReadSupport.java": 63,
                "parquet-thrift/src/main/java/parquet/thrift/BufferedProtocolReadToWrite.java": 19,
                "parquet-thrift/src/main/java/parquet/thrift/ParquetProtocol.java": 10,
                "parquet-thrift/src/main/java/parquet/thrift/ThriftMetaData.java": 59,
                "parquet-thrift/src/main/java/parquet/thrift/ThriftRecordConverter.java": 386,
                "parquet-thrift/src/test/java/parquet/hadoop/thrift/TestInputOutputFormat.java": 108,
                "parquet-thrift/src/test/java/parquet/thrift/TestProtocolReadToWrite.java": 30
            },
            "is_test": true,
            "is_fix": false
        },
        "6f374b74e3766da468e1b481247070cd7c7593d1": {
            "datetime": "2013-09-10T11:14:46-07:00",
            "summary": "store thriftType in converter[fix merge error]",
            "message": "store thriftType in converter[fix merge error]\n",
            "diff": {
                "parquet-thrift/src/main/java/parquet/thrift/ThriftRecordConverter.java": 6
            },
            "is_test": false,
            "is_fix": false
        },
        "3e160d9c95ac9cdb058f9f917dae1276f462c82f": {
            "datetime": "2013-09-10T11:23:12-07:00",
            "summary": "add license headers",
            "message": "add license headers\n",
            "diff": {
                "parquet-thrift/src/main/java/parquet/thrift/projection/amend/DummyCreatorVisitor.java": 26,
                "parquet-thrift/src/main/java/parquet/thrift/projection/amend/ProtocolEventsAmender.java": 60,
                "parquet-thrift/src/main/java/parquet/thrift/projection/amend/ProtocolEventsGenerator.java": 16,
                "parquet-thrift/src/main/java/parquet/thrift/projection/amend/ReadFieldBeginProtocol.java": 22,
                "parquet-thrift/src/main/java/parquet/thrift/projection/amend/StringProtocol.java": 9,
                "parquet-thrift/src/main/java/parquet/thrift/projection/amend/StructBeginProtocol.java": 7
            },
            "is_test": false,
            "is_fix": false
        },
        "b4a8eb1e95ca30db1c14eb17e08bf2ca8fd200cf": {
            "datetime": "2013-09-10T11:25:31-07:00",
            "summary": "fix test",
            "message": "fix test\n",
            "diff": {
                "parquet-thrift/src/test/java/parquet/thrift/TestProtocolReadToWrite.java": 4
            },
            "is_test": true,
            "is_fix": false
        },
        "3060f85cd096bd75c25cad72f27f65b239c95e14": {
            "datetime": "2013-09-10T14:12:17-07:00",
            "summary": "added unit tests",
            "message": "added unit tests\n",
            "diff": {
                "parquet-thrift/src/main/java/parquet/thrift/projection/amend/DummyCreatorVisitor.java": 27,
                "parquet-thrift/src/test/java/parquet/hadoop/thrift/TestParquetToThriftReadProjection.java": 150
            },
            "is_test": true,
            "is_fix": false
        },
        "8aadc0ac6ef8e229baee584385002c488c042207": {
            "datetime": "2013-09-10T14:25:39-07:00",
            "summary": "fix bug, use a new list for fixed events",
            "message": "fix bug, use a new list for fixed events\n",
            "diff": {
                "parquet-thrift/src/main/java/parquet/thrift/ThriftRecordConverter.java": 4,
                "parquet-thrift/src/main/java/parquet/thrift/projection/amend/DummyCreatorVisitor.java": 2,
                "parquet-thrift/src/main/java/parquet/thrift/projection/amend/ProtocolEventsGenerator.java": 2
            },
            "is_test": false,
            "is_fix": false
        },
        "b81238938165d7179357041bad40ca510cb9c687": {
            "datetime": "2013-09-10T14:48:24-07:00",
            "summary": "inline some classes",
            "message": "inline some classes\n",
            "diff": {
                "parquet-thrift/src/main/java/parquet/thrift/projection/amend/DefaultEventsVisitor.java": 35,
                "parquet-thrift/src/main/java/parquet/thrift/projection/amend/ProtocolEventsAmender.java": 5,
                "parquet-thrift/src/main/java/parquet/thrift/projection/amend/ProtocolEventsGenerator.java": 1,
                "parquet-thrift/src/main/java/parquet/thrift/projection/amend/ReadFieldBeginProtocol.java": 2,
                "parquet-thrift/src/main/java/parquet/thrift/projection/amend/StringProtocol.java": 26,
                "parquet-thrift/src/main/java/parquet/thrift/projection/amend/StructBeginProtocol.java": 18
            },
            "is_test": false,
            "is_fix": false
        },
        "f702fdfb5b8b46e90ef14daa58d80cb59f1d26a4": {
            "datetime": "2013-09-10T14:51:56-07:00",
            "summary": "better naming",
            "message": "better naming\n",
            "diff": {
                "parquet-thrift/src/main/java/parquet/thrift/projection/amend/DefaultEventsVisitor.java": 10,
                "parquet-thrift/src/main/java/parquet/thrift/projection/amend/ProtocolEventsAmender.java": 4,
                "parquet-thrift/src/main/java/parquet/thrift/projection/amend/ProtocolEventsGenerator.java": 2
            },
            "is_test": false,
            "is_fix": false
        },
        "133b2528a56c06ea5c3bd16fa50963edaf76f644": {
            "datetime": "2013-09-10T15:38:10-07:00",
            "summary": "add missing file",
            "message": "add missing file\n",
            "diff": {
                "parquet-thrift/src/main/java/parquet/thrift/SkippableException.java": 32
            },
            "is_test": false,
            "is_fix": false
        },
        "073e20295c0620c3cb7374bc822c267e34296300": {
            "datetime": "2013-09-10T15:42:24-07:00",
            "summary": "fix test path",
            "message": "fix test path\n",
            "diff": {
                "parquet-hadoop/src/test/java/parquet/hadoop/example/TestInputOutputFormat.java": 2
            },
            "is_test": true,
            "is_fix": false
        },
        "eff7237c798a1057c9be4148dbd555a790bea3bb": {
            "datetime": "2013-09-10T16:06:03-07:00",
            "summary": "remove converted Type",
            "message": "remove converted Type\n",
            "diff": {
                "parquet-thrift/src/main/java/parquet/thrift/ParquetReadProtocol.java": 14,
                "parquet-thrift/src/main/java/parquet/thrift/ThriftRecordConverter.java": 2,
                "parquet-thrift/src/main/java/parquet/thrift/ThriftSchemaConverter.java": 150
            },
            "is_test": false,
            "is_fix": false
        },
        "d7b00834098a7f3b705656e9c0e12b077084e8c0": {
            "datetime": "2013-09-10T16:12:14-07:00",
            "summary": "Add empty map and array to test Avro schema all-minus-fixed and add empty map and array fields to parquet-avro test that tests fields of all (except fixed) types.",
            "message": "Add empty map and array to test Avro schema all-minus-fixed and add empty map and array fields to parquet-avro test that tests fields of all (except fixed) types.\n",
            "diff": {
                "parquet-avro/src/test/java/parquet/avro/TestReadWrite.java": 132
            },
            "is_test": true,
            "is_fix": false
        },
        "365d84ef8706aae8aaabeb6062dd24357ececbd5": {
            "datetime": "2013-09-10T16:57:47-07:00",
            "summary": "prepare for commit, remove format diff",
            "message": "prepare for commit, remove format diff\n",
            "diff": {
                "parquet-thrift/src/main/java/parquet/thrift/ThriftSchemaConverter.java": 128
            },
            "is_test": false,
            "is_fix": false
        },
        "5ca767137557e8a54040f35481a3041245783417": {
            "datetime": "2013-09-10T18:27:10-07:00",
            "summary": "Re-enable test for fixed type fields in Avro TestReadWrite.",
            "message": "Re-enable test for fixed type fields in Avro TestReadWrite.\n",
            "diff": {
                "parquet-avro/src/test/java/parquet/avro/TestReadWrite.java": 9
            },
            "is_test": true,
            "is_fix": false
        },
        "ffbdf6dd649775eff7a26ce78244395a934902a0": {
            "datetime": "2013-09-11T10:28:56-07:00",
            "summary": "visitor pattern for schemaConverter",
            "message": "visitor pattern for schemaConverter\n",
            "diff": {
                "parquet-thrift/src/main/java/parquet/thrift/SchemaConvertVisitor.java": 263,
                "parquet-thrift/src/main/java/parquet/thrift/ThriftSchemaConverter.java": 154
            },
            "is_test": false,
            "is_fix": false
        },
        "2b2837f55ad92211c1da450195672ae02230b82c": {
            "datetime": "2013-09-11T10:39:49-07:00",
            "summary": "refactor matching filter",
            "message": "refactor matching filter\n",
            "diff": {
                "parquet-thrift/src/main/java/parquet/thrift/SchemaConvertVisitor.java": 98,
                "parquet-thrift/src/main/java/parquet/thrift/ThriftSchemaConverter.java": 2
            },
            "is_test": false,
            "is_fix": false
        },
        "079e295072516c46fff087d3d38ee3310f6a1b5b": {
            "datetime": "2013-09-11T10:40:52-07:00",
            "summary": "rename",
            "message": "rename\n",
            "diff": {
                "parquet-thrift/src/main/java/parquet/thrift/SchemaConvertVisitor.java": 4,
                "parquet-thrift/src/main/java/parquet/thrift/ThriftSchemaConverter.java": 10
            },
            "is_test": false,
            "is_fix": false
        },
        "7b68b4738d50f1ca12f9ebf048d28db20682b984": {
            "datetime": "2013-09-12T09:37:06-07:00",
            "summary": "sucess: compile scrooge generated classes in parquet-thrift",
            "message": "sucess: compile scrooge generated classes in parquet-thrift\n",
            "diff": {
                "parquet-thrift/src/main/java/parquet/hadoop/thrift/ThriftReadSupport.java": 1,
                "parquet-thrift/src/main/java/parquet/thrift/ThriftMetaData.java": 28,
                "parquet-thrift/src/test/java/parquet/hadoop/thrift/TestParquetToThriftReadProjection.java": 10,
                "parquet-thrift/src/test/java/parquet/thrift/TestThriftSchemaConverter.java": 24
            },
            "is_test": true,
            "is_fix": false
        },
        "5393833758daf1bc67e759f03de3507fca0aca65": {
            "datetime": "2013-09-12T12:33:50-07:00",
            "summary": "migrated tests to parquet-scrooge [tests passed]",
            "message": "migrated tests to parquet-scrooge [tests passed]\n",
            "diff": {
                "parquet-scrooge/src/test/java/parquet/scrooge/ParquetScroogeSchemeTest.java": 216
            },
            "is_test": true,
            "is_fix": false
        },
        "d9ce72660790484784897905f34ebbd2a6a278d9": {
            "datetime": "2013-09-12T12:56:45-07:00",
            "summary": "add test in scrooge [only maven passed]",
            "message": "add test in scrooge [only maven passed]\n",
            "diff": {
                "parquet-scrooge/src/test/java/parquet/scrooge/ParquetScroogeSchemeTest.java": 53
            },
            "is_test": true,
            "is_fix": false
        },
        "0570f46ce688f9361f4264c36cc3723074e459e8": {
            "datetime": "2013-09-12T21:55:14-07:00",
            "summary": "better fallback mechanism",
            "message": "better fallback mechanism\n",
            "diff": {
                "parquet-column/src/main/java/parquet/column/values/dictionary/DictionaryValuesWriter.java": 52,
                "parquet-column/src/test/java/parquet/column/values/dictionary/TestDictionary.java": 82
            },
            "is_test": true,
            "is_fix": false
        },
        "015ed30d5b681a8a082166d4692f0a813dd31fa0": {
            "datetime": "2013-09-12T23:13:04-07:00",
            "summary": "fix oom error dues to bad estimation",
            "message": "fix oom error dues to bad estimation\n",
            "diff": {
                "parquet-hadoop/src/main/java/parquet/hadoop/InternalParquetRecordWriter.java": 17
            },
            "is_test": false,
            "is_fix": false
        },
        "1e472d2d8dcacdca52fdda81443703484974ca93": {
            "datetime": "2013-09-12T23:21:19-07:00",
            "summary": "Merge pull request #167 from Parquet/fix_oom",
            "message": "Merge pull request #167 from Parquet/fix_oom\n\nfix oom error dues to bad estimation",
            "diff": {
                "parquet-hadoop/src/main/java/parquet/hadoop/InternalParquetRecordWriter.java": 17
            },
            "is_test": false,
            "is_fix": false
        },
        "1d928046faec8f83fd0ed112e602eefbca396d31": {
            "datetime": "2013-09-13T11:00:21-07:00",
            "summary": "Add typeLength to ColumnDescriptor.",
            "message": "Add typeLength to ColumnDescriptor.\n",
            "diff": {
                "parquet-avro/src/main/java/parquet/avro/AvroWriteSupport.java": 1,
                "parquet-column/src/main/java/parquet/column/ColumnDescriptor.java": 31,
                "parquet-column/src/main/java/parquet/column/impl/ColumnWriterImpl.java": 17,
                "parquet-hadoop/src/main/java/parquet/format/converter/ParquetMetadataConverter.java": 14
            },
            "is_test": false,
            "is_fix": false
        },
        "a7ba48ba7caf2ef58868dca8bc710f66eac199f5": {
            "datetime": "2013-09-13T11:29:19-07:00",
            "summary": "created ScroogeSchemaConverter",
            "message": "created ScroogeSchemaConverter\n",
            "diff": {
                "parquet-scrooge/src/main/java/parquet/scrooge/ScroogeRecordConverter.java": 2,
                "parquet-scrooge/src/main/java/parquet/scrooge/ScroogeSchemaConverter.java": 113,
                "parquet-scrooge/src/test/java/parquet/scrooge/ParquetScroogeSchemeTest.java": 34,
                "parquet-thrift/src/main/java/parquet/thrift/ThriftSchemaConverter.java": 3,
                "parquet-thrift/src/test/java/parquet/thrift/TestThriftSchemaConverter.java": 5
            },
            "is_test": true,
            "is_fix": false
        },
        "e2d3bb299a29b7df44cef06a555bd1e5c5b775f5": {
            "datetime": "2013-09-13T11:33:08-07:00",
            "summary": "[style]fix if...else in ConversionPatterns",
            "message": "[style]fix if...else in ConversionPatterns\n",
            "diff": {
                "parquet-column/src/main/java/parquet/schema/ConversionPatterns.java": 63
            },
            "is_test": false,
            "is_fix": false
        },
        "64e6d82f69249c0e3a2747b3f6b59d39cd2df873": {
            "datetime": "2013-09-13T11:42:09-07:00",
            "summary": "[style] add spaces around =",
            "message": "[style] add spaces around =\n",
            "diff": {
                "parquet-column/src/main/java/parquet/schema/ConversionPatterns.java": 2,
                "parquet-thrift/src/main/java/parquet/thrift/ThriftRecordConverter.java": 4
            },
            "is_test": false,
            "is_fix": false
        },
        "99b6dfcc7c82c09e098fa8583442bafc1d8a3151": {
            "datetime": "2013-09-13T11:44:44-07:00",
            "summary": "remove julien's TODO",
            "message": "remove julien's TODO\n",
            "diff": {
                "parquet-thrift/src/main/java/parquet/thrift/ThriftSchemaConvertVisitor.java": 5
            },
            "is_test": false,
            "is_fix": false
        },
        "bbc0aa71677b4d9f3c20c41b710b0f55250025a1": {
            "datetime": "2013-09-13T12:07:06-07:00",
            "summary": "Merge pull request #166 from Parquet/avoid_pruning_required_fields",
            "message": "Merge pull request #166 from Parquet/avoid_pruning_required_fields\n\nAvoid pruning required fields in projection pushdown for thrift",
            "diff": {
                "parquet-column/src/main/java/parquet/schema/ConversionPatterns.java": 71,
                "parquet-thrift/src/main/java/parquet/thrift/ParquetProtocol.java": 4,
                "parquet-thrift/src/main/java/parquet/thrift/ThriftRecordConverter.java": 6,
                "parquet-thrift/src/main/java/parquet/thrift/ThriftSchemaConvertVisitor.java": 256,
                "parquet-thrift/src/main/java/parquet/thrift/ThriftSchemaConverter.java": 186,
                "parquet-thrift/src/main/java/parquet/thrift/projection/FieldProjectionFilter.java": 12,
                "parquet-thrift/src/main/java/parquet/thrift/projection/FieldsPath.java": 82,
                "parquet-thrift/src/main/java/parquet/thrift/projection/amend/DefaultEventsVisitor.java": 212,
                "parquet-thrift/src/main/java/parquet/thrift/projection/amend/DefaultProtocolEventsGenerator.java": 65,
                "parquet-thrift/src/main/java/parquet/thrift/projection/amend/ProtocolEventsAmender.java": 170,
                "parquet-thrift/src/main/java/parquet/thrift/projection/amend/ReadFieldBeginProtocol.java": 41,
                "parquet-thrift/src/test/java/parquet/hadoop/thrift/TestParquetToThriftReadProjection.java": 152,
                "parquet-thrift/src/test/java/parquet/thrift/TestThriftSchemaConverter.java": 95
            },
            "is_test": true,
            "is_fix": false
        },
        "9d84697a0b1759b7b4dccaa3278c4836bad011ef": {
            "datetime": "2013-09-13T13:19:59-07:00",
            "summary": "merge master",
            "message": "merge master\n",
            "diff": {
                "parquet-column/src/main/java/parquet/schema/ConversionPatterns.java": 63,
                "parquet-hadoop/src/main/java/parquet/hadoop/InternalParquetRecordWriter.java": 17,
                "parquet-thrift/src/main/java/parquet/thrift/ThriftRecordConverter.java": 4,
                "parquet-thrift/src/main/java/parquet/thrift/ThriftSchemaConvertVisitor.java": 5
            },
            "is_test": false,
            "is_fix": false
        },
        "f6f3eaa01e0a503d78eb028be64554ca0a0f85c3": {
            "datetime": "2013-09-13T14:12:35-07:00",
            "summary": "broken tests for scroogeRead",
            "message": "broken tests for scroogeRead\n",
            "diff": {
                "parquet-scrooge/src/main/java/parquet/scrooge/ScroogeSchemaConverter.java": 46,
                "parquet-scrooge/src/test/java/parquet/scrooge/ParquetScroogeSchemeTest.java": 26
            },
            "is_test": true,
            "is_fix": false
        },
        "3803d2d478ef73e1bccc2d887daad4b30647d854": {
            "datetime": "2013-09-16T05:47:09-07:00",
            "summary": "Plumb FIXED type length from Avro schema through to Parquet metadata.",
            "message": "Plumb FIXED type length from Avro schema through to Parquet metadata.\n",
            "diff": {
                "parquet-avro/src/main/java/parquet/avro/AvroSchemaConverter.java": 19,
                "parquet-column/src/main/java/parquet/schema/PrimitiveType.java": 21,
                "parquet-hadoop/src/main/java/parquet/format/converter/ParquetMetadataConverter.java": 7
            },
            "is_test": false,
            "is_fix": false
        },
        "b4c45d3a5fa2972a0fbb214179350c55a7051927": {
            "datetime": "2013-09-16T10:31:59-07:00",
            "summary": "fix bug, missing break in thriftSchemaConverter",
            "message": "fix bug, missing break in thriftSchemaConverter\n",
            "diff": {
                "parquet-thrift/src/main/java/parquet/thrift/ThriftSchemaConverter.java": 1
            },
            "is_test": false,
            "is_fix": false
        },
        "dcc0d81849c4064fee779844b2b39737c75fd230": {
            "datetime": "2013-09-16T11:10:11-07:00",
            "summary": "Merge branch 'master' into fixed_len_byte_array",
            "message": "Merge branch 'master' into fixed_len_byte_array\n",
            "diff": {
                "parquet-column/src/main/java/parquet/schema/ConversionPatterns.java": 71,
                "parquet-hadoop/src/main/java/parquet/hadoop/InternalParquetRecordWriter.java": 17,
                "parquet-thrift/src/main/java/parquet/thrift/ParquetProtocol.java": 4,
                "parquet-thrift/src/main/java/parquet/thrift/ThriftRecordConverter.java": 6,
                "parquet-thrift/src/main/java/parquet/thrift/ThriftSchemaConvertVisitor.java": 256,
                "parquet-thrift/src/main/java/parquet/thrift/ThriftSchemaConverter.java": 186,
                "parquet-thrift/src/main/java/parquet/thrift/projection/FieldProjectionFilter.java": 12,
                "parquet-thrift/src/main/java/parquet/thrift/projection/FieldsPath.java": 82,
                "parquet-thrift/src/main/java/parquet/thrift/projection/amend/DefaultEventsVisitor.java": 212,
                "parquet-thrift/src/main/java/parquet/thrift/projection/amend/DefaultProtocolEventsGenerator.java": 65,
                "parquet-thrift/src/main/java/parquet/thrift/projection/amend/ProtocolEventsAmender.java": 170,
                "parquet-thrift/src/main/java/parquet/thrift/projection/amend/ReadFieldBeginProtocol.java": 41,
                "parquet-thrift/src/test/java/parquet/hadoop/thrift/TestParquetToThriftReadProjection.java": 152,
                "parquet-thrift/src/test/java/parquet/thrift/TestThriftSchemaConverter.java": 95
            },
            "is_test": true,
            "is_fix": false
        },
        "04784c2e024cd3db1165150448f19ef4532793d6": {
            "datetime": "2013-09-16T13:30:10-07:00",
            "summary": "test pass",
            "message": "test pass\n",
            "diff": {
                "parquet-scrooge/src/test/java/parquet/scrooge/ParquetScroogeSchemeTest.java": 232
            },
            "is_test": true,
            "is_fix": false
        },
        "2a2696dcee58fb7fd6d9072b97f0411b5ceb9470": {
            "datetime": "2013-09-16T13:36:30-07:00",
            "summary": "format",
            "message": "format\n",
            "diff": {
                "parquet-scrooge/src/test/java/parquet/scrooge/ParquetScroogeSchemeTest.java": 66
            },
            "is_test": true,
            "is_fix": false
        },
        "78b3f86774685d5d8beb1b12880fd127de9a6222": {
            "datetime": "2013-09-16T13:40:23-07:00",
            "summary": "update scrooge denepdency, add unit tests for reading in scrooge",
            "message": "update scrooge denepdency, add unit tests for reading in scrooge\n",
            "diff": {
                "parquet-scrooge/src/test/java/parquet/scrooge/ParquetScroogeSchemeTest.java": 93
            },
            "is_test": true,
            "is_fix": false
        },
        "249581dd38d82e5b36f39a25e45e84f109c12e69": {
            "datetime": "2013-09-16T13:49:08-07:00",
            "summary": "add TestCase for scrooge schema converter",
            "message": "add TestCase for scrooge schema converter\n",
            "diff": {
                "parquet-scrooge/src/test/java/parquet/scrooge/ScroogeSchemaConverterTest.java": 15
            },
            "is_test": true,
            "is_fix": false
        },
        "c1f3512b1e78137f01cdc11221ab64242a6fe1b6": {
            "datetime": "2013-09-16T13:56:18-07:00",
            "summary": "change some ParquetOutputFormat interfaces to mirror ParquetInputFormat (and be useful for writing a DeprecatedOutputFormat)",
            "message": "change some ParquetOutputFormat interfaces to mirror ParquetInputFormat (and be useful for writing a DeprecatedOutputFormat)\n",
            "diff": {
                "parquet-hadoop/src/main/java/parquet/hadoop/ParquetOutputFormat.java": 169
            },
            "is_test": false,
            "is_fix": false
        },
        "93d6770be153472c0da28dd2b9b3fc8797604703": {
            "datetime": "2013-09-16T13:56:28-07:00",
            "summary": "add a simple test for DeprecatedOutputFormat",
            "message": "add a simple test for DeprecatedOutputFormat\n",
            "diff": {
                "parquet-hadoop/src/test/java/parquet/hadoop/DeprecatedOutputFormatTest.java": 106
            },
            "is_test": true,
            "is_fix": false
        },
        "521d08127d3355273fa00d2d0a4819069813f0c8": {
            "datetime": "2013-09-16T13:56:28-07:00",
            "summary": "add some convenience methods (from ParquetOutputFormat)",
            "message": "add some convenience methods (from ParquetOutputFormat)\n",
            "diff": {
                "parquet-hadoop/src/main/java/parquet/hadoop/mapred/DeprecatedParquetOutputFormat.java": 31
            },
            "is_test": false,
            "is_fix": false
        },
        "a00fd5e21b94692d4e3daf59946589fe1f6b16b4": {
            "datetime": "2013-09-16T13:56:28-07:00",
            "summary": "remove tests that check that TBaseScheme doesn't support writes",
            "message": "remove tests that check that TBaseScheme doesn't support writes\n",
            "diff": {
                "parquet-cascading/src/test/java/parquet/cascading/TestParquetTBaseScheme.java": 20
            },
            "is_test": true,
            "is_fix": false
        },
        "9ae1d88da88554b643e201c04484c4b5177157ad": {
            "datetime": "2013-09-16T13:56:28-07:00",
            "summary": "add Sink functionality to parquet.cascading.ParquetTBaseScheme",
            "message": "add Sink functionality to parquet.cascading.ParquetTBaseScheme\n",
            "diff": {
                "parquet-cascading/src/main/java/parquet/cascading/ParquetTBaseScheme.java": 28,
                "parquet-cascading/src/main/java/parquet/cascading/ParquetValueScheme.java": 16,
                "parquet-cascading/src/test/java/parquet/cascading/TestParquetTBaseScheme.java": 8
            },
            "is_test": true,
            "is_fix": false
        },
        "7adc26426d67cb3046a4db4c5f265f02ea2d420a": {
            "datetime": "2013-09-16T13:56:28-07:00",
            "summary": "add another getRecordWriter overload",
            "message": "add another getRecordWriter overload\n",
            "diff": {
                "parquet-hadoop/src/main/java/parquet/hadoop/ParquetOutputFormat.java": 6
            },
            "is_test": false,
            "is_fix": false
        },
        "ce6bfcc103e94a3c2f9f62eea588805ffe59bc2c": {
            "datetime": "2013-09-16T13:56:28-07:00",
            "summary": "add a DeprecatedParquetOutputFormat to mirror DeprecatedParquetInputFormat",
            "message": "add a DeprecatedParquetOutputFormat to mirror DeprecatedParquetInputFormat\n",
            "diff": {
                "parquet-hadoop/src/main/java/parquet/hadoop/mapred/DeprecatedParquetOutputFormat.java": 94
            },
            "is_test": false,
            "is_fix": false
        },
        "bba977549ca72f92b89cb0a72d16d93fe46621cb": {
            "datetime": "2013-09-16T13:56:29-07:00",
            "summary": "two unused imports",
            "message": "two unused imports\n",
            "diff": {
                "parquet-cascading/src/main/java/parquet/cascading/ParquetTBaseScheme.java": 3
            },
            "is_test": false,
            "is_fix": false
        },
        "34bbb9072b93e1770dc3bf6369a7312d476d8bb0": {
            "datetime": "2013-09-16T13:56:29-07:00",
            "summary": "missing copyright notice",
            "message": "missing copyright notice\n",
            "diff": {
                "parquet-hadoop/src/main/java/parquet/hadoop/mapred/DeprecatedParquetOutputFormat.java": 15
            },
            "is_test": false,
            "is_fix": false
        },
        "3c65205c5056c51d912dd7297be90eb3feb7165e": {
            "datetime": "2013-09-16T14:08:32-07:00",
            "summary": "field requirement depends on if the getter returns option",
            "message": "field requirement depends on if the getter returns option\n",
            "diff": {
                "parquet-scrooge/src/main/java/parquet/scrooge/ScroogeSchemaConverter.java": 6
            },
            "is_test": false,
            "is_fix": false
        },
        "e2fec1c3c1840645a26943c918292a621e91f3f1": {
            "datetime": "2013-09-16T14:30:36-07:00",
            "summary": "add optional map field to thrift file",
            "message": "add optional map field to thrift file\n",
            "diff": {
                "parquet-scrooge/src/main/java/parquet/scrooge/ScroogeSchemaConverter.java": 19
            },
            "is_test": false,
            "is_fix": false
        },
        "234a1cbfcfd2dc0af57be4091f82b28acee4d0db": {
            "datetime": "2013-09-16T14:37:59-07:00",
            "summary": "extracted key and value type from map and optional map",
            "message": "extracted key and value type from map and optional map\n",
            "diff": {
                "parquet-scrooge/src/main/java/parquet/scrooge/ScroogeSchemaConverter.java": 34
            },
            "is_test": false,
            "is_fix": false
        },
        "9a5eea0cbaf1083412b2a057c6190814f196292c": {
            "datetime": "2013-09-16T14:52:37-07:00",
            "summary": "working on map",
            "message": "working on map\n",
            "diff": {
                "parquet-scrooge/src/main/java/parquet/scrooge/ScroogeSchemaConverter.java": 11
            },
            "is_test": false,
            "is_fix": false
        },
        "dd02df03c3ed08d03a0333af68f43c7f2b59df6d": {
            "datetime": "2013-09-16T15:49:18-07:00",
            "summary": "added map test",
            "message": "added map test\n",
            "diff": {
                "parquet-scrooge/src/main/java/parquet/scrooge/ScroogeSchemaConverter.java": 18,
                "parquet-scrooge/src/test/java/parquet/scrooge/ScroogeSchemaConverterTest.java": 3
            },
            "is_test": true,
            "is_fix": false
        },
        "5aa7a682910bd138511aac0191b13fed9716f1e0": {
            "datetime": "2013-09-16T17:22:32-07:00",
            "summary": "accidentally deleted a space",
            "message": "accidentally deleted a space\n",
            "diff": {
                "parquet-hadoop/src/main/java/parquet/hadoop/ParquetOutputFormat.java": 2
            },
            "is_test": false,
            "is_fix": false
        },
        "b11e2a005014ecd827855dde9ce4d50b1f58aa4b": {
            "datetime": "2013-09-16T19:02:18-07:00",
            "summary": "Plumb type_length for FIXED types through to reading pages.",
            "message": "Plumb type_length for FIXED types through to reading pages.\n",
            "diff": {
                "parquet-avro/src/main/java/parquet/avro/AvroParquetReader.java": 2,
                "parquet-avro/src/main/java/parquet/avro/AvroReadSupport.java": 1,
                "parquet-avro/src/main/java/parquet/avro/AvroSchemaConverter.java": 2,
                "parquet-avro/src/test/java/parquet/avro/TestReadWrite.java": 4,
                "parquet-column/src/main/java/parquet/column/ColumnDescriptor.java": 7,
                "parquet-column/src/main/java/parquet/column/Encoding.java": 6,
                "parquet-column/src/main/java/parquet/column/impl/ColumnReaderImpl.java": 19,
                "parquet-column/src/main/java/parquet/column/values/ValuesWriter.java": 7,
                "parquet-column/src/main/java/parquet/column/values/plain/FixedLenByteArrayPlainValuesReader.java": 59,
                "parquet-column/src/main/java/parquet/column/values/plain/PlainValuesWriter.java": 10,
                "parquet-column/src/main/java/parquet/io/PrimitiveColumnIO.java": 9,
                "parquet-column/src/main/java/parquet/schema/MessageType.java": 13,
                "parquet-column/src/main/java/parquet/schema/PrimitiveType.java": 26,
                "parquet-hadoop/src/main/java/parquet/format/converter/ParquetMetadataConverter.java": 22
            },
            "is_test": true,
            "is_fix": false
        },
        "4e82ab632d39b236d302ff4283cae0a94f7cdbc0": {
            "datetime": "2013-09-17T03:59:46-07:00",
            "summary": "Add methods to write fixed Binary without prepending length.",
            "message": "Add methods to write fixed Binary without prepending length.\n",
            "diff": {
                "parquet-avro/src/main/java/parquet/avro/AvroWriteSupport.java": 2,
                "parquet-column/src/main/java/parquet/column/ColumnWriter.java": 8,
                "parquet-column/src/main/java/parquet/column/impl/ColumnWriterImpl.java": 9,
                "parquet-column/src/main/java/parquet/io/MessageColumnIO.java": 10,
                "parquet-column/src/main/java/parquet/io/RecordConsumerLoggingWrapper.java": 9,
                "parquet-column/src/main/java/parquet/io/ValidatingRecordConsumer.java": 8,
                "parquet-column/src/main/java/parquet/io/api/PrimitiveConverter.java": 7,
                "parquet-column/src/main/java/parquet/io/api/RecordConsumer.java": 6,
                "parquet-column/src/test/java/parquet/io/ConverterConsumer.java": 5,
                "parquet-column/src/test/java/parquet/io/ExpectationValidatingRecordConsumer.java": 5,
                "parquet-column/src/test/java/parquet/io/TestColumnIO.java": 5
            },
            "is_test": true,
            "is_fix": false
        },
        "1f630137267fed0b81871bd8eb0b315a6f009a35": {
            "datetime": "2013-09-17T09:42:02-07:00",
            "summary": "Added two boolean options for record filters.",
            "message": "Added two boolean options for record filters.\n",
            "diff": {
                "parquet-column/src/main/java/parquet/filter/NotRecordFilter.java": 55,
                "parquet-column/src/main/java/parquet/filter/OrRecordFilter.java": 59
            },
            "is_test": false,
            "is_fix": false
        },
        "58051d0629121332a8f96e00d2e9603583cbd564": {
            "datetime": "2013-09-17T10:17:51-07:00",
            "summary": "Added functionality to allow users to implement functions to be used as predicates.",
            "message": "Added functionality to allow users to implement functions to be used as predicates.\n",
            "diff": {
                "parquet-column/src/main/java/parquet/filter/ColumnPredicates.java": 59
            },
            "is_test": false,
            "is_fix": false
        },
        "232d521dc0860e0e657970d5bbab241d7a58d283": {
            "datetime": "2013-09-17T11:00:59-07:00",
            "summary": "use class.getName",
            "message": "use class.getName\n",
            "diff": {
                "parquet-scrooge/src/test/java/parquet/scrooge/ParquetScroogeSchemeTest.java": 2
            },
            "is_test": true,
            "is_fix": false
        },
        "0f9e39b7fc3743ed641c9c28dbc0f0f26493f476": {
            "datetime": "2013-09-17T13:47:52-07:00",
            "summary": "Merge pull request #165 from Parquet/distinguish_recoverable_exception",
            "message": "Merge pull request #165 from Parquet/distinguish_recoverable_exception\n\ndistinguish recoverable errors",
            "diff": {
                "parquet-thrift/src/main/java/parquet/thrift/BufferedProtocolReadToWrite.java": 21,
                "parquet-thrift/src/main/java/parquet/thrift/SkippableException.java": 32,
                "parquet-thrift/src/test/java/parquet/thrift/TestProtocolReadToWrite.java": 4
            },
            "is_test": true,
            "is_fix": false
        },
        "f8ac0f01deb15cf7b54ec9355dd57f6b96471b0d": {
            "datetime": "2013-09-17T14:41:09-07:00",
            "summary": "Initial end-to-end write and read support for Avro FIXED fields without runtime exceptions, but still with data representation issues.",
            "message": "Initial end-to-end write and read support for Avro FIXED fields without runtime exceptions, but still with data representation issues.\n",
            "diff": {
                "parquet-avro/src/main/java/parquet/avro/AvroIndexedRecordConverter.java": 3,
                "parquet-column/src/main/java/parquet/column/Encoding.java": 4,
                "parquet-column/src/main/java/parquet/column/impl/ColumnReaderImpl.java": 3,
                "parquet-column/src/main/java/parquet/column/values/plain/FixedLenByteArrayPlainValuesReader.java": 5
            },
            "is_test": false,
            "is_fix": false
        },
        "4f1493b0aa663111871404b026064ea35a5234e2": {
            "datetime": "2013-09-17T18:04:30-07:00",
            "summary": "Fix broken tests. Test failures encountered previously were due to broken tests.",
            "message": "Fix broken tests. Test failures encountered previously were due to broken tests.\n",
            "diff": {
                "parquet-avro/src/test/java/parquet/avro/TestAvroSchemaConverter.java": 3,
                "parquet-avro/src/test/java/parquet/avro/TestReadWrite.java": 21
            },
            "is_test": true,
            "is_fix": false
        },
        "08b45b0c1c5a8b7766544ba01dd9861d8b0fbfb4": {
            "datetime": "2013-09-18T03:14:08-07:00",
            "summary": "Add fixed_len_byte_array to oneOfEach in TestColumnIO.",
            "message": "Add fixed_len_byte_array to oneOfEach in TestColumnIO.\n",
            "diff": {
                "parquet-column/src/test/java/parquet/io/TestColumnIO.java": 22
            },
            "is_test": true,
            "is_fix": false
        },
        "201d80c57a711c232539732df1c109f045ec09a1": {
            "datetime": "2013-09-18T03:14:23-07:00",
            "summary": "Merge branch 'fixed_len_byte_array' of https://github.com/davidzchen/parquet-mr into fixed_len_byte_array",
            "message": "Merge branch 'fixed_len_byte_array' of https://github.com/davidzchen/parquet-mr into fixed_len_byte_array\n",
            "diff": {
                "parquet-avro/src/main/java/parquet/avro/AvroIndexedRecordConverter.java": 3,
                "parquet-avro/src/test/java/parquet/avro/TestAvroSchemaConverter.java": 3,
                "parquet-avro/src/test/java/parquet/avro/TestReadWrite.java": 21,
                "parquet-column/src/main/java/parquet/column/Encoding.java": 4,
                "parquet-column/src/main/java/parquet/column/impl/ColumnReaderImpl.java": 3,
                "parquet-column/src/main/java/parquet/column/values/plain/FixedLenByteArrayPlainValuesReader.java": 5
            },
            "is_test": true,
            "is_fix": false
        },
        "e8c2a399a79cfd2905dd8d8e7c0e58bec68ece7b": {
            "datetime": "2013-09-18T10:02:16-07:00",
            "summary": "better log messages",
            "message": "better log messages\n",
            "diff": {
                "parquet-hadoop/src/main/java/parquet/hadoop/InternalParquetRecordWriter.java": 7
            },
            "is_test": false,
            "is_fix": false
        },
        "562e8111552be8fbbe701c02dddfa3a3496a5f47": {
            "datetime": "2013-09-18T11:13:39-07:00",
            "summary": "make binary dictionary encoding use fastutils; fix tests",
            "message": "make binary dictionary encoding use fastutils; fix tests\n",
            "diff": {
                "parquet-column/src/main/java/parquet/column/values/dictionary/DictionaryValuesWriter.java": 15,
                "parquet-column/src/test/java/parquet/column/values/dictionary/TestDictionary.java": 459
            },
            "is_test": true,
            "is_fix": false
        },
        "1c9c19cf08dc6aae5e82dc96a6b945f0b140eec3": {
            "datetime": "2013-09-18T14:12:38-07:00",
            "summary": "Merge pull request #171 from Parquet/scrooge_tests",
            "message": "Merge pull request #171 from Parquet/scrooge_tests\n\nupdate scrooge denepdency, add unit tests for reading in scrooge",
            "diff": {
                "parquet-scrooge/src/test/java/parquet/scrooge/ParquetScroogeSchemeTest.java": 93
            },
            "is_test": true,
            "is_fix": false
        },
        "8305bdb1937a24bc7e778ec497ceafb8b883be42": {
            "datetime": "2013-09-19T03:01:24-07:00",
            "summary": "Add FixedBinary type by creating a wrapper class around Binary and plumb FixedBinary through for read and write support for FIXED_LEN_BYTE_ARRAY. Undo change to add FIXED field to oneOfEach schema for parquet-column TestColumnIO for now.",
            "message": "Add FixedBinary type by creating a wrapper class around Binary and plumb FixedBinary through for read and write support for FIXED_LEN_BYTE_ARRAY. Undo change to add FIXED field to oneOfEach schema for parquet-column TestColumnIO for now.\n",
            "diff": {
                "parquet-avro/src/main/java/parquet/avro/AvroIndexedRecordConverter.java": 3,
                "parquet-avro/src/main/java/parquet/avro/AvroWriteSupport.java": 4,
                "parquet-column/src/main/java/parquet/column/ColumnReader.java": 6,
                "parquet-column/src/main/java/parquet/column/ColumnWriter.java": 3,
                "parquet-column/src/main/java/parquet/column/impl/ColumnReaderImpl.java": 26,
                "parquet-column/src/main/java/parquet/column/impl/ColumnWriterImpl.java": 3,
                "parquet-column/src/main/java/parquet/column/values/ValuesReader.java": 8,
                "parquet-column/src/main/java/parquet/column/values/ValuesWriter.java": 3,
                "parquet-column/src/main/java/parquet/column/values/plain/FixedLenByteArrayPlainValuesReader.java": 8,
                "parquet-column/src/main/java/parquet/column/values/plain/PlainValuesWriter.java": 3,
                "parquet-column/src/main/java/parquet/io/MessageColumnIO.java": 5,
                "parquet-column/src/main/java/parquet/io/RecordConsumerLoggingWrapper.java": 3,
                "parquet-column/src/main/java/parquet/io/ValidatingRecordConsumer.java": 3,
                "parquet-column/src/main/java/parquet/io/api/Binary.java": 1,
                "parquet-column/src/main/java/parquet/io/api/FixedBinary.java": 117,
                "parquet-column/src/main/java/parquet/io/api/PrimitiveConverter.java": 2,
                "parquet-column/src/main/java/parquet/io/api/RecordConsumer.java": 2,
                "parquet-column/src/test/java/parquet/io/ConverterConsumer.java": 3,
                "parquet-column/src/test/java/parquet/io/ExpectationValidatingRecordConsumer.java": 3,
                "parquet-column/src/test/java/parquet/io/TestColumnIO.java": 7
            },
            "is_test": true,
            "is_fix": false
        },
        "a48f56f85ab758796ba072b8140fed6f712dd8fb": {
            "datetime": "2013-09-19T06:23:53-07:00",
            "summary": "Re-add FIXED_LEN_BYTE_ARRAY to oneOfEach and plumb through FIXED support for example Group. Test still fails and need to solve read issues.",
            "message": "Re-add FIXED_LEN_BYTE_ARRAY to oneOfEach and plumb through FIXED support for example Group. Test still fails and need to solve read issues.\n",
            "diff": {
                "parquet-column/src/main/java/parquet/example/data/Group.java": 12,
                "parquet-column/src/main/java/parquet/example/data/GroupValueSource.java": 7,
                "parquet-column/src/main/java/parquet/example/data/simple/FixedBinaryValue.java": 48,
                "parquet-column/src/main/java/parquet/example/data/simple/Primitive.java": 5,
                "parquet-column/src/main/java/parquet/example/data/simple/SimpleGroup.java": 12,
                "parquet-column/src/main/java/parquet/example/data/simple/convert/SimplePrimitiveConverter.java": 17,
                "parquet-column/src/main/java/parquet/io/ValidatingRecordConsumer.java": 2,
                "parquet-column/src/test/java/parquet/io/TestColumnIO.java": 21
            },
            "is_test": true,
            "is_fix": false
        },
        "1c99a117f1d4860891d4ad04242cf71581ef7137": {
            "datetime": "2013-09-19T11:02:51-07:00",
            "summary": "rename variables for readability",
            "message": "rename variables for readability\n",
            "diff": {
                "parquet-column/src/main/java/parquet/io/RecordReaderImplementation.java": 75
            },
            "is_test": false,
            "is_fix": false
        },
        "108509fc30a01c1e52a9a02f44a00f5be1398622": {
            "datetime": "2013-09-19T11:13:40-07:00",
            "summary": "Merge pull request #173 from Parquet/better_log_messages",
            "message": "Merge pull request #173 from Parquet/better_log_messages\n\nbetter log messages",
            "diff": {
                "parquet-hadoop/src/main/java/parquet/hadoop/InternalParquetRecordWriter.java": 7
            },
            "is_test": false,
            "is_fix": false
        },
        "bbf34480888124fd875150e15ac4064067675600": {
            "datetime": "2013-09-19T13:14:48-05:00",
            "summary": "add overloaded getFooConfiguration(JobContext) methods to ParquetOutputFormat",
            "message": "add overloaded getFooConfiguration(JobContext) methods to ParquetOutputFormat\n",
            "diff": {
                "parquet-hadoop/src/main/java/parquet/hadoop/ParquetOutputFormat.java": 29
            },
            "is_test": false,
            "is_fix": false
        },
        "310e55170d1cea2846fcdc5ecd56c394b70c799c": {
            "datetime": "2013-09-19T13:16:14-05:00",
            "summary": "throw the writeSupportClass as part of the exception message if instantiation fails",
            "message": "throw the writeSupportClass as part of the exception message if instantiation fails\n",
            "diff": {
                "parquet-hadoop/src/main/java/parquet/hadoop/ParquetOutputFormat.java": 7
            },
            "is_test": false,
            "is_fix": false
        },
        "20f3f46cbd9c6fe3e162690802a6696a64ca7232": {
            "datetime": "2013-09-19T11:21:01-07:00",
            "summary": "continue renaming",
            "message": "continue renaming\n",
            "diff": {
                "parquet-column/src/main/java/parquet/io/RecordReaderImplementation.java": 40
            },
            "is_test": false,
            "is_fix": false
        },
        "6da759455251c47813202cfac29056a8e3f6e834": {
            "datetime": "2013-09-19T17:07:14-07:00",
            "summary": "fix problem with projection pushdown in parquetloader",
            "message": "fix problem with projection pushdown in parquetloader\n",
            "diff": {
                "parquet-pig/src/main/java/parquet/pig/ParquetLoader.java": 57,
                "parquet-pig/src/main/java/parquet/pig/PigSchemaConverter.java": 2,
                "parquet-pig/src/test/java/parquet/pig/TestParquetLoader.java": 68
            },
            "is_test": true,
            "is_fix": false
        },
        "cc59cb82675499870e9b0433c350f01a3522c2c9": {
            "datetime": "2013-09-19T17:54:27-07:00",
            "summary": "Use ValuesWriter and ValuesReader specific to FIXED_LEN_BYTE_ARRAY rather than overloading on a FixedBinary class.",
            "message": "Use ValuesWriter and ValuesReader specific to FIXED_LEN_BYTE_ARRAY rather than overloading on a FixedBinary class.\n",
            "diff": {
                "parquet-avro/src/main/java/parquet/avro/AvroIndexedRecordConverter.java": 3,
                "parquet-avro/src/main/java/parquet/avro/AvroWriteSupport.java": 4,
                "parquet-column/src/main/java/parquet/column/ColumnReader.java": 6,
                "parquet-column/src/main/java/parquet/column/ColumnWriter.java": 9,
                "parquet-column/src/main/java/parquet/column/Encoding.java": 3,
                "parquet-column/src/main/java/parquet/column/impl/ColumnReaderImpl.java": 26,
                "parquet-column/src/main/java/parquet/column/impl/ColumnWriterImpl.java": 14,
                "parquet-column/src/main/java/parquet/column/values/ValuesReader.java": 8,
                "parquet-column/src/main/java/parquet/column/values/ValuesWriter.java": 8,
                "parquet-column/src/main/java/parquet/column/values/plain/FixedLenByteArrayPlainValuesReader.java": 6,
                "parquet-column/src/main/java/parquet/column/values/plain/FixedLenByteArrayPlainValuesWriter.java": 90,
                "parquet-column/src/main/java/parquet/column/values/plain/PlainValuesWriter.java": 12,
                "parquet-column/src/main/java/parquet/example/data/Group.java": 12,
                "parquet-column/src/main/java/parquet/example/data/GroupValueSource.java": 7,
                "parquet-column/src/main/java/parquet/example/data/simple/FixedBinaryValue.java": 48,
                "parquet-column/src/main/java/parquet/example/data/simple/Primitive.java": 5,
                "parquet-column/src/main/java/parquet/example/data/simple/SimpleGroup.java": 11,
                "parquet-column/src/main/java/parquet/example/data/simple/convert/SimplePrimitiveConverter.java": 10,
                "parquet-column/src/main/java/parquet/io/MessageColumnIO.java": 11,
                "parquet-column/src/main/java/parquet/io/RecordConsumerLoggingWrapper.java": 10,
                "parquet-column/src/main/java/parquet/io/ValidatingRecordConsumer.java": 9,
                "parquet-column/src/main/java/parquet/io/api/FixedBinary.java": 117,
                "parquet-column/src/main/java/parquet/io/api/PrimitiveConverter.java": 7,
                "parquet-column/src/main/java/parquet/io/api/RecordConsumer.java": 6,
                "parquet-column/src/test/java/parquet/io/ConverterConsumer.java": 6,
                "parquet-column/src/test/java/parquet/io/ExpectationValidatingRecordConsumer.java": 6,
                "parquet-column/src/test/java/parquet/io/TestColumnIO.java": 10
            },
            "is_test": true,
            "is_fix": false
        },
        "3e02a841bb37f17d6218c23255e254db990846bd": {
            "datetime": "2013-09-19T18:30:51-07:00",
            "summary": "Merge branch 'master' into fixed_len_byte_array",
            "message": "Merge branch 'master' into fixed_len_byte_array\n",
            "diff": {
                "parquet-hadoop/src/main/java/parquet/hadoop/InternalParquetRecordWriter.java": 7,
                "parquet-scrooge/src/test/java/parquet/scrooge/ParquetScroogeSchemeTest.java": 93,
                "parquet-thrift/src/main/java/parquet/thrift/BufferedProtocolReadToWrite.java": 21,
                "parquet-thrift/src/main/java/parquet/thrift/SkippableException.java": 32,
                "parquet-thrift/src/test/java/parquet/thrift/TestProtocolReadToWrite.java": 4
            },
            "is_test": true,
            "is_fix": false
        },
        "e37cd2b70fcc8471451f134e37d2b25a5b36464f": {
            "datetime": "2013-09-19T21:42:30-07:00",
            "summary": "Add fixed field to parquet-avro TestSpecificReadWrite.",
            "message": "Add fixed field to parquet-avro TestSpecificReadWrite.\n",
            "diff": {
                "parquet-avro/src/test/java/parquet/avro/TestSpecificReadWrite.java": 15
            },
            "is_test": true,
            "is_fix": false
        },
        "ebe07c6fb3f3ea3a50511fac4bd71ba683043b73": {
            "datetime": "2013-09-20T08:55:59-07:00",
            "summary": "changes as per code review comments",
            "message": "changes as per code review comments\n",
            "diff": {
                "parquet-pig/src/main/java/parquet/pig/ParquetLoader.java": 5
            },
            "is_test": false,
            "is_fix": false
        },
        "a73e73c8c0f5314aed0bc7f8ccd9454f461e28be": {
            "datetime": "2013-09-20T09:24:37-07:00",
            "summary": "changes as per code review comments for test",
            "message": "changes as per code review comments for test\n",
            "diff": {
                "parquet-pig/src/test/java/parquet/pig/TestParquetLoader.java": 4
            },
            "is_test": true,
            "is_fix": false
        },
        "469400156f8e85bad333f48730b9160cecba7df0": {
            "datetime": "2013-09-20T09:25:21-07:00",
            "summary": "Merge pull request #175 from Parquet/pig_projection_pushdown",
            "message": "Merge pull request #175 from Parquet/pig_projection_pushdown\n\nfix problem with projection pushdown in parquetloader",
            "diff": {
                "parquet-pig/src/main/java/parquet/pig/ParquetLoader.java": 58,
                "parquet-pig/src/main/java/parquet/pig/PigSchemaConverter.java": 2,
                "parquet-pig/src/test/java/parquet/pig/TestParquetLoader.java": 66
            },
            "is_test": true,
            "is_fix": false
        },
        "51d33328b3d6b503d1366b7a683b5a4520d814d2": {
            "datetime": "2013-09-20T09:38:22-07:00",
            "summary": "Merge pull request #174 from Parquet/readability",
            "message": "Merge pull request #174 from Parquet/readability\n\nrename variables for readability",
            "diff": {
                "parquet-column/src/main/java/parquet/io/RecordReaderImplementation.java": 87
            },
            "is_test": false,
            "is_fix": false
        },
        "3b5d32bcab01886a5a4b3c1378809fc5af9cc434": {
            "datetime": "2013-09-20T12:35:12-07:00",
            "summary": "Add new Vin field to Avro TestSpecificInputOutputFormat.",
            "message": "Add new Vin field to Avro TestSpecificInputOutputFormat.\n",
            "diff": {
                "parquet-avro/src/test/java/parquet/avro/TestSpecificInputOutputFormat.java": 2
            },
            "is_test": true,
            "is_fix": false
        },
        "e6fab0681a31aa60af07136aba65b3e69c8f45e3": {
            "datetime": "2013-09-20T17:33:37-07:00",
            "summary": "Document why FIXED_LEN_BYTE_ARRAY is not supported with Avro specific schema right now.",
            "message": "Document why FIXED_LEN_BYTE_ARRAY is not supported with Avro specific schema right now.\n",
            "diff": {
                "parquet-avro/src/main/java/parquet/avro/AvroIndexedRecordConverter.java": 6,
                "parquet-avro/src/test/java/parquet/avro/TestSpecificInputOutputFormat.java": 4,
                "parquet-avro/src/test/java/parquet/avro/TestSpecificReadWrite.java": 52
            },
            "is_test": true,
            "is_fix": false
        },
        "e242085ac3f79d377ed62fd2620fbeaf9a61c969": {
            "datetime": "2013-09-20T21:54:38-05:00",
            "summary": "add an empty constructor for ParquetTBaseScheme (which only works for reads)",
            "message": "add an empty constructor for ParquetTBaseScheme (which only works for reads)\n",
            "diff": {
                "parquet-cascading/src/main/java/parquet/cascading/ParquetTBaseScheme.java": 16
            },
            "is_test": false,
            "is_fix": false
        },
        "3105009fe85cb78922e9f70ac52297cccc9101c9": {
            "datetime": "2013-09-20T22:55:47-05:00",
            "summary": "add read and write tests for ParquetTBaseScheme",
            "message": "add read and write tests for ParquetTBaseScheme\n",
            "diff": {
                "parquet-cascading/src/test/java/parquet/cascading/TestParquetTBaseScheme.java": 153
            },
            "is_test": true,
            "is_fix": false
        },
        "458dd70f1820f5bac10bda10f9b47cb14d31246f": {
            "datetime": "2013-09-20T22:55:59-05:00",
            "summary": "remove redundant test",
            "message": "remove redundant test\n",
            "diff": {
                "parquet-cascading/src/test/java/parquet/cascading/TestParquetTBaseScheme.java": 39
            },
            "is_test": true,
            "is_fix": false
        },
        "3b7359b347edb1d3ed780e7872f6bdf3efc2e2c7": {
            "datetime": "2013-09-22T22:29:30-07:00",
            "summary": "Re-enable tests for writing FIXED for Avro Specific records. Preliminary end-to-end for writing FIXED but write is still not completely correct yet.",
            "message": "Re-enable tests for writing FIXED for Avro Specific records. Preliminary end-to-end for writing FIXED but write is still not completely correct yet.\n",
            "diff": {
                "parquet-avro/src/main/java/parquet/avro/AvroIndexedRecordConverter.java": 12,
                "parquet-avro/src/test/java/parquet/avro/TestSpecificInputOutputFormat.java": 4,
                "parquet-avro/src/test/java/parquet/avro/TestSpecificReadWrite.java": 12
            },
            "is_test": true,
            "is_fix": false
        },
        "1b326b7fee6616cb63016dbce2a07daf2b0213b1": {
            "datetime": "2013-09-23T04:29:01-07:00",
            "summary": "Fix reflection for converting fixed Binary to Avro SpecificFixed. Ensure that FIXED values are written using the FLBA PlainValuesReader when dictionary is enabled.",
            "message": "Fix reflection for converting fixed Binary to Avro SpecificFixed. Ensure that FIXED values are written using the FLBA PlainValuesReader when dictionary is enabled.\n",
            "diff": {
                "parquet-avro/src/main/java/parquet/avro/AvroIndexedRecordConverter.java": 15,
                "parquet-avro/src/main/java/parquet/avro/AvroReadSupport.java": 1,
                "parquet-avro/src/main/java/parquet/avro/AvroWriteSupport.java": 1,
                "parquet-avro/src/test/java/parquet/avro/TestSpecificInputOutputFormat.java": 2,
                "parquet-avro/src/test/java/parquet/avro/TestSpecificReadWrite.java": 12,
                "parquet-column/src/main/java/parquet/column/impl/ColumnWriterImpl.java": 3
            },
            "is_test": true,
            "is_fix": false
        },
        "12d41ac61f6d3a18c9f00634cc3fde0a7a295cf9": {
            "datetime": "2013-09-23T04:36:34-07:00",
            "summary": "De-fluffify inadvertently added whitespace changes.",
            "message": "De-fluffify inadvertently added whitespace changes.\n",
            "diff": {
                "parquet-avro/src/main/java/parquet/avro/AvroWriteSupport.java": 2,
                "parquet-column/src/main/java/parquet/column/ColumnWriter.java": 3,
                "parquet-column/src/main/java/parquet/column/values/ValuesReader.java": 3,
                "parquet-column/src/main/java/parquet/column/values/plain/PlainValuesWriter.java": 1,
                "parquet-column/src/main/java/parquet/example/data/simple/SimpleGroup.java": 1,
                "parquet-column/src/main/java/parquet/io/MessageColumnIO.java": 2,
                "parquet-column/src/main/java/parquet/io/api/Binary.java": 1,
                "parquet-column/src/main/java/parquet/io/api/PrimitiveConverter.java": 2,
                "parquet-column/src/test/java/parquet/io/ExpectationValidatingRecordConsumer.java": 1
            },
            "is_test": false,
            "is_fix": false
        },
        "e31d46c428a332d7aec53f35029a5774d039676d": {
            "datetime": "2013-09-24T17:45:58-07:00",
            "summary": "merge master",
            "message": "merge master\n",
            "diff": {
                "parquet-column/src/main/java/parquet/io/RecordReaderImplementation.java": 87,
                "parquet-hadoop/src/main/java/parquet/hadoop/InternalParquetRecordWriter.java": 7,
                "parquet-pig/src/main/java/parquet/pig/ParquetLoader.java": 58,
                "parquet-pig/src/main/java/parquet/pig/PigSchemaConverter.java": 2,
                "parquet-pig/src/test/java/parquet/pig/TestParquetLoader.java": 66,
                "parquet-scrooge/src/test/java/parquet/scrooge/ParquetScroogeSchemeTest.java": 2,
                "parquet-thrift/src/main/java/parquet/thrift/BufferedProtocolReadToWrite.java": 21,
                "parquet-thrift/src/main/java/parquet/thrift/SkippableException.java": 32,
                "parquet-thrift/src/test/java/parquet/thrift/TestProtocolReadToWrite.java": 4
            },
            "is_test": true,
            "is_fix": false
        },
        "a79eab750d002eb91efbe4cc02abb009b9db1ee9": {
            "datetime": "2013-09-25T03:58:39-07:00",
            "summary": "Complete support for supporting FIXED_LEN_BYTE_ARRAY for Avro SpecificRecord. Add syntax to specify type length for FLBA type fields to MessageTypeParser.",
            "message": "Complete support for supporting FIXED_LEN_BYTE_ARRAY for Avro SpecificRecord. Add syntax to specify type length for FLBA type fields to MessageTypeParser.\n",
            "diff": {
                "parquet-avro/src/test/java/parquet/avro/TestAvroSchemaConverter.java": 15,
                "parquet-column/src/main/java/parquet/schema/MessageTypeParser.java": 12,
                "parquet-column/src/main/java/parquet/schema/PrimitiveType.java": 32
            },
            "is_test": true,
            "is_fix": false
        },
        "24d72673d1ae3cba9cf90312550b32f954e343ec": {
            "datetime": "2013-09-25T04:08:39-07:00",
            "summary": "Remove print statements.",
            "message": "Remove print statements.\n",
            "diff": {
                "parquet-avro/src/main/java/parquet/avro/AvroIndexedRecordConverter.java": 1,
                "parquet-column/src/main/java/parquet/column/impl/ColumnWriterImpl.java": 1,
                "parquet-column/src/main/java/parquet/io/api/RecordConsumer.java": 2,
                "parquet-hadoop/src/main/java/parquet/format/converter/ParquetMetadataConverter.java": 7
            },
            "is_test": false,
            "is_fix": false
        },
        "976c68acb31b590bb8b2b509da05164b23c529ad": {
            "datetime": "2013-09-25T04:25:15-07:00",
            "summary": "Merge branch 'master' into fixed_len_byte_array",
            "message": "Merge branch 'master' into fixed_len_byte_array\n",
            "diff": {
                "parquet-column/src/main/java/parquet/io/RecordReaderImplementation.java": 87,
                "parquet-pig/src/main/java/parquet/pig/ParquetLoader.java": 58,
                "parquet-pig/src/main/java/parquet/pig/PigSchemaConverter.java": 2,
                "parquet-pig/src/test/java/parquet/pig/TestParquetLoader.java": 66
            },
            "is_test": true,
            "is_fix": false
        },
        "ca7da658ca18ef6775557ebba9776ece5a21554f": {
            "datetime": "2013-09-25T14:04:49-07:00",
            "summary": "basic support for map",
            "message": "basic support for map\n",
            "diff": {
                "parquet-scrooge/src/main/java/parquet/scrooge/ScroogeSchemaConverter.java": 46,
                "parquet-scrooge/src/test/java/parquet/scrooge/ScroogeSchemaConverterTest.java": 9
            },
            "is_test": true,
            "is_fix": false
        },
        "6a6613fc746bf409eff1372fa7d92cb556db9f44": {
            "datetime": "2013-09-25T14:11:32-07:00",
            "summary": "tests all primitive key types in map",
            "message": "tests all primitive key types in map\n",
            "diff": {
                "parquet-scrooge/src/test/java/parquet/scrooge/ScroogeSchemaConverterTest.java": 3
            },
            "is_test": true,
            "is_fix": false
        },
        "49f3ad17a066dde80e9d7f84fc859a1afb791c02": {
            "datetime": "2013-09-25T14:21:58-07:00",
            "summary": "Add support for reading FIXED_LEN_BYTE_ARRAY to Pig support.",
            "message": "Add support for reading FIXED_LEN_BYTE_ARRAY to Pig support.\n",
            "diff": {
                "parquet-avro/src/test/java/parquet/avro/TestSpecificInputOutputFormat.java": 24,
                "parquet-pig/src/main/java/parquet/pig/PigSchemaConverter.java": 199,
                "parquet-pig/src/test/java/parquet/pig/TestParquetLoader.java": 5,
                "parquet-pig/src/test/java/parquet/pig/TestPigSchemaConverter.java": 27
            },
            "is_test": true,
            "is_fix": false
        },
        "5ab6cccf9fcd280680f8ffdb74a17a5a71a327a7": {
            "datetime": "2013-09-25T14:33:27-07:00",
            "summary": "Merge pull request #169 from davidzchen/fix_avro_empty_maps_arrays",
            "message": "Merge pull request #169 from davidzchen/fix_avro_empty_maps_arrays\n\nSupport avro records with empty maps and arrays",
            "diff": {
                "parquet-avro/src/main/java/parquet/avro/AvroWriteSupport.java": 74,
                "parquet-avro/src/test/java/parquet/avro/TestReadWrite.java": 65
            },
            "is_test": true,
            "is_fix": false
        },
        "0822e32631e50c751f4b1a8b33111d6f2a50a56f": {
            "datetime": "2013-09-25T14:42:11-07:00",
            "summary": "add unit test for primitive value for maps",
            "message": "add unit test for primitive value for maps\n",
            "diff": {
                "parquet-scrooge/src/test/java/parquet/scrooge/ScroogeSchemaConverterTest.java": 14
            },
            "is_test": true,
            "is_fix": false
        },
        "9cd67375d2d64eaf9e1ae4021885f9130881a325": {
            "datetime": "2013-09-25T14:46:37-07:00",
            "summary": "Add comments to new files.",
            "message": "Add comments to new files.\n",
            "diff": {
                "parquet-column/src/main/java/parquet/column/values/plain/FixedLenByteArrayPlainValuesReader.java": 5,
                "parquet-column/src/main/java/parquet/column/values/plain/FixedLenByteArrayPlainValuesWriter.java": 5
            },
            "is_test": false,
            "is_fix": false
        },
        "d9ced33ef44c87b11b1bee0808de2e2362bd5323": {
            "datetime": "2013-09-25T15:03:39-07:00",
            "summary": "test optional map",
            "message": "test optional map\n",
            "diff": {
                "parquet-scrooge/src/test/java/parquet/scrooge/ScroogeSchemaConverterTest.java": 173
            },
            "is_test": true,
            "is_fix": false
        },
        "f45b384e7d0d2d9d501f0dfd278c247dec31a369": {
            "datetime": "2013-09-25T16:40:24-07:00",
            "summary": "convert list and unit tests",
            "message": "convert list and unit tests\n",
            "diff": {
                "parquet-scrooge/src/main/java/parquet/scrooge/ScroogeSchemaConverter.java": 9,
                "parquet-scrooge/src/test/java/parquet/scrooge/ScroogeSchemaConverterTest.java": 8,
                "parquet-thrift/src/main/java/parquet/thrift/struct/ThriftField.java": 23,
                "parquet-thrift/src/main/java/parquet/thrift/struct/ThriftType.java": 96
            },
            "is_test": true,
            "is_fix": false
        },
        "5410381c14187990675c62b6627eb0adcc45193c": {
            "datetime": "2013-09-25T16:47:19-07:00",
            "summary": "convert set and unit tests",
            "message": "convert set and unit tests\n",
            "diff": {
                "parquet-scrooge/src/main/java/parquet/scrooge/ScroogeSchemaConverter.java": 8,
                "parquet-scrooge/src/test/java/parquet/scrooge/ScroogeSchemaConverterTest.java": 10
            },
            "is_test": true,
            "is_fix": false
        },
        "d0fc6a0d16d89f903859f69be3d08666f2fa50ed": {
            "datetime": "2013-09-25T18:37:12-07:00",
            "summary": "Correct schema syntaxes for TestHiveSchemaConverter.",
            "message": "Correct schema syntaxes for TestHiveSchemaConverter.\n",
            "diff": {
                "parquet-hive/src/test/java/parquet/hive/TestHiveSchemaConverter.java": 5
            },
            "is_test": true,
            "is_fix": false
        },
        "6ffc1b9fe17309b409b54c7b053bf511768a29e4": {
            "datetime": "2013-09-26T09:20:35-07:00",
            "summary": "implemented conversion for enum",
            "message": "implemented conversion for enum\n",
            "diff": {
                "parquet-scrooge/src/main/java/parquet/scrooge/ScroogeSchemaConverter.java": 64,
                "parquet-scrooge/src/test/java/parquet/scrooge/ScroogeSchemaConverterTest.java": 11,
                "parquet-thrift/src/main/java/parquet/thrift/struct/ThriftType.java": 40
            },
            "is_test": true,
            "is_fix": false
        },
        "bfcb120889ce52409093536f24000d75da0594d3": {
            "datetime": "2013-09-26T10:17:51-07:00",
            "summary": "implemented map with nested structure, TODO: tests failing since the default requirement can not be determined",
            "message": "implemented map with nested structure, TODO: tests failing since the default requirement can not be determined\n",
            "diff": {
                "parquet-scrooge/src/main/java/parquet/scrooge/ScroogeSchemaConverter.java": 50,
                "parquet-scrooge/src/test/java/parquet/scrooge/ScroogeSchemaConverterTest.java": 19
            },
            "is_test": true,
            "is_fix": false
        },
        "835f12eae78c762322dd6b77481a5aca47637ec7": {
            "datetime": "2013-09-26T17:07:46-07:00",
            "summary": "refactor code",
            "message": "refactor code\n",
            "diff": {
                "parquet-scrooge/src/main/java/parquet/scrooge/EnumConverter.java": 44,
                "parquet-scrooge/src/main/java/parquet/scrooge/ScroogeEnumDesc.java": 34,
                "parquet-scrooge/src/main/java/parquet/scrooge/ScroogeSchemaConverter.java": 152
            },
            "is_test": false,
            "is_fix": false
        },
        "4b2cb26341eefb679cd599c75952509aa76af55a": {
            "datetime": "2013-09-26T18:07:08-07:00",
            "summary": "Added unit tests for predicates. Got predicates compiling, and passing on tests.",
            "message": "Added unit tests for predicates. Got predicates compiling, and passing on tests.\n",
            "diff": {
                "parquet-column/src/main/java/parquet/filter/ColumnPredicates.java": 32,
                "parquet-column/src/main/java/parquet/filter/NotRecordFilter.java": 4,
                "parquet-column/src/main/java/parquet/filter/OrRecordFilter.java": 2,
                "parquet-column/src/test/java/parquet/io/TestFiltered.java": 38
            },
            "is_test": true,
            "is_fix": false
        },
        "1ee42327bbde2513edb48a22a207da36623d000d": {
            "datetime": "2013-09-27T06:14:29-07:00",
            "summary": "Merge changes from master that fix handling empty Avro arrays and maps.",
            "message": "Merge changes from master that fix handling empty Avro arrays and maps.\n",
            "diff": {
                "parquet-avro/src/main/java/parquet/avro/AvroWriteSupport.java": 74,
                "parquet-avro/src/test/java/parquet/avro/TestAvroSchemaConverter.java": 9,
                "parquet-avro/src/test/java/parquet/avro/TestReadWrite.java": 66
            },
            "is_test": true,
            "is_fix": false
        },
        "52c32a3a296892a4fa94a040f242313620518258": {
            "datetime": "2013-09-27T08:31:11-07:00",
            "summary": "Removing predicate functions to prepare for pushing or/not filters. Limits number of features pushed.",
            "message": "Removing predicate functions to prepare for pushing or/not filters. Limits number of features pushed.\n",
            "diff": {
                "parquet-column/src/main/java/parquet/filter/ColumnPredicates.java": 59
            },
            "is_test": false,
            "is_fix": false
        },
        "b49018bb7908610533a6d3f60140d884a891c3a9": {
            "datetime": "2013-09-27T08:42:02-07:00",
            "summary": "Merging in changes from main repository that I have forked from to minimize work after pull request.",
            "message": "Merging in changes from main repository that I have forked from to minimize work after pull request.\n",
            "diff": {
                "parquet-avro/src/main/java/parquet/avro/AvroWriteSupport.java": 74,
                "parquet-avro/src/test/java/parquet/avro/TestReadWrite.java": 65,
                "parquet-column/src/main/java/parquet/io/RecordReaderImplementation.java": 87,
                "parquet-hadoop/src/main/java/parquet/hadoop/InternalParquetRecordWriter.java": 7,
                "parquet-pig/src/main/java/parquet/pig/ParquetLoader.java": 58,
                "parquet-pig/src/main/java/parquet/pig/PigSchemaConverter.java": 2,
                "parquet-pig/src/test/java/parquet/pig/TestParquetLoader.java": 66,
                "parquet-scrooge/src/test/java/parquet/scrooge/ParquetScroogeSchemeTest.java": 93,
                "parquet-thrift/src/main/java/parquet/thrift/BufferedProtocolReadToWrite.java": 21,
                "parquet-thrift/src/main/java/parquet/thrift/SkippableException.java": 32,
                "parquet-thrift/src/test/java/parquet/thrift/TestProtocolReadToWrite.java": 4
            },
            "is_test": true,
            "is_fix": false
        },
        "2c5e07f02fd8edbfcabfab5813e486f9a192ba6b": {
            "datetime": "2013-09-27T17:22:15-07:00",
            "summary": "Add support to AvroWriteSupport for writing out records with maps containing Utf8-type keys.",
            "message": "Add support to AvroWriteSupport for writing out records with maps containing Utf8-type keys.\n",
            "diff": {
                "parquet-avro/src/main/java/parquet/avro/AvroWriteSupport.java": 6,
                "parquet-avro/src/test/java/parquet/avro/TestReadWrite.java": 28
            },
            "is_test": true,
            "is_fix": false
        },
        "3778e45fcc084f0559ea1d43deb36cf4c6a1527b": {
            "datetime": "2013-09-29T10:41:15-07:00",
            "summary": "Pulling in clean modifications for adding ColumnPredicate functions.",
            "message": "Pulling in clean modifications for adding ColumnPredicate functions.\n",
            "diff": {
                "parquet-column/src/main/java/parquet/filter/ColumnPredicates.java": 59,
                "parquet-column/src/test/java/parquet/io/TestFiltered.java": 73
            },
            "is_test": true,
            "is_fix": false
        },
        "a2895bfe6ea0f3289739d63d3715b775108a607c": {
            "datetime": "2013-09-30T13:48:52-07:00",
            "summary": "Remove print statement.",
            "message": "Remove print statement.\n",
            "diff": {
                "parquet-avro/src/main/java/parquet/avro/AvroIndexedRecordConverter.java": 1
            },
            "is_test": false,
            "is_fix": false
        },
        "6ec199d4333a5aea8db5777c3d35da36a922f93c": {
            "datetime": "2013-10-01T14:00:34-05:00",
            "summary": "Disable the time read counter check in DeprecatedInputFormatTest.",
            "message": "Disable the time read counter check in DeprecatedInputFormatTest.\n\nThis mirrors the commit 6dfd97551fc1b8606704dcf656b185b34ceffcd4\nwhich disabled the check in TestInputOutputFormat.\n",
            "diff": {
                "parquet-hadoop/src/test/java/parquet/hadoop/DeprecatedInputFormatTest.java": 2
            },
            "is_test": true,
            "is_fix": false
        },
        "7802a9ab00a81853cbc95e04a46cc2eb721046e2": {
            "datetime": "2013-10-01T14:04:04-05:00",
            "summary": "Update ParquetReader to take Configuration as a constructor argument.",
            "message": "Update ParquetReader to take Configuration as a constructor argument.\n\nThis enables schema projection for both AvroParquetReader and\nThriftParquetReader by allowing configuration of\nAVRO_REQUESTED_PROJECTION, THRIFT_COLUMN_FILTER_KEY, and\nPARQUET_READ_SCHEMA.\n",
            "diff": {
                "parquet-avro/src/main/java/parquet/avro/AvroParquetReader.java": 12,
                "parquet-avro/src/test/java/parquet/avro/TestSpecificReadWrite.java": 47,
                "parquet-hadoop/src/main/java/parquet/hadoop/ParquetReader.java": 23,
                "parquet-thrift/src/main/java/parquet/thrift/ThriftParquetReader.java": 21
            },
            "is_test": true,
            "is_fix": false
        },
        "bb52d33b3ebcd2c4df30b790c82db17879c97e63": {
            "datetime": "2013-10-01T13:22:39-07:00",
            "summary": "Merge pull request #179 from fnothaft/master",
            "message": "Merge pull request #179 from fnothaft/master\n\nAdded Or/Not logical filters for column predicates",
            "diff": {
                "parquet-column/src/main/java/parquet/filter/NotRecordFilter.java": 55,
                "parquet-column/src/main/java/parquet/filter/OrRecordFilter.java": 59,
                "parquet-column/src/test/java/parquet/io/TestFiltered.java": 38
            },
            "is_test": true,
            "is_fix": false
        },
        "a146ebb1885f11a47c613d2be9001a545e659829": {
            "datetime": "2013-10-01T13:52:05-07:00",
            "summary": "Merge pull request #183 from wesleypeck/fix_timeread",
            "message": "Merge pull request #183 from wesleypeck/fix_timeread\n\nDisable the time read counter check in DeprecatedInputFormatTest.",
            "diff": {
                "parquet-hadoop/src/test/java/parquet/hadoop/DeprecatedInputFormatTest.java": 2
            },
            "is_test": true,
            "is_fix": false
        },
        "e20c490b6949bf1451c6da79472691d8b72a625c": {
            "datetime": "2013-10-01T13:53:56-07:00",
            "summary": "Merge pull request #184 from wesleypeck/parquet_reader_projection",
            "message": "Merge pull request #184 from wesleypeck/parquet_reader_projection\n\nUpdate ParquetReader to take Configuration as a constructor argument.",
            "diff": {
                "parquet-avro/src/main/java/parquet/avro/AvroParquetReader.java": 12,
                "parquet-avro/src/test/java/parquet/avro/TestSpecificReadWrite.java": 47,
                "parquet-hadoop/src/main/java/parquet/hadoop/ParquetReader.java": 23,
                "parquet-thrift/src/main/java/parquet/thrift/ThriftParquetReader.java": 21
            },
            "is_test": true,
            "is_fix": false
        },
        "753473cdc63a4105e0f74cd8b747a1a705710dff": {
            "datetime": "2013-10-01T14:07:33-07:00",
            "summary": "Change syntax for fixed_len_byte_array to placing length parameter after type name rather after field name.",
            "message": "Change syntax for fixed_len_byte_array to placing length parameter after type name rather after field name.\n",
            "diff": {
                "parquet-avro/src/test/java/parquet/avro/TestAvroSchemaConverter.java": 2,
                "parquet-column/src/main/java/parquet/schema/MessageTypeParser.java": 9,
                "parquet-column/src/main/java/parquet/schema/PrimitiveType.java": 5,
                "parquet-pig/src/test/java/parquet/pig/TestPigSchemaConverter.java": 4
            },
            "is_test": true,
            "is_fix": false
        },
        "9aad6416a4c7448727bcb71db739d7a1bc8a392f": {
            "datetime": "2013-10-01T14:42:44-07:00",
            "summary": "Move reflection checks for specific Avro Fixed type into FieldFixedConverter constructor.",
            "message": "Move reflection checks for specific Avro Fixed type into FieldFixedConverter constructor.\n",
            "diff": {
                "parquet-avro/src/main/java/parquet/avro/AvroIndexedRecordConverter.java": 21
            },
            "is_test": false,
            "is_fix": false
        },
        "a8d99d9be812e17e86cfad2a13966c754ce7c287": {
            "datetime": "2013-10-01T14:50:34-07:00",
            "summary": "add an assertion to check the output created by reading with ParquetTBaseScheme",
            "message": "add an assertion to check the output created by reading with ParquetTBaseScheme\n",
            "diff": {
                "parquet-cascading/src/test/java/parquet/cascading/TestParquetTBaseScheme.java": 5
            },
            "is_test": true,
            "is_fix": false
        },
        "2ffde6adbd5588d98838e3fd12ca8c4dcab3e367": {
            "datetime": "2013-10-01T16:55:01-07:00",
            "summary": "Merge pull request #172 from colinmarc/cascading-tbase-write-support",
            "message": "Merge pull request #172 from colinmarc/cascading-tbase-write-support\n\nAdd sink support for parquet.cascading.ParquetTBaseScheme",
            "diff": {
                "parquet-cascading/src/main/java/parquet/cascading/ParquetTBaseScheme.java": 43,
                "parquet-cascading/src/main/java/parquet/cascading/ParquetValueScheme.java": 16,
                "parquet-cascading/src/test/java/parquet/cascading/TestParquetTBaseScheme.java": 181,
                "parquet-hadoop/src/main/java/parquet/hadoop/ParquetOutputFormat.java": 187,
                "parquet-hadoop/src/main/java/parquet/hadoop/mapred/DeprecatedParquetOutputFormat.java": 130,
                "parquet-hadoop/src/test/java/parquet/hadoop/DeprecatedOutputFormatTest.java": 106
            },
            "is_test": true,
            "is_fix": false
        },
        "d24f4a7add1855675a3c2d19f7c9ab435ccfb028": {
            "datetime": "2013-10-02T14:17:42-07:00",
            "summary": "fix",
            "message": "fix\n",
            "diff": {
                "parquet-scrooge/src/main/java/parquet/scrooge/ScroogeSchemaConverter.java": 23,
                "parquet-scrooge/src/test/java/parquet/scrooge/ScroogeSchemaConverterTest.java": 12
            },
            "is_test": true,
            "is_fix": false
        },
        "4e6863aaeb765f62322ed79bb7e82c930cb6e364": {
            "datetime": "2013-10-02T14:18:52-07:00",
            "summary": "add checker",
            "message": "add checker\n",
            "diff": {
                "parquet-thrift/src/main/java/parquet/thrift/struct/CompatibilityChecker.java": 7
            },
            "is_test": false,
            "is_fix": false
        },
        "6d9d2b334db9db4896599f07e9a545961422db5f": {
            "datetime": "2013-10-02T14:19:25-07:00",
            "summary": "add test",
            "message": "add test\n",
            "diff": {
                "parquet-thrift/src/test/java/parquet/thrift/struct/CompatibilityCheckerTest.java": 28
            },
            "is_test": true,
            "is_fix": false
        },
        "f325418daa9ebb103eda6a08e8f16522267f56a7": {
            "datetime": "2013-10-02T15:15:51-07:00",
            "summary": "generate_json",
            "message": "generate_json\n",
            "diff": {
                "parquet-thrift/src/main/java/parquet/thrift/struct/CompatibilityChecker.java": 3,
                "parquet-thrift/src/main/java/parquet/thrift/struct/CompatibilityRunner.java": 35,
                "parquet-thrift/src/test/java/parquet/thrift/struct/CompatibilityCheckerTest.java": 1
            },
            "is_test": true,
            "is_fix": false
        },
        "5bd87b1c579017ebd76382335bf258f51598bae8": {
            "datetime": "2013-10-02T15:37:48-07:00",
            "summary": "check compatible",
            "message": "check compatible\n",
            "diff": {
                "parquet-thrift/src/main/java/parquet/thrift/struct/CompatibilityChecker.java": 12,
                "parquet-thrift/src/main/java/parquet/thrift/struct/CompatibilityRunner.java": 32
            },
            "is_test": false,
            "is_fix": false
        },
        "8856e45178a8ed73a7f7ac1aab5fe45e367bf4be": {
            "datetime": "2013-10-02T15:39:19-07:00",
            "summary": "todos",
            "message": "todos\n",
            "diff": {
                "parquet-thrift/src/main/java/parquet/thrift/struct/CompatibilityChecker.java": 1
            },
            "is_test": false,
            "is_fix": false
        },
        "bd311f54b0c7b043a4164413e35d014e3cc41683": {
            "datetime": "2013-10-02T15:52:17-07:00",
            "summary": "fix_test",
            "message": "fix_test\n",
            "diff": {
                "parquet-thrift/src/main/java/parquet/thrift/struct/CompatibilityChecker.java": 92,
                "parquet-thrift/src/test/java/parquet/thrift/struct/CompatibilityCheckerTest.java": 2
            },
            "is_test": true,
            "is_fix": false
        },
        "001e3deef9c2f3f8e6f257b3e497da2934e6b1bf": {
            "datetime": "2013-10-02T16:04:29-07:00",
            "summary": "map checker",
            "message": "map checker\n",
            "diff": {
                "parquet-thrift/src/main/java/parquet/thrift/struct/CompatibilityChecker.java": 48
            },
            "is_test": false,
            "is_fix": false
        },
        "5bf612787838361fa2922d07aaa6833a4ee595a3": {
            "datetime": "2013-10-02T16:07:09-07:00",
            "summary": "SetChecker",
            "message": "SetChecker\n",
            "diff": {
                "parquet-thrift/src/main/java/parquet/thrift/struct/CompatibilityChecker.java": 8
            },
            "is_test": false,
            "is_fix": false
        },
        "5427f4434ee24062c83f35fe154b071491a322be": {
            "datetime": "2013-10-02T16:08:12-07:00",
            "summary": "list checker",
            "message": "list checker\n",
            "diff": {
                "parquet-thrift/src/main/java/parquet/thrift/struct/CompatibilityChecker.java": 5
            },
            "is_test": false,
            "is_fix": false
        },
        "2fb1f7d79693fea18933092c8993be60b476f265": {
            "datetime": "2013-10-02T16:09:59-07:00",
            "summary": "accept visitor",
            "message": "accept visitor\n",
            "diff": {
                "parquet-thrift/src/main/java/parquet/thrift/struct/CompatibilityChecker.java": 16
            },
            "is_test": false,
            "is_fix": false
        },
        "64b2f7268878cc19d246383f62900c8c2a275e27": {
            "datetime": "2013-10-02T16:10:46-07:00",
            "summary": "fix",
            "message": "fix\n",
            "diff": {
                "parquet-thrift/src/main/java/parquet/thrift/struct/CompatibilityChecker.java": 1
            },
            "is_test": false,
            "is_fix": false
        },
        "0d39e1ce31a0a0d6e94032bcd4f07ef2fae2fd48": {
            "datetime": "2013-10-02T16:38:17-07:00",
            "summary": "add compatibility report",
            "message": "add compatibility report\n",
            "diff": {
                "parquet-thrift/src/main/java/parquet/thrift/struct/CompatibilityChecker.java": 60,
                "parquet-thrift/src/test/java/parquet/thrift/struct/CompatibilityCheckerTest.java": 23
            },
            "is_test": true,
            "is_fix": false
        },
        "6f0f23627674edcef5cd4d816dbe2816a5ce0edf": {
            "datetime": "2013-10-02T16:41:24-07:00",
            "summary": "fix tests",
            "message": "fix tests\n",
            "diff": {
                "parquet-thrift/src/main/java/parquet/thrift/struct/CompatibilityChecker.java": 2,
                "parquet-thrift/src/test/java/parquet/thrift/struct/CompatibilityCheckerTest.java": 6
            },
            "is_test": true,
            "is_fix": false
        },
        "2b62da3e29716295d87a31bbc497a9a8217e4fc2": {
            "datetime": "2013-10-02T17:03:58-07:00",
            "summary": "requirement check",
            "message": "requirement check\n",
            "diff": {
                "parquet-thrift/src/main/java/parquet/thrift/struct/CompatibilityChecker.java": 117,
                "parquet-thrift/src/test/java/parquet/thrift/struct/CompatibilityCheckerTest.java": 32
            },
            "is_test": true,
            "is_fix": false
        },
        "2731c0fe26ebae217f8616d4e1cedf9e3b765d78": {
            "datetime": "2013-10-02T17:11:39-07:00",
            "summary": "refactor tests",
            "message": "refactor tests\n",
            "diff": {
                "parquet-thrift/src/main/java/parquet/thrift/struct/CompatibilityChecker.java": 4,
                "parquet-thrift/src/test/java/parquet/thrift/struct/CompatibilityCheckerTest.java": 44
            },
            "is_test": true,
            "is_fix": false
        },
        "2ed9b5037a1a4b9e5ad704d9d0b5c783b9882ec1": {
            "datetime": "2013-10-02T17:53:55-07:00",
            "summary": "fail when required field is added",
            "message": "fail when required field is added\n",
            "diff": {
                "parquet-thrift/src/main/java/parquet/thrift/struct/CompatibilityChecker.java": 26,
                "parquet-thrift/src/test/java/parquet/thrift/struct/CompatibilityCheckerTest.java": 20
            },
            "is_test": true,
            "is_fix": false
        },
        "fdb07254ca5ab8698653a7adb9ea2a74e2b09c06": {
            "datetime": "2013-10-02T18:09:29-07:00",
            "summary": "add tests for list set map",
            "message": "add tests for list set map\n",
            "diff": {
                "parquet-thrift/src/main/java/parquet/thrift/struct/CompatibilityChecker.java": 2,
                "parquet-thrift/src/test/java/parquet/thrift/struct/CompatibilityCheckerTest.java": 71
            },
            "is_test": true,
            "is_fix": false
        },
        "e3292ed203d2e5a1b7aa4643a3c628cc76745e3f": {
            "datetime": "2013-10-03T10:41:27-07:00",
            "summary": "Merge branch 'master' of github.com:Parquet/parquet-mr into pig_BUNDLE",
            "message": "Merge branch 'master' of github.com:Parquet/parquet-mr into pig_BUNDLE\n\nConflicts:\n\tparquet-hive/pom.xml\n",
            "diff": {
                "parquet-avro/src/main/java/parquet/avro/AvroParquetReader.java": 12,
                "parquet-avro/src/main/java/parquet/avro/AvroWriteSupport.java": 74,
                "parquet-avro/src/test/java/parquet/avro/TestReadWrite.java": 65,
                "parquet-avro/src/test/java/parquet/avro/TestSpecificReadWrite.java": 47,
                "parquet-cascading/src/main/java/parquet/cascading/ParquetTBaseScheme.java": 43,
                "parquet-cascading/src/main/java/parquet/cascading/ParquetValueScheme.java": 16,
                "parquet-cascading/src/test/java/parquet/cascading/TestParquetTBaseScheme.java": 181,
                "parquet-column/src/main/java/parquet/filter/NotRecordFilter.java": 55,
                "parquet-column/src/main/java/parquet/filter/OrRecordFilter.java": 59,
                "parquet-column/src/main/java/parquet/io/RecordReaderImplementation.java": 87,
                "parquet-column/src/test/java/parquet/io/TestFiltered.java": 38,
                "parquet-hadoop/src/main/java/parquet/hadoop/InternalParquetRecordWriter.java": 7,
                "parquet-hadoop/src/main/java/parquet/hadoop/ParquetOutputFormat.java": 187,
                "parquet-hadoop/src/main/java/parquet/hadoop/ParquetReader.java": 23,
                "parquet-hadoop/src/main/java/parquet/hadoop/mapred/DeprecatedParquetOutputFormat.java": 130,
                "parquet-hadoop/src/test/java/parquet/hadoop/DeprecatedInputFormatTest.java": 2,
                "parquet-hadoop/src/test/java/parquet/hadoop/DeprecatedOutputFormatTest.java": 106,
                "parquet-pig/src/main/java/parquet/pig/ParquetLoader.java": 58,
                "parquet-pig/src/main/java/parquet/pig/PigSchemaConverter.java": 2,
                "parquet-pig/src/test/java/parquet/pig/TestParquetLoader.java": 66,
                "parquet-scrooge/src/test/java/parquet/scrooge/ParquetScroogeSchemeTest.java": 93,
                "parquet-thrift/src/main/java/parquet/thrift/ThriftParquetReader.java": 21
            },
            "is_test": true,
            "is_fix": false
        },
        "ff4d13a771565d307a803098fe0c7e9a5b91e820": {
            "datetime": "2013-10-03T10:47:54-07:00",
            "summary": "add null check",
            "message": "add null check\n",
            "diff": {
                "parquet-column/src/main/java/parquet/column/values/dictionary/DictionaryValuesWriter.java": 2
            },
            "is_test": false,
            "is_fix": false
        },
        "5adf79f33884b3564360c0cf431160e86984c712": {
            "datetime": "2013-10-03T10:50:15-07:00",
            "summary": "Merge pull request #180 from davidzchen/fix_avro_utf8_map_keys",
            "message": "Merge pull request #180 from davidzchen/fix_avro_utf8_map_keys\n\nSupport writing Avro records with maps with Utf8 keys",
            "diff": {
                "parquet-avro/src/main/java/parquet/avro/AvroWriteSupport.java": 6,
                "parquet-avro/src/test/java/parquet/avro/TestReadWrite.java": 28
            },
            "is_test": true,
            "is_fix": false
        },
        "7247538c6bb70f608eb408e02f196211f65bef5b": {
            "datetime": "2013-10-03T10:55:16-07:00",
            "summary": "compatibility runner print more detailed info",
            "message": "compatibility runner print more detailed info\n",
            "diff": {
                "parquet-thrift/src/main/java/parquet/thrift/struct/CompatibilityChecker.java": 4,
                "parquet-thrift/src/main/java/parquet/thrift/struct/CompatibilityRunner.java": 8
            },
            "is_test": false,
            "is_fix": false
        },
        "b3b0bbb67490d9a2a15c5307fec60c831e94de60": {
            "datetime": "2013-10-03T11:05:50-07:00",
            "summary": "fix indent",
            "message": "fix indent\n",
            "diff": {
                "parquet-column/src/main/java/parquet/column/values/dictionary/DictionaryValuesWriter.java": 3
            },
            "is_test": false,
            "is_fix": false
        },
        "7c6ba3e752bcda02a13a1f85d904e583ae936655": {
            "datetime": "2013-10-03T11:46:54-07:00",
            "summary": "Merge changes from master.",
            "message": "Merge changes from master.\n",
            "diff": {
                "parquet-avro/src/main/java/parquet/avro/AvroParquetReader.java": 12,
                "parquet-avro/src/main/java/parquet/avro/AvroWriteSupport.java": 6,
                "parquet-avro/src/test/java/parquet/avro/TestReadWrite.java": 28,
                "parquet-avro/src/test/java/parquet/avro/TestSpecificReadWrite.java": 49,
                "parquet-cascading/src/main/java/parquet/cascading/ParquetTBaseScheme.java": 43,
                "parquet-cascading/src/main/java/parquet/cascading/ParquetValueScheme.java": 16,
                "parquet-cascading/src/test/java/parquet/cascading/TestParquetTBaseScheme.java": 181,
                "parquet-column/src/main/java/parquet/filter/NotRecordFilter.java": 55,
                "parquet-column/src/main/java/parquet/filter/OrRecordFilter.java": 59,
                "parquet-column/src/test/java/parquet/io/TestFiltered.java": 38,
                "parquet-hadoop/src/main/java/parquet/hadoop/ParquetOutputFormat.java": 187,
                "parquet-hadoop/src/main/java/parquet/hadoop/ParquetReader.java": 23,
                "parquet-hadoop/src/main/java/parquet/hadoop/mapred/DeprecatedParquetOutputFormat.java": 130,
                "parquet-hadoop/src/test/java/parquet/hadoop/DeprecatedInputFormatTest.java": 2,
                "parquet-hadoop/src/test/java/parquet/hadoop/DeprecatedOutputFormatTest.java": 106,
                "parquet-thrift/src/main/java/parquet/thrift/ThriftParquetReader.java": 21
            },
            "is_test": true,
            "is_fix": false
        },
        "989e9dc13556213acf92758caaa7093679b4d52d": {
            "datetime": "2013-10-03T11:57:59-07:00",
            "summary": "Plumb OriginalType through to ConvertedType in file in ParquetMetadataConverter.",
            "message": "Plumb OriginalType through to ConvertedType in file in ParquetMetadataConverter.\n",
            "diff": {
                "parquet-hadoop/src/main/java/parquet/format/converter/ParquetMetadataConverter.java": 58
            },
            "is_test": false,
            "is_fix": false
        },
        "e40dcfb9ffaab5735097a5cc71a6ec79aa36e46f": {
            "datetime": "2013-10-03T13:35:59-07:00",
            "summary": "Merge pull request #181 from davidzchen/fixed_len_byte_array",
            "message": "Merge pull request #181 from davidzchen/fixed_len_byte_array\n\nFIXED_LEN_BYTE_ARRAY support",
            "diff": {
                "parquet-avro/src/main/java/parquet/avro/AvroIndexedRecordConverter.java": 33,
                "parquet-avro/src/main/java/parquet/avro/AvroParquetReader.java": 2,
                "parquet-avro/src/main/java/parquet/avro/AvroSchemaConverter.java": 19,
                "parquet-avro/src/test/java/parquet/avro/TestAvroSchemaConverter.java": 27,
                "parquet-avro/src/test/java/parquet/avro/TestReadWrite.java": 25,
                "parquet-avro/src/test/java/parquet/avro/TestSpecificInputOutputFormat.java": 22,
                "parquet-avro/src/test/java/parquet/avro/TestSpecificReadWrite.java": 61,
                "parquet-column/src/main/java/parquet/column/ColumnDescriptor.java": 26,
                "parquet-column/src/main/java/parquet/column/ColumnWriter.java": 1,
                "parquet-column/src/main/java/parquet/column/Encoding.java": 3,
                "parquet-column/src/main/java/parquet/column/impl/ColumnReaderImpl.java": 22,
                "parquet-column/src/main/java/parquet/column/impl/ColumnWriterImpl.java": 23,
                "parquet-column/src/main/java/parquet/column/values/ValuesReader.java": 1,
                "parquet-column/src/main/java/parquet/column/values/plain/FixedLenByteArrayPlainValuesReader.java": 67,
                "parquet-column/src/main/java/parquet/column/values/plain/FixedLenByteArrayPlainValuesWriter.java": 95,
                "parquet-column/src/main/java/parquet/example/data/simple/convert/SimplePrimitiveConverter.java": 9,
                "parquet-column/src/main/java/parquet/io/PrimitiveColumnIO.java": 9,
                "parquet-column/src/main/java/parquet/schema/MessageType.java": 13,
                "parquet-column/src/main/java/parquet/schema/MessageTypeParser.java": 19,
                "parquet-column/src/main/java/parquet/schema/PrimitiveType.java": 68,
                "parquet-column/src/test/java/parquet/io/ExpectationValidatingRecordConsumer.java": 1,
                "parquet-column/src/test/java/parquet/io/TestColumnIO.java": 39,
                "parquet-hadoop/src/main/java/parquet/format/converter/ParquetMetadataConverter.java": 30,
                "parquet-hive/src/test/java/parquet/hive/TestHiveSchemaConverter.java": 5,
                "parquet-pig/src/main/java/parquet/pig/PigSchemaConverter.java": 199,
                "parquet-pig/src/test/java/parquet/pig/TestParquetLoader.java": 5,
                "parquet-pig/src/test/java/parquet/pig/TestPigSchemaConverter.java": 27
            },
            "is_test": true,
            "is_fix": false
        },
        "5303197f00a46d5d6bd133e330dbbc6af0897126": {
            "datetime": "2013-10-03T13:59:08-07:00",
            "summary": "Merge changes from master.",
            "message": "Merge changes from master.\n",
            "diff": {
                "parquet-avro/src/main/java/parquet/avro/AvroIndexedRecordConverter.java": 33,
                "parquet-avro/src/main/java/parquet/avro/AvroParquetReader.java": 2,
                "parquet-avro/src/main/java/parquet/avro/AvroSchemaConverter.java": 19,
                "parquet-avro/src/test/java/parquet/avro/TestAvroSchemaConverter.java": 27,
                "parquet-avro/src/test/java/parquet/avro/TestReadWrite.java": 25,
                "parquet-avro/src/test/java/parquet/avro/TestSpecificInputOutputFormat.java": 22,
                "parquet-avro/src/test/java/parquet/avro/TestSpecificReadWrite.java": 61,
                "parquet-column/src/main/java/parquet/column/ColumnDescriptor.java": 26,
                "parquet-column/src/main/java/parquet/column/ColumnWriter.java": 1,
                "parquet-column/src/main/java/parquet/column/Encoding.java": 3,
                "parquet-column/src/main/java/parquet/column/impl/ColumnReaderImpl.java": 22,
                "parquet-column/src/main/java/parquet/column/impl/ColumnWriterImpl.java": 23,
                "parquet-column/src/main/java/parquet/column/values/ValuesReader.java": 1,
                "parquet-column/src/main/java/parquet/column/values/plain/FixedLenByteArrayPlainValuesReader.java": 67,
                "parquet-column/src/main/java/parquet/column/values/plain/FixedLenByteArrayPlainValuesWriter.java": 95,
                "parquet-column/src/main/java/parquet/example/data/simple/convert/SimplePrimitiveConverter.java": 9,
                "parquet-column/src/main/java/parquet/io/PrimitiveColumnIO.java": 9,
                "parquet-column/src/main/java/parquet/schema/MessageType.java": 13,
                "parquet-column/src/main/java/parquet/schema/MessageTypeParser.java": 19,
                "parquet-column/src/main/java/parquet/schema/PrimitiveType.java": 68,
                "parquet-column/src/test/java/parquet/io/ExpectationValidatingRecordConsumer.java": 1,
                "parquet-column/src/test/java/parquet/io/TestColumnIO.java": 39,
                "parquet-hadoop/src/main/java/parquet/format/converter/ParquetMetadataConverter.java": 33,
                "parquet-hive/src/test/java/parquet/hive/TestHiveSchemaConverter.java": 5,
                "parquet-pig/src/main/java/parquet/pig/PigSchemaConverter.java": 199,
                "parquet-pig/src/test/java/parquet/pig/TestParquetLoader.java": 5,
                "parquet-pig/src/test/java/parquet/pig/TestPigSchemaConverter.java": 27
            },
            "is_test": true,
            "is_fix": false
        },
        "cfd63fd61cb8b05a61b65fbd8021f19d6d19a493": {
            "datetime": "2013-10-03T18:23:50-07:00",
            "summary": "Fixed issue with test case that was causing runtime error. Was trying to call getInteger on long...",
            "message": "Fixed issue with test case that was causing runtime error. Was trying to call getInteger on long...\n",
            "diff": {
                "parquet-column/src/test/java/parquet/io/TestFiltered.java": 12
            },
            "is_test": true,
            "is_fix": false
        },
        "c6a4d18717ca05c9cc4f169a3c2a3098f0e0a967": {
            "datetime": "2013-10-03T18:28:29-07:00",
            "summary": "Added unit tests for predicates. Got predicates compiling, and passing on tests.",
            "message": "Added unit tests for predicates. Got predicates compiling, and passing on tests.\n",
            "diff": {
                "parquet-column/src/main/java/parquet/filter/ColumnPredicates.java": 32,
                "parquet-column/src/main/java/parquet/filter/NotRecordFilter.java": 4,
                "parquet-column/src/main/java/parquet/filter/OrRecordFilter.java": 2,
                "parquet-column/src/test/java/parquet/io/TestFiltered.java": 38
            },
            "is_test": true,
            "is_fix": false
        },
        "eb35ba800654231865401503f971d19183257f30": {
            "datetime": "2013-10-03T18:28:29-07:00",
            "summary": "Added functionality to allow users to implement functions to be used as predicates.",
            "message": "Added functionality to allow users to implement functions to be used as predicates.\n",
            "diff": {
                "parquet-column/src/main/java/parquet/filter/ColumnPredicates.java": 59
            },
            "is_test": false,
            "is_fix": false
        },
        "308c1b41960e5c430a60b02db74ad4f03567b855": {
            "datetime": "2013-10-03T18:28:29-07:00",
            "summary": "Added two boolean options for record filters.",
            "message": "Added two boolean options for record filters.\n",
            "diff": {
                "parquet-column/src/main/java/parquet/filter/NotRecordFilter.java": 55,
                "parquet-column/src/main/java/parquet/filter/OrRecordFilter.java": 59
            },
            "is_test": false,
            "is_fix": false
        },
        "8be341f6bc9e7a64ceee86a570bc84c0e6787d76": {
            "datetime": "2013-10-03T18:28:30-07:00",
            "summary": "Removing predicate functions to prepare for pushing or/not filters. Limits number of features pushed.",
            "message": "Removing predicate functions to prepare for pushing or/not filters. Limits number of features pushed.\n",
            "diff": {
                "parquet-column/src/main/java/parquet/filter/ColumnPredicates.java": 59
            },
            "is_test": false,
            "is_fix": false
        },
        "3edf60dcbd90968d3b94f7f2669b485da649ee0d": {
            "datetime": "2013-10-03T18:40:54-07:00",
            "summary": "Manually merged in conflicts in TestFiltered.java.",
            "message": "Manually merged in conflicts in TestFiltered.java.\n",
            "diff": {
                "parquet-column/src/main/java/parquet/filter/ColumnPredicates.java": 59,
                "parquet-column/src/test/java/parquet/io/TestFiltered.java": 71
            },
            "is_test": true,
            "is_fix": false
        },
        "0a36e35cf6c52a9e79fdfbbb8584a8adc3a17b6c": {
            "datetime": "2013-10-07T12:17:20-05:00",
            "summary": "Fixes #189: NPE in DictionaryValuesWriter.",
            "message": "Fixes #189: NPE in DictionaryValuesWriter.\n",
            "diff": {
                "parquet-column/src/main/java/parquet/column/values/dictionary/DictionaryValuesWriter.java": 2
            },
            "is_test": false,
            "is_fix": false
        },
        "714335de4ba559645408adf692a6a90aceb8adae": {
            "datetime": "2013-10-07T13:06:51-07:00",
            "summary": "compare json",
            "message": "compare json\n",
            "diff": {
                "parquet-thrift/src/main/java/parquet/thrift/struct/CompatibilityRunner.java": 32,
                "parquet-thrift/src/test/java/parquet/thrift/struct/CompatibilityCheckerTest.java": 25
            },
            "is_test": true,
            "is_fix": false
        },
        "0d2597965153c164eed55129596a06344ec74705": {
            "datetime": "2013-10-07T13:16:51-07:00",
            "summary": "Merge branch 'master' of https://github.com/Parquet/parquet-mr into compatibility_checker",
            "message": "Merge branch 'master' of https://github.com/Parquet/parquet-mr into compatibility_checker\n",
            "diff": {
                "parquet-avro/src/main/java/parquet/avro/AvroIndexedRecordConverter.java": 33,
                "parquet-avro/src/main/java/parquet/avro/AvroParquetReader.java": 2,
                "parquet-avro/src/main/java/parquet/avro/AvroSchemaConverter.java": 19,
                "parquet-avro/src/main/java/parquet/avro/AvroWriteSupport.java": 6,
                "parquet-avro/src/test/java/parquet/avro/TestAvroSchemaConverter.java": 27,
                "parquet-avro/src/test/java/parquet/avro/TestReadWrite.java": 51,
                "parquet-avro/src/test/java/parquet/avro/TestSpecificInputOutputFormat.java": 22,
                "parquet-avro/src/test/java/parquet/avro/TestSpecificReadWrite.java": 61,
                "parquet-column/src/main/java/parquet/column/ColumnDescriptor.java": 26,
                "parquet-column/src/main/java/parquet/column/ColumnWriter.java": 1,
                "parquet-column/src/main/java/parquet/column/Encoding.java": 3,
                "parquet-column/src/main/java/parquet/column/impl/ColumnReaderImpl.java": 22,
                "parquet-column/src/main/java/parquet/column/impl/ColumnWriterImpl.java": 23,
                "parquet-column/src/main/java/parquet/column/values/ValuesReader.java": 1,
                "parquet-column/src/main/java/parquet/column/values/plain/FixedLenByteArrayPlainValuesReader.java": 67,
                "parquet-column/src/main/java/parquet/column/values/plain/FixedLenByteArrayPlainValuesWriter.java": 95,
                "parquet-column/src/main/java/parquet/example/data/simple/convert/SimplePrimitiveConverter.java": 9,
                "parquet-column/src/main/java/parquet/io/PrimitiveColumnIO.java": 9,
                "parquet-column/src/main/java/parquet/schema/MessageType.java": 13,
                "parquet-column/src/main/java/parquet/schema/MessageTypeParser.java": 19,
                "parquet-column/src/main/java/parquet/schema/PrimitiveType.java": 68,
                "parquet-column/src/test/java/parquet/io/ExpectationValidatingRecordConsumer.java": 1,
                "parquet-column/src/test/java/parquet/io/TestColumnIO.java": 39,
                "parquet-hadoop/src/main/java/parquet/format/converter/ParquetMetadataConverter.java": 30,
                "parquet-hive/src/test/java/parquet/hive/TestHiveSchemaConverter.java": 5,
                "parquet-pig/src/main/java/parquet/pig/PigSchemaConverter.java": 199,
                "parquet-pig/src/test/java/parquet/pig/TestParquetLoader.java": 5,
                "parquet-pig/src/test/java/parquet/pig/TestPigSchemaConverter.java": 27
            },
            "is_test": true,
            "is_fix": false
        },
        "820fb75108627f93af56e4d62b47730a12af27ba": {
            "datetime": "2013-10-07T13:19:39-07:00",
            "summary": "remove unused test",
            "message": "remove unused test\n",
            "diff": {
                "parquet-thrift/src/main/java/parquet/thrift/struct/CompatibilityChecker.java": 3,
                "parquet-thrift/src/test/java/parquet/thrift/struct/CompatibilityCheckerTest.java": 19
            },
            "is_test": true,
            "is_fix": false
        },
        "dc425e481b3a833d83317258b7d00f04a9afe3b0": {
            "datetime": "2013-10-07T14:27:11-07:00",
            "summary": "show field name when they are not compatible",
            "message": "show field name when they are not compatible\n",
            "diff": {
                "parquet-thrift/src/main/java/parquet/thrift/struct/CompatibilityChecker.java": 2
            },
            "is_test": false,
            "is_fix": false
        },
        "5cad37ba0be6dcbc6ede9ee31007022a9e0ff362": {
            "datetime": "2013-10-08T10:17:51-07:00",
            "summary": "remove unused command from CompatibilityRunner, add comment for rules used in compatibility checking, add license header",
            "message": "remove unused command from CompatibilityRunner, add comment for rules used in compatibility checking, add license header\n",
            "diff": {
                "parquet-thrift/src/main/java/parquet/thrift/struct/CompatibilityChecker.java": 57,
                "parquet-thrift/src/main/java/parquet/thrift/struct/CompatibilityRunner.java": 101,
                "parquet-thrift/src/test/java/parquet/thrift/struct/CompatibilityCheckerTest.java": 40
            },
            "is_test": true,
            "is_fix": false
        },
        "82052b89de0816b36713f281b2861549e7562e74": {
            "datetime": "2013-10-08T11:13:48-07:00",
            "summary": "Merge pull request #191 from Parquet/compatibility_checker",
            "message": "Merge pull request #191 from Parquet/compatibility_checker\n\nThrift compatibility checker",
            "diff": {
                "parquet-thrift/src/main/java/parquet/thrift/struct/CompatibilityChecker.java": 220,
                "parquet-thrift/src/main/java/parquet/thrift/struct/CompatibilityRunner.java": 96,
                "parquet-thrift/src/test/java/parquet/thrift/struct/CompatibilityCheckerTest.java": 117
            },
            "is_test": true,
            "is_fix": false
        },
        "09bcb1bf6d860cbbc0153861597a4e0df6a24ff4": {
            "datetime": "2013-10-08T11:37:21-07:00",
            "summary": "fix comment",
            "message": "fix comment\n",
            "diff": {
                "parquet-thrift/src/main/java/parquet/thrift/struct/CompatibilityRunner.java": 2
            },
            "is_test": false,
            "is_fix": false
        },
        "eff1e5f915f4714c32fae1ff7d0e9e540344d803": {
            "datetime": "2013-10-08T11:41:36-07:00",
            "summary": "Merge pull request #192 from Parquet/comment_fix",
            "message": "Merge pull request #192 from Parquet/comment_fix\n\nfix comment",
            "diff": {
                "parquet-thrift/src/main/java/parquet/thrift/struct/CompatibilityRunner.java": 2
            },
            "is_test": false,
            "is_fix": false
        },
        "04ad0c4461f75fec456e2e61fa4b68d960a088b5": {
            "datetime": "2013-10-08T15:16:56-07:00",
            "summary": "Merge pull request #190 from wesleypeck/fix_dvw_npe",
            "message": "Merge pull request #190 from wesleypeck/fix_dvw_npe\n\nFixes #189: NPE in DictionaryValuesWriter.",
            "diff": {
                "parquet-column/src/main/java/parquet/column/values/dictionary/DictionaryValuesWriter.java": 2
            },
            "is_test": false,
            "is_fix": false
        },
        "20201427905781726ebf946a0840b19cddf88bbb": {
            "datetime": "2013-10-09T10:28:47-07:00",
            "summary": "refactor serde to remove some unecessary boxing and include dictionary awareness",
            "message": "refactor serde to remove some unecessary boxing and include dictionary awareness\n",
            "diff": {
                "parquet-column/src/main/java/parquet/io/api/Binary.java": 20,
                "parquet-hive/src/main/java/parquet/hive/convert/DataWritableGroupConverter.java": 4,
                "parquet-hive/src/main/java/parquet/hive/convert/ETypeConverter.java": 226,
                "parquet-hive/src/main/java/parquet/hive/serde/ArrayWritableObjectInspector.java": 30,
                "parquet-hive/src/main/java/parquet/hive/serde/ParquetHiveArrayInspector.java": 4,
                "parquet-hive/src/main/java/parquet/hive/serde/ParquetHiveSerDe.java": 3,
                "parquet-hive/src/main/java/parquet/hive/writable/BinaryWritable.java": 66,
                "parquet-hive/src/main/java/parquet/hive/write/DataWritableWriter.java": 2,
                "parquet-hive/src/test/java/parquet/hive/TestParquetSerDe.java": 7,
                "parquet-hive/src/test/java/parquet/hive/UtilitiesTestMethods.java": 22
            },
            "is_test": true,
            "is_fix": false
        },
        "50bd1448a7b9df63c0fe6dbe0a60e97989fc2daa": {
            "datetime": "2013-10-10T07:56:55-07:00",
            "summary": "Merge pull request #194 from Parquet/hive_perf",
            "message": "Merge pull request #194 from Parquet/hive_perf\n\nrefactor serde to remove some unecessary boxing and include dictionary awareness",
            "diff": {
                "parquet-column/src/main/java/parquet/io/api/Binary.java": 20,
                "parquet-hive/src/main/java/parquet/hive/convert/DataWritableGroupConverter.java": 4,
                "parquet-hive/src/main/java/parquet/hive/convert/ETypeConverter.java": 226,
                "parquet-hive/src/main/java/parquet/hive/serde/ArrayWritableObjectInspector.java": 30,
                "parquet-hive/src/main/java/parquet/hive/serde/ParquetHiveArrayInspector.java": 4,
                "parquet-hive/src/main/java/parquet/hive/serde/ParquetHiveSerDe.java": 3,
                "parquet-hive/src/main/java/parquet/hive/writable/BinaryWritable.java": 66,
                "parquet-hive/src/main/java/parquet/hive/write/DataWritableWriter.java": 2,
                "parquet-hive/src/test/java/parquet/hive/TestParquetSerDe.java": 7,
                "parquet-hive/src/test/java/parquet/hive/UtilitiesTestMethods.java": 22
            },
            "is_test": true,
            "is_fix": false
        },
        "763dfde36cd67c9f539cbd0db54b4dcdf3d15b77": {
            "datetime": "2013-10-10T16:59:14+02:00",
            "summary": "Fix for columns list missing from the conf",
            "message": "Fix for columns list missing from the conf\n\n- In this case, assume that the schema and requested schema\ncorrespond to the file schema\n",
            "diff": {
                "parquet-hive/src/main/java/parquet/hive/read/DataWritableReadSupport.java": 62
            },
            "is_test": false,
            "is_fix": false
        },
        "422dfe05d5583318cc5116a688fc7e5676cafd89": {
            "datetime": "2013-10-11T09:07:28-07:00",
            "summary": "Updated files to add applyFunctionToBinary, and add specific interfaces for primitive types.",
            "message": "Updated files to add applyFunctionToBinary, and add specific interfaces for primitive types.\n",
            "diff": {
                "parquet-column/src/main/java/parquet/filter/ColumnPredicates.java": 54,
                "parquet-column/src/test/java/parquet/io/TestFiltered.java": 5
            },
            "is_test": true,
            "is_fix": false
        },
        "82f882f14c5815a809428e950c4c94a04221e9e3": {
            "datetime": "2013-10-12T08:29:01-07:00",
            "summary": "Merge branch 'master' into plumb_original_type",
            "message": "Merge branch 'master' into plumb_original_type\n",
            "diff": {
                "parquet-column/src/main/java/parquet/column/values/dictionary/DictionaryValuesWriter.java": 2,
                "parquet-column/src/main/java/parquet/io/api/Binary.java": 20,
                "parquet-hive/src/main/java/parquet/hive/convert/DataWritableGroupConverter.java": 4,
                "parquet-hive/src/main/java/parquet/hive/convert/ETypeConverter.java": 226,
                "parquet-hive/src/main/java/parquet/hive/serde/ArrayWritableObjectInspector.java": 30,
                "parquet-hive/src/main/java/parquet/hive/serde/ParquetHiveArrayInspector.java": 4,
                "parquet-hive/src/main/java/parquet/hive/serde/ParquetHiveSerDe.java": 3,
                "parquet-hive/src/main/java/parquet/hive/writable/BinaryWritable.java": 66,
                "parquet-hive/src/main/java/parquet/hive/write/DataWritableWriter.java": 2,
                "parquet-hive/src/test/java/parquet/hive/TestParquetSerDe.java": 7,
                "parquet-hive/src/test/java/parquet/hive/UtilitiesTestMethods.java": 22,
                "parquet-thrift/src/main/java/parquet/thrift/struct/CompatibilityChecker.java": 220,
                "parquet-thrift/src/main/java/parquet/thrift/struct/CompatibilityRunner.java": 96,
                "parquet-thrift/src/test/java/parquet/thrift/struct/CompatibilityCheckerTest.java": 117
            },
            "is_test": true,
            "is_fix": false
        },
        "10f266aef9faf78fb8cd07f488674c67f3bbf3a3": {
            "datetime": "2013-10-14T08:53:43-07:00",
            "summary": "Cleaning method signature for binary case.",
            "message": "Cleaning method signature for binary case.\n",
            "diff": {
                "parquet-column/src/main/java/parquet/filter/ColumnPredicates.java": 4
            },
            "is_test": false,
            "is_fix": false
        },
        "73c86295a70e6ce98ed22ab213aafb105365e475": {
            "datetime": "2013-10-14T15:43:22-07:00",
            "summary": "Misunderstood previous comment. Fixed binary predicate.",
            "message": "Misunderstood previous comment. Fixed binary predicate.\n",
            "diff": {
                "parquet-column/src/main/java/parquet/filter/ColumnPredicates.java": 3
            },
            "is_test": false,
            "is_fix": false
        },
        "cf0ee72e21df7afa17edea77d6894d40b73da4de": {
            "datetime": "2013-10-14T16:05:35-07:00",
            "summary": "Merge pull request #188 from fnothaft/master",
            "message": "Merge pull request #188 from fnothaft/master\n\nAdded ability to define arbitrary predicate functions",
            "diff": {
                "parquet-column/src/main/java/parquet/filter/ColumnPredicates.java": 90,
                "parquet-column/src/test/java/parquet/io/TestFiltered.java": 72
            },
            "is_test": true,
            "is_fix": false
        },
        "256a3a1eb328e6f02eebc82eb37d91ad69e475d5": {
            "datetime": "2013-10-15T16:20:15-07:00",
            "summary": "Fix issue 193: RLE decoder reading past the end of the stream.",
            "message": "Fix issue 193: RLE decoder reading past the end of the stream.\n\nIf literal groups are not padded to groups of 8, the decoder reads past the end.\n",
            "diff": {
                "parquet-column/src/main/java/parquet/column/values/dictionary/DictionaryValuesReader.java": 4,
                "parquet-column/src/main/java/parquet/column/values/rle/RunLengthBitPackingHybridDecoder.java": 21,
                "parquet-column/src/main/java/parquet/column/values/rle/RunLengthBitPackingHybridValuesReader.java": 2,
                "parquet-column/src/test/java/parquet/column/values/rle/RunLengthBitPackingHybridIntegrationTest.java": 5,
                "parquet-column/src/test/java/parquet/column/values/rle/TestRunLengthBitPackingHybridEncoder.java": 2
            },
            "is_test": true,
            "is_fix": false
        },
        "d4eeeccfa3f85155b0ca2892a30cba990c22a25e": {
            "datetime": "2013-10-16T16:27:01-07:00",
            "summary": "Merge pull request #197 from Parquet/issue-193",
            "message": "Merge pull request #197 from Parquet/issue-193\n\nFix issue 193: RLE decoder reading past the end of the stream.",
            "diff": {
                "parquet-column/src/main/java/parquet/column/values/dictionary/DictionaryValuesReader.java": 4,
                "parquet-column/src/main/java/parquet/column/values/rle/RunLengthBitPackingHybridDecoder.java": 21,
                "parquet-column/src/main/java/parquet/column/values/rle/RunLengthBitPackingHybridValuesReader.java": 2,
                "parquet-column/src/test/java/parquet/column/values/rle/RunLengthBitPackingHybridIntegrationTest.java": 5,
                "parquet-column/src/test/java/parquet/column/values/rle/TestRunLengthBitPackingHybridEncoder.java": 2
            },
            "is_test": true,
            "is_fix": false
        },
        "22cf7fe9d8ef12e33b3fa43fae86fc7e8680271f": {
            "datetime": "2013-10-18T17:39:12+02:00",
            "summary": "Inspect keys only for a few types in parquet hive maps",
            "message": "Inspect keys only for a few types in parquet hive maps\n",
            "diff": {
                "parquet-hive/src/main/java/parquet/hive/serde/ArrayWritableObjectInspector.java": 7,
                "parquet-hive/src/main/java/parquet/hive/serde/DeepParquetHiveMapInspector.java": 77,
                "parquet-hive/src/main/java/parquet/hive/serde/ParquetHiveMapInspector.java": 82,
                "parquet-hive/src/main/java/parquet/hive/serde/StandardParquetHiveMapInspector.java": 60
            },
            "is_test": false,
            "is_fix": false
        },
        "90645004606cfbb33c79a385bc594854edce138e": {
            "datetime": "2013-10-18T17:39:12+02:00",
            "summary": "Add some javadoc to clarify",
            "message": "Add some javadoc to clarify\n",
            "diff": {
                "parquet-hive/src/main/java/parquet/hive/serde/ArrayWritableObjectInspector.java": 4,
                "parquet-hive/src/main/java/parquet/hive/serde/ParquetHiveArrayInspector.java": 6,
                "parquet-hive/src/main/java/parquet/hive/serde/ParquetHiveMapInspector.java": 6,
                "parquet-hive/src/main/java/parquet/hive/serde/primitive/ParquetByteInspector.java": 1,
                "parquet-hive/src/main/java/parquet/hive/serde/primitive/ParquetPrimitiveInspectorFactory.java": 2,
                "parquet-hive/src/main/java/parquet/hive/serde/primitive/ParquetShortInspector.java": 1,
                "parquet-hive/src/main/java/parquet/hive/serde/primitive/ParquetStringInspector.java": 4
            },
            "is_test": false,
            "is_fix": false
        },
        "4bdaec06595f35d4b7bb4c1baf35ca0d16b25619": {
            "datetime": "2013-10-18T17:39:12+02:00",
            "summary": "Fix #177: Inspect key when accessing maps",
            "message": "Fix #177: Inspect key when accessing maps\n",
            "diff": {
                "parquet-hive/src/main/java/parquet/hive/serde/ParquetHiveMapInspector.java": 23
            },
            "is_test": false,
            "is_fix": false
        },
        "c5f68c51cb72503e7f9c483e009d94ed66aac335": {
            "datetime": "2013-10-18T17:39:12+02:00",
            "summary": "Extract primitive inspectors and instantiate them only once",
            "message": "Extract primitive inspectors and instantiate them only once\n",
            "diff": {
                "parquet-hive/src/main/java/parquet/hive/serde/ArrayWritableObjectInspector.java": 130,
                "parquet-hive/src/main/java/parquet/hive/serde/primitive/ParquetByteInspector.java": 58,
                "parquet-hive/src/main/java/parquet/hive/serde/primitive/ParquetPrimitiveInspectorFactory.java": 30,
                "parquet-hive/src/main/java/parquet/hive/serde/primitive/ParquetShortInspector.java": 58,
                "parquet-hive/src/main/java/parquet/hive/serde/primitive/ParquetStringInspector.java": 98
            },
            "is_test": false,
            "is_fix": false
        },
        "d9e5f0bc2d7482062db72bddcb3eeefda05b2143": {
            "datetime": "2013-10-18T17:39:12+02:00",
            "summary": "Implement correctly Settable inspectors",
            "message": "Implement correctly Settable inspectors\n\n- Array inspector implements correctly set and resize\n- Map inspector implements settable\n- Root (and struct) inspector implements settable\n- Inspectors will now inspect basic objects because Hive sometimes\ndoes that\n",
            "diff": {
                "parquet-hive/src/main/java/parquet/hive/serde/ArrayWritableObjectInspector.java": 101,
                "parquet-hive/src/main/java/parquet/hive/serde/ParquetHiveArrayInspector.java": 83,
                "parquet-hive/src/main/java/parquet/hive/serde/ParquetHiveMapInspector.java": 108
            },
            "is_test": false,
            "is_fix": false
        },
        "c9146a6eaa854499a5d099edf48d0b961d3a60a3": {
            "datetime": "2013-10-18T09:53:34-07:00",
            "summary": "Merge pull request #196 from Parquet/hive_fixes",
            "message": "Merge pull request #196 from Parquet/hive_fixes\n\nFixes to the Hive SerDe",
            "diff": {
                "parquet-hive/src/main/java/parquet/hive/read/DataWritableReadSupport.java": 62,
                "parquet-hive/src/main/java/parquet/hive/serde/AbstractParquetMapInspector.java": 153,
                "parquet-hive/src/main/java/parquet/hive/serde/ArrayWritableObjectInspector.java": 216,
                "parquet-hive/src/main/java/parquet/hive/serde/DeepParquetHiveMapInspector.java": 77,
                "parquet-hive/src/main/java/parquet/hive/serde/ParquetHiveArrayInspector.java": 89,
                "parquet-hive/src/main/java/parquet/hive/serde/ParquetHiveMapInspector.java": 102,
                "parquet-hive/src/main/java/parquet/hive/serde/StandardParquetHiveMapInspector.java": 60,
                "parquet-hive/src/main/java/parquet/hive/serde/primitive/ParquetByteInspector.java": 59,
                "parquet-hive/src/main/java/parquet/hive/serde/primitive/ParquetPrimitiveInspectorFactory.java": 32,
                "parquet-hive/src/main/java/parquet/hive/serde/primitive/ParquetShortInspector.java": 59,
                "parquet-hive/src/main/java/parquet/hive/serde/primitive/ParquetStringInspector.java": 100
            },
            "is_test": false,
            "is_fix": false
        },
        "a991eff830f3c384396c1eba152462c6e6d1e6c6": {
            "datetime": "2013-10-18T10:19:40-07:00",
            "summary": "Merge branch 'master' into dictionary_changes",
            "message": "Merge branch 'master' into dictionary_changes\n\nConflicts:\n\tparquet-column/src/main/java/parquet/column/impl/ColumnWriterImpl.java\n\tparquet-column/src/main/java/parquet/column/values/dictionary/DictionaryValuesWriter.java\n\tparquet-column/src/test/java/parquet/io/TestColumnIO.java\n\tparquet-column/src/test/java/parquet/io/TestFiltered.java\n\tparquet-hadoop/src/main/java/parquet/hadoop/InternalParquetRecordWriter.java\n\tparquet-hadoop/src/main/java/parquet/hadoop/ParquetOutputFormat.java\n",
            "diff": {
                "parquet-avro/src/main/java/parquet/avro/AvroIndexedRecordConverter.java": 33,
                "parquet-avro/src/main/java/parquet/avro/AvroParquetReader.java": 14,
                "parquet-avro/src/main/java/parquet/avro/AvroSchemaConverter.java": 19,
                "parquet-avro/src/main/java/parquet/avro/AvroWriteSupport.java": 76,
                "parquet-avro/src/test/java/parquet/avro/TestAvroSchemaConverter.java": 27,
                "parquet-avro/src/test/java/parquet/avro/TestReadWrite.java": 114,
                "parquet-avro/src/test/java/parquet/avro/TestSpecificInputOutputFormat.java": 22,
                "parquet-avro/src/test/java/parquet/avro/TestSpecificReadWrite.java": 106,
                "parquet-cascading/src/main/java/parquet/cascading/ParquetTBaseScheme.java": 43,
                "parquet-cascading/src/main/java/parquet/cascading/ParquetValueScheme.java": 16,
                "parquet-cascading/src/test/java/parquet/cascading/TestParquetTBaseScheme.java": 196,
                "parquet-cascading/src/test/java/parquet/cascading/TestParquetTupleScheme.java": 15,
                "parquet-column/src/main/java/parquet/column/ColumnDescriptor.java": 26,
                "parquet-column/src/main/java/parquet/column/ColumnWriter.java": 1,
                "parquet-column/src/main/java/parquet/column/Encoding.java": 3,
                "parquet-column/src/main/java/parquet/column/impl/ColumnReaderImpl.java": 22,
                "parquet-column/src/main/java/parquet/column/impl/ColumnWriterImpl.java": 22,
                "parquet-column/src/main/java/parquet/column/values/ValuesReader.java": 1,
                "parquet-column/src/main/java/parquet/column/values/dictionary/DictionaryValuesReader.java": 4,
                "parquet-column/src/main/java/parquet/column/values/dictionary/PlainValuesDictionary.java": 3,
                "parquet-column/src/main/java/parquet/column/values/plain/FixedLenByteArrayPlainValuesReader.java": 67,
                "parquet-column/src/main/java/parquet/column/values/plain/FixedLenByteArrayPlainValuesWriter.java": 95,
                "parquet-column/src/main/java/parquet/column/values/rle/RunLengthBitPackingHybridDecoder.java": 21,
                "parquet-column/src/main/java/parquet/column/values/rle/RunLengthBitPackingHybridValuesReader.java": 2,
                "parquet-column/src/main/java/parquet/example/data/simple/convert/SimplePrimitiveConverter.java": 9,
                "parquet-column/src/main/java/parquet/filter/ColumnPredicates.java": 90,
                "parquet-column/src/main/java/parquet/filter/NotRecordFilter.java": 55,
                "parquet-column/src/main/java/parquet/filter/OrRecordFilter.java": 59,
                "parquet-column/src/main/java/parquet/io/PrimitiveColumnIO.java": 9,
                "parquet-column/src/main/java/parquet/io/RecordReaderImplementation.java": 87,
                "parquet-column/src/main/java/parquet/io/api/Binary.java": 20,
                "parquet-column/src/main/java/parquet/schema/ConversionPatterns.java": 71,
                "parquet-column/src/main/java/parquet/schema/GroupType.java": 66,
                "parquet-column/src/main/java/parquet/schema/IncompatibleSchemaModificationException.java": 46,
                "parquet-column/src/main/java/parquet/schema/MessageType.java": 20,
                "parquet-column/src/main/java/parquet/schema/MessageTypeParser.java": 19,
                "parquet-column/src/main/java/parquet/schema/PrimitiveType.java": 85,
                "parquet-column/src/main/java/parquet/schema/Type.java": 66,
                "parquet-column/src/test/java/parquet/column/values/rle/RunLengthBitPackingHybridIntegrationTest.java": 5,
                "parquet-column/src/test/java/parquet/column/values/rle/TestRunLengthBitPackingHybridEncoder.java": 2,
                "parquet-column/src/test/java/parquet/io/ExpectationValidatingRecordConsumer.java": 1,
                "parquet-column/src/test/java/parquet/io/TestColumnIO.java": 34,
                "parquet-column/src/test/java/parquet/io/TestFiltered.java": 110,
                "parquet-column/src/test/java/parquet/schema/TestMessageType.java": 88,
                "parquet-hadoop/src/main/java/parquet/format/converter/ParquetMetadataConverter.java": 30,
                "parquet-hadoop/src/main/java/parquet/hadoop/InternalParquetRecordReader.java": 5,
                "parquet-hadoop/src/main/java/parquet/hadoop/InternalParquetRecordWriter.java": 22,
                "parquet-hadoop/src/main/java/parquet/hadoop/ParquetFileReader.java": 49,
                "parquet-hadoop/src/main/java/parquet/hadoop/ParquetFileWriter.java": 97,
                "parquet-hadoop/src/main/java/parquet/hadoop/ParquetInputFormat.java": 52,
                "parquet-hadoop/src/main/java/parquet/hadoop/ParquetOutputFormat.java": 196,
                "parquet-hadoop/src/main/java/parquet/hadoop/ParquetReader.java": 97,
                "parquet-hadoop/src/main/java/parquet/hadoop/api/InitContext.java": 99,
                "parquet-hadoop/src/main/java/parquet/hadoop/api/ReadSupport.java": 19,
                "parquet-hadoop/src/main/java/parquet/hadoop/codec/NonBlockedCompressorStream.java": 15,
                "parquet-hadoop/src/main/java/parquet/hadoop/codec/NonBlockedDecompressorStream.java": 15,
                "parquet-hadoop/src/main/java/parquet/hadoop/mapred/DeprecatedParquetOutputFormat.java": 130,
                "parquet-hadoop/src/main/java/parquet/hadoop/metadata/FileMetaData.java": 13,
                "parquet-hadoop/src/main/java/parquet/hadoop/metadata/GlobalMetaData.java": 103,
                "parquet-hadoop/src/main/java/parquet/hadoop/util/counters/ICounter.java": 15,
                "parquet-hadoop/src/test/java/parquet/hadoop/DeprecatedInputFormatTest.java": 2,
                "parquet-hadoop/src/test/java/parquet/hadoop/DeprecatedOutputFormatTest.java": 106,
                "parquet-hadoop/src/test/java/parquet/hadoop/TestParquetFileWriter.java": 29,
                "parquet-hadoop/src/test/java/parquet/hadoop/example/GroupReadSupportTest.java": 15,
                "parquet-hive/src/main/java/parquet/hive/convert/DataWritableGroupConverter.java": 4,
                "parquet-hive/src/main/java/parquet/hive/convert/ETypeConverter.java": 226,
                "parquet-hive/src/main/java/parquet/hive/read/DataWritableReadSupport.java": 62,
                "parquet-hive/src/main/java/parquet/hive/serde/AbstractParquetMapInspector.java": 153,
                "parquet-hive/src/main/java/parquet/hive/serde/ArrayWritableObjectInspector.java": 232,
                "parquet-hive/src/main/java/parquet/hive/serde/DeepParquetHiveMapInspector.java": 77,
                "parquet-hive/src/main/java/parquet/hive/serde/ParquetHiveArrayInspector.java": 89,
                "parquet-hive/src/main/java/parquet/hive/serde/ParquetHiveMapInspector.java": 102,
                "parquet-hive/src/main/java/parquet/hive/serde/ParquetHiveSerDe.java": 3,
                "parquet-hive/src/main/java/parquet/hive/serde/StandardParquetHiveMapInspector.java": 60,
                "parquet-hive/src/main/java/parquet/hive/serde/primitive/ParquetByteInspector.java": 59,
                "parquet-hive/src/main/java/parquet/hive/serde/primitive/ParquetPrimitiveInspectorFactory.java": 32,
                "parquet-hive/src/main/java/parquet/hive/serde/primitive/ParquetShortInspector.java": 59,
                "parquet-hive/src/main/java/parquet/hive/serde/primitive/ParquetStringInspector.java": 100,
                "parquet-hive/src/main/java/parquet/hive/writable/BinaryWritable.java": 66,
                "parquet-hive/src/main/java/parquet/hive/write/DataWritableWriter.java": 2,
                "parquet-hive/src/test/java/parquet/hive/TestHiveSchemaConverter.java": 5,
                "parquet-hive/src/test/java/parquet/hive/TestParquetSerDe.java": 7,
                "parquet-hive/src/test/java/parquet/hive/UtilitiesTestMethods.java": 22,
                "parquet-pig/src/main/java/parquet/pig/ParquetLoader.java": 106,
                "parquet-pig/src/main/java/parquet/pig/PigMetaData.java": 45,
                "parquet-pig/src/main/java/parquet/pig/PigSchemaConverter.java": 244,
                "parquet-pig/src/main/java/parquet/pig/TupleReadSupport.java": 102,
                "parquet-pig/src/test/java/parquet/pig/TestParquetLoader.java": 83,
                "parquet-pig/src/test/java/parquet/pig/TestParquetStorer.java": 64,
                "parquet-pig/src/test/java/parquet/pig/TestPigSchemaConverter.java": 65,
                "parquet-pig/src/test/java/parquet/pig/TestTupleRecordConsumer.java": 14,
                "parquet-scrooge/src/test/java/parquet/scrooge/ParquetScroogeSchemeTest.java": 93,
                "parquet-thrift/src/main/java/parquet/hadoop/thrift/ThriftBytesWriteSupport.java": 2,
                "parquet-thrift/src/main/java/parquet/hadoop/thrift/ThriftReadSupport.java": 57,
                "parquet-thrift/src/main/java/parquet/thrift/BufferedProtocolReadToWrite.java": 40,
                "parquet-thrift/src/main/java/parquet/thrift/ParquetProtocol.java": 4,
                "parquet-thrift/src/main/java/parquet/thrift/SkippableException.java": 32,
                "parquet-thrift/src/main/java/parquet/thrift/ThriftMetaData.java": 59,
                "parquet-thrift/src/main/java/parquet/thrift/ThriftParquetReader.java": 21,
                "parquet-thrift/src/main/java/parquet/thrift/ThriftRecordConverter.java": 11,
                "parquet-thrift/src/main/java/parquet/thrift/ThriftSchemaConvertVisitor.java": 256,
                "parquet-thrift/src/main/java/parquet/thrift/ThriftSchemaConverter.java": 186,
                "parquet-thrift/src/main/java/parquet/thrift/projection/FieldProjectionFilter.java": 12,
                "parquet-thrift/src/main/java/parquet/thrift/projection/FieldsPath.java": 82,
                "parquet-thrift/src/main/java/parquet/thrift/projection/amend/DefaultEventsVisitor.java": 212,
                "parquet-thrift/src/main/java/parquet/thrift/projection/amend/DefaultProtocolEventsGenerator.java": 65,
                "parquet-thrift/src/main/java/parquet/thrift/projection/amend/ProtocolEventsAmender.java": 170,
                "parquet-thrift/src/main/java/parquet/thrift/projection/amend/ReadFieldBeginProtocol.java": 41,
                "parquet-thrift/src/main/java/parquet/thrift/struct/CompatibilityChecker.java": 220,
                "parquet-thrift/src/main/java/parquet/thrift/struct/CompatibilityRunner.java": 96,
                "parquet-thrift/src/test/java/parquet/hadoop/thrift/TestInputOutputFormat.java": 108,
                "parquet-thrift/src/test/java/parquet/hadoop/thrift/TestParquetToThriftReadProjection.java": 152,
                "parquet-thrift/src/test/java/parquet/thrift/TestProtocolReadToWrite.java": 30,
                "parquet-thrift/src/test/java/parquet/thrift/TestThriftSchemaConverter.java": 95,
                "parquet-thrift/src/test/java/parquet/thrift/struct/CompatibilityCheckerTest.java": 117
            },
            "is_test": true,
            "is_fix": false
        },
        "0a76cc29b703fc95949736910a5a63ce9c1c0814": {
            "datetime": "2013-10-18T10:36:52-07:00",
            "summary": "Fix #198: simplify TupleWriteSupport constructor",
            "message": "Fix #198: simplify TupleWriteSupport constructor\n",
            "diff": {
                "parquet-pig/src/main/java/parquet/pig/ParquetStorer.java": 4,
                "parquet-pig/src/main/java/parquet/pig/TupleWriteSupport.java": 22,
                "parquet-pig/src/test/java/parquet/pig/TestTupleRecordConsumer.java": 20,
                "parquet-pig/src/test/java/parquet/pig/TupleConsumerPerfTest.java": 2,
                "parquet-thrift/src/test/java/parquet/thrift/TestParquetWriteProtocol.java": 2
            },
            "is_test": true,
            "is_fix": false
        },
        "f52d35ba6c33efe824fc59dc1fa33d23bfec85bb": {
            "datetime": "2013-10-18T10:38:23-07:00",
            "summary": "Merge pull request #164 from Parquet/dictionary_changes",
            "message": "Merge pull request #164 from Parquet/dictionary_changes\n\nDictionary changes",
            "diff": {
                "parquet-column/src/main/java/parquet/column/impl/ColumnWriteStoreImpl.java": 6,
                "parquet-column/src/main/java/parquet/column/impl/ColumnWriterImpl.java": 34,
                "parquet-column/src/main/java/parquet/column/values/dictionary/DictionaryValuesWriter.java": 96,
                "parquet-column/src/test/java/parquet/column/mem/TestMemColumn.java": 12,
                "parquet-column/src/test/java/parquet/column/values/dictionary/TestDictionary.java": 443,
                "parquet-column/src/test/java/parquet/io/PerfTest.java": 2,
                "parquet-column/src/test/java/parquet/io/TestColumnIO.java": 25,
                "parquet-column/src/test/java/parquet/io/TestFiltered.java": 56,
                "parquet-hadoop/src/main/java/parquet/hadoop/InternalParquetRecordWriter.java": 38,
                "parquet-hadoop/src/main/java/parquet/hadoop/ParquetOutputFormat.java": 39,
                "parquet-hadoop/src/main/java/parquet/hadoop/ParquetRecordWriter.java": 17,
                "parquet-hadoop/src/main/java/parquet/hadoop/ParquetWriter.java": 43,
                "parquet-hive/src/test/java/parquet/hive/TestDeprecatedParquetInputFormat.java": 2,
                "parquet-pig/src/test/java/parquet/pig/GenerateIntTestFile.java": 2,
                "parquet-pig/src/test/java/parquet/pig/GenerateTPCH.java": 2,
                "parquet-pig/src/test/java/parquet/pig/TupleConsumerPerfTest.java": 2,
                "parquet-thrift/src/test/java/parquet/thrift/TestParquetReadProtocol.java": 2
            },
            "is_test": true,
            "is_fix": false
        },
        "5601394e85387a69f171884792ad683a39c7eec1": {
            "datetime": "2013-10-18T15:18:50-07:00",
            "summary": "make static field final",
            "message": "make static field final\n",
            "diff": {
                "parquet-pig/src/main/java/parquet/pig/TupleWriteSupport.java": 2
            },
            "is_test": false,
            "is_fix": false
        },
        "a905704ee5dcaed9d42af0598782e96172ab45c1": {
            "datetime": "2013-10-18T17:20:51-07:00",
            "summary": "Merge pull request #199 from Parquet/simplify_tuple_write",
            "message": "Merge pull request #199 from Parquet/simplify_tuple_write\n\nFix #198: simplify TupleWriteSupport constructor",
            "diff": {
                "parquet-pig/src/main/java/parquet/pig/ParquetStorer.java": 4,
                "parquet-pig/src/main/java/parquet/pig/TupleWriteSupport.java": 22,
                "parquet-pig/src/test/java/parquet/pig/TestTupleRecordConsumer.java": 20,
                "parquet-pig/src/test/java/parquet/pig/TupleConsumerPerfTest.java": 2,
                "parquet-thrift/src/test/java/parquet/thrift/TestParquetWriteProtocol.java": 2
            },
            "is_test": true,
            "is_fix": false
        },
        "a736c62888e59783efc68bb480de3b8cf61fedf8": {
            "datetime": "2013-10-18T17:55:13-07:00",
            "summary": "Merge branch 'master' into plumb_original_type",
            "message": "Merge branch 'master' into plumb_original_type\n",
            "diff": {
                "parquet-column/src/main/java/parquet/column/impl/ColumnWriteStoreImpl.java": 6,
                "parquet-column/src/main/java/parquet/column/impl/ColumnWriterImpl.java": 34,
                "parquet-column/src/main/java/parquet/column/values/dictionary/DictionaryValuesReader.java": 4,
                "parquet-column/src/main/java/parquet/column/values/dictionary/DictionaryValuesWriter.java": 96,
                "parquet-column/src/main/java/parquet/column/values/rle/RunLengthBitPackingHybridDecoder.java": 21,
                "parquet-column/src/main/java/parquet/column/values/rle/RunLengthBitPackingHybridValuesReader.java": 2,
                "parquet-column/src/main/java/parquet/filter/ColumnPredicates.java": 90,
                "parquet-column/src/test/java/parquet/column/mem/TestMemColumn.java": 12,
                "parquet-column/src/test/java/parquet/column/values/dictionary/TestDictionary.java": 443,
                "parquet-column/src/test/java/parquet/column/values/rle/RunLengthBitPackingHybridIntegrationTest.java": 5,
                "parquet-column/src/test/java/parquet/column/values/rle/TestRunLengthBitPackingHybridEncoder.java": 2,
                "parquet-column/src/test/java/parquet/io/PerfTest.java": 2,
                "parquet-column/src/test/java/parquet/io/TestColumnIO.java": 25,
                "parquet-column/src/test/java/parquet/io/TestFiltered.java": 112,
                "parquet-hadoop/src/main/java/parquet/hadoop/InternalParquetRecordWriter.java": 38,
                "parquet-hadoop/src/main/java/parquet/hadoop/ParquetOutputFormat.java": 39,
                "parquet-hadoop/src/main/java/parquet/hadoop/ParquetRecordWriter.java": 17,
                "parquet-hadoop/src/main/java/parquet/hadoop/ParquetWriter.java": 43,
                "parquet-hive/src/main/java/parquet/hive/read/DataWritableReadSupport.java": 62,
                "parquet-hive/src/main/java/parquet/hive/serde/AbstractParquetMapInspector.java": 153,
                "parquet-hive/src/main/java/parquet/hive/serde/ArrayWritableObjectInspector.java": 216,
                "parquet-hive/src/main/java/parquet/hive/serde/DeepParquetHiveMapInspector.java": 77,
                "parquet-hive/src/main/java/parquet/hive/serde/ParquetHiveArrayInspector.java": 89,
                "parquet-hive/src/main/java/parquet/hive/serde/ParquetHiveMapInspector.java": 102,
                "parquet-hive/src/main/java/parquet/hive/serde/StandardParquetHiveMapInspector.java": 60,
                "parquet-hive/src/main/java/parquet/hive/serde/primitive/ParquetByteInspector.java": 59,
                "parquet-hive/src/main/java/parquet/hive/serde/primitive/ParquetPrimitiveInspectorFactory.java": 32,
                "parquet-hive/src/main/java/parquet/hive/serde/primitive/ParquetShortInspector.java": 59,
                "parquet-hive/src/main/java/parquet/hive/serde/primitive/ParquetStringInspector.java": 100,
                "parquet-hive/src/test/java/parquet/hive/TestDeprecatedParquetInputFormat.java": 2,
                "parquet-pig/src/main/java/parquet/pig/ParquetStorer.java": 4,
                "parquet-pig/src/main/java/parquet/pig/TupleWriteSupport.java": 22,
                "parquet-pig/src/test/java/parquet/pig/GenerateIntTestFile.java": 2,
                "parquet-pig/src/test/java/parquet/pig/GenerateTPCH.java": 2,
                "parquet-pig/src/test/java/parquet/pig/TestTupleRecordConsumer.java": 20,
                "parquet-pig/src/test/java/parquet/pig/TupleConsumerPerfTest.java": 4,
                "parquet-thrift/src/test/java/parquet/thrift/TestParquetReadProtocol.java": 2,
                "parquet-thrift/src/test/java/parquet/thrift/TestParquetWriteProtocol.java": 2
            },
            "is_test": true,
            "is_fix": false
        },
        "943591829c87898788558ec323a38c6946b7eb6e": {
            "datetime": "2013-10-23T18:59:56+02:00",
            "summary": "Fix requested schema when recreating splits in hive",
            "message": "Fix requested schema when recreating splits in hive\n",
            "diff": {
                "parquet-hive/src/main/java/parquet/hive/DeprecatedParquetInputFormat.java": 2
            },
            "is_test": false,
            "is_fix": false
        },
        "005bc68b000ad37cff5c0f0400d4ef18fe8af80f": {
            "datetime": "2013-10-23T11:14:09-07:00",
            "summary": "add null check for EnumWriteProtocol",
            "message": "add null check for EnumWriteProtocol\n",
            "diff": {
                "parquet-thrift/src/main/java/parquet/thrift/ParquetWriteProtocol.java": 9
            },
            "is_test": false,
            "is_fix": false
        },
        "8edc893e60e584a03369b6ac71800232bc13f7d6": {
            "datetime": "2013-10-23T12:16:27-07:00",
            "summary": "Initial commit",
            "message": "Initial commit\n",
            "diff": {
                "dev/merge_parquet_pr.py": 393,
                "parquet-arrow/src/main/java/org/apache/parquet/arrow/schema/List3Levels.java": 77,
                "parquet-arrow/src/main/java/org/apache/parquet/arrow/schema/SchemaConverter.java": 705,
                "parquet-arrow/src/main/java/org/apache/parquet/arrow/schema/SchemaMapping.java": 201,
                "parquet-arrow/src/test/java/org/apache/parquet/arrow/schema/TestSchemaConverter.java": 530,
                "parquet-avro/src/main/java/org/apache/parquet/avro/AvroCompatRecordMaterializer.java": 46,
                "parquet-avro/src/main/java/org/apache/parquet/avro/AvroConverters.java": 333,
                "parquet-avro/src/main/java/org/apache/parquet/avro/AvroDataSupplier.java": 31,
                "parquet-avro/src/main/java/org/apache/parquet/avro/AvroIndexedRecordConverter.java": 535,
                "parquet-avro/src/main/java/org/apache/parquet/avro/AvroParquetInputFormat.java": 86,
                "parquet-avro/src/main/java/org/apache/parquet/avro/AvroParquetOutputFormat.java": 63,
                "parquet-avro/src/main/java/org/apache/parquet/avro/AvroParquetReader.java": 178,
                "parquet-avro/src/main/java/org/apache/parquet/avro/AvroParquetWriter.java": 193,
                "parquet-avro/src/main/java/org/apache/parquet/avro/AvroReadSupport.java": 180,
                "parquet-avro/src/main/java/org/apache/parquet/avro/AvroRecordConverter.java": 1093,
                "parquet-avro/src/main/java/org/apache/parquet/avro/AvroRecordMaterializer.java": 45,
                "parquet-avro/src/main/java/org/apache/parquet/avro/AvroSchemaConverter.java": 565,
                "parquet-avro/src/main/java/org/apache/parquet/avro/AvroWriteSupport.java": 711,
                "parquet-avro/src/main/java/org/apache/parquet/avro/GenericDataSupplier.java": 28,
                "parquet-avro/src/main/java/org/apache/parquet/avro/ParentValueContainer.java": 238,
                "parquet-avro/src/main/java/org/apache/parquet/avro/ReflectDataSupplier.java": 29,
                "parquet-avro/src/main/java/org/apache/parquet/avro/SpecificDataSupplier.java": 29,
                "parquet-avro/src/main/java/org/apache/parquet/avro/package-info.java": 174,
                "parquet-avro/src/test/java/org/apache/parquet/avro/AvroTestUtil.java": 136,
                "parquet-avro/src/test/java/org/apache/parquet/avro/TestArrayCompatibility.java": 1164,
                "parquet-avro/src/test/java/org/apache/parquet/avro/TestAvroDataSupplier.java": 43,
                "parquet-avro/src/test/java/org/apache/parquet/avro/TestAvroRecordConverter.java": 202,
                "parquet-avro/src/test/java/org/apache/parquet/avro/TestAvroSchemaConverter.java": 942,
                "parquet-avro/src/test/java/org/apache/parquet/avro/TestAvroWriteSupport.java": 61,
                "parquet-avro/src/test/java/org/apache/parquet/avro/TestBackwardCompatibility.java": 68,
                "parquet-avro/src/test/java/org/apache/parquet/avro/TestByteStreamSplitE2E.java": 114,
                "parquet-avro/src/test/java/org/apache/parquet/avro/TestCircularReferences.java": 387,
                "parquet-avro/src/test/java/org/apache/parquet/avro/TestGenericLogicalTypes.java": 296,
                "parquet-avro/src/test/java/org/apache/parquet/avro/TestInputOutputFormat.java": 145,
                "parquet-avro/src/test/java/org/apache/parquet/avro/TestReadWrite.java": 900,
                "parquet-avro/src/test/java/org/apache/parquet/avro/TestReadWriteOldListBehavior.java": 584,
                "parquet-avro/src/test/java/org/apache/parquet/avro/TestReflectInputOutputFormat.java": 496,
                "parquet-avro/src/test/java/org/apache/parquet/avro/TestReflectLogicalTypes.java": 999,
                "parquet-avro/src/test/java/org/apache/parquet/avro/TestReflectReadWrite.java": 240,
                "parquet-avro/src/test/java/org/apache/parquet/avro/TestSpecificInputOutputFormat.java": 287,
                "parquet-avro/src/test/java/org/apache/parquet/avro/TestSpecificReadWrite.java": 360,
                "parquet-avro/src/test/java/org/apache/parquet/avro/TestStringBehavior.java": 330,
                "parquet-benchmarks/src/main/java/org/apache/parquet/benchmarks/BenchmarkConstants.java": 42,
                "parquet-benchmarks/src/main/java/org/apache/parquet/benchmarks/BenchmarkFiles.java": 64,
                "parquet-benchmarks/src/main/java/org/apache/parquet/benchmarks/BenchmarkUtils.java": 46,
                "parquet-benchmarks/src/main/java/org/apache/parquet/benchmarks/DataGenerator.java": 137,
                "parquet-benchmarks/src/main/java/org/apache/parquet/benchmarks/FilteringBenchmarks.java": 430,
                "parquet-benchmarks/src/main/java/org/apache/parquet/benchmarks/NestedNullWritingBenchmarks.java": 156,
                "parquet-benchmarks/src/main/java/org/apache/parquet/benchmarks/PageChecksumDataGenerator.java": 106,
                "parquet-benchmarks/src/main/java/org/apache/parquet/benchmarks/PageChecksumReadBenchmarks.java": 196,
                "parquet-benchmarks/src/main/java/org/apache/parquet/benchmarks/PageChecksumWriteBenchmarks.java": 178,
                "parquet-benchmarks/src/main/java/org/apache/parquet/benchmarks/ReadBenchmarks.java": 131,
                "parquet-benchmarks/src/main/java/org/apache/parquet/benchmarks/WriteBenchmarks.java": 168,
                "parquet-cli/src/main/java/org/apache/parquet/cli/BaseCommand.java": 428,
                "parquet-cli/src/main/java/org/apache/parquet/cli/Command.java": 40,
                "parquet-cli/src/main/java/org/apache/parquet/cli/HadoopFileSystemURLStreamHandler.java": 79,
                "parquet-cli/src/main/java/org/apache/parquet/cli/Help.java": 153,
                "parquet-cli/src/main/java/org/apache/parquet/cli/Main.java": 196,
                "parquet-cli/src/main/java/org/apache/parquet/cli/Util.java": 272,
                "parquet-cli/src/main/java/org/apache/parquet/cli/commands/CSVSchemaCommand.java": 131,
                "parquet-cli/src/main/java/org/apache/parquet/cli/commands/CatCommand.java": 106,
                "parquet-cli/src/main/java/org/apache/parquet/cli/commands/CheckParquet251Command.java": 352,
                "parquet-cli/src/main/java/org/apache/parquet/cli/commands/ColumnMaskingCommand.java": 115,
                "parquet-cli/src/main/java/org/apache/parquet/cli/commands/ColumnSizeCommand.java": 137,
                "parquet-cli/src/main/java/org/apache/parquet/cli/commands/ConvertCSVCommand.java": 204,
                "parquet-cli/src/main/java/org/apache/parquet/cli/commands/ConvertCommand.java": 165,
                "parquet-cli/src/main/java/org/apache/parquet/cli/commands/ParquetMetadataCommand.java": 183,
                "parquet-cli/src/main/java/org/apache/parquet/cli/commands/PruneColumnsCommand.java": 82,
                "parquet-cli/src/main/java/org/apache/parquet/cli/commands/RewriteCommand.java": 131,
                "parquet-cli/src/main/java/org/apache/parquet/cli/commands/ScanCommand.java": 91,
                "parquet-cli/src/main/java/org/apache/parquet/cli/commands/SchemaCommand.java": 132,
                "parquet-cli/src/main/java/org/apache/parquet/cli/commands/ShowBloomFilterCommand.java": 133,
                "parquet-cli/src/main/java/org/apache/parquet/cli/commands/ShowColumnIndexCommand.java": 157,
                "parquet-cli/src/main/java/org/apache/parquet/cli/commands/ShowDictionaryCommand.java": 139,
                "parquet-cli/src/main/java/org/apache/parquet/cli/commands/ShowFooterCommand.java": 101,
                "parquet-cli/src/main/java/org/apache/parquet/cli/commands/ShowPagesCommand.java": 234,
                "parquet-cli/src/main/java/org/apache/parquet/cli/commands/ToAvroCommand.java": 134,
                "parquet-cli/src/main/java/org/apache/parquet/cli/commands/TransCompressionCommand.java": 101,
                "parquet-cli/src/main/java/org/apache/parquet/cli/csv/AvroCSV.java": 258,
                "parquet-cli/src/main/java/org/apache/parquet/cli/csv/AvroCSVReader.java": 121,
                "parquet-cli/src/main/java/org/apache/parquet/cli/csv/CSVProperties.java": 120,
                "parquet-cli/src/main/java/org/apache/parquet/cli/csv/RecordBuilder.java": 200,
                "parquet-cli/src/main/java/org/apache/parquet/cli/json/AvroJson.java": 631,
                "parquet-cli/src/main/java/org/apache/parquet/cli/json/AvroJsonReader.java": 77,
                "parquet-cli/src/main/java/org/apache/parquet/cli/rawpages/RawPagesReader.java": 92,
                "parquet-cli/src/main/java/org/apache/parquet/cli/util/Codecs.java": 52,
                "parquet-cli/src/main/java/org/apache/parquet/cli/util/Expressions.java": 395,
                "parquet-cli/src/main/java/org/apache/parquet/cli/util/Formats.java": 47,
                "parquet-cli/src/main/java/org/apache/parquet/cli/util/GetClassLoader.java": 39,
                "parquet-cli/src/main/java/org/apache/parquet/cli/util/RawUtils.java": 85,
                "parquet-cli/src/main/java/org/apache/parquet/cli/util/RecordException.java": 55,
                "parquet-cli/src/main/java/org/apache/parquet/cli/util/RuntimeIOException.java": 31,
                "parquet-cli/src/main/java/org/apache/parquet/cli/util/Schemas.java": 501,
                "parquet-cli/src/main/java/org/apache/parquet/cli/util/SeekableFSDataInputStream.java": 76,
                "parquet-cli/src/test/java/org/apache/parquet/cli/BaseCommandTest.java": 100,
                "parquet-cli/src/test/java/org/apache/parquet/cli/MainTest.java": 34,
                "parquet-cli/src/test/java/org/apache/parquet/cli/commands/AvroFileTest.java": 53,
                "parquet-cli/src/test/java/org/apache/parquet/cli/commands/CSVFileTest.java": 51,
                "parquet-cli/src/test/java/org/apache/parquet/cli/commands/CSVSchemaCommandTest.java": 39,
                "parquet-cli/src/test/java/org/apache/parquet/cli/commands/CatCommandTest.java": 38,
                "parquet-cli/src/test/java/org/apache/parquet/cli/commands/CheckParquet251CommandTest.java": 38,
                "parquet-cli/src/test/java/org/apache/parquet/cli/commands/ColumnSizeCommandTest.java": 91,
                "parquet-cli/src/test/java/org/apache/parquet/cli/commands/ConvertCSVCommandTest.java": 41,
                "parquet-cli/src/test/java/org/apache/parquet/cli/commands/ConvertCommandTest.java": 41,
                "parquet-cli/src/test/java/org/apache/parquet/cli/commands/FileTest.java": 58,
                "parquet-cli/src/test/java/org/apache/parquet/cli/commands/ParquetFileTest.java": 117,
                "parquet-cli/src/test/java/org/apache/parquet/cli/commands/ParquetMetadataCommandTest.java": 38,
                "parquet-cli/src/test/java/org/apache/parquet/cli/commands/RewriteCommandTest.java": 41,
                "parquet-cli/src/test/java/org/apache/parquet/cli/commands/ScanCommandTest.java": 38,
                "parquet-cli/src/test/java/org/apache/parquet/cli/commands/SchemaCommandTest.java": 68,
                "parquet-cli/src/test/java/org/apache/parquet/cli/commands/ShowBloomFilterCommandTest.java": 41,
                "parquet-cli/src/test/java/org/apache/parquet/cli/commands/ShowColumnIndexTest.java": 38,
                "parquet-cli/src/test/java/org/apache/parquet/cli/commands/ShowDictionaryCommandTest.java": 50,
                "parquet-cli/src/test/java/org/apache/parquet/cli/commands/ShowFooterCommandTest.java": 43,
                "parquet-cli/src/test/java/org/apache/parquet/cli/commands/ShowPagesCommandTest.java": 38,
                "parquet-cli/src/test/java/org/apache/parquet/cli/commands/ToAvroCommandTest.java": 113,
                "parquet-cli/src/test/java/org/apache/parquet/cli/commands/TransCompressionCommandTest.java": 45,
                "parquet-column/src/main/java/org/apache/parquet/CorruptDeltaByteArrays.java": 97,
                "parquet-column/src/main/java/org/apache/parquet/CorruptStatistics.java": 116,
                "parquet-column/src/main/java/org/apache/parquet/column/ColumnDescriptor.java": 156,
                "parquet-column/src/main/java/org/apache/parquet/column/ColumnProperty.java": 137,
                "parquet-column/src/main/java/org/apache/parquet/column/ColumnReadStore.java": 32,
                "parquet-column/src/main/java/org/apache/parquet/column/ColumnReader.java": 117,
                "parquet-column/src/main/java/org/apache/parquet/column/ColumnWriteStore.java": 75,
                "parquet-column/src/main/java/org/apache/parquet/column/ColumnWriter.java": 96,
                "parquet-column/src/main/java/org/apache/parquet/column/Dictionary.java": 63,
                "parquet-column/src/main/java/org/apache/parquet/column/Encoding.java": 309,
                "parquet-column/src/main/java/org/apache/parquet/column/EncodingStats.java": 157,
                "parquet-column/src/main/java/org/apache/parquet/column/MinMax.java": 56,
                "parquet-column/src/main/java/org/apache/parquet/column/ParquetProperties.java": 589,
                "parquet-column/src/main/java/org/apache/parquet/column/UnknownColumnException.java": 40,
                "parquet-column/src/main/java/org/apache/parquet/column/UnknownColumnTypeException.java": 41,
                "parquet-column/src/main/java/org/apache/parquet/column/ValuesType.java": 26,
                "parquet-column/src/main/java/org/apache/parquet/column/impl/ColumnReadStoreImpl.java": 104,
                "parquet-column/src/main/java/org/apache/parquet/column/impl/ColumnReaderBase.java": 790,
                "parquet-column/src/main/java/org/apache/parquet/column/impl/ColumnReaderImpl.java": 58,
                "parquet-column/src/main/java/org/apache/parquet/column/impl/ColumnWriteStoreBase.java": 273,
                "parquet-column/src/main/java/org/apache/parquet/column/impl/ColumnWriteStoreV1.java": 52,
                "parquet-column/src/main/java/org/apache/parquet/column/impl/ColumnWriteStoreV2.java": 46,
                "parquet-column/src/main/java/org/apache/parquet/column/impl/ColumnWriterBase.java": 408,
                "parquet-column/src/main/java/org/apache/parquet/column/impl/ColumnWriterV1.java": 68,
                "parquet-column/src/main/java/org/apache/parquet/column/impl/ColumnWriterV2.java": 94,
                "parquet-column/src/main/java/org/apache/parquet/column/impl/SynchronizingColumnReader.java": 111,
                "parquet-column/src/main/java/org/apache/parquet/column/page/DataPage.java": 72,
                "parquet-column/src/main/java/org/apache/parquet/column/page/DataPageV1.java": 127,
                "parquet-column/src/main/java/org/apache/parquet/column/page/DataPageV2.java": 207,
                "parquet-column/src/main/java/org/apache/parquet/column/page/DictionaryPage.java": 83,
                "parquet-column/src/main/java/org/apache/parquet/column/page/DictionaryPageReadStore.java": 36,
                "parquet-column/src/main/java/org/apache/parquet/column/page/Page.java": 62,
                "parquet-column/src/main/java/org/apache/parquet/column/page/PageReadStore.java": 64,
                "parquet-column/src/main/java/org/apache/parquet/column/page/PageReader.java": 40,
                "parquet-column/src/main/java/org/apache/parquet/column/page/PageWriteStore.java": 35,
                "parquet-column/src/main/java/org/apache/parquet/column/page/PageWriter.java": 102,
                "parquet-column/src/main/java/org/apache/parquet/column/statistics/BinaryStatistics.java": 188,
                "parquet-column/src/main/java/org/apache/parquet/column/statistics/BooleanStatistics.java": 147,
                "parquet-column/src/main/java/org/apache/parquet/column/statistics/DoubleStatistics.java": 147,
                "parquet-column/src/main/java/org/apache/parquet/column/statistics/FloatStatistics.java": 148,
                "parquet-column/src/main/java/org/apache/parquet/column/statistics/IntStatistics.java": 147,
                "parquet-column/src/main/java/org/apache/parquet/column/statistics/LongStatistics.java": 147,
                "parquet-column/src/main/java/org/apache/parquet/column/statistics/Statistics.java": 539,
                "parquet-column/src/main/java/org/apache/parquet/column/statistics/StatisticsClassException.java": 44,
                "parquet-column/src/main/java/org/apache/parquet/column/values/RequiresFallback.java": 51,
                "parquet-column/src/main/java/org/apache/parquet/column/values/RequiresPreviousReader.java": 23,
                "parquet-column/src/main/java/org/apache/parquet/column/values/ValuesReader.java": 205,
                "parquet-column/src/main/java/org/apache/parquet/column/values/ValuesWriter.java": 136,
                "parquet-column/src/main/java/org/apache/parquet/column/values/bitpacking/BitPackingValuesReader.java": 84,
                "parquet-column/src/main/java/org/apache/parquet/column/values/bitpacking/BitPackingValuesWriter.java": 130,
                "parquet-column/src/main/java/org/apache/parquet/column/values/bitpacking/ByteBitPackingValuesReader.java": 99,
                "parquet-column/src/main/java/org/apache/parquet/column/values/bitpacking/ByteBitPackingValuesWriter.java": 86,
                "parquet-column/src/main/java/org/apache/parquet/column/values/bitpacking/DevNullValuesWriter.java": 89,
                "parquet-column/src/main/java/org/apache/parquet/column/values/bloomfilter/AdaptiveBlockSplitBloomFilter.java": 305,
                "parquet-column/src/main/java/org/apache/parquet/column/values/bloomfilter/BlockSplitBloomFilter.java": 424,
                "parquet-column/src/main/java/org/apache/parquet/column/values/bloomfilter/BloomFilter.java": 203,
                "parquet-column/src/main/java/org/apache/parquet/column/values/bloomfilter/BloomFilterWriteStore.java": 35,
                "parquet-column/src/main/java/org/apache/parquet/column/values/bloomfilter/BloomFilterWriter.java": 31,
                "parquet-column/src/main/java/org/apache/parquet/column/values/bloomfilter/HashFunction.java": 41,
                "parquet-column/src/main/java/org/apache/parquet/column/values/bloomfilter/XxHash.java": 40,
                "parquet-column/src/main/java/org/apache/parquet/column/values/bytestreamsplit/ByteStreamSplitValuesReader.java": 111,
                "parquet-column/src/main/java/org/apache/parquet/column/values/bytestreamsplit/ByteStreamSplitValuesReaderForDouble.java": 37,
                "parquet-column/src/main/java/org/apache/parquet/column/values/bytestreamsplit/ByteStreamSplitValuesReaderForFloat.java": 37,
                "parquet-column/src/main/java/org/apache/parquet/column/values/bytestreamsplit/ByteStreamSplitValuesWriter.java": 142,
                "parquet-column/src/main/java/org/apache/parquet/column/values/delta/DeltaBinaryPackingConfig.java": 55,
                "parquet-column/src/main/java/org/apache/parquet/column/values/delta/DeltaBinaryPackingValuesReader.java": 171,
                "parquet-column/src/main/java/org/apache/parquet/column/values/delta/DeltaBinaryPackingValuesWriter.java": 136,
                "parquet-column/src/main/java/org/apache/parquet/column/values/delta/DeltaBinaryPackingValuesWriterForInteger.java": 196,
                "parquet-column/src/main/java/org/apache/parquet/column/values/delta/DeltaBinaryPackingValuesWriterForLong.java": 198,
                "parquet-column/src/main/java/org/apache/parquet/column/values/deltalengthbytearray/DeltaLengthByteArrayValuesReader.java": 80,
                "parquet-column/src/main/java/org/apache/parquet/column/values/deltalengthbytearray/DeltaLengthByteArrayValuesWriter.java": 115,
                "parquet-column/src/main/java/org/apache/parquet/column/values/deltastrings/DeltaByteArrayReader.java": 96,
                "parquet-column/src/main/java/org/apache/parquet/column/values/deltastrings/DeltaByteArrayWriter.java": 100,
                "parquet-column/src/main/java/org/apache/parquet/column/values/dictionary/DictionaryValuesReader.java": 131,
                "parquet-column/src/main/java/org/apache/parquet/column/values/dictionary/DictionaryValuesWriter.java": 597,
                "parquet-column/src/main/java/org/apache/parquet/column/values/dictionary/IntList.java": 159,
                "parquet-column/src/main/java/org/apache/parquet/column/values/dictionary/PlainValuesDictionary.java": 313,
                "parquet-column/src/main/java/org/apache/parquet/column/values/factory/DefaultV1ValuesWriterFactory.java": 122,
                "parquet-column/src/main/java/org/apache/parquet/column/values/factory/DefaultV2ValuesWriterFactory.java": 126,
                "parquet-column/src/main/java/org/apache/parquet/column/values/factory/DefaultValuesWriterFactory.java": 87,
                "parquet-column/src/main/java/org/apache/parquet/column/values/factory/ValuesWriterFactory.java": 52,
                "parquet-column/src/main/java/org/apache/parquet/column/values/fallback/FallbackValuesWriter.java": 204,
                "parquet-column/src/main/java/org/apache/parquet/column/values/plain/BinaryPlainValuesReader.java": 63,
                "parquet-column/src/main/java/org/apache/parquet/column/values/plain/BooleanPlainValuesReader.java": 73,
                "parquet-column/src/main/java/org/apache/parquet/column/values/plain/BooleanPlainValuesWriter.java": 81,
                "parquet-column/src/main/java/org/apache/parquet/column/values/plain/FixedLenByteArrayPlainValuesReader.java": 72,
                "parquet-column/src/main/java/org/apache/parquet/column/values/plain/FixedLenByteArrayPlainValuesWriter.java": 106,
                "parquet-column/src/main/java/org/apache/parquet/column/values/plain/PlainValuesReader.java": 139,
                "parquet-column/src/main/java/org/apache/parquet/column/values/plain/PlainValuesWriter.java": 148,
                "parquet-column/src/main/java/org/apache/parquet/column/values/rle/RunLengthBitPackingHybridDecoder.java": 107,
                "parquet-column/src/main/java/org/apache/parquet/column/values/rle/RunLengthBitPackingHybridEncoder.java": 293,
                "parquet-column/src/main/java/org/apache/parquet/column/values/rle/RunLengthBitPackingHybridValuesReader.java": 68,
                "parquet-column/src/main/java/org/apache/parquet/column/values/rle/RunLengthBitPackingHybridValuesWriter.java": 95,
                "parquet-column/src/main/java/org/apache/parquet/column/values/rle/ZeroIntegerValuesReader.java": 50,
                "parquet-column/src/main/java/org/apache/parquet/example/DummyRecordConverter.java": 114,
                "parquet-column/src/main/java/org/apache/parquet/example/Paper.java": 164,
                "parquet-column/src/main/java/org/apache/parquet/example/data/Group.java": 147,
                "parquet-column/src/main/java/org/apache/parquet/example/data/GroupFactory.java": 25,
                "parquet-column/src/main/java/org/apache/parquet/example/data/GroupValueSource.java": 89,
                "parquet-column/src/main/java/org/apache/parquet/example/data/GroupWriter.java": 62,
                "parquet-column/src/main/java/org/apache/parquet/example/data/simple/BinaryValue.java": 52,
                "parquet-column/src/main/java/org/apache/parquet/example/data/simple/BooleanValue.java": 44,
                "parquet-column/src/main/java/org/apache/parquet/example/data/simple/DoubleValue.java": 45,
                "parquet-column/src/main/java/org/apache/parquet/example/data/simple/FloatValue.java": 45,
                "parquet-column/src/main/java/org/apache/parquet/example/data/simple/Int96Value.java": 46,
                "parquet-column/src/main/java/org/apache/parquet/example/data/simple/IntegerValue.java": 46,
                "parquet-column/src/main/java/org/apache/parquet/example/data/simple/LongValue.java": 45,
                "parquet-column/src/main/java/org/apache/parquet/example/data/simple/NanoTime.java": 80,
                "parquet-column/src/main/java/org/apache/parquet/example/data/simple/Primitive.java": 60,
                "parquet-column/src/main/java/org/apache/parquet/example/data/simple/SimpleGroup.java": 236,
                "parquet-column/src/main/java/org/apache/parquet/example/data/simple/SimpleGroupFactory.java": 38,
                "parquet-column/src/main/java/org/apache/parquet/example/data/simple/convert/GroupRecordConverter.java": 57,
                "parquet-column/src/main/java/org/apache/parquet/example/data/simple/convert/SimpleGroupConverter.java": 67,
                "parquet-column/src/main/java/org/apache/parquet/example/data/simple/convert/SimplePrimitiveConverter.java": 88,
                "parquet-column/src/main/java/org/apache/parquet/filter/AndRecordFilter.java": 65,
                "parquet-column/src/main/java/org/apache/parquet/filter/ColumnPredicates.java": 191,
                "parquet-column/src/main/java/org/apache/parquet/filter/ColumnRecordFilter.java": 76,
                "parquet-column/src/main/java/org/apache/parquet/filter/NotRecordFilter.java": 60,
                "parquet-column/src/main/java/org/apache/parquet/filter/OrRecordFilter.java": 62,
                "parquet-column/src/main/java/org/apache/parquet/filter/PagedRecordFilter.java": 65,
                "parquet-column/src/main/java/org/apache/parquet/filter/RecordFilter.java": 33,
                "parquet-column/src/main/java/org/apache/parquet/filter/UnboundRecordFilter.java": 37,
                "parquet-column/src/main/java/org/apache/parquet/filter2/compat/FilterCompat.java": 181,
                "parquet-column/src/main/java/org/apache/parquet/filter2/predicate/FilterApi.java": 328,
                "parquet-column/src/main/java/org/apache/parquet/filter2/predicate/FilterPredicate.java": 84,
                "parquet-column/src/main/java/org/apache/parquet/filter2/predicate/LogicalInverseRewriter.java": 126,
                "parquet-column/src/main/java/org/apache/parquet/filter2/predicate/LogicalInverter.java": 120,
                "parquet-column/src/main/java/org/apache/parquet/filter2/predicate/Operators.java": 587,
                "parquet-column/src/main/java/org/apache/parquet/filter2/predicate/PrimitiveToBoxedClass.java": 50,
                "parquet-column/src/main/java/org/apache/parquet/filter2/predicate/SchemaCompatibilityValidator.java": 204,
                "parquet-column/src/main/java/org/apache/parquet/filter2/predicate/Statistics.java": 93,
                "parquet-column/src/main/java/org/apache/parquet/filter2/predicate/UserDefinedPredicate.java": 131,
                "parquet-column/src/main/java/org/apache/parquet/filter2/predicate/ValidTypeMap.java": 128,
                "parquet-column/src/main/java/org/apache/parquet/filter2/recordlevel/FilteringGroupConverter.java": 112,
                "parquet-column/src/main/java/org/apache/parquet/filter2/recordlevel/FilteringPrimitiveConverter.java": 109,
                "parquet-column/src/main/java/org/apache/parquet/filter2/recordlevel/FilteringRecordMaterializer.java": 116,
                "parquet-column/src/main/java/org/apache/parquet/filter2/recordlevel/IncrementallyUpdatedFilterPredicate.java": 166,
                "parquet-column/src/main/java/org/apache/parquet/filter2/recordlevel/IncrementallyUpdatedFilterPredicateBuilderBase.java": 116,
                "parquet-column/src/main/java/org/apache/parquet/filter2/recordlevel/IncrementallyUpdatedFilterPredicateEvaluator.java": 62,
                "parquet-column/src/main/java/org/apache/parquet/filter2/recordlevel/IncrementallyUpdatedFilterPredicateResetter.java": 59,
                "parquet-column/src/main/java/org/apache/parquet/internal/column/columnindex/BinaryColumnIndexBuilder.java": 140,
                "parquet-column/src/main/java/org/apache/parquet/internal/column/columnindex/BinaryTruncator.java": 221,
                "parquet-column/src/main/java/org/apache/parquet/internal/column/columnindex/BooleanColumnIndexBuilder.java": 133,
                "parquet-column/src/main/java/org/apache/parquet/internal/column/columnindex/BoundaryOrder.java": 384,
                "parquet-column/src/main/java/org/apache/parquet/internal/column/columnindex/ColumnIndex.java": 60,
                "parquet-column/src/main/java/org/apache/parquet/internal/column/columnindex/ColumnIndexBuilder.java": 686,
                "parquet-column/src/main/java/org/apache/parquet/internal/column/columnindex/DoubleColumnIndexBuilder.java": 155,
                "parquet-column/src/main/java/org/apache/parquet/internal/column/columnindex/FloatColumnIndexBuilder.java": 155,
                "parquet-column/src/main/java/org/apache/parquet/internal/column/columnindex/IndexIterator.java": 89,
                "parquet-column/src/main/java/org/apache/parquet/internal/column/columnindex/IntColumnIndexBuilder.java": 136,
                "parquet-column/src/main/java/org/apache/parquet/internal/column/columnindex/LongColumnIndexBuilder.java": 136,
                "parquet-column/src/main/java/org/apache/parquet/internal/column/columnindex/OffsetIndex.java": 73,
                "parquet-column/src/main/java/org/apache/parquet/internal/column/columnindex/OffsetIndexBuilder.java": 193,
                "parquet-column/src/main/java/org/apache/parquet/internal/filter2/columnindex/ColumnIndexFilter.java": 217,
                "parquet-column/src/main/java/org/apache/parquet/internal/filter2/columnindex/ColumnIndexStore.java": 55,
                "parquet-column/src/main/java/org/apache/parquet/internal/filter2/columnindex/RowRanges.java": 318,
                "parquet-column/src/main/java/org/apache/parquet/io/BaseRecordReader.java": 149,
                "parquet-column/src/main/java/org/apache/parquet/io/ColumnIO.java": 138,
                "parquet-column/src/main/java/org/apache/parquet/io/ColumnIOFactory.java": 174,
                "parquet-column/src/main/java/org/apache/parquet/io/CompilationException.java": 44,
                "parquet-column/src/main/java/org/apache/parquet/io/EmptyRecordReader.java": 48,
                "parquet-column/src/main/java/org/apache/parquet/io/FilteredRecordReader.java": 97,
                "parquet-column/src/main/java/org/apache/parquet/io/GroupColumnIO.java": 121,
                "parquet-column/src/main/java/org/apache/parquet/io/InvalidFileOffsetException.java": 29,
                "parquet-column/src/main/java/org/apache/parquet/io/InvalidRecordException.java": 45,
                "parquet-column/src/main/java/org/apache/parquet/io/MessageColumnIO.java": 534,
                "parquet-column/src/main/java/org/apache/parquet/io/ParquetDecodingException.java": 44,
                "parquet-column/src/main/java/org/apache/parquet/io/ParquetEncodingException.java": 44,
                "parquet-column/src/main/java/org/apache/parquet/io/PrimitiveColumnIO.java": 108,
                "parquet-column/src/main/java/org/apache/parquet/io/RecordConsumerLoggingWrapper.java": 187,
                "parquet-column/src/main/java/org/apache/parquet/io/RecordReader.java": 43,
                "parquet-column/src/main/java/org/apache/parquet/io/RecordReaderImplementation.java": 474,
                "parquet-column/src/main/java/org/apache/parquet/io/ValidatingRecordConsumer.java": 247,
                "parquet-column/src/main/java/org/apache/parquet/io/api/Binary.java": 737,
                "parquet-column/src/main/java/org/apache/parquet/io/api/Converter.java": 37,
                "parquet-column/src/main/java/org/apache/parquet/io/api/GroupConverter.java": 55,
                "parquet-column/src/main/java/org/apache/parquet/io/api/PrimitiveConverter.java": 108,
                "parquet-column/src/main/java/org/apache/parquet/io/api/RecordConsumer.java": 134,
                "parquet-column/src/main/java/org/apache/parquet/io/api/RecordMaterializer.java": 73,
                "parquet-column/src/main/java/org/apache/parquet/schema/ColumnOrder.java": 97,
                "parquet-column/src/main/java/org/apache/parquet/schema/ConversionPatterns.java": 133,
                "parquet-column/src/main/java/org/apache/parquet/schema/DecimalMetadata.java": 62,
                "parquet-column/src/main/java/org/apache/parquet/schema/GroupType.java": 421,
                "parquet-column/src/main/java/org/apache/parquet/schema/IncompatibleSchemaModificationException.java": 46,
                "parquet-column/src/main/java/org/apache/parquet/schema/InvalidSchemaException.java": 31,
                "parquet-column/src/main/java/org/apache/parquet/schema/LogicalTypeAnnotation.java": 1064,
                "parquet-column/src/main/java/org/apache/parquet/schema/MessageType.java": 145,
                "parquet-column/src/main/java/org/apache/parquet/schema/MessageTypeParser.java": 243,
                "parquet-column/src/main/java/org/apache/parquet/schema/OriginalType.java": 48,
                "parquet-column/src/main/java/org/apache/parquet/schema/PrimitiveComparator.java": 279,
                "parquet-column/src/main/java/org/apache/parquet/schema/PrimitiveStringifier.java": 451,
                "parquet-column/src/main/java/org/apache/parquet/schema/PrimitiveType.java": 797,
                "parquet-column/src/main/java/org/apache/parquet/schema/Type.java": 366,
                "parquet-column/src/main/java/org/apache/parquet/schema/TypeConverter.java": 53,
                "parquet-column/src/main/java/org/apache/parquet/schema/TypeUtil.java": 45,
                "parquet-column/src/main/java/org/apache/parquet/schema/TypeVisitor.java": 43,
                "parquet-column/src/main/java/org/apache/parquet/schema/Types.java": 1542,
                "parquet-column/src/test/java/org/apache/parquet/CorruptStatisticsTest.java": 92,
                "parquet-column/src/test/java/org/apache/parquet/FixedBinaryTestUtils.java": 96,
                "parquet-column/src/test/java/org/apache/parquet/ResourceIntensiveTestRule.java": 58,
                "parquet-column/src/test/java/org/apache/parquet/column/TestColumnDescriptor.java": 52,
                "parquet-column/src/test/java/org/apache/parquet/column/TestEncodingStats.java": 202,
                "parquet-column/src/test/java/org/apache/parquet/column/impl/TestColumnReaderImpl.java": 131,
                "parquet-column/src/test/java/org/apache/parquet/column/impl/TestCorruptDeltaByteArrays.java": 269,
                "parquet-column/src/test/java/org/apache/parquet/column/mem/TestMemColumn.java": 246,
                "parquet-column/src/test/java/org/apache/parquet/column/mem/TestMemPageStore.java": 61,
                "parquet-column/src/test/java/org/apache/parquet/column/page/mem/MemPageReader.java": 67,
                "parquet-column/src/test/java/org/apache/parquet/column/page/mem/MemPageStore.java": 78,
                "parquet-column/src/test/java/org/apache/parquet/column/page/mem/MemPageWriter.java": 117,
                "parquet-column/src/test/java/org/apache/parquet/column/statistics/TestStatistics.java": 789,
                "parquet-column/src/test/java/org/apache/parquet/column/values/TestValuesReaderImpl.java": 148,
                "parquet-column/src/test/java/org/apache/parquet/column/values/Utils.java": 76,
                "parquet-column/src/test/java/org/apache/parquet/column/values/bitpacking/BitPackingPerfTest.java": 103,
                "parquet-column/src/test/java/org/apache/parquet/column/values/bitpacking/TestBitPackingColumn.java": 232,
                "parquet-column/src/test/java/org/apache/parquet/column/values/bloomfilter/TestBlockSplitBloomFilter.java": 325,
                "parquet-column/src/test/java/org/apache/parquet/column/values/bytestreamsplit/ByteStreamSplitValuesEndToEndTest.java": 111,
                "parquet-column/src/test/java/org/apache/parquet/column/values/bytestreamsplit/ByteStreamSplitValuesReaderTest.java": 193,
                "parquet-column/src/test/java/org/apache/parquet/column/values/bytestreamsplit/ByteStreamSplitValuesWriterTest.java": 189,
                "parquet-column/src/test/java/org/apache/parquet/column/values/delta/DeltaBinaryPackingValuesWriterForIntegerTest.java": 294,
                "parquet-column/src/test/java/org/apache/parquet/column/values/delta/DeltaBinaryPackingValuesWriterForLongTest.java": 291,
                "parquet-column/src/test/java/org/apache/parquet/column/values/delta/benchmark/BenchMarkTest.java": 41,
                "parquet-column/src/test/java/org/apache/parquet/column/values/delta/benchmark/BenchmarkIntegerOutputSize.java": 107,
                "parquet-column/src/test/java/org/apache/parquet/column/values/delta/benchmark/BenchmarkReadingRandomIntegers.java": 102,
                "parquet-column/src/test/java/org/apache/parquet/column/values/delta/benchmark/RandomWritingBenchmarkTest.java": 76,
                "parquet-column/src/test/java/org/apache/parquet/column/values/delta/benchmark/SmallRangeWritingBenchmarkTest.java": 49,
                "parquet-column/src/test/java/org/apache/parquet/column/values/deltalengthbytearray/TestDeltaLengthByteArray.java": 103,
                "parquet-column/src/test/java/org/apache/parquet/column/values/deltalengthbytearray/benchmark/BenchmarkDeltaLengthByteArray.java": 73,
                "parquet-column/src/test/java/org/apache/parquet/column/values/deltastrings/TestDeltaByteArray.java": 130,
                "parquet-column/src/test/java/org/apache/parquet/column/values/deltastrings/benchmark/BenchmarkDeltaByteArray.java": 103,
                "parquet-column/src/test/java/org/apache/parquet/column/values/dictionary/IntListTest.java": 84,
                "parquet-column/src/test/java/org/apache/parquet/column/values/dictionary/TestDictionary.java": 661,
                "parquet-column/src/test/java/org/apache/parquet/column/values/factory/DefaultValuesWriterFactoryTest.java": 546,
                "parquet-column/src/test/java/org/apache/parquet/column/values/rle/RunLengthBitPackingHybridIntegrationTest.java": 86,
                "parquet-column/src/test/java/org/apache/parquet/column/values/rle/TestRunLengthBitPackingHybridEncoder.java": 329,
                "parquet-column/src/test/java/org/apache/parquet/filter2/predicate/DummyUdp.java": 37,
                "parquet-column/src/test/java/org/apache/parquet/filter2/predicate/TestFilterApiMethods.java": 172,
                "parquet-column/src/test/java/org/apache/parquet/filter2/predicate/TestLogicalInverseRewriter.java": 103,
                "parquet-column/src/test/java/org/apache/parquet/filter2/predicate/TestLogicalInverter.java": 94,
                "parquet-column/src/test/java/org/apache/parquet/filter2/predicate/TestSchemaCompatibilityValidator.java": 142,
                "parquet-column/src/test/java/org/apache/parquet/filter2/predicate/TestValidTypeMap.java": 98,
                "parquet-column/src/test/java/org/apache/parquet/filter2/recordlevel/TestIncrementallyUpdatedFilterPredicateEvaluator.java": 209,
                "parquet-column/src/test/java/org/apache/parquet/filter2/recordlevel/TestIncrementallyUpdatedFilterPredicateResetter.java": 69,
                "parquet-column/src/test/java/org/apache/parquet/filter2/recordlevel/TestValueInspector.java": 97,
                "parquet-column/src/test/java/org/apache/parquet/internal/column/columnindex/TestBinaryTruncator.java": 285,
                "parquet-column/src/test/java/org/apache/parquet/internal/column/columnindex/TestBoundaryOrder.java": 543,
                "parquet-column/src/test/java/org/apache/parquet/internal/column/columnindex/TestColumnIndexBuilder.java": 1728,
                "parquet-column/src/test/java/org/apache/parquet/internal/column/columnindex/TestIndexIterator.java": 63,
                "parquet-column/src/test/java/org/apache/parquet/internal/column/columnindex/TestOffsetIndexBuilder.java": 111,
                "parquet-column/src/test/java/org/apache/parquet/internal/filter2/columnindex/TestColumnIndexFilter.java": 555,
                "parquet-column/src/test/java/org/apache/parquet/internal/filter2/columnindex/TestRowRanges.java": 155,
                "parquet-column/src/test/java/org/apache/parquet/io/ConverterConsumer.java": 125,
                "parquet-column/src/test/java/org/apache/parquet/io/ExpectationValidatingConverter.java": 169,
                "parquet-column/src/test/java/org/apache/parquet/io/ExpectationValidatingRecordConsumer.java": 112,
                "parquet-column/src/test/java/org/apache/parquet/io/PerfTest.java": 128,
                "parquet-column/src/test/java/org/apache/parquet/io/TestColumnIO.java": 709,
                "parquet-column/src/test/java/org/apache/parquet/io/TestFiltered.java": 278,
                "parquet-column/src/test/java/org/apache/parquet/io/api/TestBinary.java": 271,
                "parquet-column/src/test/java/org/apache/parquet/parser/TestParquetParser.java": 374,
                "parquet-column/src/test/java/org/apache/parquet/schema/TestMessageType.java": 247,
                "parquet-column/src/test/java/org/apache/parquet/schema/TestPrimitiveComparator.java": 330,
                "parquet-column/src/test/java/org/apache/parquet/schema/TestPrimitiveStringifier.java": 391,
                "parquet-column/src/test/java/org/apache/parquet/schema/TestRepetitionType.java": 36,
                "parquet-column/src/test/java/org/apache/parquet/schema/TestTypeBuilders.java": 1372,
                "parquet-column/src/test/java/org/apache/parquet/schema/TestTypeBuildersWithLogicalTypes.java": 422,
                "parquet-column/src/test/java/org/apache/parquet/schema/TestTypeUtil.java": 80,
                "parquet-common/src/main/java/org/apache/parquet/Closeables.java": 60,
                "parquet-common/src/main/java/org/apache/parquet/Exceptions.java": 39,
                "parquet-common/src/main/java/org/apache/parquet/Files.java": 54,
                "parquet-common/src/main/java/org/apache/parquet/IOExceptionUtils.java": 45,
                "parquet-common/src/main/java/org/apache/parquet/Ints.java": 44,
                "parquet-common/src/main/java/org/apache/parquet/Log.java": 146,
                "parquet-common/src/main/java/org/apache/parquet/OutputStreamCloseException.java": 46,
                "parquet-common/src/main/java/org/apache/parquet/ParquetRuntimeException.java": 42,
                "parquet-common/src/main/java/org/apache/parquet/Preconditions.java": 251,
                "parquet-common/src/main/java/org/apache/parquet/SemanticVersion.java": 293,
                "parquet-common/src/main/java/org/apache/parquet/ShouldNeverHappenException.java": 40,
                "parquet-common/src/main/java/org/apache/parquet/Strings.java": 132,
                "parquet-common/src/main/java/org/apache/parquet/VersionParser.java": 129,
                "parquet-common/src/main/java/org/apache/parquet/bytes/ByteBufferAllocator.java": 40,
                "parquet-common/src/main/java/org/apache/parquet/bytes/ByteBufferInputStream.java": 160,
                "parquet-common/src/main/java/org/apache/parquet/bytes/BytesInput.java": 545,
                "parquet-common/src/main/java/org/apache/parquet/bytes/BytesUtils.java": 335,
                "parquet-common/src/main/java/org/apache/parquet/bytes/CapacityByteArrayOutputStream.java": 352,
                "parquet-common/src/main/java/org/apache/parquet/bytes/ConcatenatingByteArrayCollector.java": 63,
                "parquet-common/src/main/java/org/apache/parquet/bytes/DirectByteBufferAllocator.java": 43,
                "parquet-common/src/main/java/org/apache/parquet/bytes/HeapByteBufferAllocator.java": 44,
                "parquet-common/src/main/java/org/apache/parquet/bytes/LittleEndianDataInputStream.java": 421,
                "parquet-common/src/main/java/org/apache/parquet/bytes/LittleEndianDataOutputStream.java": 218,
                "parquet-common/src/main/java/org/apache/parquet/bytes/MultiBufferInputStream.java": 382,
                "parquet-common/src/main/java/org/apache/parquet/bytes/SingleBufferInputStream.java": 177,
                "parquet-common/src/main/java/org/apache/parquet/compression/CompressionCodecFactory.java": 47,
                "parquet-common/src/main/java/org/apache/parquet/glob/GlobExpander.java": 129,
                "parquet-common/src/main/java/org/apache/parquet/glob/GlobNode.java": 157,
                "parquet-common/src/main/java/org/apache/parquet/glob/GlobParser.java": 224,
                "parquet-common/src/main/java/org/apache/parquet/glob/WildcardPath.java": 121,
                "parquet-common/src/main/java/org/apache/parquet/hadoop/codec/CompressionCodecNotSupportedException.java": 38,
                "parquet-common/src/main/java/org/apache/parquet/hadoop/metadata/Canonicalizer.java": 61,
                "parquet-common/src/main/java/org/apache/parquet/hadoop/metadata/ColumnPath.java": 88,
                "parquet-common/src/main/java/org/apache/parquet/hadoop/metadata/CompressionCodecName.java": 99,
                "parquet-common/src/main/java/org/apache/parquet/io/DelegatingPositionOutputStream.java": 63,
                "parquet-common/src/main/java/org/apache/parquet/io/DelegatingSeekableInputStream.java": 171,
                "parquet-common/src/main/java/org/apache/parquet/io/InputFile.java": 44,
                "parquet-common/src/main/java/org/apache/parquet/io/LocalInputFile.java": 102,
                "parquet-common/src/main/java/org/apache/parquet/io/LocalOutputFile.java": 107,
                "parquet-common/src/main/java/org/apache/parquet/io/OutputFile.java": 62,
                "parquet-common/src/main/java/org/apache/parquet/io/PositionOutputStream.java": 39,
                "parquet-common/src/main/java/org/apache/parquet/io/SeekableInputStream.java": 108,
                "parquet-common/src/main/java/org/apache/parquet/util/DynConstructors.java": 263,
                "parquet-common/src/main/java/org/apache/parquet/util/DynMethods.java": 506,
                "parquet-common/src/test/java/org/apache/parquet/SemanticVersionTest.java": 114,
                "parquet-common/src/test/java/org/apache/parquet/TestPreconditions.java": 246,
                "parquet-common/src/test/java/org/apache/parquet/TestUtils.java": 70,
                "parquet-common/src/test/java/org/apache/parquet/VersionTest.java": 100,
                "parquet-common/src/test/java/org/apache/parquet/bytes/TestByteBufferInputStreams.java": 589,
                "parquet-common/src/test/java/org/apache/parquet/bytes/TestBytesUtil.java": 49,
                "parquet-common/src/test/java/org/apache/parquet/bytes/TestDeprecatedBufferInputStream.java": 152,
                "parquet-common/src/test/java/org/apache/parquet/bytes/TestMultiBufferInputStream.java": 141,
                "parquet-common/src/test/java/org/apache/parquet/bytes/TestSingleBufferInputStream.java": 130,
                "parquet-common/src/test/java/org/apache/parquet/glob/TestGlob.java": 144,
                "parquet-common/src/test/java/org/apache/parquet/glob/TestWildcardPath.java": 125,
                "parquet-common/src/test/java/org/apache/parquet/io/MockInputStream.java": 56,
                "parquet-common/src/test/java/org/apache/parquet/io/TestDelegatingSeekableInputStream.java": 844,
                "parquet-common/src/test/java/org/apache/parquet/io/TestLocalInputOutput.java": 92,
                "parquet-common/src/test/java/org/apache/parquet/util/Concatenator.java": 82,
                "parquet-common/src/test/java/org/apache/parquet/util/TestDynConstructors.java": 165,
                "parquet-common/src/test/java/org/apache/parquet/util/TestDynMethods.java": 315,
                "parquet-encoding/src/main/java/org/apache/parquet/column/values/bitpacking/BitPacking.java": 717,
                "parquet-encoding/src/main/java/org/apache/parquet/column/values/bitpacking/ByteBasedBitPackingEncoder.java": 142,
                "parquet-encoding/src/main/java/org/apache/parquet/column/values/bitpacking/BytePacker.java": 141,
                "parquet-encoding/src/main/java/org/apache/parquet/column/values/bitpacking/BytePackerFactory.java": 25,
                "parquet-encoding/src/main/java/org/apache/parquet/column/values/bitpacking/BytePackerForLong.java": 109,
                "parquet-encoding/src/main/java/org/apache/parquet/column/values/bitpacking/BytePackerForLongFactory.java": 25,
                "parquet-encoding/src/main/java/org/apache/parquet/column/values/bitpacking/IntPacker.java": 63,
                "parquet-encoding/src/main/java/org/apache/parquet/column/values/bitpacking/IntPackerFactory.java": 25,
                "parquet-encoding/src/main/java/org/apache/parquet/column/values/bitpacking/Packer.java": 137,
                "parquet-encoding/src/test/java/org/apache/parquet/bytes/TestBytesInput.java": 42,
                "parquet-encoding/src/test/java/org/apache/parquet/bytes/TestCapacityByteArrayOutputStream.java": 242,
                "parquet-encoding/src/test/java/org/apache/parquet/column/values/bitpacking/TestBitPacking.java": 233,
                "parquet-encoding/src/test/java/org/apache/parquet/column/values/bitpacking/TestByteBasedBitPackingEncoder.java": 46,
                "parquet-encoding/src/test/java/org/apache/parquet/column/values/bitpacking/TestByteBitPacking.java": 198,
                "parquet-encoding/src/test/java/org/apache/parquet/column/values/bitpacking/TestLemireBitPacking.java": 125,
                "parquet-format-structures/src/main/java/org/apache/parquet/format/BlockCipher.java": 76,
                "parquet-format-structures/src/main/java/org/apache/parquet/format/CliUtils.java": 55,
                "parquet-format-structures/src/main/java/org/apache/parquet/format/InterningProtocol.java": 236,
                "parquet-format-structures/src/main/java/org/apache/parquet/format/InvalidParquetMetadataException.java": 30,
                "parquet-format-structures/src/main/java/org/apache/parquet/format/LogicalTypes.java": 55,
                "parquet-format-structures/src/main/java/org/apache/parquet/format/MetadataValidator.java": 44,
                "parquet-format-structures/src/main/java/org/apache/parquet/format/Util.java": 389,
                "parquet-format-structures/src/main/java/org/apache/parquet/format/event/Consumers.java": 191,
                "parquet-format-structures/src/main/java/org/apache/parquet/format/event/EventBasedThriftReader.java": 126,
                "parquet-format-structures/src/main/java/org/apache/parquet/format/event/FieldConsumer.java": 39,
                "parquet-format-structures/src/main/java/org/apache/parquet/format/event/TypedConsumer.java": 205,
                "parquet-format-structures/src/test/java/org/apache/parquet/format/TestUtil.java": 101,
                "parquet-generator/src/main/java/org/apache/parquet/encoding/Generator.java": 34,
                "parquet-generator/src/main/java/org/apache/parquet/encoding/bitpacking/ByteBasedBitPackingGenerator.java": 319,
                "parquet-generator/src/main/java/org/apache/parquet/encoding/bitpacking/IntBasedBitPackingGenerator.java": 208,
                "parquet-generator/src/main/java/org/apache/parquet/filter2/Generator.java": 28,
                "parquet-generator/src/main/java/org/apache/parquet/filter2/IncrementallyUpdatedFilterPredicateGenerator.java": 335,
                "parquet-generator/src/main/java/org/apache/parquet/version/Generator.java": 28,
                "parquet-generator/src/main/java/org/apache/parquet/version/VersionGenerator.java": 87,
                "parquet-hadoop/src/main/java/org/apache/parquet/HadoopReadOptions.java": 143,
                "parquet-hadoop/src/main/java/org/apache/parquet/ParquetReadOptions.java": 345,
                "parquet-hadoop/src/main/java/org/apache/parquet/crypto/AADPrefixVerifier.java": 32,
                "parquet-hadoop/src/main/java/org/apache/parquet/crypto/AesCipher.java": 164,
                "parquet-hadoop/src/main/java/org/apache/parquet/crypto/AesCtrDecryptor.java": 170,
                "parquet-hadoop/src/main/java/org/apache/parquet/crypto/AesCtrEncryptor.java": 104,
                "parquet-hadoop/src/main/java/org/apache/parquet/crypto/AesGcmDecryptor.java": 151,
                "parquet-hadoop/src/main/java/org/apache/parquet/crypto/AesGcmEncryptor.java": 91,
                "parquet-hadoop/src/main/java/org/apache/parquet/crypto/AesMode.java": 35,
                "parquet-hadoop/src/main/java/org/apache/parquet/crypto/ColumnDecryptionProperties.java": 104,
                "parquet-hadoop/src/main/java/org/apache/parquet/crypto/ColumnEncryptionProperties.java": 195,
                "parquet-hadoop/src/main/java/org/apache/parquet/crypto/DecryptionKeyRetriever.java": 39,
                "parquet-hadoop/src/main/java/org/apache/parquet/crypto/DecryptionPropertiesFactory.java": 88,
                "parquet-hadoop/src/main/java/org/apache/parquet/crypto/EncryptionPropertiesFactory.java": 93,
                "parquet-hadoop/src/main/java/org/apache/parquet/crypto/FileDecryptionProperties.java": 254,
                "parquet-hadoop/src/main/java/org/apache/parquet/crypto/FileEncryptionProperties.java": 278,
                "parquet-hadoop/src/main/java/org/apache/parquet/crypto/InternalColumnDecryptionSetup.java": 74,
                "parquet-hadoop/src/main/java/org/apache/parquet/crypto/InternalColumnEncryptionSetup.java": 82,
                "parquet-hadoop/src/main/java/org/apache/parquet/crypto/InternalFileDecryptor.java": 312,
                "parquet-hadoop/src/main/java/org/apache/parquet/crypto/InternalFileEncryptor.java": 200,
                "parquet-hadoop/src/main/java/org/apache/parquet/crypto/KeyAccessDeniedException.java": 39,
                "parquet-hadoop/src/main/java/org/apache/parquet/crypto/ModuleCipherFactory.java": 73,
                "parquet-hadoop/src/main/java/org/apache/parquet/crypto/ParquetCipher.java": 42,
                "parquet-hadoop/src/main/java/org/apache/parquet/crypto/ParquetCryptoRuntimeException.java": 42,
                "parquet-hadoop/src/main/java/org/apache/parquet/crypto/TagVerificationException.java": 39,
                "parquet-hadoop/src/main/java/org/apache/parquet/crypto/keytools/FileKeyMaterialStore.java": 72,
                "parquet-hadoop/src/main/java/org/apache/parquet/crypto/keytools/FileKeyUnwrapper.java": 178,
                "parquet-hadoop/src/main/java/org/apache/parquet/crypto/keytools/FileKeyWrapper.java": 177,
                "parquet-hadoop/src/main/java/org/apache/parquet/crypto/keytools/HadoopFSKeyMaterialStore.java": 136,
                "parquet-hadoop/src/main/java/org/apache/parquet/crypto/keytools/KeyMaterial.java": 210,
                "parquet-hadoop/src/main/java/org/apache/parquet/crypto/keytools/KeyMetadata.java": 130,
                "parquet-hadoop/src/main/java/org/apache/parquet/crypto/keytools/KeyToolkit.java": 394,
                "parquet-hadoop/src/main/java/org/apache/parquet/crypto/keytools/KmsClient.java": 72,
                "parquet-hadoop/src/main/java/org/apache/parquet/crypto/keytools/LocalWrapKmsClient.java": 181,
                "parquet-hadoop/src/main/java/org/apache/parquet/crypto/keytools/PropertiesDrivenCryptoFactory.java": 258,
                "parquet-hadoop/src/main/java/org/apache/parquet/crypto/keytools/TwoLevelCacheWithExpiration.java": 105,
                "parquet-hadoop/src/main/java/org/apache/parquet/filter2/bloomfilterlevel/BloomFilterImpl.java": 187,
                "parquet-hadoop/src/main/java/org/apache/parquet/filter2/compat/RowGroupFilter.java": 131,
                "parquet-hadoop/src/main/java/org/apache/parquet/filter2/dictionarylevel/DictionaryFilter.java": 570,
                "parquet-hadoop/src/main/java/org/apache/parquet/filter2/statisticslevel/StatisticsFilter.java": 485,
                "parquet-hadoop/src/main/java/org/apache/parquet/format/converter/ParquetMetadataConverter.java": 2080,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/BadConfigurationException.java": 44,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/BloomFilterReader.java": 70,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/CodecFactory.java": 289,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ColumnChunkPageReadStore.java": 364,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ColumnChunkPageWriteStore.java": 462,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ColumnConfigParser.java": 72,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ColumnIndexFilterUtils.java": 162,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ColumnIndexStoreImpl.java": 155,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ColumnIndexValidator.java": 613,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/DictionaryPageReader.java": 115,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/DirectCodecFactory.java": 528,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/DirectZstd.java": 144,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/Footer.java": 53,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/InternalParquetRecordReader.java": 321,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/InternalParquetRecordWriter.java": 209,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/LruCache.java": 195,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/MemoryManager.java": 199,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/Offsets.java": 94,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ParquetEmptyBlockException.java": 41,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ParquetFileReader.java": 1869,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ParquetFileWriter.java": 1731,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ParquetInputFormat.java": 837,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ParquetInputSplit.java": 295,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ParquetMemoryManagerRuntimeException.java": 38,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ParquetOutputCommitter.java": 112,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ParquetOutputFormat.java": 570,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ParquetReader.java": 379,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ParquetRecordReader.java": 233,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ParquetRecordWriter.java": 184,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ParquetWriter.java": 744,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/PrintFooter.java": 265,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/UnmaterializableRecordCounter.java": 103,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/api/DelegatingReadSupport.java": 60,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/api/DelegatingWriteSupport.java": 69,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/api/InitContext.java": 99,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/api/ReadSupport.java": 145,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/api/WriteSupport.java": 140,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/api/package-info.java": 27,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/codec/CleanUtil.java": 111,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/codec/CodecConfig.java": 167,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/codec/Lz4RawCodec.java": 112,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/codec/Lz4RawCompressor.java": 44,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/codec/Lz4RawDecompressor.java": 46,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/codec/NonBlockedCompressor.java": 192,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/codec/NonBlockedCompressorStream.java": 50,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/codec/NonBlockedDecompressor.java": 180,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/codec/NonBlockedDecompressorStream.java": 57,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/codec/SnappyCodec.java": 105,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/codec/SnappyCompressor.java": 38,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/codec/SnappyDecompressor.java": 38,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/codec/SnappyUtil.java": 33,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/codec/ZstandardCodec.java": 130,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/codec/ZstdCompressorStream.java": 70,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/codec/ZstdDecompressorStream.java": 62,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/example/ExampleInputFormat.java": 35,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/example/ExampleOutputFormat.java": 58,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/example/ExampleParquetWriter.java": 118,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/example/GroupReadSupport.java": 49,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/example/GroupWriteSupport.java": 88,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/mapred/Container.java": 37,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/mapred/DeprecatedParquetInputFormat.java": 209,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/mapred/DeprecatedParquetOutputFormat.java": 119,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/mapred/MapredParquetOutputCommitter.java": 42,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/metadata/BlockMetaData.java": 153,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/metadata/ColumnChunkMetaData.java": 683,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/metadata/ColumnChunkProperties.java": 118,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/metadata/ConcatenatingKeyValueMetadataMergeStrategy.java": 61,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/metadata/EncodingList.java": 81,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/metadata/FileMetaData.java": 108,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/metadata/GlobalMetaData.java": 110,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/metadata/KeyValueMetadataMergeStrategy.java": 42,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/metadata/ParquetMetadata.java": 134,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/metadata/StrictKeyValueMetadataMergeStrategy.java": 42,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/package-info.java": 33,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/rewrite/MaskMode.java": 38,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/rewrite/ParquetRewriter.java": 819,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/rewrite/RewriteOptions.java": 262,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/util/ColumnEncryptor.java": 90,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/util/ColumnMasker.java": 98,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/util/ColumnPruner.java": 42,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/util/CompressionConverter.java": 81,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/util/ConfigurationUtil.java": 44,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/util/ContextUtil.java": 315,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/util/H1SeekableInputStream.java": 59,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/util/H2SeekableInputStream.java": 99,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/util/HadoopCodecs.java": 39,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/util/HadoopInputFile.java": 76,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/util/HadoopOutputFile.java": 105,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/util/HadoopPositionOutputStream.java": 66,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/util/HadoopStreams.java": 148,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/util/HiddenFileFilter.java": 39,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/util/SerializationUtil.java": 93,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/util/counters/BenchmarkCounter.java": 112,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/util/counters/CounterLoader.java": 27,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/util/counters/ICounter.java": 28,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/util/counters/mapred/MapRedCounterAdapter.java": 43,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/util/counters/mapred/MapRedCounterLoader.java": 51,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/util/counters/mapreduce/MapReduceCounterAdapter.java": 44,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/util/counters/mapreduce/MapReduceCounterLoader.java": 47,
                "parquet-hadoop/src/main/java/org/apache/parquet/internal/hadoop/metadata/IndexReference.java": 41,
                "parquet-hadoop/src/test/java/org/apache/parquet/DirectWriterTest.java": 102,
                "parquet-hadoop/src/test/java/org/apache/parquet/crypto/DecryptionKeyRetrieverMock.java": 41,
                "parquet-hadoop/src/test/java/org/apache/parquet/crypto/DecryptionPropertiesFactoryTest.java": 43,
                "parquet-hadoop/src/test/java/org/apache/parquet/crypto/EncryptionPropertiesFactoryTest.java": 45,
                "parquet-hadoop/src/test/java/org/apache/parquet/crypto/SampleDecryptionPropertiesFactory.java": 57,
                "parquet-hadoop/src/test/java/org/apache/parquet/crypto/SampleEncryptionPropertiesFactory.java": 58,
                "parquet-hadoop/src/test/java/org/apache/parquet/crypto/SingleRow.java": 139,
                "parquet-hadoop/src/test/java/org/apache/parquet/crypto/TestPropertiesDrivenEncryption.java": 705,
                "parquet-hadoop/src/test/java/org/apache/parquet/crypto/keytools/mocks/InMemoryKMS.java": 116,
                "parquet-hadoop/src/test/java/org/apache/parquet/crypto/keytools/mocks/LocalWrapInMemoryKMS.java": 79,
                "parquet-hadoop/src/test/java/org/apache/parquet/crypto/keytools/samples/VaultClient.java": 184,
                "parquet-hadoop/src/test/java/org/apache/parquet/crypto/propertiesfactory/SchemaControlEncryptionTest.java": 250,
                "parquet-hadoop/src/test/java/org/apache/parquet/crypto/propertiesfactory/SchemaCryptoPropertiesFactory.java": 137,
                "parquet-hadoop/src/test/java/org/apache/parquet/encodings/FileEncodingsIT.java": 564,
                "parquet-hadoop/src/test/java/org/apache/parquet/filter2/TestFiltersWithMissingColumns.java": 275,
                "parquet-hadoop/src/test/java/org/apache/parquet/filter2/compat/TestRowGroupFilter.java": 128,
                "parquet-hadoop/src/test/java/org/apache/parquet/filter2/dictionarylevel/DictionaryFilterTest.java": 839,
                "parquet-hadoop/src/test/java/org/apache/parquet/filter2/recordlevel/PhoneBookWriter.java": 373,
                "parquet-hadoop/src/test/java/org/apache/parquet/filter2/recordlevel/TestRecordLevelFilters.java": 310,
                "parquet-hadoop/src/test/java/org/apache/parquet/filter2/statisticslevel/TestStatisticsFilter.java": 561,
                "parquet-hadoop/src/test/java/org/apache/parquet/format/converter/TestParquetMetadataConverter.java": 1389,
                "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/DeprecatedInputFormatTest.java": 346,
                "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/DeprecatedOutputFormatTest.java": 108,
                "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/ITTestEncryptionOptions.java": 50,
                "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/TestAdaptiveBlockSplitBloomFiltering.java": 78,
                "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/TestBloomFiltering.java": 421,
                "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/TestColumnChunkPageWriteStore.java": 288,
                "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/TestColumnIndexFiltering.java": 617,
                "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/TestDataPageV1Checksums.java": 563,
                "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/TestDirectCodecFactory.java": 178,
                "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/TestEncryptionOptions.java": 752,
                "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/TestInputFormat.java": 555,
                "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/TestInputFormatColumnProjection.java": 180,
                "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/TestInputOutputFormatWithPadding.java": 214,
                "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/TestLargeColumnChunk.java": 145,
                "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/TestLruCache.java": 162,
                "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/TestMemoryManager.java": 189,
                "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/TestMergeMetadataFiles.java": 221,
                "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/TestMultipleWriteRead.java": 250,
                "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/TestParquetFileWriter.java": 1218,
                "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/TestParquetOutputFormatJobSummaryLevel.java": 69,
                "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/TestParquetReader.java": 198,
                "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/TestParquetReaderEmptyBlock.java": 170,
                "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/TestParquetReaderRandomAccess.java": 387,
                "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/TestParquetWriter.java": 431,
                "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/TestParquetWriterAppendBlocks.java": 361,
                "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/TestParquetWriterNewPage.java": 136,
                "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/TestParquetWriterTruncation.java": 125,
                "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/TestReadWriteEncodingStats.java": 122,
                "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/TestSnappyCodec.java": 140,
                "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/TestStoreBloomFilter.java": 132,
                "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/TestUtils.java": 85,
                "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/TestZstandardCodec.java": 173,
                "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/codec/CodecConfigTest.java": 77,
                "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/codec/TestCompressionCodec.java": 177,
                "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/codec/TestInteropReadLz4RawCodec.java": 129,
                "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/example/GroupReadSupportTest.java": 65,
                "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/example/TestInputOutputFormat.java": 364,
                "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/metadata/TestColumnChunkMetaData.java": 83,
                "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/rewrite/ParquetRewriterTest.java": 772,
                "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/util/ColumnEncryptorTest.java": 315,
                "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/util/ColumnMaskerTest.java": 223,
                "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/util/ColumnPrunerTest.java": 246,
                "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/util/CompressionConverterTest.java": 312,
                "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/util/EncDecProperties.java": 94,
                "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/util/EncryptionTestFile.java": 38,
                "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/util/MockHadoopInputStream.java": 87,
                "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/util/TestFileBuilder.java": 198,
                "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/util/TestHadoop2ByteBufferReads.java": 446,
                "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/util/TestSerializationUtil.java": 71,
                "parquet-hadoop/src/test/java/org/apache/parquet/statistics/DataGenerationContext.java": 85,
                "parquet-hadoop/src/test/java/org/apache/parquet/statistics/RandomValues.java": 383,
                "parquet-hadoop/src/test/java/org/apache/parquet/statistics/TestColumnIndexes.java": 304,
                "parquet-hadoop/src/test/java/org/apache/parquet/statistics/TestStatistics.java": 459,
                "parquet-pig/src/main/java/org/apache/parquet/pig/ParquetLoader.java": 575,
                "parquet-pig/src/main/java/org/apache/parquet/pig/ParquetStorer.java": 152,
                "parquet-pig/src/main/java/org/apache/parquet/pig/PigMetaData.java": 91,
                "parquet-pig/src/main/java/org/apache/parquet/pig/PigSchemaConverter.java": 551,
                "parquet-pig/src/main/java/org/apache/parquet/pig/SchemaConversionException.java": 44,
                "parquet-pig/src/main/java/org/apache/parquet/pig/TupleConversionException.java": 42,
                "parquet-pig/src/main/java/org/apache/parquet/pig/TupleReadSupport.java": 191,
                "parquet-pig/src/main/java/org/apache/parquet/pig/TupleWriteSupport.java": 209,
                "parquet-pig/src/main/java/org/apache/parquet/pig/convert/DecimalUtils.java": 65,
                "parquet-pig/src/main/java/org/apache/parquet/pig/convert/MapConverter.java": 190,
                "parquet-pig/src/main/java/org/apache/parquet/pig/convert/ParentValueContainer.java": 32,
                "parquet-pig/src/main/java/org/apache/parquet/pig/convert/TupleConverter.java": 592,
                "parquet-pig/src/main/java/org/apache/parquet/pig/convert/TupleRecordMaterializer.java": 50,
                "parquet-pig/src/main/java/org/apache/parquet/pig/summary/BagSummaryData.java": 72,
                "parquet-pig/src/main/java/org/apache/parquet/pig/summary/EnumStat.java": 115,
                "parquet-pig/src/main/java/org/apache/parquet/pig/summary/FieldSummaryData.java": 178,
                "parquet-pig/src/main/java/org/apache/parquet/pig/summary/MapSummaryData.java": 85,
                "parquet-pig/src/main/java/org/apache/parquet/pig/summary/NumberSummaryData.java": 47,
                "parquet-pig/src/main/java/org/apache/parquet/pig/summary/StringSummaryData.java": 82,
                "parquet-pig/src/main/java/org/apache/parquet/pig/summary/Summary.java": 224,
                "parquet-pig/src/main/java/org/apache/parquet/pig/summary/SummaryData.java": 135,
                "parquet-pig/src/main/java/org/apache/parquet/pig/summary/TupleSummaryData.java": 98,
                "parquet-pig/src/main/java/org/apache/parquet/pig/summary/ValueStat.java": 64,
                "parquet-pig/src/test/java/org/apache/parquet/pig/PerfTest.java": 104,
                "parquet-pig/src/test/java/org/apache/parquet/pig/PerfTest2.java": 185,
                "parquet-pig/src/test/java/org/apache/parquet/pig/PerfTestReadAllCols.java": 47,
                "parquet-pig/src/test/java/org/apache/parquet/pig/TestDecimalUtils.java": 79,
                "parquet-pig/src/test/java/org/apache/parquet/pig/TestParquetLoader.java": 367,
                "parquet-pig/src/test/java/org/apache/parquet/pig/TestParquetStorer.java": 264,
                "parquet-pig/src/test/java/org/apache/parquet/pig/TestPigSchemaConverter.java": 291,
                "parquet-pig/src/test/java/org/apache/parquet/pig/TestTupleRecordConsumer.java": 210,
                "parquet-pig/src/test/java/org/apache/parquet/pig/TupleConsumerPerfTest.java": 206,
                "parquet-pig/src/test/java/org/apache/parquet/pig/summary/TestSummary.java": 158,
                "parquet-plugins/parquet-encoding-vector/src/main/java/org/apache/parquet/column/values/bitpacking/ByteBitPacking512VectorLE.java": 3010,
                "parquet-plugins/parquet-encoding-vector/src/main/java/org/apache/parquet/column/values/bitpacking/ParquetReadRouter.java": 133,
                "parquet-plugins/parquet-encoding-vector/src/main/java/org/apache/parquet/column/values/bitpacking/VectorSupport.java": 27,
                "parquet-plugins/parquet-encoding-vector/src/test/java/org/apache/parquet/column/values/bitpacking/TestByteBitPacking512VectorLE.java": 169,
                "parquet-plugins/parquet-encoding-vector/src/test/java/org/apache/parquet/column/values/bitpacking/TestParquetReadRouter.java": 59,
                "parquet-plugins/parquet-plugins-benchmarks/src/main/java/org/apache/parquet/plugins/benchmarks/ByteBitPackingVectorBenchmarks.java": 92,
                "parquet-protobuf/src/main/java/org/apache/parquet/proto/ProtoConstants.java": 46,
                "parquet-protobuf/src/main/java/org/apache/parquet/proto/ProtoMessageConverter.java": 599,
                "parquet-protobuf/src/main/java/org/apache/parquet/proto/ProtoParquetInputFormat.java": 38,
                "parquet-protobuf/src/main/java/org/apache/parquet/proto/ProtoParquetOutputFormat.java": 52,
                "parquet-protobuf/src/main/java/org/apache/parquet/proto/ProtoParquetReader.java": 101,
                "parquet-protobuf/src/main/java/org/apache/parquet/proto/ProtoParquetWriter.java": 127,
                "parquet-protobuf/src/main/java/org/apache/parquet/proto/ProtoReadSupport.java": 97,
                "parquet-protobuf/src/main/java/org/apache/parquet/proto/ProtoRecordConverter.java": 100,
                "parquet-protobuf/src/main/java/org/apache/parquet/proto/ProtoRecordMaterializer.java": 47,
                "parquet-protobuf/src/main/java/org/apache/parquet/proto/ProtoSchemaConverter.java": 297,
                "parquet-protobuf/src/main/java/org/apache/parquet/proto/ProtoWriteSupport.java": 586,
                "parquet-protobuf/src/test/java/org/apache/parquet/proto/ProtoInputOutputFormatTest.java": 618,
                "parquet-protobuf/src/test/java/org/apache/parquet/proto/ProtoRecordConverterTest.java": 363,
                "parquet-protobuf/src/test/java/org/apache/parquet/proto/ProtoSchemaConverterTest.java": 539,
                "parquet-protobuf/src/test/java/org/apache/parquet/proto/ProtoSchemaEvolutionTest.java": 133,
                "parquet-protobuf/src/test/java/org/apache/parquet/proto/ProtoWriteSupportTest.java": 1204,
                "parquet-protobuf/src/test/java/org/apache/parquet/proto/TestUtils.java": 232,
                "parquet-protobuf/src/test/java/org/apache/parquet/proto/utils/ReadUsingMR.java": 94,
                "parquet-protobuf/src/test/java/org/apache/parquet/proto/utils/WriteUsingMR.java": 121,
                "parquet-thrift/src/main/java/org/apache/parquet/hadoop/thrift/AbstractThriftWriteSupport.java": 129,
                "parquet-thrift/src/main/java/org/apache/parquet/hadoop/thrift/ParquetThriftBytesOutputFormat.java": 96,
                "parquet-thrift/src/main/java/org/apache/parquet/hadoop/thrift/ParquetThriftInputFormat.java": 66,
                "parquet-thrift/src/main/java/org/apache/parquet/hadoop/thrift/ParquetThriftOutputFormat.java": 43,
                "parquet-thrift/src/main/java/org/apache/parquet/hadoop/thrift/TBaseWriteSupport.java": 70,
                "parquet-thrift/src/main/java/org/apache/parquet/hadoop/thrift/ThriftBytesWriteSupport.java": 196,
                "parquet-thrift/src/main/java/org/apache/parquet/hadoop/thrift/ThriftReadSupport.java": 289,
                "parquet-thrift/src/main/java/org/apache/parquet/hadoop/thrift/ThriftToParquetFileWriter.java": 125,
                "parquet-thrift/src/main/java/org/apache/parquet/hadoop/thrift/ThriftWriteSupport.java": 80,
                "parquet-thrift/src/main/java/org/apache/parquet/thrift/BufferedProtocolReadToWrite.java": 738,
                "parquet-thrift/src/main/java/org/apache/parquet/thrift/ConvertedField.java": 169,
                "parquet-thrift/src/main/java/org/apache/parquet/thrift/DecodingSchemaMismatchException.java": 30,
                "parquet-thrift/src/main/java/org/apache/parquet/thrift/FieldIgnoredHandler.java": 45,
                "parquet-thrift/src/main/java/org/apache/parquet/thrift/KeepOnlyFirstPrimitiveFilter.java": 44,
                "parquet-thrift/src/main/java/org/apache/parquet/thrift/ParquetProtocol.java": 282,
                "parquet-thrift/src/main/java/org/apache/parquet/thrift/ParquetReadProtocol.java": 164,
                "parquet-thrift/src/main/java/org/apache/parquet/thrift/ParquetWriteProtocol.java": 778,
                "parquet-thrift/src/main/java/org/apache/parquet/thrift/ProtocolPipe.java": 29,
                "parquet-thrift/src/main/java/org/apache/parquet/thrift/ProtocolReadToWrite.java": 142,
                "parquet-thrift/src/main/java/org/apache/parquet/thrift/SkippableException.java": 47,
                "parquet-thrift/src/main/java/org/apache/parquet/thrift/TBaseRecordConverter.java": 61,
                "parquet-thrift/src/main/java/org/apache/parquet/thrift/ThriftMetaData.java": 147,
                "parquet-thrift/src/main/java/org/apache/parquet/thrift/ThriftParquetReader.java": 139,
                "parquet-thrift/src/main/java/org/apache/parquet/thrift/ThriftParquetWriter.java": 52,
                "parquet-thrift/src/main/java/org/apache/parquet/thrift/ThriftReader.java": 28,
                "parquet-thrift/src/main/java/org/apache/parquet/thrift/ThriftRecordConverter.java": 954,
                "parquet-thrift/src/main/java/org/apache/parquet/thrift/ThriftSchemaConvertVisitor.java": 409,
                "parquet-thrift/src/main/java/org/apache/parquet/thrift/ThriftSchemaConverter.java": 226,
                "parquet-thrift/src/main/java/org/apache/parquet/thrift/pig/ParquetThriftStorer.java": 90,
                "parquet-thrift/src/main/java/org/apache/parquet/thrift/pig/TupleToThriftWriteSupport.java": 79,
                "parquet-thrift/src/main/java/org/apache/parquet/thrift/projection/FieldProjectionFilter.java": 62,
                "parquet-thrift/src/main/java/org/apache/parquet/thrift/projection/FieldsPath.java": 87,
                "parquet-thrift/src/main/java/org/apache/parquet/thrift/projection/StrictFieldProjectionFilter.java": 187,
                "parquet-thrift/src/main/java/org/apache/parquet/thrift/projection/ThriftProjectionException.java": 45,
                "parquet-thrift/src/main/java/org/apache/parquet/thrift/projection/amend/DefaultEventsVisitor.java": 228,
                "parquet-thrift/src/main/java/org/apache/parquet/thrift/projection/amend/DefaultProtocolEventsGenerator.java": 68,
                "parquet-thrift/src/main/java/org/apache/parquet/thrift/projection/amend/ProtocolEventsAmender.java": 171,
                "parquet-thrift/src/main/java/org/apache/parquet/thrift/projection/amend/ReadFieldBeginProtocol.java": 44,
                "parquet-thrift/src/main/java/org/apache/parquet/thrift/projection/deprecated/DeprecatedFieldProjectionFilter.java": 106,
                "parquet-thrift/src/main/java/org/apache/parquet/thrift/projection/deprecated/PathGlobPattern.java": 173,
                "parquet-thrift/src/main/java/org/apache/parquet/thrift/struct/CompatibilityChecker.java": 265,
                "parquet-thrift/src/main/java/org/apache/parquet/thrift/struct/CompatibilityRunner.java": 104,
                "parquet-thrift/src/main/java/org/apache/parquet/thrift/struct/JSON.java": 50,
                "parquet-thrift/src/main/java/org/apache/parquet/thrift/struct/ThriftField.java": 121,
                "parquet-thrift/src/main/java/org/apache/parquet/thrift/struct/ThriftType.java": 698,
                "parquet-thrift/src/main/java/org/apache/parquet/thrift/struct/ThriftTypeID.java": 108,
                "parquet-thrift/src/test/java/org/apache/parquet/hadoop/thrift/TestArrayCompatibility.java": 779,
                "parquet-thrift/src/test/java/org/apache/parquet/hadoop/thrift/TestBinary.java": 86,
                "parquet-thrift/src/test/java/org/apache/parquet/hadoop/thrift/TestCorruptThriftRecords.java": 213,
                "parquet-thrift/src/test/java/org/apache/parquet/hadoop/thrift/TestInputOutputFormat.java": 258,
                "parquet-thrift/src/test/java/org/apache/parquet/hadoop/thrift/TestParquetToThriftReadWriteAndProjection.java": 385,
                "parquet-thrift/src/test/java/org/apache/parquet/hadoop/thrift/TestThriftToParquetFileWriter.java": 360,
                "parquet-thrift/src/test/java/org/apache/parquet/thrift/TestParquetReadProtocol.java": 173,
                "parquet-thrift/src/test/java/org/apache/parquet/thrift/TestParquetWriteProtocol.java": 719,
                "parquet-thrift/src/test/java/org/apache/parquet/thrift/TestProtocolReadToWrite.java": 384,
                "parquet-thrift/src/test/java/org/apache/parquet/thrift/TestThriftMetaData.java": 56,
                "parquet-thrift/src/test/java/org/apache/parquet/thrift/TestThriftParquetReaderWriter.java": 83,
                "parquet-thrift/src/test/java/org/apache/parquet/thrift/TestThriftRecordConverter.java": 101,
                "parquet-thrift/src/test/java/org/apache/parquet/thrift/TestThriftSchemaConvertVisitor.java": 178,
                "parquet-thrift/src/test/java/org/apache/parquet/thrift/TestThriftSchemaConverter.java": 353,
                "parquet-thrift/src/test/java/org/apache/parquet/thrift/TestThriftSchemaConverterProjectUnion.java": 480,
                "parquet-thrift/src/test/java/org/apache/parquet/thrift/TestThriftToPigCompatibility.java": 171,
                "parquet-thrift/src/test/java/org/apache/parquet/thrift/pig/TestParquetThriftStorer.java": 82,
                "parquet-thrift/src/test/java/org/apache/parquet/thrift/projection/TestFieldsPath.java": 162,
                "parquet-thrift/src/test/java/org/apache/parquet/thrift/projection/TestStrictFieldProjectionFilter.java": 119,
                "parquet-thrift/src/test/java/org/apache/parquet/thrift/projection/deprecated/PathGlobPatternTest.java": 59,
                "parquet-thrift/src/test/java/org/apache/parquet/thrift/struct/CompatibilityCheckerTest.java": 132,
                "parquet-thrift/src/test/java/org/apache/parquet/thrift/struct/TestThriftType.java": 70
            },
            "is_test": true,
            "is_fix": false
        },
        "5c46f055890eb86652e9b573c686190769599c29": {
            "datetime": "2013-10-23T21:48:16+02:00",
            "summary": "initial commit",
            "message": "initial commit\n",
            "diff": {
                "dev/merge_parquet_pr.py": 393,
                "parquet-arrow/src/main/java/org/apache/parquet/arrow/schema/List3Levels.java": 77,
                "parquet-arrow/src/main/java/org/apache/parquet/arrow/schema/SchemaConverter.java": 705,
                "parquet-arrow/src/main/java/org/apache/parquet/arrow/schema/SchemaMapping.java": 201,
                "parquet-arrow/src/test/java/org/apache/parquet/arrow/schema/TestSchemaConverter.java": 530,
                "parquet-avro/src/main/java/org/apache/parquet/avro/AvroCompatRecordMaterializer.java": 46,
                "parquet-avro/src/main/java/org/apache/parquet/avro/AvroConverters.java": 333,
                "parquet-avro/src/main/java/org/apache/parquet/avro/AvroDataSupplier.java": 31,
                "parquet-avro/src/main/java/org/apache/parquet/avro/AvroIndexedRecordConverter.java": 535,
                "parquet-avro/src/main/java/org/apache/parquet/avro/AvroParquetInputFormat.java": 86,
                "parquet-avro/src/main/java/org/apache/parquet/avro/AvroParquetOutputFormat.java": 63,
                "parquet-avro/src/main/java/org/apache/parquet/avro/AvroParquetReader.java": 178,
                "parquet-avro/src/main/java/org/apache/parquet/avro/AvroParquetWriter.java": 193,
                "parquet-avro/src/main/java/org/apache/parquet/avro/AvroReadSupport.java": 180,
                "parquet-avro/src/main/java/org/apache/parquet/avro/AvroRecordConverter.java": 1093,
                "parquet-avro/src/main/java/org/apache/parquet/avro/AvroRecordMaterializer.java": 45,
                "parquet-avro/src/main/java/org/apache/parquet/avro/AvroSchemaConverter.java": 565,
                "parquet-avro/src/main/java/org/apache/parquet/avro/AvroWriteSupport.java": 711,
                "parquet-avro/src/main/java/org/apache/parquet/avro/GenericDataSupplier.java": 28,
                "parquet-avro/src/main/java/org/apache/parquet/avro/ParentValueContainer.java": 238,
                "parquet-avro/src/main/java/org/apache/parquet/avro/ReflectDataSupplier.java": 29,
                "parquet-avro/src/main/java/org/apache/parquet/avro/SpecificDataSupplier.java": 29,
                "parquet-avro/src/main/java/org/apache/parquet/avro/package-info.java": 174,
                "parquet-avro/src/test/java/org/apache/parquet/avro/AvroTestUtil.java": 136,
                "parquet-avro/src/test/java/org/apache/parquet/avro/TestArrayCompatibility.java": 1164,
                "parquet-avro/src/test/java/org/apache/parquet/avro/TestAvroDataSupplier.java": 43,
                "parquet-avro/src/test/java/org/apache/parquet/avro/TestAvroRecordConverter.java": 202,
                "parquet-avro/src/test/java/org/apache/parquet/avro/TestAvroSchemaConverter.java": 942,
                "parquet-avro/src/test/java/org/apache/parquet/avro/TestAvroWriteSupport.java": 61,
                "parquet-avro/src/test/java/org/apache/parquet/avro/TestBackwardCompatibility.java": 68,
                "parquet-avro/src/test/java/org/apache/parquet/avro/TestByteStreamSplitE2E.java": 114,
                "parquet-avro/src/test/java/org/apache/parquet/avro/TestCircularReferences.java": 387,
                "parquet-avro/src/test/java/org/apache/parquet/avro/TestGenericLogicalTypes.java": 296,
                "parquet-avro/src/test/java/org/apache/parquet/avro/TestInputOutputFormat.java": 145,
                "parquet-avro/src/test/java/org/apache/parquet/avro/TestReadWrite.java": 900,
                "parquet-avro/src/test/java/org/apache/parquet/avro/TestReadWriteOldListBehavior.java": 584,
                "parquet-avro/src/test/java/org/apache/parquet/avro/TestReflectInputOutputFormat.java": 496,
                "parquet-avro/src/test/java/org/apache/parquet/avro/TestReflectLogicalTypes.java": 999,
                "parquet-avro/src/test/java/org/apache/parquet/avro/TestReflectReadWrite.java": 240,
                "parquet-avro/src/test/java/org/apache/parquet/avro/TestSpecificInputOutputFormat.java": 287,
                "parquet-avro/src/test/java/org/apache/parquet/avro/TestSpecificReadWrite.java": 360,
                "parquet-avro/src/test/java/org/apache/parquet/avro/TestStringBehavior.java": 330,
                "parquet-benchmarks/src/main/java/org/apache/parquet/benchmarks/BenchmarkConstants.java": 42,
                "parquet-benchmarks/src/main/java/org/apache/parquet/benchmarks/BenchmarkFiles.java": 64,
                "parquet-benchmarks/src/main/java/org/apache/parquet/benchmarks/BenchmarkUtils.java": 46,
                "parquet-benchmarks/src/main/java/org/apache/parquet/benchmarks/DataGenerator.java": 137,
                "parquet-benchmarks/src/main/java/org/apache/parquet/benchmarks/FilteringBenchmarks.java": 430,
                "parquet-benchmarks/src/main/java/org/apache/parquet/benchmarks/NestedNullWritingBenchmarks.java": 156,
                "parquet-benchmarks/src/main/java/org/apache/parquet/benchmarks/PageChecksumDataGenerator.java": 106,
                "parquet-benchmarks/src/main/java/org/apache/parquet/benchmarks/PageChecksumReadBenchmarks.java": 196,
                "parquet-benchmarks/src/main/java/org/apache/parquet/benchmarks/PageChecksumWriteBenchmarks.java": 178,
                "parquet-benchmarks/src/main/java/org/apache/parquet/benchmarks/ReadBenchmarks.java": 131,
                "parquet-benchmarks/src/main/java/org/apache/parquet/benchmarks/WriteBenchmarks.java": 168,
                "parquet-cli/src/main/java/org/apache/parquet/cli/BaseCommand.java": 428,
                "parquet-cli/src/main/java/org/apache/parquet/cli/Command.java": 40,
                "parquet-cli/src/main/java/org/apache/parquet/cli/HadoopFileSystemURLStreamHandler.java": 79,
                "parquet-cli/src/main/java/org/apache/parquet/cli/Help.java": 153,
                "parquet-cli/src/main/java/org/apache/parquet/cli/Main.java": 196,
                "parquet-cli/src/main/java/org/apache/parquet/cli/Util.java": 272,
                "parquet-cli/src/main/java/org/apache/parquet/cli/commands/CSVSchemaCommand.java": 131,
                "parquet-cli/src/main/java/org/apache/parquet/cli/commands/CatCommand.java": 106,
                "parquet-cli/src/main/java/org/apache/parquet/cli/commands/CheckParquet251Command.java": 352,
                "parquet-cli/src/main/java/org/apache/parquet/cli/commands/ColumnMaskingCommand.java": 115,
                "parquet-cli/src/main/java/org/apache/parquet/cli/commands/ColumnSizeCommand.java": 137,
                "parquet-cli/src/main/java/org/apache/parquet/cli/commands/ConvertCSVCommand.java": 204,
                "parquet-cli/src/main/java/org/apache/parquet/cli/commands/ConvertCommand.java": 165,
                "parquet-cli/src/main/java/org/apache/parquet/cli/commands/ParquetMetadataCommand.java": 183,
                "parquet-cli/src/main/java/org/apache/parquet/cli/commands/PruneColumnsCommand.java": 82,
                "parquet-cli/src/main/java/org/apache/parquet/cli/commands/RewriteCommand.java": 131,
                "parquet-cli/src/main/java/org/apache/parquet/cli/commands/ScanCommand.java": 91,
                "parquet-cli/src/main/java/org/apache/parquet/cli/commands/SchemaCommand.java": 132,
                "parquet-cli/src/main/java/org/apache/parquet/cli/commands/ShowBloomFilterCommand.java": 133,
                "parquet-cli/src/main/java/org/apache/parquet/cli/commands/ShowColumnIndexCommand.java": 157,
                "parquet-cli/src/main/java/org/apache/parquet/cli/commands/ShowDictionaryCommand.java": 139,
                "parquet-cli/src/main/java/org/apache/parquet/cli/commands/ShowFooterCommand.java": 101,
                "parquet-cli/src/main/java/org/apache/parquet/cli/commands/ShowPagesCommand.java": 234,
                "parquet-cli/src/main/java/org/apache/parquet/cli/commands/ToAvroCommand.java": 134,
                "parquet-cli/src/main/java/org/apache/parquet/cli/commands/TransCompressionCommand.java": 101,
                "parquet-cli/src/main/java/org/apache/parquet/cli/csv/AvroCSV.java": 258,
                "parquet-cli/src/main/java/org/apache/parquet/cli/csv/AvroCSVReader.java": 121,
                "parquet-cli/src/main/java/org/apache/parquet/cli/csv/CSVProperties.java": 120,
                "parquet-cli/src/main/java/org/apache/parquet/cli/csv/RecordBuilder.java": 200,
                "parquet-cli/src/main/java/org/apache/parquet/cli/json/AvroJson.java": 631,
                "parquet-cli/src/main/java/org/apache/parquet/cli/json/AvroJsonReader.java": 77,
                "parquet-cli/src/main/java/org/apache/parquet/cli/rawpages/RawPagesReader.java": 92,
                "parquet-cli/src/main/java/org/apache/parquet/cli/util/Codecs.java": 52,
                "parquet-cli/src/main/java/org/apache/parquet/cli/util/Expressions.java": 395,
                "parquet-cli/src/main/java/org/apache/parquet/cli/util/Formats.java": 47,
                "parquet-cli/src/main/java/org/apache/parquet/cli/util/GetClassLoader.java": 39,
                "parquet-cli/src/main/java/org/apache/parquet/cli/util/RawUtils.java": 85,
                "parquet-cli/src/main/java/org/apache/parquet/cli/util/RecordException.java": 55,
                "parquet-cli/src/main/java/org/apache/parquet/cli/util/RuntimeIOException.java": 31,
                "parquet-cli/src/main/java/org/apache/parquet/cli/util/Schemas.java": 501,
                "parquet-cli/src/main/java/org/apache/parquet/cli/util/SeekableFSDataInputStream.java": 76,
                "parquet-cli/src/test/java/org/apache/parquet/cli/BaseCommandTest.java": 100,
                "parquet-cli/src/test/java/org/apache/parquet/cli/MainTest.java": 34,
                "parquet-cli/src/test/java/org/apache/parquet/cli/commands/AvroFileTest.java": 53,
                "parquet-cli/src/test/java/org/apache/parquet/cli/commands/CSVFileTest.java": 51,
                "parquet-cli/src/test/java/org/apache/parquet/cli/commands/CSVSchemaCommandTest.java": 39,
                "parquet-cli/src/test/java/org/apache/parquet/cli/commands/CatCommandTest.java": 38,
                "parquet-cli/src/test/java/org/apache/parquet/cli/commands/CheckParquet251CommandTest.java": 38,
                "parquet-cli/src/test/java/org/apache/parquet/cli/commands/ColumnSizeCommandTest.java": 91,
                "parquet-cli/src/test/java/org/apache/parquet/cli/commands/ConvertCSVCommandTest.java": 41,
                "parquet-cli/src/test/java/org/apache/parquet/cli/commands/ConvertCommandTest.java": 41,
                "parquet-cli/src/test/java/org/apache/parquet/cli/commands/FileTest.java": 58,
                "parquet-cli/src/test/java/org/apache/parquet/cli/commands/ParquetFileTest.java": 117,
                "parquet-cli/src/test/java/org/apache/parquet/cli/commands/ParquetMetadataCommandTest.java": 38,
                "parquet-cli/src/test/java/org/apache/parquet/cli/commands/RewriteCommandTest.java": 41,
                "parquet-cli/src/test/java/org/apache/parquet/cli/commands/ScanCommandTest.java": 38,
                "parquet-cli/src/test/java/org/apache/parquet/cli/commands/SchemaCommandTest.java": 68,
                "parquet-cli/src/test/java/org/apache/parquet/cli/commands/ShowBloomFilterCommandTest.java": 41,
                "parquet-cli/src/test/java/org/apache/parquet/cli/commands/ShowColumnIndexTest.java": 38,
                "parquet-cli/src/test/java/org/apache/parquet/cli/commands/ShowDictionaryCommandTest.java": 50,
                "parquet-cli/src/test/java/org/apache/parquet/cli/commands/ShowFooterCommandTest.java": 43,
                "parquet-cli/src/test/java/org/apache/parquet/cli/commands/ShowPagesCommandTest.java": 38,
                "parquet-cli/src/test/java/org/apache/parquet/cli/commands/ToAvroCommandTest.java": 113,
                "parquet-cli/src/test/java/org/apache/parquet/cli/commands/TransCompressionCommandTest.java": 45,
                "parquet-column/src/main/java/org/apache/parquet/CorruptDeltaByteArrays.java": 97,
                "parquet-column/src/main/java/org/apache/parquet/CorruptStatistics.java": 116,
                "parquet-column/src/main/java/org/apache/parquet/column/ColumnDescriptor.java": 156,
                "parquet-column/src/main/java/org/apache/parquet/column/ColumnProperty.java": 137,
                "parquet-column/src/main/java/org/apache/parquet/column/ColumnReadStore.java": 32,
                "parquet-column/src/main/java/org/apache/parquet/column/ColumnReader.java": 117,
                "parquet-column/src/main/java/org/apache/parquet/column/ColumnWriteStore.java": 75,
                "parquet-column/src/main/java/org/apache/parquet/column/ColumnWriter.java": 96,
                "parquet-column/src/main/java/org/apache/parquet/column/Dictionary.java": 63,
                "parquet-column/src/main/java/org/apache/parquet/column/Encoding.java": 309,
                "parquet-column/src/main/java/org/apache/parquet/column/EncodingStats.java": 157,
                "parquet-column/src/main/java/org/apache/parquet/column/MinMax.java": 56,
                "parquet-column/src/main/java/org/apache/parquet/column/ParquetProperties.java": 589,
                "parquet-column/src/main/java/org/apache/parquet/column/UnknownColumnException.java": 40,
                "parquet-column/src/main/java/org/apache/parquet/column/UnknownColumnTypeException.java": 41,
                "parquet-column/src/main/java/org/apache/parquet/column/ValuesType.java": 26,
                "parquet-column/src/main/java/org/apache/parquet/column/impl/ColumnReadStoreImpl.java": 104,
                "parquet-column/src/main/java/org/apache/parquet/column/impl/ColumnReaderBase.java": 790,
                "parquet-column/src/main/java/org/apache/parquet/column/impl/ColumnReaderImpl.java": 58,
                "parquet-column/src/main/java/org/apache/parquet/column/impl/ColumnWriteStoreBase.java": 273,
                "parquet-column/src/main/java/org/apache/parquet/column/impl/ColumnWriteStoreV1.java": 52,
                "parquet-column/src/main/java/org/apache/parquet/column/impl/ColumnWriteStoreV2.java": 46,
                "parquet-column/src/main/java/org/apache/parquet/column/impl/ColumnWriterBase.java": 408,
                "parquet-column/src/main/java/org/apache/parquet/column/impl/ColumnWriterV1.java": 68,
                "parquet-column/src/main/java/org/apache/parquet/column/impl/ColumnWriterV2.java": 94,
                "parquet-column/src/main/java/org/apache/parquet/column/impl/SynchronizingColumnReader.java": 111,
                "parquet-column/src/main/java/org/apache/parquet/column/page/DataPage.java": 72,
                "parquet-column/src/main/java/org/apache/parquet/column/page/DataPageV1.java": 127,
                "parquet-column/src/main/java/org/apache/parquet/column/page/DataPageV2.java": 207,
                "parquet-column/src/main/java/org/apache/parquet/column/page/DictionaryPage.java": 83,
                "parquet-column/src/main/java/org/apache/parquet/column/page/DictionaryPageReadStore.java": 36,
                "parquet-column/src/main/java/org/apache/parquet/column/page/Page.java": 62,
                "parquet-column/src/main/java/org/apache/parquet/column/page/PageReadStore.java": 64,
                "parquet-column/src/main/java/org/apache/parquet/column/page/PageReader.java": 40,
                "parquet-column/src/main/java/org/apache/parquet/column/page/PageWriteStore.java": 35,
                "parquet-column/src/main/java/org/apache/parquet/column/page/PageWriter.java": 102,
                "parquet-column/src/main/java/org/apache/parquet/column/statistics/BinaryStatistics.java": 188,
                "parquet-column/src/main/java/org/apache/parquet/column/statistics/BooleanStatistics.java": 147,
                "parquet-column/src/main/java/org/apache/parquet/column/statistics/DoubleStatistics.java": 147,
                "parquet-column/src/main/java/org/apache/parquet/column/statistics/FloatStatistics.java": 148,
                "parquet-column/src/main/java/org/apache/parquet/column/statistics/IntStatistics.java": 147,
                "parquet-column/src/main/java/org/apache/parquet/column/statistics/LongStatistics.java": 147,
                "parquet-column/src/main/java/org/apache/parquet/column/statistics/Statistics.java": 539,
                "parquet-column/src/main/java/org/apache/parquet/column/statistics/StatisticsClassException.java": 44,
                "parquet-column/src/main/java/org/apache/parquet/column/values/RequiresFallback.java": 51,
                "parquet-column/src/main/java/org/apache/parquet/column/values/RequiresPreviousReader.java": 23,
                "parquet-column/src/main/java/org/apache/parquet/column/values/ValuesReader.java": 205,
                "parquet-column/src/main/java/org/apache/parquet/column/values/ValuesWriter.java": 136,
                "parquet-column/src/main/java/org/apache/parquet/column/values/bitpacking/BitPackingValuesReader.java": 84,
                "parquet-column/src/main/java/org/apache/parquet/column/values/bitpacking/BitPackingValuesWriter.java": 130,
                "parquet-column/src/main/java/org/apache/parquet/column/values/bitpacking/ByteBitPackingValuesReader.java": 99,
                "parquet-column/src/main/java/org/apache/parquet/column/values/bitpacking/ByteBitPackingValuesWriter.java": 86,
                "parquet-column/src/main/java/org/apache/parquet/column/values/bitpacking/DevNullValuesWriter.java": 89,
                "parquet-column/src/main/java/org/apache/parquet/column/values/bloomfilter/AdaptiveBlockSplitBloomFilter.java": 305,
                "parquet-column/src/main/java/org/apache/parquet/column/values/bloomfilter/BlockSplitBloomFilter.java": 424,
                "parquet-column/src/main/java/org/apache/parquet/column/values/bloomfilter/BloomFilter.java": 203,
                "parquet-column/src/main/java/org/apache/parquet/column/values/bloomfilter/BloomFilterWriteStore.java": 35,
                "parquet-column/src/main/java/org/apache/parquet/column/values/bloomfilter/BloomFilterWriter.java": 31,
                "parquet-column/src/main/java/org/apache/parquet/column/values/bloomfilter/HashFunction.java": 41,
                "parquet-column/src/main/java/org/apache/parquet/column/values/bloomfilter/XxHash.java": 40,
                "parquet-column/src/main/java/org/apache/parquet/column/values/bytestreamsplit/ByteStreamSplitValuesReader.java": 111,
                "parquet-column/src/main/java/org/apache/parquet/column/values/bytestreamsplit/ByteStreamSplitValuesReaderForDouble.java": 37,
                "parquet-column/src/main/java/org/apache/parquet/column/values/bytestreamsplit/ByteStreamSplitValuesReaderForFloat.java": 37,
                "parquet-column/src/main/java/org/apache/parquet/column/values/bytestreamsplit/ByteStreamSplitValuesWriter.java": 142,
                "parquet-column/src/main/java/org/apache/parquet/column/values/delta/DeltaBinaryPackingConfig.java": 55,
                "parquet-column/src/main/java/org/apache/parquet/column/values/delta/DeltaBinaryPackingValuesReader.java": 171,
                "parquet-column/src/main/java/org/apache/parquet/column/values/delta/DeltaBinaryPackingValuesWriter.java": 136,
                "parquet-column/src/main/java/org/apache/parquet/column/values/delta/DeltaBinaryPackingValuesWriterForInteger.java": 196,
                "parquet-column/src/main/java/org/apache/parquet/column/values/delta/DeltaBinaryPackingValuesWriterForLong.java": 198,
                "parquet-column/src/main/java/org/apache/parquet/column/values/deltalengthbytearray/DeltaLengthByteArrayValuesReader.java": 80,
                "parquet-column/src/main/java/org/apache/parquet/column/values/deltalengthbytearray/DeltaLengthByteArrayValuesWriter.java": 115,
                "parquet-column/src/main/java/org/apache/parquet/column/values/deltastrings/DeltaByteArrayReader.java": 96,
                "parquet-column/src/main/java/org/apache/parquet/column/values/deltastrings/DeltaByteArrayWriter.java": 100,
                "parquet-column/src/main/java/org/apache/parquet/column/values/dictionary/DictionaryValuesReader.java": 131,
                "parquet-column/src/main/java/org/apache/parquet/column/values/dictionary/DictionaryValuesWriter.java": 597,
                "parquet-column/src/main/java/org/apache/parquet/column/values/dictionary/IntList.java": 159,
                "parquet-column/src/main/java/org/apache/parquet/column/values/dictionary/PlainValuesDictionary.java": 313,
                "parquet-column/src/main/java/org/apache/parquet/column/values/factory/DefaultV1ValuesWriterFactory.java": 122,
                "parquet-column/src/main/java/org/apache/parquet/column/values/factory/DefaultV2ValuesWriterFactory.java": 126,
                "parquet-column/src/main/java/org/apache/parquet/column/values/factory/DefaultValuesWriterFactory.java": 87,
                "parquet-column/src/main/java/org/apache/parquet/column/values/factory/ValuesWriterFactory.java": 52,
                "parquet-column/src/main/java/org/apache/parquet/column/values/fallback/FallbackValuesWriter.java": 204,
                "parquet-column/src/main/java/org/apache/parquet/column/values/plain/BinaryPlainValuesReader.java": 63,
                "parquet-column/src/main/java/org/apache/parquet/column/values/plain/BooleanPlainValuesReader.java": 73,
                "parquet-column/src/main/java/org/apache/parquet/column/values/plain/BooleanPlainValuesWriter.java": 81,
                "parquet-column/src/main/java/org/apache/parquet/column/values/plain/FixedLenByteArrayPlainValuesReader.java": 72,
                "parquet-column/src/main/java/org/apache/parquet/column/values/plain/FixedLenByteArrayPlainValuesWriter.java": 106,
                "parquet-column/src/main/java/org/apache/parquet/column/values/plain/PlainValuesReader.java": 139,
                "parquet-column/src/main/java/org/apache/parquet/column/values/plain/PlainValuesWriter.java": 148,
                "parquet-column/src/main/java/org/apache/parquet/column/values/rle/RunLengthBitPackingHybridDecoder.java": 107,
                "parquet-column/src/main/java/org/apache/parquet/column/values/rle/RunLengthBitPackingHybridEncoder.java": 293,
                "parquet-column/src/main/java/org/apache/parquet/column/values/rle/RunLengthBitPackingHybridValuesReader.java": 68,
                "parquet-column/src/main/java/org/apache/parquet/column/values/rle/RunLengthBitPackingHybridValuesWriter.java": 95,
                "parquet-column/src/main/java/org/apache/parquet/column/values/rle/ZeroIntegerValuesReader.java": 50,
                "parquet-column/src/main/java/org/apache/parquet/example/DummyRecordConverter.java": 114,
                "parquet-column/src/main/java/org/apache/parquet/example/Paper.java": 164,
                "parquet-column/src/main/java/org/apache/parquet/example/data/Group.java": 147,
                "parquet-column/src/main/java/org/apache/parquet/example/data/GroupFactory.java": 25,
                "parquet-column/src/main/java/org/apache/parquet/example/data/GroupValueSource.java": 89,
                "parquet-column/src/main/java/org/apache/parquet/example/data/GroupWriter.java": 62,
                "parquet-column/src/main/java/org/apache/parquet/example/data/simple/BinaryValue.java": 52,
                "parquet-column/src/main/java/org/apache/parquet/example/data/simple/BooleanValue.java": 44,
                "parquet-column/src/main/java/org/apache/parquet/example/data/simple/DoubleValue.java": 45,
                "parquet-column/src/main/java/org/apache/parquet/example/data/simple/FloatValue.java": 45,
                "parquet-column/src/main/java/org/apache/parquet/example/data/simple/Int96Value.java": 46,
                "parquet-column/src/main/java/org/apache/parquet/example/data/simple/IntegerValue.java": 46,
                "parquet-column/src/main/java/org/apache/parquet/example/data/simple/LongValue.java": 45,
                "parquet-column/src/main/java/org/apache/parquet/example/data/simple/NanoTime.java": 80,
                "parquet-column/src/main/java/org/apache/parquet/example/data/simple/Primitive.java": 60,
                "parquet-column/src/main/java/org/apache/parquet/example/data/simple/SimpleGroup.java": 236,
                "parquet-column/src/main/java/org/apache/parquet/example/data/simple/SimpleGroupFactory.java": 38,
                "parquet-column/src/main/java/org/apache/parquet/example/data/simple/convert/GroupRecordConverter.java": 57,
                "parquet-column/src/main/java/org/apache/parquet/example/data/simple/convert/SimpleGroupConverter.java": 67,
                "parquet-column/src/main/java/org/apache/parquet/example/data/simple/convert/SimplePrimitiveConverter.java": 88,
                "parquet-column/src/main/java/org/apache/parquet/filter/AndRecordFilter.java": 65,
                "parquet-column/src/main/java/org/apache/parquet/filter/ColumnPredicates.java": 191,
                "parquet-column/src/main/java/org/apache/parquet/filter/ColumnRecordFilter.java": 76,
                "parquet-column/src/main/java/org/apache/parquet/filter/NotRecordFilter.java": 60,
                "parquet-column/src/main/java/org/apache/parquet/filter/OrRecordFilter.java": 62,
                "parquet-column/src/main/java/org/apache/parquet/filter/PagedRecordFilter.java": 65,
                "parquet-column/src/main/java/org/apache/parquet/filter/RecordFilter.java": 33,
                "parquet-column/src/main/java/org/apache/parquet/filter/UnboundRecordFilter.java": 37,
                "parquet-column/src/main/java/org/apache/parquet/filter2/compat/FilterCompat.java": 181,
                "parquet-column/src/main/java/org/apache/parquet/filter2/predicate/FilterApi.java": 328,
                "parquet-column/src/main/java/org/apache/parquet/filter2/predicate/FilterPredicate.java": 84,
                "parquet-column/src/main/java/org/apache/parquet/filter2/predicate/LogicalInverseRewriter.java": 126,
                "parquet-column/src/main/java/org/apache/parquet/filter2/predicate/LogicalInverter.java": 120,
                "parquet-column/src/main/java/org/apache/parquet/filter2/predicate/Operators.java": 587,
                "parquet-column/src/main/java/org/apache/parquet/filter2/predicate/PrimitiveToBoxedClass.java": 50,
                "parquet-column/src/main/java/org/apache/parquet/filter2/predicate/SchemaCompatibilityValidator.java": 204,
                "parquet-column/src/main/java/org/apache/parquet/filter2/predicate/Statistics.java": 93,
                "parquet-column/src/main/java/org/apache/parquet/filter2/predicate/UserDefinedPredicate.java": 131,
                "parquet-column/src/main/java/org/apache/parquet/filter2/predicate/ValidTypeMap.java": 128,
                "parquet-column/src/main/java/org/apache/parquet/filter2/recordlevel/FilteringGroupConverter.java": 112,
                "parquet-column/src/main/java/org/apache/parquet/filter2/recordlevel/FilteringPrimitiveConverter.java": 109,
                "parquet-column/src/main/java/org/apache/parquet/filter2/recordlevel/FilteringRecordMaterializer.java": 116,
                "parquet-column/src/main/java/org/apache/parquet/filter2/recordlevel/IncrementallyUpdatedFilterPredicate.java": 166,
                "parquet-column/src/main/java/org/apache/parquet/filter2/recordlevel/IncrementallyUpdatedFilterPredicateBuilderBase.java": 116,
                "parquet-column/src/main/java/org/apache/parquet/filter2/recordlevel/IncrementallyUpdatedFilterPredicateEvaluator.java": 62,
                "parquet-column/src/main/java/org/apache/parquet/filter2/recordlevel/IncrementallyUpdatedFilterPredicateResetter.java": 59,
                "parquet-column/src/main/java/org/apache/parquet/internal/column/columnindex/BinaryColumnIndexBuilder.java": 140,
                "parquet-column/src/main/java/org/apache/parquet/internal/column/columnindex/BinaryTruncator.java": 221,
                "parquet-column/src/main/java/org/apache/parquet/internal/column/columnindex/BooleanColumnIndexBuilder.java": 133,
                "parquet-column/src/main/java/org/apache/parquet/internal/column/columnindex/BoundaryOrder.java": 384,
                "parquet-column/src/main/java/org/apache/parquet/internal/column/columnindex/ColumnIndex.java": 60,
                "parquet-column/src/main/java/org/apache/parquet/internal/column/columnindex/ColumnIndexBuilder.java": 686,
                "parquet-column/src/main/java/org/apache/parquet/internal/column/columnindex/DoubleColumnIndexBuilder.java": 155,
                "parquet-column/src/main/java/org/apache/parquet/internal/column/columnindex/FloatColumnIndexBuilder.java": 155,
                "parquet-column/src/main/java/org/apache/parquet/internal/column/columnindex/IndexIterator.java": 89,
                "parquet-column/src/main/java/org/apache/parquet/internal/column/columnindex/IntColumnIndexBuilder.java": 136,
                "parquet-column/src/main/java/org/apache/parquet/internal/column/columnindex/LongColumnIndexBuilder.java": 136,
                "parquet-column/src/main/java/org/apache/parquet/internal/column/columnindex/OffsetIndex.java": 73,
                "parquet-column/src/main/java/org/apache/parquet/internal/column/columnindex/OffsetIndexBuilder.java": 193,
                "parquet-column/src/main/java/org/apache/parquet/internal/filter2/columnindex/ColumnIndexFilter.java": 217,
                "parquet-column/src/main/java/org/apache/parquet/internal/filter2/columnindex/ColumnIndexStore.java": 55,
                "parquet-column/src/main/java/org/apache/parquet/internal/filter2/columnindex/RowRanges.java": 318,
                "parquet-column/src/main/java/org/apache/parquet/io/BaseRecordReader.java": 149,
                "parquet-column/src/main/java/org/apache/parquet/io/ColumnIO.java": 138,
                "parquet-column/src/main/java/org/apache/parquet/io/ColumnIOFactory.java": 174,
                "parquet-column/src/main/java/org/apache/parquet/io/CompilationException.java": 44,
                "parquet-column/src/main/java/org/apache/parquet/io/EmptyRecordReader.java": 48,
                "parquet-column/src/main/java/org/apache/parquet/io/FilteredRecordReader.java": 97,
                "parquet-column/src/main/java/org/apache/parquet/io/GroupColumnIO.java": 121,
                "parquet-column/src/main/java/org/apache/parquet/io/InvalidFileOffsetException.java": 29,
                "parquet-column/src/main/java/org/apache/parquet/io/InvalidRecordException.java": 45,
                "parquet-column/src/main/java/org/apache/parquet/io/MessageColumnIO.java": 534,
                "parquet-column/src/main/java/org/apache/parquet/io/ParquetDecodingException.java": 44,
                "parquet-column/src/main/java/org/apache/parquet/io/ParquetEncodingException.java": 44,
                "parquet-column/src/main/java/org/apache/parquet/io/PrimitiveColumnIO.java": 108,
                "parquet-column/src/main/java/org/apache/parquet/io/RecordConsumerLoggingWrapper.java": 187,
                "parquet-column/src/main/java/org/apache/parquet/io/RecordReader.java": 43,
                "parquet-column/src/main/java/org/apache/parquet/io/RecordReaderImplementation.java": 474,
                "parquet-column/src/main/java/org/apache/parquet/io/ValidatingRecordConsumer.java": 247,
                "parquet-column/src/main/java/org/apache/parquet/io/api/Binary.java": 737,
                "parquet-column/src/main/java/org/apache/parquet/io/api/Converter.java": 37,
                "parquet-column/src/main/java/org/apache/parquet/io/api/GroupConverter.java": 55,
                "parquet-column/src/main/java/org/apache/parquet/io/api/PrimitiveConverter.java": 108,
                "parquet-column/src/main/java/org/apache/parquet/io/api/RecordConsumer.java": 134,
                "parquet-column/src/main/java/org/apache/parquet/io/api/RecordMaterializer.java": 73,
                "parquet-column/src/main/java/org/apache/parquet/schema/ColumnOrder.java": 97,
                "parquet-column/src/main/java/org/apache/parquet/schema/ConversionPatterns.java": 133,
                "parquet-column/src/main/java/org/apache/parquet/schema/DecimalMetadata.java": 62,
                "parquet-column/src/main/java/org/apache/parquet/schema/GroupType.java": 421,
                "parquet-column/src/main/java/org/apache/parquet/schema/IncompatibleSchemaModificationException.java": 46,
                "parquet-column/src/main/java/org/apache/parquet/schema/InvalidSchemaException.java": 31,
                "parquet-column/src/main/java/org/apache/parquet/schema/LogicalTypeAnnotation.java": 1064,
                "parquet-column/src/main/java/org/apache/parquet/schema/MessageType.java": 145,
                "parquet-column/src/main/java/org/apache/parquet/schema/MessageTypeParser.java": 243,
                "parquet-column/src/main/java/org/apache/parquet/schema/OriginalType.java": 48,
                "parquet-column/src/main/java/org/apache/parquet/schema/PrimitiveComparator.java": 279,
                "parquet-column/src/main/java/org/apache/parquet/schema/PrimitiveStringifier.java": 451,
                "parquet-column/src/main/java/org/apache/parquet/schema/PrimitiveType.java": 797,
                "parquet-column/src/main/java/org/apache/parquet/schema/Type.java": 366,
                "parquet-column/src/main/java/org/apache/parquet/schema/TypeConverter.java": 53,
                "parquet-column/src/main/java/org/apache/parquet/schema/TypeUtil.java": 45,
                "parquet-column/src/main/java/org/apache/parquet/schema/TypeVisitor.java": 43,
                "parquet-column/src/main/java/org/apache/parquet/schema/Types.java": 1542,
                "parquet-column/src/test/java/org/apache/parquet/CorruptStatisticsTest.java": 92,
                "parquet-column/src/test/java/org/apache/parquet/FixedBinaryTestUtils.java": 96,
                "parquet-column/src/test/java/org/apache/parquet/ResourceIntensiveTestRule.java": 58,
                "parquet-column/src/test/java/org/apache/parquet/column/TestColumnDescriptor.java": 52,
                "parquet-column/src/test/java/org/apache/parquet/column/TestEncodingStats.java": 202,
                "parquet-column/src/test/java/org/apache/parquet/column/impl/TestColumnReaderImpl.java": 131,
                "parquet-column/src/test/java/org/apache/parquet/column/impl/TestCorruptDeltaByteArrays.java": 269,
                "parquet-column/src/test/java/org/apache/parquet/column/mem/TestMemColumn.java": 246,
                "parquet-column/src/test/java/org/apache/parquet/column/mem/TestMemPageStore.java": 61,
                "parquet-column/src/test/java/org/apache/parquet/column/page/mem/MemPageReader.java": 67,
                "parquet-column/src/test/java/org/apache/parquet/column/page/mem/MemPageStore.java": 78,
                "parquet-column/src/test/java/org/apache/parquet/column/page/mem/MemPageWriter.java": 117,
                "parquet-column/src/test/java/org/apache/parquet/column/statistics/TestStatistics.java": 789,
                "parquet-column/src/test/java/org/apache/parquet/column/values/TestValuesReaderImpl.java": 148,
                "parquet-column/src/test/java/org/apache/parquet/column/values/Utils.java": 76,
                "parquet-column/src/test/java/org/apache/parquet/column/values/bitpacking/BitPackingPerfTest.java": 103,
                "parquet-column/src/test/java/org/apache/parquet/column/values/bitpacking/TestBitPackingColumn.java": 232,
                "parquet-column/src/test/java/org/apache/parquet/column/values/bloomfilter/TestBlockSplitBloomFilter.java": 325,
                "parquet-column/src/test/java/org/apache/parquet/column/values/bytestreamsplit/ByteStreamSplitValuesEndToEndTest.java": 111,
                "parquet-column/src/test/java/org/apache/parquet/column/values/bytestreamsplit/ByteStreamSplitValuesReaderTest.java": 193,
                "parquet-column/src/test/java/org/apache/parquet/column/values/bytestreamsplit/ByteStreamSplitValuesWriterTest.java": 189,
                "parquet-column/src/test/java/org/apache/parquet/column/values/delta/DeltaBinaryPackingValuesWriterForIntegerTest.java": 294,
                "parquet-column/src/test/java/org/apache/parquet/column/values/delta/DeltaBinaryPackingValuesWriterForLongTest.java": 291,
                "parquet-column/src/test/java/org/apache/parquet/column/values/delta/benchmark/BenchMarkTest.java": 41,
                "parquet-column/src/test/java/org/apache/parquet/column/values/delta/benchmark/BenchmarkIntegerOutputSize.java": 107,
                "parquet-column/src/test/java/org/apache/parquet/column/values/delta/benchmark/BenchmarkReadingRandomIntegers.java": 102,
                "parquet-column/src/test/java/org/apache/parquet/column/values/delta/benchmark/RandomWritingBenchmarkTest.java": 76,
                "parquet-column/src/test/java/org/apache/parquet/column/values/delta/benchmark/SmallRangeWritingBenchmarkTest.java": 49,
                "parquet-column/src/test/java/org/apache/parquet/column/values/deltalengthbytearray/TestDeltaLengthByteArray.java": 103,
                "parquet-column/src/test/java/org/apache/parquet/column/values/deltalengthbytearray/benchmark/BenchmarkDeltaLengthByteArray.java": 73,
                "parquet-column/src/test/java/org/apache/parquet/column/values/deltastrings/TestDeltaByteArray.java": 130,
                "parquet-column/src/test/java/org/apache/parquet/column/values/deltastrings/benchmark/BenchmarkDeltaByteArray.java": 103,
                "parquet-column/src/test/java/org/apache/parquet/column/values/dictionary/IntListTest.java": 84,
                "parquet-column/src/test/java/org/apache/parquet/column/values/dictionary/TestDictionary.java": 661,
                "parquet-column/src/test/java/org/apache/parquet/column/values/factory/DefaultValuesWriterFactoryTest.java": 546,
                "parquet-column/src/test/java/org/apache/parquet/column/values/rle/RunLengthBitPackingHybridIntegrationTest.java": 86,
                "parquet-column/src/test/java/org/apache/parquet/column/values/rle/TestRunLengthBitPackingHybridEncoder.java": 329,
                "parquet-column/src/test/java/org/apache/parquet/filter2/predicate/DummyUdp.java": 37,
                "parquet-column/src/test/java/org/apache/parquet/filter2/predicate/TestFilterApiMethods.java": 172,
                "parquet-column/src/test/java/org/apache/parquet/filter2/predicate/TestLogicalInverseRewriter.java": 103,
                "parquet-column/src/test/java/org/apache/parquet/filter2/predicate/TestLogicalInverter.java": 94,
                "parquet-column/src/test/java/org/apache/parquet/filter2/predicate/TestSchemaCompatibilityValidator.java": 142,
                "parquet-column/src/test/java/org/apache/parquet/filter2/predicate/TestValidTypeMap.java": 98,
                "parquet-column/src/test/java/org/apache/parquet/filter2/recordlevel/TestIncrementallyUpdatedFilterPredicateEvaluator.java": 209,
                "parquet-column/src/test/java/org/apache/parquet/filter2/recordlevel/TestIncrementallyUpdatedFilterPredicateResetter.java": 69,
                "parquet-column/src/test/java/org/apache/parquet/filter2/recordlevel/TestValueInspector.java": 97,
                "parquet-column/src/test/java/org/apache/parquet/internal/column/columnindex/TestBinaryTruncator.java": 285,
                "parquet-column/src/test/java/org/apache/parquet/internal/column/columnindex/TestBoundaryOrder.java": 543,
                "parquet-column/src/test/java/org/apache/parquet/internal/column/columnindex/TestColumnIndexBuilder.java": 1728,
                "parquet-column/src/test/java/org/apache/parquet/internal/column/columnindex/TestIndexIterator.java": 63,
                "parquet-column/src/test/java/org/apache/parquet/internal/column/columnindex/TestOffsetIndexBuilder.java": 111,
                "parquet-column/src/test/java/org/apache/parquet/internal/filter2/columnindex/TestColumnIndexFilter.java": 555,
                "parquet-column/src/test/java/org/apache/parquet/internal/filter2/columnindex/TestRowRanges.java": 155,
                "parquet-column/src/test/java/org/apache/parquet/io/ConverterConsumer.java": 125,
                "parquet-column/src/test/java/org/apache/parquet/io/ExpectationValidatingConverter.java": 169,
                "parquet-column/src/test/java/org/apache/parquet/io/ExpectationValidatingRecordConsumer.java": 112,
                "parquet-column/src/test/java/org/apache/parquet/io/PerfTest.java": 128,
                "parquet-column/src/test/java/org/apache/parquet/io/TestColumnIO.java": 709,
                "parquet-column/src/test/java/org/apache/parquet/io/TestFiltered.java": 278,
                "parquet-column/src/test/java/org/apache/parquet/io/api/TestBinary.java": 271,
                "parquet-column/src/test/java/org/apache/parquet/parser/TestParquetParser.java": 374,
                "parquet-column/src/test/java/org/apache/parquet/schema/TestMessageType.java": 247,
                "parquet-column/src/test/java/org/apache/parquet/schema/TestPrimitiveComparator.java": 330,
                "parquet-column/src/test/java/org/apache/parquet/schema/TestPrimitiveStringifier.java": 391,
                "parquet-column/src/test/java/org/apache/parquet/schema/TestRepetitionType.java": 36,
                "parquet-column/src/test/java/org/apache/parquet/schema/TestTypeBuilders.java": 1372,
                "parquet-column/src/test/java/org/apache/parquet/schema/TestTypeBuildersWithLogicalTypes.java": 422,
                "parquet-column/src/test/java/org/apache/parquet/schema/TestTypeUtil.java": 80,
                "parquet-common/src/main/java/org/apache/parquet/Closeables.java": 60,
                "parquet-common/src/main/java/org/apache/parquet/Exceptions.java": 39,
                "parquet-common/src/main/java/org/apache/parquet/Files.java": 54,
                "parquet-common/src/main/java/org/apache/parquet/IOExceptionUtils.java": 45,
                "parquet-common/src/main/java/org/apache/parquet/Ints.java": 44,
                "parquet-common/src/main/java/org/apache/parquet/Log.java": 146,
                "parquet-common/src/main/java/org/apache/parquet/OutputStreamCloseException.java": 46,
                "parquet-common/src/main/java/org/apache/parquet/ParquetRuntimeException.java": 42,
                "parquet-common/src/main/java/org/apache/parquet/Preconditions.java": 251,
                "parquet-common/src/main/java/org/apache/parquet/SemanticVersion.java": 293,
                "parquet-common/src/main/java/org/apache/parquet/ShouldNeverHappenException.java": 40,
                "parquet-common/src/main/java/org/apache/parquet/Strings.java": 132,
                "parquet-common/src/main/java/org/apache/parquet/VersionParser.java": 129,
                "parquet-common/src/main/java/org/apache/parquet/bytes/ByteBufferAllocator.java": 40,
                "parquet-common/src/main/java/org/apache/parquet/bytes/ByteBufferInputStream.java": 160,
                "parquet-common/src/main/java/org/apache/parquet/bytes/BytesInput.java": 545,
                "parquet-common/src/main/java/org/apache/parquet/bytes/BytesUtils.java": 335,
                "parquet-common/src/main/java/org/apache/parquet/bytes/CapacityByteArrayOutputStream.java": 352,
                "parquet-common/src/main/java/org/apache/parquet/bytes/ConcatenatingByteArrayCollector.java": 63,
                "parquet-common/src/main/java/org/apache/parquet/bytes/DirectByteBufferAllocator.java": 43,
                "parquet-common/src/main/java/org/apache/parquet/bytes/HeapByteBufferAllocator.java": 44,
                "parquet-common/src/main/java/org/apache/parquet/bytes/LittleEndianDataInputStream.java": 421,
                "parquet-common/src/main/java/org/apache/parquet/bytes/LittleEndianDataOutputStream.java": 218,
                "parquet-common/src/main/java/org/apache/parquet/bytes/MultiBufferInputStream.java": 382,
                "parquet-common/src/main/java/org/apache/parquet/bytes/SingleBufferInputStream.java": 177,
                "parquet-common/src/main/java/org/apache/parquet/compression/CompressionCodecFactory.java": 47,
                "parquet-common/src/main/java/org/apache/parquet/glob/GlobExpander.java": 129,
                "parquet-common/src/main/java/org/apache/parquet/glob/GlobNode.java": 157,
                "parquet-common/src/main/java/org/apache/parquet/glob/GlobParser.java": 224,
                "parquet-common/src/main/java/org/apache/parquet/glob/WildcardPath.java": 121,
                "parquet-common/src/main/java/org/apache/parquet/hadoop/codec/CompressionCodecNotSupportedException.java": 38,
                "parquet-common/src/main/java/org/apache/parquet/hadoop/metadata/Canonicalizer.java": 61,
                "parquet-common/src/main/java/org/apache/parquet/hadoop/metadata/ColumnPath.java": 88,
                "parquet-common/src/main/java/org/apache/parquet/hadoop/metadata/CompressionCodecName.java": 99,
                "parquet-common/src/main/java/org/apache/parquet/io/DelegatingPositionOutputStream.java": 63,
                "parquet-common/src/main/java/org/apache/parquet/io/DelegatingSeekableInputStream.java": 171,
                "parquet-common/src/main/java/org/apache/parquet/io/InputFile.java": 44,
                "parquet-common/src/main/java/org/apache/parquet/io/LocalInputFile.java": 102,
                "parquet-common/src/main/java/org/apache/parquet/io/LocalOutputFile.java": 107,
                "parquet-common/src/main/java/org/apache/parquet/io/OutputFile.java": 62,
                "parquet-common/src/main/java/org/apache/parquet/io/PositionOutputStream.java": 39,
                "parquet-common/src/main/java/org/apache/parquet/io/SeekableInputStream.java": 108,
                "parquet-common/src/main/java/org/apache/parquet/util/DynConstructors.java": 263,
                "parquet-common/src/main/java/org/apache/parquet/util/DynMethods.java": 506,
                "parquet-common/src/test/java/org/apache/parquet/SemanticVersionTest.java": 114,
                "parquet-common/src/test/java/org/apache/parquet/TestPreconditions.java": 246,
                "parquet-common/src/test/java/org/apache/parquet/TestUtils.java": 70,
                "parquet-common/src/test/java/org/apache/parquet/VersionTest.java": 100,
                "parquet-common/src/test/java/org/apache/parquet/bytes/TestByteBufferInputStreams.java": 589,
                "parquet-common/src/test/java/org/apache/parquet/bytes/TestBytesUtil.java": 49,
                "parquet-common/src/test/java/org/apache/parquet/bytes/TestDeprecatedBufferInputStream.java": 152,
                "parquet-common/src/test/java/org/apache/parquet/bytes/TestMultiBufferInputStream.java": 141,
                "parquet-common/src/test/java/org/apache/parquet/bytes/TestSingleBufferInputStream.java": 130,
                "parquet-common/src/test/java/org/apache/parquet/glob/TestGlob.java": 144,
                "parquet-common/src/test/java/org/apache/parquet/glob/TestWildcardPath.java": 125,
                "parquet-common/src/test/java/org/apache/parquet/io/MockInputStream.java": 56,
                "parquet-common/src/test/java/org/apache/parquet/io/TestDelegatingSeekableInputStream.java": 844,
                "parquet-common/src/test/java/org/apache/parquet/io/TestLocalInputOutput.java": 92,
                "parquet-common/src/test/java/org/apache/parquet/util/Concatenator.java": 82,
                "parquet-common/src/test/java/org/apache/parquet/util/TestDynConstructors.java": 165,
                "parquet-common/src/test/java/org/apache/parquet/util/TestDynMethods.java": 315,
                "parquet-encoding/src/main/java/org/apache/parquet/column/values/bitpacking/BitPacking.java": 717,
                "parquet-encoding/src/main/java/org/apache/parquet/column/values/bitpacking/ByteBasedBitPackingEncoder.java": 142,
                "parquet-encoding/src/main/java/org/apache/parquet/column/values/bitpacking/BytePacker.java": 141,
                "parquet-encoding/src/main/java/org/apache/parquet/column/values/bitpacking/BytePackerFactory.java": 25,
                "parquet-encoding/src/main/java/org/apache/parquet/column/values/bitpacking/BytePackerForLong.java": 109,
                "parquet-encoding/src/main/java/org/apache/parquet/column/values/bitpacking/BytePackerForLongFactory.java": 25,
                "parquet-encoding/src/main/java/org/apache/parquet/column/values/bitpacking/IntPacker.java": 63,
                "parquet-encoding/src/main/java/org/apache/parquet/column/values/bitpacking/IntPackerFactory.java": 25,
                "parquet-encoding/src/main/java/org/apache/parquet/column/values/bitpacking/Packer.java": 137,
                "parquet-encoding/src/test/java/org/apache/parquet/bytes/TestBytesInput.java": 42,
                "parquet-encoding/src/test/java/org/apache/parquet/bytes/TestCapacityByteArrayOutputStream.java": 242,
                "parquet-encoding/src/test/java/org/apache/parquet/column/values/bitpacking/TestBitPacking.java": 233,
                "parquet-encoding/src/test/java/org/apache/parquet/column/values/bitpacking/TestByteBasedBitPackingEncoder.java": 46,
                "parquet-encoding/src/test/java/org/apache/parquet/column/values/bitpacking/TestByteBitPacking.java": 198,
                "parquet-encoding/src/test/java/org/apache/parquet/column/values/bitpacking/TestLemireBitPacking.java": 125,
                "parquet-format-structures/src/main/java/org/apache/parquet/format/BlockCipher.java": 76,
                "parquet-format-structures/src/main/java/org/apache/parquet/format/CliUtils.java": 55,
                "parquet-format-structures/src/main/java/org/apache/parquet/format/InterningProtocol.java": 236,
                "parquet-format-structures/src/main/java/org/apache/parquet/format/InvalidParquetMetadataException.java": 30,
                "parquet-format-structures/src/main/java/org/apache/parquet/format/LogicalTypes.java": 55,
                "parquet-format-structures/src/main/java/org/apache/parquet/format/MetadataValidator.java": 44,
                "parquet-format-structures/src/main/java/org/apache/parquet/format/Util.java": 389,
                "parquet-format-structures/src/main/java/org/apache/parquet/format/event/Consumers.java": 191,
                "parquet-format-structures/src/main/java/org/apache/parquet/format/event/EventBasedThriftReader.java": 126,
                "parquet-format-structures/src/main/java/org/apache/parquet/format/event/FieldConsumer.java": 39,
                "parquet-format-structures/src/main/java/org/apache/parquet/format/event/TypedConsumer.java": 205,
                "parquet-format-structures/src/test/java/org/apache/parquet/format/TestUtil.java": 101,
                "parquet-generator/src/main/java/org/apache/parquet/encoding/Generator.java": 34,
                "parquet-generator/src/main/java/org/apache/parquet/encoding/bitpacking/ByteBasedBitPackingGenerator.java": 319,
                "parquet-generator/src/main/java/org/apache/parquet/encoding/bitpacking/IntBasedBitPackingGenerator.java": 208,
                "parquet-generator/src/main/java/org/apache/parquet/filter2/Generator.java": 28,
                "parquet-generator/src/main/java/org/apache/parquet/filter2/IncrementallyUpdatedFilterPredicateGenerator.java": 335,
                "parquet-generator/src/main/java/org/apache/parquet/version/Generator.java": 28,
                "parquet-generator/src/main/java/org/apache/parquet/version/VersionGenerator.java": 87,
                "parquet-hadoop/src/main/java/org/apache/parquet/HadoopReadOptions.java": 143,
                "parquet-hadoop/src/main/java/org/apache/parquet/ParquetReadOptions.java": 345,
                "parquet-hadoop/src/main/java/org/apache/parquet/crypto/AADPrefixVerifier.java": 32,
                "parquet-hadoop/src/main/java/org/apache/parquet/crypto/AesCipher.java": 164,
                "parquet-hadoop/src/main/java/org/apache/parquet/crypto/AesCtrDecryptor.java": 170,
                "parquet-hadoop/src/main/java/org/apache/parquet/crypto/AesCtrEncryptor.java": 104,
                "parquet-hadoop/src/main/java/org/apache/parquet/crypto/AesGcmDecryptor.java": 151,
                "parquet-hadoop/src/main/java/org/apache/parquet/crypto/AesGcmEncryptor.java": 91,
                "parquet-hadoop/src/main/java/org/apache/parquet/crypto/AesMode.java": 35,
                "parquet-hadoop/src/main/java/org/apache/parquet/crypto/ColumnDecryptionProperties.java": 104,
                "parquet-hadoop/src/main/java/org/apache/parquet/crypto/ColumnEncryptionProperties.java": 195,
                "parquet-hadoop/src/main/java/org/apache/parquet/crypto/DecryptionKeyRetriever.java": 39,
                "parquet-hadoop/src/main/java/org/apache/parquet/crypto/DecryptionPropertiesFactory.java": 88,
                "parquet-hadoop/src/main/java/org/apache/parquet/crypto/EncryptionPropertiesFactory.java": 93,
                "parquet-hadoop/src/main/java/org/apache/parquet/crypto/FileDecryptionProperties.java": 254,
                "parquet-hadoop/src/main/java/org/apache/parquet/crypto/FileEncryptionProperties.java": 278,
                "parquet-hadoop/src/main/java/org/apache/parquet/crypto/InternalColumnDecryptionSetup.java": 74,
                "parquet-hadoop/src/main/java/org/apache/parquet/crypto/InternalColumnEncryptionSetup.java": 82,
                "parquet-hadoop/src/main/java/org/apache/parquet/crypto/InternalFileDecryptor.java": 312,
                "parquet-hadoop/src/main/java/org/apache/parquet/crypto/InternalFileEncryptor.java": 200,
                "parquet-hadoop/src/main/java/org/apache/parquet/crypto/KeyAccessDeniedException.java": 39,
                "parquet-hadoop/src/main/java/org/apache/parquet/crypto/ModuleCipherFactory.java": 73,
                "parquet-hadoop/src/main/java/org/apache/parquet/crypto/ParquetCipher.java": 42,
                "parquet-hadoop/src/main/java/org/apache/parquet/crypto/ParquetCryptoRuntimeException.java": 42,
                "parquet-hadoop/src/main/java/org/apache/parquet/crypto/TagVerificationException.java": 39,
                "parquet-hadoop/src/main/java/org/apache/parquet/crypto/keytools/FileKeyMaterialStore.java": 72,
                "parquet-hadoop/src/main/java/org/apache/parquet/crypto/keytools/FileKeyUnwrapper.java": 178,
                "parquet-hadoop/src/main/java/org/apache/parquet/crypto/keytools/FileKeyWrapper.java": 177,
                "parquet-hadoop/src/main/java/org/apache/parquet/crypto/keytools/HadoopFSKeyMaterialStore.java": 136,
                "parquet-hadoop/src/main/java/org/apache/parquet/crypto/keytools/KeyMaterial.java": 210,
                "parquet-hadoop/src/main/java/org/apache/parquet/crypto/keytools/KeyMetadata.java": 130,
                "parquet-hadoop/src/main/java/org/apache/parquet/crypto/keytools/KeyToolkit.java": 394,
                "parquet-hadoop/src/main/java/org/apache/parquet/crypto/keytools/KmsClient.java": 72,
                "parquet-hadoop/src/main/java/org/apache/parquet/crypto/keytools/LocalWrapKmsClient.java": 181,
                "parquet-hadoop/src/main/java/org/apache/parquet/crypto/keytools/PropertiesDrivenCryptoFactory.java": 258,
                "parquet-hadoop/src/main/java/org/apache/parquet/crypto/keytools/TwoLevelCacheWithExpiration.java": 105,
                "parquet-hadoop/src/main/java/org/apache/parquet/filter2/bloomfilterlevel/BloomFilterImpl.java": 187,
                "parquet-hadoop/src/main/java/org/apache/parquet/filter2/compat/RowGroupFilter.java": 131,
                "parquet-hadoop/src/main/java/org/apache/parquet/filter2/dictionarylevel/DictionaryFilter.java": 570,
                "parquet-hadoop/src/main/java/org/apache/parquet/filter2/statisticslevel/StatisticsFilter.java": 485,
                "parquet-hadoop/src/main/java/org/apache/parquet/format/converter/ParquetMetadataConverter.java": 2080,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/BadConfigurationException.java": 44,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/BloomFilterReader.java": 70,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/CodecFactory.java": 289,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ColumnChunkPageReadStore.java": 364,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ColumnChunkPageWriteStore.java": 462,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ColumnConfigParser.java": 72,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ColumnIndexFilterUtils.java": 162,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ColumnIndexStoreImpl.java": 155,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ColumnIndexValidator.java": 613,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/DictionaryPageReader.java": 115,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/DirectCodecFactory.java": 528,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/DirectZstd.java": 144,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/Footer.java": 53,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/InternalParquetRecordReader.java": 321,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/InternalParquetRecordWriter.java": 209,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/LruCache.java": 195,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/MemoryManager.java": 199,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/Offsets.java": 94,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ParquetEmptyBlockException.java": 41,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ParquetFileReader.java": 1869,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ParquetFileWriter.java": 1731,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ParquetInputFormat.java": 837,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ParquetInputSplit.java": 295,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ParquetMemoryManagerRuntimeException.java": 38,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ParquetOutputCommitter.java": 112,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ParquetOutputFormat.java": 570,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ParquetReader.java": 379,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ParquetRecordReader.java": 233,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ParquetRecordWriter.java": 184,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ParquetWriter.java": 744,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/PrintFooter.java": 265,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/UnmaterializableRecordCounter.java": 103,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/api/DelegatingReadSupport.java": 60,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/api/DelegatingWriteSupport.java": 69,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/api/InitContext.java": 99,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/api/ReadSupport.java": 145,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/api/WriteSupport.java": 140,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/api/package-info.java": 27,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/codec/CleanUtil.java": 111,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/codec/CodecConfig.java": 167,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/codec/Lz4RawCodec.java": 112,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/codec/Lz4RawCompressor.java": 44,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/codec/Lz4RawDecompressor.java": 46,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/codec/NonBlockedCompressor.java": 192,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/codec/NonBlockedCompressorStream.java": 50,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/codec/NonBlockedDecompressor.java": 180,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/codec/NonBlockedDecompressorStream.java": 57,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/codec/SnappyCodec.java": 105,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/codec/SnappyCompressor.java": 38,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/codec/SnappyDecompressor.java": 38,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/codec/SnappyUtil.java": 33,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/codec/ZstandardCodec.java": 130,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/codec/ZstdCompressorStream.java": 70,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/codec/ZstdDecompressorStream.java": 62,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/example/ExampleInputFormat.java": 35,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/example/ExampleOutputFormat.java": 58,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/example/ExampleParquetWriter.java": 118,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/example/GroupReadSupport.java": 49,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/example/GroupWriteSupport.java": 88,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/mapred/Container.java": 37,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/mapred/DeprecatedParquetInputFormat.java": 209,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/mapred/DeprecatedParquetOutputFormat.java": 119,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/mapred/MapredParquetOutputCommitter.java": 42,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/metadata/BlockMetaData.java": 153,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/metadata/ColumnChunkMetaData.java": 683,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/metadata/ColumnChunkProperties.java": 118,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/metadata/ConcatenatingKeyValueMetadataMergeStrategy.java": 61,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/metadata/EncodingList.java": 81,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/metadata/FileMetaData.java": 108,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/metadata/GlobalMetaData.java": 110,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/metadata/KeyValueMetadataMergeStrategy.java": 42,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/metadata/ParquetMetadata.java": 134,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/metadata/StrictKeyValueMetadataMergeStrategy.java": 42,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/package-info.java": 33,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/rewrite/MaskMode.java": 38,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/rewrite/ParquetRewriter.java": 819,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/rewrite/RewriteOptions.java": 262,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/util/ColumnEncryptor.java": 90,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/util/ColumnMasker.java": 98,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/util/ColumnPruner.java": 42,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/util/CompressionConverter.java": 81,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/util/ConfigurationUtil.java": 44,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/util/ContextUtil.java": 315,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/util/H1SeekableInputStream.java": 59,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/util/H2SeekableInputStream.java": 99,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/util/HadoopCodecs.java": 39,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/util/HadoopInputFile.java": 76,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/util/HadoopOutputFile.java": 105,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/util/HadoopPositionOutputStream.java": 66,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/util/HadoopStreams.java": 148,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/util/HiddenFileFilter.java": 39,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/util/SerializationUtil.java": 93,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/util/counters/BenchmarkCounter.java": 112,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/util/counters/CounterLoader.java": 27,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/util/counters/ICounter.java": 28,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/util/counters/mapred/MapRedCounterAdapter.java": 43,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/util/counters/mapred/MapRedCounterLoader.java": 51,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/util/counters/mapreduce/MapReduceCounterAdapter.java": 44,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/util/counters/mapreduce/MapReduceCounterLoader.java": 47,
                "parquet-hadoop/src/main/java/org/apache/parquet/internal/hadoop/metadata/IndexReference.java": 41,
                "parquet-hadoop/src/test/java/org/apache/parquet/DirectWriterTest.java": 102,
                "parquet-hadoop/src/test/java/org/apache/parquet/crypto/DecryptionKeyRetrieverMock.java": 41,
                "parquet-hadoop/src/test/java/org/apache/parquet/crypto/DecryptionPropertiesFactoryTest.java": 43,
                "parquet-hadoop/src/test/java/org/apache/parquet/crypto/EncryptionPropertiesFactoryTest.java": 45,
                "parquet-hadoop/src/test/java/org/apache/parquet/crypto/SampleDecryptionPropertiesFactory.java": 57,
                "parquet-hadoop/src/test/java/org/apache/parquet/crypto/SampleEncryptionPropertiesFactory.java": 58,
                "parquet-hadoop/src/test/java/org/apache/parquet/crypto/SingleRow.java": 139,
                "parquet-hadoop/src/test/java/org/apache/parquet/crypto/TestPropertiesDrivenEncryption.java": 705,
                "parquet-hadoop/src/test/java/org/apache/parquet/crypto/keytools/mocks/InMemoryKMS.java": 116,
                "parquet-hadoop/src/test/java/org/apache/parquet/crypto/keytools/mocks/LocalWrapInMemoryKMS.java": 79,
                "parquet-hadoop/src/test/java/org/apache/parquet/crypto/keytools/samples/VaultClient.java": 184,
                "parquet-hadoop/src/test/java/org/apache/parquet/crypto/propertiesfactory/SchemaControlEncryptionTest.java": 250,
                "parquet-hadoop/src/test/java/org/apache/parquet/crypto/propertiesfactory/SchemaCryptoPropertiesFactory.java": 137,
                "parquet-hadoop/src/test/java/org/apache/parquet/encodings/FileEncodingsIT.java": 564,
                "parquet-hadoop/src/test/java/org/apache/parquet/filter2/TestFiltersWithMissingColumns.java": 275,
                "parquet-hadoop/src/test/java/org/apache/parquet/filter2/compat/TestRowGroupFilter.java": 128,
                "parquet-hadoop/src/test/java/org/apache/parquet/filter2/dictionarylevel/DictionaryFilterTest.java": 839,
                "parquet-hadoop/src/test/java/org/apache/parquet/filter2/recordlevel/PhoneBookWriter.java": 373,
                "parquet-hadoop/src/test/java/org/apache/parquet/filter2/recordlevel/TestRecordLevelFilters.java": 310,
                "parquet-hadoop/src/test/java/org/apache/parquet/filter2/statisticslevel/TestStatisticsFilter.java": 561,
                "parquet-hadoop/src/test/java/org/apache/parquet/format/converter/TestParquetMetadataConverter.java": 1389,
                "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/DeprecatedInputFormatTest.java": 346,
                "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/DeprecatedOutputFormatTest.java": 108,
                "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/ITTestEncryptionOptions.java": 50,
                "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/TestAdaptiveBlockSplitBloomFiltering.java": 78,
                "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/TestBloomFiltering.java": 421,
                "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/TestColumnChunkPageWriteStore.java": 288,
                "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/TestColumnIndexFiltering.java": 617,
                "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/TestDataPageV1Checksums.java": 563,
                "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/TestDirectCodecFactory.java": 178,
                "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/TestEncryptionOptions.java": 752,
                "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/TestInputFormat.java": 555,
                "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/TestInputFormatColumnProjection.java": 180,
                "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/TestInputOutputFormatWithPadding.java": 214,
                "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/TestLargeColumnChunk.java": 145,
                "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/TestLruCache.java": 162,
                "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/TestMemoryManager.java": 189,
                "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/TestMergeMetadataFiles.java": 221,
                "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/TestMultipleWriteRead.java": 250,
                "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/TestParquetFileWriter.java": 1218,
                "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/TestParquetOutputFormatJobSummaryLevel.java": 69,
                "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/TestParquetReader.java": 198,
                "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/TestParquetReaderEmptyBlock.java": 170,
                "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/TestParquetReaderRandomAccess.java": 387,
                "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/TestParquetWriter.java": 431,
                "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/TestParquetWriterAppendBlocks.java": 361,
                "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/TestParquetWriterNewPage.java": 136,
                "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/TestParquetWriterTruncation.java": 125,
                "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/TestReadWriteEncodingStats.java": 122,
                "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/TestSnappyCodec.java": 140,
                "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/TestStoreBloomFilter.java": 132,
                "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/TestUtils.java": 85,
                "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/TestZstandardCodec.java": 173,
                "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/codec/CodecConfigTest.java": 77,
                "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/codec/TestCompressionCodec.java": 177,
                "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/codec/TestInteropReadLz4RawCodec.java": 129,
                "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/example/GroupReadSupportTest.java": 65,
                "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/example/TestInputOutputFormat.java": 364,
                "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/metadata/TestColumnChunkMetaData.java": 83,
                "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/rewrite/ParquetRewriterTest.java": 772,
                "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/util/ColumnEncryptorTest.java": 315,
                "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/util/ColumnMaskerTest.java": 223,
                "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/util/ColumnPrunerTest.java": 246,
                "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/util/CompressionConverterTest.java": 312,
                "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/util/EncDecProperties.java": 94,
                "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/util/EncryptionTestFile.java": 38,
                "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/util/MockHadoopInputStream.java": 87,
                "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/util/TestFileBuilder.java": 198,
                "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/util/TestHadoop2ByteBufferReads.java": 446,
                "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/util/TestSerializationUtil.java": 71,
                "parquet-hadoop/src/test/java/org/apache/parquet/statistics/DataGenerationContext.java": 85,
                "parquet-hadoop/src/test/java/org/apache/parquet/statistics/RandomValues.java": 383,
                "parquet-hadoop/src/test/java/org/apache/parquet/statistics/TestColumnIndexes.java": 304,
                "parquet-hadoop/src/test/java/org/apache/parquet/statistics/TestStatistics.java": 459,
                "parquet-pig/src/main/java/org/apache/parquet/pig/ParquetLoader.java": 575,
                "parquet-pig/src/main/java/org/apache/parquet/pig/ParquetStorer.java": 152,
                "parquet-pig/src/main/java/org/apache/parquet/pig/PigMetaData.java": 91,
                "parquet-pig/src/main/java/org/apache/parquet/pig/PigSchemaConverter.java": 551,
                "parquet-pig/src/main/java/org/apache/parquet/pig/SchemaConversionException.java": 44,
                "parquet-pig/src/main/java/org/apache/parquet/pig/TupleConversionException.java": 42,
                "parquet-pig/src/main/java/org/apache/parquet/pig/TupleReadSupport.java": 191,
                "parquet-pig/src/main/java/org/apache/parquet/pig/TupleWriteSupport.java": 209,
                "parquet-pig/src/main/java/org/apache/parquet/pig/convert/DecimalUtils.java": 65,
                "parquet-pig/src/main/java/org/apache/parquet/pig/convert/MapConverter.java": 190,
                "parquet-pig/src/main/java/org/apache/parquet/pig/convert/ParentValueContainer.java": 32,
                "parquet-pig/src/main/java/org/apache/parquet/pig/convert/TupleConverter.java": 592,
                "parquet-pig/src/main/java/org/apache/parquet/pig/convert/TupleRecordMaterializer.java": 50,
                "parquet-pig/src/main/java/org/apache/parquet/pig/summary/BagSummaryData.java": 72,
                "parquet-pig/src/main/java/org/apache/parquet/pig/summary/EnumStat.java": 115,
                "parquet-pig/src/main/java/org/apache/parquet/pig/summary/FieldSummaryData.java": 178,
                "parquet-pig/src/main/java/org/apache/parquet/pig/summary/MapSummaryData.java": 85,
                "parquet-pig/src/main/java/org/apache/parquet/pig/summary/NumberSummaryData.java": 47,
                "parquet-pig/src/main/java/org/apache/parquet/pig/summary/StringSummaryData.java": 82,
                "parquet-pig/src/main/java/org/apache/parquet/pig/summary/Summary.java": 224,
                "parquet-pig/src/main/java/org/apache/parquet/pig/summary/SummaryData.java": 135,
                "parquet-pig/src/main/java/org/apache/parquet/pig/summary/TupleSummaryData.java": 98,
                "parquet-pig/src/main/java/org/apache/parquet/pig/summary/ValueStat.java": 64,
                "parquet-pig/src/test/java/org/apache/parquet/pig/PerfTest.java": 104,
                "parquet-pig/src/test/java/org/apache/parquet/pig/PerfTest2.java": 185,
                "parquet-pig/src/test/java/org/apache/parquet/pig/PerfTestReadAllCols.java": 47,
                "parquet-pig/src/test/java/org/apache/parquet/pig/TestDecimalUtils.java": 79,
                "parquet-pig/src/test/java/org/apache/parquet/pig/TestParquetLoader.java": 367,
                "parquet-pig/src/test/java/org/apache/parquet/pig/TestParquetStorer.java": 264,
                "parquet-pig/src/test/java/org/apache/parquet/pig/TestPigSchemaConverter.java": 291,
                "parquet-pig/src/test/java/org/apache/parquet/pig/TestTupleRecordConsumer.java": 210,
                "parquet-pig/src/test/java/org/apache/parquet/pig/TupleConsumerPerfTest.java": 206,
                "parquet-pig/src/test/java/org/apache/parquet/pig/summary/TestSummary.java": 158,
                "parquet-plugins/parquet-encoding-vector/src/main/java/org/apache/parquet/column/values/bitpacking/ByteBitPacking512VectorLE.java": 3010,
                "parquet-plugins/parquet-encoding-vector/src/main/java/org/apache/parquet/column/values/bitpacking/ParquetReadRouter.java": 133,
                "parquet-plugins/parquet-encoding-vector/src/main/java/org/apache/parquet/column/values/bitpacking/VectorSupport.java": 27,
                "parquet-plugins/parquet-encoding-vector/src/test/java/org/apache/parquet/column/values/bitpacking/TestByteBitPacking512VectorLE.java": 169,
                "parquet-plugins/parquet-encoding-vector/src/test/java/org/apache/parquet/column/values/bitpacking/TestParquetReadRouter.java": 59,
                "parquet-plugins/parquet-plugins-benchmarks/src/main/java/org/apache/parquet/plugins/benchmarks/ByteBitPackingVectorBenchmarks.java": 92,
                "parquet-protobuf/src/main/java/org/apache/parquet/proto/ProtoConstants.java": 46,
                "parquet-protobuf/src/main/java/org/apache/parquet/proto/ProtoMessageConverter.java": 599,
                "parquet-protobuf/src/main/java/org/apache/parquet/proto/ProtoParquetInputFormat.java": 38,
                "parquet-protobuf/src/main/java/org/apache/parquet/proto/ProtoParquetOutputFormat.java": 52,
                "parquet-protobuf/src/main/java/org/apache/parquet/proto/ProtoParquetReader.java": 101,
                "parquet-protobuf/src/main/java/org/apache/parquet/proto/ProtoParquetWriter.java": 127,
                "parquet-protobuf/src/main/java/org/apache/parquet/proto/ProtoReadSupport.java": 97,
                "parquet-protobuf/src/main/java/org/apache/parquet/proto/ProtoRecordConverter.java": 100,
                "parquet-protobuf/src/main/java/org/apache/parquet/proto/ProtoRecordMaterializer.java": 47,
                "parquet-protobuf/src/main/java/org/apache/parquet/proto/ProtoSchemaConverter.java": 297,
                "parquet-protobuf/src/main/java/org/apache/parquet/proto/ProtoWriteSupport.java": 586,
                "parquet-protobuf/src/test/java/org/apache/parquet/proto/ProtoInputOutputFormatTest.java": 618,
                "parquet-protobuf/src/test/java/org/apache/parquet/proto/ProtoRecordConverterTest.java": 363,
                "parquet-protobuf/src/test/java/org/apache/parquet/proto/ProtoSchemaConverterTest.java": 539,
                "parquet-protobuf/src/test/java/org/apache/parquet/proto/ProtoSchemaEvolutionTest.java": 133,
                "parquet-protobuf/src/test/java/org/apache/parquet/proto/ProtoWriteSupportTest.java": 1204,
                "parquet-protobuf/src/test/java/org/apache/parquet/proto/TestUtils.java": 232,
                "parquet-protobuf/src/test/java/org/apache/parquet/proto/utils/ReadUsingMR.java": 94,
                "parquet-protobuf/src/test/java/org/apache/parquet/proto/utils/WriteUsingMR.java": 121,
                "parquet-thrift/src/main/java/org/apache/parquet/hadoop/thrift/AbstractThriftWriteSupport.java": 129,
                "parquet-thrift/src/main/java/org/apache/parquet/hadoop/thrift/ParquetThriftBytesOutputFormat.java": 96,
                "parquet-thrift/src/main/java/org/apache/parquet/hadoop/thrift/ParquetThriftInputFormat.java": 66,
                "parquet-thrift/src/main/java/org/apache/parquet/hadoop/thrift/ParquetThriftOutputFormat.java": 43,
                "parquet-thrift/src/main/java/org/apache/parquet/hadoop/thrift/TBaseWriteSupport.java": 70,
                "parquet-thrift/src/main/java/org/apache/parquet/hadoop/thrift/ThriftBytesWriteSupport.java": 196,
                "parquet-thrift/src/main/java/org/apache/parquet/hadoop/thrift/ThriftReadSupport.java": 289,
                "parquet-thrift/src/main/java/org/apache/parquet/hadoop/thrift/ThriftToParquetFileWriter.java": 125,
                "parquet-thrift/src/main/java/org/apache/parquet/hadoop/thrift/ThriftWriteSupport.java": 80,
                "parquet-thrift/src/main/java/org/apache/parquet/thrift/BufferedProtocolReadToWrite.java": 738,
                "parquet-thrift/src/main/java/org/apache/parquet/thrift/ConvertedField.java": 169,
                "parquet-thrift/src/main/java/org/apache/parquet/thrift/DecodingSchemaMismatchException.java": 30,
                "parquet-thrift/src/main/java/org/apache/parquet/thrift/FieldIgnoredHandler.java": 45,
                "parquet-thrift/src/main/java/org/apache/parquet/thrift/KeepOnlyFirstPrimitiveFilter.java": 44,
                "parquet-thrift/src/main/java/org/apache/parquet/thrift/ParquetProtocol.java": 282,
                "parquet-thrift/src/main/java/org/apache/parquet/thrift/ParquetReadProtocol.java": 164,
                "parquet-thrift/src/main/java/org/apache/parquet/thrift/ParquetWriteProtocol.java": 778,
                "parquet-thrift/src/main/java/org/apache/parquet/thrift/ProtocolPipe.java": 29,
                "parquet-thrift/src/main/java/org/apache/parquet/thrift/ProtocolReadToWrite.java": 142,
                "parquet-thrift/src/main/java/org/apache/parquet/thrift/SkippableException.java": 47,
                "parquet-thrift/src/main/java/org/apache/parquet/thrift/TBaseRecordConverter.java": 61,
                "parquet-thrift/src/main/java/org/apache/parquet/thrift/ThriftMetaData.java": 147,
                "parquet-thrift/src/main/java/org/apache/parquet/thrift/ThriftParquetReader.java": 139,
                "parquet-thrift/src/main/java/org/apache/parquet/thrift/ThriftParquetWriter.java": 52,
                "parquet-thrift/src/main/java/org/apache/parquet/thrift/ThriftReader.java": 28,
                "parquet-thrift/src/main/java/org/apache/parquet/thrift/ThriftRecordConverter.java": 954,
                "parquet-thrift/src/main/java/org/apache/parquet/thrift/ThriftSchemaConvertVisitor.java": 409,
                "parquet-thrift/src/main/java/org/apache/parquet/thrift/ThriftSchemaConverter.java": 226,
                "parquet-thrift/src/main/java/org/apache/parquet/thrift/pig/ParquetThriftStorer.java": 90,
                "parquet-thrift/src/main/java/org/apache/parquet/thrift/pig/TupleToThriftWriteSupport.java": 79,
                "parquet-thrift/src/main/java/org/apache/parquet/thrift/projection/FieldProjectionFilter.java": 62,
                "parquet-thrift/src/main/java/org/apache/parquet/thrift/projection/FieldsPath.java": 87,
                "parquet-thrift/src/main/java/org/apache/parquet/thrift/projection/StrictFieldProjectionFilter.java": 187,
                "parquet-thrift/src/main/java/org/apache/parquet/thrift/projection/ThriftProjectionException.java": 45,
                "parquet-thrift/src/main/java/org/apache/parquet/thrift/projection/amend/DefaultEventsVisitor.java": 228,
                "parquet-thrift/src/main/java/org/apache/parquet/thrift/projection/amend/DefaultProtocolEventsGenerator.java": 68,
                "parquet-thrift/src/main/java/org/apache/parquet/thrift/projection/amend/ProtocolEventsAmender.java": 171,
                "parquet-thrift/src/main/java/org/apache/parquet/thrift/projection/amend/ReadFieldBeginProtocol.java": 44,
                "parquet-thrift/src/main/java/org/apache/parquet/thrift/projection/deprecated/DeprecatedFieldProjectionFilter.java": 106,
                "parquet-thrift/src/main/java/org/apache/parquet/thrift/projection/deprecated/PathGlobPattern.java": 173,
                "parquet-thrift/src/main/java/org/apache/parquet/thrift/struct/CompatibilityChecker.java": 265,
                "parquet-thrift/src/main/java/org/apache/parquet/thrift/struct/CompatibilityRunner.java": 104,
                "parquet-thrift/src/main/java/org/apache/parquet/thrift/struct/JSON.java": 50,
                "parquet-thrift/src/main/java/org/apache/parquet/thrift/struct/ThriftField.java": 121,
                "parquet-thrift/src/main/java/org/apache/parquet/thrift/struct/ThriftType.java": 698,
                "parquet-thrift/src/main/java/org/apache/parquet/thrift/struct/ThriftTypeID.java": 108,
                "parquet-thrift/src/test/java/org/apache/parquet/hadoop/thrift/TestArrayCompatibility.java": 779,
                "parquet-thrift/src/test/java/org/apache/parquet/hadoop/thrift/TestBinary.java": 86,
                "parquet-thrift/src/test/java/org/apache/parquet/hadoop/thrift/TestCorruptThriftRecords.java": 213,
                "parquet-thrift/src/test/java/org/apache/parquet/hadoop/thrift/TestInputOutputFormat.java": 258,
                "parquet-thrift/src/test/java/org/apache/parquet/hadoop/thrift/TestParquetToThriftReadWriteAndProjection.java": 385,
                "parquet-thrift/src/test/java/org/apache/parquet/hadoop/thrift/TestThriftToParquetFileWriter.java": 360,
                "parquet-thrift/src/test/java/org/apache/parquet/thrift/TestParquetReadProtocol.java": 173,
                "parquet-thrift/src/test/java/org/apache/parquet/thrift/TestParquetWriteProtocol.java": 719,
                "parquet-thrift/src/test/java/org/apache/parquet/thrift/TestProtocolReadToWrite.java": 384,
                "parquet-thrift/src/test/java/org/apache/parquet/thrift/TestThriftMetaData.java": 56,
                "parquet-thrift/src/test/java/org/apache/parquet/thrift/TestThriftParquetReaderWriter.java": 83,
                "parquet-thrift/src/test/java/org/apache/parquet/thrift/TestThriftRecordConverter.java": 101,
                "parquet-thrift/src/test/java/org/apache/parquet/thrift/TestThriftSchemaConvertVisitor.java": 178,
                "parquet-thrift/src/test/java/org/apache/parquet/thrift/TestThriftSchemaConverter.java": 353,
                "parquet-thrift/src/test/java/org/apache/parquet/thrift/TestThriftSchemaConverterProjectUnion.java": 480,
                "parquet-thrift/src/test/java/org/apache/parquet/thrift/TestThriftToPigCompatibility.java": 171,
                "parquet-thrift/src/test/java/org/apache/parquet/thrift/pig/TestParquetThriftStorer.java": 82,
                "parquet-thrift/src/test/java/org/apache/parquet/thrift/projection/TestFieldsPath.java": 162,
                "parquet-thrift/src/test/java/org/apache/parquet/thrift/projection/TestStrictFieldProjectionFilter.java": 119,
                "parquet-thrift/src/test/java/org/apache/parquet/thrift/projection/deprecated/PathGlobPatternTest.java": 59,
                "parquet-thrift/src/test/java/org/apache/parquet/thrift/struct/CompatibilityCheckerTest.java": 132,
                "parquet-thrift/src/test/java/org/apache/parquet/thrift/struct/TestThriftType.java": 70,
                "src/main/java/parquet/proto/ProtoParquetInputFormat.java": 35,
                "src/main/java/parquet/proto/ProtoParquetOutputFormat.java": 37,
                "src/main/java/parquet/proto/ProtoParquetReader.java": 40,
                "src/main/java/parquet/proto/ProtoParquetWriter.java": 78,
                "src/main/java/parquet/proto/ProtoReadSupport.java": 70,
                "src/main/java/parquet/proto/ProtoRecordMaterializer.java": 41,
                "src/main/java/parquet/proto/ProtoSchemaConverter.java": 131,
                "src/main/java/parquet/proto/ProtoWriteSupport.java": 185,
                "src/main/java/parquet/proto/ProtobufferRecordConverter.java": 68,
                "src/main/java/parquet/proto/converters/ParentValueContainer.java": 10,
                "src/main/java/parquet/proto/converters/ProtoArrayConverter.java": 28,
                "src/main/java/parquet/proto/converters/ProtoBinaryConverter.java": 18,
                "src/main/java/parquet/proto/converters/ProtoBooleanConverter.java": 18,
                "src/main/java/parquet/proto/converters/ProtoDoubleConverter.java": 17,
                "src/main/java/parquet/proto/converters/ProtoEnumConverter.java": 48,
                "src/main/java/parquet/proto/converters/ProtoFloatConverter.java": 17,
                "src/main/java/parquet/proto/converters/ProtoIntConverter.java": 17,
                "src/main/java/parquet/proto/converters/ProtoLongConverter.java": 17,
                "src/main/java/parquet/proto/converters/ProtoMessageConverter.java": 170,
                "src/main/java/parquet/proto/converters/ProtobufStringConverter.java": 20,
                "src/main/java/parquet/proto/package-info.java": 89,
                "src/test/java/parquet/proto/BugHuntingTest.java": 54,
                "src/test/java/parquet/proto/ProtoTest.java": 154,
                "src/test/java/parquet/proto/TestSandbox.java": 43,
                "src/test/java/parquet/proto/TestUtils.java": 159
            },
            "is_test": true,
            "is_fix": false
        },
        "ab4cb69e09b109f82e92de8ed21925d75751eef0": {
            "datetime": "2013-10-23T16:43:29-07:00",
            "summary": "Make the ParquetLoader.inputFormatCache HashMap a WeakHashMap in order to free memory for long running processes that do not leverage caching",
            "message": "Make the ParquetLoader.inputFormatCache HashMap a WeakHashMap in order to free memory for long running processes that do not leverage caching\n",
            "diff": {
                "parquet-pig/src/main/java/parquet/pig/ParquetLoader.java": 4
            },
            "is_test": false,
            "is_fix": false
        },
        "5f29f4374ee0b4925b7fdc36945a9a104389e964": {
            "datetime": "2013-10-23T20:30:49-07:00",
            "summary": "use a new string in order to enforce weak reference on the key",
            "message": "use a new string in order to enforce weak reference on the key\n",
            "diff": {
                "parquet-pig/src/main/java/parquet/pig/ParquetLoader.java": 4
            },
            "is_test": false,
            "is_fix": false
        },
        "93780e026d08c7541ca7af703aebc9d26e52e68f": {
            "datetime": "2013-10-23T20:33:18-07:00",
            "summary": "use a new string in order to enforce weak reference on the key",
            "message": "use a new string in order to enforce weak reference on the key\n",
            "diff": {
                "parquet-pig/src/main/java/parquet/pig/ParquetLoader.java": 4
            },
            "is_test": false,
            "is_fix": false
        },
        "cf1f44268d802922b0a1b26d6cdcf5edf8e45f0e": {
            "datetime": "2013-10-23T20:34:52-07:00",
            "summary": "use a new string in order to enforce weak reference on the key",
            "message": "use a new string in order to enforce weak reference on the key\n",
            "diff": {
                "parquet-pig/src/main/java/parquet/pig/ParquetLoader.java": 4
            },
            "is_test": false,
            "is_fix": false
        },
        "8edc1029818ab9b5e3b712eae3546e54eda6a1a6": {
            "datetime": "2013-10-24T08:36:19-07:00",
            "summary": "throw ParquetEncodingException",
            "message": "throw ParquetEncodingException\n",
            "diff": {
                "parquet-thrift/src/main/java/parquet/thrift/ParquetWriteProtocol.java": 4
            },
            "is_test": false,
            "is_fix": false
        },
        "be83477f361d90d5b78d10affe13f173b85192cc": {
            "datetime": "2013-10-24T09:04:57-07:00",
            "summary": "Merge pull request #203 from Parquet/check_null_for_enum_write_protocol",
            "message": "Merge pull request #203 from Parquet/check_null_for_enum_write_protocol\n\nadd null check for EnumWriteProtocol",
            "diff": {
                "parquet-thrift/src/main/java/parquet/thrift/ParquetWriteProtocol.java": 9
            },
            "is_test": false,
            "is_fix": false
        },
        "3b63d13250862534a1ae6532750e3a343987ce36": {
            "datetime": "2013-10-24T09:42:42-07:00",
            "summary": "fix comment",
            "message": "fix comment\n",
            "diff": {
                "parquet-pig/src/main/java/parquet/pig/ParquetLoader.java": 4
            },
            "is_test": false,
            "is_fix": false
        },
        "c5ce1fa1ee49419f0e809596a272ed369d93cfc7": {
            "datetime": "2013-10-24T09:45:15-07:00",
            "summary": "fix comment, remove size",
            "message": "fix comment, remove size\n",
            "diff": {
                "parquet-pig/src/main/java/parquet/pig/ParquetLoader.java": 2
            },
            "is_test": false,
            "is_fix": false
        },
        "a34df077d0607ad80b2a3977321d7c2a3fdf3fa8": {
            "datetime": "2013-10-24T09:55:02-07:00",
            "summary": "Merge pull request #204 from aaghevli/ParquetLoader.inputFormatCache",
            "message": "Merge pull request #204 from aaghevli/ParquetLoader.inputFormatCache\n\nParquetLoader.inputFormatCache as WeakHashMap",
            "diff": {
                "parquet-pig/src/main/java/parquet/pig/ParquetLoader.java": 8
            },
            "is_test": false,
            "is_fix": false
        },
        "464945308c70beb14373ac5987cd38d0c9478cfc": {
            "datetime": "2013-10-25T16:53:17-07:00",
            "summary": "Merge branch 'master' into plumb_original_type",
            "message": "Merge branch 'master' into plumb_original_type\n",
            "diff": {
                "parquet-pig/src/main/java/parquet/pig/ParquetLoader.java": 8,
                "parquet-thrift/src/main/java/parquet/thrift/ParquetWriteProtocol.java": 9
            },
            "is_test": false,
            "is_fix": false
        },
        "e337bd2f9c54b58245e3e050372a32c555b2417f": {
            "datetime": "2013-10-27T21:24:46+01:00",
            "summary": "Protobuf conversion over Java types",
            "message": "Protobuf conversion over Java types\n",
            "diff": {
                "src/main/java/parquet/proto/ProtoSchemaConverter.java": 23
            },
            "is_test": false,
            "is_fix": false
        },
        "81a1af0c47219598a6ebf4c86a2e0d43d028706d": {
            "datetime": "2013-10-29T13:18:36-07:00",
            "summary": "improve fallback for IntDictionaryWriter",
            "message": "improve fallback for IntDictionaryWriter\n",
            "diff": {
                "parquet-column/src/main/java/parquet/column/values/dictionary/DictionaryValuesWriter.java": 12,
                "parquet-column/src/test/java/parquet/column/values/dictionary/TestDictionary.java": 34
            },
            "is_test": true,
            "is_fix": false
        },
        "11f30faffbc095068d23e8173fb3387e99b1a341": {
            "datetime": "2013-10-29T13:58:52-07:00",
            "summary": "fix bug, add rawDataByteSize for dictionaryValuesWriter to decide if fall back to Plain encoding or not",
            "message": "fix bug, add rawDataByteSize for dictionaryValuesWriter to decide if fall back to Plain encoding or not\n",
            "diff": {
                "parquet-column/src/main/java/parquet/column/values/dictionary/DictionaryValuesWriter.java": 19
            },
            "is_test": false,
            "is_fix": false
        },
        "be6a4aeed809a0a78cbf0c156ace3ed8c1a12af9": {
            "datetime": "2013-10-29T14:56:51-07:00",
            "summary": "fix bug: reverse dictionary lookup for fallbacking to plain encoding",
            "message": "fix bug: reverse dictionary lookup for fallbacking to plain encoding\n",
            "diff": {
                "parquet-column/src/main/java/parquet/column/values/dictionary/DictionaryValuesWriter.java": 16
            },
            "is_test": false,
            "is_fix": false
        },
        "4d55b59776ff9be7a97c8bff605204f9c625747a": {
            "datetime": "2013-10-29T15:11:05-07:00",
            "summary": "improve fallback for float",
            "message": "improve fallback for float\n",
            "diff": {
                "parquet-column/src/main/java/parquet/column/values/dictionary/DictionaryValuesWriter.java": 22,
                "parquet-column/src/test/java/parquet/column/values/dictionary/TestDictionary.java": 28
            },
            "is_test": true,
            "is_fix": false
        },
        "1afdf14faa875b268aca616e323957040a9695f8": {
            "datetime": "2013-10-30T16:06:25-07:00",
            "summary": "minor fix, the length used in RLEValuesReader",
            "message": "minor fix, the length used in RLEValuesReader\n",
            "diff": {
                "parquet-column/src/main/java/parquet/column/values/rle/RunLengthBitPackingHybridValuesReader.java": 2
            },
            "is_test": false,
            "is_fix": false
        },
        "d942b454af8bf930394744311a523a76802cb7c5": {
            "datetime": "2013-10-30T16:07:36-07:00",
            "summary": "format",
            "message": "format\n",
            "diff": {
                "parquet-column/src/main/java/parquet/column/values/rle/RunLengthBitPackingHybridValuesReader.java": 2
            },
            "is_test": false,
            "is_fix": false
        },
        "3c99aa31c350d4b87e31c5d1dfd740f6938b5b47": {
            "datetime": "2013-10-31T09:50:38-07:00",
            "summary": "improve fallback for double",
            "message": "improve fallback for double\n",
            "diff": {
                "parquet-column/src/main/java/parquet/column/values/dictionary/DictionaryValuesWriter.java": 22,
                "parquet-column/src/test/java/parquet/column/values/dictionary/TestDictionary.java": 35
            },
            "is_test": true,
            "is_fix": false
        },
        "b84e2726bed4ec02a896e5142c363a9426c3295e": {
            "datetime": "2013-10-31T10:39:53-07:00",
            "summary": "Merge pull request #207 from Parquet/fix_offset",
            "message": "Merge pull request #207 from Parquet/fix_offset\n\nFix offset",
            "diff": {
                "parquet-column/src/main/java/parquet/column/values/rle/RunLengthBitPackingHybridValuesReader.java": 2
            },
            "is_test": false,
            "is_fix": false
        },
        "245d43ea7eb45f11d0c3822eb3704eccf429dc04": {
            "datetime": "2013-10-31T11:43:09-07:00",
            "summary": "use primitve array for int, float , double, get rid of auto boxing,unboxing",
            "message": "use primitve array for int, float , double, get rid of auto boxing,unboxing\n",
            "diff": {
                "parquet-column/src/main/java/parquet/column/values/dictionary/DictionaryValuesWriter.java": 43
            },
            "is_test": false,
            "is_fix": false
        },
        "c9b768f4d2a942dd29cecfd3871549794d337b25": {
            "datetime": "2013-10-31T12:05:22-07:00",
            "summary": "improve long fallback",
            "message": "improve long fallback\n",
            "diff": {
                "parquet-column/src/main/java/parquet/column/values/dictionary/DictionaryValuesWriter.java": 22,
                "parquet-column/src/test/java/parquet/column/values/dictionary/TestDictionary.java": 25
            },
            "is_test": true,
            "is_fix": false
        },
        "bee675509d8fc7f927d410b4815e95f457ee1fa2": {
            "datetime": "2013-10-31T13:49:39-07:00",
            "summary": "improve binary fallback",
            "message": "improve binary fallback\n",
            "diff": {
                "parquet-column/src/main/java/parquet/column/values/dictionary/DictionaryValuesWriter.java": 21,
                "parquet-column/src/test/java/parquet/column/values/dictionary/TestDictionary.java": 27
            },
            "is_test": true,
            "is_fix": false
        },
        "d33aa40c7e9e9f577bfe05f0a15eb9687ad22cba": {
            "datetime": "2013-10-31T14:13:23-07:00",
            "summary": "bug fix: separate fallBackDictionaryEncodedData to a method, will always be called when fallbacking to plainEncoding",
            "message": "bug fix: separate fallBackDictionaryEncodedData to a method, will always be called when fallbacking to plainEncoding\n",
            "diff": {
                "parquet-column/src/main/java/parquet/column/values/dictionary/DictionaryValuesWriter.java": 39
            },
            "is_test": false,
            "is_fix": false
        },
        "1278cde66ac37c94e2e0c602282ff6d0d13a4700": {
            "datetime": "2013-10-31T14:16:09-07:00",
            "summary": "remove unused import",
            "message": "remove unused import\n",
            "diff": {
                "parquet-column/src/main/java/parquet/column/values/dictionary/DictionaryValuesWriter.java": 3
            },
            "is_test": false,
            "is_fix": false
        },
        "65ca5ed89db94a8217e8300b3222abd2918f1848": {
            "datetime": "2013-11-01T16:28:27+01:00",
            "summary": "Copyrights in converters",
            "message": "Copyrights in converters\n",
            "diff": {
                "src/main/java/parquet/proto/converters/ParentValueContainer.java": 16,
                "src/main/java/parquet/proto/converters/ProtoArrayConverter.java": 16,
                "src/main/java/parquet/proto/converters/ProtoBinaryConverter.java": 16,
                "src/main/java/parquet/proto/converters/ProtoBooleanConverter.java": 16,
                "src/main/java/parquet/proto/converters/ProtoDoubleConverter.java": 16,
                "src/main/java/parquet/proto/converters/ProtoEnumConverter.java": 16,
                "src/main/java/parquet/proto/converters/ProtoFloatConverter.java": 16,
                "src/main/java/parquet/proto/converters/ProtoIntConverter.java": 16,
                "src/main/java/parquet/proto/converters/ProtoLongConverter.java": 16,
                "src/main/java/parquet/proto/converters/ProtoMessageConverter.java": 16,
                "src/main/java/parquet/proto/converters/ProtobufStringConverter.java": 16
            },
            "is_test": false,
            "is_fix": false
        },
        "492da11c61dfc6d58a8b093affa2b8b6e7054df1": {
            "datetime": "2013-11-01T13:49:09-07:00",
            "summary": "remove hash lookup and unused comments",
            "message": "remove hash lookup and unused comments\n",
            "diff": {
                "parquet-column/src/main/java/parquet/column/values/dictionary/DictionaryValuesWriter.java": 65
            },
            "is_test": false,
            "is_fix": false
        },
        "edfd7d96f939f5602d9338575d6fa5ad243b8b2e": {
            "datetime": "2013-11-01T14:04:57-07:00",
            "summary": "return raw data size as bufferSize in dictionaryValuesWriter",
            "message": "return raw data size as bufferSize in dictionaryValuesWriter\n",
            "diff": {
                "parquet-column/src/main/java/parquet/column/values/dictionary/DictionaryValuesWriter.java": 7
            },
            "is_test": false,
            "is_fix": false
        },
        "66900aada51693bd977cb54cb96e7078001231d1": {
            "datetime": "2013-11-01T14:07:27-07:00",
            "summary": "more comment",
            "message": "more comment\n",
            "diff": {
                "parquet-column/src/main/java/parquet/column/values/dictionary/DictionaryValuesWriter.java": 1
            },
            "is_test": false,
            "is_fix": false
        },
        "7427a895ef33a8b8703e8c7af9a17ffb15fe2bb2": {
            "datetime": "2013-11-01T15:10:17-07:00",
            "summary": "revert fixing page cutting, fix bug, raw data size should be long",
            "message": "revert fixing page cutting, fix bug, raw data size should be long\n",
            "diff": {
                "parquet-column/src/main/java/parquet/column/values/dictionary/DictionaryValuesWriter.java": 9
            },
            "is_test": false,
            "is_fix": false
        },
        "198f5540fdbca63bbd73943a30be79dd9761af4a": {
            "datetime": "2013-11-01T15:32:44-07:00",
            "summary": "revert revert.. use rawDataByteSize as buffered size in DictionaryValuesWriter",
            "message": "revert revert.. use rawDataByteSize as buffered size in DictionaryValuesWriter\n",
            "diff": {
                "parquet-column/src/main/java/parquet/column/values/dictionary/DictionaryValuesWriter.java": 7
            },
            "is_test": false,
            "is_fix": false
        },
        "a7de264ff2fa559ca5d5e6b8a33e3a5d2590952f": {
            "datetime": "2013-11-03T00:53:40+01:00",
            "summary": "Specification of written protobuffer class in output format",
            "message": "Specification of written protobuffer class in output format\n",
            "diff": {
                "src/main/java/parquet/proto/ProtoParquetOutputFormat.java": 23,
                "src/main/java/parquet/proto/ProtoWriteSupport.java": 15
            },
            "is_test": false,
            "is_fix": false
        },
        "2e78704e82f62822f1183131340cbd59c7b7831f": {
            "datetime": "2013-11-03T16:36:59+01:00",
            "summary": "Code cleanup",
            "message": "Code cleanup\n",
            "diff": {
                "src/main/java/parquet/proto/ProtoWriteSupport.java": 19
            },
            "is_test": false,
            "is_fix": false
        },
        "090a2a41e5e7ef8c409fbfc8f872707d3e1907c4": {
            "datetime": "2013-11-03T16:51:10+01:00",
            "summary": "Code Cleanup",
            "message": "Code Cleanup\n",
            "diff": {
                "src/main/java/parquet/proto/ProtoSchemaConverter.java": 14
            },
            "is_test": false,
            "is_fix": false
        },
        "1bec97fa188a450a52289a4836b71edfa607e017": {
            "datetime": "2013-11-03T17:06:03+01:00",
            "summary": "Projections in read support",
            "message": "Projections in read support\n",
            "diff": {
                "src/main/java/parquet/proto/ProtoReadSupport.java": 13
            },
            "is_test": false,
            "is_fix": false
        },
        "0d47734c372a5322e17feea56bf426226b6bebb5": {
            "datetime": "2013-11-04T14:49:49+01:00",
            "summary": "Add test on DeprecatedParquetInputFormat.getSplit()",
            "message": "Add test on DeprecatedParquetInputFormat.getSplit()\n",
            "diff": {
                "parquet-hive/src/main/java/parquet/hive/DeprecatedParquetInputFormat.java": 20,
                "parquet-hive/src/test/java/parquet/hive/TestDeprecatedParquetInputFormat.java": 93,
                "parquet-hive/src/test/java/parquet/hive/UtilitiesTestMethods.java": 34
            },
            "is_test": true,
            "is_fix": false
        },
        "f479aeee14eb7373b8e1daf9e94e1b6a56530736": {
            "datetime": "2013-11-04T11:17:15-08:00",
            "summary": "Merge pull request #208 from Parquet/improve_dic_fall_back",
            "message": "Merge pull request #208 from Parquet/improve_dic_fall_back\n\nImprove dic fall back",
            "diff": {
                "parquet-column/src/main/java/parquet/column/values/dictionary/DictionaryValuesWriter.java": 142,
                "parquet-column/src/test/java/parquet/column/values/dictionary/TestDictionary.java": 133
            },
            "is_test": true,
            "is_fix": false
        },
        "7c2785f95170ca95a786bf33b8427a44b53aeb27": {
            "datetime": "2013-11-05T13:33:58-08:00",
            "summary": "Merge pull request #202 from Parquet/hive_requested_schema",
            "message": "Merge pull request #202 from Parquet/hive_requested_schema\n\nFix requested schema when recreating splits in hive",
            "diff": {
                "parquet-hive/src/main/java/parquet/hive/DeprecatedParquetInputFormat.java": 22,
                "parquet-hive/src/test/java/parquet/hive/TestDeprecatedParquetInputFormat.java": 93,
                "parquet-hive/src/test/java/parquet/hive/UtilitiesTestMethods.java": 34
            },
            "is_test": true,
            "is_fix": false
        },
        "6e9004190ee16ff5e338fd6dbddc1dd56ca2911f": {
            "datetime": "2013-11-05T19:04:32-08:00",
            "summary": "Merge branch 'master' into plumb_original_type",
            "message": "Merge branch 'master' into plumb_original_type\n",
            "diff": {
                "parquet-column/src/main/java/parquet/column/values/dictionary/DictionaryValuesWriter.java": 142,
                "parquet-column/src/main/java/parquet/column/values/rle/RunLengthBitPackingHybridValuesReader.java": 2,
                "parquet-column/src/test/java/parquet/column/values/dictionary/TestDictionary.java": 133,
                "parquet-hive/src/main/java/parquet/hive/DeprecatedParquetInputFormat.java": 22,
                "parquet-hive/src/test/java/parquet/hive/TestDeprecatedParquetInputFormat.java": 93,
                "parquet-hive/src/test/java/parquet/hive/UtilitiesTestMethods.java": 34
            },
            "is_test": true,
            "is_fix": false
        },
        "59bd08b9a98483dec17ca10f9dd3d9eaae1ce774": {
            "datetime": "2013-11-06T14:19:34-05:00",
            "summary": "One of the constructors in ParquetWriter ignores",
            "message": "One of the constructors in ParquetWriter ignores\nthe enable dictionary and validating flags.\n",
            "diff": {
                "parquet-hadoop/src/main/java/parquet/hadoop/ParquetWriter.java": 2
            },
            "is_test": false,
            "is_fix": false
        },
        "484915554e374b1322bc5e5cdf47442077133d55": {
            "datetime": "2013-11-06T14:56:31-08:00",
            "summary": "Merge pull request #210 from wesleypeck/fixwriter",
            "message": "Merge pull request #210 from wesleypeck/fixwriter\n\nParquetWriter ignores enable dictionary and validating flags.",
            "diff": {
                "parquet-hadoop/src/main/java/parquet/hadoop/ParquetWriter.java": 2
            },
            "is_test": false,
            "is_fix": false
        },
        "402e96dfb58077cdf3e6bf2e496bdca6bad11743": {
            "datetime": "2013-11-09T22:43:56+01:00",
            "summary": "Wrong merge",
            "message": "Wrong merge\n",
            "diff": {
                "src/main/java/parquet/proto/ProtoWriteSupport.java": 1
            },
            "is_test": false,
            "is_fix": false
        },
        "8af5a22fd64699fe6c7063870a82704c81dd8bff": {
            "datetime": "2013-11-13T17:32:55-08:00",
            "summary": "Fix Binary.equals().",
            "message": "Fix Binary.equals().\n",
            "diff": {
                "parquet-column/src/main/java/parquet/io/api/Binary.java": 3
            },
            "is_test": false,
            "is_fix": false
        },
        "0b3400add17a2920ca96b757cd45d361c5022cf0": {
            "datetime": "2013-11-13T18:01:53-08:00",
            "summary": "Merge pull request #215 from Parquet/binary_equals",
            "message": "Merge pull request #215 from Parquet/binary_equals\n\nFix Binary.equals().",
            "diff": {
                "parquet-column/src/main/java/parquet/io/api/Binary.java": 3
            },
            "is_test": false,
            "is_fix": false
        },
        "f4d6e17d027eeadc379ffab9498e1f392b82f514": {
            "datetime": "2013-11-15T13:35:04-08:00",
            "summary": "Merge branch 'master' into plumb_original_type",
            "message": "Merge branch 'master' into plumb_original_type\n",
            "diff": {
                "parquet-column/src/main/java/parquet/io/api/Binary.java": 3,
                "parquet-hadoop/src/main/java/parquet/hadoop/ParquetWriter.java": 2
            },
            "is_test": false,
            "is_fix": false
        },
        "0334948eadddfac9891277d673117e6b4bec0d7e": {
            "datetime": "2013-11-19T10:26:37-06:00",
            "summary": "parquet-hive should ship and uber jar",
            "message": "parquet-hive should ship and uber jar\n\n* Creates parquet-hive-bundle which is an uber jar of dependencies required for Hive.\n* Removes runtime dependency on commons-lang\n* Marks Hadoop and Hive dependencies as optional so they don't have to be excluded by dependees\n",
            "diff": {
                "parquet-hive/src/main/java/parquet/hive/convert/HiveSchemaConverter.java": 11,
                "parquet-hive/src/main/java/parquet/hive/serde/ArrayWritableObjectInspector.java": 3,
                "parquet-hive/src/main/java/parquet/hive/write/DataWritableWriter.java": 3
            },
            "is_test": false,
            "is_fix": false
        },
        "700c223954d9d9508812a985b39f8542845635e9": {
            "datetime": "2013-11-19T14:10:03-08:00",
            "summary": "Merge pull request #220 from brockn/master",
            "message": "Merge pull request #220 from brockn/master\n\nIssue #219 - parquet-hive should ship and uber jar",
            "diff": {
                "parquet-hive/src/main/java/parquet/hive/convert/HiveSchemaConverter.java": 11,
                "parquet-hive/src/main/java/parquet/hive/serde/ArrayWritableObjectInspector.java": 3,
                "parquet-hive/src/main/java/parquet/hive/write/DataWritableWriter.java": 3
            },
            "is_test": false,
            "is_fix": false
        },
        "e54735a988f331dced9317dbccdd317c72e16f66": {
            "datetime": "2013-11-19T14:25:26-08:00",
            "summary": "Merge branch 'master' into cleanup_dependencies",
            "message": "Merge branch 'master' into cleanup_dependencies\n",
            "diff": {
                "parquet-hive/src/main/java/parquet/hive/convert/HiveSchemaConverter.java": 11,
                "parquet-hive/src/main/java/parquet/hive/serde/ArrayWritableObjectInspector.java": 3,
                "parquet-hive/src/main/java/parquet/hive/write/DataWritableWriter.java": 3
            },
            "is_test": false,
            "is_fix": false
        },
        "6b5d2d1399c62c5d58436befd72a09491e29904b": {
            "datetime": "2013-11-20T13:30:36-08:00",
            "summary": "fix bug: set raw data size to 0 after reset",
            "message": "fix bug: set raw data size to 0 after reset\n",
            "diff": {
                "parquet-column/src/main/java/parquet/column/values/dictionary/DictionaryValuesWriter.java": 1,
                "parquet-column/src/test/java/parquet/column/values/dictionary/TestDictionary.java": 22
            },
            "is_test": true,
            "is_fix": false
        },
        "8e1110b1433199d6fd638d04b013ec806c52f729": {
            "datetime": "2013-11-20T14:17:59-08:00",
            "summary": "Merge pull request #222 from Parquet/fix_dic_fallback_page_cutting",
            "message": "Merge pull request #222 from Parquet/fix_dic_fallback_page_cutting\n\nfix bug: set raw data size to 0 after reset",
            "diff": {
                "parquet-column/src/main/java/parquet/column/values/dictionary/DictionaryValuesWriter.java": 1,
                "parquet-column/src/test/java/parquet/column/values/dictionary/TestDictionary.java": 22
            },
            "is_test": true,
            "is_fix": false
        },
        "f4ad9dfc394f1336e68444944e41772d6d435744": {
            "datetime": "2013-11-20T14:50:10-08:00",
            "summary": "refactor encoded values changes and test that resetDictionary works",
            "message": "refactor encoded values changes and test that resetDictionary works\n",
            "diff": {
                "parquet-column/src/main/java/parquet/column/values/dictionary/DictionaryValuesWriter.java": 10,
                "parquet-column/src/test/java/parquet/column/values/dictionary/TestDictionary.java": 122
            },
            "is_test": true,
            "is_fix": false
        },
        "e0c5ac84285e4aaa6f684f45249bb7f0245480ac": {
            "datetime": "2013-11-20T15:09:30-08:00",
            "summary": "Merge pull request #223 from Parquet/dictionary_reset",
            "message": "Merge pull request #223 from Parquet/dictionary_reset\n\nrefactor encoded values changes and test that resetDictionary works",
            "diff": {
                "parquet-column/src/main/java/parquet/column/values/dictionary/DictionaryValuesWriter.java": 10,
                "parquet-column/src/test/java/parquet/column/values/dictionary/TestDictionary.java": 122
            },
            "is_test": true,
            "is_fix": false
        },
        "493bb9fd70a008e7c083509d93a419c99fd7bc26": {
            "datetime": "2013-11-22T02:31:12-08:00",
            "summary": "Changing read and write methods in ParquetInputSplit so that they can deal with large schemas (avoiding use of writeUTF and readUTF which are limited to 65536 characters).",
            "message": "Changing read and write methods in ParquetInputSplit so that they can deal with large schemas (avoiding use of writeUTF and readUTF which are limited to 65536 characters).\n",
            "diff": {
                "parquet-hadoop/src/main/java/parquet/hadoop/ParquetInputSplit.java": 9
            },
            "is_test": false,
            "is_fix": false
        },
        "d2ccc72cb739ada1ce3d5ae9af7032952908352c": {
            "datetime": "2013-11-26T13:30:13-06:00",
            "summary": "Breaks parquet-hive up into several submodules, creating infrastructure to handle",
            "message": "Breaks parquet-hive up into several submodules, creating infrastructure to handle\nvarious versions of Hive going forward.\n\n* parquet-hive-storage-handler - this is almost all the previous code\n* parquet-hive-binding - contains the various binding modules for specific hive versions\n* parquet-hive-binding-interface - the interface the storage handler compiles to\n* parquet-hive-binding-factory - factory which can depend on interface, 0.10, and 0.12\n* parquet-hive-0.10-binding - binding layer for 0.10 (and 0.11)\n* parquet-hive-0.12-binding - binding layer for 0.12 (and 0.13)\n",
            "diff": {
                "parquet-hive/parquet-hive-binding/parquet-hive-0.12-binding/src/main/java/parquet/hive/internal/Hive012Binding.java": 135,
                "parquet-hive/parquet-hive-binding/parquet-hive-binding-factory/src/main/java/parquet/hive/HiveBindingFactory.java": 104,
                "parquet-hive/parquet-hive-binding/parquet-hive-binding-factory/src/test/java/parquet/hive/TestHiveBindingFactory.java": 106,
                "parquet-hive/parquet-hive-binding/parquet-hive-binding-interface/src/main/java/parquet/hive/HiveBinding.java": 48,
                "parquet-hive/parquet-hive-binding/parquet-hive-binding-interface/src/main/java/parquet/hive/internal/AbstractHiveBinding.java": 31,
                "parquet-hive/src/main/java/parquet/hive/DeprecatedParquetInputFormat.java": 33,
                "parquet-hive/src/main/java/parquet/hive/DeprecatedParquetOutputFormat.java": 0,
                "parquet-hive/src/main/java/parquet/hive/ManageJobConfig.java": 74,
                "parquet-hive/src/main/java/parquet/hive/convert/ArrayWritableGroupConverter.java": 0,
                "parquet-hive/src/main/java/parquet/hive/convert/DataWritableGroupConverter.java": 0,
                "parquet-hive/src/main/java/parquet/hive/convert/DataWritableRecordConverter.java": 0,
                "parquet-hive/src/main/java/parquet/hive/convert/ETypeConverter.java": 0,
                "parquet-hive/src/main/java/parquet/hive/convert/HiveGroupConverter.java": 0,
                "parquet-hive/src/main/java/parquet/hive/convert/HiveSchemaConverter.java": 0,
                "parquet-hive/src/main/java/parquet/hive/read/DataWritableReadSupport.java": 5,
                "parquet-hive/src/main/java/parquet/hive/serde/AbstractParquetMapInspector.java": 0,
                "parquet-hive/src/main/java/parquet/hive/serde/ArrayWritableObjectInspector.java": 0,
                "parquet-hive/src/main/java/parquet/hive/serde/DeepParquetHiveMapInspector.java": 0,
                "parquet-hive/src/main/java/parquet/hive/serde/ParquetHiveArrayInspector.java": 0,
                "parquet-hive/src/main/java/parquet/hive/serde/ParquetHiveSerDe.java": 0,
                "parquet-hive/src/main/java/parquet/hive/serde/StandardParquetHiveMapInspector.java": 0,
                "parquet-hive/src/main/java/parquet/hive/serde/primitive/ParquetByteInspector.java": 0,
                "parquet-hive/src/main/java/parquet/hive/serde/primitive/ParquetPrimitiveInspectorFactory.java": 0,
                "parquet-hive/src/main/java/parquet/hive/serde/primitive/ParquetShortInspector.java": 0,
                "parquet-hive/src/main/java/parquet/hive/serde/primitive/ParquetStringInspector.java": 0,
                "parquet-hive/src/main/java/parquet/hive/writable/BigDecimalWritable.java": 0,
                "parquet-hive/src/main/java/parquet/hive/writable/BinaryWritable.java": 0,
                "parquet-hive/src/main/java/parquet/hive/write/DataWritableWriteSupport.java": 0,
                "parquet-hive/src/main/java/parquet/hive/write/DataWritableWriter.java": 0,
                "parquet-hive/src/test/java/parquet/hive/TestDeprecatedParquetInputFormat.java": 0,
                "parquet-hive/src/test/java/parquet/hive/TestDeprecatedParquetOuputFormat.java": 0,
                "parquet-hive/src/test/java/parquet/hive/TestHiveSchemaConverter.java": 0,
                "parquet-hive/src/test/java/parquet/hive/TestParquetSerDe.java": 0,
                "parquet-hive/src/test/java/parquet/hive/UtilitiesTestMethods.java": 0
            },
            "is_test": true,
            "is_fix": false
        },
        "f18bc49046d51e1700d419e401ad49093322771d": {
            "datetime": "2013-11-26T15:10:15-08:00",
            "summary": "enable globing files for parquetTupleScheme, refactor unit tests and remove binary test fixture",
            "message": "enable globing files for parquetTupleScheme, refactor unit tests and remove binary test fixture\n",
            "diff": {
                "parquet-cascading/src/main/java/parquet/cascading/ParquetTupleScheme.java": 6,
                "parquet-cascading/src/test/java/parquet/cascading/TestParquetTupleScheme.java": 192,
                "parquet-hadoop/src/main/java/parquet/hadoop/mapred/DeprecatedParquetInputFormat.java": 8
            },
            "is_test": true,
            "is_fix": false
        },
        "d7c8467f4614483f3d2aa5f872f9a603c3725ad3": {
            "datetime": "2013-11-26T18:26:48-08:00",
            "summary": "Merge pull request #224 from dave2718/master",
            "message": "Merge pull request #224 from dave2718/master\n\nChanging read and write methods in ParquetInputSplit so that they can de...",
            "diff": {
                "parquet-hadoop/src/main/java/parquet/hadoop/ParquetInputSplit.java": 9
            },
            "is_test": false,
            "is_fix": false
        },
        "60c651262e87540bd06f884b25c66ede491c34b7": {
            "datetime": "2013-11-27T11:00:22-06:00",
            "summary": "Updates Hive 0.12 compatability patch by adressing all comments",
            "message": "Updates Hive 0.12 compatability patch by adressing all comments\nfrom Julien's review plus a few additional cleanups, specifically:\n\n* If hive is version 0.12 or newer return 0.12 binding\n* Adds javadoc and inheritDoc statements where appropiate\n* Add's link to Hive*Binding implementations describing where code came from\n* Renames Deprecated{Input,Output}Format to Mapred{Input,Output}Format\n* Creates shell classes Deprecated{Input,Output}Format inheriting from Mapred{Input,Output}Format\n* Moves TestMapred{Input,Output}Format to the JUnit 4 API\n* Replaces Apache licenses in files touched with the version capped at a shorter line length\n* Add's debug log statements to the binding layers to log items of interest\n",
            "diff": {
                "parquet-hive/parquet-hive-binding/parquet-hive-0.10-binding/src/main/java/parquet/hive/internal/Hive010Binding.java": 39,
                "parquet-hive/parquet-hive-binding/parquet-hive-0.12-binding/src/main/java/parquet/hive/internal/Hive012Binding.java": 40,
                "parquet-hive/parquet-hive-binding/parquet-hive-binding-factory/src/main/java/parquet/hive/HiveBindingFactory.java": 48,
                "parquet-hive/parquet-hive-binding/parquet-hive-binding-factory/src/test/java/parquet/hive/TestHiveBindingFactory.java": 11,
                "parquet-hive/parquet-hive-binding/parquet-hive-binding-interface/src/main/java/parquet/hive/HiveBinding.java": 12,
                "parquet-hive/parquet-hive-binding/parquet-hive-binding-interface/src/main/java/parquet/hive/internal/AbstractHiveBinding.java": 9,
                "parquet-hive/parquet-hive-storage-handler/src/main/java/parquet/hive/DeprecatedParquetInputFormat.java": 370,
                "parquet-hive/parquet-hive-storage-handler/src/main/java/parquet/hive/DeprecatedParquetOutputFormat.java": 159,
                "parquet-hive/parquet-hive-storage-handler/src/main/java/parquet/hive/MapredParquetInputFormat.java": 379,
                "parquet-hive/parquet-hive-storage-handler/src/main/java/parquet/hive/MapredParquetOutputFormat.java": 167,
                "parquet-hive/parquet-hive-storage-handler/src/main/java/parquet/hive/read/DataWritableReadSupport.java": 2,
                "parquet-hive/parquet-hive-storage-handler/src/test/java/parquet/hive/TestDeprecatedParquetInputFormat.java": 60,
                "parquet-hive/parquet-hive-storage-handler/src/test/java/parquet/hive/TestDeprecatedParquetOuputFormat.java": 52
            },
            "is_test": true,
            "is_fix": false
        },
        "4d13df5a42a3212914e2da6c9e479607aeff5ddc": {
            "datetime": "2013-11-27T10:23:28-08:00",
            "summary": "encapuslate getFooter into a separate method",
            "message": "encapuslate getFooter into a separate method\n",
            "diff": {
                "parquet-cascading/src/main/java/parquet/cascading/ParquetTupleScheme.java": 14
            },
            "is_test": false,
            "is_fix": false
        },
        "c31a6be5e50a303ab8d12f810a1f3a44c3326272": {
            "datetime": "2013-11-27T11:35:45-08:00",
            "summary": "Merge pull request #228 from Parquet/glob_files_for_parquet_tuple_scheme",
            "message": "Merge pull request #228 from Parquet/glob_files_for_parquet_tuple_scheme\n\nenable globing files for parquetTupleScheme, refactor unit tests and rem...",
            "diff": {
                "parquet-cascading/src/main/java/parquet/cascading/ParquetTupleScheme.java": 12,
                "parquet-cascading/src/test/java/parquet/cascading/TestParquetTupleScheme.java": 192,
                "parquet-hadoop/src/main/java/parquet/hadoop/mapred/DeprecatedParquetInputFormat.java": 8
            },
            "is_test": true,
            "is_fix": false
        },
        "b297c73c1082728ad9626d17ce0f7abe6abaa36b": {
            "datetime": "2013-12-03T11:54:55-08:00",
            "summary": "optimize chunk scan; fix compressed size",
            "message": "optimize chunk scan; fix compressed size\n",
            "diff": {
                "parquet-hadoop/src/main/java/parquet/hadoop/ParquetFileReader.java": 43,
                "parquet-hadoop/src/main/java/parquet/hadoop/ParquetFileWriter.java": 5
            },
            "is_test": false,
            "is_fix": false
        },
        "476b8ea875c653fee292b8fa4291cf2834102442": {
            "datetime": "2013-12-03T12:16:17-08:00",
            "summary": "Merge branch 'master' into plumb_original_type",
            "message": "Merge branch 'master' into plumb_original_type\n",
            "diff": {
                "parquet-cascading/src/main/java/parquet/cascading/ParquetTupleScheme.java": 12,
                "parquet-cascading/src/test/java/parquet/cascading/TestParquetTupleScheme.java": 192,
                "parquet-column/src/main/java/parquet/column/values/dictionary/DictionaryValuesWriter.java": 11,
                "parquet-column/src/test/java/parquet/column/values/dictionary/TestDictionary.java": 134,
                "parquet-hadoop/src/main/java/parquet/hadoop/ParquetInputSplit.java": 9,
                "parquet-hadoop/src/main/java/parquet/hadoop/mapred/DeprecatedParquetInputFormat.java": 8,
                "parquet-hive/src/main/java/parquet/hive/convert/HiveSchemaConverter.java": 11,
                "parquet-hive/src/main/java/parquet/hive/serde/ArrayWritableObjectInspector.java": 3,
                "parquet-hive/src/main/java/parquet/hive/write/DataWritableWriter.java": 3
            },
            "is_test": true,
            "is_fix": false
        },
        "e1ce0632157706beed11f3ecf12590cd33bc711a": {
            "datetime": "2013-12-03T14:35:54-08:00",
            "summary": "check if pig is loaded when writing pig metadata",
            "message": "check if pig is loaded when writing pig metadata\n",
            "diff": {
                "parquet-thrift/src/main/java/parquet/hadoop/thrift/ThriftWriteSupport.java": 17
            },
            "is_test": false,
            "is_fix": false
        },
        "7dfd436245c4ff9ced2bf9ab07cb0fe4289734a0": {
            "datetime": "2013-12-03T16:28:56-08:00",
            "summary": "format",
            "message": "format\n",
            "diff": {
                "parquet-thrift/src/main/java/parquet/hadoop/thrift/ThriftWriteSupport.java": 2
            },
            "is_test": false,
            "is_fix": false
        },
        "3b829a21759d3a2e47f95a2cb880e4abfc4ba6fe": {
            "datetime": "2013-12-03T22:50:46-08:00",
            "summary": "refactor get codec logic to remove duplication in DeprecatedParquetOutputFormat",
            "message": "refactor get codec logic to remove duplication in DeprecatedParquetOutputFormat\n",
            "diff": {
                "parquet-hadoop/src/main/java/parquet/hadoop/ParquetOutputFormat.java": 93,
                "parquet-hadoop/src/main/java/parquet/hadoop/mapred/DeprecatedParquetOutputFormat.java": 38
            },
            "is_test": false,
            "is_fix": false
        },
        "407a52d538c31f65e3ba313c1d7be4fb5f9831b8": {
            "datetime": "2013-12-04T15:00:34-08:00",
            "summary": "fix missing codec",
            "message": "fix missing codec\n",
            "diff": {
                "parquet-hadoop/src/main/java/parquet/hadoop/CodecFactory.java": 2,
                "parquet-hadoop/src/main/java/parquet/hadoop/ParquetOutputFormat.java": 64,
                "parquet-hadoop/src/main/java/parquet/hadoop/codec/CompressionCodecNotSupportedException.java": 14,
                "parquet-hadoop/src/main/java/parquet/hadoop/codec/HadoopCodecConfig.java": 92,
                "parquet-hadoop/src/main/java/parquet/hadoop/codec/MapReduceCodecConfig.java": 48,
                "parquet-hadoop/src/main/java/parquet/hadoop/codec/MapredCodecConfig.java": 46,
                "parquet-hadoop/src/main/java/parquet/hadoop/mapred/DeprecatedParquetOutputFormat.java": 28,
                "parquet-hadoop/src/main/java/parquet/hadoop/metadata/CompressionCodecName.java": 19,
                "parquet-hadoop/src/test/java/parquet/hadoop/codec/MapReduceCodecConfigTest.java": 46
            },
            "is_test": true,
            "is_fix": false
        },
        "7641febd3373d5703596dfafaaf8e304a716856c": {
            "datetime": "2013-12-04T16:09:52-08:00",
            "summary": "Merge pull request #227 from brockn/master",
            "message": "Merge pull request #227 from brockn/master\n\nBreaks parquet-hive up into several submodules, creating infrastructure ...",
            "diff": {
                "parquet-hive/parquet-hive-binding/parquet-hive-0.12-binding/src/main/java/parquet/hive/internal/Hive012Binding.java": 149,
                "parquet-hive/parquet-hive-binding/parquet-hive-binding-factory/src/main/java/parquet/hive/HiveBindingFactory.java": 120,
                "parquet-hive/parquet-hive-binding/parquet-hive-binding-factory/src/test/java/parquet/hive/TestHiveBindingFactory.java": 109,
                "parquet-hive/parquet-hive-binding/parquet-hive-binding-interface/src/main/java/parquet/hive/HiveBinding.java": 52,
                "parquet-hive/parquet-hive-binding/parquet-hive-binding-interface/src/main/java/parquet/hive/internal/AbstractHiveBinding.java": 36,
                "parquet-hive/parquet-hive-storage-handler/src/main/java/parquet/hive/DeprecatedParquetInputFormat.java": 35,
                "parquet-hive/parquet-hive-storage-handler/src/main/java/parquet/hive/DeprecatedParquetOutputFormat.java": 35,
                "parquet-hive/src/main/java/parquet/hive/DeprecatedParquetInputFormat.java": 65,
                "parquet-hive/src/main/java/parquet/hive/DeprecatedParquetOutputFormat.java": 21,
                "parquet-hive/src/main/java/parquet/hive/ManageJobConfig.java": 99,
                "parquet-hive/src/main/java/parquet/hive/convert/ArrayWritableGroupConverter.java": 0,
                "parquet-hive/src/main/java/parquet/hive/convert/DataWritableGroupConverter.java": 0,
                "parquet-hive/src/main/java/parquet/hive/convert/DataWritableRecordConverter.java": 0,
                "parquet-hive/src/main/java/parquet/hive/convert/ETypeConverter.java": 0,
                "parquet-hive/src/main/java/parquet/hive/convert/HiveGroupConverter.java": 0,
                "parquet-hive/src/main/java/parquet/hive/convert/HiveSchemaConverter.java": 0,
                "parquet-hive/src/main/java/parquet/hive/read/DataWritableReadSupport.java": 5,
                "parquet-hive/src/main/java/parquet/hive/serde/AbstractParquetMapInspector.java": 0,
                "parquet-hive/src/main/java/parquet/hive/serde/ArrayWritableObjectInspector.java": 0,
                "parquet-hive/src/main/java/parquet/hive/serde/DeepParquetHiveMapInspector.java": 0,
                "parquet-hive/src/main/java/parquet/hive/serde/ParquetHiveArrayInspector.java": 0,
                "parquet-hive/src/main/java/parquet/hive/serde/ParquetHiveSerDe.java": 0,
                "parquet-hive/src/main/java/parquet/hive/serde/StandardParquetHiveMapInspector.java": 0,
                "parquet-hive/src/main/java/parquet/hive/serde/primitive/ParquetByteInspector.java": 0,
                "parquet-hive/src/main/java/parquet/hive/serde/primitive/ParquetPrimitiveInspectorFactory.java": 0,
                "parquet-hive/src/main/java/parquet/hive/serde/primitive/ParquetShortInspector.java": 0,
                "parquet-hive/src/main/java/parquet/hive/serde/primitive/ParquetStringInspector.java": 0,
                "parquet-hive/src/main/java/parquet/hive/writable/BigDecimalWritable.java": 0,
                "parquet-hive/src/main/java/parquet/hive/writable/BinaryWritable.java": 0,
                "parquet-hive/src/main/java/parquet/hive/write/DataWritableWriteSupport.java": 0,
                "parquet-hive/src/main/java/parquet/hive/write/DataWritableWriter.java": 0,
                "parquet-hive/src/test/java/parquet/hive/TestDeprecatedParquetInputFormat.java": 60,
                "parquet-hive/src/test/java/parquet/hive/TestDeprecatedParquetOuputFormat.java": 52,
                "parquet-hive/src/test/java/parquet/hive/TestHiveSchemaConverter.java": 0,
                "parquet-hive/src/test/java/parquet/hive/TestParquetSerDe.java": 0,
                "parquet-hive/src/test/java/parquet/hive/UtilitiesTestMethods.java": 0
            },
            "is_test": true,
            "is_fix": false
        },
        "716a030d9cd05b47dd0e78dadb5311ab0594adf6": {
            "datetime": "2013-12-04T16:42:54-08:00",
            "summary": "remove lzo test and lzo dependency",
            "message": "remove lzo test and lzo dependency\n",
            "diff": {
                "parquet-hadoop/src/main/java/parquet/hadoop/codec/HadoopCodecConfig.java": 36,
                "parquet-hadoop/src/test/java/parquet/hadoop/codec/MapReduceCodecConfigTest.java": 33
            },
            "is_test": true,
            "is_fix": false
        },
        "0b61cd9df927e2657712739ba3dd1b7e602f0b25": {
            "datetime": "2013-12-04T17:13:33-08:00",
            "summary": "Merge branch 'not_write_pig_meta_data_only_when_pig_is_not_avaliable' into handle_codec_not_found",
            "message": "Merge branch 'not_write_pig_meta_data_only_when_pig_is_not_avaliable' into handle_codec_not_found\n",
            "diff": {
                "parquet-thrift/src/main/java/parquet/hadoop/thrift/ThriftWriteSupport.java": 17
            },
            "is_test": false,
            "is_fix": false
        },
        "5a04096a4a09f8ad26ff01be05d20836643f54b9": {
            "datetime": "2013-12-04T22:11:03-08:00",
            "summary": "license header",
            "message": "license header\n",
            "diff": {
                "parquet-hadoop/src/main/java/parquet/hadoop/codec/CompressionCodecNotSupportedException.java": 15,
                "parquet-hadoop/src/test/java/parquet/hadoop/codec/HadoopCodecConfigTest.java": 15
            },
            "is_test": true,
            "is_fix": false
        },
        "491481e96db9eae8a139466cd6a2a2b6b2fdffe3": {
            "datetime": "2013-12-05T10:53:14-08:00",
            "summary": "Merge pull request #235 from Parquet/not_write_pig_meta_data_only_when_pig_is_not_avaliable",
            "message": "Merge pull request #235 from Parquet/not_write_pig_meta_data_only_when_pig_is_not_avaliable\n\nNot write pig meta data only when pig is not avaliable",
            "diff": {
                "parquet-thrift/src/main/java/parquet/hadoop/thrift/ThriftWriteSupport.java": 17
            },
            "is_test": false,
            "is_fix": false
        },
        "f7b2cd78fc1b8f0c22edf1d5537fe37dc6c28d50": {
            "datetime": "2013-12-05T11:36:53-08:00",
            "summary": "make CodecConfig a factory",
            "message": "make CodecConfig a factory\n",
            "diff": {
                "parquet-hadoop/src/main/java/parquet/hadoop/ParquetOutputFormat.java": 12,
                "parquet-hadoop/src/main/java/parquet/hadoop/codec/CompressionCodecNotSupportedException.java": 4,
                "parquet-hadoop/src/main/java/parquet/hadoop/codec/HadoopCodecConfig.java": 101,
                "parquet-hadoop/src/main/java/parquet/hadoop/codec/MapReduceCodecConfig.java": 48,
                "parquet-hadoop/src/main/java/parquet/hadoop/codec/MapredCodecConfig.java": 46,
                "parquet-hadoop/src/main/java/parquet/hadoop/mapred/DeprecatedParquetOutputFormat.java": 4,
                "parquet-hadoop/src/test/java/parquet/hadoop/codec/HadoopCodecConfigTest.java": 10
            },
            "is_test": true,
            "is_fix": false
        },
        "2e3a37018bf9b92224975fab5e2708d6c2c5328b": {
            "datetime": "2013-12-05T11:51:16-08:00",
            "summary": "restore getCompression methods in ParquetOutputFormat for compatibility",
            "message": "restore getCompression methods in ParquetOutputFormat for compatibility\n",
            "diff": {
                "parquet-hadoop/src/main/java/parquet/hadoop/ParquetOutputFormat.java": 8,
                "parquet-hadoop/src/main/java/parquet/hadoop/codec/CodecConfig.java": 3
            },
            "is_test": false,
            "is_fix": false
        },
        "8958626f6453e828b3fb27a14159f0ef810d6e56": {
            "datetime": "2013-12-05T16:04:25-08:00",
            "summary": "Merge branch 'master' into handle_codec_not_found",
            "message": "Merge branch 'master' into handle_codec_not_found\n",
            "diff": {
                "parquet-hive/parquet-hive-binding/parquet-hive-0.12-binding/src/main/java/parquet/hive/internal/Hive012Binding.java": 149,
                "parquet-hive/parquet-hive-binding/parquet-hive-binding-factory/src/main/java/parquet/hive/HiveBindingFactory.java": 120,
                "parquet-hive/parquet-hive-binding/parquet-hive-binding-factory/src/test/java/parquet/hive/TestHiveBindingFactory.java": 109,
                "parquet-hive/parquet-hive-binding/parquet-hive-binding-interface/src/main/java/parquet/hive/HiveBinding.java": 52,
                "parquet-hive/parquet-hive-binding/parquet-hive-binding-interface/src/main/java/parquet/hive/internal/AbstractHiveBinding.java": 36,
                "parquet-hive/parquet-hive-storage-handler/src/main/java/parquet/hive/DeprecatedParquetInputFormat.java": 35,
                "parquet-hive/parquet-hive-storage-handler/src/main/java/parquet/hive/DeprecatedParquetOutputFormat.java": 35,
                "parquet-hive/src/main/java/parquet/hive/DeprecatedParquetInputFormat.java": 65,
                "parquet-hive/src/main/java/parquet/hive/DeprecatedParquetOutputFormat.java": 21,
                "parquet-hive/src/main/java/parquet/hive/ManageJobConfig.java": 99,
                "parquet-hive/src/main/java/parquet/hive/convert/ArrayWritableGroupConverter.java": 0,
                "parquet-hive/src/main/java/parquet/hive/convert/DataWritableGroupConverter.java": 0,
                "parquet-hive/src/main/java/parquet/hive/convert/DataWritableRecordConverter.java": 0,
                "parquet-hive/src/main/java/parquet/hive/convert/ETypeConverter.java": 0,
                "parquet-hive/src/main/java/parquet/hive/convert/HiveGroupConverter.java": 0,
                "parquet-hive/src/main/java/parquet/hive/convert/HiveSchemaConverter.java": 0,
                "parquet-hive/src/main/java/parquet/hive/read/DataWritableReadSupport.java": 5,
                "parquet-hive/src/main/java/parquet/hive/serde/AbstractParquetMapInspector.java": 0,
                "parquet-hive/src/main/java/parquet/hive/serde/ArrayWritableObjectInspector.java": 0,
                "parquet-hive/src/main/java/parquet/hive/serde/DeepParquetHiveMapInspector.java": 0,
                "parquet-hive/src/main/java/parquet/hive/serde/ParquetHiveArrayInspector.java": 0,
                "parquet-hive/src/main/java/parquet/hive/serde/ParquetHiveSerDe.java": 0,
                "parquet-hive/src/main/java/parquet/hive/serde/StandardParquetHiveMapInspector.java": 0,
                "parquet-hive/src/main/java/parquet/hive/serde/primitive/ParquetByteInspector.java": 0,
                "parquet-hive/src/main/java/parquet/hive/serde/primitive/ParquetPrimitiveInspectorFactory.java": 0,
                "parquet-hive/src/main/java/parquet/hive/serde/primitive/ParquetShortInspector.java": 0,
                "parquet-hive/src/main/java/parquet/hive/serde/primitive/ParquetStringInspector.java": 0,
                "parquet-hive/src/main/java/parquet/hive/writable/BigDecimalWritable.java": 0,
                "parquet-hive/src/main/java/parquet/hive/writable/BinaryWritable.java": 0,
                "parquet-hive/src/main/java/parquet/hive/write/DataWritableWriteSupport.java": 0,
                "parquet-hive/src/main/java/parquet/hive/write/DataWritableWriter.java": 0,
                "parquet-hive/src/test/java/parquet/hive/TestDeprecatedParquetInputFormat.java": 60,
                "parquet-hive/src/test/java/parquet/hive/TestDeprecatedParquetOuputFormat.java": 52,
                "parquet-hive/src/test/java/parquet/hive/TestHiveSchemaConverter.java": 0,
                "parquet-hive/src/test/java/parquet/hive/TestParquetSerDe.java": 0,
                "parquet-hive/src/test/java/parquet/hive/UtilitiesTestMethods.java": 0
            },
            "is_test": true,
            "is_fix": false
        },
        "e8796802ad20acc562e77a08a7114f6eb57e9396": {
            "datetime": "2013-12-05T16:36:19-08:00",
            "summary": "Merge pull request #237 from Parquet/handle_codec_not_found",
            "message": "Merge pull request #237 from Parquet/handle_codec_not_found\n\nHandle codec not found",
            "diff": {
                "parquet-hadoop/src/main/java/parquet/hadoop/CodecFactory.java": 2,
                "parquet-hadoop/src/main/java/parquet/hadoop/ParquetOutputFormat.java": 29,
                "parquet-hadoop/src/main/java/parquet/hadoop/codec/CodecConfig.java": 166,
                "parquet-hadoop/src/main/java/parquet/hadoop/codec/CompressionCodecNotSupportedException.java": 33,
                "parquet-hadoop/src/main/java/parquet/hadoop/mapred/DeprecatedParquetOutputFormat.java": 26,
                "parquet-hadoop/src/main/java/parquet/hadoop/metadata/CompressionCodecName.java": 19,
                "parquet-hadoop/src/test/java/parquet/hadoop/codec/CodecConfigTest.java": 74
            },
            "is_test": true,
            "is_fix": false
        },
        "92a47b2d9eb76ca3ee0756a934e807b8aa72b49a": {
            "datetime": "2013-12-06T16:18:03+01:00",
            "summary": "Fix hive map and array inspectors with null containers",
            "message": "Fix hive map and array inspectors with null containers\n\n- This can happen if the data was not generated by Hive\n- Also add unit tests on these\n",
            "diff": {
                "parquet-hive/parquet-hive-storage-handler/src/main/java/parquet/hive/serde/AbstractParquetMapInspector.java": 12,
                "parquet-hive/parquet-hive-storage-handler/src/main/java/parquet/hive/serde/DeepParquetHiveMapInspector.java": 5,
                "parquet-hive/parquet-hive-storage-handler/src/main/java/parquet/hive/serde/ParquetHiveArrayInspector.java": 24,
                "parquet-hive/parquet-hive-storage-handler/src/main/java/parquet/hive/serde/StandardParquetHiveMapInspector.java": 5,
                "parquet-hive/parquet-hive-storage-handler/src/test/java/parquet/hive/serde/TestAbstractParquetMapInspector.java": 102,
                "parquet-hive/parquet-hive-storage-handler/src/test/java/parquet/hive/serde/TestDeepParquetHiveMapInspector.java": 94,
                "parquet-hive/parquet-hive-storage-handler/src/test/java/parquet/hive/serde/TestParquetHiveArrayInspector.java": 84,
                "parquet-hive/parquet-hive-storage-handler/src/test/java/parquet/hive/serde/TestStandardParquetHiveMapInspector.java": 92
            },
            "is_test": true,
            "is_fix": false
        },
        "a39ad4cdf231adaf7ce18c10bce406eea529fc16": {
            "datetime": "2013-12-06T11:38:07-08:00",
            "summary": "fix loader cache",
            "message": "fix loader cache\n",
            "diff": {
                "parquet-pig/src/main/java/parquet/pig/ParquetLoader.java": 20
            },
            "is_test": false,
            "is_fix": false
        },
        "ca01d15d79f8c6197e38c24fa6543f591f6efdc7": {
            "datetime": "2013-12-06T12:45:55-08:00",
            "summary": "make the cache use a SoftReference",
            "message": "make the cache use a SoftReference\n",
            "diff": {
                "parquet-pig/src/main/java/parquet/pig/ParquetLoader.java": 8
            },
            "is_test": false,
            "is_fix": false
        },
        "aca1d8b895fb6f47e1e97e1f0133148ccbe4ab17": {
            "datetime": "2013-12-06T13:06:05-08:00",
            "summary": "Merge pull request #234 from Parquet/optimize_chunk_scan",
            "message": "Merge pull request #234 from Parquet/optimize_chunk_scan\n\noptimize chunk scan; fix compressed size",
            "diff": {
                "parquet-hadoop/src/main/java/parquet/hadoop/ParquetFileReader.java": 43,
                "parquet-hadoop/src/main/java/parquet/hadoop/ParquetFileWriter.java": 5
            },
            "is_test": false,
            "is_fix": false
        },
        "c95cb214f7821a9beb2a065e7c237ea3da67ac4a": {
            "datetime": "2013-12-06T13:07:03-08:00",
            "summary": "Merge pull request #239 from Parquet/hive_fix_null_maps",
            "message": "Merge pull request #239 from Parquet/hive_fix_null_maps\n\nFix hive map and array inspectors with null containers",
            "diff": {
                "parquet-hive/parquet-hive-storage-handler/src/main/java/parquet/hive/serde/AbstractParquetMapInspector.java": 12,
                "parquet-hive/parquet-hive-storage-handler/src/main/java/parquet/hive/serde/DeepParquetHiveMapInspector.java": 5,
                "parquet-hive/parquet-hive-storage-handler/src/main/java/parquet/hive/serde/ParquetHiveArrayInspector.java": 24,
                "parquet-hive/parquet-hive-storage-handler/src/main/java/parquet/hive/serde/StandardParquetHiveMapInspector.java": 5,
                "parquet-hive/parquet-hive-storage-handler/src/test/java/parquet/hive/serde/TestAbstractParquetMapInspector.java": 102,
                "parquet-hive/parquet-hive-storage-handler/src/test/java/parquet/hive/serde/TestDeepParquetHiveMapInspector.java": 94,
                "parquet-hive/parquet-hive-storage-handler/src/test/java/parquet/hive/serde/TestParquetHiveArrayInspector.java": 84,
                "parquet-hive/parquet-hive-storage-handler/src/test/java/parquet/hive/serde/TestStandardParquetHiveMapInspector.java": 92
            },
            "is_test": true,
            "is_fix": false
        },
        "760367b9fe669ca1a7e75c850a1f455ab1bbbc2c": {
            "datetime": "2013-12-08T16:24:35-06:00",
            "summary": "Update reference to 0.10 in Hive012Binding javadoc and remove some trailing",
            "message": "Update reference to 0.10 in Hive012Binding javadoc and remove some trailing\nwhitespace I noticed when while updating the javadoc.\n",
            "diff": {
                "parquet-hive/parquet-hive-binding/parquet-hive-0.10-binding/src/main/java/parquet/hive/internal/Hive010Binding.java": 2,
                "parquet-hive/parquet-hive-binding/parquet-hive-0.12-binding/src/main/java/parquet/hive/internal/Hive012Binding.java": 6
            },
            "is_test": false,
            "is_fix": false
        },
        "54308f7fa8ecbfd12de053a4bfb3c2619bff9f9a": {
            "datetime": "2013-12-08T15:54:20-08:00",
            "summary": "Merge pull request #241 from brockn/master",
            "message": "Merge pull request #241 from brockn/master\n\nUpdate reference to 0.10 in Hive012Binding javadoc",
            "diff": {
                "parquet-hive/parquet-hive-binding/parquet-hive-0.10-binding/src/main/java/parquet/hive/internal/Hive010Binding.java": 2,
                "parquet-hive/parquet-hive-binding/parquet-hive-0.12-binding/src/main/java/parquet/hive/internal/Hive012Binding.java": 6
            },
            "is_test": false,
            "is_fix": false
        },
        "bb9d898021d53d879c3b5d6e4d5af3a030f10d0d": {
            "datetime": "2013-12-09T11:29:12-08:00",
            "summary": "Merge pull request #240 from Parquet/fix_loader_cache",
            "message": "Merge pull request #240 from Parquet/fix_loader_cache\n\nfix loader cache",
            "diff": {
                "parquet-pig/src/main/java/parquet/pig/ParquetLoader.java": 22
            },
            "is_test": false,
            "is_fix": false
        },
        "17146c31cefd81b5b13eaede7b36296e580546b8": {
            "datetime": "2013-12-11T16:43:00-08:00",
            "summary": "Merge branch 'master' into plumb_original_type",
            "message": "Merge branch 'master' into plumb_original_type\n",
            "diff": {
                "parquet-hadoop/src/main/java/parquet/hadoop/CodecFactory.java": 2,
                "parquet-hadoop/src/main/java/parquet/hadoop/ParquetFileReader.java": 43,
                "parquet-hadoop/src/main/java/parquet/hadoop/ParquetFileWriter.java": 5,
                "parquet-hadoop/src/main/java/parquet/hadoop/ParquetOutputFormat.java": 29,
                "parquet-hadoop/src/main/java/parquet/hadoop/codec/CodecConfig.java": 166,
                "parquet-hadoop/src/main/java/parquet/hadoop/codec/CompressionCodecNotSupportedException.java": 33,
                "parquet-hadoop/src/main/java/parquet/hadoop/mapred/DeprecatedParquetOutputFormat.java": 26,
                "parquet-hadoop/src/main/java/parquet/hadoop/metadata/CompressionCodecName.java": 19,
                "parquet-hadoop/src/test/java/parquet/hadoop/codec/CodecConfigTest.java": 74,
                "parquet-hive/parquet-hive-binding/parquet-hive-0.12-binding/src/main/java/parquet/hive/internal/Hive012Binding.java": 149,
                "parquet-hive/parquet-hive-binding/parquet-hive-binding-factory/src/main/java/parquet/hive/HiveBindingFactory.java": 120,
                "parquet-hive/parquet-hive-binding/parquet-hive-binding-factory/src/test/java/parquet/hive/TestHiveBindingFactory.java": 109,
                "parquet-hive/parquet-hive-binding/parquet-hive-binding-interface/src/main/java/parquet/hive/HiveBinding.java": 52,
                "parquet-hive/parquet-hive-binding/parquet-hive-binding-interface/src/main/java/parquet/hive/internal/AbstractHiveBinding.java": 36,
                "parquet-hive/parquet-hive-storage-handler/src/main/java/parquet/hive/DeprecatedParquetInputFormat.java": 35,
                "parquet-hive/parquet-hive-storage-handler/src/main/java/parquet/hive/DeprecatedParquetOutputFormat.java": 35,
                "parquet-hive/parquet-hive-storage-handler/src/test/java/parquet/hive/serde/TestAbstractParquetMapInspector.java": 102,
                "parquet-hive/parquet-hive-storage-handler/src/test/java/parquet/hive/serde/TestDeepParquetHiveMapInspector.java": 94,
                "parquet-hive/parquet-hive-storage-handler/src/test/java/parquet/hive/serde/TestParquetHiveArrayInspector.java": 84,
                "parquet-hive/parquet-hive-storage-handler/src/test/java/parquet/hive/serde/TestStandardParquetHiveMapInspector.java": 92,
                "parquet-hive/src/main/java/parquet/hive/DeprecatedParquetInputFormat.java": 65,
                "parquet-hive/src/main/java/parquet/hive/DeprecatedParquetOutputFormat.java": 21,
                "parquet-hive/src/main/java/parquet/hive/ManageJobConfig.java": 99,
                "parquet-hive/src/main/java/parquet/hive/convert/ArrayWritableGroupConverter.java": 0,
                "parquet-hive/src/main/java/parquet/hive/convert/DataWritableGroupConverter.java": 0,
                "parquet-hive/src/main/java/parquet/hive/convert/DataWritableRecordConverter.java": 0,
                "parquet-hive/src/main/java/parquet/hive/convert/ETypeConverter.java": 0,
                "parquet-hive/src/main/java/parquet/hive/convert/HiveGroupConverter.java": 0,
                "parquet-hive/src/main/java/parquet/hive/convert/HiveSchemaConverter.java": 0,
                "parquet-hive/src/main/java/parquet/hive/read/DataWritableReadSupport.java": 5,
                "parquet-hive/src/main/java/parquet/hive/serde/AbstractParquetMapInspector.java": 12,
                "parquet-hive/src/main/java/parquet/hive/serde/ArrayWritableObjectInspector.java": 0,
                "parquet-hive/src/main/java/parquet/hive/serde/DeepParquetHiveMapInspector.java": 5,
                "parquet-hive/src/main/java/parquet/hive/serde/ParquetHiveArrayInspector.java": 24,
                "parquet-hive/src/main/java/parquet/hive/serde/ParquetHiveSerDe.java": 0,
                "parquet-hive/src/main/java/parquet/hive/serde/StandardParquetHiveMapInspector.java": 5,
                "parquet-hive/src/main/java/parquet/hive/serde/primitive/ParquetByteInspector.java": 0,
                "parquet-hive/src/main/java/parquet/hive/serde/primitive/ParquetPrimitiveInspectorFactory.java": 0,
                "parquet-hive/src/main/java/parquet/hive/serde/primitive/ParquetShortInspector.java": 0,
                "parquet-hive/src/main/java/parquet/hive/serde/primitive/ParquetStringInspector.java": 0,
                "parquet-hive/src/main/java/parquet/hive/writable/BigDecimalWritable.java": 0,
                "parquet-hive/src/main/java/parquet/hive/writable/BinaryWritable.java": 0,
                "parquet-hive/src/main/java/parquet/hive/write/DataWritableWriteSupport.java": 0,
                "parquet-hive/src/main/java/parquet/hive/write/DataWritableWriter.java": 0,
                "parquet-hive/src/test/java/parquet/hive/TestDeprecatedParquetInputFormat.java": 60,
                "parquet-hive/src/test/java/parquet/hive/TestDeprecatedParquetOuputFormat.java": 52,
                "parquet-hive/src/test/java/parquet/hive/TestHiveSchemaConverter.java": 0,
                "parquet-hive/src/test/java/parquet/hive/TestParquetSerDe.java": 0,
                "parquet-hive/src/test/java/parquet/hive/UtilitiesTestMethods.java": 0,
                "parquet-pig/src/main/java/parquet/pig/ParquetLoader.java": 22,
                "parquet-thrift/src/main/java/parquet/hadoop/thrift/ThriftWriteSupport.java": 17
            },
            "is_test": true,
            "is_fix": false
        },
        "e2d819c2ae6ab5573606e32f325c0743c6ec0c2f": {
            "datetime": "2013-12-12T16:59:33+01:00",
            "summary": "Loading correct pbClass to ProtoSchemaConverter",
            "message": "Loading correct pbClass to ProtoSchemaConverter\n",
            "diff": {
                "src/main/java/parquet/proto/ProtoWriteSupport.java": 9
            },
            "is_test": false,
            "is_fix": false
        },
        "08a204ddb8cfda6b41309af911c5a4511fd426df": {
            "datetime": "2013-12-12T17:00:34+01:00",
            "summary": "Depricated init override removed",
            "message": "Depricated init override removed\n",
            "diff": {
                "src/main/java/parquet/proto/ProtoReadSupport.java": 9
            },
            "is_test": false,
            "is_fix": false
        },
        "051725362f48c5b6490a15ae5241967a81b523f9": {
            "datetime": "2013-12-12T17:09:03+01:00",
            "summary": "TestUtils refactoring",
            "message": "TestUtils refactoring\n",
            "diff": {
                "src/test/java/parquet/proto/ProtoTest.java": 2,
                "src/test/java/parquet/proto/TestUtils.java": 14
            },
            "is_test": true,
            "is_fix": false
        },
        "c590038425156af6a99f5424d8ccecd4526f071f": {
            "datetime": "2013-12-12T17:13:16+01:00",
            "summary": "Obsolete test removed",
            "message": "Obsolete test removed\n",
            "diff": {
                "src/test/java/parquet/proto/BugHuntingTest.java": 54,
                "src/test/java/parquet/proto/ProtoTest.java": 154,
                "src/test/java/parquet/proto/TestSandbox.java": 43
            },
            "is_test": true,
            "is_fix": false
        },
        "5bb9e8d9a5aa6dbb459e2d7243cfda40f095bb9e": {
            "datetime": "2013-12-13T18:00:43-08:00",
            "summary": "integrate parquet format 2.0",
            "message": "integrate parquet format 2.0\n",
            "diff": {
                "parquet-column/src/main/java/parquet/column/Encoding.java": 34,
                "parquet-hadoop/src/main/java/parquet/hadoop/metadata/EncodingList.java": 1
            },
            "is_test": false,
            "is_fix": false
        },
        "314ac2b98a8119ee028417f8045ae3c50e488a95": {
            "datetime": "2013-12-14T09:52:35-08:00",
            "summary": "Merge pull request #245 from Parquet/integrate_parquet_format_2",
            "message": "Merge pull request #245 from Parquet/integrate_parquet_format_2\n\nintegrate parquet format 2.0",
            "diff": {
                "parquet-column/src/main/java/parquet/column/Encoding.java": 34,
                "parquet-hadoop/src/main/java/parquet/hadoop/metadata/EncodingList.java": 1
            },
            "is_test": false,
            "is_fix": false
        },
        "652b0fe0521c5b57c3a61cecf9889d7eac054981": {
            "datetime": "2013-12-14T15:48:56-08:00",
            "summary": "Merge branch 'master' into plumb_original_type",
            "message": "Merge branch 'master' into plumb_original_type\n",
            "diff": {
                "parquet-column/src/main/java/parquet/column/Encoding.java": 34,
                "parquet-hadoop/src/main/java/parquet/hadoop/metadata/EncodingList.java": 1
            },
            "is_test": false,
            "is_fix": false
        },
        "e36b2f0b4c724cdc610eb3b6879b795fe301f24c": {
            "datetime": "2013-12-15T12:30:22-08:00",
            "summary": "implement error handler",
            "message": "implement error handler\n",
            "diff": {
                "parquet-thrift/src/main/java/parquet/thrift/BufferedProtocolReadToWrite.java": 71,
                "parquet-thrift/src/test/java/parquet/thrift/TestProtocolReadToWrite.java": 65
            },
            "is_test": true,
            "is_fix": false
        },
        "8269a6f5bd54a80328d77b2c42443c709b373953": {
            "datetime": "2013-12-15T12:31:06-08:00",
            "summary": "handle extra field in data",
            "message": "handle extra field in data\n",
            "diff": {
                "parquet-thrift/src/main/java/parquet/thrift/BufferedProtocolReadToWrite.java": 366,
                "parquet-thrift/src/main/java/parquet/thrift/ProtocolReadToWrite.java": 2,
                "parquet-thrift/src/test/java/parquet/thrift/TestProtocolReadToWrite.java": 62
            },
            "is_test": true,
            "is_fix": false
        },
        "3d4513f0073de5026e75643a725f9a22bf2f677f": {
            "datetime": "2013-12-15T13:17:14-08:00",
            "summary": "add checkEnum",
            "message": "add checkEnum\n",
            "diff": {
                "parquet-thrift/src/main/java/parquet/thrift/BufferedProtocolReadToWrite.java": 60,
                "parquet-thrift/src/main/java/parquet/thrift/DecodingSchemaMismatchException.java": 12,
                "parquet-thrift/src/test/java/parquet/thrift/TestProtocolReadToWrite.java": 9
            },
            "is_test": true,
            "is_fix": false
        },
        "564f370e84e3ac920a5f5d2bb160293d64609e73": {
            "datetime": "2013-12-15T13:27:04-08:00",
            "summary": "add tests, fix bug",
            "message": "add tests, fix bug\n",
            "diff": {
                "parquet-thrift/src/main/java/parquet/thrift/BufferedProtocolReadToWrite.java": 7,
                "parquet-thrift/src/test/java/parquet/thrift/TestProtocolReadToWrite.java": 144
            },
            "is_test": true,
            "is_fix": false
        },
        "da4b7fd73b9c6179b2b521dfce40c96490cf4ec4": {
            "datetime": "2013-12-15T13:32:54-08:00",
            "summary": "refactor",
            "message": "refactor\n",
            "diff": {
                "parquet-thrift/src/main/java/parquet/thrift/BufferedProtocolReadToWrite.java": 182
            },
            "is_test": false,
            "is_fix": false
        },
        "bdf5d6b57203e2c7b494bd34babcdf8849963185": {
            "datetime": "2013-12-15T18:23:48-08:00",
            "summary": "Merge pull request #187 from davidzchen/plumb_original_type",
            "message": "Merge pull request #187 from davidzchen/plumb_original_type\n\nPlumb OriginalType",
            "diff": {
                "parquet-hadoop/src/main/java/parquet/format/converter/ParquetMetadataConverter.java": 61
            },
            "is_test": false,
            "is_fix": false
        },
        "f5eb89d45ccbe373534e249d711155d98a0a49de": {
            "datetime": "2013-12-15T18:24:21-08:00",
            "summary": "Merge pull request #244 from Parquet/feature/error_handler",
            "message": "Merge pull request #244 from Parquet/feature/error_handler\n\nFeature/error handler",
            "diff": {
                "parquet-thrift/src/main/java/parquet/thrift/BufferedProtocolReadToWrite.java": 564,
                "parquet-thrift/src/main/java/parquet/thrift/DecodingSchemaMismatchException.java": 12,
                "parquet-thrift/src/main/java/parquet/thrift/ProtocolReadToWrite.java": 2,
                "parquet-thrift/src/test/java/parquet/thrift/TestProtocolReadToWrite.java": 136
            },
            "is_test": true,
            "is_fix": false
        },
        "e29c2dfa1b92c4daacf242f7003ca5e0bd583aad": {
            "datetime": "2013-12-16T10:50:00-08:00",
            "summary": "fix when field index is greater than zero",
            "message": "fix when field index is greater than zero\n",
            "diff": {
                "parquet-thrift/src/main/java/parquet/thrift/BufferedProtocolReadToWrite.java": 5,
                "parquet-thrift/src/main/java/parquet/thrift/struct/CompatibilityChecker.java": 6,
                "parquet-thrift/src/main/java/parquet/thrift/struct/ThriftType.java": 6,
                "parquet-thrift/src/test/java/parquet/thrift/TestProtocolReadToWrite.java": 32
            },
            "is_test": true,
            "is_fix": false
        },
        "e94b392ede6bb50a158a8df161da88b54f92ff61": {
            "datetime": "2013-12-16T10:53:08-08:00",
            "summary": "format",
            "message": "format\n",
            "diff": {
                "parquet-thrift/src/main/java/parquet/thrift/BufferedProtocolReadToWrite.java": 1
            },
            "is_test": false,
            "is_fix": false
        },
        "cd00dc8944f768753522ca10930919ba1d8b7161": {
            "datetime": "2013-12-16T11:13:43-08:00",
            "summary": "Merge pull request #247 from Parquet/fix/detect_extra_field_when_index_is_not_start_from_zero",
            "message": "Merge pull request #247 from Parquet/fix/detect_extra_field_when_index_is_not_start_from_zero\n\nfix bug: when field index is greater than zero",
            "diff": {
                "parquet-thrift/src/main/java/parquet/thrift/BufferedProtocolReadToWrite.java": 4,
                "parquet-thrift/src/main/java/parquet/thrift/struct/CompatibilityChecker.java": 6,
                "parquet-thrift/src/main/java/parquet/thrift/struct/ThriftType.java": 6,
                "parquet-thrift/src/test/java/parquet/thrift/TestProtocolReadToWrite.java": 32
            },
            "is_test": true,
            "is_fix": false
        },
        "0a01dae77c560e3309766ddf1a0cae4600d4cc39": {
            "datetime": "2013-12-17T12:18:24+00:00",
            "summary": "Use ContextUtil in tests to avoid dependency on parts of new MR API",
            "message": "Use ContextUtil in tests to avoid dependency on parts of new MR API\nthat are incompatible between MR1 and MR2.\n",
            "diff": {
                "parquet-cascading/src/test/java/parquet/cascading/TestParquetTBaseScheme.java": 3,
                "parquet-cascading/src/test/java/parquet/cascading/TestParquetTupleScheme.java": 3,
                "parquet-hadoop/src/test/java/parquet/hadoop/codec/CodecConfigTest.java": 5,
                "parquet-hive/parquet-hive-storage-handler/src/main/java/parquet/hive/MapredParquetOutputFormat.java": 2,
                "parquet-pig/src/test/java/parquet/pig/PerfTest2.java": 8,
                "parquet-scrooge/src/test/java/parquet/scrooge/ParquetScroogeSchemeTest.java": 6,
                "parquet-thrift/src/test/java/parquet/hadoop/thrift/TestParquetToThriftReadProjection.java": 6,
                "parquet-thrift/src/test/java/parquet/hadoop/thrift/TestThriftToParquetFileWriter.java": 4
            },
            "is_test": true,
            "is_fix": false
        },
        "0df24f071e70b19aad5e9c45f16a14b379313f5d": {
            "datetime": "2013-12-17T12:19:10+00:00",
            "summary": "Rename ParquetInputFormat#addInputPathRecursively to avoid",
            "message": "Rename ParquetInputFormat#addInputPathRecursively to avoid\nclash with non-static Hadoop 2 method of same name on FileInputFormat.\n",
            "diff": {
                "parquet-hadoop/src/main/java/parquet/hadoop/ParquetInputFormat.java": 6
            },
            "is_test": false,
            "is_fix": false
        },
        "ea9fd2049243400cd8b75943b3fda56a95295367": {
            "datetime": "2013-12-17T12:19:55+00:00",
            "summary": "Fix syntax error in test that Pig 0.12 complains about.",
            "message": "Fix syntax error in test that Pig 0.12 complains about.\n",
            "diff": {
                "parquet-pig/src/test/java/parquet/pig/TestPigSchemaConverter.java": 2
            },
            "is_test": true,
            "is_fix": false
        },
        "e83778a2588dfb14e1b225ad5c5cae817291a655": {
            "datetime": "2013-12-17T13:23:10-08:00",
            "summary": "make summary files read in parallel; improve memory footprint of metadata",
            "message": "make summary files read in parallel; improve memory footprint of metadata\n",
            "diff": {
                "parquet-hadoop/src/main/java/parquet/hadoop/ParquetFileReader.java": 106,
                "parquet-hadoop/src/main/java/parquet/hadoop/metadata/BlockMetaData.java": 3,
                "parquet-hadoop/src/main/java/parquet/hadoop/metadata/ColumnChunkMetaData.java": 30
            },
            "is_test": false,
            "is_fix": false
        },
        "f21fb3158a92837ea33187335d0c1029f0890cbe": {
            "datetime": "2013-12-17T13:37:01-08:00",
            "summary": "Merge pull request #248 from tomwhite/hadoop-2-compatibility-fixes",
            "message": "Merge pull request #248 from tomwhite/hadoop-2-compatibility-fixes\n\nMore Hadoop 2 compatibility fixes",
            "diff": {
                "parquet-cascading/src/test/java/parquet/cascading/TestParquetTBaseScheme.java": 3,
                "parquet-cascading/src/test/java/parquet/cascading/TestParquetTupleScheme.java": 3,
                "parquet-hadoop/src/main/java/parquet/hadoop/ParquetInputFormat.java": 6,
                "parquet-hadoop/src/test/java/parquet/hadoop/codec/CodecConfigTest.java": 5,
                "parquet-hive/parquet-hive-storage-handler/src/main/java/parquet/hive/MapredParquetOutputFormat.java": 2,
                "parquet-pig/src/test/java/parquet/pig/PerfTest2.java": 8,
                "parquet-pig/src/test/java/parquet/pig/TestPigSchemaConverter.java": 2,
                "parquet-scrooge/src/test/java/parquet/scrooge/ParquetScroogeSchemeTest.java": 6,
                "parquet-thrift/src/test/java/parquet/hadoop/thrift/TestParquetToThriftReadProjection.java": 6,
                "parquet-thrift/src/test/java/parquet/hadoop/thrift/TestThriftToParquetFileWriter.java": 4
            },
            "is_test": true,
            "is_fix": false
        },
        "a34507d54550a794e55cee68d39b483793954561": {
            "datetime": "2013-12-17T15:59:40-08:00",
            "summary": "pretty_print_json_for_compatibility_checker",
            "message": "pretty_print_json_for_compatibility_checker\n",
            "diff": {
                "parquet-thrift/src/main/java/parquet/thrift/struct/CompatibilityRunner.java": 2
            },
            "is_test": false,
            "is_fix": false
        },
        "18012a0db7e6fac06a36670fc1c2b4050d903e07": {
            "datetime": "2013-12-17T16:03:21-08:00",
            "summary": "Merge pull request #250 from Parquet/pretty_print_json_for_compatibility_checker",
            "message": "Merge pull request #250 from Parquet/pretty_print_json_for_compatibility_checker\n\npretty_print_json_for_compatibility_checker",
            "diff": {
                "parquet-thrift/src/main/java/parquet/thrift/struct/CompatibilityRunner.java": 2
            },
            "is_test": false,
            "is_fix": false
        },
        "392a801878836e50d992353910dceb802393a6f5": {
            "datetime": "2013-12-18T14:37:48-08:00",
            "summary": "refactor",
            "message": "refactor\n",
            "diff": {
                "parquet-thrift/src/main/java/parquet/hadoop/thrift/ParquetThriftBytesOutputFormat.java": 6,
                "parquet-thrift/src/main/java/parquet/hadoop/thrift/ThriftBytesWriteSupport.java": 11,
                "parquet-thrift/src/main/java/parquet/hadoop/thrift/ThriftToParquetFileWriter.java": 28,
                "parquet-thrift/src/main/java/parquet/thrift/BufferedProtocolReadToWrite.java": 49,
                "parquet-thrift/src/main/java/parquet/thrift/ReadWriteErrorHandler.java": 39,
                "parquet-thrift/src/test/java/parquet/thrift/TestProtocolReadToWrite.java": 147
            },
            "is_test": true,
            "is_fix": false
        },
        "0888bdeacf422a6def35239abd69f0ad8b580abc": {
            "datetime": "2013-12-18T15:38:55-08:00",
            "summary": "adress comments",
            "message": "adress comments\n",
            "diff": {
                "parquet-hadoop/src/main/java/parquet/hadoop/ParquetFileReader.java": 1,
                "parquet-hadoop/src/main/java/parquet/hadoop/metadata/ColumnChunkMetaData.java": 62
            },
            "is_test": false,
            "is_fix": false
        },
        "67a7a9d242a4831e8e79a1606c0f7304a802ed6e": {
            "datetime": "2013-12-18T17:01:17-08:00",
            "summary": "Add writer version flag to parquet and make initial changes for supported parquet 2.0 encodings",
            "message": "Add writer version flag to parquet and make initial changes for supported parquet 2.0 encodings\n",
            "diff": {
                "parquet-column/src/main/java/parquet/column/ParquetProperties.java": 119,
                "parquet-column/src/main/java/parquet/column/impl/ColumnWriteStoreImpl.java": 6,
                "parquet-column/src/main/java/parquet/column/impl/ColumnWriterImpl.java": 61,
                "parquet-column/src/test/java/parquet/column/mem/TestMemColumn.java": 4,
                "parquet-column/src/test/java/parquet/io/PerfTest.java": 3,
                "parquet-column/src/test/java/parquet/io/TestColumnIO.java": 4,
                "parquet-column/src/test/java/parquet/io/TestFiltered.java": 3,
                "parquet-hadoop/src/main/java/parquet/hadoop/InternalParquetRecordWriter.java": 7,
                "parquet-hadoop/src/main/java/parquet/hadoop/ParquetOutputFormat.java": 25,
                "parquet-hadoop/src/main/java/parquet/hadoop/ParquetRecordWriter.java": 5,
                "parquet-hadoop/src/main/java/parquet/hadoop/ParquetWriter.java": 33,
                "parquet-hive/parquet-hive-storage-handler/src/test/java/parquet/hive/TestMapredParquetInputFormat.java": 3,
                "parquet-pig/src/test/java/parquet/pig/GenerateIntTestFile.java": 3,
                "parquet-pig/src/test/java/parquet/pig/GenerateTPCH.java": 3,
                "parquet-pig/src/test/java/parquet/pig/TupleConsumerPerfTest.java": 3,
                "parquet-thrift/src/test/java/parquet/thrift/TestParquetReadProtocol.java": 3
            },
            "is_test": true,
            "is_fix": false
        },
        "cf9a3677ac749ed0789be77eb7de70f80b203a2d": {
            "datetime": "2013-12-18T17:31:00-08:00",
            "summary": "Merge pull request #252 from Parquet/refactor_error_handler",
            "message": "Merge pull request #252 from Parquet/refactor_error_handler\n\nrefactor error handler for BufferedProtocolReadToWrite to be non-static",
            "diff": {
                "parquet-thrift/src/main/java/parquet/hadoop/thrift/ParquetThriftBytesOutputFormat.java": 6,
                "parquet-thrift/src/main/java/parquet/hadoop/thrift/ThriftBytesWriteSupport.java": 11,
                "parquet-thrift/src/main/java/parquet/hadoop/thrift/ThriftToParquetFileWriter.java": 28,
                "parquet-thrift/src/main/java/parquet/thrift/BufferedProtocolReadToWrite.java": 49,
                "parquet-thrift/src/main/java/parquet/thrift/ReadWriteErrorHandler.java": 39,
                "parquet-thrift/src/test/java/parquet/thrift/TestProtocolReadToWrite.java": 147
            },
            "is_test": true,
            "is_fix": false
        },
        "f2e7baae6817aae3440edef23f6379d7270f998f": {
            "datetime": "2013-12-19T11:02:40-06:00",
            "summary": "Resolves issue #251 by doing additional checks if Hive returns \"Unknown\" as a version.",
            "message": "Resolves issue #251 by doing additional checks if Hive returns \"Unknown\" as a version.\n",
            "diff": {
                "parquet-hive/parquet-hive-binding/parquet-hive-binding-factory/src/main/java/parquet/hive/HiveBindingFactory.java": 27,
                "parquet-hive/parquet-hive-binding/parquet-hive-binding-factory/src/test/java/parquet/hive/TestHiveBindingFactory.java": 20
            },
            "is_test": true,
            "is_fix": false
        },
        "956ad0770b644153317d45c276ec1615c509da5b": {
            "datetime": "2013-12-19T10:58:19-08:00",
            "summary": "Merge pull request #256 from brockn/master",
            "message": "Merge pull request #256 from brockn/master\n\nResolves issue #251 by doing additional checks if Hive returns \"Unknown\" as a version",
            "diff": {
                "parquet-hive/parquet-hive-binding/parquet-hive-binding-factory/src/main/java/parquet/hive/HiveBindingFactory.java": 27,
                "parquet-hive/parquet-hive-binding/parquet-hive-binding-factory/src/test/java/parquet/hive/TestHiveBindingFactory.java": 20
            },
            "is_test": true,
            "is_fix": false
        },
        "4a18684068266d8f8130e7f1ecf098fc039a672e": {
            "datetime": "2013-12-19T12:15:35-08:00",
            "summary": "changes for code review comments - enum as params, shortname for writerversion",
            "message": "changes for code review comments - enum as params, shortname for writerversion\n",
            "diff": {
                "parquet-column/src/main/java/parquet/column/ParquetProperties.java": 34,
                "parquet-column/src/main/java/parquet/column/impl/ColumnWriteStoreImpl.java": 5,
                "parquet-column/src/main/java/parquet/column/impl/ColumnWriterImpl.java": 3,
                "parquet-column/src/test/java/parquet/column/mem/TestMemColumn.java": 2,
                "parquet-column/src/test/java/parquet/io/PerfTest.java": 2,
                "parquet-column/src/test/java/parquet/io/TestColumnIO.java": 2,
                "parquet-column/src/test/java/parquet/io/TestFiltered.java": 2,
                "parquet-hadoop/src/main/java/parquet/hadoop/InternalParquetRecordWriter.java": 5,
                "parquet-hadoop/src/main/java/parquet/hadoop/ParquetOutputFormat.java": 8,
                "parquet-hadoop/src/main/java/parquet/hadoop/ParquetRecordWriter.java": 4,
                "parquet-hadoop/src/main/java/parquet/hadoop/ParquetWriter.java": 4,
                "parquet-hive/parquet-hive-storage-handler/src/test/java/parquet/hive/TestMapredParquetInputFormat.java": 2,
                "parquet-pig/src/test/java/parquet/pig/GenerateIntTestFile.java": 2,
                "parquet-pig/src/test/java/parquet/pig/GenerateTPCH.java": 2,
                "parquet-pig/src/test/java/parquet/pig/TupleConsumerPerfTest.java": 2,
                "parquet-thrift/src/test/java/parquet/thrift/TestParquetReadProtocol.java": 2
            },
            "is_test": true,
            "is_fix": false
        },
        "a68c8fc97685eab6e1c916f47badedd70a1c0670": {
            "datetime": "2013-12-19T13:33:43-08:00",
            "summary": "Merge pull request #254 from Parquet/parquet_2.0_writer",
            "message": "Merge pull request #254 from Parquet/parquet_2.0_writer\n\nAdd writer version flag to parquet and make initial changes for supported parquet 2.0 encodings",
            "diff": {
                "parquet-column/src/main/java/parquet/column/ParquetProperties.java": 135,
                "parquet-column/src/main/java/parquet/column/impl/ColumnWriteStoreImpl.java": 7,
                "parquet-column/src/main/java/parquet/column/impl/ColumnWriterImpl.java": 62,
                "parquet-column/src/test/java/parquet/column/mem/TestMemColumn.java": 4,
                "parquet-column/src/test/java/parquet/io/PerfTest.java": 3,
                "parquet-column/src/test/java/parquet/io/TestColumnIO.java": 4,
                "parquet-column/src/test/java/parquet/io/TestFiltered.java": 3,
                "parquet-hadoop/src/main/java/parquet/hadoop/InternalParquetRecordWriter.java": 8,
                "parquet-hadoop/src/main/java/parquet/hadoop/ParquetOutputFormat.java": 23,
                "parquet-hadoop/src/main/java/parquet/hadoop/ParquetRecordWriter.java": 7,
                "parquet-hadoop/src/main/java/parquet/hadoop/ParquetWriter.java": 33,
                "parquet-hive/parquet-hive-storage-handler/src/test/java/parquet/hive/TestMapredParquetInputFormat.java": 3,
                "parquet-pig/src/test/java/parquet/pig/GenerateIntTestFile.java": 3,
                "parquet-pig/src/test/java/parquet/pig/GenerateTPCH.java": 3,
                "parquet-pig/src/test/java/parquet/pig/TupleConsumerPerfTest.java": 3,
                "parquet-thrift/src/test/java/parquet/thrift/TestParquetReadProtocol.java": 3
            },
            "is_test": true,
            "is_fix": false
        },
        "c81778533dd1c963f0cf7b8e704afd7c6259907e": {
            "datetime": "2013-12-19T14:31:15-08:00",
            "summary": "delta int bin pack",
            "message": "delta int bin pack\n",
            "diff": {
                "parquet-column/src/main/java/parquet/column/Encoding.java": 12,
                "parquet-column/src/main/java/parquet/column/values/delta/DeltaBinaryPackingConfig.java": 54,
                "parquet-column/src/main/java/parquet/column/values/delta/DeltaBinaryPackingValuesReader.java": 167,
                "parquet-column/src/main/java/parquet/column/values/delta/DeltaBinaryPackingValuesWriter.java": 267,
                "parquet-column/src/test/java/parquet/column/values/delta/DeltaBinaryPackingValuesWriterTest.java": 338,
                "parquet-column/src/test/java/parquet/column/values/delta/benchmark/BenchMarkTest.java": 26,
                "parquet-column/src/test/java/parquet/column/values/delta/benchmark/BenchmarkIntegerOutputSize.java": 105,
                "parquet-column/src/test/java/parquet/column/values/delta/benchmark/BenchmarkReadingRandomIntegers.java": 94,
                "parquet-column/src/test/java/parquet/column/values/delta/benchmark/RandomWritingBenchmarkTest.java": 55,
                "parquet-column/src/test/java/parquet/column/values/delta/benchmark/SmallRangeWritingBenchmarkTest.java": 32,
                "parquet-common/src/main/java/parquet/bytes/BytesUtils.java": 16,
                "parquet-encoding/src/main/java/parquet/bytes/BytesInput.java": 37
            },
            "is_test": true,
            "is_fix": false
        },
        "d617084a4552621c887b078447de3ab725e47f63": {
            "datetime": "2013-12-19T14:50:43-08:00",
            "summary": "formatting and license header",
            "message": "formatting and license header\n",
            "diff": {
                "parquet-column/src/main/java/parquet/column/values/delta/DeltaBinaryPackingValuesReader.java": 3,
                "parquet-column/src/main/java/parquet/column/values/delta/DeltaBinaryPackingValuesWriter.java": 1,
                "parquet-column/src/test/java/parquet/column/values/delta/DeltaBinaryPackingValuesWriterTest.java": 78,
                "parquet-column/src/test/java/parquet/column/values/delta/benchmark/BenchMarkTest.java": 16,
                "parquet-column/src/test/java/parquet/column/values/delta/benchmark/BenchmarkIntegerOutputSize.java": 5,
                "parquet-column/src/test/java/parquet/column/values/delta/benchmark/BenchmarkReadingRandomIntegers.java": 1,
                "parquet-column/src/test/java/parquet/column/values/delta/benchmark/RandomWritingBenchmarkTest.java": 17,
                "parquet-column/src/test/java/parquet/column/values/delta/benchmark/SmallRangeWritingBenchmarkTest.java": 16
            },
            "is_test": true,
            "is_fix": false
        },
        "290385c888b05797e5663acbd8f1ce10bc6fb8a6": {
            "datetime": "2013-12-19T14:55:40-08:00",
            "summary": "format",
            "message": "format\n",
            "diff": {
                "parquet-column/src/test/java/parquet/column/values/delta/benchmark/BenchmarkIntegerOutputSize.java": 1,
                "parquet-column/src/test/java/parquet/column/values/delta/benchmark/RandomWritingBenchmarkTest.java": 1,
                "parquet-column/src/test/java/parquet/column/values/delta/benchmark/SmallRangeWritingBenchmarkTest.java": 1
            },
            "is_test": true,
            "is_fix": false
        },
        "74269e42bca92c8fd531d81b5f3eecf386883ff3": {
            "datetime": "2013-12-19T15:01:11-08:00",
            "summary": "Merge pull request #253 from Parquet/delta_int",
            "message": "Merge pull request #253 from Parquet/delta_int\n\nDelta Binary Packing for Int",
            "diff": {
                "parquet-column/src/main/java/parquet/column/Encoding.java": 12,
                "parquet-column/src/main/java/parquet/column/values/delta/DeltaBinaryPackingConfig.java": 54,
                "parquet-column/src/main/java/parquet/column/values/delta/DeltaBinaryPackingValuesReader.java": 164,
                "parquet-column/src/main/java/parquet/column/values/delta/DeltaBinaryPackingValuesWriter.java": 266,
                "parquet-column/src/test/java/parquet/column/values/delta/DeltaBinaryPackingValuesWriterTest.java": 262,
                "parquet-column/src/test/java/parquet/column/values/delta/benchmark/BenchMarkTest.java": 40,
                "parquet-column/src/test/java/parquet/column/values/delta/benchmark/BenchmarkIntegerOutputSize.java": 99,
                "parquet-column/src/test/java/parquet/column/values/delta/benchmark/BenchmarkReadingRandomIntegers.java": 93,
                "parquet-column/src/test/java/parquet/column/values/delta/benchmark/RandomWritingBenchmarkTest.java": 67,
                "parquet-column/src/test/java/parquet/column/values/delta/benchmark/SmallRangeWritingBenchmarkTest.java": 45,
                "parquet-common/src/main/java/parquet/bytes/BytesUtils.java": 16,
                "parquet-encoding/src/main/java/parquet/bytes/BytesInput.java": 37
            },
            "is_test": true,
            "is_fix": false
        },
        "978e396663297338a186bac466f5ee7319943c6e": {
            "datetime": "2013-12-20T12:28:27+01:00",
            "summary": "ProtoSchemaConverterUnitTest",
            "message": "ProtoSchemaConverterUnitTest\n",
            "diff": {
                "src/main/java/parquet/proto/ProtoSchemaConverter.java": 22,
                "src/test/java/parquet/proto/ProtoSchemaConverterTest.java": 101
            },
            "is_test": true,
            "is_fix": false
        },
        "273728238acad7800a074b11ad3ef0beb3a4af4d": {
            "datetime": "2013-12-20T11:04:43-08:00",
            "summary": "optimize consecutive row groups scans",
            "message": "optimize consecutive row groups scans\n",
            "diff": {
                "parquet-hadoop/src/main/java/parquet/hadoop/ParquetFileReader.java": 334
            },
            "is_test": false,
            "is_fix": false
        },
        "dba65be43fd824266f947570ac310775187cef83": {
            "datetime": "2013-12-20T21:59:42+01:00",
            "summary": "tests for Input and Output Formats",
            "message": "tests for Input and Output Formats\n",
            "diff": {
                "src/main/java/parquet/proto/ProtobufferRecordConverter.java": 12,
                "src/test/java/parquet/proto/ProtoInputOutputFormatTest.java": 173
            },
            "is_test": true,
            "is_fix": false
        },
        "16b2f7362bfcf64eb23a28933098d32ce19cddaf": {
            "datetime": "2013-12-20T22:10:12+01:00",
            "summary": "ProtoSchemaConverter Code Style",
            "message": "ProtoSchemaConverter Code Style\n",
            "diff": {
                "src/test/java/parquet/proto/ProtoSchemaConverterTest.java": 92
            },
            "is_test": true,
            "is_fix": false
        },
        "13942364d47d493fe10c66c17644d8284a84cbc7": {
            "datetime": "2013-12-20T22:41:52+01:00",
            "summary": "CodeStyle",
            "message": "CodeStyle\n",
            "diff": {
                "src/main/java/parquet/proto/ProtoParquetOutputFormat.java": 4,
                "src/main/java/parquet/proto/ProtoWriteSupport.java": 4,
                "src/main/java/parquet/proto/ProtobufferRecordConverter.java": 2,
                "src/test/java/parquet/proto/ProtoInputOutputFormatTest.java": 26,
                "src/test/java/parquet/proto/ProtoSchemaConverterTest.java": 87,
                "src/test/java/parquet/proto/TestUtils.java": 23
            },
            "is_test": true,
            "is_fix": false
        },
        "c1b616132a7625ffb0b7b3230e0738b06b49a1a3": {
            "datetime": "2013-12-20T14:31:27-08:00",
            "summary": "add delta length byte arrays and delta byte arrays encodings",
            "message": "add delta length byte arrays and delta byte arrays encodings\n",
            "diff": {
                "parquet-column/src/main/java/parquet/column/Encoding.java": 30,
                "parquet-column/src/main/java/parquet/column/impl/ColumnReaderImpl.java": 8,
                "parquet-column/src/main/java/parquet/column/values/ValuesReader.java": 13,
                "parquet-column/src/main/java/parquet/column/values/bitpacking/BitPackingValuesReader.java": 13,
                "parquet-column/src/main/java/parquet/column/values/bitpacking/ByteBitPackingValuesReader.java": 13,
                "parquet-column/src/main/java/parquet/column/values/boundedint/BoundedIntValuesReader.java": 10,
                "parquet-column/src/main/java/parquet/column/values/boundedint/ZeroIntegerValuesReader.java": 11,
                "parquet-column/src/main/java/parquet/column/values/delta/DeltaBinaryPackingValuesReader.java": 7,
                "parquet-column/src/main/java/parquet/column/values/deltalengthbytearray/DeltaLengthByteArrayValuesReader.java": 67,
                "parquet-column/src/main/java/parquet/column/values/deltalengthbytearray/DeltaLengthByteArrayValuesWriter.java": 103,
                "parquet-column/src/main/java/parquet/column/values/deltastrings/DeltaByteArrayReader.java": 75,
                "parquet-column/src/main/java/parquet/column/values/deltastrings/DeltaByteArrayWriter.java": 89,
                "parquet-column/src/main/java/parquet/column/values/dictionary/DictionaryValuesReader.java": 3,
                "parquet-column/src/main/java/parquet/column/values/plain/BinaryPlainValuesReader.java": 3,
                "parquet-column/src/main/java/parquet/column/values/plain/BooleanPlainValuesReader.java": 9,
                "parquet-column/src/main/java/parquet/column/values/plain/FixedLenByteArrayPlainValuesReader.java": 4,
                "parquet-column/src/main/java/parquet/column/values/plain/PlainValuesReader.java": 19,
                "parquet-column/src/main/java/parquet/column/values/plain/PlainValuesWriter.java": 1,
                "parquet-column/src/main/java/parquet/column/values/rle/RunLengthBitPackingHybridValuesReader.java": 26,
                "parquet-column/src/main/java/parquet/column/values/rle/RunLengthBitPackingHybridValuesWriter.java": 5,
                "parquet-column/src/test/java/parquet/column/values/RandomStr.java": 53,
                "parquet-column/src/test/java/parquet/column/values/Utils.java": 87,
                "parquet-column/src/test/java/parquet/column/values/boundedint/TestBoundedColumns.java": 3,
                "parquet-column/src/test/java/parquet/column/values/deltalengthbytearray/TestDeltaLengthByteArray.java": 72,
                "parquet-column/src/test/java/parquet/column/values/deltalengthbytearray/benchmark/BenchmarkDeltaLengthByteArray.java": 68,
                "parquet-column/src/test/java/parquet/column/values/deltastrings/TestDeltaByteArray.java": 82,
                "parquet-column/src/test/java/parquet/column/values/deltastrings/benchmark/BenchmarkDeltaByteArray.java": 98
            },
            "is_test": true,
            "is_fix": false
        },
        "5051acc8d2ba103a7b544383f275c18ad913df7f": {
            "datetime": "2013-12-20T14:33:23-08:00",
            "summary": "fix minor typo in Encoding reader",
            "message": "fix minor typo in Encoding reader\n",
            "diff": {
                "parquet-column/src/main/java/parquet/column/Encoding.java": 3
            },
            "is_test": false,
            "is_fix": false
        },
        "017d08860a816203d7c4cd92600bb99792327631": {
            "datetime": "2013-12-20T14:41:15-08:00",
            "summary": "minor javadoc changes",
            "message": "minor javadoc changes\n",
            "diff": {
                "parquet-column/src/main/java/parquet/column/values/ValuesReader.java": 4
            },
            "is_test": false,
            "is_fix": false
        },
        "82b889c0af816ba7be2d59f84d2fac6918304037": {
            "datetime": "2013-12-20T14:55:37-08:00",
            "summary": "Merge pull request #1 from Parquet/master",
            "message": "Merge pull request #1 from Parquet/master\n\nupdate",
            "diff": {
                "parquet-cascading/src/main/java/parquet/cascading/ParquetTupleScheme.java": 12,
                "parquet-cascading/src/test/java/parquet/cascading/TestParquetTBaseScheme.java": 3,
                "parquet-cascading/src/test/java/parquet/cascading/TestParquetTupleScheme.java": 193,
                "parquet-column/src/main/java/parquet/column/Encoding.java": 44,
                "parquet-column/src/main/java/parquet/column/ParquetProperties.java": 135,
                "parquet-column/src/main/java/parquet/column/impl/ColumnWriteStoreImpl.java": 9,
                "parquet-column/src/main/java/parquet/column/impl/ColumnWriterImpl.java": 78,
                "parquet-column/src/main/java/parquet/column/values/delta/DeltaBinaryPackingConfig.java": 54,
                "parquet-column/src/main/java/parquet/column/values/delta/DeltaBinaryPackingValuesReader.java": 164,
                "parquet-column/src/main/java/parquet/column/values/delta/DeltaBinaryPackingValuesWriter.java": 266,
                "parquet-column/src/main/java/parquet/column/values/dictionary/DictionaryValuesReader.java": 4,
                "parquet-column/src/main/java/parquet/column/values/dictionary/DictionaryValuesWriter.java": 247,
                "parquet-column/src/main/java/parquet/column/values/rle/RunLengthBitPackingHybridDecoder.java": 21,
                "parquet-column/src/main/java/parquet/column/values/rle/RunLengthBitPackingHybridValuesReader.java": 4,
                "parquet-column/src/main/java/parquet/filter/ColumnPredicates.java": 90,
                "parquet-column/src/main/java/parquet/io/api/Binary.java": 23,
                "parquet-column/src/test/java/parquet/column/mem/TestMemColumn.java": 14,
                "parquet-column/src/test/java/parquet/column/values/delta/DeltaBinaryPackingValuesWriterTest.java": 262,
                "parquet-column/src/test/java/parquet/column/values/delta/benchmark/BenchMarkTest.java": 40,
                "parquet-column/src/test/java/parquet/column/values/delta/benchmark/BenchmarkIntegerOutputSize.java": 99,
                "parquet-column/src/test/java/parquet/column/values/delta/benchmark/BenchmarkReadingRandomIntegers.java": 93,
                "parquet-column/src/test/java/parquet/column/values/delta/benchmark/RandomWritingBenchmarkTest.java": 67,
                "parquet-column/src/test/java/parquet/column/values/delta/benchmark/SmallRangeWritingBenchmarkTest.java": 45,
                "parquet-column/src/test/java/parquet/column/values/dictionary/TestDictionary.java": 606,
                "parquet-column/src/test/java/parquet/column/values/rle/RunLengthBitPackingHybridIntegrationTest.java": 5,
                "parquet-column/src/test/java/parquet/column/values/rle/TestRunLengthBitPackingHybridEncoder.java": 2,
                "parquet-column/src/test/java/parquet/io/PerfTest.java": 3,
                "parquet-column/src/test/java/parquet/io/TestColumnIO.java": 27,
                "parquet-column/src/test/java/parquet/io/TestFiltered.java": 113,
                "parquet-common/src/main/java/parquet/bytes/BytesUtils.java": 16,
                "parquet-encoding/src/main/java/parquet/bytes/BytesInput.java": 37,
                "parquet-hadoop/src/main/java/parquet/format/converter/ParquetMetadataConverter.java": 61,
                "parquet-hadoop/src/main/java/parquet/hadoop/CodecFactory.java": 2,
                "parquet-hadoop/src/main/java/parquet/hadoop/InternalParquetRecordWriter.java": 42,
                "parquet-hadoop/src/main/java/parquet/hadoop/ParquetFileReader.java": 43,
                "parquet-hadoop/src/main/java/parquet/hadoop/ParquetFileWriter.java": 5,
                "parquet-hadoop/src/main/java/parquet/hadoop/ParquetInputFormat.java": 6,
                "parquet-hadoop/src/main/java/parquet/hadoop/ParquetInputSplit.java": 9,
                "parquet-hadoop/src/main/java/parquet/hadoop/ParquetOutputFormat.java": 89,
                "parquet-hadoop/src/main/java/parquet/hadoop/ParquetRecordWriter.java": 20,
                "parquet-hadoop/src/main/java/parquet/hadoop/ParquetWriter.java": 74,
                "parquet-hadoop/src/main/java/parquet/hadoop/codec/CodecConfig.java": 166,
                "parquet-hadoop/src/main/java/parquet/hadoop/codec/CompressionCodecNotSupportedException.java": 33,
                "parquet-hadoop/src/main/java/parquet/hadoop/mapred/DeprecatedParquetInputFormat.java": 8,
                "parquet-hadoop/src/main/java/parquet/hadoop/mapred/DeprecatedParquetOutputFormat.java": 26,
                "parquet-hadoop/src/main/java/parquet/hadoop/metadata/CompressionCodecName.java": 19,
                "parquet-hadoop/src/main/java/parquet/hadoop/metadata/EncodingList.java": 1,
                "parquet-hadoop/src/test/java/parquet/hadoop/codec/CodecConfigTest.java": 75,
                "parquet-hive/parquet-hive-binding/parquet-hive-0.12-binding/src/main/java/parquet/hive/internal/Hive012Binding.java": 149,
                "parquet-hive/parquet-hive-binding/parquet-hive-binding-factory/src/main/java/parquet/hive/HiveBindingFactory.java": 147,
                "parquet-hive/parquet-hive-binding/parquet-hive-binding-factory/src/test/java/parquet/hive/TestHiveBindingFactory.java": 121,
                "parquet-hive/parquet-hive-binding/parquet-hive-binding-interface/src/main/java/parquet/hive/HiveBinding.java": 52,
                "parquet-hive/parquet-hive-binding/parquet-hive-binding-interface/src/main/java/parquet/hive/internal/AbstractHiveBinding.java": 36,
                "parquet-hive/parquet-hive-storage-handler/src/main/java/parquet/hive/DeprecatedParquetInputFormat.java": 35,
                "parquet-hive/parquet-hive-storage-handler/src/main/java/parquet/hive/DeprecatedParquetOutputFormat.java": 35,
                "parquet-hive/parquet-hive-storage-handler/src/main/java/parquet/hive/convert/ETypeConverter.java": 165,
                "parquet-hive/parquet-hive-storage-handler/src/main/java/parquet/hive/serde/AbstractParquetMapInspector.java": 163,
                "parquet-hive/parquet-hive-storage-handler/src/main/java/parquet/hive/serde/ArrayWritableObjectInspector.java": 224,
                "parquet-hive/parquet-hive-storage-handler/src/main/java/parquet/hive/serde/DeepParquetHiveMapInspector.java": 82,
                "parquet-hive/parquet-hive-storage-handler/src/main/java/parquet/hive/serde/ParquetHiveArrayInspector.java": 185,
                "parquet-hive/parquet-hive-storage-handler/src/main/java/parquet/hive/serde/StandardParquetHiveMapInspector.java": 65,
                "parquet-hive/parquet-hive-storage-handler/src/main/java/parquet/hive/serde/primitive/ParquetByteInspector.java": 59,
                "parquet-hive/parquet-hive-storage-handler/src/main/java/parquet/hive/serde/primitive/ParquetPrimitiveInspectorFactory.java": 32,
                "parquet-hive/parquet-hive-storage-handler/src/main/java/parquet/hive/serde/primitive/ParquetShortInspector.java": 59,
                "parquet-hive/parquet-hive-storage-handler/src/main/java/parquet/hive/serde/primitive/ParquetStringInspector.java": 100,
                "parquet-hive/parquet-hive-storage-handler/src/main/java/parquet/hive/writable/BinaryWritable.java": 98,
                "parquet-hive/parquet-hive-storage-handler/src/test/java/parquet/hive/serde/TestAbstractParquetMapInspector.java": 102,
                "parquet-hive/parquet-hive-storage-handler/src/test/java/parquet/hive/serde/TestDeepParquetHiveMapInspector.java": 94,
                "parquet-hive/parquet-hive-storage-handler/src/test/java/parquet/hive/serde/TestParquetHiveArrayInspector.java": 84,
                "parquet-hive/parquet-hive-storage-handler/src/test/java/parquet/hive/serde/TestStandardParquetHiveMapInspector.java": 92,
                "parquet-hive/src/main/java/parquet/hive/DeprecatedParquetInputFormat.java": 77,
                "parquet-hive/src/main/java/parquet/hive/DeprecatedParquetOutputFormat.java": 23,
                "parquet-hive/src/main/java/parquet/hive/ManageJobConfig.java": 99,
                "parquet-hive/src/main/java/parquet/hive/convert/ArrayWritableGroupConverter.java": 0,
                "parquet-hive/src/main/java/parquet/hive/convert/DataWritableGroupConverter.java": 4,
                "parquet-hive/src/main/java/parquet/hive/convert/DataWritableRecordConverter.java": 0,
                "parquet-hive/src/main/java/parquet/hive/convert/ETypeConverter.java": 283,
                "parquet-hive/src/main/java/parquet/hive/convert/HiveGroupConverter.java": 0,
                "parquet-hive/src/main/java/parquet/hive/convert/HiveSchemaConverter.java": 11,
                "parquet-hive/src/main/java/parquet/hive/read/DataWritableReadSupport.java": 63,
                "parquet-hive/src/main/java/parquet/hive/serde/ArrayWritableObjectInspector.java": 313,
                "parquet-hive/src/main/java/parquet/hive/serde/ParquetHiveArrayInspector.java": 144,
                "parquet-hive/src/main/java/parquet/hive/serde/ParquetHiveMapInspector.java": 102,
                "parquet-hive/src/main/java/parquet/hive/serde/ParquetHiveSerDe.java": 3,
                "parquet-hive/src/main/java/parquet/hive/writable/BigDecimalWritable.java": 0,
                "parquet-hive/src/main/java/parquet/hive/writable/BinaryWritable.java": 46,
                "parquet-hive/src/main/java/parquet/hive/write/DataWritableWriteSupport.java": 0,
                "parquet-hive/src/main/java/parquet/hive/write/DataWritableWriter.java": 5,
                "parquet-hive/src/test/java/parquet/hive/TestDeprecatedParquetInputFormat.java": 138,
                "parquet-hive/src/test/java/parquet/hive/TestDeprecatedParquetOuputFormat.java": 52,
                "parquet-hive/src/test/java/parquet/hive/TestHiveSchemaConverter.java": 0,
                "parquet-hive/src/test/java/parquet/hive/TestParquetSerDe.java": 7,
                "parquet-hive/src/test/java/parquet/hive/UtilitiesTestMethods.java": 54,
                "parquet-pig/src/main/java/parquet/pig/ParquetLoader.java": 24,
                "parquet-pig/src/main/java/parquet/pig/ParquetStorer.java": 4,
                "parquet-pig/src/main/java/parquet/pig/TupleWriteSupport.java": 22,
                "parquet-pig/src/test/java/parquet/pig/GenerateIntTestFile.java": 3,
                "parquet-pig/src/test/java/parquet/pig/GenerateTPCH.java": 3,
                "parquet-pig/src/test/java/parquet/pig/PerfTest2.java": 8,
                "parquet-pig/src/test/java/parquet/pig/TestPigSchemaConverter.java": 2,
                "parquet-pig/src/test/java/parquet/pig/TestTupleRecordConsumer.java": 20,
                "parquet-pig/src/test/java/parquet/pig/TupleConsumerPerfTest.java": 5,
                "parquet-scrooge/src/test/java/parquet/scrooge/ParquetScroogeSchemeTest.java": 6,
                "parquet-thrift/src/main/java/parquet/hadoop/thrift/ParquetThriftBytesOutputFormat.java": 6,
                "parquet-thrift/src/main/java/parquet/hadoop/thrift/ThriftBytesWriteSupport.java": 11,
                "parquet-thrift/src/main/java/parquet/hadoop/thrift/ThriftToParquetFileWriter.java": 28,
                "parquet-thrift/src/main/java/parquet/hadoop/thrift/ThriftWriteSupport.java": 17,
                "parquet-thrift/src/main/java/parquet/thrift/BufferedProtocolReadToWrite.java": 531,
                "parquet-thrift/src/main/java/parquet/thrift/DecodingSchemaMismatchException.java": 12,
                "parquet-thrift/src/main/java/parquet/thrift/ParquetWriteProtocol.java": 9,
                "parquet-thrift/src/main/java/parquet/thrift/ProtocolReadToWrite.java": 2,
                "parquet-thrift/src/main/java/parquet/thrift/ReadWriteErrorHandler.java": 39,
                "parquet-thrift/src/main/java/parquet/thrift/struct/CompatibilityChecker.java": 218,
                "parquet-thrift/src/main/java/parquet/thrift/struct/CompatibilityRunner.java": 96,
                "parquet-thrift/src/main/java/parquet/thrift/struct/ThriftType.java": 6,
                "parquet-thrift/src/test/java/parquet/hadoop/thrift/TestParquetToThriftReadProjection.java": 6,
                "parquet-thrift/src/test/java/parquet/hadoop/thrift/TestThriftToParquetFileWriter.java": 4,
                "parquet-thrift/src/test/java/parquet/thrift/TestParquetReadProtocol.java": 3,
                "parquet-thrift/src/test/java/parquet/thrift/TestParquetWriteProtocol.java": 2,
                "parquet-thrift/src/test/java/parquet/thrift/TestProtocolReadToWrite.java": 203,
                "parquet-thrift/src/test/java/parquet/thrift/struct/CompatibilityCheckerTest.java": 117
            },
            "is_test": true,
            "is_fix": false
        },
        "1f75813a03305c30da1d2f9326affc92e541443a": {
            "datetime": "2013-12-21T00:05:07+01:00",
            "summary": "junit test for enum schema conversion",
            "message": "junit test for enum schema conversion\n",
            "diff": {
                "src/main/java/parquet/proto/converters/ProtoEnumConverter.java": 7,
                "src/test/java/parquet/proto/ProtoSchemaConverterTest.java": 3
            },
            "is_test": true,
            "is_fix": false
        },
        "51ca71a63e332e8976649f0631664de808529a25": {
            "datetime": "2013-12-21T00:12:22+01:00",
            "summary": "remove old package info",
            "message": "remove old package info\n",
            "diff": {
                "src/main/java/parquet/proto/package-info.java": 89
            },
            "is_test": false,
            "is_fix": false
        },
        "52ffcfe6eea65f54b4d06ee5a6680497f4905b2a": {
            "datetime": "2013-12-21T00:14:36+01:00",
            "summary": "remove commented code",
            "message": "remove commented code\n",
            "diff": {
                "src/main/java/parquet/proto/converters/ProtoMessageConverter.java": 3
            },
            "is_test": false,
            "is_fix": false
        },
        "f2e607efe4683f5a111dafe602951206b6ce4726": {
            "datetime": "2013-12-20T15:37:55-08:00",
            "summary": "add unit test",
            "message": "add unit test\n",
            "diff": {
                "parquet-hadoop/src/test/java/parquet/hadoop/metadata/TestColumnChunkMetaData.java": 64
            },
            "is_test": true,
            "is_fix": false
        },
        "3013b9f1ec57db26d9b09ee1981e3881fd65641f": {
            "datetime": "2013-12-20T15:59:13-08:00",
            "summary": "Merge pull request #249 from Parquet/metadata_opt",
            "message": "Merge pull request #249 from Parquet/metadata_opt\n\nmake summary files read in parallel; improve memory footprint of metadata; avoid unnecessary seek",
            "diff": {
                "parquet-hadoop/src/main/java/parquet/hadoop/ParquetFileReader.java": 107,
                "parquet-hadoop/src/main/java/parquet/hadoop/metadata/BlockMetaData.java": 3,
                "parquet-hadoop/src/main/java/parquet/hadoop/metadata/ColumnChunkMetaData.java": 62,
                "parquet-hadoop/src/test/java/parquet/hadoop/metadata/TestColumnChunkMetaData.java": 64
            },
            "is_test": true,
            "is_fix": false
        },
        "124f2ed8314083d0c2c642e9efdf1a08cba6f9c1": {
            "datetime": "2013-12-20T16:00:37-08:00",
            "summary": "Merge branch 'master' into optimize_scan",
            "message": "Merge branch 'master' into optimize_scan\n",
            "diff": {
                "parquet-cascading/src/test/java/parquet/cascading/TestParquetTBaseScheme.java": 3,
                "parquet-cascading/src/test/java/parquet/cascading/TestParquetTupleScheme.java": 3,
                "parquet-column/src/main/java/parquet/column/Encoding.java": 12,
                "parquet-column/src/main/java/parquet/column/ParquetProperties.java": 135,
                "parquet-column/src/main/java/parquet/column/impl/ColumnWriteStoreImpl.java": 7,
                "parquet-column/src/main/java/parquet/column/impl/ColumnWriterImpl.java": 62,
                "parquet-column/src/main/java/parquet/column/values/delta/DeltaBinaryPackingConfig.java": 54,
                "parquet-column/src/main/java/parquet/column/values/delta/DeltaBinaryPackingValuesReader.java": 164,
                "parquet-column/src/main/java/parquet/column/values/delta/DeltaBinaryPackingValuesWriter.java": 266,
                "parquet-column/src/test/java/parquet/column/mem/TestMemColumn.java": 4,
                "parquet-column/src/test/java/parquet/column/values/delta/DeltaBinaryPackingValuesWriterTest.java": 262,
                "parquet-column/src/test/java/parquet/column/values/delta/benchmark/BenchMarkTest.java": 40,
                "parquet-column/src/test/java/parquet/column/values/delta/benchmark/BenchmarkIntegerOutputSize.java": 99,
                "parquet-column/src/test/java/parquet/column/values/delta/benchmark/BenchmarkReadingRandomIntegers.java": 93,
                "parquet-column/src/test/java/parquet/column/values/delta/benchmark/RandomWritingBenchmarkTest.java": 67,
                "parquet-column/src/test/java/parquet/column/values/delta/benchmark/SmallRangeWritingBenchmarkTest.java": 45,
                "parquet-column/src/test/java/parquet/io/PerfTest.java": 3,
                "parquet-column/src/test/java/parquet/io/TestColumnIO.java": 4,
                "parquet-column/src/test/java/parquet/io/TestFiltered.java": 3,
                "parquet-common/src/main/java/parquet/bytes/BytesUtils.java": 16,
                "parquet-encoding/src/main/java/parquet/bytes/BytesInput.java": 37,
                "parquet-hadoop/src/main/java/parquet/hadoop/InternalParquetRecordWriter.java": 8,
                "parquet-hadoop/src/main/java/parquet/hadoop/ParquetInputFormat.java": 6,
                "parquet-hadoop/src/main/java/parquet/hadoop/ParquetOutputFormat.java": 23,
                "parquet-hadoop/src/main/java/parquet/hadoop/ParquetRecordWriter.java": 7,
                "parquet-hadoop/src/main/java/parquet/hadoop/ParquetWriter.java": 33,
                "parquet-hadoop/src/test/java/parquet/hadoop/codec/CodecConfigTest.java": 5,
                "parquet-hadoop/src/test/java/parquet/hadoop/metadata/TestColumnChunkMetaData.java": 64,
                "parquet-hive/parquet-hive-binding/parquet-hive-binding-factory/src/main/java/parquet/hive/HiveBindingFactory.java": 27,
                "parquet-hive/parquet-hive-binding/parquet-hive-binding-factory/src/test/java/parquet/hive/TestHiveBindingFactory.java": 20,
                "parquet-hive/parquet-hive-storage-handler/src/main/java/parquet/hive/MapredParquetOutputFormat.java": 2,
                "parquet-hive/parquet-hive-storage-handler/src/test/java/parquet/hive/TestMapredParquetInputFormat.java": 3,
                "parquet-pig/src/test/java/parquet/pig/GenerateIntTestFile.java": 3,
                "parquet-pig/src/test/java/parquet/pig/GenerateTPCH.java": 3,
                "parquet-pig/src/test/java/parquet/pig/PerfTest2.java": 8,
                "parquet-pig/src/test/java/parquet/pig/TestPigSchemaConverter.java": 2,
                "parquet-pig/src/test/java/parquet/pig/TupleConsumerPerfTest.java": 3,
                "parquet-scrooge/src/test/java/parquet/scrooge/ParquetScroogeSchemeTest.java": 6,
                "parquet-thrift/src/main/java/parquet/hadoop/thrift/ParquetThriftBytesOutputFormat.java": 6,
                "parquet-thrift/src/main/java/parquet/hadoop/thrift/ThriftBytesWriteSupport.java": 11,
                "parquet-thrift/src/main/java/parquet/hadoop/thrift/ThriftToParquetFileWriter.java": 28,
                "parquet-thrift/src/main/java/parquet/thrift/BufferedProtocolReadToWrite.java": 49,
                "parquet-thrift/src/main/java/parquet/thrift/ReadWriteErrorHandler.java": 39,
                "parquet-thrift/src/main/java/parquet/thrift/struct/CompatibilityRunner.java": 2,
                "parquet-thrift/src/test/java/parquet/hadoop/thrift/TestParquetToThriftReadProjection.java": 6,
                "parquet-thrift/src/test/java/parquet/hadoop/thrift/TestThriftToParquetFileWriter.java": 4,
                "parquet-thrift/src/test/java/parquet/thrift/TestParquetReadProtocol.java": 3,
                "parquet-thrift/src/test/java/parquet/thrift/TestProtocolReadToWrite.java": 147
            },
            "is_test": true,
            "is_fix": false
        },
        "3c91e46cb37600a78532233e888c7f27a42d9fea": {
            "datetime": "2013-12-20T16:05:34-08:00",
            "summary": "refactor dictionary page handling",
            "message": "refactor dictionary page handling\n",
            "diff": {
                "parquet-hadoop/src/main/java/parquet/hadoop/ParquetFileReader.java": 14
            },
            "is_test": false,
            "is_fix": false
        },
        "dc7addc32651005e67e7d50b70247ec1127e3304": {
            "datetime": "2013-12-20T16:18:58-08:00",
            "summary": "update with correct junit imports",
            "message": "update with correct junit imports\n",
            "diff": {
                "parquet-column/src/test/java/parquet/column/values/delta/DeltaBinaryPackingValuesWriterTest.java": 4,
                "parquet-column/src/test/java/parquet/column/values/deltalengthbytearray/TestDeltaLengthByteArray.java": 3,
                "parquet-column/src/test/java/parquet/column/values/deltastrings/TestDeltaByteArray.java": 3,
                "parquet-hadoop/src/test/java/parquet/hadoop/codec/CodecConfigTest.java": 3,
                "parquet-pig/src/main/java/parquet/pig/ParquetLoader.java": 1,
                "parquet-pig/src/main/java/parquet/pig/TupleReadSupport.java": 4,
                "parquet-pig/src/test/java/parquet/pig/TestParquetLoader.java": 6,
                "parquet-pig/src/test/java/parquet/pig/TestPigSchemaConverter.java": 4
            },
            "is_test": true,
            "is_fix": false
        },
        "9af41250a6852df1a0705c23b3655f0e504f3b6f": {
            "datetime": "2013-12-20T16:26:44-08:00",
            "summary": "turn on parquet 2.0 flags",
            "message": "turn on parquet 2.0 flags\n",
            "diff": {
                "parquet-column/src/main/java/parquet/column/ParquetProperties.java": 10,
                "parquet-column/src/test/java/parquet/column/values/delta/DeltaBinaryPackingValuesWriterTest.java": 11
            },
            "is_test": true,
            "is_fix": false
        },
        "e91cda90fabda87d82a14708422933e2f9b44ab7": {
            "datetime": "2013-12-20T16:42:52-08:00",
            "summary": "Merge pull request #259 from Parquet/delta_strings",
            "message": "Merge pull request #259 from Parquet/delta_strings\n\nadd delta length byte arrays and delta byte arrays encodings",
            "diff": {
                "parquet-column/src/main/java/parquet/column/Encoding.java": 31,
                "parquet-column/src/main/java/parquet/column/ParquetProperties.java": 10,
                "parquet-column/src/main/java/parquet/column/impl/ColumnReaderImpl.java": 8,
                "parquet-column/src/main/java/parquet/column/values/ValuesReader.java": 13,
                "parquet-column/src/main/java/parquet/column/values/bitpacking/BitPackingValuesReader.java": 13,
                "parquet-column/src/main/java/parquet/column/values/bitpacking/ByteBitPackingValuesReader.java": 13,
                "parquet-column/src/main/java/parquet/column/values/boundedint/BoundedIntValuesReader.java": 10,
                "parquet-column/src/main/java/parquet/column/values/boundedint/ZeroIntegerValuesReader.java": 11,
                "parquet-column/src/main/java/parquet/column/values/delta/DeltaBinaryPackingValuesReader.java": 7,
                "parquet-column/src/main/java/parquet/column/values/deltalengthbytearray/DeltaLengthByteArrayValuesReader.java": 67,
                "parquet-column/src/main/java/parquet/column/values/deltalengthbytearray/DeltaLengthByteArrayValuesWriter.java": 103,
                "parquet-column/src/main/java/parquet/column/values/deltastrings/DeltaByteArrayReader.java": 75,
                "parquet-column/src/main/java/parquet/column/values/deltastrings/DeltaByteArrayWriter.java": 89,
                "parquet-column/src/main/java/parquet/column/values/dictionary/DictionaryValuesReader.java": 3,
                "parquet-column/src/main/java/parquet/column/values/plain/BinaryPlainValuesReader.java": 3,
                "parquet-column/src/main/java/parquet/column/values/plain/BooleanPlainValuesReader.java": 9,
                "parquet-column/src/main/java/parquet/column/values/plain/FixedLenByteArrayPlainValuesReader.java": 4,
                "parquet-column/src/main/java/parquet/column/values/plain/PlainValuesReader.java": 19,
                "parquet-column/src/main/java/parquet/column/values/plain/PlainValuesWriter.java": 1,
                "parquet-column/src/main/java/parquet/column/values/rle/RunLengthBitPackingHybridValuesReader.java": 26,
                "parquet-column/src/main/java/parquet/column/values/rle/RunLengthBitPackingHybridValuesWriter.java": 5,
                "parquet-column/src/test/java/parquet/column/values/RandomStr.java": 53,
                "parquet-column/src/test/java/parquet/column/values/Utils.java": 87,
                "parquet-column/src/test/java/parquet/column/values/boundedint/TestBoundedColumns.java": 3,
                "parquet-column/src/test/java/parquet/column/values/delta/DeltaBinaryPackingValuesWriterTest.java": 15,
                "parquet-column/src/test/java/parquet/column/values/deltalengthbytearray/TestDeltaLengthByteArray.java": 71,
                "parquet-column/src/test/java/parquet/column/values/deltalengthbytearray/benchmark/BenchmarkDeltaLengthByteArray.java": 68,
                "parquet-column/src/test/java/parquet/column/values/deltastrings/TestDeltaByteArray.java": 81,
                "parquet-column/src/test/java/parquet/column/values/deltastrings/benchmark/BenchmarkDeltaByteArray.java": 98,
                "parquet-hadoop/src/test/java/parquet/hadoop/codec/CodecConfigTest.java": 3,
                "parquet-pig/src/main/java/parquet/pig/ParquetLoader.java": 1,
                "parquet-pig/src/main/java/parquet/pig/TupleReadSupport.java": 4,
                "parquet-pig/src/test/java/parquet/pig/TestParquetLoader.java": 6,
                "parquet-pig/src/test/java/parquet/pig/TestPigSchemaConverter.java": 4
            },
            "is_test": true,
            "is_fix": false
        },
        "2b80e47b6346d4f34dacd0d6314ab6bea80fe6d7": {
            "datetime": "2013-12-20T16:55:54-08:00",
            "summary": "Merge branch 'master' into add-parquet-jackson-module",
            "message": "Merge branch 'master' into add-parquet-jackson-module\n",
            "diff": {
                "parquet-cascading/src/test/java/parquet/cascading/TestParquetTBaseScheme.java": 3,
                "parquet-cascading/src/test/java/parquet/cascading/TestParquetTupleScheme.java": 3,
                "parquet-column/src/main/java/parquet/column/Encoding.java": 43,
                "parquet-column/src/main/java/parquet/column/ParquetProperties.java": 133,
                "parquet-column/src/main/java/parquet/column/impl/ColumnReaderImpl.java": 8,
                "parquet-column/src/main/java/parquet/column/impl/ColumnWriteStoreImpl.java": 7,
                "parquet-column/src/main/java/parquet/column/impl/ColumnWriterImpl.java": 62,
                "parquet-column/src/main/java/parquet/column/values/ValuesReader.java": 13,
                "parquet-column/src/main/java/parquet/column/values/bitpacking/BitPackingValuesReader.java": 13,
                "parquet-column/src/main/java/parquet/column/values/bitpacking/ByteBitPackingValuesReader.java": 13,
                "parquet-column/src/main/java/parquet/column/values/boundedint/BoundedIntValuesReader.java": 10,
                "parquet-column/src/main/java/parquet/column/values/boundedint/ZeroIntegerValuesReader.java": 11,
                "parquet-column/src/main/java/parquet/column/values/delta/DeltaBinaryPackingConfig.java": 54,
                "parquet-column/src/main/java/parquet/column/values/delta/DeltaBinaryPackingValuesReader.java": 167,
                "parquet-column/src/main/java/parquet/column/values/delta/DeltaBinaryPackingValuesWriter.java": 266,
                "parquet-column/src/main/java/parquet/column/values/deltalengthbytearray/DeltaLengthByteArrayValuesReader.java": 67,
                "parquet-column/src/main/java/parquet/column/values/deltalengthbytearray/DeltaLengthByteArrayValuesWriter.java": 103,
                "parquet-column/src/main/java/parquet/column/values/deltastrings/DeltaByteArrayReader.java": 75,
                "parquet-column/src/main/java/parquet/column/values/deltastrings/DeltaByteArrayWriter.java": 89,
                "parquet-column/src/main/java/parquet/column/values/dictionary/DictionaryValuesReader.java": 3,
                "parquet-column/src/main/java/parquet/column/values/plain/BinaryPlainValuesReader.java": 3,
                "parquet-column/src/main/java/parquet/column/values/plain/BooleanPlainValuesReader.java": 9,
                "parquet-column/src/main/java/parquet/column/values/plain/FixedLenByteArrayPlainValuesReader.java": 4,
                "parquet-column/src/main/java/parquet/column/values/plain/PlainValuesReader.java": 19,
                "parquet-column/src/main/java/parquet/column/values/plain/PlainValuesWriter.java": 1,
                "parquet-column/src/main/java/parquet/column/values/rle/RunLengthBitPackingHybridValuesReader.java": 26,
                "parquet-column/src/main/java/parquet/column/values/rle/RunLengthBitPackingHybridValuesWriter.java": 5,
                "parquet-column/src/test/java/parquet/column/mem/TestMemColumn.java": 4,
                "parquet-column/src/test/java/parquet/column/values/RandomStr.java": 53,
                "parquet-column/src/test/java/parquet/column/values/Utils.java": 87,
                "parquet-column/src/test/java/parquet/column/values/boundedint/TestBoundedColumns.java": 3,
                "parquet-column/src/test/java/parquet/column/values/delta/DeltaBinaryPackingValuesWriterTest.java": 259,
                "parquet-column/src/test/java/parquet/column/values/delta/benchmark/BenchMarkTest.java": 40,
                "parquet-column/src/test/java/parquet/column/values/delta/benchmark/BenchmarkIntegerOutputSize.java": 99,
                "parquet-column/src/test/java/parquet/column/values/delta/benchmark/BenchmarkReadingRandomIntegers.java": 93,
                "parquet-column/src/test/java/parquet/column/values/delta/benchmark/RandomWritingBenchmarkTest.java": 67,
                "parquet-column/src/test/java/parquet/column/values/delta/benchmark/SmallRangeWritingBenchmarkTest.java": 45,
                "parquet-column/src/test/java/parquet/column/values/deltalengthbytearray/TestDeltaLengthByteArray.java": 71,
                "parquet-column/src/test/java/parquet/column/values/deltalengthbytearray/benchmark/BenchmarkDeltaLengthByteArray.java": 68,
                "parquet-column/src/test/java/parquet/column/values/deltastrings/TestDeltaByteArray.java": 81,
                "parquet-column/src/test/java/parquet/column/values/deltastrings/benchmark/BenchmarkDeltaByteArray.java": 98,
                "parquet-column/src/test/java/parquet/io/PerfTest.java": 3,
                "parquet-column/src/test/java/parquet/io/TestColumnIO.java": 4,
                "parquet-column/src/test/java/parquet/io/TestFiltered.java": 3,
                "parquet-common/src/main/java/parquet/bytes/BytesUtils.java": 16,
                "parquet-encoding/src/main/java/parquet/bytes/BytesInput.java": 37,
                "parquet-hadoop/src/main/java/parquet/hadoop/InternalParquetRecordWriter.java": 8,
                "parquet-hadoop/src/main/java/parquet/hadoop/ParquetFileReader.java": 107,
                "parquet-hadoop/src/main/java/parquet/hadoop/ParquetInputFormat.java": 6,
                "parquet-hadoop/src/main/java/parquet/hadoop/ParquetOutputFormat.java": 23,
                "parquet-hadoop/src/main/java/parquet/hadoop/ParquetRecordWriter.java": 7,
                "parquet-hadoop/src/main/java/parquet/hadoop/ParquetWriter.java": 33,
                "parquet-hadoop/src/main/java/parquet/hadoop/metadata/BlockMetaData.java": 3,
                "parquet-hadoop/src/main/java/parquet/hadoop/metadata/ColumnChunkMetaData.java": 62,
                "parquet-hadoop/src/test/java/parquet/hadoop/codec/CodecConfigTest.java": 8,
                "parquet-hadoop/src/test/java/parquet/hadoop/metadata/TestColumnChunkMetaData.java": 64,
                "parquet-hive/parquet-hive-binding/parquet-hive-binding-factory/src/main/java/parquet/hive/HiveBindingFactory.java": 27,
                "parquet-hive/parquet-hive-binding/parquet-hive-binding-factory/src/test/java/parquet/hive/TestHiveBindingFactory.java": 20,
                "parquet-hive/parquet-hive-storage-handler/src/main/java/parquet/hive/MapredParquetOutputFormat.java": 2,
                "parquet-hive/parquet-hive-storage-handler/src/test/java/parquet/hive/TestMapredParquetInputFormat.java": 3,
                "parquet-pig/src/main/java/parquet/pig/ParquetLoader.java": 1,
                "parquet-pig/src/main/java/parquet/pig/TupleReadSupport.java": 4,
                "parquet-pig/src/test/java/parquet/pig/GenerateIntTestFile.java": 3,
                "parquet-pig/src/test/java/parquet/pig/GenerateTPCH.java": 3,
                "parquet-pig/src/test/java/parquet/pig/PerfTest2.java": 8,
                "parquet-pig/src/test/java/parquet/pig/TestParquetLoader.java": 6,
                "parquet-pig/src/test/java/parquet/pig/TestPigSchemaConverter.java": 6,
                "parquet-pig/src/test/java/parquet/pig/TupleConsumerPerfTest.java": 3,
                "parquet-scrooge/src/test/java/parquet/scrooge/ParquetScroogeSchemeTest.java": 6,
                "parquet-thrift/src/main/java/parquet/hadoop/thrift/ParquetThriftBytesOutputFormat.java": 6,
                "parquet-thrift/src/main/java/parquet/hadoop/thrift/ThriftBytesWriteSupport.java": 11,
                "parquet-thrift/src/main/java/parquet/hadoop/thrift/ThriftToParquetFileWriter.java": 28,
                "parquet-thrift/src/main/java/parquet/thrift/BufferedProtocolReadToWrite.java": 49,
                "parquet-thrift/src/main/java/parquet/thrift/ReadWriteErrorHandler.java": 39,
                "parquet-thrift/src/main/java/parquet/thrift/struct/CompatibilityRunner.java": 2,
                "parquet-thrift/src/test/java/parquet/hadoop/thrift/TestParquetToThriftReadProjection.java": 6,
                "parquet-thrift/src/test/java/parquet/hadoop/thrift/TestThriftToParquetFileWriter.java": 4,
                "parquet-thrift/src/test/java/parquet/thrift/TestParquetReadProtocol.java": 3,
                "parquet-thrift/src/test/java/parquet/thrift/TestProtocolReadToWrite.java": 147
            },
            "is_test": true,
            "is_fix": false
        },
        "cc8375c1c708dfbcfbd02207129bbd9a8b5756a4": {
            "datetime": "2013-12-20T16:58:27-08:00",
            "summary": "Merge pull request #258 from Parquet/optimize_scan",
            "message": "Merge pull request #258 from Parquet/optimize_scan\n\nOptimize scan",
            "diff": {
                "parquet-hadoop/src/main/java/parquet/hadoop/ParquetFileReader.java": 334
            },
            "is_test": false,
            "is_fix": false
        },
        "f7a90232cab0da9121c327ad0b43c2d39811fb53": {
            "datetime": "2013-12-26T14:15:12+01:00",
            "summary": "correct byte[] storage",
            "message": "correct byte[] storage\n",
            "diff": {
                "src/main/java/parquet/proto/ProtoWriteSupport.java": 16,
                "src/main/java/parquet/proto/converters/ProtoBinaryConverter.java": 6
            },
            "is_test": false,
            "is_fix": false
        },
        "5997bf5ce0f588c7ea8ad0e6786d7dc3105908b5": {
            "datetime": "2013-12-26T16:18:22+01:00",
            "summary": "#projection test",
            "message": "#projection test\n",
            "diff": {
                "src/main/java/parquet/proto/ProtoParquetInputFormat.java": 9,
                "src/test/java/parquet/proto/ProtoInputOutputFormatTest.java": 129,
                "src/test/java/parquet/proto/utils/ReadUsingMR.java": 74,
                "src/test/java/parquet/proto/utils/WriteUsingMR.java": 104
            },
            "is_test": true,
            "is_fix": false
        },
        "96f230019ae8e91f0eacf1490481a73161b4d8a2": {
            "datetime": "2013-12-26T16:22:11+01:00",
            "summary": "#projection test - fix - cannot use inner class as mapper",
            "message": "#projection test - fix - cannot use inner class as mapper\n",
            "diff": {
                "src/test/java/parquet/proto/utils/ReadUsingMR.java": 55,
                "src/test/java/parquet/proto/utils/WriteUsingMR.java": 71
            },
            "is_test": false,
            "is_fix": false
        },
        "985002ee33ffe6c199ff6471b3df89394bb22f14": {
            "datetime": "2013-12-26T21:00:30+01:00",
            "summary": "Code cleanup",
            "message": "Code cleanup\n",
            "diff": {
                "src/main/java/parquet/proto/converters/ProtoEnumConverter.java": 6,
                "src/main/java/parquet/proto/converters/ProtoMessageConverter.java": 10,
                "src/main/java/parquet/proto/converters/ProtobufStringConverter.java": 5,
                "src/test/java/parquet/proto/utils/ReadUsingMR.java": 3
            },
            "is_test": false,
            "is_fix": false
        },
        "b273684b5a4efdd49a5bc3e0e5aa70ad3abbb155": {
            "datetime": "2013-12-26T21:00:45+01:00",
            "summary": "ConverterTest",
            "message": "ConverterTest\n",
            "diff": {
                "src/test/java/parquet/proto/ProtoSchemaConverterTest.java": 2,
                "src/test/java/parquet/proto/ProtobufferRecordConverterTest.java": 134,
                "src/test/java/parquet/proto/TestUtils.java": 8
            },
            "is_test": true,
            "is_fix": false
        },
        "99b7e52a58d55d894dc244c93e5a4c4d183e411e": {
            "datetime": "2013-12-26T21:08:35+01:00",
            "summary": "new root directory",
            "message": "new root directory\n",
            "diff": {
                "src/main/java/parquet/proto/ProtoParquetInputFormat.java": 0,
                "src/main/java/parquet/proto/ProtoParquetOutputFormat.java": 0,
                "src/main/java/parquet/proto/ProtoParquetReader.java": 0,
                "src/main/java/parquet/proto/ProtoParquetWriter.java": 0,
                "src/main/java/parquet/proto/ProtoReadSupport.java": 0,
                "src/main/java/parquet/proto/ProtoRecordMaterializer.java": 0,
                "src/main/java/parquet/proto/ProtoSchemaConverter.java": 0,
                "src/main/java/parquet/proto/ProtoWriteSupport.java": 0,
                "src/main/java/parquet/proto/ProtobufferRecordConverter.java": 0,
                "src/main/java/parquet/proto/converters/ParentValueContainer.java": 0,
                "src/main/java/parquet/proto/converters/ProtoArrayConverter.java": 0,
                "src/main/java/parquet/proto/converters/ProtoBinaryConverter.java": 0,
                "src/main/java/parquet/proto/converters/ProtoBooleanConverter.java": 0,
                "src/main/java/parquet/proto/converters/ProtoDoubleConverter.java": 0,
                "src/main/java/parquet/proto/converters/ProtoEnumConverter.java": 0,
                "src/main/java/parquet/proto/converters/ProtoFloatConverter.java": 0,
                "src/main/java/parquet/proto/converters/ProtoIntConverter.java": 0,
                "src/main/java/parquet/proto/converters/ProtoLongConverter.java": 0,
                "src/main/java/parquet/proto/converters/ProtoMessageConverter.java": 0,
                "src/main/java/parquet/proto/converters/ProtobufStringConverter.java": 0,
                "src/test/java/parquet/proto/ProtoInputOutputFormatTest.java": 0,
                "src/test/java/parquet/proto/ProtoSchemaConverterTest.java": 0,
                "src/test/java/parquet/proto/ProtobufferRecordConverterTest.java": 0,
                "src/test/java/parquet/proto/TestUtils.java": 0,
                "src/test/java/parquet/proto/utils/ReadUsingMR.java": 0,
                "src/test/java/parquet/proto/utils/WriteUsingMR.java": 0
            },
            "is_test": true,
            "is_fix": false
        },
        "a717bbf2fc28f26e84f8374f6ffce4d30d8c618c": {
            "datetime": "2013-12-26T22:13:52+01:00",
            "summary": "merge",
            "message": "merge\n",
            "diff": {
                "parquet-protobuf/src/main/java/parquet/proto/ProtoParquetInputFormat.java": 34,
                "parquet-protobuf/src/main/java/parquet/proto/ProtoParquetOutputFormat.java": 54,
                "parquet-protobuf/src/main/java/parquet/proto/ProtoParquetReader.java": 40,
                "parquet-protobuf/src/main/java/parquet/proto/ProtoParquetWriter.java": 78,
                "parquet-protobuf/src/main/java/parquet/proto/ProtoReadSupport.java": 66,
                "parquet-protobuf/src/main/java/parquet/proto/ProtoRecordMaterializer.java": 41,
                "parquet-protobuf/src/main/java/parquet/proto/ProtoSchemaConverter.java": 136,
                "parquet-protobuf/src/main/java/parquet/proto/ProtoWriteSupport.java": 193,
                "parquet-protobuf/src/main/java/parquet/proto/ProtobufferRecordConverter.java": 72,
                "parquet-protobuf/src/main/java/parquet/proto/converters/ParentValueContainer.java": 26,
                "parquet-protobuf/src/main/java/parquet/proto/converters/ProtoArrayConverter.java": 44,
                "parquet-protobuf/src/main/java/parquet/proto/converters/ProtoBinaryConverter.java": 36,
                "parquet-protobuf/src/main/java/parquet/proto/converters/ProtoBooleanConverter.java": 34,
                "parquet-protobuf/src/main/java/parquet/proto/converters/ProtoDoubleConverter.java": 33,
                "parquet-protobuf/src/main/java/parquet/proto/converters/ProtoEnumConverter.java": 69,
                "parquet-protobuf/src/main/java/parquet/proto/converters/ProtoFloatConverter.java": 33,
                "parquet-protobuf/src/main/java/parquet/proto/converters/ProtoIntConverter.java": 33,
                "parquet-protobuf/src/main/java/parquet/proto/converters/ProtoLongConverter.java": 33,
                "parquet-protobuf/src/main/java/parquet/proto/converters/ProtoMessageConverter.java": 183,
                "parquet-protobuf/src/main/java/parquet/proto/converters/ProtobufStringConverter.java": 37,
                "parquet-protobuf/src/test/java/parquet/proto/ProtoInputOutputFormatTest.java": 102,
                "parquet-protobuf/src/test/java/parquet/proto/ProtoSchemaConverterTest.java": 99,
                "parquet-protobuf/src/test/java/parquet/proto/ProtobufferRecordConverterTest.java": 134,
                "parquet-protobuf/src/test/java/parquet/proto/TestUtils.java": 174,
                "parquet-protobuf/src/test/java/parquet/proto/utils/ReadUsingMR.java": 78,
                "parquet-protobuf/src/test/java/parquet/proto/utils/WriteUsingMR.java": 113
            },
            "is_test": true,
            "is_fix": false
        },
        "919db0ba56e7bce8d22c9a5a69d2b29e674a24ec": {
            "datetime": "2013-12-26T23:40:46+01:00",
            "summary": "Consistent naming protoXYZ",
            "message": "Consistent naming protoXYZ\n",
            "diff": {
                "parquet-protobuf/src/main/java/parquet/proto/ProtoParquetOutputFormat.java": 6,
                "parquet-protobuf/src/main/java/parquet/proto/ProtoParquetReader.java": 4,
                "parquet-protobuf/src/main/java/parquet/proto/ProtoParquetWriter.java": 4,
                "parquet-protobuf/src/main/java/parquet/proto/ProtoReadSupport.java": 2,
                "parquet-protobuf/src/main/java/parquet/proto/ProtoRecordMaterializer.java": 6,
                "parquet-protobuf/src/main/java/parquet/proto/ProtoSchemaConverter.java": 8,
                "parquet-protobuf/src/main/java/parquet/proto/ProtoWriteSupport.java": 6,
                "parquet-protobuf/src/main/java/parquet/proto/ProtobufferRecordConverter.java": 6,
                "parquet-protobuf/src/main/java/parquet/proto/converters/ProtoEnumConverter.java": 2,
                "parquet-protobuf/src/test/java/parquet/proto/ProtoInputOutputFormatTest.java": 4,
                "parquet-protobuf/src/test/java/parquet/proto/ProtoSchemaConverterTest.java": 4,
                "parquet-protobuf/src/test/java/parquet/proto/ProtobufferRecordConverterTest.java": 7,
                "parquet-protobuf/src/test/java/parquet/proto/TestUtils.java": 4,
                "parquet-protobuf/src/test/java/parquet/proto/utils/WriteUsingMR.java": 14
            },
            "is_test": true,
            "is_fix": false
        },
        "1f4a9db0b7216e5d7d5444aa86ae56ecdfda1b71": {
            "datetime": "2013-12-27T00:01:29+01:00",
            "summary": "Code cleanup",
            "message": "Code cleanup\n",
            "diff": {
                "parquet-protobuf/src/main/java/parquet/proto/ProtoReadSupport.java": 17,
                "parquet-protobuf/src/main/java/parquet/proto/ProtoSchemaConverter.java": 4,
                "parquet-protobuf/src/main/java/parquet/proto/converters/ProtoMessageConverter.java": 7,
                "parquet-protobuf/src/main/java/parquet/proto/converters/ProtobufStringConverter.java": 4,
                "parquet-protobuf/src/test/java/parquet/proto/ProtoInputOutputFormatTest.java": 4
            },
            "is_test": true,
            "is_fix": false
        },
        "c7c39c3f5a12d3b823813bd6307d2e0e2ed98fce": {
            "datetime": "2013-12-27T00:50:48+01:00",
            "summary": "Repeated Messages test",
            "message": "Repeated Messages test\n",
            "diff": {
                "parquet-protobuf/src/main/java/parquet/proto/converters/ProtoMessageConverter.java": 3,
                "parquet-protobuf/src/test/java/parquet/proto/ProtoRecordConverterTest.java": 27
            },
            "is_test": true,
            "is_fix": false
        },
        "47cd5723c39fd87c4aac676bebf67a6d6c931e43": {
            "datetime": "2013-12-27T00:51:42+01:00",
            "summary": "Method ProtoParquetInputFormat.setRequestedProjection signature",
            "message": "Method ProtoParquetInputFormat.setRequestedProjection signature\n",
            "diff": {
                "parquet-protobuf/src/main/java/parquet/proto/ProtoParquetInputFormat.java": 7,
                "parquet-protobuf/src/main/java/parquet/proto/ProtoRecordConverter.java": 10,
                "parquet-protobuf/src/test/java/parquet/proto/ProtoInputOutputFormatTest.java": 5,
                "parquet-protobuf/src/test/java/parquet/proto/utils/ReadUsingMR.java": 16,
                "parquet-protobuf/src/test/java/parquet/proto/utils/WriteUsingMR.java": 8
            },
            "is_test": true,
            "is_fix": false
        },
        "565638f859d07256bc9f22218a54c04ae48f162f": {
            "datetime": "2013-12-26T16:17:12-08:00",
            "summary": "refactor",
            "message": "refactor\n",
            "diff": {
                "parquet-scrooge/src/main/java/parquet/scrooge/EnumConverter.java": 44,
                "parquet-scrooge/src/main/java/parquet/scrooge/ScroogeEnumDesc.java": 34,
                "parquet-scrooge/src/main/java/parquet/scrooge/ScroogeSchemaConverter.java": 289,
                "parquet-scrooge/src/test/java/parquet/scrooge/ParquetScroogeSchemeTest.java": 5,
                "parquet-scrooge/src/test/java/parquet/scrooge/ScroogeSchemaConverterTest.java": 201
            },
            "is_test": true,
            "is_fix": false
        },
        "1d1dd2fa7832a51133c8003451334c1f4068cfe8": {
            "datetime": "2013-12-26T19:26:14-08:00",
            "summary": "1. refactor: maket ThriftSchemaConverter pluggable, can use",
            "message": "1. refactor: maket ThriftSchemaConverter pluggable, can use\nThriftStructConverter or ScroogeStructConvert to convert class to\nThriftType\n2. support scrooge read projection pushdown\n3. add scroogeReadSupport\n",
            "diff": {
                "parquet-scrooge/src/main/java/parquet/scrooge/ParquetScroogeScheme.java": 2,
                "parquet-scrooge/src/main/java/parquet/scrooge/ScroogeReadSupport.java": 42,
                "parquet-scrooge/src/main/java/parquet/scrooge/ScroogeSchemaConverter.java": 53,
                "parquet-scrooge/src/test/java/parquet/scrooge/ParquetScroogeSchemeTest.java": 49,
                "parquet-scrooge/src/test/java/parquet/scrooge/ScroogeSchemaConverterTest.java": 47,
                "parquet-thrift/src/main/java/parquet/hadoop/thrift/ThriftReadSupport.java": 13,
                "parquet-thrift/src/main/java/parquet/thrift/ThriftSchemaConverter.java": 156,
                "parquet-thrift/src/test/java/parquet/thrift/TestThriftSchemaConverter.java": 6
            },
            "is_test": true,
            "is_fix": false
        },
        "ebc87de72be2249ce749b6893021b9c48f6a93c8": {
            "datetime": "2013-12-26T19:38:01-08:00",
            "summary": "format",
            "message": "format\n",
            "diff": {
                "parquet-scrooge/src/main/java/parquet/scrooge/ScroogeRecordConverter.java": 2,
                "parquet-scrooge/src/main/java/parquet/scrooge/ScroogeStructConverter.java": 4,
                "parquet-scrooge/src/test/java/parquet/scrooge/ParquetScroogeSchemeTest.java": 1
            },
            "is_test": true,
            "is_fix": false
        },
        "0fb0173132b27a3077d0faefc0a70888f5b49baf": {
            "datetime": "2013-12-26T19:45:40-08:00",
            "summary": "merge master",
            "message": "merge master\n",
            "diff": {
                "parquet-avro/src/main/java/parquet/avro/AvroIndexedRecordConverter.java": 33,
                "parquet-avro/src/main/java/parquet/avro/AvroParquetReader.java": 14,
                "parquet-avro/src/main/java/parquet/avro/AvroSchemaConverter.java": 19,
                "parquet-avro/src/main/java/parquet/avro/AvroWriteSupport.java": 76,
                "parquet-avro/src/test/java/parquet/avro/TestAvroSchemaConverter.java": 27,
                "parquet-avro/src/test/java/parquet/avro/TestReadWrite.java": 114,
                "parquet-avro/src/test/java/parquet/avro/TestSpecificInputOutputFormat.java": 22,
                "parquet-avro/src/test/java/parquet/avro/TestSpecificReadWrite.java": 106,
                "parquet-cascading/src/main/java/parquet/cascading/ParquetTBaseScheme.java": 43,
                "parquet-cascading/src/main/java/parquet/cascading/ParquetTupleScheme.java": 12,
                "parquet-cascading/src/main/java/parquet/cascading/ParquetValueScheme.java": 16,
                "parquet-cascading/src/test/java/parquet/cascading/TestParquetTBaseScheme.java": 182,
                "parquet-cascading/src/test/java/parquet/cascading/TestParquetTupleScheme.java": 193,
                "parquet-column/src/main/java/parquet/column/ColumnDescriptor.java": 26,
                "parquet-column/src/main/java/parquet/column/ColumnWriter.java": 1,
                "parquet-column/src/main/java/parquet/column/Encoding.java": 74,
                "parquet-column/src/main/java/parquet/column/ParquetProperties.java": 133,
                "parquet-column/src/main/java/parquet/column/impl/ColumnReaderImpl.java": 30,
                "parquet-column/src/main/java/parquet/column/impl/ColumnWriteStoreImpl.java": 9,
                "parquet-column/src/main/java/parquet/column/impl/ColumnWriterImpl.java": 77,
                "parquet-column/src/main/java/parquet/column/values/ValuesReader.java": 14,
                "parquet-column/src/main/java/parquet/column/values/bitpacking/BitPackingValuesReader.java": 13,
                "parquet-column/src/main/java/parquet/column/values/bitpacking/ByteBitPackingValuesReader.java": 13,
                "parquet-column/src/main/java/parquet/column/values/boundedint/BoundedIntValuesReader.java": 10,
                "parquet-column/src/main/java/parquet/column/values/boundedint/ZeroIntegerValuesReader.java": 11,
                "parquet-column/src/main/java/parquet/column/values/delta/DeltaBinaryPackingConfig.java": 54,
                "parquet-column/src/main/java/parquet/column/values/delta/DeltaBinaryPackingValuesReader.java": 167,
                "parquet-column/src/main/java/parquet/column/values/delta/DeltaBinaryPackingValuesWriter.java": 266,
                "parquet-column/src/main/java/parquet/column/values/deltalengthbytearray/DeltaLengthByteArrayValuesReader.java": 67,
                "parquet-column/src/main/java/parquet/column/values/deltalengthbytearray/DeltaLengthByteArrayValuesWriter.java": 103,
                "parquet-column/src/main/java/parquet/column/values/deltastrings/DeltaByteArrayReader.java": 75,
                "parquet-column/src/main/java/parquet/column/values/deltastrings/DeltaByteArrayWriter.java": 89,
                "parquet-column/src/main/java/parquet/column/values/dictionary/DictionaryValuesReader.java": 7,
                "parquet-column/src/main/java/parquet/column/values/dictionary/DictionaryValuesWriter.java": 247,
                "parquet-column/src/main/java/parquet/column/values/plain/BinaryPlainValuesReader.java": 3,
                "parquet-column/src/main/java/parquet/column/values/plain/BooleanPlainValuesReader.java": 9,
                "parquet-column/src/main/java/parquet/column/values/plain/FixedLenByteArrayPlainValuesReader.java": 65,
                "parquet-column/src/main/java/parquet/column/values/plain/FixedLenByteArrayPlainValuesWriter.java": 95,
                "parquet-column/src/main/java/parquet/column/values/plain/PlainValuesReader.java": 19,
                "parquet-column/src/main/java/parquet/column/values/plain/PlainValuesWriter.java": 1,
                "parquet-column/src/main/java/parquet/column/values/rle/RunLengthBitPackingHybridDecoder.java": 21,
                "parquet-column/src/main/java/parquet/column/values/rle/RunLengthBitPackingHybridValuesReader.java": 30,
                "parquet-column/src/main/java/parquet/column/values/rle/RunLengthBitPackingHybridValuesWriter.java": 5,
                "parquet-column/src/main/java/parquet/example/data/simple/convert/SimplePrimitiveConverter.java": 9,
                "parquet-column/src/main/java/parquet/filter/ColumnPredicates.java": 90,
                "parquet-column/src/main/java/parquet/filter/NotRecordFilter.java": 55,
                "parquet-column/src/main/java/parquet/filter/OrRecordFilter.java": 59,
                "parquet-column/src/main/java/parquet/io/PrimitiveColumnIO.java": 9,
                "parquet-column/src/main/java/parquet/io/api/Binary.java": 23,
                "parquet-column/src/main/java/parquet/schema/MessageType.java": 13,
                "parquet-column/src/main/java/parquet/schema/MessageTypeParser.java": 19,
                "parquet-column/src/main/java/parquet/schema/PrimitiveType.java": 68,
                "parquet-column/src/test/java/parquet/column/mem/TestMemColumn.java": 14,
                "parquet-column/src/test/java/parquet/column/values/RandomStr.java": 53,
                "parquet-column/src/test/java/parquet/column/values/Utils.java": 87,
                "parquet-column/src/test/java/parquet/column/values/boundedint/TestBoundedColumns.java": 3,
                "parquet-column/src/test/java/parquet/column/values/delta/DeltaBinaryPackingValuesWriterTest.java": 259,
                "parquet-column/src/test/java/parquet/column/values/delta/benchmark/BenchMarkTest.java": 40,
                "parquet-column/src/test/java/parquet/column/values/delta/benchmark/BenchmarkIntegerOutputSize.java": 99,
                "parquet-column/src/test/java/parquet/column/values/delta/benchmark/BenchmarkReadingRandomIntegers.java": 93,
                "parquet-column/src/test/java/parquet/column/values/delta/benchmark/RandomWritingBenchmarkTest.java": 67,
                "parquet-column/src/test/java/parquet/column/values/delta/benchmark/SmallRangeWritingBenchmarkTest.java": 45,
                "parquet-column/src/test/java/parquet/column/values/deltalengthbytearray/TestDeltaLengthByteArray.java": 71,
                "parquet-column/src/test/java/parquet/column/values/deltalengthbytearray/benchmark/BenchmarkDeltaLengthByteArray.java": 68,
                "parquet-column/src/test/java/parquet/column/values/deltastrings/TestDeltaByteArray.java": 81,
                "parquet-column/src/test/java/parquet/column/values/deltastrings/benchmark/BenchmarkDeltaByteArray.java": 98,
                "parquet-column/src/test/java/parquet/column/values/dictionary/TestDictionary.java": 606,
                "parquet-column/src/test/java/parquet/column/values/rle/RunLengthBitPackingHybridIntegrationTest.java": 5,
                "parquet-column/src/test/java/parquet/column/values/rle/TestRunLengthBitPackingHybridEncoder.java": 2,
                "parquet-column/src/test/java/parquet/io/ExpectationValidatingRecordConsumer.java": 1,
                "parquet-column/src/test/java/parquet/io/PerfTest.java": 3,
                "parquet-column/src/test/java/parquet/io/TestColumnIO.java": 50,
                "parquet-column/src/test/java/parquet/io/TestFiltered.java": 141,
                "parquet-common/src/main/java/parquet/bytes/BytesUtils.java": 16,
                "parquet-encoding/src/main/java/parquet/bytes/BytesInput.java": 37,
                "parquet-hadoop/src/main/java/parquet/format/converter/ParquetMetadataConverter.java": 87,
                "parquet-hadoop/src/main/java/parquet/hadoop/CodecFactory.java": 2,
                "parquet-hadoop/src/main/java/parquet/hadoop/InternalParquetRecordWriter.java": 42,
                "parquet-hadoop/src/main/java/parquet/hadoop/ParquetFileReader.java": 424,
                "parquet-hadoop/src/main/java/parquet/hadoop/ParquetFileWriter.java": 5,
                "parquet-hadoop/src/main/java/parquet/hadoop/ParquetInputFormat.java": 6,
                "parquet-hadoop/src/main/java/parquet/hadoop/ParquetInputSplit.java": 9,
                "parquet-hadoop/src/main/java/parquet/hadoop/ParquetOutputFormat.java": 186,
                "parquet-hadoop/src/main/java/parquet/hadoop/ParquetReader.java": 23,
                "parquet-hadoop/src/main/java/parquet/hadoop/ParquetRecordWriter.java": 20,
                "parquet-hadoop/src/main/java/parquet/hadoop/ParquetWriter.java": 74,
                "parquet-hadoop/src/main/java/parquet/hadoop/codec/CodecConfig.java": 166,
                "parquet-hadoop/src/main/java/parquet/hadoop/codec/CompressionCodecNotSupportedException.java": 33,
                "parquet-hadoop/src/main/java/parquet/hadoop/mapred/DeprecatedParquetInputFormat.java": 8,
                "parquet-hadoop/src/main/java/parquet/hadoop/mapred/DeprecatedParquetOutputFormat.java": 114,
                "parquet-hadoop/src/main/java/parquet/hadoop/metadata/BlockMetaData.java": 3,
                "parquet-hadoop/src/main/java/parquet/hadoop/metadata/ColumnChunkMetaData.java": 62,
                "parquet-hadoop/src/main/java/parquet/hadoop/metadata/CompressionCodecName.java": 19,
                "parquet-hadoop/src/main/java/parquet/hadoop/metadata/EncodingList.java": 1,
                "parquet-hadoop/src/test/java/parquet/hadoop/DeprecatedInputFormatTest.java": 2,
                "parquet-hadoop/src/test/java/parquet/hadoop/DeprecatedOutputFormatTest.java": 106,
                "parquet-hadoop/src/test/java/parquet/hadoop/codec/CodecConfigTest.java": 74,
                "parquet-hadoop/src/test/java/parquet/hadoop/metadata/TestColumnChunkMetaData.java": 64,
                "parquet-hive/parquet-hive-binding/parquet-hive-0.12-binding/src/main/java/parquet/hive/internal/Hive012Binding.java": 149,
                "parquet-hive/parquet-hive-binding/parquet-hive-binding-factory/src/main/java/parquet/hive/HiveBindingFactory.java": 147,
                "parquet-hive/parquet-hive-binding/parquet-hive-binding-factory/src/test/java/parquet/hive/TestHiveBindingFactory.java": 121,
                "parquet-hive/parquet-hive-binding/parquet-hive-binding-interface/src/main/java/parquet/hive/HiveBinding.java": 52,
                "parquet-hive/parquet-hive-binding/parquet-hive-binding-interface/src/main/java/parquet/hive/internal/AbstractHiveBinding.java": 36,
                "parquet-hive/parquet-hive-storage-handler/src/main/java/parquet/hive/DeprecatedParquetInputFormat.java": 35,
                "parquet-hive/parquet-hive-storage-handler/src/main/java/parquet/hive/DeprecatedParquetOutputFormat.java": 35,
                "parquet-hive/parquet-hive-storage-handler/src/main/java/parquet/hive/convert/ETypeConverter.java": 165,
                "parquet-hive/parquet-hive-storage-handler/src/main/java/parquet/hive/serde/AbstractParquetMapInspector.java": 163,
                "parquet-hive/parquet-hive-storage-handler/src/main/java/parquet/hive/serde/ArrayWritableObjectInspector.java": 224,
                "parquet-hive/parquet-hive-storage-handler/src/main/java/parquet/hive/serde/DeepParquetHiveMapInspector.java": 82,
                "parquet-hive/parquet-hive-storage-handler/src/main/java/parquet/hive/serde/ParquetHiveArrayInspector.java": 185,
                "parquet-hive/parquet-hive-storage-handler/src/main/java/parquet/hive/serde/StandardParquetHiveMapInspector.java": 65,
                "parquet-hive/parquet-hive-storage-handler/src/main/java/parquet/hive/serde/primitive/ParquetByteInspector.java": 59,
                "parquet-hive/parquet-hive-storage-handler/src/main/java/parquet/hive/serde/primitive/ParquetPrimitiveInspectorFactory.java": 32,
                "parquet-hive/parquet-hive-storage-handler/src/main/java/parquet/hive/serde/primitive/ParquetShortInspector.java": 59,
                "parquet-hive/parquet-hive-storage-handler/src/main/java/parquet/hive/serde/primitive/ParquetStringInspector.java": 100,
                "parquet-hive/parquet-hive-storage-handler/src/main/java/parquet/hive/writable/BinaryWritable.java": 98,
                "parquet-hive/parquet-hive-storage-handler/src/test/java/parquet/hive/serde/TestAbstractParquetMapInspector.java": 102,
                "parquet-hive/parquet-hive-storage-handler/src/test/java/parquet/hive/serde/TestDeepParquetHiveMapInspector.java": 94,
                "parquet-hive/parquet-hive-storage-handler/src/test/java/parquet/hive/serde/TestParquetHiveArrayInspector.java": 84,
                "parquet-hive/parquet-hive-storage-handler/src/test/java/parquet/hive/serde/TestStandardParquetHiveMapInspector.java": 92,
                "parquet-hive/src/main/java/parquet/hive/DeprecatedParquetInputFormat.java": 77,
                "parquet-hive/src/main/java/parquet/hive/DeprecatedParquetOutputFormat.java": 23,
                "parquet-hive/src/main/java/parquet/hive/ManageJobConfig.java": 99,
                "parquet-hive/src/main/java/parquet/hive/convert/ArrayWritableGroupConverter.java": 0,
                "parquet-hive/src/main/java/parquet/hive/convert/DataWritableGroupConverter.java": 4,
                "parquet-hive/src/main/java/parquet/hive/convert/DataWritableRecordConverter.java": 0,
                "parquet-hive/src/main/java/parquet/hive/convert/ETypeConverter.java": 283,
                "parquet-hive/src/main/java/parquet/hive/convert/HiveGroupConverter.java": 0,
                "parquet-hive/src/main/java/parquet/hive/convert/HiveSchemaConverter.java": 11,
                "parquet-hive/src/main/java/parquet/hive/read/DataWritableReadSupport.java": 63,
                "parquet-hive/src/main/java/parquet/hive/serde/ArrayWritableObjectInspector.java": 313,
                "parquet-hive/src/main/java/parquet/hive/serde/ParquetHiveArrayInspector.java": 144,
                "parquet-hive/src/main/java/parquet/hive/serde/ParquetHiveMapInspector.java": 102,
                "parquet-hive/src/main/java/parquet/hive/serde/ParquetHiveSerDe.java": 3,
                "parquet-hive/src/main/java/parquet/hive/writable/BigDecimalWritable.java": 0,
                "parquet-hive/src/main/java/parquet/hive/writable/BinaryWritable.java": 46,
                "parquet-hive/src/main/java/parquet/hive/write/DataWritableWriteSupport.java": 0,
                "parquet-hive/src/main/java/parquet/hive/write/DataWritableWriter.java": 5,
                "parquet-hive/src/test/java/parquet/hive/TestDeprecatedParquetInputFormat.java": 138,
                "parquet-hive/src/test/java/parquet/hive/TestDeprecatedParquetOuputFormat.java": 52,
                "parquet-hive/src/test/java/parquet/hive/TestHiveSchemaConverter.java": 5,
                "parquet-hive/src/test/java/parquet/hive/TestParquetSerDe.java": 7,
                "parquet-hive/src/test/java/parquet/hive/UtilitiesTestMethods.java": 54,
                "parquet-pig/src/main/java/parquet/pig/ParquetLoader.java": 23,
                "parquet-pig/src/main/java/parquet/pig/ParquetStorer.java": 4,
                "parquet-pig/src/main/java/parquet/pig/PigSchemaConverter.java": 199,
                "parquet-pig/src/main/java/parquet/pig/TupleReadSupport.java": 4,
                "parquet-pig/src/main/java/parquet/pig/TupleWriteSupport.java": 22,
                "parquet-pig/src/test/java/parquet/pig/GenerateIntTestFile.java": 3,
                "parquet-pig/src/test/java/parquet/pig/GenerateTPCH.java": 3,
                "parquet-pig/src/test/java/parquet/pig/PerfTest2.java": 8,
                "parquet-pig/src/test/java/parquet/pig/TestParquetLoader.java": 11,
                "parquet-pig/src/test/java/parquet/pig/TestPigSchemaConverter.java": 33,
                "parquet-pig/src/test/java/parquet/pig/TestTupleRecordConsumer.java": 20,
                "parquet-pig/src/test/java/parquet/pig/TupleConsumerPerfTest.java": 5,
                "parquet-scrooge/src/test/java/parquet/scrooge/ParquetScroogeSchemeTest.java": 3,
                "parquet-thrift/src/main/java/parquet/hadoop/thrift/ParquetThriftBytesOutputFormat.java": 6,
                "parquet-thrift/src/main/java/parquet/hadoop/thrift/ThriftBytesWriteSupport.java": 11,
                "parquet-thrift/src/main/java/parquet/hadoop/thrift/ThriftToParquetFileWriter.java": 28,
                "parquet-thrift/src/main/java/parquet/hadoop/thrift/ThriftWriteSupport.java": 17,
                "parquet-thrift/src/main/java/parquet/thrift/BufferedProtocolReadToWrite.java": 531,
                "parquet-thrift/src/main/java/parquet/thrift/DecodingSchemaMismatchException.java": 12,
                "parquet-thrift/src/main/java/parquet/thrift/ParquetWriteProtocol.java": 9,
                "parquet-thrift/src/main/java/parquet/thrift/ProtocolReadToWrite.java": 2,
                "parquet-thrift/src/main/java/parquet/thrift/ReadWriteErrorHandler.java": 39,
                "parquet-thrift/src/main/java/parquet/thrift/ThriftParquetReader.java": 21,
                "parquet-thrift/src/main/java/parquet/thrift/struct/CompatibilityChecker.java": 218,
                "parquet-thrift/src/main/java/parquet/thrift/struct/CompatibilityRunner.java": 96,
                "parquet-thrift/src/main/java/parquet/thrift/struct/ThriftType.java": 6,
                "parquet-thrift/src/test/java/parquet/hadoop/thrift/TestParquetToThriftReadProjection.java": 16,
                "parquet-thrift/src/test/java/parquet/hadoop/thrift/TestThriftToParquetFileWriter.java": 4,
                "parquet-thrift/src/test/java/parquet/thrift/TestParquetReadProtocol.java": 3,
                "parquet-thrift/src/test/java/parquet/thrift/TestParquetWriteProtocol.java": 2,
                "parquet-thrift/src/test/java/parquet/thrift/TestProtocolReadToWrite.java": 203,
                "parquet-thrift/src/test/java/parquet/thrift/struct/CompatibilityCheckerTest.java": 117
            },
            "is_test": true,
            "is_fix": false
        },
        "b9e272aecbcbfb500245720eec41566fd918a18a": {
            "datetime": "2013-12-26T19:59:30-08:00",
            "summary": "fix test",
            "message": "fix test\n",
            "diff": {
                "parquet-scrooge/src/test/java/parquet/scrooge/ParquetScroogeSchemeTest.java": 1
            },
            "is_test": true,
            "is_fix": false
        },
        "36c3b66f327c823ee3a68fafb3744bc23321dea4": {
            "datetime": "2013-12-26T20:13:32-08:00",
            "summary": "format",
            "message": "format\n",
            "diff": {
                "parquet-thrift/src/main/java/parquet/thrift/ThriftMetaData.java": 9,
                "parquet-thrift/src/main/java/parquet/thrift/ThriftSchemaConverter.java": 2,
                "parquet-thrift/src/main/java/parquet/thrift/struct/ThriftType.java": 2
            },
            "is_test": false,
            "is_fix": false
        },
        "7c0d29037f59ec37c1f652df9cc4fc1bef76ea82": {
            "datetime": "2013-12-27T22:41:15+01:00",
            "summary": "Code cleanup",
            "message": "Code cleanup\n",
            "diff": {
                "parquet-protobuf/src/main/java/parquet/proto/ProtoWriteSupport.java": 13,
                "parquet-protobuf/src/test/java/parquet/proto/ProtoInputOutputFormatTest.java": 8,
                "parquet-protobuf/src/test/java/parquet/proto/TestUtils.java": 2,
                "parquet-protobuf/src/test/java/parquet/proto/utils/WriteUsingMR.java": 9
            },
            "is_test": true,
            "is_fix": false
        },
        "63b710dad7aa9e87cab013d701b100aa0178ec38": {
            "datetime": "2013-12-29T19:09:34+01:00",
            "summary": "Code cleanup - Enum comparsions",
            "message": "Code cleanup - Enum comparsions\n",
            "diff": {
                "parquet-protobuf/src/main/java/parquet/proto/ProtoSchemaConverter.java": 50,
                "parquet-protobuf/src/main/java/parquet/proto/ProtoWriteSupport.java": 42,
                "parquet-protobuf/src/main/java/parquet/proto/converters/ProtoMessageConverter.java": 22
            },
            "is_test": false,
            "is_fix": false
        },
        "8ed45d07603a354f4e05a454a841995f5d558eb1": {
            "datetime": "2013-12-29T19:14:58+01:00",
            "summary": "Unnecessary unboxing",
            "message": "Unnecessary unboxing\n",
            "diff": {
                "parquet-protobuf/src/main/java/parquet/proto/ProtoWriteSupport.java": 8
            },
            "is_test": false,
            "is_fix": false
        },
        "0261cd6a7525fa37229d6c4f8df1d6409332646d": {
            "datetime": "2014-01-02T17:19:57-08:00",
            "summary": "upgrade parquet-mr to elephant-bird 4.4",
            "message": "upgrade parquet-mr to elephant-bird 4.4\n",
            "diff": {
                "parquet-thrift/src/test/java/parquet/thrift/TestParquetReadProtocol.java": 4,
                "parquet-thrift/src/test/java/parquet/thrift/TestParquetWriteProtocol.java": 82,
                "parquet-thrift/src/test/java/parquet/thrift/TestThriftToPigCompatibility.java": 4
            },
            "is_test": true,
            "is_fix": false
        },
        "622a4000f69dcc87947e1566835fc51b3be46aaf": {
            "datetime": "2014-01-02T17:39:05-08:00",
            "summary": "handler only handle ignored field, exception during will be thrown as SkippableException",
            "message": "handler only handle ignored field, exception during will be thrown as SkippableException\n",
            "diff": {
                "parquet-thrift/src/main/java/parquet/hadoop/thrift/ParquetThriftBytesOutputFormat.java": 4,
                "parquet-thrift/src/main/java/parquet/hadoop/thrift/ThriftBytesWriteSupport.java": 6,
                "parquet-thrift/src/main/java/parquet/hadoop/thrift/ThriftToParquetFileWriter.java": 6,
                "parquet-thrift/src/main/java/parquet/thrift/BufferedProtocolReadToWrite.java": 41,
                "parquet-thrift/src/main/java/parquet/thrift/ReadWriteErrorHandler.java": 23,
                "parquet-thrift/src/test/java/parquet/thrift/TestProtocolReadToWrite.java": 70
            },
            "is_test": true,
            "is_fix": false
        },
        "7dac815773821154f76b38adc0e6ca75fcbdc4fa": {
            "datetime": "2014-01-03T10:22:45-08:00",
            "summary": "Merge pull request #266 from aniket486/upgrade_eb_4.4",
            "message": "Merge pull request #266 from aniket486/upgrade_eb_4.4\n\nupgrade parquet-mr to elephant-bird 4.4",
            "diff": {
                "parquet-thrift/src/test/java/parquet/thrift/TestParquetReadProtocol.java": 4,
                "parquet-thrift/src/test/java/parquet/thrift/TestParquetWriteProtocol.java": 82,
                "parquet-thrift/src/test/java/parquet/thrift/TestThriftToPigCompatibility.java": 4
            },
            "is_test": true,
            "is_fix": false
        },
        "79cc35df33325166d24b68be6f13e19d24370c91": {
            "datetime": "2014-01-03T10:36:46-08:00",
            "summary": "Merge pull request #267 from Parquet/handler_only_handle_ignored_fields",
            "message": "Merge pull request #267 from Parquet/handler_only_handle_ignored_fields\n\nhandler only handle ignored field, exception during will be thrown as Sk...",
            "diff": {
                "parquet-thrift/src/main/java/parquet/hadoop/thrift/ParquetThriftBytesOutputFormat.java": 4,
                "parquet-thrift/src/main/java/parquet/hadoop/thrift/ThriftBytesWriteSupport.java": 6,
                "parquet-thrift/src/main/java/parquet/hadoop/thrift/ThriftToParquetFileWriter.java": 6,
                "parquet-thrift/src/main/java/parquet/thrift/BufferedProtocolReadToWrite.java": 41,
                "parquet-thrift/src/main/java/parquet/thrift/ReadWriteErrorHandler.java": 23,
                "parquet-thrift/src/test/java/parquet/thrift/TestProtocolReadToWrite.java": 70
            },
            "is_test": true,
            "is_fix": false
        },
        "da9642074fe1eefcaababfc79cee6cb73065d2a1": {
            "datetime": "2014-01-03T17:09:35-08:00",
            "summary": "Merge branch 'master' of github.com:Parquet/parquet-mr into add_semver_checks",
            "message": "Merge branch 'master' of github.com:Parquet/parquet-mr into add_semver_checks\n",
            "diff": {
                "parquet-thrift/src/main/java/parquet/hadoop/thrift/ParquetThriftBytesOutputFormat.java": 4,
                "parquet-thrift/src/main/java/parquet/hadoop/thrift/ThriftBytesWriteSupport.java": 6,
                "parquet-thrift/src/main/java/parquet/hadoop/thrift/ThriftToParquetFileWriter.java": 6,
                "parquet-thrift/src/main/java/parquet/thrift/BufferedProtocolReadToWrite.java": 41,
                "parquet-thrift/src/main/java/parquet/thrift/ReadWriteErrorHandler.java": 23,
                "parquet-thrift/src/test/java/parquet/thrift/TestParquetReadProtocol.java": 4,
                "parquet-thrift/src/test/java/parquet/thrift/TestParquetWriteProtocol.java": 82,
                "parquet-thrift/src/test/java/parquet/thrift/TestProtocolReadToWrite.java": 70,
                "parquet-thrift/src/test/java/parquet/thrift/TestThriftToPigCompatibility.java": 4
            },
            "is_test": true,
            "is_fix": false
        },
        "4dae164fe36075b8470a1cd9d7ac365982a48e29": {
            "datetime": "2014-01-05T16:31:34+01:00",
            "summary": "unused method in TestUtils",
            "message": "unused method in TestUtils\n",
            "diff": {
                "parquet-protobuf/src/test/java/parquet/proto/ProtoRecordConverterTest.java": 2,
                "parquet-protobuf/src/test/java/parquet/proto/TestUtils.java": 6
            },
            "is_test": true,
            "is_fix": false
        },
        "81ab42663de1c0976fea942374227808443662ed": {
            "datetime": "2014-01-06T18:31:52+01:00",
            "summary": "Make package java.parquet.proto.converters (mostly) package protected",
            "message": "Make package java.parquet.proto.converters (mostly) package protected\n",
            "diff": {
                "parquet-protobuf/src/main/java/parquet/proto/ProtoRecordConverter.java": 6,
                "parquet-protobuf/src/main/java/parquet/proto/ProtoRecordMaterializer.java": 1,
                "parquet-protobuf/src/main/java/parquet/proto/converters/ParentValueContainer.java": 2,
                "parquet-protobuf/src/main/java/parquet/proto/converters/ProtoArrayConverter.java": 2,
                "parquet-protobuf/src/main/java/parquet/proto/converters/ProtoBinaryConverter.java": 2,
                "parquet-protobuf/src/main/java/parquet/proto/converters/ProtoBooleanConverter.java": 2,
                "parquet-protobuf/src/main/java/parquet/proto/converters/ProtoDoubleConverter.java": 2,
                "parquet-protobuf/src/main/java/parquet/proto/converters/ProtoEnumConverter.java": 2,
                "parquet-protobuf/src/main/java/parquet/proto/converters/ProtoFloatConverter.java": 2,
                "parquet-protobuf/src/main/java/parquet/proto/converters/ProtoIntConverter.java": 2,
                "parquet-protobuf/src/main/java/parquet/proto/converters/ProtoLongConverter.java": 2,
                "parquet-protobuf/src/main/java/parquet/proto/converters/ProtoMessageConverter.java": 2,
                "parquet-protobuf/src/main/java/parquet/proto/converters/ProtoStringConverter.java": 2,
                "parquet-protobuf/src/test/java/parquet/proto/ProtoRecordConverterTest.java": 2
            },
            "is_test": true,
            "is_fix": false
        },
        "2207cb95ba17bfabdd9e03ef035aa1349f162fd6": {
            "datetime": "2014-01-06T20:38:19+01:00",
            "summary": "switches on enums",
            "message": "switches on enums\n",
            "diff": {
                "parquet-protobuf/src/main/java/parquet/proto/ProtoSchemaConverter.java": 35,
                "parquet-protobuf/src/main/java/parquet/proto/ProtoWriteSupport.java": 65
            },
            "is_test": false,
            "is_fix": false
        },
        "09914752a40cc7f950695b66395d1fe783a97224": {
            "datetime": "2014-01-06T20:41:14+01:00",
            "summary": "Code style - small fixes",
            "message": "Code style - small fixes\n",
            "diff": {
                "parquet-protobuf/src/main/java/parquet/proto/ProtoParquetReader.java": 5,
                "parquet-protobuf/src/main/java/parquet/proto/ProtoParquetWriter.java": 10,
                "parquet-protobuf/src/main/java/parquet/proto/converters/ProtoBooleanConverter.java": 2
            },
            "is_test": false,
            "is_fix": false
        },
        "f232e7793f85d1cd4c2121c8d14df73a217e4df3": {
            "datetime": "2014-01-06T15:09:24-08:00",
            "summary": "Make ParquetInputSplit extend FileSplit",
            "message": "Make ParquetInputSplit extend FileSplit\n",
            "diff": {
                "parquet-hadoop/src/main/java/parquet/hadoop/ParquetInputSplit.java": 76,
                "parquet-hadoop/src/main/java/parquet/hadoop/mapred/DeprecatedParquetInputFormat.java": 10
            },
            "is_test": false,
            "is_fix": false
        },
        "5c6876accde093e56efb244345f1b77e3bce7144": {
            "datetime": "2014-01-06T15:27:52-08:00",
            "summary": "Revert \"Make ParquetInputSplit extend FileSplit\"",
            "message": "Revert \"Make ParquetInputSplit extend FileSplit\"\n\nThis reverts commit f232e7793f85d1cd4c2121c8d14df73a217e4df3.\n",
            "diff": {
                "parquet-hadoop/src/main/java/parquet/hadoop/ParquetInputSplit.java": 76,
                "parquet-hadoop/src/main/java/parquet/hadoop/mapred/DeprecatedParquetInputFormat.java": 10
            },
            "is_test": false,
            "is_fix": false
        },
        "af880ec55c070b9239f073b36e6b95e888b4a684": {
            "datetime": "2014-01-06T15:42:58-08:00",
            "summary": "Make ParquetInputSplit extend FileSplit",
            "message": "Make ParquetInputSplit extend FileSplit\n",
            "diff": {
                "parquet-hadoop/src/main/java/parquet/hadoop/ParquetInputSplit.java": 76,
                "parquet-hadoop/src/main/java/parquet/hadoop/mapred/DeprecatedParquetInputFormat.java": 10
            },
            "is_test": false,
            "is_fix": false
        },
        "6664165962e47903e3facb289e617d0b323a0acf": {
            "datetime": "2014-01-06T17:07:15-08:00",
            "summary": "fix MapredParquetInputFormat exception issue caused by ParquetInputSplit extending FileSplit",
            "message": "fix MapredParquetInputFormat exception issue caused by ParquetInputSplit extending FileSplit\n",
            "diff": {
                "parquet-hive/parquet-hive-storage-handler/src/main/java/parquet/hive/MapredParquetInputFormat.java": 10
            },
            "is_test": false,
            "is_fix": false
        },
        "46b1ad00a8169943d9d8b4096cdd21260a55b73a": {
            "datetime": "2014-01-07T21:45:44-08:00",
            "summary": "fix bug: when enum index being written is the last index defined in the Enum, a DecodingSchemaMismatchException is thrown. maintain enum loopup table in EnumType",
            "message": "fix bug: when enum index being written is the last index defined in the Enum, a DecodingSchemaMismatchException is thrown. maintain enum loopup table in EnumType\n",
            "diff": {
                "parquet-thrift/src/main/java/parquet/thrift/BufferedProtocolReadToWrite.java": 5,
                "parquet-thrift/src/main/java/parquet/thrift/ParquetWriteProtocol.java": 12,
                "parquet-thrift/src/main/java/parquet/thrift/ThriftRecordConverter.java": 2,
                "parquet-thrift/src/main/java/parquet/thrift/struct/ThriftType.java": 28,
                "parquet-thrift/src/test/java/parquet/thrift/TestProtocolReadToWrite.java": 6
            },
            "is_test": true,
            "is_fix": false
        },
        "40f9b24c036733e2d02afcb1b8c78c3feb28a5f9": {
            "datetime": "2014-01-07T22:06:18-08:00",
            "summary": "name fix",
            "message": "name fix\n",
            "diff": {
                "parquet-thrift/src/main/java/parquet/thrift/BufferedProtocolReadToWrite.java": 4
            },
            "is_test": false,
            "is_fix": false
        },
        "ff6219464d65dcf6376c0155b5c8d89e03f2bfd4": {
            "datetime": "2014-01-07T23:31:02-08:00",
            "summary": "Merge pull request #271 from Parquet/fix_bug_enum_last_value_exception",
            "message": "Merge pull request #271 from Parquet/fix_bug_enum_last_value_exception\n\nfix bug: last enum index throws DecodingSchemaMismatchException",
            "diff": {
                "parquet-thrift/src/main/java/parquet/thrift/BufferedProtocolReadToWrite.java": 5,
                "parquet-thrift/src/main/java/parquet/thrift/ParquetWriteProtocol.java": 12,
                "parquet-thrift/src/main/java/parquet/thrift/ThriftRecordConverter.java": 2,
                "parquet-thrift/src/main/java/parquet/thrift/struct/ThriftType.java": 28,
                "parquet-thrift/src/test/java/parquet/thrift/TestProtocolReadToWrite.java": 6
            },
            "is_test": true,
            "is_fix": false
        },
        "ac8968ec23bc59937f56394648a2797fcbf486e4": {
            "datetime": "2014-01-08T12:36:31-08:00",
            "summary": "prettify a few lines",
            "message": "prettify a few lines\n",
            "diff": {
                "parquet-hadoop/src/main/java/parquet/hadoop/ParquetInputSplit.java": 4
            },
            "is_test": false,
            "is_fix": false
        },
        "81f33a66055ee9ba23ccc6d9422f0c27304e12ad": {
            "datetime": "2014-01-11T21:20:13-08:00",
            "summary": "Merge remote branch 'upstream/master'",
            "message": "Merge remote branch 'upstream/master'\n",
            "diff": {
                "parquet-thrift/src/main/java/parquet/hadoop/thrift/ParquetThriftBytesOutputFormat.java": 4,
                "parquet-thrift/src/main/java/parquet/hadoop/thrift/ThriftBytesWriteSupport.java": 6,
                "parquet-thrift/src/main/java/parquet/hadoop/thrift/ThriftToParquetFileWriter.java": 6,
                "parquet-thrift/src/main/java/parquet/thrift/BufferedProtocolReadToWrite.java": 46,
                "parquet-thrift/src/main/java/parquet/thrift/ParquetWriteProtocol.java": 12,
                "parquet-thrift/src/main/java/parquet/thrift/ReadWriteErrorHandler.java": 23,
                "parquet-thrift/src/main/java/parquet/thrift/ThriftRecordConverter.java": 2,
                "parquet-thrift/src/main/java/parquet/thrift/struct/ThriftType.java": 28,
                "parquet-thrift/src/test/java/parquet/thrift/TestParquetReadProtocol.java": 4,
                "parquet-thrift/src/test/java/parquet/thrift/TestParquetWriteProtocol.java": 82,
                "parquet-thrift/src/test/java/parquet/thrift/TestProtocolReadToWrite.java": 76,
                "parquet-thrift/src/test/java/parquet/thrift/TestThriftToPigCompatibility.java": 4
            },
            "is_test": true,
            "is_fix": false
        },
        "21faa3d82f4f4c10713b07544a0650b896f67ef8": {
            "datetime": "2014-01-13T23:20:56-08:00",
            "summary": "Merge pull request #270 from ledbit/master",
            "message": "Merge pull request #270 from ledbit/master\n\nMake ParquetInputSplit extend FileSplit",
            "diff": {
                "parquet-hadoop/src/main/java/parquet/hadoop/ParquetInputSplit.java": 78,
                "parquet-hadoop/src/main/java/parquet/hadoop/mapred/DeprecatedParquetInputFormat.java": 10,
                "parquet-hive/parquet-hive-storage-handler/src/main/java/parquet/hive/MapredParquetInputFormat.java": 10
            },
            "is_test": false,
            "is_fix": false
        },
        "a2691a742379c023acb2e7a3d6ae7bd08f92a8be": {
            "datetime": "2014-01-16T10:43:40+01:00",
            "summary": "Exception message",
            "message": "Exception message\n",
            "diff": {
                "parquet-column/src/main/java/parquet/io/api/Converter.java": 4
            },
            "is_test": false,
            "is_fix": false
        },
        "6763f71bdb48cc3f955825ed5e2090ca10688d54": {
            "datetime": "2014-01-16T18:50:24+01:00",
            "summary": "storage of repeated fields without extra level",
            "message": "storage of repeated fields without extra level\n",
            "diff": {
                "parquet-protobuf/src/main/java/parquet/proto/ProtoSchemaConverter.java": 11,
                "parquet-protobuf/src/main/java/parquet/proto/ProtoWriteSupport.java": 137,
                "parquet-protobuf/src/main/java/parquet/proto/converters/ProtoArrayConverter.java": 44,
                "parquet-protobuf/src/main/java/parquet/proto/converters/ProtoMessageConverter.java": 34,
                "parquet-protobuf/src/test/java/parquet/proto/ProtoSchemaConverterTest.java": 10,
                "parquet-protobuf/src/test/java/parquet/proto/converters/ProtoRecordConverterTest.java": 19
            },
            "is_test": true,
            "is_fix": false
        },
        "b25de9814b5d20afe380a0fe1e59d3329102e1d0": {
            "datetime": "2014-01-17T20:44:30-08:00",
            "summary": "style: junit.framework to org.junit",
            "message": "style: junit.framework to org.junit\n",
            "diff": {
                "parquet-hive/parquet-hive-storage-handler/src/test/java/parquet/hive/TestParquetSerDe.java": 2,
                "parquet-hive/parquet-hive-storage-handler/src/test/java/parquet/hive/serde/TestAbstractParquetMapInspector.java": 2,
                "parquet-hive/parquet-hive-storage-handler/src/test/java/parquet/hive/serde/TestDeepParquetHiveMapInspector.java": 2,
                "parquet-hive/parquet-hive-storage-handler/src/test/java/parquet/hive/serde/TestParquetHiveArrayInspector.java": 2,
                "parquet-hive/parquet-hive-storage-handler/src/test/java/parquet/hive/serde/TestStandardParquetHiveMapInspector.java": 2,
                "parquet-thrift/src/test/java/parquet/hadoop/thrift/TestInputOutputFormat.java": 2,
                "parquet-thrift/src/test/java/parquet/thrift/TestThriftParquetReaderWriter.java": 2,
                "parquet-thrift/src/test/java/parquet/thrift/struct/CompatibilityCheckerTest.java": 2
            },
            "is_test": true,
            "is_fix": false
        },
        "da17462e59a01b01017b0a90a2e850e2743ce663": {
            "datetime": "2014-01-19T00:04:38+01:00",
            "summary": "Matching parquet and pbfields by index",
            "message": "Matching parquet and pbfields by index\n",
            "diff": {
                "parquet-protobuf/src/main/java/parquet/proto/ProtoWriteSupport.java": 61
            },
            "is_test": false,
            "is_fix": false
        },
        "3c0ab7a908e7e503660781c94f463c8f3f314ec3": {
            "datetime": "2014-01-19T00:29:39+01:00",
            "summary": "List cannot be empty",
            "message": "List cannot be empty\n",
            "diff": {
                "parquet-protobuf/src/main/java/parquet/proto/ProtoWriteSupport.java": 14
            },
            "is_test": false,
            "is_fix": false
        },
        "942cfe26cceb69cc420e5019f854213c654ec844": {
            "datetime": "2014-01-19T00:31:15+01:00",
            "summary": "Dictionary enum conversion",
            "message": "Dictionary enum conversion\n",
            "diff": {
                "parquet-protobuf/src/main/java/parquet/proto/converters/ProtoEnumConverter.java": 45
            },
            "is_test": false,
            "is_fix": false
        },
        "d00eb4e682599300d9b1f5a1e22594da6700cf80": {
            "datetime": "2014-01-23T14:46:31-08:00",
            "summary": "Merge branch 'master' of github.com:Parquet/parquet-mr into junit_framework_to_org",
            "message": "Merge branch 'master' of github.com:Parquet/parquet-mr into junit_framework_to_org\n",
            "diff": {
                "parquet-hadoop/src/main/java/parquet/hadoop/ParquetInputSplit.java": 78,
                "parquet-hadoop/src/main/java/parquet/hadoop/mapred/DeprecatedParquetInputFormat.java": 10,
                "parquet-hive/parquet-hive-storage-handler/src/main/java/parquet/hive/MapredParquetInputFormat.java": 10
            },
            "is_test": false,
            "is_fix": false
        },
        "e4329cde9f32e8f3cea88d82420d0ab920348d02": {
            "datetime": "2014-01-23T15:51:17-08:00",
            "summary": "move from junit3 to junit4",
            "message": "move from junit3 to junit4\n",
            "diff": {
                "parquet-hive/parquet-hive-storage-handler/src/test/java/parquet/hive/TestParquetSerDe.java": 8,
                "parquet-hive/parquet-hive-storage-handler/src/test/java/parquet/hive/serde/TestAbstractParquetMapInspector.java": 11,
                "parquet-hive/parquet-hive-storage-handler/src/test/java/parquet/hive/serde/TestDeepParquetHiveMapInspector.java": 8,
                "parquet-hive/parquet-hive-storage-handler/src/test/java/parquet/hive/serde/TestParquetHiveArrayInspector.java": 9,
                "parquet-hive/parquet-hive-storage-handler/src/test/java/parquet/hive/serde/TestStandardParquetHiveMapInspector.java": 10
            },
            "is_test": true,
            "is_fix": false
        },
        "6edfa7e6ee517536dbde935c0c6cfc68e7155b44": {
            "datetime": "2014-01-25T00:32:42+01:00",
            "summary": "ProtoWriteSupport unit tests",
            "message": "ProtoWriteSupport unit tests\n",
            "diff": {
                "parquet-protobuf/src/test/java/parquet/proto/ProtoWriteSupportTest.java": 143
            },
            "is_test": true,
            "is_fix": false
        },
        "8cc4cecd580438643c3423bf147c476c8ad606e0": {
            "datetime": "2014-01-25T18:08:48+01:00",
            "summary": "New ProtoWriteSupport",
            "message": "New ProtoWriteSupport\n",
            "diff": {
                "parquet-protobuf/src/main/java/parquet/proto/ProtoWriteSupport.java": 395,
                "parquet-protobuf/src/main/java/parquet/proto/converters/ProtoMessageConverter.java": 6,
                "parquet-protobuf/src/test/java/parquet/proto/ProtoWriteSupportTest.java": 44
            },
            "is_test": true,
            "is_fix": false
        },
        "496e3fd019ad524b165242ee6fc914d9cdcbf174": {
            "datetime": "2014-01-26T14:11:35+01:00",
            "summary": "Scalar Converters are part of Message converter",
            "message": "Scalar Converters are part of Message converter\n",
            "diff": {
                "parquet-protobuf/src/main/java/parquet/proto/ProtoMessageConverter.java": 361,
                "parquet-protobuf/src/main/java/parquet/proto/converters/ParentValueContainer.java": 26,
                "parquet-protobuf/src/main/java/parquet/proto/converters/ProtoBinaryConverter.java": 36,
                "parquet-protobuf/src/main/java/parquet/proto/converters/ProtoBooleanConverter.java": 34,
                "parquet-protobuf/src/main/java/parquet/proto/converters/ProtoDoubleConverter.java": 33,
                "parquet-protobuf/src/main/java/parquet/proto/converters/ProtoEnumConverter.java": 102,
                "parquet-protobuf/src/main/java/parquet/proto/converters/ProtoFloatConverter.java": 33,
                "parquet-protobuf/src/main/java/parquet/proto/converters/ProtoIntConverter.java": 33,
                "parquet-protobuf/src/main/java/parquet/proto/converters/ProtoLongConverter.java": 33,
                "parquet-protobuf/src/main/java/parquet/proto/converters/ProtoMessageConverter.java": 161,
                "parquet-protobuf/src/main/java/parquet/proto/converters/ProtoRecordConverter.java": 9,
                "parquet-protobuf/src/main/java/parquet/proto/converters/ProtoStringConverter.java": 37,
                "parquet-protobuf/src/test/java/parquet/proto/converters/ProtoRecordConverterTest.java": 43
            },
            "is_test": true,
            "is_fix": false
        },
        "5b1b79c7cca8df23c0bb387e19a14e4c55645998": {
            "datetime": "2014-01-26T14:14:00+01:00",
            "summary": "javadoc",
            "message": "javadoc\n",
            "diff": {
                "parquet-protobuf/src/main/java/parquet/proto/ProtoMessageConverter.java": 2,
                "parquet-protobuf/src/main/java/parquet/proto/ProtoRecordConverter.java": 4
            },
            "is_test": false,
            "is_fix": false
        },
        "02f7707e13755b6ab9e4c5a5bd8cf98152488631": {
            "datetime": "2014-01-26T14:36:57+01:00",
            "summary": "ProtoMessageConverter case",
            "message": "ProtoMessageConverter case\n",
            "diff": {
                "parquet-protobuf/src/main/java/parquet/proto/ProtoMessageConverter.java": 41
            },
            "is_test": false,
            "is_fix": false
        },
        "2d9cf95dfa0cbc2c969ff4c61f6cdae16cac87d6": {
            "datetime": "2014-01-27T18:24:37-08:00",
            "summary": "make setup calls static in tests",
            "message": "make setup calls static in tests\n",
            "diff": {
                "parquet-hive/parquet-hive-storage-handler/src/test/java/parquet/hive/serde/TestAbstractParquetMapInspector.java": 6,
                "parquet-hive/parquet-hive-storage-handler/src/test/java/parquet/hive/serde/TestDeepParquetHiveMapInspector.java": 4,
                "parquet-hive/parquet-hive-storage-handler/src/test/java/parquet/hive/serde/TestParquetHiveArrayInspector.java": 4,
                "parquet-hive/parquet-hive-storage-handler/src/test/java/parquet/hive/serde/TestStandardParquetHiveMapInspector.java": 4
            },
            "is_test": true,
            "is_fix": false
        },
        "b929d196fc3190d705096362e76cd9878fbf35cf": {
            "datetime": "2014-01-28T14:26:34-08:00",
            "summary": "Merge pull request #280 from aniket486/junit_framework_to_org",
            "message": "Merge pull request #280 from aniket486/junit_framework_to_org\n\nstyle: junit.framework to org.junit",
            "diff": {
                "parquet-hive/parquet-hive-storage-handler/src/test/java/parquet/hive/TestParquetSerDe.java": 8,
                "parquet-hive/parquet-hive-storage-handler/src/test/java/parquet/hive/serde/TestAbstractParquetMapInspector.java": 17,
                "parquet-hive/parquet-hive-storage-handler/src/test/java/parquet/hive/serde/TestDeepParquetHiveMapInspector.java": 12,
                "parquet-hive/parquet-hive-storage-handler/src/test/java/parquet/hive/serde/TestParquetHiveArrayInspector.java": 13,
                "parquet-hive/parquet-hive-storage-handler/src/test/java/parquet/hive/serde/TestStandardParquetHiveMapInspector.java": 14,
                "parquet-thrift/src/test/java/parquet/hadoop/thrift/TestInputOutputFormat.java": 2,
                "parquet-thrift/src/test/java/parquet/thrift/TestThriftParquetReaderWriter.java": 2,
                "parquet-thrift/src/test/java/parquet/thrift/struct/CompatibilityCheckerTest.java": 2
            },
            "is_test": true,
            "is_fix": false
        },
        "c8b7ba82e630f1813a8a1d29c9dd8585767d39bc": {
            "datetime": "2014-01-29T10:36:57+01:00",
            "summary": "Merge remote branch 'upstream/master' into protobuf",
            "message": "Merge remote branch 'upstream/master' into protobuf\n",
            "diff": {
                "parquet-column/src/main/java/parquet/column/Encoding.java": 31,
                "parquet-column/src/main/java/parquet/column/ParquetProperties.java": 10,
                "parquet-column/src/main/java/parquet/column/impl/ColumnReaderImpl.java": 8,
                "parquet-column/src/main/java/parquet/column/values/ValuesReader.java": 13,
                "parquet-column/src/main/java/parquet/column/values/bitpacking/BitPackingValuesReader.java": 13,
                "parquet-column/src/main/java/parquet/column/values/bitpacking/ByteBitPackingValuesReader.java": 13,
                "parquet-column/src/main/java/parquet/column/values/boundedint/BoundedIntValuesReader.java": 10,
                "parquet-column/src/main/java/parquet/column/values/boundedint/ZeroIntegerValuesReader.java": 11,
                "parquet-column/src/main/java/parquet/column/values/delta/DeltaBinaryPackingValuesReader.java": 7,
                "parquet-column/src/main/java/parquet/column/values/deltalengthbytearray/DeltaLengthByteArrayValuesReader.java": 67,
                "parquet-column/src/main/java/parquet/column/values/deltalengthbytearray/DeltaLengthByteArrayValuesWriter.java": 103,
                "parquet-column/src/main/java/parquet/column/values/deltastrings/DeltaByteArrayReader.java": 75,
                "parquet-column/src/main/java/parquet/column/values/deltastrings/DeltaByteArrayWriter.java": 89,
                "parquet-column/src/main/java/parquet/column/values/dictionary/DictionaryValuesReader.java": 3,
                "parquet-column/src/main/java/parquet/column/values/plain/BinaryPlainValuesReader.java": 3,
                "parquet-column/src/main/java/parquet/column/values/plain/BooleanPlainValuesReader.java": 9,
                "parquet-column/src/main/java/parquet/column/values/plain/FixedLenByteArrayPlainValuesReader.java": 4,
                "parquet-column/src/main/java/parquet/column/values/plain/PlainValuesReader.java": 19,
                "parquet-column/src/main/java/parquet/column/values/plain/PlainValuesWriter.java": 1,
                "parquet-column/src/main/java/parquet/column/values/rle/RunLengthBitPackingHybridValuesReader.java": 26,
                "parquet-column/src/main/java/parquet/column/values/rle/RunLengthBitPackingHybridValuesWriter.java": 5,
                "parquet-column/src/test/java/parquet/column/values/RandomStr.java": 53,
                "parquet-column/src/test/java/parquet/column/values/Utils.java": 87,
                "parquet-column/src/test/java/parquet/column/values/boundedint/TestBoundedColumns.java": 3,
                "parquet-column/src/test/java/parquet/column/values/delta/DeltaBinaryPackingValuesWriterTest.java": 15,
                "parquet-column/src/test/java/parquet/column/values/deltalengthbytearray/TestDeltaLengthByteArray.java": 71,
                "parquet-column/src/test/java/parquet/column/values/deltalengthbytearray/benchmark/BenchmarkDeltaLengthByteArray.java": 68,
                "parquet-column/src/test/java/parquet/column/values/deltastrings/TestDeltaByteArray.java": 81,
                "parquet-column/src/test/java/parquet/column/values/deltastrings/benchmark/BenchmarkDeltaByteArray.java": 98,
                "parquet-hadoop/src/main/java/parquet/hadoop/ParquetFileReader.java": 435,
                "parquet-hadoop/src/main/java/parquet/hadoop/ParquetInputSplit.java": 78,
                "parquet-hadoop/src/main/java/parquet/hadoop/mapred/DeprecatedParquetInputFormat.java": 10,
                "parquet-hadoop/src/main/java/parquet/hadoop/metadata/BlockMetaData.java": 3,
                "parquet-hadoop/src/main/java/parquet/hadoop/metadata/ColumnChunkMetaData.java": 62,
                "parquet-hadoop/src/test/java/parquet/hadoop/codec/CodecConfigTest.java": 3,
                "parquet-hadoop/src/test/java/parquet/hadoop/metadata/TestColumnChunkMetaData.java": 64,
                "parquet-hive/parquet-hive-storage-handler/src/main/java/parquet/hive/MapredParquetInputFormat.java": 10,
                "parquet-hive/parquet-hive-storage-handler/src/test/java/parquet/hive/TestParquetSerDe.java": 8,
                "parquet-hive/parquet-hive-storage-handler/src/test/java/parquet/hive/serde/TestAbstractParquetMapInspector.java": 17,
                "parquet-hive/parquet-hive-storage-handler/src/test/java/parquet/hive/serde/TestDeepParquetHiveMapInspector.java": 12,
                "parquet-hive/parquet-hive-storage-handler/src/test/java/parquet/hive/serde/TestParquetHiveArrayInspector.java": 13,
                "parquet-hive/parquet-hive-storage-handler/src/test/java/parquet/hive/serde/TestStandardParquetHiveMapInspector.java": 14,
                "parquet-pig/src/main/java/parquet/pig/ParquetLoader.java": 1,
                "parquet-pig/src/main/java/parquet/pig/TupleReadSupport.java": 4,
                "parquet-pig/src/test/java/parquet/pig/TestParquetLoader.java": 6,
                "parquet-pig/src/test/java/parquet/pig/TestPigSchemaConverter.java": 4,
                "parquet-thrift/src/main/java/parquet/hadoop/thrift/ParquetThriftBytesOutputFormat.java": 4,
                "parquet-thrift/src/main/java/parquet/hadoop/thrift/ThriftBytesWriteSupport.java": 6,
                "parquet-thrift/src/main/java/parquet/hadoop/thrift/ThriftToParquetFileWriter.java": 6,
                "parquet-thrift/src/main/java/parquet/thrift/BufferedProtocolReadToWrite.java": 46,
                "parquet-thrift/src/main/java/parquet/thrift/ParquetWriteProtocol.java": 12,
                "parquet-thrift/src/main/java/parquet/thrift/ReadWriteErrorHandler.java": 23,
                "parquet-thrift/src/main/java/parquet/thrift/ThriftRecordConverter.java": 2,
                "parquet-thrift/src/main/java/parquet/thrift/struct/ThriftType.java": 28,
                "parquet-thrift/src/test/java/parquet/hadoop/thrift/TestInputOutputFormat.java": 2,
                "parquet-thrift/src/test/java/parquet/thrift/TestParquetReadProtocol.java": 4,
                "parquet-thrift/src/test/java/parquet/thrift/TestParquetWriteProtocol.java": 82,
                "parquet-thrift/src/test/java/parquet/thrift/TestProtocolReadToWrite.java": 76,
                "parquet-thrift/src/test/java/parquet/thrift/TestThriftParquetReaderWriter.java": 2,
                "parquet-thrift/src/test/java/parquet/thrift/TestThriftToPigCompatibility.java": 4,
                "parquet-thrift/src/test/java/parquet/thrift/struct/CompatibilityCheckerTest.java": 2
            },
            "is_test": true,
            "is_fix": false
        },
        "024d5abf6a2c96f13c733d04501fcdaed66aa860": {
            "datetime": "2014-01-29T14:17:09+01:00",
            "summary": "build fix - deleted package",
            "message": "build fix - deleted package\n",
            "diff": {
                "parquet-protobuf/src/main/java/parquet/proto/ProtoRecordMaterializer.java": 1
            },
            "is_test": false,
            "is_fix": false
        },
        "8ecb0b22d80cae8f962b0de573fd276bbcac3385": {
            "datetime": "2014-01-30T09:49:17-08:00",
            "summary": "first use current thread's classloader to load a class, if current thread does not have a classloader, use the class's current classloader to load a class.",
            "message": "first use current thread's classloader to load a class, if current thread does not have a classloader, use the class's current classloader to load a class.\nThis will make sure a class not packaged in parquet but on classpath loaded properly. Otherwise, for example, if you set your own ReadSupport class to the\nConfiguration object and expect it to be loaded by ParquetInputFormat, it will fail and throw ClassNotFoundException.\n",
            "diff": {
                "parquet-hadoop/src/main/java/parquet/hadoop/util/ConfigurationUtil.java": 6
            },
            "is_test": false,
            "is_fix": false
        },
        "a1b7a315726ebf3038ef4160aede0fe8e91024f6": {
            "datetime": "2014-01-30T18:46:04-08:00",
            "summary": "use utility method from Configuration class to load class to avoid ClassNotFoundException",
            "message": "use utility method from Configuration class to load class to avoid ClassNotFoundException\n",
            "diff": {
                "parquet-hadoop/src/main/java/parquet/hadoop/util/ConfigurationUtil.java": 7
            },
            "is_test": false,
            "is_fix": false
        },
        "83bb4b89b433df79049411a7642b615821c03654": {
            "datetime": "2014-02-02T22:08:09-08:00",
            "summary": "Added ParquetWriter() that takes an instance of Hadoop's Configuration.",
            "message": "Added ParquetWriter() that takes an instance of Hadoop's Configuration.\n",
            "diff": {
                "parquet-hadoop/src/main/java/parquet/hadoop/ParquetWriter.java": 42
            },
            "is_test": false,
            "is_fix": false
        },
        "0185b491c9e0264a591611259a4233e068390f0c": {
            "datetime": "2014-02-04T16:22:49+00:00",
            "summary": "Minor changes following Julien's review",
            "message": "Minor changes following Julien's review\n",
            "diff": {
                "parquet-avro/src/main/java/parquet/avro/AvroReadSupport.java": 4
            },
            "is_test": false,
            "is_fix": false
        },
        "ab54b702f1039d827a1a0a04299368338e2554ac": {
            "datetime": "2014-02-04T16:22:49+00:00",
            "summary": "Add tests for reading Parquet files using the default",
            "message": "Add tests for reading Parquet files using the default\nAvro schema.\n",
            "diff": {
                "parquet-avro/src/main/java/parquet/avro/AvroReadSupport.java": 14,
                "parquet-avro/src/main/java/parquet/avro/AvroSchemaConverter.java": 3,
                "parquet-avro/src/test/java/parquet/avro/TestAvroSchemaConverter.java": 64,
                "parquet-avro/src/test/java/parquet/avro/TestReadWrite.java": 211
            },
            "is_test": true,
            "is_fix": false
        },
        "e29d26bebca603e00c8f437ef46befd9ef0d7a02": {
            "datetime": "2014-02-04T16:22:49+00:00",
            "summary": "Use a default Avro read schema when none specified in Parquet-Avro.",
            "message": "Use a default Avro read schema when none specified in Parquet-Avro.\n",
            "diff": {
                "parquet-avro/src/main/java/parquet/avro/AvroSchemaConverter.java": 122,
                "parquet-avro/src/main/java/parquet/avro/package-info.java": 79,
                "parquet-avro/src/test/java/parquet/avro/TestAvroSchemaConverter.java": 153
            },
            "is_test": true,
            "is_fix": false
        },
        "01bba92984f12d111042cb54332d906d3d8add4c": {
            "datetime": "2014-02-04T16:22:49+00:00",
            "summary": "Support promotion of int, long and float to wider types.",
            "message": "Support promotion of int, long and float to wider types.\n\nThis is specified in http://avro.apache.org/docs/current/spec.html#Schema+Resolution\n",
            "diff": {
                "parquet-avro/src/main/java/parquet/avro/AvroIndexedRecordConverter.java": 30
            },
            "is_test": false,
            "is_fix": false
        },
        "be43f8847748bf810142f1c9df500b085e87b21c": {
            "datetime": "2014-02-04T16:22:49+00:00",
            "summary": "Make setting requested projection and avro schema more independent, so that",
            "message": "Make setting requested projection and avro schema more independent, so that\nyou only need to set the Avro schema if it is different to the\nwriter's schema.\n",
            "diff": {
                "parquet-avro/src/main/java/parquet/avro/AvroIndexedRecordConverter.java": 2,
                "parquet-avro/src/main/java/parquet/avro/AvroParquetInputFormat.java": 36,
                "parquet-avro/src/main/java/parquet/avro/AvroParquetOutputFormat.java": 9,
                "parquet-avro/src/main/java/parquet/avro/AvroReadSupport.java": 48,
                "parquet-avro/src/main/java/parquet/avro/AvroWriteSupport.java": 11,
                "parquet-avro/src/test/java/parquet/avro/TestSpecificInputOutputFormat.java": 11,
                "parquet-avro/src/test/java/parquet/avro/TestSpecificReadWrite.java": 22
            },
            "is_test": true,
            "is_fix": false
        },
        "f2f8e42e95f4d1851f5bcc6dc82e03a159f8abd1": {
            "datetime": "2014-02-04T16:22:49+00:00",
            "summary": "Fix to read a new avro schema...",
            "message": "Fix to read a new avro schema...\n",
            "diff": {
                "parquet-avro/src/main/java/parquet/avro/AvroIndexedRecordConverter.java": 7,
                "parquet-avro/src/main/java/parquet/avro/AvroParquetInputFormat.java": 4,
                "parquet-avro/src/main/java/parquet/avro/AvroReadSupport.java": 22,
                "parquet-avro/src/test/java/parquet/avro/TestSpecificInputOutputFormat.java": 167,
                "parquet-avro/src/test/java/parquet/avro/TestSpecificReadWrite.java": 28
            },
            "is_test": true,
            "is_fix": false
        },
        "aadaae5be5d207f73b54b89e11d73ea06fa45171": {
            "datetime": "2014-02-04T16:28:18+00:00",
            "summary": "Revert change making field final that failed compatibility test.",
            "message": "Revert change making field final that failed compatibility test.\n",
            "diff": {
                "parquet-avro/src/main/java/parquet/avro/AvroReadSupport.java": 2
            },
            "is_test": false,
            "is_fix": false
        },
        "644bf006a2fb19cde2cebdf3e4f47a7eee42a118": {
            "datetime": "2014-02-04T11:36:57-08:00",
            "summary": "Merge pull request #282 from tomwhite/avro-default-read-schema",
            "message": "Merge pull request #282 from tomwhite/avro-default-read-schema\n\nAvro default read schema",
            "diff": {
                "parquet-avro/src/main/java/parquet/avro/AvroIndexedRecordConverter.java": 35,
                "parquet-avro/src/main/java/parquet/avro/AvroParquetInputFormat.java": 36,
                "parquet-avro/src/main/java/parquet/avro/AvroParquetOutputFormat.java": 9,
                "parquet-avro/src/main/java/parquet/avro/AvroReadSupport.java": 46,
                "parquet-avro/src/main/java/parquet/avro/AvroSchemaConverter.java": 121,
                "parquet-avro/src/main/java/parquet/avro/AvroWriteSupport.java": 11,
                "parquet-avro/src/main/java/parquet/avro/package-info.java": 79,
                "parquet-avro/src/test/java/parquet/avro/TestAvroSchemaConverter.java": 159,
                "parquet-avro/src/test/java/parquet/avro/TestReadWrite.java": 211,
                "parquet-avro/src/test/java/parquet/avro/TestSpecificInputOutputFormat.java": 164,
                "parquet-avro/src/test/java/parquet/avro/TestSpecificReadWrite.java": 44
            },
            "is_test": true,
            "is_fix": false
        },
        "3d7d9ad11bedb4772aca271b73bc952f2542c6bc": {
            "datetime": "2014-02-04T11:38:17-08:00",
            "summary": "Merge pull request #292 from esammer/master",
            "message": "Merge pull request #292 from esammer/master\n\nAdded ParquetWriter() that takes an instance of Hadoop's Configuration.",
            "diff": {
                "parquet-hadoop/src/main/java/parquet/hadoop/ParquetWriter.java": 42
            },
            "is_test": false,
            "is_fix": false
        },
        "137b1e292eacbccb06c9723e9b86d2259045b860": {
            "datetime": "2014-02-04T12:09:20-08:00",
            "summary": "Merge pull request #289 from allanyan/master",
            "message": "Merge pull request #289 from allanyan/master\n\nfirst use current thread's classloader to load a class, if current threa...",
            "diff": {
                "parquet-hadoop/src/main/java/parquet/hadoop/util/ConfigurationUtil.java": 3
            },
            "is_test": false,
            "is_fix": false
        },
        "68b531441eb4fc19d00d2a18ff61bef140fd25ee": {
            "datetime": "2014-02-06T14:29:15-08:00",
            "summary": "better error messages, create ParquetScroogeInputFormat class",
            "message": "better error messages, create ParquetScroogeInputFormat class\n",
            "diff": {
                "parquet-scrooge/src/main/java/parquet/scrooge/ParquetScroogeInputFormat.java": 28,
                "parquet-scrooge/src/main/java/parquet/scrooge/ScroogeStructConverter.java": 23,
                "parquet-scrooge/src/test/java/parquet/scrooge/ParquetScroogeSchemeTest.java": 5,
                "parquet-scrooge/src/test/java/parquet/scrooge/ScroogeStructConverterTest.java": 2,
                "parquet-thrift/src/main/java/parquet/hadoop/thrift/ParquetThriftInputFormat.java": 10
            },
            "is_test": true,
            "is_fix": false
        },
        "045343dd5153c879cb35e55da28232e4cd436a8a": {
            "datetime": "2014-02-07T23:43:41+01:00",
            "summary": "Merge remote-tracking branch 'upstream/master' into protobuf",
            "message": "Merge remote-tracking branch 'upstream/master' into protobuf\n",
            "diff": {
                "parquet-avro/src/main/java/parquet/avro/AvroIndexedRecordConverter.java": 35,
                "parquet-avro/src/main/java/parquet/avro/AvroParquetInputFormat.java": 36,
                "parquet-avro/src/main/java/parquet/avro/AvroParquetOutputFormat.java": 9,
                "parquet-avro/src/main/java/parquet/avro/AvroReadSupport.java": 46,
                "parquet-avro/src/main/java/parquet/avro/AvroSchemaConverter.java": 121,
                "parquet-avro/src/main/java/parquet/avro/AvroWriteSupport.java": 11,
                "parquet-avro/src/main/java/parquet/avro/package-info.java": 79,
                "parquet-avro/src/test/java/parquet/avro/TestAvroSchemaConverter.java": 159,
                "parquet-avro/src/test/java/parquet/avro/TestReadWrite.java": 211,
                "parquet-avro/src/test/java/parquet/avro/TestSpecificInputOutputFormat.java": 164,
                "parquet-avro/src/test/java/parquet/avro/TestSpecificReadWrite.java": 44,
                "parquet-hadoop/src/main/java/parquet/hadoop/ParquetWriter.java": 42,
                "parquet-hadoop/src/main/java/parquet/hadoop/util/ConfigurationUtil.java": 3
            },
            "is_test": true,
            "is_fix": false
        },
        "38241cc7e85e943d404f186fe684bf2ceb855de6": {
            "datetime": "2014-02-10T09:16:57-06:00",
            "summary": "Ports HIVE-5783 to the parquet-hive module so that patches",
            "message": "Ports HIVE-5783 to the parquet-hive module so that patches\ncan be ported between the two code bases with ease. Note\nthat the code base in Hive itself should be considered the\ngolden copy and any changes made there and then ported\nto the parquet-hive module.\n",
            "diff": {
                "parquet-hive/parquet-hive-binding/parquet-hive-binding-factory/src/main/java/parquet/hive/HiveBindingFactory.java": 7,
                "parquet-hive/parquet-hive-binding/parquet-hive-binding-factory/src/test/java/parquet/hive/TestHiveBindingFactory.java": 6,
                "parquet-hive/parquet-hive-storage-handler/src/main/java/org/apache/hadoop/hive/ql/io/IOConstants.java": 28,
                "parquet-hive/parquet-hive-storage-handler/src/main/java/org/apache/hadoop/hive/ql/io/parquet/MapredParquetInputFormat.java": 56,
                "parquet-hive/parquet-hive-storage-handler/src/main/java/org/apache/hadoop/hive/ql/io/parquet/MapredParquetOutputFormat.java": 125,
                "parquet-hive/parquet-hive-storage-handler/src/main/java/org/apache/hadoop/hive/ql/io/parquet/read/ParquetRecordReaderWrapper.java": 238,
                "parquet-hive/parquet-hive-storage-handler/src/main/java/org/apache/hadoop/hive/ql/io/parquet/serde/ParquetHiveSerDe.java": 274,
                "parquet-hive/parquet-hive-storage-handler/src/main/java/org/apache/hadoop/hive/ql/io/parquet/write/ParquetRecordWriterWrapper.java": 93,
                "parquet-hive/parquet-hive-storage-handler/src/main/java/parquet/hive/DeprecatedParquetInputFormat.java": 8,
                "parquet-hive/parquet-hive-storage-handler/src/main/java/parquet/hive/DeprecatedParquetOutputFormat.java": 3,
                "parquet-hive/parquet-hive-storage-handler/src/main/java/parquet/hive/MapredParquetInputFormat.java": 351,
                "parquet-hive/parquet-hive-storage-handler/src/main/java/parquet/hive/MapredParquetOutputFormat.java": 150,
                "parquet-hive/parquet-hive-storage-handler/src/main/java/parquet/hive/convert/ArrayWritableGroupConverter.java": 39,
                "parquet-hive/parquet-hive-storage-handler/src/main/java/parquet/hive/convert/DataWritableGroupConverter.java": 46,
                "parquet-hive/parquet-hive-storage-handler/src/main/java/parquet/hive/convert/DataWritableRecordConverter.java": 18,
                "parquet-hive/parquet-hive-storage-handler/src/main/java/parquet/hive/convert/ETypeConverter.java": 31,
                "parquet-hive/parquet-hive-storage-handler/src/main/java/parquet/hive/convert/HiveGroupConverter.java": 15,
                "parquet-hive/parquet-hive-storage-handler/src/main/java/parquet/hive/convert/HiveSchemaConverter.java": 61,
                "parquet-hive/parquet-hive-storage-handler/src/main/java/parquet/hive/read/DataWritableReadSupport.java": 57,
                "parquet-hive/parquet-hive-storage-handler/src/main/java/parquet/hive/serde/AbstractParquetMapInspector.java": 28,
                "parquet-hive/parquet-hive-storage-handler/src/main/java/parquet/hive/serde/ArrayWritableObjectInspector.java": 24,
                "parquet-hive/parquet-hive-storage-handler/src/main/java/parquet/hive/serde/DeepParquetHiveMapInspector.java": 18,
                "parquet-hive/parquet-hive-storage-handler/src/main/java/parquet/hive/serde/ParquetHiveArrayInspector.java": 18,
                "parquet-hive/parquet-hive-storage-handler/src/main/java/parquet/hive/serde/ParquetHiveSerDe.java": 278,
                "parquet-hive/parquet-hive-storage-handler/src/main/java/parquet/hive/serde/StandardParquetHiveMapInspector.java": 27,
                "parquet-hive/parquet-hive-storage-handler/src/main/java/parquet/hive/serde/primitive/ParquetByteInspector.java": 9,
                "parquet-hive/parquet-hive-storage-handler/src/main/java/parquet/hive/serde/primitive/ParquetPrimitiveInspectorFactory.java": 9,
                "parquet-hive/parquet-hive-storage-handler/src/main/java/parquet/hive/serde/primitive/ParquetShortInspector.java": 9,
                "parquet-hive/parquet-hive-storage-handler/src/main/java/parquet/hive/serde/primitive/ParquetStringInspector.java": 12,
                "parquet-hive/parquet-hive-storage-handler/src/main/java/parquet/hive/writable/BigDecimalWritable.java": 21,
                "parquet-hive/parquet-hive-storage-handler/src/main/java/parquet/hive/writable/BinaryWritable.java": 13,
                "parquet-hive/parquet-hive-storage-handler/src/main/java/parquet/hive/write/DataWritableWriteSupport.java": 24,
                "parquet-hive/parquet-hive-storage-handler/src/main/java/parquet/hive/write/DataWritableWriter.java": 31,
                "parquet-hive/parquet-hive-storage-handler/src/test/java/org/apache/hadoop/hive/ql/io/parquet/TestMapredParquetInputFormat.java": 37,
                "parquet-hive/parquet-hive-storage-handler/src/test/java/org/apache/hadoop/hive/ql/io/parquet/TestMapredParquetOutputFormat.java": 90,
                "parquet-hive/parquet-hive-storage-handler/src/test/java/parquet/hive/TestHiveSchemaConverter.java": 14,
                "parquet-hive/parquet-hive-storage-handler/src/test/java/parquet/hive/TestMapredParquetInputFormat.java": 388,
                "parquet-hive/parquet-hive-storage-handler/src/test/java/parquet/hive/TestMapredParquetOuputFormat.java": 235,
                "parquet-hive/parquet-hive-storage-handler/src/test/java/parquet/hive/TestParquetSerDe.java": 65,
                "parquet-hive/parquet-hive-storage-handler/src/test/java/parquet/hive/UtilitiesTestMethods.java": 245,
                "parquet-hive/parquet-hive-storage-handler/src/test/java/parquet/hive/serde/TestAbstractParquetMapInspector.java": 31,
                "parquet-hive/parquet-hive-storage-handler/src/test/java/parquet/hive/serde/TestDeepParquetHiveMapInspector.java": 28,
                "parquet-hive/parquet-hive-storage-handler/src/test/java/parquet/hive/serde/TestParquetHiveArrayInspector.java": 27,
                "parquet-hive/parquet-hive-storage-handler/src/test/java/parquet/hive/serde/TestStandardParquetHiveMapInspector.java": 28
            },
            "is_test": true,
            "is_fix": false
        },
        "083c51317f4cde839c2a948e6fa5c2b62221be31": {
            "datetime": "2014-02-10T11:14:31-06:00",
            "summary": "Convert ParquetHiveSerDe back to SerDe interface to support Hive 0.10",
            "message": "Convert ParquetHiveSerDe back to SerDe interface to support Hive 0.10\n",
            "diff": {
                "parquet-hive/parquet-hive-storage-handler/src/main/java/org/apache/hadoop/hive/ql/io/parquet/serde/ParquetHiveSerDe.java": 4
            },
            "is_test": false,
            "is_fix": false
        },
        "1be4d6c9ac35c133d5e257839c65aa83155a4455": {
            "datetime": "2014-02-10T22:49:46-08:00",
            "summary": "bugfix: reorder fields in thrift struct caused writting nulls. fixed it by keeping track of which fields are being written in each level, and only write nulls when current level is finished in MessageColumnIO",
            "message": "bugfix: reorder fields in thrift struct caused writting nulls. fixed it by keeping track of which fields are being written in each level, and only write nulls when current level is finished in MessageColumnIO\n",
            "diff": {
                "parquet-column/src/main/java/parquet/io/MessageColumnIO.java": 80,
                "parquet-column/src/test/java/parquet/io/TestColumnIO.java": 11,
                "parquet-thrift/src/test/java/parquet/hadoop/thrift/TestParquetToThriftReadProjection.java": 23
            },
            "is_test": true,
            "is_fix": false
        },
        "02f50f7ea0b417a8b963b8b2b081b16190ffc9ef": {
            "datetime": "2014-02-10T22:52:28-08:00",
            "summary": "rename var",
            "message": "rename var\n",
            "diff": {
                "parquet-column/src/main/java/parquet/io/MessageColumnIO.java": 6
            },
            "is_test": false,
            "is_fix": false
        },
        "94d703c7cad93228ddee626622841953eae665b1": {
            "datetime": "2014-02-11T17:37:48+00:00",
            "summary": "Fill in default values for new fields in the read schema that",
            "message": "Fill in default values for new fields in the read schema that\nwere not in the write schema.\n\nSome of the implementation was inspired by\nhttps://issues.apache.org/jira/browse/AVRO-1228.\n",
            "diff": {
                "parquet-avro/src/main/java/parquet/avro/AvroIndexedRecordConverter.java": 24,
                "parquet-avro/src/test/java/parquet/avro/TestSpecificReadWrite.java": 1
            },
            "is_test": true,
            "is_fix": false
        },
        "0d111b1defc6cc5100470dd1162b6eece86fdbd8": {
            "datetime": "2014-02-11T13:19:34-08:00",
            "summary": "remove fieldCount from marker",
            "message": "remove fieldCount from marker\n",
            "diff": {
                "parquet-column/src/main/java/parquet/io/MessageColumnIO.java": 12
            },
            "is_test": false,
            "is_fix": false
        },
        "5dccd0cdf5d1384bcc46b738c27cf4c7f42a2d6c": {
            "datetime": "2014-02-11T13:24:16-08:00",
            "summary": "format",
            "message": "format\n",
            "diff": {
                "parquet-column/src/test/java/parquet/io/TestColumnIO.java": 2,
                "parquet-thrift/src/test/java/parquet/hadoop/thrift/TestParquetToThriftReadWriteAndProjection.java": 1
            },
            "is_test": true,
            "is_fix": false
        },
        "6496bcc8e1ed9150614fdca9ad8ec46294336ed2": {
            "datetime": "2014-02-11T13:42:42-08:00",
            "summary": "Merge pull request #298 from Parquet/bugfix_reorder_thrift_fields_causing_writting_nulls",
            "message": "Merge pull request #298 from Parquet/bugfix_reorder_thrift_fields_causing_writting_nulls\n\nBugfix reorder thrift fields causing writting nulls",
            "diff": {
                "parquet-column/src/main/java/parquet/io/MessageColumnIO.java": 74,
                "parquet-column/src/test/java/parquet/io/TestColumnIO.java": 9,
                "parquet-thrift/src/test/java/parquet/hadoop/thrift/TestParquetToThriftReadProjection.java": 22
            },
            "is_test": true,
            "is_fix": false
        },
        "76bbf4a88645abc657ba6e4c2dc636712f03b944": {
            "datetime": "2014-02-12T11:00:17+01:00",
            "summary": "[CASCADING] Provide the sink implementation",
            "message": "[CASCADING] Provide the sink implementation\nin order to write some parquet files with ParquetTupleScheme\n",
            "diff": {
                "parquet-cascading/src/main/java/parquet/cascading/ParquetTupleScheme.java": 43,
                "parquet-cascading/src/main/java/parquet/cascading/TupleWriteSupport.java": 103,
                "parquet-hadoop/src/main/java/parquet/hadoop/ParquetOutputFormat.java": 5
            },
            "is_test": false,
            "is_fix": false
        },
        "cc59a4077dc880bb5de5555954906bda64369678": {
            "datetime": "2014-02-12T12:07:04+00:00",
            "summary": "Don't deep copy immutable primitive types.",
            "message": "Don't deep copy immutable primitive types.\n",
            "diff": {
                "parquet-avro/src/main/java/parquet/avro/AvroIndexedRecordConverter.java": 16
            },
            "is_test": false,
            "is_fix": false
        },
        "808de5d963b4186d69b2ae39c00ed5f5bb08b2cc": {
            "datetime": "2014-02-12T12:48:55+00:00",
            "summary": "Support field renaming for Avro read schemas, by means of",
            "message": "Support field renaming for Avro read schemas, by means of\nfield aliases.\n\nAvro 1.7.6 is required since it fixes https://issues.apache.org/jira/browse/AVRO-1433\nBut note that this is only to allow the test to run correctly.\n",
            "diff": {
                "parquet-avro/src/main/java/parquet/avro/AvroIndexedRecordConverter.java": 20,
                "parquet-avro/src/test/java/parquet/avro/TestSpecificReadWrite.java": 2
            },
            "is_test": true,
            "is_fix": false
        },
        "3151b2f76eaf0c43f1b321ab7480d5c4a3288622": {
            "datetime": "2014-02-13T15:09:43-08:00",
            "summary": "Merge pull request #299 from tomwhite/avro-fill-in-default-values",
            "message": "Merge pull request #299 from tomwhite/avro-fill-in-default-values\n\nFill in default values for new fields in the Avro read schema",
            "diff": {
                "parquet-avro/src/main/java/parquet/avro/AvroIndexedRecordConverter.java": 38,
                "parquet-avro/src/test/java/parquet/avro/TestSpecificReadWrite.java": 1
            },
            "is_test": true,
            "is_fix": false
        },
        "29fe0e0e42b24a8155084375acc1d99fa484830e": {
            "datetime": "2014-02-14T09:44:37+00:00",
            "summary": "Merge pull request #303 from tomwhite/avro-read-schema-aliases",
            "message": "Merge pull request #303 from tomwhite/avro-read-schema-aliases\n\nAvro read schema aliases",
            "diff": {
                "parquet-avro/src/main/java/parquet/avro/AvroIndexedRecordConverter.java": 20,
                "parquet-avro/src/test/java/parquet/avro/TestSpecificReadWrite.java": 2
            },
            "is_test": true,
            "is_fix": false
        },
        "c48e8c1324562937cdca552657afb4e090f119f2": {
            "datetime": "2014-02-18T13:21:03-06:00",
            "summary": "HIVE-6456 - Implement Parquet schema evolution",
            "message": "HIVE-6456 - Implement Parquet schema evolution\n",
            "diff": {
                "parquet-hive/parquet-hive-storage-handler/src/main/java/org/apache/hadoop/hive/ql/io/parquet/read/DataWritableReadSupport.java": 3
            },
            "is_test": false,
            "is_fix": false
        },
        "81028366038e22cff7a3f62e8eab6d00758f978e": {
            "datetime": "2014-02-18T13:31:18-06:00",
            "summary": "Merge the parquet-tools project into parquet-mr.",
            "message": "Merge the parquet-tools project into parquet-mr.\n",
            "diff": {
                "parquet-tools/src/main/java/parquet/tools/Main.java": 229,
                "parquet-tools/src/main/java/parquet/tools/command/ArgsOnlyCommand.java": 53,
                "parquet-tools/src/main/java/parquet/tools/command/CatCommand.java": 67,
                "parquet-tools/src/main/java/parquet/tools/command/Command.java": 27,
                "parquet-tools/src/main/java/parquet/tools/command/DumpCommand.java": 320,
                "parquet-tools/src/main/java/parquet/tools/command/HeadCommand.java": 92,
                "parquet-tools/src/main/java/parquet/tools/command/Registry.java": 57,
                "parquet-tools/src/main/java/parquet/tools/command/ShowMetaCommand.java": 67,
                "parquet-tools/src/main/java/parquet/tools/command/ShowSchemaCommand.java": 83,
                "parquet-tools/src/main/java/parquet/tools/read/SimpleReadSupport.java": 38,
                "parquet-tools/src/main/java/parquet/tools/read/SimpleRecord.java": 117,
                "parquet-tools/src/main/java/parquet/tools/read/SimpleRecordConverter.java": 165,
                "parquet-tools/src/main/java/parquet/tools/read/SimpleRecordMaterializer.java": 39,
                "parquet-tools/src/main/java/parquet/tools/util/MetadataUtils.java": 225,
                "parquet-tools/src/main/java/parquet/tools/util/PrettyPrintWriter.java": 1032
            },
            "is_test": false,
            "is_fix": false
        },
        "555837ad2df87cf19d269919e6dbb809c3b060bb": {
            "datetime": "2014-02-18T13:31:18-06:00",
            "summary": "Support field renaming for Avro read schemas, by means of",
            "message": "Support field renaming for Avro read schemas, by means of\nfield aliases.\n\nAvro 1.7.6 is required since it fixes https://issues.apache.org/jira/browse/AVRO-1433\nBut note that this is only to allow the test to run correctly.\n",
            "diff": {
                "parquet-avro/src/main/java/parquet/avro/AvroIndexedRecordConverter.java": 20,
                "parquet-avro/src/test/java/parquet/avro/TestSpecificReadWrite.java": 2
            },
            "is_test": true,
            "is_fix": false
        },
        "8cc8bdc05260d0f5f60b3435da7d0f0edef6a786": {
            "datetime": "2014-02-18T13:35:04-06:00",
            "summary": "Merge the parquet-tools project into parquet-mr.",
            "message": "Merge the parquet-tools project into parquet-mr.\n",
            "diff": {
                "parquet-tools/src/main/java/parquet/tools/Main.java": 229,
                "parquet-tools/src/main/java/parquet/tools/command/ArgsOnlyCommand.java": 53,
                "parquet-tools/src/main/java/parquet/tools/command/CatCommand.java": 67,
                "parquet-tools/src/main/java/parquet/tools/command/Command.java": 27,
                "parquet-tools/src/main/java/parquet/tools/command/DumpCommand.java": 320,
                "parquet-tools/src/main/java/parquet/tools/command/HeadCommand.java": 92,
                "parquet-tools/src/main/java/parquet/tools/command/Registry.java": 57,
                "parquet-tools/src/main/java/parquet/tools/command/ShowMetaCommand.java": 67,
                "parquet-tools/src/main/java/parquet/tools/command/ShowSchemaCommand.java": 83,
                "parquet-tools/src/main/java/parquet/tools/read/SimpleReadSupport.java": 38,
                "parquet-tools/src/main/java/parquet/tools/read/SimpleRecord.java": 117,
                "parquet-tools/src/main/java/parquet/tools/read/SimpleRecordConverter.java": 165,
                "parquet-tools/src/main/java/parquet/tools/read/SimpleRecordMaterializer.java": 39,
                "parquet-tools/src/main/java/parquet/tools/util/MetadataUtils.java": 225,
                "parquet-tools/src/main/java/parquet/tools/util/PrettyPrintWriter.java": 1032
            },
            "is_test": false,
            "is_fix": false
        },
        "712e6d796c41a44a751dcf441f0db4dae87eb693": {
            "datetime": "2014-02-18T13:54:01-06:00",
            "summary": "fix compile error in previous commit",
            "message": "fix compile error in previous commit\n",
            "diff": {
                "parquet-hive/parquet-hive-storage-handler/src/main/java/org/apache/hadoop/hive/ql/io/parquet/read/DataWritableReadSupport.java": 3
            },
            "is_test": false,
            "is_fix": false
        },
        "7b0778c490e6782a83663bd5b1ec9d8a7dd7c2ae": {
            "datetime": "2014-02-20T11:59:03-08:00",
            "summary": "Merge pull request #297 from brockn/master",
            "message": "Merge pull request #297 from brockn/master\n\nPorts HIVE-5783 to the parquet-hive module",
            "diff": {
                "parquet-hive/parquet-hive-binding/parquet-hive-binding-factory/src/main/java/parquet/hive/HiveBindingFactory.java": 7,
                "parquet-hive/parquet-hive-binding/parquet-hive-binding-factory/src/test/java/parquet/hive/TestHiveBindingFactory.java": 6,
                "parquet-hive/parquet-hive-storage-handler/src/main/java/org/apache/hadoop/hive/ql/io/IOConstants.java": 28,
                "parquet-hive/parquet-hive-storage-handler/src/main/java/org/apache/hadoop/hive/ql/io/parquet/MapredParquetInputFormat.java": 56,
                "parquet-hive/parquet-hive-storage-handler/src/main/java/org/apache/hadoop/hive/ql/io/parquet/MapredParquetOutputFormat.java": 125,
                "parquet-hive/parquet-hive-storage-handler/src/main/java/org/apache/hadoop/hive/ql/io/parquet/read/ParquetRecordReaderWrapper.java": 238,
                "parquet-hive/parquet-hive-storage-handler/src/main/java/org/apache/hadoop/hive/ql/io/parquet/serde/ParquetHiveSerDe.java": 274,
                "parquet-hive/parquet-hive-storage-handler/src/main/java/org/apache/hadoop/hive/ql/io/parquet/write/ParquetRecordWriterWrapper.java": 93,
                "parquet-hive/parquet-hive-storage-handler/src/main/java/parquet/hive/DeprecatedParquetInputFormat.java": 8,
                "parquet-hive/parquet-hive-storage-handler/src/main/java/parquet/hive/DeprecatedParquetOutputFormat.java": 3,
                "parquet-hive/parquet-hive-storage-handler/src/main/java/parquet/hive/MapredParquetInputFormat.java": 351,
                "parquet-hive/parquet-hive-storage-handler/src/main/java/parquet/hive/MapredParquetOutputFormat.java": 150,
                "parquet-hive/parquet-hive-storage-handler/src/main/java/parquet/hive/convert/ArrayWritableGroupConverter.java": 39,
                "parquet-hive/parquet-hive-storage-handler/src/main/java/parquet/hive/convert/DataWritableGroupConverter.java": 46,
                "parquet-hive/parquet-hive-storage-handler/src/main/java/parquet/hive/convert/DataWritableRecordConverter.java": 18,
                "parquet-hive/parquet-hive-storage-handler/src/main/java/parquet/hive/convert/ETypeConverter.java": 31,
                "parquet-hive/parquet-hive-storage-handler/src/main/java/parquet/hive/convert/HiveGroupConverter.java": 15,
                "parquet-hive/parquet-hive-storage-handler/src/main/java/parquet/hive/convert/HiveSchemaConverter.java": 61,
                "parquet-hive/parquet-hive-storage-handler/src/main/java/parquet/hive/read/DataWritableReadSupport.java": 55,
                "parquet-hive/parquet-hive-storage-handler/src/main/java/parquet/hive/serde/AbstractParquetMapInspector.java": 28,
                "parquet-hive/parquet-hive-storage-handler/src/main/java/parquet/hive/serde/ArrayWritableObjectInspector.java": 24,
                "parquet-hive/parquet-hive-storage-handler/src/main/java/parquet/hive/serde/DeepParquetHiveMapInspector.java": 18,
                "parquet-hive/parquet-hive-storage-handler/src/main/java/parquet/hive/serde/ParquetHiveArrayInspector.java": 18,
                "parquet-hive/parquet-hive-storage-handler/src/main/java/parquet/hive/serde/ParquetHiveSerDe.java": 278,
                "parquet-hive/parquet-hive-storage-handler/src/main/java/parquet/hive/serde/StandardParquetHiveMapInspector.java": 27,
                "parquet-hive/parquet-hive-storage-handler/src/main/java/parquet/hive/serde/primitive/ParquetByteInspector.java": 9,
                "parquet-hive/parquet-hive-storage-handler/src/main/java/parquet/hive/serde/primitive/ParquetPrimitiveInspectorFactory.java": 9,
                "parquet-hive/parquet-hive-storage-handler/src/main/java/parquet/hive/serde/primitive/ParquetShortInspector.java": 9,
                "parquet-hive/parquet-hive-storage-handler/src/main/java/parquet/hive/serde/primitive/ParquetStringInspector.java": 12,
                "parquet-hive/parquet-hive-storage-handler/src/main/java/parquet/hive/writable/BigDecimalWritable.java": 21,
                "parquet-hive/parquet-hive-storage-handler/src/main/java/parquet/hive/writable/BinaryWritable.java": 13,
                "parquet-hive/parquet-hive-storage-handler/src/main/java/parquet/hive/write/DataWritableWriteSupport.java": 24,
                "parquet-hive/parquet-hive-storage-handler/src/main/java/parquet/hive/write/DataWritableWriter.java": 31,
                "parquet-hive/parquet-hive-storage-handler/src/test/java/org/apache/hadoop/hive/ql/io/parquet/TestMapredParquetInputFormat.java": 37,
                "parquet-hive/parquet-hive-storage-handler/src/test/java/org/apache/hadoop/hive/ql/io/parquet/TestMapredParquetOutputFormat.java": 90,
                "parquet-hive/parquet-hive-storage-handler/src/test/java/parquet/hive/TestHiveSchemaConverter.java": 14,
                "parquet-hive/parquet-hive-storage-handler/src/test/java/parquet/hive/TestMapredParquetInputFormat.java": 388,
                "parquet-hive/parquet-hive-storage-handler/src/test/java/parquet/hive/TestMapredParquetOuputFormat.java": 235,
                "parquet-hive/parquet-hive-storage-handler/src/test/java/parquet/hive/TestParquetSerDe.java": 65,
                "parquet-hive/parquet-hive-storage-handler/src/test/java/parquet/hive/UtilitiesTestMethods.java": 245,
                "parquet-hive/parquet-hive-storage-handler/src/test/java/parquet/hive/serde/TestAbstractParquetMapInspector.java": 31,
                "parquet-hive/parquet-hive-storage-handler/src/test/java/parquet/hive/serde/TestDeepParquetHiveMapInspector.java": 28,
                "parquet-hive/parquet-hive-storage-handler/src/test/java/parquet/hive/serde/TestParquetHiveArrayInspector.java": 27,
                "parquet-hive/parquet-hive-storage-handler/src/test/java/parquet/hive/serde/TestStandardParquetHiveMapInspector.java": 28
            },
            "is_test": true,
            "is_fix": false
        },
        "ed08077daa9c780a8dfea360a638bcab50269bbc": {
            "datetime": "2014-02-20T15:59:39-08:00",
            "summary": "Don't fail if no default value specified for a new value in the",
            "message": "Don't fail if no default value specified for a new value in the\nread schema.\n",
            "diff": {
                "parquet-avro/src/main/java/parquet/avro/AvroIndexedRecordConverter.java": 3
            },
            "is_test": false,
            "is_fix": false
        },
        "c7e892cbd3c8fa5f03dadda55c9d529517c8c74c": {
            "datetime": "2014-02-21T10:48:51-08:00",
            "summary": "merge master",
            "message": "merge master\n",
            "diff": {
                "parquet-avro/src/main/java/parquet/avro/AvroIndexedRecordConverter.java": 93,
                "parquet-avro/src/main/java/parquet/avro/AvroParquetInputFormat.java": 36,
                "parquet-avro/src/main/java/parquet/avro/AvroParquetOutputFormat.java": 9,
                "parquet-avro/src/main/java/parquet/avro/AvroReadSupport.java": 46,
                "parquet-avro/src/main/java/parquet/avro/AvroSchemaConverter.java": 121,
                "parquet-avro/src/main/java/parquet/avro/AvroWriteSupport.java": 11,
                "parquet-avro/src/main/java/parquet/avro/package-info.java": 79,
                "parquet-avro/src/test/java/parquet/avro/TestAvroSchemaConverter.java": 159,
                "parquet-avro/src/test/java/parquet/avro/TestReadWrite.java": 211,
                "parquet-avro/src/test/java/parquet/avro/TestSpecificInputOutputFormat.java": 164,
                "parquet-avro/src/test/java/parquet/avro/TestSpecificReadWrite.java": 45,
                "parquet-column/src/main/java/parquet/io/MessageColumnIO.java": 74,
                "parquet-column/src/test/java/parquet/io/TestColumnIO.java": 9,
                "parquet-hadoop/src/main/java/parquet/hadoop/ParquetInputSplit.java": 78,
                "parquet-hadoop/src/main/java/parquet/hadoop/ParquetWriter.java": 42,
                "parquet-hadoop/src/main/java/parquet/hadoop/mapred/DeprecatedParquetInputFormat.java": 10,
                "parquet-hadoop/src/main/java/parquet/hadoop/util/ConfigurationUtil.java": 3,
                "parquet-hive/parquet-hive-binding/parquet-hive-binding-factory/src/main/java/parquet/hive/HiveBindingFactory.java": 7,
                "parquet-hive/parquet-hive-binding/parquet-hive-binding-factory/src/test/java/parquet/hive/TestHiveBindingFactory.java": 6,
                "parquet-hive/parquet-hive-storage-handler/src/main/java/org/apache/hadoop/hive/ql/io/IOConstants.java": 28,
                "parquet-hive/parquet-hive-storage-handler/src/main/java/org/apache/hadoop/hive/ql/io/parquet/MapredParquetInputFormat.java": 56,
                "parquet-hive/parquet-hive-storage-handler/src/main/java/org/apache/hadoop/hive/ql/io/parquet/MapredParquetOutputFormat.java": 125,
                "parquet-hive/parquet-hive-storage-handler/src/main/java/org/apache/hadoop/hive/ql/io/parquet/read/ParquetRecordReaderWrapper.java": 238,
                "parquet-hive/parquet-hive-storage-handler/src/main/java/org/apache/hadoop/hive/ql/io/parquet/serde/ParquetHiveSerDe.java": 274,
                "parquet-hive/parquet-hive-storage-handler/src/main/java/org/apache/hadoop/hive/ql/io/parquet/write/ParquetRecordWriterWrapper.java": 93,
                "parquet-hive/parquet-hive-storage-handler/src/main/java/parquet/hive/DeprecatedParquetInputFormat.java": 8,
                "parquet-hive/parquet-hive-storage-handler/src/main/java/parquet/hive/DeprecatedParquetOutputFormat.java": 3,
                "parquet-hive/parquet-hive-storage-handler/src/main/java/parquet/hive/MapredParquetInputFormat.java": 361,
                "parquet-hive/parquet-hive-storage-handler/src/main/java/parquet/hive/MapredParquetOutputFormat.java": 150,
                "parquet-hive/parquet-hive-storage-handler/src/main/java/parquet/hive/convert/ArrayWritableGroupConverter.java": 39,
                "parquet-hive/parquet-hive-storage-handler/src/main/java/parquet/hive/convert/DataWritableGroupConverter.java": 46,
                "parquet-hive/parquet-hive-storage-handler/src/main/java/parquet/hive/convert/DataWritableRecordConverter.java": 18,
                "parquet-hive/parquet-hive-storage-handler/src/main/java/parquet/hive/convert/ETypeConverter.java": 31,
                "parquet-hive/parquet-hive-storage-handler/src/main/java/parquet/hive/convert/HiveGroupConverter.java": 15,
                "parquet-hive/parquet-hive-storage-handler/src/main/java/parquet/hive/convert/HiveSchemaConverter.java": 61,
                "parquet-hive/parquet-hive-storage-handler/src/main/java/parquet/hive/read/DataWritableReadSupport.java": 55,
                "parquet-hive/parquet-hive-storage-handler/src/main/java/parquet/hive/serde/AbstractParquetMapInspector.java": 28,
                "parquet-hive/parquet-hive-storage-handler/src/main/java/parquet/hive/serde/ArrayWritableObjectInspector.java": 24,
                "parquet-hive/parquet-hive-storage-handler/src/main/java/parquet/hive/serde/DeepParquetHiveMapInspector.java": 18,
                "parquet-hive/parquet-hive-storage-handler/src/main/java/parquet/hive/serde/ParquetHiveArrayInspector.java": 18,
                "parquet-hive/parquet-hive-storage-handler/src/main/java/parquet/hive/serde/ParquetHiveSerDe.java": 278,
                "parquet-hive/parquet-hive-storage-handler/src/main/java/parquet/hive/serde/StandardParquetHiveMapInspector.java": 27,
                "parquet-hive/parquet-hive-storage-handler/src/main/java/parquet/hive/serde/primitive/ParquetByteInspector.java": 9,
                "parquet-hive/parquet-hive-storage-handler/src/main/java/parquet/hive/serde/primitive/ParquetPrimitiveInspectorFactory.java": 9,
                "parquet-hive/parquet-hive-storage-handler/src/main/java/parquet/hive/serde/primitive/ParquetShortInspector.java": 9,
                "parquet-hive/parquet-hive-storage-handler/src/main/java/parquet/hive/serde/primitive/ParquetStringInspector.java": 12,
                "parquet-hive/parquet-hive-storage-handler/src/main/java/parquet/hive/writable/BigDecimalWritable.java": 21,
                "parquet-hive/parquet-hive-storage-handler/src/main/java/parquet/hive/writable/BinaryWritable.java": 13,
                "parquet-hive/parquet-hive-storage-handler/src/main/java/parquet/hive/write/DataWritableWriteSupport.java": 24,
                "parquet-hive/parquet-hive-storage-handler/src/main/java/parquet/hive/write/DataWritableWriter.java": 31,
                "parquet-hive/parquet-hive-storage-handler/src/test/java/org/apache/hadoop/hive/ql/io/parquet/TestMapredParquetInputFormat.java": 37,
                "parquet-hive/parquet-hive-storage-handler/src/test/java/org/apache/hadoop/hive/ql/io/parquet/TestMapredParquetOutputFormat.java": 90,
                "parquet-hive/parquet-hive-storage-handler/src/test/java/parquet/hive/TestHiveSchemaConverter.java": 14,
                "parquet-hive/parquet-hive-storage-handler/src/test/java/parquet/hive/TestMapredParquetInputFormat.java": 388,
                "parquet-hive/parquet-hive-storage-handler/src/test/java/parquet/hive/TestMapredParquetOuputFormat.java": 235,
                "parquet-hive/parquet-hive-storage-handler/src/test/java/parquet/hive/TestParquetSerDe.java": 57,
                "parquet-hive/parquet-hive-storage-handler/src/test/java/parquet/hive/UtilitiesTestMethods.java": 245,
                "parquet-hive/parquet-hive-storage-handler/src/test/java/parquet/hive/serde/TestAbstractParquetMapInspector.java": 14,
                "parquet-hive/parquet-hive-storage-handler/src/test/java/parquet/hive/serde/TestDeepParquetHiveMapInspector.java": 16,
                "parquet-hive/parquet-hive-storage-handler/src/test/java/parquet/hive/serde/TestParquetHiveArrayInspector.java": 14,
                "parquet-hive/parquet-hive-storage-handler/src/test/java/parquet/hive/serde/TestStandardParquetHiveMapInspector.java": 14,
                "parquet-thrift/src/main/java/parquet/hadoop/thrift/ParquetThriftBytesOutputFormat.java": 4,
                "parquet-thrift/src/main/java/parquet/hadoop/thrift/ThriftBytesWriteSupport.java": 6,
                "parquet-thrift/src/main/java/parquet/hadoop/thrift/ThriftToParquetFileWriter.java": 6,
                "parquet-thrift/src/main/java/parquet/thrift/BufferedProtocolReadToWrite.java": 46,
                "parquet-thrift/src/main/java/parquet/thrift/ParquetWriteProtocol.java": 12,
                "parquet-thrift/src/main/java/parquet/thrift/ReadWriteErrorHandler.java": 23,
                "parquet-thrift/src/main/java/parquet/thrift/ThriftRecordConverter.java": 2,
                "parquet-thrift/src/main/java/parquet/thrift/struct/ThriftType.java": 28,
                "parquet-thrift/src/test/java/parquet/hadoop/thrift/TestInputOutputFormat.java": 2,
                "parquet-thrift/src/test/java/parquet/hadoop/thrift/TestParquetToThriftReadProjection.java": 22,
                "parquet-thrift/src/test/java/parquet/thrift/TestParquetReadProtocol.java": 4,
                "parquet-thrift/src/test/java/parquet/thrift/TestParquetWriteProtocol.java": 82,
                "parquet-thrift/src/test/java/parquet/thrift/TestProtocolReadToWrite.java": 76,
                "parquet-thrift/src/test/java/parquet/thrift/TestThriftParquetReaderWriter.java": 2,
                "parquet-thrift/src/test/java/parquet/thrift/TestThriftToPigCompatibility.java": 4,
                "parquet-thrift/src/test/java/parquet/thrift/struct/CompatibilityCheckerTest.java": 2
            },
            "is_test": true,
            "is_fix": false
        },
        "b07b16013482fe8af9333727814f9e6ff1d3ca7a": {
            "datetime": "2014-02-21T11:43:16-08:00",
            "summary": "Merge pull request #262 from Parquet/scrooge_schema_converter",
            "message": "Merge pull request #262 from Parquet/scrooge_schema_converter\n\nReadSupport for Scrooge including Scrooge schema converter and projection pushdown in Scrooge",
            "diff": {
                "parquet-scrooge/src/main/java/parquet/scrooge/ParquetScroogeInputFormat.java": 28,
                "parquet-scrooge/src/main/java/parquet/scrooge/ParquetScroogeScheme.java": 2,
                "parquet-scrooge/src/main/java/parquet/scrooge/ScroogeReadSupport.java": 42,
                "parquet-scrooge/src/main/java/parquet/scrooge/ScroogeStructConverter.java": 294,
                "parquet-scrooge/src/test/java/parquet/scrooge/ParquetScroogeSchemeTest.java": 50,
                "parquet-scrooge/src/test/java/parquet/scrooge/ScroogeStructConverterTest.java": 105,
                "parquet-thrift/src/main/java/parquet/hadoop/thrift/ParquetThriftInputFormat.java": 10,
                "parquet-thrift/src/main/java/parquet/hadoop/thrift/ThriftReadSupport.java": 14,
                "parquet-thrift/src/main/java/parquet/thrift/ThriftMetaData.java": 19,
                "parquet-thrift/src/main/java/parquet/thrift/ThriftSchemaConverter.java": 156,
                "parquet-thrift/src/main/java/parquet/thrift/struct/ThriftField.java": 23,
                "parquet-thrift/src/main/java/parquet/thrift/struct/ThriftType.java": 134,
                "parquet-thrift/src/test/java/parquet/thrift/TestThriftSchemaConverter.java": 25
            },
            "is_test": true,
            "is_fix": false
        },
        "70eada470f069ea27c5e2d47d1004fec56f7dcca": {
            "datetime": "2014-02-22T01:28:16+01:00",
            "summary": "NULL tuples cause NPE when writing",
            "message": "NULL tuples cause NPE when writing\n",
            "diff": {
                "parquet-cascading/src/main/java/parquet/cascading/TupleWriteSupport.java": 4
            },
            "is_test": false,
            "is_fix": false
        }
    },
    "2014-02-22T15:17:05-07:00": {
        "000659a2d80ca4584e0e39fae4164009944d3549": {
            "datetime": "2014-02-24T15:41:59+01:00",
            "summary": "Merge pull request #1 from jalkjaer/cascading_sink",
            "message": "Merge pull request #1 from jalkjaer/cascading_sink\n\nNULL tuples causes NPE when writing",
            "diff": {
                "parquet-cascading/src/main/java/parquet/cascading/TupleWriteSupport.java": 4
            },
            "is_test": false,
            "is_fix": false
        },
        "509e26883b30a2d505c64b28633be2e628cd1f56": {
            "datetime": "2014-02-24T15:46:28+01:00",
            "summary": "Better writing of a loop",
            "message": "Better writing of a loop\n",
            "diff": {
                "parquet-cascading/src/main/java/parquet/cascading/TupleWriteSupport.java": 14
            },
            "is_test": false,
            "is_fix": false
        },
        "2403257ff4c412465e4bfc4af5f0e745b5d96565": {
            "datetime": "2014-02-27T08:16:18-08:00",
            "summary": "Use toStringUsingUTF8 to fix tests.",
            "message": "Use toStringUsingUTF8 to fix tests.\n\nBinary values will not necessarily decode with UTF8, but the\nExpectationValidatingRecordConsumer can decode because its inputs are\ncontrolled for testing.\n",
            "diff": {
                "parquet-column/src/test/java/parquet/io/ExpectationValidatingRecordConsumer.java": 2
            },
            "is_test": false,
            "is_fix": false
        },
        "3fc099fd7b315a2daecf2f832071f8b91006ecf8": {
            "datetime": "2014-02-27T08:16:18-08:00",
            "summary": "Factoring out common Binary impl in dictionary writer.",
            "message": "Factoring out common Binary impl in dictionary writer.\n",
            "diff": {
                "parquet-column/src/main/java/parquet/column/values/dictionary/DictionaryValuesWriter.java": 74
            },
            "is_test": false,
            "is_fix": false
        },
        "d7c7395b44144d05ff4dcb464bdcc4e90056c3c6": {
            "datetime": "2014-02-27T08:16:18-08:00",
            "summary": "Merge Fixed dictionary with Binary dictionary.",
            "message": "Merge Fixed dictionary with Binary dictionary.\n",
            "diff": {
                "parquet-column/src/main/java/parquet/column/Encoding.java": 3,
                "parquet-column/src/main/java/parquet/column/values/dictionary/PlainValuesDictionary.java": 104
            },
            "is_test": false,
            "is_fix": false
        },
        "6b2eef9d99600f4fc48a9ba40e15fea3e5e748ad": {
            "datetime": "2014-02-27T08:16:18-08:00",
            "summary": "Delegate fixed and int96 types to convertBINARY.",
            "message": "Delegate fixed and int96 types to convertBINARY.\n",
            "diff": {
                "parquet-column/src/main/java/parquet/column/impl/ColumnReaderImpl.java": 36
            },
            "is_test": false,
            "is_fix": false
        },
        "56387e33db7df5f50b5754b756d1551af2735fe3": {
            "datetime": "2014-02-27T08:16:18-08:00",
            "summary": "Remove int96 references from RecordConsumer and Converters.",
            "message": "Remove int96 references from RecordConsumer and Converters.\n\nThis commit removes int96-specific code from the RecordConsumer and\nthe Converters. Implementations are responsible for checking the Type of\ncolumns.\n\nBecause Binary is used for int96 values, it is no longer assumed that\na Binary is printable as a UTF8 string in methods like Binary#toString.\n",
            "diff": {
                "parquet-column/src/main/java/parquet/example/data/simple/Int96Value.java": 2,
                "parquet-column/src/main/java/parquet/example/data/simple/convert/SimplePrimitiveConverter.java": 9,
                "parquet-column/src/main/java/parquet/io/MessageColumnIO.java": 10,
                "parquet-column/src/main/java/parquet/io/RecordConsumerLoggingWrapper.java": 11,
                "parquet-column/src/main/java/parquet/io/ValidatingRecordConsumer.java": 38,
                "parquet-column/src/main/java/parquet/io/api/Binary.java": 2,
                "parquet-column/src/main/java/parquet/io/api/PrimitiveConverter.java": 7,
                "parquet-column/src/main/java/parquet/io/api/RecordConsumer.java": 5,
                "parquet-column/src/main/java/parquet/schema/PrimitiveType.java": 4,
                "parquet-column/src/test/java/parquet/io/ConverterConsumer.java": 5,
                "parquet-column/src/test/java/parquet/io/ExpectationValidatingConverter.java": 5,
                "parquet-column/src/test/java/parquet/io/ExpectationValidatingRecordConsumer.java": 7
            },
            "is_test": false,
            "is_fix": false
        },
        "34b90d7b86c600804038048e905f0f3587aba687": {
            "datetime": "2014-02-27T08:16:18-08:00",
            "summary": "Removing Int96 class, using Binary instead.",
            "message": "Removing Int96 class, using Binary instead.\n\nThis removes all references to the Int96 class and uses Binary instead.\nInt96 calls are still used at the RecordConsumer and Converter level,\nspecifically used by PrimitiveType.PrimitiveTypeName.INT96.\n",
            "diff": {
                "parquet-column/src/main/java/parquet/column/ColumnReader.java": 6,
                "parquet-column/src/main/java/parquet/column/ColumnWriter.java": 9,
                "parquet-column/src/main/java/parquet/column/Dictionary.java": 5,
                "parquet-column/src/main/java/parquet/column/Encoding.java": 7,
                "parquet-column/src/main/java/parquet/column/ParquetProperties.java": 6,
                "parquet-column/src/main/java/parquet/column/impl/ColumnReaderImpl.java": 29,
                "parquet-column/src/main/java/parquet/column/impl/ColumnWriterImpl.java": 10,
                "parquet-column/src/main/java/parquet/column/values/ValuesReader.java": 8,
                "parquet-column/src/main/java/parquet/column/values/ValuesWriter.java": 8,
                "parquet-column/src/main/java/parquet/column/values/dictionary/DictionaryValuesReader.java": 10,
                "parquet-column/src/main/java/parquet/column/values/dictionary/DictionaryValuesWriter.java": 42,
                "parquet-column/src/main/java/parquet/column/values/dictionary/PlainValuesDictionary.java": 45,
                "parquet-column/src/main/java/parquet/column/values/plain/FixedLenByteArrayPlainValuesReader.java": 16,
                "parquet-column/src/main/java/parquet/column/values/plain/Int96PlainValuesReader.java": 14,
                "parquet-column/src/main/java/parquet/column/values/plain/PlainValuesWriter.java": 14,
                "parquet-column/src/main/java/parquet/example/DummyRecordConverter.java": 5,
                "parquet-column/src/main/java/parquet/example/data/Group.java": 12,
                "parquet-column/src/main/java/parquet/example/data/GroupValueSource.java": 7,
                "parquet-column/src/main/java/parquet/example/data/simple/Primitive.java": 3,
                "parquet-column/src/main/java/parquet/example/data/simple/SimpleGroup.java": 21,
                "parquet-column/src/main/java/parquet/example/data/simple/convert/Int96Value.java": 11,
                "parquet-column/src/main/java/parquet/example/data/simple/convert/SimplePrimitiveConverter.java": 7,
                "parquet-column/src/main/java/parquet/io/MessageColumnIO.java": 5,
                "parquet-column/src/main/java/parquet/io/RecordConsumerLoggingWrapper.java": 6,
                "parquet-column/src/main/java/parquet/io/ValidatingRecordConsumer.java": 4,
                "parquet-column/src/main/java/parquet/io/api/Int96.java": 26,
                "parquet-column/src/main/java/parquet/io/api/PrimitiveConverter.java": 2,
                "parquet-column/src/main/java/parquet/io/api/RecordConsumer.java": 2,
                "parquet-column/src/main/java/parquet/schema/PrimitiveType.java": 19,
                "parquet-column/src/test/java/parquet/io/ConverterConsumer.java": 3,
                "parquet-column/src/test/java/parquet/io/ExpectationValidatingConverter.java": 5,
                "parquet-column/src/test/java/parquet/io/ExpectationValidatingRecordConsumer.java": 6,
                "parquet-column/src/test/java/parquet/io/TestColumnIO.java": 12
            },
            "is_test": true,
            "is_fix": false
        },
        "77a355af4b7828daeffcdf312108ad9f1fa738d7": {
            "datetime": "2014-02-27T08:16:18-08:00",
            "summary": "Extending example and group classes for int96.",
            "message": "Extending example and group classes for int96.\n\nThis commit gets TestColumnIO#testOneOfEach passing with an int96\ncolumn.\n",
            "diff": {
                "parquet-column/src/main/java/parquet/example/DummyRecordConverter.java": 5,
                "parquet-column/src/main/java/parquet/example/data/Group.java": 12,
                "parquet-column/src/main/java/parquet/example/data/GroupValueSource.java": 3,
                "parquet-column/src/main/java/parquet/example/data/simple/Primitive.java": 5,
                "parquet-column/src/main/java/parquet/example/data/simple/SimpleGroup.java": 12,
                "parquet-column/src/main/java/parquet/example/data/simple/convert/Int96Value.java": 29,
                "parquet-column/src/main/java/parquet/example/data/simple/convert/SimplePrimitiveConverter.java": 12,
                "parquet-column/src/main/java/parquet/io/api/Int96.java": 2,
                "parquet-column/src/test/java/parquet/io/TestColumnIO.java": 6
            },
            "is_test": true,
            "is_fix": false
        },
        "7043a64617eb25608498f502feb6c76c58b15242": {
            "datetime": "2014-02-27T08:16:18-08:00",
            "summary": "Initial int96 implementation.",
            "message": "Initial int96 implementation.\n\nThis primarily adds int96 calls throughout the read and write paths.\nInt96 is mostly a place-holder class that wraps a ByteBuffer.\n\nThis adds int96 support to the PLAIN and PLAIN_DICTIONARY encodings.\n\nExisting tests are passing.\n",
            "diff": {
                "parquet-column/src/main/java/parquet/column/ColumnReader.java": 6,
                "parquet-column/src/main/java/parquet/column/ColumnWriter.java": 9,
                "parquet-column/src/main/java/parquet/column/Dictionary.java": 5,
                "parquet-column/src/main/java/parquet/column/Encoding.java": 7,
                "parquet-column/src/main/java/parquet/column/ParquetProperties.java": 7,
                "parquet-column/src/main/java/parquet/column/impl/ColumnReaderImpl.java": 41,
                "parquet-column/src/main/java/parquet/column/impl/ColumnWriterImpl.java": 10,
                "parquet-column/src/main/java/parquet/column/values/ValuesReader.java": 8,
                "parquet-column/src/main/java/parquet/column/values/ValuesWriter.java": 8,
                "parquet-column/src/main/java/parquet/column/values/dictionary/DictionaryValuesReader.java": 10,
                "parquet-column/src/main/java/parquet/column/values/dictionary/DictionaryValuesWriter.java": 79,
                "parquet-column/src/main/java/parquet/column/values/dictionary/PlainValuesDictionary.java": 48,
                "parquet-column/src/main/java/parquet/column/values/plain/FixedLenByteArrayPlainValuesReader.java": 11,
                "parquet-column/src/main/java/parquet/column/values/plain/Int96PlainValuesReader.java": 14,
                "parquet-column/src/main/java/parquet/column/values/plain/PlainValuesWriter.java": 14,
                "parquet-column/src/main/java/parquet/io/MessageColumnIO.java": 11,
                "parquet-column/src/main/java/parquet/io/RecordConsumerLoggingWrapper.java": 10,
                "parquet-column/src/main/java/parquet/io/ValidatingRecordConsumer.java": 9,
                "parquet-column/src/main/java/parquet/io/api/Binary.java": 2,
                "parquet-column/src/main/java/parquet/io/api/Int96.java": 24,
                "parquet-column/src/main/java/parquet/io/api/PrimitiveConverter.java": 7,
                "parquet-column/src/main/java/parquet/io/api/RecordConsumer.java": 5,
                "parquet-column/src/main/java/parquet/schema/PrimitiveType.java": 19,
                "parquet-column/src/test/java/parquet/io/ConverterConsumer.java": 6,
                "parquet-column/src/test/java/parquet/io/ExpectationValidatingConverter.java": 6,
                "parquet-column/src/test/java/parquet/io/ExpectationValidatingRecordConsumer.java": 6,
                "parquet-column/src/test/java/parquet/io/TestColumnIO.java": 6
            },
            "is_test": true,
            "is_fix": false
        },
        "af2380fbcf5d440315d0a5335975197586ebf929": {
            "datetime": "2014-02-27T08:16:19-08:00",
            "summary": "Add NanoTime to example.",
            "message": "Add NanoTime to example.\n\nThis adds NanoTime to the example objects, stored as an int96, for\ntesting.\n",
            "diff": {
                "parquet-column/src/main/java/parquet/example/data/Group.java": 12,
                "parquet-column/src/main/java/parquet/example/data/simple/NanoTime.java": 57,
                "parquet-column/src/main/java/parquet/example/data/simple/SimpleGroup.java": 9,
                "parquet-column/src/test/java/parquet/io/TestColumnIO.java": 4
            },
            "is_test": true,
            "is_fix": false
        },
        "a5d2de14fda5215cece2b25ab2dd1e73396ec25e": {
            "datetime": "2014-02-27T08:26:06-08:00",
            "summary": "Add avro constructors with Configuration for #295.",
            "message": "Add avro constructors with Configuration for #295.\n\nTo avoid doubling the number of constructors in ParquetWriter, this\ncreates more defaults that subclasses can use. The new AvroParquetWriter\nconstructors call the most specific constructor directly and use the\ndefault constants from ParquetWriter to match the default behavior of\nits constructors.\n\nAlso fixed a few doc mistakes.\n",
            "diff": {
                "parquet-avro/src/main/java/parquet/avro/AvroParquetWriter.java": 36,
                "parquet-hadoop/src/main/java/parquet/hadoop/ParquetWriter.java": 15
            },
            "is_test": false,
            "is_fix": false
        },
        "603c0dc927c2b1aa46dba6675b24a375cfb3fc1c": {
            "datetime": "2014-02-27T08:28:56-08:00",
            "summary": "Fix avro schema conv for arrays of optional type for #312.",
            "message": "Fix avro schema conv for arrays of optional type for #312.\n",
            "diff": {
                "parquet-avro/src/main/java/parquet/avro/AvroSchemaConverter.java": 6,
                "parquet-avro/src/test/java/parquet/avro/TestAvroSchemaConverter.java": 35
            },
            "is_test": true,
            "is_fix": false
        },
        "5e74bbed3698e94a2b7d3e3353880bdf5f5d3205": {
            "datetime": "2014-02-27T08:34:28-08:00",
            "summary": "Add Configuration constructor in thrift writer for #295.",
            "message": "Add Configuration constructor in thrift writer for #295.\n",
            "diff": {
                "parquet-thrift/src/main/java/parquet/thrift/ThriftParquetWriter.java": 7
            },
            "is_test": false,
            "is_fix": false
        },
        "8cc3e29cc28896cfd47c90abec97f1aa866832c1": {
            "datetime": "2014-02-27T21:57:08+00:00",
            "summary": "Merge pull request #313 from rdblue/295-add-conf",
            "message": "Merge pull request #313 from rdblue/295-add-conf\n\nAdd hadoop Configuration to Avro and Thrift writers (#295).",
            "diff": {
                "parquet-avro/src/main/java/parquet/avro/AvroParquetWriter.java": 36,
                "parquet-hadoop/src/main/java/parquet/hadoop/ParquetWriter.java": 15,
                "parquet-thrift/src/main/java/parquet/thrift/ThriftParquetWriter.java": 7
            },
            "is_test": false,
            "is_fix": false
        },
        "132f75d8d4a43772d7ae99a809345542a8c2fb83": {
            "datetime": "2014-02-27T22:11:37+00:00",
            "summary": "Merge pull request #293 from rdblue/int96-support",
            "message": "Merge pull request #293 from rdblue/int96-support\n\nInt96 support",
            "diff": {
                "parquet-column/src/main/java/parquet/column/Encoding.java": 5,
                "parquet-column/src/main/java/parquet/column/ParquetProperties.java": 7,
                "parquet-column/src/main/java/parquet/column/impl/ColumnReaderImpl.java": 22,
                "parquet-column/src/main/java/parquet/column/values/dictionary/DictionaryValuesWriter.java": 79,
                "parquet-column/src/main/java/parquet/column/values/dictionary/PlainValuesDictionary.java": 55,
                "parquet-column/src/main/java/parquet/column/values/plain/FixedLenByteArrayPlainValuesReader.java": 5,
                "parquet-column/src/main/java/parquet/example/DummyRecordConverter.java": 0,
                "parquet-column/src/main/java/parquet/example/data/Group.java": 12,
                "parquet-column/src/main/java/parquet/example/data/GroupValueSource.java": 6,
                "parquet-column/src/main/java/parquet/example/data/simple/Int96Value.java": 28,
                "parquet-column/src/main/java/parquet/example/data/simple/NanoTime.java": 57,
                "parquet-column/src/main/java/parquet/example/data/simple/Primitive.java": 4,
                "parquet-column/src/main/java/parquet/example/data/simple/SimpleGroup.java": 26,
                "parquet-column/src/main/java/parquet/example/data/simple/convert/SimplePrimitiveConverter.java": 4,
                "parquet-column/src/main/java/parquet/io/RecordConsumerLoggingWrapper.java": 3,
                "parquet-column/src/main/java/parquet/io/ValidatingRecordConsumer.java": 29,
                "parquet-column/src/main/java/parquet/io/api/Binary.java": 4,
                "parquet-column/src/main/java/parquet/schema/PrimitiveType.java": 18,
                "parquet-column/src/test/java/parquet/io/ExpectationValidatingRecordConsumer.java": 1,
                "parquet-column/src/test/java/parquet/io/TestColumnIO.java": 6
            },
            "is_test": true,
            "is_fix": false
        },
        "d35657890c351e2945711e712f9a784cf8a9fbd6": {
            "datetime": "2014-02-28T13:25:16-08:00",
            "summary": "Merge pull request #264 from lukasnalezenec/protobuf",
            "message": "Merge pull request #264 from lukasnalezenec/protobuf\n\nNative Protocol Buffer support",
            "diff": {
                "parquet-column/src/main/java/parquet/io/api/Converter.java": 4,
                "parquet-protobuf/src/main/java/parquet/proto/ProtoMessageConverter.java": 346,
                "parquet-protobuf/src/main/java/parquet/proto/ProtoParquetInputFormat.java": 35,
                "parquet-protobuf/src/main/java/parquet/proto/ProtoParquetOutputFormat.java": 54,
                "parquet-protobuf/src/main/java/parquet/proto/ProtoParquetReader.java": 39,
                "parquet-protobuf/src/main/java/parquet/proto/ProtoParquetWriter.java": 78,
                "parquet-protobuf/src/main/java/parquet/proto/ProtoReadSupport.java": 77,
                "parquet-protobuf/src/main/java/parquet/proto/ProtoRecordConverter.java": 81,
                "parquet-protobuf/src/main/java/parquet/proto/ProtoRecordMaterializer.java": 41,
                "parquet-protobuf/src/main/java/parquet/proto/ProtoSchemaConverter.java": 116,
                "parquet-protobuf/src/main/java/parquet/proto/ProtoWriteSupport.java": 336,
                "parquet-protobuf/src/test/java/parquet/proto/ProtoInputOutputFormatTest.java": 103,
                "parquet-protobuf/src/test/java/parquet/proto/ProtoRecordConverterTest.java": 222,
                "parquet-protobuf/src/test/java/parquet/proto/ProtoSchemaConverterTest.java": 95,
                "parquet-protobuf/src/test/java/parquet/proto/ProtoWriteSupportTest.java": 165,
                "parquet-protobuf/src/test/java/parquet/proto/TestUtils.java": 170,
                "parquet-protobuf/src/test/java/parquet/proto/utils/ReadUsingMR.java": 84,
                "parquet-protobuf/src/test/java/parquet/proto/utils/WriteUsingMR.java": 110
            },
            "is_test": true,
            "is_fix": false
        },
        "6063921a37a77d9cd29eab64be3f91146ac52a15": {
            "datetime": "2014-02-28T13:33:47-08:00",
            "summary": "Merge pull request #285 from mickaellcr/cascading_sink",
            "message": "Merge pull request #285 from mickaellcr/cascading_sink\n\n[CASCADING] Provide the sink implementation for ParquetTupleScheme",
            "diff": {
                "parquet-cascading/src/main/java/parquet/cascading/ParquetTupleScheme.java": 43,
                "parquet-cascading/src/main/java/parquet/cascading/TupleWriteSupport.java": 103,
                "parquet-hadoop/src/main/java/parquet/hadoop/ParquetOutputFormat.java": 5
            },
            "is_test": false,
            "is_fix": false
        },
        "2d5563b5296f60a053ea2fb84fee33db5c67fc76": {
            "datetime": "2014-02-28T13:54:21-08:00",
            "summary": "Merge pull request #311 from tomwhite/avro-null-default-values-bug",
            "message": "Merge pull request #311 from tomwhite/avro-null-default-values-bug\n\nAvro null default values bug",
            "diff": {
                "parquet-avro/src/main/java/parquet/avro/AvroIndexedRecordConverter.java": 3
            },
            "is_test": false,
            "is_fix": false
        },
        "b722e7bd77ead0676c253bd9bdbd30cd263864f1": {
            "datetime": "2014-02-28T13:57:26-08:00",
            "summary": "Merge pull request #314 from rdblue/312-fix-avro-array-of-optional",
            "message": "Merge pull request #314 from rdblue/312-fix-avro-array-of-optional\n\nFix avro schema conv for arrays of optional type for #312.",
            "diff": {
                "parquet-avro/src/main/java/parquet/avro/AvroSchemaConverter.java": 6,
                "parquet-avro/src/test/java/parquet/avro/TestAvroSchemaConverter.java": 35
            },
            "is_test": true,
            "is_fix": false
        },
        "3cfea0a6b817a43cb9ac4fbcfb3fdb9d66b1ab30": {
            "datetime": "2014-03-05T17:09:13-08:00",
            "summary": "Merge pull request #310 from wesleypeck/merge_parquet_tools",
            "message": "Merge pull request #310 from wesleypeck/merge_parquet_tools\n\nMerge parquet tools",
            "diff": {
                "parquet-tools/src/main/java/parquet/tools/Main.java": 229,
                "parquet-tools/src/main/java/parquet/tools/command/ArgsOnlyCommand.java": 53,
                "parquet-tools/src/main/java/parquet/tools/command/CatCommand.java": 67,
                "parquet-tools/src/main/java/parquet/tools/command/Command.java": 27,
                "parquet-tools/src/main/java/parquet/tools/command/DumpCommand.java": 320,
                "parquet-tools/src/main/java/parquet/tools/command/HeadCommand.java": 92,
                "parquet-tools/src/main/java/parquet/tools/command/Registry.java": 57,
                "parquet-tools/src/main/java/parquet/tools/command/ShowMetaCommand.java": 67,
                "parquet-tools/src/main/java/parquet/tools/command/ShowSchemaCommand.java": 83,
                "parquet-tools/src/main/java/parquet/tools/read/SimpleReadSupport.java": 38,
                "parquet-tools/src/main/java/parquet/tools/read/SimpleRecord.java": 117,
                "parquet-tools/src/main/java/parquet/tools/read/SimpleRecordConverter.java": 165,
                "parquet-tools/src/main/java/parquet/tools/read/SimpleRecordMaterializer.java": 39,
                "parquet-tools/src/main/java/parquet/tools/util/MetadataUtils.java": 225,
                "parquet-tools/src/main/java/parquet/tools/util/PrettyPrintWriter.java": 1032
            },
            "is_test": false,
            "is_fix": false
        },
        "9899e5ba66d3c9d0a8611b9dc914ed79ca7d70f0": {
            "datetime": "2014-03-20T10:41:40-07:00",
            "summary": "fix filesystem resolution",
            "message": "fix filesystem resolution\n",
            "diff": {
                "parquet-hadoop/src/main/java/parquet/hadoop/ParquetReader.java": 2
            },
            "is_test": false,
            "is_fix": false
        },
        "0b5116a6d694b99e7b460ac32fd02810162f49f9": {
            "datetime": "2014-03-20T11:22:50-07:00",
            "summary": "Merge pull request #329 from Parquet/fix_file_system_resolution",
            "message": "Merge pull request #329 from Parquet/fix_file_system_resolution\n\nfix filesystem resolution",
            "diff": {
                "parquet-hadoop/src/main/java/parquet/hadoop/ParquetReader.java": 2
            },
            "is_test": false,
            "is_fix": false
        },
        "1920abc2b5c2c4007e44b2c452870e24f7a0e17a": {
            "datetime": "2014-03-23T19:43:48-07:00",
            "summary": "compress schemas in input splits",
            "message": "compress schemas in input splits\n",
            "diff": {
                "parquet-hadoop/src/main/java/parquet/hadoop/ParquetInputSplit.java": 65,
                "parquet-hadoop/src/test/java/parquet/hadoop/TestParquetInputSplit.java": 45
            },
            "is_test": true,
            "is_fix": false
        },
        "4246d18a5fd8d87b29740a56ec3616f14320f07c": {
            "datetime": "2014-03-23T22:39:11-07:00",
            "summary": "close gzip stream in finally",
            "message": "close gzip stream in finally\n",
            "diff": {
                "parquet-hadoop/src/main/java/parquet/hadoop/ParquetInputSplit.java": 15
            },
            "is_test": false,
            "is_fix": false
        },
        "9fdafc0e255e086d849b0738117d1e01f47208fd": {
            "datetime": "2014-03-24T11:35:45-07:00",
            "summary": "Merge pull request #333 from Parquet/compress_schemas_in_split",
            "message": "Merge pull request #333 from Parquet/compress_schemas_in_split\n\nCompress schemas in split",
            "diff": {
                "parquet-hadoop/src/main/java/parquet/hadoop/ParquetInputSplit.java": 72,
                "parquet-hadoop/src/test/java/parquet/hadoop/TestParquetInputSplit.java": 45
            },
            "is_test": true,
            "is_fix": false
        },
        "737a5d5d8447ef410819f71c8ed112c3af694a3c": {
            "datetime": "2014-03-24T19:23:53-07:00",
            "summary": "issue #290, hive map conversion to parquet schema",
            "message": "issue #290, hive map conversion to parquet schema\n",
            "diff": {
                "parquet-column/src/main/java/parquet/schema/GroupType.java": 1,
                "parquet-hive/parquet-hive-storage-handler/src/main/java/org/apache/hadoop/hive/ql/io/parquet/convert/HiveSchemaConverter.java": 4
            },
            "is_test": false,
            "is_fix": false
        },
        "3d4311fd2d4ab7a2ae3ee326a974bbdc6c62b538": {
            "datetime": "2014-03-25T11:27:08-07:00",
            "summary": "remove originalType check for typeEquals of GroupType and add tests for HiveSchemaConverter",
            "message": "remove originalType check for typeEquals of GroupType and add tests for HiveSchemaConverter\n",
            "diff": {
                "parquet-column/src/main/java/parquet/schema/GroupType.java": 1,
                "parquet-hive/parquet-hive-storage-handler/src/main/java/org/apache/hadoop/hive/ql/io/parquet/convert/HiveSchemaConverter.java": 4,
                "parquet-hive/parquet-hive-storage-handler/src/test/java/org/apache/hadoop/hive/ql/io/parquet/TestHiveSchemaConverter.java": 24
            },
            "is_test": true,
            "is_fix": false
        },
        "05dea98103d8115a50302be4bda7c957c0dd9d9e": {
            "datetime": "2014-03-26T17:25:50-07:00",
            "summary": " issue #324, move ParquetStringInspector to org.apache.hadoop.hive.serde2.objectinspector.primitive package",
            "message": " issue #324, move ParquetStringInspector to org.apache.hadoop.hive.serde2.objectinspector.primitive package\n",
            "diff": {
                "parquet-hive/parquet-hive-storage-handler/src/main/java/org/apache/hadoop/hive/ql/io/parquet/serde/ArrayWritableObjectInspector.java": 9,
                "parquet-hive/parquet-hive-storage-handler/src/main/java/org/apache/hadoop/hive/ql/io/parquet/serde/primitive/ParquetPrimitiveInspectorFactory.java": 1,
                "parquet-hive/parquet-hive-storage-handler/src/main/java/org/apache/hadoop/hive/ql/io/parquet/serde/primitive/ParquetStringInspector.java": 11
            },
            "is_test": false,
            "is_fix": false
        },
        "621cf4e92be3dd3f2dd1a92a8dd12f244a7d7be3": {
            "datetime": "2014-03-27T16:42:15-07:00",
            "summary": "Added statistics to Parquet pages and rowGroups",
            "message": "Added statistics to Parquet pages and rowGroups\n",
            "diff": {
                "parquet-column/src/main/java/parquet/column/ColumnWriter.java": 6,
                "parquet-column/src/main/java/parquet/column/UnknownColumnTypeException.java": 40,
                "parquet-column/src/main/java/parquet/column/impl/ColumnWriteStoreImpl.java": 5,
                "parquet-column/src/main/java/parquet/column/impl/ColumnWriterImpl.java": 58,
                "parquet-column/src/main/java/parquet/column/page/Page.java": 15,
                "parquet-column/src/main/java/parquet/column/page/PageWriter.java": 4,
                "parquet-column/src/main/java/parquet/column/statistics/BinaryStatistics.java": 95,
                "parquet-column/src/main/java/parquet/column/statistics/BooleanStatistics.java": 93,
                "parquet-column/src/main/java/parquet/column/statistics/DoubleStatistics.java": 93,
                "parquet-column/src/main/java/parquet/column/statistics/FloatStatistics.java": 94,
                "parquet-column/src/main/java/parquet/column/statistics/IntStatistics.java": 93,
                "parquet-column/src/main/java/parquet/column/statistics/LongStatistics.java": 92,
                "parquet-column/src/main/java/parquet/column/statistics/Statistics.java": 77,
                "parquet-column/src/main/java/parquet/column/statistics/StatisticsClassException.java": 31,
                "parquet-column/src/main/java/parquet/column/statistics/StatsHelper.java": 30,
                "parquet-column/src/test/java/parquet/column/mem/TestMemPageStore.java": 10,
                "parquet-column/src/test/java/parquet/column/page/mem/MemPageWriter.java": 8,
                "parquet-column/src/test/java/parquet/column/statistics/TestStatistics.java": 447,
                "parquet-column/src/test/java/parquet/io/TestColumnIO.java": 127,
                "parquet-common/src/main/java/parquet/bytes/BytesUtils.java": 50,
                "parquet-hadoop/src/main/java/parquet/format/converter/ParquetMetadataConverter.java": 36,
                "parquet-hadoop/src/main/java/parquet/hadoop/ColumnChunkPageReadStore.java": 1,
                "parquet-hadoop/src/main/java/parquet/hadoop/ColumnChunkPageWriteStore.java": 16,
                "parquet-hadoop/src/main/java/parquet/hadoop/ParquetFileReader.java": 1,
                "parquet-hadoop/src/main/java/parquet/hadoop/ParquetFileWriter.java": 23,
                "parquet-hadoop/src/main/java/parquet/hadoop/ParquetInputSplit.java": 10,
                "parquet-hadoop/src/main/java/parquet/hadoop/metadata/ColumnChunkMetaData.java": 48,
                "parquet-hadoop/src/main/java/parquet/hadoop/metadata/ColumnChunkProperties.java": 12,
                "parquet-hadoop/src/test/java/parquet/hadoop/TestInputFormat.java": 10,
                "parquet-hadoop/src/test/java/parquet/hadoop/TestParquetFileWriter.java": 131,
                "parquet-hadoop/src/test/java/parquet/hadoop/metadata/TestColumnChunkMetaData.java": 7
            },
            "is_test": true,
            "is_fix": false
        },
        "860e123b8b8df55eaa81c0e4192373bdd7fd2497": {
            "datetime": "2014-03-29T11:52:40-07:00",
            "summary": "remove originalType check for typeEquals of GroupType and add tests for HiveSchemaConverter",
            "message": "remove originalType check for typeEquals of GroupType and add tests for HiveSchemaConverter\n",
            "diff": {
                "parquet-column/src/main/java/parquet/schema/GroupType.java": 1,
                "parquet-hive/parquet-hive-storage-handler/src/main/java/org/apache/hadoop/hive/ql/io/parquet/convert/HiveSchemaConverter.java": 4,
                "parquet-hive/parquet-hive-storage-handler/src/test/java/org/apache/hadoop/hive/ql/io/parquet/TestHiveSchemaConverter.java": 24
            },
            "is_test": true,
            "is_fix": false
        },
        "5ba0ff1ebf8a46a9589cc7476559da1266525cec": {
            "datetime": "2014-03-29T11:57:25-07:00",
            "summary": "Merge branch 'master' of github.com:tongjiechen/parquet-mr",
            "message": "Merge branch 'master' of github.com:tongjiechen/parquet-mr\n\nremove unnecessary tab and spaces\n",
            "diff": {
                "parquet-hive/parquet-hive-storage-handler/src/test/java/org/apache/hadoop/hive/ql/io/parquet/TestHiveSchemaConverter.java": 2
            },
            "is_test": true,
            "is_fix": false
        },
        "7b5e2ecf2cbc54ed9e53445ba52e2fc6efd3745e": {
            "datetime": "2014-04-01T13:07:21-07:00",
            "summary": "Addresses some initial comments. Javadocs, removed StatsHelper",
            "message": "Addresses some initial comments. Javadocs, removed StatsHelper\n",
            "diff": {
                "parquet-column/src/main/java/parquet/column/UnknownColumnTypeException.java": 2,
                "parquet-column/src/main/java/parquet/column/impl/ColumnWriterImpl.java": 4,
                "parquet-column/src/main/java/parquet/column/statistics/Statistics.java": 112,
                "parquet-column/src/main/java/parquet/column/statistics/StatsHelper.java": 30,
                "parquet-hadoop/src/main/java/parquet/format/converter/ParquetMetadataConverter.java": 3,
                "parquet-hadoop/src/main/java/parquet/hadoop/ColumnChunkPageWriteStore.java": 3,
                "parquet-hadoop/src/main/java/parquet/hadoop/ParquetFileWriter.java": 3
            },
            "is_test": false,
            "is_fix": false
        },
        "670c94065a21d639f5b5dc41690fb9352ffbe06f": {
            "datetime": "2014-04-01T13:47:49-07:00",
            "summary": "Merge branch 'master' of github.com:egonina/parquet-mr into stats",
            "message": "Merge branch 'master' of github.com:egonina/parquet-mr into stats\n\nConflicts:\n\tparquet-hadoop/src/main/java/parquet/hadoop/ParquetInputSplit.java\n",
            "diff": {
                "parquet-hadoop/src/main/java/parquet/hadoop/ParquetInputSplit.java": 66,
                "parquet-hadoop/src/main/java/parquet/hadoop/ParquetReader.java": 2,
                "parquet-hadoop/src/test/java/parquet/hadoop/TestParquetInputSplit.java": 45
            },
            "is_test": true,
            "is_fix": false
        },
        "594c47ea97bde54cccdd60cae2389509bfd85d2a": {
            "datetime": "2014-04-01T13:56:17-07:00",
            "summary": "Added licence to new files",
            "message": "Added licence to new files\n",
            "diff": {
                "parquet-column/src/main/java/parquet/column/UnknownColumnTypeException.java": 2,
                "parquet-column/src/main/java/parquet/column/statistics/BinaryStatistics.java": 15,
                "parquet-column/src/main/java/parquet/column/statistics/BooleanStatistics.java": 15,
                "parquet-column/src/main/java/parquet/column/statistics/DoubleStatistics.java": 15,
                "parquet-column/src/main/java/parquet/column/statistics/FloatStatistics.java": 15,
                "parquet-column/src/main/java/parquet/column/statistics/IntStatistics.java": 15,
                "parquet-column/src/main/java/parquet/column/statistics/LongStatistics.java": 15,
                "parquet-column/src/main/java/parquet/column/statistics/Statistics.java": 15,
                "parquet-column/src/main/java/parquet/column/statistics/StatisticsClassException.java": 2,
                "parquet-column/src/test/java/parquet/column/statistics/TestStatistics.java": 15
            },
            "is_test": true,
            "is_fix": false
        },
        "125529bbb0a8e49d6b78d60472121eb20d53a9f8": {
            "datetime": "2014-04-01T15:47:30-07:00",
            "summary": " issue #324, move ParquetStringInspector to org.apache.hadoop.hive.serde2.objectinspector.primitive package",
            "message": " issue #324, move ParquetStringInspector to org.apache.hadoop.hive.serde2.objectinspector.primitive package\n",
            "diff": {
                "parquet-hive/parquet-hive-storage-handler/src/main/java/org/apache/hadoop/hive/ql/io/parquet/serde/ArrayWritableObjectInspector.java": 7,
                "parquet-hive/parquet-hive-storage-handler/src/main/java/org/apache/hadoop/hive/ql/io/parquet/serde/primitive/ParquetPrimitiveInspectorFactory.java": 1,
                "parquet-hive/parquet-hive-storage-handler/src/main/java/org/apache/hadoop/hive/ql/io/parquet/serde/primitive/ParquetStringInspector.java": 11
            },
            "is_test": false,
            "is_fix": false
        },
        "9f43945682e73992bb3958ec8d478873b20b5b0e": {
            "datetime": "2014-04-01T17:16:09-07:00",
            "summary": "Refactored the *Statistics classes to reuse more code. Added Binary compareTo methods",
            "message": "Refactored the *Statistics classes to reuse more code. Added Binary compareTo methods\n",
            "diff": {
                "parquet-column/src/main/java/parquet/column/statistics/BinaryStatistics.java": 53,
                "parquet-column/src/main/java/parquet/column/statistics/BooleanStatistics.java": 51,
                "parquet-column/src/main/java/parquet/column/statistics/DoubleStatistics.java": 51,
                "parquet-column/src/main/java/parquet/column/statistics/FloatStatistics.java": 52,
                "parquet-column/src/main/java/parquet/column/statistics/IntStatistics.java": 51,
                "parquet-column/src/main/java/parquet/column/statistics/LongStatistics.java": 52,
                "parquet-column/src/main/java/parquet/column/statistics/Statistics.java": 29,
                "parquet-column/src/main/java/parquet/io/api/Binary.java": 63
            },
            "is_test": false,
            "is_fix": false
        },
        "7345536789597b798332bc49d0e2e8b3836ae7c0": {
            "datetime": "2014-04-01T17:30:31-07:00",
            "summary": "Merge branch 'issue324' of github.com:tongjiechen/parquet-mr into issue324",
            "message": "Merge branch 'issue324' of github.com:tongjiechen/parquet-mr into issue324\n\nConflicts:\n\tparquet-hive/parquet-hive-storage-handler/src/main/java/org/apache/hadoop/hive/serde2/objectinspector/primitive/ParquetStringInspector.java\n",
            "diff": {
                "parquet-hive/parquet-hive-storage-handler/src/main/java/org/apache/hadoop/hive/ql/io/parquet/serde/ArrayWritableObjectInspector.java": 9
            },
            "is_test": false,
            "is_fix": false
        },
        "07c54722a2ebf6edb45a1765c8fc6a5d7bc02795": {
            "datetime": "2014-04-01T17:59:42-07:00",
            "summary": "Merge branch 'issue324' of github.com:tongjiechen/parquet-mr into issue324",
            "message": "Merge branch 'issue324' of github.com:tongjiechen/parquet-mr into issue324\n\nremove additional tab\n",
            "diff": {
                "parquet-hive/parquet-hive-storage-handler/src/main/java/org/apache/hadoop/hive/ql/io/parquet/serde/ArrayWritableObjectInspector.java": 9
            },
            "is_test": false,
            "is_fix": false
        },
        "82ec5842372645535e1602df8c51ec05d683d5bd": {
            "datetime": "2014-04-01T18:00:41-07:00",
            "summary": "issue #324 remove additional tab",
            "message": "issue #324 remove additional tab\n",
            "diff": {
                "parquet-hive/parquet-hive-storage-handler/src/main/java/org/apache/hadoop/hive/ql/io/parquet/serde/ArrayWritableObjectInspector.java": 2
            },
            "is_test": false,
            "is_fix": false
        },
        "156b186bac66598c1eb6f81c2507fe4f116575d8": {
            "datetime": "2014-04-01T18:28:56-07:00",
            "summary": "remove duplicate code",
            "message": "remove duplicate code\n",
            "diff": {
                "parquet-hive/parquet-hive-storage-handler/src/main/java/org/apache/hadoop/hive/ql/io/parquet/serde/ArrayWritableObjectInspector.java": 7
            },
            "is_test": false,
            "is_fix": false
        },
        "c54cad5e4a54dbbae417bc1561c623b1267f2079": {
            "datetime": "2014-04-01T18:51:00-07:00",
            "summary": "compress kv pairs in ParquetInputSplits",
            "message": "compress kv pairs in ParquetInputSplits\n",
            "diff": {
                "parquet-hadoop/src/main/java/parquet/hadoop/ParquetInputSplit.java": 8
            },
            "is_test": false,
            "is_fix": false
        },
        "5207422b349f30ec26958be86dc7390b46d63990": {
            "datetime": "2014-04-01T19:53:05-07:00",
            "summary": "Merge pull request #342 from Parquet/compress_kv_pairs_in_split",
            "message": "Merge pull request #342 from Parquet/compress_kv_pairs_in_split\n\ncompress kv pairs in ParquetInputSplits",
            "diff": {
                "parquet-hadoop/src/main/java/parquet/hadoop/ParquetInputSplit.java": 8
            },
            "is_test": false,
            "is_fix": false
        },
        "253eb6a182b1abe746aa792eae9ddf9389d99b61": {
            "datetime": "2014-04-02T11:04:45-07:00",
            "summary": "select * from parquet hive table containing map columns runs into exception. Issue #341.",
            "message": "select * from parquet hive table containing map columns runs into exception. Issue #341.\n",
            "diff": {
                "parquet-hive/parquet-hive-storage-handler/src/main/java/org/apache/hadoop/hive/ql/io/parquet/serde/AbstractParquetMapInspector.java": 38
            },
            "is_test": false,
            "is_fix": false
        },
        "f9a867689a18e33cb95fbd21b10fcd5b648739be": {
            "datetime": "2014-04-02T22:10:46-07:00",
            "summary": "stop using strings and b64 for compressed input splits",
            "message": "stop using strings and b64 for compressed input splits\n",
            "diff": {
                "parquet-hadoop/src/main/java/parquet/hadoop/ParquetInputSplit.java": 47,
                "parquet-hadoop/src/test/java/parquet/hadoop/TestParquetInputSplit.java": 4
            },
            "is_test": true,
            "is_fix": false
        },
        "ce2301e2c663a2944d9ca1ea6349d55074bf70f9": {
            "datetime": "2014-04-03T09:20:16-07:00",
            "summary": "Merge pull request #346 from Parquet/compress_kv_pairs_in_split",
            "message": "Merge pull request #346 from Parquet/compress_kv_pairs_in_split\n\nstop using strings and b64 for compressed input splits",
            "diff": {
                "parquet-hadoop/src/main/java/parquet/hadoop/ParquetInputSplit.java": 47,
                "parquet-hadoop/src/test/java/parquet/hadoop/TestParquetInputSplit.java": 4
            },
            "is_test": true,
            "is_fix": false
        },
        "5b8af1f8097e7729c41cd86562b6706cefe2c56d": {
            "datetime": "2014-04-03T11:14:47-07:00",
            "summary": "set reading length in ThriftBytesWriteSupport to avoid potential OOM caused by corrupted data",
            "message": "set reading length in ThriftBytesWriteSupport to avoid potential OOM caused by corrupted data\n",
            "diff": {
                "parquet-thrift/src/main/java/parquet/hadoop/thrift/ThriftBytesWriteSupport.java": 14
            },
            "is_test": false,
            "is_fix": false
        },
        "f5edd0a74598f951310e9014ae552f89c60a5853": {
            "datetime": "2014-04-03T13:39:34-07:00",
            "summary": "Merge pull request #347 from Parquet/check_read_length_avoid_oom",
            "message": "Merge pull request #347 from Parquet/check_read_length_avoid_oom\n\nset reading length in ThriftBytesWriteSupport to avoid potential OOM caused by trying to allocate big byte arrays caused by corrupted thrift data.",
            "diff": {
                "parquet-thrift/src/main/java/parquet/hadoop/thrift/ThriftBytesWriteSupport.java": 14
            },
            "is_test": false,
            "is_fix": false
        },
        "3f5de7612fdcfa5a8d6e0c81477cf297d6006316": {
            "datetime": "2014-04-04T14:42:14-07:00",
            "summary": "Merge pull request #344 from szehon/master",
            "message": "Merge pull request #344 from szehon/master\n\nselect * from parquet hive table containing map columns runs into exception. Issue #341.",
            "diff": {
                "parquet-hive/parquet-hive-storage-handler/src/main/java/org/apache/hadoop/hive/ql/io/parquet/serde/AbstractParquetMapInspector.java": 38
            },
            "is_test": false,
            "is_fix": false
        },
        "30810ff61f5bd033b0bf90bbccd574c331b62d2f": {
            "datetime": "2014-04-04T16:26:37-07:00",
            "summary": "fix header bug",
            "message": "fix header bug\n",
            "diff": {
                "parquet-hadoop/src/main/java/parquet/hadoop/ParquetFileReader.java": 21
            },
            "is_test": false,
            "is_fix": false
        },
        "05327c1cacd598106b8d8228927a5a8884faaec9": {
            "datetime": "2014-04-04T16:45:02-07:00",
            "summary": "Added hashCode() method for Statistics class",
            "message": "Added hashCode() method for Statistics class\n",
            "diff": {
                "parquet-column/src/main/java/parquet/column/statistics/Statistics.java": 8
            },
            "is_test": false,
            "is_fix": false
        },
        "16d38e2d32f1d09bd10a8455bdcf11905f8cdd72": {
            "datetime": "2014-04-07T12:29:25-07:00",
            "summary": "Fix bug #350, fixed length argument out of order.",
            "message": "Fix bug #350, fixed length argument out of order.\n",
            "diff": {
                "parquet-column/src/main/java/parquet/column/ParquetProperties.java": 2
            },
            "is_test": false,
            "is_fix": false
        },
        "93359c0f2cac705cc7b2fbf3c057d74142025b37": {
            "datetime": "2014-04-08T12:41:22-07:00",
            "summary": "Added length check for comparing two byte arrays",
            "message": "Added length check for comparing two byte arrays\n",
            "diff": {
                "parquet-column/src/main/java/parquet/io/api/Binary.java": 2
            },
            "is_test": false,
            "is_fix": false
        },
        "f98de7588149bba0d731f38232b4a8fdde14b94a": {
            "datetime": "2014-04-08T14:31:06-07:00",
            "summary": "adding comments",
            "message": "adding comments\n",
            "diff": {
                "parquet-hadoop/src/main/java/parquet/hadoop/ParquetFileReader.java": 10
            },
            "is_test": false,
            "is_fix": false
        },
        "41df19051825d724626e91425c8e690c04a39998": {
            "datetime": "2014-04-08T15:10:17-07:00",
            "summary": "Merge pull request #349 from Parquet/null_header",
            "message": "Merge pull request #349 from Parquet/null_header\n\nfix header bug #334",
            "diff": {
                "parquet-hadoop/src/main/java/parquet/hadoop/ParquetFileReader.java": 27
            },
            "is_test": false,
            "is_fix": false
        },
        "b8149e92dd283d98132319d506248c3204718302": {
            "datetime": "2014-04-08T18:36:26-07:00",
            "summary": "ParquetThriftStorer",
            "message": "ParquetThriftStorer\n",
            "diff": {
                "parquet-thrift/src/main/java/parquet/thrift/pig/ParquetThriftStorer.java": 77,
                "parquet-thrift/src/main/java/parquet/thrift/pig/TupleToThriftWriteSupport.java": 75,
                "parquet-thrift/src/test/java/parquet/thrift/pig/TestParquetThriftStorer.java": 65
            },
            "is_test": true,
            "is_fix": false
        },
        "a13ae411677847137c93aec573abe6b0601079ff": {
            "datetime": "2014-04-08T18:57:39-07:00",
            "summary": "cleanup",
            "message": "cleanup\n",
            "diff": {
                "parquet-thrift/src/main/java/parquet/thrift/pig/ParquetThriftStorer.java": 2,
                "parquet-thrift/src/main/java/parquet/thrift/pig/TupleToThriftWriteSupport.java": 17
            },
            "is_test": false,
            "is_fix": false
        },
        "0943978a7e37f960db6ee280096cac8a2e7ee38b": {
            "datetime": "2014-04-09T13:54:53-07:00",
            "summary": "headers",
            "message": "headers\n",
            "diff": {
                "parquet-thrift/src/main/java/parquet/thrift/pig/ParquetThriftStorer.java": 15,
                "parquet-thrift/src/test/java/parquet/thrift/pig/TestParquetThriftStorer.java": 15
            },
            "is_test": true,
            "is_fix": false
        },
        "67c1e11364455dfa8b48dcc013398657d080376e": {
            "datetime": "2014-04-09T18:35:55-07:00",
            "summary": "use own test fixtures",
            "message": "use own test fixtures\n",
            "diff": {
                "parquet-thrift/src/test/java/parquet/thrift/pig/TestParquetThriftStorer.java": 11
            },
            "is_test": true,
            "is_fix": false
        },
        "6417baede9f9e9b4cb711d7120ee31499a19b5ea": {
            "datetime": "2014-04-10T17:35:23-07:00",
            "summary": "1. upgrade scrooge dep to 3.12.1  2. fix bug when an enum field is optional, scroogeSchemaConverter would fail",
            "message": "1. upgrade scrooge dep to 3.12.1  2. fix bug when an enum field is optional, scroogeSchemaConverter would fail\n",
            "diff": {
                "parquet-scrooge/src/main/java/parquet/scrooge/ScroogeStructConverter.java": 10,
                "parquet-scrooge/src/test/java/parquet/scrooge/ScroogeStructConverterTest.java": 1
            },
            "is_test": true,
            "is_fix": false
        },
        "ddca03c2754bd67b3aa9f37a5d404814ed79b4bd": {
            "datetime": "2014-04-14T16:01:18-07:00",
            "summary": "cleanup log messages in tests",
            "message": "cleanup log messages in tests\n",
            "diff": {
                "parquet-encoding/src/test/java/parquet/column/values/bitpacking/TestBitPacking.java": 8,
                "parquet-encoding/src/test/java/parquet/column/values/bitpacking/TestByteBitPacking.java": 38,
                "parquet-encoding/src/test/java/parquet/column/values/bitpacking/TestLemireBitPacking.java": 12
            },
            "is_test": true,
            "is_fix": false
        },
        "de0bfe3a7b9cddf4e949e6ebfd97d9c16bd143fc": {
            "datetime": "2014-04-14T16:34:41-07:00",
            "summary": "cleanup log messages in tests",
            "message": "cleanup log messages in tests\n",
            "diff": {
                "parquet-encoding/src/test/java/parquet/column/values/bitpacking/TestLemireBitPacking.java": 14
            },
            "is_test": true,
            "is_fix": false
        },
        "9ef1be6697ed432e5de5d5d7aa2f5810e134350a": {
            "datetime": "2014-04-14T18:29:27-07:00",
            "summary": "cleanup log messages in tests",
            "message": "cleanup log messages in tests\n",
            "diff": {
                "parquet-column/src/test/java/parquet/column/values/bitpacking/TestBitPackingColumn.java": 10
            },
            "is_test": true,
            "is_fix": false
        },
        "f5c3151d057708a7377430b6c51621071656d10e": {
            "datetime": "2014-04-15T12:17:27+01:00",
            "summary": "Expose values in SimpleRecord",
            "message": "Expose values in SimpleRecord\n\nThis allows for quick'n dirty integration with clojure/pigpen in local mode, without the hassle of reimplementing file reading.",
            "diff": {
                "parquet-tools/src/main/java/parquet/tools/read/SimpleRecord.java": 4
            },
            "is_test": false,
            "is_fix": false
        },
        "f8877f1648b607a288af159c810b32049a49e086": {
            "datetime": "2014-04-15T13:56:18-07:00",
            "summary": "cleanup log messages for default codec",
            "message": "cleanup log messages for default codec\n",
            "diff": {
                "parquet-hadoop/src/main/java/parquet/hadoop/metadata/CompressionCodecName.java": 3
            },
            "is_test": false,
            "is_fix": false
        },
        "110fe216e493ebe52eea32275a7fc0896552ab3c": {
            "datetime": "2014-04-15T14:40:55-07:00",
            "summary": "fix test runtime dep missing from pig",
            "message": "fix test runtime dep missing from pig\n",
            "diff": {
                "parquet-hadoop/src/test/java/parquet/hadoop/codec/CodecConfigTest.java": 4
            },
            "is_test": true,
            "is_fix": false
        },
        "d093f497007e140c9ee0350b88d5b93b00ab9382": {
            "datetime": "2014-04-15T15:41:40-07:00",
            "summary": "reverse codec changes",
            "message": "reverse codec changes\n",
            "diff": {
                "parquet-hadoop/src/main/java/parquet/hadoop/metadata/CompressionCodecName.java": 3,
                "parquet-hadoop/src/test/java/parquet/hadoop/codec/CodecConfigTest.java": 4
            },
            "is_test": true,
            "is_fix": false
        },
        "3fad81609562f2819639f4fdb02d6d6481a7165b": {
            "datetime": "2014-04-15T19:00:26-04:00",
            "summary": "Fix output bug during parquet-dump command",
            "message": "Fix output bug during parquet-dump command\n\nIt was outputting the current definition level as both the repetition &\ndefinition level for the current value.\n",
            "diff": {
                "parquet-tools/src/main/java/parquet/tools/command/DumpCommand.java": 2
            },
            "is_test": false,
            "is_fix": false
        },
        "79a4ac84c969d1dbe14644d6d01f705883a36b6d": {
            "datetime": "2014-04-16T09:37:01-07:00",
            "summary": "Merge pull request #352 from Parquet/ParquetThriftStorer",
            "message": "Merge pull request #352 from Parquet/ParquetThriftStorer\n\nParquet thrift storer",
            "diff": {
                "parquet-column/src/test/java/parquet/column/values/bitpacking/TestBitPackingColumn.java": 10,
                "parquet-encoding/src/test/java/parquet/column/values/bitpacking/TestBitPacking.java": 8,
                "parquet-encoding/src/test/java/parquet/column/values/bitpacking/TestByteBitPacking.java": 38,
                "parquet-encoding/src/test/java/parquet/column/values/bitpacking/TestLemireBitPacking.java": 26,
                "parquet-thrift/src/main/java/parquet/thrift/pig/ParquetThriftStorer.java": 90,
                "parquet-thrift/src/main/java/parquet/thrift/pig/TupleToThriftWriteSupport.java": 74,
                "parquet-thrift/src/test/java/parquet/thrift/pig/TestParquetThriftStorer.java": 79
            },
            "is_test": true,
            "is_fix": false
        },
        "5d06526d49451135bd5c3befc06a64624431de02": {
            "datetime": "2014-04-16T12:53:13-07:00",
            "summary": "generate splits by min max size, and align to HDFS block when possible",
            "message": "generate splits by min max size, and align to HDFS block when possible\n",
            "diff": {
                "parquet-hadoop/src/main/java/parquet/hadoop/ParquetInputFormat.java": 222,
                "parquet-hadoop/src/test/java/parquet/hadoop/TestInputFormat.java": 160
            },
            "is_test": true,
            "is_fix": false
        },
        "796b7dd3d6fa9ec70e36d9502c0f79bbd94550fb": {
            "datetime": "2014-04-17T10:40:05-07:00",
            "summary": "do not call schema converter to generate projected schema when the projectionFilterStrubg or projectionSchemaStr is specified",
            "message": "do not call schema converter to generate projected schema when the projectionFilterStrubg or projectionSchemaStr is specified\n",
            "diff": {
                "parquet-thrift/src/main/java/parquet/hadoop/thrift/ThriftReadSupport.java": 9
            },
            "is_test": false,
            "is_fix": false
        },
        "3321b67329a895171d47e321279901d0dc346aad": {
            "datetime": "2014-04-17T11:12:21-07:00",
            "summary": "fix enum to be upper case",
            "message": "fix enum to be upper case\n",
            "diff": {
                "parquet-scrooge/src/main/java/parquet/scrooge/ScroogeStructConverter.java": 2
            },
            "is_test": false,
            "is_fix": false
        },
        "f4a0900ba9fecfa81b2fb15eb1b562b0beff6371": {
            "datetime": "2014-04-17T11:21:46-07:00",
            "summary": "remove unused code",
            "message": "remove unused code\n",
            "diff": {
                "parquet-thrift/src/main/java/parquet/hadoop/thrift/ThriftReadSupport.java": 1
            },
            "is_test": false,
            "is_fix": false
        },
        "b55eea04135d41a67b8c5d321f993ccf35a17c99": {
            "datetime": "2014-04-17T15:28:58-07:00",
            "summary": "make ParquetFileWriter throw IOException in invalid state case",
            "message": "make ParquetFileWriter throw IOException in invalid state case\n",
            "diff": {
                "parquet-hadoop/src/main/java/parquet/hadoop/ParquetFileWriter.java": 18
            },
            "is_test": false,
            "is_fix": false
        },
        "eeae127a20759116200070ac154748ad3709d2ab": {
            "datetime": "2014-04-17T16:02:06-07:00",
            "summary": "Merge pull request #367 from Parquet/ioexception",
            "message": "Merge pull request #367 from Parquet/ioexception\n\nmake ParquetFileWriter throw IOException in invalid state case",
            "diff": {
                "parquet-hadoop/src/main/java/parquet/hadoop/ParquetFileWriter.java": 18
            },
            "is_test": false,
            "is_fix": false
        },
        "6b7bc5411deb24a50025577b4384f8626cd273e5": {
            "datetime": "2014-04-17T16:22:11-07:00",
            "summary": "Merge pull request #366 from Parquet/avoid_convert_thrift_scrooge_class_when_projection_is_not_specified",
            "message": "Merge pull request #366 from Parquet/avoid_convert_thrift_scrooge_class_when_projection_is_not_specified\n\ndo not call schema converter to generate projected schema when projection is not set",
            "diff": {
                "parquet-thrift/src/main/java/parquet/hadoop/thrift/ThriftReadSupport.java": 10
            },
            "is_test": false,
            "is_fix": false
        },
        "0a96b2c66c1367a88d750357c6d6527b2efbbb08": {
            "datetime": "2014-04-17T17:25:37-07:00",
            "summary": "local variable of hdfsBlock",
            "message": "local variable of hdfsBlock\n",
            "diff": {
                "parquet-hadoop/src/main/java/parquet/hadoop/ParquetInputFormat.java": 3
            },
            "is_test": false,
            "is_fix": false
        },
        "dd8c32a41670e831a09558bf3f2697f54fb5fcfa": {
            "datetime": "2014-04-17T17:26:10-07:00",
            "summary": "fix missing space",
            "message": "fix missing space\n",
            "diff": {
                "parquet-hadoop/src/main/java/parquet/hadoop/ParquetInputFormat.java": 2
            },
            "is_test": false,
            "is_fix": false
        },
        "23958b8fde926368176dd8ade908938e17f713c0": {
            "datetime": "2014-04-17T17:38:07-07:00",
            "summary": "check maxSplit size must be greater or equal to minSplitSize",
            "message": "check maxSplit size must be greater or equal to minSplitSize\n",
            "diff": {
                "parquet-hadoop/src/main/java/parquet/hadoop/ParquetInputFormat.java": 8
            },
            "is_test": false,
            "is_fix": false
        },
        "83493c59396479659d3d260d53498faf2d7518ac": {
            "datetime": "2014-04-17T18:00:07-07:00",
            "summary": "maxSplitSize should always be positive",
            "message": "maxSplitSize should always be positive\n",
            "diff": {
                "parquet-hadoop/src/main/java/parquet/hadoop/ParquetInputFormat.java": 4,
                "parquet-hadoop/src/test/java/parquet/hadoop/TestInputFormat.java": 24
            },
            "is_test": true,
            "is_fix": false
        },
        "2056bfab8080ff013905268fbccbde835b9ae63e": {
            "datetime": "2014-04-17T18:06:27-07:00",
            "summary": "separate out getParquetInputSplit method in the SplitInfo class, reduce LOC in the generateSplit method",
            "message": "separate out getParquetInputSplit method in the SplitInfo class, reduce LOC in the generateSplit method\n",
            "diff": {
                "parquet-hadoop/src/main/java/parquet/hadoop/ParquetInputFormat.java": 52
            },
            "is_test": false,
            "is_fix": false
        },
        "fca4cc9fcb3dbfd622e11861e0b7a8f2a3ac26d1": {
            "datetime": "2014-04-17T18:08:07-07:00",
            "summary": "move parseMessageType out of the loop",
            "message": "move parseMessageType out of the loop\n",
            "diff": {
                "parquet-hadoop/src/main/java/parquet/hadoop/ParquetInputFormat.java": 3
            },
            "is_test": false,
            "is_fix": false
        },
        "7845cc76fb72aef6908ae16a89df92e60b171f66": {
            "datetime": "2014-04-17T18:15:23-07:00",
            "summary": "1. remove unused readSupportClass parameter from generateSplit method; 2. double check split min max to be postive in the getSplits method; 3. explicit import java.util.xx in test",
            "message": "1. remove unused readSupportClass parameter from generateSplit method; 2. double check split min max to be postive in the getSplits method; 3. explicit import java.util.xx in test\n",
            "diff": {
                "parquet-hadoop/src/main/java/parquet/hadoop/ParquetInputFormat.java": 6,
                "parquet-hadoop/src/test/java/parquet/hadoop/TestInputFormat.java": 9
            },
            "is_test": true,
            "is_fix": false
        },
        "9814332cc3fed776eab8ebd03bbbc241ec562c15": {
            "datetime": "2014-04-17T18:58:50-07:00",
            "summary": "add more tests so the hdfsSize is not multiple of rowGroup size",
            "message": "add more tests so the hdfsSize is not multiple of rowGroup size\n",
            "diff": {
                "parquet-hadoop/src/test/java/parquet/hadoop/TestInputFormat.java": 107
            },
            "is_test": true,
            "is_fix": false
        },
        "ac816d91e2c30f7bceacb8601ae13a0ab0107277": {
            "datetime": "2014-04-18T09:49:20-07:00",
            "summary": "min split size default to 0",
            "message": "min split size default to 0\n",
            "diff": {
                "parquet-hadoop/src/main/java/parquet/hadoop/ParquetInputFormat.java": 2
            },
            "is_test": false,
            "is_fix": false
        },
        "83e34bec54298265c50e366fae364c02a9e2dfe3": {
            "datetime": "2014-04-18T09:53:48-07:00",
            "summary": "add non-negative check in generateSplits method",
            "message": "add non-negative check in generateSplits method\n",
            "diff": {
                "parquet-hadoop/src/main/java/parquet/hadoop/ParquetInputFormat.java": 4
            },
            "is_test": false,
            "is_fix": false
        },
        "a85b7fddbbdd381378a7075741be74c19c681ed0": {
            "datetime": "2014-04-18T10:40:09-07:00",
            "summary": "better message",
            "message": "better message\n",
            "diff": {
                "parquet-hadoop/src/test/java/parquet/hadoop/TestInputFormat.java": 2
            },
            "is_test": true,
            "is_fix": false
        },
        "4c870b0f2ff514d31f5933f29973ddbc56ccaa58": {
            "datetime": "2014-04-18T12:06:45-07:00",
            "summary": "Merge pull request #362 from nealsid/master",
            "message": "Merge pull request #362 from nealsid/master\n\nFix output bug during parquet-dump command",
            "diff": {
                "parquet-tools/src/main/java/parquet/tools/command/DumpCommand.java": 2
            },
            "is_test": false,
            "is_fix": false
        },
        "8e348e60b822d86a7e0862902c315beb56388725": {
            "datetime": "2014-04-18T13:51:34-07:00",
            "summary": "create a getStartingPos in ColumnChunkMetaData",
            "message": "create a getStartingPos in ColumnChunkMetaData\n",
            "diff": {
                "parquet-hadoop/src/main/java/parquet/hadoop/ParquetFileReader.java": 15,
                "parquet-hadoop/src/main/java/parquet/hadoop/ParquetInputFormat.java": 13,
                "parquet-hadoop/src/main/java/parquet/hadoop/metadata/ColumnChunkMetaData.java": 23,
                "parquet-hadoop/src/test/java/parquet/hadoop/TestInputFormat.java": 4
            },
            "is_test": true,
            "is_fix": false
        },
        "00d631c15d147e7e7a07d65fe50999c878a921a8": {
            "datetime": "2014-04-18T14:08:37-07:00",
            "summary": "make SplitInfo contain the hdfsBlock",
            "message": "make SplitInfo contain the hdfsBlock\n",
            "diff": {
                "parquet-hadoop/src/main/java/parquet/hadoop/ParquetInputFormat.java": 37
            },
            "is_test": false,
            "is_fix": false
        },
        "9705f4905a5077ec7208a0fa3e230668157fe471": {
            "datetime": "2014-04-18T14:16:47-07:00",
            "summary": "1. check row groups are sorted; 2. add getStartingPos for BlockMetadata, which returns the startingPos for the first Column",
            "message": "1. check row groups are sorted; 2. add getStartingPos for BlockMetadata, which returns the startingPos for the first Column\n",
            "diff": {
                "parquet-hadoop/src/main/java/parquet/hadoop/ParquetInputFormat.java": 12,
                "parquet-hadoop/src/main/java/parquet/hadoop/metadata/BlockMetaData.java": 7
            },
            "is_test": false,
            "is_fix": false
        },
        "70707e4bd2f5b41a08d4b5a306d5876473532e01": {
            "datetime": "2014-04-18T14:20:48-07:00",
            "summary": "use getStartingPos for BlockMetadata, which returns the startingPos for the first Column",
            "message": "use getStartingPos for BlockMetadata, which returns the startingPos for the first Column\n",
            "diff": {
                "parquet-hadoop/src/main/java/parquet/hadoop/ParquetInputFormat.java": 9
            },
            "is_test": false,
            "is_fix": false
        },
        "05c3e2706a356ea878177faf93ed108a348bc7ae": {
            "datetime": "2014-04-21T12:57:05+01:00",
            "summary": "ensure SimpleRecord#getValues() is unmodifiable",
            "message": "ensure SimpleRecord#getValues() is unmodifiable\n\nThis avoids modification from the outside",
            "diff": {
                "parquet-tools/src/main/java/parquet/tools/read/SimpleRecord.java": 3
            },
            "is_test": false,
            "is_fix": false
        },
        "9f672d69432e6339fc69c6848b384bd6bb744051": {
            "datetime": "2014-04-21T13:10:10-07:00",
            "summary": "use mid point of a row group to decide to create a split or not",
            "message": "use mid point of a row group to decide to create a split or not\n",
            "diff": {
                "parquet-hadoop/src/main/java/parquet/hadoop/ParquetInputFormat.java": 49,
                "parquet-hadoop/src/main/java/parquet/hadoop/metadata/BlockMetaData.java": 10,
                "parquet-hadoop/src/test/java/parquet/hadoop/TestInputFormat.java": 68
            },
            "is_test": true,
            "is_fix": false
        },
        "bba221d789909dcce126b9875c9859b4359ce911": {
            "datetime": "2014-04-21T13:26:09-07:00",
            "summary": "format",
            "message": "format\n",
            "diff": {
                "parquet-hadoop/src/main/java/parquet/hadoop/ParquetInputFormat.java": 4
            },
            "is_test": false,
            "is_fix": false
        },
        "72dbbdc4d14e9fb7479cdb8921394fea30b27745": {
            "datetime": "2014-04-21T13:41:17-07:00",
            "summary": "Merge pull request #353 from Parquet/bugfix_failed_convert_to_scrooge_struct_when_enum_is_optional",
            "message": "Merge pull request #353 from Parquet/bugfix_failed_convert_to_scrooge_struct_when_enum_is_optional\n\nFix bug: optional enum field causing ScroogeSchemaConverter to fail",
            "diff": {
                "parquet-scrooge/src/main/java/parquet/scrooge/ScroogeStructConverter.java": 10,
                "parquet-scrooge/src/test/java/parquet/scrooge/ScroogeStructConverterTest.java": 1
            },
            "is_test": true,
            "is_fix": false
        },
        "ac2b15ebb0d4d5140587e11a0e7a71f898293668": {
            "datetime": "2014-04-21T13:52:18-07:00",
            "summary": "change name to checkBelongingToANewHDFSBlock",
            "message": "change name to checkBelongingToANewHDFSBlock\n",
            "diff": {
                "parquet-hadoop/src/main/java/parquet/hadoop/ParquetInputFormat.java": 10
            },
            "is_test": false,
            "is_fix": false
        },
        "93d11c5316e494cb42d646e58d9f7ac98e942266": {
            "datetime": "2014-04-21T14:48:21-07:00",
            "summary": "Merge pull request #365 from Parquet/generate_splits_by_min_max_size",
            "message": "Merge pull request #365 from Parquet/generate_splits_by_min_max_size\n\ngenerate splits by min max size, and align to HDFS block when possible",
            "diff": {
                "parquet-hadoop/src/main/java/parquet/hadoop/ParquetFileReader.java": 15,
                "parquet-hadoop/src/main/java/parquet/hadoop/ParquetInputFormat.java": 264,
                "parquet-hadoop/src/main/java/parquet/hadoop/metadata/BlockMetaData.java": 17,
                "parquet-hadoop/src/main/java/parquet/hadoop/metadata/ColumnChunkMetaData.java": 23,
                "parquet-hadoop/src/test/java/parquet/hadoop/TestInputFormat.java": 286
            },
            "is_test": true,
            "is_fix": false
        },
        "8aeea149f7c78090cf3a63ff9f21188553ee8b94": {
            "datetime": "2014-04-21T15:39:28-07:00",
            "summary": "Merge pull request #335 from tongjiechen/master",
            "message": "Merge pull request #335 from tongjiechen/master\n\nissue #290, hive map conversion to parquet schema",
            "diff": {
                "parquet-hive/parquet-hive-storage-handler/src/main/java/org/apache/hadoop/hive/ql/io/parquet/convert/HiveSchemaConverter.java": 4,
                "parquet-hive/parquet-hive-storage-handler/src/test/java/org/apache/hadoop/hive/ql/io/parquet/TestHiveSchemaConverter.java": 24
            },
            "is_test": true,
            "is_fix": false
        },
        "c0b96220312ab371f05ad721c4dcf6bde3fefa1f": {
            "datetime": "2014-04-21T15:49:14-07:00",
            "summary": "Merge pull request #359 from mping/patch-1",
            "message": "Merge pull request #359 from mping/patch-1\n\nExpose values in SimpleRecord",
            "diff": {
                "parquet-tools/src/main/java/parquet/tools/read/SimpleRecord.java": 5
            },
            "is_test": false,
            "is_fix": false
        },
        "7640224b3fee25e3c347f1ffdabdf5392212256b": {
            "datetime": "2014-04-23T16:02:12-07:00",
            "summary": "Adding back the Page() and writePage() methods for backward-compatibility",
            "message": "Adding back the Page() and writePage() methods for backward-compatibility\nThe methods now pass an empty Stats object downstream\n",
            "diff": {
                "parquet-column/src/main/java/parquet/column/page/Page.java": 22,
                "parquet-column/src/main/java/parquet/column/page/PageWriter.java": 12,
                "parquet-column/src/test/java/parquet/column/page/mem/MemPageWriter.java": 15,
                "parquet-hadoop/src/main/java/parquet/hadoop/ColumnChunkPageWriteStore.java": 31
            },
            "is_test": false,
            "is_fix": false
        },
        "3e90b41aa06a04af2873fc6fcf68530e4a4976e9": {
            "datetime": "2014-04-23T16:39:31-07:00",
            "summary": "Merge branch 'master' of https://github.com/Parquet/parquet-mr into stats",
            "message": "Merge branch 'master' of https://github.com/Parquet/parquet-mr into stats\n\nConflicts:\n\tparquet-hadoop/src/main/java/parquet/hadoop/metadata/ColumnChunkMetaData.java\n\tparquet-hadoop/src/test/java/parquet/hadoop/TestInputFormat.java\n",
            "diff": {
                "parquet-column/src/test/java/parquet/column/values/bitpacking/TestBitPackingColumn.java": 10,
                "parquet-encoding/src/test/java/parquet/column/values/bitpacking/TestBitPacking.java": 8,
                "parquet-encoding/src/test/java/parquet/column/values/bitpacking/TestByteBitPacking.java": 38,
                "parquet-encoding/src/test/java/parquet/column/values/bitpacking/TestLemireBitPacking.java": 26,
                "parquet-hadoop/src/main/java/parquet/hadoop/ParquetFileReader.java": 42,
                "parquet-hadoop/src/main/java/parquet/hadoop/ParquetFileWriter.java": 18,
                "parquet-hadoop/src/main/java/parquet/hadoop/ParquetInputFormat.java": 264,
                "parquet-hadoop/src/main/java/parquet/hadoop/ParquetInputSplit.java": 47,
                "parquet-hadoop/src/main/java/parquet/hadoop/metadata/BlockMetaData.java": 17,
                "parquet-hadoop/src/main/java/parquet/hadoop/metadata/ColumnChunkMetaData.java": 23,
                "parquet-hadoop/src/test/java/parquet/hadoop/TestInputFormat.java": 283,
                "parquet-hadoop/src/test/java/parquet/hadoop/TestParquetInputSplit.java": 4,
                "parquet-hive/parquet-hive-storage-handler/src/main/java/org/apache/hadoop/hive/ql/io/parquet/convert/HiveSchemaConverter.java": 4,
                "parquet-hive/parquet-hive-storage-handler/src/main/java/org/apache/hadoop/hive/ql/io/parquet/serde/AbstractParquetMapInspector.java": 38,
                "parquet-hive/parquet-hive-storage-handler/src/test/java/org/apache/hadoop/hive/ql/io/parquet/TestHiveSchemaConverter.java": 24,
                "parquet-scrooge/src/main/java/parquet/scrooge/ScroogeStructConverter.java": 10,
                "parquet-scrooge/src/test/java/parquet/scrooge/ScroogeStructConverterTest.java": 1,
                "parquet-thrift/src/main/java/parquet/hadoop/thrift/ThriftBytesWriteSupport.java": 14,
                "parquet-thrift/src/main/java/parquet/hadoop/thrift/ThriftReadSupport.java": 10,
                "parquet-thrift/src/main/java/parquet/thrift/pig/ParquetThriftStorer.java": 90,
                "parquet-thrift/src/main/java/parquet/thrift/pig/TupleToThriftWriteSupport.java": 74,
                "parquet-thrift/src/test/java/parquet/thrift/pig/TestParquetThriftStorer.java": 79,
                "parquet-tools/src/main/java/parquet/tools/command/DumpCommand.java": 2,
                "parquet-tools/src/main/java/parquet/tools/read/SimpleRecord.java": 5
            },
            "is_test": true,
            "is_fix": false
        },
        "9a38aecccf96ceee20779d838aa395262270ea36": {
            "datetime": "2014-04-29T15:54:54-07:00",
            "summary": "fix metadata concurency problem",
            "message": "fix metadata concurency problem\n",
            "diff": {
                "parquet-hadoop/src/main/java/parquet/hadoop/metadata/Canonicalizer.java": 59,
                "parquet-hadoop/src/main/java/parquet/hadoop/metadata/ColumnChunkProperties.java": 12,
                "parquet-hadoop/src/main/java/parquet/hadoop/metadata/ColumnPath.java": 23,
                "parquet-hadoop/src/main/java/parquet/hadoop/metadata/EncodingList.java": 12
            },
            "is_test": false,
            "is_fix": false
        },
        "6aed5288fd4a1398063a5a219b2ae4a9f71b02cf": {
            "datetime": "2014-04-29T16:48:12-07:00",
            "summary": "Merge pull request #381 from Parquet/fix_concurency_problem",
            "message": "Merge pull request #381 from Parquet/fix_concurency_problem\n\nfix metadata concurency problem",
            "diff": {
                "parquet-hadoop/src/main/java/parquet/hadoop/metadata/Canonicalizer.java": 59,
                "parquet-hadoop/src/main/java/parquet/hadoop/metadata/ColumnChunkProperties.java": 12,
                "parquet-hadoop/src/main/java/parquet/hadoop/metadata/ColumnPath.java": 23,
                "parquet-hadoop/src/main/java/parquet/hadoop/metadata/EncodingList.java": 12
            },
            "is_test": false,
            "is_fix": false
        },
        "0e334ca38b9f76b5b5df6a56510400b7b151f5af": {
            "datetime": "2014-05-02T16:46:27-07:00",
            "summary": "Use parameterized to test with and without dictionary.",
            "message": "Use parameterized to test with and without dictionary.\n",
            "diff": {
                "parquet-column/src/test/java/parquet/io/TestColumnIO.java": 21
            },
            "is_test": true,
            "is_fix": false
        },
        "346b387ae779e2eda2d4ef9b3bff361fac2d753d": {
            "datetime": "2014-05-05T16:09:59-07:00",
            "summary": "Merge pull request #337 from tongjiechen/issue324",
            "message": "Merge pull request #337 from tongjiechen/issue324\n\n issue #324, move ParquetStringInspector to org.apache.hadoop.hive.serde...",
            "diff": {
                "parquet-hive/parquet-hive-storage-handler/src/main/java/org/apache/hadoop/hive/ql/io/parquet/serde/ArrayWritableObjectInspector.java": 7,
                "parquet-hive/parquet-hive-storage-handler/src/main/java/org/apache/hadoop/hive/ql/io/parquet/serde/primitive/ParquetPrimitiveInspectorFactory.java": 1,
                "parquet-hive/parquet-hive-storage-handler/src/main/java/org/apache/hadoop/hive/ql/io/parquet/serde/primitive/ParquetStringInspector.java": 11
            },
            "is_test": false,
            "is_fix": false
        },
        "50701e7d2af0aab49b77518c2fb4c4b8c931f855": {
            "datetime": "2014-05-07T16:09:15-07:00",
            "summary": "Merge branch 'master' into tweak_semver",
            "message": "Merge branch 'master' into tweak_semver\n",
            "diff": {
                "parquet-hadoop/src/main/java/parquet/hadoop/metadata/Canonicalizer.java": 59,
                "parquet-hadoop/src/main/java/parquet/hadoop/metadata/ColumnChunkProperties.java": 12,
                "parquet-hadoop/src/main/java/parquet/hadoop/metadata/ColumnPath.java": 23,
                "parquet-hadoop/src/main/java/parquet/hadoop/metadata/EncodingList.java": 12,
                "parquet-hive/parquet-hive-storage-handler/src/main/java/org/apache/hadoop/hive/ql/io/parquet/serde/ArrayWritableObjectInspector.java": 7,
                "parquet-hive/parquet-hive-storage-handler/src/main/java/org/apache/hadoop/hive/ql/io/parquet/serde/primitive/ParquetPrimitiveInspectorFactory.java": 1,
                "parquet-hive/parquet-hive-storage-handler/src/main/java/org/apache/hadoop/hive/ql/io/parquet/serde/primitive/ParquetStringInspector.java": 11
            },
            "is_test": false,
            "is_fix": false
        },
        "163bf6bd3436ee8d558524b09d7cc9e4df8a0275": {
            "datetime": "2014-05-07T19:43:22-07:00",
            "summary": "Add support for DECIMAL type annotation.",
            "message": "Add support for DECIMAL type annotation.\n\nChanges:\n* Add Types builder API to consolidate type building, consistency checks\n* Update schema parser to support precision and scale on DECIMAL:\n  required binary aDecimal (DECIMAL(9,2));\n* Update writeToStringBuilder methods to add precision and scale\n* Add DECIMAL conversion in ParquetMetadataConverter\n* Add precision, scale conversion in ParquetMetadataConverter\n* Add OriginalTypeMeta to hold type annotation metadata (e.g., scale)\n* Add more testing to ensure compatibility\n",
            "diff": {
                "parquet-column/src/main/java/parquet/schema/GroupType.java": 23,
                "parquet-column/src/main/java/parquet/schema/MessageTypeParser.java": 73,
                "parquet-column/src/main/java/parquet/schema/OriginalType.java": 3,
                "parquet-column/src/main/java/parquet/schema/OriginalTypeMeta.java": 39,
                "parquet-column/src/main/java/parquet/schema/PrimitiveType.java": 48,
                "parquet-column/src/main/java/parquet/schema/Type.java": 23,
                "parquet-column/src/main/java/parquet/schema/Types.java": 282,
                "parquet-column/src/test/java/parquet/parser/TestParquetParser.java": 139,
                "parquet-column/src/test/java/parquet/schema/TestTypeBuilders.java": 151,
                "parquet-common/src/main/java/parquet/Preconditions.java": 6,
                "parquet-hadoop/src/main/java/parquet/format/converter/ParquetMetadataConverter.java": 75,
                "parquet-hadoop/src/test/java/parquet/format/converter/TestParquetMetadataConverter.java": 35
            },
            "is_test": true,
            "is_fix": false
        },
        "0189ff1757a3b3f0c9c268ed68cee6387d3e5187": {
            "datetime": "2014-05-07T19:43:23-07:00",
            "summary": "Fix more code review finds.",
            "message": "Fix more code review finds.\n",
            "diff": {
                "parquet-column/src/main/java/parquet/schema/PrimitiveType.java": 5,
                "parquet-column/src/main/java/parquet/schema/Types.java": 14,
                "parquet-hadoop/src/main/java/parquet/format/converter/ParquetMetadataConverter.java": 6
            },
            "is_test": false,
            "is_fix": false
        },
        "c825e89c84fa78222baae7a35c4843b2ef199869": {
            "datetime": "2014-05-07T19:43:23-07:00",
            "summary": "Remove unchecked casts from Types.Builder.",
            "message": "Remove unchecked casts from Types.Builder.\n\nThis simplifies the logic so that either a return object is supplied\nwhen a Builder is constructed, or the expected type is supplied so that\nthe code can check the return type is valid.\n",
            "diff": {
                "parquet-column/src/main/java/parquet/schema/Types.java": 59
            },
            "is_test": false,
            "is_fix": false
        },
        "acaac8bb700debdec66d0a633a60be503b7a20b4": {
            "datetime": "2014-05-07T19:43:23-07:00",
            "summary": "Implement code review changes.",
            "message": "Implement code review changes.\n",
            "diff": {
                "parquet-column/src/main/java/parquet/schema/GroupType.java": 23,
                "parquet-column/src/main/java/parquet/schema/MessageTypeParser.java": 61,
                "parquet-column/src/main/java/parquet/schema/OriginalTypeMeta.java": 6,
                "parquet-column/src/main/java/parquet/schema/PrimitiveType.java": 22,
                "parquet-column/src/main/java/parquet/schema/Type.java": 23,
                "parquet-column/src/main/java/parquet/schema/Types.java": 126,
                "parquet-column/src/test/java/parquet/schema/TestTypeBuilders.java": 37,
                "parquet-common/src/main/java/parquet/Preconditions.java": 5,
                "parquet-hadoop/src/main/java/parquet/format/converter/ParquetMetadataConverter.java": 22
            },
            "is_test": true,
            "is_fix": false
        },
        "86501c2352413feb8a4128362d862c89e6cbb1f7": {
            "datetime": "2014-05-07T19:43:23-07:00",
            "summary": "Add INT32 and INT64 as supported types for DECIMAL.",
            "message": "Add INT32 and INT64 as supported types for DECIMAL.\n",
            "diff": {
                "parquet-column/src/main/java/parquet/schema/Types.java": 23,
                "parquet-column/src/test/java/parquet/schema/TestTypeBuilders.java": 184
            },
            "is_test": true,
            "is_fix": false
        },
        "9ef22e630907eeb85600ab3ef53257fb575a0f8e": {
            "datetime": "2014-05-07T19:43:23-07:00",
            "summary": "Fix maximum precision calculation, account for sign bit.",
            "message": "Fix maximum precision calculation, account for sign bit.\n",
            "diff": {
                "parquet-column/src/main/java/parquet/schema/Types.java": 6,
                "parquet-column/src/test/java/parquet/schema/TestTypeBuilders.java": 4
            },
            "is_test": true,
            "is_fix": false
        },
        "5c807055aa1959737c2b2a1d2256e5769c9a7f25": {
            "datetime": "2014-05-07T19:43:23-07:00",
            "summary": "Update documentation and formatting.",
            "message": "Update documentation and formatting.\n",
            "diff": {
                "parquet-column/src/main/java/parquet/schema/Types.java": 42
            },
            "is_test": false,
            "is_fix": false
        },
        "73d7558bdaf966a9fbfae7fc1c8f0ba727a98de9": {
            "datetime": "2014-05-07T19:43:23-07:00",
            "summary": "Simplify Types API by moving repetition.",
            "message": "Simplify Types API by moving repetition.\n",
            "diff": {
                "parquet-column/src/main/java/parquet/schema/MessageTypeParser.java": 7,
                "parquet-column/src/main/java/parquet/schema/PrimitiveType.java": 4,
                "parquet-column/src/main/java/parquet/schema/Types.java": 22,
                "parquet-column/src/test/java/parquet/schema/TestTypeBuilders.java": 32,
                "parquet-hadoop/src/main/java/parquet/format/converter/ParquetMetadataConverter.java": 8
            },
            "is_test": true,
            "is_fix": false
        },
        "299e0ca760ccc0608ba7b0ebd3461f4ec5e606f8": {
            "datetime": "2014-05-07T19:43:23-07:00",
            "summary": "Add Types builder API documentation.",
            "message": "Add Types builder API documentation.\n\nAlso add check that scale <= precision and test.\n",
            "diff": {
                "parquet-column/src/main/java/parquet/schema/Types.java": 264,
                "parquet-column/src/test/java/parquet/schema/TestTypeBuilders.java": 25
            },
            "is_test": true,
            "is_fix": false
        },
        "63ffdce40355d8c75dae6a6888ca315889737f1c": {
            "datetime": "2014-05-07T19:43:23-07:00",
            "summary": "Add test for decimal with unsupported primitive types.",
            "message": "Add test for decimal with unsupported primitive types.\n",
            "diff": {
                "parquet-column/src/test/java/parquet/schema/TestTypeBuilders.java": 18
            },
            "is_test": true,
            "is_fix": false
        },
        "3af02db83a4b18f814a400bfe8569c31de4932b7": {
            "datetime": "2014-05-07T19:43:23-07:00",
            "summary": "Add more tests for type builders.",
            "message": "Add more tests for type builders.\n",
            "diff": {
                "parquet-column/src/test/java/parquet/schema/TestTypeBuilders.java": 199
            },
            "is_test": true,
            "is_fix": false
        },
        "a1d7260a4ace24a8d6f514149271ad998019eb5e": {
            "datetime": "2014-05-07T19:43:23-07:00",
            "summary": "Fix primitive type equality for fixed with different lengths.",
            "message": "Fix primitive type equality for fixed with different lengths.\n",
            "diff": {
                "parquet-column/src/main/java/parquet/schema/PrimitiveType.java": 4,
                "parquet-column/src/test/java/parquet/schema/TestTypeBuilders.java": 8
            },
            "is_test": true,
            "is_fix": false
        },
        "9f75dd1f59236f22e199bd5561f511dc5e45d66a": {
            "datetime": "2014-05-08T16:57:28+01:00",
            "summary": "Merge pull request #355 from rdblue/decimal",
            "message": "Merge pull request #355 from rdblue/decimal\n\nAdd support for DECIMAL type annotation.",
            "diff": {
                "parquet-column/src/main/java/parquet/schema/DecimalMetadata.java": 39,
                "parquet-column/src/main/java/parquet/schema/MessageTypeParser.java": 101,
                "parquet-column/src/main/java/parquet/schema/OriginalType.java": 3,
                "parquet-column/src/main/java/parquet/schema/PrimitiveType.java": 53,
                "parquet-column/src/main/java/parquet/schema/Types.java": 602,
                "parquet-column/src/test/java/parquet/parser/TestParquetParser.java": 139,
                "parquet-column/src/test/java/parquet/schema/TestTypeBuilders.java": 478,
                "parquet-common/src/main/java/parquet/Preconditions.java": 11,
                "parquet-hadoop/src/main/java/parquet/format/converter/ParquetMetadataConverter.java": 73,
                "parquet-hadoop/src/test/java/parquet/format/converter/TestParquetMetadataConverter.java": 35
            },
            "is_test": true,
            "is_fix": false
        },
        "96b94e1b7e61c8c9b17c9c08ce059a9d4015052e": {
            "datetime": "2014-05-08T14:17:16-07:00",
            "summary": "Merge pull request #351 from rdblue/350-fix-int96-dictionary",
            "message": "Merge pull request #351 from rdblue/350-fix-int96-dictionary\n\nFix bug #350, fixed length argument out of order.",
            "diff": {
                "parquet-column/src/main/java/parquet/column/ParquetProperties.java": 2,
                "parquet-column/src/test/java/parquet/io/TestColumnIO.java": 21
            },
            "is_test": true,
            "is_fix": false
        },
        "2678e39483965083c3604e10b9dd143a2c89dd7b": {
            "datetime": "2014-05-09T10:26:21-07:00",
            "summary": "Merge branch 'master' of https://github.com/Parquet/parquet-mr into stats",
            "message": "Merge branch 'master' of https://github.com/Parquet/parquet-mr into stats\n\nConflicts:\n\tparquet-hadoop/src/main/java/parquet/hadoop/metadata/ColumnChunkProperties.java\n\tpom.xml\n",
            "diff": {
                "parquet-column/src/main/java/parquet/column/ParquetProperties.java": 2,
                "parquet-column/src/main/java/parquet/schema/DecimalMetadata.java": 39,
                "parquet-column/src/main/java/parquet/schema/MessageTypeParser.java": 101,
                "parquet-column/src/main/java/parquet/schema/OriginalType.java": 3,
                "parquet-column/src/main/java/parquet/schema/PrimitiveType.java": 53,
                "parquet-column/src/main/java/parquet/schema/Types.java": 602,
                "parquet-column/src/test/java/parquet/io/TestColumnIO.java": 21,
                "parquet-column/src/test/java/parquet/parser/TestParquetParser.java": 139,
                "parquet-column/src/test/java/parquet/schema/TestTypeBuilders.java": 478,
                "parquet-common/src/main/java/parquet/Preconditions.java": 11,
                "parquet-hadoop/src/main/java/parquet/format/converter/ParquetMetadataConverter.java": 73,
                "parquet-hadoop/src/main/java/parquet/hadoop/metadata/Canonicalizer.java": 59,
                "parquet-hadoop/src/main/java/parquet/hadoop/metadata/ColumnChunkProperties.java": 17,
                "parquet-hadoop/src/main/java/parquet/hadoop/metadata/ColumnPath.java": 23,
                "parquet-hadoop/src/main/java/parquet/hadoop/metadata/EncodingList.java": 12,
                "parquet-hadoop/src/test/java/parquet/format/converter/TestParquetMetadataConverter.java": 35,
                "parquet-hive/parquet-hive-storage-handler/src/main/java/org/apache/hadoop/hive/ql/io/parquet/serde/ArrayWritableObjectInspector.java": 7,
                "parquet-hive/parquet-hive-storage-handler/src/main/java/org/apache/hadoop/hive/ql/io/parquet/serde/primitive/ParquetPrimitiveInspectorFactory.java": 1,
                "parquet-hive/parquet-hive-storage-handler/src/main/java/org/apache/hadoop/hive/ql/io/parquet/serde/primitive/ParquetStringInspector.java": 11
            },
            "is_test": true,
            "is_fix": false
        },
        "c98d8af5c26a5622b2b830fc3410e8f8ae1f83e7": {
            "datetime": "2014-05-09T14:01:19-07:00",
            "summary": "adding back the parquet-hadoop methods that don't have statistics parameters, for backward comp",
            "message": "adding back the parquet-hadoop methods that don't have statistics parameters, for backward comp\n",
            "diff": {
                "parquet-hadoop/src/main/java/parquet/format/converter/ParquetMetadataConverter.java": 18,
                "parquet-hadoop/src/main/java/parquet/hadoop/ParquetFileWriter.java": 38,
                "parquet-hadoop/src/main/java/parquet/hadoop/metadata/ColumnChunkMetaData.java": 39
            },
            "is_test": false,
            "is_fix": false
        },
        "041146e6b0eb0dca699cf66991a19d3991bfe3e6": {
            "datetime": "2014-05-12T10:55:19+10:00",
            "summary": "Fixed hadoop WriteSupportClass loading",
            "message": "Fixed hadoop WriteSupportClass loading\n",
            "diff": {
                "parquet-hadoop/src/main/java/parquet/hadoop/ParquetOutputFormat.java": 12
            },
            "is_test": false,
            "is_fix": false
        },
        "882740f032fb57b48a5bc775da609532084c7fe4": {
            "datetime": "2014-05-12T16:11:22+02:00",
            "summary": "return NullCounter when read via Cascading, but not within a cluster side job",
            "message": "return NullCounter when read via Cascading, but not within a cluster side job\n",
            "diff": {
                "parquet-hadoop/src/main/java/parquet/hadoop/util/counters/mapred/MapRedCounterLoader.java": 11
            },
            "is_test": false,
            "is_fix": false
        },
        "05b4e7c6be490255f89f4beaddd5cbfa84560e38": {
            "datetime": "2014-05-12T14:54:57-07:00",
            "summary": "Merge pull request #338 from egonina/stats",
            "message": "Merge pull request #338 from egonina/stats\n\nAdded statistics to Parquet pages and rowGroups",
            "diff": {
                "parquet-column/src/main/java/parquet/column/ColumnWriter.java": 6,
                "parquet-column/src/main/java/parquet/column/UnknownColumnTypeException.java": 40,
                "parquet-column/src/main/java/parquet/column/impl/ColumnWriteStoreImpl.java": 5,
                "parquet-column/src/main/java/parquet/column/impl/ColumnWriterImpl.java": 58,
                "parquet-column/src/main/java/parquet/column/page/Page.java": 35,
                "parquet-column/src/main/java/parquet/column/page/PageWriter.java": 14,
                "parquet-column/src/main/java/parquet/column/statistics/BinaryStatistics.java": 85,
                "parquet-column/src/main/java/parquet/column/statistics/BooleanStatistics.java": 85,
                "parquet-column/src/main/java/parquet/column/statistics/DoubleStatistics.java": 85,
                "parquet-column/src/main/java/parquet/column/statistics/FloatStatistics.java": 85,
                "parquet-column/src/main/java/parquet/column/statistics/IntStatistics.java": 85,
                "parquet-column/src/main/java/parquet/column/statistics/LongStatistics.java": 85,
                "parquet-column/src/main/java/parquet/column/statistics/Statistics.java": 221,
                "parquet-column/src/main/java/parquet/column/statistics/StatisticsClassException.java": 31,
                "parquet-column/src/main/java/parquet/io/api/Binary.java": 63,
                "parquet-column/src/test/java/parquet/column/mem/TestMemPageStore.java": 10,
                "parquet-column/src/test/java/parquet/column/page/mem/MemPageWriter.java": 15,
                "parquet-column/src/test/java/parquet/column/statistics/TestStatistics.java": 462,
                "parquet-column/src/test/java/parquet/io/TestColumnIO.java": 127,
                "parquet-common/src/main/java/parquet/bytes/BytesUtils.java": 50,
                "parquet-hadoop/src/main/java/parquet/format/converter/ParquetMetadataConverter.java": 53,
                "parquet-hadoop/src/main/java/parquet/hadoop/ColumnChunkPageReadStore.java": 1,
                "parquet-hadoop/src/main/java/parquet/hadoop/ColumnChunkPageWriteStore.java": 46,
                "parquet-hadoop/src/main/java/parquet/hadoop/ParquetFileReader.java": 1,
                "parquet-hadoop/src/main/java/parquet/hadoop/ParquetFileWriter.java": 60,
                "parquet-hadoop/src/main/java/parquet/hadoop/ParquetInputSplit.java": 4,
                "parquet-hadoop/src/main/java/parquet/hadoop/metadata/ColumnChunkMetaData.java": 87,
                "parquet-hadoop/src/main/java/parquet/hadoop/metadata/ColumnChunkProperties.java": 7,
                "parquet-hadoop/src/test/java/parquet/hadoop/TestInputFormat.java": 11,
                "parquet-hadoop/src/test/java/parquet/hadoop/TestParquetFileWriter.java": 131,
                "parquet-hadoop/src/test/java/parquet/hadoop/metadata/TestColumnChunkMetaData.java": 7
            },
            "is_test": true,
            "is_fix": false
        },
        "cc28822843f97a6c791dfc2cb1c860c2e731d22a": {
            "datetime": "2014-05-13T11:57:34-07:00",
            "summary": "Added padding for columns not found in file schema",
            "message": "Added padding for columns not found in file schema\n",
            "diff": {
                "parquet-pig/src/main/java/parquet/pig/convert/TupleConverter.java": 29
            },
            "is_test": false,
            "is_fix": false
        },
        "70bb0ea0009f25f7ff432c177f94aa40dbd0ebe4": {
            "datetime": "2014-05-16T17:24:01-07:00",
            "summary": "fixes for converting from bytes, toString() methods, writing stats to Footer, unit testing for MAX/MIN_VALUE",
            "message": "fixes for converting from bytes, toString() methods, writing stats to Footer, unit testing for MAX/MIN_VALUE\n",
            "diff": {
                "parquet-column/src/main/java/parquet/column/statistics/BinaryStatistics.java": 8,
                "parquet-column/src/main/java/parquet/column/statistics/BooleanStatistics.java": 8,
                "parquet-column/src/main/java/parquet/column/statistics/DoubleStatistics.java": 8,
                "parquet-column/src/main/java/parquet/column/statistics/FloatStatistics.java": 8,
                "parquet-column/src/main/java/parquet/column/statistics/IntStatistics.java": 8,
                "parquet-column/src/main/java/parquet/column/statistics/LongStatistics.java": 12,
                "parquet-column/src/main/java/parquet/column/statistics/Statistics.java": 6,
                "parquet-column/src/test/java/parquet/column/statistics/TestStatistics.java": 114,
                "parquet-hadoop/src/main/java/parquet/hadoop/PrintFooter.java": 21
            },
            "is_test": true,
            "is_fix": false
        },
        "4d42afbaa5f1e67250bf00806c1e3e84088d101b": {
            "datetime": "2014-05-19T09:23:10-07:00",
            "summary": "Merge pull request #392 from egonina/stats",
            "message": "Merge pull request #392 from egonina/stats\n\nValue stats fixes",
            "diff": {
                "parquet-column/src/main/java/parquet/column/statistics/BinaryStatistics.java": 8,
                "parquet-column/src/main/java/parquet/column/statistics/BooleanStatistics.java": 8,
                "parquet-column/src/main/java/parquet/column/statistics/DoubleStatistics.java": 8,
                "parquet-column/src/main/java/parquet/column/statistics/FloatStatistics.java": 8,
                "parquet-column/src/main/java/parquet/column/statistics/IntStatistics.java": 8,
                "parquet-column/src/main/java/parquet/column/statistics/LongStatistics.java": 12,
                "parquet-column/src/main/java/parquet/column/statistics/Statistics.java": 6,
                "parquet-column/src/test/java/parquet/column/statistics/TestStatistics.java": 114,
                "parquet-hadoop/src/main/java/parquet/hadoop/PrintFooter.java": 21
            },
            "is_test": true,
            "is_fix": false
        },
        "10dc714bdbb9f7209538d412dc1fcf2219cc9afb": {
            "datetime": "2014-05-19T09:53:02-07:00",
            "summary": "Added test for null padding",
            "message": "Added test for null padding\n",
            "diff": {
                "parquet-pig/src/test/java/parquet/pig/TestParquetLoader.java": 45
            },
            "is_test": true,
            "is_fix": false
        },
        "d5a8f9fa4a34bfc6dfa7369cb7b786634914698c": {
            "datetime": "2014-05-19T10:27:54-07:00",
            "summary": "Merge pull request #389 from dcw-netflix/pad-schema",
            "message": "Merge pull request #389 from dcw-netflix/pad-schema\n\nAdded padding for requested columns not found in file schema",
            "diff": {
                "parquet-pig/src/main/java/parquet/pig/convert/TupleConverter.java": 29,
                "parquet-pig/src/test/java/parquet/pig/TestParquetLoader.java": 45
            },
            "is_test": true,
            "is_fix": false
        },
        "24076a4a44ab08534e4528ff4b08e8eec60ddcb7": {
            "datetime": "2014-05-20T16:15:27-07:00",
            "summary": "Fixed issue with column pruning when using requested schema",
            "message": "Fixed issue with column pruning when using requested schema\n",
            "diff": {
                "parquet-pig/src/main/java/parquet/pig/ParquetLoader.java": 4,
                "parquet-pig/src/test/java/parquet/pig/TestParquetLoader.java": 34
            },
            "is_test": true,
            "is_fix": false
        },
        "fb7dba1ad4bef40ffe6dbe59f6f9ace9ecd1c131": {
            "datetime": "2014-05-20T17:18:29-07:00",
            "summary": "Updated test and remove shortcut return statement in loader",
            "message": "Updated test and remove shortcut return statement in loader\n",
            "diff": {
                "parquet-pig/src/main/java/parquet/pig/ParquetLoader.java": 1,
                "parquet-pig/src/test/java/parquet/pig/TestParquetLoader.java": 13
            },
            "is_test": true,
            "is_fix": false
        },
        "b70509ddc393a51332977bd9c67c4de0073173c7": {
            "datetime": "2014-05-20T17:45:48-07:00",
            "summary": "Merge pull request #397 from dcw-netflix/requested-schema-pruning",
            "message": "Merge pull request #397 from dcw-netflix/requested-schema-pruning\n\nFixed issue with column pruning when using requested schema",
            "diff": {
                "parquet-pig/src/main/java/parquet/pig/ParquetLoader.java": 5,
                "parquet-pig/src/test/java/parquet/pig/TestParquetLoader.java": 43
            },
            "is_test": true,
            "is_fix": false
        },
        "8091a1b511aa66ff3775644a757bd30a8c869faf": {
            "datetime": "2014-05-20T23:31:33-07:00",
            "summary": "fix null stats",
            "message": "fix null stats\n",
            "diff": {
                "parquet-column/src/main/java/parquet/column/impl/ColumnWriterImpl.java": 7
            },
            "is_test": false,
            "is_fix": false
        },
        "7e4346b2120d13a958aa93df26dfc265a8756b2b": {
            "datetime": "2014-05-21T14:04:09-07:00",
            "summary": "merging with fix_null_stats branch",
            "message": "merging with fix_null_stats branch\n",
            "diff": {
                "parquet-column/src/main/java/parquet/column/impl/ColumnWriterImpl.java": 7,
                "parquet-column/src/test/java/parquet/io/TestColumnIO.java": 21,
                "parquet-hadoop/src/main/java/parquet/format/converter/ParquetMetadataConverter.java": 4,
                "parquet-hadoop/src/test/java/parquet/hadoop/TestParquetFileWriter.java": 30,
                "parquet-thrift/src/test/java/parquet/hadoop/thrift/TestThriftToParquetFileWriter.java": 35
            },
            "is_test": true,
            "is_fix": false
        },
        "e4991ffe47aec9ed991b269d3cbe6fa9c9665627": {
            "datetime": "2014-05-21T15:49:28-07:00",
            "summary": "Merge branch 'master' of https://github.com/Parquet/parquet-mr into stats",
            "message": "Merge branch 'master' of https://github.com/Parquet/parquet-mr into stats\n",
            "diff": {
                "parquet-pig/src/main/java/parquet/pig/ParquetLoader.java": 5,
                "parquet-pig/src/main/java/parquet/pig/convert/TupleConverter.java": 29,
                "parquet-pig/src/test/java/parquet/pig/TestParquetLoader.java": 80
            },
            "is_test": true,
            "is_fix": false
        },
        "4fee0a7cb53e37d6866f5dc52c51b09ccea330a9": {
            "datetime": "2014-05-21T16:03:15-07:00",
            "summary": "Bug fix - resetting stats after writing page. Fixed unit test to test reading footer",
            "message": "Bug fix - resetting stats after writing page. Fixed unit test to test reading footer\n",
            "diff": {
                "parquet-column/src/main/java/parquet/column/ColumnWriter.java": 6,
                "parquet-column/src/main/java/parquet/column/impl/ColumnWriterImpl.java": 5,
                "parquet-column/src/test/java/parquet/io/TestColumnIO.java": 128,
                "parquet-thrift/src/test/java/parquet/hadoop/thrift/TestThriftToParquetFileWriter.java": 79
            },
            "is_test": true,
            "is_fix": false
        },
        "54f9b1044d23c53a153743441b44bfbd631ff0e6": {
            "datetime": "2014-05-21T16:47:40-07:00",
            "summary": "Cleaning up + testing small & large values",
            "message": "Cleaning up + testing small & large values\n",
            "diff": {
                "parquet-hadoop/src/test/java/parquet/hadoop/TestParquetFileWriter.java": 11,
                "parquet-thrift/src/test/java/parquet/hadoop/thrift/TestThriftToParquetFileWriter.java": 88
            },
            "is_test": true,
            "is_fix": false
        },
        "fd8d18f26af9ad7813dda71352b5dcb0080306eb": {
            "datetime": "2014-05-21T17:43:35-07:00",
            "summary": "Merge pull request #399 from egonina/stats",
            "message": "Merge pull request #399 from egonina/stats\n\nFixed resetting stats after writePage bug, unit testing of readFooter",
            "diff": {
                "parquet-column/src/main/java/parquet/column/ColumnWriter.java": 6,
                "parquet-column/src/main/java/parquet/column/impl/ColumnWriterImpl.java": 15,
                "parquet-column/src/test/java/parquet/io/TestColumnIO.java": 125,
                "parquet-hadoop/src/main/java/parquet/format/converter/ParquetMetadataConverter.java": 4,
                "parquet-hadoop/src/test/java/parquet/hadoop/TestParquetFileWriter.java": 19,
                "parquet-thrift/src/test/java/parquet/hadoop/thrift/TestThriftToParquetFileWriter.java": 118
            },
            "is_test": true,
            "is_fix": false
        },
        "a05afe2682ce33e401e9fdf87a4c8b147f6daa3a": {
            "datetime": "2014-05-22T17:55:28-07:00",
            "summary": "Merge pull request #387 from ambiata/fix-writeclass",
            "message": "Merge pull request #387 from ambiata/fix-writeclass\n\nFixed hadoop WriteSupportClass loading",
            "diff": {
                "parquet-hadoop/src/main/java/parquet/hadoop/ParquetOutputFormat.java": 12
            },
            "is_test": false,
            "is_fix": false
        },
        "ee0b98ceaec86f94ca6ef2f9292510b92c5a073c": {
            "datetime": "2014-05-27T14:30:47-07:00",
            "summary": "Merge pull request #388 from fs111/master",
            "message": "Merge pull request #388 from fs111/master\n\nreturn NullCounter when read via Cascading, but not within a cluster side job",
            "diff": {
                "parquet-hadoop/src/main/java/parquet/hadoop/util/counters/mapred/MapRedCounterLoader.java": 11
            },
            "is_test": false,
            "is_fix": false
        },
        "859b6b4b9485186fdfd3dd0cd0439d2a48b56aa5": {
            "datetime": "2014-06-20T18:37:19-07:00",
            "summary": "PARQUET-3: tool to merge pull requests based on Spark",
            "message": "PARQUET-3: tool to merge pull requests based on Spark\n\ngiven a pull request id on github.com/apache/incubator-parquet-mr this script will merge it\nrequires 2 remotes: apache-github and apache to point to the corresponding repos.\ntested here (pretending my fork is the apache remote):\nhttps://github.com/julienledem/incubator-parquet-mr/commit/485658a5b7654198ab1fcc77e2b850ee12999491\n\noriginal tool:\nhttps://github.com/apache/spark/blob/master/dev/merge_spark_pr.py\n\nAuthor: Julien Le Dem <julien@twitter.com>\nAuthor: julien <julien@twitter.com>\n\nCloses #5 from julienledem/merge_pr_tool and squashes the following commits:\n\nf719846 [Julien Le Dem] rephrase 'apache credentials'\nfaab516 [Julien Le Dem] Create README.md\nab3b8fa [julien] tool to merge pull requests based on Spark\n",
            "diff": {
                "dev/merge_parquet_pr.py": 336
            },
            "is_test": false,
            "is_fix": false
        },
        "9ad5485c3310a8c51510ea50e24834b6cf98c45c": {
            "datetime": "2014-06-24T10:19:27-07:00",
            "summary": "PARQUET-2: Adding Type Persuasion for Primitive Types",
            "message": "PARQUET-2: Adding Type Persuasion for Primitive Types\n\nOriginal from the old repo: https://github.com/Parquet/parquet-mr/pull/410\nJIRA: https://issues.apache.org/jira/browse/PARQUET-2\n\nThese changes allow primitive types to be requested as different types than what is stored in the file format using a flag to turn off strict type checking (default is on). Types are cast to the requested type where possible and will suffer precision loss for casting where necessary (e.g. requesting a double as an int).\n\nNo performance penalty is imposed for using the type defined in the file type.  A flag exists to\n\nA 6x6 test case is provided to test conversion between the primitive types.\n\nAuthor: Daniel Weeks <dweeks@netflix.com>\n\nCloses #3 from dcw-netflix/type-persuasion and squashes the following commits:\n\n97f4e9a [Daniel Weeks] Added documentation as suggested by code review\n1c3c0c7 [Daniel Weeks] Fixed test with strict checking off\nf3cb495 [Daniel Weeks] Added type persuasion for primitive types with a flag to control strict type checking for conflicting schemas, which is strict by default.\n",
            "diff": {
                "parquet-column/src/main/java/parquet/io/ColumnIOFactory.java": 21,
                "parquet-column/src/main/java/parquet/schema/GroupType.java": 17,
                "parquet-column/src/main/java/parquet/schema/MessageType.java": 6,
                "parquet-column/src/main/java/parquet/schema/PrimitiveType.java": 9,
                "parquet-column/src/main/java/parquet/schema/Type.java": 7,
                "parquet-hadoop/src/main/java/parquet/hadoop/InternalParquetRecordReader.java": 6,
                "parquet-hadoop/src/main/java/parquet/hadoop/ParquetFileWriter.java": 32,
                "parquet-hadoop/src/main/java/parquet/hadoop/ParquetInputFormat.java": 7,
                "parquet-pig/src/main/java/parquet/pig/convert/TupleConverter.java": 153,
                "parquet-pig/src/test/java/parquet/pig/TestParquetLoader.java": 70
            },
            "is_test": true,
            "is_fix": false
        },
        "4ad7303dc25c998fbb23dacb5bcf950f89ef6a6f": {
            "datetime": "2014-07-10T16:08:48-07:00",
            "summary": "Minor fix",
            "message": "Minor fix\n\nSpell and comment issue.\n\nAuthor: WangTao <barneystinson@aliyun.com>\n\nCloses #10 from WangTaoTheTonic/minorFix and squashes the following commits:\n\n0727a8f [WangTao] Minor fix\n",
            "diff": {
                "parquet-column/src/main/java/parquet/schema/GroupType.java": 4,
                "parquet-column/src/main/java/parquet/schema/Type.java": 8
            },
            "is_test": false,
            "is_fix": false
        },
        "2d8ebdbe00786823658bcdd2817e6b5afee15b25": {
            "datetime": "2014-07-16T14:50:29+01:00",
            "summary": "PARQUET-9: Filtering records across multiple blocks",
            "message": "PARQUET-9: Filtering records across multiple blocks\n\nUpdate of the minimal fix discussed in https://github.com/apache/incubator-parquet-mr/pull/1, with the recursive call changed to to a loop.\n\nAuthor: Tom White <tom@cloudera.com>\nAuthor: Steven Willis <swillis@compete.com>\n\nCloses #9 from tomwhite/filtering-records-across-multiple-blocks and squashes the following commits:\n\nafb08a4 [Tom White] Minimal fix\n9e723ee [Steven Willis] Test for filtering records across multiple blocks\n",
            "diff": {
                "parquet-avro/src/test/java/parquet/avro/TestSpecificReadWrite.java": 52,
                "parquet-hadoop/src/main/java/parquet/hadoop/InternalParquetRecordReader.java": 14
            },
            "is_test": true,
            "is_fix": true
        },
        "5dffe3521588016cf3519792953b0879054c3bfd": {
            "datetime": "2014-07-18T16:02:09-07:00",
            "summary": "PARQUET-4: Use LRU caching for footers in ParquetInputFormat.",
            "message": "PARQUET-4: Use LRU caching for footers in ParquetInputFormat.\n\nReopening https://github.com/Parquet/parquet-mr/pull/403 against the new Apache repository.\n\nAuthor: Matthieu Martin <ma.tt.b.ma.rt.in+parquet@gmail.com>\n\nCloses #2 from matt-martin/master and squashes the following commits:\n\n99bb5a3 [Matthieu Martin] Minor javadoc and whitespace changes. Also added the FileStatusWrapper class to ParquetInputFormat to make sure that the debugging log statements print out meaningful paths.\n250a398 [Matthieu Martin] Be less aggressive about checking whether the underlying file has been appended to/overwritten/deleted in order to minimize the number of namenode interactions.\nd946445 [Matthieu Martin] Add javadocs to parquet.hadoop.LruCache.  Rename cache \"entries\" as cache \"values\" to avoid confusion with java.util.Map.Entry (which contains key value pairs whereas our old \"entries\" really only refer to the values).\na363622 [Matthieu Martin] Use LRU caching for footers in ParquetInputFormat.\n",
            "diff": {
                "parquet-hadoop/src/main/java/parquet/hadoop/LruCache.java": 181,
                "parquet-hadoop/src/main/java/parquet/hadoop/ParquetInputFormat.java": 145,
                "parquet-hadoop/src/test/java/parquet/hadoop/TestInputFormat.java": 52,
                "parquet-hadoop/src/test/java/parquet/hadoop/TestLruCache.java": 144
            },
            "is_test": true,
            "is_fix": true
        },
        "fb0104896815d55183f61c24b78c277dbae3987e": {
            "datetime": "2014-07-18T16:19:25-07:00",
            "summary": "PARQUET-18: Fix all-null value pages with dict encoding.",
            "message": "PARQUET-18: Fix all-null value pages with dict encoding.\n\nTestDictionary#testZeroValues demonstrates the problem, where a page of\nall null values is decoded using the DicitonaryValuesReader. Because\nthere are no non-null values, the page values section is 0 byte, but the\nDictionaryValuesReader assumes there is at least one encoded value and\nattempts to read a bit width. The test passes a byte array to\ninitFromPage with the offset equal to the array's length.\n\nThe fix is to detect that there are no input bytes to read. To avoid\nadding validity checks to the read path, this sets the internal decoder\nto one that will throw an exception if any reads are attempted.\n\nAuthor: Ryan Blue <rblue@cloudera.com>\n\nCloses #18 from rdblue/PARQUET-18-fix-nulls-with-dictionary and squashes the following commits:\n\n0711766 [Ryan Blue] PARQUET-18: Fix all-null value pages with dict encoding.\n",
            "diff": {
                "parquet-column/src/main/java/parquet/column/values/dictionary/DictionaryValuesReader.java": 19,
                "parquet-column/src/test/java/parquet/column/values/dictionary/TestDictionary.java": 14
            },
            "is_test": true,
            "is_fix": true
        },
        "f284238631cb1026b4977f6f0b7ef342260d35c5": {
            "datetime": "2014-07-18T18:35:12-07:00",
            "summary": "PARQUET-22: Backport of HIVE-6938 adding rename support for parquet",
            "message": "PARQUET-22: Backport of HIVE-6938 adding rename support for parquet\n\nThis patch was included in hive after the moving the Serde to hive (included in hive 0.14+).  Backport is required for use with previous versions.\n\nAuthor: Daniel Weeks <dweeks@netflix.com>\n\nCloses #13 from dcw-netflix/backport-hive-6938-rename and squashes the following commits:\n\n453367b [Daniel Weeks] Backport of HIVE-6938 adding rename support for parquet\n",
            "diff": {
                "parquet-hive/parquet-hive-storage-handler/src/main/java/org/apache/hadoop/hive/ql/io/parquet/read/DataWritableReadSupport.java": 31
            },
            "is_test": false,
            "is_fix": false
        },
        "4a07b3f545aaf60f0b1d6bba91ee22d214dfaff8": {
            "datetime": "2014-07-23T14:29:35+01:00",
            "summary": "PARQUET-25. Pushdown predicates only work with hardcoded arguments.",
            "message": "PARQUET-25. Pushdown predicates only work with hardcoded arguments.\n\nPull request for Sandy Ryza's fix for PARQUET-25.\n\nAuthor: Sandy Ryza <sandy.ryza@cloudera.com>\n\nCloses #22 from tomwhite/PARQUET-25-unbound-record-filter-configurable and squashes the following commits:\n\na9d3fdc [Sandy Ryza] PARQUET-25. Pushdown predicates only work with hardcoded arguments.\n",
            "diff": {
                "parquet-hadoop/src/main/java/parquet/hadoop/ParquetInputFormat.java": 12
            },
            "is_test": false,
            "is_fix": false
        },
        "17864dfc0711d52d5af330469a1c2bd76128d46e": {
            "datetime": "2014-07-28T18:07:07-07:00",
            "summary": "Column index access support",
            "message": "Column index access support\n\nThis patch adds the ability to use column index based access to parquet files in pig, which allows for rename capability similar to other file formats.  This is achieved by using the parametrized loader with an alternate schema.\n\nExample:\n# File Schema: {c1:int, c2:float, c3:chararray}\np = LOAD '/data/parquet/' USING parquet.pig.ParquetLoader('n1:int, n2:float, n3:chararray', 'true');\n\nIn this example, the names from the requested schema will be translated to the column positions from the file and will produce tuples based on the index position.\n\nTwo test cases are included that exercise index based access for both full file reads and column projected reads.\n\nNote:  This patch also disables the enforcer plugin on the pig project per discussion at the parquet meetup.  The justification for this is that the enforcer is too strict for internal classes and results in dead code because duplicating methods is required to add parameters where there is only one usage of the constructor/method.  The interface for the pig loader is imposed by LoadFunc and StoreFunc by the pig project and the implementations internals should not be used directly.\n\nAuthor: Daniel Weeks <dweeks@netflix.com>\n\nCloses #12 from dcw-netflix/column-index-access and squashes the following commits:\n\n1b5c5cf [Daniel Weeks] Refactored based on rewview comments\n12b53c1 [Daniel Weeks] Fixed some formatting and the missing filter method sig\ne5553f1 [Daniel Weeks] Adding back default constructor to satisfy other project requirements\n69d21e0 [Daniel Weeks] Merge branch 'master' into column-index-access\nf725c6f [Daniel Weeks] Removed enforcer for pig support\nd182dc6 [Daniel Weeks] Introduces column index access\n1c3c0c7 [Daniel Weeks] Fixed test with strict checking off\nf3cb495 [Daniel Weeks] Added type persuasion for primitive types with a flag to control strict type checking for conflicting schemas, which is strict by default.\n",
            "diff": {
                "parquet-pig/src/main/java/parquet/pig/ParquetLoader.java": 55,
                "parquet-pig/src/main/java/parquet/pig/PigSchemaConverter.java": 128,
                "parquet-pig/src/main/java/parquet/pig/TupleReadSupport.java": 43,
                "parquet-pig/src/main/java/parquet/pig/TupleWriteSupport.java": 2,
                "parquet-pig/src/main/java/parquet/pig/convert/MapConverter.java": 10,
                "parquet-pig/src/main/java/parquet/pig/convert/TupleConverter.java": 37,
                "parquet-pig/src/main/java/parquet/pig/convert/TupleRecordMaterializer.java": 6,
                "parquet-pig/src/test/java/parquet/pig/TestParquetLoader.java": 74,
                "parquet-pig/src/test/java/parquet/pig/TestPigSchemaConverter.java": 2
            },
            "is_test": true,
            "is_fix": false
        },
        "fc2c29df71c8455346a00b43dd1c4f118c335d2c": {
            "datetime": "2014-07-29T10:15:42-07:00",
            "summary": "PARQUET-19: Fix NPE when an empty file is included in a Hive query that uses CombineHiveInputFormat",
            "message": "PARQUET-19: Fix NPE when an empty file is included in a Hive query that uses CombineHiveInputFormat\n\nMake sure the valueObj instance variable is always initialized.  This change is neeeded when running a Hive query that uses the CombineHiveInputFormat and the first file in the combined split is empty.  This can lead to a NullPointerException because the valueObj is null when the CombineHiveInputFormat calls the createValue method.\n\nAuthor: Matthieu Martin <ma.tt.b.ma.rt.in+parquet@gmail.com>\n\nCloses #19 from matt-martin/fix_for_empty_files_NPE_with_CombineHiveInputFormat and squashes the following commits:\n\n6c3a7f5 [Matthieu Martin] Make sure the valueObj instance variable is always initialized.  This change is neeeded when running a Hive query that uses the CombineHiveInputFormat and the first file in the combined split is empty.  This can lead to a NullPointerException because the valueObj is null when the CombineHiveInputFormat calls the createValue method.\n",
            "diff": {
                "parquet-hive/parquet-hive-storage-handler/src/main/java/org/apache/hadoop/hive/ql/io/parquet/read/ParquetRecordReaderWrapper.java": 6
            },
            "is_test": false,
            "is_fix": false
        },
        "ad32bf0fd111ab473ad1080cde11de39e3c5a67f": {
            "datetime": "2014-07-29T14:38:59-07:00",
            "summary": "Add a unified and optionally more constrained API for expressing filters on columns",
            "message": "Add a unified and optionally more constrained API for expressing filters on columns\n\nThis is a re-opened version of:\nhttps://github.com/Parquet/parquet-mr/pull/412\n\nThe idea behind this pull request is to add a way to express filters on columns using DSL that allows parquet visibility into what is being filtered and how. This visibility will allow us to make optimizations at read time, the biggest one being filtering entire row groups or pages of records without even reading them based on the statistics / metadata that is stored along with each row group or page.\n\nIncluded in this api are interfaces for user defined predicates, which must operate at the value level by may opt in to operating at the row group / page level as well. This should make this new API a superset of the `parquet.filter` package. This new api will need to be reconciled with the column filters currently in the `parquet.filter` package, but I wanted to get feedback on this first.\n\nA limitation in both this api and the old one is that you can't do cross-column filters, eg: columX > columnY.\n\nAuthor: Alex Levenson <alexlevenson@twitter.com>\n\nCloses #4 from isnotinvain/alexlevenson/filter-api and squashes the following commits:\n\nc1ab7e3 [Alex Levenson] Address feedback\nc1bd610 [Alex Levenson] cleanup dotString in ColumnPath\n418bfc1 [Alex Levenson] Update version, add temporary hacks for semantic enforcer\n6643bd3 [Alex Levenson] Fix some more non backward incompatible changes\n39f977f [Alex Levenson] Put a bunch of backwards compatible stuff back in, add @Deprecated\n13a02c6 [Alex Levenson] Fix compile errors, add back in overloaded getRecordReader\nf82edb7 [Alex Levenson] Merge branch 'master' into alexlevenson/filter-api\n9bd014f [Alex Levenson] clean up TODOs and reference jiras\n4cc7e87 [Alex Levenson] Add some comments\n30e3d61 [Alex Levenson] Create a common interface for both kinds of filters\nac153a6 [Alex Levenson] Create a Statistics class for use in UDPs\nfbbf601 [Alex Levenson] refactor IncrementallyUpdatedFilterPredicateGenerator to only generate the parts that require generation\n5df47cd [Alex Levenson] Static imports of checkNotNull\nc1d1823 [Alex Levenson] address some of the minor feedback items\n67a3ba0 [Alex Levenson] update binary's toString\n3d7372b [Alex Levenson] minor fixes\nfed9531 [Alex Levenson] Add skipCurrentRecord method to clear events in thrift converter\n2e632d5 [Alex Levenson] Make Binary Serializable\n09c024f [Alex Levenson] update comments\n3169849 [Alex Levenson] fix compilation error\n0185030 [Alex Levenson] Add integration test for value level filters\n4fde18c [Alex Levenson] move to right package\nae36b37 [Alex Levenson] Handle merge issues\naf69486 [Alex Levenson] Merge branch 'master' into alexlevenson/filter-api\n0665271 [Alex Levenson] Add tests for value inspector\nc5e3b07 [Alex Levenson] Add tests for resetter and evaluator\n29f677a [Alex Levenson] Fix scala DSL\n8897a28 [Alex Levenson] Fix some tests\nb448bee [Alex Levenson] Fix mistake in MessageColumnIO\nc8133f8 [Alex Levenson] Fix some tests\n4cf686d [Alex Levenson] more null checks\n69e683b [Alex Levenson] check all the nulls\n220a682 [Alex Levenson] more cleanup\naad5af3 [Alex Levenson] rm generated src file from git\n5075243 [Alex Levenson] more minor cleanup\n9966713 [Alex Levenson] Hook generation into maven build\n8282725 [Alex Levenson] minor cleanup\nfea3ea9 [Alex Levenson] minor cleanup\n9e35406 [Alex Levenson] move statistics filter\nc52750c [Alex Levenson] finish moving things around\n97a6bfd [Alex Levenson] Move things around pt2\n843b9fe [Alex Levenson] Move some files around pt 1\n5eedcc0 [Alex Levenson] turn off dictionary support for AtomicConverter\n541319e [Alex Levenson] various cleanup and fixes\n08e9638 [Alex Levenson] rm ColumnPathUtil\nbfe6795 [Alex Levenson] Add type bounds to FilterApi\n6c831ab [Alex Levenson] don't double log exception in SerializationUtil\na7a58d1 [Alex Levenson] use ColumnPath instead of String\n8f11a6b [Alex Levenson] Move ColumnPath and Canonicalizer to parquet-common\n9164359 [Alex Levenson] stash\nabc2be2 [Alex Levenson] Add null handling to record filters -- this impl is still broken though\n90ba8f7 [Alex Levenson] Update Serialization Util\n0a261f1 [Alex Levenson] Add compression in SerializationUtil\nf1278be [Alex Levenson] Add comment, fix tests\ncbd1a85 [Alex Levenson] Replace some specialization with generic views\ne496cbf [Alex Levenson] Fix short circuiting in StatisticsFilter\ndb6b32d [Alex Levenson] Address some comments, fix constructor in ParquetReader\nfd6f44d [Alex Levenson] Fix semver backward compat\n2fdd304 [Alex Levenson] Some more cleanup\nd34fb89 [Alex Levenson] Cleanup some TODOs\n544499c [Alex Levenson] stash\n7b32016 [Alex Levenson] Merge branch 'master' into alexlevenson/filter-api\n0e31251 [Alex Levenson] First pass at values filter, needs reworking\n470e409 [Alex Levenson] fix java6/7 bug, minor cleanup\nee7b221 [Alex Levenson] more InputFormat tests\n5ef849e [Alex Levenson] Add guards for not specifying both kinds of filter\n0186b1f [Alex Levenson] Add logging to ParquetInputFormat and tests for configuration\na622648 [Alex Levenson] cleanup imports\n9b1ea88 [Alex Levenson] Add tests for statistics filter\nd517373 [Alex Levenson] tests for filter validator\nb25fc44 [Alex Levenson] small cleanup of filter validator\n32067a1 [Alex Levenson] add test for collapse logical nots\n1efc198 [Alex Levenson] Add tests for invert filter predicate\n046b106 [Alex Levenson] some more fixes\nd3c4d7a [Alex Levenson] fix some more types, add in test for SerializationUtil\ncc51274 [Alex Levenson] fix generics in FilterPredicateInverter\nea08349 [Alex Levenson] First pass at rowgroup filter, needs testing\n156d91b [Alex Levenson] Add runtime type checker\n4dfb4f2 [Alex Levenson] Add serialization util\n8f80b20 [Alex Levenson] update comment\n7c25121 [Alex Levenson] Add class to Column struct\n58f1190 [Alex Levenson] Remove filterByUniqueValues\n7f20de6 [Alex Levenson] rename user predicates\naf14b42 [Alex Levenson] Update dsl\n04409c5 [Alex Levenson] Add generic types into Visitor\nba42884 [Alex Levenson] rm getClassName\n65f8af9 [Alex Levenson] Add in support for user defined predicates on columns\n6926337 [Alex Levenson] Add explicit tokens for notEq, ltEq, gtEq\n667ec9f [Alex Levenson] remove test for collapsing double negation\ndb2f71a [Alex Levenson] rename FilterPredicatesTest\na0a0533 [Alex Levenson] Address first round of comments\nb2bca94 [Alex Levenson] Add scala DSL and tests\nbedda87 [Alex Levenson] Add tests for FilterPredicate building\n238cbbe [Alex Levenson] Add scala dsl\n39f7b24 [Alex Levenson] add scala mvn boilerplate\n2ec71a7 [Alex Levenson] Add predicate API\n",
            "diff": {
                "parquet-avro/src/main/java/parquet/avro/AvroParquetReader.java": 39,
                "parquet-column/src/main/java/parquet/column/statistics/BinaryStatistics.java": 12,
                "parquet-column/src/main/java/parquet/column/statistics/BooleanStatistics.java": 12,
                "parquet-column/src/main/java/parquet/column/statistics/DoubleStatistics.java": 12,
                "parquet-column/src/main/java/parquet/column/statistics/FloatStatistics.java": 12,
                "parquet-column/src/main/java/parquet/column/statistics/IntStatistics.java": 12,
                "parquet-column/src/main/java/parquet/column/statistics/LongStatistics.java": 12,
                "parquet-column/src/main/java/parquet/column/statistics/Statistics.java": 5,
                "parquet-column/src/main/java/parquet/filter2/compat/FilterCompat.java": 140,
                "parquet-column/src/main/java/parquet/filter2/predicate/FilterApi.java": 177,
                "parquet-column/src/main/java/parquet/filter2/predicate/FilterPredicate.java": 54,
                "parquet-column/src/main/java/parquet/filter2/predicate/LogicalInverseRewriter.java": 95,
                "parquet-column/src/main/java/parquet/filter2/predicate/LogicalInverter.java": 90,
                "parquet-column/src/main/java/parquet/filter2/predicate/Operators.java": 455,
                "parquet-column/src/main/java/parquet/filter2/predicate/SchemaCompatibilityValidator.java": 172,
                "parquet-column/src/main/java/parquet/filter2/predicate/Statistics.java": 24,
                "parquet-column/src/main/java/parquet/filter2/predicate/UserDefinedPredicate.java": 90,
                "parquet-column/src/main/java/parquet/filter2/predicate/ValidTypeMap.java": 160,
                "parquet-column/src/main/java/parquet/filter2/recordlevel/FilteringGroupConverter.java": 97,
                "parquet-column/src/main/java/parquet/filter2/recordlevel/FilteringPrimitiveConverter.java": 91,
                "parquet-column/src/main/java/parquet/filter2/recordlevel/FilteringRecordMaterializer.java": 97,
                "parquet-column/src/main/java/parquet/filter2/recordlevel/IncrementallyUpdatedFilterPredicate.java": 139,
                "parquet-column/src/main/java/parquet/filter2/recordlevel/IncrementallyUpdatedFilterPredicateBuilderBase.java": 79,
                "parquet-column/src/main/java/parquet/filter2/recordlevel/IncrementallyUpdatedFilterPredicateEvaluator.java": 45,
                "parquet-column/src/main/java/parquet/filter2/recordlevel/IncrementallyUpdatedFilterPredicateResetter.java": 42,
                "parquet-column/src/main/java/parquet/io/FilteredRecordReader.java": 6,
                "parquet-column/src/main/java/parquet/io/MessageColumnIO.java": 98,
                "parquet-column/src/main/java/parquet/io/RecordReader.java": 9,
                "parquet-column/src/main/java/parquet/io/RecordReaderImplementation.java": 14,
                "parquet-column/src/main/java/parquet/io/api/Binary.java": 514,
                "parquet-column/src/main/java/parquet/io/api/RecordMaterializer.java": 5,
                "parquet-column/src/test/java/parquet/filter2/predicate/DummyUdp.java": 19,
                "parquet-column/src/test/java/parquet/filter2/predicate/TestFilterApiMethods.java": 103,
                "parquet-column/src/test/java/parquet/filter2/predicate/TestLogicalInverseRewriter.java": 85,
                "parquet-column/src/test/java/parquet/filter2/predicate/TestLogicalInverter.java": 76,
                "parquet-column/src/test/java/parquet/filter2/predicate/TestSchemaCompatibilityValidator.java": 124,
                "parquet-column/src/test/java/parquet/filter2/predicate/TestValidTypeMap.java": 93,
                "parquet-column/src/test/java/parquet/filter2/recordlevel/TestIncrementallyUpdatedFilterPredicateEvaluator.java": 191,
                "parquet-column/src/test/java/parquet/filter2/recordlevel/TestIncrementallyUpdatedFilterPredicateResetter.java": 51,
                "parquet-column/src/test/java/parquet/filter2/recordlevel/TestValueInspector.java": 79,
                "parquet-column/src/test/java/parquet/io/TestFiltered.java": 62,
                "parquet-common/src/main/java/parquet/Closeables.java": 37,
                "parquet-generator/src/main/java/parquet/encoding/Generator.java": 2,
                "parquet-generator/src/main/java/parquet/filter2/Generator.java": 10,
                "parquet-generator/src/main/java/parquet/filter2/IncrementallyUpdatedFilterPredicateGenerator.java": 251,
                "parquet-hadoop/src/main/java/parquet/filter2/compat/RowGroupFilter.java": 63,
                "parquet-hadoop/src/main/java/parquet/filter2/statisticslevel/StatisticsFilter.java": 244,
                "parquet-hadoop/src/main/java/parquet/format/converter/ParquetMetadataConverter.java": 12,
                "parquet-hadoop/src/main/java/parquet/hadoop/InternalParquetRecordReader.java": 61,
                "parquet-hadoop/src/main/java/parquet/hadoop/ParquetFileReader.java": 12,
                "parquet-hadoop/src/main/java/parquet/hadoop/ParquetFileWriter.java": 8,
                "parquet-hadoop/src/main/java/parquet/hadoop/ParquetInputFormat.java": 118,
                "parquet-hadoop/src/main/java/parquet/hadoop/ParquetInputSplit.java": 2,
                "parquet-hadoop/src/main/java/parquet/hadoop/ParquetReader.java": 96,
                "parquet-hadoop/src/main/java/parquet/hadoop/ParquetRecordReader.java": 24,
                "parquet-hadoop/src/main/java/parquet/hadoop/ParquetWriter.java": 13,
                "parquet-hadoop/src/main/java/parquet/hadoop/mapred/DeprecatedParquetInputFormat.java": 13,
                "parquet-hadoop/src/main/java/parquet/hadoop/metadata/Canonicalizer.java": 2,
                "parquet-hadoop/src/main/java/parquet/hadoop/metadata/ColumnChunkMetaData.java": 3,
                "parquet-hadoop/src/main/java/parquet/hadoop/metadata/ColumnChunkProperties.java": 2,
                "parquet-hadoop/src/main/java/parquet/hadoop/metadata/ColumnPath.java": 27,
                "parquet-hadoop/src/main/java/parquet/hadoop/metadata/EncodingList.java": 1,
                "parquet-hadoop/src/main/java/parquet/hadoop/util/SerializationUtil.java": 93,
                "parquet-hadoop/src/test/java/parquet/filter2/compat/TestRowGroupFilter.java": 84,
                "parquet-hadoop/src/test/java/parquet/filter2/recordlevel/PhoneBookWriter.java": 251,
                "parquet-hadoop/src/test/java/parquet/filter2/recordlevel/TestRecordLevelFilters.java": 205,
                "parquet-hadoop/src/test/java/parquet/filter2/statisticslevel/TestStatisticsFilter.java": 307,
                "parquet-hadoop/src/test/java/parquet/hadoop/TestInputFormat.java": 110,
                "parquet-hadoop/src/test/java/parquet/hadoop/metadata/TestColumnChunkMetaData.java": 9,
                "parquet-hadoop/src/test/java/parquet/hadoop/util/TestSerializationUtil.java": 53,
                "parquet-protobuf/src/main/java/parquet/proto/ProtoParquetReader.java": 23,
                "parquet-thrift/src/main/java/parquet/thrift/ThriftParquetReader.java": 64,
                "parquet-thrift/src/main/java/parquet/thrift/ThriftRecordConverter.java": 5,
                "parquet-tools/src/main/java/parquet/tools/command/DumpCommand.java": 1
            },
            "is_test": true,
            "is_fix": false
        },
        "b0e26ee6f20a00a0d0769408575744c51a016018": {
            "datetime": "2014-07-30T13:49:00-07:00",
            "summary": "Only call put() when needed in SchemaCompatibilityValidator#validateColumn()",
            "message": "Only call put() when needed in SchemaCompatibilityValidator#validateColumn()\n\nThis is some minor cleanup suggested by @tsdeng\n\nAuthor: Alex Levenson <alexlevenson@twitter.com>\n\nCloses #24 from isnotinvain/alexlevenson/columnTypesEncountered and squashes the following commits:\n\n7f05d90 [Alex Levenson] Only call put() when needed in SchemaCompatibilityValidator#validateColumn()\n",
            "diff": {
                "parquet-column/src/main/java/parquet/filter2/predicate/SchemaCompatibilityValidator.java": 5
            },
            "is_test": false,
            "is_fix": false
        },
        "21d871b54940ad8e552fac54808fe0b31872ade8": {
            "datetime": "2014-07-30T14:19:00-07:00",
            "summary": "PARQUET-56: Added an accessor for the Long column type.",
            "message": "PARQUET-56: Added an accessor for the Long column type.\n\nI noticed there was a missing accessor for the Long column type in the example Group.\n\nAuthor: James Scott <jim.scott@urbanairship.com>\n\nCloses #25 from scottjab/getLong and squashes the following commits:\n\nf96bb83 [James Scott] Added support for getting Longs in the sample group object.\n",
            "diff": {
                "parquet-column/src/main/java/parquet/example/data/GroupValueSource.java": 6,
                "parquet-column/src/main/java/parquet/example/data/simple/SimpleGroup.java": 5
            },
            "is_test": false,
            "is_fix": false
        },
        "0793e49b85d34135fee9f55030997d95f62af97b": {
            "datetime": "2014-07-31T14:57:54-07:00",
            "summary": "PARQUET-57 - Update dev README to clarify two points",
            "message": "PARQUET-57 - Update dev README to clarify two points\n\nAuthor: Brock Noland <brock@apache.org>\n\nCloses #26 from brockn/PARQUET-57 and squashes the following commits:\n\nffb2a9a [Brock Noland] Prompt for jira user/pass if not set\n0135cdd [Brock Noland] Fix spelling\n171d714 [Brock Noland] PARQUET-57 - Update dev README to clarify two points\n",
            "diff": {
                "dev/merge_parquet_pr.py": 10
            },
            "is_test": false,
            "is_fix": false
        },
        "0148455170be07f89bd6b9230960a6cd510c7ca6": {
            "datetime": "2014-08-01T16:38:03-07:00",
            "summary": "PARQUET-13: The `-d` option for `parquet-schema` shouldn't have optional argument",
            "message": "PARQUET-13: The `-d` option for `parquet-schema` shouldn't have optional argument\n\nAuthor: Cheng Lian <lian.cs.zju@gmail.com>\n\nCloses #11 from liancheng/fix-cli-arg and squashes the following commits:\n\n85a5453 [Cheng Lian] Reverted the dummy change\n47ce817 [Cheng Lian] Dummy change to trigger Travis\n1c0a244 [Cheng Lian] The `-d` option for `parquet-schema` shouldn't have optional argument\n",
            "diff": {
                "parquet-tools/src/main/java/parquet/tools/command/ShowSchemaCommand.java": 1
            },
            "is_test": false,
            "is_fix": false
        },
        "3a396d3a4000bd2575e5314cdea0ba1e2367804c": {
            "datetime": "2014-08-04T19:04:18-07:00",
            "summary": "PARQUET-59: Fix parquet-scrooge test on hadoop-2.",
            "message": "PARQUET-59: Fix parquet-scrooge test on hadoop-2.\n\nAuthor: Ryan Blue <rblue@cloudera.com>\n\nCloses #27 from rdblue/PARQUET-59-fix-scrooge-test-on-hadoop-2 and squashes the following commits:\n\nac34369 [Ryan Blue] PARQUET-59: Fix parquet-scrooge test on hadoop-2.\n",
            "diff": {
                "parquet-scrooge/src/test/java/parquet/scrooge/ParquetScroogeSchemeTest.java": 4
            },
            "is_test": true,
            "is_fix": true
        },
        "0d497c4547934485f2aa9e2e9ead46f26fab7bd2": {
            "datetime": "2014-08-18T10:38:11-07:00",
            "summary": "PARQUET-73: Add support for FilterPredicates to cascading schemes",
            "message": "PARQUET-73: Add support for FilterPredicates to cascading schemes\n\nAuthor: Alex Levenson <alexlevenson@twitter.com>\n\nCloses #34 from isnotinvain/alexlevenson/filter-cascading-scheme and squashes the following commits:\n\ncd69a8e [Alex Levenson] Add support for FilterPredicates to cascading schemes\n",
            "diff": {
                "parquet-cascading/src/main/java/parquet/cascading/ParquetTBaseScheme.java": 16,
                "parquet-cascading/src/main/java/parquet/cascading/ParquetTupleScheme.java": 69,
                "parquet-cascading/src/main/java/parquet/cascading/ParquetValueScheme.java": 27,
                "parquet-scrooge/src/main/java/parquet/scrooge/ParquetScroogeScheme.java": 16
            },
            "is_test": false,
            "is_fix": false
        },
        "7b415faaed09eba1103ea30577ef1a32fba7048c": {
            "datetime": "2014-08-20T13:52:42-07:00",
            "summary": "Parquet-70: Fixed storing pig schema to udfcontext for non projection case and moved...",
            "message": "Parquet-70: Fixed storing pig schema to udfcontext for non projection case and moved...\n\n... column index access setting to udfcontext so as not to affect other loaders.\n\nI found an problem that affects both the Column name access and column index access due to the way the pig schema is stored by the loader.\n\n##Column Name Access:\nThe ParquetLoader was only storing the pig schema in the UDFContext when push projection is applied.  In the full load case, the schema was not stored which triggered a full reload of the schema during task execution.  You can see in initSchema references the UDFContext for the schema, but that is only set in push projection.  However, the schema needs to be set in both the job context (so the TupleReadSupport can access the schema) and the UDFContext (so the task side loader can access it), which is why it is set in both locations.  This also meant the requested schema was never set to the task side either, which could cause other problems as well.\n\n##Column Index Access:\nFor index based access, the problem was that the column index access setting and the requested schema were not stored in the udfcontext and sent to the task side (unless pushProjection was called).  The schema was stored in the job context, but this would be overwritten if another loader was executed first.  Also, the property to use column index access was only being set at the job context level, so subsequent loaders would use column index access even if they didn't request it.\n\nThis fix now ensures that both the schema and column index access are set in the udfcontext and loaded in the initSchema method.\n\nJIRA: https://issues.apache.org/jira/browse/PARQUET-70\n\n-Dan\n\nAuthor: Daniel Weeks <dweeks@netflix.com>\n\nCloses #36 from dcw-netflix/pig-schema-context and squashes the following commits:\n\nf896a25 [Daniel Weeks] Moved property loading into setInput\n8f3dc28 [Daniel Weeks] Changed to set job conf settings in both front and backend\nd758de0 [Daniel Weeks] Updated to use isFrontend() for setting context properties\nb7ef96a [Daniel Weeks] Fixed storing pig schema to udfcontext for non projection case and moved column index access setting to udfcontext so as not to affect other loaders.\n",
            "diff": {
                "parquet-pig/src/main/java/parquet/pig/ParquetLoader.java": 35
            },
            "is_test": false,
            "is_fix": false
        },
        "54bb983271adcbcc1519ab9e2288871d69093708": {
            "datetime": "2014-08-20T14:02:01-07:00",
            "summary": "PARQUET-62: Fix binary dictionary write bug.",
            "message": "PARQUET-62: Fix binary dictionary write bug.\n\nThe binary dictionary writers keep track of written values in memory to\ndeduplicate and write dictionary pages periodically. If the written\nvalues are changed by the caller, then this corrupts the dictionary\nwithout an error message. This adds a defensive copy to fix the problem.\n\nAuthor: Ryan Blue <rblue@cloudera.com>\n\nCloses #29 from rdblue/PARQUET-62-fix-dictionary-bug and squashes the following commits:\n\n42b6920 [Ryan Blue] PARQUET-62: Fix binary dictionary write bug.\n",
            "diff": {
                "parquet-column/src/main/java/parquet/column/values/dictionary/DictionaryValuesWriter.java": 10,
                "parquet-column/src/test/java/parquet/column/values/dictionary/TestDictionary.java": 31
            },
            "is_test": true,
            "is_fix": true
        },
        "792b1490db122e953c9120279ddc86407ffae3c0": {
            "datetime": "2014-08-20T14:09:28-07:00",
            "summary": "PARQUET-67: mechanism to add extra metadata in the footer",
            "message": "PARQUET-67: mechanism to add extra metadata in the footer\n\nthis expands on the idea proposed by @wesleypeck in https://github.com/Parquet/parquet-mr/pull/185\n\nAuthor: julien <julien@twitter.com>\n\nCloses #32 from julienledem/extensible_metadata and squashes the following commits:\n\n72e0a50 [julien] mechanism to add extra metadata in the footer\n",
            "diff": {
                "parquet-hadoop/src/main/java/parquet/hadoop/InternalParquetRecordWriter.java": 7,
                "parquet-hadoop/src/main/java/parquet/hadoop/ParquetOutputFormat.java": 9,
                "parquet-hadoop/src/main/java/parquet/hadoop/api/DelegatingReadSupport.java": 44,
                "parquet-hadoop/src/main/java/parquet/hadoop/api/DelegatingWriteSupport.java": 48,
                "parquet-hadoop/src/main/java/parquet/hadoop/api/WriteSupport.java": 53,
                "parquet-hadoop/src/test/java/parquet/hadoop/example/TestInputOutputFormat.java": 76
            },
            "is_test": true,
            "is_fix": false
        },
        "84ebe4c82405895706552ccf1becf6647886663f": {
            "datetime": "2014-08-20T14:09:38-07:00",
            "summary": "PARQUET-66: Upcast blockSize to long to prevent integer overflow.",
            "message": "PARQUET-66: Upcast blockSize to long to prevent integer overflow.\n\nAuthor: Eric Snyder <snyderep@gmail.com>\n\nCloses #33 from snyderep/master and squashes the following commits:\n\nc99802e [Eric Snyder] PARQUET-66: Upcast blockSize to long to prevent integer overflow.\n",
            "diff": {
                "parquet-hadoop/src/main/java/parquet/hadoop/InternalParquetRecordWriter.java": 2
            },
            "is_test": false,
            "is_fix": false
        }
    },
    "2014-08-21T15:17:05-07:00": {
        "02abe096f293608906d0f06708bfece92156b49a": {
            "datetime": "2014-08-22T15:34:48-07:00",
            "summary": "PARQUET-11: Reduce memory pressure when reading footers",
            "message": "PARQUET-11: Reduce memory pressure when reading footers\n\nbased on https://github.com/apache/incubator-parquet-format/pull/2\n\nAuthor: julien <julien@twitter.com>\nAuthor: Dmitriy Ryaboy <dvryaboy@gmail.com>\n\nCloses #7 from julienledem/reduce_metadata_memory and squashes the following commits:\n\n96ff408 [julien] Merge branch 'master' into reduce_metadata_memory\n1c382cc [julien] implement delegate instead\n7664919 [Dmitriy Ryaboy] intern parquet metadata strings when reading them\n",
            "diff": {
                "src/main/java/parquet/format/InterningProtocol.java": 215,
                "src/main/java/parquet/format/Util.java": 13
            },
            "is_test": false,
            "is_fix": false
        },
        "d3cd97a8ad7f1c1df48bf42080d993b861158786": {
            "datetime": "2014-08-28T11:30:50-07:00",
            "summary": "PARQUET-75: Fixed string decode performance issue",
            "message": "PARQUET-75: Fixed string decode performance issue\n\nSwitch to using 'UTF8.decode' as opposed to 'new String'\n\nhttps://issues.apache.org/jira/browse/PARQUET-75\n\nAuthor: Daniel Weeks <dweeks@netflix.com>\n\nCloses #40 from dcw-netflix/string-decode and squashes the following commits:\n\n2cf53e7 [Daniel Weeks] Fixed string decode performance issue\n",
            "diff": {
                "parquet-column/src/main/java/parquet/io/api/Binary.java": 4
            },
            "is_test": false,
            "is_fix": false
        },
        "97964f357e9e6e6eb37fbb83acebf434cd2d7d45": {
            "datetime": "2014-08-29T17:33:19-07:00",
            "summary": "PARQUET-79: add a streaming Thrift API, to enable processing the metadata as we read it and skipping unnecessary fields.",
            "message": "PARQUET-79: add a streaming Thrift API, to enable processing the metadata as we read it and skipping unnecessary fields.\n\nThis pull request provides an API to read thrift in a streaming fashion.\nThis enables ignoring fields that are not needed without loading them into memory.\nIt also aloow treating the data as it comes instead of when it's fully loaded in memory.\n\nAuthor: julien <julien@twitter.com>\n\nCloses #8 from julienledem/streaming_metadata and squashes the following commits:\n\n621769a [julien] cleanup refactoring\na58913d [julien] rename add to consume\ne5c78fc [julien] #simplify\ncb386ce [julien] RIP TypedConsumerProvider, @tsdeng did not like you\n8dd801e [julien] Merge branch 'master' into streaming_metadata\n958726f [julien] javadoc; fix apis\n9be786a [julien] added simple readMetaData method\nbee937a [julien] refactor, cleanup\n6368bdc [julien] streaming thrift reader\n71c85de [julien] first stab\n",
            "diff": {
                "src/main/java/parquet/format/Util.java": 142,
                "src/main/java/parquet/format/event/Consumers.java": 181,
                "src/main/java/parquet/format/event/EventBasedThriftReader.java": 111,
                "src/main/java/parquet/format/event/FieldConsumer.java": 25,
                "src/main/java/parquet/format/event/TypedConsumer.java": 186,
                "src/test/java/parquet/format/TestUtil.java": 65
            },
            "is_test": true,
            "is_fix": false
        },
        "78de104a807504a3597d8c00f0771b42c1a8b810": {
            "datetime": "2014-09-02T17:09:31-07:00",
            "summary": "PARQUET-72: Prepare for Apache release",
            "message": "PARQUET-72: Prepare for Apache release\n\nAdd license headers and other documentation required by the ASF.\n\nThis doesn't update the maven release configuration.\n\nAuthor: Ryan Blue <rblue@cloudera.com>\n\nCloses #6 from rdblue/PARQUET-72-prepare-apache-release and squashes the following commits:\n\ne48a607 [Ryan Blue] Adding NOTICE, DISCLAIMER, and KEYS.\n3d2ca06 [Ryan Blue] Add license headers and enable apache-rat-plugin.\n",
            "diff": {
                "src/main/java/parquet/format/InterningProtocol.java": 19,
                "src/main/java/parquet/format/Util.java": 19
            },
            "is_test": false,
            "is_fix": false
        },
        "f6608e6d64e1fdb2bff7b3957dc06c7aad58b5f0": {
            "datetime": "2014-09-03T09:00:15-07:00",
            "summary": "PARQUET-85: add license headers",
            "message": "PARQUET-85: add license headers\n\nAuthor: julien <julien@twitter.com>\n\nCloses #10 from julienledem/fix_headers and squashes the following commits:\n\ne6922a0 [julien] add license headers\n",
            "diff": {
                "src/main/java/parquet/format/event/Consumers.java": 18,
                "src/main/java/parquet/format/event/EventBasedThriftReader.java": 18,
                "src/main/java/parquet/format/event/FieldConsumer.java": 18,
                "src/main/java/parquet/format/event/TypedConsumer.java": 18,
                "src/test/java/parquet/format/TestUtil.java": 18
            },
            "is_test": true,
            "is_fix": true
        },
        "f8b06df7a56f92f4bc7dd564ad7ec026e3b4f3da": {
            "datetime": "2014-09-03T15:37:00-07:00",
            "summary": "do ProtocolEvents fixing only when there is required fields missing in the requested schema",
            "message": "do ProtocolEvents fixing only when there is required fields missing in the requested schema\n\nhttps://issues.apache.org/jira/browse/PARQUET-61\nThis PR is trying to redo the https://github.com/apache/incubator-parquet-mr/pull/7\n\nIn this PR, it fixes the protocol event in a more precise condition:\nOnly when the requested schema missing some required fields that are present in the full schema\n\nSo even if there a projection, as long as the projection is not getting rid of the required field, the protocol events amender will not be called.\n\nCould you take a look at this ? @dvryaboy @yan-qi\n\nAuthor: Tianshuo Deng <tdeng@twitter.com>\n\nCloses #28 from tsdeng/fix_protocol_when_required_field_missing and squashes the following commits:\n\nba778b9 [Tianshuo Deng] add continue for readability\nd5639df [Tianshuo Deng] fix unused import\n090e894 [Tianshuo Deng] format\n13a609d [Tianshuo Deng] comment format\nef1fe58 [Tianshuo Deng] little refactor, remove the hasMissingRequiredFieldFromProjection method\n7c2c158 [Tianshuo Deng] format\n83a5655 [Tianshuo Deng] do ProtocolEvents fixing only when there is required fields missing in the requested schema\n",
            "diff": {
                "parquet-thrift/src/main/java/parquet/thrift/ThriftRecordConverter.java": 37
            },
            "is_test": false,
            "is_fix": false
        },
        "647b8a70f9b7c94cabf9a7ec7bce2e7cbbb4c05b": {
            "datetime": "2014-09-04T11:28:03-07:00",
            "summary": "PARQUET-63: Enable dictionary encoding for FIXED.",
            "message": "PARQUET-63: Enable dictionary encoding for FIXED.\n\nThis uses the existing dictionary support introduced for int96. Encoding\nand ParquetProperties have been updated to use the dictionary supporting\nclasses, when requested for write or present during read. This also\nfixes a bug in the fixed dictionary values writer, where the length was\nhard-coded for int96, 12 bytes.\n\nAuthor: Ryan Blue <rblue@cloudera.com>\n\nCloses #30 from rdblue/PARQUET-63-add-fixed-dictionary-support and squashes the following commits:\n\nbc34a34 [Ryan Blue] PARQUET-63: Enable dictionary encoding for FIXED.\n",
            "diff": {
                "parquet-column/src/main/java/parquet/column/Encoding.java": 3,
                "parquet-column/src/main/java/parquet/column/ParquetProperties.java": 6,
                "parquet-column/src/main/java/parquet/column/values/dictionary/DictionaryValuesWriter.java": 2,
                "parquet-column/src/main/java/parquet/example/data/simple/SimpleGroup.java": 1,
                "parquet-column/src/main/java/parquet/io/ValidatingRecordConsumer.java": 39,
                "parquet-column/src/test/java/parquet/io/TestColumnIO.java": 4
            },
            "is_test": true,
            "is_fix": true
        },
        "5dafd127f3de7c516ce9c1b7329087a01ab2fc57": {
            "datetime": "2014-09-05T11:32:46-07:00",
            "summary": "PARQUET-84: Avoid reading rowgroup metadata in memory on the client side.",
            "message": "PARQUET-84: Avoid reading rowgroup metadata in memory on the client side.\n\nThis will improve reading big datasets with a large schema (thousands of columns)\nInstead rowgroup metadata can be read in the tasks where each tasks reads only the metadata of the file it's reading\n\nAuthor: julien <julien@twitter.com>\n\nCloses #45 from julienledem/skip_reading_row_groups and squashes the following commits:\n\nccdd08c [julien] fix parquet-hive\n24a2050 [julien] Merge branch 'master' into skip_reading_row_groups\n3d7e35a [julien] adress review feedback\n5b6bd1b [julien] more tests\n323d254 [julien] sdd unit tests\nf599259 [julien] review feedback\nfb11f02 [julien] fix backward compatibility check\n2c20b46 [julien] cleanup readFooters methods\n3da37d8 [julien] fix read summary\nab95a45 [julien] cleanup\n4d16df3 [julien] implement task side metadata\n9bb8059 [julien] first stab at integrating skipping row groups\n",
            "diff": {
                "parquet-hadoop/src/main/java/parquet/format/converter/ParquetMetadataConverter.java": 185,
                "parquet-hadoop/src/main/java/parquet/hadoop/ParquetFileReader.java": 219,
                "parquet-hadoop/src/main/java/parquet/hadoop/ParquetFileWriter.java": 31,
                "parquet-hadoop/src/main/java/parquet/hadoop/ParquetInputFormat.java": 638,
                "parquet-hadoop/src/main/java/parquet/hadoop/ParquetInputSplit.java": 362,
                "parquet-hadoop/src/main/java/parquet/hadoop/ParquetOutputCommitter.java": 1,
                "parquet-hadoop/src/main/java/parquet/hadoop/ParquetOutputFormat.java": 1,
                "parquet-hadoop/src/main/java/parquet/hadoop/ParquetReader.java": 6,
                "parquet-hadoop/src/main/java/parquet/hadoop/ParquetRecordReader.java": 70,
                "parquet-hadoop/src/main/java/parquet/hadoop/PrintFooter.java": 3,
                "parquet-hadoop/src/main/java/parquet/hadoop/mapred/DeprecatedParquetInputFormat.java": 30,
                "parquet-hadoop/src/main/java/parquet/hadoop/mapred/DeprecatedParquetOutputFormat.java": 17,
                "parquet-hadoop/src/test/java/parquet/format/converter/TestParquetMetadataConverter.java": 128,
                "parquet-hadoop/src/test/java/parquet/hadoop/DeprecatedInputFormatTest.java": 2,
                "parquet-hadoop/src/test/java/parquet/hadoop/TestInputFormat.java": 237,
                "parquet-hadoop/src/test/java/parquet/hadoop/TestParquetFileWriter.java": 14,
                "parquet-hadoop/src/test/java/parquet/hadoop/TestParquetInputSplit.java": 45,
                "parquet-hadoop/src/test/java/parquet/hadoop/example/TestInputOutputFormat.java": 24,
                "parquet-hive/parquet-hive-storage-handler/src/main/java/org/apache/hadoop/hive/ql/io/parquet/read/ParquetRecordReaderWrapper.java": 51,
                "parquet-pig/src/main/java/parquet/pig/ParquetLoader.java": 38,
                "parquet-pig/src/main/java/parquet/pig/TupleReadSupport.java": 14
            },
            "is_test": true,
            "is_fix": false
        },
        "5f39948b2414ea2582892f6447566d7fe4909b4f": {
            "datetime": "2014-09-08T14:12:11-07:00",
            "summary": "update scala 2.10",
            "message": "update scala 2.10\n\nTry to upgrade to scala 2.10\n\nAuthor: Tianshuo Deng <tdeng@twitter.com>\n\nCloses #35 from tsdeng/update_scala_2_10 and squashes the following commits:\n\n1b7e55f [Tianshuo Deng] fix comment\nbed9de3 [Tianshuo Deng] remove twitter artifactory\n2bce643 [Tianshuo Deng] publish fix\n06b374e [Tianshuo Deng] define scala.binary.version\nfcf6965 [Tianshuo Deng] Merge branch 'master' into update_scala_2_10\ne91d9f7 [Tianshuo Deng] update version\n5d18b88 [Tianshuo Deng] version\n83df898 [Tianshuo Deng] update scala 2.10\n",
            "diff": {
                "parquet-scrooge/src/main/java/parquet/scrooge/ScroogeStructConverter.java": 3
            },
            "is_test": false,
            "is_fix": false
        },
        "f637c4458a3b1dc4ecaa35957adf13ecfbe7d12d": {
            "datetime": "2014-09-10T10:37:51-07:00",
            "summary": "PARQUET-87: Add API for projection pushdown on the cascading scheme level",
            "message": "PARQUET-87: Add API for projection pushdown on the cascading scheme level\n\nJIRA: https://issues.apache.org/jira/browse/PARQUET-87\nPreviously, the projection pushdown configuration is global, and not bind to a specific tap.\nAfter adding this API, projection pushdown can be done more \"naturally\", which may benefit scalding. The code that uses this API would look like:\n\n```\nScheme sourceScheme = new ParquetScroogeScheme(new Config().withProjection(projectionFilter));\n Tap source = new Hfs(sourceScheme, PARQUET_PATH);\n```\n\nAuthor: Tianshuo Deng <tdeng@twitter.com>\n\nCloses #51 from tsdeng/projection_from_scheme and squashes the following commits:\n\n2c72757 [Tianshuo Deng] make config class final\n813dc1a [Tianshuo Deng] erge branch 'master' into projection_from_scheme\nb587b79 [Tianshuo Deng] make constructor of Config private, fix format\n3aa7dd2 [Tianshuo Deng] remove builder\n9348266 [Tianshuo Deng] use builder()\n7c91869 [Tianshuo Deng] make fields of Config private, create builder method for Config\n5fdc881 [Tianshuo Deng] builder for setting projection pushdown and predicate pushdown\na47f271 [Tianshuo Deng] immutable\n3d514b1 [Tianshuo Deng] done\n",
            "diff": {
                "parquet-cascading/src/main/java/parquet/cascading/ParquetTBaseScheme.java": 23,
                "parquet-cascading/src/main/java/parquet/cascading/ParquetValueScheme.java": 78,
                "parquet-scrooge/src/main/java/parquet/scrooge/ParquetScroogeScheme.java": 12,
                "parquet-scrooge/src/test/java/parquet/scrooge/ParquetScroogeSchemeTest.java": 123,
                "parquet-thrift/src/main/java/parquet/hadoop/thrift/ThriftReadSupport.java": 4
            },
            "is_test": true,
            "is_fix": false
        },
        "8d878afb497810ceb34a0b8a4788914d9debf74b": {
            "datetime": "2014-09-10T16:13:20-07:00",
            "summary": "PARQUET-24: enforce JIRA prefix",
            "message": "PARQUET-24: enforce JIRA prefix\n\nAuthor: julien <julien@twitter.com>\n\nCloses #54 from julienledem/PARQUET-24 and squashes the following commits:\n\nd444f2f [julien] add option to not close JIRA\n00d4b13 [julien] fix close jira\n7cf9bb3 [julien] enforce JIRA prefix\n",
            "diff": {
                "dev/merge_parquet_pr.py": 26
            },
            "is_test": false,
            "is_fix": false
        },
        "9cdcf3bbdf8f772d3fadf388b2db048598c155e9": {
            "datetime": "2014-09-22T11:11:08-07:00",
            "summary": "PARQUET-94: Fix bug in ParquetScroogeScheme constructor, minor cleanup",
            "message": "PARQUET-94: Fix bug in ParquetScroogeScheme constructor, minor cleanup\n\nI noticed that ParquetScroogeScheme's constructor ignores the provided klass argument.\nI also added in missing type parameters for the Config object where they were missing.\n\nAuthor: Alex Levenson <alexlevenson@twitter.com>\n\nCloses #61 from isnotinvain/alexlevenson/parquet-scrooge-cleanup and squashes the following commits:\n\n2b16007 [Alex Levenson] Fix bug in ParquetScroogeScheme constructor, minor cleanup\n",
            "diff": {
                "parquet-cascading/src/main/java/parquet/cascading/ParquetTBaseScheme.java": 13,
                "parquet-cascading/src/main/java/parquet/cascading/ParquetValueScheme.java": 23,
                "parquet-scrooge/src/main/java/parquet/scrooge/ParquetScroogeScheme.java": 10
            },
            "is_test": false,
            "is_fix": false
        },
        "3dc223cc85022e11dc6cd954784e715e3a49fe5c": {
            "datetime": "2014-09-22T11:21:20-07:00",
            "summary": "PARQUET-92: Pig parallel control",
            "message": "PARQUET-92: Pig parallel control\n\nThe parallelism for reading footers was fixed at '5', which isn't optimal for using pig with S3.  Just adding a property to adjust the parallelism.\n\nJIRA: https://issues.apache.org/jira/browse/PARQUET-92\n\nAuthor: Daniel Weeks <dweeks@netflix.com>\n\nCloses #57 from dcw-netflix/pig-parallel-control and squashes the following commits:\n\ne49087c [Daniel Weeks] Update ParquetFileReader.java\nec4f8ca [Daniel Weeks] Added configurable control of parallelism\nd37a6de [Daniel Weeks] Resetting pom to main\n0c1572e [Daniel Weeks] Merge remote-tracking branch 'upstream/master'\n98c6607 [Daniel Weeks] Merge remote-tracking branch 'upstream/master'\n96ba602 [Daniel Weeks] Disabled projects that don't compile\n",
            "diff": {
                "parquet-hadoop/src/main/java/parquet/hadoop/ParquetFileReader.java": 7
            },
            "is_test": false,
            "is_fix": false
        },
        "0eb96379518db4f84f7a95b651c6dc9a639cc9ac": {
            "datetime": "2014-09-22T15:07:04-07:00",
            "summary": "PARQUET-89: Add hadoop-2 test profile for Travis CI.",
            "message": "PARQUET-89: Add hadoop-2 test profile for Travis CI.\n\nThis also fixes problems that prevented hadoop-2 from passing:\n* Dynamically resolve counter methods in parquet-hadoop\n* Parameterize pig version with hadoop-2 support\n* Update pig test for hadoop-2 change (no nulls allowed)\n* Update parquet-hive to depend on hadoop-client\n\nThe travis config will now run each test profile in a different run.\n\nAuthor: Ryan Blue <rblue@cloudera.com>\n\nCloses #55 from rdblue/PARQUET-89-add-test-profiles and squashes the following commits:\n\n006c6d8 [Ryan Blue] PARQUET-89: Add hadoop-2 test profile for travis CI.\n",
            "diff": {
                "parquet-hadoop/src/test/java/parquet/hadoop/example/TestInputOutputFormat.java": 29,
                "parquet-pig/src/test/java/parquet/pig/summary/TestSummary.java": 13,
                "parquet-test-hadoop2/src/test/java/parquet/hadoop2/TestInputOutputFormat.java": 139
            },
            "is_test": true,
            "is_fix": false
        },
        "59c58d0b829aa156f038cc900b803508f8849765": {
            "datetime": "2014-09-23T12:14:17-07:00",
            "summary": "PARQUET-82: Check page size is valid when writing.",
            "message": "PARQUET-82: Check page size is valid when writing.\n\nAuthor: Ryan Blue <rblue@cloudera.com>\n\nCloses #48 from rdblue/PARQUET-82-check-page-size and squashes the following commits:\n\n9f31402 [Ryan Blue] PARQUET-82: Check page size is valid when writing.\n",
            "diff": {
                "parquet-hadoop/src/main/java/parquet/hadoop/ColumnChunkPageWriteStore.java": 20
            },
            "is_test": false,
            "is_fix": false
        },
        "0c4f13a846b458e31cfcaafd8e83f0f4c1d04237": {
            "datetime": "2014-09-25T10:12:58-07:00",
            "summary": "PARQUET-101: fix meta data lookup when not using task.side.metadata",
            "message": "PARQUET-101: fix meta data lookup when not using task.side.metadata\n\nAuthor: julien <julien@twitter.com>\n\nCloses #64 from julienledem/PARQUET-101 and squashes the following commits:\n\n54ffbc9 [julien] fix meta data lookup when not using task.side.metadata\n",
            "diff": {
                "parquet-hadoop/src/main/java/parquet/hadoop/ParquetRecordReader.java": 20
            },
            "is_test": false,
            "is_fix": false
        },
        "3a082e8e390898646c094d20f4ec1eeba45b79ac": {
            "datetime": "2014-09-25T11:25:53-07:00",
            "summary": "PARQUET-90: integrate field ids in schema",
            "message": "PARQUET-90: integrate field ids in schema\n\nThis integrates support for field is that was introduced in Parquet format.\nThrift and Protobufs ids will now be saved in the Parquet schema.\n\nAuthor: julien <julien@twitter.com>\n\nCloses #56 from julienledem/field_ids and squashes the following commits:\n\n62c2809 [julien] remove withOriginalType; use Typles builder more\n8ff0034 [julien] review feedback\n084c8be [julien] binary compat\n85d785c [julien] add proto id in schema; fix schema parsing for ids\nd4be488 [julien] integrate field ids in schema\n",
            "diff": {
                "parquet-column/src/main/java/parquet/schema/GroupType.java": 94,
                "parquet-column/src/main/java/parquet/schema/MessageType.java": 10,
                "parquet-column/src/main/java/parquet/schema/MessageTypeParser.java": 21,
                "parquet-column/src/main/java/parquet/schema/PrimitiveType.java": 101,
                "parquet-column/src/main/java/parquet/schema/Type.java": 106,
                "parquet-column/src/main/java/parquet/schema/Types.java": 31,
                "parquet-column/src/test/java/parquet/parser/TestParquetParser.java": 200,
                "parquet-column/src/test/java/parquet/schema/TestMessageType.java": 14,
                "parquet-column/src/test/java/parquet/schema/TestTypeBuilders.java": 16,
                "parquet-hadoop/src/main/java/parquet/format/converter/ParquetMetadataConverter.java": 3,
                "parquet-pig/src/main/java/parquet/pig/PigSchemaConverter.java": 66,
                "parquet-protobuf/src/main/java/parquet/proto/ProtoSchemaConverter.java": 108,
                "parquet-protobuf/src/test/java/parquet/proto/ProtoSchemaConverterTest.java": 58,
                "parquet-thrift/src/main/java/parquet/thrift/ThriftSchemaConvertVisitor.java": 96,
                "parquet-thrift/src/main/java/parquet/thrift/projection/FieldsPath.java": 5,
                "parquet-thrift/src/test/java/parquet/thrift/TestThriftSchemaConverter.java": 113
            },
            "is_test": true,
            "is_fix": true
        },
        "bf20abbf4825fa5892d8e15c066e768671a39289": {
            "datetime": "2014-09-25T16:45:56-07:00",
            "summary": "PARQUET-96: fill out some missing methods on parquet.example classes",
            "message": "PARQUET-96: fill out some missing methods on parquet.example classes\n\nI'm slightly embarrassed to say that we use these, and we'd really like to stop needing a fork, so here we are.\n\nAuthor: Colin Marc <colinmarc@gmail.com>\n\nCloses #59 from colinmarc/missing-group-methods and squashes the following commits:\n\naf8ea08 [Colin Marc] fill out some missing methods on parquet.example classes\n",
            "diff": {
                "parquet-column/src/main/java/parquet/example/data/Group.java": 6,
                "parquet-column/src/main/java/parquet/example/data/GroupValueSource.java": 12,
                "parquet-column/src/main/java/parquet/example/data/simple/SimpleGroup.java": 17
            },
            "is_test": false,
            "is_fix": false
        },
        "0b17cbee9541998df66d33c8a99b675ced80d9aa": {
            "datetime": "2014-09-29T12:00:03-07:00",
            "summary": "PARQUET-104: Fix writing empty row group at the end of the file",
            "message": "PARQUET-104: Fix writing empty row group at the end of the file\n\nAt then end of a parquet file, it may writes an empty rowgroup.\nThis happens when: numberOfRecords mod sizeOfRowGroup = 0\n\nAuthor: Tianshuo Deng <tdeng@twitter.com>\n\nCloses #66 from tsdeng/fix_empty_row_group and squashes the following commits:\n\n10b93fb [Tianshuo Deng] rename\ne3a5896 [Tianshuo Deng] format\n91fa0d4 [Tianshuo Deng] fix empty row group\n",
            "diff": {
                "parquet-hadoop/src/main/java/parquet/hadoop/InternalParquetRecordWriter.java": 64
            },
            "is_test": false,
            "is_fix": false
        },
        "da9129927bce90feb6d2860745263f4d74d0dfa8": {
            "datetime": "2014-10-01T13:44:45-07:00",
            "summary": "PARQUET-64: Add new OriginalTypes in parquet-format 2.2.0.",
            "message": "PARQUET-64: Add new OriginalTypes in parquet-format 2.2.0.\n\nThis implements the restrictions for those types documented in the parquet-format logical types spec.\n\nThis requires a release of parquet-format 2.2.0 with the new types. I'll rebase and update the dependency when it is released.\n\nAuthor: Ryan Blue <rblue@cloudera.com>\n\nCloses #31 from rdblue/PARQUET-64-add-new-types and squashes the following commits:\n\n10feab9 [Ryan Blue] PARQUET-64: Add new OriginalTypes in parquet-format 2.2.0.\n",
            "diff": {
                "parquet-column/src/main/java/parquet/schema/OriginalType.java": 16,
                "parquet-column/src/main/java/parquet/schema/Types.java": 27,
                "parquet-column/src/test/java/parquet/parser/TestParquetParser.java": 82,
                "parquet-column/src/test/java/parquet/schema/TestTypeBuilders.java": 219,
                "parquet-hadoop/src/main/java/parquet/format/converter/ParquetMetadataConverter.java": 57,
                "parquet-hadoop/src/test/java/parquet/format/converter/TestParquetMetadataConverter.java": 6
            },
            "is_test": true,
            "is_fix": false
        },
        "be1222ef4a3260ddcf516d73c6ceecd144a134cb": {
            "datetime": "2014-10-01T14:14:24-07:00",
            "summary": "PARQUET-107: Add option to disable summary metadata.",
            "message": "PARQUET-107: Add option to disable summary metadata.\n\nThis adds an option to the commitJob phase of the MR OutputCommitter,\nparquet.enable.summary-metadata (default true), that can be used to\ndisable the summary metadata files generated from the footers of all of\nthe files produced. This enables more control over when those summary\nfiles are produced and makes it possible to rename MR outputs and then\ngenerate the summaries.\n\nAuthor: Ryan Blue <rblue@cloudera.com>\n\nCloses #68 from rdblue/PARQUET-107-add-summary-metadata-option and squashes the following commits:\n\n261e5e4 [Ryan Blue] PARQUET-107: Add option to disable summary metadata.\n",
            "diff": {
                "parquet-hadoop/src/main/java/parquet/hadoop/ParquetOutputCommitter.java": 26,
                "parquet-hadoop/src/main/java/parquet/hadoop/ParquetOutputFormat.java": 5
            },
            "is_test": false,
            "is_fix": false
        },
        "31fb4dfef212791f86f052ce8a3adeabaf830cf2": {
            "datetime": "2014-10-21T09:54:20-07:00",
            "summary": "PARQUET-105: use mvn shade plugin to create uber jar, support meta on a folder",
            "message": "PARQUET-105: use mvn shade plugin to create uber jar, support meta on a folder\n\n1. Make hadoop dependency from parquet-tools so it is provided. It can be used against different version of hadoop\n2. Use maven shade plugin to create a all in one jar, which can be used both locally or in hadoop\n3. Make parquet-meta command support both folder(read summary file) and a single file\n\nAuthor: Tianshuo Deng <tdeng@twitter.com>\n\nCloses #69 from tsdeng/bundle_parquet_tools and squashes the following commits:\n\nd8dcd3e [Tianshuo Deng] print file offset, file path, and cancel autoCrop\na2d1399 [Tianshuo Deng] support local mode\n5009a85 [Tianshuo Deng] fix README\n0756f81 [Tianshuo Deng] remove semver check for parquet_tools\n78c7f4b [Tianshuo Deng] use mvn shade plugin to create uber jar, support meta on a folder\n",
            "diff": {
                "parquet-tools/src/main/java/parquet/tools/Main.java": 29,
                "parquet-tools/src/main/java/parquet/tools/command/ShowMetaCommand.java": 20,
                "parquet-tools/src/main/java/parquet/tools/command/ShowSchemaCommand.java": 2,
                "parquet-tools/src/main/java/parquet/tools/util/MetadataUtils.java": 3
            },
            "is_test": false,
            "is_fix": false
        },
        "ccfca8f714055cd9fbd00cf7e847b880132cae69": {
            "datetime": "2014-10-29T11:10:16-07:00",
            "summary": "PARQUET-106: Relax InputSplit Protections",
            "message": "PARQUET-106: Relax InputSplit Protections\n\nhttps://issues.apache.org/jira/browse/PARQUET-106\n\nAuthor: Daniel Weeks <dweeks@netflix.com>\n\nCloses #67 from dcw-netflix/input-split2 and squashes the following commits:\n\n2f2c0c7 [Daniel Weeks] Update ParquetInputSplit.java\n12bd3c1 [Daniel Weeks] Update ParquetInputSplit.java\n6c662ee [Daniel Weeks] Update ParquetInputSplit.java\n5f9f02e [Daniel Weeks] Update ParquetInputSplit.java\nd19e1ac [Daniel Weeks] Merge branch 'master' into input-split2\nc4172bb [Daniel Weeks] Merge remote-tracking branch 'upstream/master'\n01a5e8f [Daniel Weeks] Relaxed protections on input split class\nd37a6de [Daniel Weeks] Resetting pom to main\n0c1572e [Daniel Weeks] Merge remote-tracking branch 'upstream/master'\n98c6607 [Daniel Weeks] Merge remote-tracking branch 'upstream/master'\n96ba602 [Daniel Weeks] Disabled projects that don't compile\n",
            "diff": {
                "parquet-hadoop/src/main/java/parquet/hadoop/ParquetInputSplit.java": 12
            },
            "is_test": false,
            "is_fix": false
        },
        "a29815abf4f0e51b332a8af1b83ad344104c14d9": {
            "datetime": "2014-11-03T14:00:33+00:00",
            "summary": "PARQUET-123: Enable dictionary support in AvroIndexedRecordConverter",
            "message": "PARQUET-123: Enable dictionary support in AvroIndexedRecordConverter\n\nIf consumers are loading Parquet records into an immutable structure\nlike an Apache Spark RDD, being able to configure string reuse in\nAvroIndexedRecordConverter can drastically reduce the overall memory\nfootprint of strings.\n\nNOTE: This isn't meant to be a merge-able PR (yet). I want to use\nthis PR as a way to discuss: (1) if this is a reasonable approach\nand (2) to learn if PrimitiveConverter needs to be thread-safe as\nI'm currently using a ConcurrentHashMap. If there's agreement\nthat this would be worthwhile, I'll create a JIRA and write some\nunit tests.\n\nAuthor: Matt Massie <massie@cs.berkeley.edu>\n\nCloses #76 from massie/immutable-strings and squashes the following commits:\n\n88ce5bf [Matt Massie] PARQUET-123: Enable dictionary support in AvroIndexedRecordConverter\n",
            "diff": {
                "parquet-avro/src/main/java/parquet/avro/AvroIndexedRecordConverter.java": 26,
                "parquet-avro/src/test/java/parquet/avro/TestSpecificInputOutputFormat.java": 11
            },
            "is_test": true,
            "is_fix": false
        },
        "f1da5e927ed18aeec1610bec67f88facd6a470e1": {
            "datetime": "2014-11-03T14:11:03+00:00",
            "summary": "PARQUET-121: Allow Parquet to build with Java 8",
            "message": "PARQUET-121: Allow Parquet to build with Java 8\n\nThere are test failures running with Java 8 due to http://openjdk.java.net/jeps/180 which changed retrieval order for HashMap.\n\nHere's how I tested this:\n\n```bash\nuse-java8\nmvn clean install -DskipTests -Dmaven.javadoc.skip=true\nmvn test\nmvn test -P hadoop-2\n```\n\nI also compiled the main code with Java 7 (target=1.6 bytecode), and compiled the tests with Java 8, and ran them with Java 8. The idea here is to simulate users who want to run Parquet with JRE 8.\n```bash\nuse-java7\nmvn clean install -DskipTests -Dmaven.javadoc.skip=true\nuse-java8\nfind . -name test-classes | grep target/test-classes | grep -v 'parquet-scrooge' | xargs rm -rf\nmvn test -DtargetJavaVersion=1.8 -Dmaven.main.skip=true -Dscala.maven.test.skip=true\n```\nA couple of notes about this:\n* The targetJavaVersion property is used since other Hadoop projects use the same name.\n* I couldn\u2019t get parquet-scrooge to compile with target=1.8, which is why I introduced scala.maven.test.skip (and updated scala-maven-plugin to the latest version which supports the property). Compiling with target=1.8 should be fixed in another JIRA as it looks pretty involved.\n\nAuthor: Tom White <tom@cloudera.com>\n\nCloses #77 from tomwhite/PARQUET-121-java8 and squashes the following commits:\n\n8717e13 [Tom White] Fix tests to run under Java 8.\n35ea670 [Tom White] PARQUET-121. Allow Parquet to build with Java 8.\n",
            "diff": {
                "parquet-pig/src/main/java/parquet/pig/convert/MapConverter.java": 3,
                "parquet-pig/src/test/java/parquet/pig/TestParquetStorer.java": 20,
                "parquet-pig/src/test/java/parquet/pig/TestPigSchemaConverter.java": 7,
                "parquet-thrift/src/test/java/parquet/thrift/TestParquetWriteProtocol.java": 39
            },
            "is_test": true,
            "is_fix": false
        },
        "92e6d716069686583b852a6dcf12af986d6dc694": {
            "datetime": "2014-11-07T11:02:27-08:00",
            "summary": "PARQUET-122: make task side metadata true by default",
            "message": "PARQUET-122: make task side metadata true by default\n\nAuthor: julien <julien@twitter.com>\n\nCloses #78 from julienledem/task_side_metadata_default_true and squashes the following commits:\n\n32451a7 [julien] make task side metadata true by default\n",
            "diff": {
                "parquet-hadoop/src/main/java/parquet/hadoop/ParquetInputFormat.java": 15
            },
            "is_test": false,
            "is_fix": false
        },
        "251a495d2a72de7e892ade7f64980f51f2fcc0dd": {
            "datetime": "2014-11-17T16:53:08-08:00",
            "summary": "PARQUET-135: Input location is not getting set for the getStatistics in ParquetLoader when using two different loaders within a Pig script.",
            "message": "PARQUET-135: Input location is not getting set for the getStatistics in ParquetLoader when using two different loaders within a Pig script.\n\nAuthor: elif dede <edede@twitter.com>\n\nCloses #86 from elifdd/parquetLoader_error_PARQUET-135 and squashes the following commits:\n\nb0150ee [elif dede] fixed white space\nbdb381a [elif dede] PARQUET-135: Call setInput from getStatistics in ParquetLoader to fix ReduceEstimator errors in pig jobs\n",
            "diff": {
                "parquet-hadoop/src/test/java/parquet/format/converter/TestParquetMetadataConverter.java": 2,
                "parquet-pig/src/main/java/parquet/pig/ParquetLoader.java": 5
            },
            "is_test": true,
            "is_fix": true
        },
        "d105819a0e72765ff5ba4efa5622d727360ee2b8": {
            "datetime": "2014-11-18T20:20:04-08:00",
            "summary": "PARQUET-132: Add type parameter to AvroParquetInputFormat.",
            "message": "PARQUET-132: Add type parameter to AvroParquetInputFormat.\n\nAuthor: Ryan Blue <blue@apache.org>\n\nCloses #84 from rdblue/PARQUET-132-parameterize-avro-inputformat and squashes the following commits:\n\n63114b0 [Ryan Blue] PARQUET-132: Add type parameter to AvroParquetInputFormat.\n",
            "diff": {
                "parquet-avro/src/main/java/parquet/avro/AvroParquetInputFormat.java": 2
            },
            "is_test": false,
            "is_fix": false
        },
        "3aa6f11785a2f1b3b09df328a02a2c28dfa0bb57": {
            "datetime": "2014-11-20T09:19:25-08:00",
            "summary": "PARQUET-114: Sample NanoTime class serializes and deserializes Timestamp incorrectly",
            "message": "PARQUET-114: Sample NanoTime class serializes and deserializes Timestamp incorrectly\n\nI ran the Parquet Column tests and they passed.\n\nFYI @rdblue\n\nAuthor: Brock Noland <brock@apache.org>\n\nCloses #71 from brockn/master and squashes the following commits:\n\n69ba484 [Brock Noland] PARQUET-114 - Sample NanoTime class serializes and deserializes Timestamp incorrectly\n",
            "diff": {
                "parquet-column/src/main/java/parquet/example/data/simple/NanoTime.java": 9
            },
            "is_test": false,
            "is_fix": false
        },
        "ad06e61143d6ad3d883907e75100014b9554c357": {
            "datetime": "2014-11-25T10:48:54-08:00",
            "summary": "PARQUET-52: refactor fallback mechanism",
            "message": "PARQUET-52: refactor fallback mechanism\n\nSee: https://issues.apache.org/jira/browse/PARQUET-52\nContext:\nIn the ValuesWriter API there is a mechanism to return the Encoding actually used which allows to fallback to a different encoding.\nFor example the dictionary encoding may fail if there are too many distinct values and the dictionary grows too big. In such cases the DictionaryValuesWriter was falling back to the Plain encoding.\nThis can happen as well if the space savings are not satisfying when writing the first page and we prefer to fallback to a more light weight encoding.\nWith Parquet 2.0 we are adding new encodings and the fall back is not necessarily Plain anymore.\nThis Pull Request decouple the fallback mechanism from Dictionary and Plain encodings and allows to reuse the fallback logic with other encodings.\nOne could imagine more than one level of fallback in the future by chaining the FallBackValuesWriter.\n\nAuthor: julien <julien@twitter.com>\n\nCloses #74 from julienledem/fallback and squashes the following commits:\n\nb74a4ca [julien] Merge branch 'master' into fallback\nd9abd62 [julien] better naming\naa90caf [julien] exclude values encoding from SemVer\n10f295e [julien] better test setup\nc516bd9 [julien] improve test\n780c4c3 [julien] license header\nf16311a [julien] javadoc\naeb8084 [julien] add more test; fix dic decoding\n0793399 [julien] Merge branch 'master' into fallback\n2638ec9 [julien] fix dictionary encoding labelling\n2fd9372 [julien] consistent naming\ncf7a734 [julien] rewrite ParquetProperties to enable proper fallback\nbf1474a [julien] refactor fallback mechanism\n",
            "diff": {
                "parquet-column/src/main/java/parquet/column/Encoding.java": 113,
                "parquet-column/src/main/java/parquet/column/ParquetProperties.java": 190,
                "parquet-column/src/main/java/parquet/column/values/RequiresFallback.java": 51,
                "parquet-column/src/main/java/parquet/column/values/dictionary/DictionaryValuesWriter.java": 344,
                "parquet-column/src/main/java/parquet/column/values/dictionary/PlainValuesDictionary.java": 4,
                "parquet-column/src/main/java/parquet/column/values/fallback/FallbackValuesWriter.java": 187,
                "parquet-column/src/test/java/parquet/column/values/dictionary/TestDictionary.java": 125,
                "parquet-hadoop/src/main/java/parquet/hadoop/example/GroupWriteSupport.java": 6,
                "parquet-hadoop/src/test/java/parquet/hadoop/TestParquetFileWriter.java": 4,
                "parquet-hadoop/src/test/java/parquet/hadoop/TestParquetWriter.java": 111,
                "parquet-hadoop/src/test/java/parquet/hadoop/TestUtils.java": 22
            },
            "is_test": true,
            "is_fix": false
        },
        "b5f6a3bd86bfe0f186b07eb69480564d5fc854dc": {
            "datetime": "2014-12-02T16:19:14+00:00",
            "summary": "PARQUET-140: Allow clients to control the GenericData instance used to read Avro records",
            "message": "PARQUET-140: Allow clients to control the GenericData instance used to read Avro records\n\nAuthor: Josh Wills <jwills@cloudera.com>\n\nCloses #90 from jwills/master and squashes the following commits:\n\n044cf54 [Josh Wills] PARQUET-140: Allow clients to control the GenericData object that is used to read Avro records\n",
            "diff": {
                "parquet-avro/src/main/java/parquet/avro/AvroDataSupplier.java": 28,
                "parquet-avro/src/main/java/parquet/avro/AvroIndexedRecordConverter.java": 66,
                "parquet-avro/src/main/java/parquet/avro/AvroParquetInputFormat.java": 11,
                "parquet-avro/src/main/java/parquet/avro/AvroReadSupport.java": 14,
                "parquet-avro/src/main/java/parquet/avro/AvroRecordMaterializer.java": 6,
                "parquet-avro/src/main/java/parquet/avro/SpecificDataSupplier.java": 26
            },
            "is_test": false,
            "is_fix": false
        },
        "ccc29e4dde24584118211f27c71bb01bacc39326": {
            "datetime": "2014-12-04T13:16:11-08:00",
            "summary": "PARQUET-117: implement the new page format for Parquet 2.0",
            "message": "PARQUET-117: implement the new page format for Parquet 2.0\n\nThe new page format was defined some time ago:\nhttps://github.com/Parquet/parquet-format/pull/64\nhttps://github.com/Parquet/parquet-format/issues/44\nThe goals are the following:\n - cut pages on record boundaries to facilitate skipping pages in predicate poush down\n - read rl and dl independently of data\n - optionally not compress data\n\nAuthor: julien <julien@twitter.com>\n\nCloses #75 from julienledem/new_page_format and squashes the following commits:\n\nfbbc23a [julien] make mvn install display output only if it fails\n4189383 [julien] save output lines as travis cuts after 10000\n44d3684 [julien] fix parquet-tools for new page format\n0fb8c15 [julien] Merge branch 'master' into new_page_format\n5880cbb [julien] Merge branch 'master' into new_page_format\n6ee7303 [julien] make parquet.column package not semver compliant\n42f6c9f [julien] add tests and fix bugs\n266302b [julien] fix write path\n4e76369 [julien] read path\n050a487 [julien] fix compilation\ne0e9d00 [julien] better ColumnWriterStore definition\necf04ce [julien] remove unnecessary change\n2bc4d01 [julien] first stab at write path for the new page format\n",
            "diff": {
                "parquet-column/src/main/java/parquet/column/ColumnWriteStore.java": 22,
                "parquet-column/src/main/java/parquet/column/ColumnWriter.java": 12,
                "parquet-column/src/main/java/parquet/column/ParquetProperties.java": 25,
                "parquet-column/src/main/java/parquet/column/impl/ColumnReaderImpl.java": 143,
                "parquet-column/src/main/java/parquet/column/impl/ColumnWriteStoreImpl.java": 59,
                "parquet-column/src/main/java/parquet/column/impl/ColumnWriteStoreV2.java": 163,
                "parquet-column/src/main/java/parquet/column/impl/ColumnWriterImpl.java": 12,
                "parquet-column/src/main/java/parquet/column/impl/ColumnWriterV2.java": 295,
                "parquet-column/src/main/java/parquet/column/page/DataPage.java": 50,
                "parquet-column/src/main/java/parquet/column/page/DataPageV1.java": 80,
                "parquet-column/src/main/java/parquet/column/page/DataPageV2.java": 138,
                "parquet-column/src/main/java/parquet/column/page/DictionaryPage.java": 14,
                "parquet-column/src/main/java/parquet/column/page/Page.java": 134,
                "parquet-column/src/main/java/parquet/column/page/PageReader.java": 2,
                "parquet-column/src/main/java/parquet/column/page/PageWriter.java": 40,
                "parquet-column/src/main/java/parquet/column/values/ValuesWriter.java": 3,
                "parquet-column/src/main/java/parquet/column/values/rle/RunLengthBitPackingHybridDecoder.java": 7,
                "parquet-column/src/main/java/parquet/column/values/rle/RunLengthBitPackingHybridValuesWriter.java": 10,
                "parquet-column/src/main/java/parquet/io/MessageColumnIO.java": 3,
                "parquet-column/src/test/java/parquet/column/impl/TestColumnReaderImpl.java": 105,
                "parquet-column/src/test/java/parquet/column/mem/TestMemColumn.java": 27,
                "parquet-column/src/test/java/parquet/column/mem/TestMemPageStore.java": 4,
                "parquet-column/src/test/java/parquet/column/page/mem/MemPageReader.java": 10,
                "parquet-column/src/test/java/parquet/column/page/mem/MemPageStore.java": 4,
                "parquet-column/src/test/java/parquet/column/page/mem/MemPageWriter.java": 41,
                "parquet-column/src/test/java/parquet/io/PerfTest.java": 6,
                "parquet-column/src/test/java/parquet/io/TestColumnIO.java": 170,
                "parquet-column/src/test/java/parquet/io/TestFiltered.java": 4,
                "parquet-hadoop/src/main/java/parquet/format/converter/ParquetMetadataConverter.java": 53,
                "parquet-hadoop/src/main/java/parquet/hadoop/ColumnChunkPageReadStore.java": 72,
                "parquet-hadoop/src/main/java/parquet/hadoop/ColumnChunkPageWriteStore.java": 101,
                "parquet-hadoop/src/main/java/parquet/hadoop/InternalParquetRecordWriter.java": 28,
                "parquet-hadoop/src/main/java/parquet/hadoop/ParquetFileReader.java": 74,
                "parquet-hadoop/src/test/java/parquet/hadoop/TestColumnChunkPageWriteStore.java": 107,
                "parquet-hadoop/src/test/java/parquet/hadoop/TestParquetFileWriter.java": 7,
                "parquet-hadoop/src/test/java/parquet/hadoop/TestParquetWriterNewPage.java": 117,
                "parquet-pig/src/test/java/parquet/pig/GenerateIntTestFile.java": 142,
                "parquet-pig/src/test/java/parquet/pig/GenerateTPCH.java": 112,
                "parquet-pig/src/test/java/parquet/pig/TupleConsumerPerfTest.java": 8,
                "parquet-thrift/src/test/java/parquet/thrift/TestParquetReadProtocol.java": 4,
                "parquet-tools/src/main/java/parquet/tools/command/DumpCommand.java": 34
            },
            "is_test": true,
            "is_fix": false
        },
        "b7a82a918f0a595a96047f7eef2672fd95d5626c": {
            "datetime": "2014-12-11T14:01:27-08:00",
            "summary": "PARQUET-145 InternalParquetRecordReader.close() should not throw an exception if initialization has failed",
            "message": "PARQUET-145 InternalParquetRecordReader.close() should not throw an exception if initialization has failed\n\nPARQUET-145 InternalParquetRecordReader.close() should not throw an exception if initialization has failed\n\nAuthor: Wolfgang Hoschek <whoschek@cloudera.com>\n\nCloses #93 from whoschek/PARQUET-145-3 and squashes the following commits:\n\n52a6acb [Wolfgang Hoschek] PARQUET-145 InternalParquetRecordReader.close() should not throw an exception if initialization has failed\n",
            "diff": {
                "parquet-hadoop/src/main/java/parquet/hadoop/InternalParquetRecordReader.java": 4
            },
            "is_test": false,
            "is_fix": false
        },
        "8e2ea92ee6ed83f74619681fd1158dd081c4dd4e": {
            "datetime": "2014-12-16T09:56:02-08:00",
            "summary": "PARQUET-150 Update merge script issue id matching.",
            "message": "PARQUET-150 Update merge script issue id matching.\n\nThis matches a word boundary after the issue id rather than a colon.\n\nAuthor: Ryan Blue <blue@apache.org>\n\nThis patch had conflicts when merged, resolved by\nCommitter: Ryan Blue <blue@apache.org>\n\nCloses #94 from rdblue/PARQUET-150-update-merge-script and squashes the following commits:\n\ncc39713 [Ryan Blue] PARQUET-150: Update merge script issue id matching.\n",
            "diff": {
                "dev/merge_parquet_pr.py": 2
            },
            "is_test": false,
            "is_fix": false
        },
        "0fcfe617859603a31fac471255cf5bef7190714b": {
            "datetime": "2014-12-18T15:33:56-08:00",
            "summary": "PARQUET-23: Refactor parquet-format to org.apache names.",
            "message": "PARQUET-23: Refactor parquet-format to org.apache names.\n\nThis updates parquet-format to use org.apache names. Still need to:\n* Validate that parquet-mr works as expected when relying on these changes\n\nAuthor: Ryan Blue <blue@apache.org>\n\nCloses #18 from rdblue/PARQUET-23-rename-to-org-apache and squashes the following commits:\n\nddcd50e [Ryan Blue] PARQUET-23: Update changelog for org.apache parquet-format 2.2.0.\n5c339d4 [Ryan Blue] PARQUET-23: Update POM to use Apache maven release config.\nac982ca [Ryan Blue] PARQUET-23: Refactor parquet-format to org.apache names.\n",
            "diff": {
                "src/main/java/parquet/format/InterningProtocol.java": 2,
                "src/main/java/parquet/format/Util.java": 36,
                "src/main/java/parquet/format/event/Consumers.java": 10,
                "src/main/java/parquet/format/event/EventBasedThriftReader.java": 8,
                "src/main/java/parquet/format/event/FieldConsumer.java": 2,
                "src/main/java/parquet/format/event/TypedConsumer.java": 2,
                "src/test/java/parquet/format/TestUtil.java": 8
            },
            "is_test": true,
            "is_fix": false
        },
        "23db4eb88aa018da25563586bab322e7c1867ad5": {
            "datetime": "2014-12-29T09:17:34-06:00",
            "summary": "PARQUET-108: Parquet Memory Management in Java",
            "message": "PARQUET-108: Parquet Memory Management in Java\n\nPARQUET-108: Parquet Memory Management in Java.\nWhen Parquet tries to write very large \"row groups\", it may causes tasks to run out of memory during dynamic partitions when a reducer may have many Parquet files open at a given time.\n\nThis patch implements a memory manager to control the total memory size used by writers and balance their memory usage, which ensures that we don't run out of memory due to writing too many row groups within a single JVM.\n\nAuthor: dongche1 <dong1.chen@intel.com>\n\nCloses #80 from dongche/master and squashes the following commits:\n\ne511f85 [dongche1] Merge remote branch 'upstream/master'\n60a96b5 [dongche1] Merge remote branch 'upstream/master'\n2d17212 [dongche1] improve MemoryManger instantiation, change access level\n6e9333e [dongche1] change blocksize type from int to long\ne07b16e [dongche1] Refine updateAllocation(), addWriter(). Remove redundant getMemoryPoolRatio\n9a0a831 [dongche1] log the inconsistent ratio config instead of thowing an exception\n3a35d22 [dongche1] Move the creation of MemoryManager. Throw exception instead of logging it\naeda7bc [dongche1] PARQUET-108: Parquet Memory Management in Java\" ;\nc883bba [dongche1] PARQUET-108: Parquet Memory Management in Java\n7b45b2c [dongche1] PARQUET-108: Parquet Memory Management in Java\n6d766aa [dongche1] PARQUET-108: Parquet Memory Management in Java --- address some comments\n3abfe2b [dongche1] parquet 108\n",
            "diff": {
                "parquet-hadoop/src/main/java/parquet/hadoop/InternalParquetRecordWriter.java": 28,
                "parquet-hadoop/src/main/java/parquet/hadoop/MemoryManager.java": 137,
                "parquet-hadoop/src/main/java/parquet/hadoop/ParquetInputSplit.java": 23,
                "parquet-hadoop/src/main/java/parquet/hadoop/ParquetOutputFormat.java": 30,
                "parquet-hadoop/src/main/java/parquet/hadoop/ParquetRecordWriter.java": 45,
                "parquet-hadoop/src/test/java/parquet/hadoop/TestInputFormat.java": 38,
                "parquet-hadoop/src/test/java/parquet/hadoop/TestMemoryManager.java": 103
            },
            "is_test": true,
            "is_fix": false
        },
        "52f3240d90f2397cd1850ab11674ba08a0ecb2a0": {
            "datetime": "2015-01-12T16:01:06-08:00",
            "summary": "PARQUET-141: upgrade to scrooge 3.17.0, remove reflection based field info inspection...",
            "message": "PARQUET-141: upgrade to scrooge 3.17.0, remove reflection based field info inspection...\n\nupgrade to scrooge 3.17.0, remove reflection based field info inspection, support enum and requirement type correctly\n\nThis PR is essential for scrooge write support https://github.com/apache/incubator-parquet-mr/pull/58\n\nAuthor: Tianshuo Deng <tdeng@twitter.com>\n\nCloses #88 from tsdeng/scrooge_schema_converter_upgrade and squashes the following commits:\n\n77cc12a [Tianshuo Deng] delete empty line, retrigger jenkins\n80d61ad [Tianshuo Deng] format\n26e1fe1 [Tianshuo Deng] fix exception handling\n706497d [Tianshuo Deng] support union\n1b51f0f [Tianshuo Deng] upgrade to scrooge 3.17.0, remove reflection based field info inspection, support enum and requirement type correctly\n",
            "diff": {
                "parquet-scrooge/src/main/java/parquet/scrooge/ScroogeSchemaConversionException.java": 18,
                "parquet-scrooge/src/main/java/parquet/scrooge/ScroogeStructConverter.java": 191,
                "parquet-scrooge/src/test/java/parquet/scrooge/ScroogeStructConverterTest.java": 11
            },
            "is_test": true,
            "is_fix": false
        },
        "d70fdbc40195077057a1edb14ccd16a26435d007": {
            "datetime": "2015-01-23T16:20:10-08:00",
            "summary": "PARQUET-168: Fixes parquet-tools command line option description",
            "message": "PARQUET-168: Fixes parquet-tools command line option description\n\n<!-- Reviewable:start -->\n[<img src=\"https://reviewable.io/review_button.png\" height=40 alt=\"Review on Reviewable\"/>](https://reviewable.io/reviews/apache/incubator-parquet-mr/106)\n<!-- Reviewable:end -->\n\nAuthor: Cheng Lian <lian@databricks.com>\n\nCloses #106 from liancheng/PARQUET-168 and squashes the following commits:\n\n4524f2d [Cheng Lian] Fixes command line option description\n",
            "diff": {
                "parquet-tools/src/main/java/parquet/tools/Main.java": 4
            },
            "is_test": false,
            "is_fix": false
        },
        "4bf9be34a87b51d07e0b0c9e74831bbcdbce0f74": {
            "datetime": "2015-01-26T18:21:11-08:00",
            "summary": "PARQUET-136: NPE thrown in StatisticsFilter when all values in a string/binary column trunk are null",
            "message": "PARQUET-136: NPE thrown in StatisticsFilter when all values in a string/binary column trunk are null\n\nIn case of all nulls in a binary column, statistics object read from file metadata is empty, and should return true for all nulls check for the column. Even if column has no values, it can be ignored.\n\nThe other way is to fix this behaviour in the writer, but is that what we want ?\n\nAuthor: Yash Datta <Yash.Datta@guavus.com>\nAuthor: Alex Levenson <alexlevenson@twitter.com>\nAuthor: Yash Datta <saucam@gmail.com>\n\nCloses #99 from saucam/npe and squashes the following commits:\n\n5138e44 [Yash Datta] PARQUET-136: Remove unreachable block\nb17cd38 [Yash Datta] Revert \"PARQUET-161: Trigger tests\"\n82209e6 [Yash Datta] PARQUET-161: Trigger tests\naab2f81 [Yash Datta] PARQUET-161: Review comments for the test case\n2217ee2 [Yash Datta] PARQUET-161: Add a test case for checking the correct statistics info is recorded in case of all nulls in a column\nc2f8d6f [Yash Datta] PARQUET-161: Fix the write path to write statistics object in case of only nulls in the column\n97bb517 [Yash Datta] Revert \"revert TestStatisticsFilter.java\"\na06f0d0 [Yash Datta] Merge pull request #1 from isnotinvain/alexlevenson/PARQUET-161-136\nb1001eb [Alex Levenson] Fix statistics isEmpty, handle more edge cases in statistics filter\n0c88be0 [Alex Levenson] revert TestStatisticsFilter.java\n1ac9192 [Yash Datta] PARQUET-136: Its better to not filter chunks for which empty statistics object is returned. Empty statistics can be read in case of 1. pre-statistics files, 2. files written from current writer that has a bug, as it does not write the statistics if column has all nulls\ne5e924e [Yash Datta] Revert \"PARQUET-136: In case of all nulls in a binary column, statistics object read from file metadata is empty, and should return true for all nulls check for the column\"\n8cc5106 [Yash Datta] Revert \"PARQUET-136: fix hasNulls to cater to the case where all values are nulls\"\nc7c126f [Yash Datta] PARQUET-136: fix hasNulls to cater to the case where all values are nulls\n974a22b [Yash Datta] PARQUET-136: In case of all nulls in a binary column, statistics object read from file metadata is empty, and should return true for all nulls check for the column\n",
            "diff": {
                "parquet-column/src/main/java/parquet/column/statistics/BinaryStatistics.java": 10,
                "parquet-column/src/main/java/parquet/column/statistics/BooleanStatistics.java": 10,
                "parquet-column/src/main/java/parquet/column/statistics/DoubleStatistics.java": 8,
                "parquet-column/src/main/java/parquet/column/statistics/FloatStatistics.java": 8,
                "parquet-column/src/main/java/parquet/column/statistics/IntStatistics.java": 8,
                "parquet-column/src/main/java/parquet/column/statistics/LongStatistics.java": 8,
                "parquet-column/src/main/java/parquet/column/statistics/Statistics.java": 24,
                "parquet-hadoop/src/main/java/parquet/filter2/statisticslevel/StatisticsFilter.java": 63,
                "parquet-hadoop/src/main/java/parquet/format/converter/ParquetMetadataConverter.java": 10,
                "parquet-hadoop/src/test/java/parquet/filter2/statisticslevel/TestStatisticsFilter.java": 8,
                "parquet-hadoop/src/test/java/parquet/hadoop/TestParquetFileWriter.java": 36
            },
            "is_test": true,
            "is_fix": true
        },
        "0751f97bf6677c3d55aa71542d572dc8fcb9e79a": {
            "datetime": "2015-01-28T16:07:48-08:00",
            "summary": "PARQUET-174: Replaces AssertionError constructor introduced in Java7",
            "message": "PARQUET-174: Replaces AssertionError constructor introduced in Java7\n\nAssertionError(String, Throwable) was introduced in Java7. Replacing it with AssertionError(String) + initCause(Throwable)\n\nAuthor: Laurent Goujon <laurentgo@users.noreply.github.com>\n\nCloses #101 from laurentgo/fix-java7ism and squashes the following commits:\n\nc00fb7c [Laurent Goujon] Replaces AssertionError constructor introduced in Java7\n",
            "diff": {
                "parquet-hadoop/src/test/java/parquet/format/converter/TestParquetMetadataConverter.java": 2
            },
            "is_test": true,
            "is_fix": true
        },
        "e505e1fea57e0ab9f1d5edab92546d778a5f41e0": {
            "datetime": "2015-01-29T17:29:06-08:00",
            "summary": "PARQUET-124: normalize path checking to prevent mismatch between URI and ...",
            "message": "PARQUET-124: normalize path checking to prevent mismatch between URI and ...\n\n...path\n\nAuthor: Chris Albright <calbright@cj.com>\n\nCloses #79 from chrisalbright/master and squashes the following commits:\n\nb1b0086 [Chris Albright] Merge remote-tracking branch 'upstream/master'\n9669427 [Chris Albright] PARQUET-124: Adding test (Thanks Ryan Blue) that proves mergeFooters was failing\n8e342ed [Chris Albright] PARQUET-124: normalize path checking to prevent mismatch between URI and path\n",
            "diff": {
                "parquet-hadoop/src/main/java/parquet/hadoop/ParquetFileWriter.java": 18,
                "parquet-hadoop/src/test/java/parquet/hadoop/TestParquetFileWriter.java": 80
            },
            "is_test": true,
            "is_fix": true
        },
        "b4380f20059dc9e4ccfe2b709587e8069ac0fa34": {
            "datetime": "2015-01-29T17:31:04-08:00",
            "summary": "PARQUET-142: add path filter in ParquetReader",
            "message": "PARQUET-142: add path filter in ParquetReader\n\nCurrently parquet-tools command fails when input is a directory with _SUCCESS file from mapreduce. Filtering those out like ParquetFileReader does fixes the problem.\n\n```\nparquet-cat /tmp/parquet_write_test\nCould not read footer: java.lang.RuntimeException: file:/tmp/parquet_write_test/_SUCCESS is not a Parquet file (too small)\n\n$ tree /tmp/parquet_write_test\n/tmp/parquet_write_test\n\u251c\u2500\u2500 part-m-00000.parquet\n\u2514\u2500\u2500 _SUCCESS\n```\n\nAuthor: Neville Li <neville@spotify.com>\n\nCloses #89 from nevillelyh/gh/path-filter and squashes the following commits:\n\n7377a20 [Neville Li] PARQUET-142: add path filter in ParquetReader\n",
            "diff": {
                "parquet-hadoop/src/main/java/parquet/hadoop/ParquetReader.java": 8
            },
            "is_test": false,
            "is_fix": false
        },
        "32a9c6d42a3a48314d3f9fe2956bfc8bf49ac5d5": {
            "datetime": "2015-01-29T17:32:54-08:00",
            "summary": "PARQUET-157: Divide by zero fix",
            "message": "PARQUET-157: Divide by zero fix\n\nThere is a divide by zero error in logging code inside the InternalParquetRecordReader. I've been running with this fixed for a while but everytime I revert I hit the problem again. I can't believe anyone else hasn't had this problem. I submitted a Jira ticket a few weeks ago but didn't hear anything on the list so here's the fix.\n\nThis also avoids compiling log statements in some cases where it's unnecessary inside the checkRead method of InternalParquetRecordReader.\n\nAlso added a .gitignore entry to clean up a build artifact.\n\nAuthor: Jim Carroll <jim@dontcallme.com>\n\nCloses #102 from jimfcarroll/divide-by-zero-fix and squashes the following commits:\n\n423200c [Jim Carroll] Filter out parquet-scrooge build artifact from git.\n22337f3 [Jim Carroll] PARQUET-157: Fix a divide by zero error when Parquet runs quickly. Also avoid compiling log statements in some cases where it's unnecessary.\n",
            "diff": {
                "parquet-hadoop/src/main/java/parquet/hadoop/InternalParquetRecordReader.java": 19
            },
            "is_test": false,
            "is_fix": false
        },
        "3df3372a1ee7b6ea74af89f53a614895b8078609": {
            "datetime": "2015-02-02T16:43:01-08:00",
            "summary": "PARQUET-111: Updates for apache release",
            "message": "PARQUET-111: Updates for apache release\n\nUpdates for first Apache release of parquet-mr.\n\nAuthor: Ryan Blue <blue@apache.org>\n\nCloses #109 from rdblue/PARQUET-111-update-for-apache-release and squashes the following commits:\n\nbf19849 [Ryan Blue] PARQUET-111: Add ARRIS copyright header to parquet-tools.\nf1a5c28 [Ryan Blue] PARQUET-111: Update headers in parquet-protobuf.\nee4ea88 [Ryan Blue] PARQUET-111: Remove leaked LICENSE and NOTICE files.\n5bf178b [Ryan Blue] PARQUET-111: Update module names, urls, and binary LICENSE files.\n6736320 [Ryan Blue] PARQUET-111: Add RAT exclusion for auto-generated POM files.\n7db4553 [Ryan Blue] PARQUET-111: Add attribution for Spark dev script to LICENSE.\n45e29f2 [Ryan Blue] PARQUET-111: Update LICENSE and NOTICE.\n516c058 [Ryan Blue] PARQUET-111: Update license headers to pass RAT check.\nda688e3 [Ryan Blue] PARQUET-111: Update NOTICE with Apache boilerplate.\n234715d [Ryan Blue] PARQUET-111: Add DISCLAIMER and KEYS.\nf1d3601 [Ryan Blue] PARQUET-111: Update to use Apache parent POM.\n",
            "diff": {
                "parquet-avro/src/main/java/parquet/avro/AvroDataSupplier.java": 31,
                "parquet-avro/src/main/java/parquet/avro/AvroIndexedRecordConverter.java": 31,
                "parquet-avro/src/main/java/parquet/avro/AvroParquetInputFormat.java": 31,
                "parquet-avro/src/main/java/parquet/avro/AvroParquetOutputFormat.java": 31,
                "parquet-avro/src/main/java/parquet/avro/AvroParquetReader.java": 31,
                "parquet-avro/src/main/java/parquet/avro/AvroParquetWriter.java": 31,
                "parquet-avro/src/main/java/parquet/avro/AvroReadSupport.java": 31,
                "parquet-avro/src/main/java/parquet/avro/AvroRecordMaterializer.java": 31,
                "parquet-avro/src/main/java/parquet/avro/AvroSchemaConverter.java": 31,
                "parquet-avro/src/main/java/parquet/avro/AvroWriteSupport.java": 31,
                "parquet-avro/src/main/java/parquet/avro/SpecificDataSupplier.java": 31,
                "parquet-avro/src/main/java/parquet/avro/package-info.java": 31,
                "parquet-avro/src/test/java/parquet/avro/TestAvroSchemaConverter.java": 31,
                "parquet-avro/src/test/java/parquet/avro/TestInputOutputFormat.java": 31,
                "parquet-avro/src/test/java/parquet/avro/TestReadWrite.java": 31,
                "parquet-avro/src/test/java/parquet/avro/TestSpecificInputOutputFormat.java": 31,
                "parquet-avro/src/test/java/parquet/avro/TestSpecificReadWrite.java": 31,
                "parquet-cascading/src/main/java/parquet/cascading/ParquetTBaseScheme.java": 31,
                "parquet-cascading/src/main/java/parquet/cascading/ParquetTupleScheme.java": 31,
                "parquet-cascading/src/main/java/parquet/cascading/ParquetValueScheme.java": 31,
                "parquet-cascading/src/main/java/parquet/cascading/SchemaIntersection.java": 31,
                "parquet-cascading/src/main/java/parquet/cascading/TupleReadSupport.java": 31,
                "parquet-cascading/src/main/java/parquet/cascading/TupleWriteSupport.java": 31,
                "parquet-cascading/src/main/java/parquet/cascading/convert/TupleConverter.java": 31,
                "parquet-cascading/src/main/java/parquet/cascading/convert/TupleRecordMaterializer.java": 31,
                "parquet-cascading/src/test/java/parquet/cascading/TestParquetTBaseScheme.java": 31,
                "parquet-cascading/src/test/java/parquet/cascading/TestParquetTupleScheme.java": 31,
                "parquet-column/src/main/java/parquet/column/ColumnDescriptor.java": 31,
                "parquet-column/src/main/java/parquet/column/ColumnReadStore.java": 31,
                "parquet-column/src/main/java/parquet/column/ColumnReader.java": 31,
                "parquet-column/src/main/java/parquet/column/ColumnWriteStore.java": 31,
                "parquet-column/src/main/java/parquet/column/ColumnWriter.java": 31,
                "parquet-column/src/main/java/parquet/column/Dictionary.java": 31,
                "parquet-column/src/main/java/parquet/column/Encoding.java": 31,
                "parquet-column/src/main/java/parquet/column/ParquetProperties.java": 18,
                "parquet-column/src/main/java/parquet/column/UnknownColumnException.java": 31,
                "parquet-column/src/main/java/parquet/column/UnknownColumnTypeException.java": 31,
                "parquet-column/src/main/java/parquet/column/ValuesType.java": 31,
                "parquet-column/src/main/java/parquet/column/impl/ColumnReadStoreImpl.java": 31,
                "parquet-column/src/main/java/parquet/column/impl/ColumnReaderImpl.java": 31,
                "parquet-column/src/main/java/parquet/column/impl/ColumnWriteStoreV1.java": 31,
                "parquet-column/src/main/java/parquet/column/impl/ColumnWriteStoreV2.java": 31,
                "parquet-column/src/main/java/parquet/column/impl/ColumnWriterV1.java": 31,
                "parquet-column/src/main/java/parquet/column/impl/ColumnWriterV2.java": 31,
                "parquet-column/src/main/java/parquet/column/page/DataPage.java": 31,
                "parquet-column/src/main/java/parquet/column/page/DataPageV1.java": 18,
                "parquet-column/src/main/java/parquet/column/page/DataPageV2.java": 18,
                "parquet-column/src/main/java/parquet/column/page/DictionaryPage.java": 31,
                "parquet-column/src/main/java/parquet/column/page/Page.java": 18,
                "parquet-column/src/main/java/parquet/column/page/PageReadStore.java": 31,
                "parquet-column/src/main/java/parquet/column/page/PageReader.java": 31,
                "parquet-column/src/main/java/parquet/column/page/PageWriteStore.java": 31,
                "parquet-column/src/main/java/parquet/column/page/PageWriter.java": 31,
                "parquet-column/src/main/java/parquet/column/statistics/BinaryStatistics.java": 31,
                "parquet-column/src/main/java/parquet/column/statistics/BooleanStatistics.java": 31,
                "parquet-column/src/main/java/parquet/column/statistics/DoubleStatistics.java": 31,
                "parquet-column/src/main/java/parquet/column/statistics/FloatStatistics.java": 31,
                "parquet-column/src/main/java/parquet/column/statistics/IntStatistics.java": 31,
                "parquet-column/src/main/java/parquet/column/statistics/LongStatistics.java": 31,
                "parquet-column/src/main/java/parquet/column/statistics/Statistics.java": 31,
                "parquet-column/src/main/java/parquet/column/statistics/StatisticsClassException.java": 31,
                "parquet-column/src/main/java/parquet/column/values/RequiresFallback.java": 31,
                "parquet-column/src/main/java/parquet/column/values/ValuesReader.java": 31,
                "parquet-column/src/main/java/parquet/column/values/ValuesWriter.java": 31,
                "parquet-column/src/main/java/parquet/column/values/bitpacking/BitPackingValuesReader.java": 31,
                "parquet-column/src/main/java/parquet/column/values/bitpacking/BitPackingValuesWriter.java": 31,
                "parquet-column/src/main/java/parquet/column/values/bitpacking/ByteBitPackingValuesReader.java": 31,
                "parquet-column/src/main/java/parquet/column/values/bitpacking/ByteBitPackingValuesWriter.java": 31,
                "parquet-column/src/main/java/parquet/column/values/boundedint/BitReader.java": 31,
                "parquet-column/src/main/java/parquet/column/values/boundedint/BitWriter.java": 31,
                "parquet-column/src/main/java/parquet/column/values/boundedint/BoundedIntValuesFactory.java": 31,
                "parquet-column/src/main/java/parquet/column/values/boundedint/BoundedIntValuesReader.java": 31,
                "parquet-column/src/main/java/parquet/column/values/boundedint/BoundedIntValuesWriter.java": 31,
                "parquet-column/src/main/java/parquet/column/values/boundedint/DevNullValuesWriter.java": 31,
                "parquet-column/src/main/java/parquet/column/values/boundedint/ZeroIntegerValuesReader.java": 31,
                "parquet-column/src/main/java/parquet/column/values/delta/DeltaBinaryPackingConfig.java": 31,
                "parquet-column/src/main/java/parquet/column/values/delta/DeltaBinaryPackingValuesReader.java": 31,
                "parquet-column/src/main/java/parquet/column/values/delta/DeltaBinaryPackingValuesWriter.java": 31,
                "parquet-column/src/main/java/parquet/column/values/deltalengthbytearray/DeltaLengthByteArrayValuesReader.java": 31,
                "parquet-column/src/main/java/parquet/column/values/deltalengthbytearray/DeltaLengthByteArrayValuesWriter.java": 31,
                "parquet-column/src/main/java/parquet/column/values/deltastrings/DeltaByteArrayReader.java": 31,
                "parquet-column/src/main/java/parquet/column/values/deltastrings/DeltaByteArrayWriter.java": 31,
                "parquet-column/src/main/java/parquet/column/values/dictionary/DictionaryValuesReader.java": 31,
                "parquet-column/src/main/java/parquet/column/values/dictionary/DictionaryValuesWriter.java": 31,
                "parquet-column/src/main/java/parquet/column/values/dictionary/IntList.java": 31,
                "parquet-column/src/main/java/parquet/column/values/dictionary/PlainValuesDictionary.java": 31,
                "parquet-column/src/main/java/parquet/column/values/fallback/FallbackValuesWriter.java": 31,
                "parquet-column/src/main/java/parquet/column/values/plain/BinaryPlainValuesReader.java": 31,
                "parquet-column/src/main/java/parquet/column/values/plain/BooleanPlainValuesReader.java": 31,
                "parquet-column/src/main/java/parquet/column/values/plain/BooleanPlainValuesWriter.java": 31,
                "parquet-column/src/main/java/parquet/column/values/plain/FixedLenByteArrayPlainValuesReader.java": 31,
                "parquet-column/src/main/java/parquet/column/values/plain/FixedLenByteArrayPlainValuesWriter.java": 31,
                "parquet-column/src/main/java/parquet/column/values/plain/PlainValuesReader.java": 31,
                "parquet-column/src/main/java/parquet/column/values/plain/PlainValuesWriter.java": 31,
                "parquet-column/src/main/java/parquet/column/values/rle/RunLengthBitPackingHybridDecoder.java": 31,
                "parquet-column/src/main/java/parquet/column/values/rle/RunLengthBitPackingHybridEncoder.java": 31,
                "parquet-column/src/main/java/parquet/column/values/rle/RunLengthBitPackingHybridValuesReader.java": 31,
                "parquet-column/src/main/java/parquet/column/values/rle/RunLengthBitPackingHybridValuesWriter.java": 31,
                "parquet-column/src/main/java/parquet/example/DummyRecordConverter.java": 31,
                "parquet-column/src/main/java/parquet/example/Paper.java": 31,
                "parquet-column/src/main/java/parquet/example/data/Group.java": 31,
                "parquet-column/src/main/java/parquet/example/data/GroupFactory.java": 31,
                "parquet-column/src/main/java/parquet/example/data/GroupValueSource.java": 31,
                "parquet-column/src/main/java/parquet/example/data/GroupWriter.java": 31,
                "parquet-column/src/main/java/parquet/example/data/simple/BinaryValue.java": 31,
                "parquet-column/src/main/java/parquet/example/data/simple/BooleanValue.java": 31,
                "parquet-column/src/main/java/parquet/example/data/simple/DoubleValue.java": 31,
                "parquet-column/src/main/java/parquet/example/data/simple/FloatValue.java": 31,
                "parquet-column/src/main/java/parquet/example/data/simple/Int96Value.java": 18,
                "parquet-column/src/main/java/parquet/example/data/simple/IntegerValue.java": 31,
                "parquet-column/src/main/java/parquet/example/data/simple/LongValue.java": 31,
                "parquet-column/src/main/java/parquet/example/data/simple/NanoTime.java": 18,
                "parquet-column/src/main/java/parquet/example/data/simple/Primitive.java": 31,
                "parquet-column/src/main/java/parquet/example/data/simple/SimpleGroup.java": 31,
                "parquet-column/src/main/java/parquet/example/data/simple/SimpleGroupFactory.java": 31,
                "parquet-column/src/main/java/parquet/example/data/simple/convert/GroupRecordConverter.java": 31,
                "parquet-column/src/main/java/parquet/example/data/simple/convert/SimpleGroupConverter.java": 31,
                "parquet-column/src/main/java/parquet/example/data/simple/convert/SimplePrimitiveConverter.java": 31,
                "parquet-column/src/main/java/parquet/filter/AndRecordFilter.java": 31,
                "parquet-column/src/main/java/parquet/filter/ColumnPredicates.java": 31,
                "parquet-column/src/main/java/parquet/filter/ColumnRecordFilter.java": 31,
                "parquet-column/src/main/java/parquet/filter/NotRecordFilter.java": 31,
                "parquet-column/src/main/java/parquet/filter/OrRecordFilter.java": 31,
                "parquet-column/src/main/java/parquet/filter/PagedRecordFilter.java": 31,
                "parquet-column/src/main/java/parquet/filter/RecordFilter.java": 31,
                "parquet-column/src/main/java/parquet/filter/UnboundRecordFilter.java": 31,
                "parquet-column/src/main/java/parquet/filter2/compat/FilterCompat.java": 18,
                "parquet-column/src/main/java/parquet/filter2/predicate/FilterApi.java": 18,
                "parquet-column/src/main/java/parquet/filter2/predicate/FilterPredicate.java": 18,
                "parquet-column/src/main/java/parquet/filter2/predicate/LogicalInverseRewriter.java": 18,
                "parquet-column/src/main/java/parquet/filter2/predicate/LogicalInverter.java": 18,
                "parquet-column/src/main/java/parquet/filter2/predicate/Operators.java": 18,
                "parquet-column/src/main/java/parquet/filter2/predicate/SchemaCompatibilityValidator.java": 18,
                "parquet-column/src/main/java/parquet/filter2/predicate/Statistics.java": 18,
                "parquet-column/src/main/java/parquet/filter2/predicate/UserDefinedPredicate.java": 18,
                "parquet-column/src/main/java/parquet/filter2/predicate/ValidTypeMap.java": 18,
                "parquet-column/src/main/java/parquet/filter2/recordlevel/FilteringGroupConverter.java": 18,
                "parquet-column/src/main/java/parquet/filter2/recordlevel/FilteringPrimitiveConverter.java": 18,
                "parquet-column/src/main/java/parquet/filter2/recordlevel/FilteringRecordMaterializer.java": 18,
                "parquet-column/src/main/java/parquet/filter2/recordlevel/IncrementallyUpdatedFilterPredicate.java": 18,
                "parquet-column/src/main/java/parquet/filter2/recordlevel/IncrementallyUpdatedFilterPredicateBuilderBase.java": 18,
                "parquet-column/src/main/java/parquet/filter2/recordlevel/IncrementallyUpdatedFilterPredicateEvaluator.java": 18,
                "parquet-column/src/main/java/parquet/filter2/recordlevel/IncrementallyUpdatedFilterPredicateResetter.java": 18,
                "parquet-column/src/main/java/parquet/io/BaseRecordReader.java": 31,
                "parquet-column/src/main/java/parquet/io/ColumnIO.java": 31,
                "parquet-column/src/main/java/parquet/io/ColumnIOFactory.java": 31,
                "parquet-column/src/main/java/parquet/io/CompilationException.java": 31,
                "parquet-column/src/main/java/parquet/io/EmptyRecordReader.java": 31,
                "parquet-column/src/main/java/parquet/io/FilteredRecordReader.java": 31,
                "parquet-column/src/main/java/parquet/io/GroupColumnIO.java": 31,
                "parquet-column/src/main/java/parquet/io/InvalidRecordException.java": 31,
                "parquet-column/src/main/java/parquet/io/MessageColumnIO.java": 31,
                "parquet-column/src/main/java/parquet/io/ParquetDecodingException.java": 31,
                "parquet-column/src/main/java/parquet/io/ParquetEncodingException.java": 31,
                "parquet-column/src/main/java/parquet/io/PrimitiveColumnIO.java": 31,
                "parquet-column/src/main/java/parquet/io/RecordConsumerLoggingWrapper.java": 31,
                "parquet-column/src/main/java/parquet/io/RecordReader.java": 31,
                "parquet-column/src/main/java/parquet/io/RecordReaderImplementation.java": 31,
                "parquet-column/src/main/java/parquet/io/ValidatingRecordConsumer.java": 31,
                "parquet-column/src/main/java/parquet/io/api/Binary.java": 31,
                "parquet-column/src/main/java/parquet/io/api/Converter.java": 31,
                "parquet-column/src/main/java/parquet/io/api/GroupConverter.java": 31,
                "parquet-column/src/main/java/parquet/io/api/PrimitiveConverter.java": 31,
                "parquet-column/src/main/java/parquet/io/api/RecordConsumer.java": 31,
                "parquet-column/src/main/java/parquet/io/api/RecordMaterializer.java": 31,
                "parquet-column/src/main/java/parquet/schema/ConversionPatterns.java": 31,
                "parquet-column/src/main/java/parquet/schema/DecimalMetadata.java": 18,
                "parquet-column/src/main/java/parquet/schema/GroupType.java": 31,
                "parquet-column/src/main/java/parquet/schema/IncompatibleSchemaModificationException.java": 31,
                "parquet-column/src/main/java/parquet/schema/MessageType.java": 31,
                "parquet-column/src/main/java/parquet/schema/MessageTypeParser.java": 31,
                "parquet-column/src/main/java/parquet/schema/OriginalType.java": 31,
                "parquet-column/src/main/java/parquet/schema/PrimitiveType.java": 31,
                "parquet-column/src/main/java/parquet/schema/Type.java": 31,
                "parquet-column/src/main/java/parquet/schema/TypeConverter.java": 31,
                "parquet-column/src/main/java/parquet/schema/TypeVisitor.java": 31,
                "parquet-column/src/main/java/parquet/schema/Types.java": 18,
                "parquet-column/src/test/java/parquet/column/impl/TestColumnReaderImpl.java": 18,
                "parquet-column/src/test/java/parquet/column/mem/TestMemColumn.java": 31,
                "parquet-column/src/test/java/parquet/column/mem/TestMemPageStore.java": 31,
                "parquet-column/src/test/java/parquet/column/page/mem/MemPageReader.java": 31,
                "parquet-column/src/test/java/parquet/column/page/mem/MemPageStore.java": 31,
                "parquet-column/src/test/java/parquet/column/page/mem/MemPageWriter.java": 31,
                "parquet-column/src/test/java/parquet/column/statistics/TestStatistics.java": 31,
                "parquet-column/src/test/java/parquet/column/values/RandomStr.java": 31,
                "parquet-column/src/test/java/parquet/column/values/Utils.java": 31,
                "parquet-column/src/test/java/parquet/column/values/bitpacking/BitPackingPerfTest.java": 31,
                "parquet-column/src/test/java/parquet/column/values/bitpacking/TestBitPackingColumn.java": 31,
                "parquet-column/src/test/java/parquet/column/values/boundedint/TestBoundedColumns.java": 31,
                "parquet-column/src/test/java/parquet/column/values/delta/DeltaBinaryPackingValuesWriterTest.java": 31,
                "parquet-column/src/test/java/parquet/column/values/delta/benchmark/BenchMarkTest.java": 31,
                "parquet-column/src/test/java/parquet/column/values/delta/benchmark/BenchmarkIntegerOutputSize.java": 31,
                "parquet-column/src/test/java/parquet/column/values/delta/benchmark/BenchmarkReadingRandomIntegers.java": 31,
                "parquet-column/src/test/java/parquet/column/values/delta/benchmark/RandomWritingBenchmarkTest.java": 31,
                "parquet-column/src/test/java/parquet/column/values/delta/benchmark/SmallRangeWritingBenchmarkTest.java": 31,
                "parquet-column/src/test/java/parquet/column/values/deltalengthbytearray/TestDeltaLengthByteArray.java": 31,
                "parquet-column/src/test/java/parquet/column/values/deltalengthbytearray/benchmark/BenchmarkDeltaLengthByteArray.java": 31,
                "parquet-column/src/test/java/parquet/column/values/deltastrings/TestDeltaByteArray.java": 31,
                "parquet-column/src/test/java/parquet/column/values/deltastrings/benchmark/BenchmarkDeltaByteArray.java": 31,
                "parquet-column/src/test/java/parquet/column/values/dictionary/TestDictionary.java": 31,
                "parquet-column/src/test/java/parquet/column/values/rle/RunLengthBitPackingHybridIntegrationTest.java": 31,
                "parquet-column/src/test/java/parquet/column/values/rle/TestRunLengthBitPackingHybridEncoder.java": 31,
                "parquet-column/src/test/java/parquet/filter2/predicate/DummyUdp.java": 18,
                "parquet-column/src/test/java/parquet/filter2/predicate/TestFilterApiMethods.java": 18,
                "parquet-column/src/test/java/parquet/filter2/predicate/TestLogicalInverseRewriter.java": 18,
                "parquet-column/src/test/java/parquet/filter2/predicate/TestLogicalInverter.java": 18,
                "parquet-column/src/test/java/parquet/filter2/predicate/TestSchemaCompatibilityValidator.java": 18,
                "parquet-column/src/test/java/parquet/filter2/predicate/TestValidTypeMap.java": 18,
                "parquet-column/src/test/java/parquet/filter2/recordlevel/TestIncrementallyUpdatedFilterPredicateEvaluator.java": 18,
                "parquet-column/src/test/java/parquet/filter2/recordlevel/TestIncrementallyUpdatedFilterPredicateResetter.java": 18,
                "parquet-column/src/test/java/parquet/filter2/recordlevel/TestValueInspector.java": 18,
                "parquet-column/src/test/java/parquet/io/ConverterConsumer.java": 31,
                "parquet-column/src/test/java/parquet/io/ExpectationValidatingConverter.java": 31,
                "parquet-column/src/test/java/parquet/io/ExpectationValidatingRecordConsumer.java": 31,
                "parquet-column/src/test/java/parquet/io/PerfTest.java": 31,
                "parquet-column/src/test/java/parquet/io/TestColumnIO.java": 31,
                "parquet-column/src/test/java/parquet/io/TestFiltered.java": 31,
                "parquet-column/src/test/java/parquet/parser/TestParquetParser.java": 31,
                "parquet-column/src/test/java/parquet/schema/TestMessageType.java": 31,
                "parquet-column/src/test/java/parquet/schema/TestTypeBuilders.java": 18,
                "parquet-common/src/main/java/parquet/Closeables.java": 18,
                "parquet-common/src/main/java/parquet/Ints.java": 31,
                "parquet-common/src/main/java/parquet/Log.java": 31,
                "parquet-common/src/main/java/parquet/ParquetRuntimeException.java": 31,
                "parquet-common/src/main/java/parquet/Preconditions.java": 31,
                "parquet-common/src/main/java/parquet/Version.java": 31,
                "parquet-common/src/main/java/parquet/bytes/BytesUtils.java": 31,
                "parquet-common/src/main/java/parquet/common/internal/Canonicalizer.java": 31,
                "parquet-common/src/main/java/parquet/common/schema/ColumnPath.java": 31,
                "parquet-common/src/test/java/parquet/TestLog.java": 31,
                "parquet-common/src/test/java/parquet/bytes/TestBytesUtil.java": 31,
                "parquet-encoding/src/main/java/parquet/bytes/BytesInput.java": 31,
                "parquet-encoding/src/main/java/parquet/bytes/CapacityByteArrayOutputStream.java": 31,
                "parquet-encoding/src/main/java/parquet/bytes/LittleEndianDataInputStream.java": 31,
                "parquet-encoding/src/main/java/parquet/bytes/LittleEndianDataOutputStream.java": 31,
                "parquet-encoding/src/main/java/parquet/column/values/bitpacking/BitPacking.java": 31,
                "parquet-encoding/src/main/java/parquet/column/values/bitpacking/ByteBasedBitPackingEncoder.java": 31,
                "parquet-encoding/src/main/java/parquet/column/values/bitpacking/BytePacker.java": 31,
                "parquet-encoding/src/main/java/parquet/column/values/bitpacking/BytePackerFactory.java": 31,
                "parquet-encoding/src/main/java/parquet/column/values/bitpacking/IntPacker.java": 31,
                "parquet-encoding/src/main/java/parquet/column/values/bitpacking/IntPackerFactory.java": 31,
                "parquet-encoding/src/main/java/parquet/column/values/bitpacking/Packer.java": 31,
                "parquet-encoding/src/test/java/parquet/bytes/TestCapacityByteArrayOutputStream.java": 31,
                "parquet-encoding/src/test/java/parquet/column/values/bitpacking/TestBitPacking.java": 31,
                "parquet-encoding/src/test/java/parquet/column/values/bitpacking/TestByteBasedBitPackingEncoder.java": 31,
                "parquet-encoding/src/test/java/parquet/column/values/bitpacking/TestByteBitPacking.java": 31,
                "parquet-encoding/src/test/java/parquet/column/values/bitpacking/TestLemireBitPacking.java": 31,
                "parquet-generator/src/main/java/parquet/encoding/Generator.java": 31,
                "parquet-generator/src/main/java/parquet/encoding/bitpacking/ByteBasedBitPackingGenerator.java": 31,
                "parquet-generator/src/main/java/parquet/encoding/bitpacking/IntBasedBitPackingGenerator.java": 31,
                "parquet-generator/src/main/java/parquet/filter2/Generator.java": 18,
                "parquet-generator/src/main/java/parquet/filter2/IncrementallyUpdatedFilterPredicateGenerator.java": 18,
                "parquet-hadoop/src/main/java/parquet/filter2/compat/RowGroupFilter.java": 18,
                "parquet-hadoop/src/main/java/parquet/filter2/statisticslevel/StatisticsFilter.java": 18,
                "parquet-hadoop/src/main/java/parquet/format/converter/ParquetMetadataConverter.java": 31,
                "parquet-hadoop/src/main/java/parquet/hadoop/BadConfigurationException.java": 31,
                "parquet-hadoop/src/main/java/parquet/hadoop/CodecFactory.java": 31,
                "parquet-hadoop/src/main/java/parquet/hadoop/ColumnChunkPageReadStore.java": 31,
                "parquet-hadoop/src/main/java/parquet/hadoop/ColumnChunkPageWriteStore.java": 31,
                "parquet-hadoop/src/main/java/parquet/hadoop/Footer.java": 31,
                "parquet-hadoop/src/main/java/parquet/hadoop/InternalParquetRecordReader.java": 31,
                "parquet-hadoop/src/main/java/parquet/hadoop/InternalParquetRecordWriter.java": 31,
                "parquet-hadoop/src/main/java/parquet/hadoop/LruCache.java": 18,
                "parquet-hadoop/src/main/java/parquet/hadoop/MemoryManager.java": 31,
                "parquet-hadoop/src/main/java/parquet/hadoop/ParquetFileReader.java": 31,
                "parquet-hadoop/src/main/java/parquet/hadoop/ParquetFileWriter.java": 31,
                "parquet-hadoop/src/main/java/parquet/hadoop/ParquetInputFormat.java": 31,
                "parquet-hadoop/src/main/java/parquet/hadoop/ParquetInputSplit.java": 31,
                "parquet-hadoop/src/main/java/parquet/hadoop/ParquetOutputCommitter.java": 31,
                "parquet-hadoop/src/main/java/parquet/hadoop/ParquetOutputFormat.java": 31,
                "parquet-hadoop/src/main/java/parquet/hadoop/ParquetReader.java": 31,
                "parquet-hadoop/src/main/java/parquet/hadoop/ParquetRecordReader.java": 25,
                "parquet-hadoop/src/main/java/parquet/hadoop/ParquetRecordWriter.java": 31,
                "parquet-hadoop/src/main/java/parquet/hadoop/ParquetWriter.java": 31,
                "parquet-hadoop/src/main/java/parquet/hadoop/PrintFooter.java": 31,
                "parquet-hadoop/src/main/java/parquet/hadoop/api/DelegatingReadSupport.java": 18,
                "parquet-hadoop/src/main/java/parquet/hadoop/api/DelegatingWriteSupport.java": 18,
                "parquet-hadoop/src/main/java/parquet/hadoop/api/InitContext.java": 31,
                "parquet-hadoop/src/main/java/parquet/hadoop/api/ReadSupport.java": 31,
                "parquet-hadoop/src/main/java/parquet/hadoop/api/WriteSupport.java": 31,
                "parquet-hadoop/src/main/java/parquet/hadoop/api/package-info.java": 28,
                "parquet-hadoop/src/main/java/parquet/hadoop/codec/CodecConfig.java": 31,
                "parquet-hadoop/src/main/java/parquet/hadoop/codec/CompressionCodecNotSupportedException.java": 31,
                "parquet-hadoop/src/main/java/parquet/hadoop/codec/NonBlockedCompressorStream.java": 31,
                "parquet-hadoop/src/main/java/parquet/hadoop/codec/NonBlockedDecompressorStream.java": 31,
                "parquet-hadoop/src/main/java/parquet/hadoop/codec/SnappyCodec.java": 31,
                "parquet-hadoop/src/main/java/parquet/hadoop/codec/SnappyCompressor.java": 31,
                "parquet-hadoop/src/main/java/parquet/hadoop/codec/SnappyDecompressor.java": 31,
                "parquet-hadoop/src/main/java/parquet/hadoop/codec/SnappyUtil.java": 31,
                "parquet-hadoop/src/main/java/parquet/hadoop/example/ExampleInputFormat.java": 31,
                "parquet-hadoop/src/main/java/parquet/hadoop/example/ExampleOutputFormat.java": 31,
                "parquet-hadoop/src/main/java/parquet/hadoop/example/GroupReadSupport.java": 31,
                "parquet-hadoop/src/main/java/parquet/hadoop/example/GroupWriteSupport.java": 31,
                "parquet-hadoop/src/main/java/parquet/hadoop/mapred/Container.java": 31,
                "parquet-hadoop/src/main/java/parquet/hadoop/mapred/DeprecatedParquetInputFormat.java": 31,
                "parquet-hadoop/src/main/java/parquet/hadoop/mapred/DeprecatedParquetOutputFormat.java": 31,
                "parquet-hadoop/src/main/java/parquet/hadoop/metadata/BlockMetaData.java": 31,
                "parquet-hadoop/src/main/java/parquet/hadoop/metadata/ColumnChunkMetaData.java": 31,
                "parquet-hadoop/src/main/java/parquet/hadoop/metadata/ColumnChunkProperties.java": 31,
                "parquet-hadoop/src/main/java/parquet/hadoop/metadata/CompressionCodecName.java": 31,
                "parquet-hadoop/src/main/java/parquet/hadoop/metadata/EncodingList.java": 31,
                "parquet-hadoop/src/main/java/parquet/hadoop/metadata/FileMetaData.java": 31,
                "parquet-hadoop/src/main/java/parquet/hadoop/metadata/GlobalMetaData.java": 31,
                "parquet-hadoop/src/main/java/parquet/hadoop/metadata/ParquetMetadata.java": 31,
                "parquet-hadoop/src/main/java/parquet/hadoop/package-info.java": 28,
                "parquet-hadoop/src/main/java/parquet/hadoop/util/ConfigurationUtil.java": 31,
                "parquet-hadoop/src/main/java/parquet/hadoop/util/ContextUtil.java": 31,
                "parquet-hadoop/src/main/java/parquet/hadoop/util/SerializationUtil.java": 18,
                "parquet-hadoop/src/main/java/parquet/hadoop/util/counters/BenchmarkCounter.java": 31,
                "parquet-hadoop/src/main/java/parquet/hadoop/util/counters/CounterLoader.java": 31,
                "parquet-hadoop/src/main/java/parquet/hadoop/util/counters/ICounter.java": 31,
                "parquet-hadoop/src/main/java/parquet/hadoop/util/counters/mapred/MapRedCounterAdapter.java": 31,
                "parquet-hadoop/src/main/java/parquet/hadoop/util/counters/mapred/MapRedCounterLoader.java": 31,
                "parquet-hadoop/src/main/java/parquet/hadoop/util/counters/mapreduce/MapReduceCounterAdapter.java": 31,
                "parquet-hadoop/src/main/java/parquet/hadoop/util/counters/mapreduce/MapReduceCounterLoader.java": 31,
                "parquet-hadoop/src/test/java/parquet/filter2/compat/TestRowGroupFilter.java": 18,
                "parquet-hadoop/src/test/java/parquet/filter2/recordlevel/PhoneBookWriter.java": 18,
                "parquet-hadoop/src/test/java/parquet/filter2/recordlevel/TestRecordLevelFilters.java": 18,
                "parquet-hadoop/src/test/java/parquet/filter2/statisticslevel/TestStatisticsFilter.java": 18,
                "parquet-hadoop/src/test/java/parquet/format/converter/TestParquetMetadataConverter.java": 31,
                "parquet-hadoop/src/test/java/parquet/hadoop/DeprecatedInputFormatTest.java": 31,
                "parquet-hadoop/src/test/java/parquet/hadoop/DeprecatedOutputFormatTest.java": 31,
                "parquet-hadoop/src/test/java/parquet/hadoop/TestColumnChunkPageWriteStore.java": 18,
                "parquet-hadoop/src/test/java/parquet/hadoop/TestInputFormat.java": 31,
                "parquet-hadoop/src/test/java/parquet/hadoop/TestLruCache.java": 18,
                "parquet-hadoop/src/test/java/parquet/hadoop/TestMemoryManager.java": 31,
                "parquet-hadoop/src/test/java/parquet/hadoop/TestParquetFileWriter.java": 31,
                "parquet-hadoop/src/test/java/parquet/hadoop/TestParquetWriter.java": 18,
                "parquet-hadoop/src/test/java/parquet/hadoop/TestParquetWriterNewPage.java": 18,
                "parquet-hadoop/src/test/java/parquet/hadoop/TestSnappyCodec.java": 31,
                "parquet-hadoop/src/test/java/parquet/hadoop/TestUtils.java": 18,
                "parquet-hadoop/src/test/java/parquet/hadoop/codec/CodecConfigTest.java": 31,
                "parquet-hadoop/src/test/java/parquet/hadoop/example/GroupReadSupportTest.java": 31,
                "parquet-hadoop/src/test/java/parquet/hadoop/example/TestInputOutputFormat.java": 31,
                "parquet-hadoop/src/test/java/parquet/hadoop/metadata/TestColumnChunkMetaData.java": 18,
                "parquet-hadoop/src/test/java/parquet/hadoop/util/TestSerializationUtil.java": 18,
                "parquet-hive/parquet-hive-binding/parquet-hive-0.10-binding/src/main/java/parquet/hive/internal/Hive010Binding.java": 18,
                "parquet-hive/parquet-hive-binding/parquet-hive-0.12-binding/src/main/java/parquet/hive/internal/Hive012Binding.java": 18,
                "parquet-hive/parquet-hive-binding/parquet-hive-binding-factory/src/main/java/parquet/hive/HiveBindingFactory.java": 29,
                "parquet-hive/parquet-hive-binding/parquet-hive-binding-factory/src/test/java/parquet/hive/TestHiveBindingFactory.java": 18,
                "parquet-hive/parquet-hive-binding/parquet-hive-binding-interface/src/main/java/parquet/hive/HiveBinding.java": 29,
                "parquet-hive/parquet-hive-binding/parquet-hive-binding-interface/src/main/java/parquet/hive/internal/AbstractHiveBinding.java": 18,
                "parquet-hive/parquet-hive-storage-handler/src/main/java/org/apache/hadoop/hive/ql/io/IOConstants.java": 19,
                "parquet-hive/parquet-hive-storage-handler/src/main/java/org/apache/hadoop/hive/ql/io/parquet/MapredParquetInputFormat.java": 29,
                "parquet-hive/parquet-hive-storage-handler/src/main/java/org/apache/hadoop/hive/ql/io/parquet/MapredParquetOutputFormat.java": 29,
                "parquet-hive/parquet-hive-storage-handler/src/main/java/org/apache/hadoop/hive/ql/io/parquet/convert/ArrayWritableGroupConverter.java": 29,
                "parquet-hive/parquet-hive-storage-handler/src/main/java/org/apache/hadoop/hive/ql/io/parquet/convert/DataWritableGroupConverter.java": 29,
                "parquet-hive/parquet-hive-storage-handler/src/main/java/org/apache/hadoop/hive/ql/io/parquet/convert/DataWritableRecordConverter.java": 29,
                "parquet-hive/parquet-hive-storage-handler/src/main/java/org/apache/hadoop/hive/ql/io/parquet/convert/ETypeConverter.java": 29,
                "parquet-hive/parquet-hive-storage-handler/src/main/java/org/apache/hadoop/hive/ql/io/parquet/convert/HiveGroupConverter.java": 29,
                "parquet-hive/parquet-hive-storage-handler/src/main/java/org/apache/hadoop/hive/ql/io/parquet/convert/HiveSchemaConverter.java": 29,
                "parquet-hive/parquet-hive-storage-handler/src/main/java/org/apache/hadoop/hive/ql/io/parquet/read/DataWritableReadSupport.java": 29,
                "parquet-hive/parquet-hive-storage-handler/src/main/java/org/apache/hadoop/hive/ql/io/parquet/read/ParquetRecordReaderWrapper.java": 29,
                "parquet-hive/parquet-hive-storage-handler/src/main/java/org/apache/hadoop/hive/ql/io/parquet/serde/AbstractParquetMapInspector.java": 29,
                "parquet-hive/parquet-hive-storage-handler/src/main/java/org/apache/hadoop/hive/ql/io/parquet/serde/ArrayWritableObjectInspector.java": 29,
                "parquet-hive/parquet-hive-storage-handler/src/main/java/org/apache/hadoop/hive/ql/io/parquet/serde/DeepParquetHiveMapInspector.java": 29,
                "parquet-hive/parquet-hive-storage-handler/src/main/java/org/apache/hadoop/hive/ql/io/parquet/serde/ParquetHiveArrayInspector.java": 29,
                "parquet-hive/parquet-hive-storage-handler/src/main/java/org/apache/hadoop/hive/ql/io/parquet/serde/ParquetHiveSerDe.java": 29,
                "parquet-hive/parquet-hive-storage-handler/src/main/java/org/apache/hadoop/hive/ql/io/parquet/serde/StandardParquetHiveMapInspector.java": 29,
                "parquet-hive/parquet-hive-storage-handler/src/main/java/org/apache/hadoop/hive/ql/io/parquet/serde/primitive/ParquetByteInspector.java": 29,
                "parquet-hive/parquet-hive-storage-handler/src/main/java/org/apache/hadoop/hive/ql/io/parquet/serde/primitive/ParquetPrimitiveInspectorFactory.java": 29,
                "parquet-hive/parquet-hive-storage-handler/src/main/java/org/apache/hadoop/hive/ql/io/parquet/serde/primitive/ParquetShortInspector.java": 29,
                "parquet-hive/parquet-hive-storage-handler/src/main/java/org/apache/hadoop/hive/ql/io/parquet/writable/BigDecimalWritable.java": 29,
                "parquet-hive/parquet-hive-storage-handler/src/main/java/org/apache/hadoop/hive/ql/io/parquet/writable/BinaryWritable.java": 29,
                "parquet-hive/parquet-hive-storage-handler/src/main/java/org/apache/hadoop/hive/ql/io/parquet/write/DataWritableWriteSupport.java": 29,
                "parquet-hive/parquet-hive-storage-handler/src/main/java/org/apache/hadoop/hive/ql/io/parquet/write/DataWritableWriter.java": 29,
                "parquet-hive/parquet-hive-storage-handler/src/main/java/org/apache/hadoop/hive/ql/io/parquet/write/ParquetRecordWriterWrapper.java": 29,
                "parquet-hive/parquet-hive-storage-handler/src/main/java/org/apache/hadoop/hive/serde2/objectinspector/primitive/ParquetStringInspector.java": 29,
                "parquet-hive/parquet-hive-storage-handler/src/main/java/parquet/hive/DeprecatedParquetInputFormat.java": 29,
                "parquet-hive/parquet-hive-storage-handler/src/main/java/parquet/hive/DeprecatedParquetOutputFormat.java": 29,
                "parquet-hive/parquet-hive-storage-handler/src/main/java/parquet/hive/MapredParquetInputFormat.java": 29,
                "parquet-hive/parquet-hive-storage-handler/src/main/java/parquet/hive/MapredParquetOutputFormat.java": 29,
                "parquet-hive/parquet-hive-storage-handler/src/main/java/parquet/hive/serde/ParquetHiveSerDe.java": 29,
                "parquet-hive/parquet-hive-storage-handler/src/test/java/org/apache/hadoop/hive/ql/io/parquet/TestHiveSchemaConverter.java": 29,
                "parquet-hive/parquet-hive-storage-handler/src/test/java/org/apache/hadoop/hive/ql/io/parquet/TestMapredParquetInputFormat.java": 29,
                "parquet-hive/parquet-hive-storage-handler/src/test/java/org/apache/hadoop/hive/ql/io/parquet/TestMapredParquetOutputFormat.java": 29,
                "parquet-hive/parquet-hive-storage-handler/src/test/java/org/apache/hadoop/hive/ql/io/parquet/TestParquetSerDe.java": 29,
                "parquet-hive/parquet-hive-storage-handler/src/test/java/org/apache/hadoop/hive/ql/io/parquet/serde/TestAbstractParquetMapInspector.java": 29,
                "parquet-hive/parquet-hive-storage-handler/src/test/java/org/apache/hadoop/hive/ql/io/parquet/serde/TestDeepParquetHiveMapInspector.java": 29,
                "parquet-hive/parquet-hive-storage-handler/src/test/java/org/apache/hadoop/hive/ql/io/parquet/serde/TestParquetHiveArrayInspector.java": 29,
                "parquet-hive/parquet-hive-storage-handler/src/test/java/org/apache/hadoop/hive/ql/io/parquet/serde/TestStandardParquetHiveMapInspector.java": 29,
                "parquet-pig/src/main/java/parquet/pig/ParquetLoader.java": 31,
                "parquet-pig/src/main/java/parquet/pig/ParquetStorer.java": 31,
                "parquet-pig/src/main/java/parquet/pig/PigMetaData.java": 31,
                "parquet-pig/src/main/java/parquet/pig/PigSchemaConverter.java": 31,
                "parquet-pig/src/main/java/parquet/pig/SchemaConversionException.java": 31,
                "parquet-pig/src/main/java/parquet/pig/TupleConversionException.java": 31,
                "parquet-pig/src/main/java/parquet/pig/TupleReadSupport.java": 31,
                "parquet-pig/src/main/java/parquet/pig/TupleWriteSupport.java": 31,
                "parquet-pig/src/main/java/parquet/pig/convert/MapConverter.java": 31,
                "parquet-pig/src/main/java/parquet/pig/convert/ParentValueContainer.java": 31,
                "parquet-pig/src/main/java/parquet/pig/convert/TupleConverter.java": 31,
                "parquet-pig/src/main/java/parquet/pig/convert/TupleRecordMaterializer.java": 31,
                "parquet-pig/src/main/java/parquet/pig/summary/BagSummaryData.java": 31,
                "parquet-pig/src/main/java/parquet/pig/summary/EnumStat.java": 31,
                "parquet-pig/src/main/java/parquet/pig/summary/FieldSummaryData.java": 31,
                "parquet-pig/src/main/java/parquet/pig/summary/MapSummaryData.java": 31,
                "parquet-pig/src/main/java/parquet/pig/summary/NumberSummaryData.java": 31,
                "parquet-pig/src/main/java/parquet/pig/summary/StringSummaryData.java": 31,
                "parquet-pig/src/main/java/parquet/pig/summary/Summary.java": 31,
                "parquet-pig/src/main/java/parquet/pig/summary/SummaryData.java": 31,
                "parquet-pig/src/main/java/parquet/pig/summary/TupleSummaryData.java": 31,
                "parquet-pig/src/main/java/parquet/pig/summary/ValueStat.java": 31,
                "parquet-pig/src/test/java/parquet/pig/PerfTest.java": 31,
                "parquet-pig/src/test/java/parquet/pig/PerfTest2.java": 31,
                "parquet-pig/src/test/java/parquet/pig/PerfTestReadAllCols.java": 31,
                "parquet-pig/src/test/java/parquet/pig/TestParquetLoader.java": 31,
                "parquet-pig/src/test/java/parquet/pig/TestParquetStorer.java": 31,
                "parquet-pig/src/test/java/parquet/pig/TestPigSchemaConverter.java": 31,
                "parquet-pig/src/test/java/parquet/pig/TestTupleRecordConsumer.java": 31,
                "parquet-pig/src/test/java/parquet/pig/TupleConsumerPerfTest.java": 31,
                "parquet-pig/src/test/java/parquet/pig/summary/TestSummary.java": 31,
                "parquet-protobuf/src/main/java/parquet/proto/ProtoMessageConverter.java": 32,
                "parquet-protobuf/src/main/java/parquet/proto/ProtoParquetInputFormat.java": 31,
                "parquet-protobuf/src/main/java/parquet/proto/ProtoParquetOutputFormat.java": 31,
                "parquet-protobuf/src/main/java/parquet/proto/ProtoParquetReader.java": 31,
                "parquet-protobuf/src/main/java/parquet/proto/ProtoParquetWriter.java": 31,
                "parquet-protobuf/src/main/java/parquet/proto/ProtoReadSupport.java": 31,
                "parquet-protobuf/src/main/java/parquet/proto/ProtoRecordConverter.java": 31,
                "parquet-protobuf/src/main/java/parquet/proto/ProtoRecordMaterializer.java": 31,
                "parquet-protobuf/src/main/java/parquet/proto/ProtoSchemaConverter.java": 31,
                "parquet-protobuf/src/main/java/parquet/proto/ProtoWriteSupport.java": 31,
                "parquet-protobuf/src/test/java/parquet/proto/ProtoInputOutputFormatTest.java": 31,
                "parquet-protobuf/src/test/java/parquet/proto/ProtoRecordConverterTest.java": 32,
                "parquet-protobuf/src/test/java/parquet/proto/ProtoSchemaConverterTest.java": 32,
                "parquet-protobuf/src/test/java/parquet/proto/ProtoWriteSupportTest.java": 31,
                "parquet-protobuf/src/test/java/parquet/proto/TestUtils.java": 18,
                "parquet-protobuf/src/test/java/parquet/proto/utils/ReadUsingMR.java": 31,
                "parquet-protobuf/src/test/java/parquet/proto/utils/WriteUsingMR.java": 31,
                "parquet-scrooge/src/main/java/parquet/scrooge/ParquetScroogeInputFormat.java": 33,
                "parquet-scrooge/src/main/java/parquet/scrooge/ParquetScroogeScheme.java": 32,
                "parquet-scrooge/src/main/java/parquet/scrooge/ScroogeReadSupport.java": 31,
                "parquet-scrooge/src/main/java/parquet/scrooge/ScroogeRecordConverter.java": 31,
                "parquet-scrooge/src/main/java/parquet/scrooge/ScroogeSchemaConversionException.java": 18,
                "parquet-scrooge/src/main/java/parquet/scrooge/ScroogeStructConverter.java": 31,
                "parquet-scrooge/src/test/java/parquet/scrooge/ParquetScroogeSchemeTest.java": 31,
                "parquet-scrooge/src/test/java/parquet/scrooge/ScroogeStructConverterTest.java": 31,
                "parquet-thrift/src/main/java/parquet/hadoop/thrift/ParquetThriftBytesOutputFormat.java": 31,
                "parquet-thrift/src/main/java/parquet/hadoop/thrift/ParquetThriftInputFormat.java": 31,
                "parquet-thrift/src/main/java/parquet/hadoop/thrift/ParquetThriftOutputFormat.java": 31,
                "parquet-thrift/src/main/java/parquet/hadoop/thrift/ThriftBytesWriteSupport.java": 31,
                "parquet-thrift/src/main/java/parquet/hadoop/thrift/ThriftReadSupport.java": 31,
                "parquet-thrift/src/main/java/parquet/hadoop/thrift/ThriftToParquetFileWriter.java": 31,
                "parquet-thrift/src/main/java/parquet/hadoop/thrift/ThriftWriteSupport.java": 31,
                "parquet-thrift/src/main/java/parquet/thrift/BufferedProtocolReadToWrite.java": 31,
                "parquet-thrift/src/main/java/parquet/thrift/DecodingSchemaMismatchException.java": 18,
                "parquet-thrift/src/main/java/parquet/thrift/FieldIgnoredHandler.java": 18,
                "parquet-thrift/src/main/java/parquet/thrift/ParquetProtocol.java": 31,
                "parquet-thrift/src/main/java/parquet/thrift/ParquetReadProtocol.java": 31,
                "parquet-thrift/src/main/java/parquet/thrift/ParquetWriteProtocol.java": 31,
                "parquet-thrift/src/main/java/parquet/thrift/ProtocolPipe.java": 31,
                "parquet-thrift/src/main/java/parquet/thrift/ProtocolReadToWrite.java": 31,
                "parquet-thrift/src/main/java/parquet/thrift/SkippableException.java": 18,
                "parquet-thrift/src/main/java/parquet/thrift/TBaseRecordConverter.java": 31,
                "parquet-thrift/src/main/java/parquet/thrift/ThriftMetaData.java": 31,
                "parquet-thrift/src/main/java/parquet/thrift/ThriftParquetReader.java": 31,
                "parquet-thrift/src/main/java/parquet/thrift/ThriftParquetWriter.java": 31,
                "parquet-thrift/src/main/java/parquet/thrift/ThriftReader.java": 31,
                "parquet-thrift/src/main/java/parquet/thrift/ThriftRecordConverter.java": 31,
                "parquet-thrift/src/main/java/parquet/thrift/ThriftSchemaConvertVisitor.java": 32,
                "parquet-thrift/src/main/java/parquet/thrift/ThriftSchemaConverter.java": 31,
                "parquet-thrift/src/main/java/parquet/thrift/pig/ParquetThriftStorer.java": 31,
                "parquet-thrift/src/main/java/parquet/thrift/pig/TupleToThriftWriteSupport.java": 31,
                "parquet-thrift/src/main/java/parquet/thrift/projection/FieldProjectionFilter.java": 32,
                "parquet-thrift/src/main/java/parquet/thrift/projection/FieldsPath.java": 31,
                "parquet-thrift/src/main/java/parquet/thrift/projection/PathGlobPattern.java": 18,
                "parquet-thrift/src/main/java/parquet/thrift/projection/ThriftProjectionException.java": 32,
                "parquet-thrift/src/main/java/parquet/thrift/projection/amend/DefaultEventsVisitor.java": 31,
                "parquet-thrift/src/main/java/parquet/thrift/projection/amend/DefaultProtocolEventsGenerator.java": 31,
                "parquet-thrift/src/main/java/parquet/thrift/projection/amend/ProtocolEventsAmender.java": 31,
                "parquet-thrift/src/main/java/parquet/thrift/projection/amend/ReadFieldBeginProtocol.java": 31,
                "parquet-thrift/src/main/java/parquet/thrift/struct/CompatibilityChecker.java": 31,
                "parquet-thrift/src/main/java/parquet/thrift/struct/CompatibilityRunner.java": 31,
                "parquet-thrift/src/main/java/parquet/thrift/struct/JSON.java": 31,
                "parquet-thrift/src/main/java/parquet/thrift/struct/ThriftField.java": 31,
                "parquet-thrift/src/main/java/parquet/thrift/struct/ThriftType.java": 31,
                "parquet-thrift/src/main/java/parquet/thrift/struct/ThriftTypeID.java": 31,
                "parquet-thrift/src/test/java/parquet/hadoop/thrift/TestInputOutputFormat.java": 31,
                "parquet-thrift/src/test/java/parquet/hadoop/thrift/TestParquetToThriftReadWriteAndProjection.java": 31,
                "parquet-thrift/src/test/java/parquet/hadoop/thrift/TestThriftToParquetFileWriter.java": 31,
                "parquet-thrift/src/test/java/parquet/thrift/TestParquetReadProtocol.java": 31,
                "parquet-thrift/src/test/java/parquet/thrift/TestParquetWriteProtocol.java": 31,
                "parquet-thrift/src/test/java/parquet/thrift/TestProtocolReadToWrite.java": 31,
                "parquet-thrift/src/test/java/parquet/thrift/TestThriftParquetReaderWriter.java": 31,
                "parquet-thrift/src/test/java/parquet/thrift/TestThriftSchemaConverter.java": 31,
                "parquet-thrift/src/test/java/parquet/thrift/TestThriftToPigCompatibility.java": 31,
                "parquet-thrift/src/test/java/parquet/thrift/pig/TestParquetThriftStorer.java": 31,
                "parquet-thrift/src/test/java/parquet/thrift/projection/PathGlobPatternTest.java": 32,
                "parquet-thrift/src/test/java/parquet/thrift/struct/CompatibilityCheckerTest.java": 31
            },
            "is_test": true,
            "is_fix": false
        },
        "80417356f04c5ee1cd6f636e9b043db3f2de24f2": {
            "datetime": "2015-02-03T12:53:37-08:00",
            "summary": "PARQUET-173: Fixes `StatisticsFilter` for `And` filter predicate",
            "message": "PARQUET-173: Fixes `StatisticsFilter` for `And` filter predicate\n\n<!-- Reviewable:start -->\n[<img src=\"https://reviewable.io/review_button.png\" height=40 alt=\"Review on Reviewable\"/>](https://reviewable.io/reviews/apache/incubator-parquet-mr/108)\n<!-- Reviewable:end -->\n\nAuthor: Cheng Lian <lian@databricks.com>\n\nCloses #108 from liancheng/PARQUET-173 and squashes the following commits:\n\nd188f0b [Cheng Lian] Fixes test case\nbe2c8a1 [Cheng Lian] Fixes `StatisticsFilter` for `And` filter predicate\n",
            "diff": {
                "parquet-hadoop/src/main/java/parquet/filter2/statisticslevel/StatisticsFilter.java": 6,
                "parquet-hadoop/src/test/java/parquet/filter2/statisticslevel/TestStatisticsFilter.java": 4
            },
            "is_test": true,
            "is_fix": true
        },
        "668d031d7213d5e76cf39770ffce7f030c9bf056": {
            "datetime": "2015-02-05T11:37:06-08:00",
            "summary": "PARQUET-181: Scrooge Write Support (take two)",
            "message": "PARQUET-181: Scrooge Write Support (take two)\n\nThis is similar to https://github.com/apache/incubator-parquet-mr/pull/43, but instead of making `ThriftWriteSupport` abstract, it keeps it around (but deprecated) and adds `AbstractThriftWriteSupport`. This is a little less elegant, but it seems to appease the semver overlords.\n\nAuthor: Colin Marc <colinmarc@gmail.com>\n\nCloses #58 from colinmarc/scrooge-write-support-2 and squashes the following commits:\n\ne2a0abd [Colin Marc] add write support to ParquetScroogeScheme\n19cf1a8 [Colin Marc] Add ScroogeWriteSupport and ParquetScroogeOutputFormat.\n",
            "diff": {
                "parquet-cascading/src/main/java/parquet/cascading/ParquetTBaseScheme.java": 6,
                "parquet-scrooge/src/main/java/parquet/scrooge/ParquetScroogeOutputFormat.java": 39,
                "parquet-scrooge/src/main/java/parquet/scrooge/ParquetScroogeScheme.java": 22,
                "parquet-scrooge/src/main/java/parquet/scrooge/ScroogeWriteSupport.java": 65,
                "parquet-scrooge/src/test/java/parquet/scrooge/ParquetScroogeSchemeTest.java": 78,
                "parquet-thrift/src/main/java/parquet/hadoop/thrift/AbstractThriftWriteSupport.java": 126,
                "parquet-thrift/src/main/java/parquet/hadoop/thrift/ParquetThriftBytesOutputFormat.java": 4,
                "parquet-thrift/src/main/java/parquet/hadoop/thrift/TBaseWriteSupport.java": 63,
                "parquet-thrift/src/main/java/parquet/hadoop/thrift/ThriftBytesWriteSupport.java": 10,
                "parquet-thrift/src/main/java/parquet/hadoop/thrift/ThriftWriteSupport.java": 82,
                "parquet-thrift/src/main/java/parquet/thrift/ThriftMetaData.java": 3,
                "parquet-thrift/src/main/java/parquet/thrift/ThriftParquetWriter.java": 8
            },
            "is_test": true,
            "is_fix": false
        },
        "05adc21b15dbe30d9bded0cde56f482f1c932d6f": {
            "datetime": "2015-02-05T14:36:28-08:00",
            "summary": "PARQUET-177: Added lower bound to memory manager resize",
            "message": "PARQUET-177: Added lower bound to memory manager resize\n\nPARQUET-177\n\nAuthor: Daniel Weeks <dweeks@netflix.com>\n\nCloses #115 from danielcweeks/memory-manager-limit and squashes the following commits:\n\nb2e4708 [Daniel Weeks] Updated to base memory allocation off estimated chunk size\n09d7aa3 [Daniel Weeks] Updated property name and default value\n8f6cff1 [Daniel Weeks] Added low bound to memory manager resize\n",
            "diff": {
                "parquet-hadoop/src/main/java/parquet/hadoop/InternalParquetRecordWriter.java": 4,
                "parquet-hadoop/src/main/java/parquet/hadoop/MemoryManager.java": 16,
                "parquet-hadoop/src/main/java/parquet/hadoop/ParquetOutputFormat.java": 5
            },
            "is_test": false,
            "is_fix": false
        },
        "ce65dfb394623c34dd7919aba5c0687f1bcf39f2": {
            "datetime": "2015-02-05T15:06:12-08:00",
            "summary": "PARQUET-139: Avoid reading footers when using task-side metadata",
            "message": "PARQUET-139: Avoid reading footers when using task-side metadata\n\nThis updates the InternalParquetRecordReader to initialize the ReadContext in each task rather than once for an entire job. There are two reasons for this change:\n\n1. For correctness, the requested projection schema must be validated against each file schema, not once using the merged schema.\n2. To avoid reading file footers on the client side, which is a performance bottleneck.\n\nBecause the read context is reinitialized in every task, it is no longer necessary to pass the its contents to each task in ParquetInputSplit. The fields and accessors have been removed.\n\nThis also adds a new InputFormat, ParquetFileInputFormat that uses FileSplits instead of ParquetSplits. It goes through the normal ParquetRecordReader and creates a ParquetSplit on the task side. This is to avoid accidental behavior changes in ParquetInputFormat.\n\nAuthor: Ryan Blue <blue@apache.org>\n\nCloses #91 from rdblue/PARQUET-139-input-format-task-side and squashes the following commits:\n\ncb30660 [Ryan Blue] PARQUET-139: Fix deprecated reader bug from review fixes.\n09cde8d [Ryan Blue] PARQUET-139: Implement changes from reviews.\n3eec553 [Ryan Blue] PARQUET-139: Merge new InputFormat into ParquetInputFormat.\n8971b80 [Ryan Blue] PARQUET-139: Add ParquetFileInputFormat that uses FileSplit.\n87dfe86 [Ryan Blue] PARQUET-139: Expose read support helper methods.\n057c7dc [Ryan Blue] PARQUET-139: Update reader to initialize read context in tasks.\n",
            "diff": {
                "parquet-avro/src/main/java/parquet/avro/AvroReadSupport.java": 4,
                "parquet-hadoop/src/main/java/parquet/hadoop/InternalParquetRecordReader.java": 30,
                "parquet-hadoop/src/main/java/parquet/hadoop/ParquetInputFormat.java": 188,
                "parquet-hadoop/src/main/java/parquet/hadoop/ParquetInputSplit.java": 101,
                "parquet-hadoop/src/main/java/parquet/hadoop/ParquetReader.java": 22,
                "parquet-hadoop/src/main/java/parquet/hadoop/ParquetRecordReader.java": 28,
                "parquet-hadoop/src/main/java/parquet/hadoop/mapred/DeprecatedParquetInputFormat.java": 32,
                "parquet-hadoop/src/test/java/parquet/hadoop/TestInputFormat.java": 163,
                "parquet-hive/parquet-hive-storage-handler/src/main/java/org/apache/hadoop/hive/ql/io/parquet/read/ParquetRecordReaderWrapper.java": 4
            },
            "is_test": true,
            "is_fix": false
        },
        "807915b4cacede6a8de49630469b673b7c248a6f": {
            "datetime": "2015-02-09T17:51:46-08:00",
            "summary": "PARQUET-116: Pass a filter object to user defined predicate in filter2 api",
            "message": "PARQUET-116: Pass a filter object to user defined predicate in filter2 api\n\nCurrently for creating a user defined predicate using the new filter api, no value can be passed to create a dynamic filter at runtime. This reduces the usefulness of the user defined predicate, and meaningful predicates cannot be created. We can add a generic Object value that is passed through the api, which can internally be used in the keep function of the user defined predicate for creating many different types of filters.\nFor example, in spark sql, we can pass in a list of filter values for a where IN clause query and filter the row values based on that list.\n\nAuthor: Yash Datta <Yash.Datta@guavus.com>\nAuthor: Alex Levenson <alexlevenson@twitter.com>\nAuthor: Yash Datta <saucam@gmail.com>\n\nCloses #73 from saucam/master and squashes the following commits:\n\n7231a3b [Yash Datta] Merge pull request #3 from isnotinvain/alexlevenson/fix-binary-compat\ndcc276b [Alex Levenson] Ignore binary incompatibility in private filter2 class\n7bfa5ad [Yash Datta] Merge pull request #2 from isnotinvain/alexlevenson/simplify-udp-state\n0187376 [Alex Levenson] Resolve merge conflicts\n25aa716 [Alex Levenson] Simplify user defined predicates with state\n51952f8 [Yash Datta] PARQUET-116: Fix whitespace\nd7b7159 [Yash Datta] PARQUET-116: Make UserDefined abstract, add two subclasses, one accepting udp class, other accepting serializable udp instance\n40d394a [Yash Datta] PARQUET-116: Fix whitespace\n9a63611 [Yash Datta] PARQUET-116: Fix whitespace\n7caa4dc [Yash Datta] PARQUET-116: Add ConfiguredUserDefined that takes a serialiazble udp directly\n0eaabf4 [Yash Datta] PARQUET-116: Move the config object from keep method to a configure method in udp predicate\nf51a431 [Yash Datta] PARQUET-116: Adding type safety for the filter object to be passed to user defined predicate\nd5a2b9e [Yash Datta] PARQUET-116: Enforce that the filter object to be passed must be Serializable\ndfd0478 [Yash Datta] PARQUET-116: Add a test case for passing a filter object to user defined predicate\n4ab46ec [Yash Datta] PARQUET-116: Pass a filter object to user defined predicate in filter2 api\n",
            "diff": {
                "parquet-column/src/main/java/parquet/filter2/predicate/FilterApi.java": 19,
                "parquet-column/src/main/java/parquet/filter2/predicate/Operators.java": 81,
                "parquet-column/src/main/java/parquet/filter2/predicate/UserDefinedPredicate.java": 0,
                "parquet-column/src/test/java/parquet/filter2/predicate/TestFilterApiMethods.java": 59,
                "parquet-hadoop/src/test/java/parquet/filter2/recordlevel/TestRecordLevelFilters.java": 54
            },
            "is_test": true,
            "is_fix": false
        },
        "f48bca0510703b0673709b10a806a9d54894a999": {
            "datetime": "2015-02-09T23:07:35-08:00",
            "summary": "PARQUET-164: Add warning when scaling row group sizes.",
            "message": "PARQUET-164: Add warning when scaling row group sizes.\n\nAuthor: Ryan Blue <blue@apache.org>\n\nCloses #119 from rdblue/PARQUET-164-add-memory-manager-warning and squashes the following commits:\n\n241144f [Ryan Blue] PARQUET-164: Add warning when scaling row group sizes.\n",
            "diff": {
                "parquet-hadoop/src/main/java/parquet/hadoop/MemoryManager.java": 4
            },
            "is_test": false,
            "is_fix": false
        }
    },
    "2015-02-17T15:17:05-07:00": {
        "4f87e0f483ed76a885c228c6ab75249f25041081": {
            "datetime": "2015-02-26T13:40:02-08:00",
            "summary": "PARQUET-190: fix an inconsistent Javadoc comment of ReadSupport.prepareForRead",
            "message": "PARQUET-190: fix an inconsistent Javadoc comment of ReadSupport.prepareForRead\n\nReadSupport.prepareForRead does not return RecordConsumer but RecordMaterializer\n\nAuthor: choplin <choplin.choplin@gmail.com>\n\nCloses #125 from choplin/fix-javadoc-comment and squashes the following commits:\n\nc3574f3 [choplin] fix an inconsistent Javadoc comment of ReadSupport.prepareForRead\n",
            "diff": {
                "parquet-hadoop/src/main/java/parquet/hadoop/api/ReadSupport.java": 4
            },
            "is_test": false,
            "is_fix": false
        },
        "f1b54876ab8893a5d9c0e3d7c1a9c884e683dc8a": {
            "datetime": "2015-03-04T12:11:50-08:00",
            "summary": "PARQUET-191: Fix map Type to Avro Schema conversion.",
            "message": "PARQUET-191: Fix map Type to Avro Schema conversion.\n\nAuthor: Ryan Blue <blue@apache.org>\n\nCloses #126 from rdblue/PARQUET-191-fix-map-value-conversion and squashes the following commits:\n\n33f6bbc [Ryan Blue] PARQUET-191: Fix map Type to Avro Schema conversion.\n",
            "diff": {
                "parquet-avro/src/main/java/parquet/avro/AvroIndexedRecordConverter.java": 4,
                "parquet-avro/src/main/java/parquet/avro/AvroSchemaConverter.java": 19,
                "parquet-avro/src/test/java/parquet/avro/TestAvroSchemaConverter.java": 31
            },
            "is_test": true,
            "is_fix": false
        },
        "c82f703768eb8a122546de23e412a037aa1770b2": {
            "datetime": "2015-03-04T12:26:52-08:00",
            "summary": "PARQUET-192: Fix map null encoding",
            "message": "PARQUET-192: Fix map null encoding\n\nThis depends on PARQUET-191 for the correct schema representation.\n\nAuthor: Ryan Blue <blue@apache.org>\n\nCloses #127 from rdblue/PARQUET-192-fix-map-null-encoding and squashes the following commits:\n\nfffde82 [Ryan Blue] PARQUET-192: Fix parquet-avro maps with null values.\n",
            "diff": {
                "parquet-avro/src/main/java/parquet/avro/AvroWriteSupport.java": 36,
                "parquet-avro/src/test/java/parquet/avro/TestReadWrite.java": 57
            },
            "is_test": true,
            "is_fix": false
        },
        "36a02dc549f32433d7329444455dbb1be2e67f20": {
            "datetime": "2015-03-04T12:35:40-08:00",
            "summary": "PARQUET-188: Change column ordering to match the field order.",
            "message": "PARQUET-188: Change column ordering to match the field order.\n\nThis was the behavior before the V2 pages were added.\n\nAuthor: Ryan Blue <blue@apache.org>\n\nCloses #129 from rdblue/PARQUET-188-fix-column-metadata-order and squashes the following commits:\n\n3c9fa5d [Ryan Blue] PARQUET-188: Change column ordering to match the field order.\n",
            "diff": {
                "parquet-hadoop/src/main/java/parquet/hadoop/ColumnChunkPageWriteStore.java": 6,
                "parquet-hadoop/src/test/java/parquet/hadoop/TestColumnChunkPageWriteStore.java": 74
            },
            "is_test": true,
            "is_fix": true
        },
        "fa8957d7939b59e8d391fa17000b34e865de015d": {
            "datetime": "2015-03-04T12:49:50-08:00",
            "summary": "PARQUET-187: Replace JavaConversions.asJavaList with JavaConversions.seqAsJavaList",
            "message": "PARQUET-187: Replace JavaConversions.asJavaList with JavaConversions.seqAsJavaList\n\nThe former was removed in 2.11, but the latter exists in 2.9, 2.10 and 2.11. With this change, I can build on 2.11 without any issue.\n\nAuthor: Colin Marc <colinmarc@gmail.com>\n\nCloses #121 from colinmarc/build-211 and squashes the following commits:\n\n8a29319 [Colin Marc] Replace JavaConversions.asJavaList with JavaConversions.seqAsJavaList.\n",
            "diff": {
                "parquet-scrooge/src/main/java/parquet/scrooge/ScroogeStructConverter.java": 2
            },
            "is_test": false,
            "is_fix": false
        },
        "d084ad29e0a2f456407f655c99999e070bf529f9": {
            "datetime": "2015-03-04T17:26:44-08:00",
            "summary": "PARQUET-160: avoid wasting 64K per empty buffer.",
            "message": "PARQUET-160: avoid wasting 64K per empty buffer.\n\nThis buffer initializes itself to a default size when instantiated.\nThis leads to a lot of unused small buffers when there are a lot of empty columns.\n\nAuthor: Alex Levenson <alexlevenson@twitter.com>\nAuthor: julien <julien@twitter.com>\nAuthor: Julien Le Dem <julien@twitter.com>\n\nCloses #98 from julienledem/avoid_wasting_64K_per_empty_buffer and squashes the following commits:\n\nb0200dd [julien] add license\na1b278e [julien] Merge branch 'master' into avoid_wasting_64K_per_empty_buffer\n5304ee1 [julien] remove unused constant\n81e399f [julien] Merge branch 'avoid_wasting_64K_per_empty_buffer' of github.com:julienledem/incubator-parquet-mr into avoid_wasting_64K_per_empty_buffer\nccf677d [julien] Merge branch 'master' into avoid_wasting_64K_per_empty_buffer\n37148d6 [Julien Le Dem] Merge pull request #2 from isnotinvain/PR-98\nb9abab0 [Alex Levenson] Address Julien's comment\n965af7f [Alex Levenson] one more typo\n9939d8d [Alex Levenson] fix typos in comments\n61c0100 [Alex Levenson] Make initial slab size heuristic into a helper method, apply in DictionaryValuesWriter as well\na257ee4 [Alex Levenson] Improve IndexOutOfBoundsException message\n64d6c7f [Alex Levenson] update comments\n8b54667 [Alex Levenson] Don't use CapacityByteArrayOutputStream for writing page chunks\n6a20e8b [Alex Levenson] Remove initialSlabSize decision from InternalParquetRecordReader, use a simpler heuristic in the column writers instead\n3a0f8e4 [Alex Levenson] Use simpler settings for column chunk writer\nb2736a1 [Alex Levenson] Some cleanup in CapacityByteArrayOutputStream\n1df4a71 [julien] refactor CapacityByteArray to be aware of page size\n95c8fb6 [julien] avoid wasting 64K per empty buffer.\n",
            "diff": {
                "parquet-column/src/main/java/parquet/column/ParquetProperties.java": 51,
                "parquet-column/src/main/java/parquet/column/impl/ColumnWriteStoreV1.java": 6,
                "parquet-column/src/main/java/parquet/column/impl/ColumnWriteStoreV2.java": 4,
                "parquet-column/src/main/java/parquet/column/impl/ColumnWriterV1.java": 15,
                "parquet-column/src/main/java/parquet/column/impl/ColumnWriterV2.java": 17,
                "parquet-column/src/main/java/parquet/column/values/bitpacking/BitPackingValuesWriter.java": 5,
                "parquet-column/src/main/java/parquet/column/values/boundedint/BitWriter.java": 4,
                "parquet-column/src/main/java/parquet/column/values/boundedint/BoundedIntValuesFactory.java": 4,
                "parquet-column/src/main/java/parquet/column/values/boundedint/BoundedIntValuesWriter.java": 4,
                "parquet-column/src/main/java/parquet/column/values/delta/DeltaBinaryPackingValuesWriter.java": 14,
                "parquet-column/src/main/java/parquet/column/values/deltalengthbytearray/DeltaLengthByteArrayValuesWriter.java": 10,
                "parquet-column/src/main/java/parquet/column/values/deltastrings/DeltaByteArrayWriter.java": 8,
                "parquet-column/src/main/java/parquet/column/values/dictionary/DictionaryValuesWriter.java": 22,
                "parquet-column/src/main/java/parquet/column/values/plain/FixedLenByteArrayPlainValuesWriter.java": 14,
                "parquet-column/src/main/java/parquet/column/values/plain/PlainValuesWriter.java": 4,
                "parquet-column/src/main/java/parquet/column/values/rle/RunLengthBitPackingHybridEncoder.java": 4,
                "parquet-column/src/main/java/parquet/column/values/rle/RunLengthBitPackingHybridValuesWriter.java": 4,
                "parquet-column/src/test/java/parquet/column/impl/TestColumnReaderImpl.java": 4,
                "parquet-column/src/test/java/parquet/column/mem/TestMemColumn.java": 2,
                "parquet-column/src/test/java/parquet/column/values/bitpacking/TestBitPackingColumn.java": 2,
                "parquet-column/src/test/java/parquet/column/values/boundedint/TestBoundedColumns.java": 4,
                "parquet-column/src/test/java/parquet/column/values/delta/DeltaBinaryPackingValuesWriterTest.java": 4,
                "parquet-column/src/test/java/parquet/column/values/delta/benchmark/BenchmarkIntegerOutputSize.java": 4,
                "parquet-column/src/test/java/parquet/column/values/delta/benchmark/BenchmarkReadingRandomIntegers.java": 4,
                "parquet-column/src/test/java/parquet/column/values/delta/benchmark/RandomWritingBenchmarkTest.java": 6,
                "parquet-column/src/test/java/parquet/column/values/delta/benchmark/SmallRangeWritingBenchmarkTest.java": 2,
                "parquet-column/src/test/java/parquet/column/values/deltalengthbytearray/TestDeltaLengthByteArray.java": 8,
                "parquet-column/src/test/java/parquet/column/values/deltalengthbytearray/benchmark/BenchmarkDeltaLengthByteArray.java": 16,
                "parquet-column/src/test/java/parquet/column/values/deltastrings/TestDeltaByteArray.java": 12,
                "parquet-column/src/test/java/parquet/column/values/deltastrings/benchmark/BenchmarkDeltaByteArray.java": 28,
                "parquet-column/src/test/java/parquet/column/values/dictionary/TestDictionary.java": 2,
                "parquet-column/src/test/java/parquet/column/values/rle/RunLengthBitPackingHybridIntegrationTest.java": 2,
                "parquet-column/src/test/java/parquet/column/values/rle/TestRunLengthBitPackingHybridEncoder.java": 22,
                "parquet-column/src/test/java/parquet/io/PerfTest.java": 2,
                "parquet-column/src/test/java/parquet/io/TestColumnIO.java": 2,
                "parquet-column/src/test/java/parquet/io/TestFiltered.java": 2,
                "parquet-encoding/src/main/java/parquet/bytes/CapacityByteArrayOutputStream.java": 268,
                "parquet-encoding/src/main/java/parquet/bytes/ConcatenatingByteArrayCollector.java": 63,
                "parquet-encoding/src/test/java/parquet/bytes/TestCapacityByteArrayOutputStream.java": 26,
                "parquet-hadoop/src/main/java/parquet/hadoop/ColumnChunkPageWriteStore.java": 54,
                "parquet-hadoop/src/main/java/parquet/hadoop/InternalParquetRecordWriter.java": 16,
                "parquet-hadoop/src/test/java/parquet/hadoop/TestColumnChunkPageWriteStore.java": 13,
                "parquet-pig/src/test/java/parquet/pig/TupleConsumerPerfTest.java": 2,
                "parquet-thrift/src/test/java/parquet/thrift/TestParquetReadProtocol.java": 2
            },
            "is_test": true,
            "is_fix": false
        },
        "ea81e9aac328b2a89226417e58d4d8366891a9f4": {
            "datetime": "2015-03-04T17:56:52-08:00",
            "summary": "PARQUET-186: Fix Precondition performance problem in SnappyUtil.",
            "message": "PARQUET-186: Fix Precondition performance problem in SnappyUtil.\n\nThis fixes the problem by adding string formatting to the preconditions. This avoids any string formatting unless the precondition throws an Exception. We should check for string operations in other tight loops as well.\n\nAuthor: Ryan Blue <blue@apache.org>\n\nCloses #133 from rdblue/PARQUET-186-precondition-format-string and squashes the following commits:\n\nbe0b8fe [Ryan Blue] PARQUET-186: Fix Precondition performance bug in SnappyUtil.\n67f9bf2 [Ryan Blue] PARQUET-186: Add format string and args to Preconditions.\n",
            "diff": {
                "parquet-common/src/main/java/parquet/Preconditions.java": 79,
                "parquet-common/src/test/java/parquet/TestPreconditions.java": 58,
                "parquet-hadoop/src/main/java/parquet/hadoop/codec/SnappyUtil.java": 4
            },
            "is_test": true,
            "is_fix": true
        },
        "998d6507ecabf025188d9f3e8c8367f810895a17": {
            "datetime": "2015-03-04T18:24:21-08:00",
            "summary": "PARQUET-134 patch - Support file write mode",
            "message": "PARQUET-134 patch - Support file write mode\n\nJulien,\n   I changed the integer constants to enum as you requested.  Please review the patch.\n\nThanks.\n\nAuthor: Mariappan Asokan <masokan@gmail.com>\n\nCloses #111 from masokan/master and squashes the following commits:\n\n7a8aa6f [Mariappan Asokan] PARQUET-134 patch - Support file write mode\n",
            "diff": {
                "parquet-hadoop/src/main/java/parquet/hadoop/ParquetFileWriter.java": 29,
                "parquet-hadoop/src/main/java/parquet/hadoop/ParquetWriter.java": 35,
                "parquet-hadoop/src/test/java/parquet/hadoop/TestParquetFileWriter.java": 33
            },
            "is_test": true,
            "is_fix": false
        },
        "258349426eecfbe5c135f91809bae80e60c6db6a": {
            "datetime": "2015-03-05T15:22:03-08:00",
            "summary": "PARQUET-162: ParquetThrift should throw when unrecognized columns are passed to the column projection API",
            "message": "PARQUET-162: ParquetThrift should throw when unrecognized columns are passed to the column projection API\n\nParquetThrift should throw when unrecognized columns are passed to the column projection API\n\nAuthor: Tianshuo Deng <tdeng@twitter.com>\n\nCloses #123 from tsdeng/throw_when_projection_filter_matches_nothing and squashes the following commits:\n\n12c08da [Tianshuo Deng] make PathGlobPatternStatus static\n4360b36 [Tianshuo Deng] fix tests\na74f621 [Tianshuo Deng] clean up test\n3c581f3 [Tianshuo Deng] refactor unit test\n6a86de7 [Tianshuo Deng] format\nbdc625d [Tianshuo Deng] throw when projection filter matches nothing\n",
            "diff": {
                "parquet-thrift/src/main/java/parquet/thrift/ThriftSchemaConvertVisitor.java": 4,
                "parquet-thrift/src/main/java/parquet/thrift/ThriftSchemaConverter.java": 12,
                "parquet-thrift/src/main/java/parquet/thrift/projection/FieldProjectionFilter.java": 46,
                "parquet-thrift/src/main/java/parquet/thrift/projection/PathGlobPattern.java": 5,
                "parquet-thrift/src/test/java/parquet/hadoop/thrift/TestParquetToThriftReadWriteAndProjection.java": 119,
                "parquet-thrift/src/test/java/parquet/thrift/TestThriftSchemaConverter.java": 25
            },
            "is_test": true,
            "is_fix": true
        },
        "5851e6da7a05b5d53a01803ccabc0f685fc36d52": {
            "datetime": "2015-03-05T15:56:58-08:00",
            "summary": "PARQUET-197 : fix parquet-cascading not writing parquet metadata file",
            "message": "PARQUET-197 : fix parquet-cascading not writing parquet metadata file\n\nRepro: run a scalding job that writes parquet files to a folder. no _metadata and _common_metadata file is created\nImpact: potential performance problem if parquet metadata is read from client side, which is the case for sparkSQL\ncasue: the metatdata writing logic is in the mapreduce API but not the mapred API of parquet.\n\nAuthor: Tianshuo Deng <tdeng@twitter.com>\n\nCloses #131 from tsdeng/fix_mapred_output_committer and squashes the following commits:\n\n6e8d8eb [Tianshuo Deng] rename to MapredParquetOutputCommiter, add setAsOutputFormat method to set the outputCommiter\nec758db [Tianshuo Deng] license\n448b649 [Tianshuo Deng] fix parquet-cascading not writing parquet metadata file\n",
            "diff": {
                "parquet-cascading/src/main/java/parquet/cascading/ParquetTBaseScheme.java": 2,
                "parquet-cascading/src/main/java/parquet/cascading/ParquetTupleScheme.java": 2,
                "parquet-cascading/src/test/java/parquet/cascading/TestParquetTBaseScheme.java": 3,
                "parquet-hadoop/src/main/java/parquet/hadoop/ParquetOutputCommitter.java": 4,
                "parquet-hadoop/src/main/java/parquet/hadoop/mapred/DeprecatedParquetOutputFormat.java": 5,
                "parquet-hadoop/src/main/java/parquet/hadoop/mapred/MapredParquetOutputCommitter.java": 42,
                "parquet-scrooge/src/main/java/parquet/scrooge/ParquetScroogeScheme.java": 5
            },
            "is_test": true,
            "is_fix": true
        },
        "12ee6b442bbf6557c06ecd7c1f7ae2fceeae55d6": {
            "datetime": "2015-03-06T16:38:49-08:00",
            "summary": "PARQUET-208: Revert PARQUET-197",
            "message": "PARQUET-208: Revert PARQUET-197\n\nRevert \"PARQUET-197 : fix parquet-cascading not writing parquet metadata...\n\nAuthor: Tianshuo Deng <tdeng@twitter.com>\n\nCloses #139 from tsdeng/revert_parquet_197 and squashes the following commits:\n\na74b5c8 [Tianshuo Deng] Revert \"PARQUET-197 : fix parquet-cascading not writing parquet metadata file\"\n",
            "diff": {
                "parquet-cascading/src/main/java/parquet/cascading/ParquetTBaseScheme.java": 2,
                "parquet-cascading/src/main/java/parquet/cascading/ParquetTupleScheme.java": 2,
                "parquet-cascading/src/test/java/parquet/cascading/TestParquetTBaseScheme.java": 3,
                "parquet-hadoop/src/main/java/parquet/hadoop/ParquetOutputCommitter.java": 4,
                "parquet-hadoop/src/main/java/parquet/hadoop/mapred/DeprecatedParquetOutputFormat.java": 5,
                "parquet-hadoop/src/main/java/parquet/hadoop/mapred/MapredParquetOutputCommitter.java": 42,
                "parquet-scrooge/src/main/java/parquet/scrooge/ParquetScroogeScheme.java": 5
            },
            "is_test": true,
            "is_fix": true
        },
        "3fc28541f001ce6e4a7afa91fec8d21bfeaa17db": {
            "datetime": "2015-03-06T17:06:34-08:00",
            "summary": "PARQUET-193: Implement nested types compatibility rules in Avro",
            "message": "PARQUET-193: Implement nested types compatibility rules in Avro\n\nThis depends on PARQUET-191 and PARQUET-192.\n\nThis replaces #83.\n\nAuthor: Ryan Blue <blue@apache.org>\n\nCloses #128 from rdblue/PARQUET-193-implement-compatilibity-avro and squashes the following commits:\n\nbd0491e [Ryan Blue] PARQUET-193: Implement nested types rules in Avro.\n",
            "diff": {
                "parquet-avro/src/main/java/parquet/avro/AvroIndexedRecordConverter.java": 137,
                "parquet-avro/src/main/java/parquet/avro/AvroReadSupport.java": 18,
                "parquet-avro/src/main/java/parquet/avro/AvroSchemaConverter.java": 58,
                "parquet-avro/src/main/java/parquet/avro/AvroWriteSupport.java": 19,
                "parquet-avro/src/test/java/parquet/avro/AvroTestUtil.java": 69,
                "parquet-avro/src/test/java/parquet/avro/TestArrayCompatibility.java": 999
            },
            "is_test": true,
            "is_fix": false
        },
        "a0c77b6a442e2c4a355a4b145898bed976f23bb4": {
            "datetime": "2015-03-09T12:59:45-07:00",
            "summary": "PARQUET-111: Update headers in parquet-tools, remove NOTICE.",
            "message": "PARQUET-111: Update headers in parquet-tools, remove NOTICE.\n\nThis commit update the copyright headers in parquet-tools from ARRIS to the standard Apache license header. This needs ARRIS or @wesleypeck to \"provide written permission for the ASF to make such removal or relocation of the notices\". Please +1 this commit, or submit a PR with similar changes. Thanks!\n\nAuthor: Ryan Blue <blue@apache.org>\n\nCloses #114 from rdblue/PARQUET-111-parquet-tools-changes and squashes the following commits:\n\n87eb75f [Ryan Blue] PARQUET-111: Update headers in parquet-tools, remove NOTICE.\n",
            "diff": {
                "parquet-tools/src/main/java/parquet/tools/Main.java": 31,
                "parquet-tools/src/main/java/parquet/tools/command/ArgsOnlyCommand.java": 31,
                "parquet-tools/src/main/java/parquet/tools/command/CatCommand.java": 31,
                "parquet-tools/src/main/java/parquet/tools/command/Command.java": 31,
                "parquet-tools/src/main/java/parquet/tools/command/DumpCommand.java": 31,
                "parquet-tools/src/main/java/parquet/tools/command/HeadCommand.java": 31,
                "parquet-tools/src/main/java/parquet/tools/command/Registry.java": 31,
                "parquet-tools/src/main/java/parquet/tools/command/ShowMetaCommand.java": 31,
                "parquet-tools/src/main/java/parquet/tools/command/ShowSchemaCommand.java": 31,
                "parquet-tools/src/main/java/parquet/tools/read/SimpleReadSupport.java": 31,
                "parquet-tools/src/main/java/parquet/tools/read/SimpleRecord.java": 31,
                "parquet-tools/src/main/java/parquet/tools/read/SimpleRecordConverter.java": 31,
                "parquet-tools/src/main/java/parquet/tools/read/SimpleRecordMaterializer.java": 31,
                "parquet-tools/src/main/java/parquet/tools/util/MetadataUtils.java": 31,
                "parquet-tools/src/main/java/parquet/tools/util/PrettyPrintWriter.java": 31
            },
            "is_test": false,
            "is_fix": false
        },
        "5acc6a5502bffaa66be7e859849856de0ea27acb": {
            "datetime": "2015-03-10T14:04:59+01:00",
            "summary": "PARQUET-97: make ProtoParquetReader#builder static",
            "message": "PARQUET-97: make ProtoParquetReader#builder static\n\nAuthor: Viktor Szathma\u0301ry <phraktle@gmail.com>\n\nCloses #63 from phraktle/fix_ppr_factory and squashes the following commits:\n\n8b67439 [Viktor Szathma\u0301ry] make ProtoParquetReader#builder static\n9c8fcd5 [Viktor Szathma\u0301ry] make ProtoParquetReader#builder static\n",
            "diff": {
                "parquet-protobuf/src/main/java/parquet/proto/ProtoParquetReader.java": 2
            },
            "is_test": false,
            "is_fix": false
        },
        "031a762d105bceda2049204ba54b8f8737f359b4": {
            "datetime": "2015-03-11T15:11:16-07:00",
            "summary": "PARQUET-172: Add parquet-thrift binary tests.",
            "message": "PARQUET-172: Add parquet-thrift binary tests.\n\nThese tests validate that there is no encoding problem with parquet-thrift or parquet-scrooge. See https://github.com/laurencer/parquet-mr-bug\n\nAuthor: Ryan Blue <blue@apache.org>\n\nCloses #145 from rdblue/PARQUET-172-add-thrift-binary-test and squashes the following commits:\n\n6856414 [Ryan Blue] PARQUET-172: Add parquet-thrift binary tests.\n",
            "diff": {
                "parquet-scrooge/src/test/java/parquet/scrooge/ScroogeBinaryTest.java": 100,
                "parquet-scrooge/src/test/java/parquet/scrooge/ScroogeStructConverterTest.java": 7,
                "parquet-thrift/src/test/java/parquet/hadoop/thrift/TestBinary.java": 66
            },
            "is_test": true,
            "is_fix": true
        },
        "b58789c5badc4f9680ec5724568af05a84670e22": {
            "datetime": "2015-03-11T15:21:45-07:00",
            "summary": "PARQUET-180: Update use of TBinaryProtocol#setReadLength.",
            "message": "PARQUET-180: Update use of TBinaryProtocol#setReadLength.\n\nThis is no longer supported in thrift 0.9.2 and was only used\ndefensively. The reason to remove it now is to avoid linker errors when\nthe wrong version of thrift is found in the classpath.\n\nAuthor: Ryan Blue <blue@apache.org>\n\nCloses #118 from rdblue/PARQUET-180 and squashes the following commits:\n\n5100424 [Ryan Blue] PARQUET-180: Dynamic use of TBinaryProtocol#setReadLength.\n",
            "diff": {
                "parquet-thrift/src/main/java/parquet/hadoop/thrift/ThriftBytesWriteSupport.java": 13
            },
            "is_test": false,
            "is_fix": false
        },
        "77826fda8751bd5c0acbca5d0c3887e9a6b10f65": {
            "datetime": "2015-03-12T14:25:13-07:00",
            "summary": "PARQUET-215 Discard records with unrecognized union members in the thrift write path",
            "message": "PARQUET-215 Discard records with unrecognized union members in the thrift write path\n\nFixes Parquet-215, adds a test case for it, and fixes some tests that were quietly not doing anything previously to actually exercise the code they were intended to exercise. (they were tests that catch exceptions and make assertions about them, but never enforced that the exception was actually thrown, and in one case, it never was).\n\nAuthor: Alex Levenson <alexlevenson@twitter.com>\n\nCloses #146 from isnotinvain/alexlevenson/unrecognized-union and squashes the following commits:\n\n7bec4a6 [Alex Levenson] Add license header\nb0d8e6c [Alex Levenson] Merge branch 'master' into alexlevenson/unrecognized-union\ne152bc8 [Alex Levenson] Update comment\n97232b7 [Alex Levenson] Address comments\nc542199 [Alex Levenson] Go back to using boolean for isUnion\n2e18dbd [Alex Levenson] Remove exclusion\n0a60c46 [Alex Levenson] Support isUnion being unknown\nb0dfdf9 [Alex Levenson] Fix tests\n68940d7 [Alex Levenson] Discard records with unrecognized union members in the thrift write path\n",
            "diff": {
                "parquet-scrooge/src/main/java/parquet/scrooge/ScroogeStructConverter.java": 7,
                "parquet-thrift/src/main/java/parquet/thrift/BufferedProtocolReadToWrite.java": 29,
                "parquet-thrift/src/main/java/parquet/thrift/ThriftSchemaConverter.java": 9,
                "parquet-thrift/src/main/java/parquet/thrift/struct/ThriftType.java": 28,
                "parquet-thrift/src/test/java/parquet/thrift/TestProtocolReadToWrite.java": 45,
                "parquet-thrift/src/test/java/parquet/thrift/struct/TestThriftType.java": 67
            },
            "is_test": true,
            "is_fix": true
        },
        "9ee3a16179cb65f5fe4170257ab7cde558f1dbeb": {
            "datetime": "2015-03-13T12:54:58-07:00",
            "summary": "PARQUET-217 Use simpler heuristic in MemoryManager",
            "message": "PARQUET-217 Use simpler heuristic in MemoryManager\n\nWe found that the heuristic of throwing when:\n```\nminMemoryAllocation > 0 && newSize/maxColCount < minMemoryAllocation\n```\nin MemoryManager is not really valid when you have many (3k +) columns, due to the division by the number of columns.\nThis check throws immediately when writing a single file with a 3GB heap and > 3K columns.\n\nThis PR introduces a simpler heuristic, which is a min scale, and we throw when the MemoryManager's scale gets too small. By default I chose 25%, but I'm happy to change that to something else.\n\nFor backwards compatibility I've left the original check in, but it's not executed by default anymore, to get this behavior the min chunk size will have to be set in the hadoop configuration. I'm also open to removing it entirely if we don't think we need it anymore.\n\nWhat do you think?\n@danielcweeks @rdblue @dongche @julienledem\n\nAuthor: Alex Levenson <alexlevenson@twitter.com>\n\nCloses #143 from isnotinvain/alexlevenson/mem-manager-heuristic and squashes the following commits:\n\nacda66f [Alex Levenson] Add units to exception\n10237c6 [Alex Levenson] Decouple DEFAULT_MIN_MEMORY_ALLOCATION from DEFAULT_PAGE_SIZE\n29c9881 [Alex Levenson] Use an absolute minimum on rowgroup size, only apply when scale < 1\n8877125 [Alex Levenson] Merge branch 'master' into alexlevenson/mem-manager-heuristic\ne5117a0 [Alex Levenson] Merge branch 'master' into alexlevenson/mem-manager-heuristic\n6ee5f46 [Alex Levenson] Use simpler heuristic in MemoryManager\n",
            "diff": {
                "parquet-hadoop/src/main/java/parquet/hadoop/MemoryManager.java": 10
            },
            "is_test": false,
            "is_fix": false
        },
        "2e3c05359a0e21be44d307104eea3134afcef5f0": {
            "datetime": "2015-03-13T13:36:49-07:00",
            "summary": "PARQUET-197 : Gen parquet metadata from cascading",
            "message": "PARQUET-197 : Gen parquet metadata from cascading\n\nretry of PARQUET-197\n\nfixed support for hadoop2 API\n\nAuthor: Tianshuo Deng <tdeng@twitter.com>\n\nCloses #141 from tsdeng/gen_parquet_meta and squashes the following commits:\n\nd1211a0 [Tianshuo Deng] fix hadoop2 API\n8686ce4 [Tianshuo Deng] gem parquet metadata\n",
            "diff": {
                "parquet-cascading/src/main/java/parquet/cascading/ParquetTBaseScheme.java": 2,
                "parquet-cascading/src/main/java/parquet/cascading/ParquetTupleScheme.java": 2,
                "parquet-cascading/src/test/java/parquet/cascading/TestParquetTBaseScheme.java": 19,
                "parquet-hadoop/src/main/java/parquet/hadoop/ParquetOutputCommitter.java": 4,
                "parquet-hadoop/src/main/java/parquet/hadoop/mapred/DeprecatedParquetOutputFormat.java": 5,
                "parquet-hadoop/src/main/java/parquet/hadoop/mapred/MapredParquetOutputCommitter.java": 45,
                "parquet-scrooge/src/main/java/parquet/scrooge/ParquetScroogeScheme.java": 5
            },
            "is_test": true,
            "is_fix": true
        },
        "fd3085ed31d920e8ca6bba391e75d1423ed8b607": {
            "datetime": "2015-03-24T16:06:26-07:00",
            "summary": "PARQUET-204: add parquet-schema directory support",
            "message": "PARQUET-204: add parquet-schema directory support\n\nAuthor: Neville Li <neville@spotify.com>\n\nCloses #136 from nevillelyh/neville/PARQUET-204 and squashes the following commits:\n\n633829b [Neville Li] PARQUET-204: add parquet-schema directory support\n7aa8581 [Neville Li] PARQUET-203: consolidate PathFilter for hidden files\n",
            "diff": {
                "parquet-hadoop/src/main/java/parquet/hadoop/ParquetFileReader.java": 9,
                "parquet-hadoop/src/main/java/parquet/hadoop/ParquetInputFormat.java": 10,
                "parquet-hadoop/src/main/java/parquet/hadoop/ParquetReader.java": 9,
                "parquet-hadoop/src/main/java/parquet/hadoop/PrintFooter.java": 9,
                "parquet-hadoop/src/main/java/parquet/hadoop/util/HiddenFileFilter.java": 33,
                "parquet-hadoop/src/test/java/parquet/hadoop/TestParquetFileWriter.java": 9,
                "parquet-tools/src/main/java/parquet/tools/command/ShowSchemaCommand.java": 19
            },
            "is_test": true,
            "is_fix": false
        },
        "4fea3ea6997c8135bc18a2bff31dc0a54e7bd82d": {
            "datetime": "2015-03-31T11:23:42-07:00",
            "summary": "PARQUET-165: Add a new parquet-benchmark module",
            "message": "PARQUET-165: Add a new parquet-benchmark module\n\nPARQUET-165\n\nThis PR is an initial version of a new ``parquet-benchmark`` module that we can build upon. The module already contains some simple benchmarks for read/writes, we can discuss how we can make those more representative.\n\nWhen run, various statistics will be printed for all the benchmarks in this module. For example, for the read benchmarks the output will look like:\n\n```\n# Run complete. Total time: 00:03:16\n\nBenchmark                                                             Mode  Samples  Score   Error  Units\np.b.ReadBenchmarks.read1MRowsBS256MPS4MUncompressed                  thrpt        1  0.248 \u00b1   NaN  ops/s\np.b.ReadBenchmarks.read1MRowsBS256MPS8MUncompressed                  thrpt        1  0.331 \u00b1   NaN  ops/s\np.b.ReadBenchmarks.read1MRowsBS512MPS4MUncompressed                  thrpt        1  0.309 \u00b1   NaN  ops/s\np.b.ReadBenchmarks.read1MRowsBS512MPS8MUncompressed                  thrpt        1  0.303 \u00b1   NaN  ops/s\np.b.ReadBenchmarks.read1MRowsDefaultBlockAndPageSizeGZIP             thrpt        1  0.264 \u00b1   NaN  ops/s\np.b.ReadBenchmarks.read1MRowsDefaultBlockAndPageSizeSNAPPY           thrpt        1  0.499 \u00b1   NaN  ops/s\np.b.ReadBenchmarks.read1MRowsDefaultBlockAndPageSizeUncompressed     thrpt        1  0.360 \u00b1   NaN  ops/s\np.b.ReadBenchmarks.read1MRowsBS256MPS4MUncompressed                   avgt        1  3.623 \u00b1   NaN   s/op\np.b.ReadBenchmarks.read1MRowsBS256MPS8MUncompressed                   avgt        1  3.162 \u00b1   NaN   s/op\np.b.ReadBenchmarks.read1MRowsBS512MPS4MUncompressed                   avgt        1  3.231 \u00b1   NaN   s/op\np.b.ReadBenchmarks.read1MRowsBS512MPS8MUncompressed                   avgt        1  2.583 \u00b1   NaN   s/op\np.b.ReadBenchmarks.read1MRowsDefaultBlockAndPageSizeGZIP              avgt        1  3.713 \u00b1   NaN   s/op\np.b.ReadBenchmarks.read1MRowsDefaultBlockAndPageSizeSNAPPY            avgt        1  2.055 \u00b1   NaN   s/op\np.b.ReadBenchmarks.read1MRowsDefaultBlockAndPageSizeUncompressed      avgt        1  2.904 \u00b1   NaN   s/op\np.b.ReadBenchmarks.read1MRowsBS256MPS4MUncompressed                 sample        1  2.772 \u00b1   NaN   s/op\np.b.ReadBenchmarks.read1MRowsBS256MPS8MUncompressed                 sample        1  2.538 \u00b1   NaN   s/op\np.b.ReadBenchmarks.read1MRowsBS512MPS4MUncompressed                 sample        1  2.496 \u00b1   NaN   s/op\np.b.ReadBenchmarks.read1MRowsBS512MPS8MUncompressed                 sample        1  2.416 \u00b1   NaN   s/op\np.b.ReadBenchmarks.read1MRowsDefaultBlockAndPageSizeGZIP            sample        1  3.712 \u00b1   NaN   s/op\np.b.ReadBenchmarks.read1MRowsDefaultBlockAndPageSizeSNAPPY          sample        1  1.772 \u00b1   NaN   s/op\np.b.ReadBenchmarks.read1MRowsDefaultBlockAndPageSizeUncompressed    sample        1  2.819 \u00b1   NaN   s/op\np.b.ReadBenchmarks.read1MRowsBS256MPS4MUncompressed                     ss        1  2.416 \u00b1   NaN      s\np.b.ReadBenchmarks.read1MRowsBS256MPS8MUncompressed                     ss        1  2.564 \u00b1   NaN      s\np.b.ReadBenchmarks.read1MRowsBS512MPS4MUncompressed                     ss        1  2.547 \u00b1   NaN      s\np.b.ReadBenchmarks.read1MRowsBS512MPS8MUncompressed                     ss        1  3.094 \u00b1   NaN      s\np.b.ReadBenchmarks.read1MRowsDefaultBlockAndPageSizeGZIP                ss        1  3.689 \u00b1   NaN      s\np.b.ReadBenchmarks.read1MRowsDefaultBlockAndPageSizeSNAPPY              ss        1  1.983 \u00b1   NaN      s\np.b.ReadBenchmarks.read1MRowsDefaultBlockAndPageSizeUncompressed        ss        1  2.928 \u00b1   NaN      s\n\n```\n\nAuthor: Nezih Yigitbasi <nyigitbasi@netflix.com>\n\nCloses #104 from nezihyigitbasi/benchmark-module and squashes the following commits:\n\n90c72f5 [Nezih Yigitbasi] Add a new parquet-benchmark module\n",
            "diff": {
                "parquet-benchmarks/src/main/java/parquet/benchmarks/BenchmarkConstants.java": 42,
                "parquet-benchmarks/src/main/java/parquet/benchmarks/BenchmarkFiles.java": 40,
                "parquet-benchmarks/src/main/java/parquet/benchmarks/BenchmarkUtils.java": 46,
                "parquet-benchmarks/src/main/java/parquet/benchmarks/DataGenerator.java": 144,
                "parquet-benchmarks/src/main/java/parquet/benchmarks/ReadBenchmarks.java": 106,
                "parquet-benchmarks/src/main/java/parquet/benchmarks/WriteBenchmarks.java": 159
            },
            "is_test": false,
            "is_fix": false
        },
        "0ab0013522df1dc03a68bce6e7539bbfd0ea67d9": {
            "datetime": "2015-03-31T16:34:47-07:00",
            "summary": "PARQUET-210: add JSON support for parquet-cat",
            "message": "PARQUET-210: add JSON support for parquet-cat\n\nJSON output with this patch:\n```\n{\"int_field\":99,\"long_field\":1099,\"float_field\":2099.5,\"double_field\":5099.5,\"boolean_field\":true,\"string_field\":\"str99\",\"nested\":{\"numbers\":[100,101,102,103,104],\"name\":\"name99\",\"dict\":{\"a\":100,\"b\":200,\"c\":300}}}\n```\n\nCurrent output format:\n```\nint_field = 99\nlong_field = 1099\nfloat_field = 2099.5\ndouble_field = 5099.5\nboolean_field = true\nstring_field = str99\nnested:\n.numbers:\n..array = 100\n..array = 101\n..array = 102\n..array = 103\n..array = 104\n.name = name99\n.dict:\n..map:\n...key = a\n...value = 100\n..map:\n...key = b\n...value = 200\n..map:\n...key = c\n...value = 300\n```\n\nAuthor: Neville Li <neville@spotify.com>\n\nCloses #140 from nevillelyh/neville/PARQUET-210 and squashes the following commits:\n\n45fd629 [Neville Li] PARQUET-210: add JSON support for parquet-cat\n",
            "diff": {
                "parquet-tools/src/main/java/parquet/tools/command/CatCommand.java": 23,
                "parquet-tools/src/main/java/parquet/tools/read/SimpleListRecord.java": 30,
                "parquet-tools/src/main/java/parquet/tools/read/SimpleListRecordConverter.java": 34,
                "parquet-tools/src/main/java/parquet/tools/read/SimpleMapRecord.java": 43,
                "parquet-tools/src/main/java/parquet/tools/read/SimpleMapRecordConverter.java": 34,
                "parquet-tools/src/main/java/parquet/tools/read/SimpleRecord.java": 36,
                "parquet-tools/src/main/java/parquet/tools/read/SimpleRecordConverter.java": 31
            },
            "is_test": false,
            "is_fix": false
        },
        "4ed0bdf1c73fd82d3080d15085675de96d5be0aa": {
            "datetime": "2015-03-31T16:49:30-07:00",
            "summary": "PARQUET-214: Fix Avro string regression.",
            "message": "PARQUET-214: Fix Avro string regression.\n\nAt some point, parquet-avro converted string fields to binary without\nthe UTF8 annotation. The change in PARQUET-139 to filter the file's\nschema using the requested projection causes a regression because the\nannotation is not present in some file schemas, but is present in the\nprojection schema converted from Avro.\n\nThis reverts the projection change to avoid a regression in a release.\nFixing the projection as in PARQUET-139 will need to be done as a\nfollow-up.\n\nAuthor: Ryan Blue <blue@apache.org>\n\nCloses #142 from rdblue/PARQUET-214-fix-avro-regression and squashes the following commits:\n\n71e0207 [Ryan Blue] PARQUET-214: Add support for old avro.schema property.\n95148f9 [Ryan Blue] PARQUET-214: Revert Schema projection change from PARQUET-139.\n",
            "diff": {
                "parquet-avro/src/main/java/parquet/avro/AvroReadSupport.java": 9,
                "parquet-avro/src/test/java/parquet/avro/TestBackwardCompatibility.java": 51
            },
            "is_test": true,
            "is_fix": true
        },
        "bfb314505469afcd5ea7b5bd15121acd50425318": {
            "datetime": "2015-04-06T14:39:53-07:00",
            "summary": "PARQUET-220: Remove unnecessary warnings initializing ParquetRecordReader",
            "message": "PARQUET-220: Remove unnecessary warnings initializing ParquetRecordReader\n\nRefactored to replace TaskInputOutputContext with TaskAttemptContext.\n\nParquetRecordReader used to check that the passed context is instance of\nTaskInputOutputContext however the functionality it uses doesn't rely on this\nfact.\n\nThis closes #152 when committed. It fixes the review feedback on that issue to include it in 1.6.0.\n\nAuthor: Konstantin Shaposhnikov <Konstantin.Shaposhnikov@sc.com>\n\nCloses #162 from rdblue/PARQUET-152-remove-counter-warning and squashes the following commits:\n\n0a7780f [Konstantin Shaposhnikov] PARQUET-220: do not log unnecessary warnings on initializing ParquetRecordReader\n",
            "diff": {
                "parquet-hadoop/src/main/java/parquet/hadoop/ParquetRecordReader.java": 10,
                "parquet-hadoop/src/main/java/parquet/hadoop/util/ContextUtil.java": 3,
                "parquet-hadoop/src/main/java/parquet/hadoop/util/counters/BenchmarkCounter.java": 15,
                "parquet-hadoop/src/main/java/parquet/hadoop/util/counters/mapreduce/MapReduceCounterLoader.java": 15
            },
            "is_test": false,
            "is_fix": false
        },
        "ff7a4863152a4d3873ea038af73024e9999426ac": {
            "datetime": "2015-04-06T15:49:39-07:00",
            "summary": "Revert \"PARQUET-220: Remove unnecessary warnings initializing ParquetRecordReader\"",
            "message": "Revert \"PARQUET-220: Remove unnecessary warnings initializing ParquetRecordReader\"\n\nThis reverts commit bfb314505469afcd5ea7b5bd15121acd50425318.\n",
            "diff": {
                "parquet-hadoop/src/main/java/parquet/hadoop/ParquetRecordReader.java": 10,
                "parquet-hadoop/src/main/java/parquet/hadoop/util/ContextUtil.java": 3,
                "parquet-hadoop/src/main/java/parquet/hadoop/util/counters/BenchmarkCounter.java": 15,
                "parquet-hadoop/src/main/java/parquet/hadoop/util/counters/mapreduce/MapReduceCounterLoader.java": 15
            },
            "is_test": false,
            "is_fix": false
        },
        "4950ad86a16e63fa26d51cd709e39666008c5fbc": {
            "datetime": "2015-04-07T09:43:55-07:00",
            "summary": "PARQUET-242: Fix AvroReadSupport.setAvroDataSupplier.",
            "message": "PARQUET-242: Fix AvroReadSupport.setAvroDataSupplier.\n\nThis should use the supplier class's name, rather than its toString\nrepresentation or else loading the class doesn't work.\n\nAuthor: Ryan Blue <blue@apache.org>\n\nCloses #161 from rdblue/PARQUET-242-fix-avro-data-supplier and squashes the following commits:\n\nff5b7f8 [Ryan Blue] PARQUET-242: Add Avro data supplier test.\n87a488b [Ryan Blue] PARQUET-242: Fix AvroReadSupport.setAvroDataSupplier.\n",
            "diff": {
                "parquet-avro/src/main/java/parquet/avro/AvroReadSupport.java": 2,
                "parquet-avro/src/test/java/parquet/avro/TestAvroDataSupplier.java": 43
            },
            "is_test": true,
            "is_fix": true
        },
        "f272a6e96f0fe80b0c2b4643836006d840d5aa8a": {
            "datetime": "2015-04-07T13:12:55-07:00",
            "summary": "PARQUET-234: Add ParquetInputSplit methods for compatibility.",
            "message": "PARQUET-234: Add ParquetInputSplit methods for compatibility.\n\nAuthor: Ryan Blue <blue@apache.org>\n\nCloses #159 from rdblue/PARQUET-234 and squashes the following commits:\n\nb09d34d [Ryan Blue] PARQUET-234: Add ParquetInputSplit methods for compatibility.\n",
            "diff": {
                "parquet-hadoop/src/main/java/parquet/hadoop/ParquetInputSplit.java": 50
            },
            "is_test": false,
            "is_fix": false
        },
        "920192a542ab9e9dd2fbf090e1efd3c4ec99977d": {
            "datetime": "2015-04-07T13:14:13-07:00",
            "summary": "PARQUET-235: Fix parquet.metadata compatibility.",
            "message": "PARQUET-235: Fix parquet.metadata compatibility.\n\nColumnPath and Canonicalizer were moved from parquet-hadoop to\nparquet-common in parquet.common.{internal,schema}, which broke\ncompatibility and would require bumping the major version. This moves\nthe classes back into parquet.hadoop.metadata and adds temporary\nexclusions for the move between modules. There are no breaking changes\nto the classes themselves, verified by copying them into parquet-hadoop\nand building.\n\nThis also changes the previous version back to 1.5.0 rather than an RC\n(which carries no compatibility guarantees, though this is compatible\nwith both version). It also adds an exclusions for a false positive in\nBinary.\n\nAuthor: Ryan Blue <blue@apache.org>\n\nCloses #166 from rdblue/PARQUET-235-fix-parquet-metadata and squashes the following commits:\n\nf56a57e [Ryan Blue] PARQUET-235: Fix parquet.metadata compatibility.\n",
            "diff": {
                "parquet-column/src/main/java/parquet/filter2/predicate/FilterApi.java": 2,
                "parquet-column/src/main/java/parquet/filter2/predicate/Operators.java": 2,
                "parquet-column/src/main/java/parquet/filter2/predicate/SchemaCompatibilityValidator.java": 2,
                "parquet-column/src/main/java/parquet/filter2/predicate/ValidTypeMap.java": 2,
                "parquet-column/src/main/java/parquet/filter2/recordlevel/FilteringGroupConverter.java": 2,
                "parquet-column/src/main/java/parquet/filter2/recordlevel/FilteringRecordMaterializer.java": 2,
                "parquet-column/src/main/java/parquet/filter2/recordlevel/IncrementallyUpdatedFilterPredicateBuilderBase.java": 2,
                "parquet-column/src/test/java/parquet/filter2/predicate/TestFilterApiMethods.java": 2,
                "parquet-column/src/test/java/parquet/filter2/predicate/TestValidTypeMap.java": 2,
                "parquet-common/src/main/java/parquet/common/internal/Canonicalizer.java": 2,
                "parquet-common/src/main/java/parquet/common/schema/ColumnPath.java": 4,
                "parquet-generator/src/main/java/parquet/filter2/IncrementallyUpdatedFilterPredicateGenerator.java": 2,
                "parquet-hadoop/src/main/java/parquet/filter2/statisticslevel/StatisticsFilter.java": 2,
                "parquet-hadoop/src/main/java/parquet/format/converter/ParquetMetadataConverter.java": 2,
                "parquet-hadoop/src/main/java/parquet/hadoop/ParquetFileReader.java": 2,
                "parquet-hadoop/src/main/java/parquet/hadoop/ParquetFileWriter.java": 2,
                "parquet-hadoop/src/main/java/parquet/hadoop/metadata/ColumnChunkMetaData.java": 1,
                "parquet-hadoop/src/main/java/parquet/hadoop/metadata/ColumnChunkProperties.java": 2,
                "parquet-hadoop/src/main/java/parquet/hadoop/metadata/EncodingList.java": 1,
                "parquet-hadoop/src/test/java/parquet/filter2/statisticslevel/TestStatisticsFilter.java": 2,
                "parquet-hadoop/src/test/java/parquet/hadoop/TestInputFormat.java": 2,
                "parquet-hadoop/src/test/java/parquet/hadoop/metadata/TestColumnChunkMetaData.java": 1
            },
            "is_test": true,
            "is_fix": true
        },
        "b61362933f7a564d2ae0b7d6b9723f79f4948769": {
            "datetime": "2015-04-07T13:43:06-07:00",
            "summary": "PARQUET-239: Make AvroParquetReader#builder static.",
            "message": "PARQUET-239: Make AvroParquetReader#builder static.\n\nFixes new API method added since 1.5.0.\n\nAuthor: Ryan Blue <blue@apache.org>\n\nCloses #158 from rdblue/PARQUET-239-fix-avro-builder and squashes the following commits:\n\nc8c64d7 [Ryan Blue] PARQUET-239: Make AvroParquetReader#builder static.\n",
            "diff": {
                "parquet-avro/src/main/java/parquet/avro/AvroParquetReader.java": 2
            },
            "is_test": false,
            "is_fix": false
        },
        "f28aa71041181867a720134e26b64b03cbccb6ec": {
            "datetime": "2015-04-27T10:34:38-07:00",
            "summary": "PARQUET-252 : Support nests container types for scrooge support",
            "message": "PARQUET-252 : Support nests container types for scrooge support\n\nparquet should support nested container type for scrooge, like list<list> or list<map>\n\nAuthor: Tianshuo Deng <tdeng@twitter.com>\n\nCloses #175 from tsdeng/support_nests_container_types_for_scrooge_support and squashes the following commits:\n\nbae3e68 [Tianshuo Deng] move set list and map inner elem name conversion to private static methods\n48b4342 [Tianshuo Deng] catch ClassCastException\nfc25bd0 [Tianshuo Deng] remove hack/fix for nested name\n429c61c [Tianshuo Deng] fix exception handling, use explicit imports\nf54e648 [Tianshuo Deng] comments\n815ee29 [Tianshuo Deng] support nested scrooge type\n",
            "diff": {
                "parquet-scrooge/src/main/java/parquet/scrooge/ScroogeStructConverter.java": 318,
                "parquet-scrooge/src/test/java/parquet/scrooge/ScroogeStructConverterTest.java": 157
            },
            "is_test": true,
            "is_fix": true
        },
        "720b988fd8d7a50fbe922e6c73a3681b1c566331": {
            "datetime": "2015-04-27T15:37:21-07:00",
            "summary": "Revert \"PARQUET-252 : Support nests container types for scrooge support\"",
            "message": "Revert \"PARQUET-252 : Support nests container types for scrooge support\"\n\nThis reverts commit f28aa71041181867a720134e26b64b03cbccb6ec.\n",
            "diff": {
                "parquet-scrooge/src/main/java/parquet/scrooge/ScroogeStructConverter.java": 318,
                "parquet-scrooge/src/test/java/parquet/scrooge/ScroogeStructConverterTest.java": 157
            },
            "is_test": true,
            "is_fix": false
        },
        "b10870e4ee7d4168a7a1530494e0a8acd8e6cb3f": {
            "datetime": "2015-04-27T16:11:42-07:00",
            "summary": "PARQUET-23: Rename to org.apache.parquet.",
            "message": "PARQUET-23: Rename to org.apache.parquet.\n\nThis includes all of the code updates by module (so that we can use github for the review). I think this is currently all of the changes needed.\n\nAuthor: Ryan Blue <blue@apache.org>\n\nCloses #179 from rdblue/PARQUET-23-rename-to-org-apache and squashes the following commits:\n\n5018c94 [Ryan Blue] PARQUET-23: Change artifacts to org.apache.parquet group id.\n487b044 [Ryan Blue] PARQUET-23: POM fixes for move to org.apache.parquet.\nfe76459 [Ryan Blue] PARQUET-23: Move parquet-tools to org.apache.parquet.\n431bc6e [Ryan Blue] PARQUET-23: Move parquet-hive to org.apache.parquet.\n382db6f [Ryan Blue] PARQUET-23: Move parquet-scrooge to org.apache.parquet.\nf76b052 [Ryan Blue] PARQUET-23: Move parquet-scala to org.apache.parquet.\nc557515 [Ryan Blue] PARQUET-23: Move parquet-protobuf to org.apache.parquet.\n2a82366 [Ryan Blue] PARQUET-23: Move parquet-cascading to org.apache.parquet.\nf33db35 [Ryan Blue] PARQUET-23: Move parquet-thrift to org.apache.parquet.\n02399d2 [Ryan Blue] PARQUET-23: Move parquet-pig to org.apache.parquet.\ne0bb9ad [Ryan Blue] PARQUET-23: Move parquet-benchmarks to org.apache.parquet.\n55fb0c4 [Ryan Blue] PARQUET-23: Move parquet-avro to org.apache.parquet.\n8b7318f [Ryan Blue] PARQUET-23: Move parquet-hadoop to org.apache.parquet.\n666b3d7 [Ryan Blue] PARQUET-23: Move parquet-column to org.apache.parquet.\n3aaf772 [Ryan Blue] PARQUET-23: Move parquet-encoding to org.apache.parquet.\n9f6df3e [Ryan Blue] PARQUET-23: Move parquet-generator to org.apache.parquet.\ne34edab [Ryan Blue] PARQUET-23: Move parquet-common to org.apache.parquet.\n3ae3f7e [Ryan Blue] PARQUET-23: Use org.apache.parquet:parquet-format.\n",
            "diff": {
                "parquet-avro/src/main/java/org/apache/parquet/avro/AvroDataSupplier.java": 31,
                "parquet-avro/src/main/java/org/apache/parquet/avro/AvroIndexedRecordConverter.java": 700,
                "parquet-avro/src/main/java/org/apache/parquet/avro/AvroParquetInputFormat.java": 84,
                "parquet-avro/src/main/java/org/apache/parquet/avro/AvroParquetOutputFormat.java": 50,
                "parquet-avro/src/main/java/org/apache/parquet/avro/AvroParquetReader.java": 70,
                "parquet-avro/src/main/java/org/apache/parquet/avro/AvroParquetWriter.java": 106,
                "parquet-avro/src/main/java/org/apache/parquet/avro/AvroReadSupport.java": 113,
                "parquet-avro/src/main/java/org/apache/parquet/avro/AvroRecordMaterializer.java": 46,
                "parquet-avro/src/main/java/org/apache/parquet/avro/AvroSchemaConverter.java": 355,
                "parquet-avro/src/main/java/org/apache/parquet/avro/AvroWriteSupport.java": 234,
                "parquet-avro/src/main/java/org/apache/parquet/avro/SpecificDataSupplier.java": 29,
                "parquet-avro/src/main/java/org/apache/parquet/avro/package-info.java": 171,
                "parquet-avro/src/main/java/parquet/avro/AvroDataSupplier.java": 31,
                "parquet-avro/src/main/java/parquet/avro/AvroIndexedRecordConverter.java": 700,
                "parquet-avro/src/main/java/parquet/avro/AvroParquetInputFormat.java": 84,
                "parquet-avro/src/main/java/parquet/avro/AvroParquetOutputFormat.java": 50,
                "parquet-avro/src/main/java/parquet/avro/AvroParquetReader.java": 70,
                "parquet-avro/src/main/java/parquet/avro/AvroParquetWriter.java": 106,
                "parquet-avro/src/main/java/parquet/avro/AvroReadSupport.java": 113,
                "parquet-avro/src/main/java/parquet/avro/AvroRecordMaterializer.java": 46,
                "parquet-avro/src/main/java/parquet/avro/AvroSchemaConverter.java": 355,
                "parquet-avro/src/main/java/parquet/avro/AvroWriteSupport.java": 234,
                "parquet-avro/src/main/java/parquet/avro/SpecificDataSupplier.java": 29,
                "parquet-avro/src/main/java/parquet/avro/package-info.java": 171,
                "parquet-avro/src/test/java/org/apache/parquet/avro/AvroTestUtil.java": 69,
                "parquet-avro/src/test/java/org/apache/parquet/avro/TestArrayCompatibility.java": 999,
                "parquet-avro/src/test/java/org/apache/parquet/avro/TestAvroDataSupplier.java": 43,
                "parquet-avro/src/test/java/org/apache/parquet/avro/TestAvroSchemaConverter.java": 256,
                "parquet-avro/src/test/java/org/apache/parquet/avro/TestBackwardCompatibility.java": 51,
                "parquet-avro/src/test/java/org/apache/parquet/avro/TestInputOutputFormat.java": 144,
                "parquet-avro/src/test/java/org/apache/parquet/avro/TestReadWrite.java": 460,
                "parquet-avro/src/test/java/org/apache/parquet/avro/TestSpecificInputOutputFormat.java": 286,
                "parquet-avro/src/test/java/org/apache/parquet/avro/TestSpecificReadWrite.java": 288,
                "parquet-avro/src/test/java/parquet/avro/AvroTestUtil.java": 69,
                "parquet-avro/src/test/java/parquet/avro/TestArrayCompatibility.java": 999,
                "parquet-avro/src/test/java/parquet/avro/TestAvroDataSupplier.java": 43,
                "parquet-avro/src/test/java/parquet/avro/TestAvroSchemaConverter.java": 256,
                "parquet-avro/src/test/java/parquet/avro/TestBackwardCompatibility.java": 51,
                "parquet-avro/src/test/java/parquet/avro/TestInputOutputFormat.java": 144,
                "parquet-avro/src/test/java/parquet/avro/TestReadWrite.java": 460,
                "parquet-avro/src/test/java/parquet/avro/TestSpecificInputOutputFormat.java": 286,
                "parquet-avro/src/test/java/parquet/avro/TestSpecificReadWrite.java": 288,
                "parquet-benchmarks/src/main/java/org/apache/parquet/benchmarks/BenchmarkConstants.java": 42,
                "parquet-benchmarks/src/main/java/org/apache/parquet/benchmarks/BenchmarkFiles.java": 40,
                "parquet-benchmarks/src/main/java/org/apache/parquet/benchmarks/BenchmarkUtils.java": 46,
                "parquet-benchmarks/src/main/java/org/apache/parquet/benchmarks/DataGenerator.java": 144,
                "parquet-benchmarks/src/main/java/org/apache/parquet/benchmarks/ReadBenchmarks.java": 106,
                "parquet-benchmarks/src/main/java/org/apache/parquet/benchmarks/WriteBenchmarks.java": 159,
                "parquet-benchmarks/src/main/java/parquet/benchmarks/BenchmarkConstants.java": 42,
                "parquet-benchmarks/src/main/java/parquet/benchmarks/BenchmarkFiles.java": 40,
                "parquet-benchmarks/src/main/java/parquet/benchmarks/BenchmarkUtils.java": 46,
                "parquet-benchmarks/src/main/java/parquet/benchmarks/DataGenerator.java": 144,
                "parquet-benchmarks/src/main/java/parquet/benchmarks/ReadBenchmarks.java": 106,
                "parquet-benchmarks/src/main/java/parquet/benchmarks/WriteBenchmarks.java": 159,
                "parquet-cascading/src/main/java/org/apache/parquet/cascading/ParquetTBaseScheme.java": 80,
                "parquet-cascading/src/main/java/org/apache/parquet/cascading/ParquetTupleScheme.java": 191,
                "parquet-cascading/src/main/java/org/apache/parquet/cascading/ParquetValueScheme.java": 162,
                "parquet-cascading/src/main/java/org/apache/parquet/cascading/SchemaIntersection.java": 63,
                "parquet-cascading/src/main/java/org/apache/parquet/cascading/TupleReadSupport.java": 80,
                "parquet-cascading/src/main/java/org/apache/parquet/cascading/TupleWriteSupport.java": 106,
                "parquet-cascading/src/main/java/org/apache/parquet/cascading/convert/TupleConverter.java": 115,
                "parquet-cascading/src/main/java/org/apache/parquet/cascading/convert/TupleRecordMaterializer.java": 46,
                "parquet-cascading/src/main/java/parquet/cascading/ParquetTBaseScheme.java": 80,
                "parquet-cascading/src/main/java/parquet/cascading/ParquetTupleScheme.java": 191,
                "parquet-cascading/src/main/java/parquet/cascading/ParquetValueScheme.java": 162,
                "parquet-cascading/src/main/java/parquet/cascading/SchemaIntersection.java": 63,
                "parquet-cascading/src/main/java/parquet/cascading/TupleReadSupport.java": 80,
                "parquet-cascading/src/main/java/parquet/cascading/TupleWriteSupport.java": 106,
                "parquet-cascading/src/main/java/parquet/cascading/convert/TupleConverter.java": 115,
                "parquet-cascading/src/main/java/parquet/cascading/convert/TupleRecordMaterializer.java": 46,
                "parquet-cascading/src/test/java/org/apache/parquet/cascading/TestParquetTBaseScheme.java": 186,
                "parquet-cascading/src/test/java/org/apache/parquet/cascading/TestParquetTupleScheme.java": 182,
                "parquet-cascading/src/test/java/parquet/cascading/TestParquetTBaseScheme.java": 186,
                "parquet-cascading/src/test/java/parquet/cascading/TestParquetTupleScheme.java": 182,
                "parquet-column/src/main/java/org/apache/parquet/column/ColumnDescriptor.java": 129,
                "parquet-column/src/main/java/org/apache/parquet/column/ColumnReadStore.java": 34,
                "parquet-column/src/main/java/org/apache/parquet/column/ColumnReader.java": 115,
                "parquet-column/src/main/java/org/apache/parquet/column/ColumnWriteStore.java": 61,
                "parquet-column/src/main/java/org/apache/parquet/column/ColumnWriter.java": 87,
                "parquet-column/src/main/java/org/apache/parquet/column/Dictionary.java": 66,
                "parquet-column/src/main/java/org/apache/parquet/column/Encoding.java": 291,
                "parquet-column/src/main/java/org/apache/parquet/column/ParquetProperties.java": 242,
                "parquet-column/src/main/java/org/apache/parquet/column/UnknownColumnException.java": 42,
                "parquet-column/src/main/java/org/apache/parquet/column/UnknownColumnTypeException.java": 43,
                "parquet-column/src/main/java/org/apache/parquet/column/ValuesType.java": 29,
                "parquet-column/src/main/java/org/apache/parquet/column/impl/ColumnReadStoreImpl.java": 82,
                "parquet-column/src/main/java/org/apache/parquet/column/impl/ColumnReaderImpl.java": 661,
                "parquet-column/src/main/java/org/apache/parquet/column/impl/ColumnWriteStoreV1.java": 135,
                "parquet-column/src/main/java/org/apache/parquet/column/impl/ColumnWriteStoreV2.java": 166,
                "parquet-column/src/main/java/org/apache/parquet/column/impl/ColumnWriterV1.java": 278,
                "parquet-column/src/main/java/org/apache/parquet/column/impl/ColumnWriterV2.java": 304,
                "parquet-column/src/main/java/org/apache/parquet/column/page/DataPage.java": 53,
                "parquet-column/src/main/java/org/apache/parquet/column/page/DataPageV1.java": 98,
                "parquet-column/src/main/java/org/apache/parquet/column/page/DataPageV2.java": 156,
                "parquet-column/src/main/java/org/apache/parquet/column/page/DictionaryPage.java": 88,
                "parquet-column/src/main/java/org/apache/parquet/column/page/Page.java": 49,
                "parquet-column/src/main/java/org/apache/parquet/column/page/PageReadStore.java": 46,
                "parquet-column/src/main/java/org/apache/parquet/column/page/PageReader.java": 43,
                "parquet-column/src/main/java/org/apache/parquet/column/page/PageWriteStore.java": 38,
                "parquet-column/src/main/java/org/apache/parquet/column/page/PageWriter.java": 89,
                "parquet-column/src/main/java/org/apache/parquet/column/statistics/BinaryStatistics.java": 108,
                "parquet-column/src/main/java/org/apache/parquet/column/statistics/BooleanStatistics.java": 108,
                "parquet-column/src/main/java/org/apache/parquet/column/statistics/DoubleStatistics.java": 108,
                "parquet-column/src/main/java/org/apache/parquet/column/statistics/FloatStatistics.java": 108,
                "parquet-column/src/main/java/org/apache/parquet/column/statistics/IntStatistics.java": 108,
                "parquet-column/src/main/java/org/apache/parquet/column/statistics/LongStatistics.java": 108,
                "parquet-column/src/main/java/org/apache/parquet/column/statistics/Statistics.java": 247,
                "parquet-column/src/main/java/org/apache/parquet/column/statistics/StatisticsClassException.java": 34,
                "parquet-column/src/main/java/org/apache/parquet/column/values/RequiresFallback.java": 54,
                "parquet-column/src/main/java/org/apache/parquet/column/values/ValuesReader.java": 126,
                "parquet-column/src/main/java/org/apache/parquet/column/values/ValuesWriter.java": 128,
                "parquet-column/src/main/java/org/apache/parquet/column/values/bitpacking/BitPackingValuesReader.java": 91,
                "parquet-column/src/main/java/org/apache/parquet/column/values/bitpacking/BitPackingValuesWriter.java": 125,
                "parquet-column/src/main/java/org/apache/parquet/column/values/bitpacking/ByteBitPackingValuesReader.java": 83,
                "parquet-column/src/main/java/org/apache/parquet/column/values/bitpacking/ByteBitPackingValuesWriter.java": 86,
                "parquet-column/src/main/java/org/apache/parquet/column/values/boundedint/BitReader.java": 123,
                "parquet-column/src/main/java/org/apache/parquet/column/values/boundedint/BitWriter.java": 159,
                "parquet-column/src/main/java/org/apache/parquet/column/values/boundedint/BoundedIntValuesFactory.java": 32,
                "parquet-column/src/main/java/org/apache/parquet/column/values/boundedint/BoundedIntValuesReader.java": 93,
                "parquet-column/src/main/java/org/apache/parquet/column/values/boundedint/BoundedIntValuesWriter.java": 159,
                "parquet-column/src/main/java/org/apache/parquet/column/values/boundedint/DevNullValuesWriter.java": 89,
                "parquet-column/src/main/java/org/apache/parquet/column/values/boundedint/ZeroIntegerValuesReader.java": 52,
                "parquet-column/src/main/java/org/apache/parquet/column/values/delta/DeltaBinaryPackingConfig.java": 57,
                "parquet-column/src/main/java/org/apache/parquet/column/values/delta/DeltaBinaryPackingValuesReader.java": 170,
                "parquet-column/src/main/java/org/apache/parquet/column/values/delta/DeltaBinaryPackingValuesWriter.java": 269,
                "parquet-column/src/main/java/org/apache/parquet/column/values/deltalengthbytearray/DeltaLengthByteArrayValuesReader.java": 70,
                "parquet-column/src/main/java/org/apache/parquet/column/values/deltalengthbytearray/DeltaLengthByteArrayValuesWriter.java": 106,
                "parquet-column/src/main/java/org/apache/parquet/column/values/deltastrings/DeltaByteArrayReader.java": 78,
                "parquet-column/src/main/java/org/apache/parquet/column/values/deltastrings/DeltaByteArrayWriter.java": 92,
                "parquet-column/src/main/java/org/apache/parquet/column/values/dictionary/DictionaryValuesReader.java": 135,
                "parquet-column/src/main/java/org/apache/parquet/column/values/dictionary/DictionaryValuesWriter.java": 625,
                "parquet-column/src/main/java/org/apache/parquet/column/values/dictionary/IntList.java": 123,
                "parquet-column/src/main/java/org/apache/parquet/column/values/dictionary/PlainValuesDictionary.java": 310,
                "parquet-column/src/main/java/org/apache/parquet/column/values/fallback/FallbackValuesWriter.java": 190,
                "parquet-column/src/main/java/org/apache/parquet/column/values/plain/BinaryPlainValuesReader.java": 70,
                "parquet-column/src/main/java/org/apache/parquet/column/values/plain/BooleanPlainValuesReader.java": 75,
                "parquet-column/src/main/java/org/apache/parquet/column/values/plain/BooleanPlainValuesWriter.java": 78,
                "parquet-column/src/main/java/org/apache/parquet/column/values/plain/FixedLenByteArrayPlainValuesReader.java": 67,
                "parquet-column/src/main/java/org/apache/parquet/column/values/plain/FixedLenByteArrayPlainValuesWriter.java": 98,
                "parquet-column/src/main/java/org/apache/parquet/column/values/plain/PlainValuesReader.java": 135,
                "parquet-column/src/main/java/org/apache/parquet/column/values/plain/PlainValuesWriter.java": 143,
                "parquet-column/src/main/java/org/apache/parquet/column/values/rle/RunLengthBitPackingHybridDecoder.java": 109,
                "parquet-column/src/main/java/org/apache/parquet/column/values/rle/RunLengthBitPackingHybridEncoder.java": 291,
                "parquet-column/src/main/java/org/apache/parquet/column/values/rle/RunLengthBitPackingHybridValuesReader.java": 77,
                "parquet-column/src/main/java/org/apache/parquet/column/values/rle/RunLengthBitPackingHybridValuesWriter.java": 88,
                "parquet-column/src/main/java/org/apache/parquet/example/DummyRecordConverter.java": 114,
                "parquet-column/src/main/java/org/apache/parquet/example/Paper.java": 167,
                "parquet-column/src/main/java/org/apache/parquet/example/data/Group.java": 143,
                "parquet-column/src/main/java/org/apache/parquet/example/data/GroupFactory.java": 25,
                "parquet-column/src/main/java/org/apache/parquet/example/data/GroupValueSource.java": 89,
                "parquet-column/src/main/java/org/apache/parquet/example/data/GroupWriter.java": 62,
                "parquet-column/src/main/java/org/apache/parquet/example/data/simple/BinaryValue.java": 52,
                "parquet-column/src/main/java/org/apache/parquet/example/data/simple/BooleanValue.java": 44,
                "parquet-column/src/main/java/org/apache/parquet/example/data/simple/DoubleValue.java": 45,
                "parquet-column/src/main/java/org/apache/parquet/example/data/simple/FloatValue.java": 45,
                "parquet-column/src/main/java/org/apache/parquet/example/data/simple/Int96Value.java": 46,
                "parquet-column/src/main/java/org/apache/parquet/example/data/simple/IntegerValue.java": 46,
                "parquet-column/src/main/java/org/apache/parquet/example/data/simple/LongValue.java": 45,
                "parquet-column/src/main/java/org/apache/parquet/example/data/simple/NanoTime.java": 80,
                "parquet-column/src/main/java/org/apache/parquet/example/data/simple/Primitive.java": 60,
                "parquet-column/src/main/java/org/apache/parquet/example/data/simple/SimpleGroup.java": 232,
                "parquet-column/src/main/java/org/apache/parquet/example/data/simple/SimpleGroupFactory.java": 38,
                "parquet-column/src/main/java/org/apache/parquet/example/data/simple/convert/GroupRecordConverter.java": 57,
                "parquet-column/src/main/java/org/apache/parquet/example/data/simple/convert/SimpleGroupConverter.java": 67,
                "parquet-column/src/main/java/org/apache/parquet/example/data/simple/convert/SimplePrimitiveConverter.java": 88,
                "parquet-column/src/main/java/org/apache/parquet/filter/AndRecordFilter.java": 64,
                "parquet-column/src/main/java/org/apache/parquet/filter/ColumnPredicates.java": 190,
                "parquet-column/src/main/java/org/apache/parquet/filter/ColumnRecordFilter.java": 75,
                "parquet-column/src/main/java/org/apache/parquet/filter/NotRecordFilter.java": 58,
                "parquet-column/src/main/java/org/apache/parquet/filter/OrRecordFilter.java": 62,
                "parquet-column/src/main/java/org/apache/parquet/filter/PagedRecordFilter.java": 64,
                "parquet-column/src/main/java/org/apache/parquet/filter/RecordFilter.java": 34,
                "parquet-column/src/main/java/org/apache/parquet/filter/UnboundRecordFilter.java": 36,
                "parquet-column/src/main/java/org/apache/parquet/filter2/compat/FilterCompat.java": 158,
                "parquet-column/src/main/java/org/apache/parquet/filter2/predicate/FilterApi.java": 212,
                "parquet-column/src/main/java/org/apache/parquet/filter2/predicate/FilterPredicate.java": 72,
                "parquet-column/src/main/java/org/apache/parquet/filter2/predicate/LogicalInverseRewriter.java": 113,
                "parquet-column/src/main/java/org/apache/parquet/filter2/predicate/LogicalInverter.java": 108,
                "parquet-column/src/main/java/org/apache/parquet/filter2/predicate/Operators.java": 526,
                "parquet-column/src/main/java/org/apache/parquet/filter2/predicate/SchemaCompatibilityValidator.java": 193,
                "parquet-column/src/main/java/org/apache/parquet/filter2/predicate/Statistics.java": 42,
                "parquet-column/src/main/java/org/apache/parquet/filter2/predicate/UserDefinedPredicate.java": 108,
                "parquet-column/src/main/java/org/apache/parquet/filter2/predicate/ValidTypeMap.java": 178,
                "parquet-column/src/main/java/org/apache/parquet/filter2/recordlevel/FilteringGroupConverter.java": 115,
                "parquet-column/src/main/java/org/apache/parquet/filter2/recordlevel/FilteringPrimitiveConverter.java": 109,
                "parquet-column/src/main/java/org/apache/parquet/filter2/recordlevel/FilteringRecordMaterializer.java": 115,
                "parquet-column/src/main/java/org/apache/parquet/filter2/recordlevel/IncrementallyUpdatedFilterPredicate.java": 157,
                "parquet-column/src/main/java/org/apache/parquet/filter2/recordlevel/IncrementallyUpdatedFilterPredicateBuilderBase.java": 97,
                "parquet-column/src/main/java/org/apache/parquet/filter2/recordlevel/IncrementallyUpdatedFilterPredicateEvaluator.java": 63,
                "parquet-column/src/main/java/org/apache/parquet/filter2/recordlevel/IncrementallyUpdatedFilterPredicateResetter.java": 60,
                "parquet-column/src/main/java/org/apache/parquet/io/BaseRecordReader.java": 144,
                "parquet-column/src/main/java/org/apache/parquet/io/ColumnIO.java": 138,
                "parquet-column/src/main/java/org/apache/parquet/io/ColumnIOFactory.java": 161,
                "parquet-column/src/main/java/org/apache/parquet/io/CompilationException.java": 47,
                "parquet-column/src/main/java/org/apache/parquet/io/EmptyRecordReader.java": 50,
                "parquet-column/src/main/java/org/apache/parquet/io/FilteredRecordReader.java": 99,
                "parquet-column/src/main/java/org/apache/parquet/io/GroupColumnIO.java": 122,
                "parquet-column/src/main/java/org/apache/parquet/io/InvalidRecordException.java": 48,
                "parquet-column/src/main/java/org/apache/parquet/io/MessageColumnIO.java": 396,
                "parquet-column/src/main/java/org/apache/parquet/io/ParquetDecodingException.java": 47,
                "parquet-column/src/main/java/org/apache/parquet/io/ParquetEncodingException.java": 47,
                "parquet-column/src/main/java/org/apache/parquet/io/PrimitiveColumnIO.java": 113,
                "parquet-column/src/main/java/org/apache/parquet/io/RecordConsumerLoggingWrapper.java": 178,
                "parquet-column/src/main/java/org/apache/parquet/io/RecordReader.java": 43,
                "parquet-column/src/main/java/org/apache/parquet/io/RecordReaderImplementation.java": 473,
                "parquet-column/src/main/java/org/apache/parquet/io/ValidatingRecordConsumer.java": 230,
                "parquet-column/src/main/java/org/apache/parquet/io/api/Binary.java": 413,
                "parquet-column/src/main/java/org/apache/parquet/io/api/Converter.java": 40,
                "parquet-column/src/main/java/org/apache/parquet/io/api/GroupConverter.java": 58,
                "parquet-column/src/main/java/org/apache/parquet/io/api/PrimitiveConverter.java": 111,
                "parquet-column/src/main/java/org/apache/parquet/io/api/RecordConsumer.java": 128,
                "parquet-column/src/main/java/org/apache/parquet/io/api/RecordMaterializer.java": 48,
                "parquet-column/src/main/java/org/apache/parquet/schema/ConversionPatterns.java": 104,
                "parquet-column/src/main/java/org/apache/parquet/schema/DecimalMetadata.java": 57,
                "parquet-column/src/main/java/org/apache/parquet/schema/GroupType.java": 391,
                "parquet-column/src/main/java/org/apache/parquet/schema/IncompatibleSchemaModificationException.java": 49,
                "parquet-column/src/main/java/org/apache/parquet/schema/MessageType.java": 148,
                "parquet-column/src/main/java/org/apache/parquet/schema/MessageTypeParser.java": 216,
                "parquet-column/src/main/java/org/apache/parquet/schema/OriginalType.java": 42,
                "parquet-column/src/main/java/org/apache/parquet/schema/PrimitiveType.java": 530,
                "parquet-column/src/main/java/org/apache/parquet/schema/Type.java": 317,
                "parquet-column/src/main/java/org/apache/parquet/schema/TypeConverter.java": 55,
                "parquet-column/src/main/java/org/apache/parquet/schema/TypeVisitor.java": 46,
                "parquet-column/src/main/java/org/apache/parquet/schema/Types.java": 668,
                "parquet-column/src/main/java/parquet/column/ColumnDescriptor.java": 129,
                "parquet-column/src/main/java/parquet/column/ColumnReadStore.java": 34,
                "parquet-column/src/main/java/parquet/column/ColumnReader.java": 115,
                "parquet-column/src/main/java/parquet/column/ColumnWriteStore.java": 61,
                "parquet-column/src/main/java/parquet/column/ColumnWriter.java": 87,
                "parquet-column/src/main/java/parquet/column/Dictionary.java": 66,
                "parquet-column/src/main/java/parquet/column/Encoding.java": 291,
                "parquet-column/src/main/java/parquet/column/ParquetProperties.java": 242,
                "parquet-column/src/main/java/parquet/column/UnknownColumnException.java": 42,
                "parquet-column/src/main/java/parquet/column/UnknownColumnTypeException.java": 43,
                "parquet-column/src/main/java/parquet/column/ValuesType.java": 29,
                "parquet-column/src/main/java/parquet/column/impl/ColumnReadStoreImpl.java": 82,
                "parquet-column/src/main/java/parquet/column/impl/ColumnReaderImpl.java": 661,
                "parquet-column/src/main/java/parquet/column/impl/ColumnWriteStoreV1.java": 135,
                "parquet-column/src/main/java/parquet/column/impl/ColumnWriteStoreV2.java": 166,
                "parquet-column/src/main/java/parquet/column/impl/ColumnWriterV1.java": 279,
                "parquet-column/src/main/java/parquet/column/impl/ColumnWriterV2.java": 305,
                "parquet-column/src/main/java/parquet/column/page/DataPage.java": 53,
                "parquet-column/src/main/java/parquet/column/page/DataPageV1.java": 98,
                "parquet-column/src/main/java/parquet/column/page/DataPageV2.java": 156,
                "parquet-column/src/main/java/parquet/column/page/DictionaryPage.java": 88,
                "parquet-column/src/main/java/parquet/column/page/Page.java": 49,
                "parquet-column/src/main/java/parquet/column/page/PageReadStore.java": 46,
                "parquet-column/src/main/java/parquet/column/page/PageReader.java": 43,
                "parquet-column/src/main/java/parquet/column/page/PageWriteStore.java": 38,
                "parquet-column/src/main/java/parquet/column/page/PageWriter.java": 89,
                "parquet-column/src/main/java/parquet/column/statistics/BinaryStatistics.java": 108,
                "parquet-column/src/main/java/parquet/column/statistics/BooleanStatistics.java": 108,
                "parquet-column/src/main/java/parquet/column/statistics/DoubleStatistics.java": 108,
                "parquet-column/src/main/java/parquet/column/statistics/FloatStatistics.java": 108,
                "parquet-column/src/main/java/parquet/column/statistics/IntStatistics.java": 108,
                "parquet-column/src/main/java/parquet/column/statistics/LongStatistics.java": 108,
                "parquet-column/src/main/java/parquet/column/statistics/Statistics.java": 247,
                "parquet-column/src/main/java/parquet/column/statistics/StatisticsClassException.java": 34,
                "parquet-column/src/main/java/parquet/column/values/RequiresFallback.java": 54,
                "parquet-column/src/main/java/parquet/column/values/ValuesReader.java": 126,
                "parquet-column/src/main/java/parquet/column/values/ValuesWriter.java": 128,
                "parquet-column/src/main/java/parquet/column/values/bitpacking/BitPackingValuesReader.java": 91,
                "parquet-column/src/main/java/parquet/column/values/bitpacking/BitPackingValuesWriter.java": 125,
                "parquet-column/src/main/java/parquet/column/values/bitpacking/ByteBitPackingValuesReader.java": 83,
                "parquet-column/src/main/java/parquet/column/values/bitpacking/ByteBitPackingValuesWriter.java": 86,
                "parquet-column/src/main/java/parquet/column/values/boundedint/BitReader.java": 123,
                "parquet-column/src/main/java/parquet/column/values/boundedint/BitWriter.java": 159,
                "parquet-column/src/main/java/parquet/column/values/boundedint/BoundedIntValuesFactory.java": 32,
                "parquet-column/src/main/java/parquet/column/values/boundedint/BoundedIntValuesReader.java": 93,
                "parquet-column/src/main/java/parquet/column/values/boundedint/BoundedIntValuesWriter.java": 159,
                "parquet-column/src/main/java/parquet/column/values/boundedint/DevNullValuesWriter.java": 89,
                "parquet-column/src/main/java/parquet/column/values/boundedint/ZeroIntegerValuesReader.java": 52,
                "parquet-column/src/main/java/parquet/column/values/delta/DeltaBinaryPackingConfig.java": 57,
                "parquet-column/src/main/java/parquet/column/values/delta/DeltaBinaryPackingValuesReader.java": 170,
                "parquet-column/src/main/java/parquet/column/values/delta/DeltaBinaryPackingValuesWriter.java": 269,
                "parquet-column/src/main/java/parquet/column/values/deltalengthbytearray/DeltaLengthByteArrayValuesReader.java": 70,
                "parquet-column/src/main/java/parquet/column/values/deltalengthbytearray/DeltaLengthByteArrayValuesWriter.java": 106,
                "parquet-column/src/main/java/parquet/column/values/deltastrings/DeltaByteArrayReader.java": 78,
                "parquet-column/src/main/java/parquet/column/values/deltastrings/DeltaByteArrayWriter.java": 92,
                "parquet-column/src/main/java/parquet/column/values/dictionary/DictionaryValuesReader.java": 135,
                "parquet-column/src/main/java/parquet/column/values/dictionary/DictionaryValuesWriter.java": 625,
                "parquet-column/src/main/java/parquet/column/values/dictionary/IntList.java": 123,
                "parquet-column/src/main/java/parquet/column/values/dictionary/PlainValuesDictionary.java": 310,
                "parquet-column/src/main/java/parquet/column/values/fallback/FallbackValuesWriter.java": 190,
                "parquet-column/src/main/java/parquet/column/values/plain/BinaryPlainValuesReader.java": 70,
                "parquet-column/src/main/java/parquet/column/values/plain/BooleanPlainValuesReader.java": 75,
                "parquet-column/src/main/java/parquet/column/values/plain/BooleanPlainValuesWriter.java": 78,
                "parquet-column/src/main/java/parquet/column/values/plain/FixedLenByteArrayPlainValuesReader.java": 67,
                "parquet-column/src/main/java/parquet/column/values/plain/FixedLenByteArrayPlainValuesWriter.java": 98,
                "parquet-column/src/main/java/parquet/column/values/plain/PlainValuesReader.java": 135,
                "parquet-column/src/main/java/parquet/column/values/plain/PlainValuesWriter.java": 143,
                "parquet-column/src/main/java/parquet/column/values/rle/RunLengthBitPackingHybridDecoder.java": 109,
                "parquet-column/src/main/java/parquet/column/values/rle/RunLengthBitPackingHybridEncoder.java": 291,
                "parquet-column/src/main/java/parquet/column/values/rle/RunLengthBitPackingHybridValuesReader.java": 77,
                "parquet-column/src/main/java/parquet/column/values/rle/RunLengthBitPackingHybridValuesWriter.java": 88,
                "parquet-column/src/main/java/parquet/example/DummyRecordConverter.java": 114,
                "parquet-column/src/main/java/parquet/example/Paper.java": 167,
                "parquet-column/src/main/java/parquet/example/data/Group.java": 143,
                "parquet-column/src/main/java/parquet/example/data/GroupFactory.java": 25,
                "parquet-column/src/main/java/parquet/example/data/GroupValueSource.java": 89,
                "parquet-column/src/main/java/parquet/example/data/GroupWriter.java": 62,
                "parquet-column/src/main/java/parquet/example/data/simple/BinaryValue.java": 52,
                "parquet-column/src/main/java/parquet/example/data/simple/BooleanValue.java": 44,
                "parquet-column/src/main/java/parquet/example/data/simple/DoubleValue.java": 45,
                "parquet-column/src/main/java/parquet/example/data/simple/FloatValue.java": 45,
                "parquet-column/src/main/java/parquet/example/data/simple/Int96Value.java": 46,
                "parquet-column/src/main/java/parquet/example/data/simple/IntegerValue.java": 46,
                "parquet-column/src/main/java/parquet/example/data/simple/LongValue.java": 45,
                "parquet-column/src/main/java/parquet/example/data/simple/NanoTime.java": 80,
                "parquet-column/src/main/java/parquet/example/data/simple/Primitive.java": 60,
                "parquet-column/src/main/java/parquet/example/data/simple/SimpleGroup.java": 232,
                "parquet-column/src/main/java/parquet/example/data/simple/SimpleGroupFactory.java": 38,
                "parquet-column/src/main/java/parquet/example/data/simple/convert/GroupRecordConverter.java": 57,
                "parquet-column/src/main/java/parquet/example/data/simple/convert/SimpleGroupConverter.java": 67,
                "parquet-column/src/main/java/parquet/example/data/simple/convert/SimplePrimitiveConverter.java": 88,
                "parquet-column/src/main/java/parquet/filter/AndRecordFilter.java": 64,
                "parquet-column/src/main/java/parquet/filter/ColumnPredicates.java": 190,
                "parquet-column/src/main/java/parquet/filter/ColumnRecordFilter.java": 75,
                "parquet-column/src/main/java/parquet/filter/NotRecordFilter.java": 58,
                "parquet-column/src/main/java/parquet/filter/OrRecordFilter.java": 62,
                "parquet-column/src/main/java/parquet/filter/PagedRecordFilter.java": 64,
                "parquet-column/src/main/java/parquet/filter/RecordFilter.java": 34,
                "parquet-column/src/main/java/parquet/filter/UnboundRecordFilter.java": 36,
                "parquet-column/src/main/java/parquet/filter2/compat/FilterCompat.java": 158,
                "parquet-column/src/main/java/parquet/filter2/predicate/FilterApi.java": 212,
                "parquet-column/src/main/java/parquet/filter2/predicate/FilterPredicate.java": 72,
                "parquet-column/src/main/java/parquet/filter2/predicate/LogicalInverseRewriter.java": 113,
                "parquet-column/src/main/java/parquet/filter2/predicate/LogicalInverter.java": 108,
                "parquet-column/src/main/java/parquet/filter2/predicate/Operators.java": 526,
                "parquet-column/src/main/java/parquet/filter2/predicate/SchemaCompatibilityValidator.java": 193,
                "parquet-column/src/main/java/parquet/filter2/predicate/Statistics.java": 42,
                "parquet-column/src/main/java/parquet/filter2/predicate/UserDefinedPredicate.java": 108,
                "parquet-column/src/main/java/parquet/filter2/predicate/ValidTypeMap.java": 178,
                "parquet-column/src/main/java/parquet/filter2/recordlevel/FilteringGroupConverter.java": 115,
                "parquet-column/src/main/java/parquet/filter2/recordlevel/FilteringPrimitiveConverter.java": 109,
                "parquet-column/src/main/java/parquet/filter2/recordlevel/FilteringRecordMaterializer.java": 115,
                "parquet-column/src/main/java/parquet/filter2/recordlevel/IncrementallyUpdatedFilterPredicate.java": 157,
                "parquet-column/src/main/java/parquet/filter2/recordlevel/IncrementallyUpdatedFilterPredicateBuilderBase.java": 97,
                "parquet-column/src/main/java/parquet/filter2/recordlevel/IncrementallyUpdatedFilterPredicateEvaluator.java": 63,
                "parquet-column/src/main/java/parquet/filter2/recordlevel/IncrementallyUpdatedFilterPredicateResetter.java": 60,
                "parquet-column/src/main/java/parquet/io/BaseRecordReader.java": 144,
                "parquet-column/src/main/java/parquet/io/ColumnIO.java": 138,
                "parquet-column/src/main/java/parquet/io/ColumnIOFactory.java": 163,
                "parquet-column/src/main/java/parquet/io/CompilationException.java": 47,
                "parquet-column/src/main/java/parquet/io/EmptyRecordReader.java": 50,
                "parquet-column/src/main/java/parquet/io/FilteredRecordReader.java": 99,
                "parquet-column/src/main/java/parquet/io/GroupColumnIO.java": 122,
                "parquet-column/src/main/java/parquet/io/InvalidRecordException.java": 48,
                "parquet-column/src/main/java/parquet/io/MessageColumnIO.java": 396,
                "parquet-column/src/main/java/parquet/io/ParquetDecodingException.java": 47,
                "parquet-column/src/main/java/parquet/io/ParquetEncodingException.java": 47,
                "parquet-column/src/main/java/parquet/io/PrimitiveColumnIO.java": 113,
                "parquet-column/src/main/java/parquet/io/RecordConsumerLoggingWrapper.java": 178,
                "parquet-column/src/main/java/parquet/io/RecordReader.java": 43,
                "parquet-column/src/main/java/parquet/io/RecordReaderImplementation.java": 473,
                "parquet-column/src/main/java/parquet/io/ValidatingRecordConsumer.java": 230,
                "parquet-column/src/main/java/parquet/io/api/Binary.java": 414,
                "parquet-column/src/main/java/parquet/io/api/Converter.java": 40,
                "parquet-column/src/main/java/parquet/io/api/GroupConverter.java": 58,
                "parquet-column/src/main/java/parquet/io/api/PrimitiveConverter.java": 111,
                "parquet-column/src/main/java/parquet/io/api/RecordConsumer.java": 128,
                "parquet-column/src/main/java/parquet/io/api/RecordMaterializer.java": 48,
                "parquet-column/src/main/java/parquet/schema/ConversionPatterns.java": 104,
                "parquet-column/src/main/java/parquet/schema/DecimalMetadata.java": 57,
                "parquet-column/src/main/java/parquet/schema/GroupType.java": 391,
                "parquet-column/src/main/java/parquet/schema/IncompatibleSchemaModificationException.java": 49,
                "parquet-column/src/main/java/parquet/schema/MessageType.java": 148,
                "parquet-column/src/main/java/parquet/schema/MessageTypeParser.java": 216,
                "parquet-column/src/main/java/parquet/schema/OriginalType.java": 42,
                "parquet-column/src/main/java/parquet/schema/PrimitiveType.java": 530,
                "parquet-column/src/main/java/parquet/schema/Type.java": 317,
                "parquet-column/src/main/java/parquet/schema/TypeConverter.java": 55,
                "parquet-column/src/main/java/parquet/schema/TypeVisitor.java": 46,
                "parquet-column/src/main/java/parquet/schema/Types.java": 668,
                "parquet-column/src/test/java/org/apache/parquet/column/impl/TestColumnReaderImpl.java": 123,
                "parquet-column/src/test/java/org/apache/parquet/column/mem/TestMemColumn.java": 164,
                "parquet-column/src/test/java/org/apache/parquet/column/mem/TestMemPageStore.java": 61,
                "parquet-column/src/test/java/org/apache/parquet/column/page/mem/MemPageReader.java": 69,
                "parquet-column/src/test/java/org/apache/parquet/column/page/mem/MemPageStore.java": 77,
                "parquet-column/src/test/java/org/apache/parquet/column/page/mem/MemPageWriter.java": 113,
                "parquet-column/src/test/java/org/apache/parquet/column/statistics/TestStatistics.java": 569,
                "parquet-column/src/test/java/org/apache/parquet/column/values/RandomStr.java": 56,
                "parquet-column/src/test/java/org/apache/parquet/column/values/Utils.java": 90,
                "parquet-column/src/test/java/org/apache/parquet/column/values/bitpacking/BitPackingPerfTest.java": 103,
                "parquet-column/src/test/java/org/apache/parquet/column/values/bitpacking/TestBitPackingColumn.java": 208,
                "parquet-column/src/test/java/org/apache/parquet/column/values/boundedint/TestBoundedColumns.java": 172,
                "parquet-column/src/test/java/org/apache/parquet/column/values/delta/DeltaBinaryPackingValuesWriterTest.java": 262,
                "parquet-column/src/test/java/org/apache/parquet/column/values/delta/benchmark/BenchMarkTest.java": 43,
                "parquet-column/src/test/java/org/apache/parquet/column/values/delta/benchmark/BenchmarkIntegerOutputSize.java": 102,
                "parquet-column/src/test/java/org/apache/parquet/column/values/delta/benchmark/BenchmarkReadingRandomIntegers.java": 96,
                "parquet-column/src/test/java/org/apache/parquet/column/values/delta/benchmark/RandomWritingBenchmarkTest.java": 70,
                "parquet-column/src/test/java/org/apache/parquet/column/values/delta/benchmark/SmallRangeWritingBenchmarkTest.java": 48,
                "parquet-column/src/test/java/org/apache/parquet/column/values/deltalengthbytearray/TestDeltaLengthByteArray.java": 74,
                "parquet-column/src/test/java/org/apache/parquet/column/values/deltalengthbytearray/benchmark/BenchmarkDeltaLengthByteArray.java": 71,
                "parquet-column/src/test/java/org/apache/parquet/column/values/deltastrings/TestDeltaByteArray.java": 84,
                "parquet-column/src/test/java/org/apache/parquet/column/values/deltastrings/benchmark/BenchmarkDeltaByteArray.java": 101,
                "parquet-column/src/test/java/org/apache/parquet/column/values/dictionary/TestDictionary.java": 531,
                "parquet-column/src/test/java/org/apache/parquet/column/values/rle/RunLengthBitPackingHybridIntegrationTest.java": 99,
                "parquet-column/src/test/java/org/apache/parquet/column/values/rle/TestRunLengthBitPackingHybridEncoder.java": 322,
                "parquet-column/src/test/java/org/apache/parquet/filter2/predicate/DummyUdp.java": 37,
                "parquet-column/src/test/java/org/apache/parquet/filter2/predicate/TestFilterApiMethods.java": 172,
                "parquet-column/src/test/java/org/apache/parquet/filter2/predicate/TestLogicalInverseRewriter.java": 103,
                "parquet-column/src/test/java/org/apache/parquet/filter2/predicate/TestLogicalInverter.java": 94,
                "parquet-column/src/test/java/org/apache/parquet/filter2/predicate/TestSchemaCompatibilityValidator.java": 142,
                "parquet-column/src/test/java/org/apache/parquet/filter2/predicate/TestValidTypeMap.java": 111,
                "parquet-column/src/test/java/org/apache/parquet/filter2/recordlevel/TestIncrementallyUpdatedFilterPredicateEvaluator.java": 209,
                "parquet-column/src/test/java/org/apache/parquet/filter2/recordlevel/TestIncrementallyUpdatedFilterPredicateResetter.java": 69,
                "parquet-column/src/test/java/org/apache/parquet/filter2/recordlevel/TestValueInspector.java": 97,
                "parquet-column/src/test/java/org/apache/parquet/io/ConverterConsumer.java": 117,
                "parquet-column/src/test/java/org/apache/parquet/io/ExpectationValidatingConverter.java": 169,
                "parquet-column/src/test/java/org/apache/parquet/io/ExpectationValidatingRecordConsumer.java": 104,
                "parquet-column/src/test/java/org/apache/parquet/io/PerfTest.java": 132,
                "parquet-column/src/test/java/org/apache/parquet/io/TestColumnIO.java": 674,
                "parquet-column/src/test/java/org/apache/parquet/io/TestFiltered.java": 270,
                "parquet-column/src/test/java/org/apache/parquet/parser/TestParquetParser.java": 313,
                "parquet-column/src/test/java/org/apache/parquet/schema/TestMessageType.java": 148,
                "parquet-column/src/test/java/org/apache/parquet/schema/TestTypeBuilders.java": 619,
                "parquet-column/src/test/java/parquet/column/impl/TestColumnReaderImpl.java": 123,
                "parquet-column/src/test/java/parquet/column/mem/TestMemColumn.java": 164,
                "parquet-column/src/test/java/parquet/column/mem/TestMemPageStore.java": 61,
                "parquet-column/src/test/java/parquet/column/page/mem/MemPageReader.java": 69,
                "parquet-column/src/test/java/parquet/column/page/mem/MemPageStore.java": 77,
                "parquet-column/src/test/java/parquet/column/page/mem/MemPageWriter.java": 114,
                "parquet-column/src/test/java/parquet/column/statistics/TestStatistics.java": 569,
                "parquet-column/src/test/java/parquet/column/values/RandomStr.java": 56,
                "parquet-column/src/test/java/parquet/column/values/Utils.java": 90,
                "parquet-column/src/test/java/parquet/column/values/bitpacking/BitPackingPerfTest.java": 103,
                "parquet-column/src/test/java/parquet/column/values/bitpacking/TestBitPackingColumn.java": 208,
                "parquet-column/src/test/java/parquet/column/values/boundedint/TestBoundedColumns.java": 175,
                "parquet-column/src/test/java/parquet/column/values/delta/DeltaBinaryPackingValuesWriterTest.java": 262,
                "parquet-column/src/test/java/parquet/column/values/delta/benchmark/BenchMarkTest.java": 43,
                "parquet-column/src/test/java/parquet/column/values/delta/benchmark/BenchmarkIntegerOutputSize.java": 102,
                "parquet-column/src/test/java/parquet/column/values/delta/benchmark/BenchmarkReadingRandomIntegers.java": 96,
                "parquet-column/src/test/java/parquet/column/values/delta/benchmark/RandomWritingBenchmarkTest.java": 70,
                "parquet-column/src/test/java/parquet/column/values/delta/benchmark/SmallRangeWritingBenchmarkTest.java": 48,
                "parquet-column/src/test/java/parquet/column/values/deltalengthbytearray/TestDeltaLengthByteArray.java": 74,
                "parquet-column/src/test/java/parquet/column/values/deltalengthbytearray/benchmark/BenchmarkDeltaLengthByteArray.java": 71,
                "parquet-column/src/test/java/parquet/column/values/deltastrings/TestDeltaByteArray.java": 84,
                "parquet-column/src/test/java/parquet/column/values/deltastrings/benchmark/BenchmarkDeltaByteArray.java": 101,
                "parquet-column/src/test/java/parquet/column/values/dictionary/TestDictionary.java": 531,
                "parquet-column/src/test/java/parquet/column/values/rle/RunLengthBitPackingHybridIntegrationTest.java": 100,
                "parquet-column/src/test/java/parquet/column/values/rle/TestRunLengthBitPackingHybridEncoder.java": 322,
                "parquet-column/src/test/java/parquet/filter2/predicate/DummyUdp.java": 37,
                "parquet-column/src/test/java/parquet/filter2/predicate/TestFilterApiMethods.java": 172,
                "parquet-column/src/test/java/parquet/filter2/predicate/TestLogicalInverseRewriter.java": 103,
                "parquet-column/src/test/java/parquet/filter2/predicate/TestLogicalInverter.java": 94,
                "parquet-column/src/test/java/parquet/filter2/predicate/TestSchemaCompatibilityValidator.java": 142,
                "parquet-column/src/test/java/parquet/filter2/predicate/TestValidTypeMap.java": 111,
                "parquet-column/src/test/java/parquet/filter2/recordlevel/TestIncrementallyUpdatedFilterPredicateEvaluator.java": 209,
                "parquet-column/src/test/java/parquet/filter2/recordlevel/TestIncrementallyUpdatedFilterPredicateResetter.java": 69,
                "parquet-column/src/test/java/parquet/filter2/recordlevel/TestValueInspector.java": 97,
                "parquet-column/src/test/java/parquet/io/ConverterConsumer.java": 117,
                "parquet-column/src/test/java/parquet/io/ExpectationValidatingConverter.java": 169,
                "parquet-column/src/test/java/parquet/io/ExpectationValidatingRecordConsumer.java": 105,
                "parquet-column/src/test/java/parquet/io/PerfTest.java": 132,
                "parquet-column/src/test/java/parquet/io/TestColumnIO.java": 674,
                "parquet-column/src/test/java/parquet/io/TestFiltered.java": 270,
                "parquet-column/src/test/java/parquet/parser/TestParquetParser.java": 313,
                "parquet-column/src/test/java/parquet/schema/TestMessageType.java": 148,
                "parquet-column/src/test/java/parquet/schema/TestTypeBuilders.java": 619,
                "parquet-common/src/main/java/org/apache/parquet/Closeables.java": 55,
                "parquet-common/src/main/java/org/apache/parquet/Ints.java": 44,
                "parquet-common/src/main/java/org/apache/parquet/Log.java": 206,
                "parquet-common/src/main/java/org/apache/parquet/ParquetRuntimeException.java": 46,
                "parquet-common/src/main/java/org/apache/parquet/Preconditions.java": 123,
                "parquet-common/src/main/java/org/apache/parquet/Version.java": 103,
                "parquet-common/src/main/java/org/apache/parquet/bytes/BytesUtils.java": 269,
                "parquet-common/src/main/java/org/apache/parquet/hadoop/metadata/Canonicalizer.java": 62,
                "parquet-common/src/main/java/org/apache/parquet/hadoop/metadata/ColumnPath.java": 97,
                "parquet-common/src/main/java/parquet/Closeables.java": 55,
                "parquet-common/src/main/java/parquet/Ints.java": 44,
                "parquet-common/src/main/java/parquet/Log.java": 206,
                "parquet-common/src/main/java/parquet/ParquetRuntimeException.java": 46,
                "parquet-common/src/main/java/parquet/Preconditions.java": 123,
                "parquet-common/src/main/java/parquet/Version.java": 103,
                "parquet-common/src/main/java/parquet/bytes/BytesUtils.java": 269,
                "parquet-common/src/main/java/parquet/hadoop/metadata/Canonicalizer.java": 62,
                "parquet-common/src/main/java/parquet/hadoop/metadata/ColumnPath.java": 97,
                "parquet-common/src/test/java/org/apache/parquet/TestLog.java": 31,
                "parquet-common/src/test/java/org/apache/parquet/TestPreconditions.java": 58,
                "parquet-common/src/test/java/org/apache/parquet/bytes/TestBytesUtil.java": 49,
                "parquet-common/src/test/java/parquet/TestLog.java": 31,
                "parquet-common/src/test/java/parquet/TestPreconditions.java": 58,
                "parquet-common/src/test/java/parquet/bytes/TestBytesUtil.java": 49,
                "parquet-encoding/src/main/java/org/apache/parquet/bytes/BytesInput.java": 365,
                "parquet-encoding/src/main/java/org/apache/parquet/bytes/CapacityByteArrayOutputStream.java": 276,
                "parquet-encoding/src/main/java/org/apache/parquet/bytes/ConcatenatingByteArrayCollector.java": 63,
                "parquet-encoding/src/main/java/org/apache/parquet/bytes/LittleEndianDataInputStream.java": 424,
                "parquet-encoding/src/main/java/org/apache/parquet/bytes/LittleEndianDataOutputStream.java": 213,
                "parquet-encoding/src/main/java/org/apache/parquet/column/values/bitpacking/BitPacking.java": 725,
                "parquet-encoding/src/main/java/org/apache/parquet/column/values/bitpacking/ByteBasedBitPackingEncoder.java": 130,
                "parquet-encoding/src/main/java/org/apache/parquet/column/values/bitpacking/BytePacker.java": 86,
                "parquet-encoding/src/main/java/org/apache/parquet/column/values/bitpacking/BytePackerFactory.java": 25,
                "parquet-encoding/src/main/java/org/apache/parquet/column/values/bitpacking/IntPacker.java": 66,
                "parquet-encoding/src/main/java/org/apache/parquet/column/values/bitpacking/IntPackerFactory.java": 25,
                "parquet-encoding/src/main/java/org/apache/parquet/column/values/bitpacking/Packer.java": 99,
                "parquet-encoding/src/main/java/parquet/bytes/BytesInput.java": 365,
                "parquet-encoding/src/main/java/parquet/bytes/CapacityByteArrayOutputStream.java": 276,
                "parquet-encoding/src/main/java/parquet/bytes/ConcatenatingByteArrayCollector.java": 63,
                "parquet-encoding/src/main/java/parquet/bytes/LittleEndianDataInputStream.java": 424,
                "parquet-encoding/src/main/java/parquet/bytes/LittleEndianDataOutputStream.java": 213,
                "parquet-encoding/src/main/java/parquet/column/values/bitpacking/BitPacking.java": 725,
                "parquet-encoding/src/main/java/parquet/column/values/bitpacking/ByteBasedBitPackingEncoder.java": 130,
                "parquet-encoding/src/main/java/parquet/column/values/bitpacking/BytePacker.java": 86,
                "parquet-encoding/src/main/java/parquet/column/values/bitpacking/BytePackerFactory.java": 25,
                "parquet-encoding/src/main/java/parquet/column/values/bitpacking/IntPacker.java": 66,
                "parquet-encoding/src/main/java/parquet/column/values/bitpacking/IntPackerFactory.java": 25,
                "parquet-encoding/src/main/java/parquet/column/values/bitpacking/Packer.java": 99,
                "parquet-encoding/src/test/java/org/apache/parquet/bytes/TestCapacityByteArrayOutputStream.java": 242,
                "parquet-encoding/src/test/java/org/apache/parquet/column/values/bitpacking/TestBitPacking.java": 218,
                "parquet-encoding/src/test/java/org/apache/parquet/column/values/bitpacking/TestByteBasedBitPackingEncoder.java": 40,
                "parquet-encoding/src/test/java/org/apache/parquet/column/values/bitpacking/TestByteBitPacking.java": 150,
                "parquet-encoding/src/test/java/org/apache/parquet/column/values/bitpacking/TestLemireBitPacking.java": 123,
                "parquet-encoding/src/test/java/parquet/bytes/TestCapacityByteArrayOutputStream.java": 242,
                "parquet-encoding/src/test/java/parquet/column/values/bitpacking/TestBitPacking.java": 218,
                "parquet-encoding/src/test/java/parquet/column/values/bitpacking/TestByteBasedBitPackingEncoder.java": 40,
                "parquet-encoding/src/test/java/parquet/column/values/bitpacking/TestByteBitPacking.java": 151,
                "parquet-encoding/src/test/java/parquet/column/values/bitpacking/TestLemireBitPacking.java": 123,
                "parquet-generator/src/main/java/org/apache/parquet/encoding/Generator.java": 37,
                "parquet-generator/src/main/java/org/apache/parquet/encoding/bitpacking/ByteBasedBitPackingGenerator.java": 259,
                "parquet-generator/src/main/java/org/apache/parquet/encoding/bitpacking/IntBasedBitPackingGenerator.java": 211,
                "parquet-generator/src/main/java/org/apache/parquet/filter2/Generator.java": 28,
                "parquet-generator/src/main/java/org/apache/parquet/filter2/IncrementallyUpdatedFilterPredicateGenerator.java": 269,
                "parquet-generator/src/main/java/parquet/encoding/Generator.java": 37,
                "parquet-generator/src/main/java/parquet/encoding/bitpacking/ByteBasedBitPackingGenerator.java": 259,
                "parquet-generator/src/main/java/parquet/encoding/bitpacking/IntBasedBitPackingGenerator.java": 211,
                "parquet-generator/src/main/java/parquet/filter2/Generator.java": 28,
                "parquet-generator/src/main/java/parquet/filter2/IncrementallyUpdatedFilterPredicateGenerator.java": 269,
                "parquet-hadoop/src/main/java/org/apache/parquet/filter2/compat/RowGroupFilter.java": 81,
                "parquet-hadoop/src/main/java/org/apache/parquet/filter2/statisticslevel/StatisticsFilter.java": 305,
                "parquet-hadoop/src/main/java/org/apache/parquet/format/converter/ParquetMetadataConverter.java": 735,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/BadConfigurationException.java": 47,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/CodecFactory.java": 195,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ColumnChunkPageReadStore.java": 170,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ColumnChunkPageWriteStore.java": 242,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/Footer.java": 57,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/InternalParquetRecordReader.java": 244,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/InternalParquetRecordWriter.java": 175,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/LruCache.java": 199,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/MemoryManager.java": 158,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ParquetFileReader.java": 782,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ParquetFileWriter.java": 553,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ParquetInputFormat.java": 778,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ParquetInputSplit.java": 294,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ParquetOutputCommitter.java": 72,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ParquetOutputFormat.java": 353,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ParquetReader.java": 195,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ParquetRecordReader.java": 217,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ParquetRecordWriter.java": 126,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ParquetWriter.java": 272,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/PrintFooter.java": 271,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/api/DelegatingReadSupport.java": 62,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/api/DelegatingWriteSupport.java": 66,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/api/InitContext.java": 102,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/api/ReadSupport.java": 150,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/api/WriteSupport.java": 131,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/api/package-info.java": 27,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/codec/CodecConfig.java": 169,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/codec/CompressionCodecNotSupportedException.java": 36,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/codec/NonBlockedCompressorStream.java": 50,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/codec/NonBlockedDecompressorStream.java": 57,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/codec/SnappyCodec.java": 105,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/codec/SnappyCompressor.java": 161,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/codec/SnappyDecompressor.java": 150,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/codec/SnappyUtil.java": 33,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/example/ExampleInputFormat.java": 38,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/example/ExampleOutputFormat.java": 62,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/example/GroupReadSupport.java": 49,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/example/GroupWriteSupport.java": 67,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/mapred/Container.java": 37,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/mapred/DeprecatedParquetInputFormat.java": 208,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/mapred/DeprecatedParquetOutputFormat.java": 119,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/mapred/MapredParquetOutputCommitter.java": 45,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/metadata/BlockMetaData.java": 123,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/metadata/ColumnChunkMetaData.java": 389,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/metadata/ColumnChunkProperties.java": 89,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/metadata/CompressionCodecName.java": 93,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/metadata/EncodingList.java": 81,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/metadata/FileMetaData.java": 83,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/metadata/GlobalMetaData.java": 106,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/metadata/ParquetMetadata.java": 132,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/package-info.java": 35,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/util/ConfigurationUtil.java": 44,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/util/ContextUtil.java": 275,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/util/HiddenFileFilter.java": 33,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/util/SerializationUtil.java": 111,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/util/counters/BenchmarkCounter.java": 114,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/util/counters/CounterLoader.java": 28,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/util/counters/ICounter.java": 29,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/util/counters/mapred/MapRedCounterAdapter.java": 44,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/util/counters/mapred/MapRedCounterLoader.java": 52,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/util/counters/mapreduce/MapReduceCounterAdapter.java": 45,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/util/counters/mapreduce/MapReduceCounterLoader.java": 47,
                "parquet-hadoop/src/main/java/parquet/filter2/compat/RowGroupFilter.java": 81,
                "parquet-hadoop/src/main/java/parquet/filter2/statisticslevel/StatisticsFilter.java": 305,
                "parquet-hadoop/src/main/java/parquet/format/converter/ParquetMetadataConverter.java": 735,
                "parquet-hadoop/src/main/java/parquet/hadoop/BadConfigurationException.java": 47,
                "parquet-hadoop/src/main/java/parquet/hadoop/CodecFactory.java": 195,
                "parquet-hadoop/src/main/java/parquet/hadoop/ColumnChunkPageReadStore.java": 170,
                "parquet-hadoop/src/main/java/parquet/hadoop/ColumnChunkPageWriteStore.java": 242,
                "parquet-hadoop/src/main/java/parquet/hadoop/Footer.java": 57,
                "parquet-hadoop/src/main/java/parquet/hadoop/InternalParquetRecordReader.java": 244,
                "parquet-hadoop/src/main/java/parquet/hadoop/InternalParquetRecordWriter.java": 175,
                "parquet-hadoop/src/main/java/parquet/hadoop/LruCache.java": 199,
                "parquet-hadoop/src/main/java/parquet/hadoop/MemoryManager.java": 158,
                "parquet-hadoop/src/main/java/parquet/hadoop/ParquetFileReader.java": 782,
                "parquet-hadoop/src/main/java/parquet/hadoop/ParquetFileWriter.java": 553,
                "parquet-hadoop/src/main/java/parquet/hadoop/ParquetInputFormat.java": 778,
                "parquet-hadoop/src/main/java/parquet/hadoop/ParquetInputSplit.java": 294,
                "parquet-hadoop/src/main/java/parquet/hadoop/ParquetOutputCommitter.java": 72,
                "parquet-hadoop/src/main/java/parquet/hadoop/ParquetOutputFormat.java": 353,
                "parquet-hadoop/src/main/java/parquet/hadoop/ParquetReader.java": 195,
                "parquet-hadoop/src/main/java/parquet/hadoop/ParquetRecordReader.java": 217,
                "parquet-hadoop/src/main/java/parquet/hadoop/ParquetRecordWriter.java": 126,
                "parquet-hadoop/src/main/java/parquet/hadoop/ParquetWriter.java": 272,
                "parquet-hadoop/src/main/java/parquet/hadoop/PrintFooter.java": 271,
                "parquet-hadoop/src/main/java/parquet/hadoop/api/DelegatingReadSupport.java": 62,
                "parquet-hadoop/src/main/java/parquet/hadoop/api/DelegatingWriteSupport.java": 66,
                "parquet-hadoop/src/main/java/parquet/hadoop/api/InitContext.java": 102,
                "parquet-hadoop/src/main/java/parquet/hadoop/api/ReadSupport.java": 150,
                "parquet-hadoop/src/main/java/parquet/hadoop/api/WriteSupport.java": 131,
                "parquet-hadoop/src/main/java/parquet/hadoop/api/package-info.java": 27,
                "parquet-hadoop/src/main/java/parquet/hadoop/codec/CodecConfig.java": 169,
                "parquet-hadoop/src/main/java/parquet/hadoop/codec/CompressionCodecNotSupportedException.java": 36,
                "parquet-hadoop/src/main/java/parquet/hadoop/codec/NonBlockedCompressorStream.java": 50,
                "parquet-hadoop/src/main/java/parquet/hadoop/codec/NonBlockedDecompressorStream.java": 57,
                "parquet-hadoop/src/main/java/parquet/hadoop/codec/SnappyCodec.java": 105,
                "parquet-hadoop/src/main/java/parquet/hadoop/codec/SnappyCompressor.java": 161,
                "parquet-hadoop/src/main/java/parquet/hadoop/codec/SnappyDecompressor.java": 150,
                "parquet-hadoop/src/main/java/parquet/hadoop/codec/SnappyUtil.java": 33,
                "parquet-hadoop/src/main/java/parquet/hadoop/example/ExampleInputFormat.java": 38,
                "parquet-hadoop/src/main/java/parquet/hadoop/example/ExampleOutputFormat.java": 62,
                "parquet-hadoop/src/main/java/parquet/hadoop/example/GroupReadSupport.java": 49,
                "parquet-hadoop/src/main/java/parquet/hadoop/example/GroupWriteSupport.java": 67,
                "parquet-hadoop/src/main/java/parquet/hadoop/mapred/Container.java": 37,
                "parquet-hadoop/src/main/java/parquet/hadoop/mapred/DeprecatedParquetInputFormat.java": 208,
                "parquet-hadoop/src/main/java/parquet/hadoop/mapred/DeprecatedParquetOutputFormat.java": 119,
                "parquet-hadoop/src/main/java/parquet/hadoop/mapred/MapredParquetOutputCommitter.java": 45,
                "parquet-hadoop/src/main/java/parquet/hadoop/metadata/BlockMetaData.java": 123,
                "parquet-hadoop/src/main/java/parquet/hadoop/metadata/ColumnChunkMetaData.java": 389,
                "parquet-hadoop/src/main/java/parquet/hadoop/metadata/ColumnChunkProperties.java": 89,
                "parquet-hadoop/src/main/java/parquet/hadoop/metadata/CompressionCodecName.java": 93,
                "parquet-hadoop/src/main/java/parquet/hadoop/metadata/EncodingList.java": 81,
                "parquet-hadoop/src/main/java/parquet/hadoop/metadata/FileMetaData.java": 83,
                "parquet-hadoop/src/main/java/parquet/hadoop/metadata/GlobalMetaData.java": 106,
                "parquet-hadoop/src/main/java/parquet/hadoop/metadata/ParquetMetadata.java": 132,
                "parquet-hadoop/src/main/java/parquet/hadoop/package-info.java": 35,
                "parquet-hadoop/src/main/java/parquet/hadoop/util/ConfigurationUtil.java": 44,
                "parquet-hadoop/src/main/java/parquet/hadoop/util/ContextUtil.java": 275,
                "parquet-hadoop/src/main/java/parquet/hadoop/util/HiddenFileFilter.java": 33,
                "parquet-hadoop/src/main/java/parquet/hadoop/util/SerializationUtil.java": 111,
                "parquet-hadoop/src/main/java/parquet/hadoop/util/counters/BenchmarkCounter.java": 114,
                "parquet-hadoop/src/main/java/parquet/hadoop/util/counters/CounterLoader.java": 28,
                "parquet-hadoop/src/main/java/parquet/hadoop/util/counters/ICounter.java": 29,
                "parquet-hadoop/src/main/java/parquet/hadoop/util/counters/mapred/MapRedCounterAdapter.java": 44,
                "parquet-hadoop/src/main/java/parquet/hadoop/util/counters/mapred/MapRedCounterLoader.java": 52,
                "parquet-hadoop/src/main/java/parquet/hadoop/util/counters/mapreduce/MapReduceCounterAdapter.java": 45,
                "parquet-hadoop/src/main/java/parquet/hadoop/util/counters/mapreduce/MapReduceCounterLoader.java": 47,
                "parquet-hadoop/src/test/java/org/apache/parquet/filter2/compat/TestRowGroupFilter.java": 102,
                "parquet-hadoop/src/test/java/org/apache/parquet/filter2/recordlevel/PhoneBookWriter.java": 269,
                "parquet-hadoop/src/test/java/org/apache/parquet/filter2/recordlevel/TestRecordLevelFilters.java": 276,
                "parquet-hadoop/src/test/java/org/apache/parquet/filter2/statisticslevel/TestStatisticsFilter.java": 325,
                "parquet-hadoop/src/test/java/org/apache/parquet/format/converter/TestParquetMetadataConverter.java": 255,
                "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/DeprecatedInputFormatTest.java": 182,
                "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/DeprecatedOutputFormatTest.java": 109,
                "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/TestColumnChunkPageWriteStore.java": 180,
                "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/TestInputFormat.java": 498,
                "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/TestLruCache.java": 162,
                "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/TestMemoryManager.java": 106,
                "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/TestParquetFileWriter.java": 499,
                "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/TestParquetWriter.java": 129,
                "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/TestParquetWriterNewPage.java": 135,
                "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/TestSnappyCodec.java": 140,
                "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/TestUtils.java": 40,
                "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/codec/CodecConfigTest.java": 77,
                "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/example/GroupReadSupportTest.java": 65,
                "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/example/TestInputOutputFormat.java": 291,
                "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/metadata/TestColumnChunkMetaData.java": 83,
                "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/util/TestSerializationUtil.java": 71,
                "parquet-hadoop/src/test/java/parquet/filter2/compat/TestRowGroupFilter.java": 102,
                "parquet-hadoop/src/test/java/parquet/filter2/recordlevel/PhoneBookWriter.java": 269,
                "parquet-hadoop/src/test/java/parquet/filter2/recordlevel/TestRecordLevelFilters.java": 277,
                "parquet-hadoop/src/test/java/parquet/filter2/statisticslevel/TestStatisticsFilter.java": 325,
                "parquet-hadoop/src/test/java/parquet/format/converter/TestParquetMetadataConverter.java": 255,
                "parquet-hadoop/src/test/java/parquet/hadoop/DeprecatedInputFormatTest.java": 182,
                "parquet-hadoop/src/test/java/parquet/hadoop/DeprecatedOutputFormatTest.java": 109,
                "parquet-hadoop/src/test/java/parquet/hadoop/TestColumnChunkPageWriteStore.java": 180,
                "parquet-hadoop/src/test/java/parquet/hadoop/TestInputFormat.java": 498,
                "parquet-hadoop/src/test/java/parquet/hadoop/TestLruCache.java": 162,
                "parquet-hadoop/src/test/java/parquet/hadoop/TestMemoryManager.java": 106,
                "parquet-hadoop/src/test/java/parquet/hadoop/TestParquetFileWriter.java": 499,
                "parquet-hadoop/src/test/java/parquet/hadoop/TestParquetWriter.java": 129,
                "parquet-hadoop/src/test/java/parquet/hadoop/TestParquetWriterNewPage.java": 135,
                "parquet-hadoop/src/test/java/parquet/hadoop/TestSnappyCodec.java": 140,
                "parquet-hadoop/src/test/java/parquet/hadoop/TestUtils.java": 40,
                "parquet-hadoop/src/test/java/parquet/hadoop/codec/CodecConfigTest.java": 77,
                "parquet-hadoop/src/test/java/parquet/hadoop/example/GroupReadSupportTest.java": 65,
                "parquet-hadoop/src/test/java/parquet/hadoop/example/TestInputOutputFormat.java": 291,
                "parquet-hadoop/src/test/java/parquet/hadoop/metadata/TestColumnChunkMetaData.java": 83,
                "parquet-hadoop/src/test/java/parquet/hadoop/util/TestSerializationUtil.java": 71,
                "parquet-hive/parquet-hive-binding/parquet-hive-0.10-binding/src/main/java/org/apache/parquet/hive/internal/Hive010Binding.java": 166,
                "parquet-hive/parquet-hive-binding/parquet-hive-0.10-binding/src/main/java/parquet/hive/internal/Hive010Binding.java": 166,
                "parquet-hive/parquet-hive-binding/parquet-hive-0.12-binding/src/main/java/org/apache/parquet/hive/internal/Hive012Binding.java": 167,
                "parquet-hive/parquet-hive-binding/parquet-hive-0.12-binding/src/main/java/parquet/hive/internal/Hive012Binding.java": 167,
                "parquet-hive/parquet-hive-binding/parquet-hive-binding-factory/src/main/java/org/apache/parquet/hive/HiveBindingFactory.java": 159,
                "parquet-hive/parquet-hive-binding/parquet-hive-binding-factory/src/main/java/parquet/hive/HiveBindingFactory.java": 159,
                "parquet-hive/parquet-hive-binding/parquet-hive-binding-factory/src/test/java/org/apache/parquet/hive/TestHiveBindingFactory.java": 139,
                "parquet-hive/parquet-hive-binding/parquet-hive-binding-factory/src/test/java/parquet/hive/TestHiveBindingFactory.java": 139,
                "parquet-hive/parquet-hive-binding/parquet-hive-binding-interface/src/main/java/org/apache/parquet/hive/HiveBinding.java": 57,
                "parquet-hive/parquet-hive-binding/parquet-hive-binding-interface/src/main/java/org/apache/parquet/hive/internal/AbstractHiveBinding.java": 54,
                "parquet-hive/parquet-hive-binding/parquet-hive-binding-interface/src/main/java/parquet/hive/HiveBinding.java": 57,
                "parquet-hive/parquet-hive-binding/parquet-hive-binding-interface/src/main/java/parquet/hive/internal/AbstractHiveBinding.java": 54,
                "parquet-hive/parquet-hive-storage-handler/src/main/java/org/apache/hadoop/hive/ql/io/parquet/MapredParquetInputFormat.java": 2,
                "parquet-hive/parquet-hive-storage-handler/src/main/java/org/apache/hadoop/hive/ql/io/parquet/MapredParquetOutputFormat.java": 2,
                "parquet-hive/parquet-hive-storage-handler/src/main/java/org/apache/hadoop/hive/ql/io/parquet/convert/ArrayWritableGroupConverter.java": 6,
                "parquet-hive/parquet-hive-storage-handler/src/main/java/org/apache/hadoop/hive/ql/io/parquet/convert/DataWritableGroupConverter.java": 6,
                "parquet-hive/parquet-hive-storage-handler/src/main/java/org/apache/hadoop/hive/ql/io/parquet/convert/DataWritableRecordConverter.java": 6,
                "parquet-hive/parquet-hive-storage-handler/src/main/java/org/apache/hadoop/hive/ql/io/parquet/convert/ETypeConverter.java": 8,
                "parquet-hive/parquet-hive-storage-handler/src/main/java/org/apache/hadoop/hive/ql/io/parquet/convert/HiveGroupConverter.java": 8,
                "parquet-hive/parquet-hive-storage-handler/src/main/java/org/apache/hadoop/hive/ql/io/parquet/convert/HiveSchemaConverter.java": 16,
                "parquet-hive/parquet-hive-storage-handler/src/main/java/org/apache/hadoop/hive/ql/io/parquet/read/DataWritableReadSupport.java": 22,
                "parquet-hive/parquet-hive-storage-handler/src/main/java/org/apache/hadoop/hive/ql/io/parquet/read/ParquetRecordReaderWrapper.java": 22,
                "parquet-hive/parquet-hive-storage-handler/src/main/java/org/apache/hadoop/hive/ql/io/parquet/serde/ParquetHiveSerDe.java": 2,
                "parquet-hive/parquet-hive-storage-handler/src/main/java/org/apache/hadoop/hive/ql/io/parquet/writable/BinaryWritable.java": 2,
                "parquet-hive/parquet-hive-storage-handler/src/main/java/org/apache/hadoop/hive/ql/io/parquet/write/DataWritableWriteSupport.java": 8,
                "parquet-hive/parquet-hive-storage-handler/src/main/java/org/apache/hadoop/hive/ql/io/parquet/write/DataWritableWriter.java": 8,
                "parquet-hive/parquet-hive-storage-handler/src/main/java/org/apache/hadoop/hive/ql/io/parquet/write/ParquetRecordWriterWrapper.java": 4,
                "parquet-hive/parquet-hive-storage-handler/src/main/java/org/apache/hadoop/hive/serde2/objectinspector/primitive/ParquetStringInspector.java": 2,
                "parquet-hive/parquet-hive-storage-handler/src/main/java/org/apache/parquet/hive/DeprecatedParquetInputFormat.java": 42,
                "parquet-hive/parquet-hive-storage-handler/src/main/java/org/apache/parquet/hive/DeprecatedParquetOutputFormat.java": 41,
                "parquet-hive/parquet-hive-storage-handler/src/main/java/org/apache/parquet/hive/MapredParquetInputFormat.java": 41,
                "parquet-hive/parquet-hive-storage-handler/src/main/java/org/apache/parquet/hive/MapredParquetOutputFormat.java": 40,
                "parquet-hive/parquet-hive-storage-handler/src/main/java/org/apache/parquet/hive/serde/ParquetHiveSerDe.java": 30,
                "parquet-hive/parquet-hive-storage-handler/src/main/java/parquet/hive/DeprecatedParquetInputFormat.java": 42,
                "parquet-hive/parquet-hive-storage-handler/src/main/java/parquet/hive/DeprecatedParquetOutputFormat.java": 41,
                "parquet-hive/parquet-hive-storage-handler/src/main/java/parquet/hive/MapredParquetInputFormat.java": 41,
                "parquet-hive/parquet-hive-storage-handler/src/main/java/parquet/hive/MapredParquetOutputFormat.java": 40,
                "parquet-hive/parquet-hive-storage-handler/src/main/java/parquet/hive/serde/ParquetHiveSerDe.java": 30,
                "parquet-hive/parquet-hive-storage-handler/src/test/java/org/apache/hadoop/hive/ql/io/parquet/TestHiveSchemaConverter.java": 12,
                "parquet-hive/parquet-hive-storage-handler/src/test/java/org/apache/hadoop/hive/ql/io/parquet/TestMapredParquetInputFormat.java": 2,
                "parquet-hive/parquet-hive-storage-handler/src/test/java/org/apache/hadoop/hive/ql/io/parquet/TestMapredParquetOutputFormat.java": 2,
                "parquet-hive/parquet-hive-storage-handler/src/test/java/org/apache/hadoop/hive/ql/io/parquet/TestParquetSerDe.java": 2,
                "parquet-pig/src/main/java/org/apache/parquet/pig/ParquetLoader.java": 383,
                "parquet-pig/src/main/java/org/apache/parquet/pig/ParquetStorer.java": 155,
                "parquet-pig/src/main/java/org/apache/parquet/pig/PigMetaData.java": 94,
                "parquet-pig/src/main/java/org/apache/parquet/pig/PigSchemaConverter.java": 514,
                "parquet-pig/src/main/java/org/apache/parquet/pig/SchemaConversionException.java": 47,
                "parquet-pig/src/main/java/org/apache/parquet/pig/TupleConversionException.java": 42,
                "parquet-pig/src/main/java/org/apache/parquet/pig/TupleReadSupport.java": 193,
                "parquet-pig/src/main/java/org/apache/parquet/pig/TupleWriteSupport.java": 206,
                "parquet-pig/src/main/java/org/apache/parquet/pig/convert/MapConverter.java": 201,
                "parquet-pig/src/main/java/org/apache/parquet/pig/convert/ParentValueContainer.java": 35,
                "parquet-pig/src/main/java/org/apache/parquet/pig/convert/TupleConverter.java": 594,
                "parquet-pig/src/main/java/org/apache/parquet/pig/convert/TupleRecordMaterializer.java": 50,
                "parquet-pig/src/main/java/org/apache/parquet/pig/summary/BagSummaryData.java": 80,
                "parquet-pig/src/main/java/org/apache/parquet/pig/summary/EnumStat.java": 115,
                "parquet-pig/src/main/java/org/apache/parquet/pig/summary/FieldSummaryData.java": 184,
                "parquet-pig/src/main/java/org/apache/parquet/pig/summary/MapSummaryData.java": 92,
                "parquet-pig/src/main/java/org/apache/parquet/pig/summary/NumberSummaryData.java": 50,
                "parquet-pig/src/main/java/org/apache/parquet/pig/summary/StringSummaryData.java": 85,
                "parquet-pig/src/main/java/org/apache/parquet/pig/summary/Summary.java": 283,
                "parquet-pig/src/main/java/org/apache/parquet/pig/summary/SummaryData.java": 159,
                "parquet-pig/src/main/java/org/apache/parquet/pig/summary/TupleSummaryData.java": 106,
                "parquet-pig/src/main/java/org/apache/parquet/pig/summary/ValueStat.java": 64,
                "parquet-pig/src/main/java/parquet/pig/ParquetLoader.java": 383,
                "parquet-pig/src/main/java/parquet/pig/ParquetStorer.java": 155,
                "parquet-pig/src/main/java/parquet/pig/PigMetaData.java": 94,
                "parquet-pig/src/main/java/parquet/pig/PigSchemaConverter.java": 514,
                "parquet-pig/src/main/java/parquet/pig/SchemaConversionException.java": 47,
                "parquet-pig/src/main/java/parquet/pig/TupleConversionException.java": 42,
                "parquet-pig/src/main/java/parquet/pig/TupleReadSupport.java": 193,
                "parquet-pig/src/main/java/parquet/pig/TupleWriteSupport.java": 206,
                "parquet-pig/src/main/java/parquet/pig/convert/MapConverter.java": 201,
                "parquet-pig/src/main/java/parquet/pig/convert/ParentValueContainer.java": 35,
                "parquet-pig/src/main/java/parquet/pig/convert/TupleConverter.java": 594,
                "parquet-pig/src/main/java/parquet/pig/convert/TupleRecordMaterializer.java": 50,
                "parquet-pig/src/main/java/parquet/pig/summary/BagSummaryData.java": 80,
                "parquet-pig/src/main/java/parquet/pig/summary/EnumStat.java": 115,
                "parquet-pig/src/main/java/parquet/pig/summary/FieldSummaryData.java": 184,
                "parquet-pig/src/main/java/parquet/pig/summary/MapSummaryData.java": 92,
                "parquet-pig/src/main/java/parquet/pig/summary/NumberSummaryData.java": 50,
                "parquet-pig/src/main/java/parquet/pig/summary/StringSummaryData.java": 85,
                "parquet-pig/src/main/java/parquet/pig/summary/Summary.java": 283,
                "parquet-pig/src/main/java/parquet/pig/summary/SummaryData.java": 159,
                "parquet-pig/src/main/java/parquet/pig/summary/TupleSummaryData.java": 106,
                "parquet-pig/src/main/java/parquet/pig/summary/ValueStat.java": 64,
                "parquet-pig/src/test/java/org/apache/parquet/pig/PerfTest.java": 108,
                "parquet-pig/src/test/java/org/apache/parquet/pig/PerfTest2.java": 185,
                "parquet-pig/src/test/java/org/apache/parquet/pig/PerfTestReadAllCols.java": 51,
                "parquet-pig/src/test/java/org/apache/parquet/pig/TestParquetLoader.java": 334,
                "parquet-pig/src/test/java/org/apache/parquet/pig/TestParquetStorer.java": 264,
                "parquet-pig/src/test/java/org/apache/parquet/pig/TestPigSchemaConverter.java": 228,
                "parquet-pig/src/test/java/org/apache/parquet/pig/TestTupleRecordConsumer.java": 209,
                "parquet-pig/src/test/java/org/apache/parquet/pig/TupleConsumerPerfTest.java": 209,
                "parquet-pig/src/test/java/org/apache/parquet/pig/summary/TestSummary.java": 160,
                "parquet-pig/src/test/java/parquet/pig/PerfTest.java": 111,
                "parquet-pig/src/test/java/parquet/pig/PerfTest2.java": 187,
                "parquet-pig/src/test/java/parquet/pig/PerfTestReadAllCols.java": 51,
                "parquet-pig/src/test/java/parquet/pig/TestParquetLoader.java": 334,
                "parquet-pig/src/test/java/parquet/pig/TestParquetStorer.java": 267,
                "parquet-pig/src/test/java/parquet/pig/TestPigSchemaConverter.java": 231,
                "parquet-pig/src/test/java/parquet/pig/TestTupleRecordConsumer.java": 209,
                "parquet-pig/src/test/java/parquet/pig/TupleConsumerPerfTest.java": 209,
                "parquet-pig/src/test/java/parquet/pig/summary/TestSummary.java": 160,
                "parquet-protobuf/src/main/java/org/apache/parquet/proto/ProtoMessageConverter.java": 348,
                "parquet-protobuf/src/main/java/org/apache/parquet/proto/ProtoParquetInputFormat.java": 38,
                "parquet-protobuf/src/main/java/org/apache/parquet/proto/ProtoParquetOutputFormat.java": 57,
                "parquet-protobuf/src/main/java/org/apache/parquet/proto/ProtoParquetReader.java": 57,
                "parquet-protobuf/src/main/java/org/apache/parquet/proto/ProtoParquetWriter.java": 81,
                "parquet-protobuf/src/main/java/org/apache/parquet/proto/ProtoReadSupport.java": 80,
                "parquet-protobuf/src/main/java/org/apache/parquet/proto/ProtoRecordConverter.java": 84,
                "parquet-protobuf/src/main/java/org/apache/parquet/proto/ProtoRecordMaterializer.java": 44,
                "parquet-protobuf/src/main/java/org/apache/parquet/proto/ProtoSchemaConverter.java": 107,
                "parquet-protobuf/src/main/java/org/apache/parquet/proto/ProtoWriteSupport.java": 339,
                "parquet-protobuf/src/main/java/parquet/proto/ProtoMessageConverter.java": 348,
                "parquet-protobuf/src/main/java/parquet/proto/ProtoParquetInputFormat.java": 38,
                "parquet-protobuf/src/main/java/parquet/proto/ProtoParquetOutputFormat.java": 57,
                "parquet-protobuf/src/main/java/parquet/proto/ProtoParquetReader.java": 57,
                "parquet-protobuf/src/main/java/parquet/proto/ProtoParquetWriter.java": 81,
                "parquet-protobuf/src/main/java/parquet/proto/ProtoReadSupport.java": 80,
                "parquet-protobuf/src/main/java/parquet/proto/ProtoRecordConverter.java": 84,
                "parquet-protobuf/src/main/java/parquet/proto/ProtoRecordMaterializer.java": 44,
                "parquet-protobuf/src/main/java/parquet/proto/ProtoSchemaConverter.java": 107,
                "parquet-protobuf/src/main/java/parquet/proto/ProtoWriteSupport.java": 339,
                "parquet-protobuf/src/test/java/org/apache/parquet/proto/ProtoInputOutputFormatTest.java": 106,
                "parquet-protobuf/src/test/java/org/apache/parquet/proto/ProtoRecordConverterTest.java": 224,
                "parquet-protobuf/src/test/java/org/apache/parquet/proto/ProtoSchemaConverterTest.java": 97,
                "parquet-protobuf/src/test/java/org/apache/parquet/proto/ProtoWriteSupportTest.java": 168,
                "parquet-protobuf/src/test/java/org/apache/parquet/proto/TestUtils.java": 188,
                "parquet-protobuf/src/test/java/org/apache/parquet/proto/utils/ReadUsingMR.java": 87,
                "parquet-protobuf/src/test/java/org/apache/parquet/proto/utils/WriteUsingMR.java": 113,
                "parquet-protobuf/src/test/java/parquet/proto/ProtoInputOutputFormatTest.java": 106,
                "parquet-protobuf/src/test/java/parquet/proto/ProtoRecordConverterTest.java": 224,
                "parquet-protobuf/src/test/java/parquet/proto/ProtoSchemaConverterTest.java": 97,
                "parquet-protobuf/src/test/java/parquet/proto/ProtoWriteSupportTest.java": 168,
                "parquet-protobuf/src/test/java/parquet/proto/TestUtils.java": 188,
                "parquet-protobuf/src/test/java/parquet/proto/utils/ReadUsingMR.java": 87,
                "parquet-protobuf/src/test/java/parquet/proto/utils/WriteUsingMR.java": 113,
                "parquet-scrooge/src/main/java/org/apache/parquet/scrooge/ParquetScroogeInputFormat.java": 31,
                "parquet-scrooge/src/main/java/org/apache/parquet/scrooge/ParquetScroogeOutputFormat.java": 39,
                "parquet-scrooge/src/main/java/org/apache/parquet/scrooge/ParquetScroogeScheme.java": 69,
                "parquet-scrooge/src/main/java/org/apache/parquet/scrooge/ScroogeReadSupport.java": 45,
                "parquet-scrooge/src/main/java/org/apache/parquet/scrooge/ScroogeRecordConverter.java": 57,
                "parquet-scrooge/src/main/java/org/apache/parquet/scrooge/ScroogeSchemaConversionException.java": 36,
                "parquet-scrooge/src/main/java/org/apache/parquet/scrooge/ScroogeStructConverter.java": 332,
                "parquet-scrooge/src/main/java/org/apache/parquet/scrooge/ScroogeWriteSupport.java": 65,
                "parquet-scrooge/src/main/java/parquet/scrooge/ParquetScroogeInputFormat.java": 31,
                "parquet-scrooge/src/main/java/parquet/scrooge/ParquetScroogeOutputFormat.java": 39,
                "parquet-scrooge/src/main/java/parquet/scrooge/ParquetScroogeScheme.java": 69,
                "parquet-scrooge/src/main/java/parquet/scrooge/ScroogeReadSupport.java": 45,
                "parquet-scrooge/src/main/java/parquet/scrooge/ScroogeRecordConverter.java": 57,
                "parquet-scrooge/src/main/java/parquet/scrooge/ScroogeSchemaConversionException.java": 36,
                "parquet-scrooge/src/main/java/parquet/scrooge/ScroogeStructConverter.java": 332,
                "parquet-scrooge/src/main/java/parquet/scrooge/ScroogeWriteSupport.java": 65,
                "parquet-scrooge/src/test/java/org/apache/parquet/scrooge/ParquetScroogeSchemeTest.java": 237,
                "parquet-scrooge/src/test/java/org/apache/parquet/scrooge/ScroogeBinaryTest.java": 100,
                "parquet-scrooge/src/test/java/org/apache/parquet/scrooge/ScroogeStructConverterTest.java": 123,
                "parquet-scrooge/src/test/java/parquet/scrooge/ParquetScroogeSchemeTest.java": 237,
                "parquet-scrooge/src/test/java/parquet/scrooge/ScroogeBinaryTest.java": 100,
                "parquet-scrooge/src/test/java/parquet/scrooge/ScroogeStructConverterTest.java": 123,
                "parquet-thrift/src/main/java/org/apache/parquet/hadoop/thrift/AbstractThriftWriteSupport.java": 125,
                "parquet-thrift/src/main/java/org/apache/parquet/hadoop/thrift/ParquetThriftBytesOutputFormat.java": 73,
                "parquet-thrift/src/main/java/org/apache/parquet/hadoop/thrift/ParquetThriftInputFormat.java": 64,
                "parquet-thrift/src/main/java/org/apache/parquet/hadoop/thrift/ParquetThriftOutputFormat.java": 46,
                "parquet-thrift/src/main/java/org/apache/parquet/hadoop/thrift/TBaseWriteSupport.java": 62,
                "parquet-thrift/src/main/java/org/apache/parquet/hadoop/thrift/ThriftBytesWriteSupport.java": 162,
                "parquet-thrift/src/main/java/org/apache/parquet/hadoop/thrift/ThriftReadSupport.java": 180,
                "parquet-thrift/src/main/java/org/apache/parquet/hadoop/thrift/ThriftToParquetFileWriter.java": 125,
                "parquet-thrift/src/main/java/org/apache/parquet/hadoop/thrift/ThriftWriteSupport.java": 75,
                "parquet-thrift/src/main/java/org/apache/parquet/thrift/BufferedProtocolReadToWrite.java": 680,
                "parquet-thrift/src/main/java/org/apache/parquet/thrift/DecodingSchemaMismatchException.java": 30,
                "parquet-thrift/src/main/java/org/apache/parquet/thrift/FieldIgnoredHandler.java": 46,
                "parquet-thrift/src/main/java/org/apache/parquet/thrift/ParquetProtocol.java": 280,
                "parquet-thrift/src/main/java/org/apache/parquet/thrift/ParquetReadProtocol.java": 161,
                "parquet-thrift/src/main/java/org/apache/parquet/thrift/ParquetWriteProtocol.java": 690,
                "parquet-thrift/src/main/java/org/apache/parquet/thrift/ProtocolPipe.java": 32,
                "parquet-thrift/src/main/java/org/apache/parquet/thrift/ProtocolReadToWrite.java": 145,
                "parquet-thrift/src/main/java/org/apache/parquet/thrift/SkippableException.java": 50,
                "parquet-thrift/src/main/java/org/apache/parquet/thrift/TBaseRecordConverter.java": 48,
                "parquet-thrift/src/main/java/org/apache/parquet/thrift/ThriftMetaData.java": 134,
                "parquet-thrift/src/main/java/org/apache/parquet/thrift/ThriftParquetReader.java": 138,
                "parquet-thrift/src/main/java/org/apache/parquet/thrift/ThriftParquetWriter.java": 54,
                "parquet-thrift/src/main/java/org/apache/parquet/thrift/ThriftReader.java": 28,
                "parquet-thrift/src/main/java/org/apache/parquet/thrift/ThriftRecordConverter.java": 883,
                "parquet-thrift/src/main/java/org/apache/parquet/thrift/ThriftSchemaConvertVisitor.java": 276,
                "parquet-thrift/src/main/java/org/apache/parquet/thrift/ThriftSchemaConverter.java": 165,
                "parquet-thrift/src/main/java/org/apache/parquet/thrift/pig/ParquetThriftStorer.java": 93,
                "parquet-thrift/src/main/java/org/apache/parquet/thrift/pig/TupleToThriftWriteSupport.java": 77,
                "parquet-thrift/src/main/java/org/apache/parquet/thrift/projection/FieldProjectionFilter.java": 93,
                "parquet-thrift/src/main/java/org/apache/parquet/thrift/projection/FieldsPath.java": 84,
                "parquet-thrift/src/main/java/org/apache/parquet/thrift/projection/PathGlobPattern.java": 184,
                "parquet-thrift/src/main/java/org/apache/parquet/thrift/projection/ThriftProjectionException.java": 48,
                "parquet-thrift/src/main/java/org/apache/parquet/thrift/projection/amend/DefaultEventsVisitor.java": 215,
                "parquet-thrift/src/main/java/org/apache/parquet/thrift/projection/amend/DefaultProtocolEventsGenerator.java": 68,
                "parquet-thrift/src/main/java/org/apache/parquet/thrift/projection/amend/ProtocolEventsAmender.java": 173,
                "parquet-thrift/src/main/java/org/apache/parquet/thrift/projection/amend/ReadFieldBeginProtocol.java": 44,
                "parquet-thrift/src/main/java/org/apache/parquet/thrift/struct/CompatibilityChecker.java": 221,
                "parquet-thrift/src/main/java/org/apache/parquet/thrift/struct/CompatibilityRunner.java": 99,
                "parquet-thrift/src/main/java/org/apache/parquet/thrift/struct/JSON.java": 51,
                "parquet-thrift/src/main/java/org/apache/parquet/thrift/struct/ThriftField.java": 121,
                "parquet-thrift/src/main/java/org/apache/parquet/thrift/struct/ThriftType.java": 578,
                "parquet-thrift/src/main/java/org/apache/parquet/thrift/struct/ThriftTypeID.java": 111,
                "parquet-thrift/src/main/java/parquet/hadoop/thrift/AbstractThriftWriteSupport.java": 126,
                "parquet-thrift/src/main/java/parquet/hadoop/thrift/ParquetThriftBytesOutputFormat.java": 73,
                "parquet-thrift/src/main/java/parquet/hadoop/thrift/ParquetThriftInputFormat.java": 64,
                "parquet-thrift/src/main/java/parquet/hadoop/thrift/ParquetThriftOutputFormat.java": 46,
                "parquet-thrift/src/main/java/parquet/hadoop/thrift/TBaseWriteSupport.java": 63,
                "parquet-thrift/src/main/java/parquet/hadoop/thrift/ThriftBytesWriteSupport.java": 162,
                "parquet-thrift/src/main/java/parquet/hadoop/thrift/ThriftReadSupport.java": 180,
                "parquet-thrift/src/main/java/parquet/hadoop/thrift/ThriftToParquetFileWriter.java": 125,
                "parquet-thrift/src/main/java/parquet/hadoop/thrift/ThriftWriteSupport.java": 78,
                "parquet-thrift/src/main/java/parquet/thrift/BufferedProtocolReadToWrite.java": 680,
                "parquet-thrift/src/main/java/parquet/thrift/DecodingSchemaMismatchException.java": 30,
                "parquet-thrift/src/main/java/parquet/thrift/FieldIgnoredHandler.java": 46,
                "parquet-thrift/src/main/java/parquet/thrift/ParquetProtocol.java": 280,
                "parquet-thrift/src/main/java/parquet/thrift/ParquetReadProtocol.java": 161,
                "parquet-thrift/src/main/java/parquet/thrift/ParquetWriteProtocol.java": 692,
                "parquet-thrift/src/main/java/parquet/thrift/ProtocolPipe.java": 32,
                "parquet-thrift/src/main/java/parquet/thrift/ProtocolReadToWrite.java": 145,
                "parquet-thrift/src/main/java/parquet/thrift/SkippableException.java": 50,
                "parquet-thrift/src/main/java/parquet/thrift/TBaseRecordConverter.java": 48,
                "parquet-thrift/src/main/java/parquet/thrift/ThriftMetaData.java": 136,
                "parquet-thrift/src/main/java/parquet/thrift/ThriftParquetReader.java": 138,
                "parquet-thrift/src/main/java/parquet/thrift/ThriftParquetWriter.java": 54,
                "parquet-thrift/src/main/java/parquet/thrift/ThriftReader.java": 28,
                "parquet-thrift/src/main/java/parquet/thrift/ThriftRecordConverter.java": 883,
                "parquet-thrift/src/main/java/parquet/thrift/ThriftSchemaConvertVisitor.java": 276,
                "parquet-thrift/src/main/java/parquet/thrift/ThriftSchemaConverter.java": 165,
                "parquet-thrift/src/main/java/parquet/thrift/pig/ParquetThriftStorer.java": 93,
                "parquet-thrift/src/main/java/parquet/thrift/pig/TupleToThriftWriteSupport.java": 77,
                "parquet-thrift/src/main/java/parquet/thrift/projection/FieldProjectionFilter.java": 93,
                "parquet-thrift/src/main/java/parquet/thrift/projection/FieldsPath.java": 84,
                "parquet-thrift/src/main/java/parquet/thrift/projection/PathGlobPattern.java": 184,
                "parquet-thrift/src/main/java/parquet/thrift/projection/ThriftProjectionException.java": 48,
                "parquet-thrift/src/main/java/parquet/thrift/projection/amend/DefaultEventsVisitor.java": 215,
                "parquet-thrift/src/main/java/parquet/thrift/projection/amend/DefaultProtocolEventsGenerator.java": 68,
                "parquet-thrift/src/main/java/parquet/thrift/projection/amend/ProtocolEventsAmender.java": 173,
                "parquet-thrift/src/main/java/parquet/thrift/projection/amend/ReadFieldBeginProtocol.java": 44,
                "parquet-thrift/src/main/java/parquet/thrift/struct/CompatibilityChecker.java": 221,
                "parquet-thrift/src/main/java/parquet/thrift/struct/CompatibilityRunner.java": 99,
                "parquet-thrift/src/main/java/parquet/thrift/struct/JSON.java": 51,
                "parquet-thrift/src/main/java/parquet/thrift/struct/ThriftField.java": 121,
                "parquet-thrift/src/main/java/parquet/thrift/struct/ThriftType.java": 578,
                "parquet-thrift/src/main/java/parquet/thrift/struct/ThriftTypeID.java": 111,
                "parquet-thrift/src/test/java/org/apache/parquet/hadoop/thrift/TestBinary.java": 66,
                "parquet-thrift/src/test/java/org/apache/parquet/hadoop/thrift/TestInputOutputFormat.java": 257,
                "parquet-thrift/src/test/java/org/apache/parquet/hadoop/thrift/TestParquetToThriftReadWriteAndProjection.java": 244,
                "parquet-thrift/src/test/java/org/apache/parquet/hadoop/thrift/TestThriftToParquetFileWriter.java": 294,
                "parquet-thrift/src/test/java/org/apache/parquet/thrift/TestParquetReadProtocol.java": 167,
                "parquet-thrift/src/test/java/org/apache/parquet/thrift/TestParquetWriteProtocol.java": 550,
                "parquet-thrift/src/test/java/org/apache/parquet/thrift/TestProtocolReadToWrite.java": 286,
                "parquet-thrift/src/test/java/org/apache/parquet/thrift/TestThriftParquetReaderWriter.java": 73,
                "parquet-thrift/src/test/java/org/apache/parquet/thrift/TestThriftSchemaConverter.java": 250,
                "parquet-thrift/src/test/java/org/apache/parquet/thrift/TestThriftToPigCompatibility.java": 171,
                "parquet-thrift/src/test/java/org/apache/parquet/thrift/pig/TestParquetThriftStorer.java": 82,
                "parquet-thrift/src/test/java/org/apache/parquet/thrift/projection/PathGlobPatternTest.java": 59,
                "parquet-thrift/src/test/java/org/apache/parquet/thrift/struct/CompatibilityCheckerTest.java": 120,
                "parquet-thrift/src/test/java/org/apache/parquet/thrift/struct/TestThriftType.java": 67,
                "parquet-thrift/src/test/java/parquet/hadoop/thrift/TestBinary.java": 66,
                "parquet-thrift/src/test/java/parquet/hadoop/thrift/TestInputOutputFormat.java": 257,
                "parquet-thrift/src/test/java/parquet/hadoop/thrift/TestParquetToThriftReadWriteAndProjection.java": 244,
                "parquet-thrift/src/test/java/parquet/hadoop/thrift/TestThriftToParquetFileWriter.java": 294,
                "parquet-thrift/src/test/java/parquet/thrift/TestParquetReadProtocol.java": 167,
                "parquet-thrift/src/test/java/parquet/thrift/TestParquetWriteProtocol.java": 550,
                "parquet-thrift/src/test/java/parquet/thrift/TestProtocolReadToWrite.java": 286,
                "parquet-thrift/src/test/java/parquet/thrift/TestThriftParquetReaderWriter.java": 73,
                "parquet-thrift/src/test/java/parquet/thrift/TestThriftSchemaConverter.java": 250,
                "parquet-thrift/src/test/java/parquet/thrift/TestThriftToPigCompatibility.java": 171,
                "parquet-thrift/src/test/java/parquet/thrift/pig/TestParquetThriftStorer.java": 82,
                "parquet-thrift/src/test/java/parquet/thrift/projection/PathGlobPatternTest.java": 59,
                "parquet-thrift/src/test/java/parquet/thrift/struct/CompatibilityCheckerTest.java": 120,
                "parquet-thrift/src/test/java/parquet/thrift/struct/TestThriftType.java": 67,
                "parquet-tools/src/main/java/org/apache/parquet/tools/Main.java": 231,
                "parquet-tools/src/main/java/org/apache/parquet/tools/command/ArgsOnlyCommand.java": 56,
                "parquet-tools/src/main/java/org/apache/parquet/tools/command/CatCommand.java": 91,
                "parquet-tools/src/main/java/org/apache/parquet/tools/command/Command.java": 30,
                "parquet-tools/src/main/java/org/apache/parquet/tools/command/DumpCommand.java": 338,
                "parquet-tools/src/main/java/org/apache/parquet/tools/command/HeadCommand.java": 95,
                "parquet-tools/src/main/java/org/apache/parquet/tools/command/Registry.java": 60,
                "parquet-tools/src/main/java/org/apache/parquet/tools/command/ShowMetaCommand.java": 76,
                "parquet-tools/src/main/java/org/apache/parquet/tools/command/ShowSchemaCommand.java": 100,
                "parquet-tools/src/main/java/org/apache/parquet/tools/read/SimpleListRecord.java": 30,
                "parquet-tools/src/main/java/org/apache/parquet/tools/read/SimpleListRecordConverter.java": 34,
                "parquet-tools/src/main/java/org/apache/parquet/tools/read/SimpleMapRecord.java": 43,
                "parquet-tools/src/main/java/org/apache/parquet/tools/read/SimpleMapRecordConverter.java": 34,
                "parquet-tools/src/main/java/org/apache/parquet/tools/read/SimpleReadSupport.java": 41,
                "parquet-tools/src/main/java/org/apache/parquet/tools/read/SimpleRecord.java": 149,
                "parquet-tools/src/main/java/org/apache/parquet/tools/read/SimpleRecordConverter.java": 159,
                "parquet-tools/src/main/java/org/apache/parquet/tools/read/SimpleRecordMaterializer.java": 42,
                "parquet-tools/src/main/java/org/apache/parquet/tools/util/MetadataUtils.java": 229,
                "parquet-tools/src/main/java/org/apache/parquet/tools/util/PrettyPrintWriter.java": 1035,
                "parquet-tools/src/main/java/parquet/tools/Main.java": 231,
                "parquet-tools/src/main/java/parquet/tools/command/ArgsOnlyCommand.java": 56,
                "parquet-tools/src/main/java/parquet/tools/command/CatCommand.java": 91,
                "parquet-tools/src/main/java/parquet/tools/command/Command.java": 30,
                "parquet-tools/src/main/java/parquet/tools/command/DumpCommand.java": 338,
                "parquet-tools/src/main/java/parquet/tools/command/HeadCommand.java": 95,
                "parquet-tools/src/main/java/parquet/tools/command/Registry.java": 60,
                "parquet-tools/src/main/java/parquet/tools/command/ShowMetaCommand.java": 76,
                "parquet-tools/src/main/java/parquet/tools/command/ShowSchemaCommand.java": 100,
                "parquet-tools/src/main/java/parquet/tools/read/SimpleListRecord.java": 30,
                "parquet-tools/src/main/java/parquet/tools/read/SimpleListRecordConverter.java": 34,
                "parquet-tools/src/main/java/parquet/tools/read/SimpleMapRecord.java": 43,
                "parquet-tools/src/main/java/parquet/tools/read/SimpleMapRecordConverter.java": 34,
                "parquet-tools/src/main/java/parquet/tools/read/SimpleReadSupport.java": 41,
                "parquet-tools/src/main/java/parquet/tools/read/SimpleRecord.java": 149,
                "parquet-tools/src/main/java/parquet/tools/read/SimpleRecordConverter.java": 159,
                "parquet-tools/src/main/java/parquet/tools/read/SimpleRecordMaterializer.java": 42,
                "parquet-tools/src/main/java/parquet/tools/util/MetadataUtils.java": 229,
                "parquet-tools/src/main/java/parquet/tools/util/PrettyPrintWriter.java": 1035
            },
            "is_test": true,
            "is_fix": false
        },
        "7c42398332bf1522b7fcc952110471c86cd7ec28": {
            "datetime": "2015-04-27T17:59:44-07:00",
            "summary": "PARQUET-211: Update version for 1.8.0 development.",
            "message": "PARQUET-211: Update version for 1.8.0 development.\n\nAuthor: Ryan Blue <blue@apache.org>\n\nCloses #182 from rdblue/PARQUET-211-update-to-1.8.0 and squashes the following commits:\n\n139e682 [Ryan Blue] PARQUET-211: Update version for 1.8.0 development.\n",
            "diff": {
                "dev/merge_parquet_pr.py": 2
            },
            "is_test": false,
            "is_fix": false
        },
        "9d744f7136f23da9a5f9324432b300b5a68e3b39": {
            "datetime": "2015-04-29T17:47:03-07:00",
            "summary": "PARQUET-268: Downgrade scrooge-maven-plugin.",
            "message": "PARQUET-268: Downgrade scrooge-maven-plugin.\n\nThe 3.17.0 version no longer works because a transitive dependency has\nbeen purged. 3.18.0 is the natural upgrade, but fails with a\nconfiguration problem. The latest documentation on updates is for moving\nto 3.17.0, so the easiest solution that works is to downgrade to 3.16.0.\nThe build is working.\n\nAuthor: Ryan Blue <blue@apache.org>\n\nCloses #187 from rdblue/PARQUET-268-fix-scrooge-plugin-version and squashes the following commits:\n\n2b90634 [Ryan Blue] PARQUET-268: Downgrade scrooge-maven-plugin.\n",
            "diff": {
                "parquet-scrooge/src/test/java/org/apache/parquet/scrooge/ScroogeStructConverterTest.java": 3
            },
            "is_test": true,
            "is_fix": true
        },
        "9993450ad1f023e0e2b59291361d0b3b9f0e1c8d": {
            "datetime": "2015-04-29T23:18:47-07:00",
            "summary": "PARQUET-227 Enforce that unions have only 1 set value, tolerate bad records in read path",
            "message": "PARQUET-227 Enforce that unions have only 1 set value, tolerate bad records in read path\n\nSee https://issues.apache.org/jira/browse/PARQUET-227\n\nAuthor: Alex Levenson <alexlevenson@twitter.com>\n\nCloses #153 from isnotinvain/alexlevenson/double-union and squashes the following commits:\n\nef4d36f [Alex Levenson] fix package names\ne201deb [Alex Levenson] Merge branch 'master' into alexlevenson/double-union\n01694fa [Alex Levenson] Forgot a break in a switch statement\n2f31321 [Alex Levenson] Merge branch 'master' into alexlevenson/double-union\n9292274 [Alex Levenson] Add in ShouldNeverHappenException which I forgot to check in\n8d61515 [Alex Levenson] Address first round of comments\n4d71bcb [Alex Levenson] Merge branch 'master' into alexlevenson/double-union\n8f9334c [Alex Levenson] Some cleanup and fixes\n8153bc9 [Alex Levenson] Enforce that unions have only 1 set value, tolerate bad records in read path\n",
            "diff": {
                "parquet-column/src/main/java/org/apache/parquet/io/api/RecordMaterializer.java": 27,
                "parquet-common/src/main/java/org/apache/parquet/ShouldNeverHappenException.java": 40,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/InternalParquetRecordReader.java": 16,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/UnmaterializableRecordCounter.java": 87,
                "parquet-scrooge/src/test/java/org/apache/parquet/scrooge/TestCorruptScroogeRecords.java": 69,
                "parquet-thrift/src/main/java/org/apache/parquet/hadoop/thrift/ThriftReadSupport.java": 15,
                "parquet-thrift/src/main/java/org/apache/parquet/thrift/BufferedProtocolReadToWrite.java": 113,
                "parquet-thrift/src/main/java/org/apache/parquet/thrift/ParquetProtocol.java": 4,
                "parquet-thrift/src/main/java/org/apache/parquet/thrift/ParquetReadProtocol.java": 4,
                "parquet-thrift/src/main/java/org/apache/parquet/thrift/ThriftRecordConverter.java": 5,
                "parquet-thrift/src/test/java/org/apache/parquet/hadoop/thrift/TestCorruptThriftRecords.java": 213,
                "parquet-thrift/src/test/java/org/apache/parquet/hadoop/thrift/TestInputOutputFormat.java": 2,
                "parquet-thrift/src/test/java/org/apache/parquet/thrift/TestProtocolReadToWrite.java": 60
            },
            "is_test": true,
            "is_fix": true
        },
        "98f54c158acb12a26fa6f335b1665accd2aed347": {
            "datetime": "2015-04-30T12:33:56+02:00",
            "summary": "PARQUET-175 reading custom protobuf class",
            "message": "PARQUET-175 reading custom protobuf class\n\n Changes to be committed:\n\tmodified:   parquet-protobuf/src/main/java/org/apache/parquet/proto/ProtoReadSupport.java\n\tmodified:   parquet-protobuf/src/test/java/org/apache/parquet/proto/ProtoInputOutputFormatTest.java\n\tmodified:   parquet-protobuf/src/test/resources/TestProtobuf.proto\n\nAuthor: Nalezenec, Lukas <lukas.nalezenec@gmail.com>\n\nCloses #183 from lukasnalezenec/master and squashes the following commits:\n\n796cd39 [Nalezenec, Lukas] PARQUET-175 Allow setting of a custom protobuf class when reading parquet file using parquet-protobuf.\n",
            "diff": {
                "parquet-protobuf/src/main/java/org/apache/parquet/proto/ProtoReadSupport.java": 24,
                "parquet-protobuf/src/test/java/org/apache/parquet/proto/ProtoInputOutputFormatTest.java": 41
            },
            "is_test": true,
            "is_fix": false
        },
        "22c6d087012fd55bc65e578a27f2edb66f4d3808": {
            "datetime": "2015-04-30T16:59:20-07:00",
            "summary": "PARQUET-269: Restore scrooge-maven-plugin to version 3.17.0",
            "message": "PARQUET-269: Restore scrooge-maven-plugin to version 3.17.0\n\nScrooge has re-published scrooge-maven-plugin 3.17.0, so we should be able to use it again.\nLets see if travis is able to pick up the changes.\n\nAuthor: Alex Levenson <alexlevenson@twitter.com>\n\nCloses #188 from isnotinvain/alexlevenson/restore-scrooge-plugin and squashes the following commits:\n\nfbec238 [Alex Levenson] Revert \"make a whitespace change to trigger tests\"\n5ea3d26 [Alex Levenson] make a whitespace change to trigger tests\nbfe181f [Alex Levenson] Restore scrooge-maven-plugin to version 3.17.0\n",
            "diff": {
                "parquet-scrooge/src/test/java/org/apache/parquet/scrooge/ScroogeStructConverterTest.java": 3
            },
            "is_test": true,
            "is_fix": true
        },
        "7fc7998398373a14b4cdc0ce18abdeb221b1ccf9": {
            "datetime": "2015-04-30T17:45:11-07:00",
            "summary": "PARQUET-229 Add a strict thrift projection API with backwards compat support",
            "message": "PARQUET-229 Add a strict thrift projection API with backwards compat support\n\nCurrently, the thrift projection API accepts strings in a very general glob format that supports not only wildcards like `*` and `?` and expansions (`{x,y,z}`) but also character classes `[abc]`, and negation.\nBecause of this flexibility, it's hard to give users good error reporting, for example letting them know that when they requested columns `foo.bar.{a,b,c}` there is actually no such column `foo.bar.c`.\n\nThis PR introduces a new syntax that supports a more restrictive form of glob syntax and enforces that all **expansions** of a glob match a column, not just that all globs match a column. The new syntax is very simple and only has four special characters: `{`,`}`,`,`, and `*`\n\nIt supports glob expansion, for example:\n`home.{phone,address}` or `org.apache{-incubator,}.foo`\n\nAnd the wildcard `*` which is treated the same way as java regex treats `(.*)`, for example:\n`home.*` or `org.apache*.foo`\n\nIn the new syntax glob paths mean \"keep all the child fields of the field matched by this glob\", just like variable access would work in a programming language. For example: `x.y.z` means keep field `z` and all of its children (if any). So it's not necessary to do `x.y.z.*`. However, `x.y.z` would not keep field `x.y.zoo`. If that was desired, then `x.y.z*` could be used instead.\n\nSetting `\"parquet.thrift.column.filter\"` will result in the same behavior that it does currently in master, though a deprecation warning will be logged. The classes that implement the current behavior have been marked as deprecated, and using this will log a warning.\n\nSetting `\"parquet.thrift.column.projection.globs\"` will instead use this new syntax, and entry points in the various Builder's in the codebase is added as well.\n\nThis PR does a little bit of cleanup as well, moving some shared methods to a `Strings` class and simplifying some of the class hierarchy in `ThriftSchemaConverterVisitor`. There are a few `// TODO Why?` added as well that I wanted to ask about.\n\nAuthor: Alex Levenson <alexlevenson@twitter.com>\n\nCloses #150 from isnotinvain/alexlevenson/strict-projection and squashes the following commits:\n\n6c58e1c [Alex Levenson] clean up docs\n1aab666 [Alex Levenson] Merge branch 'master' into alexlevenson/strict-projection\n92b6ba6 [Alex Levenson] Merge branch 'master' into alexlevenson/strict-projection\nceaf6cd [Alex Levenson] update packages\na28dc19 [Alex Levenson] Merge branch 'master' into alexlevenson/strict-projection\nebc4761 [Alex Levenson] Remove unneeded TODO\nc2e12c5 [Alex Levenson] Update docs\neecf5f3 [Alex Levenson] Merge branch 'master' into alexlevenson/strict-projection\n671f0b5 [Alex Levenson] Merge branch 'master' into alexlevenson/strict-projection\n298cad8 [Alex Levenson] Add warning\n8b7e4bb [Alex Levenson] Add more comments to StrictFieldProjectionFilter\n8f65ed2 [Alex Levenson] Add tests for strict projection filter\nc81d9e1 [Alex Levenson] Docs and cleanup for FieldProjectionFilter\n71139a7 [Alex Levenson] Add tests for FieldsPath\n7d17068 [Alex Levenson] Tests for WildcardPath\n8a3d2af [Alex Levenson] Add some tests\nf3fd931 [Alex Levenson] More docs\n0b190c3 [Alex Levenson] Add more comments\n6e67df5 [Alex Levenson] Add a strict thrift projection API with backwards support for the current API\n",
            "diff": {
                "parquet-cascading/src/main/java/org/apache/parquet/cascading/ParquetValueScheme.java": 42,
                "parquet-common/src/main/java/org/apache/parquet/Strings.java": 110,
                "parquet-common/src/main/java/org/apache/parquet/glob/GlobExpander.java": 114,
                "parquet-common/src/main/java/org/apache/parquet/glob/GlobNode.java": 157,
                "parquet-common/src/main/java/org/apache/parquet/glob/GlobParser.java": 224,
                "parquet-common/src/main/java/org/apache/parquet/glob/WildcardPath.java": 122,
                "parquet-common/src/main/java/org/apache/parquet/hadoop/metadata/ColumnPath.java": 12,
                "parquet-common/src/test/java/org/apache/parquet/glob/TestGlob.java": 144,
                "parquet-common/src/test/java/org/apache/parquet/glob/TestWildcardPath.java": 125,
                "parquet-thrift/src/main/java/org/apache/parquet/hadoop/thrift/ThriftReadSupport.java": 78,
                "parquet-thrift/src/main/java/org/apache/parquet/thrift/ThriftSchemaConvertVisitor.java": 38,
                "parquet-thrift/src/main/java/org/apache/parquet/thrift/ThriftSchemaConverter.java": 69,
                "parquet-thrift/src/main/java/org/apache/parquet/thrift/projection/FieldProjectionFilter.java": 94,
                "parquet-thrift/src/main/java/org/apache/parquet/thrift/projection/FieldsPath.java": 63,
                "parquet-thrift/src/main/java/org/apache/parquet/thrift/projection/PathGlobPattern.java": 7,
                "parquet-thrift/src/main/java/org/apache/parquet/thrift/projection/StrictFieldProjectionFilter.java": 182,
                "parquet-thrift/src/main/java/org/apache/parquet/thrift/projection/deprecated/DeprecatedFieldProjectionFilter.java": 107,
                "parquet-thrift/src/test/java/org/apache/parquet/hadoop/thrift/TestParquetToThriftReadWriteAndProjection.java": 2,
                "parquet-thrift/src/test/java/org/apache/parquet/thrift/TestThriftSchemaConverter.java": 101,
                "parquet-thrift/src/test/java/org/apache/parquet/thrift/projection/PathGlobPatternTest.java": 2,
                "parquet-thrift/src/test/java/org/apache/parquet/thrift/projection/TestFieldsPath.java": 166,
                "parquet-thrift/src/test/java/org/apache/parquet/thrift/projection/TestStrictFieldProjectionFilter.java": 119
            },
            "is_test": true,
            "is_fix": false
        },
        "890b387d713d04c22406db6d5a5fc9b51bec2df5": {
            "datetime": "2015-05-04T12:08:41-07:00",
            "summary": "PARQUET-252 : support nested container type for parquet-scrooge",
            "message": "PARQUET-252 : support nested container type for parquet-scrooge\n\nresubmit\n\nAuthor: Tianshuo Deng <tdeng@twitter.com>\n\nCloses #185 from tsdeng/scrooge_nested_container and squashes the following commits:\n\nb29465f [Tianshuo Deng] retrigger jenkins\n4542c1a [Tianshuo Deng] support nested container type for parquet-scrooge\n",
            "diff": {
                "parquet-scrooge/src/main/java/org/apache/parquet/scrooge/ScroogeStructConverter.java": 318,
                "parquet-scrooge/src/test/java/org/apache/parquet/scrooge/ScroogeStructConverterTest.java": 158
            },
            "is_test": true,
            "is_fix": true
        },
        "c7d56cffbb4668d0955ef00196e08f42f2efe363": {
            "datetime": "2015-05-12T11:15:40-07:00",
            "summary": "PARQUET-273 : remove usage of ReflectiveOperationException to support JAVA6",
            "message": "PARQUET-273 : remove usage of ReflectiveOperationException to support JAVA6\n\nas commented here: https://github.com/apache/parquet-mr/commit/52f3240d90f2397cd1850ab11674ba08a0ecb2a0#commitcomment-11065301\n\nAuthor: Tianshuo Deng <tdeng@twitter.com>\n\nCloses #191 from tsdeng/remove_usage_of_reflective_operation_exception and squashes the following commits:\n\nadbe37a [Tianshuo Deng] remove usage of ReflectiveOperationException to support JAVA6\n",
            "diff": {
                "parquet-scrooge/src/main/java/org/apache/parquet/scrooge/ScroogeStructConverter.java": 26
            },
            "is_test": false,
            "is_fix": false
        },
        "7680fae14c9f544d0585a7b150004a1e48fff53a": {
            "datetime": "2015-05-15T12:40:27-07:00",
            "summary": "PARQUET-254: Fixes exception message",
            "message": "PARQUET-254: Fixes exception message\n\n<!-- Reviewable:start -->\n[<img src=\"https://reviewable.io/review_button.png\" height=40 alt=\"Review on Reviewable\"/>](https://reviewable.io/reviews/apache/incubator-parquet-mr/174)\n<!-- Reviewable:end -->\n\nAuthor: Cheng Lian <lian@databricks.com>\n\nCloses #174 from liancheng/fix-exception-message and squashes the following commits:\n\ndb816c2 [Cheng Lian] Fixes exception message\n",
            "diff": {
                "parquet-avro/src/main/java/org/apache/parquet/avro/AvroSchemaConverter.java": 2
            },
            "is_test": false,
            "is_fix": false
        },
        "136c5ffe80e558a87cde01baebf823b06e3cbe75": {
            "datetime": "2015-05-15T12:41:15-07:00",
            "summary": "PARQUET-253: Fixes Javadoc of AvroSchemaConverter",
            "message": "PARQUET-253: Fixes Javadoc of AvroSchemaConverter\n\nGot confused by the original Javadoc at first and didn't realize `AvroSchemaConverter` is also capable to convert a Parquet schema to an Avro schema.\n\n<!-- Reviewable:start -->\n[<img src=\"https://reviewable.io/review_button.png\" height=40 alt=\"Review on Reviewable\"/>](https://reviewable.io/reviews/apache/incubator-parquet-mr/173)\n<!-- Reviewable:end -->\n\nAuthor: Cheng Lian <lian@databricks.com>\n\nCloses #173 from liancheng/avro-schema-converter-comment-fix and squashes the following commits:\n\n47b11ce [Cheng Lian] Fixes Javadoc of AvroSchemaConverter\n",
            "diff": {
                "parquet-avro/src/main/java/org/apache/parquet/avro/AvroSchemaConverter.java": 18
            },
            "is_test": false,
            "is_fix": false
        },
        "60edcf9df1bbe271b1414b04e914641937395d8a": {
            "datetime": "2015-05-15T13:07:14-07:00",
            "summary": "PARQUET-278 : enforce non empty group on MessageType level",
            "message": "PARQUET-278 : enforce non empty group on MessageType level\n\nAs columnar format, parquet currently does not support empty struct/group without leaves. We should throw when constructing an empty GroupType to give a clear message.\n\nAuthor: Tianshuo Deng <tdeng@twitter.com>\n\nCloses #195 from tsdeng/message_type_enforce_non_empty_group and squashes the following commits:\n\na286c58 [Tianshuo Deng] revert change to merge_parquet_pr\na09f6ba [Tianshuo Deng] fix test\nac63567 [Tianshuo Deng] fix tests\naa2633c [Tianshuo Deng] enforce non empty group on MessageType level\n",
            "diff": {
                "parquet-column/src/main/java/org/apache/parquet/schema/GroupType.java": 3,
                "parquet-column/src/main/java/org/apache/parquet/schema/IncompatibleSchemaModificationException.java": 6,
                "parquet-column/src/main/java/org/apache/parquet/schema/InvalidSchemaException.java": 31,
                "parquet-column/src/test/java/org/apache/parquet/schema/TestMessageType.java": 14,
                "parquet-pig/src/test/java/org/apache/parquet/pig/TestPigSchemaConverter.java": 7,
                "parquet-thrift/src/main/java/org/apache/parquet/thrift/ThriftSchemaConverter.java": 2
            },
            "is_test": true,
            "is_fix": false
        },
        "a458e1a2f3cd1ccd692f1530b64d3143c9beda51": {
            "datetime": "2015-05-18T10:08:32-07:00",
            "summary": "PARQUET-243: Add Avro reflect support",
            "message": "PARQUET-243: Add Avro reflect support\n\nAuthor: Ryan Blue <blue@apache.org>\n\nCloses #165 from rdblue/PARQUET-243-add-avro-reflect and squashes the following commits:\n\na1a17b4 [Ryan Blue] PARQUET-243: Update for Tom's review comments.\n16584d1 [Ryan Blue] PARQUET-243: Fix AvroWriteSupport bug.\nfa4a9ec [Ryan Blue] PARQUET-243: Add reflect tests.\n4c50cd1 [Ryan Blue] PARQUET-243: Update write support for reflected objects.\nb50c482 [Ryan Blue] PARQUET-243: Update tests to run with new converters.\n0b7a333 [Ryan Blue] PARQUET-243: Use common AvroConverters where possible.\n2f6825d [Ryan Blue] PARQUET-243: Add reflect converters that behave more like Avro.\n98f10df [Ryan Blue] PARQUET-243: Add Avro compatible record materializer.\n",
            "diff": {
                "parquet-avro/src/main/java/org/apache/parquet/avro/AvroCompatRecordMaterializer.java": 46,
                "parquet-avro/src/main/java/org/apache/parquet/avro/AvroConverters.java": 253,
                "parquet-avro/src/main/java/org/apache/parquet/avro/AvroIndexedRecordConverter.java": 229,
                "parquet-avro/src/main/java/org/apache/parquet/avro/AvroParquetOutputFormat.java": 17,
                "parquet-avro/src/main/java/org/apache/parquet/avro/AvroParquetReader.java": 5,
                "parquet-avro/src/main/java/org/apache/parquet/avro/AvroParquetWriter.java": 141,
                "parquet-avro/src/main/java/org/apache/parquet/avro/AvroReadSupport.java": 54,
                "parquet-avro/src/main/java/org/apache/parquet/avro/AvroRecordConverter.java": 827,
                "parquet-avro/src/main/java/org/apache/parquet/avro/AvroRecordMaterializer.java": 7,
                "parquet-avro/src/main/java/org/apache/parquet/avro/AvroWriteSupport.java": 236,
                "parquet-avro/src/main/java/org/apache/parquet/avro/GenericDataSupplier.java": 28,
                "parquet-avro/src/main/java/org/apache/parquet/avro/ParentValueContainer.java": 63,
                "parquet-avro/src/main/java/org/apache/parquet/avro/ReflectDataSupplier.java": 29,
                "parquet-avro/src/test/java/org/apache/parquet/avro/TestBackwardCompatibility.java": 18,
                "parquet-avro/src/test/java/org/apache/parquet/avro/TestReadWrite.java": 41,
                "parquet-avro/src/test/java/org/apache/parquet/avro/TestReflectInputOutputFormat.java": 495,
                "parquet-avro/src/test/java/org/apache/parquet/avro/TestReflectReadWrite.java": 215,
                "parquet-avro/src/test/java/org/apache/parquet/avro/TestSpecificReadWrite.java": 45
            },
            "is_test": true,
            "is_fix": false
        },
        "181affd5c937755f54ff31ef056a6ec091e95f51": {
            "datetime": "2015-05-19T11:26:07-07:00",
            "summary": "PARQUET-164: Add a counter and increment when parquet memory manager kicks in",
            "message": "PARQUET-164: Add a counter and increment when parquet memory manager kicks in\n\nAdd a counter for writers, and increment it when memory manager scaling down row group size.\n\nHive could use this counter to warn users.\n\nAuthor: dongche1 <dong1.chen@intel.com>\nAuthor: dongche <dong1.chen@intel.com>\nAuthor: root <root@bdpe15.sh.intel.com>\n\nCloses #120 from dongche/PARQUET-164 and squashes the following commits:\n\n9bcb1ba [dongche] Remove stats, and change returned callbacks map unmodifiable\n3cbbeb9 [dongche] Merge remote branch 'upstream1/master' into PARQUET-164\nbdef233 [dongche] Merge remote branch 'upstream1/master' into PARQUET-164\n780be6d [root] revert change about callable and address comments\n11f9163 [dongche1] Merge remote branch 'upstream/master' into PARQUET-164\n55549a5 [dongche1] Use callable and strict registerScallCallBack method.\n74054aa [dongche1] Use Runnable as a generic callback\n8782a02 [dongche1] Add a callback mechanism instead of shims. And rebase trunk\nb138b7f [dongche1] Merge remote branch 'upstream/master' into PARQUET-164\n93a4678 [dongche1] PARQUET-164: Add a counter and increment when parquet memory manager kicks in\n",
            "diff": {
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/MemoryManager.java": 42,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ParquetOutputFormat.java": 2,
                "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/TestMemoryManager.java": 28
            },
            "is_test": true,
            "is_fix": true
        },
        "ded56ffd598e41e32817f6c1b091595fe7122e8b": {
            "datetime": "2015-05-19T19:36:04-07:00",
            "summary": "PARQUET-287: Keep a least 1 column from union members when projecting thrift unions",
            "message": "PARQUET-287: Keep a least 1 column from union members when projecting thrift unions\n\nCurrently, the projection API allows you to select only some \"kinds\" of a union, or to drop a required union entirely. This becomes an issue when assembling these records, as they will be appear to be unions of an unknown type (how do you coerce an empty struct into a union?). The way this case is handled for primitives is by supplying a default value (like 0, or null). However, with a union, you have to choose what \"kind\" of the union it will act as, and in the interest of not being misleading, this PR reads one column to figure out what the correct \"kind\" is.\n\nIn the future, the better solution is to filter these records out -- a projection is really a request for a filter in this case. But for now, this should get us correctness without involving the filter API.\n\nI think this PR needs some more tests before merging, but I wanted to get it out and get some feedback now.\n\nI also refactored how ThriftSchemaVisitor works to not be stateful, by explicitly passing state through the recursion -- this makes it much easier to reason about.\n\n*edit* This PR also includes a fix for PARQUET-275 because I encountered it during testing.\n\n*edit 2* This PR also includes a fix for PARQUET-283\n\nAuthor: Alex Levenson <alexlevenson@twitter.com>\n\nCloses #189 from isnotinvain/alexlevenson/project-union and squashes the following commits:\n\nc710702 [Alex Levenson] Avoid instantiating (unused) empty group type\nc43a44c [Alex Levenson] Merge branch 'master' into alexlevenson/project-union\nd62ee8c [Alex Levenson] Merge branch 'master' into alexlevenson/project-union\ndf51f41 [Alex Levenson] Fix tests\n4d3f825 [Alex Levenson] Address review comments\n6dd95f5 [Alex Levenson] Update tests to reflect changes\nd7cee7e [Alex Levenson] Add tests for nested maps\n9c34b20 [Alex Levenson] Keep a sentinel column in map values\n53e5580 [Alex Levenson] Remove debug println\nc525a65 [Alex Levenson] update docs to reflect set projection rules\naefb637 [Alex Levenson] Do not allow partial projection of keys or set elements\n8b4e791 [Alex Levenson] Add tests for maps of unions\n35de282 [Alex Levenson] Add test for list<union>\n098630f [Alex Levenson] Merge branch 'master' into alexlevenson/project-union\n77cc9e9 [Alex Levenson] Add license header\n63b80fd [Alex Levenson] more clean up\n6341747 [Alex Levenson] Clean up ConvertedField\ndcd3ea9 [Alex Levenson] Merge branch 'master' into alexlevenson/project-union\n9ce4781 [Alex Levenson] Some cleanup and comments\n6964837 [Alex Levenson] Keep one sentinel column in projected unions that cannot be dropped entirely\n37a9bef [Alex Levenson] Clean up visitor pattern for thrift types\n",
            "diff": {
                "parquet-thrift/src/main/java/org/apache/parquet/thrift/ConvertedField.java": 167,
                "parquet-thrift/src/main/java/org/apache/parquet/thrift/KeepOnlyFirstPrimitiveFilter.java": 44,
                "parquet-thrift/src/main/java/org/apache/parquet/thrift/ThriftSchemaConvertVisitor.java": 477,
                "parquet-thrift/src/main/java/org/apache/parquet/thrift/ThriftSchemaConverter.java": 11,
                "parquet-thrift/src/main/java/org/apache/parquet/thrift/projection/FieldProjectionFilter.java": 3,
                "parquet-thrift/src/main/java/org/apache/parquet/thrift/projection/FieldsPath.java": 18,
                "parquet-thrift/src/main/java/org/apache/parquet/thrift/projection/amend/DefaultEventsVisitor.java": 45,
                "parquet-thrift/src/main/java/org/apache/parquet/thrift/projection/amend/DefaultProtocolEventsGenerator.java": 2,
                "parquet-thrift/src/main/java/org/apache/parquet/thrift/struct/CompatibilityChecker.java": 71,
                "parquet-thrift/src/main/java/org/apache/parquet/thrift/struct/ThriftType.java": 121,
                "parquet-thrift/src/test/java/org/apache/parquet/hadoop/thrift/TestParquetToThriftReadWriteAndProjection.java": 140,
                "parquet-thrift/src/test/java/org/apache/parquet/thrift/TestThriftSchemaConverter.java": 95,
                "parquet-thrift/src/test/java/org/apache/parquet/thrift/TestThriftSchemaConverterProjectUnion.java": 480,
                "parquet-thrift/src/test/java/org/apache/parquet/thrift/projection/TestFieldsPath.java": 80
            },
            "is_test": true,
            "is_fix": true
        },
        "8769d0f2cc4b7555dc025b7c0e49a81346a1e2dd": {
            "datetime": "2015-05-21T16:18:03-07:00",
            "summary": "PARQUET-262: Restore semver checks.",
            "message": "PARQUET-262: Restore semver checks.\n\nBecause 1.6.0 to 1.7.0 was a breaking rename, semver was turned off\nuntil the 1.7.0 artifacts were released. Now that they are available,\nthe check needs to be restored.\n\nThere were already 2 breaking changes that are fixed by this commit:\n* A field in AvroReadSupport was made final\n* An accessor method in ThriftSchemaConvertVisitor was removed\n\nAuthor: Ryan Blue <blue@apache.org>\n\nCloses #200 from rdblue/PARQUET-262-restore-semver and squashes the following commits:\n\n09aeaf4 [Ryan Blue] PARQUET-262: Restore semver checks.\n",
            "diff": {
                "parquet-avro/src/main/java/org/apache/parquet/avro/AvroReadSupport.java": 3,
                "parquet-thrift/src/main/java/org/apache/parquet/thrift/ThriftSchemaConvertVisitor.java": 8
            },
            "is_test": false,
            "is_fix": false
        },
        "dd92a9db6b288def8159f30336f6793239882c9d": {
            "datetime": "2015-05-26T14:31:51-07:00",
            "summary": "PARQUET-223: Add builders for MAP and LIST types",
            "message": "PARQUET-223: Add builders for MAP and LIST types\n\nAs of now, Parquet does not provide builders for Maps and Lists. This leaves margin for user errors. Having Map and List builders will make it easier for users to build these types.\n\nAuthor: asingh <asingh@cloudera.com>\n\nCloses #148 from SinghAsDev/map and squashes the following commits:\n\ncc7da06 [asingh] Pull changes made by Ryan\n825b5b8 [asingh] Remove non-functional changes\nbec675b [asingh] Remove required and optional version of methods that take pre-built Type\n6dcaa78 [asingh] Address review comments and some clean up\n544d1e4 [asingh] Add key(Type) and value(Type) variants to MapBuilder\nf2a1697 [asingh] Add listKey support\n68c06f5 [asingh] Add support for null value in MapBuilder\nf31f2b0 [asingh] Add more tests to cover list and map value types in map builder\nf035439 [asingh] Add Map and List value types to map\n1afa2c7 [asingh] Address review comments\n484495b [asingh] PARQUET-223: Add builders for MAP and LIST types\n",
            "diff": {
                "parquet-column/src/main/java/org/apache/parquet/schema/Types.java": 878,
                "parquet-column/src/test/java/org/apache/parquet/schema/TestTypeBuilders.java": 769
            },
            "is_test": true,
            "is_fix": false
        },
        "4b5cda5a2c6ca613db5129d50ffffce2604ad9eb": {
            "datetime": "2015-06-01T14:21:53-07:00",
            "summary": "PARQUET-151: Skip writing _metadata file in case of no footers since schema cannot be determined.",
            "message": "PARQUET-151: Skip writing _metadata file in case of no footers since schema cannot be determined.\n\nThis fixes npe seen during mergeFooters in such a case.\n For this scenario onus of writing any summary files lies with the caller (It might have some global schema available) So for example spark does it when persisting empty RDD.\n\nAuthor: Yash Datta <Yash.Datta@guavus.com>\n\nCloses #205 from saucam/footer_bug and squashes the following commits:\n\nb2b3ddf [Yash Datta] PARQUET-151: Skip writing _metadata file in case of no footers since schema cannot be determined. This fixes npe seen during mergeFooters in such a case.              For this scenario onus of writing any summary files lies with the caller (It might have some global schema available)\n",
            "diff": {
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ParquetOutputCommitter.java": 5
            },
            "is_test": false,
            "is_fix": false
        },
        "d6f082b9be5d507ff60c6bc83a179cc44015ab97": {
            "datetime": "2015-06-01T17:46:29-07:00",
            "summary": "PARQUET-285: Implement 3-level lists in Avro",
            "message": "PARQUET-285: Implement 3-level lists in Avro\n\nThis includes the write-side the changes from #83 that implement the 3-level list structure for parquet-avro. The old commit was https://github.com/rdblue/parquet-mr/commit/3589a7367c829b9eabc36b2e2e1cab31685415eb.\n\nAuthor: Ryan Blue <blue@apache.org>\n\nCloses #198 from rdblue/PARQUET-285-avro-nested-lists and squashes the following commits:\n\n3498571 [Ryan Blue] PARQUET-285: Fix review issues.\n67ed2f4 [Ryan Blue] PARQUET-285: Add tests for new list write behavior.\n6ec9120 [Ryan Blue] PARQUET-285: Implement nested type rules for Avro.\n109111f [Ryan Blue] PARQUET-285: Add a better conversion pattern for lists.\n",
            "diff": {
                "parquet-avro/src/main/java/org/apache/parquet/avro/AvroIndexedRecordConverter.java": 3,
                "parquet-avro/src/main/java/org/apache/parquet/avro/AvroParquetWriter.java": 12,
                "parquet-avro/src/main/java/org/apache/parquet/avro/AvroRecordConverter.java": 2,
                "parquet-avro/src/main/java/org/apache/parquet/avro/AvroSchemaConverter.java": 17,
                "parquet-avro/src/main/java/org/apache/parquet/avro/AvroWriteSupport.java": 453,
                "parquet-avro/src/test/java/org/apache/parquet/avro/TestAvroSchemaConverter.java": 194,
                "parquet-avro/src/test/java/org/apache/parquet/avro/TestReadWrite.java": 85,
                "parquet-avro/src/test/java/org/apache/parquet/avro/TestReadWriteOldBehavior.java": 588,
                "parquet-column/src/main/java/org/apache/parquet/schema/ConversionPatterns.java": 28
            },
            "is_test": true,
            "is_fix": true
        },
        "918609f2cc4e4de95445ce4fdd7dc952b9625017": {
            "datetime": "2015-06-04T10:45:50-07:00",
            "summary": "PARQUET-286: Update String support to match upstream Avro.",
            "message": "PARQUET-286: Update String support to match upstream Avro.\n\nThis adds getStringableClass, which determines what String\nrepresentation upstream Avro would use. Specific and reflect will use an\nalternative String class if java-class is set that is instantiated using\na constructor that takes a String. Otherwise, reflect will always use\nString and both specific and generic will use Utf8 or String depending\non whether avro.java.string is set to \"string\".\n\nThe new string representations required two new converters: one for Utf8\nand one for stringable classes (those with constructors that take a\nsingle String). The converters have also been refactored so that all\nbinary converters now implement dictionary support.\n\nAuthor: Ryan Blue <blue@apache.org>\n\nCloses #201 from rdblue/PARQUET-286-avro-utf8-support and squashes the following commits:\n\nbeb5a44 [Ryan Blue] PARQUET-286: Add tests, support for stringable map keys.\n0e9240f [Ryan Blue] PARQUET-286: Update string support to match upstream Avro.\n",
            "diff": {
                "parquet-avro/src/main/java/org/apache/parquet/avro/AvroConverters.java": 376,
                "parquet-avro/src/main/java/org/apache/parquet/avro/AvroRecordConverter.java": 112,
                "parquet-avro/src/test/java/org/apache/parquet/avro/TestBackwardCompatibility.java": 3,
                "parquet-avro/src/test/java/org/apache/parquet/avro/TestReadWrite.java": 27,
                "parquet-avro/src/test/java/org/apache/parquet/avro/TestReadWriteOldBehavior.java": 30,
                "parquet-avro/src/test/java/org/apache/parquet/avro/TestReflectReadWrite.java": 21,
                "parquet-avro/src/test/java/org/apache/parquet/avro/TestStringBehavior.java": 363
            },
            "is_test": true,
            "is_fix": false
        },
        "2e62764c0c386632e87ee8d12d0505848df1015e": {
            "datetime": "2015-06-05T10:32:54-07:00",
            "summary": "PARQUET-266: Add support for lists of primitives to Pig schema converter",
            "message": "PARQUET-266: Add support for lists of primitives to Pig schema converter\n\nAuthor: Christian Rolf <christian.rolf@adello.com>\n\nCloses #209 from ccrolf/PigPrimitivesList and squashes the following commits:\n\n5a69273 [Christian Rolf] Add support for lists of primitives to Pig schema converter\n",
            "diff": {
                "parquet-pig/src/main/java/org/apache/parquet/pig/PigSchemaConverter.java": 9,
                "parquet-pig/src/test/java/org/apache/parquet/pig/TestPigSchemaConverter.java": 33
            },
            "is_test": true,
            "is_fix": false
        },
        "4590f14e97beb6d10ffb7b5dd312c632af155ed3": {
            "datetime": "2015-06-17T09:17:23-07:00",
            "summary": "PARQUET-246: fix incomplete state reset in DeltaByteArrayWriter.reset()",
            "message": "PARQUET-246: fix incomplete state reset in DeltaByteArrayWriter.reset()\n\n...thod\n\nAuthor: Alex Levenson <alexlevenson@twitter.com>\nAuthor: Konstantin Shaposhnikov <Konstantin.Shaposhnikov@sc.com>\nAuthor: kostya-sh <kostya-sh@users.noreply.github.com>\n\nCloses #171 from kostya-sh/PARQUET-246 and squashes the following commits:\n\n75950c5 [kostya-sh] Merge pull request #1 from isnotinvain/PR-171\na718309 [Konstantin Shaposhnikov] Merge remote-tracking branch 'refs/remotes/origin/master' into PARQUET-246\n0367588 [Alex Levenson] Add regression test for PR-171\n94e8fda [Alex Levenson] Merge branch 'master' into PR-171\n0a9ac9f [Konstantin Shaposhnikov] [PARQUET-246] bugfix: reset all DeltaByteArrayWriter state in reset() method\n",
            "diff": {
                "parquet-column/src/main/java/org/apache/parquet/column/values/deltastrings/DeltaByteArrayWriter.java": 1,
                "parquet-column/src/test/java/org/apache/parquet/column/values/deltastrings/TestDeltaByteArray.java": 39
            },
            "is_test": true,
            "is_fix": true
        },
        "ad443210312d2420efef6d03a0296d71e71feb22": {
            "datetime": "2015-06-18T16:58:45-07:00",
            "summary": "PARQUET-297: generate Version class using parquet-generator",
            "message": "PARQUET-297: generate Version class using parquet-generator\n\nAuthor: Konstantin Shaposhnikov <Konstantin.Shaposhnikov@sc.com>\nAuthor: Konstantin Shaposhnikov <k.shaposhnikov@gmail.com>\n\nCloses #213 from kostya-sh/PARQUET-297_2 and squashes the following commits:\n\nddb469a [Konstantin Shaposhnikov] add comment about paddedByteCountFromBits coming from ByteUtils\n6b47b04 [Konstantin Shaposhnikov] Change VersionGenerator to generate main() method\n10d0b38 [Konstantin Shaposhnikov] PARQUET-297: generate Version class using parquet-generator\n11d29bc [Konstantin Shaposhnikov] parquet-generator: remove dependency on parquet-common\n",
            "diff": {
                "parquet-common/src/main/java/org/apache/parquet/Version.java": 103,
                "parquet-generator/src/main/java/org/apache/parquet/encoding/bitpacking/ByteBasedBitPackingGenerator.java": 9,
                "parquet-generator/src/main/java/org/apache/parquet/version/Generator.java": 28,
                "parquet-generator/src/main/java/org/apache/parquet/version/VersionGenerator.java": 83
            },
            "is_test": false,
            "is_fix": false
        },
        "079bcd0339f30343c01c5fd3d5521be4b822d30f": {
            "datetime": "2015-06-18T17:50:28-07:00",
            "summary": "PARQUET-297: Tests for PR 213 (Version generator)",
            "message": "PARQUET-297: Tests for PR 213 (Version generator)\n\nAdds tests for #213\n\nHow's this look @rdblue @kostya-sh ?\n\nAuthor: Alex Levenson <alexlevenson@twitter.com>\n\nCloses #218 from isnotinvain/tests-for-pr-213 and squashes the following commits:\n\n8ee996b [Alex Levenson] Fix group indexes off by 1\nb239a2a [Alex Levenson] Add license header :p\n38fc78d [Alex Levenson] Add test for Version generator\n",
            "diff": {
                "parquet-common/src/test/java/org/apache/parquet/VersionTest.java": 62
            },
            "is_test": true,
            "is_fix": true
        },
        "29283b775291bf03cd9a7e1aaa496faaa5757578": {
            "datetime": "2015-06-22T12:37:37-07:00",
            "summary": "PARQUET-314: Fix broken equals implementations",
            "message": "PARQUET-314: Fix broken equals implementations\n\nAuthor: Nezih Yigitbasi <nyigitbasi@netflix.com>\n\nCloses #223 from nezihyigitbasi/parquet-fixes and squashes the following commits:\n\n5279e60 [Nezih Yigitbasi] Override Object.equals properly\n",
            "diff": {
                "parquet-column/src/main/java/org/apache/parquet/column/ColumnDescriptor.java": 9,
                "parquet-column/src/main/java/org/apache/parquet/column/statistics/Statistics.java": 15
            },
            "is_test": false,
            "is_fix": false
        },
        "89321a2dee438328e75a11954e972175c78f0a2a": {
            "datetime": "2015-06-22T14:28:42-07:00",
            "summary": "PARQUET-311: Fix NPE when debug logging metadata",
            "message": "PARQUET-311: Fix NPE when debug logging metadata\n\nFixes the issue reported at https://issues.apache.org/jira/browse/PARQUET-311\n\nAuthor: Nezih Yigitbasi <nyigitbasi@netflix.com>\n\nCloses #221 from nezihyigitbasi/debug-log-fix and squashes the following commits:\n\n59129ed [Nezih Yigitbasi] PARQUET-311: Fix NPE when debug logging metadata\n",
            "diff": {
                "parquet-column/src/main/java/org/apache/parquet/column/statistics/BinaryStatistics.java": 4,
                "parquet-hadoop/src/test/java/org/apache/parquet/format/converter/TestParquetMetadataConverter.java": 31
            },
            "is_test": true,
            "is_fix": true
        },
        "412ab9669810921d04f9feabfbeafa906d4de506": {
            "datetime": "2015-06-22T17:11:27-07:00",
            "summary": "PARQUET-306: Add row group alignment",
            "message": "PARQUET-306: Add row group alignment\n\nThis adds `AlignmentStrategy` to the `ParquetFileWriter` that can alter the position of row groups and recommend a target size for the next row group. There are two strategies: `NoAlignment` and `PaddingAlignment`. Padding alignment is used for HDFS and no alignment is used for all other file systems. When HDFS-3689 is available, we can add a strategy to use that.\n\nThe amount of padding is controlled by a threshold between 0 and 1 that controls the fraction of the row group size that can be padded. This is interpreted as the maximum amount of padding that is acceptable, in terms of the row group size. For example, setting this to 5% will write padding when the bytes left in a HDFS block are less than 5% of the row group size. This defaults to 0%, which prevents padding from being added and matches the current behavior. The threshold is controlled by a new OutputFormat configuration property, `parquet.writer.padding-thresh`.\n\nAuthor: Ryan Blue <blue@apache.org>\n\nCloses #211 from rdblue/PARQUET-306-row-group-alignment and squashes the following commits:\n\n0137ddf [Ryan Blue] PARQUET-306: Add MR test with padding.\n6ce3f08 [Ryan Blue] PARQUET-306: Add parquet.writer.max-padding setting.\nf1dc659 [Ryan Blue] PARQUET-306: Base next row group size on bytes remaining.\nc6a3e97 [Ryan Blue] PARQUET-306: Add AlignmentStrategy to ParquetFileWriter.\n",
            "diff": {
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/InternalParquetRecordWriter.java": 20,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ParquetFileWriter.java": 186,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ParquetOutputFormat.java": 26,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ParquetWriter.java": 6,
                "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/TestInputOutputFormatWithPadding.java": 216,
                "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/TestParquetFileWriter.java": 319
            },
            "is_test": true,
            "is_fix": false
        },
        "46448e934250705b6ebd6f21caa09698d611dbfd": {
            "datetime": "2015-06-24T13:58:04-07:00",
            "summary": "PARQUET-201: Fix ValidTypeMap being overly strict with respect to OriginalTypes",
            "message": "PARQUET-201: Fix ValidTypeMap being overly strict with respect to OriginalTypes\n\nAuthor: Alex Levenson <alexlevenson@twitter.com>\n\nCloses #219 from isnotinvain/alexlevenson/PARQUET-201 and squashes the following commits:\n\n1cd8b58 [Alex Levenson] Merge branch 'master' into alexlevenson/PARQUET-201\n1d83e13 [Alex Levenson] Fix ValidTypeMap being overly strict with respect to OriginalTypes\n",
            "diff": {
                "parquet-column/src/main/java/org/apache/parquet/filter2/predicate/PrimitiveToBoxedClass.java": 50,
                "parquet-column/src/main/java/org/apache/parquet/filter2/predicate/SchemaCompatibilityValidator.java": 13,
                "parquet-column/src/main/java/org/apache/parquet/filter2/predicate/ValidTypeMap.java": 96,
                "parquet-column/src/test/java/org/apache/parquet/filter2/predicate/TestSchemaCompatibilityValidator.java": 2,
                "parquet-column/src/test/java/org/apache/parquet/filter2/predicate/TestValidTypeMap.java": 34
            },
            "is_test": true,
            "is_fix": true
        },
        "5c2ba72f9b4897d4441eff34ff0591e74a1d94bb": {
            "datetime": "2015-06-24T16:02:30-07:00",
            "summary": "PARQUET-284: Clean up ParquetMetadataConverter",
            "message": "PARQUET-284: Clean up ParquetMetadataConverter\n\nmakes all method static, removes unused thread-unsafe cache, etc.\n\nTurns out the \"cache\" was only read from *after* rebuilding what needed to be cached... so no performance gain there (and no loss by getting rid of it)\n\nHowever, I don't know if this will fix the issue mentioned in PARQUET-284, I don't think concurrent access to a HashMap will cause deadlock, it would just cause undefined behavior in reads or maybe ConcurrentModificationException\n\nUPDATE: I'm wrong, it can cause an infinite loop so this should fix the issue https://gist.github.com/rednaxelafx/1081908\n\nUPDATE2: Put the cache back in, made it static + thread safe\n\nAuthor: Alex Levenson <alexlevenson@twitter.com>\n\nCloses #220 from isnotinvain/alexlevenson/PARQUET-284 and squashes the following commits:\n\n4797b48 [Alex Levenson] Fix merge conflict issue\n8ff5775 [Alex Levenson] Merge branch 'master' into alexlevenson/PARQUET-284\nccd4776 [Alex Levenson] add encoding cache back in\n9ea5a5f [Alex Levenson] Clean up ParquetMetadataConverter: make all method static, remove unused thread-unsafe cache\n",
            "diff": {
                "parquet-hadoop/src/main/java/org/apache/parquet/format/converter/ParquetMetadataConverter.java": 128,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ColumnChunkPageWriteStore.java": 6,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ParquetFileReader.java": 16,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ParquetFileWriter.java": 10,
                "parquet-hadoop/src/test/java/org/apache/parquet/format/converter/TestParquetMetadataConverter.java": 67
            },
            "is_test": true,
            "is_fix": true
        },
        "cb04562742688f8a444a52c90b2183c4be528be6": {
            "datetime": "2015-06-25T09:40:21-07:00",
            "summary": "PARQUET-248: Add ParquetWriter.Builder.",
            "message": "PARQUET-248: Add ParquetWriter.Builder.\n\nThis refactors the builder recently added to parquet-avro so that it can\nbe used by all object models. The Builder class is abstract and\nimplementations should extend it.\n\nThis changes the API slightly from AvroParquetWriter, renaming\nwithBlockSize to withRowGroupSize. The Avro builder has not been\nreleased so this isn't a breaking change.\n\nAuthor: Ryan Blue <blue@apache.org>\n\nCloses #199 from rdblue/PARQUET-248-add-parquet-writer-builder and squashes the following commits:\n\na1a25ee [Ryan Blue] PARQUET-248: Add write mode and max padding to writer builder.\n622af4c [Ryan Blue] PARQUET-248: Add ParquetWriter.Builder.\n",
            "diff": {
                "parquet-avro/src/main/java/org/apache/parquet/avro/AvroParquetWriter.java": 75,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ParquetWriter.java": 267
            },
            "is_test": false,
            "is_fix": false
        },
        "1f3e72fa069536ae20f37b29575288ff65e66803": {
            "datetime": "2015-06-25T21:48:00-07:00",
            "summary": "PARQUET-317: Fix writeMetadataFile crash when a relative root path is used",
            "message": "PARQUET-317: Fix writeMetadataFile crash when a relative root path is used\n\nThis commit ensures the fully-qualified path is used prior to calling mergeFooters(..).\n\nAuthor: Steven She <steven@canopylabs.com>\n\nCloses #228 from stevencanopy/relative-metadata-path and squashes the following commits:\n\n988772b [Steven She] use outputPath.getFileSystem(...) to get the FS for the path\n1cea508 [Steven She] PARQUET-317: Fix writeMetadataFile crash when a relative root path is used\n",
            "diff": {
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ParquetFileWriter.java": 2,
                "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/TestParquetFileWriter.java": 27
            },
            "is_test": true,
            "is_fix": true
        },
        "e3b95020f777eb5e0651977f654c1662e3ea1f29": {
            "datetime": "2015-06-30T18:34:48-07:00",
            "summary": "PARQUET-251: Binary column statistics error when reuse byte[] among rows",
            "message": "PARQUET-251: Binary column statistics error when reuse byte[] among rows\n\nAuthor: asingh <asingh@cloudera.com>\nAuthor: Alex Levenson <alexlevenson@twitter.com>\nAuthor: Ashish Singh <asingh@cloudera.com>\n\nCloses #197 from SinghAsDev/PARQUET-251 and squashes the following commits:\n\n68e0eae [asingh] Remove deprecated constructors from private classes\n67e4e5f [asingh] Add removed public methods in Binary and deprecate them\n0e71728 [asingh] Add comment for BinaryStatistics.setMinMaxFromBytes\nfbe873f [Ashish Singh] Merge pull request #4 from isnotinvain/PR-197-3\n9826ee6 [Alex Levenson] Some minor cleanup\n7570035 [asingh] Remove test for stats getting ingnored for version 160 when type is int64\naf43d28 [Alex Levenson] Address PR feedback\n89ab4ee [Alex Levenson] put the headers in the right location\n2838cc9 [Alex Levenson] Split out version checks to separate files, add some tests\n5af9142 [Alex Levenson] Generalize tests, make Binary.fromString reused=false\ne00d9b7 [asingh] Rename isReused => isBackingBytesReused\nd2ad939 [asingh] Rebase over latest trunk\n857141a [asingh] Remove redundant junit dependency\n32b88ed [asingh] Remove semver from hadoop-common\n7a0e99e [asingh] Revert to fromConstantByteArray for ByteString\nc820ec9 [asingh] Add unit tests for Binary and to check if stats are ignored for version 160\n9bbd1e5 [asingh] Improve version parsing\n84a1d8b [asingh] Remove ignoring stats on write side and ignore it on read side\n903f8e3 [asingh] Address some review comments. * Ignore stats for writer's version < 1.8.0 * Refactor shoudlIgnoreStatistics method a bit * Assume implementations other than parquet-mr were writing binary   statistics correctly * Add toParquetStatistics method's original method signature to maintain   backwards compatibility and mark it as deprecated\n64c2617 [asingh] Revert changes for ignoring stats at RowGroupFilter level\ne861b18 [asingh] Ignore max min stats while reading\n3a8cb8d [asingh] Fix typo\n8e12618 [asingh] Fix usage of fromConstant versions of Binary constructors\n860adf7 [asingh] Rename unmodified to constant and isReused instead of isUnmodifiable\n0d127a7 [asingh] Add unmodfied and Reused versions for creating a Binary. Add copy() to Binary.\nb4e2950 [asingh] Skip filtering based on stats when file was written with version older than 1.6.1\n6fcee8c [asingh] Add getBytesUnsafe() to Binary that returns backing byte[] if possible, else returns result of getBytes()\n30b07dd [asingh] PARQUET-251: Binary column statistics error when reuse byte[] among rows\n",
            "diff": {
                "parquet-avro/src/main/java/org/apache/parquet/avro/AvroWriteSupport.java": 8,
                "parquet-avro/src/test/java/org/apache/parquet/avro/TestReadWrite.java": 5,
                "parquet-avro/src/test/java/org/apache/parquet/avro/TestReadWriteOldListBehavior.java": 4,
                "parquet-benchmarks/src/main/java/org/apache/parquet/benchmarks/DataGenerator.java": 2,
                "parquet-column/src/main/java/org/apache/parquet/CorruptStatistics.java": 104,
                "parquet-column/src/main/java/org/apache/parquet/column/statistics/BinaryStatistics.java": 18,
                "parquet-column/src/main/java/org/apache/parquet/column/values/deltalengthbytearray/DeltaLengthByteArrayValuesReader.java": 2,
                "parquet-column/src/main/java/org/apache/parquet/column/values/deltalengthbytearray/DeltaLengthByteArrayValuesWriter.java": 2,
                "parquet-column/src/main/java/org/apache/parquet/column/values/deltastrings/DeltaByteArrayReader.java": 8,
                "parquet-column/src/main/java/org/apache/parquet/column/values/deltastrings/DeltaByteArrayWriter.java": 2,
                "parquet-column/src/main/java/org/apache/parquet/column/values/dictionary/DictionaryValuesWriter.java": 9,
                "parquet-column/src/main/java/org/apache/parquet/column/values/dictionary/PlainValuesDictionary.java": 4,
                "parquet-column/src/main/java/org/apache/parquet/column/values/plain/BinaryPlainValuesReader.java": 2,
                "parquet-column/src/main/java/org/apache/parquet/column/values/plain/FixedLenByteArrayPlainValuesReader.java": 2,
                "parquet-column/src/main/java/org/apache/parquet/example/data/simple/NanoTime.java": 2,
                "parquet-column/src/main/java/org/apache/parquet/io/RecordConsumerLoggingWrapper.java": 2,
                "parquet-column/src/main/java/org/apache/parquet/io/api/Binary.java": 169,
                "parquet-column/src/main/java/org/apache/parquet/schema/PrimitiveType.java": 2,
                "parquet-column/src/test/java/org/apache/parquet/CorruptStatisticsTest.java": 78,
                "parquet-column/src/test/java/org/apache/parquet/column/statistics/TestStatistics.java": 18,
                "parquet-column/src/test/java/org/apache/parquet/column/values/dictionary/TestDictionary.java": 8,
                "parquet-column/src/test/java/org/apache/parquet/io/api/TestBinary.java": 215,
                "parquet-common/src/main/java/org/apache/parquet/SemanticVersion.java": 133,
                "parquet-common/src/main/java/org/apache/parquet/VersionParser.java": 105,
                "parquet-common/src/test/java/org/apache/parquet/SemanticVersionTest.java": 53,
                "parquet-common/src/test/java/org/apache/parquet/VersionTest.java": 44,
                "parquet-hadoop/src/main/java/org/apache/parquet/format/converter/ParquetMetadataConverter.java": 41,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/InternalParquetRecordReader.java": 6,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ParquetFileReader.java": 39,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ParquetReader.java": 2,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ParquetRecordReader.java": 3,
                "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/TestColumnChunkPageWriteStore.java": 3,
                "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/TestParquetFileWriter.java": 27,
                "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/TestParquetWriter.java": 6,
                "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/TestParquetWriterNewPage.java": 5,
                "parquet-hive/parquet-hive-storage-handler/src/main/java/org/apache/hadoop/hive/ql/io/parquet/writable/BinaryWritable.java": 2,
                "parquet-hive/parquet-hive-storage-handler/src/main/java/org/apache/hadoop/hive/serde2/objectinspector/primitive/ParquetStringInspector.java": 3,
                "parquet-pig/src/main/java/org/apache/parquet/pig/TupleWriteSupport.java": 2,
                "parquet-protobuf/src/main/java/org/apache/parquet/proto/ProtoWriteSupport.java": 2,
                "parquet-protobuf/src/test/java/org/apache/parquet/proto/ProtoWriteSupportTest.java": 12,
                "parquet-thrift/src/main/java/org/apache/parquet/thrift/ParquetWriteProtocol.java": 3,
                "parquet-tools/src/main/java/org/apache/parquet/tools/command/DumpCommand.java": 10
            },
            "is_test": true,
            "is_fix": true
        },
        "9fde65345e677256975bcecdc027649f31450a57": {
            "datetime": "2015-07-01T16:33:39-07:00",
            "summary": "PARQUET-320: Fix semver problems for parquet-hadoop.",
            "message": "PARQUET-320: Fix semver problems for parquet-hadoop.\n\nRe-enables semver checks for Parquet packages by removing the parquet/** exclusion that was matching unexpected classes. This also fixes all of the semver problems that have been committed since the check started excluding all Parquet classes.\n\nAuthor: Ryan Blue <blue@apache.org>\n\nCloses #230 from rdblue/PARQUET-320-fix-semver-issues and squashes the following commits:\n\na0e730d [Ryan Blue] PARQUET-320: Fix Thrift incompatibilities from ded56ffd.\nba71f3f [Ryan Blue] PARQUET-320: Fix semver problems for parquet-hadoop.\n",
            "diff": {
                "parquet-hadoop/src/main/java/org/apache/parquet/format/converter/ParquetMetadataConverter.java": 51,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ColumnChunkPageWriteStore.java": 6,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ParquetFileReader.java": 16,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ParquetFileWriter.java": 10,
                "parquet-hadoop/src/test/java/org/apache/parquet/format/converter/TestParquetMetadataConverter.java": 33,
                "parquet-thrift/src/main/java/org/apache/parquet/thrift/ThriftSchemaConvertVisitor.java": 2,
                "parquet-thrift/src/main/java/org/apache/parquet/thrift/projection/amend/DefaultEventsVisitor.java": 2,
                "parquet-thrift/src/main/java/org/apache/parquet/thrift/struct/CompatibilityChecker.java": 48,
                "parquet-thrift/src/main/java/org/apache/parquet/thrift/struct/ThriftType.java": 195,
                "parquet-thrift/src/test/java/org/apache/parquet/thrift/projection/TestFieldsPath.java": 2
            },
            "is_test": true,
            "is_fix": true
        },
        "c7720ca4c232d317cfc800a04eda4a1d5a44a944": {
            "datetime": "2015-07-01T16:46:23-07:00",
            "summary": "PARQUET-325: Always use row group size when padding is 0.",
            "message": "PARQUET-325: Always use row group size when padding is 0.\n\nFor block file systems, if the size left in the block is greater than\nthe max padding, a row group will be targeted at the remaining size.\nHowever, when using 0 to turn padding off, the remaining bytes will\nalways be greater than padding and row groups can be targeted at very\ntiny spaces. When padding is off, the next row group's size should\nalways be the default size.\n\nAuthor: Ryan Blue <blue@apache.org>\n\nCloses #234 from rdblue/PARQUET-325-padding-0-fix and squashes the following commits:\n\nf4b3c2b [Ryan Blue] PARQUET-325: Always use row group size when padding is 0.\n",
            "diff": {
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ParquetFileWriter.java": 4
            },
            "is_test": false,
            "is_fix": false
        },
        "a747456bfe077da467ff036172968a37f3b1e893": {
            "datetime": "2015-07-01T16:53:34-07:00",
            "summary": "PARQUET-308: Add ParquetWriter#getDataSize accessor.",
            "message": "PARQUET-308: Add ParquetWriter#getDataSize accessor.\n\nThis returns the current file position plus the amount of data buffered\nin the current row group as an estimate of final data size.\n\nAuthor: Ryan Blue <blue@apache.org>\n\nCloses #212 from rdblue/PARQUET-308-add-data-size-accessor and squashes the following commits:\n\n1c0d798 [Ryan Blue] PARQUET-308: Add ParquetWriter#getDataSize accessor.\n",
            "diff": {
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/InternalParquetRecordWriter.java": 9,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ParquetWriter.java": 7
            },
            "is_test": false,
            "is_fix": false
        },
        "2f2c8b1cc6e6e731f7bc52b0988ea8316f475004": {
            "datetime": "2015-07-01T17:18:41-07:00",
            "summary": "PARQUET-289: Allow ParquetReader.Builder subclasses.",
            "message": "PARQUET-289: Allow ParquetReader.Builder subclasses.\n\nThis adds a protected constructor for subclasses, a getReadSupport\nmethod for subclasses to override, and exposes the configuration for\nsubclasses to modify inside of getReadSupport.\n\nAuthor: Ryan Blue <blue@apache.org>\n\nCloses #203 from rdblue/PARQUET-289-extend-reader-builder and squashes the following commits:\n\n692f159 [Ryan Blue] PARQUET-289: Allow ParquetReader.Builder subclasses.\n",
            "diff": {
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ParquetReader.java": 19
            },
            "is_test": false,
            "is_fix": false
        },
        "c334a1bca8338c92e76f0f1cf2ef4884e3eb5dbd": {
            "datetime": "2015-07-01T17:30:29-07:00",
            "summary": "PARQUET-290: Add data model to Avro reader builder",
            "message": "PARQUET-290: Add data model to Avro reader builder\n\nThis PR currently includes #203, which will be removed when it is merged.\n\nAuthor: Ryan Blue <blue@apache.org>\n\nCloses #204 from rdblue/PARQUET-290-data-model-builder and squashes the following commits:\n\nd257a2c [Ryan Blue] PARQUET-290: Add Avro data model to reader builder.\n",
            "diff": {
                "parquet-avro/src/main/java/org/apache/parquet/avro/AvroParquetReader.java": 48,
                "parquet-avro/src/main/java/org/apache/parquet/avro/AvroReadSupport.java": 14,
                "parquet-avro/src/main/java/org/apache/parquet/avro/SpecificDataSupplier.java": 2
            },
            "is_test": false,
            "is_fix": false
        },
        "013b445ede8d9e7aad4915859d0c869b9b712f8d": {
            "datetime": "2015-07-03T10:51:34-07:00",
            "summary": "PARQUET-152: Add validation on Encoding.DELTA_BYTE_ARRAY to allow FIX\u2026",
            "message": "PARQUET-152: Add validation on Encoding.DELTA_BYTE_ARRAY to allow FIX\u2026\n\nPARQUET-152: Add validation on Encoding.DELTA_BYTE_ARRAY to allow FIXED_LEN_BYTE_ARRAY types.\n\n  * FIXED_LEN_BYTE_ARRAY types are binary values that may use DELTA_BYTE_ARRAY encoding,\n    so they should be allowed to be decoded using the same DELTA_BYTE_ARRAY encoding.\n\n@rdblue @nezihyigitbasi  Could you review this fix?\n\nI executed a test by writing a file that fall backs to DELTA_BYTE_ARRAY encoding, then read the file, and compare the read values with the written values, and it worked fine.\n\nAuthor: Sergio Pena <sergio.pena@cloudera.com>\n\nCloses #225 from spena/parquet-152 and squashes the following commits:\n\n93fa03e [Sergio Pena] PARQUET-152: Add validation on Encoding.DELTA_BYTE_ARRAY to allow FIXED_LEN_BYTE_ARRAY types.\n",
            "diff": {
                "parquet-column/src/main/java/org/apache/parquet/column/Encoding.java": 5
            },
            "is_test": false,
            "is_fix": false
        },
        "f4e754e66e3661274df624bc328991cd88dd03d6": {
            "datetime": "2015-07-03T10:53:22-07:00",
            "summary": "PARQUET-324: row count incorrect if data file has more than 2^31 rows",
            "message": "PARQUET-324: row count incorrect if data file has more than 2^31 rows\n\nNeed to change numRows counter from int to long to account for input files with more than 2^31 rows.\n\nAuthor: Thomas Friedrich <tfriedr@us.ibm.com>\n\nCloses #233 from tfriedr/parquet-324 and squashes the following commits:\n\n0120205 [Thomas Friedrich] change numRows from int to long\n",
            "diff": {
                "parquet-hadoop/src/main/java/org/apache/parquet/format/converter/ParquetMetadataConverter.java": 2
            },
            "is_test": false,
            "is_fix": false
        },
        "043fcde300267e183972056a007bcf406e5c484a": {
            "datetime": "2015-07-09T10:19:51-07:00",
            "summary": "PARQUET-246: File recovery and work-arounds",
            "message": "PARQUET-246: File recovery and work-arounds\n\nThis is another way to recover data written with the delta byte array problem in PARQUET-246. This builds on @isnotinvain's strategy for solving the problem by adding a method to the encoding to detect it. This version is more similar to the fix for PARQUET-251 and includes a CorruptDeltaByteArrays helper class that uses the writer version. Most of the file changes are to get the file writer version to Encoding and the ColumnReaderImpl.\n\nThis also repairs the problem by using a new interface, RequiresPreviousReader, to pass the previous ValuesReader, which is slightly cleaner because the reader doesn't need to expose getter and setter methods.\n\nThe problem affects pages written to different row groups, so it was necessary to detect the problem in parquet-hadoop and fail jobs that cannot reconstruct data. The work-around to recover is to set \"parquet.split.files\" to false so that files are read sequentially. This could be set automatically in isSplittable, but this would require reading all file footers before submitting jobs, which was recently fixed. I think it is a fair compromise to detect the error case and recommend a solution.\n\nThis also includes tests for the problem to verify the fix.\n\nReplaces old pull requests: closes #217 closes #235\n\nAuthor: Ryan Blue <blue@apache.org>\n\nCloses #235 from rdblue/PARQUET-246-recover-files and squashes the following commits:\n\n067d5ca [Ryan Blue] PARQUET-246: Refactor after review comments.\n3236a3b [Ryan Blue] PARQUET-246: Fix ParquetInputFormat for delta byte[] corruption.\n3107362 [Ryan Blue] PARQUET-246: Add tests for delta byte array fix.\na10b157 [Ryan Blue] PARQUET-246: Fix reading for corrupt delta byte arrays.\n5c9497c [Ryan Blue] PARQUET-246: Parse semantic version with full version.\n",
            "diff": {
                "parquet-column/src/main/java/org/apache/parquet/CorruptDeltaByteArrays.java": 99,
                "parquet-column/src/main/java/org/apache/parquet/CorruptStatistics.java": 4,
                "parquet-column/src/main/java/org/apache/parquet/column/impl/ColumnReadStoreImpl.java": 22,
                "parquet-column/src/main/java/org/apache/parquet/column/impl/ColumnReaderImpl.java": 42,
                "parquet-column/src/main/java/org/apache/parquet/column/values/RequiresPreviousReader.java": 23,
                "parquet-column/src/main/java/org/apache/parquet/column/values/deltastrings/DeltaByteArrayReader.java": 25,
                "parquet-column/src/main/java/org/apache/parquet/io/ColumnIOFactory.java": 38,
                "parquet-column/src/main/java/org/apache/parquet/io/MessageColumnIO.java": 11,
                "parquet-column/src/test/java/org/apache/parquet/column/impl/TestColumnReaderImpl.java": 10,
                "parquet-column/src/test/java/org/apache/parquet/column/impl/TestCorruptDeltaByteArrays.java": 259,
                "parquet-column/src/test/java/org/apache/parquet/column/mem/TestMemColumn.java": 3,
                "parquet-common/src/main/java/org/apache/parquet/SemanticVersion.java": 29,
                "parquet-common/src/main/java/org/apache/parquet/VersionParser.java": 39,
                "parquet-common/src/test/java/org/apache/parquet/SemanticVersionTest.java": 10,
                "parquet-common/src/test/java/org/apache/parquet/VersionTest.java": 9,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/InternalParquetRecordReader.java": 3,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ParquetInputFormat.java": 10,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ParquetRecordReader.java": 27,
                "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/TestParquetFileWriter.java": 11,
                "parquet-tools/src/main/java/org/apache/parquet/tools/command/DumpCommand.java": 4
            },
            "is_test": true,
            "is_fix": true
        },
        "4c7d7523088373be3c7ff203ea895d5a6d84083e": {
            "datetime": "2015-07-11T16:26:51-07:00",
            "summary": "PARQUET-329: Restore ThriftReadSupport#THRIFT_COLUMN_FILTER_KEY",
            "message": "PARQUET-329: Restore ThriftReadSupport#THRIFT_COLUMN_FILTER_KEY\n\nThriftReadSupport#THRIFT_COLUMN_FILTER_KEY was removed (incompatible change)\n\nAuthor: asingh <asingh@cloudera.com>\n\nCloses #239 from SinghAsDev/PARQUET-329 and squashes the following commits:\n\n1e44a70 [asingh] Remove o.a.p.hadoop.thrift from semver excludes\n4a1e572 [asingh] PARQUET-329: Restore ThriftReadSupport#THRIFT_COLUMN_FILTER_KEY\n",
            "diff": {
                "parquet-thrift/src/main/java/org/apache/parquet/hadoop/thrift/ThriftReadSupport.java": 14,
                "parquet-thrift/src/main/java/org/apache/parquet/thrift/projection/deprecated/DeprecatedFieldProjectionFilter.java": 2,
                "parquet-thrift/src/main/java/org/apache/parquet/thrift/projection/deprecated/PathGlobPattern.java": 2,
                "parquet-thrift/src/test/java/org/apache/parquet/hadoop/thrift/TestParquetToThriftReadWriteAndProjection.java": 2
            },
            "is_test": true,
            "is_fix": true
        },
        "fcd568282b2a150f9f42953f12268dc88d09da89": {
            "datetime": "2015-07-13T10:36:18-07:00",
            "summary": "PARQUET-279 : Check empty struct in compatibility checker",
            "message": "PARQUET-279 : Check empty struct in compatibility checker\n\nAdd the empty struct check in the CompatibilityChecker util.\nParquet currently does not support empty struct/group without leaves\n\nAuthor: Tianshuo Deng <tdeng@twitter.com>\n\nCloses #194 from tsdeng/check_empty_struct and squashes the following commits:\n\n35d77a1 [Tianshuo Deng] fix rebase\nd781cf3 [Tianshuo Deng] simplify constructor\ncd2fa8e [Tianshuo Deng] add State\ne75a6ac [Tianshuo Deng] use immutable FieldsPath\n2bff920 [Tianshuo Deng] fix test\n69b4b9c [Tianshuo Deng] minor fixes\n2db8c4b [Tianshuo Deng] remove unused println\n5107ce2 [Tianshuo Deng] fix comments\n265e228 [Tianshuo Deng] wip\n",
            "diff": {
                "parquet-common/src/main/java/org/apache/parquet/Strings.java": 14,
                "parquet-thrift/src/main/java/org/apache/parquet/thrift/ThriftSchemaConverter.java": 4,
                "parquet-thrift/src/main/java/org/apache/parquet/thrift/struct/CompatibilityChecker.java": 159,
                "parquet-thrift/src/main/java/org/apache/parquet/thrift/struct/CompatibilityRunner.java": 7,
                "parquet-thrift/src/test/java/org/apache/parquet/thrift/struct/CompatibilityCheckerTest.java": 16
            },
            "is_test": true,
            "is_fix": false
        },
        "be9f3cb2a8095c89b5a11c33a498532f3c6413a3": {
            "datetime": "2015-07-14T09:56:20-07:00",
            "summary": "PARQUET-331: Surface subprocess stderr in merge script",
            "message": "PARQUET-331: Surface subprocess stderr in merge script\n\nThis makes it a little easier to understand why the merge script failed\n\nAuthor: Alex Levenson <alexlevenson@twitter.com>\n\nCloses #240 from isnotinvain/alexlevenson/merge-script-error-handling and squashes the following commits:\n\n7c38c01 [Alex Levenson] Surface subprocess stderr in merge script\n",
            "diff": {
                "dev/merge_parquet_pr.py": 18
            },
            "is_test": false,
            "is_fix": false
        },
        "f79c9365d0ee89cb407b90cc084eece8fcf9a8a2": {
            "datetime": "2015-07-16T16:41:04-07:00",
            "summary": "PARQUET-337 handle binary fields in set/map/list in parquet-scrooge",
            "message": "PARQUET-337 handle binary fields in set/map/list in parquet-scrooge\n\nhttps://issues.apache.org/jira/browse/PARQUET-337\n\nAuthor: Jake Donham <jdonham@twitter.com>\n\nCloses #243 from jaked/PARQUET-337 and squashes the following commits:\n\n8129fe5 [Jake Donham] parquet-scrooge: handle binary fields in set/map/list\n",
            "diff": {
                "parquet-scrooge/src/main/java/org/apache/parquet/scrooge/ScroogeStructConverter.java": 9,
                "parquet-scrooge/src/test/java/org/apache/parquet/scrooge/ScroogeStructConverterTest.java": 12
            },
            "is_test": true,
            "is_fix": true
        },
        "8714dd031647be34d0d27f461894e7b194f25cd7": {
            "datetime": "2015-07-16T16:42:38-07:00",
            "summary": "PARQUET-336: Fix ArrayIndexOutOfBounds in checkDeltaByteArrayProblem",
            "message": "PARQUET-336: Fix ArrayIndexOutOfBounds in checkDeltaByteArrayProblem\n\nAuthor: Alex Levenson <alexlevenson@twitter.com>\nAuthor: Alex Levenson <alex@isnotinvain.com>\n\nCloses #242 from isnotinvain/patch-1 and squashes the following commits:\n\nce1f81e [Alex Levenson] Add tests\n4688930 [Alex Levenson] Fix ArrayIndexOutOfBounds in checkDeltaByteArrayProblem\n",
            "diff": {
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ParquetRecordReader.java": 4,
                "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/example/TestInputOutputFormat.java": 71
            },
            "is_test": true,
            "is_fix": true
        },
        "83406b73e70a251eec5daae34f1bd8d554cdddec": {
            "datetime": "2015-07-20T09:59:29-07:00",
            "summary": "PARQUET-340: MemoryManager: max memory can be truncated",
            "message": "PARQUET-340: MemoryManager: max memory can be truncated\n\nUsing float will cause the max heap limit to be limited to 2147483647\ndue to math.round(float) if used with a large heap. This should be a double\nprecision to prevent rounding to an int32 before storing into a long.\n\nAuthor: Chris Bannister <c.bannister@gmail.com>\n\nCloses #246 from Zariel/default-mem-truncated and squashes the following commits:\n\nbf375f6 [Chris Bannister] MemoryManager: ensure max memory is not truncated\n",
            "diff": {
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/MemoryManager.java": 2,
                "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/TestMemoryManager.java": 2
            },
            "is_test": true,
            "is_fix": true
        },
        "454fc3655509f1f4f47ce44acaff7c1566ede108": {
            "datetime": "2015-07-28T14:55:14-07:00",
            "summary": "PARQUET-342: Updates to be Java 6 compatible",
            "message": "PARQUET-342: Updates to be Java 6 compatible\n\nAuthor: Nezih Yigitbasi <nyigitbasi@netflix.com>\n\nCloses #248 from nezihyigitbasi/java6-fixes and squashes the following commits:\n\n2ab2598 [Nezih Yigitbasi] Updates to be Java 6 compatible\n",
            "diff": {
                "parquet-common/src/main/java/org/apache/parquet/Files.java": 51,
                "parquet-common/src/main/java/org/apache/parquet/SemanticVersion.java": 16,
                "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/TestInputOutputFormatWithPadding.java": 11,
                "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/example/TestInputOutputFormat.java": 9
            },
            "is_test": true,
            "is_fix": true
        },
        "b86f68e39dc7b6a7c2bff1e4fea3bb7c28d103f0": {
            "datetime": "2015-07-31T16:57:19-07:00",
            "summary": "PARQUET-346: Minor fixes for PARQUET-350, PARQUET-348, PARQUET-346, PARQUET-345",
            "message": "PARQUET-346: Minor fixes for PARQUET-350, PARQUET-348, PARQUET-346, PARQUET-345\n\nPARQUET-346:\nThriftSchemaConverter throws for unknown struct or union type\nThis is triggered when passing a StructType that comes from old file metadata\n\nPARQUET-350:\nThriftRecordConverter throws NPE for unrecognized enum values\nThis is just some better error reporting.\n\nPARQUET-348:\nshouldIgnoreStatistics too noisy\nThis is just a case of way over logging something, to the point that it make the logs unreadable\n\nPARQUET-345\nThriftMetaData toString() should not try to load class reflectively\nThis is a case where the error reporting itself crashes, which results in the real error message getting lost\n\nAuthor: Alex Levenson <alexlevenson@twitter.com>\n\nCloses #252 from isnotinvain/alexlevenson/various-fixes and squashes the following commits:\n\n9b5cb0e [Alex Levenson] Add comments, cleanup some minor use of ThriftSchemaConverter\n376343e [Alex Levenson] Fix test\nd9d5dad [Alex Levenson] add license headers\ne26dc0c [Alex Levenson] Add tests\n8d9dde0 [Alex Levenson] Fixes for PARQUET-350, PARQUET-348, PARQUET-346, PARQUET-345\n",
            "diff": {
                "parquet-column/src/main/java/org/apache/parquet/CorruptStatistics.java": 30,
                "parquet-scrooge/src/test/java/org/apache/parquet/scrooge/ScroogeStructConverterTest.java": 5,
                "parquet-thrift/src/main/java/org/apache/parquet/hadoop/thrift/AbstractThriftWriteSupport.java": 3,
                "parquet-thrift/src/main/java/org/apache/parquet/hadoop/thrift/TBaseWriteSupport.java": 3,
                "parquet-thrift/src/main/java/org/apache/parquet/hadoop/thrift/ThriftBytesWriteSupport.java": 5,
                "parquet-thrift/src/main/java/org/apache/parquet/thrift/ThriftMetaData.java": 3,
                "parquet-thrift/src/main/java/org/apache/parquet/thrift/ThriftRecordConverter.java": 49,
                "parquet-thrift/src/main/java/org/apache/parquet/thrift/ThriftSchemaConvertVisitor.java": 23,
                "parquet-thrift/src/main/java/org/apache/parquet/thrift/ThriftSchemaConverter.java": 16,
                "parquet-thrift/src/main/java/org/apache/parquet/thrift/struct/CompatibilityRunner.java": 2,
                "parquet-thrift/src/test/java/org/apache/parquet/thrift/TestProtocolReadToWrite.java": 14,
                "parquet-thrift/src/test/java/org/apache/parquet/thrift/TestThriftMetaData.java": 55,
                "parquet-thrift/src/test/java/org/apache/parquet/thrift/TestThriftRecordConverter.java": 101,
                "parquet-thrift/src/test/java/org/apache/parquet/thrift/TestThriftToPigCompatibility.java": 2,
                "parquet-thrift/src/test/java/org/apache/parquet/thrift/struct/CompatibilityCheckerTest.java": 2
            },
            "is_test": true,
            "is_fix": true
        },
        "2f956f46580e5b4752173e885d37a20fe31a78d8": {
            "datetime": "2015-08-05T16:29:00-07:00",
            "summary": "PARQUET-341 improve write performance for wide schema sparse data",
            "message": "PARQUET-341 improve write performance for wide schema sparse data\n\nIn write path, when there are tons of sparse data, most of time is spent on writing nulls.\nCurrently writing nulls has the same code path as writing values, which is reclusive traverse all the leaves when a group is null.\nDue to the fact that when a group is null all the leaves beneath it should be written with null value with the same repetition level and definition level, we can eliminate the recursion call to get the leaves\n\nThis PR caches the leaves for each group node. So when a group node is null, their leaves can be flushed with null values directly.\n\nWe tested it with a really wide schema on one of our production data. It improves the performance by ~20%\n\nAuthor: Tianshuo Deng <tdeng@twitter.com>\n\nCloses #247 from tsdeng/flush_null_directly and squashes the following commits:\n\n253f2e3 [Tianshuo Deng] address comments\n8676cd7 [Tianshuo Deng] flush null directly to leaves\n",
            "diff": {
                "parquet-column/src/main/java/org/apache/parquet/io/MessageColumnIO.java": 39,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/InternalParquetRecordReader.java": 3
            },
            "is_test": false,
            "is_fix": false
        }
    },
    "2015-08-16T15:17:05-07:00": {
        "3f36b7b50bdda3eeca632ad5440bb82b8e34cb40": {
            "datetime": "2015-08-20T13:52:56-07:00",
            "summary": "PARQUET-362 - Fix parquet buffered writer being oversensitive to union schema changes",
            "message": "PARQUET-362 - Fix parquet buffered writer being oversensitive to union schema changes\n\nParquet does prevent records with unknown union fields to be written as it would\ncreate a TProtocol violation. But it also prevents records with unions having one their field\nitself having an unknown field (which is acceptable if it is a struct).\n\nAuthor: Laurent Goujon <lgoujon@twitter.com>\n\nCloses #262 from laurentgo/fix-parquet-union-write-bug and squashes the following commits:\n\nd15ee74 [Laurent Goujon] Fix parquet buffered writer being oversentive to union changes\n",
            "diff": {
                "parquet-thrift/src/main/java/org/apache/parquet/thrift/BufferedProtocolReadToWrite.java": 9,
                "parquet-thrift/src/test/java/org/apache/parquet/thrift/TestProtocolReadToWrite.java": 37
            },
            "is_test": true,
            "is_fix": true
        },
        "01fbf81e34a36cedf505f20b1c52306afceedc3e": {
            "datetime": "2015-08-20T14:21:12-07:00",
            "summary": "PARQUET-343 Caching nulls on group node to improve write performance on wide schema sparse data",
            "message": "PARQUET-343 Caching nulls on group node to improve write performance on wide schema sparse data\n\nFor really wide schema with sparse data, If a group node is empty, it could have a huge number of leaves underneath it. Calling writeMull for each leaf every time when it's ancestor group node is null is in-effcient and is bad for data locality in the memory especially when the number of leaves is huge.\n\nInstead, null can be cached on the group node. Flushing is only triggered when a group node becomes non-null from null. This way, all the cached null values will be flushed to the leaf nodes in a tight loop and improves write performance.\n\nWe tested this approach combined with PARQUET-341 on a really large schema and gave us ~2X improvement on write performance\n\nAuthor: Tianshuo Deng <tdeng@twitter.com>\n\nCloses #249 from tsdeng/batch_null and squashes the following commits:\n\n0a61646 [Tianshuo Deng] use curly braces even for 1 line if statements\na8964c0 [Tianshuo Deng] optimize writeNullToLeaves\n5309612 [Tianshuo Deng] optimize cacheNullForGroup\necbdfca [Tianshuo Deng] add comments\ned692c0 [Tianshuo Deng] WIP\n0cae1b6 [Tianshuo Deng] remove unused class\n8e07db4 [Tianshuo Deng] refactor\ndead618 [Tianshuo Deng] reformat\nc3c0c70 [Tianshuo Deng] refactor\n636ab52 [Tianshuo Deng] remove unused method\n767b4fd [Tianshuo Deng] use parent definition level\n8f251a0 [Tianshuo Deng] use IntArrayList\nc549c84 [Tianshuo Deng] fix\n9583d04 [Tianshuo Deng] wIP\nd8cb878 [Tianshuo Deng] WIP\n35f1fa1 [Tianshuo Deng] cache columnWriter for each parent\n46fd464 [Tianshuo Deng] address comments\n8c83964 [Tianshuo Deng] flush null directly to leaves\n",
            "diff": {
                "parquet-column/src/main/java/org/apache/parquet/io/MessageColumnIO.java": 145,
                "parquet-column/src/main/java/org/apache/parquet/io/ValidatingRecordConsumer.java": 4,
                "parquet-column/src/main/java/org/apache/parquet/io/api/RecordConsumer.java": 7,
                "parquet-column/src/test/java/org/apache/parquet/io/TestColumnIO.java": 21,
                "parquet-column/src/test/java/org/apache/parquet/io/TestFiltered.java": 5,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/InternalParquetRecordReader.java": 3,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/InternalParquetRecordWriter.java": 6,
                "parquet-thrift/src/test/java/org/apache/parquet/thrift/TestParquetReadProtocol.java": 1
            },
            "is_test": true,
            "is_fix": false
        },
        "04f524d5ad91b1cdda66dfde4089f2f83f4528aa": {
            "datetime": "2015-08-20T15:23:22-07:00",
            "summary": "PARQUET-361: Add semver prerelease logic.",
            "message": "PARQUET-361: Add semver prerelease logic.\n\nThis also adds more versions where PARQUET-251 is fixed.\n\nAuthor: Ryan Blue <blue@apache.org>\n\nCloses #261 from rdblue/PARQUET-361-add-semver-prerelease and squashes the following commits:\n\nc01142d [Ryan Blue] PARQUET-361: Add semver prerelease logic.\n",
            "diff": {
                "parquet-column/src/main/java/org/apache/parquet/CorruptStatistics.java": 6,
                "parquet-column/src/test/java/org/apache/parquet/CorruptStatisticsTest.java": 14,
                "parquet-common/src/main/java/org/apache/parquet/SemanticVersion.java": 155,
                "parquet-common/src/test/java/org/apache/parquet/SemanticVersionTest.java": 61
            },
            "is_test": true,
            "is_fix": false
        },
        "9962a0fd02fe2ef06765271605b06729af8b2e59": {
            "datetime": "2015-09-11T10:31:38-07:00",
            "summary": "PARQUET-335: Remove Avro check for MAP_KEY_VALUE.",
            "message": "PARQUET-335: Remove Avro check for MAP_KEY_VALUE.\n\nThis is not required by the map type spec. This does not affect data\nwritten by the Avro object model because this bug is in the conversion\nfrom a Parquet schema to an Avro schema. Files written with parquet-avro\ndo not convert the underlying schema because they use the Avro schema.\n\nAuthor: Ryan Blue <blue@apache.org>\n\nCloses #241 from rdblue/PARQUET-335-remove-key-value-check and squashes the following commits:\n\n1fd9541 [Ryan Blue] PARQUET-335: Test that MAP_KEY_VALUE is not required.\n247cc76 [Ryan Blue] PARQUET-335: Remove Avro check for MAP_KEY_VALUE.\n",
            "diff": {
                "parquet-avro/src/main/java/org/apache/parquet/avro/AvroSchemaConverter.java": 1,
                "parquet-avro/src/test/java/org/apache/parquet/avro/TestAvroSchemaConverter.java": 20
            },
            "is_test": true,
            "is_fix": true
        },
        "f203d809d7b94501a2e5409c667ba86206480f90": {
            "datetime": "2015-09-11T15:14:00-07:00",
            "summary": "PARQUET-363: Allow empty schema groups.",
            "message": "PARQUET-363: Allow empty schema groups.\n\nThis removes the check added in PARQUET-278 that rejects schema groups\nthat have no fields. Selecting 0 columns from a file is allowed and used\nby Hive and SparkSQL to implement queries like `select count(1) ...`\n\nAuthor: Ryan Blue <blue@apache.org>\n\nCloses #263 from rdblue/PARQUET-363-allow-empty-groups and squashes the following commits:\n\nab370f1 [Ryan Blue] PARQUET-363: Update Type builder tests to allow empty groups.\n926932b [Ryan Blue] PARQUET-363: Add write-side schema validation.\n365f30d [Ryan Blue] PARQUET-363: Allow empty schema groups.\n",
            "diff": {
                "parquet-column/src/main/java/org/apache/parquet/schema/GroupType.java": 3,
                "parquet-column/src/main/java/org/apache/parquet/schema/TypeUtil.java": 45,
                "parquet-column/src/main/java/org/apache/parquet/schema/Types.java": 2,
                "parquet-column/src/test/java/org/apache/parquet/schema/TestMessageType.java": 13,
                "parquet-column/src/test/java/org/apache/parquet/schema/TestTypeBuilders.java": 40,
                "parquet-column/src/test/java/org/apache/parquet/schema/TestTypeUtil.java": 89,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ParquetFileWriter.java": 2,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/example/ExampleParquetWriter.java": 93,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/example/GroupWriteSupport.java": 14,
                "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/TestParquetWriter.java": 37,
                "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/TestUtils.java": 19
            },
            "is_test": true,
            "is_fix": true
        },
        "d24ecb32ff58d13c178991f0c8618980ff123080": {
            "datetime": "2015-09-14T16:39:25-07:00",
            "summary": "PARQUET-376: Tolerate square brackets in PR titles",
            "message": "PARQUET-376: Tolerate square brackets in PR titles\n\nThis allows for PRs like:\n\n`[PARQUET-XXXX] description`\n\nto be parsed, as we often get this format and we usually have to ask the submitter to change the title for us.\n\nAuthor: Alex Levenson <alexlevenson@twitter.com>\n\nCloses #271 from isnotinvain/alexlevenson/tolerate-brackets-pr-merge and squashes the following commits:\n\nedf086d [Alex Levenson] Remove brackets from commit message\n3ba963d [Alex Levenson] Tolerate square brackets in PR titles\n",
            "diff": {
                "dev/merge_parquet_pr.py": 13
            },
            "is_test": false,
            "is_fix": false
        },
        "415761dc0d7c86bc455608f6b12184ae7ff296ce": {
            "datetime": "2015-09-14T16:40:52-07:00",
            "summary": "Revert \"PARQUET-376: Tolerate square brackets in PR titles\"",
            "message": "Revert \"PARQUET-376: Tolerate square brackets in PR titles\"\n\nThis reverts commit d24ecb32ff58d13c178991f0c8618980ff123080.\n",
            "diff": {
                "dev/merge_parquet_pr.py": 13
            },
            "is_test": false,
            "is_fix": false
        },
        "0637e2fbcd401f47bb062d5c2d1cceddabf372b7": {
            "datetime": "2015-09-17T11:46:41-07:00",
            "summary": "PARQUET-360: Handle all map key types with cat tool's json dump",
            "message": "PARQUET-360: Handle all map key types with cat tool's json dump\n\nWhen dumping a parquet map with `parquet-cat --json` it throws a class cast exception as it doesn't properly handle all map key types.\n\n```\njava.lang.ClassCastException: [B cannot be cast to java.lang.String\n\tat org.apache.parquet.tools.read.SimpleMapRecord.toJsonObject(SimpleMapRecord.java:34)\n\tat org.apache.parquet.tools.read.SimpleRecord.toJsonValue(SimpleRecord.java:119)\n\tat org.apache.parquet.tools.read.SimpleRecord.toJsonObject(SimpleRecord.java:112)\n\tat org.apache.parquet.tools.read.SimpleRecord.prettyPrintJson(SimpleRecord.java:106)\n\tat org.apache.parquet.tools.command.CatCommand.execute(CatCommand.java:76)\n\tat org.apache.parquet.tools.Main.main(Main.java:222)\n[B cannot be cast to java.lang.String\n```\n\nAuthor: Nezih Yigitbasi <nyigitbasi@netflix.com>\n\nCloses #259 from nezihyigitbasi/parquet-cat-json and squashes the following commits:\n\nd047502 [Nezih Yigitbasi] Add unit test\ne4cd545 [Nezih Yigitbasi] Get rid of deprecated methods\nbdc8fdf [Nezih Yigitbasi] Handle all map key types with cat tool's json dump\n",
            "diff": {
                "parquet-tools/src/main/java/org/apache/parquet/tools/command/CatCommand.java": 2,
                "parquet-tools/src/main/java/org/apache/parquet/tools/command/DumpCommand.java": 5,
                "parquet-tools/src/main/java/org/apache/parquet/tools/command/HeadCommand.java": 2,
                "parquet-tools/src/main/java/org/apache/parquet/tools/command/ShowSchemaCommand.java": 4,
                "parquet-tools/src/main/java/org/apache/parquet/tools/read/SimpleMapRecord.java": 51,
                "parquet-tools/src/test/java/org/apache/parquet/tools/read/TestSimpleMapRecord.java": 56
            },
            "is_test": true,
            "is_fix": true
        },
        "c3819688c48480ec75a9563c71f18ea755e34620": {
            "datetime": "2015-09-18T15:08:49-07:00",
            "summary": "PARQUET-355: Add Statistics Test for Parquet Columns",
            "message": "PARQUET-355: Add Statistics Test for Parquet Columns\n\nIn response to PARQUET-251 created an integration test that generates random values and compares the statistics against the values read from a parquet file.\n\nThere are two tools classes `DataGenerationContext` and `RandomValueGenerators` which are located in the same package as the unit test. I'm sure there is a better place to put these, but I leave that to your discretion.\n\nThanks\nReuben\n\nAuthor: Reuben Kuhnert <sircodesalot@gmail.com>\nAuthor: Ryan Blue <blue@apache.org>\n\nCloses #255 from sircodesalotOfTheRound/stats-validation and squashes the following commits:\n\n680e96a [Reuben Kuhnert] Merge pull request #1 from rdblue/PARQUET-355-stats-validation-tests\n9f0033f [Ryan Blue] PARQUET-355: Use ColumnReaderImpl.\n7d0b4fe [Reuben Kuhnert] PARQUET-355: Add Statistics Validation Test\n",
            "diff": {
                "parquet-column/src/main/java/org/apache/parquet/column/impl/ColumnReaderImpl.java": 6,
                "parquet-hadoop/src/test/java/org/apache/parquet/statistics/RandomValues.java": 271,
                "parquet-hadoop/src/test/java/org/apache/parquet/statistics/TestStatistics.java": 449
            },
            "is_test": true,
            "is_fix": false
        },
        "b1ea059a66c7d6d6bb4cb53d2005a9b7bb599ada": {
            "datetime": "2015-10-13T15:54:03-07:00",
            "summary": "PARQUET-381: Add feature to merge metadata (summary) files, and control which files are generated",
            "message": "PARQUET-381: Add feature to merge metadata (summary) files, and control which files are generated\n\n1) Add helper to merge 2 summary files, useful for merging 2 directories of data into 1\n2) Add more control over whether _common_metadata, _metadata, or both is written\n\nAuthor: Alex Levenson <alexlevenson@twitter.com>\n\nCloses #277 from isnotinvain/alexlevenson/merge-summary-files and squashes the following commits:\n\n86232f5 [Alex Levenson] Address comments\n96b9495 [Alex Levenson] Fix null extraMetaData\n099c913 [Alex Levenson] Make deprecated method delegate to new method\n7a98957 [Alex Levenson] Merge branch 'master' into alexlevenson/merge-summary-files\nddaf4ff [Alex Levenson] Introduce job summary levels for controlling which metadata files are generated\n87a2ebc [Alex Levenson] Update comments\n9d2b8da [Alex Levenson] Add helper method for merging metadata files\n",
            "diff": {
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ParquetFileReader.java": 13,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ParquetFileWriter.java": 65,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ParquetOutputCommitter.java": 66,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ParquetOutputFormat.java": 51,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/example/ExampleParquetWriter.java": 11,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/example/GroupWriteSupport.java": 12,
                "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/TestMergeMetadataFiles.java": 215,
                "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/TestParquetFileWriter.java": 5,
                "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/TestParquetOutputFormatJobSummaryLevel.java": 69
            },
            "is_test": true,
            "is_fix": false
        },
        "5294c64b342818e021800b38413f36f426e35b3c": {
            "datetime": "2015-10-19T15:51:07-07:00",
            "summary": "PARQUET-373: Fix flaky MemoryManager tests.",
            "message": "PARQUET-373: Fix flaky MemoryManager tests.\n\nAuthor: Ryan Blue <blue@apache.org>\n\nCloses #269 from rdblue/PARQUET-373-fix-flaky-mem-manager-tests and squashes the following commits:\n\n1b55889 [Ryan Blue] PARQUET-373: Fix flaky MemoryManager tests.\n",
            "diff": {
                "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/TestMemoryManager.java": 169
            },
            "is_test": true,
            "is_fix": true
        },
        "5a45ae3b1deb5117cb9e9a13141eeab1e9ad3d71": {
            "datetime": "2015-10-29T15:42:43-07:00",
            "summary": "PARQUET-241: Fix ParquetInputFormat.getFooters() order",
            "message": "PARQUET-241: Fix ParquetInputFormat.getFooters() order\n\nParquetInputFormat.getFooters() should return in the same order as what listStatus() returns\n\nAuthor: Mingyu Kim <mkim@palantir.com>\n\nCloses #164 from mingyukim/parquet-241 and squashes the following commits:\n\n86fe900 [Mingyu Kim] Address PR comments\nb0181e2 [Mingyu Kim] PARQUET-241: ParquetInputFormat.getFooters() should return in the same order as what listStatus() returns\n",
            "diff": {
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ParquetInputFormat.java": 49,
                "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/TestInputFormat.java": 65
            },
            "is_test": true,
            "is_fix": true
        },
        "6b605a4ea05b66e1a6bf843353abcb4834a4ced8": {
            "datetime": "2015-11-04T09:13:09-08:00",
            "summary": "PARQUET-77: ByteBuffer use in read and write paths",
            "message": "PARQUET-77: ByteBuffer use in read and write paths\n\nThis work is based on the GSOC project from the summer of 2014. We have expanded on it to fix bugs and change the write path to use ByteBuffers as well. This PR replaces the earlier PRs #6, #49 and #50\n\nAuthor: Jason Altekruse <altekrusejason@gmail.com>\nAuthor: sunyu <stormdsy@gmail.com>\nAuthor: adeneche <adeneche@gmail.com>\nAuthor: Jacques Nadeau <jacques@apache.org>\nAuthor: Parth Chandra <pchandra@maprtech.com>\nAuthor: stormdsy@gmail.com <stormdsy@gmail.com>\nAuthor: Jason Altekruse <altekrusejason@open-math.com>\nAuthor: dsy <stormdsy@gmail.com>\nAuthor: Steven Phillips <sphillips@maprtech.com>\nAuthor: Gera Shegalov <gera@twitter.com>\nAuthor: Ryan Blue <blue@apache.org>\n\nCloses #267 from jaltekruse/1.6.0rc3-drill-r0.3-merge and squashes the following commits:\n\n56316d0 [Jason Altekruse] An exception out of the read method doesn't necessarily mean something is very wrong, so it shouldn't get wrapped in a ShouldNeverHappenException. This invocationTargetException will wrap any kind of exception coming out of the method, including an IOException.\n58340d8 [Jason Altekruse] Fix CompatibilityUtil, primary issue was a small error in the package name for the class that was being used to detect if the Hadoop 2.x API was available.\n96e19a8 [Jason Altekruse] Properly set the byte buffer position when reading out of a filesystem that does not implement the byte buffer based read method in the Hadoop 2.x API.\n269daef [Jason Altekruse] Make CodecFactory public\nbd7aa97 [Jason Altekruse] Remove unused imports, one of which has been moved to package private and is no longer accessible in this class.\na44fdba [Jason Altekruse] Fix logging and restrict access to classes inside of CodecFactory.\n723701c [Jason Altekruse] Adding isDirect interface to ByteBufferAllocator to add a restriction on the allocators used by a DirectCodecFactory.\n10b5ba3 [Jason Altekruse] Remove unneeded TODO\n57491a2 [Jason Altekruse] Delete older version of test file, all of these tests look to be covered in the newer version.\nd6501b1 [Jason Altekruse] Thought I had fixed this double deallocation earlier, guess the change got lost somewhere.\na8d2dc1 [Jason Altekruse] Address review comments.\n40714a4 [Jason Altekruse] Move pageSize to the constructor of codecfactory rather than the method for getting a compressor.\ndf7fd9c [Jason Altekruse] Limit access to classes and methods used for reflection based access to Hadoop 2.0 compression APIs.\n192c717 [Jason Altekruse] Fix error message\n1a47767 [Jason Altekruse] Address review comments\n5869156 [Jason Altekruse] Move fallback classes from HeapCodecFactory to the DirectCodecFactory\n3945674 [Jason Altekruse] Switch to using the DirectCodecFactory everywhere, one test is failing form the command line that is passing in intellij.\ne7f7f7f [Jason Altekruse] WIP - removing unneeded generics form CodecFactories\n659230f [Jason Altekruse] Remove second version of the class ByteBufferBytesInput that was nested in DirectCodecFactory. Replace with the one that was declared in the BytesInput class.\nc305984 [Jason Altekruse] Adding back code generation for method to take a byte array as well as the new implementation that takes a Bytebuffer.\nb8f54c2 [Jason Altekruse] Add a unit test for ByteBufferBackedBinary.\nae58486 [Jason Altekruse] Changing argument lists that previously included both an allocator and a ParquetProperties object.\nb4266fb [Jason Altekruse] Add license header to new class\nf8e5988 [Jason Altekruse] Added javadocs, removed unused code in DirectCodecFactory\nd332ca7 [Jason Altekruse] Add test for UnsignedVarIntBytesInput\nb7a6457 [Jason Altekruse] fix license leader\n8ff878a [Jason Altekruse] Addressing review comments\n862eb13 [Jason Altekruse] Fix usage of old constructor in Thrift module that caused a compilation failure. I had been skipping this module entirely during my work as the tests will fail to compile without a binary version of thrift 0.7, which seems hard to come by or compile yourself on Mac OS X.\n0496350 [Jason Altekruse] Add unit test for direct codec factory.\nda1b52a [Jason Altekruse] Moving classes into parquet from Drill.\n2f1a6c7 [Jason Altekruse] Consolidate a little more code\n8f66e43 [Jason Altekruse] Create utility methods to transform checked exceptions to unchecked when using reflection.\nf217e6a [Jason Altekruse] Restore old interfaces\nd5536b6 [Jason Altekruse] Restore original name of CapacityByteArrayOutputStream to keep compatibility with 1.7\n4c3195e [Jason Altekruse] Turn back on SemVer\n2e95915 [Jason Altekruse] Addressing minor review comments, comments out code, star import, formatting\na793be8 [Jason Altekruse] Add closeQuietly method to convert checked  IOExceptions from classless into runtime exceptions. Remove a bunch of unused imports from when there were previously try catch blocks that did this wrapping themselves (many actually were refactored to remove any need for special exception handling in an earlier commit, only one is actually using the new method).\nfdb689c [Jason Altekruse] Remove unnecessary copy writing a Binary to an OutputStream if it is backed by a byte array.\nd4819b4 [Jason Altekruse] remove methods now unneccesary as same implementation has been moved to the base class.\nad58bbe [Jason Altekruse] Addressing small review comments, unused imports, doc cleanup, etc.\n9fb65dd [Jason Altekruse] Rename method to get a dictionary page to clarify that the dictionary will be closed and not available for further insertion.\ne79684e [Jason Altekruse] Review comments - fixing use of ParquetProperties and removing unused interfaces on PageWriter\nb1040a8 [Jason Altekruse] Remove code used to debug a test that was failing after the initial merge.\n9dccb94 [Jason Altekruse] Add new method to turn BytesInput into an InputStream.\nf0e31ec [Jason Altekruse] revert small formatting and renaming changes, TODO make sure these result in a net diff of no changes (or only intended functional changes)\n0098b1c [Jason Altekruse] Remove unused method\n8c6e4a9 [Jason Altekruse] Addressing review comments, moving code out of generated class into abstract base class.\n29cc747 [Jason Altekruse] Factor out common code\n6959db7 [Jason Altekruse] addressing review comments, avoiding unnecessary copies when creating ByteBuffers\nfec4242 [Jason Altekruse] Address review comments - factoring out code in tests\n104a1d1 [Jason Altekruse] Remove test requiring a hard-coded binary file. This was actually a bad file being produced by Drill because we were not flushing the RecordConsumer.\n86317b0 [Jason Altekruse] Address review comments, make field in immutable ParquetProperties object final, make an interface now expecting a ByteBuffer deprecated for the version that takes a byte[].\n1971fc5 [Jason Altekruse] Fixes made while debugging drill unit tests\nebae775 [Jason Altekruse] Fix issue reading page data into an off-heap ByteBuffer\n705b864 [Jason Altekruse] Rename CapacityByteArrayOutputStream to CapacityByteBufferOutputStream to reflect new implementation internals. Add close method to CapacityByteBufferOutputStream and a few other classes.\n35d8386 [Jason Altekruse] Move call to getBytes() on dictionaryPages to remove the need to cache a list of dictionaryEncoders to be closed later.\nd40706b [Jason Altekruse] Get rid of unnecessary calls to Bytebuffer.wrap(byte[]), as an interface that takes a byte array is still available.\nfddd4af [Jason Altekruse] WIP - removing copies from the ByteBufferBasedBinary equals, compareTo, hashCode methods. Current tests are passing, but I should add some new ones.\n829af6f [Jason Altekruse] WIP - getting rid of unnecessary copies in Binary.java\n23ad48e [Jason Altekruse] WIP - addressing review comments\n7e252f3 [Jason Altekruse] WIP - addressing review comments\n1f4f504 [Jason Altekruse] WIP - addressing review comments\nab54c4e [Jason Altekruse] Moving classes out of the old packages.\n45cadee [Jason Altekruse] Cleaning up code in Binary after merge.\n864b011 [Jason Altekruse] Simplifying how buffer allocators are passed when creating ValuesWriters.\n2b8328b [Jason Altekruse] I all of the tests are now passing after the merge.\n1bfa3a0 [Jason Altekruse] Merge branch 'master' into 1.6.0rc3-drill-r0.3-merge\n9bbc269 [Jacques Nadeau] Update to 1.6.0rc3-drill-r0.3\n9f22bd7 [Jacques Nadeau] Make CodecFactory pluggable\n4a9dd28 [Jacques Nadeau] update pom version\n173aa25 [Jacques Nadeau] Set max preferred slab size to 16mb\nc98ec2a [adeneche] bumped version to 1.6.0rc3-drill-r0.1\n51cf2f1 [Ryan Blue] cherry pick pull#188\ne1df3b9 [adeneche] disabled enforcer and changed version to -drill\n6943536 [adeneche] fixing bug related to testDictionaryError_419\n48cceef [Steven Phillips] Fix allocation in DictionaryValuesWriter\n98b99ea [Parth Chandra] Revert readFooter to not use ZeroCopy path.\na6389db [Steven Phillips] Make constructor for PrimitiveType that takes decimalMetadata public.\ne488924 [adeneche] after merge code cleanup\n35b10af [Parth Chandra] Use ByteBuffers in the Write path. Allow callers to pass in an allocator to allocate the ByteBuffer.\n2187697 [Jacques Nadeau] Update Binary to make a copy of data for initial statistics.\n8143174 [adeneche] update pig.version to build with Hadoop 2 jars\n2c2b183 [Parth Chandra] Remove Zero Copy read path while reading footers\n7bc2a4d [Parth Chandra] Make a copy of Min and Max values for BinaryStatistics so that direct memory can be released before stats are written.\n5bc8774 [Parth Chandra] Update Snappy Codec to implement DirectDecompressionCodec interface Add compatibility function to read directly into a byte buffer\n0d22908 [adeneche] merging with master\n8be638a [sunyu] Address tsdeng's comments\n861e541 [dsy] enable enforcer check.\n912cbaf [sunyu] fix a bug in equals in ByteBuffer Binary with offset and length\n016e89c [sunyu] remove some unncessary codes. add compatible method initFromPage in ValueReaders. add toByteBuffer method in ByteBufferInputStream. add V21FileAPI class to encapsulate v21 APIs and make it a singlton. add ByteBuffer based equal and compareto method in Binary.\n26dc879 [dsy] disable enforcer to pass build.\na7bcfbb [sunyu] Make BytePacker consume ByteBuffer directly.\n01c2ae5 [sunyu] Implement FSDISTransport in Compatible layer. Fix bugs in Binary.\n47b177d [sunyu] Move CompatibilityUtil to parquet.hadoop.util. Use reflect to call new API to keep compatible.\n970fc8b [stormdsy@gmail.com] Add a Hadoop compatible layer to abstract away the zero copy API and old API.\n4f399aa [stormdsy@gmail.com] Add original readIntLittleEndian function to keep compatible with previous verision.\n7ac1df5 [stormdsy@gmail.com] Using Writable Channel to replace write to OutputStream one by one.\n36aba13 [sunyu] Read from ByteBuffer instead of ByteArray to avoid unnecessary array copy through read path.\n53500d4 [sunyu] Add ByteBufferInputStream and modify Chunk to consume ByteBuffer instead of byte array.\ndf1ad93 [stormdsy@gmail.com] Reading chunk using zero-copy API\n2d32f49 [Gera Shegalov] Reading file metadata using zero-copy API\n686d598 [Gera Shegalov] Use ByteBuf-based api to read magic.\n",
            "diff": {
                "parquet-column/src/main/java/org/apache/parquet/column/ColumnWriteStore.java": 6,
                "parquet-column/src/main/java/org/apache/parquet/column/ColumnWriter.java": 11,
                "parquet-column/src/main/java/org/apache/parquet/column/ParquetProperties.java": 53,
                "parquet-column/src/main/java/org/apache/parquet/column/impl/ColumnReaderImpl.java": 11,
                "parquet-column/src/main/java/org/apache/parquet/column/impl/ColumnWriteStoreV1.java": 14,
                "parquet-column/src/main/java/org/apache/parquet/column/impl/ColumnWriteStoreV2.java": 11,
                "parquet-column/src/main/java/org/apache/parquet/column/impl/ColumnWriterV1.java": 22,
                "parquet-column/src/main/java/org/apache/parquet/column/impl/ColumnWriterV2.java": 27,
                "parquet-column/src/main/java/org/apache/parquet/column/page/PageWriter.java": 2,
                "parquet-column/src/main/java/org/apache/parquet/column/values/ValuesReader.java": 19,
                "parquet-column/src/main/java/org/apache/parquet/column/values/ValuesWriter.java": 13,
                "parquet-column/src/main/java/org/apache/parquet/column/values/bitpacking/BitPackingValuesReader.java": 13,
                "parquet-column/src/main/java/org/apache/parquet/column/values/bitpacking/BitPackingValuesWriter.java": 10,
                "parquet-column/src/main/java/org/apache/parquet/column/values/bitpacking/ByteBitPackingValuesReader.java": 14,
                "parquet-column/src/main/java/org/apache/parquet/column/values/bitpacking/ByteBitPackingValuesWriter.java": 1,
                "parquet-column/src/main/java/org/apache/parquet/column/values/boundedint/BitReader.java": 7,
                "parquet-column/src/main/java/org/apache/parquet/column/values/boundedint/BitWriter.java": 12,
                "parquet-column/src/main/java/org/apache/parquet/column/values/boundedint/BoundedIntValuesFactory.java": 5,
                "parquet-column/src/main/java/org/apache/parquet/column/values/boundedint/BoundedIntValuesReader.java": 5,
                "parquet-column/src/main/java/org/apache/parquet/column/values/boundedint/BoundedIntValuesWriter.java": 10,
                "parquet-column/src/main/java/org/apache/parquet/column/values/boundedint/ZeroIntegerValuesReader.java": 3,
                "parquet-column/src/main/java/org/apache/parquet/column/values/delta/DeltaBinaryPackingValuesReader.java": 15,
                "parquet-column/src/main/java/org/apache/parquet/column/values/delta/DeltaBinaryPackingValuesWriter.java": 17,
                "parquet-column/src/main/java/org/apache/parquet/column/values/deltalengthbytearray/DeltaLengthByteArrayValuesReader.java": 11,
                "parquet-column/src/main/java/org/apache/parquet/column/values/deltalengthbytearray/DeltaLengthByteArrayValuesWriter.java": 14,
                "parquet-column/src/main/java/org/apache/parquet/column/values/deltastrings/DeltaByteArrayReader.java": 5,
                "parquet-column/src/main/java/org/apache/parquet/column/values/deltastrings/DeltaByteArrayWriter.java": 14,
                "parquet-column/src/main/java/org/apache/parquet/column/values/dictionary/DictionaryValuesReader.java": 13,
                "parquet-column/src/main/java/org/apache/parquet/column/values/dictionary/DictionaryValuesWriter.java": 88,
                "parquet-column/src/main/java/org/apache/parquet/column/values/dictionary/PlainValuesDictionary.java": 26,
                "parquet-column/src/main/java/org/apache/parquet/column/values/fallback/FallbackValuesWriter.java": 12,
                "parquet-column/src/main/java/org/apache/parquet/column/values/plain/BinaryPlainValuesReader.java": 10,
                "parquet-column/src/main/java/org/apache/parquet/column/values/plain/BooleanPlainValuesReader.java": 5,
                "parquet-column/src/main/java/org/apache/parquet/column/values/plain/BooleanPlainValuesWriter.java": 6,
                "parquet-column/src/main/java/org/apache/parquet/column/values/plain/FixedLenByteArrayPlainValuesReader.java": 9,
                "parquet-column/src/main/java/org/apache/parquet/column/values/plain/FixedLenByteArrayPlainValuesWriter.java": 13,
                "parquet-column/src/main/java/org/apache/parquet/column/values/plain/PlainValuesReader.java": 15,
                "parquet-column/src/main/java/org/apache/parquet/column/values/plain/PlainValuesWriter.java": 11,
                "parquet-column/src/main/java/org/apache/parquet/column/values/rle/RunLengthBitPackingHybridDecoder.java": 8,
                "parquet-column/src/main/java/org/apache/parquet/column/values/rle/RunLengthBitPackingHybridEncoder.java": 10,
                "parquet-column/src/main/java/org/apache/parquet/column/values/rle/RunLengthBitPackingHybridValuesReader.java": 7,
                "parquet-column/src/main/java/org/apache/parquet/column/values/rle/RunLengthBitPackingHybridValuesWriter.java": 10,
                "parquet-column/src/main/java/org/apache/parquet/io/api/Binary.java": 214,
                "parquet-column/src/main/java/org/apache/parquet/schema/PrimitiveType.java": 7,
                "parquet-column/src/test/java/org/apache/parquet/column/impl/TestColumnReaderImpl.java": 1,
                "parquet-column/src/test/java/org/apache/parquet/column/impl/TestCorruptDeltaByteArrays.java": 59,
                "parquet-column/src/test/java/org/apache/parquet/column/mem/TestMemColumn.java": 3,
                "parquet-column/src/test/java/org/apache/parquet/column/page/mem/MemPageWriter.java": 1,
                "parquet-column/src/test/java/org/apache/parquet/column/values/Utils.java": 5,
                "parquet-column/src/test/java/org/apache/parquet/column/values/bitpacking/BitPackingPerfTest.java": 3,
                "parquet-column/src/test/java/org/apache/parquet/column/values/bitpacking/TestBitPackingColumn.java": 6,
                "parquet-column/src/test/java/org/apache/parquet/column/values/boundedint/TestBoundedColumns.java": 11,
                "parquet-column/src/test/java/org/apache/parquet/column/values/delta/DeltaBinaryPackingValuesWriterTest.java": 12,
                "parquet-column/src/test/java/org/apache/parquet/column/values/delta/benchmark/BenchmarkIntegerOutputSize.java": 5,
                "parquet-column/src/test/java/org/apache/parquet/column/values/delta/benchmark/BenchmarkReadingRandomIntegers.java": 8,
                "parquet-column/src/test/java/org/apache/parquet/column/values/delta/benchmark/RandomWritingBenchmarkTest.java": 7,
                "parquet-column/src/test/java/org/apache/parquet/column/values/delta/benchmark/SmallRangeWritingBenchmarkTest.java": 3,
                "parquet-column/src/test/java/org/apache/parquet/column/values/deltalengthbytearray/TestDeltaLengthByteArray.java": 13,
                "parquet-column/src/test/java/org/apache/parquet/column/values/deltalengthbytearray/benchmark/BenchmarkDeltaLengthByteArray.java": 5,
                "parquet-column/src/test/java/org/apache/parquet/column/values/deltastrings/TestDeltaByteArray.java": 9,
                "parquet-column/src/test/java/org/apache/parquet/column/values/deltastrings/benchmark/BenchmarkDeltaByteArray.java": 9,
                "parquet-column/src/test/java/org/apache/parquet/column/values/dictionary/TestDictionary.java": 50,
                "parquet-column/src/test/java/org/apache/parquet/column/values/rle/RunLengthBitPackingHybridIntegrationTest.java": 10,
                "parquet-column/src/test/java/org/apache/parquet/column/values/rle/TestRunLengthBitPackingHybridEncoder.java": 30,
                "parquet-column/src/test/java/org/apache/parquet/io/PerfTest.java": 3,
                "parquet-column/src/test/java/org/apache/parquet/io/TestColumnIO.java": 24,
                "parquet-column/src/test/java/org/apache/parquet/io/TestFiltered.java": 3,
                "parquet-column/src/test/java/org/apache/parquet/io/api/TestBinary.java": 25,
                "parquet-common/src/main/java/org/apache/parquet/IOExceptionUtils.java": 43,
                "parquet-common/src/main/java/org/apache/parquet/OutputStreamCloseException.java": 46,
                "parquet-common/src/main/java/org/apache/parquet/ParquetRuntimeException.java": 4,
                "parquet-common/src/main/java/org/apache/parquet/bytes/ByteBufferAllocator.java": 38,
                "parquet-common/src/main/java/org/apache/parquet/bytes/ByteBufferInputStream.java": 82,
                "parquet-common/src/main/java/org/apache/parquet/bytes/BytesUtils.java": 24,
                "parquet-common/src/main/java/org/apache/parquet/bytes/DirectByteBufferAllocator.java": 43,
                "parquet-common/src/main/java/org/apache/parquet/bytes/HeapByteBufferAllocator.java": 44,
                "parquet-encoding/src/main/java/org/apache/parquet/bytes/BytesInput.java": 84,
                "parquet-encoding/src/main/java/org/apache/parquet/bytes/CapacityByteArrayOutputStream.java": 115,
                "parquet-encoding/src/main/java/org/apache/parquet/bytes/LittleEndianDataOutputStream.java": 7,
                "parquet-encoding/src/main/java/org/apache/parquet/column/values/bitpacking/BytePacker.java": 21,
                "parquet-encoding/src/test/java/org/apache/parquet/bytes/TestBytesInput.java": 42,
                "parquet-encoding/src/test/java/org/apache/parquet/bytes/TestCapacityByteArrayOutputStream.java": 6,
                "parquet-encoding/src/test/java/org/apache/parquet/column/values/bitpacking/TestByteBitPacking.java": 5,
                "parquet-encoding/src/test/java/org/apache/parquet/column/values/bitpacking/TestLemireBitPacking.java": 3,
                "parquet-generator/src/main/java/org/apache/parquet/encoding/bitpacking/ByteBasedBitPackingGenerator.java": 26,
                "parquet-hadoop/src/main/java/org/apache/parquet/format/converter/ParquetMetadataConverter.java": 1,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/CodecFactory.java": 173,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ColumnChunkPageReadStore.java": 6,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ColumnChunkPageWriteStore.java": 34,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/DirectCodecFactory.java": 522,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/InternalParquetRecordWriter.java": 21,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ParquetFileReader.java": 81,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ParquetFileWriter.java": 3,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ParquetOutputFormat.java": 5,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ParquetRecordWriter.java": 14,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ParquetWriter.java": 8,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/codec/SnappyDecompressor.java": 3,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/util/CompatibilityUtil.java": 114,
                "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/TestColumnChunkPageWriteStore.java": 9,
                "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/TestDirectCodecFactory.java": 165,
                "parquet-pig/src/test/java/org/apache/parquet/pig/TupleConsumerPerfTest.java": 3,
                "parquet-thrift/src/test/java/org/apache/parquet/thrift/TestParquetReadProtocol.java": 4
            },
            "is_test": true,
            "is_fix": false
        },
        "440882c659967572311402c7fe534cf13d501cf4": {
            "datetime": "2015-11-17T15:09:50-08:00",
            "summary": "PARQUET-364: Fix compatibility for Avro lists of lists.",
            "message": "PARQUET-364: Fix compatibility for Avro lists of lists.\n\nThis fixes lists of lists that have been written with Avro's 2-level\nrepresentation. The conversion setup logic missed the case where the\ninner field is repeated and cannot be the element in a 3-level list.\n\nThis also fixes the schema conversion for cases where an unknown\nwriter used a 2-level list of lists.\n\nThis is based on @liancheng's #264 but fixes the problem in a slightly different way.\n\nAuthor: Ryan Blue <blue@apache.org>\n\nCloses #272 from rdblue/PARQUET-364-fix-avro-lists-of-lists and squashes the following commits:\n\n41a70e0 [Ryan Blue] PARQUET-364: Fix compatibility for Avro lists of lists.\n",
            "diff": {
                "parquet-avro/src/main/java/org/apache/parquet/avro/AvroIndexedRecordConverter.java": 36,
                "parquet-avro/src/main/java/org/apache/parquet/avro/AvroRecordConverter.java": 8,
                "parquet-avro/src/main/java/org/apache/parquet/avro/AvroSchemaConverter.java": 10,
                "parquet-avro/src/test/java/org/apache/parquet/avro/TestArrayCompatibility.java": 148,
                "parquet-avro/src/test/java/org/apache/parquet/avro/TestAvroSchemaConverter.java": 92
            },
            "is_test": true,
            "is_fix": true
        },
        "efafa61992658eab64c893e9eef49f545d75673c": {
            "datetime": "2015-11-19T10:46:07-08:00",
            "summary": "PARQUET-378: Add thoroughly parquet test encodings",
            "message": "PARQUET-378: Add thoroughly parquet test encodings\n\nA new test case TestTypeEncodings is added that test v1 and v2 encodings for all\nsupported column types. This test case spans many pages and row groups, and reads\neach page individually from first-to-last and from last-to-first.\n\nAuthor: Sergio Pena <sergio.pena@cloudera.com>\n\nCloses #274 from spena/parquet-378 and squashes the following commits:\n\nb35c339 [Sergio Pena] PARQUET-378: Add thoroughly parquet test encodings\n",
            "diff": {
                "parquet-hadoop/src/test/java/org/apache/parquet/encodings/FileEncodingsIT.java": 490,
                "parquet-hadoop/src/test/java/org/apache/parquet/statistics/RandomValues.java": 18
            },
            "is_test": true,
            "is_fix": false
        },
        "630830476a6270e317e84229996a6bf92bd903ca": {
            "datetime": "2015-11-30T16:26:37-08:00",
            "summary": "PARQUET-396: Extend ParquetReader.Builder<T>",
            "message": "PARQUET-396: Extend ParquetReader.Builder<T>\n\nIn AvroParquetReader.Builder extend ParquetReader.Builder<T>\n\nAuthor: Chris Bannister <c.bannister@gmail.com>\n\nCloses #294 from Zariel/PARQUET-396 and squashes the following commits:\n\n79c1d0e [Chris Bannister] PARQUET-396: Extend ParquetReader.Builder<T>\n",
            "diff": {
                "parquet-avro/src/main/java/org/apache/parquet/avro/AvroParquetReader.java": 2
            },
            "is_test": false,
            "is_fix": false
        },
        "14097c64d243794610788d3ebb2e81ba8fd867c0": {
            "datetime": "2015-12-04T11:47:38-08:00",
            "summary": "PARQUET-387: Improve NPE message when avro arrays contain null.",
            "message": "PARQUET-387: Improve NPE message when avro arrays contain null.\n\nPreviously, the NPE had no error message but the Avro support accepts\nschemas that have nullable array elements.\n\nAuthor: Ryan Blue <blue@apache.org>\n\nCloses #291 from rdblue/PARQUET-387-fix-npe-message and squashes the following commits:\n\n39d3c83 [Ryan Blue] PARQUET-387: Update test case to verify help message.\nd6b6bd8 [Ryan Blue] PARQUET-387: Improve NPE message when avro arrays contain null.\n",
            "diff": {
                "parquet-avro/src/main/java/org/apache/parquet/avro/AvroWriteSupport.java": 38,
                "parquet-avro/src/test/java/org/apache/parquet/avro/TestReadWriteOldListBehavior.java": 4
            },
            "is_test": true,
            "is_fix": true
        },
        "f2615d9a611db401cdedc022112c87ad938b5680": {
            "datetime": "2015-12-08T10:02:31-08:00",
            "summary": "PARQUET-349: VersionParser does not handle versions missing 'build' section",
            "message": "PARQUET-349: VersionParser does not handle versions missing 'build' section\n\nThis change reworks the regular expression in VersionParser.java to allow for missing 'version' and 'build' sections.\n\nAuthor: Reuben Kuhnert <reuben.kuhnert@cloudera.com>\n\nCloses #283 from sircodesalotOfTheRound/fix-version-test and squashes the following commits:\n\n0f4a22f [Reuben Kuhnert] PARQUET-349: VersionParser does not handle versions missing 'build' section.\n",
            "diff": {
                "parquet-common/src/main/java/org/apache/parquet/VersionParser.java": 6,
                "parquet-common/src/test/java/org/apache/parquet/VersionTest.java": 17
            },
            "is_test": true,
            "is_fix": true
        },
        "dcd1c33f0dba247b43418b922c1c3a2fc432dc11": {
            "datetime": "2015-12-08T10:15:30-08:00",
            "summary": "PARQUET-352: Add object model property to file footers.",
            "message": "PARQUET-352: Add object model property to file footers.\n\nWriteSupport now has a getName getter method that is added to the footer\nif it returns a non-null string as writer.model.name. This is intended\nto help identify files written by object models incorrectly.\n\nAuthor: Ryan Blue <blue@apache.org>\n\nCloses #289 from rdblue/PARQUET-352-add-object-model-property and squashes the following commits:\n\n23f8f67 [Ryan Blue] PARQUET-352: Add object model property to file footers.\n",
            "diff": {
                "parquet-avro/src/main/java/org/apache/parquet/avro/AvroWriteSupport.java": 5,
                "parquet-cascading/src/main/java/org/apache/parquet/cascading/TupleWriteSupport.java": 5,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/InternalParquetRecordWriter.java": 4,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ParquetWriter.java": 2,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/api/DelegatingWriteSupport.java": 5,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/api/WriteSupport.java": 12,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/example/GroupWriteSupport.java": 5,
                "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/TestParquetWriter.java": 3,
                "parquet-pig/src/main/java/org/apache/parquet/pig/TupleWriteSupport.java": 5,
                "parquet-protobuf/src/main/java/org/apache/parquet/proto/ProtoWriteSupport.java": 5,
                "parquet-scrooge/src/main/java/org/apache/parquet/scrooge/ScroogeWriteSupport.java": 5,
                "parquet-thrift/src/main/java/org/apache/parquet/hadoop/thrift/TBaseWriteSupport.java": 5,
                "parquet-thrift/src/main/java/org/apache/parquet/hadoop/thrift/ThriftBytesWriteSupport.java": 5,
                "parquet-thrift/src/main/java/org/apache/parquet/hadoop/thrift/ThriftWriteSupport.java": 5,
                "parquet-thrift/src/main/java/org/apache/parquet/thrift/pig/TupleToThriftWriteSupport.java": 5
            },
            "is_test": true,
            "is_fix": true
        },
        "a24d624aaabc14a455d18450d9127f88d1b4f8be": {
            "datetime": "2015-12-08T10:39:47-08:00",
            "summary": "PARQUET-305: Update logging to SLF4J.",
            "message": "PARQUET-305: Update logging to SLF4J.\n\nThis removes the Log implementation based on java.util.logging and\nreplaces it with SLF4J. The compiler removal of debug log messages still\nworks because Log.DEBUG and similar final constants are unchanged.\n\nThis commit adds slf4j-simple as the test logger implementation.\nConfiguration for slf4j-simple is in the root pom. Two modules can't use\nslf4j-simple, parquet-pig and parquet-thrift, and use slf4j-log4j12\ninstead because pig depends on log4j and tests die without it.\n\nAuthor: Ryan Blue <blue@apache.org>\n\nCloses #290 from rdblue/PARQUET-305-update-logging and squashes the following commits:\n\n89257e8 [Ryan Blue] PARQUET-305: Remove deprecation annotations on Log.\n9f9b99a [Ryan Blue] PARQUET-305: Update logging to SLF4J.\n",
            "diff": {
                "parquet-common/src/main/java/org/apache/parquet/Log.java": 87
            },
            "is_test": false,
            "is_fix": false
        },
        "56326400fcb5df7bd9336f143f7a3b7d601e5f58": {
            "datetime": "2015-12-08T14:41:38-08:00",
            "summary": "PARQUET-99: Add page size check properties",
            "message": "PARQUET-99: Add page size check properties\n\nThis adds properties to set the min and max number of records that are passed between page checks, as well as a property that controls whether the next check will be based on records already seen or set to the minimum number of records between checks.\n\n* `parquet.page.size.row.check.min` - minimum number of records between page size checks\n* `parquet.page.size.row.check.max` - maximum number of records between page size checks\n* `parquet.page.size.check.estimate` - whether to estimate the number of records before the next check, or to always use the minimum number of records.\n\nThis also updates the internal API to use ParquetProperties to carry encoding settings (used in parquet-column) to reduce the number of parameters passed through internal APIs. It also adds a builder for ParquetProperties to avoid needing to reference defaults in other modules.\n\nThis closes #250\n\nAuthor: Daniel Weeks <dweeks@netflix.com>\nAuthor: Ryan Blue <blue@apache.org>\n\nCloses #297 from rdblue/parquet-properties-update and squashes the following commits:\n\nc93b73e [Ryan Blue] PARQUET-99: Use ParquetProperties to carry encoding config.\n18f8d3a [Daniel Weeks] Spacing\n2090719 [Daniel Weeks] Update sizeCheck to write page properly if estimating is turned off\n71336ee [Daniel Weeks] Fixed param name\n5d99072 [Daniel Weeks] Update page size checking for v2 writer\n3f7870c [Daniel Weeks] Rebase to resolve byte buffer conflicts\n68794f0 [Daniel Weeks] Merge branch 'master' into page_size_check\nb49f03c [Daniel Weeks] Fixed reset of nextSizeCheck\na057f46 [Daniel Weeks] Fixed inverted property logic\ne7cd54b [Daniel Weeks] Added property to toggle page size check estimation and initial row size checking\n",
            "diff": {
                "parquet-column/src/main/java/org/apache/parquet/column/ParquetProperties.java": 245,
                "parquet-column/src/main/java/org/apache/parquet/column/impl/ColumnWriteStoreV1.java": 19,
                "parquet-column/src/main/java/org/apache/parquet/column/impl/ColumnWriteStoreV2.java": 48,
                "parquet-column/src/main/java/org/apache/parquet/column/impl/ColumnWriterV1.java": 48,
                "parquet-column/src/main/java/org/apache/parquet/column/impl/ColumnWriterV2.java": 15,
                "parquet-column/src/test/java/org/apache/parquet/column/impl/TestColumnReaderImpl.java": 11,
                "parquet-column/src/test/java/org/apache/parquet/column/impl/TestCorruptDeltaByteArrays.java": 6,
                "parquet-column/src/test/java/org/apache/parquet/column/mem/TestMemColumn.java": 9,
                "parquet-column/src/test/java/org/apache/parquet/io/PerfTest.java": 10,
                "parquet-column/src/test/java/org/apache/parquet/io/TestColumnIO.java": 10,
                "parquet-column/src/test/java/org/apache/parquet/io/TestFiltered.java": 10,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/InternalParquetRecordWriter.java": 23,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ParquetOutputFormat.java": 71,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ParquetRecordWriter.java": 47,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ParquetWriter.java": 55,
                "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/TestUtils.java": 7,
                "parquet-pig/src/test/java/org/apache/parquet/pig/TupleConsumerPerfTest.java": 9,
                "parquet-thrift/src/test/java/org/apache/parquet/thrift/TestParquetReadProtocol.java": 10
            },
            "is_test": true,
            "is_fix": false
        },
        "b45c4bdb496381b5f90df6872edca12e0a2e68ca": {
            "datetime": "2015-12-08T14:45:48-08:00",
            "summary": "PARQUET-382: Add methods to append encoded data to files.",
            "message": "PARQUET-382: Add methods to append encoded data to files.\n\nThis allows appending encoded data blocks to open ParquetFileWriters,\nwhich makes it possible to merge multiple Parquet files without\nre-encoding all of the records.\n\nThis works by finding the column chunk for each column in the file\nschema and then streaming the encoded data from one file to the other.\nNew starting offsets are tracked and the column chunk metadata in the\nfooter is updated with the new starting positions.\n\nAuthor: Ryan Blue <blue@apache.org>\n\nCloses #278 from rdblue/PARQUET-382-append-encoded-blocks and squashes the following commits:\n\ncb98552 [Ryan Blue] PARQUET-382: Add methods to append encoded data to files.\n",
            "diff": {
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ParquetFileReader.java": 9,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ParquetFileWriter.java": 160,
                "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/TestParquetWriterAppendBlocks.java": 310
            },
            "is_test": true,
            "is_fix": false
        },
        "49169033546d893dae3db903a2fa6af712f125c0": {
            "datetime": "2015-12-11T13:17:04-08:00",
            "summary": "PARQUET-353: Release compression resources.",
            "message": "PARQUET-353: Release compression resources.\n\nThis updates the use of CodecFactory in the output format and writer\nclasses so that its lifecycle is tied to ParquetWriter and\nParquetRecordWriter. When those classes are closed, the resources held\nby the CodecFactory associated with the instance are released.\n\nThis is an alternative to and closes #282.\n\nAuthor: Ryan Blue <blue@apache.org>\n\nCloses #295 from rdblue/PARQUET-353-release-compressor-resources and squashes the following commits:\n\na00f4b7 [Ryan Blue] PARQUET-353: Release compression resources.\n",
            "diff": {
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ParquetOutputFormat.java": 11,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ParquetRecordWriter.java": 51,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ParquetWriter.java": 6
            },
            "is_test": false,
            "is_fix": false
        },
        "fa7588c4c0f8d403e4815fa72e3b8a3bc98d73ec": {
            "datetime": "2015-12-12T15:35:21-08:00",
            "summary": "PARQUET-334: UT test failure with Pig 0.15",
            "message": "PARQUET-334: UT test failure with Pig 0.15\n\nI made a few updates to the original patch PARQUET-334-1.patch proposed by Daniel. As the inputschema is maintained in EvalFunc, any reference to the private class variable inputSchema should be changed to getInputSchema(), and inputSchema can be removed because it will be null always.\n\nAuthor: Thomas Friedrich <tfriedr@us.ibm.com>\n\nCloses #292 from tfriedr/parquet-334 and squashes the following commits:\n\n012563e [Thomas Friedrich] PARQUET_334: UT test failure with Pig 0.15\n",
            "diff": {
                "parquet-pig/src/main/java/org/apache/parquet/pig/summary/Summary.java": 56
            },
            "is_test": false,
            "is_fix": false
        },
        "367fe13b46a0b4dda56b7f12273d6c9afb1da23f": {
            "datetime": "2015-12-16T11:41:46-08:00",
            "summary": "PARQUET-318: Remove unnecessary object mapper",
            "message": "PARQUET-318: Remove unnecessary object mapper\n\nAuthor: Nezih Yigitbasi <nyigitbasi@netflix.com>\n\nCloses #227 from nezihyigitbasi/318 and squashes the following commits:\n\nb8e4ca9 [Nezih Yigitbasi] Remove unnecessary object mapper\n",
            "diff": {
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/metadata/ParquetMetadata.java": 19,
                "parquet-hadoop/src/test/java/org/apache/parquet/format/converter/TestParquetMetadataConverter.java": 12
            },
            "is_test": true,
            "is_fix": false
        },
        "368588b5c5c4140f39ea8b9a8ceb3d1af0708804": {
            "datetime": "2016-01-07T10:48:02-06:00",
            "summary": "PARQUET-413: Fix Java 8 test failure.",
            "message": "PARQUET-413: Fix Java 8 test failure.\n\nThe footer merge tests rely the order of unmergable values. This uses a\nLinkedHashSet to ensure the order doesn't change.\n\nAuthor: Ryan Blue <blue@apache.org>\n\nCloses #304 from rdblue/PARQUET-413-java-8-test-failure and squashes the following commits:\n\n57a83a8 [Ryan Blue] PARQUET-413: Fix Java 8 test failure.\n",
            "diff": {
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ParquetFileWriter.java": 3
            },
            "is_test": false,
            "is_fix": false
        },
        "37f72dc079c4cd69b2de16f3532b55f8108d3ac8": {
            "datetime": "2016-01-12T14:15:40-08:00",
            "summary": "PARQUET-212: Implement LIST read compatibility rules in Thrift",
            "message": "PARQUET-212: Implement LIST read compatibility rules in Thrift\n\nThis implements the read-side compatibility rules for 2-level and 3-level lists in Thrift.\n\nThrift doesn't allow null elements inside lists, but 3-level lists may have optional elements. This PR adds a property, parquet.thrift.ignore-null-elements, that allows thrift to read lists with optional elements by ignoring nulls. This is off by default, but is provided as an opt-in for compatibility with data written by Hive.\n\nThrift's schema conversion does not change because a Thrift class (or Scrooge etc.) must be set in a file's metadata or provided when constructing a reader.\n\nThis replaces and closes #144.\n\nAuthor: Ryan Blue <blue@apache.org>\n\nCloses #300 from rdblue/PARQUET-212-fix-thrift-3-level-lists and squashes the following commits:\n\nac7c405 [Ryan Blue] PARQUET-212: Add tests for list of list cases from PARQUET-364.\n356fdb7 [Ryan Blue] PARQUET-212: Rename isElementType => isListElementType.\n5d3b094 [Ryan Blue] PARQUET-212: Fix list handling with projection.\nb5f207f [Ryan Blue] PARQUET-212: Add Configuration to the ThriftRecordConverter ctor.\nb87eb65 [Ryan Blue] PARQUET-212: Add property to ignore nulls in lists.\n3d1e92f [Ryan Blue] PARQUET-212: Update thrift reads for LIST compatibility rules.\n0bf2b45 [Ryan Blue] PARQUET-212: Read non-thrift files if a Thrift class is supplied.\n4e148dc [Ryan Blue] PARQUET-212: Add DirectWriterTest base class.\n",
            "diff": {
                "parquet-avro/src/main/java/org/apache/parquet/avro/AvroRecordConverter.java": 13,
                "parquet-avro/src/test/java/org/apache/parquet/avro/TestArrayCompatibility.java": 76,
                "parquet-hadoop/src/test/java/org/apache/parquet/DirectWriterTest.java": 102,
                "parquet-scrooge/src/main/java/org/apache/parquet/scrooge/ScroogeRecordConverter.java": 13,
                "parquet-thrift/src/main/java/org/apache/parquet/hadoop/thrift/ThriftReadSupport.java": 63,
                "parquet-thrift/src/main/java/org/apache/parquet/thrift/TBaseRecordConverter.java": 12,
                "parquet-thrift/src/main/java/org/apache/parquet/thrift/ThriftMetaData.java": 21,
                "parquet-thrift/src/main/java/org/apache/parquet/thrift/ThriftRecordConverter.java": 123,
                "parquet-thrift/src/main/java/org/apache/parquet/thrift/ThriftSchemaConverter.java": 38,
                "parquet-thrift/src/test/java/org/apache/parquet/hadoop/thrift/TestArrayCompatibility.java": 779
            },
            "is_test": true,
            "is_fix": true
        },
        "84b2b74179da8e279e2fafdafd031748c285e1b7": {
            "datetime": "2016-01-12T14:21:32-08:00",
            "summary": "PARQUET-421: Fix mismatch of javadoc names and method parameters in m...",
            "message": "PARQUET-421: Fix mismatch of javadoc names and method parameters in m...\n\n\u2026odule encoding, column, and hadoop\n\nCodes change now and then, but some corresponding doc comments are left out.\n\nThis PR fixes only the doc comments that should have been changed. It should be OK, since none codes are touched.\n\n@rdblue could you take a look please? Cheers.\n\nAuthor: proflin <proflin.me@gmail.com>\n\nCloses #307 from proflin/Minor--Fix-the-mismatch-of-the-parameters-and-their-doc-comments-in-module-encoding,-column,-and-hadoop and squashes the following commits:\n\n34c7b01 [proflin] Minor: Fix the mismatch of the parameters and their doc comments in module encoding, column, and hadoop\n",
            "diff": {
                "parquet-column/src/main/java/org/apache/parquet/column/page/DataPageV1.java": 4,
                "parquet-column/src/main/java/org/apache/parquet/column/values/ValuesWriter.java": 14,
                "parquet-column/src/main/java/org/apache/parquet/column/values/plain/BooleanPlainValuesReader.java": 4,
                "parquet-column/src/main/java/org/apache/parquet/schema/TypeConverter.java": 2,
                "parquet-encoding/src/main/java/org/apache/parquet/column/values/bitpacking/BitPacking.java": 2,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/example/ExampleOutputFormat.java": 6,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/metadata/ParquetMetadata.java": 1
            },
            "is_test": false,
            "is_fix": false
        },
        "30ee10d2740fe1f28595989c6b21f22b75a147fc": {
            "datetime": "2016-01-12T14:45:24-08:00",
            "summary": "PARQUET-422: Fix a potential bug in MessageTypeParser where we ignore\u2026",
            "message": "PARQUET-422: Fix a potential bug in MessageTypeParser where we ignore\u2026\n\n\u2026 and overwrite the initial value of a method parameter\n\nIn org.apache.parquet.schema.MessageTypeParser, for addGroupType() and addPrimitiveType(), the initial value of this parameter t is ignored, and t is overwritten here.\n\nThis often indicates a mistaken belief that the write to the parameter will be conveyed back to the caller.\n\nThis is a bug found by FindBugs\u2122.\n\nAuthor: proflin <proflin.me@gmail.com>\n\nCloses #308 from proflin/PARQUET-422 and squashes the following commits:\n\ndf1f908 [proflin] PARQUET-422: Fix a potential bug in MessageTypeParser where we ignore and overwrite the initial value of a method parameter\n",
            "diff": {
                "parquet-column/src/main/java/org/apache/parquet/schema/MessageTypeParser.java": 14
            },
            "is_test": false,
            "is_fix": false
        },
        "c38386d6b5622915a2d42d989c56d37f17c673d6": {
            "datetime": "2016-01-28T17:33:08-08:00",
            "summary": "PARQUET-393: Update to parquet-format 2.3.1.",
            "message": "PARQUET-393: Update to parquet-format 2.3.1.\n\nAuthor: Ryan Blue <blue@apache.org>\n\nCloses #303 from rdblue/PARQUET-393-update-parquet-format-version and squashes the following commits:\n\n0e4c798 [Ryan Blue] PARQUET-393: Add TIME_MICROS and TIMESTAMP_MICROS.\nca4a741 [Ryan Blue] PARQUET-393: Update to parquet-format 2.3.1.\n",
            "diff": {
                "parquet-column/src/main/java/org/apache/parquet/schema/OriginalType.java": 2,
                "parquet-column/src/main/java/org/apache/parquet/schema/Types.java": 2,
                "parquet-column/src/test/java/org/apache/parquet/schema/TestTypeBuilders.java": 4,
                "parquet-hadoop/src/main/java/org/apache/parquet/format/converter/ParquetMetadataConverter.java": 9
            },
            "is_test": true,
            "is_fix": false
        },
        "af9fd052d1c208f191fbdf85873f965552465598": {
            "datetime": "2016-01-29T11:38:34-08:00",
            "summary": "PARQUET-432: Complete a todo for method ColumnDescriptor.compareTo()",
            "message": "PARQUET-432: Complete a todo for method ColumnDescriptor.compareTo()\n\nThe ticket proposes to consider the case *path.length < o.path.length* in, for method ColumnDescriptor.compareTo().\n\nAuthor: proflin <proflin.me@gmail.com>\n\nCloses #314 from proflin/PARQUET-432 and squashes the following commits:\n\n80ba94b [proflin] Addresses PR comments\n6ccd00f [proflin] Revert Updates\na4d2a4a [proflin] PARQUET-432: Complete a todo in method ColumnDescriptor.compareTo()\n694b76b [proflin] Updates\n",
            "diff": {
                "parquet-column/src/main/java/org/apache/parquet/column/ColumnDescriptor.java": 6,
                "parquet-column/src/test/java/org/apache/parquet/column/TestColumnDescriptor.java": 52
            },
            "is_test": true,
            "is_fix": false
        },
        "57694790f8ca0e1a4f3ac76fbd25a6dd13041e03": {
            "datetime": "2016-01-31T19:21:48-08:00",
            "summary": "PARQUET-480: Update for Cascading 3.0",
            "message": "PARQUET-480: Update for Cascading 3.0\n\nThe code in parquet-cascading is adapted to the API as of Cascading 2.5.3\n\nSome incompatible changes were introduced in Cascading 3.0. This patch forks the parquet-cascading module to also provide a parquet-cascading3 module, which is about identical save for overloads which changed from requiring a Foo<JobConf> to requiring a Foo<? extends JobConf>\n\nAuthor: Cyrille Ch\u00e9p\u00e9lov (TP12) <cch@transparencyrights.com>\n\nCloses #284 from cchepelov/try_cascading3 and squashes the following commits:\n\ne7d1304 [Cyrille Ch\u00e9p\u00e9lov (TP12)] Adding a @Deprecated notice on parquet-cascading's remaining classes\n05a417d [Cyrille Ch\u00e9p\u00e9lov (TP12)] cascading2/3: share back TupleWriteSupport.java (accidentally unmerged)\n7fff2d4 [Cyrille Ch\u00e9p\u00e9lov (TP12)] cascading/cascading3: remove duplicates, push common files into parquet-cascading-common23\n338a416 [Cyrille Ch\u00e9p\u00e9lov (TP12)] Removing unwanted file (what?!) + .gitignoring this kind of files\nd9f0455 [Cyrille Ch\u00e9p\u00e9lov (TP12)] TupleEntry#get is now TupleEntry#getObject\na7f490a [Cyrille Ch\u00e9p\u00e9lov (TP12)] Revert \"Missing test conversion to Cascading 3.0\"\ncc8b870 [Cyrille Ch\u00e9p\u00e9lov (TP12)] Missing test conversion to Cascading 3.0\n2d73512 [Cyrille Ch\u00e9p\u00e9lov (TP12)] conflicting values can come in one order or the other. Accept both.\n33355d5 [Cyrille Ch\u00e9p\u00e9lov (TP12)] Fix version mismatch (duh!)\n7128639 [Cyrille Ch\u00e9p\u00e9lov (TP12)] non-C locale can break tests implementation (decimal formats)\n53aa2f9 [Cyrille Ch\u00e9p\u00e9lov (TP12)] Adding a parquet-cascading3 module (forking the parquet-cascading module and accounting for API changes)\n",
            "diff": {
                "parquet-cascading/src/main/java/org/apache/parquet/cascading/ParquetTBaseScheme.java": 1,
                "parquet-cascading/src/main/java/org/apache/parquet/cascading/ParquetTupleScheme.java": 1,
                "parquet-cascading/src/main/java/org/apache/parquet/cascading/ParquetValueScheme.java": 1,
                "parquet-cascading/src/main/java/org/apache/parquet/cascading/SchemaIntersection.java": 0,
                "parquet-cascading/src/main/java/org/apache/parquet/cascading/TupleReadSupport.java": 0,
                "parquet-cascading/src/main/java/org/apache/parquet/cascading/TupleWriteSupport.java": 0,
                "parquet-cascading/src/main/java/org/apache/parquet/cascading/convert/TupleConverter.java": 0,
                "parquet-cascading/src/main/java/org/apache/parquet/cascading/convert/TupleRecordMaterializer.java": 0,
                "parquet-cascading/src/test/java/org/apache/parquet/cascading/TestParquetTBaseScheme.java": 3,
                "parquet-cascading/src/test/java/org/apache/parquet/cascading/TestParquetTupleScheme.java": 0,
                "parquet-cascading3/src/main/java/org/apache/parquet/cascading/ParquetTBaseScheme.java": 80,
                "parquet-cascading3/src/main/java/org/apache/parquet/cascading/ParquetTupleScheme.java": 191,
                "parquet-cascading3/src/main/java/org/apache/parquet/cascading/ParquetValueScheme.java": 184,
                "parquet-cascading3/src/test/java/org/apache/parquet/cascading/TestParquetTBaseScheme.java": 186,
                "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/TestMergeMetadataFiles.java": 10
            },
            "is_test": true,
            "is_fix": false
        },
        "63d5ae78ac00d710c9bf631f8cb9ed6d07e6a2c9": {
            "datetime": "2016-02-01T10:09:20-08:00",
            "summary": "PARQUET-495: Fix mismatches in Types class comments",
            "message": "PARQUET-495: Fix mismatches in Types class comments\n\nTo produce\n> required group User {\n    required int64 id;\n    **optional** binary email (UTF8);\n }\n\nwe should do:\n>\nTypes.requiredGroup()\n      .required(INT64).named(\"id\")\n      .~~**required** (BINARY).as(UTF8).named(\"email\")~~\n      .**optional** (BINARY).as(UTF8).named(\"email\")\n      .named(\"User\")\n\n@rdblue @liancheng would you mind taking a look at it when you have time? Thanks!\n\nAuthor: Liwei Lin <proflin.me@gmail.com>\nAuthor: proflin <proflin.me@gmail.com>\n\nCloses #317 from proflin/PARQUET-495--Fix-mismatches-in-Types-class-comments and squashes the following commits:\n\nf26d57d [Liwei Lin] PARQUET-495: Fix mismatches in Types class comments\n839b458 [proflin] Merge remote-tracking branch 'refs/remotes/apache/master'\n",
            "diff": {
                "parquet-column/src/main/java/org/apache/parquet/schema/Types.java": 6
            },
            "is_test": false,
            "is_fix": false
        },
        "06a4689959e361729c405e78b8a5964228cb521f": {
            "datetime": "2016-02-03T11:49:08-08:00",
            "summary": "PARQUET-410: Fix hanging subprocess call in merge script.",
            "message": "PARQUET-410: Fix hanging subprocess call in merge script.\n\nThis removes the option that redirects stderr to stdout because it\ncauses git push to hang.\n\nAuthor: Ryan Blue <blue@apache.org>\n\nCloses #302 from rdblue/PARQUET-410-fix-subprocess-hang and squashes the following commits:\n\n340c316 [Ryan Blue] PARQUET-410: Fix hanging subprocess call in merge script.\n",
            "diff": {
                "dev/merge_parquet_pr.py": 4
            },
            "is_test": false,
            "is_fix": false
        },
        "0a711ebcec7d32b66ab3c90b2a1f48681201e557": {
            "datetime": "2016-02-03T12:45:27-08:00",
            "summary": "PARQUET-415: Fix ByteBuffer Binary serialization.",
            "message": "PARQUET-415: Fix ByteBuffer Binary serialization.\n\nThis also adds a test to validate that serialization works for all\nBinary objects that are already test cases.\n\nAuthor: Ryan Blue <blue@apache.org>\n\nCloses #305 from rdblue/PARQUET-415-fix-bytebuffer-binary-serialization and squashes the following commits:\n\n4e75d54 [Ryan Blue] PARQUET-415: Fix ByteBuffer Binary serialization.\n",
            "diff": {
                "parquet-column/src/main/java/org/apache/parquet/io/api/Binary.java": 8,
                "parquet-column/src/test/java/org/apache/parquet/io/api/TestBinary.java": 21
            },
            "is_test": true,
            "is_fix": true
        },
        "a4acf53336a482f50335d33b4f650a70c9243b7b": {
            "datetime": "2016-02-06T11:41:21-08:00",
            "summary": "PARQUET-509: Fix args passed to string format calls",
            "message": "PARQUET-509: Fix args passed to string format calls\n\nThis PR fixes the args passed to the `String.format()` call.\n\nAuthor: Nezih Yigitbasi <nyigitbasi@netflix.com>\n\nCloses #320 from nezihyigitbasi/debug_args and squashes the following commits:\n\n43a6088 [Nezih Yigitbasi] Fix args passed to string format calls\n",
            "diff": {
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/DirectCodecFactory.java": 4
            },
            "is_test": false,
            "is_fix": false
        },
        "c26fa78817f30cc3eb91165b783e07fb80d80f59": {
            "datetime": "2016-02-06T11:57:19-08:00",
            "summary": "PARQUET-385 PARQUET-379: Fixes strict schema merging",
            "message": "PARQUET-385 PARQUET-379: Fixes strict schema merging\n\nThis PR fixes strict mode schema merging. To merge two `PrimitiveType` `t1` and `t2`, they must satisfy the following conditions:\n\n1. `t1` and `t2` have the same primitive type name\n1. `t1` and `t2` either\n   - don't have original type, or\n   - have the same original type\n1. If `t1` and `t2` are both `FIXED_LEN_BYTE_ARRAY`, they should have the same length\n\nAlso, merged schema now preserves original name if there's any.\n\nAuthor: Cheng Lian <lian@databricks.com>\n\nCloses #315 from liancheng/fix-strict-schema-merge and squashes the following commits:\n\na29138c [Cheng Lian] Addresses PR comment\n1ac804e [Cheng Lian] Fixes strict schema merging\n",
            "diff": {
                "parquet-column/src/main/java/org/apache/parquet/schema/PrimitiveType.java": 38,
                "parquet-column/src/test/java/org/apache/parquet/schema/TestMessageType.java": 35
            },
            "is_test": true,
            "is_fix": true
        }
    },
    "2016-02-12T15:17:05-07:00": {
        "6c9ca4d4c0de4dff29b79f28ac5c51b4f6fed0da": {
            "datetime": "2016-02-15T16:35:33-08:00",
            "summary": "PARQUET-430: Change to use Locale parameterized version of String.toUpperCase()/toLowerCase",
            "message": "PARQUET-430: Change to use Locale parameterized version of String.toUpperCase()/toLowerCase\n\nA String is being converted to upper or lowercase, using the platform's default encoding. This may result in improper conversions when used with international characters.\n\nFor instance, \"TITLE\".toLowerCase() in a Turkish locale returns \"t\u0131tle\", where '\u0131' -- without a dot -- is the LATIN SMALL LETTER DOTLESS I character. To obtain correct results for locale insensitive strings, we'd better use toLowerCase(Locale.ENGLISH).\n\nFor more information on this, please see:\n- http://stackoverflow.com/questions/11063102/using-locales-with-javas-tolowercase-and-touppercase\n- http://lotusnotus.com/lotusnotus_en.nsf/dx/dotless-i-tolowercase-and-touppercase-functions-use-responsibly.htm\n- http://java.sys-con.com/node/46241\n\nThis PR changes our use of String.toUpperCase()/toLowerCase() to String.toUpperCase(Locale.*ENGLISH*)/toLowerCase(*Locale.ENGLISH*)\n\nAuthor: proflin <proflin.me@gmail.com>\n\nCloses #312 from proflin/PARQUET-430 and squashes the following commits:\n\ned55822 [proflin] PARQUET-430\n",
            "diff": {
                "parquet-column/src/main/java/org/apache/parquet/filter2/predicate/Operators.java": 9,
                "parquet-column/src/main/java/org/apache/parquet/schema/GroupType.java": 3,
                "parquet-column/src/main/java/org/apache/parquet/schema/MessageTypeParser.java": 5,
                "parquet-column/src/main/java/org/apache/parquet/schema/PrimitiveType.java": 3,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/metadata/CompressionCodecName.java": 4
            },
            "is_test": false,
            "is_fix": false
        },
        "944291b748bcfec4e2f3c17623884db7a17b9f21": {
            "datetime": "2016-02-15T16:37:04-08:00",
            "summary": "PARQUET-431: Make ParquetOutputFormat.memoryManager volatile",
            "message": "PARQUET-431: Make ParquetOutputFormat.memoryManager volatile\n\nCurrently ParquetOutputFormat.getRecordWriter() contains an unsynchronized lazy initialization of the non-volatile static field *memoryManager*.\n\nBecause the compiler or processor may reorder instructions, threads are not guaranteed to see a completely initialized object, when ParquetOutputFormat.getRecordWriter() is called by multiple threads.\n\nThis PR makes *memoryManager* volatile to correct the problem.\n\nAuthor: Liwei Lin <proflin.me@gmail.com>\nAuthor: proflin <proflin.me@gmail.com>\n\nCloses #313 from proflin/PARQUET-431 and squashes the following commits:\n\n1aa4a44 [Liwei Lin] empty commit to trigger CI\n5e94fa3 [Liwei Lin] Remove the volatile modifier for memoryManager\nd54bb99 [Liwei Lin] Undo the Deprecated anotation\nfd1df4e [Liwei Lin] Adds synchronization around the creation of memoryManager as well as getMemoryManager()\n615aa5a [proflin] PARQUET-431\n",
            "diff": {
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ParquetOutputFormat.java": 12
            },
            "is_test": false,
            "is_fix": false
        },
        "c44f982e89b63a97190638cd12bd8bee2bafb883": {
            "datetime": "2016-02-21T18:36:50-08:00",
            "summary": "PARQUET-529: Avoid evoking job.toString() in ParquetLoader",
            "message": "PARQUET-529: Avoid evoking job.toString() in ParquetLoader\n\nWhen ran under hadoop2 environment and log level setting to `DEBUG`, ParquetLoader would evoke `job.toString()` in several methods, which might cause the whole application to stop due to :\n\n```\njava.lang.IllegalStateException: Job in state DEFINE instead of RUNNING\n\n\tat org.apache.hadoop.mapreduce.Job.ensureState(Job.java:283)\n\tat org.apache.hadoop.mapreduce.Job.toString(Job.java:452)\n\tat java.lang.String.valueOf(String.java:2847)\n\tat java.lang.StringBuilder.append(StringBuilder.java:128)\n\tat org.apache.parquet.pig.ParquetLoader.getSchema(ParquetLoader.java:260)\n\tat org.apache.parquet.pig.TestParquetLoader.testSchema(TestParquetLoader.java:54)\n    ...\n```\n\nThe reason is that in the hadoop 2.x branch, `org.apache.hadoop.mapreduce.Job.toString()` has added an `ensureState(JobState.RUNNING)` check; see [map-reduce: Job.java#452](http://grepcode.com/file/repo1.maven.org/maven2/org.apache.hadoop/hadoop-mapreduce-client-core/2.3.0/org/apache/hadoop/mapreduce/Job.java#452). In contrast, the hadoop 1.x branch does not contain such checks, so `ParquetLoader` works well.\n\nThis PR simply avoids evoking `job.toString()` in `ParquetLoader`.\n\nAuthor: proflin <proflin.me@gmail.com>\nAuthor: Liwei Lin <proflin.me@gmail.com>\n\nCloses #326 from proflin/PARQUET-529--Avoid-evoking-job.toString()-in-ParquetLoader and squashes the following commits:\n\nf464c7b [proflin] Add jobToString\n5d4c750 [proflin] PARQUET-529: Avoid evoking job.toString() in ParquetLoader.java\nbb4283a [Liwei Lin] Merge branch 'master' of https://github.com/proflin/parquet-mr\n839b458 [proflin] Merge remote-tracking branch 'refs/remotes/apache/master'\n",
            "diff": {
                "parquet-pig/src/main/java/org/apache/parquet/pig/ParquetLoader.java": 20
            },
            "is_test": false,
            "is_fix": false
        },
        "fb46b941f7763314d667c437c06b1675e61c3d38": {
            "datetime": "2016-02-26T10:28:07-08:00",
            "summary": "PARQUET-397: Implement Pig predicate pushdown",
            "message": "PARQUET-397: Implement Pig predicate pushdown\n\nThis is based on #296 from @danielcweeks and implements a few remaining review items.\n\nCloses #296.\n\nAuthor: Daniel Weeks <dweeks@netflix.com>\nAuthor: Ryan Blue <blue@apache.org>\n\nCloses #331 from rdblue/PARQUET-397-pig-predicate-pushdown and squashes the following commits:\n\nc7a9b02 [Ryan Blue] PARQUET-397: Address review comments.\n54e23a6 [Ryan Blue] PARQUET-397: Update Pig PPD to throw for bad expressions.\n388099b [Daniel Weeks] Cleaning up imports\n6b405b4 [Daniel Weeks] Merge remote-tracking branch 'rdblue/pig-predicate-pushdown' into pig-predicate-pushdown\nf1ef73e [Daniel Weeks] Fixed binary type and storing filter predicate\na39fdff [Ryan Blue] WIP: Handle a few error cases in Pig predicate pushdown.\n2666849 [Daniel Weeks] Fixed test to check the actual number of materialized rows from the reader\n7b019a6 [Daniel Weeks] update tests and logging\nf8ca447 [Daniel Weeks] Add predicate pushdown using filter2 api\n",
            "diff": {
                "parquet-pig/src/main/java/org/apache/parquet/pig/ParquetLoader.java": 186,
                "parquet-pig/src/test/java/org/apache/parquet/pig/TestParquetLoader.java": 57
            },
            "is_test": true,
            "is_fix": false
        },
        "1f91c79de5e2d852c6e7d0cf7a4255087ef618ef": {
            "datetime": "2016-03-05T19:45:25+08:00",
            "summary": "PARQUET-528: Fix flush() for RecordConsumer and implementations",
            "message": "PARQUET-528: Fix flush() for RecordConsumer and implementations\n\n`flush()` was added in `RecordConsumer` and `MessageColumnIO` to help implementing nulls caching.\n\nHowever, other `RecordConsumer` implementations should also implements `flush()` properly. For instance, `RecordConsumerLoggingWrapper` and `ValidatingRecordConsumer` should call `delegate.flush()` in their `flush()` methods, otherwise data might be mistakenly truncated.\n\nThis PR:\n- makes `flush()` abstract in `RecordConsumer`\n- implements `flush()` properly for all `RecordConsumer` subclasses, specifically:\n - `RecordConsumerLoggingWrapper`\n - `ValidatingRecordConsumer`\n - `ConverterConsumer `\n - `ExpectationValidatingRecordConsumer `\n\nAuthor: proflin <proflin.me@gmail.com>\nAuthor: Liwei Lin <proflin.me@gmail.com>\n\nCloses #325 from proflin/PARQUET-528 and squashes the following commits:\n\n2c90740 [proflin] Minor style issue\n25444b9 [proflin] Still keep RecordConsumer.flush() non-abstract\n8776e3a [proflin] PARQUET-528: Fix flush() for RecordConsumer and implementations\nbb4283a [Liwei Lin] Merge branch 'master' of https://github.com/proflin/parquet-mr\n839b458 [proflin] Merge remote-tracking branch 'refs/remotes/apache/master'\n",
            "diff": {
                "parquet-column/src/main/java/org/apache/parquet/io/MessageColumnIO.java": 4,
                "parquet-column/src/main/java/org/apache/parquet/io/RecordConsumerLoggingWrapper.java": 9,
                "parquet-column/src/main/java/org/apache/parquet/io/ValidatingRecordConsumer.java": 4,
                "parquet-column/src/main/java/org/apache/parquet/io/api/RecordConsumer.java": 1,
                "parquet-column/src/test/java/org/apache/parquet/io/ConverterConsumer.java": 8,
                "parquet-column/src/test/java/org/apache/parquet/io/ExpectationValidatingRecordConsumer.java": 8
            },
            "is_test": false,
            "is_fix": false
        },
        "4b1ff8f4b9dfa0ccb064ef286cf2953bfb2c492d": {
            "datetime": "2016-03-09T13:20:37-08:00",
            "summary": "PARQUET-384: Add dictionary filtering.",
            "message": "PARQUET-384: Add dictionary filtering.\n\nThis builds on #286 from @danielcweeks and cleans up some of the interfaces. It introduces `DictionaryPageReadStore` to expose dictionary pages to the filters and cleans up some internal calls by passing `ParquetFileReader`.\n\nWhen committed, this closes #286.\n\nAuthor: Ryan Blue <blue@apache.org>\nAuthor: Daniel Weeks <dweeks@netflix.com>\n\nCloses #330 from rdblue/PARQUET-384-add-dictionary-filtering and squashes the following commits:\n\nff89424 [Ryan Blue] PARQUET-384: Add a cache to DictionaryPageReader.\n1f6861c [Ryan Blue] PARQUET-384: Use ParquetFileReader to initialize readers.\n21ef4b6 [Daniel Weeks] PARQUET-384: Add dictionary row group filter.\n",
            "diff": {
                "parquet-column/src/main/java/org/apache/parquet/column/page/DictionaryPageReadStore.java": 36,
                "parquet-hadoop/src/main/java/org/apache/parquet/filter2/compat/RowGroupFilter.java": 37,
                "parquet-hadoop/src/main/java/org/apache/parquet/filter2/dictionarylevel/DictionaryFilter.java": 356,
                "parquet-hadoop/src/main/java/org/apache/parquet/format/converter/ParquetMetadataConverter.java": 47,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ColumnChunkPageReadStore.java": 10,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/DictionaryPageReader.java": 110,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/InternalParquetRecordReader.java": 39,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ParquetFileReader.java": 330,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ParquetReader.java": 17,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ParquetRecordReader.java": 77,
                "parquet-hadoop/src/test/java/org/apache/parquet/filter2/dictionarylevel/DictionaryFilterTest.java": 387
            },
            "is_test": true,
            "is_fix": false
        },
        "e9928c94ce1385ec72028336417f19f30ac38ac0": {
            "datetime": "2016-03-25T12:19:39-07:00",
            "summary": "PARQUET-571: Fix potential leak in ParquetFileReader.close()",
            "message": "PARQUET-571: Fix potential leak in ParquetFileReader.close()\n\nIf an exception occurs when closing the input stream `f`, the codecs\nwill not be released. This may cause native memory leaks for some codecs. \\cc @rdblue\n\nAuthor: Nezih Yigitbasi <nyigitbasi@netflix.com>\n\nCloses #338 from nezihyigitbasi/leak-fix and squashes the following commits:\n\nfcc5528 [Nezih Yigitbasi] Fix potential leak in close()\n",
            "diff": {
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ParquetFileReader.java": 13
            },
            "is_test": false,
            "is_fix": false
        },
        "d4021487539b0f7758ec644f2e0d83df95c66bba": {
            "datetime": "2016-04-16T17:23:59-07:00",
            "summary": "PARQUET-581: Fix two instances of the conflation of the min and max row",
            "message": "PARQUET-581: Fix two instances of the conflation of the min and max row\n\ncount for page size check in ParquetOutputFormat.java\n\nAuthor: Michael Allman <michael@videoamp.com>\n\nCloses #340 from mallman/fix_minmax_conflation and squashes the following commits:\n\n79331a5 [Michael Allman] PARQUET-581: Fix two instances of the conflation of the min and max row count for page size check in ParquetOutputFormat.java\n",
            "diff": {
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ParquetOutputFormat.java": 4
            },
            "is_test": false,
            "is_fix": false
        },
        "ac62c1c29f319a97a2552c39f32c8e6acd70c9e1": {
            "datetime": "2016-04-16T17:25:31-07:00",
            "summary": "PARQUET-580: Switch int[] initialization in IntList to be lazy",
            "message": "PARQUET-580: Switch int[] initialization in IntList to be lazy\n\nNoticed that for a dataset that we were trying to import that had a lot of columns (few thousand) that weren't being used, we ended up allocating a lot of unnecessary int arrays (each 64K in size). Heap footprint for all those int[]s turned out to be around 2GB or so (and results in some jobs OOMing). This seems unnecessary for columns that might not be used. The changes in this PR switch over to initialize the int[] only when it being used for the first time.\n\nAlso wondering if 64K is the right size to start off with. Wondering if a potential improvement is if we could allocate these int[]s in IntList in a way that slowly ramps up their size. So rather than create arrays of size 64K at a time (which is potentially wasteful if there are only a few hundred bytes), we could create say a 4K int[], then when it fills up an 8K[] and so on till we reach 64K (at which point the behavior is the same as the current implementation). If this sounds like a reasonable idea, I can update this PR to do that as well. Wasn't sure if there was some historical context around that..\n\nAuthor: Piyush Narang <pnarang@twitter.com>\n\nCloses #339 from piyushnarang/master and squashes the following commits:\n\n3ecc577 [Piyush Narang] Remove redundant IntList ctor\nf7dfd5f [Piyush Narang] Switch int[] initialization in IntList to be lazy\n",
            "diff": {
                "parquet-column/src/main/java/org/apache/parquet/column/values/dictionary/IntList.java": 21
            },
            "is_test": false,
            "is_fix": false
        },
        "dc08bb8ea6cdf01188f6699559e779e6cc296287": {
            "datetime": "2016-04-19T08:26:34-07:00",
            "summary": "PARQUET-584 show proper command usage when there's no arguments",
            "message": "PARQUET-584 show proper command usage when there's no arguments\n\nAuthor: Kaufman Ng <kaufman@cloudera.com>\nAuthor: Ryan Blue <blue@apache.org>\n\nCloses #336 from coughman/master and squashes the following commits:\n\ncd459f9 [Kaufman Ng] PARQUET-584: fixed formatting\n1d1e965 [Kaufman Ng] Merge branch 'master' of https://github.com/coughman/incubator-parquet-mr\n25b6d86 [Kaufman Ng] Merge branch 'master' of https://github.com/apache/parquet-mr\nbee66e5 [Ryan Blue] PARQUET-384: Add dictionary filtering.\n283f7c7 [Kaufman Ng] show proper command usage when there's no arguments\n",
            "diff": {
                "parquet-tools/src/main/java/org/apache/parquet/tools/Main.java": 7
            },
            "is_test": false,
            "is_fix": false
        },
        "82b8ecc3275d7c3578a6531ac3f1da3ffada9dcc": {
            "datetime": "2016-04-19T09:17:01-07:00",
            "summary": "PARQUET-484: Warn when Decimal is stored as INT64 while could be stored as INT32",
            "message": "PARQUET-484: Warn when Decimal is stored as INT64 while could be stored as INT32\n\nBelow is documented in [LogicalTypes.md](https://github.com/Parquet/parquet-format/blob/master/LogicalTypes.md#decimal):\n\n> int32: for 1 <= precision <= 9\n> int64: for 1 <= precision <= 18; precision < 10 will produce a warning\n\nThis PR implements the `precision < 10 will produce a warning` part.\n\n@rdblue @liancheng would mind taking a look at this when you have time? It's a fairly small addition; cheers.\n\nAuthor: Liwei Lin <proflin.me@gmail.com>\nAuthor: proflin <proflin.me@gmail.com>\n\nCloses #316 from lw-lin/P-484-2 and squashes the following commits:\n\n207e509 [Liwei Lin] Address comments\nb227484 [proflin] PARQUET-484: Warn when Decimal is stored as INT64 while could be stored as INT32\n",
            "diff": {
                "parquet-column/src/main/java/org/apache/parquet/schema/Types.java": 9
            },
            "is_test": false,
            "is_fix": false
        },
        "6b24a1d1b5e2792a7821ad172a45e38d2b04f9b8": {
            "datetime": "2016-04-20T08:41:22-07:00",
            "summary": "PARQUET-358: Add support for Avro's logical types API.",
            "message": "PARQUET-358: Add support for Avro's logical types API.\n\nThis adds support for Avro's logical types API to parquet-avro.\n\n* The logical types API was introduced in Avro 1.8.0, so this bumps the Avro dependency version to 1.8.0.\n* Types supported are: decimal, date, time-millis, time-micros, timestamp-millis, and timestamp-micros\n* Tests have been copied from Avro and ported to the parquet-avro API\n\nAuthor: Ryan Blue <blue@apache.org>\n\nCloses #318 from rdblue/PARQUET-358-add-avro-logical-types-api and squashes the following commits:\n\nbd81f9c [Ryan Blue] PARQUET-358: Fix review items.\n0a882ee [Ryan Blue] PARQUET-358: Add logical types circular reference test.\n5124618 [Ryan Blue] PARQUET-358: Add license documentation for code from Avro.\ndcb14be [Ryan Blue] PARQUET-358: Add support for Avro's logical types API.\n",
            "diff": {
                "parquet-avro/src/main/java/org/apache/parquet/avro/AvroIndexedRecordConverter.java": 18,
                "parquet-avro/src/main/java/org/apache/parquet/avro/AvroReadSupport.java": 4,
                "parquet-avro/src/main/java/org/apache/parquet/avro/AvroRecordConverter.java": 121,
                "parquet-avro/src/main/java/org/apache/parquet/avro/AvroSchemaConverter.java": 149,
                "parquet-avro/src/main/java/org/apache/parquet/avro/AvroWriteSupport.java": 167,
                "parquet-avro/src/main/java/org/apache/parquet/avro/ParentValueContainer.java": 175,
                "parquet-avro/src/test/java/org/apache/parquet/avro/AvroTestUtil.java": 53,
                "parquet-avro/src/test/java/org/apache/parquet/avro/TestAvroSchemaConverter.java": 280,
                "parquet-avro/src/test/java/org/apache/parquet/avro/TestCircularReferences.java": 383,
                "parquet-avro/src/test/java/org/apache/parquet/avro/TestGenericLogicalTypes.java": 271,
                "parquet-avro/src/test/java/org/apache/parquet/avro/TestReadWrite.java": 118,
                "parquet-avro/src/test/java/org/apache/parquet/avro/TestReadWriteOldListBehavior.java": 1,
                "parquet-avro/src/test/java/org/apache/parquet/avro/TestReflectLogicalTypes.java": 705,
                "parquet-column/src/main/java/org/apache/parquet/io/api/Binary.java": 55,
                "parquet-column/src/main/java/org/apache/parquet/schema/Types.java": 12,
                "parquet-column/src/test/java/org/apache/parquet/io/api/TestBinary.java": 10
            },
            "is_test": true,
            "is_fix": false
        },
        "36ce032b612fc0a1156d28bca7327e06337c8815": {
            "datetime": "2016-04-20T20:47:49-07:00",
            "summary": "PARQUET-585: Slowly ramp up sizes of int[]s in IntList to keep sizes small when data sets are small",
            "message": "PARQUET-585: Slowly ramp up sizes of int[]s in IntList to keep sizes small when data sets are small\n\nOne of the follow up items from PR - https://github.com/apache/parquet-mr/pull/339 was to slowly ramp up the size of the int[] created in IntList to ensure we don't allocate 64K arrays right off the bat. This PR updates the code to start with a 4K array then keeps doubling till 64K (and stays at 64K after that).\n\nAuthor: Piyush Narang <pnarang@twitter.com>\n\nCloses #341 from piyushnarang/master and squashes the following commits:\n\n0bc6b84 [Piyush Narang] Fix review comments - add spaces, check slab size, fix slab init\nd1b4df1 [Piyush Narang] Make IntListTest values relative to constants in IntList\n9617015 [Piyush Narang] Update IntList slab creation to keep bumping up size gradually\nebf1c58 [Piyush Narang] Merge branch 'master' of https://github.com/apache/parquet-mr\n3ecc577 [Piyush Narang] Remove redundant IntList ctor\nf7dfd5f [Piyush Narang] Switch int[] initialization in IntList to be lazy\n",
            "diff": {
                "parquet-column/src/main/java/org/apache/parquet/column/values/dictionary/IntList.java": 64,
                "parquet-column/src/test/java/org/apache/parquet/column/values/dictionary/IntListTest.java": 84
            },
            "is_test": true,
            "is_fix": false
        },
        "741944332d5bd90112b610a8b5f2eeefe51e08bc": {
            "datetime": "2016-04-20T20:58:40-07:00",
            "summary": "PARQUET-327. Show statistics in the dump output.",
            "message": "PARQUET-327. Show statistics in the dump output.\n\nCloses #237\n",
            "diff": {
                "parquet-tools/src/main/java/org/apache/parquet/tools/command/DumpCommand.java": 13
            },
            "is_test": false,
            "is_fix": false
        },
        "8bcfe6c55e2588c1047368b4edbf733d1c1d5381": {
            "datetime": "2016-04-21T11:37:51-07:00",
            "summary": "PARQUET-225: Add support for INT64 delta encoding.",
            "message": "PARQUET-225: Add support for INT64 delta encoding.\n\nAuthor: Vassil Lunchev <vassil@leanplum.com>\n\nCloses #154 from lunchev:int64 and squashes the following commits:\n\n84a40fe [Vassil Lunchev] INT64 support for Delta Encoding\n4389af4 [Vassil Lunchev] splitting delta INT32 and delta INT64\ne5e8fe2 [Vassil Lunchev] split delta encoding tests for INT32 and for INT64\neb4383a [Ryan Blue] PARQUET-225: Avoid multiple small copies in delta int/long encoding.\n",
            "diff": {
                "parquet-column/src/main/java/org/apache/parquet/column/Encoding.java": 5,
                "parquet-column/src/main/java/org/apache/parquet/column/ParquetProperties.java": 8,
                "parquet-column/src/main/java/org/apache/parquet/column/values/delta/DeltaBinaryPackingValuesReader.java": 26,
                "parquet-column/src/main/java/org/apache/parquet/column/values/delta/DeltaBinaryPackingValuesWriter.java": 158,
                "parquet-column/src/main/java/org/apache/parquet/column/values/delta/DeltaBinaryPackingValuesWriterForInteger.java": 199,
                "parquet-column/src/main/java/org/apache/parquet/column/values/delta/DeltaBinaryPackingValuesWriterForLong.java": 201,
                "parquet-column/src/main/java/org/apache/parquet/column/values/deltalengthbytearray/DeltaLengthByteArrayValuesWriter.java": 3,
                "parquet-column/src/main/java/org/apache/parquet/column/values/deltastrings/DeltaByteArrayWriter.java": 4,
                "parquet-column/src/test/java/org/apache/parquet/column/values/delta/DeltaBinaryPackingValuesWriterForLongTest.java": 263,
                "parquet-column/src/test/java/org/apache/parquet/column/values/delta/DeltaBinaryPackingValuesWriterTest.java": 18,
                "parquet-column/src/test/java/org/apache/parquet/column/values/delta/benchmark/BenchmarkIntegerOutputSize.java": 12,
                "parquet-column/src/test/java/org/apache/parquet/column/values/delta/benchmark/BenchmarkReadingRandomIntegers.java": 29,
                "parquet-column/src/test/java/org/apache/parquet/column/values/delta/benchmark/RandomWritingBenchmarkTest.java": 25,
                "parquet-common/src/main/java/org/apache/parquet/bytes/BytesUtils.java": 36,
                "parquet-encoding/src/main/java/org/apache/parquet/bytes/BytesInput.java": 39,
                "parquet-encoding/src/main/java/org/apache/parquet/column/values/bitpacking/BytePackerForLong.java": 112,
                "parquet-encoding/src/main/java/org/apache/parquet/column/values/bitpacking/BytePackerForLongFactory.java": 25,
                "parquet-encoding/src/main/java/org/apache/parquet/column/values/bitpacking/Packer.java": 24,
                "parquet-encoding/src/test/java/org/apache/parquet/column/values/bitpacking/TestBitPacking.java": 14,
                "parquet-encoding/src/test/java/org/apache/parquet/column/values/bitpacking/TestByteBitPacking.java": 48,
                "parquet-generator/src/main/java/org/apache/parquet/encoding/bitpacking/ByteBasedBitPackingGenerator.java": 146
            },
            "is_test": true,
            "is_fix": false
        },
        "3dd2210e79a8eb84378c370b32652f9a53f87a93": {
            "datetime": "2016-04-22T17:39:52-07:00",
            "summary": "PARQUET-548: Add EncodingStats.",
            "message": "PARQUET-548: Add EncodingStats.\n\nThis adds `EncodingStats`, which tracks the number of pages for each encoding, separated into dictionary and data pages. It also adds convenience functions that are useful for dictionary filtering, like `hasDictionaryEncodedPages` and `hasNonDictionaryEncodedPages`.\n\n`EncodingStats` have a unit test in parquet-column and an integration test in parquet-hadoop that writes a file and verifies the stats are present and correct when it is read.\n\nThis includes commits from #330 because it updates the dictionary filter. I'll rebase and remove them once it is merged.\n\nAuthor: Ryan Blue <blue@apache.org>\n\nCloses #332 from rdblue/PARQUET-548-add-encoding-stats and squashes the following commits:\n\n5f148e6 [Ryan Blue] PARQUET-548: Fixes for review comments.\ndc332d3 [Ryan Blue] PARQUET-548: Add EncodingStats.\n",
            "diff": {
                "parquet-column/src/main/java/org/apache/parquet/column/EncodingStats.java": 162,
                "parquet-column/src/test/java/org/apache/parquet/column/TestEncodingStats.java": 202,
                "parquet-hadoop/src/main/java/org/apache/parquet/filter2/dictionarylevel/DictionaryFilter.java": 6,
                "parquet-hadoop/src/main/java/org/apache/parquet/format/converter/ParquetMetadataConverter.java": 50,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ColumnChunkPageWriteStore.java": 25,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/DictionaryPageReader.java": 7,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ParquetFileWriter.java": 31,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/metadata/ColumnChunkMetaData.java": 71,
                "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/TestReadWriteEncodingStats.java": 121
            },
            "is_test": true,
            "is_fix": false
        },
        "2f22533ef41533e2b839a6b41b262dca59e6dbf9": {
            "datetime": "2016-04-22T17:42:35-07:00",
            "summary": "PARQUET-569: Separate metadata filtering for ranges and offsets.",
            "message": "PARQUET-569: Separate metadata filtering for ranges and offsets.\n\nRange filtering should use the row group midpoint and offset filtering\nshould use the start offset.\n\nAuthor: Ryan Blue <blue@apache.org>\n\nCloses #337 from rdblue/PARQUET-569-fix-metadata-filter and squashes the following commits:\n\n6171af4 [Ryan Blue] PARQUET-569: Add tests for new offset metadata filter.\n3fe2d5e [Ryan Blue] PARQUET-569: Separate metadata filtering for ranges and offsets.\n",
            "diff": {
                "parquet-hadoop/src/main/java/org/apache/parquet/format/converter/ParquetMetadataConverter.java": 36,
                "parquet-hadoop/src/test/java/org/apache/parquet/format/converter/TestParquetMetadataConverter.java": 31
            },
            "is_test": true,
            "is_fix": true
        },
        "39a3cd0f4210dbec1ae8ef39a87d34b76eac91a3": {
            "datetime": "2016-04-25T15:05:11-07:00",
            "summary": "PARQUET-560: Synchronize writes to the finishCalled variable",
            "message": "PARQUET-560: Synchronize writes to the finishCalled variable\n\nReads of the `finishCalled` variable are properly synchronized, but writes are not -- so there's some sort of inconsistent synch. going on here. This PR fixes that.\n\n/cc @rdblue can you please take a look?\n\nAuthor: Nezih Yigitbasi <nyigitbasi@netflix.com>\n\nCloses #334 from nezihyigitbasi/sc-synch-fix and squashes the following commits:\n\na85cf0c [Nezih Yigitbasi] Synchronize writes to the finishCalled variable\n",
            "diff": {
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/codec/SnappyCompressor.java": 2
            },
            "is_test": false,
            "is_fix": false
        },
        "c3f3830f771f26a537d2930b00b270451bbc5627": {
            "datetime": "2016-05-05T13:54:28-07:00",
            "summary": "PARQUET-372: Do not write stats larger than 4k.",
            "message": "PARQUET-372: Do not write stats larger than 4k.\n\nThis updates the stats conversion to check whether the min and max\nvalues for page stats are larger than 4k. If so, no statistics for a\npage are written.\n\nAuthor: Ryan Blue <blue@apache.org>\n\nCloses #275 from rdblue/PARQUET-372-fix-min-max-for-long-values and squashes the following commits:\n\n61e05d9 [Ryan Blue] PARQUET-372: Add comment to explain not truncating values.\nfbbc1c4 [Ryan Blue] PARQUET-372: Do not write stats larger than 4k.\n",
            "diff": {
                "parquet-column/src/main/java/org/apache/parquet/column/statistics/BinaryStatistics.java": 25,
                "parquet-column/src/main/java/org/apache/parquet/column/statistics/BooleanStatistics.java": 5,
                "parquet-column/src/main/java/org/apache/parquet/column/statistics/DoubleStatistics.java": 5,
                "parquet-column/src/main/java/org/apache/parquet/column/statistics/FloatStatistics.java": 5,
                "parquet-column/src/main/java/org/apache/parquet/column/statistics/IntStatistics.java": 5,
                "parquet-column/src/main/java/org/apache/parquet/column/statistics/LongStatistics.java": 5,
                "parquet-column/src/main/java/org/apache/parquet/column/statistics/Statistics.java": 8,
                "parquet-hadoop/src/main/java/org/apache/parquet/format/converter/ParquetMetadataConverter.java": 8,
                "parquet-hadoop/src/test/java/org/apache/parquet/format/converter/TestParquetMetadataConverter.java": 159,
                "parquet-hadoop/src/test/java/org/apache/parquet/statistics/TestStatistics.java": 9
            },
            "is_test": true,
            "is_fix": true
        },
        "da69d4b764f4d13d38a4f7fe7462ef0c7d17c619": {
            "datetime": "2016-05-05T13:56:53-07:00",
            "summary": "PARQUET-367: \"parquet-cat -j\" doesn't show all records.",
            "message": "PARQUET-367: \"parquet-cat -j\" doesn't show all records.\n\nAdded JsonRecordFormatter which formats SimpleRecords into an structure that can be used with ObjectMapper to create a valid json structure. Unit test included.\n\nAuthor: Reuben Kuhnert <reuben.kuhnert@cloudera.com>\n\nCloses #281 from sircodesalotOfTheRound/fix-parquet-cat and squashes the following commits:\n\n67207ef [Reuben Kuhnert] PARQUET-367: \"parquet-cat -j\" doesn't show all records.\n",
            "diff": {
                "parquet-tools/src/main/java/org/apache/parquet/tools/command/CatCommand.java": 9,
                "parquet-tools/src/main/java/org/apache/parquet/tools/json/JsonRecordFormatter.java": 132,
                "parquet-tools/src/main/java/org/apache/parquet/tools/read/SimpleRecord.java": 1,
                "parquet-tools/src/test/java/org/apache/parquet/tools/read/TestJsonRecordFormatter.java": 231
            },
            "is_test": true,
            "is_fix": true
        },
        "1f470253c46471033048383c027192e757480492": {
            "datetime": "2016-06-30T09:41:51-07:00",
            "summary": "PARQUET-544: Add closed flag to allow for closeable contract adherence",
            "message": "PARQUET-544: Add closed flag to allow for closeable contract adherence\n\nThe closeable interface states:\n> Closes this stream and releases any system resources associated with it. If the stream is already closed then invoking this method has no effect.\n\nAs InternalParquetRecordWriter implements this interface we should adhere to this contract.\n\nAuthor: Mark Reddy <mark.l.reddy@gmail.com>\n\nCloses #345 from markreddy/PARQUET-544-adhere-to-closeable-contract and squashes the following commits:\n\n135db9b [Mark Reddy] PARQUET-544: add closed flag to allow for adherence to closeable contract\n",
            "diff": {
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/InternalParquetRecordWriter.java": 21
            },
            "is_test": false,
            "is_fix": false
        },
        "9c40a7bb3c9aca51d17490960c988dfb7b5acebb": {
            "datetime": "2016-06-30T09:47:48-07:00",
            "summary": "PARQUET-645: Fix null handling in DictionaryFilter.",
            "message": "PARQUET-645: Fix null handling in DictionaryFilter.\n\nThis fixes how null is handled by `DictionaryFilter` for equals predicates. Null is never in the dictionary and is encoded by the definition level, so the `DictionaryFilter` would never find the value in the dictionary and would incorrectly filter row groups whenever the filter was `col == null`.\n\nAuthor: Ryan Blue <blue@apache.org>\n\nCloses #348 from rdblue/PARQUET-645-fix-null-dictionary-filter and squashes the following commits:\n\nae8dd41 [Ryan Blue] PARQUET-645: Fix null handling in DictionaryFilter.\n",
            "diff": {
                "parquet-hadoop/src/main/java/org/apache/parquet/filter2/dictionarylevel/DictionaryFilter.java": 12,
                "parquet-hadoop/src/test/java/org/apache/parquet/filter2/dictionarylevel/DictionaryFilterTest.java": 6
            },
            "is_test": true,
            "is_fix": true
        },
        "7f8e952abc4d2fc4b96c97a51aa25fcf6ed8af02": {
            "datetime": "2016-06-30T09:50:59-07:00",
            "summary": "PARQUET-642: Improve performance of ByteBuffer based read / write paths",
            "message": "PARQUET-642: Improve performance of ByteBuffer based read / write paths\n\nWhile trying out the newest Parquet version, we noticed that the changes to start using ByteBuffers: https://github.com/apache/parquet-mr/commit/6b605a4ea05b66e1a6bf843353abcb4834a4ced8 and https://github.com/apache/parquet-mr/commit/6b24a1d1b5e2792a7821ad172a45e38d2b04f9b8 (mostly avro but a couple of ByteBuffer changes) caused our jobs to slow down a bit.\n\nRead overhead: 4-6% (in MB_Millis)\nWrite overhead: 6-10% (MB_Millis).\n\nSeems like this seems to be due to the encoding / decoding of Strings in the [Binary class](https://github.com/apache/parquet-mr/blob/master/parquet-column/src/main/java/org/apache/parquet/io/api/Binary.java):\n[toStringUsingUTF8()](https://github.com/apache/parquet-mr/blob/master/parquet-column/src/main/java/org/apache/parquet/io/api/Binary.java#L388) - for reads\n[encodeUTF8()](https://github.com/apache/parquet-mr/blob/master/parquet-column/src/main/java/org/apache/parquet/io/api/Binary.java#L236) - for writes\n\nWith these changes we see around 5% improvement in MB_Millis while running the job on our Hadoop cluster.\n\nAdded some microbenchmark details to the jira.\n\nNote that I've left the behavior the same for the avro write path - it still uses CharSequence and the Charset based encoders.\n\nAuthor: Piyush Narang <pnarang@twitter.com>\n\nCloses #347 from piyushnarang/bytebuffer-encoding-fix-pr and squashes the following commits:\n\n43c5bdd [Piyush Narang] Keep avro on char sequence\n2d50c8c [Piyush Narang] Update Binary approach\n9e58237 [Piyush Narang] Proof of concept fixes\n",
            "diff": {
                "parquet-avro/src/main/java/org/apache/parquet/avro/AvroWriteSupport.java": 2,
                "parquet-column/src/main/java/org/apache/parquet/io/api/Binary.java": 75
            },
            "is_test": false,
            "is_fix": false
        },
        "bd0b5af025fab9cad8f94260138741c252f45fc8": {
            "datetime": "2016-06-30T09:54:08-07:00",
            "summary": "PARQUET-612: Add compression codec to FileEncodingsIT.",
            "message": "PARQUET-612: Add compression codec to FileEncodingsIT.\n\nAuthor: Ryan Blue <blue@apache.org>\n\nCloses #343 from rdblue/PARQUET-612-test-compression and squashes the following commits:\n\na5b7dbb [Ryan Blue] PARQUET-612: Add compression codec to FileEncodingsIT.\n",
            "diff": {
                "parquet-hadoop/src/test/java/org/apache/parquet/encodings/FileEncodingsIT.java": 114
            },
            "is_test": false,
            "is_fix": false
        },
        "e036d60d8a210d5ac28b2e5c51a45ceb82b58f09": {
            "datetime": "2016-07-13T14:50:08-07:00",
            "summary": "PARQUET-654: Add option to disable record-level filtering.",
            "message": "PARQUET-654: Add option to disable record-level filtering.\n\nThis can be used by frameworks that use codegen for filtering to avoid\nrunning filters within Parquet.\n\nAuthor: Ryan Blue <blue@apache.org>\n\nCloses #353 from rdblue/PARQUET-654-add-record-level-filter-option and squashes the following commits:\n\nb497e7f [Ryan Blue] PARQUET-654: Add option to disable record-level filtering.\n",
            "diff": {
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/InternalParquetRecordReader.java": 8,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ParquetFileReader.java": 10,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ParquetInputFormat.java": 18
            },
            "is_test": false,
            "is_fix": false
        },
        "42662f8750a2c33ee169f17f4b4e4586db98d869": {
            "datetime": "2016-07-15T09:53:33-07:00",
            "summary": "PARQUET-389: Support predicate push down on missing columns.",
            "message": "PARQUET-389: Support predicate push down on missing columns.\n\nPredicate push-down will complain when predicates reference columns that aren't in a file's schema. This makes it difficult to implement predicate push-down in engines where schemas evolve because each task needs to process the predicates and prune references to columns not in that task's file. This PR implements predicate evaluation for missing columns, where the values are all null. This allows engines to pass predicates as they are written.\n\nA future commit should rewrite the predicates to avoid the extra work currently done in record-level filtering, but that isn't included here because it is an optimization.\n\nAuthor: Ryan Blue <blue@apache.org>\n\nCloses #354 from rdblue/PARQUET-389-predicate-push-down-on-missing-columns and squashes the following commits:\n\nb4d809a [Ryan Blue] PARQUET-389: Support record-level filtering with missing columns.\n91b841c [Ryan Blue] PARQUET-389: Add missing column support to StatisticsFilter.\n275f950 [Ryan Blue] PARQUET-389: Add missing column support to DictionaryFilter.\n",
            "diff": {
                "parquet-column/src/main/java/org/apache/parquet/filter2/predicate/SchemaCompatibilityValidator.java": 9,
                "parquet-hadoop/src/main/java/org/apache/parquet/filter2/dictionarylevel/DictionaryFilter.java": 82,
                "parquet-hadoop/src/main/java/org/apache/parquet/filter2/statisticslevel/StatisticsFilter.java": 138,
                "parquet-hadoop/src/test/java/org/apache/parquet/filter2/TestFiltersWithMissingColumns.java": 265,
                "parquet-hadoop/src/test/java/org/apache/parquet/filter2/dictionarylevel/DictionaryFilterTest.java": 54,
                "parquet-hadoop/src/test/java/org/apache/parquet/filter2/statisticslevel/TestStatisticsFilter.java": 39
            },
            "is_test": true,
            "is_fix": true
        },
        "626014eaf093fc2e3b53f5ad00c425bc209e1428": {
            "datetime": "2016-07-17T14:59:20-07:00",
            "summary": "PARQUET-651: Improve Avro's isElementType check.",
            "message": "PARQUET-651: Improve Avro's isElementType check.\n\nThe Avro implementation needs to check whether the read schema that is\npassed by the user (or automatically converted from the file schema)\nexpects an extra 1-field layer to be returned, which matches the\nprevious behavior of Avro when reading a 3-level list. Before this\ncommit, the check was done by testing the structure of the expected list\nelement type against the repeated group's schema. If they matched, then\nAvro assumed that the user expected an extra layer. However, for records\nthat happened to match (1-field records with a field named \"element\")\nthe check could be wrong and would cause exceptions later.\n\nThis commit updates the check to convert the file's element schema to\nAvro and compare the compatibility of that schema with what was passed\nby the user. This checks the entire tree from the element down and gets\nthe answer right based on the element and its children, not just the\nfield names on the element.\n\nAuthor: Ryan Blue <blue@apache.org>\n\nCloses #352 from rdblue/PARQUET-651-improve-is-element-type-check and squashes the following commits:\n\nad9c1ee [Ryan Blue] PARQUET-651: Undo accidental default setting change.\n1efa248 [Ryan Blue] PARQUET-651: Improve Avro's isElementType check.\n",
            "diff": {
                "parquet-avro/src/main/java/org/apache/parquet/avro/AvroRecordConverter.java": 23,
                "parquet-avro/src/main/java/org/apache/parquet/avro/AvroSchemaConverter.java": 15,
                "parquet-avro/src/test/java/org/apache/parquet/avro/TestArrayCompatibility.java": 148
            },
            "is_test": true,
            "is_fix": true
        },
        "6a62646bfcecec9c0806a216b17e1a4ccb4609aa": {
            "datetime": "2016-07-17T16:27:20-07:00",
            "summary": "PARQUET-543: Remove unused boundedint package.",
            "message": "PARQUET-543: Remove unused boundedint package.\n\nThis relocates the DevNullValuesWriter and ZeroIntegerValuesReader,\nwhich are used but are not related to the boundedint code.\n\nAuthor: Ryan Blue <blue@apache.org>\n\nCloses #329 from rdblue/PARQUET-543-remove-boundedint and squashes the following commits:\n\n0158c51 [Ryan Blue] PARQUET-543: Update new import in ParquetProperties.\n550a1a3 [Ryan Blue] PARQUET-543: Remove unused boundedint package.\n",
            "diff": {
                "parquet-column/src/main/java/org/apache/parquet/column/Encoding.java": 2,
                "parquet-column/src/main/java/org/apache/parquet/column/ParquetProperties.java": 2,
                "parquet-column/src/main/java/org/apache/parquet/column/values/boundedint/BitReader.java": 124,
                "parquet-column/src/main/java/org/apache/parquet/column/values/boundedint/BitWriter.java": 167,
                "parquet-column/src/main/java/org/apache/parquet/column/values/boundedint/BoundedIntValuesFactory.java": 33,
                "parquet-column/src/main/java/org/apache/parquet/column/values/boundedint/BoundedIntValuesReader.java": 94,
                "parquet-column/src/main/java/org/apache/parquet/column/values/boundedint/BoundedIntValuesWriter.java": 165,
                "parquet-column/src/main/java/org/apache/parquet/column/values/boundedint/DevNullValuesWriter.java": 2,
                "parquet-column/src/main/java/org/apache/parquet/column/values/boundedint/ZeroIntegerValuesReader.java": 2,
                "parquet-column/src/test/java/org/apache/parquet/column/values/boundedint/TestBoundedColumns.java": 175
            },
            "is_test": true,
            "is_fix": false
        },
        "5c85b8dda5f3047732a17b818256b9289274d071": {
            "datetime": "2016-08-01T14:38:07-07:00",
            "summary": "PARQUET-511: Integer overflow when counting values in column.",
            "message": "PARQUET-511: Integer overflow when counting values in column.\n\nThis commit fixes an issue when the number of entries in a column page is larger than the size of an integer. No exception is thrown directly, but the def level is set incorrectly, leading to a null value being returned during read.\n\nAuthor: Michal Gorecki <goreckim@amazon.com>\n\nCloses #321 from goreckm/int-overflow and squashes the following commits:\n\nd224815 [Michal Gorecki] enhancing exception message\n7334be2 [Michal Gorecki] PARQUET-511: Integer overflow when counting values in column.\n",
            "diff": {
                "parquet-column/src/main/java/org/apache/parquet/column/impl/ColumnReaderImpl.java": 6,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ColumnChunkPageReadStore.java": 2
            },
            "is_test": false,
            "is_fix": false
        },
        "ea402becca436dc1a8e47ac9385a3db475b49355": {
            "datetime": "2016-08-03T14:14:26-07:00",
            "summary": "PARQUET-668 - Provide option to disable auto crop feature in dump",
            "message": "PARQUET-668 - Provide option to disable auto crop feature in dump\n\nhttps://issues.apache.org/jira/browse/PARQUET-668\n\n1. Added option `--disable-crop`\n2. Updated `README.md` to reflect changes\n\nAuthor: djhworld <djharperuk@gmail.com>\n\nCloses #358 from djhworld/master and squashes the following commits:\n\n493c3d0 [djhworld] PARQUET-668: Removed usage instructions from README, replaced with --help flag\n696a5e6 [djhworld] PARQUET-668 -> Updated README.md to fix issue in usage string\n6cbf59b [djhworld] PARQUET-668 - Provide option to disable auto crop feature in DumpCommand output\n",
            "diff": {
                "parquet-tools/src/main/java/org/apache/parquet/tools/command/DumpCommand.java": 31
            },
            "is_test": false,
            "is_fix": false
        },
        "76a2ac814caa194c46be1cf7a3f5dc129546b1c1": {
            "datetime": "2016-08-03T14:22:27-07:00",
            "summary": "PARQUET-669: allow reading footers from provided file listing and streams",
            "message": "PARQUET-669: allow reading footers from provided file listing and streams\n\nThe use case is that I want to reuse existing listing of files and avoid doing it again when opening streams. This is in case where filesystem.open is expensive but you have other means of obtaining input stream for a file.\n\nAuthor: Robert Kruszewski <robertk@palantir.com>\n\nCloses #357 from robert3005/robertk/allow-reading-footers-from-streams and squashes the following commits:\n\n4d8a54c [Robert Kruszewski] allow reading footers from provided file listing and streams\n",
            "diff": {
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ParquetFileReader.java": 28
            },
            "is_test": false,
            "is_fix": false
        }
    },
    "2016-08-10T15:17:05-07:00": {
        "30aa91012cf6019bb9720609c1d03b5386a87ffb": {
            "datetime": "2016-08-11T13:30:43-07:00",
            "summary": "PARQUET-601: Add support to configure the encoding used by ValueWriters",
            "message": "PARQUET-601: Add support to configure the encoding used by ValueWriters\n\n### Context:\nParquet is currently structured to choose the appropriate value writer based on the type of the column as well as the Parquet version. As of now, the writer(s) (and hence encoding) for each data type is hard coded in the Parquet source code.\n\nThis PR adds support for being able to override the encodings per type via config. That allows users to experiment with various encoding strategies manually as well as enables them to override the hardcoded defaults if they don't suit their use case.\n\nWe can override encodings per data type (int32 / int64 / ...).\nSomething on the lines of:\n```\nparquet.writer.encoding-override.<type> = \"encoding1[,encoding2]\"\n```\n\nAs an example:\n```\n\"parquet.writer.encoding-override.int32\" = \"plain\"\n(Chooses Plain encoding and hence the PlainValuesWriter).\n```\n\nWhen a primary + fallback need to be specified, we can do the following:\n```\n\"parquet.writer.encoding-override.binary\" = \"rle_dictionary,delta_byte_array\"\n(Chooses RLE_DICTIONARY encoding as the initial encoding and DELTA_BYTE_ARRAY encoding as the fallback and hence creates a FallbackWriter(PlainBinaryDictionaryValuesWriter, DeltaByteArrayWriter).\n```\n\nIn such cases we can mandate that the first encoding listed must allow for Fallbacks by implementing [RequiresFallback](https://github.com/apache/parquet-mr/blob/master/parquet-column/src/main/java/org/apache/parquet/column/values/RequiresFallback.java#L31).\n\n### PR notes:\n\n- Restructured the ValuesWriter creation code. Pulled it out of ParquetProperties into a new class and refactored the flow based on type as it was getting hard to follow and I felt adding the overrides would make it harder. Added a bunch of unit tests to verify the ValuesWriter we create for combinations of type, parquet version and dictionary on / off.\n- Added unit tests to verify parsing of the encoding overrides + creation of ValuesWriters based on these overrides.\n- Manually tested some encoding overrides scenarios out on Hadoop (both parquet v1, v2).\n\nAuthor: Piyush Narang <pnarang@twitter.com>\n\nCloses #342 from piyushnarang/master and squashes the following commits:\n\n3ebab28 [Piyush Narang] Remove Configurable\n149bb98 [Piyush Narang] Switch to getValuesWriterFactory call to non-static\n0b78e04 [Piyush Narang] Address Ryan's feedback\n1da6ca3 [Piyush Narang] Merge branch 'master' into piyush/dynamic-encoding-overrides\nf021ed2 [Piyush Narang] Tweak comment in ValuesWriterFactory\ncb02ea0 [Piyush Narang] Fix review comments\nbf4bc6d [Piyush Narang] Add support for Config setting in ValuesWriter factory\n8a852a3 [Piyush Narang] Log values writer factory chosen\ne4b61a4 [Piyush Narang] Tweak factory instantiation a bit\nb46cccd [Piyush Narang] Add class based factory override\n6a5428f [Piyush Narang] Clean up some stuff in ValuesWriterFactory\n0f8cd09 [Piyush Narang] Refactor mockito version\n9ead61d [Piyush Narang] Add guava test dep\n5c636c7 [Piyush Narang] Add encoding-overrides config to ParquetOutputFormat config\nb9d6c13 [Piyush Narang] Refactor code in ValuesWriterFactory a bit\nff4c90d [Piyush Narang] Pull out value writer creation to ValuesWriterFactory and add unit tests\n",
            "diff": {
                "parquet-column/src/main/java/org/apache/parquet/column/ParquetProperties.java": 176,
                "parquet-column/src/main/java/org/apache/parquet/column/values/factory/DefaultV1ValuesWriterFactory.java": 111,
                "parquet-column/src/main/java/org/apache/parquet/column/values/factory/DefaultV2ValuesWriterFactory.java": 115,
                "parquet-column/src/main/java/org/apache/parquet/column/values/factory/DefaultValuesWriterFactory.java": 87,
                "parquet-column/src/main/java/org/apache/parquet/column/values/factory/ValuesWriterFactory.java": 47,
                "parquet-column/src/test/java/org/apache/parquet/column/values/factory/DefaultValuesWriterFactoryTest.java": 350,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ParquetOutputFormat.java": 23
            },
            "is_test": true,
            "is_fix": false
        },
        "898f3d0f652f313473c67fef32e22d94d8294d4f": {
            "datetime": "2016-08-16T10:12:00-07:00",
            "summary": "PARQUET-400: Replace CompatibilityUtil with SeekableInputStream.",
            "message": "PARQUET-400: Replace CompatibilityUtil with SeekableInputStream.\n\nThis fixes PARQUET-400 by replacing `CompatibilityUtil` with `SeekableInputStream` that's implemented for hadoop-1 and hadoop-2. The benefit of this approach is that `SeekableInputStream` can be used for non-Hadoop file systems in the future.\n\nThis also changes the default Hadoop version to Hadoop-2. The library is still compatible with Hadoop 1.x, but this makes building Hadoop-2 classes, like `H2SeekableInputStream`, much easier and removes the need for multiple hadoop versions during compilation.\n\nAuthor: Ryan Blue <blue@apache.org>\n\nCloses #349 from rdblue/PARQUET-400-byte-buffers and squashes the following commits:\n\n1bcb8a8 [Ryan Blue] PARQUET-400: Fix review nits.\n823ca00 [Ryan Blue] PARQUET-400: Add tests for Hadoop 2 readFully.\n02d3709 [Ryan Blue] PARQUET-400: Remove unused property.\nb543013 [Ryan Blue] PARQUET-400: Fix logger for HadoopStreams.\n2cb6934 [Ryan Blue] PARQUET-400: Remove H2SeekableInputStream tests.\nabaa695 [Ryan Blue] PARQUET-400: Fix review items.\n5dc50a5 [Ryan Blue] PARQUET-400: Add tests for H1SeekableInputStream methods.\n730a9e2 [Ryan Blue] PARQUET-400: Move SeekableInputStream to io package.\n506a556 [Ryan Blue] PARQUET-400: Remove Hadoop dependencies from SeekableInputStream.\nc80580c [Ryan Blue] PARQUET-400: Handle UnsupportedOperationException from read(ByteBuffer).\nba08b3f [Ryan Blue] PARQUET-400: Replace CompatibilityUtil with SeekableInputStream.\n",
            "diff": {
                "parquet-common/src/main/java/org/apache/parquet/io/SeekableInputStream.java": 106,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ParquetFileReader.java": 31,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ParquetFileWriter.java": 17,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/util/CompatibilityUtil.java": 114,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/util/H1SeekableInputStream.java": 154,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/util/H2SeekableInputStream.java": 107,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/util/HadoopStreams.java": 100,
                "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/util/MockInputStream.java": 87,
                "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/util/TestHadoop1ByteBufferReads.java": 761,
                "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/util/TestHadoop2ByteBufferReads.java": 405
            },
            "is_test": true,
            "is_fix": true
        },
        "255f10834a67cf13518316de0e2c8a345677ebbf": {
            "datetime": "2016-08-16T10:40:52-07:00",
            "summary": "PARQUET-460: merge multi parquet files to one file",
            "message": "PARQUET-460: merge multi parquet files to one file\n\nA merge command for parquet-tools based on https://issues.apache.org/jira/browse/PARQUET-382.\n\nAuthor: flykobe <flykobecy@gmail.com>\n\nCloses #327 from flykobe/merge_tool and squashes the following commits:\n\nb031c18 [flykobe] check input files\nda28832 [flykobe] merge multi parquet files to one file\n",
            "diff": {
                "parquet-tools/src/main/java/org/apache/parquet/tools/command/MergeCommand.java": 157,
                "parquet-tools/src/main/java/org/apache/parquet/tools/command/Registry.java": 1
            },
            "is_test": false,
            "is_fix": false
        },
        "044de16c14076019f87763b7b58c45664ee57c11": {
            "datetime": "2016-09-08T14:22:30-07:00",
            "summary": "PARQUET-623: Fix DeltaByteArrayReader#skip.",
            "message": "PARQUET-623: Fix DeltaByteArrayReader#skip.\n\nPreviously, this passed the skip to the underlying readers, but would\nnot update previous and would corrupt values or cause exceptions.\n\nAuthor: Ryan Blue <blue@apache.org>\n\nCloses #366 from rdblue/PARQUET-623-fix-delta-byte-array-skip and squashes the following commits:\n\nf85800c [Ryan Blue] PARQUET-623: Fix DeltaByteArrayReader#skip.\n",
            "diff": {
                "parquet-column/src/main/java/org/apache/parquet/column/values/deltastrings/DeltaByteArrayReader.java": 4,
                "parquet-column/src/test/java/org/apache/parquet/column/values/deltastrings/TestDeltaByteArray.java": 18
            },
            "is_test": true,
            "is_fix": true
        },
        "e54ca615f213f5db6d34d9163c97eec98920d7a7": {
            "datetime": "2016-09-08T14:48:42-07:00",
            "summary": "PARQUET-660: Ignore extension fields in protobuf messages.",
            "message": "PARQUET-660: Ignore extension fields in protobuf messages.\n\nCurrently, converting protobuf messages with extension can result in an uninformative error or a data corruption. A more detailed explanation in the corresponding [jira](https://issues.apache.org/jira/browse/PARQUET-660).\n\nThis patch simply ignores extension fields in protobuf messages.\n\nIn the longer run, I'd like to add a proper support for Protobuf extensions. This might take a little longer though, so I've decided to improve the current situation with this patch.\n\nAuthor: Jakub Kukul <jakub.kukul@gmail.com>\n\nCloses #351 from jkukul/master and squashes the following commits:\n\n27580ab [Jakub Kukul] PARQUET-660: Throw Unsupported exception for messages with extensions.\ndb6e08b [Jakub Kukul] PARQUET-660: Refactor: Don't use additional variable for indexing fieldWriters.\ne910a8a [Jakub Kukul] PARQUET-660: Refactor: Add missing indentation.\n",
            "diff": {
                "parquet-protobuf/src/main/java/org/apache/parquet/proto/ProtoSchemaConverter.java": 30,
                "parquet-protobuf/src/main/java/org/apache/parquet/proto/ProtoWriteSupport.java": 13,
                "parquet-protobuf/src/test/java/org/apache/parquet/proto/ProtoWriteSupportTest.java": 15
            },
            "is_test": true,
            "is_fix": true
        },
        "b59be86597cfcd805c24fa406af46071400e24c8": {
            "datetime": "2016-10-03T15:04:12-07:00",
            "summary": "PARQUET-674: Add InputFile abstraction for openable files.",
            "message": "PARQUET-674: Add InputFile abstraction for openable files.\n\nAuthor: Ryan Blue <blue@apache.org>\n\nCloses #368 from rdblue/PARQUET-674-add-data-source and squashes the following commits:\n\n8c689e9 [Ryan Blue] PARQUET-674: Implement review comments.\n4a7c327 [Ryan Blue] PARQUET-674: Add DataSource abstraction for openable files.\n",
            "diff": {
                "parquet-common/src/main/java/org/apache/parquet/io/InputFile.java": 43,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ParquetFileReader.java": 32,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/util/HadoopInputFile.java": 66
            },
            "is_test": false,
            "is_fix": false
        },
        "07a42d3ffd034e467e49b5c449d4f5f81c471cc5": {
            "datetime": "2016-10-05T13:20:41-07:00",
            "summary": "PARQUET-726: Increase max difference of testMemoryManagerUpperLimit to 10%",
            "message": "PARQUET-726: Increase max difference of testMemoryManagerUpperLimit to 10%\n\nAuthor: Niels Basjes <nbasjes@bol.com>\n\nCloses #370 from nielsbasjes/PARQUET-726 and squashes the following commits:\n\nf385ede [Niels Basjes] PARQUET-726: Increase max difference of testMemoryManagerUpperLimit to 10%\n",
            "diff": {
                "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/TestMemoryManager.java": 7
            },
            "is_test": true,
            "is_fix": true
        },
        "e6da0f682436e1387ad68e86edf7418c0f7cb368": {
            "datetime": "2016-10-05T13:21:40-07:00",
            "summary": "PARQUET-685 - Deprecated ParquetInputSplit constructor passes paramet\u2026",
            "message": "PARQUET-685 - Deprecated ParquetInputSplit constructor passes paramet\u2026\n\nThe problem was not discovered because the test was bugous. Updated both sides.\n\nAuthor: Gabor Szadovszky <gabor.szadovszky@cloudera.com>\n\nCloses #372 from gszadovszky/PARQUET-685 and squashes the following commits:\n\n9cbeee2 [Gabor Szadovszky] PARQUET-685 - Deprecated ParquetInputSplit constructor passes parameters in the wrong order.\n",
            "diff": {
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ParquetInputSplit.java": 3,
                "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/TestInputFormat.java": 5
            },
            "is_test": true,
            "is_fix": true
        },
        "de99127d77dabfc6c8134b3c58e0b9a0b74e5f37": {
            "datetime": "2016-10-12T09:35:51-07:00",
            "summary": "PARQUET-686: Do not return min/max for the wrong order.",
            "message": "PARQUET-686: Do not return min/max for the wrong order.\n\nMin and max are currently calculated using the default Java ordering\nthat uses signed comparison for all values. This is not correct for\nbinary types like strings and decimals or for unsigned numeric types.\nThis commit prevents statistics accumulated using the signed ordering\nfrom being returned by ParquetMetadataConverter when the type should use\nthe unsigned ordering.\n\nBecause many binary strings are not affected by using the wrong\nordering, this adds a property, parquet.strings.use-signed-order to\nallow overriding this change.\n\nAuthor: Ryan Blue <blue@apache.org>\n\nCloses #367 from rdblue/PARQUET-686-suppress-signed-stats and squashes the following commits:\n\nf9d459f [Ryan Blue] PARQUET-686: Add getConfiguration to HadoopInputFile.\n301bd3a [Ryan Blue] PARQUET-686: Address review comments.\nc099c35 [Ryan Blue] PARQUET-686: Do not return min/max for the wrong order.\n",
            "diff": {
                "parquet-hadoop/src/main/java/org/apache/parquet/format/converter/ParquetMetadataConverter.java": 139,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ParquetFileReader.java": 34,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/util/HadoopInputFile.java": 12,
                "parquet-hadoop/src/test/java/org/apache/parquet/format/converter/TestParquetMetadataConverter.java": 53,
                "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/TestParquetFileWriter.java": 8,
                "parquet-thrift/src/test/java/org/apache/parquet/hadoop/thrift/TestThriftToParquetFileWriter.java": 2
            },
            "is_test": true,
            "is_fix": true
        },
        "59ec4f018963eb55e32fafc2b924826c39c09682": {
            "datetime": "2016-10-12T18:05:21-07:00",
            "summary": "PARQUET-743: Fix DictionaryFilter when compressed dictionaries are reused.",
            "message": "PARQUET-743: Fix DictionaryFilter when compressed dictionaries are reused.\n\nBytesInput is not supposed to be held and reused, but decompressed\ndictionary pages do this. Reusing the dictionary will cause a failure,\nso the cleanest option is to keep the bytes around once the underlying\nstream has been read.\n\nAuthor: Ryan Blue <blue@apache.org>\n\nCloses #376 from rdblue/PARQUET-743-fix-reused-dictionaries and squashes the following commits:\n\n28c0903 [Ryan Blue] PARQUET-743: Fix DictionaryFilter when dictionaries are reused.\n",
            "diff": {
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/DictionaryPageReader.java": 19,
                "parquet-hadoop/src/test/java/org/apache/parquet/filter2/dictionarylevel/DictionaryFilterTest.java": 4
            },
            "is_test": true,
            "is_fix": true
        },
        "ece4b70cce24b89483236b4cff079c10597d680a": {
            "datetime": "2016-10-18T17:45:32-07:00",
            "summary": "PARQUET-751: Add setRequestedSchema to ParquetFileReader.",
            "message": "PARQUET-751: Add setRequestedSchema to ParquetFileReader.\n\nThis fixes a bug introduced by dictionary filters, which reused an\nexisting file reader to avoid opening multiple input streams. Before\nthat commit, a new file reader was opened and passed the projection\ncolumns from the read context. The fix is to set the requested schema on\nthe file reader instead of creating a new instance.\n\nThis also adds a test to ensure that column projection works to catch\nbugs like this in the future.\n\nAuthor: Ryan Blue <blue@apache.org>\n\nCloses #379 from rdblue/PARQUET-751-fix-column-projection and squashes the following commits:\n\n7ea0c16 [Ryan Blue] PARQUET-751: Fix column projection test.\n1da507e [Ryan Blue] PARQUET-751: Add setRequestedSchema to ParquetFileReader.\n",
            "diff": {
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/InternalParquetRecordReader.java": 1,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ParquetFileReader.java": 8,
                "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/TestInputFormatColumnProjection.java": 180
            },
            "is_test": true,
            "is_fix": true
        },
        "df9d8e415436292ae33e1ca0b8da256640de9710": {
            "datetime": "2016-10-26T09:09:56-07:00",
            "summary": "PARQUET-423: Replace old Log class with SLF4J Logging",
            "message": "PARQUET-423: Replace old Log class with SLF4J Logging\n\nAnd make writing files less noisy\n\nAuthor: Niels Basjes <nbasjes@bol.com>\n\nCloses #369 from nielsbasjes/PARQUET-423-2 and squashes the following commits:\n\nb31e30f [Niels Basjes] Merge branch 'master' of github.com:apache/parquet-mr into PARQUET-423-2\n2d4db4b [Niels Basjes] Merge branch 'PARQUET-423-2' of github.com:nielsbasjes/parquet-mr into PARQUET-423-2\n49fcaa7 [Niels Basjes] PARQUET-423: Remove debug logging statements in high performance sections during build time\naaaf4a6 [Niels Basjes] Merge branch 'PARQUET-423-2' of github.com:nielsbasjes/parquet-mr into PARQUET-423-2\n745666e [Niels Basjes] Undo needless change\n94e0c7a [Niels Basjes] PARQUET-423: Further optimize logging performance\nb72f924 [Niels Basjes] PARQUET-423: Improved the performance\ncb7eb61 [Niels Basjes] PARQUET-423: Workaround AVRO errors\n7d161b3 [Niels Basjes] PARQUET-423: Restore the old (obsolete) Log class\n05d6a47 [Niels Basjes] PARQUET-423: Replace old Log class with SLF4J Logging\n692ebfb [Niels Basjes] Undo needless change\nf1ede3d [Niels Basjes] PARQUET-423: Further optimize logging performance\na0c6b59 [Niels Basjes] PARQUET-423: Improved the performance\n67bef9b [Niels Basjes] PARQUET-423: Workaround AVRO errors\n87cd64f [Niels Basjes] PARQUET-423: Restore the old (obsolete) Log class\n96d97d5 [Niels Basjes] PARQUET-423: Replace old Log class with SLF4J Logging\n",
            "diff": {
                "parquet-avro/src/test/java/org/apache/parquet/avro/TestInputOutputFormat.java": 9,
                "parquet-avro/src/test/java/org/apache/parquet/avro/TestReflectInputOutputFormat.java": 9,
                "parquet-avro/src/test/java/org/apache/parquet/avro/TestSpecificInputOutputFormat.java": 9,
                "parquet-column/src/main/java/org/apache/parquet/CorruptDeltaByteArrays.java": 11,
                "parquet-column/src/main/java/org/apache/parquet/CorruptStatistics.java": 4,
                "parquet-column/src/main/java/org/apache/parquet/column/impl/ColumnReaderImpl.java": 20,
                "parquet-column/src/main/java/org/apache/parquet/column/impl/ColumnWriterV1.java": 14,
                "parquet-column/src/main/java/org/apache/parquet/column/impl/ColumnWriterV2.java": 16,
                "parquet-column/src/main/java/org/apache/parquet/column/values/bitpacking/BitPackingValuesReader.java": 7,
                "parquet-column/src/main/java/org/apache/parquet/column/values/bitpacking/ByteBitPackingValuesReader.java": 7,
                "parquet-column/src/main/java/org/apache/parquet/column/values/deltalengthbytearray/DeltaLengthByteArrayValuesReader.java": 8,
                "parquet-column/src/main/java/org/apache/parquet/column/values/deltalengthbytearray/DeltaLengthByteArrayValuesWriter.java": 7,
                "parquet-column/src/main/java/org/apache/parquet/column/values/dictionary/DictionaryValuesReader.java": 11,
                "parquet-column/src/main/java/org/apache/parquet/column/values/dictionary/DictionaryValuesWriter.java": 11,
                "parquet-column/src/main/java/org/apache/parquet/column/values/plain/BinaryPlainValuesReader.java": 8,
                "parquet-column/src/main/java/org/apache/parquet/column/values/plain/BooleanPlainValuesReader.java": 8,
                "parquet-column/src/main/java/org/apache/parquet/column/values/plain/FixedLenByteArrayPlainValuesReader.java": 9,
                "parquet-column/src/main/java/org/apache/parquet/column/values/plain/FixedLenByteArrayPlainValuesWriter.java": 7,
                "parquet-column/src/main/java/org/apache/parquet/column/values/plain/PlainValuesReader.java": 9,
                "parquet-column/src/main/java/org/apache/parquet/column/values/plain/PlainValuesWriter.java": 7,
                "parquet-column/src/main/java/org/apache/parquet/column/values/rle/RunLengthBitPackingHybridDecoder.java": 12,
                "parquet-column/src/main/java/org/apache/parquet/column/values/rle/RunLengthBitPackingHybridEncoder.java": 12,
                "parquet-column/src/main/java/org/apache/parquet/example/data/Group.java": 10,
                "parquet-column/src/main/java/org/apache/parquet/filter2/compat/FilterCompat.java": 9,
                "parquet-column/src/main/java/org/apache/parquet/io/BaseRecordReader.java": 28,
                "parquet-column/src/main/java/org/apache/parquet/io/ColumnIO.java": 3,
                "parquet-column/src/main/java/org/apache/parquet/io/GroupColumnIO.java": 5,
                "parquet-column/src/main/java/org/apache/parquet/io/MessageColumnIO.java": 60,
                "parquet-column/src/main/java/org/apache/parquet/io/RecordConsumerLoggingWrapper.java": 49,
                "parquet-column/src/main/java/org/apache/parquet/io/RecordReaderImplementation.java": 7,
                "parquet-column/src/main/java/org/apache/parquet/io/ValidatingRecordConsumer.java": 10,
                "parquet-column/src/main/java/org/apache/parquet/schema/MessageTypeParser.java": 5,
                "parquet-column/src/test/java/org/apache/parquet/column/mem/TestMemColumn.java": 9,
                "parquet-column/src/test/java/org/apache/parquet/column/page/mem/MemPageReader.java": 8,
                "parquet-column/src/test/java/org/apache/parquet/column/page/mem/MemPageStore.java": 17,
                "parquet-column/src/test/java/org/apache/parquet/column/page/mem/MemPageWriter.java": 33,
                "parquet-column/src/test/java/org/apache/parquet/column/values/bitpacking/TestBitPackingColumn.java": 11,
                "parquet-column/src/test/java/org/apache/parquet/io/PerfTest.java": 5,
                "parquet-column/src/test/java/org/apache/parquet/io/TestColumnIO.java": 7,
                "parquet-common/src/main/java/org/apache/parquet/Closeables.java": 5,
                "parquet-common/src/main/java/org/apache/parquet/bytes/BytesUtils.java": 7,
                "parquet-common/src/test/java/org/apache/parquet/TestLog.java": 31,
                "parquet-encoding/src/main/java/org/apache/parquet/bytes/BytesInput.java": 26,
                "parquet-encoding/src/main/java/org/apache/parquet/bytes/CapacityByteArrayOutputStream.java": 12,
                "parquet-encoding/src/main/java/org/apache/parquet/column/values/bitpacking/ByteBasedBitPackingEncoder.java": 14,
                "parquet-encoding/src/test/java/org/apache/parquet/column/values/bitpacking/TestBitPacking.java": 9,
                "parquet-encoding/src/test/java/org/apache/parquet/column/values/bitpacking/TestByteBitPacking.java": 43,
                "parquet-encoding/src/test/java/org/apache/parquet/column/values/bitpacking/TestLemireBitPacking.java": 17,
                "parquet-hadoop/src/main/java/org/apache/parquet/filter2/dictionarylevel/DictionaryFilter.java": 7,
                "parquet-hadoop/src/main/java/org/apache/parquet/format/converter/ParquetMetadataConverter.java": 9,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ColumnChunkPageReadStore.java": 5,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ColumnChunkPageWriteStore.java": 10,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/DirectCodecFactory.java": 11,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/InternalParquetRecordReader.java": 28,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/InternalParquetRecordWriter.java": 16,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/LruCache.java": 34,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/MemoryManager.java": 7,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ParquetFileReader.java": 36,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ParquetFileWriter.java": 41,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ParquetInputFormat.java": 30,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ParquetOutputCommitter.java": 5,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ParquetOutputFormat.java": 28,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ParquetRecordReader.java": 5,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/UnmaterializableRecordCounter.java": 5,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/codec/CodecConfig.java": 18,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/util/HadoopStreams.java": 6,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/util/SerializationUtil.java": 5,
                "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/TestParquetFileWriter.java": 7,
                "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/example/TestInputOutputFormat.java": 9,
                "parquet-hive/parquet-hive-binding/parquet-hive-0.10-binding/src/main/java/org/apache/parquet/hive/internal/Hive010Binding.java": 5,
                "parquet-hive/parquet-hive-binding/parquet-hive-0.12-binding/src/main/java/org/apache/parquet/hive/internal/Hive012Binding.java": 5,
                "parquet-hive/parquet-hive-binding/parquet-hive-binding-factory/src/main/java/org/apache/parquet/hive/HiveBindingFactory.java": 15,
                "parquet-hive/parquet-hive-storage-handler/src/main/java/org/apache/hadoop/hive/ql/io/parquet/MapredParquetOutputFormat.java": 8,
                "parquet-hive/parquet-hive-storage-handler/src/main/java/org/apache/hadoop/hive/ql/io/parquet/read/ParquetRecordReaderWrapper.java": 6,
                "parquet-hive/parquet-hive-storage-handler/src/main/java/org/apache/hadoop/hive/ql/io/parquet/write/ParquetRecordWriterWrapper.java": 10,
                "parquet-pig/src/main/java/org/apache/parquet/pig/ParquetLoader.java": 32,
                "parquet-pig/src/main/java/org/apache/parquet/pig/PigSchemaConverter.java": 18,
                "parquet-pig/src/main/java/org/apache/parquet/pig/TupleReadSupport.java": 5,
                "parquet-pig/src/test/java/org/apache/parquet/pig/PerfTest2.java": 8,
                "parquet-pig/src/test/java/org/apache/parquet/pig/TestTupleRecordConsumer.java": 13,
                "parquet-pig/src/test/java/org/apache/parquet/pig/TupleConsumerPerfTest.java": 1,
                "parquet-protobuf/src/main/java/org/apache/parquet/proto/ProtoReadSupport.java": 11,
                "parquet-protobuf/src/main/java/org/apache/parquet/proto/ProtoSchemaConverter.java": 5,
                "parquet-protobuf/src/main/java/org/apache/parquet/proto/ProtoWriteSupport.java": 5,
                "parquet-protobuf/src/test/java/org/apache/parquet/proto/utils/WriteUsingMR.java": 9,
                "parquet-thrift/src/main/java/org/apache/parquet/hadoop/thrift/AbstractThriftWriteSupport.java": 5,
                "parquet-thrift/src/main/java/org/apache/parquet/hadoop/thrift/ThriftReadSupport.java": 9,
                "parquet-thrift/src/main/java/org/apache/parquet/thrift/ParquetReadProtocol.java": 47,
                "parquet-thrift/src/main/java/org/apache/parquet/thrift/ParquetWriteProtocol.java": 48,
                "parquet-thrift/src/main/java/org/apache/parquet/thrift/ThriftMetaData.java": 5,
                "parquet-thrift/src/main/java/org/apache/parquet/thrift/ThriftRecordConverter.java": 5,
                "parquet-thrift/src/main/java/org/apache/parquet/thrift/projection/StrictFieldProjectionFilter.java": 5,
                "parquet-thrift/src/test/java/org/apache/parquet/hadoop/thrift/TestInputOutputFormat.java": 9,
                "parquet-thrift/src/test/java/org/apache/parquet/hadoop/thrift/TestParquetToThriftReadWriteAndProjection.java": 7,
                "parquet-thrift/src/test/java/org/apache/parquet/hadoop/thrift/TestThriftToParquetFileWriter.java": 8,
                "parquet-thrift/src/test/java/org/apache/parquet/thrift/TestParquetReadProtocol.java": 7,
                "parquet-thrift/src/test/java/org/apache/parquet/thrift/TestParquetWriteProtocol.java": 13,
                "parquet-tools/src/main/java/org/apache/parquet/tools/command/MergeCommand.java": 2
            },
            "is_test": true,
            "is_fix": false
        },
        "e5cd652aeb3305ef2b82a7925cce3a132bf6f5ae": {
            "datetime": "2016-10-26T09:47:44-07:00",
            "summary": "PARQUET-753: Fixed GroupType.union() to handle original type",
            "message": "PARQUET-753: Fixed GroupType.union() to handle original type\n\nalso fixed GroupType.equals() to compare the original type and 2 unit tests that weren't setting the original type properly on the expected results\n\nAuthor: adeneche <adeneche@apache.org>\nAuthor: adeneche <adeneche@gmail.com>\n\nCloses #380 from adeneche/fix-grouptype-union and squashes the following commits:\n\nb04af7d [adeneche] reverted unnecessary formatting changes\n5461a57 [adeneche] Fixed unit tests in TestPigSchemaConverter that were failing because of my fix to GroupType.equals()\nec91315 [adeneche] fixed expected error message in TestMessageType#testMergeSchema\na1d7f63 [adeneche] Fixed GroupType.union() to handle original type\n",
            "diff": {
                "parquet-column/src/main/java/org/apache/parquet/schema/GroupType.java": 9,
                "parquet-column/src/test/java/org/apache/parquet/parser/TestParquetParser.java": 6,
                "parquet-column/src/test/java/org/apache/parquet/schema/TestMessageType.java": 29,
                "parquet-pig/src/test/java/org/apache/parquet/pig/TestPigSchemaConverter.java": 54
            },
            "is_test": true,
            "is_fix": true
        },
        "cf991604d75d446d02baddc536c7c05b43cd8dea": {
            "datetime": "2016-11-09T08:58:59-08:00",
            "summary": "PARQUET-755: create parquet-arrow module with schema converter",
            "message": "PARQUET-755: create parquet-arrow module with schema converter\n\nAuthor: Julien Le Dem <julien@dremio.com>\n\nCloses #381 from julienledem/parquet_arrow and squashes the following commits:\n\n9792683 [Julien Le Dem] PARQUET-755: create parquet-arrow module with schema converter introduces SchemaMapping add repeated mapping\n",
            "diff": {
                "parquet-arrow/src/main/java/org/apache/parquet/arrow/schema/List3Levels.java": 77,
                "parquet-arrow/src/main/java/org/apache/parquet/arrow/schema/SchemaConverter.java": 642,
                "parquet-arrow/src/main/java/org/apache/parquet/arrow/schema/SchemaMapping.java": 203,
                "parquet-arrow/src/test/java/org/apache/parquet/arrow/schema/TestSchemaConverter.java": 343,
                "parquet-column/src/main/java/org/apache/parquet/schema/Types.java": 9
            },
            "is_test": true,
            "is_fix": false
        },
        "09d28fe7995db1a4da2c651d362007d2082c663c": {
            "datetime": "2016-12-05T15:27:14-08:00",
            "summary": "PARQUET-783: Close the underlying stream when an H2SeekableInputStream is closed",
            "message": "PARQUET-783: Close the underlying stream when an H2SeekableInputStream is closed\n\nThis PR addresses https://issues.apache.org/jira/browse/PARQUET-783.\n\n`ParquetFileReader` opens a `SeekableInputStream` to read a footer. In the process, it opens a new `FSDataInputStream` and wraps it. However, `H2SeekableInputStream` does not override the `close` method. Therefore, when `ParquetFileReader` closes it, the underlying `FSDataInputStream` is not closed. As a result, these stale connections can exhaust a clusters' data nodes' connection resources and lead to mysterious HDFS read failures in HDFS clients, e.g.\n\n```\norg.apache.hadoop.hdfs.BlockMissingException: Could not obtain block: BP-905337612-172.16.70.103-1444328960665:blk_1720536852_646811517\n```\n\nAuthor: Michael Allman <michael@videoamp.com>\n\nCloses #388 from mallman/parquet-783-close_underlying_inputstream and squashes the following commits:\n\nf4b27c1 [Michael Allman] PARQUET-783 Close the underlying stream when an H2SeekableInputStream is closed\n",
            "diff": {
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/util/H2SeekableInputStream.java": 5
            },
            "is_test": false,
            "is_fix": false
        },
        "4fd34e6517f2c400a06e3c1d43ec56df2ff5c392": {
            "datetime": "2016-12-05T17:01:38-08:00",
            "summary": "PARQUET-220: Unnecessary warning in ParquetRecordReader.initialize",
            "message": "PARQUET-220: Unnecessary warning in ParquetRecordReader.initialize\n\nRather than querying the COUNTER_METHOD up front, the counter method is resolved per object. This allows us to use the\n'getCounter' method on any TaskAttemptContext with the correct signature (ignoring versions where TaskAttemptContext does\nnot have an appropriate method/signature - preserving current behavior).\n\nAuthor: Reuben Kuhnert <reuben.kuhnert@cloudera.com>\n\nCloses #280 from sircodesalotOfTheRound/context-utils-parquet-220 and squashes the following commits:\n\nf118990 [Reuben Kuhnert] PARQUET-220: Unnecessary warning in ParquetRecordReader.initialize\n",
            "diff": {
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ParquetRecordReader.java": 10,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/util/ContextUtil.java": 57,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/util/counters/BenchmarkCounter.java": 4,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/util/counters/mapreduce/MapReduceCounterLoader.java": 5,
                "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/example/TestInputOutputFormat.java": 1
            },
            "is_test": true,
            "is_fix": false
        },
        "98c27699cbcf65c3d9d655ecbcd67adcd8b45b05": {
            "datetime": "2016-12-07T11:07:03-08:00",
            "summary": "PARQUET-321: Default maximum block padding to 8MB.",
            "message": "PARQUET-321: Default maximum block padding to 8MB.\n\nrdblue's change applied to the newest code.\n\nOriginal pull request: https://github.com/apache/parquet-mr/pull/232/\n\nAuthor: Zoltan Ivanfi <zi@cloudera.com>\n\nCloses #391 from zicl/master and squashes the following commits:\n\nb1c5c1d [Zoltan Ivanfi] PARQUET-321: Default maximum block padding to 8MB.\n",
            "diff": {
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ParquetOutputFormat.java": 6,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ParquetWriter.java": 2
            },
            "is_test": false,
            "is_fix": false
        },
        "71cff7c5940b7101ff098601850d46b7a4698180": {
            "datetime": "2016-12-08T09:07:37-08:00",
            "summary": "PARQUET-791: Add missing column support for UserDefinedPredicate",
            "message": "PARQUET-791: Add missing column support for UserDefinedPredicate\n\nThis extends the fixing #354 to UserDefinedPredicate.\n\nAuthor: Liang-Chi Hsieh <viirya@gmail.com>\n\nCloses #389 from viirya/PARQUET-791 and squashes the following commits:\n\nd6be37d [Liang-Chi Hsieh] Address comment.\n7e929c3 [Liang-Chi Hsieh] PARQUET-791: Add missing column support for UserDefinedPredicate.\n",
            "diff": {
                "parquet-hadoop/src/main/java/org/apache/parquet/filter2/statisticslevel/StatisticsFilter.java": 23,
                "parquet-hadoop/src/test/java/org/apache/parquet/filter2/statisticslevel/TestStatisticsFilter.java": 74
            },
            "is_test": true,
            "is_fix": true
        },
        "89e0607cf6470dda1a6a47b46abf37468df4e50f": {
            "datetime": "2016-12-20T14:35:57-08:00",
            "summary": "PARQUET-801: Allow UserDefinedPredicates in DictionaryFilter",
            "message": "PARQUET-801: Allow UserDefinedPredicates in DictionaryFilter\n\nAuthor: Patrick Woody <pwoody@palantir.com>\nAuthor: Patrick Woody <patrick.woody1@gmail.com>\n\nCloses #394 from pwoody/pw/dictionaryUdp and squashes the following commits:\n\nd8499a0 [Patrick Woody] short circuiting and style changes\n4cb9f0c [Patrick Woody] more missing imports\n1ec0d39 [Patrick Woody] fix missing import\n3ee4489 [Patrick Woody] PARQUET-801: Allow UserDefinedPredicates in DictionaryFilter\n",
            "diff": {
                "parquet-hadoop/src/main/java/org/apache/parquet/filter2/dictionarylevel/DictionaryFilter.java": 56,
                "parquet-hadoop/src/test/java/org/apache/parquet/filter2/dictionarylevel/DictionaryFilterTest.java": 94
            },
            "is_test": true,
            "is_fix": false
        },
        "f68dbc3ea20230cb14ed3364539ad16e114bcdd9": {
            "datetime": "2017-01-26T15:32:28-08:00",
            "summary": "PARQUET-825: Static analyzer findings (NPEs, resource leaks)",
            "message": "PARQUET-825: Static analyzer findings (NPEs, resource leaks)\n\nSome trivial code fixes based on findings on static code analyzer tools (Sonar, Fortify)\n@piyushnarang: Sorry, renaming the branch caused the closing of the original PR...\n\nAuthor: Gabor Szadovszky <gabor.szadovszky@Budapests-MacBook-Pro-8.local>\nAuthor: Gabor Szadovszky <gabor.szadovszky@cloudera.com>\n\nCloses #399 from gszadovszky/PARQUET-825 and squashes the following commits:\n\n68a4764 [Gabor Szadovszky] PARQUET-825 - Static analyzer findings (NPEs, resource leaks)\na689c1c [Gabor Szadovszky] Code fixes related to null checks, exception handling and closing streams\n",
            "diff": {
                "parquet-column/src/main/java/org/apache/parquet/io/RecordReaderImplementation.java": 3,
                "parquet-common/src/main/java/org/apache/parquet/glob/GlobNode.java": 6,
                "parquet-generator/src/main/java/org/apache/parquet/encoding/bitpacking/ByteBasedBitPackingGenerator.java": 70,
                "parquet-generator/src/main/java/org/apache/parquet/encoding/bitpacking/IntBasedBitPackingGenerator.java": 76,
                "parquet-generator/src/main/java/org/apache/parquet/version/VersionGenerator.java": 6,
                "parquet-tools/src/main/java/org/apache/parquet/tools/command/DumpCommand.java": 2,
                "parquet-tools/src/main/java/org/apache/parquet/tools/command/Registry.java": 4,
                "parquet-tools/src/main/java/org/apache/parquet/tools/util/PrettyPrintWriter.java": 4
            },
            "is_test": false,
            "is_fix": false
        },
        "6fb60857be1fed21bdacc4ce830bbf99103b6fdd": {
            "datetime": "2017-01-26T15:34:22-08:00",
            "summary": "PARQUET-822: Upgrade java dependencies",
            "message": "PARQUET-822: Upgrade java dependencies\n\n2 minor code/config modification related to the version upgrades:\n- TestMemoryManager.java: I guess, it was caused by the junit upgrade however, it is not clear why it was working before. The issue was that the second run of `createWriter(1).close(null)` failed with `IOException` about that the file already exists.\n- pom.xml (added exclusion for fastutil): The shaded dependency upgrade in `parquet-column`  caused failure of API version compatibility check.\n\n`mvn clean install` worked fine. Any idea about additional testing is welcomed.\n\nAuthor: Gabor Szadovszky <gabor.szadovszky@Budapests-MacBook-Pro-8.local>\n\nCloses #398 from gszadovszky/PARQUET-822 and squashes the following commits:\n\n25d0c7f [Gabor Szadovszky] Update hadoop-1 version; back to the old httpclient because of hadoop-1 test failure\n17a8137 [Gabor Szadovszky] PARQUET-822: Upgrade java dependencies\n",
            "diff": {
                "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/TestMemoryManager.java": 2
            },
            "is_test": true,
            "is_fix": false
        },
        "3634821fa515365618209f0452443728e7290fca": {
            "datetime": "2017-01-26T15:37:57-08:00",
            "summary": "PARQUET-806: Parquet-tools silently suppresses error messages",
            "message": "PARQUET-806: Parquet-tools silently suppresses error messages\n\nThe \"error message\" that used to be\n\norg/apache/hadoop/conf/Configuration\n\nnow becomes:\n\nNoClassDefFoundError: org/apache/hadoop/conf/Configuration\n\nAuthor: Zoltan Ivanfi <zi@cloudera.com>\n\nCloses #396 from zivanfi/PARQUET-806 and squashes the following commits:\n\nb1fe699 [Zoltan Ivanfi] PARQUET-806: Parquet-tools silently suppresses error messages\n",
            "diff": {
                "parquet-tools/src/main/java/org/apache/parquet/tools/Main.java": 2
            },
            "is_test": false,
            "is_fix": false
        },
        "2fd62ee4d524c270764e9b91dca72e5cf1a005b7": {
            "datetime": "2017-01-26T15:39:31-08:00",
            "summary": "PARQUET-772: Fix locale-specific test failures.",
            "message": "PARQUET-772: Fix locale-specific test failures.\n\nThe statistics tests were failing in locales with a decimal mark other than \".\"\n\nAuthor: Zoltan Ivanfi <zi@cloudera.com>\n\nCloses #395 from zivanfi/PARQUET-772 and squashes the following commits:\n\nacec99c [Zoltan Ivanfi] PARQUET-772: Fix locale-specific test failures.\n",
            "diff": {
                "parquet-column/src/test/java/org/apache/parquet/column/statistics/TestStatistics.java": 4
            },
            "is_test": true,
            "is_fix": true
        }
    },
    "2017-02-06T15:17:05-07:00": {
        "70f28810a5547219e18ffc3465f519c454fee6e5": {
            "datetime": "2017-04-21T16:07:55-07:00",
            "summary": "PARQUET-665 Adds support for proto3",
            "message": "PARQUET-665 Adds support for proto3\n\nThis change bumps the protobuf version and adds\ntests to show compatibility with proto3. It does\nnot actually change anything else.\n\nTests are mostly identical to existing tests, and tests\nthat tested functionality not present in proto3 are not\npresent (such as groups and extensions). Proto3\noneof and map are represented in the tests.\n\nTested by running `mvn test --am --projects parquet-protobuf`\n\nAuthor: Mark Chua <mark@asana.com>\n\nCloses #407 from markchua/mkc/proto3 and squashes the following commits:\n\n40ef997 [Mark Chua] PARQUET-665 Adds support for proto3\n",
            "diff": {
                "parquet-protobuf/src/test/java/org/apache/parquet/proto/ProtoInputOutputFormatTest.java": 79,
                "parquet-protobuf/src/test/java/org/apache/parquet/proto/ProtoRecordConverterTest.java": 192,
                "parquet-protobuf/src/test/java/org/apache/parquet/proto/ProtoSchemaConverterTest.java": 63,
                "parquet-protobuf/src/test/java/org/apache/parquet/proto/ProtoWriteSupportTest.java": 138
            },
            "is_test": true,
            "is_fix": false
        },
        "a703ee75c40e0207f6831c4d48e1c7e62f160305": {
            "datetime": "2017-05-12T14:40:29-07:00",
            "summary": "PARQUET-969: Update parquet-tools to convert Decimal datatype to BigD\u2026",
            "message": "PARQUET-969: Update parquet-tools to convert Decimal datatype to BigD\u2026\n\nUpdate parquet-tools so that decimal datatypes in parquet files are converted to their actual number representation when cat'ing to stdout. Currently they are output in binary format.\n\nAuthor: dsfcode <fowler.dn@gmail.com>\n\nCloses #412 from dsfcode/master and squashes the following commits:\n\n7f05509 [dsfcode] PARQUET-969: Update parquet-tools to convert Decimal datatype to BigDecimal\n",
            "diff": {
                "parquet-tools/src/main/java/org/apache/parquet/tools/read/SimpleRecordConverter.java": 20,
                "parquet-tools/src/test/java/org/apache/parquet/tools/read/TestSimplePrimitiveRecord.java": 58
            },
            "is_test": true,
            "is_fix": false
        },
        "fd7cfed070c2aab60521afb7dcc633a0b7abea80": {
            "datetime": "2017-05-12T15:02:27-07:00",
            "summary": "PARQUET-196: parquet-tools command for row count & size",
            "message": "PARQUET-196: parquet-tools command for row count & size\n\nThis is a rebase on already existing PR-\nhttps://github.com/apache/parquet-mr/pull/132\n\nAuthor: Swapnil Shinde <swapnilushinde@gmail.com>\n\nCloses #406 from swapnilushinde/master and squashes the following commits:\n\n59a8980 [Swapnil Shinde] Spacing to conform java style (if/for) is fixed\n5fd0279 [Swapnil Shinde] Parquet-196: parquet-tools command for row count & size\n",
            "diff": {
                "parquet-tools/src/main/java/org/apache/parquet/tools/command/Registry.java": 2,
                "parquet-tools/src/main/java/org/apache/parquet/tools/command/RowCountCommand.java": 97,
                "parquet-tools/src/main/java/org/apache/parquet/tools/command/SizeCommand.java": 140
            },
            "is_test": false,
            "is_fix": false
        },
        "1de41ef4baeee1c95e245837299f8be265294445": {
            "datetime": "2017-05-12T15:09:56-07:00",
            "summary": "PARQUET-852: Slowly ramp up sizes of byte[] in ByteBasedBitPackingEncoder",
            "message": "PARQUET-852: Slowly ramp up sizes of byte[] in ByteBasedBitPackingEncoder\n\nhttps://issues.apache.org/jira/browse/PARQUET-852\n\nAuthor: John Jenkins <jjenkins@kcg.com>\n\nCloses #401 from JohnPJenkins/PARQUET-852 and squashes the following commits:\n\n334acec [John Jenkins] PARQUET-852: Slowly ramp up sizes of byte[] in ByteBasedBitPackingEncoder\n",
            "diff": {
                "parquet-encoding/src/main/java/org/apache/parquet/column/values/bitpacking/ByteBasedBitPackingEncoder.java": 30,
                "parquet-encoding/src/test/java/org/apache/parquet/column/values/bitpacking/TestByteBasedBitPackingEncoder.java": 18
            },
            "is_test": true,
            "is_fix": false
        },
        "9491d7a61681f7acc7103a6d1d45efe96f7981d2": {
            "datetime": "2017-05-16T17:19:06-07:00",
            "summary": "PARQUET-990 More detailed error messages in footer parsing",
            "message": "PARQUET-990 More detailed error messages in footer parsing\n\nInclude invalid values in exception messages when reading footer for two situations:\n\n- too-short files (include file length)\n- files with corrupted footer lengths (include calculated footer start index)\n\nAuthor: Andrew Ash <andrew@andrewash.com>\n\nCloses #408 from ash211/patch-1 and squashes the following commits:\n\n74f5836 [Andrew Ash] More detailed error messages in footer parsing\n",
            "diff": {
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ParquetFileReader.java": 4
            },
            "is_test": false,
            "is_fix": false
        },
        "9d58b6a83aa79dcad01c3bcc2ec0a7db74ba83b1": {
            "datetime": "2017-06-07T15:22:28-07:00",
            "summary": "Parquet-884: Add support for Decimal datatype to Parquet-Pig record reader",
            "message": "Parquet-884: Add support for Decimal datatype to Parquet-Pig record reader\n\nAdds conversion support to Pig for Decimal datatype. Based on the scala code in the spark project that provides a similar function for their sql library.\n\nAuthor: EllenKletscher <ellen.kletscher@capitalone.com>\n\nCloses #404 from EllenKletscher/master and squashes the following commits:\n\n7714738 [EllenKletscher] add comment for precision check\n50c75c8 [EllenKletscher] remove check for primitiveType null\n08d4dbb [EllenKletscher] PARQUET-884: Add missing AL header\n57c4d72 [EllenKletscher] PARQUET-884: Add missing AL header\nea61267 [EllenKletscher] PARQUET-884: add support for decimal type to pig reader\n",
            "diff": {
                "parquet-pig/src/main/java/org/apache/parquet/pig/PigSchemaConverter.java": 8,
                "parquet-pig/src/main/java/org/apache/parquet/pig/convert/DecimalUtils.java": 65,
                "parquet-pig/src/main/java/org/apache/parquet/pig/convert/TupleConverter.java": 27,
                "parquet-pig/src/test/java/org/apache/parquet/pig/TestDecimalUtils.java": 79
            },
            "is_test": true,
            "is_fix": false
        },
        "2d3203b10cc8edf71a6e3e0822f0d742c9516aa3": {
            "datetime": "2017-06-09T11:34:21-07:00",
            "summary": "PARQUET-1005: Fix DumpCommand parsing to allow column projection",
            "message": "PARQUET-1005: Fix DumpCommand parsing to allow column projection\n\nDumpCommand option for -c is specified as hasArgs() for unlimited\nnumber of arguments following -c. The very description of the option\nshows the real intent of using hasArg() such that multiple columns\ncan be specified as '-c c1 -c c2 ...'. Otherwise, the input path\nis parsed as an argument for -c instead of the command itself.\n\nAuthor: Gera Shegalov <gera@twitter.com>\n\nCloses #413 from gerashegalov/dump_specific_columns_fix and squashes the following commits:\n\na6b2df3 [Gera Shegalov] Fix DumpCommand parsing to allow column projection\n",
            "diff": {
                "parquet-tools/src/main/java/org/apache/parquet/tools/Main.java": 7,
                "parquet-tools/src/main/java/org/apache/parquet/tools/command/DumpCommand.java": 9
            },
            "is_test": false,
            "is_fix": false
        },
        "352b906996f392030bfd53b93e3cf4adb78d1a55": {
            "datetime": "2017-06-09T14:31:14-07:00",
            "summary": "PARQUET-1026: allow unsigned binary stats when min == max",
            "message": "PARQUET-1026: allow unsigned binary stats when min == max\n\nWhen min equals max this is a special case where unsigned stats would actually be the same as signed stats since there is only one value.\nThis is useful when the data is partitioned by that column and there's only one value in the file.\nDrill for example takes advantage of this.\n\nAuthor: Julien Le Dem <julien@apache.org>\n\nCloses #416 from julienledem/min_eq_max and squashes the following commits:\n\n1d71624 [Julien Le Dem] revert package import ordering change\n47d89fc [Julien Le Dem] allow unsigned binary stats when min == max\n",
            "diff": {
                "parquet-hadoop/src/main/java/org/apache/parquet/format/converter/ParquetMetadataConverter.java": 7,
                "parquet-hadoop/src/test/java/org/apache/parquet/format/converter/TestParquetMetadataConverter.java": 22,
                "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/TestParquetFileWriter.java": 11
            },
            "is_test": true,
            "is_fix": false
        },
        "df9f8d869fe47a116e9e78fb59ab55d84ffa13d1": {
            "datetime": "2017-06-09T15:22:31-07:00",
            "summary": "PARQUET-1024: allow for case insensitive parquet-xxx prefix in PR title",
            "message": "PARQUET-1024: allow for case insensitive parquet-xxx prefix in PR title\n\nAuthor: Julien Le Dem <julien@apache.org>\n\nCloses #415 from julienledem/improve_merge and squashes the following commits:\n\n0e34366 [Julien Le Dem] PARQUET-1024: allow for case insensitive parquet-xxx prefix in PR title\n",
            "diff": {
                "dev/merge_parquet_pr.py": 4
            },
            "is_test": false,
            "is_fix": false
        },
        "ddbeb4dd17d9c219b99b1e66d8be28efe37e3aa6": {
            "datetime": "2017-07-28T16:25:21-07:00",
            "summary": "PARQUET-777: Add Parquet CLI.",
            "message": "PARQUET-777: Add Parquet CLI.\n\nThis adds a new parquet-cli module with an improved command-line tool. The parquet-cli/README.md file has instructions for building and testing locally.\n\nAuthor: Ryan Blue <blue@apache.org>\nAuthor: Tom White <tom@cloudera.com>\n\nCloses #384 from rdblue/PARQUET-777-add-parquet-cli and squashes the following commits:\n\nde49eff [Ryan Blue] PARQUET-777: Move dynamic support classes, add tests.\naffdfb9 [Ryan Blue] PARQUET-777: Update for review feedback.\nf953fd4 [Ryan Blue] PARQUET-777: Update README.md with better instructions.\naed223d [Tom White] Replace source file headers with Apache header.\nd718363 [Ryan Blue] PARQUET-777: Add Parquet CLI.\n",
            "diff": {
                "parquet-cli/src/main/java/org/apache/parquet/cli/BaseCommand.java": 397,
                "parquet-cli/src/main/java/org/apache/parquet/cli/Command.java": 40,
                "parquet-cli/src/main/java/org/apache/parquet/cli/HadoopFileSystemURLStreamHandler.java": 79,
                "parquet-cli/src/main/java/org/apache/parquet/cli/Help.java": 147,
                "parquet-cli/src/main/java/org/apache/parquet/cli/Main.java": 178,
                "parquet-cli/src/main/java/org/apache/parquet/cli/Util.java": 335,
                "parquet-cli/src/main/java/org/apache/parquet/cli/commands/CSVSchemaCommand.java": 131,
                "parquet-cli/src/main/java/org/apache/parquet/cli/commands/CatCommand.java": 106,
                "parquet-cli/src/main/java/org/apache/parquet/cli/commands/CheckParquet251Command.java": 351,
                "parquet-cli/src/main/java/org/apache/parquet/cli/commands/ConvertCSVCommand.java": 204,
                "parquet-cli/src/main/java/org/apache/parquet/cli/commands/ConvertCommand.java": 165,
                "parquet-cli/src/main/java/org/apache/parquet/cli/commands/ParquetMetadataCommand.java": 180,
                "parquet-cli/src/main/java/org/apache/parquet/cli/commands/SchemaCommand.java": 138,
                "parquet-cli/src/main/java/org/apache/parquet/cli/commands/ShowDictionaryCommand.java": 131,
                "parquet-cli/src/main/java/org/apache/parquet/cli/commands/ShowPagesCommand.java": 217,
                "parquet-cli/src/main/java/org/apache/parquet/cli/commands/ToAvroCommand.java": 141,
                "parquet-cli/src/main/java/org/apache/parquet/cli/csv/AvroCSV.java": 258,
                "parquet-cli/src/main/java/org/apache/parquet/cli/csv/AvroCSVReader.java": 121,
                "parquet-cli/src/main/java/org/apache/parquet/cli/csv/CSVProperties.java": 111,
                "parquet-cli/src/main/java/org/apache/parquet/cli/csv/RecordBuilder.java": 200,
                "parquet-cli/src/main/java/org/apache/parquet/cli/json/AvroJson.java": 636,
                "parquet-cli/src/main/java/org/apache/parquet/cli/json/AvroJsonReader.java": 85,
                "parquet-cli/src/main/java/org/apache/parquet/cli/util/Codecs.java": 50,
                "parquet-cli/src/main/java/org/apache/parquet/cli/util/Expressions.java": 391,
                "parquet-cli/src/main/java/org/apache/parquet/cli/util/Formats.java": 47,
                "parquet-cli/src/main/java/org/apache/parquet/cli/util/GetClassLoader.java": 39,
                "parquet-cli/src/main/java/org/apache/parquet/cli/util/RecordException.java": 53,
                "parquet-cli/src/main/java/org/apache/parquet/cli/util/RuntimeIOException.java": 31,
                "parquet-cli/src/main/java/org/apache/parquet/cli/util/Schemas.java": 498,
                "parquet-cli/src/main/java/org/apache/parquet/cli/util/SeekableFSDataInputStream.java": 76,
                "parquet-common/src/main/java/org/apache/parquet/Exceptions.java": 34,
                "parquet-common/src/main/java/org/apache/parquet/util/DynConstructors.java": 273,
                "parquet-common/src/main/java/org/apache/parquet/util/DynMethods.java": 520,
                "parquet-common/src/test/java/org/apache/parquet/TestUtils.java": 70,
                "parquet-common/src/test/java/org/apache/parquet/util/Concatenator.java": 82,
                "parquet-common/src/test/java/org/apache/parquet/util/TestDynConstructors.java": 235,
                "parquet-common/src/test/java/org/apache/parquet/util/TestDynMethods.java": 410
            },
            "is_test": true,
            "is_fix": false
        }
    },
    "2017-08-05T15:17:05-07:00": {
        "d55a572e5867832f6d5755fcd46101da51a38aa4": {
            "datetime": "2017-10-10T16:20:55-07:00",
            "summary": "PARQUET-1133 Add int96 support by returning bytearray, Skip originalType comparison for map types when originalType is null",
            "message": "PARQUET-1133 Add int96 support by returning bytearray, Skip originalType comparison for map types when originalType is null\n\n- PigSchemaConverter: Added a null check before comparing a mapKeyValueType's original type with the static constant\n- PigSchemaConverter: Changed the handling of int96 types - return bytearray instead of rejecting input\n- PigSchemaConverterTest: Added unit tests for int96 conversion and handling map entries without original type specified\n\nAuthor: Addisu Feyissa <addisu.feyissa@C1159.local>\n\nCloses #422 from adisu-feyissa/hotfix/remove_originalType_check_for_maps_and_add_int96_support and squashes the following commits:\n\ne6fa3444 [Addisu Feyissa] - PigSchemaConverter: Added a null check before comparing a mapKeyValueType's original type with the static constant - PigSchemaConverter: Changed the handling of int96 types - return bytearray instead of rejecting input - PigSchemaConverTest: Added unit tests for int96 conversion and handling map entries without original type specified\n",
            "diff": {
                "parquet-pig/src/main/java/org/apache/parquet/pig/PigSchemaConverter.java": 5,
                "parquet-pig/src/test/java/org/apache/parquet/pig/TestPigSchemaConverter.java": 28
            },
            "is_test": true,
            "is_fix": true
        },
        "328c5deb015ee5bc0a24623bc29225f6ec1ae23d": {
            "datetime": "2017-11-07T14:37:39+01:00",
            "summary": "PARQUET-1115: Warn users when misusing parquet-tools merge",
            "message": "PARQUET-1115: Warn users when misusing parquet-tools merge\n\nAuthor: Nandor Kollar <nkollar@cloudera.com>\n\nCloses #433 from nandorKollar/PARQUET-1115 and squashes the following commits:\n\n5504a39 [Nandor Kollar] PARQUET-1115: Warn users when misusing parquet-tools merge\nf2ece26 [Nandor Kollar] PARQUET-1115: Warn users when misusing parquet-tools merge\n4f3ec99 [Nandor Kollar] PARQUET-1115: Warn users when misusing parquet-tools merge\nf97e620 [Nandor Kollar] PARQUET-1115: Prevent users from misusing parquet-tools merge\n",
            "diff": {
                "parquet-tools/src/main/java/org/apache/parquet/tools/Main.java": 1,
                "parquet-tools/src/main/java/org/apache/parquet/tools/command/CatCommand.java": 5,
                "parquet-tools/src/main/java/org/apache/parquet/tools/command/Command.java": 3,
                "parquet-tools/src/main/java/org/apache/parquet/tools/command/DumpCommand.java": 7,
                "parquet-tools/src/main/java/org/apache/parquet/tools/command/HeadCommand.java": 5,
                "parquet-tools/src/main/java/org/apache/parquet/tools/command/MergeCommand.java": 26,
                "parquet-tools/src/main/java/org/apache/parquet/tools/command/RowCountCommand.java": 5,
                "parquet-tools/src/main/java/org/apache/parquet/tools/command/ShowMetaCommand.java": 8,
                "parquet-tools/src/main/java/org/apache/parquet/tools/command/ShowSchemaCommand.java": 7,
                "parquet-tools/src/main/java/org/apache/parquet/tools/command/SizeCommand.java": 5,
                "parquet-tools/src/main/java/org/apache/parquet/tools/read/SimpleRecord.java": 7,
                "parquet-tools/src/main/java/org/apache/parquet/tools/read/SimpleRecordConverter.java": 12,
                "parquet-tools/src/main/java/org/apache/parquet/tools/util/MetadataUtils.java": 3
            },
            "is_test": false,
            "is_fix": false
        },
        "170cfa758547b4d9be50058ad93cf60ce0da5564": {
            "datetime": "2017-11-09T11:23:01+01:00",
            "summary": "PARQUET-1152: Parquet-thrift doesn't compile with Thrift 0.9.3",
            "message": "PARQUET-1152: Parquet-thrift doesn't compile with Thrift 0.9.3\n\nAuthor: Nandor Kollar <nkollar@cloudera.com>\n\nCloses #432 from nandorKollar/PARQUET-1152 and squashes the following commits:\n\nfd578ec [Zoltan Ivanfi] Undo unrelated whitespace changes.\n8bbcfad [Nandor Kollar] PARQUET-1152: Parquet-thrift doesn't compile with Thrift 0.9.3\n",
            "diff": {
                "parquet-thrift/src/main/java/org/apache/parquet/hadoop/thrift/ThriftBytesWriteSupport.java": 22
            },
            "is_test": false,
            "is_fix": false
        },
        "c532b0e637f28eb934f28f7f1d7c0889b1e5c811": {
            "datetime": "2017-11-09T17:16:53+01:00",
            "summary": "PARQUET-1153: Parquet-thrift doesn't compile with Thrift 0.10.0",
            "message": "PARQUET-1153: Parquet-thrift doesn't compile with Thrift 0.10.0\n\nAuthor: Nandor Kollar <nkollar@cloudera.com>\n\nCloses #434 from nandorKollar/PARQUET-1153 and squashes the following commits:\n\nb2da7c0 [Nandor Kollar] PARQUET-1153: Parquet-thrift doesn't compile with Thrift 0.10.0\n5e96e7f [Nandor Kollar] PARQUET-1153: Parquet-thrift doesn't compile with Thrift 0.10.0\nad237b0 [Nandor Kollar] PARQUET-1153: Parquet-thrift doesn't compile with Thrift 0.10.0\n0e4e0f9 [Nandor Kollar] PARQUET-1153: Parquet-thrift doesn't compile with Thrift 0.10.0\n29544b3 [Nandor Kollar] PARQUET-1153: Parquet-thrift doesn't compile with Thrift 0.10.0\n",
            "diff": {
                "parquet-hive/parquet-hive-binding/parquet-hive-binding-interface/src/main/java/org/apache/parquet/hive/HiveBinding.java": 2,
                "parquet-hive/parquet-hive-storage-handler/src/main/java/org/apache/hadoop/hive/ql/io/parquet/read/DataWritableReadSupport.java": 2
            },
            "is_test": false,
            "is_fix": false
        },
        "132b2a8c553bdcfd445e88680beac6f225c50ac4": {
            "datetime": "2017-11-14T16:16:28-08:00",
            "summary": "PARQUET-1143: Update to Parquet format 2.4.0.",
            "message": "PARQUET-1143: Update to Parquet format 2.4.0.\n\nThis adds new compression codecs that are required by format 2.4.0.\n\nAuthor: Ryan Blue <blue@apache.org>\n\nCloses #430 from rdblue/PARQUET-1143-format-2.4.0-updates and squashes the following commits:\n\n0aca87812 [Ryan Blue] PARQUET-1143: Remove staging repository now that 2.4.0 is released.\n89b01cb64 [Ryan Blue] PARQUET-1143: Make brotli-codec an optional dependency.\na2f57ba5b [Ryan Blue] PARQUET-1143: Drop hadoop-1 tests from Travis CI.\nd0f81d7cd [Ryan Blue] PARQUET-1143: Use slf4j-simple and log4j in Thrift/Pig tests.\n326b8ac74 [Ryan Blue] PARQUET-1143: Update Travis to use the default ubuntu image.\n4ad46f94c [Ryan Blue] PARQUET-1143: Use slf4j-log4j12 in Pig tests.\n785e84dff [Ryan Blue] PARQUET-1143: Fix Travis CI.\nefa171fda [Ryan Blue] PARQUET-1143: Ban slf4j-log4j12 dependency.\nbf61e84ab [Ryan Blue] PARQUET-1143: Update to Parquet format 2.4.0.\n",
            "diff": {
                "parquet-cli/src/main/java/org/apache/parquet/cli/Util.java": 6,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/metadata/CompressionCodecName.java": 5,
                "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/TestDirectCodecFactory.java": 14
            },
            "is_test": true,
            "is_fix": false
        },
        "81f480149054399d28b0609482c978788d9f5895": {
            "datetime": "2017-11-29T16:00:19+01:00",
            "summary": "PARQUET-1156: Address dev/merge_parquet_pr.py problems.",
            "message": "PARQUET-1156: Address dev/merge_parquet_pr.py problems.\n\nAuthor: Zoltan Ivanfi <zi@cloudera.com>\n\nCloses #437 from zivanfi/PARQUET-1156 and squashes the following commits:\n\ncb4e8dc [Zoltan Ivanfi] PARQUET-1156: Address dev/merge_parquet_pr.py problems.\n",
            "diff": {
                "dev/merge_parquet_pr.py": 49
            },
            "is_test": false,
            "is_fix": false
        },
        "8bfd9b4d8f4fb0a2b522c9328f67eb642066306b": {
            "datetime": "2017-12-13T11:27:54-08:00",
            "summary": "PARQUET-1142: Add alternatives to Hadoop classes in the API",
            "message": "PARQUET-1142: Add alternatives to Hadoop classes in the API\n\nThis updates the read and write paths to avoid using Hadoop classes where possible.\n\n* Adds a generic compression interface, `CompressionCodecFactory`\n* Adds `OutputFile` and `PositionOutputStream`\n* Adds classes to help implementations wrap input and output streams: `DelegatingSeekableInputStream` and `DelegatingPositionOutputStream`\n* Adds `ParquetReadOptions` to avoid passing options with `Configuration`\n* Updates the read and write APIs to use new abstractions instead of Hadoop\n\nAuthor: Ryan Blue <blue@apache.org>\n\nCloses #429 from rdblue/PARQUET-1142-add-hadoop-alternatives and squashes the following commits:\n\n21500337b [Ryan Blue] PARQUET-1142: Fix NPE when not filtering with new read API.\n35eddd735 [Ryan Blue] PARQUET-1142: Fix problems from Gabor's review.\nda391b0d4 [Ryan Blue] PARQUET-1142: Fix binary incompatibilities.\n2e3d693ab [Ryan Blue] PARQUET-1142: Update the read and write paths to use new files and streams.\n8d57e089f [Ryan Blue] PARQUET-1142: Add OutputFile and PositionOutputStream.\n42908a95e [Ryan Blue] PARQUET-1142: Extract non-Hadoop API from CodecFactory.\n",
            "diff": {
                "parquet-common/src/main/java/org/apache/parquet/compression/CompressionCodecFactory.java": 47,
                "parquet-common/src/main/java/org/apache/parquet/hadoop/codec/CompressionCodecNotSupportedException.java": 38,
                "parquet-common/src/main/java/org/apache/parquet/io/DelegatingPositionOutputStream.java": 63,
                "parquet-common/src/main/java/org/apache/parquet/io/DelegatingSeekableInputStream.java": 171,
                "parquet-common/src/main/java/org/apache/parquet/io/InputFile.java": 9,
                "parquet-common/src/main/java/org/apache/parquet/io/OutputFile.java": 34,
                "parquet-common/src/main/java/org/apache/parquet/io/PositionOutputStream.java": 39,
                "parquet-common/src/test/java/org/apache/parquet/io/MockInputStream.java": 56,
                "parquet-encoding/src/main/java/org/apache/parquet/bytes/BytesInput.java": 0,
                "parquet-encoding/src/main/java/org/apache/parquet/bytes/CapacityByteArrayOutputStream.java": 0,
                "parquet-encoding/src/main/java/org/apache/parquet/bytes/ConcatenatingByteArrayCollector.java": 0,
                "parquet-encoding/src/main/java/org/apache/parquet/bytes/LittleEndianDataInputStream.java": 0,
                "parquet-encoding/src/main/java/org/apache/parquet/bytes/LittleEndianDataOutputStream.java": 0,
                "parquet-hadoop/src/main/java/org/apache/parquet/HadoopReadOptions.java": 98,
                "parquet-hadoop/src/main/java/org/apache/parquet/ParquetReadOptions.java": 232,
                "parquet-hadoop/src/main/java/org/apache/parquet/filter2/compat/RowGroupFilter.java": 4,
                "parquet-hadoop/src/main/java/org/apache/parquet/format/converter/ParquetMetadataConverter.java": 22,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/CodecFactory.java": 26,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ColumnChunkPageReadStore.java": 6,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/DirectCodecFactory.java": 12,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/InternalParquetRecordReader.java": 34,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ParquetFileReader.java": 256,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ParquetFileWriter.java": 147,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ParquetInputFormat.java": 3,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ParquetOutputFormat.java": 5,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ParquetReader.java": 176,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ParquetRecordReader.java": 26,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ParquetWriter.java": 50,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/UnmaterializableRecordCounter.java": 15,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/codec/CompressionCodecNotSupportedException.java": 36,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/metadata/CompressionCodecName.java": 36,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/util/H1SeekableInputStream.java": 101,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/util/H2SeekableInputStream.java": 20,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/util/HadoopCodecs.java": 39,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/util/HadoopOutputFile.java": 100,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/util/HadoopPositionOutputStream.java": 66,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/util/HadoopStreams.java": 15,
                "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/TestInputOutputFormatWithPadding.java": 6,
                "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/TestParquetFileWriter.java": 1,
                "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/util/MockInputStream.java": 4,
                "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/util/TestHadoop1ByteBufferReads.java": 354,
                "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/util/TestHadoop2ByteBufferReads.java": 30,
                "parquet-tools/src/main/java/org/apache/parquet/tools/command/MergeCommand.java": 3
            },
            "is_test": true,
            "is_fix": false
        },
        "da3e8eb7e5a8cdc28ab0e36651bd7eceed35c2fe": {
            "datetime": "2018-01-04T17:50:39+01:00",
            "summary": "PARQUET-357: Parquet-thrift generates wrong schema for Thrift binary fields",
            "message": "PARQUET-357: Parquet-thrift generates wrong schema for Thrift binary fields\n\nAuthor: Nandor Kollar <nkollar@cloudera.com>\n\nCloses #439 from nandorKollar/PARQUET-357 and squashes the following commits:\n\n90cfcfb [Nandor Kollar] Address code review feedback\n4bf8089 [Nandor Kollar] PARQUET-357: Parquet-thrift generates wrong schema for Thrift binary fields\n",
            "diff": {
                "parquet-thrift/src/main/java/org/apache/parquet/thrift/ThriftSchemaConvertVisitor.java": 2,
                "parquet-thrift/src/main/java/org/apache/parquet/thrift/ThriftSchemaConverter.java": 8,
                "parquet-thrift/src/main/java/org/apache/parquet/thrift/struct/ThriftType.java": 10,
                "parquet-thrift/src/test/java/org/apache/parquet/hadoop/thrift/TestBinary.java": 27
            },
            "is_test": true,
            "is_fix": true
        },
        "9191fbd202cd76d03fc23057c5a16cac547d90df": {
            "datetime": "2018-01-04T10:32:31-08:00",
            "summary": "PARQUET-1141: Fix field ID handling",
            "message": "PARQUET-1141: Fix field ID handling\n\nThere are two places where field IDs are dropped:\n* Map and list type builders were not passing IDs when building\n* ParquetMetadataConverter was not writing field IDs or reading the ID for root schemas\n\nAuthor: Ryan Blue <blue@apache.org>\n\nCloses #428 from rdblue/PARQUET-1141-fix-column-ids and squashes the following commits:\n\n475a90ed7 [Ryan Blue] PARQUET-1141: Fix tests by adding Type$ID#getId.\ne110c00a7 [Ryan Blue] PARQUET-1141: Fix IDs in ParquetMetadataConverter.\na63066a8c [Ryan Blue] PARQUET-1141: Fix IDs for lists and maps.\n",
            "diff": {
                "parquet-column/src/main/java/org/apache/parquet/schema/Type.java": 10,
                "parquet-column/src/main/java/org/apache/parquet/schema/Types.java": 18,
                "parquet-hadoop/src/main/java/org/apache/parquet/format/converter/ParquetMetadataConverter.java": 12
            },
            "is_test": false,
            "is_fix": false
        },
        "3783ca4476fec8186c867e4e57084e649c318c6b": {
            "datetime": "2018-01-10T14:54:01+01:00",
            "summary": "PARQUET-1185: TestBinary#testBinary unit test fails after PARQUET-1141",
            "message": "PARQUET-1185: TestBinary#testBinary unit test fails after PARQUET-1141\n\nAuthor: Nandor Kollar <nkollar@cloudera.com>\n\nCloses #444 from nandorKollar/PARQUET-1185 and squashes the following commits:\n\n533aeb4 [Nandor Kollar] PARQUET-1185: TestBinary#testBinary unit test fails after PARQUET-1141\ne75adef [Nandor Kollar] PARQUET-1185: TestBinary#testBinary unit test fails after PARQUET-1141\n5e919cb [Nandor Kollar] PARQUET-1185: TestBinary#testBinary unit test fails after PARQUET-1141\n",
            "diff": {
                "parquet-thrift/src/test/java/org/apache/parquet/hadoop/thrift/TestBinary.java": 4
            },
            "is_test": true,
            "is_fix": true
        },
        "4d996d1bac1bb1886cd9c473ba00e53e3c19cf3e": {
            "datetime": "2018-01-10T14:59:24+01:00",
            "summary": "PARQUET-386: Printing out the statistics of metadata in parquet-tools",
            "message": "PARQUET-386: Printing out the statistics of metadata in parquet-tools\n\nAuthor: Gabor Szadovszky <gabor.szadovszky@cloudera.com>\n\nCloses #442 from gszadovszky/PARQUET-386 and squashes the following commits:\n\ndb8c4b9 [Gabor Szadovszky] PARQUET-386: Printing out the statistics of metadata in parquet-tools\n",
            "diff": {
                "parquet-tools/src/main/java/org/apache/parquet/tools/util/MetadataUtils.java": 7
            },
            "is_test": false,
            "is_fix": false
        },
        "c6764c4a0848abf1d581e22df8b33e28ee9f2ced": {
            "datetime": "2018-01-12T16:29:48-08:00",
            "summary": "PARQUET-1025: Support new min-max statistics in parquet-mr",
            "message": "PARQUET-1025: Support new min-max statistics in parquet-mr\n\nAuthor: Gabor Szadovszky <gabor.szadovszky@cloudera.com>\n\nCloses #435 from gszadovszky/PARQUET-1025 and squashes the following commits:\n\n2a63fcf13 [Gabor Szadovszky] PARQUET-1025: Use constant instead of creating new TypeDefinedOrder instances\n820df6fb7 [Gabor Szadovszky] PARQUET-1025: Minor fixes at data generation for TestStatistics\ndc838f273 [Gabor Szadovszky] PARQUET-1025: Implement ColumnOrder; other updates for rdblue's findings\n524750be0 [Gabor Szadovszky] PARQUET-1025: Some updates for zi's findings\na2ae97ce5 [Gabor Szadovszky] PARQUET-1025: Unified formatting/comments/deprecation\nbc86e8a63 [Gabor Szadovszky] PARQUET-1025: Updates according to rdblue's comments\n70e56a759 [Gabor Szadovszky] PARQUET-1025: Add explicit list of types to not to read/write statistics\n95199e5e0 [Gabor Szadovszky] PARQUET-1025: Use lexicographical comparison for Binary.compareTo Also rename SIGNED_BINARY_COMPARATOR to a more descriptive name Also added comments for haxa representation of values at unsigned comparison testing\n2f28c2c0e [Gabor Szadovszky] PARQUET-1025: Finalize read/write stats updates\nc5536a0a3 [Gabor Szadovszky] PARQUET-1025: Some modifications according to zi's comments\n318e585d9 [Gabor Szadovszky] PARQUET-1025: Finalize reading/writing new stats; modify/implement unit tests accordingly\n688ef2efe [Gabor Szadovszky] PARQUET-1025: Updates according to zi's and rdblue's comments\n51bc1f827 [Gabor Szadovszky] PARQUET-1025: Add the proper comparators as required; revert Binary related changes\n20b937f46 [Gabor Szadovszky] PARQUET-1025: reading/writing new min-max statistics; use the comparators as needed\n52cd58f61 [Gabor Szadovszky] PARQUET-1025: Move comparators to Type\n3378b6d34 [Gabor Szadovszky] PARQUET-1025: Implement comparators and use them with statistics\ne1719bb3b [Gabor Szadovszky] PARQUET-1025: Refactor Binary to prepare from custom comparators\n",
            "diff": {
                "parquet-cli/src/main/java/org/apache/parquet/cli/Util.java": 50,
                "parquet-cli/src/main/java/org/apache/parquet/cli/commands/CheckParquet251Command.java": 11,
                "parquet-column/src/main/java/org/apache/parquet/column/ColumnDescriptor.java": 40,
                "parquet-column/src/main/java/org/apache/parquet/column/impl/ColumnWriterV1.java": 2,
                "parquet-column/src/main/java/org/apache/parquet/column/impl/ColumnWriterV2.java": 2,
                "parquet-column/src/main/java/org/apache/parquet/column/statistics/BinaryStatistics.java": 49,
                "parquet-column/src/main/java/org/apache/parquet/column/statistics/BooleanStatistics.java": 53,
                "parquet-column/src/main/java/org/apache/parquet/column/statistics/DoubleStatistics.java": 58,
                "parquet-column/src/main/java/org/apache/parquet/column/statistics/FloatStatistics.java": 59,
                "parquet-column/src/main/java/org/apache/parquet/column/statistics/IntStatistics.java": 59,
                "parquet-column/src/main/java/org/apache/parquet/column/statistics/LongStatistics.java": 59,
                "parquet-column/src/main/java/org/apache/parquet/column/statistics/Statistics.java": 195,
                "parquet-column/src/main/java/org/apache/parquet/column/statistics/StatisticsClassException.java": 14,
                "parquet-column/src/main/java/org/apache/parquet/filter2/predicate/Statistics.java": 36,
                "parquet-column/src/main/java/org/apache/parquet/filter2/recordlevel/IncrementallyUpdatedFilterPredicateBuilderBase.java": 19,
                "parquet-column/src/main/java/org/apache/parquet/io/MessageColumnIO.java": 2,
                "parquet-column/src/main/java/org/apache/parquet/io/PrimitiveColumnIO.java": 7,
                "parquet-column/src/main/java/org/apache/parquet/io/api/Binary.java": 120,
                "parquet-column/src/main/java/org/apache/parquet/schema/ColumnOrder.java": 97,
                "parquet-column/src/main/java/org/apache/parquet/schema/MessageType.java": 6,
                "parquet-column/src/main/java/org/apache/parquet/schema/PrimitiveComparator.java": 290,
                "parquet-column/src/main/java/org/apache/parquet/schema/PrimitiveType.java": 187,
                "parquet-column/src/main/java/org/apache/parquet/schema/Types.java": 20,
                "parquet-column/src/test/java/org/apache/parquet/column/statistics/TestStatistics.java": 28,
                "parquet-column/src/test/java/org/apache/parquet/io/api/TestBinary.java": 20,
                "parquet-column/src/test/java/org/apache/parquet/schema/TestMessageType.java": 45,
                "parquet-column/src/test/java/org/apache/parquet/schema/TestPrimitiveComparator.java": 311,
                "parquet-column/src/test/java/org/apache/parquet/schema/TestTypeBuilders.java": 47,
                "parquet-generator/src/main/java/org/apache/parquet/filter2/IncrementallyUpdatedFilterPredicateGenerator.java": 43,
                "parquet-hadoop/src/main/java/org/apache/parquet/filter2/dictionarylevel/DictionaryFilter.java": 15,
                "parquet-hadoop/src/main/java/org/apache/parquet/filter2/statisticslevel/StatisticsFilter.java": 17,
                "parquet-hadoop/src/main/java/org/apache/parquet/format/converter/ParquetMetadataConverter.java": 141,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ColumnChunkPageWriteStore.java": 20,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ParquetFileWriter.java": 22,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/metadata/ColumnChunkMetaData.java": 39,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/metadata/ColumnChunkProperties.java": 30,
                "parquet-hadoop/src/test/java/org/apache/parquet/format/converter/TestParquetMetadataConverter.java": 381,
                "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/TestParquetFileWriter.java": 8,
                "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/TestUtils.java": 21,
                "parquet-hadoop/src/test/java/org/apache/parquet/statistics/RandomValues.java": 97,
                "parquet-hadoop/src/test/java/org/apache/parquet/statistics/TestStatistics.java": 196,
                "parquet-thrift/src/test/java/org/apache/parquet/hadoop/thrift/TestThriftToParquetFileWriter.java": 23
            },
            "is_test": true,
            "is_fix": false
        },
        "878ebcd0bc2592fa9d5dda01117c07bc3c40bb33": {
            "datetime": "2018-01-19T16:53:42+01:00",
            "summary": "PARQUET-1191: Type.hashCode() takes originalType into account but Type.equals() does not",
            "message": "PARQUET-1191: Type.hashCode() takes originalType into account but Type.equals() does not\n\nAuthor: Nandor Kollar <nkollar@cloudera.com>\n\nCloses #450 from nandorKollar/PARQUET-1191 and squashes the following commits:\n\nc7131df [Nandor Kollar] PARQUET-1191: Type.hashCode() takes originalType into account but Type.equals() does not\n",
            "diff": {
                "parquet-column/src/main/java/org/apache/parquet/schema/Type.java": 4,
                "parquet-pig/src/test/java/org/apache/parquet/pig/TestPigSchemaConverter.java": 13,
                "parquet-scrooge/src/main/java/org/apache/parquet/scrooge/ScroogeStructConverter.java": 8,
                "parquet-thrift/src/main/java/org/apache/parquet/thrift/ThriftSchemaConverter.java": 2,
                "parquet-thrift/src/test/java/org/apache/parquet/hadoop/thrift/TestBinary.java": 5
            },
            "is_test": true,
            "is_fix": true
        },
        "89aeec028b6f56be96b9c56c2fdbb931f80853ad": {
            "datetime": "2018-01-22T17:21:27+01:00",
            "summary": "PARQUET-1170: Logical-type-based toString for proper representeation in tools/logs",
            "message": "PARQUET-1170: Logical-type-based toString for proper representeation in tools/logs\n\nAuthor: Gabor Szadovszky <gabor.szadovszky@cloudera.com>\n\nCloses #448 from gszadovszky/PARQUET-1170 and squashes the following commits:\n\n8f1f8cc [Gabor Szadovszky] PARQUET-1170: Make interval test more readable\n90f73b5 [Gabor Szadovszky] PARQUET-1170: Fix endianess of interval\n612d70b [Gabor Szadovszky] PARQUET-1170: Add unit test for different locale\nd8c5204 [Gabor Szadovszky] PARQUET-1170: Implement toString based on logical type so values will be represented properly in tools/logs etc.\n",
            "diff": {
                "parquet-cli/src/main/java/org/apache/parquet/cli/Util.java": 40,
                "parquet-column/src/main/java/org/apache/parquet/column/statistics/BinaryStatistics.java": 5,
                "parquet-column/src/main/java/org/apache/parquet/column/statistics/BooleanStatistics.java": 5,
                "parquet-column/src/main/java/org/apache/parquet/column/statistics/DoubleStatistics.java": 4,
                "parquet-column/src/main/java/org/apache/parquet/column/statistics/FloatStatistics.java": 4,
                "parquet-column/src/main/java/org/apache/parquet/column/statistics/IntStatistics.java": 5,
                "parquet-column/src/main/java/org/apache/parquet/column/statistics/LongStatistics.java": 5,
                "parquet-column/src/main/java/org/apache/parquet/column/statistics/Statistics.java": 13,
                "parquet-column/src/main/java/org/apache/parquet/schema/OriginalType.java": 60,
                "parquet-column/src/main/java/org/apache/parquet/schema/PrimitiveStringifier.java": 360,
                "parquet-column/src/main/java/org/apache/parquet/schema/PrimitiveType.java": 10,
                "parquet-column/src/test/java/org/apache/parquet/column/statistics/TestStatistics.java": 46,
                "parquet-column/src/test/java/org/apache/parquet/schema/TestPrimitiveStringifier.java": 298,
                "parquet-tools/src/main/java/org/apache/parquet/tools/command/DumpCommand.java": 34
            },
            "is_test": true,
            "is_fix": false
        },
        "6e0cc729d06f70a674edb8272b855062b6bda7b3": {
            "datetime": "2018-01-25T16:16:35+01:00",
            "summary": "PARQUET-1065: Deprecate type-defined sort ordering for INT96 type.",
            "message": "PARQUET-1065: Deprecate type-defined sort ordering for INT96 type.\n\nAuthor: Zoltan Ivanfi <zi@cloudera.com>\n\nCloses #454 from zivanfi/PARQUET-1065 and squashes the following commits:\n\n8559f89 [Zoltan Ivanfi] PARQUET-1065: Deprecate type-defined sort ordering for INT96 type.\n",
            "diff": {
                "parquet-hadoop/src/main/java/org/apache/parquet/format/converter/ParquetMetadataConverter.java": 1
            },
            "is_test": false,
            "is_fix": false
        }
    },
    "2018-02-01T15:17:05-07:00": {
        "445cb9dc2f07553f8e1e5f7c1150f00fbb05c63f": {
            "datetime": "2018-02-15T09:07:29-08:00",
            "summary": "PARQUET-1215: Add getFooter to ParquetWriter.",
            "message": "PARQUET-1215: Add getFooter to ParquetWriter.\n\nThis adds getFooter to ParquetWriter, which will return the file footer that was written after the file is closed.\n\nAuthor: Ryan Blue <blue@apache.org>\n\nCloses #457 from rdblue/PARQUET-1215-add-footer-accessor-to-writers and squashes the following commits:\n\n79c5965a1 [Ryan Blue] PARQUET-1215: Add getFooter to ParquetWriter.\n",
            "diff": {
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/InternalParquetRecordWriter.java": 5,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ParquetFileWriter.java": 10,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ParquetWriter.java": 8
            },
            "is_test": false,
            "is_fix": false
        },
        "ad80bfe559e7380fedd7998daea5f27393ab643b": {
            "datetime": "2018-02-19T18:37:54+01:00",
            "summary": "PARQUET-1208: Occasional endless loop in unit test",
            "message": "PARQUET-1208: Occasional endless loop in unit test\n\nAuthor: Zoltan Ivanfi <zi@cloudera.com>\n\nCloses #455 from zivanfi/PARQUET-1208 and squashes the following commits:\n\n665ba37 [Zoltan Ivanfi] PARQUET-1208: Addressing Ryan's comments.\n2ff96a3 [Zoltan Ivanfi] PARQUET-1208: Occasional endless loop in unit test\n",
            "diff": {
                "parquet-hadoop/src/test/java/org/apache/parquet/format/converter/TestParquetMetadataConverter.java": 4
            },
            "is_test": true,
            "is_fix": true
        },
        "8bbc6cb95fd9b4b9e86c924ca1e40fd555ecac1d": {
            "datetime": "2018-02-21T09:40:07-08:00",
            "summary": "PARQUET-787: Limit read allocation size",
            "message": "PARQUET-787: Limit read allocation size\n\nWIP: This update the `ParquetFileReader` to use multiple buffers when reading a row group, instead of a single humongous allocation. As a consequence, many classes needed to be updated to accept a stream backed by multiple buffers, instead of using a single buffer directly. Assuming a single contiguous buffer would require too many copies.\n\nAuthor: Ryan Blue <blue@apache.org>\n\nCloses #390 from rdblue/PARQUET-787-limit-read-allocation-size and squashes the following commits:\n\n4abba3e7a [Ryan Blue] PARQUET-787: Update byte buffer input streams for review comments.\ne7c6c5dd2 [Ryan Blue] PARQUET-787: Fix problems from Zoltan's review.\nbe52b59fa [Ryan Blue] PARQUET-787: Update tests for both ByteBufferInputStreams.\nb0b614748 [Ryan Blue] PARQUET-787: Update encodings to use ByteBufferInputStream.\na4fa05ac5 [Ryan Blue] Refactor ByteBufferInputStream implementations.\n56b22a6a1 [Ryan Blue] Make allocation size configurable.\n103ed3d86 [Ryan Blue] Add tests for ByteBufferInputStream and fix bugs.\n614a2bbc8 [Ryan Blue] Limit allocation size to 8MB chunks for better garbage collection.\n",
            "diff": {
                "parquet-column/src/main/java/org/apache/parquet/column/impl/ColumnReaderImpl.java": 30,
                "parquet-column/src/main/java/org/apache/parquet/column/values/ValuesReader.java": 36,
                "parquet-column/src/main/java/org/apache/parquet/column/values/bitpacking/BitPackingValuesReader.java": 15,
                "parquet-column/src/main/java/org/apache/parquet/column/values/bitpacking/ByteBitPackingValuesReader.java": 48,
                "parquet-column/src/main/java/org/apache/parquet/column/values/delta/DeltaBinaryPackingValuesReader.java": 40,
                "parquet-column/src/main/java/org/apache/parquet/column/values/deltalengthbytearray/DeltaLengthByteArrayValuesReader.java": 30,
                "parquet-column/src/main/java/org/apache/parquet/column/values/deltastrings/DeltaByteArrayReader.java": 11,
                "parquet-column/src/main/java/org/apache/parquet/column/values/dictionary/DictionaryValuesReader.java": 9,
                "parquet-column/src/main/java/org/apache/parquet/column/values/dictionary/PlainValuesDictionary.java": 17,
                "parquet-column/src/main/java/org/apache/parquet/column/values/plain/BinaryPlainValuesReader.java": 31,
                "parquet-column/src/main/java/org/apache/parquet/column/values/plain/BooleanPlainValuesReader.java": 16,
                "parquet-column/src/main/java/org/apache/parquet/column/values/plain/FixedLenByteArrayPlainValuesReader.java": 29,
                "parquet-column/src/main/java/org/apache/parquet/column/values/plain/PlainValuesReader.java": 15,
                "parquet-column/src/main/java/org/apache/parquet/column/values/rle/RunLengthBitPackingHybridDecoder.java": 2,
                "parquet-column/src/main/java/org/apache/parquet/column/values/rle/RunLengthBitPackingHybridValuesReader.java": 19,
                "parquet-column/src/main/java/org/apache/parquet/column/values/rle/ZeroIntegerValuesReader.java": 11,
                "parquet-column/src/test/java/org/apache/parquet/column/impl/TestCorruptDeltaByteArrays.java": 17,
                "parquet-column/src/test/java/org/apache/parquet/column/values/Utils.java": 21,
                "parquet-column/src/test/java/org/apache/parquet/column/values/bitpacking/BitPackingPerfTest.java": 3,
                "parquet-column/src/test/java/org/apache/parquet/column/values/bitpacking/TestBitPackingColumn.java": 3,
                "parquet-column/src/test/java/org/apache/parquet/column/values/delta/DeltaBinaryPackingValuesWriterForIntegerTest.java": 17,
                "parquet-column/src/test/java/org/apache/parquet/column/values/delta/DeltaBinaryPackingValuesWriterForLongTest.java": 15,
                "parquet-column/src/test/java/org/apache/parquet/column/values/delta/benchmark/BenchmarkReadingRandomIntegers.java": 3,
                "parquet-column/src/test/java/org/apache/parquet/column/values/deltalengthbytearray/TestDeltaLengthByteArray.java": 6,
                "parquet-column/src/test/java/org/apache/parquet/column/values/deltalengthbytearray/benchmark/BenchmarkDeltaLengthByteArray.java": 9,
                "parquet-column/src/test/java/org/apache/parquet/column/values/deltastrings/TestDeltaByteArray.java": 10,
                "parquet-column/src/test/java/org/apache/parquet/column/values/deltastrings/benchmark/BenchmarkDeltaByteArray.java": 17,
                "parquet-column/src/test/java/org/apache/parquet/column/values/dictionary/TestDictionary.java": 36,
                "parquet-column/src/test/java/org/apache/parquet/column/values/rle/RunLengthBitPackingHybridIntegrationTest.java": 2,
                "parquet-column/src/test/java/org/apache/parquet/column/values/rle/TestRunLengthBitPackingHybridEncoder.java": 2,
                "parquet-common/src/main/java/org/apache/parquet/bytes/ByteBufferInputStream.java": 90,
                "parquet-common/src/main/java/org/apache/parquet/bytes/BytesInput.java": 100,
                "parquet-common/src/main/java/org/apache/parquet/bytes/MultiBufferInputStream.java": 382,
                "parquet-common/src/main/java/org/apache/parquet/bytes/SingleBufferInputStream.java": 177,
                "parquet-common/src/test/java/org/apache/parquet/bytes/TestByteBufferInputStreams.java": 597,
                "parquet-common/src/test/java/org/apache/parquet/bytes/TestMultiBufferInputStream.java": 141,
                "parquet-common/src/test/java/org/apache/parquet/bytes/TestSingleBufferInputStream.java": 130,
                "parquet-hadoop/src/main/java/org/apache/parquet/HadoopReadOptions.java": 9,
                "parquet-hadoop/src/main/java/org/apache/parquet/ParquetReadOptions.java": 50,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/CodecFactory.java": 2,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/DirectCodecFactory.java": 4,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ParquetFileReader.java": 91,
                "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/TestDirectCodecFactory.java": 6
            },
            "is_test": true,
            "is_fix": false
        },
        "b82d96218bfd37f6df95a2e8d7675d091ab61970": {
            "datetime": "2018-02-27T14:19:14+01:00",
            "summary": "PARQUET-1217: Incorrect handling of missing values in Statistics",
            "message": "PARQUET-1217: Incorrect handling of missing values in Statistics\n\nIn parquet-format every value in Statistics is optional while parquet-mr does not properly handle these scenarios:\n- null_count is set but min/max or min_value/max_value are not: filtering may fail with NPE or incorrect filtering occurs\n  fix: check if min/max is set before comparing to the related values\n- null_count is not set: filtering handles null_count as if it would be 0 -> incorrect filtering may occur\n  fix: introduce new method in Statistics object to check if num_nulls is set; check if num_nulls is set by the new method before using its value for filtering\n\nAuthor: Gabor Szadovszky <gabor.szadovszky@cloudera.com>\n\nCloses #458 from gszadovszky/PARQUET-1217 and squashes the following commits:\n\n9d14090 [Gabor Szadovszky] Updates according to rdblue's comments\n116d1d3 [Gabor Szadovszky] PARQUET-1217: Updates according to zi's comments\nc264b50 [Gabor Szadovszky] PARQUET-1217: fix handling of unset nullCount\n2ec2fb1 [Gabor Szadovszky] PARQUET-1217: Incorrect handling of missing values in Statistics\n",
            "diff": {
                "parquet-cli/src/main/java/org/apache/parquet/cli/commands/ParquetMetadataCommand.java": 4,
                "parquet-cli/src/main/java/org/apache/parquet/cli/commands/ShowPagesCommand.java": 2,
                "parquet-column/src/main/java/org/apache/parquet/column/statistics/Statistics.java": 80,
                "parquet-column/src/test/java/org/apache/parquet/column/statistics/TestStatistics.java": 1,
                "parquet-hadoop/src/main/java/org/apache/parquet/filter2/statisticslevel/StatisticsFilter.java": 42,
                "parquet-hadoop/src/main/java/org/apache/parquet/format/converter/ParquetMetadataConverter.java": 25,
                "parquet-hadoop/src/test/java/org/apache/parquet/filter2/statisticslevel/TestStatisticsFilter.java": 64,
                "parquet-hadoop/src/test/java/org/apache/parquet/format/converter/TestParquetMetadataConverter.java": 33,
                "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/TestColumnChunkPageWriteStore.java": 4,
                "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/TestParquetFileWriter.java": 48
            },
            "is_test": true,
            "is_fix": true
        },
        "3d2d4fd1588c8eb3f67f34d75b66967d0c7b06b6": {
            "datetime": "2018-03-09T16:14:11-08:00",
            "summary": "PARQUET-1135: upgrade thrift and protobuf dependencies",
            "message": "PARQUET-1135: upgrade thrift and protobuf dependencies\n\nAuthor: Julien Le Dem <julien.ledem@wework.com>\nAuthor: Julien Le Dem <julien@ledem.net>\n\nCloses #427 from julienledem/PARQUET_1135_thrift_PB and squashes the following commits:\n\nf23b32d9 [Julien Le Dem] remove double install\n78cbf734 [Julien Le Dem] remove running check on protobuf build\n4bc2b8f7 [Julien Le Dem] add timing; upgrade proto version\ne17ca956 [Julien Le Dem] without-nodejs\nd15e523d [Julien Le Dem] PARQUET-1135: upgrade thrift and protobuf dependencies\n",
            "diff": {
                "parquet-thrift/src/main/java/org/apache/parquet/hadoop/thrift/ThriftBytesWriteSupport.java": 32
            },
            "is_test": false,
            "is_fix": false
        },
        "0a86429939075984edce5e3b8195dfb7f9e3ab6b": {
            "datetime": "2018-03-19T14:43:12+01:00",
            "summary": "PARQUET-1246: Ignore float/double statistics in case of NaN",
            "message": "PARQUET-1246: Ignore float/double statistics in case of NaN\n\nBecause of the ambigous sorting order of float/double the following changes made at the reading path of the related statistics:\n- Ignoring statistics in case of it contains a NaN value.\n- Using -0.0 as min value and +0.0 as max value independently from which 0.0 value was saved in the statistics.\n\nAuthor: Gabor Szadovszky <gabor.szadovszky@cloudera.com>\n\nCloses #461 from gszadovszky/PARQUET-1246 and squashes the following commits:\n\n20e9332 [Gabor Szadovszky] PARQUET-1246: Changes according to zi's comments\n3447938 [Gabor Szadovszky] PARQUET-1246: Ignore float/double statistics in case of NaN\n",
            "diff": {
                "parquet-column/src/main/java/org/apache/parquet/column/statistics/Statistics.java": 81,
                "parquet-column/src/test/java/org/apache/parquet/column/statistics/TestStatistics.java": 151,
                "parquet-hadoop/src/main/java/org/apache/parquet/format/converter/ParquetMetadataConverter.java": 2,
                "parquet-hadoop/src/test/java/org/apache/parquet/filter2/statisticslevel/TestStatisticsFilter.java": 4,
                "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/TestColumnChunkPageWriteStore.java": 2,
                "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/TestParquetFileWriter.java": 2
            },
            "is_test": true,
            "is_fix": true
        },
        "d54fad867da7f762ac4c0d947adffdc1f8f356f1": {
            "datetime": "2018-03-30T15:24:17-07:00",
            "summary": "PARQUET-1183: Add Avro builders using InputFile and OutputFile. (#460)",
            "message": "PARQUET-1183: Add Avro builders using InputFile and OutputFile. (#460)\n\n* PARQUET-1183: Add Avro builders using InputFile and OutputFile.\r\n* PARQUET-1183: Add deprecation warnings to Avro read builder.\r\n\r\nCloses #446",
            "diff": {
                "parquet-avro/src/main/java/org/apache/parquet/avro/AvroParquetReader.java": 14,
                "parquet-avro/src/main/java/org/apache/parquet/avro/AvroParquetWriter.java": 9
            },
            "is_test": false,
            "is_fix": false
        },
        "12bbaf3550d56bc945b50f538b5f18af93bd316a": {
            "datetime": "2018-03-30T15:31:01-07:00",
            "summary": "PARQUET-1263: If file has a config, use it for ParquetReadOptions. (#464)",
            "message": "PARQUET-1263: If file has a config, use it for ParquetReadOptions. (#464)\n\n",
            "diff": {
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ParquetReader.java": 14
            },
            "is_test": false,
            "is_fix": false
        },
        "d61d221c9e752ce2cc0da65ede8b55653b3ae21f": {
            "datetime": "2018-03-30T17:51:23-07:00",
            "summary": "PARQUET-1264: Fix javadoc warnings for Java 8.",
            "message": "PARQUET-1264: Fix javadoc warnings for Java 8.\n",
            "diff": {
                "parquet-column/src/main/java/org/apache/parquet/CorruptStatistics.java": 4,
                "parquet-column/src/main/java/org/apache/parquet/column/page/DataPageV1.java": 1,
                "parquet-column/src/main/java/org/apache/parquet/column/page/DataPageV2.java": 12,
                "parquet-column/src/main/java/org/apache/parquet/column/page/PageWriter.java": 7,
                "parquet-column/src/main/java/org/apache/parquet/column/statistics/BinaryStatistics.java": 8,
                "parquet-column/src/main/java/org/apache/parquet/column/values/ValuesReader.java": 2,
                "parquet-column/src/main/java/org/apache/parquet/column/values/ValuesWriter.java": 2,
                "parquet-column/src/main/java/org/apache/parquet/column/values/bitpacking/BitPackingValuesWriter.java": 4,
                "parquet-column/src/main/java/org/apache/parquet/filter/AndRecordFilter.java": 1,
                "parquet-column/src/main/java/org/apache/parquet/filter/ColumnRecordFilter.java": 1,
                "parquet-column/src/main/java/org/apache/parquet/filter/NotRecordFilter.java": 1,
                "parquet-column/src/main/java/org/apache/parquet/filter/OrRecordFilter.java": 1,
                "parquet-column/src/main/java/org/apache/parquet/filter/PagedRecordFilter.java": 1,
                "parquet-column/src/main/java/org/apache/parquet/filter/RecordFilter.java": 1,
                "parquet-column/src/main/java/org/apache/parquet/filter/UnboundRecordFilter.java": 3,
                "parquet-column/src/main/java/org/apache/parquet/io/MessageColumnIO.java": 7,
                "parquet-column/src/main/java/org/apache/parquet/io/RecordConsumerLoggingWrapper.java": 2,
                "parquet-column/src/main/java/org/apache/parquet/io/RecordReader.java": 1,
                "parquet-column/src/main/java/org/apache/parquet/io/api/Binary.java": 2,
                "parquet-column/src/main/java/org/apache/parquet/io/api/RecordConsumer.java": 12,
                "parquet-column/src/main/java/org/apache/parquet/schema/ConversionPatterns.java": 10,
                "parquet-column/src/main/java/org/apache/parquet/schema/GroupType.java": 10,
                "parquet-column/src/main/java/org/apache/parquet/schema/MessageType.java": 2,
                "parquet-column/src/main/java/org/apache/parquet/schema/PrimitiveType.java": 5,
                "parquet-column/src/main/java/org/apache/parquet/schema/Type.java": 9,
                "parquet-column/src/main/java/org/apache/parquet/schema/Types.java": 7,
                "parquet-common/src/main/java/org/apache/parquet/Exceptions.java": 5,
                "parquet-common/src/main/java/org/apache/parquet/IOExceptionUtils.java": 2,
                "parquet-common/src/main/java/org/apache/parquet/Log.java": 24,
                "parquet-common/src/main/java/org/apache/parquet/Preconditions.java": 1,
                "parquet-common/src/main/java/org/apache/parquet/Strings.java": 12,
                "parquet-common/src/main/java/org/apache/parquet/bytes/ByteBufferAllocator.java": 2,
                "parquet-common/src/main/java/org/apache/parquet/bytes/BytesInput.java": 28,
                "parquet-common/src/main/java/org/apache/parquet/bytes/BytesUtils.java": 33,
                "parquet-common/src/main/java/org/apache/parquet/bytes/CapacityByteArrayOutputStream.java": 13,
                "parquet-common/src/main/java/org/apache/parquet/bytes/LittleEndianDataInputStream.java": 44,
                "parquet-common/src/main/java/org/apache/parquet/glob/GlobExpander.java": 17,
                "parquet-common/src/main/java/org/apache/parquet/hadoop/metadata/Canonicalizer.java": 2,
                "parquet-common/src/main/java/org/apache/parquet/io/SeekableInputStream.java": 6,
                "parquet-common/src/main/java/org/apache/parquet/util/DynMethods.java": 20,
                "parquet-encoding/src/main/java/org/apache/parquet/column/values/bitpacking/BitPacking.java": 7,
                "parquet-encoding/src/main/java/org/apache/parquet/column/values/bitpacking/ByteBasedBitPackingEncoder.java": 7,
                "parquet-encoding/src/main/java/org/apache/parquet/column/values/bitpacking/BytePacker.java": 8,
                "parquet-generator/src/main/java/org/apache/parquet/encoding/bitpacking/ByteBasedBitPackingGenerator.java": 2,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/codec/CodecConfig.java": 2,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/codec/SnappyDecompressor.java": 2,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/metadata/ColumnChunkMetaData.java": 14,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/metadata/ColumnChunkProperties.java": 5,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/metadata/ParquetMetadata.java": 5
            },
            "is_test": false,
            "is_fix": false
        },
        "150c578edb161bdb2e8c039f0914984f570ef8f0": {
            "datetime": "2018-03-30T17:53:49-07:00",
            "summary": "PARQUET-1264: Fix javadoc 8 problem in VersionGenerator.",
            "message": "PARQUET-1264: Fix javadoc 8 problem in VersionGenerator.\n",
            "diff": {
                "parquet-generator/src/main/java/org/apache/parquet/version/VersionGenerator.java": 2
            },
            "is_test": false,
            "is_fix": false
        },
        "0d55abd05b0e5027c18e60d1ac3b22998dd00951": {
            "datetime": "2018-04-05T12:42:15-07:00",
            "summary": "RQUET-1264: Fix javadoc warnings for Java 8.",
            "message": "RQUET-1264: Fix javadoc warnings for Java 8.\n",
            "diff": {
                "parquet-arrow/src/main/java/org/apache/parquet/arrow/schema/SchemaConverter.java": 14,
                "parquet-arrow/src/main/java/org/apache/parquet/arrow/schema/SchemaMapping.java": 4,
                "parquet-avro/src/main/java/org/apache/parquet/avro/AvroParquetInputFormat.java": 14,
                "parquet-avro/src/main/java/org/apache/parquet/avro/AvroParquetOutputFormat.java": 4,
                "parquet-avro/src/main/java/org/apache/parquet/avro/AvroParquetReader.java": 25,
                "parquet-avro/src/main/java/org/apache/parquet/avro/AvroParquetWriter.java": 18,
                "parquet-avro/src/main/java/org/apache/parquet/avro/AvroReadSupport.java": 6,
                "parquet-avro/src/main/java/org/apache/parquet/avro/AvroWriteSupport.java": 6,
                "parquet-avro/src/main/java/org/apache/parquet/avro/package-info.java": 3,
                "parquet-cascading-common23/src/main/java/org/apache/parquet/cascading/TupleWriteSupport.java": 5,
                "parquet-cascading/src/main/java/org/apache/parquet/cascading/ParquetTupleScheme.java": 2,
                "parquet-cascading3/src/main/java/org/apache/parquet/cascading/ParquetTupleScheme.java": 2,
                "parquet-cli/src/main/java/org/apache/parquet/cli/BaseCommand.java": 23,
                "parquet-cli/src/main/java/org/apache/parquet/cli/Command.java": 2,
                "parquet-cli/src/main/java/org/apache/parquet/cli/util/Expressions.java": 4,
                "parquet-cli/src/main/java/org/apache/parquet/cli/util/RecordException.java": 2,
                "parquet-cli/src/main/java/org/apache/parquet/cli/util/Schemas.java": 3,
                "parquet-column/src/main/java/org/apache/parquet/column/ColumnDescriptor.java": 8,
                "parquet-column/src/main/java/org/apache/parquet/column/ColumnReadStore.java": 2,
                "parquet-column/src/main/java/org/apache/parquet/column/ColumnReader.java": 9,
                "parquet-column/src/main/java/org/apache/parquet/column/ColumnWriteStore.java": 2,
                "parquet-column/src/main/java/org/apache/parquet/column/ColumnWriter.java": 43,
                "parquet-column/src/main/java/org/apache/parquet/column/Dictionary.java": 3,
                "parquet-column/src/main/java/org/apache/parquet/column/Encoding.java": 12,
                "parquet-column/src/main/java/org/apache/parquet/column/ParquetProperties.java": 3,
                "parquet-column/src/main/java/org/apache/parquet/column/UnknownColumnException.java": 2,
                "parquet-column/src/main/java/org/apache/parquet/column/UnknownColumnTypeException.java": 2,
                "parquet-column/src/main/java/org/apache/parquet/column/ValuesType.java": 3,
                "parquet-column/src/main/java/org/apache/parquet/column/impl/ColumnReadStoreImpl.java": 4,
                "parquet-column/src/main/java/org/apache/parquet/column/impl/ColumnReaderImpl.java": 8,
                "parquet-column/src/main/java/org/apache/parquet/column/impl/ColumnWriterV1.java": 3,
                "parquet-column/src/main/java/org/apache/parquet/column/impl/ColumnWriterV2.java": 3,
                "parquet-column/src/main/java/org/apache/parquet/column/page/DataPage.java": 3,
                "parquet-column/src/main/java/org/apache/parquet/column/page/DictionaryPage.java": 3,
                "parquet-column/src/main/java/org/apache/parquet/column/page/Page.java": 3,
                "parquet-column/src/main/java/org/apache/parquet/column/page/PageReadStore.java": 3,
                "parquet-column/src/main/java/org/apache/parquet/column/page/PageReader.java": 3,
                "parquet-column/src/main/java/org/apache/parquet/column/page/PageWriteStore.java": 3,
                "parquet-column/src/main/java/org/apache/parquet/column/page/PageWriter.java": 3,
                "parquet-column/src/main/java/org/apache/parquet/column/statistics/Statistics.java": 18,
                "parquet-column/src/main/java/org/apache/parquet/column/statistics/StatisticsClassException.java": 2,
                "parquet-column/src/main/java/org/apache/parquet/column/values/RequiresFallback.java": 5,
                "parquet-column/src/main/java/org/apache/parquet/column/values/ValuesReader.java": 2,
                "parquet-column/src/main/java/org/apache/parquet/column/values/ValuesWriter.java": 3,
                "parquet-column/src/main/java/org/apache/parquet/column/values/bitpacking/BitPackingValuesReader.java": 3,
                "parquet-column/src/main/java/org/apache/parquet/column/values/bitpacking/BitPackingValuesWriter.java": 3,
                "parquet-column/src/main/java/org/apache/parquet/column/values/delta/DeltaBinaryPackingConfig.java": 2,
                "parquet-column/src/main/java/org/apache/parquet/column/values/delta/DeltaBinaryPackingValuesReader.java": 2,
                "parquet-column/src/main/java/org/apache/parquet/column/values/delta/DeltaBinaryPackingValuesWriter.java": 5,
                "parquet-column/src/main/java/org/apache/parquet/column/values/delta/DeltaBinaryPackingValuesWriterForInteger.java": 7,
                "parquet-column/src/main/java/org/apache/parquet/column/values/delta/DeltaBinaryPackingValuesWriterForLong.java": 6,
                "parquet-column/src/main/java/org/apache/parquet/column/values/deltalengthbytearray/DeltaLengthByteArrayValuesReader.java": 3,
                "parquet-column/src/main/java/org/apache/parquet/column/values/deltalengthbytearray/DeltaLengthByteArrayValuesWriter.java": 1,
                "parquet-column/src/main/java/org/apache/parquet/column/values/deltastrings/DeltaByteArrayReader.java": 3,
                "parquet-column/src/main/java/org/apache/parquet/column/values/deltastrings/DeltaByteArrayWriter.java": 2,
                "parquet-column/src/main/java/org/apache/parquet/column/values/dictionary/DictionaryValuesReader.java": 3,
                "parquet-column/src/main/java/org/apache/parquet/column/values/dictionary/DictionaryValuesWriter.java": 42,
                "parquet-column/src/main/java/org/apache/parquet/column/values/dictionary/IntList.java": 7,
                "parquet-column/src/main/java/org/apache/parquet/column/values/dictionary/PlainValuesDictionary.java": 22,
                "parquet-column/src/main/java/org/apache/parquet/column/values/factory/ValuesWriterFactory.java": 7,
                "parquet-column/src/main/java/org/apache/parquet/column/values/plain/BooleanPlainValuesReader.java": 3,
                "parquet-column/src/main/java/org/apache/parquet/column/values/plain/BooleanPlainValuesWriter.java": 3,
                "parquet-column/src/main/java/org/apache/parquet/column/values/plain/FixedLenByteArrayPlainValuesReader.java": 2,
                "parquet-column/src/main/java/org/apache/parquet/column/values/plain/FixedLenByteArrayPlainValuesWriter.java": 2,
                "parquet-column/src/main/java/org/apache/parquet/column/values/plain/PlainValuesReader.java": 3,
                "parquet-column/src/main/java/org/apache/parquet/column/values/plain/PlainValuesWriter.java": 3,
                "parquet-column/src/main/java/org/apache/parquet/column/values/rle/RunLengthBitPackingHybridDecoder.java": 2,
                "parquet-column/src/main/java/org/apache/parquet/column/values/rle/RunLengthBitPackingHybridEncoder.java": 4,
                "parquet-column/src/main/java/org/apache/parquet/column/values/rle/RunLengthBitPackingHybridValuesReader.java": 2,
                "parquet-column/src/main/java/org/apache/parquet/column/values/rle/RunLengthBitPackingHybridValuesWriter.java": 3,
                "parquet-column/src/main/java/org/apache/parquet/example/DummyRecordConverter.java": 3,
                "parquet-column/src/main/java/org/apache/parquet/example/Paper.java": 3,
                "parquet-column/src/main/java/org/apache/parquet/filter/AndRecordFilter.java": 2,
                "parquet-column/src/main/java/org/apache/parquet/filter/NotRecordFilter.java": 2,
                "parquet-column/src/main/java/org/apache/parquet/filter/OrRecordFilter.java": 2,
                "parquet-column/src/main/java/org/apache/parquet/filter/RecordFilter.java": 2,
                "parquet-column/src/main/java/org/apache/parquet/filter/UnboundRecordFilter.java": 2,
                "parquet-column/src/main/java/org/apache/parquet/filter2/compat/FilterCompat.java": 18,
                "parquet-column/src/main/java/org/apache/parquet/filter2/predicate/FilterApi.java": 81,
                "parquet-column/src/main/java/org/apache/parquet/filter2/predicate/FilterPredicate.java": 4,
                "parquet-column/src/main/java/org/apache/parquet/filter2/predicate/LogicalInverseRewriter.java": 2,
                "parquet-column/src/main/java/org/apache/parquet/filter2/predicate/Statistics.java": 16,
                "parquet-column/src/main/java/org/apache/parquet/filter2/predicate/UserDefinedPredicate.java": 33,
                "parquet-column/src/main/java/org/apache/parquet/filter2/predicate/ValidTypeMap.java": 3,
                "parquet-column/src/main/java/org/apache/parquet/filter2/recordlevel/IncrementallyUpdatedFilterPredicate.java": 9,
                "parquet-column/src/main/java/org/apache/parquet/filter2/recordlevel/IncrementallyUpdatedFilterPredicateBuilderBase.java": 2,
                "parquet-column/src/main/java/org/apache/parquet/io/ColumnIO.java": 3,
                "parquet-column/src/main/java/org/apache/parquet/io/ColumnIOFactory.java": 3,
                "parquet-column/src/main/java/org/apache/parquet/io/CompilationException.java": 3,
                "parquet-column/src/main/java/org/apache/parquet/io/EmptyRecordReader.java": 2,
                "parquet-column/src/main/java/org/apache/parquet/io/FilteredRecordReader.java": 2,
                "parquet-column/src/main/java/org/apache/parquet/io/GroupColumnIO.java": 4,
                "parquet-column/src/main/java/org/apache/parquet/io/InvalidRecordException.java": 3,
                "parquet-column/src/main/java/org/apache/parquet/io/MessageColumnIO.java": 3,
                "parquet-column/src/main/java/org/apache/parquet/io/ParquetDecodingException.java": 3,
                "parquet-column/src/main/java/org/apache/parquet/io/ParquetEncodingException.java": 3,
                "parquet-column/src/main/java/org/apache/parquet/io/PrimitiveColumnIO.java": 4,
                "parquet-column/src/main/java/org/apache/parquet/io/RecordConsumerLoggingWrapper.java": 3,
                "parquet-column/src/main/java/org/apache/parquet/io/RecordReader.java": 1,
                "parquet-column/src/main/java/org/apache/parquet/io/RecordReaderImplementation.java": 1,
                "parquet-column/src/main/java/org/apache/parquet/io/ValidatingRecordConsumer.java": 3,
                "parquet-column/src/main/java/org/apache/parquet/io/api/Converter.java": 3,
                "parquet-column/src/main/java/org/apache/parquet/io/api/GroupConverter.java": 3,
                "parquet-column/src/main/java/org/apache/parquet/io/api/PrimitiveConverter.java": 5,
                "parquet-column/src/main/java/org/apache/parquet/io/api/RecordConsumer.java": 2,
                "parquet-column/src/main/java/org/apache/parquet/io/api/RecordMaterializer.java": 2,
                "parquet-column/src/main/java/org/apache/parquet/schema/GroupType.java": 3,
                "parquet-column/src/main/java/org/apache/parquet/schema/IncompatibleSchemaModificationException.java": 3,
                "parquet-column/src/main/java/org/apache/parquet/schema/MessageType.java": 3,
                "parquet-column/src/main/java/org/apache/parquet/schema/MessageTypeParser.java": 2,
                "parquet-column/src/main/java/org/apache/parquet/schema/PrimitiveType.java": 6,
                "parquet-column/src/main/java/org/apache/parquet/schema/Type.java": 5,
                "parquet-column/src/main/java/org/apache/parquet/schema/TypeConverter.java": 2,
                "parquet-column/src/main/java/org/apache/parquet/schema/TypeVisitor.java": 3,
                "parquet-column/src/test/java/org/apache/parquet/column/values/RandomStr.java": 5,
                "parquet-column/src/test/java/org/apache/parquet/column/values/Utils.java": 3,
                "parquet-column/src/test/java/org/apache/parquet/column/values/bitpacking/BitPackingPerfTest.java": 2,
                "parquet-column/src/test/java/org/apache/parquet/column/values/rle/RunLengthBitPackingHybridIntegrationTest.java": 3,
                "parquet-column/src/test/java/org/apache/parquet/column/values/rle/TestRunLengthBitPackingHybridEncoder.java": 3,
                "parquet-column/src/test/java/org/apache/parquet/io/PerfTest.java": 4,
                "parquet-common/src/main/java/org/apache/parquet/Ints.java": 2,
                "parquet-common/src/main/java/org/apache/parquet/Log.java": 3,
                "parquet-common/src/main/java/org/apache/parquet/ParquetRuntimeException.java": 3,
                "parquet-common/src/main/java/org/apache/parquet/Preconditions.java": 3,
                "parquet-common/src/main/java/org/apache/parquet/bytes/BytesInput.java": 3,
                "parquet-common/src/main/java/org/apache/parquet/bytes/BytesUtils.java": 3,
                "parquet-common/src/main/java/org/apache/parquet/bytes/CapacityByteArrayOutputStream.java": 3,
                "parquet-common/src/main/java/org/apache/parquet/bytes/LittleEndianDataInputStream.java": 3,
                "parquet-common/src/main/java/org/apache/parquet/bytes/LittleEndianDataOutputStream.java": 3,
                "parquet-common/src/main/java/org/apache/parquet/hadoop/metadata/Canonicalizer.java": 1,
                "parquet-encoding/src/main/java/org/apache/parquet/column/values/bitpacking/BitPacking.java": 9,
                "parquet-encoding/src/main/java/org/apache/parquet/column/values/bitpacking/ByteBasedBitPackingEncoder.java": 3,
                "parquet-encoding/src/main/java/org/apache/parquet/column/values/bitpacking/BytePacker.java": 3,
                "parquet-encoding/src/main/java/org/apache/parquet/column/values/bitpacking/BytePackerForLong.java": 3,
                "parquet-encoding/src/main/java/org/apache/parquet/column/values/bitpacking/IntPacker.java": 3,
                "parquet-encoding/src/main/java/org/apache/parquet/column/values/bitpacking/Packer.java": 3,
                "parquet-generator/src/main/java/org/apache/parquet/encoding/Generator.java": 3,
                "parquet-generator/src/main/java/org/apache/parquet/encoding/bitpacking/ByteBasedBitPackingGenerator.java": 5,
                "parquet-generator/src/main/java/org/apache/parquet/encoding/bitpacking/IntBasedBitPackingGenerator.java": 5,
                "parquet-generator/src/main/java/org/apache/parquet/filter2/IncrementallyUpdatedFilterPredicateGenerator.java": 2,
                "parquet-hadoop/src/main/java/org/apache/parquet/filter2/compat/RowGroupFilter.java": 4,
                "parquet-hadoop/src/main/java/org/apache/parquet/format/converter/ParquetMetadataConverter.java": 20,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/BadConfigurationException.java": 3,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/CodecFactory.java": 4,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/Footer.java": 4,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ParquetFileReader.java": 117,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ParquetFileWriter.java": 66,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ParquetInputFormat.java": 18,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ParquetInputSplit.java": 32,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ParquetOutputFormat.java": 6,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ParquetReader.java": 10,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ParquetRecordReader.java": 4,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ParquetRecordWriter.java": 7,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ParquetWriter.java": 28,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/PrintFooter.java": 2,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/api/DelegatingReadSupport.java": 4,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/api/DelegatingWriteSupport.java": 4,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/api/InitContext.java": 3,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/api/ReadSupport.java": 5,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/api/WriteSupport.java": 8,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/codec/CodecConfig.java": 2,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/example/ExampleInputFormat.java": 3,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/example/ExampleOutputFormat.java": 8,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/mapred/Container.java": 4,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/mapred/MapredParquetOutputCommitter.java": 3,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/metadata/BlockMetaData.java": 3,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/metadata/ColumnChunkMetaData.java": 1,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/metadata/FileMetaData.java": 3,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/metadata/GlobalMetaData.java": 3,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/metadata/ParquetMetadata.java": 3,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/util/ContextUtil.java": 21,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/util/SerializationUtil.java": 10,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/util/counters/BenchmarkCounter.java": 8,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/util/counters/CounterLoader.java": 1,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/util/counters/ICounter.java": 1,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/util/counters/mapred/MapRedCounterAdapter.java": 1,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/util/counters/mapred/MapRedCounterLoader.java": 1,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/util/counters/mapreduce/MapReduceCounterAdapter.java": 1,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/util/counters/mapreduce/MapReduceCounterLoader.java": 1,
                "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/DeprecatedInputFormatTest.java": 1,
                "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/DeprecatedOutputFormatTest.java": 1,
                "parquet-hive/parquet-hive-binding/parquet-hive-binding-interface/src/main/java/org/apache/parquet/hive/HiveBinding.java": 6,
                "parquet-hive/parquet-hive-storage-handler/src/main/java/org/apache/hadoop/hive/ql/io/parquet/read/DataWritableReadSupport.java": 4,
                "parquet-hive/parquet-hive-storage-handler/src/main/java/org/apache/hadoop/hive/ql/io/parquet/serde/ArrayWritableObjectInspector.java": 5,
                "parquet-hive/parquet-hive-storage-handler/src/main/java/org/apache/hadoop/hive/ql/io/parquet/serde/DeepParquetHiveMapInspector.java": 9,
                "parquet-hive/parquet-hive-storage-handler/src/main/java/org/apache/hadoop/hive/ql/io/parquet/serde/ParquetHiveArrayInspector.java": 4,
                "parquet-hive/parquet-hive-storage-handler/src/main/java/org/apache/hadoop/hive/ql/io/parquet/serde/StandardParquetHiveMapInspector.java": 4,
                "parquet-pig/src/main/java/org/apache/parquet/pig/ParquetLoader.java": 7,
                "parquet-pig/src/main/java/org/apache/parquet/pig/ParquetStorer.java": 3,
                "parquet-pig/src/main/java/org/apache/parquet/pig/PigMetaData.java": 3,
                "parquet-pig/src/main/java/org/apache/parquet/pig/PigSchemaConverter.java": 4,
                "parquet-pig/src/main/java/org/apache/parquet/pig/SchemaConversionException.java": 3,
                "parquet-pig/src/main/java/org/apache/parquet/pig/TupleReadSupport.java": 3,
                "parquet-pig/src/main/java/org/apache/parquet/pig/convert/MapConverter.java": 11,
                "parquet-pig/src/main/java/org/apache/parquet/pig/convert/ParentValueContainer.java": 3,
                "parquet-pig/src/main/java/org/apache/parquet/pig/convert/TupleConverter.java": 23,
                "parquet-pig/src/main/java/org/apache/parquet/pig/summary/BagSummaryData.java": 8,
                "parquet-pig/src/main/java/org/apache/parquet/pig/summary/FieldSummaryData.java": 6,
                "parquet-pig/src/main/java/org/apache/parquet/pig/summary/MapSummaryData.java": 7,
                "parquet-pig/src/main/java/org/apache/parquet/pig/summary/NumberSummaryData.java": 3,
                "parquet-pig/src/main/java/org/apache/parquet/pig/summary/StringSummaryData.java": 3,
                "parquet-pig/src/main/java/org/apache/parquet/pig/summary/Summary.java": 3,
                "parquet-pig/src/main/java/org/apache/parquet/pig/summary/SummaryData.java": 16,
                "parquet-pig/src/main/java/org/apache/parquet/pig/summary/TupleSummaryData.java": 8,
                "parquet-pig/src/test/java/org/apache/parquet/pig/PerfTest.java": 4,
                "parquet-pig/src/test/java/org/apache/parquet/pig/PerfTest2.java": 4,
                "parquet-pig/src/test/java/org/apache/parquet/pig/PerfTestReadAllCols.java": 4,
                "parquet-pig/src/test/java/org/apache/parquet/pig/TupleConsumerPerfTest.java": 6,
                "parquet-protobuf/src/main/java/org/apache/parquet/proto/ProtoMessageConverter.java": 3,
                "parquet-protobuf/src/main/java/org/apache/parquet/proto/ProtoParquetOutputFormat.java": 7,
                "parquet-protobuf/src/main/java/org/apache/parquet/proto/ProtoParquetReader.java": 5,
                "parquet-protobuf/src/main/java/org/apache/parquet/proto/ProtoParquetWriter.java": 17,
                "parquet-protobuf/src/main/java/org/apache/parquet/proto/ProtoReadSupport.java": 8,
                "parquet-protobuf/src/main/java/org/apache/parquet/proto/ProtoRecordConverter.java": 3,
                "parquet-protobuf/src/main/java/org/apache/parquet/proto/ProtoSchemaConverter.java": 3,
                "parquet-protobuf/src/main/java/org/apache/parquet/proto/ProtoWriteSupport.java": 1,
                "parquet-scrooge/src/main/java/org/apache/parquet/scrooge/ScroogeReadSupport.java": 1,
                "parquet-scrooge/src/main/java/org/apache/parquet/scrooge/ScroogeRecordConverter.java": 3,
                "parquet-scrooge/src/main/java/org/apache/parquet/scrooge/ScroogeStructConverter.java": 8,
                "parquet-scrooge/src/test/java/org/apache/parquet/scrooge/ParquetScroogeSchemeTest.java": 2,
                "parquet-thrift/src/main/java/org/apache/parquet/hadoop/thrift/AbstractThriftWriteSupport.java": 1,
                "parquet-thrift/src/main/java/org/apache/parquet/hadoop/thrift/ParquetThriftBytesOutputFormat.java": 4,
                "parquet-thrift/src/main/java/org/apache/parquet/hadoop/thrift/ParquetThriftInputFormat.java": 12,
                "parquet-thrift/src/main/java/org/apache/parquet/hadoop/thrift/ParquetThriftOutputFormat.java": 3,
                "parquet-thrift/src/main/java/org/apache/parquet/hadoop/thrift/ThriftReadSupport.java": 5,
                "parquet-thrift/src/main/java/org/apache/parquet/hadoop/thrift/ThriftToParquetFileWriter.java": 10,
                "parquet-thrift/src/main/java/org/apache/parquet/thrift/BufferedProtocolReadToWrite.java": 5,
                "parquet-thrift/src/main/java/org/apache/parquet/thrift/ConvertedField.java": 2,
                "parquet-thrift/src/main/java/org/apache/parquet/thrift/FieldIgnoredHandler.java": 3,
                "parquet-thrift/src/main/java/org/apache/parquet/thrift/ParquetProtocol.java": 3,
                "parquet-thrift/src/main/java/org/apache/parquet/thrift/ProtocolPipe.java": 3,
                "parquet-thrift/src/main/java/org/apache/parquet/thrift/ProtocolReadToWrite.java": 5,
                "parquet-thrift/src/main/java/org/apache/parquet/thrift/SkippableException.java": 3,
                "parquet-thrift/src/main/java/org/apache/parquet/thrift/TBaseRecordConverter.java": 3,
                "parquet-thrift/src/main/java/org/apache/parquet/thrift/ThriftMetaData.java": 4,
                "parquet-thrift/src/main/java/org/apache/parquet/thrift/ThriftParquetReader.java": 12,
                "parquet-thrift/src/main/java/org/apache/parquet/thrift/ThriftParquetWriter.java": 2,
                "parquet-thrift/src/main/java/org/apache/parquet/thrift/ThriftRecordConverter.java": 39,
                "parquet-thrift/src/main/java/org/apache/parquet/thrift/ThriftSchemaConvertVisitor.java": 2,
                "parquet-thrift/src/main/java/org/apache/parquet/thrift/ThriftSchemaConverter.java": 6,
                "parquet-thrift/src/main/java/org/apache/parquet/thrift/pig/ParquetThriftStorer.java": 3,
                "parquet-thrift/src/main/java/org/apache/parquet/thrift/pig/TupleToThriftWriteSupport.java": 3,
                "parquet-thrift/src/main/java/org/apache/parquet/thrift/projection/FieldsPath.java": 2,
                "parquet-thrift/src/main/java/org/apache/parquet/thrift/projection/StrictFieldProjectionFilter.java": 8,
                "parquet-thrift/src/main/java/org/apache/parquet/thrift/projection/ThriftProjectionException.java": 3,
                "parquet-thrift/src/main/java/org/apache/parquet/thrift/projection/amend/ProtocolEventsAmender.java": 6,
                "parquet-thrift/src/main/java/org/apache/parquet/thrift/projection/deprecated/DeprecatedFieldProjectionFilter.java": 1,
                "parquet-thrift/src/main/java/org/apache/parquet/thrift/projection/deprecated/PathGlobPattern.java": 2,
                "parquet-thrift/src/main/java/org/apache/parquet/thrift/struct/CompatibilityChecker.java": 2,
                "parquet-thrift/src/main/java/org/apache/parquet/thrift/struct/CompatibilityRunner.java": 2,
                "parquet-thrift/src/main/java/org/apache/parquet/thrift/struct/ThriftType.java": 3,
                "parquet-thrift/src/main/java/org/apache/parquet/thrift/struct/ThriftTypeID.java": 3
            },
            "is_test": true,
            "is_fix": false
        },
        "af977adc43a071a09652fea4ce3deba2d5b8d171": {
            "datetime": "2018-04-21T14:58:35+01:00",
            "summary": "PARQUET-1128: [Java] Upgrade the Apache Arrow version to 0.8.0 for SchemaConverter",
            "message": "PARQUET-1128: [Java] Upgrade the Apache Arrow version to 0.8.0 for SchemaConverter\n\nWhen I converted parquet(1.9.1-SNAPSHOT) schema to arrow(0.4.0) with SchemaConverter, this exception raised.\n```\njava.lang.NoClassDefFoundError: org/apache/arrow/vector/types/pojo/ArrowType$Struct_\n\n\tat net.wrap_trap.parquet_arrow.ParquetToArrowConverter.convertToArrow(ParquetToArrowConverter.java:67)\n\tat net.wrap_trap.parquet_arrow.ParquetToArrowConverter.convertToArrow(ParquetToArrowConverter.java:40)\n\tat net.wrap_trap.parquet_arrow.ParquetToArrowConverterTest.parquetToArrowConverterTest(ParquetToArrowConverterTest.java:27)\n```\n\nThis reason is that SchemaConverter refer to Apache Arrow 0.1.0.\nI upgrade the Apache Arrow version to 0.8.0(latest) for SchemaConverter.\n\nAuthor: Masayuki Takahashi <masayuki038@gmail.com>\n\nCloses #443 from masayuki038/PARQUET-1128 and squashes the following commits:\n\n8ba47813 [Masayuki Takahashi] PARQUET-1128: [Java] Upgrade the Apache Arrow version to 0.8.0 for SchemaConverter\nb80d793a [Masayuki Takahashi] PARQUET-1128: [Java] Upgrade the Apache Arrow version to 0.8.0 for SchemaConverter\n",
            "diff": {
                "parquet-arrow/src/main/java/org/apache/parquet/arrow/schema/SchemaConverter.java": 227,
                "parquet-arrow/src/test/java/org/apache/parquet/arrow/schema/TestSchemaConverter.java": 346
            },
            "is_test": true,
            "is_fix": true
        },
        "f84938441be49c665595c936ac631c3e5f171bf9": {
            "datetime": "2018-04-26T08:48:08-04:00",
            "summary": "PARQUET-968 Add Hive/Presto support in ProtoParquet",
            "message": "PARQUET-968 Add Hive/Presto support in ProtoParquet\n\nThis PR adds Hive (https://github.com/apache/hive) and Presto (https://github.com/prestodb/presto) support for parquet messages written with ProtoParquetWriter. Hive and other tools, such as Presto (used by AWS Athena), rely on specific LIST/MAP wrappers (as defined in the parquet spec: https://github.com/apache/parquet-format/blob/master/LogicalTypes.md). These wrappers are currently missing from the ProtoParquet schema. AvroParquet works just fine, because it adds these wrappers when it deals with arrays and maps. This PR brings these wrappers in parquet-proto, providing the same functionality that already exists in parquet-avro.\n\nThis is backward compatible. Messages written without the extra LIST/MAP wrappers are still being read successfully using the updated ProtoParquetReader.\n\nRegarding the change.\nGiven the following protobuf schema:\n\n```\nmessage ListOfPrimitives {\n    repeated int64 my_repeated_id = 1;\n}\n```\n\nOld parquet schema was:\n```\nmessage ListOfPrimitives {\n  repeated int64 my_repeated_id = 1;\n}\n```\n\nNew parquet schema is:\n```\nmessage ListOfPrimitives {\n  required group my_repeated_id (LIST) = 1 {\n    repeated group list {\n      required int64 element;\n    }\n  }\n}\n```\n---\n\nFor list of messages, the changes look like this:\n\nProtobuf schema:\n```\nmessage ListOfMessages {\n    string top_field = 1;\n    repeated MyInnerMessage first_array = 2;\n}\n\nmessage MyInnerMessage {\n    int32 inner_field = 1;\n}\n```\n\nOld parquet schema was:\n```\nmessage TestProto3.ListOfMessages {\n  optional binary top_field (UTF8) = 1;\n  repeated group first_array = 2 {\n    optional int32 inner_field = 1;\n  }\n}\n```\n\nThe expected parquet schema, compatible with Hive (and similar to parquet-avro) is the following (notice the LIST wrapper):\n\n```\nmessage TestProto3.ListOfMessages {\n  optional binary top_field (UTF8) = 1;\n  required group first_array (LIST) = 2 {\n    repeated group list {\n      optional group element {\n        optional int32 inner_field = 1;\n      }\n    }\n  }\n}\n```\n\n---\n\nSimilar for maps. Protobuf schema:\n```\nmessage TopMessage {\n    map<int64, MyInnerMessage> myMap = 1;\n}\n\nmessage MyInnerMessage {\n    int32 inner_field = 1;\n}\n```\n\nOld parquet schema:\n```\nmessage TestProto3.TopMessage {\n  repeated group myMap = 1 {\n    optional int64 key = 1;\n    optional group value = 2 {\n      optional int32 inner_field = 1;\n    }\n  }\n}\n```\n\nNew parquet schema (notice the `MAP` wrapper):\n```\nmessage TestProto3.TopMessage {\n  required group myMap (MAP) = 1 {\n    repeated group key_value {\n      required int64 key;\n      optional group value {\n        optional int32 inner_field = 1;\n      }\n    }\n  }\n}\n```\n\nJira: https://issues.apache.org/jira/browse/PARQUET-968\n\nAuthor: Constantin Muraru <cmuraru@adobe.com>\nAuthor: Beno\u00eet Hanotte <BenoitHanotte@users.noreply.github.com>\n\nCloses #411 from costimuraru/PARQUET-968 and squashes the following commits:\n\n16eafcb6 [Beno\u00eet Hanotte] PARQUET-968 add proto flag to enable writing using specs-compliant schemas (#2)\na8bd7041 [Constantin Muraru] Pick up commit from @andredasilvapinto\n5cf92487 [Constantin Muraru] PARQUET-968 Add Hive support in ProtoParquet\n",
            "diff": {
                "parquet-protobuf/src/main/java/org/apache/parquet/proto/ProtoMessageConverter.java": 126,
                "parquet-protobuf/src/main/java/org/apache/parquet/proto/ProtoSchemaConverter.java": 169,
                "parquet-protobuf/src/main/java/org/apache/parquet/proto/ProtoWriteSupport.java": 190,
                "parquet-protobuf/src/test/java/org/apache/parquet/proto/ProtoInputOutputFormatTest.java": 120,
                "parquet-protobuf/src/test/java/org/apache/parquet/proto/ProtoSchemaConverterTest.java": 219,
                "parquet-protobuf/src/test/java/org/apache/parquet/proto/ProtoWriteSupportTest.java": 641,
                "parquet-protobuf/src/test/java/org/apache/parquet/proto/utils/WriteUsingMR.java": 10
            },
            "is_test": true,
            "is_fix": false
        },
        "e021734b62ea5ac273e516b4ac83727cbb99ec08": {
            "datetime": "2018-05-07T10:11:58+02:00",
            "summary": "PARQUET-1285: [Java] SchemaConverter should not convert from TimeUnit.SECOND and TimeUnit.NANOSECOND of Arrow (#469)",
            "message": "PARQUET-1285: [Java] SchemaConverter should not convert from TimeUnit.SECOND and TimeUnit.NANOSECOND of Arrow (#469)\n\n* PARQUET-1285: [Java] SchemaConverter should not convert from TimeUnit.SECOND AND TimeUnit.NANOSECOND of Arrow\r\n\r\nArrow's 'Time' definition is below:\r\n\r\n{ \"name\" : \"time\", \"unit\" : \"SECOND|MILLISECOND|MICROSECOND|NANOSECOND\", \"bitWidth\": /* integer: 32 or 64 */ }\r\nhttp://arrow.apache.org/docs/metadata.html\r\n\r\nBut Parquet only supports 'TIME_MILLIS' and 'TIME_MICROS'.\r\nhttps://github.com/Apache/parquet-format/blob/master/LogicalTypes.md\r\n\r\nTherefore SchemaConverter should not convert from TimeUnit.SECOND AND TimeUnit.NANOSECOND of Arrow to Parquet.\r\n\r\nAuthor: Masayuki Takahashi <masayuki038@gmail.com>\r\n\r\n* PARQUET-1285: [Java] SchemaConverter should not convert from TimeUnit.SECOND AND TimeUnit.NANOSECOND of Arrow\r\n\r\nSince the import statements were collected, I restored it.\r\n\r\nAuthor: Masayuki Takahashi <masayuki038@gmail.com>\r\n\r\n* PARQUET-1285: [Java] SchemaConverter should not convert from TimeUnit.SECOND AND TimeUnit.NANOSECOND of Arrow\r\n\r\nRemove unnecessary updates.\r\n\r\nAuthor: Masayuki Takahashi <masayuki038@gmail.com>\r\n\r\n* PARQUET-1285: [Java] SchemaConverter should not convert from TimeUnit.SECOND AND TimeUnit.NANOSECOND of Arrow\r\n\r\nRemove unnecessary package name\r\n\r\nAuthor: Masayuki Takahashi <masayuki038@gmail.com>\r\n\r\n* PARQUET-1285: [Java] SchemaConverter should not convert from TimeUnit.SECOND AND TimeUnit.NANOSECOND of Arrow\r\n\r\nAdd a conversion pattern from Parquet's TIME_MICROS  to Arrow's MICROSECOND\r\n\r\nAuthor: Masayuki Takahashi <masayuki038@gmail.com>\r\n\r\n* PARQUET-1285: [Java] SchemaConverter should not convert from TimeUnit.SECOND AND TimeUnit.NANOSECOND of Arrow\r\n\r\nFix to specify `expected` positions in assertEquals\r\n\r\nAuthor: Masayuki Takahashi <masayuki038@gmail.com>\r\n\r\n* PARQUET-1285: [Java] SchemaConverter should not convert from TimeUnit.SECOND AND TimeUnit.NANOSECOND of Arrow\r\n\r\nAdd a test to convert from Parquet's TIME_MICROS  to Arrow's MICROSECOND\r\n\r\nAuthor: Masayuki Takahashi <masayuki038@gmail.com>\r\n",
            "diff": {
                "parquet-arrow/src/main/java/org/apache/parquet/arrow/schema/SchemaConverter.java": 24,
                "parquet-arrow/src/test/java/org/apache/parquet/arrow/schema/TestSchemaConverter.java": 79
            },
            "is_test": true,
            "is_fix": true
        },
        "b635beb6efc07a97c143775c78a32d42b3b73c8e": {
            "datetime": "2018-05-13T19:31:02+02:00",
            "summary": "PARQUET-1297: SchemaConverter should not convert from Timestamp(TimeUnit.SECOND) and Timestamp(TimeUnit.NANOSECOND) of Arrow (#477)",
            "message": "PARQUET-1297: SchemaConverter should not convert from Timestamp(TimeUnit.SECOND) and Timestamp(TimeUnit.NANOSECOND) of Arrow (#477)\n\nArrow's 'Timestamp' definition is below:\r\n{\r\n  \"name\" : \"timestamp\",\r\n  \"unit\" : \"SECOND|MILLISECOND|MICROSECOND|NANOSECOND\"\r\n}\r\nhttp://arrow.apache.org/docs/metadata.html\r\n\r\nBut Parquet only supports 'TIMESTAMP_MILLIS' and 'TIMESTAMP_MICROS'.\r\n https://github.com/Apache/parquet-format/blob/master/LogicalTypes.md\r\n\r\nTherefore SchemaConverter should not convert from Timestamp(TimeUnit.SECOND) and Timestamp(TimeUnit.NANOSECOND) of Arrow to Parquet.\r\n\r\nRelated:\r\nhttps://issues.apache.org/jira/browse/PARQUET-1285\r\n\r\nAuthor: Masayuki Takahashi <masayuki038@gmail.com>",
            "diff": {
                "parquet-arrow/src/main/java/org/apache/parquet/arrow/schema/SchemaConverter.java": 17,
                "parquet-arrow/src/test/java/org/apache/parquet/arrow/schema/TestSchemaConverter.java": 63
            },
            "is_test": true,
            "is_fix": true
        },
        "94a8bf6d304d08e8a1fc181e7a06a545103e8ddb": {
            "datetime": "2018-05-24T13:46:11+02:00",
            "summary": "PARQUET-1253: Support for new logical type representation (#463)",
            "message": "PARQUET-1253: Support for new logical type representation (#463)\n\n",
            "diff": {
                "parquet-cascading3/src/test/java/org/apache/parquet/cascading/TestParquetTBaseScheme.java": 7,
                "parquet-column/src/main/java/org/apache/parquet/schema/GroupType.java": 17,
                "parquet-column/src/main/java/org/apache/parquet/schema/LogicalTypeAnnotation.java": 878,
                "parquet-column/src/main/java/org/apache/parquet/schema/MessageTypeParser.java": 55,
                "parquet-column/src/main/java/org/apache/parquet/schema/PrimitiveType.java": 64,
                "parquet-column/src/main/java/org/apache/parquet/schema/Type.java": 40,
                "parquet-column/src/main/java/org/apache/parquet/schema/Types.java": 79,
                "parquet-column/src/test/java/org/apache/parquet/parser/TestParquetParser.java": 46,
                "parquet-column/src/test/java/org/apache/parquet/schema/TestTypeBuilders.java": 47,
                "parquet-hadoop/src/main/java/org/apache/parquet/format/converter/ParquetMetadataConverter.java": 338,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/metadata/ParquetMetadata.java": 15,
                "parquet-hadoop/src/test/java/org/apache/parquet/format/converter/TestParquetMetadataConverter.java": 18,
                "parquet-pig/src/main/java/org/apache/parquet/pig/PigSchemaConverter.java": 6
            },
            "is_test": true,
            "is_fix": false
        },
        "345e2d541128471641e76aaa44dd5046f199197d": {
            "datetime": "2018-05-31T16:38:43+02:00",
            "summary": "PARQUET-1304: Release 1.10 contains breaking changes for Hive (#485)",
            "message": "PARQUET-1304: Release 1.10 contains breaking changes for Hive (#485)\n\n",
            "diff": {
                "parquet-column/src/main/java/org/apache/parquet/column/values/ValuesReader.java": 70,
                "parquet-column/src/main/java/org/apache/parquet/column/values/bitpacking/BitPackingValuesReader.java": 1,
                "parquet-column/src/main/java/org/apache/parquet/column/values/bitpacking/ByteBitPackingValuesReader.java": 1,
                "parquet-column/src/main/java/org/apache/parquet/column/values/delta/DeltaBinaryPackingValuesReader.java": 2,
                "parquet-column/src/main/java/org/apache/parquet/column/values/plain/BooleanPlainValuesReader.java": 6,
                "parquet-column/src/main/java/org/apache/parquet/column/values/rle/RunLengthBitPackingHybridValuesReader.java": 3,
                "parquet-column/src/main/java/org/apache/parquet/column/values/rle/ZeroIntegerValuesReader.java": 3,
                "parquet-column/src/test/java/org/apache/parquet/column/values/delta/DeltaBinaryPackingValuesWriterForIntegerTest.java": 8,
                "parquet-column/src/test/java/org/apache/parquet/column/values/delta/DeltaBinaryPackingValuesWriterForLongTest.java": 8,
                "parquet-column/src/test/java/org/apache/parquet/column/values/dictionary/TestDictionary.java": 5,
                "parquet-common/src/main/java/org/apache/parquet/bytes/ByteBufferInputStream.java": 100,
                "parquet-common/src/main/java/org/apache/parquet/bytes/BytesInput.java": 16,
                "parquet-common/src/main/java/org/apache/parquet/bytes/MultiBufferInputStream.java": 2,
                "parquet-common/src/test/java/org/apache/parquet/bytes/TestByteBufferInputStreams.java": 14,
                "parquet-common/src/test/java/org/apache/parquet/bytes/TestDeprecatedBufferInputStream.java": 152,
                "parquet-common/src/test/java/org/apache/parquet/bytes/TestSingleBufferInputStream.java": 2
            },
            "is_test": true,
            "is_fix": true
        },
        "3fd2492fcce073f0c36e4d7e23e34881557e6e5e": {
            "datetime": "2018-06-04T17:52:28+02:00",
            "summary": "PARQUET-1317: Fix ParquetMetadataConverter throw NPE (#489)",
            "message": "PARQUET-1317: Fix ParquetMetadataConverter throw NPE (#489)\n\n",
            "diff": {
                "parquet-hadoop/src/main/java/org/apache/parquet/format/converter/ParquetMetadataConverter.java": 4
            },
            "is_test": false,
            "is_fix": false
        },
        "a918c493296c88da94b36600213c7c188f2589b4": {
            "datetime": "2018-06-04T18:49:17+02:00",
            "summary": "PARQUET-1317: Fix ParquetMetadataConverter throw NPE (#491)",
            "message": "PARQUET-1317: Fix ParquetMetadataConverter throw NPE (#491)\n\nNew test case in TestParquetMetadataConverter to reproduce NPE and ensure backward compatibility",
            "diff": {
                "parquet-hadoop/src/test/java/org/apache/parquet/format/converter/TestParquetMetadataConverter.java": 16
            },
            "is_test": true,
            "is_fix": true
        },
        "9181e1d536bafedcb3587ca30e5b6e2d66f06bf0": {
            "datetime": "2018-06-05T11:16:05+02:00",
            "summary": "PARQUET-1309: Parquet Java uses incorrect stats and dictionary filter properties (#490)",
            "message": "PARQUET-1309: Parquet Java uses incorrect stats and dictionary filter properties (#490)\n\n",
            "diff": {
                "parquet-hadoop/src/main/java/org/apache/parquet/HadoopReadOptions.java": 4
            },
            "is_test": false,
            "is_fix": false
        },
        "f2d58718a5c7759d0f46d68ac954bd1d8064d7be": {
            "datetime": "2018-06-12T11:47:43+02:00",
            "summary": "PARQUET-1321: LogicalTypeAnnotation.LogicalTypeAnnotationVisitor#visit methods should have a return value (#493)",
            "message": "PARQUET-1321: LogicalTypeAnnotation.LogicalTypeAnnotationVisitor#visit methods should have a return value (#493)\n\n",
            "diff": {
                "parquet-column/src/main/java/org/apache/parquet/schema/LogicalTypeAnnotation.java": 104,
                "parquet-hadoop/src/main/java/org/apache/parquet/format/converter/ParquetMetadataConverter.java": 202
            },
            "is_test": false,
            "is_fix": false
        },
        "cc8bdf1d13639d12d02170d40cc4890180bbabc5": {
            "datetime": "2018-06-18T09:47:25+02:00",
            "summary": "PARQUET-952: Avro union with single type fails with 'is not a group' (#459)",
            "message": "PARQUET-952: Avro union with single type fails with 'is not a group' (#459)\n\n",
            "diff": {
                "parquet-avro/src/main/java/org/apache/parquet/avro/AvroSchemaConverter.java": 24,
                "parquet-avro/src/test/java/org/apache/parquet/avro/TestReadWrite.java": 31
            },
            "is_test": true,
            "is_fix": true
        },
        "33ee5497490cbc97f3eabe9ef7a6391e4dbee8bc": {
            "datetime": "2018-06-25T08:24:15+02:00",
            "summary": "PARQUET-1335: Logical type names in parquet-mr are not consistent with parquet-format (#496)",
            "message": "PARQUET-1335: Logical type names in parquet-mr are not consistent with parquet-format (#496)\n\n",
            "diff": {
                "parquet-column/src/main/java/org/apache/parquet/schema/LogicalTypeAnnotation.java": 8,
                "parquet-column/src/test/java/org/apache/parquet/parser/TestParquetParser.java": 26
            },
            "is_test": true,
            "is_fix": false
        },
        "dc61e510126aaa1a95a46fe39bf1529f394147e9": {
            "datetime": "2018-06-26T09:38:23+02:00",
            "summary": "PARQUET-1336: PrimitiveComparator should implements Serializable (#497)",
            "message": "PARQUET-1336: PrimitiveComparator should implements Serializable (#497)\n\n\r\n",
            "diff": {
                "parquet-column/src/main/java/org/apache/parquet/schema/PrimitiveComparator.java": 4
            },
            "is_test": false,
            "is_fix": false
        },
        "d320a457a9de67be25a03f79e1695d549a0145f3": {
            "datetime": "2018-07-03T15:24:53-07:00",
            "summary": "PARQUET-1341: Fix null count stats in unsigned-sort columns. (#499)",
            "message": "PARQUET-1341: Fix null count stats in unsigned-sort columns. (#499)\n\n* Fix null count stats in unsigned-sort columns.\r\n* Fix test case for old min/max values and unsigned ordering.\r\n",
            "diff": {
                "parquet-hadoop/src/main/java/org/apache/parquet/format/converter/ParquetMetadataConverter.java": 12,
                "parquet-hadoop/src/test/java/org/apache/parquet/format/converter/TestParquetMetadataConverter.java": 4
            },
            "is_test": true,
            "is_fix": true
        },
        "94ae6c84d22ed33e158b3cc822ca4a0484c829c9": {
            "datetime": "2018-07-04T13:58:33+02:00",
            "summary": "PARQUET-1344: Type builders don't honor new logical types (#500)",
            "message": "PARQUET-1344: Type builders don't honor new logical types (#500)\n\n* PARQUET-1344: Type builders don't honor new logical types\r\n\r\nCall propert constructor when builder is caller with new logical type,\r\ncall the deprecated OriginalType version otherwise.\r\n\r\n* Use static imports in test\r\n",
            "diff": {
                "parquet-column/src/main/java/org/apache/parquet/schema/Types.java": 12,
                "parquet-column/src/test/java/org/apache/parquet/schema/TestTypeBuilders.java": 29
            },
            "is_test": true,
            "is_fix": true
        },
        "e9e36cdc44a68662885e35773187cca00d20239e": {
            "datetime": "2018-07-09T10:10:24+02:00",
            "summary": "PARQUET-1335: Logical type names in parquet-mr are not consistent with parquet-format (#503)",
            "message": "PARQUET-1335: Logical type names in parquet-mr are not consistent with parquet-format (#503)\n\nAdd test case for STRING annotation and revert UTF8 annotations removed in PR#496",
            "diff": {
                "parquet-column/src/test/java/org/apache/parquet/parser/TestParquetParser.java": 28
            },
            "is_test": true,
            "is_fix": false
        }
    },
    "2018-07-31T15:17:05-07:00": {
        "55e94974e0547085a66c6242336e56230f996d52": {
            "datetime": "2018-08-07T17:56:42+02:00",
            "summary": "PARQUET-1371: Time/Timestamp UTC normalization parameter doesn't work (#511)",
            "message": "PARQUET-1371: Time/Timestamp UTC normalization parameter doesn't work (#511)\n\n",
            "diff": {
                "parquet-hadoop/src/main/java/org/apache/parquet/format/converter/ParquetMetadataConverter.java": 15,
                "parquet-hadoop/src/test/java/org/apache/parquet/format/converter/TestParquetMetadataConverter.java": 61
            },
            "is_test": true,
            "is_fix": true
        },
        "45e3ce5fd218e4f7ec645c3f2947aa2459fe9c7b": {
            "datetime": "2018-08-07T09:35:38-07:00",
            "summary": "PARQUET-1368: ParquetFileReader should close its input stream for the failure in constructor (#510)",
            "message": "PARQUET-1368: ParquetFileReader should close its input stream for the failure in constructor (#510)\n\n",
            "diff": {
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ParquetFileReader.java": 9
            },
            "is_test": false,
            "is_fix": false
        },
        "d692ce3a4205a4274e97dce6add93c687e12a9c2": {
            "datetime": "2018-08-19T11:12:36+02:00",
            "summary": "PARQUET-1390: Upgrade Arrow to 0.10.0",
            "message": "PARQUET-1390: Upgrade Arrow to 0.10.0\n\nThis upgrades arrow from 0.8.0 to 0.10.0.\n\nThis required adding new SchemaConverter visitor methods for fixedSizeBinary data type and I pretty much guessed at how to implement those so would appreciate a review of that.\n\nAuthor: Andy Grove <andy.grove@rms.com>\n\nCloses #516 from agrove-rms/arrow_upgrade and squashes the following commits:\n\n4a922876 [Andy Grove] Add new visitor methods\n9535a162 [Andy Grove] Upgrade Arrow from 0.8.0 to 0.10.0\n",
            "diff": {
                "parquet-arrow/src/main/java/org/apache/parquet/arrow/schema/SchemaConverter.java": 10
            },
            "is_test": false,
            "is_fix": false
        },
        "75f0e42f11030707878a78399552cd282280f66a": {
            "datetime": "2018-08-22T12:06:48+02:00",
            "summary": "PARQUET-1201: Implement page indexes",
            "message": "PARQUET-1201: Implement page indexes\n\nAdded helper methods to read/write ColumnIndex and OffsetIndex objects.\n\nAuthor: Gabor Szadovszky <gabor.szadovszky@cloudera.com>\n\nCloses #81 from gszadovszky/PARQUET-1201 and squashes the following commits:\n\n573dada [Gabor Szadovszky] PARQUET-1201: Implement page indexes\n",
            "diff": {
                "src/main/java/org/apache/parquet/format/Util.java": 16
            },
            "is_test": false,
            "is_fix": false
        },
        "e281913d0b033faaa0d41ec484fd00dee9610afe": {
            "datetime": "2018-08-22T12:06:48+02:00",
            "summary": "PARQUET-906: Add LogicalType annotation.",
            "message": "PARQUET-906: Add LogicalType annotation.\n\nThis commit adds a `LogicalType` union and a field for this logical type to `SchemaElement`. Adding a new structure for logical types is needed for a few reasons:\n\n1. Adding to the ConvertedType enum is not forward-compatible. Adding new types to the `LogicalType` union is forward-compatible.\n2. Using a struct for each type allows additional metadata, like `isAdjustedToUTC`, without adding more fields to `SchemaElement` that don't apply to all types.\n3. Types without additional metadata can be updated later. For example, adding an `encoding` field to `StringType` when it is needed.\n\nAuthor: Ryan Blue <blue@apache.org>\n\nCloses #51 from rdblue/PARQUET-906-add-timestamp-adjustment-metadata and squashes the following commits:\n\nad8e91d [Ryan Blue] PARQUET-906: Clarify the use of NullType.\n7cc29f7 [Ryan Blue] PARQUET-906: Rename NULL to UNKNOWN.\n02f3868 [Ryan Blue] PARQUET-906: Update from comments on the PR.\nc0386e9 [Ryan Blue] PARQUET-906: Remove NULL ConvertedType.\n190bd8a [Ryan Blue] PARQUET-906: Update for review comments.\n8203b21 [Ryan Blue] PARQUET-906: Add copyright header to LogicalTypes.\n993102e [Ryan Blue] PARQUET-906: Remove the unreleased NULL ConvertedType.\n86a22b4 [Ryan Blue] PARQUET-906: Add LogicalType annotation.\n",
            "diff": {
                "src/main/java/org/apache/parquet/format/LogicalTypes.java": 55
            },
            "is_test": false,
            "is_fix": false
        },
        "344b56803fea37af84b9c01c9b6dcff586779683": {
            "datetime": "2018-08-22T13:11:52+02:00",
            "summary": "PARQUET-1399: Move files to the module directory",
            "message": "PARQUET-1399: Move files to the module directory\n",
            "diff": {
                "src/main/java/org/apache/parquet/format/InterningProtocol.java": 0,
                "src/main/java/org/apache/parquet/format/LogicalTypes.java": 0,
                "src/main/java/org/apache/parquet/format/Util.java": 0,
                "src/main/java/org/apache/parquet/format/event/Consumers.java": 0,
                "src/main/java/org/apache/parquet/format/event/EventBasedThriftReader.java": 0,
                "src/main/java/org/apache/parquet/format/event/FieldConsumer.java": 0,
                "src/main/java/org/apache/parquet/format/event/TypedConsumer.java": 0,
                "src/test/java/org/apache/parquet/format/TestUtil.java": 0
            },
            "is_test": true,
            "is_fix": false
        },
        "863a081850e56bbbb38d7b68b478a3bd40779723": {
            "datetime": "2018-09-11T13:56:57+02:00",
            "summary": "PARQUET-1381: Add merge blocks command to parquet-tools (#512)",
            "message": "PARQUET-1381: Add merge blocks command to parquet-tools (#512)\n\nExisting implementation of merge command in parquet-tools didn't merge row groups, just placed one after the other. This commit adds API and command option to be able to merge small blocks into larger ones up to specified size limit.",
            "diff": {
                "parquet-column/src/main/java/org/apache/parquet/column/impl/ColumnReadStoreImpl.java": 2,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ColumnChunkPageWriteStore.java": 5,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ParquetFileReader.java": 93,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ParquetFileWriter.java": 115,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/util/BlocksCombiner.java": 106,
                "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/TestParquetWriterMergeBlocks.java": 280,
                "parquet-tools/src/main/java/org/apache/parquet/tools/command/MergeCommand.java": 75
            },
            "is_test": true,
            "is_fix": false
        },
        "b4198be200e7e2df82bc9a18d54c8cd16aa156ac": {
            "datetime": "2018-09-12T14:14:20+02:00",
            "summary": "PARQUET-1410: Refactor modules to use the new logical type API (#520)",
            "message": "PARQUET-1410: Refactor modules to use the new logical type API (#520)\n\n",
            "diff": {
                "parquet-arrow/src/main/java/org/apache/parquet/arrow/schema/SchemaConverter.java": 252,
                "parquet-arrow/src/test/java/org/apache/parquet/arrow/schema/TestSchemaConverter.java": 27,
                "parquet-avro/src/main/java/org/apache/parquet/avro/AvroSchemaConverter.java": 158,
                "parquet-avro/src/test/java/org/apache/parquet/avro/TestAvroSchemaConverter.java": 14,
                "parquet-cascading-common23/src/main/java/org/apache/parquet/cascading/convert/TupleConverter.java": 9,
                "parquet-cli/src/main/java/org/apache/parquet/cli/Util.java": 10,
                "parquet-cli/src/main/java/org/apache/parquet/cli/commands/ParquetMetadataCommand.java": 4,
                "parquet-cli/src/main/java/org/apache/parquet/cli/commands/ShowDictionaryCommand.java": 4,
                "parquet-cli/src/main/java/org/apache/parquet/cli/commands/ShowPagesCommand.java": 4,
                "parquet-column/src/main/java/org/apache/parquet/filter2/predicate/ValidTypeMap.java": 7,
                "parquet-column/src/main/java/org/apache/parquet/schema/ConversionPatterns.java": 28,
                "parquet-column/src/main/java/org/apache/parquet/schema/GroupType.java": 36,
                "parquet-column/src/main/java/org/apache/parquet/schema/LogicalTypeAnnotation.java": 111,
                "parquet-column/src/main/java/org/apache/parquet/schema/MessageType.java": 8,
                "parquet-column/src/main/java/org/apache/parquet/schema/OriginalType.java": 66,
                "parquet-column/src/main/java/org/apache/parquet/schema/PrimitiveType.java": 213,
                "parquet-column/src/main/java/org/apache/parquet/schema/Types.java": 136,
                "parquet-column/src/test/java/org/apache/parquet/filter2/predicate/TestValidTypeMap.java": 7,
                "parquet-column/src/test/java/org/apache/parquet/schema/TestMessageType.java": 2,
                "parquet-hadoop/src/main/java/org/apache/parquet/format/converter/ParquetMetadataConverter.java": 247,
                "parquet-hive/parquet-hive-storage-handler/src/main/java/org/apache/hadoop/hive/ql/io/parquet/convert/HiveSchemaConverter.java": 17,
                "parquet-pig/src/main/java/org/apache/parquet/pig/PigSchemaConverter.java": 124,
                "parquet-pig/src/main/java/org/apache/parquet/pig/convert/TupleConverter.java": 31,
                "parquet-protobuf/src/main/java/org/apache/parquet/proto/ProtoMessageConverter.java": 45,
                "parquet-protobuf/src/main/java/org/apache/parquet/proto/ProtoSchemaConverter.java": 45,
                "parquet-protobuf/src/main/java/org/apache/parquet/proto/ProtoWriteSupport.java": 33,
                "parquet-thrift/src/main/java/org/apache/parquet/thrift/ThriftSchemaConvertVisitor.java": 18,
                "parquet-tools/src/main/java/org/apache/parquet/tools/command/DumpCommand.java": 1,
                "parquet-tools/src/main/java/org/apache/parquet/tools/command/MetadataUtils.java": 212,
                "parquet-tools/src/main/java/org/apache/parquet/tools/command/ShowMetaCommand.java": 29,
                "parquet-tools/src/main/java/org/apache/parquet/tools/command/ShowSchemaCommand.java": 14,
                "parquet-tools/src/main/java/org/apache/parquet/tools/read/SimpleRecordConverter.java": 56,
                "parquet-tools/src/main/java/org/apache/parquet/tools/util/MetadataUtils.java": 9
            },
            "is_test": true,
            "is_fix": false
        },
        "1f79f9bd0ba61b8ec0bae1dec71ef7249d41eacd": {
            "datetime": "2018-09-18T13:38:56+02:00",
            "summary": "PARQUET-1353: Fix random data generator. (#504)",
            "message": "PARQUET-1353: Fix random data generator. (#504)\n\nThe random data generator used for tests used to repeat the same value\r\nover and over again.",
            "diff": {
                "parquet-hadoop/src/test/java/org/apache/parquet/statistics/RandomValues.java": 7
            },
            "is_test": false,
            "is_fix": false
        },
        "93767ca512524cbf51548430782f061773600971": {
            "datetime": "2018-09-20T11:13:18+02:00",
            "summary": "PARQUET-1417: BINARY_AS_SIGNED_INTEGER_COMPARATOR fails with IOBE for the same arrays with the different length (#522)",
            "message": "PARQUET-1417: BINARY_AS_SIGNED_INTEGER_COMPARATOR fails with IOBE for the same arrays with the different length (#522)\n\n",
            "diff": {
                "parquet-column/src/main/java/org/apache/parquet/schema/PrimitiveComparator.java": 6,
                "parquet-column/src/test/java/org/apache/parquet/schema/TestPrimitiveComparator.java": 19
            },
            "is_test": true,
            "is_fix": true
        },
        "411e672401a3cdec7e724fef354257f6f8119a58": {
            "datetime": "2018-09-20T16:23:29+02:00",
            "summary": "PARQUET-1421: InternalParquetRecordWriter logs debug messages at the INFO level (#526)",
            "message": "PARQUET-1421: InternalParquetRecordWriter logs debug messages at the INFO level (#526)\n\nReduced log level of said messages to DEBUG.",
            "diff": {
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/InternalParquetRecordWriter.java": 4
            },
            "is_test": false,
            "is_fix": false
        },
        "412685f5814672a490b3a64ccfc1500a0100c378": {
            "datetime": "2018-09-24T13:57:52+02:00",
            "summary": "Merge commit '344b56803fea37af84b9c01c9b6dcff586779683' into merge_PARQUET-1399",
            "message": "Merge commit '344b56803fea37af84b9c01c9b6dcff586779683' into merge_PARQUET-1399\n",
            "diff": {
                "parquet-format-structures/src/main/java/org/apache/parquet/format/InterningProtocol.java": 234,
                "parquet-format-structures/src/main/java/org/apache/parquet/format/LogicalTypes.java": 55,
                "parquet-format-structures/src/main/java/org/apache/parquet/format/Util.java": 243,
                "parquet-format-structures/src/main/java/org/apache/parquet/format/event/Consumers.java": 199,
                "parquet-format-structures/src/main/java/org/apache/parquet/format/event/EventBasedThriftReader.java": 129,
                "parquet-format-structures/src/main/java/org/apache/parquet/format/event/FieldConsumer.java": 43,
                "parquet-format-structures/src/main/java/org/apache/parquet/format/event/TypedConsumer.java": 204,
                "parquet-format-structures/src/test/java/org/apache/parquet/format/TestUtil.java": 83
            },
            "is_test": true,
            "is_fix": false
        },
        "a150f245f0783fbd7d52da04320d256c60087bdb": {
            "datetime": "2018-09-24T13:58:03+02:00",
            "summary": "PARQUET-1399: Move parquet-mr related code from parquet-format",
            "message": "PARQUET-1399: Move parquet-mr related code from parquet-format\n",
            "diff": {
                "parquet-format-structures/src/main/java/org/apache/parquet/format/InterningProtocol.java": 3,
                "parquet-format-structures/src/main/java/org/apache/parquet/format/Util.java": 9,
                "parquet-format-structures/src/main/java/org/apache/parquet/format/event/Consumers.java": 12,
                "parquet-format-structures/src/main/java/org/apache/parquet/format/event/EventBasedThriftReader.java": 15,
                "parquet-format-structures/src/main/java/org/apache/parquet/format/event/FieldConsumer.java": 6,
                "parquet-format-structures/src/main/java/org/apache/parquet/format/event/TypedConsumer.java": 15
            },
            "is_test": false,
            "is_fix": false
        },
        "0569f5128d5e529b5114ba05db9b853625918b43": {
            "datetime": "2018-09-25T14:38:00+02:00",
            "summary": "Revert \"PARQUET-1353: Fix random data generator. (#504)\"",
            "message": "Revert \"PARQUET-1353: Fix random data generator. (#504)\"\n\nThis reverts commit 1f79f9bd0ba61b8ec0bae1dec71ef7249d41eacd because of\nconcerns raised in the code review after the pull request was merged.\n",
            "diff": {
                "parquet-hadoop/src/test/java/org/apache/parquet/statistics/RandomValues.java": 7
            },
            "is_test": false,
            "is_fix": false
        },
        "0d541fc6cfdc0de9f45d2d2d7606afdef1415750": {
            "datetime": "2018-10-04T15:26:49+02:00",
            "summary": "PARQUET-1388: Nanosecond precision time and timestamp - parquet-mr (#519)",
            "message": "PARQUET-1388: Nanosecond precision time and timestamp - parquet-mr (#519)\n\n",
            "diff": {
                "parquet-arrow/src/main/java/org/apache/parquet/arrow/schema/SchemaConverter.java": 9,
                "parquet-arrow/src/test/java/org/apache/parquet/arrow/schema/TestSchemaConverter.java": 34,
                "parquet-column/src/main/java/org/apache/parquet/schema/LogicalTypeAnnotation.java": 11,
                "parquet-column/src/main/java/org/apache/parquet/schema/PrimitiveStringifier.java": 34,
                "parquet-column/src/main/java/org/apache/parquet/schema/Types.java": 1,
                "parquet-column/src/test/java/org/apache/parquet/parser/TestParquetParser.java": 5,
                "parquet-column/src/test/java/org/apache/parquet/schema/TestPrimitiveStringifier.java": 38,
                "parquet-column/src/test/java/org/apache/parquet/schema/TestTypeBuildersWithLogicalTypes.java": 408,
                "parquet-hadoop/src/main/java/org/apache/parquet/format/converter/ParquetMetadataConverter.java": 14,
                "parquet-hadoop/src/test/java/org/apache/parquet/format/converter/TestParquetMetadataConverter.java": 12
            },
            "is_test": true,
            "is_fix": false
        },
        "63003ac204369c077f8e7148799b22c2aa10d2d6": {
            "datetime": "2018-10-05T11:16:42+02:00",
            "summary": "PARQUET-1436: TimestampMicrosStringifier shows wrong microseconds for timestamps before 1970 (#529)",
            "message": "PARQUET-1436: TimestampMicrosStringifier shows wrong microseconds for timestamps before 1970 (#529)\n\n\r\n",
            "diff": {
                "parquet-column/src/main/java/org/apache/parquet/schema/PrimitiveStringifier.java": 57,
                "parquet-column/src/test/java/org/apache/parquet/schema/TestPrimitiveStringifier.java": 8
            },
            "is_test": true,
            "is_fix": false
        },
        "716fb6b3514b05e7b5ad87dea2c3b2ccad4cef60": {
            "datetime": "2018-10-10T17:54:54+02:00",
            "summary": "PARQUET-1440: Parquet-tools: Parse int32 or int64 decimal values to big decimals with the proper scale (#530)",
            "message": "PARQUET-1440: Parquet-tools: Parse int32 or int64 decimal values to big decimals with the proper scale (#530)\n\n",
            "diff": {
                "parquet-tools/src/main/java/org/apache/parquet/tools/read/SimpleRecordConverter.java": 10
            },
            "is_test": false,
            "is_fix": false
        },
        "cded3e57fc7f1eaba1dfb312a873a9f30705d14f": {
            "datetime": "2018-10-15T15:06:58+02:00",
            "summary": "PARQUET-1383: Parquet tools should indicate UTC parameter for time/timestamp types (#513)",
            "message": "PARQUET-1383: Parquet tools should indicate UTC parameter for time/timestamp types (#513)\n\n",
            "diff": {
                "parquet-column/src/main/java/org/apache/parquet/schema/LogicalTypeAnnotation.java": 26,
                "parquet-column/src/main/java/org/apache/parquet/schema/PrimitiveStringifier.java": 91,
                "parquet-column/src/test/java/org/apache/parquet/schema/TestPrimitiveStringifier.java": 144
            },
            "is_test": true,
            "is_fix": false
        },
        "e7db9e20f52c925a207ea62d6dda6dc4e870294e": {
            "datetime": "2018-10-18T14:08:13+02:00",
            "summary": "PARQUET-1201: Column indexes (#527)",
            "message": "PARQUET-1201: Column indexes (#527)\n\nThis is a squashed feature branch merge including the changes listed below. The detailed history can be found in the 'column-indexes' branch.\r\n\r\n* PARQUET-1211: Column indexes: read/write API (#456)\r\n* PARQUET-1212: Column indexes: Show indexes in tools (#479)\r\n* PARQUET-1213: Column indexes: Limit index size (#480)\r\n* PARQUET-1214: Column indexes: Truncate min/max values (#481)\r\n* PARQUET-1364: Invalid row indexes for pages starting with nulls (#507)\r\n* PARQUET-1310: Column indexes: Filtering (#509)\r\n* PARQUET-1386: Fix issues of NaN and +-0.0 in case of float/double column indexes (#515)\r\n* PARQUET-1389: Improve value skipping at page synchronization (#514)\r\n* PARQUET-1381: Fix missing endRecord after merging columnIndex",
            "diff": {
                "parquet-cli/src/main/java/org/apache/parquet/cli/Main.java": 2,
                "parquet-cli/src/main/java/org/apache/parquet/cli/commands/ShowColumnIndexCommand.java": 157,
                "parquet-column/src/main/java/org/apache/parquet/column/ColumnReader.java": 3,
                "parquet-column/src/main/java/org/apache/parquet/column/ParquetProperties.java": 20,
                "parquet-column/src/main/java/org/apache/parquet/column/impl/ColumnReadStoreImpl.java": 12,
                "parquet-column/src/main/java/org/apache/parquet/column/impl/ColumnReaderBase.java": 760,
                "parquet-column/src/main/java/org/apache/parquet/column/impl/ColumnReaderImpl.java": 680,
                "parquet-column/src/main/java/org/apache/parquet/column/impl/ColumnWriteStoreBase.java": 223,
                "parquet-column/src/main/java/org/apache/parquet/column/impl/ColumnWriteStoreV1.java": 115,
                "parquet-column/src/main/java/org/apache/parquet/column/impl/ColumnWriteStoreV2.java": 148,
                "parquet-column/src/main/java/org/apache/parquet/column/impl/ColumnWriterBase.java": 326,
                "parquet-column/src/main/java/org/apache/parquet/column/impl/ColumnWriterV1.java": 269,
                "parquet-column/src/main/java/org/apache/parquet/column/impl/ColumnWriterV2.java": 296,
                "parquet-column/src/main/java/org/apache/parquet/column/impl/SynchronizingColumnReader.java": 111,
                "parquet-column/src/main/java/org/apache/parquet/column/page/DataPage.java": 22,
                "parquet-column/src/main/java/org/apache/parquet/column/page/DataPageV1.java": 31,
                "parquet-column/src/main/java/org/apache/parquet/column/page/DataPageV2.java": 52,
                "parquet-column/src/main/java/org/apache/parquet/column/page/PageReadStore.java": 15,
                "parquet-column/src/main/java/org/apache/parquet/column/page/PageWriter.java": 17,
                "parquet-column/src/main/java/org/apache/parquet/column/values/ValuesReader.java": 12,
                "parquet-column/src/main/java/org/apache/parquet/column/values/delta/DeltaBinaryPackingValuesReader.java": 8,
                "parquet-column/src/main/java/org/apache/parquet/column/values/deltalengthbytearray/DeltaLengthByteArrayValuesReader.java": 12,
                "parquet-column/src/main/java/org/apache/parquet/column/values/plain/FixedLenByteArrayPlainValuesReader.java": 8,
                "parquet-column/src/main/java/org/apache/parquet/column/values/plain/PlainValuesReader.java": 36,
                "parquet-column/src/main/java/org/apache/parquet/column/values/rle/RunLengthBitPackingHybridValuesWriter.java": 9,
                "parquet-column/src/main/java/org/apache/parquet/column/values/rle/ZeroIntegerValuesReader.java": 4,
                "parquet-column/src/main/java/org/apache/parquet/internal/column/columnindex/BinaryColumnIndexBuilder.java": 140,
                "parquet-column/src/main/java/org/apache/parquet/internal/column/columnindex/BinaryTruncator.java": 208,
                "parquet-column/src/main/java/org/apache/parquet/internal/column/columnindex/BooleanColumnIndexBuilder.java": 133,
                "parquet-column/src/main/java/org/apache/parquet/internal/column/columnindex/BoundaryOrder.java": 352,
                "parquet-column/src/main/java/org/apache/parquet/internal/column/columnindex/ColumnIndex.java": 60,
                "parquet-column/src/main/java/org/apache/parquet/internal/column/columnindex/ColumnIndexBuilder.java": 636,
                "parquet-column/src/main/java/org/apache/parquet/internal/column/columnindex/DoubleColumnIndexBuilder.java": 155,
                "parquet-column/src/main/java/org/apache/parquet/internal/column/columnindex/FloatColumnIndexBuilder.java": 155,
                "parquet-column/src/main/java/org/apache/parquet/internal/column/columnindex/IndexIterator.java": 98,
                "parquet-column/src/main/java/org/apache/parquet/internal/column/columnindex/IntColumnIndexBuilder.java": 136,
                "parquet-column/src/main/java/org/apache/parquet/internal/column/columnindex/LongColumnIndexBuilder.java": 136,
                "parquet-column/src/main/java/org/apache/parquet/internal/column/columnindex/OffsetIndex.java": 64,
                "parquet-column/src/main/java/org/apache/parquet/internal/column/columnindex/OffsetIndexBuilder.java": 175,
                "parquet-column/src/main/java/org/apache/parquet/internal/filter2/columnindex/ColumnIndexFilter.java": 194,
                "parquet-column/src/main/java/org/apache/parquet/internal/filter2/columnindex/ColumnIndexStore.java": 55,
                "parquet-column/src/main/java/org/apache/parquet/internal/filter2/columnindex/RowRanges.java": 288,
                "parquet-column/src/test/java/org/apache/parquet/column/impl/TestColumnReaderImpl.java": 8,
                "parquet-column/src/test/java/org/apache/parquet/column/mem/TestMemColumn.java": 12,
                "parquet-column/src/test/java/org/apache/parquet/column/page/mem/MemPageWriter.java": 6,
                "parquet-column/src/test/java/org/apache/parquet/column/values/bitpacking/TestBitPackingColumn.java": 16,
                "parquet-column/src/test/java/org/apache/parquet/column/values/delta/DeltaBinaryPackingValuesWriterForIntegerTest.java": 17,
                "parquet-column/src/test/java/org/apache/parquet/column/values/delta/DeltaBinaryPackingValuesWriterForLongTest.java": 17,
                "parquet-column/src/test/java/org/apache/parquet/column/values/deltalengthbytearray/TestDeltaLengthByteArray.java": 24,
                "parquet-column/src/test/java/org/apache/parquet/column/values/deltastrings/TestDeltaByteArray.java": 19,
                "parquet-column/src/test/java/org/apache/parquet/column/values/dictionary/TestDictionary.java": 105,
                "parquet-column/src/test/java/org/apache/parquet/internal/column/columnindex/TestBinaryTruncator.java": 285,
                "parquet-column/src/test/java/org/apache/parquet/internal/column/columnindex/TestBoundaryOrder.java": 487,
                "parquet-column/src/test/java/org/apache/parquet/internal/column/columnindex/TestColumnIndexBuilder.java": 1546,
                "parquet-column/src/test/java/org/apache/parquet/internal/column/columnindex/TestIndexIterator.java": 63,
                "parquet-column/src/test/java/org/apache/parquet/internal/column/columnindex/TestOffsetIndexBuilder.java": 113,
                "parquet-column/src/test/java/org/apache/parquet/internal/filter2/columnindex/TestColumnIndexFilter.java": 464,
                "parquet-column/src/test/java/org/apache/parquet/internal/filter2/columnindex/TestRowRanges.java": 155,
                "parquet-hadoop/src/main/java/org/apache/parquet/HadoopReadOptions.java": 9,
                "parquet-hadoop/src/main/java/org/apache/parquet/ParquetReadOptions.java": 20,
                "parquet-hadoop/src/main/java/org/apache/parquet/format/converter/ParquetMetadataConverter.java": 108,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ColumnChunkPageReadStore.java": 115,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ColumnChunkPageWriteStore.java": 54,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ColumnIndexFilterUtils.java": 157,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ColumnIndexStoreImpl.java": 155,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/InternalParquetRecordReader.java": 6,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/InternalParquetRecordWriter.java": 4,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ParquetFileReader.java": 341,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ParquetFileWriter.java": 222,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ParquetInputFormat.java": 5,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ParquetOutputFormat.java": 17,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ParquetReader.java": 10,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ParquetWriter.java": 2,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/metadata/ColumnChunkMetaData.java": 41,
                "parquet-hadoop/src/main/java/org/apache/parquet/internal/hadoop/metadata/IndexReference.java": 41,
                "parquet-hadoop/src/test/java/org/apache/parquet/filter2/recordlevel/PhoneBookWriter.java": 107,
                "parquet-hadoop/src/test/java/org/apache/parquet/format/converter/TestParquetMetadataConverter.java": 62,
                "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/TestColumnChunkPageWriteStore.java": 94,
                "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/TestColumnIndexFiltering.java": 442,
                "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/TestParquetFileWriter.java": 146,
                "parquet-tools/src/main/java/org/apache/parquet/tools/command/ColumnIndexCommand.java": 182,
                "parquet-tools/src/main/java/org/apache/parquet/tools/command/Registry.java": 1
            },
            "is_test": true,
            "is_fix": false
        },
        "1e0760a1f9c138e3cb66143f1c9fdf8ee2e8eef7": {
            "datetime": "2018-11-07T09:44:06+01:00",
            "summary": "PARQUET-1414: Limit page size based on maximum row count (#531)",
            "message": "PARQUET-1414: Limit page size based on maximum row count (#531)\n\n\r\n",
            "diff": {
                "parquet-column/src/main/java/org/apache/parquet/column/ParquetProperties.java": 21,
                "parquet-column/src/main/java/org/apache/parquet/column/impl/ColumnWriteStoreBase.java": 15,
                "parquet-column/src/test/java/org/apache/parquet/column/mem/TestMemColumn.java": 71,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ParquetOutputFormat.java": 15,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ParquetWriter.java": 11
            },
            "is_test": true,
            "is_fix": false
        },
        "b6fd45ee08e08b490c35825953b51cfd8fb1b072": {
            "datetime": "2018-11-07T11:19:10+01:00",
            "summary": "PARQUET-1305: Backward incompatible change introduced in 1.8 (#483)",
            "message": "PARQUET-1305: Backward incompatible change introduced in 1.8 (#483)\n\n",
            "diff": {
                "parquet-thrift/src/main/java/org/apache/parquet/thrift/struct/ThriftType.java": 8,
                "parquet-thrift/src/test/java/org/apache/parquet/thrift/TestThriftSchemaConverter.java": 30,
                "parquet-thrift/src/test/java/org/apache/parquet/thrift/struct/TestThriftType.java": 10
            },
            "is_test": true,
            "is_fix": true
        },
        "ca294f94a9908d25174648cd1c325a994af6a56d": {
            "datetime": "2018-11-07T12:31:43+01:00",
            "summary": "PARQUET-1452: Deprecate old logical types API (#535)",
            "message": "PARQUET-1452: Deprecate old logical types API (#535)\n\n",
            "diff": {
                "parquet-column/src/main/java/org/apache/parquet/internal/column/columnindex/BinaryTruncator.java": 37,
                "parquet-column/src/main/java/org/apache/parquet/schema/DecimalMetadata.java": 11,
                "parquet-column/src/main/java/org/apache/parquet/schema/LogicalTypeAnnotation.java": 16,
                "parquet-column/src/main/java/org/apache/parquet/schema/OriginalType.java": 4,
                "parquet-column/src/main/java/org/apache/parquet/schema/PrimitiveType.java": 1
            },
            "is_test": false,
            "is_fix": false
        },
        "7f561b6053e6808b5b2c2482d1aa61c22c7a90cc": {
            "datetime": "2018-11-08T09:23:32-08:00",
            "summary": "PARQUET-1414: Simplify next row count check calculation (#537)",
            "message": "PARQUET-1414: Simplify next row count check calculation (#537)\n\n",
            "diff": {
                "parquet-column/src/main/java/org/apache/parquet/column/impl/ColumnWriteStoreBase.java": 2
            },
            "is_test": false,
            "is_fix": false
        },
        "3201bd1915bc6adee45fec59e5eb58cde3793e32": {
            "datetime": "2018-11-12T11:13:31+01:00",
            "summary": "PARQUET-1435: Benchmark filtering column-indexes (#536)",
            "message": "PARQUET-1435: Benchmark filtering column-indexes (#536)\n\n",
            "diff": {
                "parquet-benchmarks/src/main/java/org/apache/parquet/benchmarks/FilteringBenchmarks.java": 430
            },
            "is_test": false,
            "is_fix": false
        },
        "a69f2b30cd3c581588977ea4c93a53989e9c031c": {
            "datetime": "2018-11-19T13:15:39+01:00",
            "summary": "PARQUET-1365: Don't write page level statistics (#549)",
            "message": "PARQUET-1365: Don't write page level statistics (#549)\n\nPage level statistics were never used in production and became pointless after adding column indexes.",
            "diff": {
                "parquet-hadoop/src/main/java/org/apache/parquet/format/converter/ParquetMetadataConverter.java": 47,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ColumnChunkPageWriteStore.java": 4,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ParquetFileWriter.java": 5,
                "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/TestColumnChunkPageWriteStore.java": 1
            },
            "is_test": true,
            "is_fix": false
        },
        "5250dac71600d42edfa324786593a7d56135aa26": {
            "datetime": "2018-11-19T13:18:28+01:00",
            "summary": "PARQUET-1456: Use page index, ParquetFileReader throw ArrayIndexOutOfBoundsException (#548)",
            "message": "PARQUET-1456: Use page index, ParquetFileReader throw ArrayIndexOutOfBoundsException (#548)\n\nThe usage of static caching in the page index implementation did not allow using multiple readers at the same time.",
            "diff": {
                "parquet-column/src/main/java/org/apache/parquet/internal/column/columnindex/ColumnIndexBuilder.java": 14,
                "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/TestMultipleWriteRead.java": 250
            },
            "is_test": true,
            "is_fix": true
        },
        "542ab3e2b321d5f755f3e9c6b997a458f8cf0f5e": {
            "datetime": "2018-11-19T14:07:55-08:00",
            "summary": "PARQUET-1407: Avro: Fix binary values returned from dictionary encoding (#552)",
            "message": "PARQUET-1407: Avro: Fix binary values returned from dictionary encoding (#552)\n\n* PARQUET-1407: Add test case for PARQUET-1407 to demonstrate the issue\r\n* PARQUET-1407: Fix binary values from dictionary encoding.\r\n\r\nCloses #551.",
            "diff": {
                "parquet-avro/src/main/java/org/apache/parquet/avro/AvroConverters.java": 11,
                "parquet-avro/src/test/java/org/apache/parquet/avro/TestReadWrite.java": 84
            },
            "is_test": true,
            "is_fix": true
        },
        "a7b5a4b24a3e17edce9273a0654e799075c86dbe": {
            "datetime": "2018-11-21T17:12:00+01:00",
            "summary": "PARQUET-1460: Fix javadoc errors and include javadoc checking in Travis checks (#554)",
            "message": "PARQUET-1460: Fix javadoc errors and include javadoc checking in Travis checks (#554)\n\n",
            "diff": {
                "parquet-benchmarks/src/main/java/org/apache/parquet/benchmarks/FilteringBenchmarks.java": 2,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ParquetFileReader.java": 4
            },
            "is_test": false,
            "is_fix": false
        },
        "97a880cfc4fc3c2c74ff1302bc6e4aab1582b6df": {
            "datetime": "2018-11-21T17:13:46+01:00",
            "summary": "Experiment.",
            "message": "Experiment.\n",
            "diff": {
                "parquet-benchmarks/src/main/java/org/apache/parquet/benchmarks/WriteBenchmarks.java": 16,
                "parquet-benchmarks/src/main/java/org/apache/parquet/benchmarks/WriteBenchmarksParquet1.java": 159,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/InternalParquetRecordWriter.java": 2
            },
            "is_test": false,
            "is_fix": false
        },
        "4d9a2fd01f33858bd5eb392a5f7bd0967fbec3f8": {
            "datetime": "2018-11-21T18:27:42+01:00",
            "summary": "Revert \"Experiment.\"",
            "message": "Revert \"Experiment.\"\n\nThis reverts commit 97a880cfc4fc3c2c74ff1302bc6e4aab1582b6df.\n",
            "diff": {
                "parquet-benchmarks/src/main/java/org/apache/parquet/benchmarks/WriteBenchmarks.java": 16,
                "parquet-benchmarks/src/main/java/org/apache/parquet/benchmarks/WriteBenchmarksParquet1.java": 159,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/InternalParquetRecordWriter.java": 2
            },
            "is_test": false,
            "is_fix": false
        },
        "44c167ead46fe430c9e21871c4c7f993153a88cb": {
            "datetime": "2018-11-23T12:59:50+01:00",
            "summary": "PARQUET-1461: Third party code does not compile after parquet-mr minor version update (#556)",
            "message": "PARQUET-1461: Third party code does not compile after parquet-mr minor version update (#556)\n\n",
            "diff": {
                "parquet-column/src/main/java/org/apache/parquet/column/values/ValuesReader.java": 12,
                "parquet-column/src/test/java/org/apache/parquet/column/values/TestValuesReaderImpl.java": 150
            },
            "is_test": true,
            "is_fix": true
        },
        "63b45f7244f0dcf1a05c94a30a7f860973e307d2": {
            "datetime": "2018-12-13T14:37:41+01:00",
            "summary": "PARQUET-1472: Dictionary filter fails on FIXED_LEN_BYTE_ARRAY (#562)",
            "message": "PARQUET-1472: Dictionary filter fails on FIXED_LEN_BYTE_ARRAY (#562)\n\n",
            "diff": {
                "parquet-hadoop/src/main/java/org/apache/parquet/filter2/dictionarylevel/DictionaryFilter.java": 53,
                "parquet-hadoop/src/test/java/org/apache/parquet/filter2/dictionarylevel/DictionaryFilterTest.java": 177
            },
            "is_test": true,
            "is_fix": true
        },
        "94555e1f1dcd91bf371fd44dff8494385b699e09": {
            "datetime": "2018-12-13T16:58:07+01:00",
            "summary": "PARQUET-1474: Less verbose and lower level logging for missing column/offset indexes (#563)",
            "message": "PARQUET-1474: Less verbose and lower level logging for missing column/offset indexes (#563)\n\n",
            "diff": {
                "parquet-column/src/main/java/org/apache/parquet/internal/filter2/columnindex/ColumnIndexFilter.java": 4
            },
            "is_test": false,
            "is_fix": false
        },
        "3cb529cc23289a302588cf840825953e1aa1e618": {
            "datetime": "2018-12-13T18:28:11+01:00",
            "summary": "PARQUET-1476: Don't emit a warning message for files without new logical type (#577)",
            "message": "PARQUET-1476: Don't emit a warning message for files without new logical type (#577)\n\n",
            "diff": {
                "parquet-hadoop/src/main/java/org/apache/parquet/format/converter/ParquetMetadataConverter.java": 6
            },
            "is_test": false,
            "is_fix": false
        },
        "58edbd78ca93b360daee791376e4b1bcf01c5f61": {
            "datetime": "2019-01-07T16:46:06+01:00",
            "summary": "PARQUET-1478: Can't read spec compliant, 3-level lists via parquet-proto (#578)",
            "message": "PARQUET-1478: Can't read spec compliant, 3-level lists via parquet-proto (#578)\n\n",
            "diff": {
                "parquet-protobuf/src/main/java/org/apache/parquet/proto/ProtoMessageConverter.java": 2,
                "parquet-protobuf/src/test/java/org/apache/parquet/proto/ProtoInputOutputFormatTest.java": 4,
                "parquet-protobuf/src/test/java/org/apache/parquet/proto/utils/ReadUsingMR.java": 19,
                "parquet-protobuf/src/test/java/org/apache/parquet/proto/utils/WriteUsingMR.java": 9
            },
            "is_test": true,
            "is_fix": true
        },
        "514083f43f5dffbc7ff8393b808f165c01c3a28a": {
            "datetime": "2019-01-09T13:40:01+01:00",
            "summary": "PARQUET-1489: Insufficient documentation for UserDefinedPredicate.keep(T) (#588)",
            "message": "PARQUET-1489: Insufficient documentation for UserDefinedPredicate.keep(T) (#588)\n\n",
            "diff": {
                "parquet-column/src/main/java/org/apache/parquet/filter2/predicate/UserDefinedPredicate.java": 5
            },
            "is_test": false,
            "is_fix": false
        },
        "797e32aca0eadd1d460e5f5cd477e37bc828b67d": {
            "datetime": "2019-01-09T13:42:00+01:00",
            "summary": "PARQUET-1487: Do not write original type for timezone-agnostic timestamps (#585)",
            "message": "PARQUET-1487: Do not write original type for timezone-agnostic timestamps (#585)\n\n\r\n",
            "diff": {
                "parquet-column/src/main/java/org/apache/parquet/schema/LogicalTypeAnnotation.java": 6,
                "parquet-hadoop/src/main/java/org/apache/parquet/format/converter/ParquetMetadataConverter.java": 6,
                "parquet-hadoop/src/test/java/org/apache/parquet/format/converter/TestParquetMetadataConverter.java": 80
            },
            "is_test": true,
            "is_fix": false
        },
        "87646359966f9708b040e97e228af4ef8c32a151": {
            "datetime": "2019-01-14T13:41:32+01:00",
            "summary": "PARQUET-1466: Upgrade to the latest guava 27.0-jre (#559)",
            "message": "PARQUET-1466: Upgrade to the latest guava 27.0-jre (#559)\n\n\r\n",
            "diff": {
                "parquet-cli/src/main/java/org/apache/parquet/cli/util/Expressions.java": 4
            },
            "is_test": false,
            "is_fix": false
        },
        "794d55ee2e7e874a9d387c8df05003bd01e98baf": {
            "datetime": "2019-01-14T15:33:51+01:00",
            "summary": "PARQUET-1475: Fix lack of cause propagation in DirectCodecFactory.ParquetCompressionCodecException. (#564)",
            "message": "PARQUET-1475: Fix lack of cause propagation in DirectCodecFactory.ParquetCompressionCodecException. (#564)\n\n",
            "diff": {
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/DirectCodecFactory.java": 2
            },
            "is_test": false,
            "is_fix": false
        },
        "4b40d96a13f3e9bf75f8b2aaa0bef901491f2789": {
            "datetime": "2019-01-23T16:45:55+01:00",
            "summary": "PARQUET-1502: Convert FIXED_LEN_BYTE_ARRAY to arrow type in logicalTypeAnnotation if it is not null (#593)",
            "message": "PARQUET-1502: Convert FIXED_LEN_BYTE_ARRAY to arrow type in logicalTypeAnnotation if it is not null (#593)\n\n",
            "diff": {
                "parquet-arrow/src/main/java/org/apache/parquet/arrow/schema/SchemaConverter.java": 12,
                "parquet-arrow/src/test/java/org/apache/parquet/arrow/schema/TestSchemaConverter.java": 20
            },
            "is_test": true,
            "is_fix": false
        },
        "f36dd08505b5dc799d2e4e92328901796f7b3cb8": {
            "datetime": "2019-01-25T09:07:48+01:00",
            "summary": "[PARQUET-1500] Replace Closeables with try-with-resources (#597)",
            "message": "[PARQUET-1500] Replace Closeables with try-with-resources (#597)\n\n",
            "diff": {
                "parquet-common/src/main/java/org/apache/parquet/Closeables.java": 8,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/util/SerializationUtil.java": 46
            },
            "is_test": false,
            "is_fix": false
        },
        "1e62e2e2ca903d4109480bc87ceec1dc954b6c92": {
            "datetime": "2019-01-25T09:21:15+01:00",
            "summary": "PARQUET-1503: Remove Ints Utility Class (#598)",
            "message": "PARQUET-1503: Remove Ints Utility Class (#598)\n\n",
            "diff": {
                "parquet-column/src/main/java/org/apache/parquet/column/impl/ColumnWriterV2.java": 3,
                "parquet-column/src/main/java/org/apache/parquet/column/page/DataPageV1.java": 5,
                "parquet-column/src/main/java/org/apache/parquet/column/page/DataPageV2.java": 9,
                "parquet-column/src/main/java/org/apache/parquet/column/page/DictionaryPage.java": 3,
                "parquet-column/src/main/java/org/apache/parquet/column/values/rle/RunLengthBitPackingHybridValuesWriter.java": 3,
                "parquet-common/src/main/java/org/apache/parquet/Ints.java": 2,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ColumnChunkPageReadStore.java": 7
            },
            "is_test": false,
            "is_fix": false
        },
        "d1e9f15d1e94956f38880fec2cf9491b8f9711e4": {
            "datetime": "2019-01-27T11:38:02-08:00",
            "summary": "PARQUET-1513: Update HiddenFileFilter to avoid extra startsWith (#606)",
            "message": "PARQUET-1513: Update HiddenFileFilter to avoid extra startsWith (#606)\n\n",
            "diff": {
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/util/HiddenFileFilter.java": 8
            },
            "is_test": false,
            "is_fix": false
        },
        "00a7a470dbf73d6ae3bdd0774706abcda353b178": {
            "datetime": "2019-01-27T21:25:53+01:00",
            "summary": "PARQUET-1504: Add an option to convert Int96 to Arrow Timestamp (#594)",
            "message": "PARQUET-1504: Add an option to convert Int96 to Arrow Timestamp (#594)\n\nPARQUET-1504: Add an option to convert Parquet Int96 to Arrow Timestamp",
            "diff": {
                "parquet-arrow/src/main/java/org/apache/parquet/arrow/schema/SchemaConverter.java": 16,
                "parquet-arrow/src/test/java/org/apache/parquet/arrow/schema/TestSchemaConverter.java": 22
            },
            "is_test": true,
            "is_fix": false
        }
    },
    "2019-01-27T15:17:05-07:00": {
        "d9a19621370608f4431394cc36bddc063d59cc5a": {
            "datetime": "2019-01-28T08:50:52-08:00",
            "summary": "PARQUET-1510: Fix notEq for optional columns with null values. (#603)",
            "message": "PARQUET-1510: Fix notEq for optional columns with null values. (#603)\n\nDictionaries cannot contain null values, so notEq filters cannot\r\nconclude that a block cannot match using only the dictionary. Instead,\r\nit must also check whether the block may have at least one null value.\r\nIf there are no null values, then the existing check is correct.",
            "diff": {
                "parquet-hadoop/src/main/java/org/apache/parquet/filter2/dictionarylevel/DictionaryFilter.java": 5,
                "parquet-hadoop/src/test/java/org/apache/parquet/filter2/dictionarylevel/DictionaryFilterTest.java": 17
            },
            "is_test": true,
            "is_fix": true
        },
        "51c4cc30f5df1f070a211cfed652aefdc096de69": {
            "datetime": "2019-02-01T10:49:32-08:00",
            "summary": "PARQUET-138: Allow merging more restrictive field in less restrictive field (#550)",
            "message": "PARQUET-138: Allow merging more restrictive field in less restrictive field (#550)\n\n* Allow merging more restrictive field in less restrictive field\r\n* Make class and function names more explicit\r\n",
            "diff": {
                "parquet-column/src/main/java/org/apache/parquet/schema/GroupType.java": 3,
                "parquet-column/src/main/java/org/apache/parquet/schema/PrimitiveType.java": 3,
                "parquet-column/src/main/java/org/apache/parquet/schema/Type.java": 23,
                "parquet-column/src/test/java/org/apache/parquet/schema/TestMessageType.java": 17,
                "parquet-column/src/test/java/org/apache/parquet/schema/TestRepetitionType.java": 36
            },
            "is_test": true,
            "is_fix": true
        },
        "82935e6da8c9f2801d77afba998d3de622e3e7f3": {
            "datetime": "2019-02-06T09:51:50+01:00",
            "summary": "PARQUET-1470: Inputstream leakage in ParquetFileWriter.appendFile (#611)",
            "message": "PARQUET-1470: Inputstream leakage in ParquetFileWriter.appendFile (#611)\n\n",
            "diff": {
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ParquetFileWriter.java": 4
            },
            "is_test": false,
            "is_fix": false
        },
        "5bd126557cdbfccef9d0b282230cdd671c003c4f": {
            "datetime": "2019-02-06T10:20:59+01:00",
            "summary": "PARQUET-1514: ParquetFileWriter Records Compressed Bytes instead of Uncompressed Bytes (#607)",
            "message": "PARQUET-1514: ParquetFileWriter Records Compressed Bytes instead of Uncompressed Bytes (#607)\n\n",
            "diff": {
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ParquetFileWriter.java": 6
            },
            "is_test": false,
            "is_fix": false
        },
        "714bb450856dc951bd361e0cf4a732775eb3cefd": {
            "datetime": "2019-02-07T13:26:47+01:00",
            "summary": "PARQUET-1505: Use Java 7 NIO StandardCharsets (#599)",
            "message": "PARQUET-1505: Use Java 7 NIO StandardCharsets (#599)\n\n",
            "diff": {
                "parquet-avro/src/test/java/org/apache/parquet/avro/TestReadWrite.java": 10,
                "parquet-avro/src/test/java/org/apache/parquet/avro/TestReadWriteOldListBehavior.java": 12,
                "parquet-cli/src/main/java/org/apache/parquet/cli/BaseCommand.java": 8,
                "parquet-column/src/main/java/org/apache/parquet/io/api/Binary.java": 30,
                "parquet-column/src/test/java/org/apache/parquet/column/values/dictionary/TestDictionary.java": 7,
                "parquet-common/src/main/java/org/apache/parquet/bytes/BytesUtils.java": 3,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ParquetFileWriter.java": 4
            },
            "is_test": true,
            "is_fix": false
        },
        "6901a2040848c6b37fa61f4b0a76246445f396db": {
            "datetime": "2019-02-07T13:31:39+01:00",
            "summary": "PARQUET-1480 INT96 to avro not yet implemented error should mention deprecation (#579)",
            "message": "PARQUET-1480 INT96 to avro not yet implemented error should mention deprecation (#579)\n\n",
            "diff": {
                "parquet-avro/src/main/java/org/apache/parquet/avro/AvroSchemaConverter.java": 2
            },
            "is_test": false,
            "is_fix": false
        },
        "7dcdcdcf0eb5e91618c443d4a84973bf7883d79b": {
            "datetime": "2019-02-12T11:33:17+01:00",
            "summary": "PARQUET-1485: Fix Snappy direct memory leak (#581)",
            "message": "PARQUET-1485: Fix Snappy direct memory leak (#581)\n\n",
            "diff": {
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/codec/CleanUtil.java": 70,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/codec/SnappyCompressor.java": 27,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/codec/SnappyDecompressor.java": 31
            },
            "is_test": false,
            "is_fix": false
        },
        "9461845576fd762e6a9b8d17c551f38c351b017d": {
            "datetime": "2019-02-12T13:04:38+01:00",
            "summary": "PARQUET-1527:  [parquet-tools] cat command throw java.lang.ClassCastException (#612)",
            "message": "PARQUET-1527:  [parquet-tools] cat command throw java.lang.ClassCastException (#612)\n\n",
            "diff": {
                "parquet-tools/src/main/java/org/apache/parquet/tools/read/SimpleRecordConverter.java": 1,
                "parquet-tools/src/test/java/org/apache/parquet/tools/read/TestSimpleRecordConverter.java": 139
            },
            "is_test": true,
            "is_fix": true
        },
        "f7998934020ea6f4949e347616431219343d8a15": {
            "datetime": "2019-02-25T13:23:32+01:00",
            "summary": "PARQUET-1533: TestSnappy() throws OOM exception with Parquet-1485 change (#622)",
            "message": "PARQUET-1533: TestSnappy() throws OOM exception with Parquet-1485 change (#622)\n\n\r\n",
            "diff": {
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/codec/SnappyCompressor.java": 26,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/codec/SnappyDecompressor.java": 26
            },
            "is_test": false,
            "is_fix": false
        },
        "ab42fe5180366120336fb3f8b9e6540aadb5da1b": {
            "datetime": "2019-02-25T13:42:46+01:00",
            "summary": "Revert \"PARQUET-1381: Add merge blocks command to parquet-tools (#512)\" (#621)",
            "message": "Revert \"PARQUET-1381: Add merge blocks command to parquet-tools (#512)\" (#621)\n\nThis reverts commit 863a081850e56bbbb38d7b68b478a3bd40779723.\r\n\r\nThe design of this feature has conceptional problems and also works incorrectly. See PARQUET-1381 for more details.",
            "diff": {
                "parquet-column/src/main/java/org/apache/parquet/column/impl/ColumnReadStoreImpl.java": 2,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ColumnChunkPageWriteStore.java": 5,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ParquetFileReader.java": 92,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ParquetFileWriter.java": 123,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/util/BlocksCombiner.java": 106,
                "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/TestParquetWriterMergeBlocks.java": 280,
                "parquet-tools/src/main/java/org/apache/parquet/tools/command/MergeCommand.java": 75
            },
            "is_test": true,
            "is_fix": false
        },
        "892dedb23591bb4e38a061d5ea607637fd4e210f": {
            "datetime": "2019-03-13T08:25:56+01:00",
            "summary": "PARQUET-1531: Page row count limit causes empty pages to be written from MessageColumnIO (#620)",
            "message": "PARQUET-1531: Page row count limit causes empty pages to be written from MessageColumnIO (#620)\n\n\r\n",
            "diff": {
                "parquet-benchmarks/src/main/java/org/apache/parquet/benchmarks/NestedNullWritingBenchmarks.java": 151,
                "parquet-column/src/main/java/org/apache/parquet/column/ColumnWriteStore.java": 12,
                "parquet-column/src/main/java/org/apache/parquet/column/impl/ColumnWriteStoreBase.java": 5,
                "parquet-column/src/main/java/org/apache/parquet/column/impl/ColumnWriterBase.java": 3,
                "parquet-column/src/main/java/org/apache/parquet/io/MessageColumnIO.java": 7,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/example/ExampleParquetWriter.java": 16,
                "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/TestParquetWriter.java": 43
            },
            "is_test": true,
            "is_fix": true
        },
        "62dcc68acaf64012bf731e103be780956f1f446d": {
            "datetime": "2019-04-17T14:57:49+02:00",
            "summary": "PARQUET-1557: Replace deprecated Apache Avro methods (#633)",
            "message": "PARQUET-1557: Replace deprecated Apache Avro methods (#633)\n\n",
            "diff": {
                "parquet-avro/src/main/java/org/apache/parquet/avro/AvroIndexedRecordConverter.java": 2,
                "parquet-avro/src/main/java/org/apache/parquet/avro/AvroRecordConverter.java": 2,
                "parquet-avro/src/test/java/org/apache/parquet/avro/TestReflectInputOutputFormat.java": 4,
                "parquet-avro/src/test/java/org/apache/parquet/avro/TestSpecificInputOutputFormat.java": 4,
                "parquet-avro/src/test/java/org/apache/parquet/avro/TestSpecificReadWrite.java": 2
            },
            "is_test": true,
            "is_fix": false
        },
        "12f3fd2c3e8349f54ffc8814f083c8b001701f25": {
            "datetime": "2019-05-01T16:14:19+02:00",
            "summary": "PARQUET-1558: Use try-with-resource in Apache Avro tests (#634)",
            "message": "PARQUET-1558: Use try-with-resource in Apache Avro tests (#634)\n\nWe can use the try-with-resource pattern to implicitly close the\r\nresources such as readers and writers, provided by Avro and Parquet",
            "diff": {
                "parquet-avro/src/test/java/org/apache/parquet/avro/TestInputOutputFormat.java": 20,
                "parquet-avro/src/test/java/org/apache/parquet/avro/TestReadWrite.java": 247,
                "parquet-avro/src/test/java/org/apache/parquet/avro/TestReadWriteOldListBehavior.java": 133,
                "parquet-avro/src/test/java/org/apache/parquet/avro/TestReflectInputOutputFormat.java": 76,
                "parquet-avro/src/test/java/org/apache/parquet/avro/TestReflectReadWrite.java": 38,
                "parquet-avro/src/test/java/org/apache/parquet/avro/TestSpecificInputOutputFormat.java": 76,
                "parquet-avro/src/test/java/org/apache/parquet/avro/TestSpecificReadWrite.java": 153,
                "parquet-avro/src/test/java/org/apache/parquet/avro/TestStringBehavior.java": 77
            },
            "is_test": true,
            "is_fix": false
        },
        "2c257f055f0ef30b2a200a7a2e471425534a7010": {
            "datetime": "2019-05-09T08:21:24+02:00",
            "summary": "PARQUET-1557: Replace deprecated Apache Avro methods (#636)",
            "message": "PARQUET-1557: Replace deprecated Apache Avro methods (#636)\n\nSome methods are deprecated in Avro 1.8.2 and are being removed in Avro 1.9.0. This commit removes references to these methods from Parquet.",
            "diff": {
                "parquet-cli/src/main/java/org/apache/parquet/cli/json/AvroJson.java": 2,
                "parquet-cli/src/main/java/org/apache/parquet/cli/util/Schemas.java": 8
            },
            "is_test": false,
            "is_fix": false
        },
        "96a01489e0eba6304d1b029ec715a6d20b9d3308": {
            "datetime": "2019-05-27T13:32:23+02:00",
            "summary": "PARQUET-1577 Remove duplicate license (#640)",
            "message": "PARQUET-1577 Remove duplicate license (#640)\n\n",
            "diff": {
                "parquet-avro/src/test/java/org/apache/parquet/avro/TestGenericLogicalTypes.java": 18
            },
            "is_test": true,
            "is_fix": false
        },
        "c3e1a849d02042b324e4f72e1e4bba6c2a8da5bc": {
            "datetime": "2019-05-27T13:59:52+02:00",
            "summary": "PARQUET-1536: [parquet-cli] Add simple tests for each command (#625)",
            "message": "PARQUET-1536: [parquet-cli] Add simple tests for each command (#625)\n\nCurrently, parquet-cli has no tests. At first, adding simple tests for each command.",
            "diff": {
                "parquet-cli/src/test/java/org/apache/parquet/cli/commands/AvroFileTest.java": 39,
                "parquet-cli/src/test/java/org/apache/parquet/cli/commands/CSVFileTest.java": 51,
                "parquet-cli/src/test/java/org/apache/parquet/cli/commands/CSVSchemaCommandTest.java": 39,
                "parquet-cli/src/test/java/org/apache/parquet/cli/commands/CatCommandTest.java": 38,
                "parquet-cli/src/test/java/org/apache/parquet/cli/commands/CheckParquet251CommandTest.java": 38,
                "parquet-cli/src/test/java/org/apache/parquet/cli/commands/ConvertCSVCommandTest.java": 41,
                "parquet-cli/src/test/java/org/apache/parquet/cli/commands/ConvertCommandTest.java": 41,
                "parquet-cli/src/test/java/org/apache/parquet/cli/commands/FileTest.java": 57,
                "parquet-cli/src/test/java/org/apache/parquet/cli/commands/ParquetFileTest.java": 101,
                "parquet-cli/src/test/java/org/apache/parquet/cli/commands/ParquetMetadataCommandTest.java": 38,
                "parquet-cli/src/test/java/org/apache/parquet/cli/commands/SchemaCommandTest.java": 38,
                "parquet-cli/src/test/java/org/apache/parquet/cli/commands/ShowColumnIndexTest.java": 38,
                "parquet-cli/src/test/java/org/apache/parquet/cli/commands/ShowDictionaryCommandTest.java": 39,
                "parquet-cli/src/test/java/org/apache/parquet/cli/commands/ShowPagesCommandTest.java": 38,
                "parquet-cli/src/test/java/org/apache/parquet/cli/commands/ToAvroCommandTest.java": 33
            },
            "is_test": true,
            "is_fix": false
        },
        "f1a719b264cec72e17db463aaa413d3871d068a6": {
            "datetime": "2019-05-27T16:22:31+02:00",
            "summary": "PARQUET-1534:  [parquet-cli] IllegalArgumentException on Windows (#627)",
            "message": "PARQUET-1534:  [parquet-cli] IllegalArgumentException on Windows (#627)\n\nCalling BaseCommand#qualifiedURI with Windows file path, java.net.URI.create throws IllegalArgumentException and the command execution is aborted.",
            "diff": {
                "parquet-cli/src/main/java/org/apache/parquet/cli/BaseCommand.java": 15,
                "parquet-cli/src/test/java/org/apache/parquet/cli/BaseCommandTest.java": 100
            },
            "is_test": true,
            "is_fix": true
        },
        "1e5fda5310687b0856e74f00a4ea420b6b1ab34d": {
            "datetime": "2019-05-28T14:53:02+02:00",
            "summary": "PARQUET-1441: SchemaParseException: Can't redefine: list in AvroIndexedRecordConverter (#560)",
            "message": "PARQUET-1441: SchemaParseException: Can't redefine: list in AvroIndexedRecordConverter (#560)\n\nParquet Avro reader couldn't convert a schema where a group field name is reused\r\nin an inner structure. The converter created an Avro record schema in this case,\r\nbut in Avro record types should have a unique name, therefore the result was an invalid Avro\r\nschema. This patch fixes this case by adding a namespace for the record if the name was\r\ndefined before, this way making the record names unique.",
            "diff": {
                "parquet-avro/src/main/java/org/apache/parquet/avro/AvroSchemaConverter.java": 27,
                "parquet-avro/src/test/java/org/apache/parquet/avro/AvroTestUtil.java": 8,
                "parquet-avro/src/test/java/org/apache/parquet/avro/TestAvroSchemaConverter.java": 63,
                "parquet-avro/src/test/java/org/apache/parquet/avro/TestReadWrite.java": 40
            },
            "is_test": true,
            "is_fix": true
        },
        "54777b46da768df3ff88548c6b6b70bd52fba0dd": {
            "datetime": "2019-05-30T14:11:58+02:00",
            "summary": "PARQUET-1556 Use try-with-resource in Apache Avro tests (#639)",
            "message": "PARQUET-1556 Use try-with-resource in Apache Avro tests (#639)\n\n",
            "diff": {
                "parquet-avro/src/test/java/org/apache/parquet/avro/AvroTestUtil.java": 26,
                "parquet-avro/src/test/java/org/apache/parquet/avro/TestArrayCompatibility.java": 9,
                "parquet-avro/src/test/java/org/apache/parquet/avro/TestReadWrite.java": 127,
                "parquet-avro/src/test/java/org/apache/parquet/avro/TestReadWriteOldListBehavior.java": 128
            },
            "is_test": true,
            "is_fix": false
        },
        "9d6fb45e54da65cbd407bb3e7bff0981aa9f8f9f": {
            "datetime": "2019-05-30T14:12:24+02:00",
            "summary": "PARQUET-1576 Bump Apache Avro to 1.9.0 (#638)",
            "message": "PARQUET-1576 Bump Apache Avro to 1.9.0 (#638)\n\n",
            "diff": {
                "parquet-avro/src/test/java/org/apache/parquet/avro/AvroTestUtil.java": 5,
                "parquet-avro/src/test/java/org/apache/parquet/avro/TestAvroSchemaConverter.java": 22,
                "parquet-avro/src/test/java/org/apache/parquet/avro/TestReflectLogicalTypes.java": 7,
                "parquet-avro/src/test/java/org/apache/parquet/avro/TestSpecificReadWrite.java": 32
            },
            "is_test": true,
            "is_fix": false
        },
        "47398be76cfb6634000532e9432430c4676442dd": {
            "datetime": "2019-06-03T16:40:06+02:00",
            "summary": "PARQUET-1375: Upgrade to Jackson 2.9.9 (#616)",
            "message": "PARQUET-1375: Upgrade to Jackson 2.9.9 (#616)\n\n",
            "diff": {
                "parquet-cli/src/main/java/org/apache/parquet/cli/json/AvroJson.java": 13,
                "parquet-cli/src/main/java/org/apache/parquet/cli/json/AvroJsonReader.java": 22,
                "parquet-cli/src/main/java/org/apache/parquet/cli/util/Schemas.java": 2,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/metadata/ParquetMetadata.java": 13,
                "parquet-pig/src/main/java/org/apache/parquet/pig/summary/StringSummaryData.java": 10,
                "parquet-pig/src/main/java/org/apache/parquet/pig/summary/Summary.java": 4,
                "parquet-pig/src/main/java/org/apache/parquet/pig/summary/SummaryData.java": 16,
                "parquet-pig/src/test/java/org/apache/parquet/pig/summary/TestSummary.java": 4,
                "parquet-thrift/src/main/java/org/apache/parquet/thrift/struct/CompatibilityRunner.java": 2,
                "parquet-thrift/src/main/java/org/apache/parquet/thrift/struct/JSON.java": 11,
                "parquet-thrift/src/main/java/org/apache/parquet/thrift/struct/ThriftField.java": 4,
                "parquet-thrift/src/main/java/org/apache/parquet/thrift/struct/ThriftType.java": 15,
                "parquet-tools/src/main/java/org/apache/parquet/tools/json/JsonRecordFormatter.java": 2,
                "parquet-tools/src/main/java/org/apache/parquet/tools/read/SimpleMapRecord.java": 2,
                "parquet-tools/src/main/java/org/apache/parquet/tools/read/SimpleRecord.java": 4,
                "parquet-tools/src/test/java/org/apache/parquet/tools/read/TestJsonRecordFormatter.java": 2
            },
            "is_test": true,
            "is_fix": false
        },
        "0b909ab3ed9fd9411092de359d4217aa6c9abc21": {
            "datetime": "2019-07-04T10:55:34+02:00",
            "summary": "PARQUET-1550: CleanUtil does not work in Java 11 (#654)",
            "message": "PARQUET-1550: CleanUtil does not work in Java 11 (#654)\n\nCleanUtil does not work in Java 11",
            "diff": {
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/codec/CleanUtil.java": 98,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/codec/SnappyCompressor.java": 8,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/codec/SnappyDecompressor.java": 12
            },
            "is_test": false,
            "is_fix": false
        },
        "8ff867a2e183f50b7b2f2c6e51d07c5314577ce0": {
            "datetime": "2019-07-09T10:27:48+02:00",
            "summary": "PARQUET-1615: getRecordWriter shouldn't hardcode CREAT mode when new ParquetFileWriter (#660)",
            "message": "PARQUET-1615: getRecordWriter shouldn't hardcode CREAT mode when new ParquetFileWriter (#660)\n\n",
            "diff": {
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ParquetOutputFormat.java": 21
            },
            "is_test": false,
            "is_fix": false
        },
        "b34b077486473c46ff5199421c79cd2e797e5817": {
            "datetime": "2019-07-17T15:14:13+02:00",
            "summary": "PARQUET-1488: UserDefinedPredicate throw NPE (#663)",
            "message": "PARQUET-1488: UserDefinedPredicate throw NPE (#663)\n\n\r\n",
            "diff": {
                "parquet-column/src/main/java/org/apache/parquet/filter2/predicate/UserDefinedPredicate.java": 15,
                "parquet-column/src/main/java/org/apache/parquet/internal/column/columnindex/ColumnIndexBuilder.java": 4,
                "parquet-column/src/main/java/org/apache/parquet/internal/filter2/columnindex/ColumnIndexFilter.java": 4,
                "parquet-generator/src/main/java/org/apache/parquet/filter2/IncrementallyUpdatedFilterPredicateGenerator.java": 2,
                "parquet-hadoop/src/main/java/org/apache/parquet/filter2/dictionarylevel/DictionaryFilter.java": 4,
                "parquet-hadoop/src/main/java/org/apache/parquet/filter2/statisticslevel/StatisticsFilter.java": 8,
                "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/TestColumnIndexFiltering.java": 4
            },
            "is_test": true,
            "is_fix": true
        },
        "fcc5d1a5a669570de3daeafd3f3b7788aa618536": {
            "datetime": "2019-07-24T08:35:21+02:00",
            "summary": "PARQUET-1580: Page-level CRC checksum verfication for DataPageV1 (#647)",
            "message": "PARQUET-1580: Page-level CRC checksum verfication for DataPageV1 (#647)\n\n* Page-level checksums for DataPageV1\r\n\r\n* Got rid of redundant constant\r\n\r\n* Use more direct way of obtaining defaults\r\n\r\n* Revised implementation, updated tests, addressed review comments\r\n\r\n* Revert auto whitespace trimming\r\n\r\n* Variable rename for consistency\r\n\r\n* Revert whitespace changes\r\n\r\n* Revert more whitespace changes\r\n\r\n* Addressed code review comments\r\n\r\n* Enable writing out checksums by default\r\n\r\n* Added benchmarks\r\n\r\n* Addressed review comments\r\n\r\n* Addressed test failures\r\n\r\n* Added run script for checksum benchmarks\r\n\r\n* Addressed code review comments\r\n",
            "diff": {
                "parquet-benchmarks/src/main/java/org/apache/parquet/benchmarks/BenchmarkFiles.java": 22,
                "parquet-benchmarks/src/main/java/org/apache/parquet/benchmarks/PageChecksumDataGenerator.java": 127,
                "parquet-benchmarks/src/main/java/org/apache/parquet/benchmarks/PageChecksumReadBenchmarks.java": 179,
                "parquet-benchmarks/src/main/java/org/apache/parquet/benchmarks/PageChecksumWriteBenchmarks.java": 160,
                "parquet-column/src/main/java/org/apache/parquet/column/ParquetProperties.java": 21,
                "parquet-column/src/main/java/org/apache/parquet/column/page/Page.java": 16,
                "parquet-hadoop/src/main/java/org/apache/parquet/HadoopReadOptions.java": 15,
                "parquet-hadoop/src/main/java/org/apache/parquet/ParquetReadOptions.java": 30,
                "parquet-hadoop/src/main/java/org/apache/parquet/format/converter/ParquetMetadataConverter.java": 53,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ColumnChunkPageReadStore.java": 21,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ColumnChunkPageWriteStore.java": 36,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/InternalParquetRecordWriter.java": 2,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ParquetFileReader.java": 64,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ParquetFileWriter.java": 46,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ParquetInputFormat.java": 5,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ParquetOutputFormat.java": 18,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ParquetReader.java": 10,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ParquetWriter.java": 24,
                "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/TestColumnChunkPageWriteStore.java": 1,
                "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/TestDataPageV1Checksums.java": 563,
                "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/TestParquetFileWriter.java": 4,
                "parquet-tools/src/main/java/org/apache/parquet/tools/command/DumpCommand.java": 18
            },
            "is_test": true,
            "is_fix": false
        },
        "93af6b4e8db84c813530cda763f378858e8c7700": {
            "datetime": "2019-07-25T15:15:35+02:00",
            "summary": "PARQUET-1303 correct ClassCastException for Avro @Stringable fields (#482)",
            "message": "PARQUET-1303 correct ClassCastException for Avro @Stringable fields (#482)\n\n\r\n",
            "diff": {
                "parquet-avro/src/main/java/org/apache/parquet/avro/AvroWriteSupport.java": 6,
                "parquet-avro/src/test/java/org/apache/parquet/avro/TestReflectLogicalTypes.java": 18,
                "parquet-avro/src/test/java/org/apache/parquet/avro/TestReflectReadWrite.java": 24
            },
            "is_test": true,
            "is_fix": true
        }
    },
    "2019-07-26T15:17:05-07:00": {
        "340d157bda4c33b7d126cad82e222a2cfb1b2953": {
            "datetime": "2019-09-05T08:56:31+02:00",
            "summary": "PARQUET-1530: Remove Dependency on commons-codec (#618)",
            "message": "PARQUET-1530: Remove Dependency on commons-codec (#618)\n\n",
            "diff": {
                "parquet-cli/src/main/java/org/apache/parquet/cli/Util.java": 17,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/util/SerializationUtil.java": 15
            },
            "is_test": false,
            "is_fix": false
        },
        "14c1e815dfcac7f2aa7bcebf24a7fa9c14cbf961": {
            "datetime": "2019-09-05T10:07:23+02:00",
            "summary": "PARQUET-1445: Remove Files.java (#584)",
            "message": "PARQUET-1445: Remove Files.java (#584)\n\n",
            "diff": {
                "parquet-common/src/main/java/org/apache/parquet/Files.java": 5,
                "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/TestInputOutputFormatWithPadding.java": 9,
                "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/example/TestInputOutputFormat.java": 15,
                "parquet-thrift/src/test/java/org/apache/parquet/thrift/TestThriftRecordConverter.java": 8
            },
            "is_test": true,
            "is_fix": false
        },
        "e9d87163c50bf91e7ae8c4382095fa641877fa07": {
            "datetime": "2019-09-22T08:59:37+02:00",
            "summary": "PARQUET-1601: Add zstd support to parquet-cli to-avro (#653)",
            "message": "PARQUET-1601: Add zstd support to parquet-cli to-avro (#653)\n\n",
            "diff": {
                "parquet-cli/src/main/java/org/apache/parquet/cli/util/Codecs.java": 2,
                "parquet-cli/src/test/java/org/apache/parquet/cli/commands/AvroFileTest.java": 5,
                "parquet-cli/src/test/java/org/apache/parquet/cli/commands/ToAvroCommandTest.java": 23
            },
            "is_test": true,
            "is_fix": false
        },
        "76c40e7039069a71448f6f30e3de4e86302d17e7": {
            "datetime": "2019-09-24T06:59:59+02:00",
            "summary": "PARQUET-1542: Merge multiple I/O to one time I/O in method readFooter (#624)",
            "message": "PARQUET-1542: Merge multiple I/O to one time I/O in method readFooter (#624)\n\n\r\n",
            "diff": {
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ParquetFileReader.java": 10
            },
            "is_test": false,
            "is_fix": false
        },
        "7c4d1ec859d46bead9f8ed9446d2d5875082211d": {
            "datetime": "2019-09-24T12:22:40+02:00",
            "summary": "PARQUET-1644: Clean up some benchmark code and docs. (#672)",
            "message": "PARQUET-1644: Clean up some benchmark code and docs. (#672)\n\n\r\n",
            "diff": {
                "parquet-benchmarks/src/main/java/org/apache/parquet/benchmarks/BenchmarkFiles.java": 2,
                "parquet-benchmarks/src/main/java/org/apache/parquet/benchmarks/DataGenerator.java": 9,
                "parquet-benchmarks/src/main/java/org/apache/parquet/benchmarks/PageChecksumDataGenerator.java": 23,
                "parquet-benchmarks/src/main/java/org/apache/parquet/benchmarks/PageChecksumReadBenchmarks.java": 63,
                "parquet-benchmarks/src/main/java/org/apache/parquet/benchmarks/PageChecksumWriteBenchmarks.java": 56,
                "parquet-benchmarks/src/main/java/org/apache/parquet/benchmarks/ReadBenchmarks.java": 25,
                "parquet-benchmarks/src/main/java/org/apache/parquet/benchmarks/WriteBenchmarks.java": 11
            },
            "is_test": false,
            "is_fix": false
        },
        "59ae0346cdda2c2fa00698276d9cba82a73c6856": {
            "datetime": "2019-10-07T10:36:05+03:00",
            "summary": "PARQUET-1578: Introduce Lambdas (#641)",
            "message": "PARQUET-1578: Introduce Lambdas (#641)\n\nTo improve on readability",
            "diff": {
                "parquet-avro/src/test/java/org/apache/parquet/avro/TestArrayCompatibility.java": 884,
                "parquet-avro/src/test/java/org/apache/parquet/avro/TestAvroSchemaConverter.java": 35,
                "parquet-column/src/main/java/org/apache/parquet/io/api/Binary.java": 7,
                "parquet-column/src/test/java/org/apache/parquet/schema/TestTypeBuilders.java": 253,
                "parquet-column/src/test/java/org/apache/parquet/schema/TestTypeUtil.java": 39,
                "parquet-common/src/test/java/org/apache/parquet/bytes/TestByteBufferInputStreams.java": 50,
                "parquet-common/src/test/java/org/apache/parquet/io/TestDelegatingSeekableInputStream.java": 43,
                "parquet-common/src/test/java/org/apache/parquet/util/TestDynConstructors.java": 102,
                "parquet-common/src/test/java/org/apache/parquet/util/TestDynMethods.java": 137,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ParquetFileReader.java": 52,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ParquetFileWriter.java": 8,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/PrintFooter.java": 14,
                "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/TestMemoryManager.java": 7,
                "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/TestParquetWriter.java": 17,
                "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/TestParquetWriterAppendBlocks.java": 22,
                "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/util/TestHadoop2ByteBufferReads.java": 18
            },
            "is_test": true,
            "is_fix": false
        },
        "10f57a3779264ba222288defd1472d66ac2ae135": {
            "datetime": "2019-10-07T11:24:51+02:00",
            "summary": "PARQUET-1596: PARQUET-1375 broke parquet-cli's to-avro command (#648)",
            "message": "PARQUET-1596: PARQUET-1375 broke parquet-cli's to-avro command (#648)\n\n* PARQUET-1596: PARQUET-1375 broke parquet-cli's to-avro command\r\n\r\nThe expected NPE:\r\n\r\ncat /Users/fokkodriesprong/Desktop/parquet-mr/parquet-cli/target/surefire-reports/org.apache.parquet.cli.commands.ToAvroCommandTest.txt\r\n-------------------------------------------------------------------------------\r\nTest set: org.apache.parquet.cli.commands.ToAvroCommandTest\r\n-------------------------------------------------------------------------------\r\nTests run: 2, Failures: 0, Errors: 1, Skipped: 0, Time elapsed: 0.154 sec <<< FAILURE!\r\ntestToAvroCommandFromJson(org.apache.parquet.cli.commands.ToAvroCommandTest)  Time elapsed: 0.052 sec  <<< ERROR!\r\njava.lang.NullPointerException\r\n\tat org.apache.hadoop.fs.FileSystem.getDefaultUri(FileSystem.java:180)\r\n\tat org.apache.hadoop.fs.FileSystem.get(FileSystem.java:361)\r\n\tat org.apache.hadoop.fs.FileSystem.getLocal(FileSystem.java:344)\r\n\tat org.apache.parquet.cli.BaseCommand.defaultFS(BaseCommand.java:81)\r\n\tat org.apache.parquet.cli.BaseCommand.qualifiedPath(BaseCommand.java:164)\r\n\tat org.apache.parquet.cli.BaseCommand.openSeekable(BaseCommand.java:215)\r\n\tat org.apache.parquet.cli.BaseCommand.getAvroSchema(BaseCommand.java:375)\r\n\tat org.apache.parquet.cli.commands.ToAvroCommand.run(ToAvroCommand.java:93)\r\n\tat org.apache.parquet.cli.commands.ToAvroCommandTest.testToAvroCommandFromJson(ToAvroCommandTest.java:72)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\r\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\r\n\tat java.lang.reflect.Method.invoke(Method.java:498)\r\n\tat org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:50)\r\n\tat org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)\r\n\tat org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:47)\r\n\tat org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)\r\n\tat org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)\r\n\tat org.junit.rules.ExternalResource$1.evaluate(ExternalResource.java:48)\r\n\tat org.junit.rules.ExternalResource$1.evaluate(ExternalResource.java:48)\r\n\tat org.junit.rules.RunRules.evaluate(RunRules.java:20)\r\n\tat org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:325)\r\n\tat org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:78)\r\n\tat org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:57)\r\n\tat org.junit.runners.ParentRunner$3.run(ParentRunner.java:290)\r\n\tat org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:71)\r\n\tat org.junit.runners.ParentRunner.runChildren(ParentRunner.java:288)\r\n\tat org.junit.runners.ParentRunner.access$000(ParentRunner.java:58)\r\n\tat org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:268)\r\n\tat org.junit.runners.ParentRunner.run(ParentRunner.java:363)\r\n\tat org.apache.maven.surefire.junit4.JUnit4TestSet.execute(JUnit4TestSet.java:53)\r\n\tat org.apache.maven.surefire.junit4.JUnit4Provider.executeTestSet(JUnit4Provider.java:123)\r\n\tat org.apache.maven.surefire.junit4.JUnit4Provider.invoke(JUnit4Provider.java:104)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\r\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\r\n\tat java.lang.reflect.Method.invoke(Method.java:498)\r\n\tat org.apache.maven.surefire.util.ReflectionUtils.invokeMethodWithArray(ReflectionUtils.java:164)\r\n\tat org.apache.maven.surefire.booter.ProviderFactory$ProviderProxy.invoke(ProviderFactory.java:110)\r\n\tat org.apache.maven.surefire.booter.SurefireStarter.invokeProvider(SurefireStarter.java:175)\r\n\tat org.apache.maven.surefire.booter.SurefireStarter.runSuitesInProcessWhenForked(SurefireStarter.java:107)\r\n\tat org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:68)\r\n",
            "diff": {
                "parquet-cli/src/main/java/org/apache/parquet/cli/BaseCommand.java": 4,
                "parquet-cli/src/main/java/org/apache/parquet/cli/commands/ToAvroCommand.java": 22,
                "parquet-cli/src/main/java/org/apache/parquet/cli/json/AvroJson.java": 4,
                "parquet-cli/src/test/java/org/apache/parquet/cli/commands/ToAvroCommandTest.java": 40
            },
            "is_test": true,
            "is_fix": true
        },
        "52a502ebbf8a5525ea09d98fd75be7ccff08501c": {
            "datetime": "2019-10-14T20:42:54+02:00",
            "summary": "PARQUET-0000: Fix typo (#666)",
            "message": "PARQUET-0000: Fix typo (#666)\n\n",
            "diff": {
                "parquet-protobuf/src/main/java/org/apache/parquet/proto/ProtoSchemaConverter.java": 2
            },
            "is_test": false,
            "is_fix": false
        },
        "0c6a650a01d4075775af8aecdca14af78c5e7157": {
            "datetime": "2019-10-18T08:37:12+02:00",
            "summary": "PARQUET-1650: Implement unit test to validate column/offset indexes (#675)",
            "message": "PARQUET-1650: Implement unit test to validate column/offset indexes (#675)\n\n",
            "diff": {
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ColumnIndexValidator.java": 613,
                "parquet-hadoop/src/test/java/org/apache/parquet/statistics/RandomValues.java": 46,
                "parquet-hadoop/src/test/java/org/apache/parquet/statistics/TestColumnIndexes.java": 300
            },
            "is_test": true,
            "is_fix": false
        },
        "2117abcbd0ae316169e7f66655e0d202553bd290": {
            "datetime": "2019-10-22T15:24:20+02:00",
            "summary": "PARQUET-1682: Maintain forward compatibility for TIME/TIMESTAMP (#694)",
            "message": "PARQUET-1682: Maintain forward compatibility for TIME/TIMESTAMP (#694)\n\n",
            "diff": {
                "parquet-column/src/main/java/org/apache/parquet/schema/LogicalTypeAnnotation.java": 6,
                "parquet-hadoop/src/main/java/org/apache/parquet/format/converter/ParquetMetadataConverter.java": 6,
                "parquet-hadoop/src/test/java/org/apache/parquet/format/converter/TestParquetMetadataConverter.java": 8
            },
            "is_test": true,
            "is_fix": false
        },
        "2122a8a8e0fcc08307a5e1926b234bcfe3286ec1": {
            "datetime": "2019-10-23T07:33:33+02:00",
            "summary": "PARQUET-1683: Remove unnecessary string conversions (#695)",
            "message": "PARQUET-1683: Remove unnecessary string conversions (#695)\n\nRemove unnecessary string converting \r\nin readFooter method.",
            "diff": {
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ParquetFileReader.java": 5
            },
            "is_test": false,
            "is_fix": false
        },
        "4648b0609189e270c5b3bbf114b6057b943fc3be": {
            "datetime": "2019-10-23T15:22:20+02:00",
            "summary": "PARQUET-XXXX: Minor Javadoc improvements (#667)",
            "message": "PARQUET-XXXX: Minor Javadoc improvements (#667)\n\n",
            "diff": {
                "parquet-column/src/main/java/org/apache/parquet/schema/Types.java": 6
            },
            "is_test": false,
            "is_fix": false
        },
        "10b926f021a6a441685c01d3dfe32c7ef07b1900": {
            "datetime": "2019-10-23T15:24:00+02:00",
            "summary": "PARQUET-1444: Prefer ArrayList over LinkedList (#583)",
            "message": "PARQUET-1444: Prefer ArrayList over LinkedList (#583)\n\n",
            "diff": {
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ColumnChunkPageReadStore.java": 12,
                "parquet-thrift/src/main/java/org/apache/parquet/thrift/BufferedProtocolReadToWrite.java": 4,
                "parquet-thrift/src/main/java/org/apache/parquet/thrift/ParquetReadProtocol.java": 4
            },
            "is_test": false,
            "is_fix": false
        },
        "19b10acaba799098f374b32f405cd63ea7076f51": {
            "datetime": "2019-10-26T01:05:58+02:00",
            "summary": "PARQUET-1499: Add Java 11 to Travis (#596)",
            "message": "PARQUET-1499: Add Java 11 to Travis (#596)\n\nGot some weird warnings from generated code:\r\n\r\n[ERROR] Failed to execute goal org.apache.maven.plugins:maven-javadoc-plugin:2.9.1:javadoc (default-cli) on project parquet-format-structures: An error has occurred in JavaDocs report generation:\r\n[ERROR] Exit code: 1 - javadoc: error - The code being documented uses modules but the packages defined in http://docs.oracle.com/javase/7/docs/api/ are in the unnamed module.\r\n[ERROR] /home/travis/build/apache/parquet-mr/parquet-format-structures/target/generated-sources/thrift/org/apache/parquet/format/ColumnIndex.java:49: warning - invalid usage of tag <\r\n[ERROR] /home/travis/build/apache/parquet-mr/parquet-format-structures/target/generated-sources/thrift/org/apache/parquet/format/ColumnIndex.java:394: warning - invalid usage of tag <\r\n[ERROR] /home/travis/build/apache/parquet-mr/parquet-format-structures/target/generated-sources/thrift/org/apache/parquet/format/ColumnIndex.java:407: warning - invalid usage of tag <\r\n[ERROR] /home/travis/build/apache/parquet-mr/parquet-format-structures/target/generated-sources/thrift/org/apache/parquet/format/ColumnIndex.java:84: warning - invalid usage of tag <\r\n[ERROR] /home/travis/build/apache/parquet-mr/parquet-format-structures/target/generated-sources/thrift/org/apache/parquet/format/OffsetIndex.java:21: warning - invalid usage of tag <\r\n[ERROR] /home/travis/build/apache/parquet-mr/parquet-format-structures/target/generated-sources/thrift/org/apache/parquet/format/OffsetIndex.java:150: warning - invalid usage of tag <\r\n[ERROR] /home/travis/build/apache/parquet-mr/parquet-format-structures/target/generated-sources/thrift/org/apache/parquet/format/OffsetIndex.java:159: warning - invalid usage of tag <\r\n[ERROR] /home/travis/build/apache/parquet-mr/parquet-format-structures/target/generated-sources/thrift/org/apache/parquet/format/OffsetIndex.java:29: warning - invalid usage of tag <\r\n[ERROR] /home/travis/build/apache/parquet-mr/parquet-format-structures/target/generated-sources/thrift/org/apache/parquet/format/ColumnIndex.java:49: warning - invalid usage of tag <\r\n[ERROR] /home/travis/build/apache/parquet-mr/parquet-format-structures/target/generated-sources/thrift/org/apache/parquet/format/OffsetIndex.java:21: warning - invalid usage of tag <\r\n",
            "diff": {
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/codec/CleanUtil.java": 1
            },
            "is_test": false,
            "is_fix": false
        },
        "76f90101376d2589fe6071c96ae9d0203b245c0d": {
            "datetime": "2019-11-13T10:14:24+01:00",
            "summary": "PARQUET-1685: Truncate Min/Max for Statistics (#696)",
            "message": "PARQUET-1685: Truncate Min/Max for Statistics (#696)\n\n* Remove unnecessary string converting in readFooter method",
            "diff": {
                "parquet-column/src/main/java/org/apache/parquet/column/ParquetProperties.java": 20,
                "parquet-column/src/main/java/org/apache/parquet/column/statistics/BinaryStatistics.java": 11,
                "parquet-column/src/main/java/org/apache/parquet/internal/column/columnindex/BinaryTruncator.java": 16,
                "parquet-hadoop/src/main/java/org/apache/parquet/format/converter/ParquetMetadataConverter.java": 64,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ParquetFileWriter.java": 13,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ParquetOutputFormat.java": 17,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ParquetWriter.java": 3,
                "parquet-hadoop/src/test/java/org/apache/parquet/format/converter/TestParquetMetadataConverter.java": 66
            },
            "is_test": true,
            "is_fix": false
        },
        "4ca29c7114237d4bb039b7291fa2c8c182170109": {
            "datetime": "2019-12-12T17:42:31+01:00",
            "summary": "[PARQUET-1717] Convert i16 thrift to INT16 logical type instead (#706)",
            "message": "[PARQUET-1717] Convert i16 thrift to INT16 logical type instead (#706)\n\n* [PARQUET-1717] Convert i16 thrift to INT16 logical type instead of INT32 primitive\r\n\r\n* [Parquet-1717] Add unit test\r\nAdd unit test for i16 thrift type\r\n",
            "diff": {
                "parquet-thrift/src/main/java/org/apache/parquet/thrift/ThriftSchemaConvertVisitor.java": 2,
                "parquet-thrift/src/test/java/org/apache/parquet/thrift/TestThriftSchemaConverter.java": 13
            },
            "is_test": true,
            "is_fix": false
        },
        "3b4ecf2c7029d12265b3e97a1f8ea98da1c1e5c2": {
            "datetime": "2020-01-02T13:46:49+01:00",
            "summary": "PARQUET-1723: Read From Maps without using .contains(...) (#711)",
            "message": "PARQUET-1723: Read From Maps without using .contains(...) (#711)\n\n",
            "diff": {
                "parquet-column/src/main/java/org/apache/parquet/column/EncodingStats.java": 14,
                "parquet-column/src/main/java/org/apache/parquet/schema/GroupType.java": 5,
                "parquet-hadoop/src/main/java/org/apache/parquet/ParquetReadOptions.java": 9,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ColumnChunkPageReadStore.java": 5,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/MemoryManager.java": 4
            },
            "is_test": false,
            "is_fix": false
        },
        "b9f16e50244a4c7df9ea81baef5843a17d55d91c": {
            "datetime": "2020-01-02T13:52:37+01:00",
            "summary": "PARQUET-1724: Use ConcurrentHashMap for Cache in DictionaryPageReader (#712)",
            "message": "PARQUET-1724: Use ConcurrentHashMap for Cache in DictionaryPageReader (#712)\n\n",
            "diff": {
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/DictionaryPageReader.java": 67
            },
            "is_test": false,
            "is_fix": false
        },
        "1e15f604302ab96904eaa1c3d435d2a5b3632d3f": {
            "datetime": "2020-01-02T14:00:06+01:00",
            "summary": "PARQUET-1726: Use Java 8 Multi Exception Handling (#714)",
            "message": "PARQUET-1726: Use Java 8 Multi Exception Handling (#714)\n\n",
            "diff": {
                "parquet-avro/src/main/java/org/apache/parquet/avro/AvroConverters.java": 9,
                "parquet-avro/src/main/java/org/apache/parquet/avro/AvroRecordConverter.java": 4,
                "parquet-cli/src/main/java/org/apache/parquet/cli/json/AvroJson.java": 8,
                "parquet-column/src/main/java/org/apache/parquet/CorruptDeltaByteArrays.java": 5,
                "parquet-column/src/main/java/org/apache/parquet/CorruptStatistics.java": 12,
                "parquet-column/src/main/java/org/apache/parquet/column/impl/ColumnReadStoreImpl.java": 4,
                "parquet-column/src/main/java/org/apache/parquet/column/values/plain/BinaryPlainValuesReader.java": 8,
                "parquet-column/src/main/java/org/apache/parquet/filter2/predicate/Operators.java": 4,
                "parquet-common/src/main/java/org/apache/parquet/VersionParser.java": 5,
                "parquet-common/src/main/java/org/apache/parquet/util/DynConstructors.java": 22,
                "parquet-common/src/main/java/org/apache/parquet/util/DynMethods.java": 6,
                "parquet-encoding/src/main/java/org/apache/parquet/column/values/bitpacking/Packer.java": 11,
                "parquet-format-structures/src/main/java/org/apache/parquet/format/event/Consumers.java": 4,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/DirectCodecFactory.java": 8,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ParquetInputFormat.java": 11,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ParquetOutputFormat.java": 4,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/metadata/ParquetMetadata.java": 8,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/util/ContextUtil.java": 32,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/util/HadoopStreams.java": 13,
                "parquet-pig/src/main/java/org/apache/parquet/pig/TupleWriteSupport.java": 4,
                "parquet-pig/src/main/java/org/apache/parquet/pig/convert/TupleConverter.java": 7,
                "parquet-pig/src/main/java/org/apache/parquet/pig/summary/SummaryData.java": 8,
                "parquet-thrift/src/main/java/org/apache/parquet/hadoop/thrift/ThriftBytesWriteSupport.java": 4,
                "parquet-thrift/src/main/java/org/apache/parquet/hadoop/thrift/ThriftReadSupport.java": 8
            },
            "is_test": false,
            "is_fix": false
        },
        "3d8ce063986ad623d6ade4b55f1bbb1eb39f7641": {
            "datetime": "2020-01-05T19:24:15+01:00",
            "summary": "PARQUET-1727: Do Not Swallow InterruptedException in ParquetLoader (#715)",
            "message": "PARQUET-1727: Do Not Swallow InterruptedException in ParquetLoader (#715)\n\n",
            "diff": {
                "parquet-pig/src/main/java/org/apache/parquet/pig/ParquetLoader.java": 5
            },
            "is_test": false,
            "is_fix": false
        },
        "cce6fdb3304894e23231b10e1c758631e52df2d8": {
            "datetime": "2020-01-05T19:25:13+01:00",
            "summary": "PARQUET-1732: Call toArray With Empty Array (#720)",
            "message": "PARQUET-1732: Call toArray With Empty Array (#720)\n\n",
            "diff": {
                "parquet-cli/src/main/java/org/apache/parquet/cli/csv/RecordBuilder.java": 2,
                "parquet-cli/src/main/java/org/apache/parquet/cli/util/GetClassLoader.java": 2,
                "parquet-column/src/main/java/org/apache/parquet/filter2/recordlevel/FilteringGroupConverter.java": 7,
                "parquet-column/src/main/java/org/apache/parquet/internal/column/columnindex/BinaryColumnIndexBuilder.java": 4,
                "parquet-column/src/main/java/org/apache/parquet/io/PrimitiveColumnIO.java": 2,
                "parquet-column/src/main/java/org/apache/parquet/io/RecordReaderImplementation.java": 2,
                "parquet-hadoop/src/main/java/org/apache/parquet/format/converter/ParquetMetadataConverter.java": 2,
                "parquet-tools/src/main/java/org/apache/parquet/tools/command/MetadataUtils.java": 2,
                "parquet-tools/src/main/java/org/apache/parquet/tools/util/MetadataUtils.java": 2
            },
            "is_test": false,
            "is_fix": false
        },
        "a7447f698e5d8a1fff5b1542a70e42273b1b6373": {
            "datetime": "2020-01-05T19:25:54+01:00",
            "summary": "PARQUET-1731: Use JDK 8 Facilities to Simplify FilteringRecordMaterializer (#719)",
            "message": "PARQUET-1731: Use JDK 8 Facilities to Simplify FilteringRecordMaterializer (#719)\n\n",
            "diff": {
                "parquet-column/src/main/java/org/apache/parquet/filter2/recordlevel/FilteringRecordMaterializer.java": 34
            },
            "is_test": false,
            "is_fix": false
        },
        "c697d80ec1f10b381d634a01b6dd9eda2ba125e2": {
            "datetime": "2020-01-05T21:12:10+01:00",
            "summary": "PARQUET-1730: Use switch Statement in AvroIndexedRecordConverter for Enums (#718)",
            "message": "PARQUET-1730: Use switch Statement in AvroIndexedRecordConverter for Enums (#718)\n\n",
            "diff": {
                "parquet-avro/src/main/java/org/apache/parquet/avro/AvroIndexedRecordConverter.java": 57
            },
            "is_test": false,
            "is_fix": false
        },
        "e430527cdab5d0f5019c2ef665bea6283b5787b4": {
            "datetime": "2020-01-08T16:14:44+01:00",
            "summary": "PARQUET-1741: Restore APIs to keep backward compatibility (#729)",
            "message": "PARQUET-1741: Restore APIs to keep backward compatibility (#729)\n\n* PARQUET-1741: Restore APIs to keep backward compatibility\r\n\r\n* deprecate unused method\r\n",
            "diff": {
                "parquet-column/src/main/java/org/apache/parquet/filter2/recordlevel/FilteringRecordMaterializer.java": 16
            },
            "is_test": false,
            "is_fix": false
        },
        "ac7840ced22902e3880089fb4c5a533535aae256": {
            "datetime": "2020-01-08T18:00:14+01:00",
            "summary": "PARQUET-1725: Replace Usage of Strings.join with JDK Functionality in\u2026 (#713)",
            "message": "PARQUET-1725: Replace Usage of Strings.join with JDK Functionality in\u2026 (#713)\n\n* PARQUET-1725: Replace Usage of Strings.join with JDK Functionality in ColumnPath Class\r\n\r\n* Applied refactoring to DictionaryPageReader as well\r\n\r\n* Remove Strings utility class join methods\r\n\r\n* Deprecate instead of remove join methods\r\n",
            "diff": {
                "parquet-common/src/main/java/org/apache/parquet/Strings.java": 6,
                "parquet-common/src/main/java/org/apache/parquet/hadoop/metadata/ColumnPath.java": 4,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/DictionaryPageReader.java": 3,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ParquetFileWriter.java": 3,
                "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/example/TestInputOutputFormat.java": 3,
                "parquet-thrift/src/main/java/org/apache/parquet/thrift/struct/CompatibilityChecker.java": 4,
                "parquet-thrift/src/test/java/org/apache/parquet/thrift/TestThriftRecordConverter.java": 5
            },
            "is_test": true,
            "is_fix": false
        },
        "72738f59920cb8a875757d5fbb0a70bd7115fdcf": {
            "datetime": "2020-01-09T09:31:39+01:00",
            "summary": "PARQUET-1735: Clean Up parquet-columns Module (#723)",
            "message": "PARQUET-1735: Clean Up parquet-columns Module (#723)\n\n* PARQUET-1735: Clean Up parquet-columns Module\r\n\r\n* Remove superfluous parentheses\r\n",
            "diff": {
                "parquet-column/src/main/java/org/apache/parquet/column/EncodingStats.java": 10,
                "parquet-column/src/main/java/org/apache/parquet/column/impl/ColumnReaderBase.java": 30,
                "parquet-column/src/main/java/org/apache/parquet/column/impl/ColumnWriteStoreBase.java": 4,
                "parquet-column/src/main/java/org/apache/parquet/column/values/bitpacking/ByteBitPackingValuesWriter.java": 1,
                "parquet-column/src/main/java/org/apache/parquet/column/values/delta/DeltaBinaryPackingValuesWriter.java": 3,
                "parquet-column/src/main/java/org/apache/parquet/column/values/delta/DeltaBinaryPackingValuesWriterForLong.java": 1,
                "parquet-column/src/main/java/org/apache/parquet/column/values/deltastrings/DeltaByteArrayReader.java": 4,
                "parquet-column/src/main/java/org/apache/parquet/column/values/deltastrings/DeltaByteArrayWriter.java": 1,
                "parquet-column/src/main/java/org/apache/parquet/column/values/dictionary/DictionaryValuesReader.java": 2,
                "parquet-column/src/main/java/org/apache/parquet/column/values/dictionary/DictionaryValuesWriter.java": 4,
                "parquet-column/src/main/java/org/apache/parquet/column/values/dictionary/IntList.java": 2,
                "parquet-column/src/main/java/org/apache/parquet/column/values/fallback/FallbackValuesWriter.java": 10,
                "parquet-column/src/main/java/org/apache/parquet/column/values/rle/ZeroIntegerValuesReader.java": 1,
                "parquet-column/src/main/java/org/apache/parquet/example/DummyRecordConverter.java": 3,
                "parquet-column/src/main/java/org/apache/parquet/example/data/Group.java": 2,
                "parquet-column/src/main/java/org/apache/parquet/example/data/simple/SimpleGroup.java": 2,
                "parquet-column/src/main/java/org/apache/parquet/filter2/predicate/FilterApi.java": 16,
                "parquet-column/src/main/java/org/apache/parquet/filter2/predicate/LogicalInverter.java": 14,
                "parquet-column/src/main/java/org/apache/parquet/filter2/predicate/PrimitiveToBoxedClass.java": 2,
                "parquet-column/src/main/java/org/apache/parquet/filter2/predicate/SchemaCompatibilityValidator.java": 5,
                "parquet-column/src/main/java/org/apache/parquet/filter2/predicate/ValidTypeMap.java": 8,
                "parquet-column/src/main/java/org/apache/parquet/filter2/recordlevel/FilteringGroupConverter.java": 2,
                "parquet-column/src/main/java/org/apache/parquet/filter2/recordlevel/IncrementallyUpdatedFilterPredicateBuilderBase.java": 4,
                "parquet-column/src/main/java/org/apache/parquet/internal/column/columnindex/BinaryColumnIndexBuilder.java": 2,
                "parquet-column/src/main/java/org/apache/parquet/internal/column/columnindex/BooleanColumnIndexBuilder.java": 2,
                "parquet-column/src/main/java/org/apache/parquet/internal/column/columnindex/DoubleColumnIndexBuilder.java": 2,
                "parquet-column/src/main/java/org/apache/parquet/internal/column/columnindex/FloatColumnIndexBuilder.java": 2,
                "parquet-column/src/main/java/org/apache/parquet/internal/column/columnindex/IntColumnIndexBuilder.java": 2,
                "parquet-column/src/main/java/org/apache/parquet/internal/column/columnindex/LongColumnIndexBuilder.java": 2,
                "parquet-column/src/main/java/org/apache/parquet/io/ColumnIOFactory.java": 2,
                "parquet-column/src/main/java/org/apache/parquet/io/GroupColumnIO.java": 12,
                "parquet-column/src/main/java/org/apache/parquet/io/MessageColumnIO.java": 15,
                "parquet-column/src/main/java/org/apache/parquet/io/RecordReaderImplementation.java": 10,
                "parquet-column/src/main/java/org/apache/parquet/io/ValidatingRecordConsumer.java": 20,
                "parquet-column/src/main/java/org/apache/parquet/io/api/Binary.java": 1,
                "parquet-column/src/main/java/org/apache/parquet/schema/GroupType.java": 12,
                "parquet-column/src/main/java/org/apache/parquet/schema/MessageType.java": 4,
                "parquet-column/src/main/java/org/apache/parquet/schema/PrimitiveType.java": 1,
                "parquet-column/src/main/java/org/apache/parquet/schema/Type.java": 3,
                "parquet-column/src/main/java/org/apache/parquet/schema/Types.java": 90,
                "parquet-column/src/test/java/org/apache/parquet/column/TestEncodingStats.java": 8,
                "parquet-column/src/test/java/org/apache/parquet/column/impl/TestColumnReaderImpl.java": 4,
                "parquet-column/src/test/java/org/apache/parquet/column/impl/TestCorruptDeltaByteArrays.java": 4,
                "parquet-column/src/test/java/org/apache/parquet/column/mem/TestMemColumn.java": 3,
                "parquet-column/src/test/java/org/apache/parquet/column/page/mem/MemPageStore.java": 4,
                "parquet-column/src/test/java/org/apache/parquet/column/page/mem/MemPageWriter.java": 2,
                "parquet-column/src/test/java/org/apache/parquet/column/statistics/TestStatistics.java": 4,
                "parquet-column/src/test/java/org/apache/parquet/column/values/TestValuesReaderImpl.java": 2,
                "parquet-column/src/test/java/org/apache/parquet/column/values/Utils.java": 1,
                "parquet-column/src/test/java/org/apache/parquet/column/values/bitpacking/TestBitPackingColumn.java": 4,
                "parquet-column/src/test/java/org/apache/parquet/column/values/delta/benchmark/BenchMarkTest.java": 2,
                "parquet-column/src/test/java/org/apache/parquet/column/values/deltalengthbytearray/benchmark/BenchmarkDeltaLengthByteArray.java": 4,
                "parquet-column/src/test/java/org/apache/parquet/column/values/deltastrings/TestDeltaByteArray.java": 2,
                "parquet-column/src/test/java/org/apache/parquet/column/values/deltastrings/benchmark/BenchmarkDeltaByteArray.java": 8,
                "parquet-column/src/test/java/org/apache/parquet/column/values/rle/RunLengthBitPackingHybridIntegrationTest.java": 12,
                "parquet-column/src/test/java/org/apache/parquet/column/values/rle/TestRunLengthBitPackingHybridEncoder.java": 2,
                "parquet-column/src/test/java/org/apache/parquet/filter2/predicate/TestLogicalInverseRewriter.java": 4,
                "parquet-column/src/test/java/org/apache/parquet/filter2/predicate/TestLogicalInverter.java": 6,
                "parquet-column/src/test/java/org/apache/parquet/io/ConverterConsumer.java": 4,
                "parquet-column/src/test/java/org/apache/parquet/io/ExpectationValidatingConverter.java": 2,
                "parquet-column/src/test/java/org/apache/parquet/io/TestColumnIO.java": 18,
                "parquet-column/src/test/java/org/apache/parquet/io/TestFiltered.java": 6,
                "parquet-column/src/test/java/org/apache/parquet/schema/TestTypeBuilders.java": 96
            },
            "is_test": true,
            "is_fix": false
        },
        "65eba5547a5a63a318eb8b5d3974e8980055b8c7": {
            "datetime": "2020-01-09T15:09:24+01:00",
            "summary": "PARQUET-1740: Make ParquetFileReader.getFilteredRecordCount public (#728)",
            "message": "PARQUET-1740: Make ParquetFileReader.getFilteredRecordCount public (#728)\n\n",
            "diff": {
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ParquetFileReader.java": 2
            },
            "is_test": false,
            "is_fix": false
        },
        "f0fc29fd3341046f7d46a4a02a7c9ec3d7cd3e46": {
            "datetime": "2020-01-10T07:08:01+01:00",
            "summary": "PARQUET-1744: Some filters throws ArrayIndexOutOfBoundsException (#732)",
            "message": "PARQUET-1744: Some filters throws ArrayIndexOutOfBoundsException (#732)\n\n",
            "diff": {
                "parquet-column/src/main/java/org/apache/parquet/internal/column/columnindex/BoundaryOrder.java": 32,
                "parquet-column/src/test/java/org/apache/parquet/internal/column/columnindex/TestBoundaryOrder.java": 264,
                "parquet-column/src/test/java/org/apache/parquet/internal/filter2/columnindex/TestColumnIndexFilter.java": 106
            },
            "is_test": true,
            "is_fix": false
        },
        "616e35f9e164a24104da148f713b2e8258a4f54f": {
            "datetime": "2020-01-10T13:52:50+01:00",
            "summary": "PARQUET-1593: Improve parquet-cli's example usage (#646)",
            "message": "PARQUET-1593: Improve parquet-cli's example usage (#646)\n\nThe following description is a bit weird since there's no command\r\ncalled \"create\" actually. This PR replaces the subcommand with an\r\nactually existent one.\r\n\r\n```\r\n  Examples:\r\n\r\n    # print information for create\r\n    parquet help create\r\n```",
            "diff": {
                "parquet-cli/src/main/java/org/apache/parquet/cli/Help.java": 11
            },
            "is_test": false,
            "is_fix": false
        },
        "d85a8f5dcfc1381655fcccaa81a2e83ba812f6a4": {
            "datetime": "2020-01-10T13:55:15+01:00",
            "summary": "PARQUET-1729: Avoid AutoBoxing in EncodingStats (#717)",
            "message": "PARQUET-1729: Avoid AutoBoxing in EncodingStats (#717)\n\n* PARQUET-1729: Avoid AutoBoxing in EncodingStats\r\n\r\n* Updated unit tests to more properly check stats value\r\n",
            "diff": {
                "parquet-column/src/main/java/org/apache/parquet/column/EncodingStats.java": 29,
                "parquet-column/src/test/java/org/apache/parquet/column/TestEncodingStats.java": 34
            },
            "is_test": true,
            "is_fix": false
        },
        "ad07d836e6da9a8ca8e5e1f19af42ad75ece2bb7": {
            "datetime": "2020-01-15T13:00:11+01:00",
            "summary": "PARQUET-1738: Remove unused imports (#726)",
            "message": "PARQUET-1738: Remove unused imports (#726)\n\n* PARQUET-1738: Remove unused imports from tests\r\n\r\n* PARQUET-1738: Remove unused imports from column\r\n\r\nCo-authored-by: Fokko Driesprong <fokko@driesprong.frl>\r\n",
            "diff": {
                "parquet-column/src/test/java/org/apache/parquet/column/values/deltastrings/TestDeltaByteArray.java": 1,
                "parquet-column/src/test/java/org/apache/parquet/internal/column/columnindex/TestOffsetIndexBuilder.java": 2
            },
            "is_test": true,
            "is_fix": false
        },
        "8c1bc9bcdeeac8178fecf61d18dc56913907fd46": {
            "datetime": "2020-01-16T14:31:27+01:00",
            "summary": "PARQUET-1765: Invalid filteredRowCount in InternalParquetRecordReader (#747)",
            "message": "PARQUET-1765: Invalid filteredRowCount in InternalParquetRecordReader (#747)\n\n",
            "diff": {
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/InternalParquetRecordReader.java": 8,
                "parquet-hadoop/src/test/java/org/apache/parquet/filter2/recordlevel/PhoneBookWriter.java": 8,
                "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/TestColumnIndexFiltering.java": 50
            },
            "is_test": true,
            "is_fix": true
        }
    },
    "2020-01-22T15:17:05-07:00": {
        "d3e3118150d3fa5d2831443ddc944d7416b9a9f6": {
            "datetime": "2020-01-26T21:06:27+01:00",
            "summary": "PARQUET-1710: Use Objects.requireNonNull (#703)",
            "message": "PARQUET-1710: Use Objects.requireNonNull (#703)\n\n",
            "diff": {
                "parquet-cascading/src/main/java/org/apache/parquet/cascading/ParquetTupleScheme.java": 7,
                "parquet-cascading3/src/main/java/org/apache/parquet/cascading/ParquetTupleScheme.java": 9,
                "parquet-cascading3/src/main/java/org/apache/parquet/cascading/ParquetValueScheme.java": 20,
                "parquet-cli/src/main/java/org/apache/parquet/cli/csv/AvroCSV.java": 8,
                "parquet-column/src/main/java/org/apache/parquet/column/ParquetProperties.java": 9,
                "parquet-column/src/main/java/org/apache/parquet/column/impl/ColumnReaderBase.java": 8,
                "parquet-column/src/main/java/org/apache/parquet/column/page/DictionaryPage.java": 7,
                "parquet-column/src/main/java/org/apache/parquet/filter/AndRecordFilter.java": 6,
                "parquet-column/src/main/java/org/apache/parquet/filter/ColumnPredicates.java": 7,
                "parquet-column/src/main/java/org/apache/parquet/filter/ColumnRecordFilter.java": 6,
                "parquet-column/src/main/java/org/apache/parquet/filter/NotRecordFilter.java": 5,
                "parquet-column/src/main/java/org/apache/parquet/filter/OrRecordFilter.java": 7,
                "parquet-column/src/main/java/org/apache/parquet/filter2/compat/FilterCompat.java": 9,
                "parquet-column/src/main/java/org/apache/parquet/filter2/predicate/LogicalInverseRewriter.java": 5,
                "parquet-column/src/main/java/org/apache/parquet/filter2/predicate/LogicalInverter.java": 4,
                "parquet-column/src/main/java/org/apache/parquet/filter2/predicate/Operators.java": 33,
                "parquet-column/src/main/java/org/apache/parquet/filter2/predicate/SchemaCompatibilityValidator.java": 7,
                "parquet-column/src/main/java/org/apache/parquet/filter2/predicate/Statistics.java": 13,
                "parquet-column/src/main/java/org/apache/parquet/filter2/recordlevel/FilteringGroupConverter.java": 12,
                "parquet-column/src/main/java/org/apache/parquet/filter2/recordlevel/FilteringPrimitiveConverter.java": 6,
                "parquet-column/src/main/java/org/apache/parquet/filter2/recordlevel/FilteringRecordMaterializer.java": 11,
                "parquet-column/src/main/java/org/apache/parquet/filter2/recordlevel/IncrementallyUpdatedFilterPredicate.java": 6,
                "parquet-column/src/main/java/org/apache/parquet/filter2/recordlevel/IncrementallyUpdatedFilterPredicateEvaluator.java": 5,
                "parquet-column/src/main/java/org/apache/parquet/filter2/recordlevel/IncrementallyUpdatedFilterPredicateResetter.java": 5,
                "parquet-column/src/main/java/org/apache/parquet/io/MessageColumnIO.java": 9,
                "parquet-column/src/main/java/org/apache/parquet/schema/ColumnOrder.java": 4,
                "parquet-column/src/main/java/org/apache/parquet/schema/Type.java": 11,
                "parquet-column/src/main/java/org/apache/parquet/schema/Types.java": 12,
                "parquet-column/src/test/java/org/apache/parquet/column/page/mem/MemPageReader.java": 6,
                "parquet-common/src/main/java/org/apache/parquet/Preconditions.java": 4,
                "parquet-common/src/main/java/org/apache/parquet/glob/WildcardPath.java": 7,
                "parquet-common/src/main/java/org/apache/parquet/hadoop/metadata/ColumnPath.java": 5,
                "parquet-hadoop/src/main/java/org/apache/parquet/filter2/compat/RowGroupFilter.java": 15,
                "parquet-hadoop/src/main/java/org/apache/parquet/filter2/dictionarylevel/DictionaryFilter.java": 8,
                "parquet-hadoop/src/main/java/org/apache/parquet/filter2/statisticslevel/StatisticsFilter.java": 7,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/DirectCodecFactory.java": 7,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/InternalParquetRecordReader.java": 4,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/InternalParquetRecordWriter.java": 4,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/MemoryManager.java": 6,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ParquetOutputFormat.java": 6,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ParquetReader.java": 15,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ParquetRecordWriter.java": 7,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/api/WriteSupport.java": 15,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/example/GroupWriteSupport.java": 6,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/metadata/FileMetaData.java": 9,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/metadata/GlobalMetaData.java": 9,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/util/HadoopStreams.java": 6,
                "parquet-thrift/src/main/java/org/apache/parquet/thrift/ConvertedField.java": 10,
                "parquet-thrift/src/main/java/org/apache/parquet/thrift/ThriftParquetReader.java": 11,
                "parquet-thrift/src/main/java/org/apache/parquet/thrift/ThriftSchemaConvertVisitor.java": 5,
                "parquet-thrift/src/main/java/org/apache/parquet/thrift/projection/deprecated/DeprecatedFieldProjectionFilter.java": 4
            },
            "is_test": false,
            "is_fix": false
        },
        "438cb3c761daf8d916a85c8742fb321905a07df8": {
            "datetime": "2020-01-26T21:11:26+01:00",
            "summary": "PARQUET-1749: Use Java 8 Streams for Empty PrimitiveIterator (#734)",
            "message": "PARQUET-1749: Use Java 8 Streams for Empty PrimitiveIterator (#734)\n\n",
            "diff": {
                "parquet-column/src/main/java/org/apache/parquet/internal/column/columnindex/IndexIterator.java": 13
            },
            "is_test": false,
            "is_fix": false
        },
        "184965087fb320d4a5f5849d27b365420a3ef1a0": {
            "datetime": "2020-02-03T14:56:51+01:00",
            "summary": "PARQUET-1737: Replace Test Class RandomStr with Apache Commons Lang (#725)",
            "message": "PARQUET-1737: Replace Test Class RandomStr with Apache Commons Lang (#725)\n\n",
            "diff": {
                "parquet-column/src/test/java/org/apache/parquet/column/values/RandomStr.java": 51,
                "parquet-column/src/test/java/org/apache/parquet/column/values/Utils.java": 12
            },
            "is_test": false,
            "is_fix": false
        },
        "17bef40022cb9830101cff4893c9054d2d7ddce6": {
            "datetime": "2020-02-10T13:34:41+01:00",
            "summary": "PARQUET-1782: Use Switch Statement in AvroRecordConverter (#752)",
            "message": "PARQUET-1782: Use Switch Statement in AvroRecordConverter (#752)\n\n* PARQUET-1782: Use Switch Statement in AvroRecordConverter\r\n\r\n* Changed Datum Class Initialization\r\n",
            "diff": {
                "parquet-avro/src/main/java/org/apache/parquet/avro/AvroRecordConverter.java": 70
            },
            "is_test": false,
            "is_fix": false
        },
        "3bbf66c2551bb9cc36b6a41d4b3820cd9fc72c77": {
            "datetime": "2020-02-12T12:38:19+01:00",
            "summary": "PARQUET-1622: Add implementation for BYTE_STREAM_SPLIT (#705)",
            "message": "PARQUET-1622: Add implementation for BYTE_STREAM_SPLIT (#705)\n\nThe patch adds an implementation and tests for the\r\nBYTE_STREAM_SPLIT encoding.",
            "diff": {
                "parquet-column/src/main/java/org/apache/parquet/column/Encoding.java": 16,
                "parquet-column/src/main/java/org/apache/parquet/column/ParquetProperties.java": 22,
                "parquet-column/src/main/java/org/apache/parquet/column/values/bytestreamsplit/ByteStreamSplitValuesReader.java": 100,
                "parquet-column/src/main/java/org/apache/parquet/column/values/bytestreamsplit/ByteStreamSplitValuesReaderForDouble.java": 37,
                "parquet-column/src/main/java/org/apache/parquet/column/values/bytestreamsplit/ByteStreamSplitValuesReaderForFloat.java": 37,
                "parquet-column/src/main/java/org/apache/parquet/column/values/bytestreamsplit/ByteStreamSplitValuesWriter.java": 142,
                "parquet-column/src/main/java/org/apache/parquet/column/values/factory/DefaultV1ValuesWriterFactory.java": 15,
                "parquet-column/src/main/java/org/apache/parquet/column/values/factory/DefaultV2ValuesWriterFactory.java": 15,
                "parquet-column/src/test/java/org/apache/parquet/column/values/bytestreamsplit/ByteStreamSplitValuesEndToEndTest.java": 111,
                "parquet-column/src/test/java/org/apache/parquet/column/values/bytestreamsplit/ByteStreamSplitValuesReaderTest.java": 193,
                "parquet-column/src/test/java/org/apache/parquet/column/values/bytestreamsplit/ByteStreamSplitValuesWriterTest.java": 189,
                "parquet-column/src/test/java/org/apache/parquet/column/values/factory/DefaultValuesWriterFactoryTest.java": 122,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ParquetWriter.java": 5
            },
            "is_test": true,
            "is_fix": false
        },
        "57f6b46dde5926cc602c583940dd6424f10b9a17": {
            "datetime": "2020-02-12T12:55:07+01:00",
            "summary": "PARQUET-1790: Add Api for writing DataPageV2 to ParquetFileWriter class (#756)",
            "message": "PARQUET-1790: Add Api for writing DataPageV2 to ParquetFileWriter class (#756)\n\n\r\n",
            "diff": {
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ParquetFileWriter.java": 74,
                "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/TestParquetFileWriter.java": 83
            },
            "is_test": true,
            "is_fix": false
        },
        "1eaf16df379c7f1951a50360d09af3b12eb16815": {
            "datetime": "2020-02-17T10:07:18+01:00",
            "summary": "PARQUET-1794: Random data generation may cause flaky tests (#758)",
            "message": "PARQUET-1794: Random data generation may cause flaky tests (#758)\n\n",
            "diff": {
                "parquet-column/src/test/java/org/apache/parquet/FixedBinaryTestUtils.java": 96,
                "parquet-hadoop/src/test/java/org/apache/parquet/filter2/dictionarylevel/DictionaryFilterTest.java": 9,
                "parquet-hadoop/src/test/java/org/apache/parquet/format/converter/TestParquetMetadataConverter.java": 5,
                "parquet-hadoop/src/test/java/org/apache/parquet/statistics/RandomValues.java": 3
            },
            "is_test": true,
            "is_fix": true
        },
        "583063b47c2495ebcd4d87c9234faf5e3838dec5": {
            "datetime": "2020-02-24T09:35:52+01:00",
            "summary": "PARQUET-1802: Use job ClassLoader to load CompressionCodec class (#760)",
            "message": "PARQUET-1802: Use job ClassLoader to load CompressionCodec class (#760)\n\nThe MR job might be having a different ClassLoader then\r\nthe defining ClassLoader of the CodecFactory class.\r\nA CompressionCodec class that is not loadable via the\r\nCodecFactory ClassLoader might be loadable through the\r\njob ClassLoader.",
            "diff": {
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/CodecFactory.java": 8
            },
            "is_test": false,
            "is_fix": false
        },
        "a0c9e696d424d4289653cba5d6b1e70b25ae96be": {
            "datetime": "2020-02-25T10:53:13+01:00",
            "summary": "PARQUET-1791: Add 'prune' command to parquet-tools (#755)",
            "message": "PARQUET-1791: Add 'prune' command to parquet-tools (#755)\n\n\r\n",
            "diff": {
                "parquet-tools/src/main/java/org/apache/parquet/tools/command/PruneColumnsCommand.java": 168,
                "parquet-tools/src/main/java/org/apache/parquet/tools/command/Registry.java": 1,
                "parquet-tools/src/test/java/org/apache/parquet/tools/command/TestPruneColumnsCommand.java": 255
            },
            "is_test": true,
            "is_fix": false
        },
        "e3afb24a235bcfa6f8cb1335ed4ca34c46c38e96": {
            "datetime": "2020-02-25T14:25:04+01:00",
            "summary": "PARQUET-1759: InternalParquetRecordReader Use Singleton Set (#743)",
            "message": "PARQUET-1759: InternalParquetRecordReader Use Singleton Set (#743)\n\n",
            "diff": {
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/InternalParquetRecordReader.java": 7
            },
            "is_test": false,
            "is_fix": false
        },
        "7469e87dc63c0f672be7175946dc7af1219ec732": {
            "datetime": "2020-02-26T11:30:27+01:00",
            "summary": "PARQUET-1784: Column-wise configuration (#754)",
            "message": "PARQUET-1784: Column-wise configuration (#754)\n\n",
            "diff": {
                "parquet-column/src/main/java/org/apache/parquet/column/ColumnProperty.java": 137,
                "parquet-column/src/main/java/org/apache/parquet/column/ParquetProperties.java": 88,
                "parquet-column/src/main/java/org/apache/parquet/column/values/factory/DefaultValuesWriterFactory.java": 2,
                "parquet-column/src/test/java/org/apache/parquet/column/values/factory/DefaultValuesWriterFactoryTest.java": 110,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ColumnConfigParser.java": 72,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ParquetOutputFormat.java": 22,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ParquetWriter.java": 12
            },
            "is_test": true,
            "is_fix": false
        },
        "806037c080dc477798d157cd4a54a81240a85d37": {
            "datetime": "2020-02-26T14:18:36+01:00",
            "summary": "PARQUET-41: Add bloom filter  (#757)",
            "message": "PARQUET-41: Add bloom filter  (#757)\n\n* PARQUET-1328: Add Bloom filter reader and writer (#587)\r\n* PARQUET-1516: Store Bloom filters near to footer (#608)\r\n* PARQUET-1391: Integrate Bloom filter logic (#619)\r\n* PARQUET-1660: align Bloom filter implementation with format (#686)\r\n",
            "diff": {
                "parquet-column/src/main/java/org/apache/parquet/column/ParquetProperties.java": 100,
                "parquet-column/src/main/java/org/apache/parquet/column/impl/ColumnWriteStoreBase.java": 39,
                "parquet-column/src/main/java/org/apache/parquet/column/impl/ColumnWriteStoreV1.java": 13,
                "parquet-column/src/main/java/org/apache/parquet/column/impl/ColumnWriteStoreV2.java": 13,
                "parquet-column/src/main/java/org/apache/parquet/column/impl/ColumnWriterBase.java": 80,
                "parquet-column/src/main/java/org/apache/parquet/column/impl/ColumnWriterV1.java": 6,
                "parquet-column/src/main/java/org/apache/parquet/column/impl/ColumnWriterV2.java": 12,
                "parquet-column/src/main/java/org/apache/parquet/column/values/bloomfilter/BlockSplitBloomFilter.java": 382,
                "parquet-column/src/main/java/org/apache/parquet/column/values/bloomfilter/BloomFilter.java": 171,
                "parquet-column/src/main/java/org/apache/parquet/column/values/bloomfilter/BloomFilterWriteStore.java": 35,
                "parquet-column/src/main/java/org/apache/parquet/column/values/bloomfilter/BloomFilterWriter.java": 31,
                "parquet-column/src/main/java/org/apache/parquet/column/values/bloomfilter/HashFunction.java": 41,
                "parquet-column/src/main/java/org/apache/parquet/column/values/bloomfilter/XxHash.java": 40,
                "parquet-column/src/test/java/org/apache/parquet/column/values/bloomfilter/TestBlockSplitBloomFilter.java": 229,
                "parquet-format-structures/src/main/java/org/apache/parquet/format/Util.java": 8,
                "parquet-hadoop/src/main/java/org/apache/parquet/HadoopReadOptions.java": 9,
                "parquet-hadoop/src/main/java/org/apache/parquet/ParquetReadOptions.java": 21,
                "parquet-hadoop/src/main/java/org/apache/parquet/filter2/bloomfilterlevel/BloomFilterImpl.java": 150,
                "parquet-hadoop/src/main/java/org/apache/parquet/filter2/compat/RowGroupFilter.java": 16,
                "parquet-hadoop/src/main/java/org/apache/parquet/format/converter/ParquetMetadataConverter.java": 39,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/BloomFilterReader.java": 70,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ColumnChunkPageWriteStore.java": 18,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/InternalParquetRecordWriter.java": 11,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ParquetFileReader.java": 50,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ParquetFileWriter.java": 66,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ParquetInputFormat.java": 11,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ParquetOutputFormat.java": 53,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ParquetReader.java": 16,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ParquetWriter.java": 36,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/metadata/ColumnChunkMetaData.java": 25,
                "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/TestBloomFiltering.java": 257,
                "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/TestColumnChunkPageWriteStore.java": 1,
                "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/TestParquetFileWriter.java": 42,
                "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/TestParquetWriter.java": 54
            },
            "is_test": true,
            "is_fix": false
        },
        "d69192809d0d5ec36c0d8c126c8bed09ee3cee35": {
            "datetime": "2020-02-28T15:22:34+01:00",
            "summary": "PARQUET-1803 Could not find FilleInputSplit in ParquetInputSplit (#761)",
            "message": "PARQUET-1803 Could not find FilleInputSplit in ParquetInputSplit (#761)\n\n",
            "diff": {
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ParquetInputSplit.java": 8
            },
            "is_test": false,
            "is_fix": false
        },
        "ab65823ae0fd6c3afae94c7fa0670cf9b46b5b85": {
            "datetime": "2020-03-09T12:52:39+01:00",
            "summary": "[PARQUET-1808]: Replacing multiple String Object creations with StringBuilder (#766)",
            "message": "[PARQUET-1808]: Replacing multiple String Object creations with StringBuilder (#766)\n\n",
            "diff": {
                "parquet-column/src/main/java/org/apache/parquet/example/data/simple/SimpleGroup.java": 38,
                "parquet-column/src/main/java/org/apache/parquet/io/MessageColumnIO.java": 12,
                "parquet-column/src/test/java/org/apache/parquet/io/ExpectationValidatingConverter.java": 14,
                "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/TestInputFormat.java": 14
            },
            "is_test": true,
            "is_fix": true
        },
        "7ddfb4d9d89fc7ae1d9ea0ef86aaa6dd5e81aa59": {
            "datetime": "2020-03-30T10:51:25+02:00",
            "summary": "PARQUET-1805: Refactor the configuration for bloom filters (#763)",
            "message": "PARQUET-1805: Refactor the configuration for bloom filters (#763)\n\n",
            "diff": {
                "parquet-column/src/main/java/org/apache/parquet/column/ParquetProperties.java": 90,
                "parquet-column/src/main/java/org/apache/parquet/column/impl/ColumnWriteStoreBase.java": 2,
                "parquet-column/src/main/java/org/apache/parquet/column/impl/ColumnWriterBase.java": 23,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ParquetOutputFormat.java": 48,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ParquetWriter.java": 57,
                "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/TestBloomFiltering.java": 12,
                "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/TestParquetWriter.java": 2
            },
            "is_test": true,
            "is_fix": false
        },
        "5d2bf2789041fc8ff6de48a590775aafe4457db3": {
            "datetime": "2020-03-31T09:27:11+02:00",
            "summary": "PARQUET-1743: Add equals API to BloomFilter interface (#773)",
            "message": "PARQUET-1743: Add equals API to BloomFilter interface (#773)\n\n",
            "diff": {
                "parquet-column/src/main/java/org/apache/parquet/column/values/bloomfilter/BlockSplitBloomFilter.java": 15,
                "parquet-column/src/main/java/org/apache/parquet/column/values/bloomfilter/BloomFilter.java": 8,
                "parquet-column/src/test/java/org/apache/parquet/column/values/bloomfilter/TestBlockSplitBloomFilter.java": 20
            },
            "is_test": true,
            "is_fix": false
        },
        "d00b2f105f9f732e310ed43c7bfb318213e1ac81": {
            "datetime": "2020-04-01T11:49:46+02:00",
            "summary": "PARQUET-1821: Add 'column-size' command to parquet-cli and parquet-tools (#774)",
            "message": "PARQUET-1821: Add 'column-size' command to parquet-cli and parquet-tools (#774)\n\n",
            "diff": {
                "parquet-cli/src/main/java/org/apache/parquet/cli/Main.java": 2,
                "parquet-cli/src/main/java/org/apache/parquet/cli/commands/ColumnSizeCommand.java": 137,
                "parquet-cli/src/test/java/org/apache/parquet/cli/commands/ColumnSizeCommandTest.java": 91,
                "parquet-cli/src/test/java/org/apache/parquet/cli/commands/ParquetFileTest.java": 8,
                "parquet-tools/src/main/java/org/apache/parquet/tools/command/ColumnSizeCommand.java": 121,
                "parquet-tools/src/main/java/org/apache/parquet/tools/command/Registry.java": 1,
                "parquet-tools/src/test/java/org/apache/parquet/tools/command/TestColumnSizeCommand.java": 95
            },
            "is_test": true,
            "is_fix": false
        },
        "49e862704e7da7149493a953ccc18515d1eada88": {
            "datetime": "2020-04-11T09:01:27+02:00",
            "summary": "PARQUET-1599: Fix to-avro to respect the overwrite option (#650)",
            "message": "PARQUET-1599: Fix to-avro to respect the overwrite option (#650)\n\n* PARQUET-1599: Fix to-avro to respect the overwrite option\r\n\r\n* Address the same problem on SchemaCommand\r\n\r\n* Remove unused variables\r\n\r\n* Consolidate redundant try clauses",
            "diff": {
                "parquet-cli/src/main/java/org/apache/parquet/cli/BaseCommand.java": 24,
                "parquet-cli/src/main/java/org/apache/parquet/cli/commands/SchemaCommand.java": 11,
                "parquet-cli/src/main/java/org/apache/parquet/cli/commands/ToAvroCommand.java": 15,
                "parquet-cli/src/test/java/org/apache/parquet/cli/commands/AvroFileTest.java": 23,
                "parquet-cli/src/test/java/org/apache/parquet/cli/commands/SchemaCommandTest.java": 30,
                "parquet-cli/src/test/java/org/apache/parquet/cli/commands/ToAvroCommandTest.java": 19
            },
            "is_test": true,
            "is_fix": true
        },
        "2d7b63bc0ca6a8224d3a9d9a61bd4c12b0edb66d": {
            "datetime": "2020-04-15T14:55:11+02:00",
            "summary": "PARQUET-1832: Travis fails with too long output (#777)",
            "message": "PARQUET-1832: Travis fails with too long output (#777)\n\n",
            "diff": {
                "parquet-hadoop/src/test/java/org/apache/parquet/statistics/TestStatistics.java": 9
            },
            "is_test": true,
            "is_fix": false
        },
        "70d7f5249042bcc02bd6d9a4c8748f38823bd8a9": {
            "datetime": "2020-04-22T09:31:07+02:00",
            "summary": "PARQUET-1844: Eliminate using commons-lang (#787)",
            "message": "PARQUET-1844: Eliminate using commons-lang (#787)\n\n",
            "diff": {
                "parquet-cascading-common23/src/main/java/org/apache/parquet/cascading/TupleReadSupport.java": 9,
                "parquet-cli/src/main/java/org/apache/parquet/cli/commands/ParquetMetadataCommand.java": 4,
                "parquet-cli/src/main/java/org/apache/parquet/cli/commands/ShowPagesCommand.java": 4,
                "parquet-cli/src/main/java/org/apache/parquet/cli/csv/CSVProperties.java": 17,
                "parquet-hadoop/src/test/java/org/apache/parquet/filter2/dictionarylevel/DictionaryFilterTest.java": 5
            },
            "is_test": true,
            "is_fix": false
        },
        "3db93ea7b1e2a806bcbf395bc6b74754cb676c44": {
            "datetime": "2020-04-22T12:16:27+02:00",
            "summary": "PARQUET-1826: Document Hadoop configuration options (#781)",
            "message": "PARQUET-1826: Document Hadoop configuration options (#781)\n\n",
            "diff": {
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/MemoryManager.java": 4,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ParquetOutputFormat.java": 4
            },
            "is_test": false,
            "is_fix": false
        },
        "783c3b78aac41fc69e29ae5679dd8cdb1b38b568": {
            "datetime": "2020-04-26T11:44:39+02:00",
            "summary": "PARQUET-1763: Add SLF4J to TestCircularReferences (#746)",
            "message": "PARQUET-1763: Add SLF4J to TestCircularReferences (#746)\n\nCo-authored-by: David Mollitor <dmollitor@apache.org>",
            "diff": {
                "parquet-avro/src/test/java/org/apache/parquet/avro/TestCircularReferences.java": 6
            },
            "is_test": true,
            "is_fix": false
        },
        "94f89aad513521d4f15df034ec054dbde49c5ede": {
            "datetime": "2020-05-07T17:55:40+02:00",
            "summary": "PARQUET-1750: Reduce Memory Usage of RowRanges Class (#735)",
            "message": "PARQUET-1750: Reduce Memory Usage of RowRanges Class (#735)\n\n* PARQUET-1750: Reduce Memory Usage of RowRanges Class\r\n\r\n* Remove pre-initialized size constructor and add List constructor\r\n\r\nCo-authored-by: David Mollitor <dmollitor@apache.org>",
            "diff": {
                "parquet-column/src/main/java/org/apache/parquet/internal/filter2/columnindex/RowRanges.java": 44
            },
            "is_test": false,
            "is_fix": false
        },
        "a2459b68941cd1eefb3169e80004e1af434b2a80": {
            "datetime": "2020-05-07T17:57:17+02:00",
            "summary": "PARQUET-1728: Simplify NullPointerException Handling in AvroWriteSupport (#716)",
            "message": "PARQUET-1728: Simplify NullPointerException Handling in AvroWriteSupport (#716)\n\n* PARQUET-1728: Simplify NullPointerException Handling in AvroWriteSupport\r\n\r\n* Fixed issue whereby a Collection was being wrapped and not an Array\r\n\r\nCo-authored-by: David Mollitor <dmollitor@apache.org>",
            "diff": {
                "parquet-avro/src/main/java/org/apache/parquet/avro/AvroWriteSupport.java": 40
            },
            "is_test": false,
            "is_fix": false
        },
        "c6c553b412ac2fb9ad641803e918ddf5220cc757": {
            "datetime": "2020-05-07T17:58:41+02:00",
            "summary": "PARQUET-1775: Deprecate AvroParquetWriter Builder Hadoop Path (#750)",
            "message": "PARQUET-1775: Deprecate AvroParquetWriter Builder Hadoop Path (#750)\n\nCo-authored-by: David Mollitor <dmollitor@apache.org>",
            "diff": {
                "parquet-avro/src/main/java/org/apache/parquet/avro/AvroParquetWriter.java": 8
            },
            "is_test": false,
            "is_fix": false
        },
        "0acade062893cc0ac6e8cb7ed01470c38ea4bdb5": {
            "datetime": "2020-06-01T10:25:28-07:00",
            "summary": "PARQUET-1850: Fix dictionaryPageOffset flag setting in toParquetMetadata method",
            "message": "PARQUET-1850: Fix dictionaryPageOffset flag setting in toParquetMetadata method\n\n### Issue\n\ntoParquetMetadata method converts org.apache.parquet.hadoop.metadata.ParquetMetadata to org.apache.parquet.format.FileMetaData but this does not set the dictionary page offset bit in FileMetaData.\n\nWhen a FileMetaData object is serialized while writing to the footer and then deserialized, the dictionary offset is lost as the dictionary page offset bit was never set.\n\n### Fix\n\nThe flag is set to true when a dictionary page is used for encoding.\n\n### Tests\n\nA ParquetMetadata object is created with PLAIN_DICTIONARY encoding and dictionaryPageOffset is set to a non zero value.\n\nThe ParquetMetadata object is converted to FileMetaData using toParquetMetadata method.\nThe FileMetaData object is then serialized and deserialized to FileMetaData and converted back to ParquetMetadata using fromParquetMetadata method.\n\nThe new ParquetMetadata should have the same dictionaryPageOffset as the original ParquetMetadata object.\n\nAuthor: srinivasst <srinivasstxd@gmail.com>\n\nCloses #789 from srinivasst/ParquetConverterFix and squashes the following commits:\n\ne3d867e6 [srinivasst] Set dictionary page offset flag while setting the page offset\n79471854 [srinivasst] Fix dictionary flag setting in toParquetMetadata method in ParquetMetadataConverter class\n",
            "diff": {
                "parquet-hadoop/src/main/java/org/apache/parquet/format/converter/ParquetMetadataConverter.java": 4,
                "parquet-hadoop/src/test/java/org/apache/parquet/format/converter/TestParquetMetadataConverter.java": 90
            },
            "is_test": true,
            "is_fix": true
        },
        "1c63c9392db49ec7922b459677e51196178fac8e": {
            "datetime": "2020-06-02T09:45:07+02:00",
            "summary": "PARQUET-1868: Fix bloom filter toggle in reader options builder (#795)",
            "message": "PARQUET-1868: Fix bloom filter toggle in reader options builder (#795)\n\n",
            "diff": {
                "parquet-hadoop/src/main/java/org/apache/parquet/ParquetReadOptions.java": 2
            },
            "is_test": false,
            "is_fix": false
        },
        "958ed6fa8aeb4bfbb10b98c3cd6117473c69f30e": {
            "datetime": "2020-06-02T18:10:28+02:00",
            "summary": "PARQUET-1684: Do not store default protobuf values as null for proto3 (#702)",
            "message": "PARQUET-1684: Do not store default protobuf values as null for proto3 (#702)\n\nCo-authored-by: Priyank Bagrecha <pbagrecha@roku.com>",
            "diff": {
                "parquet-protobuf/src/main/java/org/apache/parquet/proto/ProtoWriteSupport.java": 74,
                "parquet-protobuf/src/test/java/org/apache/parquet/proto/ProtoInputOutputFormatTest.java": 294,
                "parquet-protobuf/src/test/java/org/apache/parquet/proto/ProtoWriteSupportTest.java": 50,
                "parquet-protobuf/src/test/java/org/apache/parquet/proto/TestUtils.java": 30
            },
            "is_test": true,
            "is_fix": true
        },
        "dc40b598a003dc8da38cadd576c9a36ece1eea1f": {
            "datetime": "2020-06-03T09:17:15+02:00",
            "summary": "PARQUET-1866: Replace Hadoop ZSTD with JNI-ZSTD (#793)",
            "message": "PARQUET-1866: Replace Hadoop ZSTD with JNI-ZSTD (#793)\n\n",
            "diff": {
                "parquet-common/src/main/java/org/apache/parquet/hadoop/metadata/CompressionCodecName.java": 2,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/CodecFactory.java": 4,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/codec/ZstandardCodec.java": 112,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/codec/ZstdCompressorStream.java": 62,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/codec/ZstdDecompressorStream.java": 47,
                "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/TestZstandardCodec.java": 167,
                "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/example/TestInputOutputFormat.java": 1
            },
            "is_test": true,
            "is_fix": false
        },
        "84c954d8a4feef2d9bdad7a236a7268ef71a1c25": {
            "datetime": "2020-06-04T08:56:31+02:00",
            "summary": "PARQUET-1827: UUID type currently not supported by parquet-mr (#778)",
            "message": "PARQUET-1827: UUID type currently not supported by parquet-mr (#778)\n\n",
            "diff": {
                "parquet-avro/src/main/java/org/apache/parquet/avro/AvroConverters.java": 16,
                "parquet-avro/src/main/java/org/apache/parquet/avro/AvroRecordConverter.java": 15,
                "parquet-avro/src/main/java/org/apache/parquet/avro/AvroSchemaConverter.java": 34,
                "parquet-avro/src/main/java/org/apache/parquet/avro/AvroWriteSupport.java": 33,
                "parquet-avro/src/test/java/org/apache/parquet/avro/AvroTestUtil.java": 21,
                "parquet-avro/src/test/java/org/apache/parquet/avro/TestAvroSchemaConverter.java": 32,
                "parquet-avro/src/test/java/org/apache/parquet/avro/TestGenericLogicalTypes.java": 49,
                "parquet-avro/src/test/java/org/apache/parquet/avro/TestReflectLogicalTypes.java": 309,
                "parquet-column/src/main/java/org/apache/parquet/schema/LogicalTypeAnnotation.java": 44,
                "parquet-column/src/main/java/org/apache/parquet/schema/PrimitiveStringifier.java": 27,
                "parquet-column/src/main/java/org/apache/parquet/schema/PrimitiveType.java": 7,
                "parquet-column/src/main/java/org/apache/parquet/schema/Types.java": 45,
                "parquet-column/src/test/java/org/apache/parquet/schema/TestPrimitiveStringifier.java": 39,
                "parquet-column/src/test/java/org/apache/parquet/schema/TestTypeBuildersWithLogicalTypes.java": 14,
                "parquet-hadoop/src/main/java/org/apache/parquet/format/converter/ParquetMetadataConverter.java": 15,
                "parquet-hadoop/src/test/java/org/apache/parquet/format/converter/TestParquetMetadataConverter.java": 3,
                "parquet-hadoop/src/test/java/org/apache/parquet/statistics/TestColumnIndexes.java": 4
            },
            "is_test": true,
            "is_fix": false
        },
        "e4988f3489663b99ff35a8573bab5522d5e6dcf8": {
            "datetime": "2020-06-23T11:40:04+02:00",
            "summary": "Parquet-1872: Add TransCompression command to parquet-tools (#796)",
            "message": "Parquet-1872: Add TransCompression command to parquet-tools (#796)\n\n",
            "diff": {
                "parquet-cli/src/main/java/org/apache/parquet/cli/commands/TransCompressionCommand.java": 96,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ParquetFileReader.java": 2,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/util/CompressionConverter.java": 271,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/util/H1SeekableInputStream.java": 2,
                "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/util/CompressionConveterTest.java": 319,
                "parquet-tools/src/main/java/org/apache/parquet/tools/command/TransCompressionCommand.java": 92
            },
            "is_test": true,
            "is_fix": false
        },
        "00b42d5000499244c8403ca536821b19d5d216ae": {
            "datetime": "2020-06-30T11:49:30+02:00",
            "summary": "Parquet-1872: Add TransCompression command to parquet-tools - Add the command to registry to complete (#799)",
            "message": "Parquet-1872: Add TransCompression command to parquet-tools - Add the command to registry to complete (#799)\n\n",
            "diff": {
                "parquet-cli/src/main/java/org/apache/parquet/cli/Main.java": 2,
                "parquet-tools/src/main/java/org/apache/parquet/tools/command/Registry.java": 1
            },
            "is_test": false,
            "is_fix": false
        },
        "2589cc821d2d470be1e79b86f511eb1f5fee4e5c": {
            "datetime": "2020-07-06T09:32:37+02:00",
            "summary": "PARQUET-1879: MapKeyValue is not a valid Logical Type (#798)",
            "message": "PARQUET-1879: MapKeyValue is not a valid Logical Type (#798)\n\n* Writing UNKNOWN logical type into the schema, causes a breakage\r\n  when parsing the file with Apache Arrow\r\n* Instead use the default, of falling back to null when that\r\n  backwards-compatibility only logical type is present, but still\r\n  write the original type",
            "diff": {
                "parquet-avro/src/test/java/org/apache/parquet/avro/TestAvroSchemaConverter.java": 10,
                "parquet-avro/src/test/java/org/apache/parquet/avro/TestReadWrite.java": 4,
                "parquet-column/src/main/java/org/apache/parquet/schema/ConversionPatterns.java": 5,
                "parquet-column/src/main/java/org/apache/parquet/schema/Types.java": 8,
                "parquet-column/src/test/java/org/apache/parquet/schema/TestTypeBuilders.java": 56,
                "parquet-hadoop/src/main/java/org/apache/parquet/format/converter/ParquetMetadataConverter.java": 7,
                "parquet-hadoop/src/test/java/org/apache/parquet/format/converter/TestParquetMetadataConverter.java": 105,
                "parquet-hive/parquet-hive-storage-handler/src/test/java/org/apache/hadoop/hive/ql/io/parquet/TestHiveSchemaConverter.java": 10,
                "parquet-pig/src/main/java/org/apache/parquet/pig/PigSchemaConverter.java": 3,
                "parquet-pig/src/test/java/org/apache/parquet/pig/TestPigSchemaConverter.java": 20,
                "parquet-pig/src/test/java/org/apache/parquet/pig/TestTupleRecordConsumer.java": 10,
                "parquet-thrift/src/test/java/org/apache/parquet/hadoop/thrift/TestThriftToParquetFileWriter.java": 22,
                "parquet-thrift/src/test/java/org/apache/parquet/thrift/TestParquetWriteProtocol.java": 30,
                "parquet-thrift/src/test/java/org/apache/parquet/thrift/TestThriftSchemaConverter.java": 8,
                "parquet-thrift/src/test/java/org/apache/parquet/thrift/TestThriftSchemaConverterProjectUnion.java": 12
            },
            "is_test": true,
            "is_fix": true
        }
    },
    "2020-07-20T15:17:05-07:00": {
        "fadbe6ef326faa5984d4d8d6df581a91c8c6cca2": {
            "datetime": "2020-07-22T22:05:38+02:00",
            "summary": "Parquet-1860: Add missing Builder Class to ProtoParquetWriter Class (#791)",
            "message": "Parquet-1860: Add missing Builder Class to ProtoParquetWriter Class (#791)\n\n* Add missing Builder support\r\n\r\nProtoParquetWriter only has basic constructors, that which call deprecated super constructors. We cannot set many other options (Write mode, encoding etc) as well. Extended the ParquetWriter.Builder class for builder support.\r\n\r\n* Add import for OutputFile\r\n\r\nParquet-1860 checks failed due ambiguous constructor. Added a missing import, and proceed to recheck.\r\n\r\n* Add Configuration import\r\n\r\nAdded missing import of class Configuration",
            "diff": {
                "parquet-protobuf/src/main/java/org/apache/parquet/proto/ProtoParquetWriter.java": 39
            },
            "is_test": false,
            "is_fix": false
        },
        "9a1fbc4ee3f63284a675eeac6c62e96ffc973575": {
            "datetime": "2020-07-22T22:06:50+02:00",
            "summary": "PARQUET-1778: Do Not Consider Class for Avro Generic Record Reader (#751)",
            "message": "PARQUET-1778: Do Not Consider Class for Avro Generic Record Reader (#751)\n\n",
            "diff": {
                "parquet-avro/src/main/java/org/apache/parquet/avro/AvroParquetReader.java": 32,
                "parquet-avro/src/test/java/org/apache/parquet/avro/TestReadWrite.java": 46
            },
            "is_test": true,
            "is_fix": false
        },
        "65b95fb72be8f5a8a193a6f7bc4560fdcd742fc7": {
            "datetime": "2020-07-29T09:52:54+02:00",
            "summary": "PARQUET-1884: Encryption branch merge in master (#800)",
            "message": "PARQUET-1884: Encryption branch merge in master (#800)\n\n* PARQUET-1228: Format Structures encryption (#613)\r\n* PARQUET-1286: Crypto package (#614)\r\n* PARQUET-1818: Fix bloom/encryption collision in format-structures (#771)\r\n* PARQUET-1817: Crypto Properties Factory (#769)\r\n* PARQUET-1229: Parquet MR encryption (#776)\r\n* PARQUET-1807: Encryption: Interop and Function test suite for Java version (#782)\r\n* PARQUET-1373: Encryption key tools (#615)\r\n\r\nCo-authored-by: shangxinli <31421745+shangxinli@users.noreply.github.com>\r\nCo-authored-by: Maya Anderson <mayaa@il.ibm.com>",
            "diff": {
                "parquet-column/src/main/java/org/apache/parquet/internal/column/columnindex/OffsetIndex.java": 7,
                "parquet-column/src/main/java/org/apache/parquet/internal/column/columnindex/OffsetIndexBuilder.java": 6,
                "parquet-format-structures/src/main/java/org/apache/parquet/format/BlockCipher.java": 67,
                "parquet-format-structures/src/main/java/org/apache/parquet/format/Util.java": 236,
                "parquet-hadoop/src/main/java/org/apache/parquet/HadoopReadOptions.java": 32,
                "parquet-hadoop/src/main/java/org/apache/parquet/ParquetReadOptions.java": 19,
                "parquet-hadoop/src/main/java/org/apache/parquet/crypto/AADPrefixVerifier.java": 32,
                "parquet-hadoop/src/main/java/org/apache/parquet/crypto/AesCipher.java": 158,
                "parquet-hadoop/src/main/java/org/apache/parquet/crypto/AesCtrDecryptor.java": 128,
                "parquet-hadoop/src/main/java/org/apache/parquet/crypto/AesCtrEncryptor.java": 98,
                "parquet-hadoop/src/main/java/org/apache/parquet/crypto/AesGcmDecryptor.java": 119,
                "parquet-hadoop/src/main/java/org/apache/parquet/crypto/AesGcmEncryptor.java": 84,
                "parquet-hadoop/src/main/java/org/apache/parquet/crypto/AesMode.java": 35,
                "parquet-hadoop/src/main/java/org/apache/parquet/crypto/ColumnDecryptionProperties.java": 104,
                "parquet-hadoop/src/main/java/org/apache/parquet/crypto/ColumnEncryptionProperties.java": 186,
                "parquet-hadoop/src/main/java/org/apache/parquet/crypto/DecryptionKeyRetriever.java": 39,
                "parquet-hadoop/src/main/java/org/apache/parquet/crypto/DecryptionPropertiesFactory.java": 88,
                "parquet-hadoop/src/main/java/org/apache/parquet/crypto/EncryptionPropertiesFactory.java": 93,
                "parquet-hadoop/src/main/java/org/apache/parquet/crypto/FileDecryptionProperties.java": 254,
                "parquet-hadoop/src/main/java/org/apache/parquet/crypto/FileEncryptionProperties.java": 278,
                "parquet-hadoop/src/main/java/org/apache/parquet/crypto/InternalColumnDecryptionSetup.java": 74,
                "parquet-hadoop/src/main/java/org/apache/parquet/crypto/InternalColumnEncryptionSetup.java": 82,
                "parquet-hadoop/src/main/java/org/apache/parquet/crypto/InternalFileDecryptor.java": 315,
                "parquet-hadoop/src/main/java/org/apache/parquet/crypto/InternalFileEncryptor.java": 196,
                "parquet-hadoop/src/main/java/org/apache/parquet/crypto/KeyAccessDeniedException.java": 39,
                "parquet-hadoop/src/main/java/org/apache/parquet/crypto/ModuleCipherFactory.java": 73,
                "parquet-hadoop/src/main/java/org/apache/parquet/crypto/ParquetCipher.java": 42,
                "parquet-hadoop/src/main/java/org/apache/parquet/crypto/ParquetCryptoRuntimeException.java": 42,
                "parquet-hadoop/src/main/java/org/apache/parquet/crypto/TagVerificationException.java": 39,
                "parquet-hadoop/src/main/java/org/apache/parquet/crypto/keytools/FileKeyMaterialStore.java": 72,
                "parquet-hadoop/src/main/java/org/apache/parquet/crypto/keytools/FileKeyUnwrapper.java": 173,
                "parquet-hadoop/src/main/java/org/apache/parquet/crypto/keytools/FileKeyWrapper.java": 158,
                "parquet-hadoop/src/main/java/org/apache/parquet/crypto/keytools/HadoopFSKeyMaterialStore.java": 133,
                "parquet-hadoop/src/main/java/org/apache/parquet/crypto/keytools/KeyMaterial.java": 210,
                "parquet-hadoop/src/main/java/org/apache/parquet/crypto/keytools/KeyMetadata.java": 130,
                "parquet-hadoop/src/main/java/org/apache/parquet/crypto/keytools/KeyToolkit.java": 372,
                "parquet-hadoop/src/main/java/org/apache/parquet/crypto/keytools/KmsClient.java": 72,
                "parquet-hadoop/src/main/java/org/apache/parquet/crypto/keytools/PropertiesDrivenCryptoFactory.java": 227,
                "parquet-hadoop/src/main/java/org/apache/parquet/crypto/keytools/RemoteKmsClient.java": 229,
                "parquet-hadoop/src/main/java/org/apache/parquet/crypto/keytools/TwoLevelCacheWithExpiration.java": 105,
                "parquet-hadoop/src/main/java/org/apache/parquet/format/converter/ParquetMetadataConverter.java": 374,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ColumnChunkPageReadStore.java": 131,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ColumnChunkPageWriteStore.java": 165,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ColumnIndexFilterUtils.java": 5,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/DictionaryPageReader.java": 19,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/InternalParquetRecordWriter.java": 10,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ParquetFileReader.java": 275,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ParquetFileWriter.java": 249,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ParquetOutputFormat.java": 24,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ParquetReader.java": 18,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ParquetRecordReader.java": 2,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ParquetWriter.java": 28,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/metadata/BlockMetaData.java": 20,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/metadata/ColumnChunkMetaData.java": 166,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/metadata/FileMetaData.java": 11,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/util/HadoopInputFile.java": 4,
                "parquet-hadoop/src/test/java/org/apache/parquet/crypto/DecryptionKeyRetrieverMock.java": 41,
                "parquet-hadoop/src/test/java/org/apache/parquet/crypto/DecryptionPropertiesFactoryTest.java": 43,
                "parquet-hadoop/src/test/java/org/apache/parquet/crypto/EncryptionPropertiesFactoryTest.java": 45,
                "parquet-hadoop/src/test/java/org/apache/parquet/crypto/SampleDecryptionPropertiesFactory.java": 57,
                "parquet-hadoop/src/test/java/org/apache/parquet/crypto/SampleEncryptionPropertiesFactory.java": 58,
                "parquet-hadoop/src/test/java/org/apache/parquet/crypto/SingleRow.java": 139,
                "parquet-hadoop/src/test/java/org/apache/parquet/crypto/TestPropertiesDrivenEncryption.java": 647,
                "parquet-hadoop/src/test/java/org/apache/parquet/crypto/keytools/mocks/InMemoryKMS.java": 123,
                "parquet-hadoop/src/test/java/org/apache/parquet/crypto/keytools/samples/VaultClient.java": 169,
                "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/TestBloomFiltering.java": 114,
                "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/TestColumnIndexFiltering.java": 122,
                "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/TestEncryptionOptions.java": 680
            },
            "is_test": true,
            "is_fix": false
        },
        "5a7c0fe15869f1a3da9790851b988cfd743a8004": {
            "datetime": "2020-07-29T15:35:20+02:00",
            "summary": "PARQUET-1891: encryption fixes (#805)",
            "message": "PARQUET-1891: encryption fixes (#805)\n\n",
            "diff": {
                "parquet-hadoop/src/test/java/org/apache/parquet/crypto/keytools/samples/VaultClient.java": 3
            },
            "is_test": false,
            "is_fix": false
        },
        "4bf67a4ee7199a317a36b3ad1207408c5f8a12f4": {
            "datetime": "2020-07-30T09:06:18+02:00",
            "summary": "PARQUET-1890: Upgrade to Apache Avro 1.10.0 (#806)",
            "message": "PARQUET-1890: Upgrade to Apache Avro 1.10.0 (#806)\n\n",
            "diff": {
                "parquet-avro/src/test/java/org/apache/parquet/avro/TestReadWrite.java": 6,
                "parquet-avro/src/test/java/org/apache/parquet/avro/TestStringBehavior.java": 26
            },
            "is_test": true,
            "is_fix": false
        },
        "3d45fd5480b1b58074c5b53d0738774cf355d11e": {
            "datetime": "2020-08-25T11:33:11+02:00",
            "summary": "PARQUET-1455: [parquet-protobuf] Handle protobuf enum schema evolution and unknown enum value (#561)",
            "message": "PARQUET-1455: [parquet-protobuf] Handle protobuf enum schema evolution and unknown enum value (#561)\n\nProtobuf can set enum field using number, while a number does not\r\nmatch any enum value defined in the schema, it is still accepted\r\nand a label \"UNKNOWN_ENUM_<enumName>_<number>\" is generated when\r\nwe use protobuf reflection API (proto descriptors) to access it.\r\nAnd in parquet-protobuf, we rely on protobuf reflection API to\r\nconvert forward/backward between the two world.\r\n\r\nThere are two cases of unknown enum while using parquet-protobuf:\r\n  1. Protobuf already contains unknown enum when we write it to\r\n  parquet (eg1. sometmes people set enum fields using numbers; eg2\r\n  writer deserialize data from wire and the sender can have a newer\r\n  version of proto schema with new enum values). The behavior of\r\n  parquet-protobuf writer as before this patch is to write a label\r\n  \"UNKNOWN_ENUM_<number>\" as string in the enum column of parquet.\r\n  And when we read it back as protobuf, we found this unknown label\r\n  which does not match any enum def (even with the same schema as\r\n  the sender in eg2)\r\n  2. Protobuf contains valid value when write to parquet, but the\r\n  reader uses an outdated proto schema which misses some enum\r\n  values. So the not-in-old-schema enum values are \"unknown\" to the\r\n  reader.\r\n\r\nPrevious behavior of parquet-proto reader is to reject in both\r\ncases with some runtime exception.\r\n\r\nTo be able to handle the problems:\r\nWe keep enum (name -> number) mapping in the parquet metadata, so\r\nthat in read time, reader can discover the number and use protobuf\r\nreflection API to set enum number.\r\nKeep in mind though, for the case reading enum with outdated schema\r\n(case 2), the enum read back will have the right number, but the\r\nlabel is set to \"UNKNOW_ENUM_<number>\". So this feature is helpful\r\nonly if the user is using number to manipulate enum data.\r\nAnd for old data containing \"true\" unknown value (thus case 1)\r\ncreated before this patch (thus name -> number mapping is not\r\navailable), we now try to parse the string regarding to the\r\n\"UNKNOWN_ENUM_<number>\" pattern.\r\nIf we read old data created before this patch (thus name -> number\r\nis not available), with an outdated schema, and we find some enum\r\nvalue not defined in the schema nor following \"UNKNOWN_ENUM_*\"\r\npattern, we could either fail the job by raising an exception or\r\ntreat the value as unknown enum with number -1, by setting a flag\r\nin the configuration.\r\n\r\nThe name -> number mapping is a new metadata under the\r\n\"parquet.proto.enum\" namespace. The metadata for protobuf enum\r\n(label:number) mapping should follow some specific pattern, throw\r\nBadConfigurationException in read time if it is not.\r\n\r\nTests for enum schema evolution (read/write with different protobuf\r\nschema) are added.\r\n",
            "diff": {
                "parquet-protobuf/src/main/java/org/apache/parquet/proto/ProtoConstants.java": 40,
                "parquet-protobuf/src/main/java/org/apache/parquet/proto/ProtoMessageConverter.java": 114,
                "parquet-protobuf/src/main/java/org/apache/parquet/proto/ProtoReadSupport.java": 8,
                "parquet-protobuf/src/main/java/org/apache/parquet/proto/ProtoRecordConverter.java": 31,
                "parquet-protobuf/src/main/java/org/apache/parquet/proto/ProtoRecordMaterializer.java": 13,
                "parquet-protobuf/src/main/java/org/apache/parquet/proto/ProtoWriteSupport.java": 54,
                "parquet-protobuf/src/test/java/org/apache/parquet/proto/ProtoRecordConverterTest.java": 25,
                "parquet-protobuf/src/test/java/org/apache/parquet/proto/ProtoSchemaEvolutionTest.java": 68,
                "parquet-protobuf/src/test/java/org/apache/parquet/proto/TestUtils.java": 48
            },
            "is_test": true,
            "is_fix": true
        },
        "0a4e3eea991f7588c9c5e056e9d7b32a76eed5da": {
            "datetime": "2020-10-05T11:39:52+02:00",
            "summary": "PARQUET-313: Implement 3 level list writing rule for Parquet-Thrift (#222)",
            "message": "PARQUET-313: Implement 3 level list writing rule for Parquet-Thrift (#222)\n\n",
            "diff": {
                "parquet-scrooge/src/main/java/org/apache/parquet/scrooge/ScroogeReadSupport.java": 16,
                "parquet-thrift/src/main/java/org/apache/parquet/hadoop/thrift/AbstractThriftWriteSupport.java": 9,
                "parquet-thrift/src/main/java/org/apache/parquet/hadoop/thrift/ParquetThriftBytesOutputFormat.java": 41,
                "parquet-thrift/src/main/java/org/apache/parquet/hadoop/thrift/TBaseWriteSupport.java": 6,
                "parquet-thrift/src/main/java/org/apache/parquet/hadoop/thrift/ThriftBytesWriteSupport.java": 37,
                "parquet-thrift/src/main/java/org/apache/parquet/hadoop/thrift/ThriftReadSupport.java": 22,
                "parquet-thrift/src/main/java/org/apache/parquet/hadoop/thrift/ThriftToParquetFileWriter.java": 4,
                "parquet-thrift/src/main/java/org/apache/parquet/thrift/ParquetWriteProtocol.java": 145,
                "parquet-thrift/src/main/java/org/apache/parquet/thrift/ThriftSchemaConvertVisitor.java": 44,
                "parquet-thrift/src/main/java/org/apache/parquet/thrift/ThriftSchemaConverter.java": 25,
                "parquet-thrift/src/test/java/org/apache/parquet/hadoop/thrift/TestThriftToParquetFileWriter.java": 83,
                "parquet-thrift/src/test/java/org/apache/parquet/thrift/TestParquetWriteProtocol.java": 176,
                "parquet-thrift/src/test/java/org/apache/parquet/thrift/TestThriftParquetReaderWriter.java": 16
            },
            "is_test": true,
            "is_fix": false
        },
        "0d09be68c289a56e9e547949a3d1ee6df10ef794": {
            "datetime": "2020-10-12T10:22:32+02:00",
            "summary": "PARQUET-1920: Fix Parquet writer's memory check interval calculation (#824)",
            "message": "PARQUET-1920: Fix Parquet writer's memory check interval calculation (#824)\n\nFix Parquet writer's memory check interval calculation, and throw helpful message while dealing with too large column chunks.",
            "diff": {
                "parquet-common/src/main/java/org/apache/parquet/bytes/BytesInput.java": 13,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/InternalParquetRecordWriter.java": 14
            },
            "is_test": false,
            "is_fix": false
        },
        "bc4c97253b51811de4e1c18a3f4113172f37e7f3": {
            "datetime": "2020-10-21T22:12:27+02:00",
            "summary": "PARQUET-1924: Do not Instantiate a New LongHashFunction (#827)",
            "message": "PARQUET-1924: Do not Instantiate a New LongHashFunction (#827)\n\n",
            "diff": {
                "parquet-column/src/main/java/org/apache/parquet/column/values/bloomfilter/XxHash.java": 4
            },
            "is_test": false,
            "is_fix": false
        },
        "05605840dc6f45bbdb9ff9d730d5cbf996747454": {
            "datetime": "2020-10-21T22:14:52+02:00",
            "summary": "PARQUET-1910 fix broken cli (#814)",
            "message": "PARQUET-1910 fix broken cli (#814)\n\nCo-authored-by: Grisha Weintraub <grisha.weintraub@ibm.com>",
            "diff": {
                "parquet-cli/src/main/java/org/apache/parquet/cli/commands/TransCompressionCommand.java": 10,
                "parquet-cli/src/test/java/org/apache/parquet/cli/MainTest.java": 34,
                "parquet-cli/src/test/java/org/apache/parquet/cli/commands/TransCompressionCommandTest.java": 45
            },
            "is_test": true,
            "is_fix": true
        },
        "0dc3fbcae56e467f143848ea6ef31ed75bda88f2": {
            "datetime": "2020-10-22T10:23:43+02:00",
            "summary": "PARQUET-1528:  Add JSON support to `parquet-tools head` (#829)",
            "message": "PARQUET-1528:  Add JSON support to `parquet-tools head` (#829)\n\nReplace usage of deprecated OptionBuilder",
            "diff": {
                "parquet-tools/src/main/java/org/apache/parquet/tools/command/HeadCommand.java": 35
            },
            "is_test": false,
            "is_fix": false
        },
        "bebd309db3d4014eadbc9f0d9f6be87c0aec6ded": {
            "datetime": "2020-10-22T16:19:30+02:00",
            "summary": "PARQUET-1893: H2SeekableInputStream readFully() doesn't respect start and len (#807)",
            "message": "PARQUET-1893: H2SeekableInputStream readFully() doesn't respect start and len (#807)\n\n",
            "diff": {
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/util/H2SeekableInputStream.java": 2
            },
            "is_test": false,
            "is_fix": false
        },
        "14b7a8be8ac98c7f96fc3fd2d5c21cbddf736b64": {
            "datetime": "2020-10-22T16:54:29+02:00",
            "summary": "PARQUET-1917: Don't write values for oneOf fields that aren't set (#820)",
            "message": "PARQUET-1917: Don't write values for oneOf fields that aren't set (#820)\n\n",
            "diff": {
                "parquet-protobuf/src/main/java/org/apache/parquet/proto/ProtoWriteSupport.java": 6,
                "parquet-protobuf/src/test/java/org/apache/parquet/proto/ProtoWriteSupportTest.java": 63
            },
            "is_test": true,
            "is_fix": true
        },
        "472eebb09d035e5073c384c319ba549f74d79691": {
            "datetime": "2020-10-22T16:57:05+02:00",
            "summary": "PARQUET-1914: Allow ProtoParquetReader To Support InputFile (#817)",
            "message": "PARQUET-1914: Allow ProtoParquetReader To Support InputFile (#817)\n\n",
            "diff": {
                "parquet-protobuf/src/main/java/org/apache/parquet/proto/ProtoParquetReader.java": 36,
                "parquet-protobuf/src/test/java/org/apache/parquet/proto/TestUtils.java": 7
            },
            "is_test": true,
            "is_fix": false
        },
        "c6187e8d50a241ff83bb364526658d5ddce34b34": {
            "datetime": "2020-11-12T17:01:33+01:00",
            "summary": "PARQUET-1940: KEK length configuration (#838)",
            "message": "PARQUET-1940: KEK length configuration (#838)\n\n",
            "diff": {
                "parquet-hadoop/src/main/java/org/apache/parquet/crypto/keytools/FileKeyWrapper.java": 13,
                "parquet-hadoop/src/main/java/org/apache/parquet/crypto/keytools/KeyToolkit.java": 6
            },
            "is_test": false,
            "is_fix": false
        },
        "2908cffca9a91d5a5d12c25755ff4b8bcf51ac89": {
            "datetime": "2020-11-12T17:03:20+01:00",
            "summary": "PARQUET-1939: Fix remote KMS client ambiguity (#841)",
            "message": "PARQUET-1939: Fix remote KMS client ambiguity (#841)\n\n",
            "diff": {
                "parquet-hadoop/src/main/java/org/apache/parquet/crypto/keytools/KeyToolkit.java": 10,
                "parquet-hadoop/src/main/java/org/apache/parquet/crypto/keytools/RemoteKmsClient.java": 120,
                "parquet-hadoop/src/test/java/org/apache/parquet/crypto/TestPropertiesDrivenEncryption.java": 12,
                "parquet-hadoop/src/test/java/org/apache/parquet/crypto/keytools/mocks/InMemoryKMS.java": 19,
                "parquet-hadoop/src/test/java/org/apache/parquet/crypto/keytools/mocks/LocalWrapInMemoryKMS.java": 79,
                "parquet-hadoop/src/test/java/org/apache/parquet/crypto/keytools/samples/VaultClient.java": 52
            },
            "is_test": true,
            "is_fix": false
        },
        "d291d05f1c9e3ee5ab87403d94cf13a5ab9cb04d": {
            "datetime": "2020-11-12T17:03:43+01:00",
            "summary": "PARQUET-1938: Key rotation - option to get KMS details from key material (#842)",
            "message": "PARQUET-1938: Key rotation - option to get KMS details from key material (#842)\n\n",
            "diff": {
                "parquet-hadoop/src/main/java/org/apache/parquet/crypto/keytools/FileKeyUnwrapper.java": 15,
                "parquet-hadoop/src/main/java/org/apache/parquet/crypto/keytools/FileKeyWrapper.java": 32,
                "parquet-hadoop/src/main/java/org/apache/parquet/crypto/keytools/HadoopFSKeyMaterialStore.java": 6,
                "parquet-hadoop/src/main/java/org/apache/parquet/crypto/keytools/KeyToolkit.java": 32
            },
            "is_test": false,
            "is_fix": false
        },
        "89c5c25d44f8959d1a66493c06630ab0060cf346": {
            "datetime": "2020-11-12T17:05:33+01:00",
            "summary": "PARQUET-1915: Add nullify column (#819)",
            "message": "PARQUET-1915: Add nullify column (#819)\n\n",
            "diff": {
                "parquet-cli/src/main/java/org/apache/parquet/cli/Main.java": 3,
                "parquet-cli/src/main/java/org/apache/parquet/cli/commands/ColumnMaskingCommand.java": 110,
                "parquet-column/src/main/java/org/apache/parquet/column/ColumnWriter.java": 1,
                "parquet-column/src/main/java/org/apache/parquet/column/impl/ColumnWriterBase.java": 1,
                "parquet-column/src/test/java/org/apache/parquet/io/TestColumnIO.java": 1,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ColumnChunkPageWriteStore.java": 4,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ParquetFileWriter.java": 40,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/util/ColumnMasker.java": 242,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/util/CompressionConverter.java": 7,
                "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/util/ColumnMaskerTest.java": 223,
                "parquet-tools/src/main/java/org/apache/parquet/tools/command/ColumnMaskingCommand.java": 96,
                "parquet-tools/src/main/java/org/apache/parquet/tools/command/PruneColumnsCommand.java": 2,
                "parquet-tools/src/main/java/org/apache/parquet/tools/command/Registry.java": 1
            },
            "is_test": true,
            "is_fix": false
        },
        "5c6916c23cb2b9c225ea80328550ee0e11aee225": {
            "datetime": "2020-11-13T13:22:29-08:00",
            "summary": "PARQUET-1396: Example of using EncryptionPropertiesFactory and DecryptionPropertiesFactory (#808)",
            "message": "PARQUET-1396: Example of using EncryptionPropertiesFactory and DecryptionPropertiesFactory (#808)\n\n* Parquet-1396: Example of using EncryptionPropertiesFactory and DecryptionPropertiesFactory\r\n\r\n* Address feedbacks\r\n\r\n* Remove ExtType and add metadata to Type directly\r\n\r\n* Use Configuration to pass the setting\r\n\r\n* Address feedback\r\n\r\n* Replace file.toString() with file.getPath()\r\n\r\n* Address feedback\r\n\r\n* fix build error\r\n\r\n* Address more feedbacks",
            "diff": {
                "parquet-benchmarks/src/main/java/org/apache/parquet/benchmarks/NestedNullWritingBenchmarks.java": 5,
                "parquet-common/src/main/java/org/apache/parquet/io/OutputFile.java": 1,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ParquetOutputFormat.java": 4,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ParquetWriter.java": 5,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/util/HadoopOutputFile.java": 5,
                "parquet-hadoop/src/test/java/org/apache/parquet/crypto/propertiesfactory/SchemaControlEncryptionTest.java": 251,
                "parquet-hadoop/src/test/java/org/apache/parquet/crypto/propertiesfactory/SchemaCryptoPropertiesFactory.java": 137,
                "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/TestColumnChunkPageWriteStore.java": 5
            },
            "is_test": true,
            "is_fix": false
        },
        "bea6b669d8ff66d938efbefcd7efd5a3d0d8801c": {
            "datetime": "2020-12-07T10:47:07+01:00",
            "summary": "PARQUET-1928: Interpret Parquet INT96 type as FIXED[12] AVRO Schema (#831)",
            "message": "PARQUET-1928: Interpret Parquet INT96 type as FIXED[12] AVRO Schema (#831)\n\n* Add configuration flag to enable reading INT96 as fixed. The flag is defaulted to false to discourage use of INT96.",
            "diff": {
                "parquet-avro/src/main/java/org/apache/parquet/avro/AvroReadSupport.java": 4,
                "parquet-avro/src/main/java/org/apache/parquet/avro/AvroSchemaConverter.java": 11,
                "parquet-avro/src/test/java/org/apache/parquet/avro/TestAvroSchemaConverter.java": 26
            },
            "is_test": true,
            "is_fix": true
        },
        "a6fde11fd11aeb19c4e23a83ee2922b9acec3251": {
            "datetime": "2020-12-07T12:07:21+01:00",
            "summary": "PARQUET-1947: DeprecatedParquetInputFormat in CombineFileInputFormat \u2026 (#844)",
            "message": "PARQUET-1947: DeprecatedParquetInputFormat in CombineFileInputFormat \u2026 (#844)\n\n* PARQUET-1947: DeprecatedParquetInputFormat in CombineFileInputFormat would produce wrong data",
            "diff": {
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/mapred/DeprecatedParquetInputFormat.java": 1,
                "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/DeprecatedInputFormatTest.java": 159
            },
            "is_test": true,
            "is_fix": true
        },
        "10df92187a02180bbc2f7134ba8c83a13063ee3a": {
            "datetime": "2020-12-14T11:30:30+01:00",
            "summary": "PARQUET-1801: Add parquet-tools 'prune' to parquet-cli (#846)",
            "message": "PARQUET-1801: Add parquet-tools 'prune' to parquet-cli (#846)\n\n",
            "diff": {
                "parquet-cli/src/main/java/org/apache/parquet/cli/Main.java": 3,
                "parquet-cli/src/main/java/org/apache/parquet/cli/commands/PruneColumnsCommand.java": 81,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/util/ColumnPruner.java": 126,
                "parquet-tools/src/main/java/org/apache/parquet/tools/command/PruneColumnsCommand.java": 101,
                "parquet-tools/src/test/java/org/apache/parquet/tools/command/TestPruneColumnsCommand.java": 41
            },
            "is_test": true,
            "is_fix": false
        },
        "74af3a8a5404e3a56d3d8d6bf3ebc8c09ff5fa1d": {
            "datetime": "2021-01-05T11:50:16+01:00",
            "summary": "PARQUET-1954: TCP connection leak in parquet dump (#849)",
            "message": "PARQUET-1954: TCP connection leak in parquet dump (#849)\n\n",
            "diff": {
                "parquet-tools/src/main/java/org/apache/parquet/tools/command/DumpCommand.java": 93
            },
            "is_test": false,
            "is_fix": false
        },
        "02170613d12b5122b07149136382a71505fa39d8": {
            "datetime": "2021-01-07T10:44:38+01:00",
            "summary": "PARQUET-1951: Allow merge strategies to combine key values (#847)",
            "message": "PARQUET-1951: Allow merge strategies to combine key values (#847)\n\n",
            "diff": {
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ParquetFileWriter.java": 39,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/metadata/ConcatenatingKeyValueMetadataMergeStrategy.java": 61,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/metadata/GlobalMetaData.java": 28,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/metadata/KeyValueMetadataMergeStrategy.java": 42,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/metadata/StrictKeyValueMetadataMergeStrategy.java": 42,
                "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/TestParquetFileWriter.java": 57,
                "parquet-tools/src/main/java/org/apache/parquet/tools/command/MergeCommand.java": 79
            },
            "is_test": true,
            "is_fix": false
        },
        "2d0742ea586db444b30dd3a682e1dee9351954b0": {
            "datetime": "2021-01-10T19:43:32-08:00",
            "summary": "PARQUET-1949: Mark Parquet-1872 with note support bloom filter yet (#845)",
            "message": "PARQUET-1949: Mark Parquet-1872 with note support bloom filter yet (#845)\n\n",
            "diff": {
                "parquet-cli/src/main/java/org/apache/parquet/cli/commands/TransCompressionCommand.java": 2,
                "parquet-tools/src/main/java/org/apache/parquet/tools/command/TransCompressionCommand.java": 2
            },
            "is_test": false,
            "is_fix": false
        },
        "7f5ff1b13b37ccb0528598a7a58420173f4949f7": {
            "datetime": "2021-01-12T11:37:35+01:00",
            "summary": "PARQUET-1666: Remove/deprecate unused modules (#851)",
            "message": "PARQUET-1666: Remove/deprecate unused modules (#851)\n\n",
            "diff": {
                "parquet-cascading-common23/src/main/java/org/apache/parquet/cascading/SchemaIntersection.java": 0,
                "parquet-cascading-common23/src/main/java/org/apache/parquet/cascading/TupleReadSupport.java": 0,
                "parquet-cascading-common23/src/main/java/org/apache/parquet/cascading/TupleWriteSupport.java": 0,
                "parquet-cascading-common23/src/main/java/org/apache/parquet/cascading/convert/TupleConverter.java": 0,
                "parquet-cascading-common23/src/main/java/org/apache/parquet/cascading/convert/TupleRecordMaterializer.java": 0,
                "parquet-cascading-common23/src/test/java/org/apache/parquet/cascading/TestParquetTupleScheme.java": 0,
                "parquet-cascading/src/main/java/org/apache/parquet/cascading/ParquetTBaseScheme.java": 0,
                "parquet-cascading/src/main/java/org/apache/parquet/cascading/ParquetTupleScheme.java": 0,
                "parquet-cascading/src/main/java/org/apache/parquet/cascading/ParquetValueScheme.java": 0,
                "parquet-cascading/src/test/java/org/apache/parquet/cascading/TestParquetTBaseScheme.java": 0,
                "parquet-cascading3/src/main/java/org/apache/parquet/cascading/ParquetTBaseScheme.java": 0,
                "parquet-cascading3/src/main/java/org/apache/parquet/cascading/ParquetTupleScheme.java": 0,
                "parquet-cascading3/src/main/java/org/apache/parquet/cascading/ParquetValueScheme.java": 0,
                "parquet-cascading3/src/test/java/org/apache/parquet/cascading/TestParquetTBaseScheme.java": 0,
                "parquet-hive/parquet-hive-binding/parquet-hive-0.10-binding/src/main/java/org/apache/parquet/hive/internal/Hive010Binding.java": 167,
                "parquet-hive/parquet-hive-binding/parquet-hive-0.12-binding/src/main/java/org/apache/parquet/hive/internal/Hive012Binding.java": 168,
                "parquet-hive/parquet-hive-binding/parquet-hive-binding-factory/src/main/java/org/apache/parquet/hive/HiveBindingFactory.java": 158,
                "parquet-hive/parquet-hive-binding/parquet-hive-binding-factory/src/test/java/org/apache/parquet/hive/TestHiveBindingFactory.java": 139,
                "parquet-hive/parquet-hive-binding/parquet-hive-binding-interface/src/main/java/org/apache/parquet/hive/HiveBinding.java": 57,
                "parquet-hive/parquet-hive-binding/parquet-hive-binding-interface/src/main/java/org/apache/parquet/hive/internal/AbstractHiveBinding.java": 54,
                "parquet-hive/parquet-hive-storage-handler/src/main/java/org/apache/hadoop/hive/ql/io/IOConstants.java": 29,
                "parquet-hive/parquet-hive-storage-handler/src/main/java/org/apache/hadoop/hive/ql/io/parquet/MapredParquetInputFormat.java": 61,
                "parquet-hive/parquet-hive-storage-handler/src/main/java/org/apache/hadoop/hive/ql/io/parquet/MapredParquetOutputFormat.java": 130,
                "parquet-hive/parquet-hive-storage-handler/src/main/java/org/apache/hadoop/hive/ql/io/parquet/convert/ArrayWritableGroupConverter.java": 90,
                "parquet-hive/parquet-hive-storage-handler/src/main/java/org/apache/hadoop/hive/ql/io/parquet/convert/DataWritableGroupConverter.java": 145,
                "parquet-hive/parquet-hive-storage-handler/src/main/java/org/apache/hadoop/hive/ql/io/parquet/convert/DataWritableRecordConverter.java": 49,
                "parquet-hive/parquet-hive-storage-handler/src/main/java/org/apache/hadoop/hive/ql/io/parquet/convert/ETypeConverter.java": 165,
                "parquet-hive/parquet-hive-storage-handler/src/main/java/org/apache/hadoop/hive/ql/io/parquet/convert/HiveGroupConverter.java": 51,
                "parquet-hive/parquet-hive-storage-handler/src/main/java/org/apache/hadoop/hive/ql/io/parquet/convert/HiveSchemaConverter.java": 137,
                "parquet-hive/parquet-hive-storage-handler/src/main/java/org/apache/hadoop/hive/ql/io/parquet/read/DataWritableReadSupport.java": 156,
                "parquet-hive/parquet-hive-storage-handler/src/main/java/org/apache/hadoop/hive/ql/io/parquet/read/ParquetRecordReaderWrapper.java": 228,
                "parquet-hive/parquet-hive-storage-handler/src/main/java/org/apache/hadoop/hive/ql/io/parquet/serde/AbstractParquetMapInspector.java": 180,
                "parquet-hive/parquet-hive-storage-handler/src/main/java/org/apache/hadoop/hive/ql/io/parquet/serde/ArrayWritableObjectInspector.java": 233,
                "parquet-hive/parquet-hive-storage-handler/src/main/java/org/apache/hadoop/hive/ql/io/parquet/serde/DeepParquetHiveMapInspector.java": 88,
                "parquet-hive/parquet-hive-storage-handler/src/main/java/org/apache/hadoop/hive/ql/io/parquet/serde/ParquetHiveArrayInspector.java": 190,
                "parquet-hive/parquet-hive-storage-handler/src/main/java/org/apache/hadoop/hive/ql/io/parquet/serde/ParquetHiveSerDe.java": 279,
                "parquet-hive/parquet-hive-storage-handler/src/main/java/org/apache/hadoop/hive/ql/io/parquet/serde/StandardParquetHiveMapInspector.java": 65,
                "parquet-hive/parquet-hive-storage-handler/src/main/java/org/apache/hadoop/hive/ql/io/parquet/serde/primitive/ParquetByteInspector.java": 61,
                "parquet-hive/parquet-hive-storage-handler/src/main/java/org/apache/hadoop/hive/ql/io/parquet/serde/primitive/ParquetPrimitiveInspectorFactory.java": 35,
                "parquet-hive/parquet-hive-storage-handler/src/main/java/org/apache/hadoop/hive/ql/io/parquet/serde/primitive/ParquetShortInspector.java": 61,
                "parquet-hive/parquet-hive-storage-handler/src/main/java/org/apache/hadoop/hive/ql/io/parquet/writable/BigDecimalWritable.java": 148,
                "parquet-hive/parquet-hive-storage-handler/src/main/java/org/apache/hadoop/hive/ql/io/parquet/writable/BinaryWritable.java": 98,
                "parquet-hive/parquet-hive-storage-handler/src/main/java/org/apache/hadoop/hive/ql/io/parquet/write/DataWritableWriteSupport.java": 66,
                "parquet-hive/parquet-hive-storage-handler/src/main/java/org/apache/hadoop/hive/ql/io/parquet/write/DataWritableWriter.java": 159,
                "parquet-hive/parquet-hive-storage-handler/src/main/java/org/apache/hadoop/hive/ql/io/parquet/write/ParquetRecordWriterWrapper.java": 98,
                "parquet-hive/parquet-hive-storage-handler/src/main/java/org/apache/hadoop/hive/serde2/objectinspector/primitive/ParquetStringInspector.java": 101,
                "parquet-hive/parquet-hive-storage-handler/src/main/java/org/apache/parquet/hive/DeprecatedParquetInputFormat.java": 42,
                "parquet-hive/parquet-hive-storage-handler/src/main/java/org/apache/parquet/hive/DeprecatedParquetOutputFormat.java": 41,
                "parquet-hive/parquet-hive-storage-handler/src/main/java/org/apache/parquet/hive/MapredParquetInputFormat.java": 41,
                "parquet-hive/parquet-hive-storage-handler/src/main/java/org/apache/parquet/hive/MapredParquetOutputFormat.java": 40,
                "parquet-hive/parquet-hive-storage-handler/src/main/java/org/apache/parquet/hive/serde/ParquetHiveSerDe.java": 30,
                "parquet-hive/parquet-hive-storage-handler/src/test/java/org/apache/hadoop/hive/ql/io/parquet/TestHiveSchemaConverter.java": 143,
                "parquet-hive/parquet-hive-storage-handler/src/test/java/org/apache/hadoop/hive/ql/io/parquet/TestMapredParquetInputFormat.java": 42,
                "parquet-hive/parquet-hive-storage-handler/src/test/java/org/apache/hadoop/hive/ql/io/parquet/TestMapredParquetOutputFormat.java": 95,
                "parquet-hive/parquet-hive-storage-handler/src/test/java/org/apache/hadoop/hive/ql/io/parquet/TestParquetSerDe.java": 145,
                "parquet-hive/parquet-hive-storage-handler/src/test/java/org/apache/hadoop/hive/ql/io/parquet/serde/TestAbstractParquetMapInspector.java": 103,
                "parquet-hive/parquet-hive-storage-handler/src/test/java/org/apache/hadoop/hive/ql/io/parquet/serde/TestDeepParquetHiveMapInspector.java": 95,
                "parquet-hive/parquet-hive-storage-handler/src/test/java/org/apache/hadoop/hive/ql/io/parquet/serde/TestParquetHiveArrayInspector.java": 85,
                "parquet-hive/parquet-hive-storage-handler/src/test/java/org/apache/hadoop/hive/ql/io/parquet/serde/TestStandardParquetHiveMapInspector.java": 93,
                "parquet-scrooge/src/main/java/org/apache/parquet/scrooge/ParquetScroogeInputFormat.java": 0,
                "parquet-scrooge/src/main/java/org/apache/parquet/scrooge/ParquetScroogeOutputFormat.java": 0,
                "parquet-scrooge/src/main/java/org/apache/parquet/scrooge/ParquetScroogeScheme.java": 0,
                "parquet-scrooge/src/main/java/org/apache/parquet/scrooge/ScroogeReadSupport.java": 0,
                "parquet-scrooge/src/main/java/org/apache/parquet/scrooge/ScroogeRecordConverter.java": 0,
                "parquet-scrooge/src/main/java/org/apache/parquet/scrooge/ScroogeSchemaConversionException.java": 0,
                "parquet-scrooge/src/main/java/org/apache/parquet/scrooge/ScroogeStructConverter.java": 0,
                "parquet-scrooge/src/main/java/org/apache/parquet/scrooge/ScroogeWriteSupport.java": 0,
                "parquet-scrooge/src/test/java/org/apache/parquet/scrooge/ParquetScroogeSchemeTest.java": 0,
                "parquet-scrooge/src/test/java/org/apache/parquet/scrooge/ScroogeBinaryTest.java": 0,
                "parquet-scrooge/src/test/java/org/apache/parquet/scrooge/ScroogeStructConverterTest.java": 0,
                "parquet-scrooge/src/test/java/org/apache/parquet/scrooge/TestCorruptScroogeRecords.java": 0,
                "parquet-tools/src/main/java/org/apache/parquet/tools/Main.java": 0,
                "parquet-tools/src/main/java/org/apache/parquet/tools/command/ArgsOnlyCommand.java": 0,
                "parquet-tools/src/main/java/org/apache/parquet/tools/command/CatCommand.java": 0,
                "parquet-tools/src/main/java/org/apache/parquet/tools/command/ColumnIndexCommand.java": 0,
                "parquet-tools/src/main/java/org/apache/parquet/tools/command/ColumnMaskingCommand.java": 0,
                "parquet-tools/src/main/java/org/apache/parquet/tools/command/ColumnSizeCommand.java": 0,
                "parquet-tools/src/main/java/org/apache/parquet/tools/command/Command.java": 0,
                "parquet-tools/src/main/java/org/apache/parquet/tools/command/DumpCommand.java": 0,
                "parquet-tools/src/main/java/org/apache/parquet/tools/command/HeadCommand.java": 0,
                "parquet-tools/src/main/java/org/apache/parquet/tools/command/MergeCommand.java": 0,
                "parquet-tools/src/main/java/org/apache/parquet/tools/command/MetadataUtils.java": 0,
                "parquet-tools/src/main/java/org/apache/parquet/tools/command/PruneColumnsCommand.java": 0,
                "parquet-tools/src/main/java/org/apache/parquet/tools/command/Registry.java": 0,
                "parquet-tools/src/main/java/org/apache/parquet/tools/command/RowCountCommand.java": 0,
                "parquet-tools/src/main/java/org/apache/parquet/tools/command/ShowMetaCommand.java": 0,
                "parquet-tools/src/main/java/org/apache/parquet/tools/command/ShowSchemaCommand.java": 0,
                "parquet-tools/src/main/java/org/apache/parquet/tools/command/SizeCommand.java": 0,
                "parquet-tools/src/main/java/org/apache/parquet/tools/command/TransCompressionCommand.java": 0,
                "parquet-tools/src/main/java/org/apache/parquet/tools/json/JsonRecordFormatter.java": 0,
                "parquet-tools/src/main/java/org/apache/parquet/tools/read/SimpleListRecord.java": 0,
                "parquet-tools/src/main/java/org/apache/parquet/tools/read/SimpleListRecordConverter.java": 0,
                "parquet-tools/src/main/java/org/apache/parquet/tools/read/SimpleMapRecord.java": 0,
                "parquet-tools/src/main/java/org/apache/parquet/tools/read/SimpleMapRecordConverter.java": 0,
                "parquet-tools/src/main/java/org/apache/parquet/tools/read/SimpleReadSupport.java": 0,
                "parquet-tools/src/main/java/org/apache/parquet/tools/read/SimpleRecord.java": 0,
                "parquet-tools/src/main/java/org/apache/parquet/tools/read/SimpleRecordConverter.java": 0,
                "parquet-tools/src/main/java/org/apache/parquet/tools/read/SimpleRecordMaterializer.java": 0,
                "parquet-tools/src/main/java/org/apache/parquet/tools/util/MetadataUtils.java": 0,
                "parquet-tools/src/main/java/org/apache/parquet/tools/util/PrettyPrintWriter.java": 0,
                "parquet-tools/src/test/java/org/apache/parquet/tools/command/TestColumnSizeCommand.java": 0,
                "parquet-tools/src/test/java/org/apache/parquet/tools/read/TestJsonRecordFormatter.java": 0,
                "parquet-tools/src/test/java/org/apache/parquet/tools/read/TestSimpleMapRecord.java": 0,
                "parquet-tools/src/test/java/org/apache/parquet/tools/read/TestSimplePrimitiveRecord.java": 0,
                "parquet-tools/src/test/java/org/apache/parquet/tools/read/TestSimpleRecordConverter.java": 0
            },
            "is_test": true,
            "is_fix": false
        },
        "e465c73d87f0b6ad190d494eea48394950fae759": {
            "datetime": "2021-01-13T13:00:50+01:00",
            "summary": "PARQUET-1851: fix parquet metadata converter NPE (#852)",
            "message": "PARQUET-1851: fix parquet metadata converter NPE (#852)\n\n",
            "diff": {
                "parquet-hadoop/src/main/java/org/apache/parquet/format/converter/ParquetMetadataConverter.java": 72,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ParquetFileWriter.java": 58,
                "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/TestParquetFileWriter.java": 21
            },
            "is_test": true,
            "is_fix": true
        }
    },
    "2021-01-16T15:17:05-07:00": {
        "358a60d17ffd49b718633d505fdb6b77ce64f7a0": {
            "datetime": "2021-01-20T17:02:15+01:00",
            "summary": "PARQUET-1963: DeprecatedParquetInputFormat in CombineFileInputFormat throw NPE when the first sub-split is empty (#854)",
            "message": "PARQUET-1963: DeprecatedParquetInputFormat in CombineFileInputFormat throw NPE when the first sub-split is empty (#854)\n\n",
            "diff": {
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/mapred/DeprecatedParquetInputFormat.java": 2,
                "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/DeprecatedInputFormatTest.java": 10
            },
            "is_test": true,
            "is_fix": true
        },
        "ee30b13bb5c3f6848c76641d3b93c9858e6746cb": {
            "datetime": "2021-01-21T09:46:20+01:00",
            "summary": "PARQUET-1964: Properly handle missing/null filter (#856)",
            "message": "PARQUET-1964: Properly handle missing/null filter (#856)\n\n",
            "diff": {
                "parquet-column/src/main/java/org/apache/parquet/filter2/compat/FilterCompat.java": 11,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/InternalParquetRecordReader.java": 2,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ParquetFileReader.java": 38,
                "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/TestColumnIndexFiltering.java": 4
            },
            "is_test": true,
            "is_fix": false
        },
        "217561a99f2b4b4382f1f2c69fbcd03fd9bbc3ff": {
            "datetime": "2021-01-27T09:57:35+01:00",
            "summary": "PARQUET-1926: Add LogicalType support to ThriftType (#832)",
            "message": "PARQUET-1926: Add LogicalType support to ThriftType (#832)\n\n",
            "diff": {
                "parquet-thrift/src/main/java/org/apache/parquet/thrift/ThriftSchemaConvertVisitor.java": 14,
                "parquet-thrift/src/main/java/org/apache/parquet/thrift/struct/ThriftType.java": 16,
                "parquet-thrift/src/test/java/org/apache/parquet/thrift/TestThriftMetaData.java": 3,
                "parquet-thrift/src/test/java/org/apache/parquet/thrift/TestThriftRecordConverter.java": 3,
                "parquet-thrift/src/test/java/org/apache/parquet/thrift/TestThriftSchemaConvertVisitor.java": 178,
                "parquet-thrift/src/test/java/org/apache/parquet/thrift/struct/TestThriftType.java": 9
            },
            "is_test": true,
            "is_fix": false
        },
        "a187fc757b7dc885423407e527f50cc4ffc4c542": {
            "datetime": "2021-01-27T21:53:20+01:00",
            "summary": "PARQUET-1736: Use StringBuilder instead of StringBuffer (#724)",
            "message": "PARQUET-1736: Use StringBuilder instead of StringBuffer (#724)\n\n",
            "diff": {
                "parquet-column/src/main/java/org/apache/parquet/schema/MessageTypeParser.java": 2
            },
            "is_test": false,
            "is_fix": false
        },
        "e6bca6f72db5b450c074676ac20dae9e33e93695": {
            "datetime": "2021-02-03T09:31:45+01:00",
            "summary": "PARQUET-1964: FOLLOWUP: Avoid constructing useless ArrayList (#855)",
            "message": "PARQUET-1964: FOLLOWUP: Avoid constructing useless ArrayList (#855)\n\n",
            "diff": {
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ParquetFileReader.java": 29
            },
            "is_test": false,
            "is_fix": false
        },
        "e7f9a666f1c55bd4084d49f027eecb745f8fe5ff": {
            "datetime": "2021-02-04T13:10:02+01:00",
            "summary": "PARQUET-1971: Further increase max difference of testMemoryManagerUpperLimit to 15% (#863)",
            "message": "PARQUET-1971: Further increase max difference of testMemoryManagerUpperLimit to 15% (#863)\n\n",
            "diff": {
                "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/TestMemoryManager.java": 12
            },
            "is_test": true,
            "is_fix": true
        },
        "279255df0c050aa95b5f5eb5963cf7eae5b8d180": {
            "datetime": "2021-02-09T09:27:19+01:00",
            "summary": "PARQUET-1973: Support ZSTD JNI BufferPool (#865)",
            "message": "PARQUET-1973: Support ZSTD JNI BufferPool (#865)\n\n",
            "diff": {
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/codec/ZstandardCodec.java": 22,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/codec/ZstdCompressorStream.java": 8,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/codec/ZstdDecompressorStream.java": 6,
                "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/TestZstandardCodec.java": 17
            },
            "is_test": true,
            "is_fix": false
        },
        "3be6273156247a52e295e002bc38217373b68b22": {
            "datetime": "2021-02-10T10:59:53+01:00",
            "summary": "PARQUET-1970: Make minor releases source compatible (#861)",
            "message": "PARQUET-1970: Make minor releases source compatible (#861)\n\n",
            "diff": {
                "parquet-column/src/main/java/org/apache/parquet/internal/column/columnindex/OffsetIndex.java": 6,
                "parquet-common/src/main/java/org/apache/parquet/io/OutputFile.java": 4,
                "parquet-hadoop/src/main/java/org/apache/parquet/crypto/keytools/PropertiesDrivenCryptoFactory.java": 3,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ParquetWriter.java": 5
            },
            "is_test": false,
            "is_fix": false
        },
        "2a23dcaa27adc643a199808773a0feb580b7d8a5": {
            "datetime": "2021-02-17T10:05:36+01:00",
            "summary": "PARQUET-1979: bloom_filter_offset is filled if there are no bloom filters (#869)",
            "message": "PARQUET-1979: bloom_filter_offset is filled if there are no bloom filters (#869)\n\n",
            "diff": {
                "parquet-hadoop/src/main/java/org/apache/parquet/format/converter/ParquetMetadataConverter.java": 9,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ParquetFileReader.java": 2,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/metadata/ColumnChunkMetaData.java": 8,
                "parquet-hadoop/src/test/java/org/apache/parquet/format/converter/TestParquetMetadataConverter.java": 20
            },
            "is_test": true,
            "is_fix": true
        },
        "434667566e140d7ca7e30b568156c43a06cc719f": {
            "datetime": "2021-02-24T12:12:59+01:00",
            "summary": "PARQUET-1984: Allow tests to run on windows (#870)",
            "message": "PARQUET-1984: Allow tests to run on windows (#870)\n\nCheck for \\r\\n lineendings instead of \\n\r\nChange file layout (backslash and slash) to check\r\nClose files / streams before deleting file",
            "diff": {
                "parquet-hadoop/src/test/java/org/apache/parquet/format/converter/TestParquetMetadataConverter.java": 4,
                "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/DeprecatedInputFormatTest.java": 26,
                "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/TestInputFormat.java": 12,
                "parquet-hadoop/src/test/java/org/apache/parquet/statistics/TestStatistics.java": 22,
                "parquet-thrift/src/test/java/org/apache/parquet/hadoop/thrift/TestParquetToThriftReadWriteAndProjection.java": 18,
                "parquet-thrift/src/test/java/org/apache/parquet/thrift/TestThriftMetaData.java": 10,
                "parquet-thrift/src/test/java/org/apache/parquet/thrift/TestThriftRecordConverter.java": 10,
                "parquet-thrift/src/test/java/org/apache/parquet/thrift/struct/TestThriftType.java": 12
            },
            "is_test": true,
            "is_fix": true
        },
        "286b078c0a205e1064e61c2efd5598795d2d8bc9": {
            "datetime": "2021-02-25T10:56:21+01:00",
            "summary": "PARQUET-1977: Invalid data_page_offset (#868)",
            "message": "PARQUET-1977: Invalid data_page_offset (#868)\n\n",
            "diff": {
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/Offsets.java": 92,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ParquetFileWriter.java": 31,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/metadata/ColumnChunkMetaData.java": 3,
                "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/TestParquetFileWriter.java": 24
            },
            "is_test": true,
            "is_fix": true
        },
        "862bac97bf62eb68e2ab3d2911d3b5f95fb6979e": {
            "datetime": "2021-02-26T17:16:50+01:00",
            "summary": "PARQUET-1975: Do not include brotli-codec for ARM64 (#872)",
            "message": "PARQUET-1975: Do not include brotli-codec for ARM64 (#872)\n\n",
            "diff": {
                "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/TestDirectCodecFactory.java": 9
            },
            "is_test": true,
            "is_fix": true
        },
        "d81b815fadc252bddb583d400e6097e56aa6708b": {
            "datetime": "2021-03-11T16:37:45+01:00",
            "summary": "PARQUET-1992: Manually download interop files inside the test and move encryption interop test to maven integration-test phase (#878)",
            "message": "PARQUET-1992: Manually download interop files inside the test and move encryption interop test to maven integration-test phase (#878)\n\n",
            "diff": {
                "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/ITTestEncryptionOptions.java": 50,
                "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/TestEncryptionOptions.java": 69
            },
            "is_test": true,
            "is_fix": true
        },
        "616c3d681c5506ebad83a7d3724e85da2154eac9": {
            "datetime": "2021-03-16T08:34:45-07:00",
            "summary": "PARQUET-1999: NPE might occur if OutputFile is implemented by the client (#881)",
            "message": "PARQUET-1999: NPE might occur if OutputFile is implemented by the client (#881)\n\n",
            "diff": {
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ParquetWriter.java": 3,
                "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/TestParquetWriter.java": 49
            },
            "is_test": true,
            "is_fix": true
        },
        "5608695f5777de1eb0899d9075ec9411cfdf31d3": {
            "datetime": "2021-03-19T11:21:36+01:00",
            "summary": "PARQUET-1978: Provide a tool to show the complete footer (#867)",
            "message": "PARQUET-1978: Provide a tool to show the complete footer (#867)\n\n",
            "diff": {
                "parquet-cli/src/main/java/org/apache/parquet/cli/Main.java": 2,
                "parquet-cli/src/main/java/org/apache/parquet/cli/commands/ShowFooterCommand.java": 144,
                "parquet-cli/src/test/java/org/apache/parquet/cli/commands/ShowFooterCommandTest.java": 43,
                "parquet-format-structures/src/main/java/org/apache/parquet/format/CliUtils.java": 55
            },
            "is_test": true,
            "is_fix": false
        },
        "86240813839f3e15d5c4a0ea56215c616841b6c1": {
            "datetime": "2021-04-01T16:02:43+02:00",
            "summary": "PARQUET-2012 Mark ProtoParquetWriter constructors deprecated (#886)",
            "message": "PARQUET-2012 Mark ProtoParquetWriter constructors deprecated (#886)\n\n",
            "diff": {
                "parquet-protobuf/src/main/java/org/apache/parquet/proto/ProtoParquetWriter.java": 18,
                "parquet-protobuf/src/test/java/org/apache/parquet/proto/TestUtils.java": 14
            },
            "is_test": true,
            "is_fix": false
        },
        "d23a9a79927a03ce6b8e192436c64ad34c36d67b": {
            "datetime": "2021-04-08T22:35:49+02:00",
            "summary": "PARQUET-2005: Upgrade thrift to 0.14.1 (#884)",
            "message": "PARQUET-2005: Upgrade thrift to 0.14.1 (#884)\n\n* PARQUET-2005: Upgrade thrift to 0.14.1\r\n\r\n* PARQUET-2005: Update thrift version in CI scripts and README\r\n\r\n* Update README.md\r\n\r\nCo-authored-by: Fokko Driesprong <fokko@driesprong.frl>\r\n\r\nCo-authored-by: Fokko Driesprong <fokko@driesprong.frl>",
            "diff": {
                "parquet-format-structures/src/main/java/org/apache/parquet/format/CliUtils.java": 2,
                "parquet-format-structures/src/main/java/org/apache/parquet/format/InterningProtocol.java": 5,
                "parquet-format-structures/src/main/java/org/apache/parquet/format/Util.java": 5,
                "parquet-thrift/src/main/java/org/apache/parquet/hadoop/thrift/ThriftBytesWriteSupport.java": 3,
                "parquet-thrift/src/main/java/org/apache/parquet/thrift/BufferedProtocolReadToWrite.java": 5,
                "parquet-thrift/src/main/java/org/apache/parquet/thrift/ParquetProtocol.java": 5,
                "parquet-thrift/src/test/java/org/apache/parquet/thrift/TestProtocolReadToWrite.java": 5
            },
            "is_test": true,
            "is_fix": false
        },
        "3f54ba09c36fec835d91d0ba1abfc4fd6e7fef3f": {
            "datetime": "2021-04-19T09:53:11+02:00",
            "summary": "PARQUET-1982: Random access to row groups in ParquetFileReader (#871)",
            "message": "PARQUET-1982: Random access to row groups in ParquetFileReader (#871)\n\nAdds a method readRowGroup(BlockMetaData) to allow random access to\r\nPageReadStores via BlockMetaData, which can be obtained using the\r\ngetRowGroups() method.\r\n\r\nThis is similar to the existing method\r\ngetDictionaryReader(BlockMetaData)\r\nthat already exists.\r\n\r\nWith random access the reader can be reused if for example someone\r\nneeds to go back a row group. This would improve performance\r\nbecause we don't need to open the file again and read the metadata.\r\n\r\nAdd test for filtered random access\r\nReads all pages of a row group\r\nChecks all columns of a page",
            "diff": {
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ParquetFileReader.java": 163,
                "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/TestParquetReaderRandomAccess.java": 387,
                "parquet-hadoop/src/test/java/org/apache/parquet/statistics/DataGenerationContext.java": 85,
                "parquet-hadoop/src/test/java/org/apache/parquet/statistics/RandomValues.java": 4,
                "parquet-hadoop/src/test/java/org/apache/parquet/statistics/TestStatistics.java": 56
            },
            "is_test": true,
            "is_fix": false
        },
        "8c0840365ab76070da0efc8bfe0559bc4e525e49": {
            "datetime": "2021-04-19T10:22:39+02:00",
            "summary": "PARQUET-2022: ZstdDecompressorStream should close `zstdInputStream` (#889)",
            "message": "PARQUET-2022: ZstdDecompressorStream should close `zstdInputStream` (#889)\n\n",
            "diff": {
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/codec/ZstdDecompressorStream.java": 9,
                "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/TestZstandardCodec.java": 9
            },
            "is_test": true,
            "is_fix": true
        },
        "907314ce317e59e25bbf572e891f7ce2a7c70a54": {
            "datetime": "2021-04-19T17:49:00+02:00",
            "summary": "PARQUET-2020: Remove deprecated modules (#888)",
            "message": "PARQUET-2020: Remove deprecated modules (#888)\n\nRemoves:\r\n\r\n- parquet-tools-deprecated\r\n- parquet-scrooge-deprecated\r\n- parquet-cascading-common23-deprecated\r\n- parquet-cascading-deprecated\r\n- parquet-cascading3-deprecated",
            "diff": {
                "parquet-cascading-common23-deprecated/src/main/java/org/apache/parquet/cascading/SchemaIntersection.java": 63,
                "parquet-cascading-common23-deprecated/src/main/java/org/apache/parquet/cascading/TupleReadSupport.java": 81,
                "parquet-cascading-common23-deprecated/src/main/java/org/apache/parquet/cascading/TupleWriteSupport.java": 106,
                "parquet-cascading-common23-deprecated/src/main/java/org/apache/parquet/cascading/convert/TupleConverter.java": 112,
                "parquet-cascading-common23-deprecated/src/main/java/org/apache/parquet/cascading/convert/TupleRecordMaterializer.java": 46,
                "parquet-cascading-common23-deprecated/src/test/java/org/apache/parquet/cascading/TestParquetTupleScheme.java": 182,
                "parquet-cascading-deprecated/src/main/java/org/apache/parquet/cascading/ParquetTBaseScheme.java": 81,
                "parquet-cascading-deprecated/src/main/java/org/apache/parquet/cascading/ParquetTupleScheme.java": 189,
                "parquet-cascading-deprecated/src/main/java/org/apache/parquet/cascading/ParquetValueScheme.java": 185,
                "parquet-cascading-deprecated/src/test/java/org/apache/parquet/cascading/TestParquetTBaseScheme.java": 187,
                "parquet-cascading3-deprecated/src/main/java/org/apache/parquet/cascading/ParquetTBaseScheme.java": 80,
                "parquet-cascading3-deprecated/src/main/java/org/apache/parquet/cascading/ParquetTupleScheme.java": 190,
                "parquet-cascading3-deprecated/src/main/java/org/apache/parquet/cascading/ParquetValueScheme.java": 192,
                "parquet-cascading3-deprecated/src/test/java/org/apache/parquet/cascading/TestParquetTBaseScheme.java": 185,
                "parquet-scrooge-deprecated/src/main/java/org/apache/parquet/scrooge/ParquetScroogeInputFormat.java": 31,
                "parquet-scrooge-deprecated/src/main/java/org/apache/parquet/scrooge/ParquetScroogeOutputFormat.java": 39,
                "parquet-scrooge-deprecated/src/main/java/org/apache/parquet/scrooge/ParquetScroogeScheme.java": 69,
                "parquet-scrooge-deprecated/src/main/java/org/apache/parquet/scrooge/ScroogeReadSupport.java": 50,
                "parquet-scrooge-deprecated/src/main/java/org/apache/parquet/scrooge/ScroogeRecordConverter.java": 69,
                "parquet-scrooge-deprecated/src/main/java/org/apache/parquet/scrooge/ScroogeSchemaConversionException.java": 36,
                "parquet-scrooge-deprecated/src/main/java/org/apache/parquet/scrooge/ScroogeStructConverter.java": 401,
                "parquet-scrooge-deprecated/src/main/java/org/apache/parquet/scrooge/ScroogeWriteSupport.java": 70,
                "parquet-scrooge-deprecated/src/test/java/org/apache/parquet/scrooge/ParquetScroogeSchemeTest.java": 235,
                "parquet-scrooge-deprecated/src/test/java/org/apache/parquet/scrooge/ScroogeBinaryTest.java": 100,
                "parquet-scrooge-deprecated/src/test/java/org/apache/parquet/scrooge/ScroogeStructConverterTest.java": 184,
                "parquet-scrooge-deprecated/src/test/java/org/apache/parquet/scrooge/TestCorruptScroogeRecords.java": 69,
                "parquet-tools-deprecated/src/main/java/org/apache/parquet/tools/Main.java": 232,
                "parquet-tools-deprecated/src/main/java/org/apache/parquet/tools/command/ArgsOnlyCommand.java": 56,
                "parquet-tools-deprecated/src/main/java/org/apache/parquet/tools/command/CatCommand.java": 103,
                "parquet-tools-deprecated/src/main/java/org/apache/parquet/tools/command/ColumnIndexCommand.java": 182,
                "parquet-tools-deprecated/src/main/java/org/apache/parquet/tools/command/ColumnMaskingCommand.java": 96,
                "parquet-tools-deprecated/src/main/java/org/apache/parquet/tools/command/ColumnSizeCommand.java": 121,
                "parquet-tools-deprecated/src/main/java/org/apache/parquet/tools/command/Command.java": 31,
                "parquet-tools-deprecated/src/main/java/org/apache/parquet/tools/command/DumpCommand.java": 397,
                "parquet-tools-deprecated/src/main/java/org/apache/parquet/tools/command/HeadCommand.java": 121,
                "parquet-tools-deprecated/src/main/java/org/apache/parquet/tools/command/MergeCommand.java": 251,
                "parquet-tools-deprecated/src/main/java/org/apache/parquet/tools/command/MetadataUtils.java": 212,
                "parquet-tools-deprecated/src/main/java/org/apache/parquet/tools/command/PruneColumnsCommand.java": 73,
                "parquet-tools-deprecated/src/main/java/org/apache/parquet/tools/command/Registry.java": 68,
                "parquet-tools-deprecated/src/main/java/org/apache/parquet/tools/command/RowCountCommand.java": 102,
                "parquet-tools-deprecated/src/main/java/org/apache/parquet/tools/command/ShowMetaCommand.java": 95,
                "parquet-tools-deprecated/src/main/java/org/apache/parquet/tools/command/ShowSchemaCommand.java": 109,
                "parquet-tools-deprecated/src/main/java/org/apache/parquet/tools/command/SizeCommand.java": 145,
                "parquet-tools-deprecated/src/main/java/org/apache/parquet/tools/command/TransCompressionCommand.java": 92,
                "parquet-tools-deprecated/src/main/java/org/apache/parquet/tools/json/JsonRecordFormatter.java": 132,
                "parquet-tools-deprecated/src/main/java/org/apache/parquet/tools/read/SimpleListRecord.java": 30,
                "parquet-tools-deprecated/src/main/java/org/apache/parquet/tools/read/SimpleListRecordConverter.java": 34,
                "parquet-tools-deprecated/src/main/java/org/apache/parquet/tools/read/SimpleMapRecord.java": 86,
                "parquet-tools-deprecated/src/main/java/org/apache/parquet/tools/read/SimpleMapRecordConverter.java": 34,
                "parquet-tools-deprecated/src/main/java/org/apache/parquet/tools/read/SimpleReadSupport.java": 41,
                "parquet-tools-deprecated/src/main/java/org/apache/parquet/tools/read/SimpleRecord.java": 153,
                "parquet-tools-deprecated/src/main/java/org/apache/parquet/tools/read/SimpleRecordConverter.java": 188,
                "parquet-tools-deprecated/src/main/java/org/apache/parquet/tools/read/SimpleRecordMaterializer.java": 42,
                "parquet-tools-deprecated/src/main/java/org/apache/parquet/tools/util/MetadataUtils.java": 234,
                "parquet-tools-deprecated/src/main/java/org/apache/parquet/tools/util/PrettyPrintWriter.java": 1035,
                "parquet-tools-deprecated/src/test/java/org/apache/parquet/tools/command/TestColumnSizeCommand.java": 95,
                "parquet-tools-deprecated/src/test/java/org/apache/parquet/tools/read/TestJsonRecordFormatter.java": 231,
                "parquet-tools-deprecated/src/test/java/org/apache/parquet/tools/read/TestSimpleMapRecord.java": 56,
                "parquet-tools-deprecated/src/test/java/org/apache/parquet/tools/read/TestSimplePrimitiveRecord.java": 58,
                "parquet-tools-deprecated/src/test/java/org/apache/parquet/tools/read/TestSimpleRecordConverter.java": 139
            },
            "is_test": true,
            "is_fix": false
        },
        "5d8fe214f16829fe258400d0c68ddaacc979b03a": {
            "datetime": "2021-04-19T17:50:41+02:00",
            "summary": "PARQUET-1448: Review of ParquetFileReader (#892)",
            "message": "PARQUET-1448: Review of ParquetFileReader (#892)\n\nCo-authored-by: David Mollitor <dmollitor@apache.org>",
            "diff": {
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ParquetFileReader.java": 51
            },
            "is_test": false,
            "is_fix": false
        },
        "8e40e69ce3e02cf4f8f0c624ff9e6173509961ee": {
            "datetime": "2021-04-22T09:32:13+02:00",
            "summary": "PARQUET-2030: Expose page size row check configurations to ParquetWriter.Builder (#895)",
            "message": "PARQUET-2030: Expose page size row check configurations to ParquetWriter.Builder (#895)\n\n",
            "diff": {
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ParquetWriter.java": 22,
                "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/TestParquetWriter.java": 47
            },
            "is_test": true,
            "is_fix": false
        },
        "48f5195cfb2662f021e928211687192249752818": {
            "datetime": "2021-04-23T10:05:05-07:00",
            "summary": "[WIP] Refactor GroupReadSupport to unuse deprecated api (#894)",
            "message": "[WIP] Refactor GroupReadSupport to unuse deprecated api (#894)\n\nCo-authored-by: Luan <xuluan@ebay.com>",
            "diff": {
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/example/GroupReadSupport.java": 15,
                "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/example/GroupReadSupportTest.java": 16,
                "parquet-thrift/src/test/java/org/apache/parquet/hadoop/thrift/TestThriftToParquetFileWriter.java": 3
            },
            "is_test": true,
            "is_fix": false
        },
        "2ce35c73746cf091ed223da150daefd323a9ad3a": {
            "datetime": "2021-04-23T10:05:34-07:00",
            "summary": "PARQUET-2027: Fix calculating directory offset for merge (#896)",
            "message": "PARQUET-2027: Fix calculating directory offset for merge (#896)\n\n",
            "diff": {
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/Offsets.java": 8,
                "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/TestParquetWriterAppendBlocks.java": 63
            },
            "is_test": true,
            "is_fix": true
        },
        "10fd78252ea2f7beff8e5af5c6ee2917c9dceca2": {
            "datetime": "2021-04-26T17:25:12+02:00",
            "summary": "Revert \"[WIP] Refactor GroupReadSupport to unuse deprecated api (#894)\"",
            "message": "Revert \"[WIP] Refactor GroupReadSupport to unuse deprecated api (#894)\"\n\nReverting this because it contains backward incompatbile changes.\n\nThis reverts commit 48f5195cfb2662f021e928211687192249752818.\n",
            "diff": {
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/example/GroupReadSupport.java": 15,
                "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/example/GroupReadSupportTest.java": 16,
                "parquet-thrift/src/test/java/org/apache/parquet/hadoop/thrift/TestThriftToParquetFileWriter.java": 3
            },
            "is_test": true,
            "is_fix": false
        },
        "709fce1b72ef894febb1722d746f085b3d1050f8": {
            "datetime": "2021-05-04T14:43:50+02:00",
            "summary": "PARQUET-2038: Upgrade Jackson version used in parquet encryption. (#898)",
            "message": "PARQUET-2038: Upgrade Jackson version used in parquet encryption. (#898)\n\n",
            "diff": {
                "parquet-hadoop/src/main/java/org/apache/parquet/crypto/keytools/HadoopFSKeyMaterialStore.java": 11,
                "parquet-hadoop/src/main/java/org/apache/parquet/crypto/keytools/KeyMaterial.java": 4,
                "parquet-hadoop/src/main/java/org/apache/parquet/crypto/keytools/KeyMetadata.java": 4,
                "parquet-hadoop/src/main/java/org/apache/parquet/crypto/keytools/LocalWrapKmsClient.java": 4,
                "parquet-hadoop/src/test/java/org/apache/parquet/crypto/keytools/samples/VaultClient.java": 4
            },
            "is_test": false,
            "is_fix": false
        },
        "a3a1ad4e58518a469970b45ccef2fb64695c1894": {
            "datetime": "2021-05-11T10:39:39+02:00",
            "summary": "PARQUET-2044: Enable ZSTD buffer pool by default (#903)",
            "message": "PARQUET-2044: Enable ZSTD buffer pool by default (#903)\n\nThis PR aims to enable ZSTD buffer pool by default to improve the performance.\r\nThe default value of config and documentation is updated.\r\n",
            "diff": {
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/codec/ZstandardCodec.java": 2
            },
            "is_test": false,
            "is_fix": false
        },
        "c72862b61399ff516e968fbd02885e573d4be81c": {
            "datetime": "2021-05-12T10:08:05+02:00",
            "summary": "PARQUET-2037: Write INT96 with parquet-avro (#901)",
            "message": "PARQUET-2037: Write INT96 with parquet-avro (#901)\n\n",
            "diff": {
                "parquet-avro/src/main/java/org/apache/parquet/avro/AvroSchemaConverter.java": 70,
                "parquet-avro/src/main/java/org/apache/parquet/avro/AvroWriteSupport.java": 3,
                "parquet-avro/src/test/java/org/apache/parquet/avro/TestAvroSchemaConverter.java": 32
            },
            "is_test": true,
            "is_fix": false
        },
        "19348dc36bd2429fe7b4c34268ab9706bd9a08ca": {
            "datetime": "2021-05-14T10:15:28+02:00",
            "summary": "PARQUET-1922: Deprecate IOExceptionUtils (#825)",
            "message": "PARQUET-1922: Deprecate IOExceptionUtils (#825)\n\n",
            "diff": {
                "parquet-common/src/main/java/org/apache/parquet/IOExceptionUtils.java": 2,
                "parquet-common/src/main/java/org/apache/parquet/bytes/LittleEndianDataOutputStream.java": 9
            },
            "is_test": false,
            "is_fix": false
        },
        "1007b053cceab0db7ed0b3d44b70d5882276eec4": {
            "datetime": "2021-05-17T11:23:27+02:00",
            "summary": "PARQUET-2048: Deprecate BaseRecordReader (#906)",
            "message": "PARQUET-2048: Deprecate BaseRecordReader (#906)\n\n",
            "diff": {
                "parquet-column/src/main/java/org/apache/parquet/io/BaseRecordReader.java": 7
            },
            "is_test": false,
            "is_fix": false
        },
        "875a4bbd82bd47f1d4d68a7e79c80941d8a76f7c": {
            "datetime": "2021-05-18T10:23:03+02:00",
            "summary": "PARQUET-1761: Lower Logging Level in ParquetOutputFormat (#745)",
            "message": "PARQUET-1761: Lower Logging Level in ParquetOutputFormat (#745)\n\n",
            "diff": {
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ParquetOutputFormat.java": 10
            },
            "is_test": false,
            "is_fix": false
        },
        "10794e63326606fe4abf5c726b8fff8683ca6c20": {
            "datetime": "2021-05-19T12:23:59+02:00",
            "summary": "PARQUET-2050: Expose repetition & definition level from ColumnIO (#908)",
            "message": "PARQUET-2050: Expose repetition & definition level from ColumnIO (#908)\n\n",
            "diff": {
                "parquet-column/src/main/java/org/apache/parquet/io/ColumnIO.java": 10
            },
            "is_test": false,
            "is_fix": false
        },
        "8ae7f31e36a298804435565e0cae584aac90f6d5": {
            "datetime": "2021-05-23T20:07:49-07:00",
            "summary": "PARQUET-2041: Add zstd to `parquet.compression` description of ParquetOutputFormat Javadoc (#899)",
            "message": "PARQUET-2041: Add zstd to `parquet.compression` description of ParquetOutputFormat Javadoc (#899)\n\nThe current Javadoc doesn't mention zstd.\r\n\r\nhttps://javadoc.io/doc/org.apache.parquet/parquet-hadoop/latest/org/apache/parquet/hadoop/ParquetOutputFormat.html\r\n\r\nThis PR aims to make Javadoc up-to-date by adding zstd.",
            "diff": {
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ParquetOutputFormat.java": 2
            },
            "is_test": false,
            "is_fix": false
        },
        "819443bc195b58735c7a2489795a219ca662c65e": {
            "datetime": "2021-05-26T09:43:22+02:00",
            "summary": "PARQUET-2052: Integer overflow when writing huge binary using dictionary encoding (#910)",
            "message": "PARQUET-2052: Integer overflow when writing huge binary using dictionary encoding (#910)\n\n",
            "diff": {
                "parquet-column/src/main/java/org/apache/parquet/column/values/dictionary/DictionaryValuesWriter.java": 6,
                "parquet-column/src/test/java/org/apache/parquet/column/values/dictionary/TestDictionary.java": 15
            },
            "is_test": true,
            "is_fix": true
        },
        "98ddadf0b8f283dec7c45937e01233869eac4467": {
            "datetime": "2021-06-11T10:23:48+02:00",
            "summary": "PARQUET-1633: Fix integer overflow (#902)",
            "message": "PARQUET-1633: Fix integer overflow (#902)\n\nUnit test:\r\n- Updated ParquetWriter to support setting row group size in long\r\n- Removed Xmx settings in the pom to allow more memory for the tests\r\n\r\nCo-authored-by: Gabor Szadovszky <gabor@apache.org>",
            "diff": {
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ParquetFileReader.java": 14,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ParquetWriter.java": 16,
                "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/TestLargeColumnChunk.java": 142
            },
            "is_test": true,
            "is_fix": true
        },
        "bab3d53bff84a74743b2f62f5e394cbd9410b31f": {
            "datetime": "2021-06-22T09:52:43+02:00",
            "summary": "PARQUET-2054: fix TCP leaking when calling ParquetFileWriter.appendFile (#913)",
            "message": "PARQUET-2054: fix TCP leaking when calling ParquetFileWriter.appendFile (#913)\n\n* use try-with-resource statement for ParquetFileReader to call close explicitly",
            "diff": {
                "parquet-cli/src/main/java/org/apache/parquet/cli/commands/CheckParquet251Command.java": 6,
                "parquet-cli/src/main/java/org/apache/parquet/cli/commands/SchemaCommand.java": 7,
                "parquet-cli/src/main/java/org/apache/parquet/cli/commands/ShowDictionaryCommand.java": 85,
                "parquet-cli/src/main/java/org/apache/parquet/cli/commands/ShowPagesCommand.java": 94,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ParquetFileWriter.java": 4,
                "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/TestParquetFileWriter.java": 167,
                "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/TestParquetWriter.java": 15,
                "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/TestReadWriteEncodingStats.java": 43
            },
            "is_test": true,
            "is_fix": false
        },
        "c3009c1da0060257554df727ed0c0d448781ce14": {
            "datetime": "2021-06-22T09:58:50+02:00",
            "summary": "PARQUET-2051: Pass Configuration to AvroSchemaConverter as to not lose options (#912)",
            "message": "PARQUET-2051: Pass Configuration to AvroSchemaConverter as to not lose options (#912)\n\n",
            "diff": {
                "parquet-avro/src/main/java/org/apache/parquet/avro/AvroWriteSupport.java": 2,
                "parquet-avro/src/test/java/org/apache/parquet/avro/TestAvroWriteSupport.java": 61
            },
            "is_test": true,
            "is_fix": true
        }
    },
    "2021-07-15T15:17:05-07:00": {
        "18df2ca255ccafa189dc70fa194214cab926a919": {
            "datetime": "2021-08-04T08:59:55+02:00",
            "summary": "PARQUET-2070: replace deprecated syntax in ProtoWriteSupport.java (#919)",
            "message": "PARQUET-2070: replace deprecated syntax in ProtoWriteSupport.java (#919)\n\n",
            "diff": {
                "parquet-protobuf/src/main/java/org/apache/parquet/proto/ProtoWriteSupport.java": 8
            },
            "is_test": false,
            "is_fix": false
        },
        "d5924226007031b6aee8c94c577f9b9eaa037554": {
            "datetime": "2021-08-09T17:21:04+02:00",
            "summary": "PARQUET-2072: Do Not Determine Both Min/Max for Binary Stats (#920)",
            "message": "PARQUET-2072: Do Not Determine Both Min/Max for Binary Stats (#920)\n\n",
            "diff": {
                "parquet-column/src/main/java/org/apache/parquet/column/statistics/BinaryStatistics.java": 10
            },
            "is_test": false,
            "is_fix": false
        },
        "b2fdd888133ddd82bddf82aa0836697506e24f55": {
            "datetime": "2021-08-09T08:30:50-07:00",
            "summary": "PARQUET-2064: Make Range public accessible in RowRanges (#918)",
            "message": "PARQUET-2064: Make Range public accessible in RowRanges (#918)\n\n* PARQUET-2064: Make Range public accessible in RowRanges\r\n\r\n* Add comments\r\n\r\n* Move RowRange out of internal folder\r\n\r\n* Revert \"Move RowRange out of internal folder\"\r\n\r\nThis reverts commit 4f49c044aca816ff844ff8634de73244fd77cd44.",
            "diff": {
                "parquet-column/src/main/java/org/apache/parquet/internal/filter2/columnindex/RowRanges.java": 11
            },
            "is_test": false,
            "is_fix": false
        },
        "7bb1663b434e069f2b5f2832fccc15e14d41b034": {
            "datetime": "2021-08-10T09:36:50+02:00",
            "summary": "PARQUET-2063: Remove Compile Warnings from MemoryManager (#917)",
            "message": "PARQUET-2063: Remove Compile Warnings from MemoryManager (#917)\n\n",
            "diff": {
                "parquet-common/src/main/java/org/apache/parquet/ParquetRuntimeException.java": 3,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/MemoryManager.java": 26,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ParquetMemoryManagerRuntimeException.java": 38,
                "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/TestMemoryManager.java": 4
            },
            "is_test": true,
            "is_fix": false
        },
        "e210d9fd4c8ebcd21cca0f57f646c4ac96a4b812": {
            "datetime": "2021-08-16T11:19:36+02:00",
            "summary": "PARQUET-2043: Fail for undeclared dependencies (#916)",
            "message": "PARQUET-2043: Fail for undeclared dependencies (#916)\n\nThe purpose of this change is to fail the build if some classes are\r\nused from not direct dependencies. Only classes from direct\r\ndependencies shall be used.\r\nAlso fixed some references that broke this rule.",
            "diff": {
                "parquet-hadoop/src/test/java/org/apache/parquet/crypto/propertiesfactory/SchemaControlEncryptionTest.java": 15
            },
            "is_test": true,
            "is_fix": false
        },
        "cc1ae9f857920cf6982a59b3fd389277877fbb9e": {
            "datetime": "2021-08-16T11:20:55+02:00",
            "summary": "PARQUET-2059: Handle resource-intensive tests in CI (#915)",
            "message": "PARQUET-2059: Handle resource-intensive tests in CI (#915)\n\n",
            "diff": {
                "parquet-column/src/test/java/org/apache/parquet/ResourceIntensiveTestRule.java": 58,
                "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/TestLargeColumnChunk.java": 9
            },
            "is_test": true,
            "is_fix": false
        },
        "5154d04f1ccc21811c0668bf68cfd19f91100907": {
            "datetime": "2021-08-16T11:23:04+02:00",
            "summary": "PARQUET-2073: Fix estimate remaining row count in ColumnWriteStoreBase. (#922)",
            "message": "PARQUET-2073: Fix estimate remaining row count in ColumnWriteStoreBase. (#922)\n\n",
            "diff": {
                "parquet-column/src/main/java/org/apache/parquet/column/impl/ColumnWriteStoreBase.java": 3
            },
            "is_test": false,
            "is_fix": false
        },
        "5f403501e9de05b6aa48f028191b4e78bb97fb12": {
            "datetime": "2021-09-09T11:17:04-07:00",
            "summary": "PARQUET-2078: Failed to read parquet file after writing with the same \u2026 (#925)",
            "message": "PARQUET-2078: Failed to read parquet file after writing with the same \u2026 (#925)\n\n* PARQUET-2078 Failed to read parquet file after writing with the same parquet version\r\n\r\n* PARQUET-2078 Failed to read parquet file after writing with the same parquet version\r\n\r\nRead path fix that make usage of this information:\r\nRowGroup[n].file_offset = RowGroup[n-1].file_offset + RowGroup[n-1].total_compressed_size\r\n\r\n* PARQUET-2078 Failed to read parquet file after writing with the same parquet version\r\n\r\naddressing review comments: more check on writer side.\r\n\r\n* PARQUET-2078 Failed to read parquet file after writing with the same parquet version\r\n\r\ntaking alignment padding and sumarry file into account\r\n\r\n* PARQUET-2078 Failed to read parquet file after writing with the same parquet version\r\n\r\nonly throw exception when: 1.footer(first column of block meta) encrypted and 2.file_offset corrupted\r\n\r\n* PARQUET-2078 Failed to read parquet file after writing with the same parquet version\r\n\r\nonly check firstColumnChunk.isSetMeta_data() for the first block\r\n\r\n* PARQUET-2078 Failed to read parquet file after writing with the same parquet version\r\n\r\naddress review comments: empty lines\r\n\r\n* PARQUET-2078 Failed to read parquet file after writing with the same parquet version\r\n\r\ncheck first rowgroup's file_offset too(SPARK-36696)\r\n\r\n* PARQUET-2078 Failed to read parquet file after writing with the same parquet version\r\n\r\nUsing Preconditions.checkState instead of assert in write path\r\nremove summary file footers case check in read path(which will never happen)\r\n\r\n* PARQUET-2078 Failed to read parquet file after writing with the same parquet version\r\n\r\nmore special case for first row group",
            "diff": {
                "parquet-column/src/main/java/org/apache/parquet/io/InvalidFileOffsetException.java": 29,
                "parquet-hadoop/src/main/java/org/apache/parquet/format/converter/ParquetMetadataConverter.java": 96,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ParquetFileWriter.java": 1,
                "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/TestParquetFileWriter.java": 83
            },
            "is_test": true,
            "is_fix": true
        },
        "cac8d5a7732c768b814f448413d5ac58e13a4ac3": {
            "datetime": "2021-09-14T11:46:34+02:00",
            "summary": "PARQUET-2083: Expose getFieldPath from ColumnIO (#926)",
            "message": "PARQUET-2083: Expose getFieldPath from ColumnIO (#926)\n\n",
            "diff": {
                "parquet-column/src/main/java/org/apache/parquet/io/ColumnIO.java": 2
            },
            "is_test": false,
            "is_fix": false
        },
        "98e3e1a770993903fbe37c8ac61321c8832d833f": {
            "datetime": "2021-09-30T09:32:06+02:00",
            "summary": "PARQUET-1968: FilterApi support In predicate (#923)",
            "message": "PARQUET-1968: FilterApi support In predicate (#923)\n\n",
            "diff": {
                "parquet-column/src/main/java/org/apache/parquet/column/MinMax.java": 56,
                "parquet-column/src/main/java/org/apache/parquet/filter2/predicate/FilterApi.java": 53,
                "parquet-column/src/main/java/org/apache/parquet/filter2/predicate/FilterPredicate.java": 8,
                "parquet-column/src/main/java/org/apache/parquet/filter2/predicate/LogicalInverseRewriter.java": 12,
                "parquet-column/src/main/java/org/apache/parquet/filter2/predicate/LogicalInverter.java": 12,
                "parquet-column/src/main/java/org/apache/parquet/filter2/predicate/Operators.java": 81,
                "parquet-column/src/main/java/org/apache/parquet/filter2/predicate/SchemaCompatibilityValidator.java": 19,
                "parquet-column/src/main/java/org/apache/parquet/internal/column/columnindex/ColumnIndexBuilder.java": 70,
                "parquet-column/src/main/java/org/apache/parquet/internal/filter2/columnindex/ColumnIndexFilter.java": 13,
                "parquet-column/src/test/java/org/apache/parquet/internal/column/columnindex/TestColumnIndexBuilder.java": 182,
                "parquet-column/src/test/java/org/apache/parquet/internal/filter2/columnindex/TestColumnIndexFilter.java": 55,
                "parquet-generator/src/main/java/org/apache/parquet/filter2/IncrementallyUpdatedFilterPredicateGenerator.java": 65,
                "parquet-hadoop/src/main/java/org/apache/parquet/filter2/bloomfilterlevel/BloomFilterImpl.java": 37,
                "parquet-hadoop/src/main/java/org/apache/parquet/filter2/dictionarylevel/DictionaryFilter.java": 102,
                "parquet-hadoop/src/main/java/org/apache/parquet/filter2/statisticslevel/StatisticsFilter.java": 69,
                "parquet-hadoop/src/test/java/org/apache/parquet/filter2/TestFiltersWithMissingColumns.java": 10,
                "parquet-hadoop/src/test/java/org/apache/parquet/filter2/compat/TestRowGroupFilter.java": 28,
                "parquet-hadoop/src/test/java/org/apache/parquet/filter2/dictionarylevel/DictionaryFilterTest.java": 116,
                "parquet-hadoop/src/test/java/org/apache/parquet/filter2/recordlevel/TestRecordLevelFilters.java": 36,
                "parquet-hadoop/src/test/java/org/apache/parquet/filter2/statisticslevel/TestStatisticsFilter.java": 91,
                "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/TestBloomFiltering.java": 26,
                "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/TestColumnIndexFiltering.java": 39
            },
            "is_test": true,
            "is_fix": false
        },
        "1695d92cc07288713a9f2230f3aac61e2dc6a8e4": {
            "datetime": "2021-09-30T10:07:06+02:00",
            "summary": "PARQUET-2094: Handle negative values in page headers (#933)",
            "message": "PARQUET-2094: Handle negative values in page headers (#933)\n\n",
            "diff": {
                "parquet-format-structures/src/main/java/org/apache/parquet/format/InvalidParquetMetadataException.java": 30,
                "parquet-format-structures/src/main/java/org/apache/parquet/format/MetadataValidator.java": 44,
                "parquet-format-structures/src/main/java/org/apache/parquet/format/Util.java": 2,
                "parquet-format-structures/src/test/java/org/apache/parquet/format/TestUtil.java": 20
            },
            "is_test": true,
            "is_fix": true
        },
        "1adc22804a700d78f8480667d083e91d6147339f": {
            "datetime": "2021-10-04T14:04:27-07:00",
            "summary": "PARQUET-2081: Encryption translation tool - Parquet-hadoop (#928)",
            "message": "PARQUET-2081: Encryption translation tool - Parquet-hadoop (#928)\n\n* PARQUET-2081: Encryption translation tool - Parquet-hadoop\r\n\r\nSummary:\r\nDesign doc - High Throughput CLAC Writer: https://docs.google.com/document/d/1-XdE8-QyDHnBsYrClwNsR8X3ks0JmKJ1-rXq7_th0hc\r\n\r\nAdded unit tests\r\n\r\nIntegration tests with real data\r\n\r\n* Address feedbacks\r\n\r\n* Address more comments\r\n\r\n* Revert the refactoring code to avoid execlusion in public api check\r\n\r\n* Address more feedbbacks\r\n\r\n* Refactor the code to have rewrite offset index always\r\n\r\n* Rename methods to reflect the change better\r\n\r\n* Use 'encrypt' flag to create different encrytion runtime\r\nAdd checking of encrypted column\r\n\r\n* Address comments\r\n\r\n* Address more comments",
            "diff": {
                "parquet-column/src/main/java/org/apache/parquet/internal/column/columnindex/OffsetIndexBuilder.java": 26,
                "parquet-hadoop/src/main/java/org/apache/parquet/crypto/ColumnEncryptionProperties.java": 11,
                "parquet-hadoop/src/main/java/org/apache/parquet/format/converter/ParquetMetadataConverter.java": 20,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ParquetFileReader.java": 2,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ParquetFileWriter.java": 79,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/metadata/ColumnChunkMetaData.java": 38,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/util/ColumnEncryptor.java": 329,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/util/ColumnMasker.java": 4,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/util/H2SeekableInputStream.java": 1,
                "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/util/ColumnEncryptorTest.java": 293,
                "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/util/CompressionConveterTest.java": 7,
                "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/util/EncDecProperties.java": 99,
                "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/util/TestFileHelper.java": 153
            },
            "is_test": true,
            "is_fix": false
        },
        "59e9f78b8b3a30073db202eb6432071ff71df0ec": {
            "datetime": "2021-11-02T10:43:48+01:00",
            "summary": "PARQUET-2101: Fix wrong descriptions about the default block size (#936)",
            "message": "PARQUET-2101: Fix wrong descriptions about the default block size (#936)\n\n",
            "diff": {
                "parquet-avro/src/main/java/org/apache/parquet/avro/AvroParquetWriter.java": 4,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ParquetWriter.java": 4,
                "parquet-protobuf/src/main/java/org/apache/parquet/proto/ProtoParquetWriter.java": 4
            },
            "is_test": false,
            "is_fix": false
        },
        "89102ca80ca6ab20919a55bfd10d9c389112dcb3": {
            "datetime": "2021-11-11T09:12:50+01:00",
            "summary": "PARQUET-2102: Fix typo in ColumnIndexBase toString (#937)",
            "message": "PARQUET-2102: Fix typo in ColumnIndexBase toString (#937)\n\n",
            "diff": {
                "parquet-column/src/main/java/org/apache/parquet/internal/column/columnindex/ColumnIndexBuilder.java": 2
            },
            "is_test": false,
            "is_fix": false
        },
        "23a217a21ce4aaac8a92dca057e9352c51719f8f": {
            "datetime": "2021-11-24T08:57:42-08:00",
            "summary": "PARQUET-2040: Uniform encryption (#935)",
            "message": "PARQUET-2040: Uniform encryption (#935)\n\n* Initial commit\r\n\r\n* Uniform encryption - count and limit operations with same key\r\n\r\n* fix the limit value\r\n\r\nCo-authored-by: Gidon Gershinsky <ggershinsky@apple.com>",
            "diff": {
                "parquet-hadoop/src/main/java/org/apache/parquet/crypto/AesCipher.java": 24,
                "parquet-hadoop/src/main/java/org/apache/parquet/crypto/AesCtrEncryptor.java": 8,
                "parquet-hadoop/src/main/java/org/apache/parquet/crypto/AesGcmEncryptor.java": 9,
                "parquet-hadoop/src/main/java/org/apache/parquet/crypto/keytools/PropertiesDrivenCryptoFactory.java": 54,
                "parquet-hadoop/src/test/java/org/apache/parquet/crypto/TestPropertiesDrivenEncryption.java": 40
            },
            "is_test": true,
            "is_fix": false
        },
        "06bb358bcf8a0855c54f20122a57a88d9fde16c1": {
            "datetime": "2021-12-09T10:29:59+01:00",
            "summary": "PARQUET-2106: Refactoring lexicographic `BinaryComparator` to avoid `ByteBuffer.wrap` in the hot-path (#940)",
            "message": "PARQUET-2106: Refactoring lexicographic `BinaryComparator` to avoid `ByteBuffer.wrap` in the hot-path (#940)\n\n",
            "diff": {
                "parquet-column/src/main/java/org/apache/parquet/io/api/Binary.java": 129,
                "parquet-column/src/main/java/org/apache/parquet/schema/PrimitiveComparator.java": 31
            },
            "is_test": false,
            "is_fix": false
        },
        "7398d9b522733c669d497c25495c9efa1c860994": {
            "datetime": "2021-12-16T15:01:35-08:00",
            "summary": "PARQUET-2105: Refactor the test code of creating the test file (#939)",
            "message": "PARQUET-2105: Refactor the test code of creating the test file (#939)\n\n",
            "diff": {
                "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/util/ColumnEncryptorTest.java": 104,
                "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/util/EncDecProperties.java": 27,
                "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/util/EncryptionTestFile.java": 38,
                "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/util/TestFileBuilder.java": 198,
                "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/util/TestFileHelper.java": 153
            },
            "is_test": true,
            "is_fix": false
        }
    },
    "2022-01-11T15:17:05-07:00": {
        "300200eb72b9f16df36d9a68cf762683234aeb08": {
            "datetime": "2022-01-24T21:30:19-08:00",
            "summary": "PARQUET-2112: Fix typo in MessageColumnIO (#943)",
            "message": "PARQUET-2112: Fix typo in MessageColumnIO (#943)\n\n* PARQUET-2112: Fix typo in MessageColumnIO\r\n\r\n* Address feedback",
            "diff": {
                "parquet-column/src/main/java/org/apache/parquet/io/MessageColumnIO.java": 22
            },
            "is_test": false,
            "is_fix": false
        },
        "2431c5c1333855c9efd532324dee5b771b0780bf": {
            "datetime": "2022-02-24T18:25:54-08:00",
            "summary": "PARQUET-2120: Make dictionary command handle pages without dictionary (#946)",
            "message": "PARQUET-2120: Make dictionary command handle pages without dictionary (#946)\n\n",
            "diff": {
                "parquet-cli/src/main/java/org/apache/parquet/cli/commands/ShowDictionaryCommand.java": 75,
                "parquet-cli/src/test/java/org/apache/parquet/cli/commands/ShowDictionaryCommandTest.java": 11
            },
            "is_test": true,
            "is_fix": true
        },
        "c00479d538353348726cf78da835078024161e55": {
            "datetime": "2022-02-24T18:50:44-08:00",
            "summary": "PARQUET-2129: Add uncompressedSize to Meta Command (#949)",
            "message": "PARQUET-2129: Add uncompressedSize to Meta Command (#949)\n\n",
            "diff": {
                "parquet-cli/src/main/java/org/apache/parquet/cli/commands/ParquetMetadataCommand.java": 15
            },
            "is_test": false,
            "is_fix": false
        },
        "4d062dc37577e719dcecc666f8e837843e44a9be": {
            "datetime": "2022-03-04T09:15:14-08:00",
            "summary": "PARQUET-2121: Remove descriptions for the removed modules (#947)",
            "message": "PARQUET-2121: Remove descriptions for the removed modules (#947)\n\n* PARQUET-2121: Remove descriptions for the removed modules\r\n\r\n* Add '(deprecated)' to removed modules in README.md instead of removing their line",
            "diff": {
                "parquet-thrift/src/main/java/org/apache/parquet/hadoop/thrift/ThriftReadSupport.java": 9
            },
            "is_test": false,
            "is_fix": false
        },
        "c7bff519094920a8609df6cbd98821a43ed779e3": {
            "datetime": "2022-03-19T17:00:24-07:00",
            "summary": "PARQUET-2117: Expose Row Index via ParquetReader and ParquetRecordReader (#945)",
            "message": "PARQUET-2117: Expose Row Index via ParquetReader and ParquetRecordReader (#945)\n\n* PARQUET-2117: Changes to generate row index in InternalParquetRecordReader, also expose the row index via ParquetReader or ParquetRecordReader\r\n\r\n - Add and populate rowIndexOffset field in BlockMetaData\r\n - Changes to generate row index in InternalParquetRecordReader, also expose the row index via ParquetReader or ParquetRecordReader\r\n - Add new unit tests and extend all the ColumnIndexFiltering and BloomFiltering unit tests to validate row indexes also.\r\n\r\n* address review comments\r\n\r\n* add test based on old parquet file without column indexes\r\n\r\n* address review comments - Return -1 when row index info not available, document the same, Return -1 when rowIndexOffset info not available in BlockMetadata\r\n\r\n* address review comments - Fix java doc style\r\n\r\n* address review comments from ggershinsky - early return and reduce indentation\r\n\r\n* fix build",
            "diff": {
                "parquet-column/src/main/java/org/apache/parquet/column/page/PageReadStore.java": 8,
                "parquet-hadoop/src/main/java/org/apache/parquet/format/converter/ParquetMetadataConverter.java": 63,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ColumnChunkPageReadStore.java": 20,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/InternalParquetRecordReader.java": 55,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ParquetFileReader.java": 4,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ParquetReader.java": 10,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ParquetRecordReader.java": 7,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/metadata/BlockMetaData.java": 19,
                "parquet-hadoop/src/test/java/org/apache/parquet/filter2/recordlevel/PhoneBookWriter.java": 19,
                "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/TestBloomFiltering.java": 2,
                "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/TestColumnIndexFiltering.java": 4,
                "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/TestParquetReader.java": 181
            },
            "is_test": true,
            "is_fix": false
        },
        "fb3a9051a62acc65b20ec58f383a67566d76cc3d": {
            "datetime": "2022-04-14T09:08:36-07:00",
            "summary": "writer constructor with encryptor (#954)",
            "message": "writer constructor with encryptor (#954)\n\nCo-authored-by: Gidon Gershinsky <ggershinsky@apple.com>",
            "diff": {
                "parquet-hadoop/src/main/java/org/apache/parquet/crypto/InternalFileEncryptor.java": 12,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ParquetFileWriter.java": 50
            },
            "is_test": false,
            "is_fix": false
        },
        "f2f7c3ec8b22cbd119689ab321cafb659ccc59ec": {
            "datetime": "2022-05-09T15:04:30+03:00",
            "summary": "Fix ColumnIndexBuilder for notIn predicate (#961)",
            "message": "Fix ColumnIndexBuilder for notIn predicate (#961)\n\n",
            "diff": {
                "parquet-column/src/main/java/org/apache/parquet/internal/column/columnindex/ColumnIndexBuilder.java": 12,
                "parquet-column/src/test/java/org/apache/parquet/internal/column/columnindex/TestColumnIndexBuilder.java": 100,
                "parquet-column/src/test/java/org/apache/parquet/internal/filter2/columnindex/TestColumnIndexFilter.java": 10
            },
            "is_test": true,
            "is_fix": false
        },
        "a2da156b251d13bce1fa81eb95b555da04880bc1": {
            "datetime": "2022-05-18T08:50:41-07:00",
            "summary": "PARQUET-2148: Enable uniform decryption with plaintext footer (#969)",
            "message": "PARQUET-2148: Enable uniform decryption with plaintext footer (#969)\n\n* fix uniform decryption with plaintext footer\r\n\r\n* fix CI failure\r\n\r\nCo-authored-by: Gidon Gershinsky <ggershinsky@apple.com>",
            "diff": {
                "parquet-hadoop/src/main/java/org/apache/parquet/crypto/InternalFileDecryptor.java": 13,
                "parquet-hadoop/src/main/java/org/apache/parquet/format/converter/ParquetMetadataConverter.java": 27,
                "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/TestEncryptionOptions.java": 19
            },
            "is_test": true,
            "is_fix": true
        },
        "c797a85b37ced716efe36597344eb2f3fa06a1cf": {
            "datetime": "2022-06-10T10:21:51+03:00",
            "summary": "PARQUET-2154: `ParquetFileReader` should close its input stream when `filterRowGroups` throw Exception in constructor (#972)",
            "message": "PARQUET-2154: `ParquetFileReader` should close its input stream when `filterRowGroups` throw Exception in constructor (#972)\n\n* fix fd leak if filterRowGroups thrown IOE\r\n\r\nSigned-off-by: yangjie01 <yangjie01@baidu.com>\r\n\r\n* change to Exception",
            "diff": {
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ParquetFileReader.java": 27
            },
            "is_test": false,
            "is_fix": false
        },
        "e06384455567c56d5906fc3a152ab00fd8dfdf33": {
            "datetime": "2022-06-17T20:09:49-07:00",
            "summary": "PARQUET-2157: add bloom filter fpp config (#975)",
            "message": "PARQUET-2157: add bloom filter fpp config (#975)\n\n* add bloom filter fpp config\r\n\r\n* Trigger Build\r\n\r\n* add commons-lang dependecy in hadoop test\r\n\r\n* address comments\r\n\r\n* update doc\r\n\r\n* fix doc format\r\n\r\n* add one more space to break the line in md file\r\n\r\n* address comments\r\n\r\n* address comments\r\n\r\n* remove fpp 0.005 from the test",
            "diff": {
                "parquet-column/src/main/java/org/apache/parquet/column/ParquetProperties.java": 19,
                "parquet-column/src/main/java/org/apache/parquet/column/impl/ColumnWriterBase.java": 4,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ParquetOutputFormat.java": 8,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ParquetWriter.java": 5,
                "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/TestParquetWriter.java": 62
            },
            "is_test": true,
            "is_fix": false
        },
        "5290bd5e0ee5dc30db0576e2bfc6eea335c465cf": {
            "datetime": "2022-06-29T22:21:45+03:00",
            "summary": "PARQUET-2161: Fix row index generation in combination with range filtering (#978)",
            "message": "PARQUET-2161: Fix row index generation in combination with range filtering (#978)\n\n* PARQUET-2161: Fix row index generation\r\n\r\nThe row indexes introduced in PARQUET-2117 are not computed correctly\r\nwhen:\r\n(1) range or offset metadata filter is applied, and\r\n(2) the first row group was eliminated by the filter\r\n\r\nFor example, if a file has two row groups with 10 rows each, and we\r\nattempt to only read the 2nd row group, we are going to produce row\r\nindexes 0, 1, 2, ..., 9 instead of expected 10, 11, ..., 19.\r\n\r\nThis happens because functions `filterFileMetaDataByStart`\r\nand `filterFileMetaDataByMidpoint` modify their input `FileMetaData`.\r\nTo return correct result, `generateRowGroupOffsets` has to be computed\r\nbefore these filters are applied.\r\n\r\n* Adjust assert message",
            "diff": {
                "parquet-hadoop/src/main/java/org/apache/parquet/format/converter/ParquetMetadataConverter.java": 8,
                "parquet-hadoop/src/test/java/org/apache/parquet/filter2/recordlevel/PhoneBookWriter.java": 2,
                "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/TestParquetReader.java": 21
            },
            "is_test": true,
            "is_fix": true
        },
        "e990eb3f14c39273e46a9fce07ec85d2edf7fccb": {
            "datetime": "2022-07-02T09:51:40-07:00",
            "summary": "PARQUET-2138: Add ShowBloomFilterCommand to parquet-cli (#958)",
            "message": "PARQUET-2138: Add ShowBloomFilterCommand to parquet-cli (#958)\n\n* PARQUET-2138: Add ShowBloomFilterCommand to parquet-cli\r\n\r\n* address comments",
            "diff": {
                "parquet-cli/src/main/java/org/apache/parquet/cli/Main.java": 2,
                "parquet-cli/src/main/java/org/apache/parquet/cli/commands/ShowBloomFilterCommand.java": 133,
                "parquet-cli/src/test/java/org/apache/parquet/cli/commands/ShowBloomFilterCommandTest.java": 41
            },
            "is_test": true,
            "is_fix": false
        }
    },
    "2022-07-10T15:17:05-07:00": {
        "19300bfbb416ae38378891868b714daa50d8769d": {
            "datetime": "2022-07-13T07:28:50-07:00",
            "summary": "PARQUET-1020 Add DynamicMessage writing support (#963)",
            "message": "PARQUET-1020 Add DynamicMessage writing support (#963)\n\n* PARQUET-1020 Add DynamicMessage writing support\r\n\r\n* PARQUET-1020 Remove useless set of Protobuf class name",
            "diff": {
                "parquet-protobuf/src/main/java/org/apache/parquet/proto/ProtoSchemaConverter.java": 10,
                "parquet-protobuf/src/main/java/org/apache/parquet/proto/ProtoWriteSupport.java": 50,
                "parquet-protobuf/src/test/java/org/apache/parquet/proto/ProtoWriteSupportTest.java": 35
            },
            "is_test": true,
            "is_fix": false
        },
        "1e1c383bda874e1722e001afa6116dc337ec0452": {
            "datetime": "2022-07-19T08:24:08-07:00",
            "summary": "PARQUET-2158: Upgrade Hadoop dependency to version 3.2.0 (#976)",
            "message": "PARQUET-2158: Upgrade Hadoop dependency to version 3.2.0 (#976)\n\n* PARQUET-2158: Upgrade Hadoop dependency to version 3.2.0\r\n\r\nThis updates Parquet's Hadoop dependency to 3.2.0.\r\nThis version adds compatibility with Java 11, as well\r\nas many other features and bug fixes.\r\n\r\n* PARQUET-2158. PathGlobPattern to compile/link with hadoop 3.2.0\r\n\r\nThe deprecated parquet-thrift class PathGlobPattern doesn't\r\ncompile against hadoop 3.x because in HADOOP-12436 the\r\nnominally private class org.apache.hadoop.fs.GlobPattern\r\nimplementation switched from using java.util.regex.Pattern\r\nto com.google.re2j.PatternSyntaxException.\r\n\r\nThe fact nobody has ever reported this problem implies that it\r\nis never used on any hadoop 3 release, ever.\r\n\r\nThis commit fixes the build by moving to the google classes.\r\nThe alternative strategy would actually be to fork the hadoop\r\nclass. This will work unless/until the hadoop project changes\r\nthe class again.\r\n\r\nIt may be time to consider removing entirely. Clearly nobody\r\nis actually using it.\r\n\r\n* PARQUET-2158. build auditing to cope with switch to google rej2j.\r\n\r\nDisables the API compatibility check and adds rej2j as a 'provided'\r\ndependency so that the relevant auditing checks do not fail.",
            "diff": {
                "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/TestInputFormat.java": 1,
                "parquet-thrift/src/main/java/org/apache/parquet/thrift/projection/deprecated/PathGlobPattern.java": 12
            },
            "is_test": true,
            "is_fix": false
        },
        "3ed2dbb9ba40d93caaa5aa3149581f2108ac2bc0": {
            "datetime": "2022-07-24T12:48:28-07:00",
            "summary": "PARQUET-2134: Fix type checking in HadoopStreams.wrap (#951)",
            "message": "PARQUET-2134: Fix type checking in HadoopStreams.wrap (#951)\n\nHadoopStreams.wrap produces a wrong H2SeekableInputStream if the\r\npassed-in FSDataInputStream wraps another FSDataInputStream.\r\n\r\nSince [HDFS-14111](https://issues.apache.org/jira/browse/HDFS-14111) all\r\ninput streams in the hadoop codebase which implement `ByteBufferReadable`\r\nreturn true on the StreamCapabilities probe\r\n`stream.hasCapability(\"in:readbytebuffer\")`;\r\nthose which don't are forbidden to do so.\r\n\r\nThis means that on Hadoop 3.3.0+ the preferred way to probe for the API\r\nis to ask the stream.\r\n\r\nThe StreamCapabilities probe was added in Hadoop 2.9. Along with\r\nmaking all use of `ByteBufferReadable` non-reflective, this makes\r\nthe checks fairly straightforward.\r\n\r\nTests verify that if a stream implements `ByteBufferReadable' then\r\nit will be bonded to H2SeekableInputStream, even if multiply wrapped\r\nby FSDataInputStreams, and that if it doesn't, it won't.\r\n\r\nCo-authored-by: Steve Loughran <stevel@cloudera.com>\r\n\r\nCo-authored-by: Steve Loughran <stevel@cloudera.com>",
            "diff": {
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/util/H2SeekableInputStream.java": 2,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/util/HadoopStreams.java": 78,
                "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/util/TestHadoop2ByteBufferReads.java": 47
            },
            "is_test": true,
            "is_fix": true
        },
        "0819356a9dafd2ca07c5eab68e2bffeddc3bd3d9": {
            "datetime": "2022-07-25T19:55:49-07:00",
            "summary": "PARQUET-2167: Fix CLI serializing of footer with date fields (#980)",
            "message": "PARQUET-2167: Fix CLI serializing of footer with date fields (#980)\n\n",
            "diff": {
                "parquet-cli/src/main/java/org/apache/parquet/cli/commands/ShowFooterCommand.java": 2,
                "parquet-cli/src/test/java/org/apache/parquet/cli/commands/FileTest.java": 1,
                "parquet-cli/src/test/java/org/apache/parquet/cli/commands/ParquetFileTest.java": 28
            },
            "is_test": true,
            "is_fix": true
        },
        "e0e66b4e61a42cdabc68403152f46a0b9c131001": {
            "datetime": "2022-09-19T10:04:04+02:00",
            "summary": "PARQUET-2192: Add Java 17 build test to GitHub action (#997)",
            "message": "PARQUET-2192: Add Java 17 build test to GitHub action (#997)\n\n",
            "diff": {
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/package-info.java": 2
            },
            "is_test": true,
            "is_fix": false
        },
        "203120642dc501c83175a86739df722748dbbfc0": {
            "datetime": "2022-09-20T11:15:15+02:00",
            "summary": "PARQUET-2185 Add path object to ParquetReadOptions builder method (#994)",
            "message": "PARQUET-2185 Add path object to ParquetReadOptions builder method (#994)\n\nCo-authored-by: Atul Mohan <atul_mohan2@apple.com>",
            "diff": {
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ParquetReader.java": 2
            },
            "is_test": false,
            "is_fix": false
        },
        "53f65a81dc5c2067aa258dfe8d832a6ff9fd0e9c": {
            "datetime": "2022-09-22T06:21:31-07:00",
            "summary": "PARQUET-2160: Close ZstdInputStream to free off-heap memory in time. (#982)",
            "message": "PARQUET-2160: Close ZstdInputStream to free off-heap memory in time. (#982)\n\n* PARQUET-2160: Close ZstdInputStream to free off-heap memory in time.\r\n\r\n* Add comment.",
            "diff": {
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/CodecFactory.java": 13
            },
            "is_test": false,
            "is_fix": false
        },
        "704ef93ff6db938f6f693f8d662380de91b94a65": {
            "datetime": "2022-10-09T11:53:27-07:00",
            "summary": "PARQUET-2176: Column index/statistics truncation in ParquetWriter (#989)",
            "message": "PARQUET-2176: Column index/statistics truncation in ParquetWriter (#989)\n\n* PARQUET-2176 Set column index truncate length\r\n\r\n* PARQUET-2176 Set statistics truncate length\r\n\r\n* PARQUET-2176 Refactor creating test temp files",
            "diff": {
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ParquetFileWriter.java": 8,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ParquetWriter.java": 22,
                "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/TestParquetWriterTruncation.java": 125
            },
            "is_test": true,
            "is_fix": false
        },
        "44dc3a4aef8e7746408381a7b11ff7ab8e888c3f": {
            "datetime": "2022-10-09T11:59:00-07:00",
            "summary": "Performance optimization to ByteBitPackingValuesReader (#962)",
            "message": "Performance optimization to ByteBitPackingValuesReader (#962)\n\nRemove object creation out of critical path\r\nMove less-used code into separate function to encourage JIT to inline\r\nmore frequently used code.",
            "diff": {
                "parquet-column/src/main/java/org/apache/parquet/column/values/bitpacking/ByteBitPackingValuesReader.java": 38
            },
            "is_test": false,
            "is_fix": false
        },
        "d75596beaa5d6d0b07ff3004310dcd2be2469b07": {
            "datetime": "2022-11-02T07:45:32-07:00",
            "summary": "PARQUET-1711: support recursive proto schemas by limiting recursion depth (#995)",
            "message": "PARQUET-1711: support recursive proto schemas by limiting recursion depth (#995)\n\n* PARQUET-1711: support recursive proto schemas by limiting recursion depth\r\n\r\nThis approach could address the other recursion related issues (PARQUET-129, PARQUET-554).\r\n\r\n* PARQUET-1711: write recursive proto schemas with limited recursion depth\r\n\r\n* Make description a sentence.  This commit is here to set a co-author.\r\n\r\nCo-authored-by: matthieun <matthieu.nahoum@gmail.com>\r\n\r\nCo-authored-by: matthieun <matthieu.nahoum@gmail.com>",
            "diff": {
                "parquet-protobuf/src/main/java/org/apache/parquet/proto/ProtoSchemaConverter.java": 156,
                "parquet-protobuf/src/main/java/org/apache/parquet/proto/ProtoWriteSupport.java": 32,
                "parquet-protobuf/src/test/java/org/apache/parquet/proto/ProtoSchemaConverterTest.java": 634,
                "parquet-protobuf/src/test/java/org/apache/parquet/proto/ProtoWriteSupportTest.java": 254,
                "parquet-protobuf/src/test/java/org/apache/parquet/proto/TestUtils.java": 5
            },
            "is_test": true,
            "is_fix": true
        },
        "dd553305321fe90b375ace5c9a5ce661763a623d": {
            "datetime": "2022-11-02T09:32:10-07:00",
            "summary": "PARQUET-2196: Support LZ4_RAW codec (#1000)",
            "message": "PARQUET-2196: Support LZ4_RAW codec (#1000)\n\n* PARQUET-2196: Support LZ4_RAW codec\r\n\r\n* use SnappyUtil\r\n\r\n* address feedback and refine test cases\r\n\r\n* add interop test\r\n\r\n* address feedback\r\n\r\n* change interop test to read from resource\r\n\r\n* revert interop test to download from parquet-testing\r\n\r\n* make the test of compression codec generic\r\n\r\n* support snappy codec in the TestCompressionCodec\r\n\r\n* add comment and rename codec extension",
            "diff": {
                "parquet-cli/src/main/java/org/apache/parquet/cli/Util.java": 2,
                "parquet-common/src/main/java/org/apache/parquet/hadoop/metadata/CompressionCodecName.java": 5,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/codec/Lz4RawCodec.java": 112,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/codec/Lz4RawCompressor.java": 44,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/codec/Lz4RawDecompressor.java": 46,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/codec/NonBlockedCompressor.java": 192,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/codec/NonBlockedDecompressor.java": 180,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/codec/SnappyCompressor.java": 138,
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/codec/SnappyDecompressor.java": 134,
                "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/codec/TestCompressionCodec.java": 177,
                "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/codec/TestInteropReadLz4RawCodec.java": 129
            },
            "is_test": true,
            "is_fix": false
        },
        "d057b39d93014fe40f5067ee4a33621e65c91552": {
            "datetime": "2022-11-07T09:21:20-08:00",
            "summary": "PARQUET-2195: Add scan command to parquet-cli (#998)",
            "message": "PARQUET-2195: Add scan command to parquet-cli (#998)\n\n* PARQUET-2195: Add scan command to parquet-cli\r\n\r\n* Add ScanCommandTest\r\n\r\n* fix argument to use single file name",
            "diff": {
                "parquet-cli/src/main/java/org/apache/parquet/cli/Main.java": 2,
                "parquet-cli/src/main/java/org/apache/parquet/cli/commands/ScanCommand.java": 91,
                "parquet-cli/src/test/java/org/apache/parquet/cli/commands/ScanCommandTest.java": 38
            },
            "is_test": true,
            "is_fix": false
        },
        "c8c6386f836587cf527a56ff5741a48d40a979cb": {
            "datetime": "2022-12-03T10:36:18-08:00",
            "summary": "PARQUET-2177: Fix parquet-cli not to fail showing descriptions (#991)",
            "message": "PARQUET-2177: Fix parquet-cli not to fail showing descriptions (#991)\n\n",
            "diff": {
                "parquet-cli/src/main/java/org/apache/parquet/cli/Help.java": 11,
                "parquet-cli/src/main/java/org/apache/parquet/cli/commands/ColumnMaskingCommand.java": 14,
                "parquet-cli/src/main/java/org/apache/parquet/cli/commands/PruneColumnsCommand.java": 8
            },
            "is_test": false,
            "is_fix": false
        },
        "433de8df33fcf31927f7b51456be9f53e64d48b9": {
            "datetime": "2022-12-03T11:10:34-08:00",
            "summary": "nested encr info (#1009)",
            "message": "nested encr info (#1009)\n\nCo-authored-by: Gidon Gershinsky <ggershinsky@apple.com>",
            "diff": {
                "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ParquetFileWriter.java": 8
            },
            "is_test": false,
            "is_fix": false
        }
    }
}