{
    "576c709724551a5122ae9b9e314b6c400f5f778d": {
        "datetime": "2012-08-31T15:17:05-07:00",
        "summary": "Initial commit",
        "message": "Initial commit\n",
        "diff": {
            ".editorconfig": null,
            ".github/PULL_REQUEST_TEMPLATE.md": null,
            ".github/dependabot.yml": null,
            ".github/workflows/ci-hadoop2.yml": null,
            ".github/workflows/ci-hadoop3.yml": null,
            ".github/workflows/vector-plugins.yml": null,
            ".gitignore": null,
            "CHANGES.md": null,
            "LICENSE": null,
            "NOTICE": null,
            "PoweredBy.md": null,
            "README.md": null,
            "changelog.sh": null,
            "dev/COMMITTERS.md": null,
            "dev/README.md": null,
            "dev/ci-before_install-master.sh": null,
            "dev/ci-before_install.sh": null,
            "dev/finalize-release": null,
            "dev/merge_parquet_pr.py": [
                393,
                0
            ],
            "dev/prepare-release.sh": null,
            "dev/source-release.sh": null,
            "doc/dremel_paper/dremel_example.png": null,
            "doc/dremel_paper/schema.png": null,
            "parquet-arrow/pom.xml": null,
            "parquet-arrow/src/main/java/org/apache/parquet/arrow/schema/List3Levels.java": [
                77,
                0
            ],
            "parquet-arrow/src/main/java/org/apache/parquet/arrow/schema/SchemaConverter.java": [
                705,
                0
            ],
            "parquet-arrow/src/main/java/org/apache/parquet/arrow/schema/SchemaMapping.java": [
                201,
                0
            ],
            "parquet-arrow/src/test/java/org/apache/parquet/arrow/schema/TestSchemaConverter.java": [
                530,
                0
            ],
            "parquet-avro/README.md": null,
            "parquet-avro/REVIEWERS.md": null,
            "parquet-avro/pom.xml": null,
            "parquet-avro/src/main/java/org/apache/parquet/avro/AvroCompatRecordMaterializer.java": [
                46,
                0
            ],
            "parquet-avro/src/main/java/org/apache/parquet/avro/AvroConverters.java": [
                333,
                0
            ],
            "parquet-avro/src/main/java/org/apache/parquet/avro/AvroDataSupplier.java": [
                31,
                0
            ],
            "parquet-avro/src/main/java/org/apache/parquet/avro/AvroIndexedRecordConverter.java": [
                535,
                0
            ],
            "parquet-avro/src/main/java/org/apache/parquet/avro/AvroParquetInputFormat.java": [
                86,
                0
            ],
            "parquet-avro/src/main/java/org/apache/parquet/avro/AvroParquetOutputFormat.java": [
                63,
                0
            ],
            "parquet-avro/src/main/java/org/apache/parquet/avro/AvroParquetReader.java": [
                178,
                0
            ],
            "parquet-avro/src/main/java/org/apache/parquet/avro/AvroParquetWriter.java": [
                193,
                0
            ],
            "parquet-avro/src/main/java/org/apache/parquet/avro/AvroReadSupport.java": [
                180,
                0
            ],
            "parquet-avro/src/main/java/org/apache/parquet/avro/AvroRecordConverter.java": [
                1093,
                0
            ],
            "parquet-avro/src/main/java/org/apache/parquet/avro/AvroRecordMaterializer.java": [
                45,
                0
            ],
            "parquet-avro/src/main/java/org/apache/parquet/avro/AvroSchemaConverter.java": [
                565,
                0
            ],
            "parquet-avro/src/main/java/org/apache/parquet/avro/AvroWriteSupport.java": [
                711,
                0
            ],
            "parquet-avro/src/main/java/org/apache/parquet/avro/GenericDataSupplier.java": [
                28,
                0
            ],
            "parquet-avro/src/main/java/org/apache/parquet/avro/ParentValueContainer.java": [
                238,
                0
            ],
            "parquet-avro/src/main/java/org/apache/parquet/avro/ReflectDataSupplier.java": [
                29,
                0
            ],
            "parquet-avro/src/main/java/org/apache/parquet/avro/SpecificDataSupplier.java": [
                29,
                0
            ],
            "parquet-avro/src/main/java/org/apache/parquet/avro/package-info.java": [
                174,
                0
            ],
            "parquet-avro/src/main/resources/META-INF/LICENSE": null,
            "parquet-avro/src/main/resources/META-INF/NOTICE": null,
            "parquet-avro/src/test/avro/logicalType.avsc": null,
            "parquet-avro/src/test/avro/stringBehavior.avsc": null,
            "parquet-avro/src/test/java/org/apache/parquet/avro/AvroTestUtil.java": [
                136,
                0
            ],
            "parquet-avro/src/test/java/org/apache/parquet/avro/TestArrayCompatibility.java": [
                1164,
                0
            ],
            "parquet-avro/src/test/java/org/apache/parquet/avro/TestAvroDataSupplier.java": [
                43,
                0
            ],
            "parquet-avro/src/test/java/org/apache/parquet/avro/TestAvroRecordConverter.java": [
                202,
                0
            ],
            "parquet-avro/src/test/java/org/apache/parquet/avro/TestAvroSchemaConverter.java": [
                942,
                0
            ],
            "parquet-avro/src/test/java/org/apache/parquet/avro/TestAvroWriteSupport.java": [
                61,
                0
            ],
            "parquet-avro/src/test/java/org/apache/parquet/avro/TestBackwardCompatibility.java": [
                68,
                0
            ],
            "parquet-avro/src/test/java/org/apache/parquet/avro/TestByteStreamSplitE2E.java": [
                114,
                0
            ],
            "parquet-avro/src/test/java/org/apache/parquet/avro/TestCircularReferences.java": [
                387,
                0
            ],
            "parquet-avro/src/test/java/org/apache/parquet/avro/TestGenericLogicalTypes.java": [
                296,
                0
            ],
            "parquet-avro/src/test/java/org/apache/parquet/avro/TestInputOutputFormat.java": [
                145,
                0
            ],
            "parquet-avro/src/test/java/org/apache/parquet/avro/TestReadWrite.java": [
                900,
                0
            ],
            "parquet-avro/src/test/java/org/apache/parquet/avro/TestReadWriteOldListBehavior.java": [
                584,
                0
            ],
            "parquet-avro/src/test/java/org/apache/parquet/avro/TestReflectInputOutputFormat.java": [
                496,
                0
            ],
            "parquet-avro/src/test/java/org/apache/parquet/avro/TestReflectLogicalTypes.java": [
                999,
                0
            ],
            "parquet-avro/src/test/java/org/apache/parquet/avro/TestReflectReadWrite.java": [
                240,
                0
            ],
            "parquet-avro/src/test/java/org/apache/parquet/avro/TestSpecificInputOutputFormat.java": [
                287,
                0
            ],
            "parquet-avro/src/test/java/org/apache/parquet/avro/TestSpecificReadWrite.java": [
                360,
                0
            ],
            "parquet-avro/src/test/java/org/apache/parquet/avro/TestStringBehavior.java": [
                330,
                0
            ],
            "parquet-avro/src/test/resources/all.avsc": null,
            "parquet-avro/src/test/resources/allFromParquetNewBehavior.avsc": null,
            "parquet-avro/src/test/resources/allFromParquetOldBehavior.avsc": null,
            "parquet-avro/src/test/resources/array.avsc": null,
            "parquet-avro/src/test/resources/car.avdl": null,
            "parquet-avro/src/test/resources/fixedToInt96.avsc": null,
            "parquet-avro/src/test/resources/list_with_nulls.avsc": null,
            "parquet-avro/src/test/resources/map.avsc": null,
            "parquet-avro/src/test/resources/map_with_nulls.avsc": null,
            "parquet-avro/src/test/resources/nested_array.avsc": null,
            "parquet-avro/src/test/resources/strings-2.parquet": null,
            "parquet-benchmarks/README.md": null,
            "parquet-benchmarks/pom.xml": null,
            "parquet-benchmarks/run.sh": null,
            "parquet-benchmarks/src/main/java/org/apache/parquet/benchmarks/BenchmarkConstants.java": [
                42,
                0
            ],
            "parquet-benchmarks/src/main/java/org/apache/parquet/benchmarks/BenchmarkFiles.java": [
                64,
                0
            ],
            "parquet-benchmarks/src/main/java/org/apache/parquet/benchmarks/BenchmarkUtils.java": [
                46,
                0
            ],
            "parquet-benchmarks/src/main/java/org/apache/parquet/benchmarks/DataGenerator.java": [
                137,
                0
            ],
            "parquet-benchmarks/src/main/java/org/apache/parquet/benchmarks/FilteringBenchmarks.java": [
                430,
                0
            ],
            "parquet-benchmarks/src/main/java/org/apache/parquet/benchmarks/NestedNullWritingBenchmarks.java": [
                156,
                0
            ],
            "parquet-benchmarks/src/main/java/org/apache/parquet/benchmarks/PageChecksumDataGenerator.java": [
                106,
                0
            ],
            "parquet-benchmarks/src/main/java/org/apache/parquet/benchmarks/PageChecksumReadBenchmarks.java": [
                196,
                0
            ],
            "parquet-benchmarks/src/main/java/org/apache/parquet/benchmarks/PageChecksumWriteBenchmarks.java": [
                178,
                0
            ],
            "parquet-benchmarks/src/main/java/org/apache/parquet/benchmarks/ReadBenchmarks.java": [
                131,
                0
            ],
            "parquet-benchmarks/src/main/java/org/apache/parquet/benchmarks/WriteBenchmarks.java": [
                168,
                0
            ],
            "parquet-benchmarks/src/main/resources/log4j.properties": null,
            "parquet-cli/README.md": null,
            "parquet-cli/pom.xml": null,
            "parquet-cli/src/main/java/org/apache/parquet/cli/BaseCommand.java": [
                428,
                0
            ],
            "parquet-cli/src/main/java/org/apache/parquet/cli/Command.java": [
                40,
                0
            ],
            "parquet-cli/src/main/java/org/apache/parquet/cli/HadoopFileSystemURLStreamHandler.java": [
                79,
                0
            ],
            "parquet-cli/src/main/java/org/apache/parquet/cli/Help.java": [
                153,
                0
            ],
            "parquet-cli/src/main/java/org/apache/parquet/cli/Main.java": [
                196,
                0
            ],
            "parquet-cli/src/main/java/org/apache/parquet/cli/Util.java": [
                272,
                0
            ],
            "parquet-cli/src/main/java/org/apache/parquet/cli/commands/CSVSchemaCommand.java": [
                131,
                0
            ],
            "parquet-cli/src/main/java/org/apache/parquet/cli/commands/CatCommand.java": [
                106,
                0
            ],
            "parquet-cli/src/main/java/org/apache/parquet/cli/commands/CheckParquet251Command.java": [
                352,
                0
            ],
            "parquet-cli/src/main/java/org/apache/parquet/cli/commands/ColumnMaskingCommand.java": [
                115,
                0
            ],
            "parquet-cli/src/main/java/org/apache/parquet/cli/commands/ColumnSizeCommand.java": [
                137,
                0
            ],
            "parquet-cli/src/main/java/org/apache/parquet/cli/commands/ConvertCSVCommand.java": [
                204,
                0
            ],
            "parquet-cli/src/main/java/org/apache/parquet/cli/commands/ConvertCommand.java": [
                165,
                0
            ],
            "parquet-cli/src/main/java/org/apache/parquet/cli/commands/ParquetMetadataCommand.java": [
                183,
                0
            ],
            "parquet-cli/src/main/java/org/apache/parquet/cli/commands/PruneColumnsCommand.java": [
                82,
                0
            ],
            "parquet-cli/src/main/java/org/apache/parquet/cli/commands/RewriteCommand.java": [
                131,
                0
            ],
            "parquet-cli/src/main/java/org/apache/parquet/cli/commands/ScanCommand.java": [
                91,
                0
            ],
            "parquet-cli/src/main/java/org/apache/parquet/cli/commands/SchemaCommand.java": [
                132,
                0
            ],
            "parquet-cli/src/main/java/org/apache/parquet/cli/commands/ShowBloomFilterCommand.java": [
                133,
                0
            ],
            "parquet-cli/src/main/java/org/apache/parquet/cli/commands/ShowColumnIndexCommand.java": [
                157,
                0
            ],
            "parquet-cli/src/main/java/org/apache/parquet/cli/commands/ShowDictionaryCommand.java": [
                139,
                0
            ],
            "parquet-cli/src/main/java/org/apache/parquet/cli/commands/ShowFooterCommand.java": [
                101,
                0
            ],
            "parquet-cli/src/main/java/org/apache/parquet/cli/commands/ShowPagesCommand.java": [
                234,
                0
            ],
            "parquet-cli/src/main/java/org/apache/parquet/cli/commands/ToAvroCommand.java": [
                134,
                0
            ],
            "parquet-cli/src/main/java/org/apache/parquet/cli/commands/TransCompressionCommand.java": [
                101,
                0
            ],
            "parquet-cli/src/main/java/org/apache/parquet/cli/csv/AvroCSV.java": [
                258,
                0
            ],
            "parquet-cli/src/main/java/org/apache/parquet/cli/csv/AvroCSVReader.java": [
                121,
                0
            ],
            "parquet-cli/src/main/java/org/apache/parquet/cli/csv/CSVProperties.java": [
                120,
                0
            ],
            "parquet-cli/src/main/java/org/apache/parquet/cli/csv/RecordBuilder.java": [
                200,
                0
            ],
            "parquet-cli/src/main/java/org/apache/parquet/cli/json/AvroJson.java": [
                631,
                0
            ],
            "parquet-cli/src/main/java/org/apache/parquet/cli/json/AvroJsonReader.java": [
                77,
                0
            ],
            "parquet-cli/src/main/java/org/apache/parquet/cli/rawpages/RawPagesReader.java": [
                92,
                0
            ],
            "parquet-cli/src/main/java/org/apache/parquet/cli/util/Codecs.java": [
                52,
                0
            ],
            "parquet-cli/src/main/java/org/apache/parquet/cli/util/Expressions.java": [
                395,
                0
            ],
            "parquet-cli/src/main/java/org/apache/parquet/cli/util/Formats.java": [
                47,
                0
            ],
            "parquet-cli/src/main/java/org/apache/parquet/cli/util/GetClassLoader.java": [
                39,
                0
            ],
            "parquet-cli/src/main/java/org/apache/parquet/cli/util/RawUtils.java": [
                85,
                0
            ],
            "parquet-cli/src/main/java/org/apache/parquet/cli/util/RecordException.java": [
                55,
                0
            ],
            "parquet-cli/src/main/java/org/apache/parquet/cli/util/RuntimeIOException.java": [
                31,
                0
            ],
            "parquet-cli/src/main/java/org/apache/parquet/cli/util/Schemas.java": [
                501,
                0
            ],
            "parquet-cli/src/main/java/org/apache/parquet/cli/util/SeekableFSDataInputStream.java": [
                76,
                0
            ],
            "parquet-cli/src/main/resources/META-INF/LICENSE": null,
            "parquet-cli/src/main/resources/META-INF/NOTICE": null,
            "parquet-cli/src/main/resources/cli-logging.properties": null,
            "parquet-cli/src/test/java/org/apache/parquet/cli/BaseCommandTest.java": [
                100,
                0
            ],
            "parquet-cli/src/test/java/org/apache/parquet/cli/MainTest.java": [
                34,
                0
            ],
            "parquet-cli/src/test/java/org/apache/parquet/cli/commands/AvroFileTest.java": [
                53,
                0
            ],
            "parquet-cli/src/test/java/org/apache/parquet/cli/commands/CSVFileTest.java": [
                51,
                0
            ],
            "parquet-cli/src/test/java/org/apache/parquet/cli/commands/CSVSchemaCommandTest.java": [
                39,
                0
            ],
            "parquet-cli/src/test/java/org/apache/parquet/cli/commands/CatCommandTest.java": [
                38,
                0
            ],
            "parquet-cli/src/test/java/org/apache/parquet/cli/commands/CheckParquet251CommandTest.java": [
                38,
                0
            ],
            "parquet-cli/src/test/java/org/apache/parquet/cli/commands/ColumnSizeCommandTest.java": [
                91,
                0
            ],
            "parquet-cli/src/test/java/org/apache/parquet/cli/commands/ConvertCSVCommandTest.java": [
                41,
                0
            ],
            "parquet-cli/src/test/java/org/apache/parquet/cli/commands/ConvertCommandTest.java": [
                41,
                0
            ],
            "parquet-cli/src/test/java/org/apache/parquet/cli/commands/FileTest.java": [
                58,
                0
            ],
            "parquet-cli/src/test/java/org/apache/parquet/cli/commands/ParquetFileTest.java": [
                117,
                0
            ],
            "parquet-cli/src/test/java/org/apache/parquet/cli/commands/ParquetMetadataCommandTest.java": [
                38,
                0
            ],
            "parquet-cli/src/test/java/org/apache/parquet/cli/commands/RewriteCommandTest.java": [
                41,
                0
            ],
            "parquet-cli/src/test/java/org/apache/parquet/cli/commands/ScanCommandTest.java": [
                38,
                0
            ],
            "parquet-cli/src/test/java/org/apache/parquet/cli/commands/SchemaCommandTest.java": [
                68,
                0
            ],
            "parquet-cli/src/test/java/org/apache/parquet/cli/commands/ShowBloomFilterCommandTest.java": [
                41,
                0
            ],
            "parquet-cli/src/test/java/org/apache/parquet/cli/commands/ShowColumnIndexTest.java": [
                38,
                0
            ],
            "parquet-cli/src/test/java/org/apache/parquet/cli/commands/ShowDictionaryCommandTest.java": [
                50,
                0
            ],
            "parquet-cli/src/test/java/org/apache/parquet/cli/commands/ShowFooterCommandTest.java": [
                43,
                0
            ],
            "parquet-cli/src/test/java/org/apache/parquet/cli/commands/ShowPagesCommandTest.java": [
                38,
                0
            ],
            "parquet-cli/src/test/java/org/apache/parquet/cli/commands/ToAvroCommandTest.java": [
                113,
                0
            ],
            "parquet-cli/src/test/java/org/apache/parquet/cli/commands/TransCompressionCommandTest.java": [
                45,
                0
            ],
            "parquet-column/REVIEWERS.md": null,
            "parquet-column/pom.xml": null,
            "parquet-column/src/main/java/org/apache/parquet/CorruptDeltaByteArrays.java": [
                97,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/CorruptStatistics.java": [
                116,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/ColumnDescriptor.java": [
                156,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/ColumnProperty.java": [
                137,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/ColumnReadStore.java": [
                32,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/ColumnReader.java": [
                117,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/ColumnWriteStore.java": [
                75,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/ColumnWriter.java": [
                96,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/Dictionary.java": [
                63,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/Encoding.java": [
                309,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/EncodingStats.java": [
                157,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/MinMax.java": [
                56,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/ParquetProperties.java": [
                589,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/UnknownColumnException.java": [
                40,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/UnknownColumnTypeException.java": [
                41,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/ValuesType.java": [
                26,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/impl/ColumnReadStoreImpl.java": [
                104,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/impl/ColumnReaderBase.java": [
                790,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/impl/ColumnReaderImpl.java": [
                58,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/impl/ColumnWriteStoreBase.java": [
                273,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/impl/ColumnWriteStoreV1.java": [
                52,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/impl/ColumnWriteStoreV2.java": [
                46,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/impl/ColumnWriterBase.java": [
                408,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/impl/ColumnWriterV1.java": [
                68,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/impl/ColumnWriterV2.java": [
                94,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/impl/SynchronizingColumnReader.java": [
                111,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/page/DataPage.java": [
                72,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/page/DataPageV1.java": [
                127,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/page/DataPageV2.java": [
                207,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/page/DictionaryPage.java": [
                83,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/page/DictionaryPageReadStore.java": [
                36,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/page/Page.java": [
                62,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/page/PageReadStore.java": [
                64,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/page/PageReader.java": [
                40,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/page/PageWriteStore.java": [
                35,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/page/PageWriter.java": [
                102,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/statistics/BinaryStatistics.java": [
                188,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/statistics/BooleanStatistics.java": [
                147,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/statistics/DoubleStatistics.java": [
                147,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/statistics/FloatStatistics.java": [
                148,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/statistics/IntStatistics.java": [
                147,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/statistics/LongStatistics.java": [
                147,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/statistics/Statistics.java": [
                539,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/statistics/StatisticsClassException.java": [
                44,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/values/RequiresFallback.java": [
                51,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/values/RequiresPreviousReader.java": [
                23,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/values/ValuesReader.java": [
                205,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/values/ValuesWriter.java": [
                136,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/values/bitpacking/BitPackingValuesReader.java": [
                84,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/values/bitpacking/BitPackingValuesWriter.java": [
                130,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/values/bitpacking/ByteBitPackingValuesReader.java": [
                99,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/values/bitpacking/ByteBitPackingValuesWriter.java": [
                86,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/values/bitpacking/DevNullValuesWriter.java": [
                89,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/values/bloomfilter/AdaptiveBlockSplitBloomFilter.java": [
                305,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/values/bloomfilter/BlockSplitBloomFilter.java": [
                424,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/values/bloomfilter/BloomFilter.java": [
                203,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/values/bloomfilter/BloomFilterWriteStore.java": [
                35,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/values/bloomfilter/BloomFilterWriter.java": [
                31,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/values/bloomfilter/HashFunction.java": [
                41,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/values/bloomfilter/XxHash.java": [
                40,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/values/bytestreamsplit/ByteStreamSplitValuesReader.java": [
                111,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/values/bytestreamsplit/ByteStreamSplitValuesReaderForDouble.java": [
                37,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/values/bytestreamsplit/ByteStreamSplitValuesReaderForFloat.java": [
                37,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/values/bytestreamsplit/ByteStreamSplitValuesWriter.java": [
                142,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/values/delta/DeltaBinaryPackingConfig.java": [
                55,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/values/delta/DeltaBinaryPackingValuesReader.java": [
                171,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/values/delta/DeltaBinaryPackingValuesWriter.java": [
                136,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/values/delta/DeltaBinaryPackingValuesWriterForInteger.java": [
                196,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/values/delta/DeltaBinaryPackingValuesWriterForLong.java": [
                198,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/values/deltalengthbytearray/DeltaLengthByteArrayValuesReader.java": [
                80,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/values/deltalengthbytearray/DeltaLengthByteArrayValuesWriter.java": [
                115,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/values/deltastrings/DeltaByteArrayReader.java": [
                96,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/values/deltastrings/DeltaByteArrayWriter.java": [
                100,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/values/dictionary/DictionaryValuesReader.java": [
                131,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/values/dictionary/DictionaryValuesWriter.java": [
                597,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/values/dictionary/IntList.java": [
                159,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/values/dictionary/PlainValuesDictionary.java": [
                313,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/values/factory/DefaultV1ValuesWriterFactory.java": [
                122,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/values/factory/DefaultV2ValuesWriterFactory.java": [
                126,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/values/factory/DefaultValuesWriterFactory.java": [
                87,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/values/factory/ValuesWriterFactory.java": [
                52,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/values/fallback/FallbackValuesWriter.java": [
                204,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/values/plain/BinaryPlainValuesReader.java": [
                63,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/values/plain/BooleanPlainValuesReader.java": [
                73,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/values/plain/BooleanPlainValuesWriter.java": [
                81,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/values/plain/FixedLenByteArrayPlainValuesReader.java": [
                72,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/values/plain/FixedLenByteArrayPlainValuesWriter.java": [
                106,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/values/plain/PlainValuesReader.java": [
                139,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/values/plain/PlainValuesWriter.java": [
                148,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/values/rle/RunLengthBitPackingHybridDecoder.java": [
                107,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/values/rle/RunLengthBitPackingHybridEncoder.java": [
                293,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/values/rle/RunLengthBitPackingHybridValuesReader.java": [
                68,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/values/rle/RunLengthBitPackingHybridValuesWriter.java": [
                95,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/values/rle/ZeroIntegerValuesReader.java": [
                50,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/example/DummyRecordConverter.java": [
                114,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/example/Paper.java": [
                164,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/example/data/Group.java": [
                147,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/example/data/GroupFactory.java": [
                25,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/example/data/GroupValueSource.java": [
                89,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/example/data/GroupWriter.java": [
                62,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/example/data/simple/BinaryValue.java": [
                52,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/example/data/simple/BooleanValue.java": [
                44,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/example/data/simple/DoubleValue.java": [
                45,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/example/data/simple/FloatValue.java": [
                45,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/example/data/simple/Int96Value.java": [
                46,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/example/data/simple/IntegerValue.java": [
                46,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/example/data/simple/LongValue.java": [
                45,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/example/data/simple/NanoTime.java": [
                80,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/example/data/simple/Primitive.java": [
                60,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/example/data/simple/SimpleGroup.java": [
                236,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/example/data/simple/SimpleGroupFactory.java": [
                38,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/example/data/simple/convert/GroupRecordConverter.java": [
                57,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/example/data/simple/convert/SimpleGroupConverter.java": [
                67,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/example/data/simple/convert/SimplePrimitiveConverter.java": [
                88,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/filter/AndRecordFilter.java": [
                65,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/filter/ColumnPredicates.java": [
                191,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/filter/ColumnRecordFilter.java": [
                76,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/filter/NotRecordFilter.java": [
                60,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/filter/OrRecordFilter.java": [
                62,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/filter/PagedRecordFilter.java": [
                65,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/filter/RecordFilter.java": [
                33,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/filter/UnboundRecordFilter.java": [
                37,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/filter2/compat/FilterCompat.java": [
                181,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/filter2/predicate/FilterApi.java": [
                328,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/filter2/predicate/FilterPredicate.java": [
                84,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/filter2/predicate/LogicalInverseRewriter.java": [
                126,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/filter2/predicate/LogicalInverter.java": [
                120,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/filter2/predicate/Operators.java": [
                587,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/filter2/predicate/PrimitiveToBoxedClass.java": [
                50,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/filter2/predicate/SchemaCompatibilityValidator.java": [
                204,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/filter2/predicate/Statistics.java": [
                93,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/filter2/predicate/UserDefinedPredicate.java": [
                131,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/filter2/predicate/ValidTypeMap.java": [
                128,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/filter2/recordlevel/FilteringGroupConverter.java": [
                112,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/filter2/recordlevel/FilteringPrimitiveConverter.java": [
                109,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/filter2/recordlevel/FilteringRecordMaterializer.java": [
                116,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/filter2/recordlevel/IncrementallyUpdatedFilterPredicate.java": [
                166,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/filter2/recordlevel/IncrementallyUpdatedFilterPredicateBuilderBase.java": [
                116,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/filter2/recordlevel/IncrementallyUpdatedFilterPredicateEvaluator.java": [
                62,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/filter2/recordlevel/IncrementallyUpdatedFilterPredicateResetter.java": [
                59,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/internal/column/columnindex/BinaryColumnIndexBuilder.java": [
                140,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/internal/column/columnindex/BinaryTruncator.java": [
                221,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/internal/column/columnindex/BooleanColumnIndexBuilder.java": [
                133,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/internal/column/columnindex/BoundaryOrder.java": [
                384,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/internal/column/columnindex/ColumnIndex.java": [
                60,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/internal/column/columnindex/ColumnIndexBuilder.java": [
                686,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/internal/column/columnindex/DoubleColumnIndexBuilder.java": [
                155,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/internal/column/columnindex/FloatColumnIndexBuilder.java": [
                155,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/internal/column/columnindex/IndexIterator.java": [
                89,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/internal/column/columnindex/IntColumnIndexBuilder.java": [
                136,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/internal/column/columnindex/LongColumnIndexBuilder.java": [
                136,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/internal/column/columnindex/OffsetIndex.java": [
                73,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/internal/column/columnindex/OffsetIndexBuilder.java": [
                193,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/internal/filter2/columnindex/ColumnIndexFilter.java": [
                217,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/internal/filter2/columnindex/ColumnIndexStore.java": [
                55,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/internal/filter2/columnindex/RowRanges.java": [
                318,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/io/BaseRecordReader.java": [
                149,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/io/ColumnIO.java": [
                138,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/io/ColumnIOFactory.java": [
                174,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/io/CompilationException.java": [
                44,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/io/EmptyRecordReader.java": [
                48,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/io/FilteredRecordReader.java": [
                97,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/io/GroupColumnIO.java": [
                121,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/io/InvalidFileOffsetException.java": [
                29,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/io/InvalidRecordException.java": [
                45,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/io/MessageColumnIO.java": [
                534,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/io/ParquetDecodingException.java": [
                44,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/io/ParquetEncodingException.java": [
                44,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/io/PrimitiveColumnIO.java": [
                108,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/io/RecordConsumerLoggingWrapper.java": [
                187,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/io/RecordReader.java": [
                43,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/io/RecordReaderImplementation.java": [
                474,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/io/ValidatingRecordConsumer.java": [
                247,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/io/api/Binary.java": [
                737,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/io/api/Converter.java": [
                37,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/io/api/GroupConverter.java": [
                55,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/io/api/PrimitiveConverter.java": [
                108,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/io/api/RecordConsumer.java": [
                134,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/io/api/RecordMaterializer.java": [
                73,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/schema/ColumnOrder.java": [
                97,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/schema/ConversionPatterns.java": [
                133,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/schema/DecimalMetadata.java": [
                62,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/schema/GroupType.java": [
                421,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/schema/IncompatibleSchemaModificationException.java": [
                46,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/schema/InvalidSchemaException.java": [
                31,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/schema/LogicalTypeAnnotation.java": [
                1064,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/schema/MessageType.java": [
                145,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/schema/MessageTypeParser.java": [
                243,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/schema/OriginalType.java": [
                48,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/schema/PrimitiveComparator.java": [
                279,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/schema/PrimitiveStringifier.java": [
                451,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/schema/PrimitiveType.java": [
                797,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/schema/Type.java": [
                366,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/schema/TypeConverter.java": [
                53,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/schema/TypeUtil.java": [
                45,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/schema/TypeVisitor.java": [
                43,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/schema/Types.java": [
                1542,
                0
            ],
            "parquet-column/src/main/resources/META-INF/LICENSE": null,
            "parquet-column/src/test/java/org/apache/parquet/CorruptStatisticsTest.java": [
                92,
                0
            ],
            "parquet-column/src/test/java/org/apache/parquet/FixedBinaryTestUtils.java": [
                96,
                0
            ],
            "parquet-column/src/test/java/org/apache/parquet/ResourceIntensiveTestRule.java": [
                58,
                0
            ],
            "parquet-column/src/test/java/org/apache/parquet/column/TestColumnDescriptor.java": [
                52,
                0
            ],
            "parquet-column/src/test/java/org/apache/parquet/column/TestEncodingStats.java": [
                202,
                0
            ],
            "parquet-column/src/test/java/org/apache/parquet/column/impl/TestColumnReaderImpl.java": [
                131,
                0
            ],
            "parquet-column/src/test/java/org/apache/parquet/column/impl/TestCorruptDeltaByteArrays.java": [
                269,
                0
            ],
            "parquet-column/src/test/java/org/apache/parquet/column/mem/TestMemColumn.java": [
                246,
                0
            ],
            "parquet-column/src/test/java/org/apache/parquet/column/mem/TestMemPageStore.java": [
                61,
                0
            ],
            "parquet-column/src/test/java/org/apache/parquet/column/page/mem/MemPageReader.java": [
                67,
                0
            ],
            "parquet-column/src/test/java/org/apache/parquet/column/page/mem/MemPageStore.java": [
                78,
                0
            ],
            "parquet-column/src/test/java/org/apache/parquet/column/page/mem/MemPageWriter.java": [
                117,
                0
            ],
            "parquet-column/src/test/java/org/apache/parquet/column/statistics/TestStatistics.java": [
                789,
                0
            ],
            "parquet-column/src/test/java/org/apache/parquet/column/values/TestValuesReaderImpl.java": [
                148,
                0
            ],
            "parquet-column/src/test/java/org/apache/parquet/column/values/Utils.java": [
                76,
                0
            ],
            "parquet-column/src/test/java/org/apache/parquet/column/values/bitpacking/BitPackingPerfTest.java": [
                103,
                0
            ],
            "parquet-column/src/test/java/org/apache/parquet/column/values/bitpacking/TestBitPackingColumn.java": [
                232,
                0
            ],
            "parquet-column/src/test/java/org/apache/parquet/column/values/bloomfilter/TestBlockSplitBloomFilter.java": [
                325,
                0
            ],
            "parquet-column/src/test/java/org/apache/parquet/column/values/bytestreamsplit/ByteStreamSplitValuesEndToEndTest.java": [
                111,
                0
            ],
            "parquet-column/src/test/java/org/apache/parquet/column/values/bytestreamsplit/ByteStreamSplitValuesReaderTest.java": [
                193,
                0
            ],
            "parquet-column/src/test/java/org/apache/parquet/column/values/bytestreamsplit/ByteStreamSplitValuesWriterTest.java": [
                189,
                0
            ],
            "parquet-column/src/test/java/org/apache/parquet/column/values/delta/DeltaBinaryPackingValuesWriterForIntegerTest.java": [
                294,
                0
            ],
            "parquet-column/src/test/java/org/apache/parquet/column/values/delta/DeltaBinaryPackingValuesWriterForLongTest.java": [
                291,
                0
            ],
            "parquet-column/src/test/java/org/apache/parquet/column/values/delta/benchmark/BenchMarkTest.java": [
                41,
                0
            ],
            "parquet-column/src/test/java/org/apache/parquet/column/values/delta/benchmark/BenchmarkIntegerOutputSize.java": [
                107,
                0
            ],
            "parquet-column/src/test/java/org/apache/parquet/column/values/delta/benchmark/BenchmarkReadingRandomIntegers.java": [
                102,
                0
            ],
            "parquet-column/src/test/java/org/apache/parquet/column/values/delta/benchmark/RandomWritingBenchmarkTest.java": [
                76,
                0
            ],
            "parquet-column/src/test/java/org/apache/parquet/column/values/delta/benchmark/SmallRangeWritingBenchmarkTest.java": [
                49,
                0
            ],
            "parquet-column/src/test/java/org/apache/parquet/column/values/deltalengthbytearray/TestDeltaLengthByteArray.java": [
                103,
                0
            ],
            "parquet-column/src/test/java/org/apache/parquet/column/values/deltalengthbytearray/benchmark/BenchmarkDeltaLengthByteArray.java": [
                73,
                0
            ],
            "parquet-column/src/test/java/org/apache/parquet/column/values/deltastrings/TestDeltaByteArray.java": [
                130,
                0
            ],
            "parquet-column/src/test/java/org/apache/parquet/column/values/deltastrings/benchmark/BenchmarkDeltaByteArray.java": [
                103,
                0
            ],
            "parquet-column/src/test/java/org/apache/parquet/column/values/dictionary/IntListTest.java": [
                84,
                0
            ],
            "parquet-column/src/test/java/org/apache/parquet/column/values/dictionary/TestDictionary.java": [
                661,
                0
            ],
            "parquet-column/src/test/java/org/apache/parquet/column/values/factory/DefaultValuesWriterFactoryTest.java": [
                546,
                0
            ],
            "parquet-column/src/test/java/org/apache/parquet/column/values/rle/RunLengthBitPackingHybridIntegrationTest.java": [
                86,
                0
            ],
            "parquet-column/src/test/java/org/apache/parquet/column/values/rle/TestRunLengthBitPackingHybridEncoder.java": [
                329,
                0
            ],
            "parquet-column/src/test/java/org/apache/parquet/filter2/predicate/DummyUdp.java": [
                37,
                0
            ],
            "parquet-column/src/test/java/org/apache/parquet/filter2/predicate/TestFilterApiMethods.java": [
                172,
                0
            ],
            "parquet-column/src/test/java/org/apache/parquet/filter2/predicate/TestLogicalInverseRewriter.java": [
                103,
                0
            ],
            "parquet-column/src/test/java/org/apache/parquet/filter2/predicate/TestLogicalInverter.java": [
                94,
                0
            ],
            "parquet-column/src/test/java/org/apache/parquet/filter2/predicate/TestSchemaCompatibilityValidator.java": [
                142,
                0
            ],
            "parquet-column/src/test/java/org/apache/parquet/filter2/predicate/TestValidTypeMap.java": [
                98,
                0
            ],
            "parquet-column/src/test/java/org/apache/parquet/filter2/recordlevel/TestIncrementallyUpdatedFilterPredicateEvaluator.java": [
                209,
                0
            ],
            "parquet-column/src/test/java/org/apache/parquet/filter2/recordlevel/TestIncrementallyUpdatedFilterPredicateResetter.java": [
                69,
                0
            ],
            "parquet-column/src/test/java/org/apache/parquet/filter2/recordlevel/TestValueInspector.java": [
                97,
                0
            ],
            "parquet-column/src/test/java/org/apache/parquet/internal/column/columnindex/TestBinaryTruncator.java": [
                285,
                0
            ],
            "parquet-column/src/test/java/org/apache/parquet/internal/column/columnindex/TestBoundaryOrder.java": [
                543,
                0
            ],
            "parquet-column/src/test/java/org/apache/parquet/internal/column/columnindex/TestColumnIndexBuilder.java": [
                1728,
                0
            ],
            "parquet-column/src/test/java/org/apache/parquet/internal/column/columnindex/TestIndexIterator.java": [
                63,
                0
            ],
            "parquet-column/src/test/java/org/apache/parquet/internal/column/columnindex/TestOffsetIndexBuilder.java": [
                111,
                0
            ],
            "parquet-column/src/test/java/org/apache/parquet/internal/filter2/columnindex/TestColumnIndexFilter.java": [
                555,
                0
            ],
            "parquet-column/src/test/java/org/apache/parquet/internal/filter2/columnindex/TestRowRanges.java": [
                155,
                0
            ],
            "parquet-column/src/test/java/org/apache/parquet/io/ConverterConsumer.java": [
                125,
                0
            ],
            "parquet-column/src/test/java/org/apache/parquet/io/ExpectationValidatingConverter.java": [
                169,
                0
            ],
            "parquet-column/src/test/java/org/apache/parquet/io/ExpectationValidatingRecordConsumer.java": [
                112,
                0
            ],
            "parquet-column/src/test/java/org/apache/parquet/io/PerfTest.java": [
                128,
                0
            ],
            "parquet-column/src/test/java/org/apache/parquet/io/TestColumnIO.java": [
                709,
                0
            ],
            "parquet-column/src/test/java/org/apache/parquet/io/TestFiltered.java": [
                278,
                0
            ],
            "parquet-column/src/test/java/org/apache/parquet/io/api/TestBinary.java": [
                271,
                0
            ],
            "parquet-column/src/test/java/org/apache/parquet/parser/TestParquetParser.java": [
                374,
                0
            ],
            "parquet-column/src/test/java/org/apache/parquet/schema/TestMessageType.java": [
                247,
                0
            ],
            "parquet-column/src/test/java/org/apache/parquet/schema/TestPrimitiveComparator.java": [
                330,
                0
            ],
            "parquet-column/src/test/java/org/apache/parquet/schema/TestPrimitiveStringifier.java": [
                391,
                0
            ],
            "parquet-column/src/test/java/org/apache/parquet/schema/TestRepetitionType.java": [
                36,
                0
            ],
            "parquet-column/src/test/java/org/apache/parquet/schema/TestTypeBuilders.java": [
                1372,
                0
            ],
            "parquet-column/src/test/java/org/apache/parquet/schema/TestTypeBuildersWithLogicalTypes.java": [
                422,
                0
            ],
            "parquet-column/src/test/java/org/apache/parquet/schema/TestTypeUtil.java": [
                80,
                0
            ],
            "parquet-common/REVIEWERS.md": null,
            "parquet-common/pom.xml": null,
            "parquet-common/src/main/java/org/apache/parquet/Closeables.java": [
                60,
                0
            ],
            "parquet-common/src/main/java/org/apache/parquet/Exceptions.java": [
                39,
                0
            ],
            "parquet-common/src/main/java/org/apache/parquet/Files.java": [
                54,
                0
            ],
            "parquet-common/src/main/java/org/apache/parquet/IOExceptionUtils.java": [
                45,
                0
            ],
            "parquet-common/src/main/java/org/apache/parquet/Ints.java": [
                44,
                0
            ],
            "parquet-common/src/main/java/org/apache/parquet/Log.java": [
                146,
                0
            ],
            "parquet-common/src/main/java/org/apache/parquet/OutputStreamCloseException.java": [
                46,
                0
            ],
            "parquet-common/src/main/java/org/apache/parquet/ParquetRuntimeException.java": [
                42,
                0
            ],
            "parquet-common/src/main/java/org/apache/parquet/Preconditions.java": [
                251,
                0
            ],
            "parquet-common/src/main/java/org/apache/parquet/SemanticVersion.java": [
                293,
                0
            ],
            "parquet-common/src/main/java/org/apache/parquet/ShouldNeverHappenException.java": [
                40,
                0
            ],
            "parquet-common/src/main/java/org/apache/parquet/Strings.java": [
                132,
                0
            ],
            "parquet-common/src/main/java/org/apache/parquet/VersionParser.java": [
                129,
                0
            ],
            "parquet-common/src/main/java/org/apache/parquet/bytes/ByteBufferAllocator.java": [
                40,
                0
            ],
            "parquet-common/src/main/java/org/apache/parquet/bytes/ByteBufferInputStream.java": [
                160,
                0
            ],
            "parquet-common/src/main/java/org/apache/parquet/bytes/BytesInput.java": [
                545,
                0
            ],
            "parquet-common/src/main/java/org/apache/parquet/bytes/BytesUtils.java": [
                335,
                0
            ],
            "parquet-common/src/main/java/org/apache/parquet/bytes/CapacityByteArrayOutputStream.java": [
                352,
                0
            ],
            "parquet-common/src/main/java/org/apache/parquet/bytes/ConcatenatingByteArrayCollector.java": [
                63,
                0
            ],
            "parquet-common/src/main/java/org/apache/parquet/bytes/DirectByteBufferAllocator.java": [
                43,
                0
            ],
            "parquet-common/src/main/java/org/apache/parquet/bytes/HeapByteBufferAllocator.java": [
                44,
                0
            ],
            "parquet-common/src/main/java/org/apache/parquet/bytes/LittleEndianDataInputStream.java": [
                421,
                0
            ],
            "parquet-common/src/main/java/org/apache/parquet/bytes/LittleEndianDataOutputStream.java": [
                218,
                0
            ],
            "parquet-common/src/main/java/org/apache/parquet/bytes/MultiBufferInputStream.java": [
                382,
                0
            ],
            "parquet-common/src/main/java/org/apache/parquet/bytes/SingleBufferInputStream.java": [
                177,
                0
            ],
            "parquet-common/src/main/java/org/apache/parquet/compression/CompressionCodecFactory.java": [
                47,
                0
            ],
            "parquet-common/src/main/java/org/apache/parquet/glob/GlobExpander.java": [
                129,
                0
            ],
            "parquet-common/src/main/java/org/apache/parquet/glob/GlobNode.java": [
                157,
                0
            ],
            "parquet-common/src/main/java/org/apache/parquet/glob/GlobParser.java": [
                224,
                0
            ],
            "parquet-common/src/main/java/org/apache/parquet/glob/WildcardPath.java": [
                121,
                0
            ],
            "parquet-common/src/main/java/org/apache/parquet/hadoop/codec/CompressionCodecNotSupportedException.java": [
                38,
                0
            ],
            "parquet-common/src/main/java/org/apache/parquet/hadoop/metadata/Canonicalizer.java": [
                61,
                0
            ],
            "parquet-common/src/main/java/org/apache/parquet/hadoop/metadata/ColumnPath.java": [
                88,
                0
            ],
            "parquet-common/src/main/java/org/apache/parquet/hadoop/metadata/CompressionCodecName.java": [
                99,
                0
            ],
            "parquet-common/src/main/java/org/apache/parquet/io/DelegatingPositionOutputStream.java": [
                63,
                0
            ],
            "parquet-common/src/main/java/org/apache/parquet/io/DelegatingSeekableInputStream.java": [
                171,
                0
            ],
            "parquet-common/src/main/java/org/apache/parquet/io/InputFile.java": [
                44,
                0
            ],
            "parquet-common/src/main/java/org/apache/parquet/io/LocalInputFile.java": [
                102,
                0
            ],
            "parquet-common/src/main/java/org/apache/parquet/io/LocalOutputFile.java": [
                107,
                0
            ],
            "parquet-common/src/main/java/org/apache/parquet/io/OutputFile.java": [
                62,
                0
            ],
            "parquet-common/src/main/java/org/apache/parquet/io/PositionOutputStream.java": [
                39,
                0
            ],
            "parquet-common/src/main/java/org/apache/parquet/io/SeekableInputStream.java": [
                108,
                0
            ],
            "parquet-common/src/main/java/org/apache/parquet/util/DynConstructors.java": [
                263,
                0
            ],
            "parquet-common/src/main/java/org/apache/parquet/util/DynMethods.java": [
                506,
                0
            ],
            "parquet-common/src/test/java/org/apache/parquet/SemanticVersionTest.java": [
                114,
                0
            ],
            "parquet-common/src/test/java/org/apache/parquet/TestPreconditions.java": [
                246,
                0
            ],
            "parquet-common/src/test/java/org/apache/parquet/TestUtils.java": [
                70,
                0
            ],
            "parquet-common/src/test/java/org/apache/parquet/VersionTest.java": [
                100,
                0
            ],
            "parquet-common/src/test/java/org/apache/parquet/bytes/TestByteBufferInputStreams.java": [
                589,
                0
            ],
            "parquet-common/src/test/java/org/apache/parquet/bytes/TestBytesUtil.java": [
                49,
                0
            ],
            "parquet-common/src/test/java/org/apache/parquet/bytes/TestDeprecatedBufferInputStream.java": [
                152,
                0
            ],
            "parquet-common/src/test/java/org/apache/parquet/bytes/TestMultiBufferInputStream.java": [
                141,
                0
            ],
            "parquet-common/src/test/java/org/apache/parquet/bytes/TestSingleBufferInputStream.java": [
                130,
                0
            ],
            "parquet-common/src/test/java/org/apache/parquet/glob/TestGlob.java": [
                144,
                0
            ],
            "parquet-common/src/test/java/org/apache/parquet/glob/TestWildcardPath.java": [
                125,
                0
            ],
            "parquet-common/src/test/java/org/apache/parquet/io/MockInputStream.java": [
                56,
                0
            ],
            "parquet-common/src/test/java/org/apache/parquet/io/TestDelegatingSeekableInputStream.java": [
                844,
                0
            ],
            "parquet-common/src/test/java/org/apache/parquet/io/TestLocalInputOutput.java": [
                92,
                0
            ],
            "parquet-common/src/test/java/org/apache/parquet/util/Concatenator.java": [
                82,
                0
            ],
            "parquet-common/src/test/java/org/apache/parquet/util/TestDynConstructors.java": [
                165,
                0
            ],
            "parquet-common/src/test/java/org/apache/parquet/util/TestDynMethods.java": [
                315,
                0
            ],
            "parquet-encoding/REVIEWERS.md": null,
            "parquet-encoding/pom.xml": null,
            "parquet-encoding/src/main/java/org/apache/parquet/column/values/bitpacking/BitPacking.java": [
                717,
                0
            ],
            "parquet-encoding/src/main/java/org/apache/parquet/column/values/bitpacking/ByteBasedBitPackingEncoder.java": [
                142,
                0
            ],
            "parquet-encoding/src/main/java/org/apache/parquet/column/values/bitpacking/BytePacker.java": [
                141,
                0
            ],
            "parquet-encoding/src/main/java/org/apache/parquet/column/values/bitpacking/BytePackerFactory.java": [
                25,
                0
            ],
            "parquet-encoding/src/main/java/org/apache/parquet/column/values/bitpacking/BytePackerForLong.java": [
                109,
                0
            ],
            "parquet-encoding/src/main/java/org/apache/parquet/column/values/bitpacking/BytePackerForLongFactory.java": [
                25,
                0
            ],
            "parquet-encoding/src/main/java/org/apache/parquet/column/values/bitpacking/IntPacker.java": [
                63,
                0
            ],
            "parquet-encoding/src/main/java/org/apache/parquet/column/values/bitpacking/IntPackerFactory.java": [
                25,
                0
            ],
            "parquet-encoding/src/main/java/org/apache/parquet/column/values/bitpacking/Packer.java": [
                137,
                0
            ],
            "parquet-encoding/src/main/resources/META-INF/LICENSE": null,
            "parquet-encoding/src/test/java/org/apache/parquet/bytes/TestBytesInput.java": [
                42,
                0
            ],
            "parquet-encoding/src/test/java/org/apache/parquet/bytes/TestCapacityByteArrayOutputStream.java": [
                242,
                0
            ],
            "parquet-encoding/src/test/java/org/apache/parquet/column/values/bitpacking/TestBitPacking.java": [
                233,
                0
            ],
            "parquet-encoding/src/test/java/org/apache/parquet/column/values/bitpacking/TestByteBasedBitPackingEncoder.java": [
                46,
                0
            ],
            "parquet-encoding/src/test/java/org/apache/parquet/column/values/bitpacking/TestByteBitPacking.java": [
                198,
                0
            ],
            "parquet-encoding/src/test/java/org/apache/parquet/column/values/bitpacking/TestLemireBitPacking.java": [
                125,
                0
            ],
            "parquet-format-structures/pom.xml": null,
            "parquet-format-structures/src/main/java/org/apache/parquet/format/BlockCipher.java": [
                76,
                0
            ],
            "parquet-format-structures/src/main/java/org/apache/parquet/format/CliUtils.java": [
                55,
                0
            ],
            "parquet-format-structures/src/main/java/org/apache/parquet/format/InterningProtocol.java": [
                236,
                0
            ],
            "parquet-format-structures/src/main/java/org/apache/parquet/format/InvalidParquetMetadataException.java": [
                30,
                0
            ],
            "parquet-format-structures/src/main/java/org/apache/parquet/format/LogicalTypes.java": [
                55,
                0
            ],
            "parquet-format-structures/src/main/java/org/apache/parquet/format/MetadataValidator.java": [
                44,
                0
            ],
            "parquet-format-structures/src/main/java/org/apache/parquet/format/Util.java": [
                389,
                0
            ],
            "parquet-format-structures/src/main/java/org/apache/parquet/format/event/Consumers.java": [
                191,
                0
            ],
            "parquet-format-structures/src/main/java/org/apache/parquet/format/event/EventBasedThriftReader.java": [
                126,
                0
            ],
            "parquet-format-structures/src/main/java/org/apache/parquet/format/event/FieldConsumer.java": [
                39,
                0
            ],
            "parquet-format-structures/src/main/java/org/apache/parquet/format/event/TypedConsumer.java": [
                205,
                0
            ],
            "parquet-format-structures/src/test/java/org/apache/parquet/format/TestUtil.java": [
                101,
                0
            ],
            "parquet-generator/REVIEWERS.md": null,
            "parquet-generator/pom.xml": null,
            "parquet-generator/src/main/java/org/apache/parquet/encoding/Generator.java": [
                34,
                0
            ],
            "parquet-generator/src/main/java/org/apache/parquet/encoding/bitpacking/ByteBasedBitPackingGenerator.java": [
                319,
                0
            ],
            "parquet-generator/src/main/java/org/apache/parquet/encoding/bitpacking/IntBasedBitPackingGenerator.java": [
                208,
                0
            ],
            "parquet-generator/src/main/java/org/apache/parquet/filter2/Generator.java": [
                28,
                0
            ],
            "parquet-generator/src/main/java/org/apache/parquet/filter2/IncrementallyUpdatedFilterPredicateGenerator.java": [
                335,
                0
            ],
            "parquet-generator/src/main/java/org/apache/parquet/version/Generator.java": [
                28,
                0
            ],
            "parquet-generator/src/main/java/org/apache/parquet/version/VersionGenerator.java": [
                87,
                0
            ],
            "parquet-generator/src/main/resources/META-INF/LICENSE": null,
            "parquet-generator/src/main/resources/parquet-version.properties": null,
            "parquet-hadoop-bundle/README": null,
            "parquet-hadoop-bundle/pom.xml": null,
            "parquet-hadoop-bundle/src/main/resources/META-INF/LICENSE": null,
            "parquet-hadoop-bundle/src/main/resources/org/apache/parquet/bundle": null,
            "parquet-hadoop/README.md": null,
            "parquet-hadoop/REVIEWERS.md": null,
            "parquet-hadoop/pom.xml": null,
            "parquet-hadoop/src/main/java/org/apache/parquet/HadoopReadOptions.java": [
                143,
                0
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/ParquetReadOptions.java": [
                345,
                0
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/crypto/AADPrefixVerifier.java": [
                32,
                0
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/crypto/AesCipher.java": [
                164,
                0
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/crypto/AesCtrDecryptor.java": [
                170,
                0
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/crypto/AesCtrEncryptor.java": [
                104,
                0
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/crypto/AesGcmDecryptor.java": [
                151,
                0
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/crypto/AesGcmEncryptor.java": [
                91,
                0
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/crypto/AesMode.java": [
                35,
                0
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/crypto/ColumnDecryptionProperties.java": [
                104,
                0
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/crypto/ColumnEncryptionProperties.java": [
                195,
                0
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/crypto/DecryptionKeyRetriever.java": [
                39,
                0
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/crypto/DecryptionPropertiesFactory.java": [
                88,
                0
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/crypto/EncryptionPropertiesFactory.java": [
                93,
                0
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/crypto/FileDecryptionProperties.java": [
                254,
                0
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/crypto/FileEncryptionProperties.java": [
                278,
                0
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/crypto/InternalColumnDecryptionSetup.java": [
                74,
                0
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/crypto/InternalColumnEncryptionSetup.java": [
                82,
                0
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/crypto/InternalFileDecryptor.java": [
                312,
                0
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/crypto/InternalFileEncryptor.java": [
                200,
                0
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/crypto/KeyAccessDeniedException.java": [
                39,
                0
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/crypto/ModuleCipherFactory.java": [
                73,
                0
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/crypto/ParquetCipher.java": [
                42,
                0
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/crypto/ParquetCryptoRuntimeException.java": [
                42,
                0
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/crypto/TagVerificationException.java": [
                39,
                0
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/crypto/keytools/FileKeyMaterialStore.java": [
                72,
                0
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/crypto/keytools/FileKeyUnwrapper.java": [
                178,
                0
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/crypto/keytools/FileKeyWrapper.java": [
                177,
                0
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/crypto/keytools/HadoopFSKeyMaterialStore.java": [
                136,
                0
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/crypto/keytools/KeyMaterial.java": [
                210,
                0
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/crypto/keytools/KeyMetadata.java": [
                130,
                0
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/crypto/keytools/KeyToolkit.java": [
                394,
                0
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/crypto/keytools/KmsClient.java": [
                72,
                0
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/crypto/keytools/LocalWrapKmsClient.java": [
                181,
                0
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/crypto/keytools/PropertiesDrivenCryptoFactory.java": [
                258,
                0
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/crypto/keytools/TwoLevelCacheWithExpiration.java": [
                105,
                0
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/filter2/bloomfilterlevel/BloomFilterImpl.java": [
                187,
                0
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/filter2/compat/RowGroupFilter.java": [
                131,
                0
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/filter2/dictionarylevel/DictionaryFilter.java": [
                570,
                0
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/filter2/statisticslevel/StatisticsFilter.java": [
                485,
                0
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/format/converter/ParquetMetadataConverter.java": [
                2080,
                0
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/BadConfigurationException.java": [
                44,
                0
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/BloomFilterReader.java": [
                70,
                0
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/CodecFactory.java": [
                289,
                0
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ColumnChunkPageReadStore.java": [
                364,
                0
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ColumnChunkPageWriteStore.java": [
                462,
                0
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ColumnConfigParser.java": [
                72,
                0
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ColumnIndexFilterUtils.java": [
                162,
                0
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ColumnIndexStoreImpl.java": [
                155,
                0
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ColumnIndexValidator.java": [
                613,
                0
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/DictionaryPageReader.java": [
                115,
                0
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/DirectCodecFactory.java": [
                528,
                0
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/DirectZstd.java": [
                144,
                0
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/Footer.java": [
                53,
                0
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/InternalParquetRecordReader.java": [
                321,
                0
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/InternalParquetRecordWriter.java": [
                209,
                0
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/LruCache.java": [
                195,
                0
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/MemoryManager.java": [
                199,
                0
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/Offsets.java": [
                94,
                0
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ParquetEmptyBlockException.java": [
                41,
                0
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ParquetFileReader.java": [
                1869,
                0
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ParquetFileWriter.java": [
                1731,
                0
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ParquetInputFormat.java": [
                837,
                0
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ParquetInputSplit.java": [
                295,
                0
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ParquetMemoryManagerRuntimeException.java": [
                38,
                0
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ParquetOutputCommitter.java": [
                112,
                0
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ParquetOutputFormat.java": [
                570,
                0
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ParquetReader.java": [
                379,
                0
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ParquetRecordReader.java": [
                233,
                0
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ParquetRecordWriter.java": [
                184,
                0
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ParquetWriter.java": [
                744,
                0
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/PrintFooter.java": [
                265,
                0
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/UnmaterializableRecordCounter.java": [
                103,
                0
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/api/DelegatingReadSupport.java": [
                60,
                0
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/api/DelegatingWriteSupport.java": [
                69,
                0
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/api/InitContext.java": [
                99,
                0
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/api/ReadSupport.java": [
                145,
                0
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/api/WriteSupport.java": [
                140,
                0
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/api/package-info.java": [
                27,
                0
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/codec/CleanUtil.java": [
                111,
                0
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/codec/CodecConfig.java": [
                167,
                0
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/codec/Lz4RawCodec.java": [
                112,
                0
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/codec/Lz4RawCompressor.java": [
                44,
                0
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/codec/Lz4RawDecompressor.java": [
                46,
                0
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/codec/NonBlockedCompressor.java": [
                192,
                0
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/codec/NonBlockedCompressorStream.java": [
                50,
                0
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/codec/NonBlockedDecompressor.java": [
                180,
                0
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/codec/NonBlockedDecompressorStream.java": [
                57,
                0
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/codec/SnappyCodec.java": [
                105,
                0
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/codec/SnappyCompressor.java": [
                38,
                0
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/codec/SnappyDecompressor.java": [
                38,
                0
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/codec/SnappyUtil.java": [
                33,
                0
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/codec/ZstandardCodec.java": [
                130,
                0
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/codec/ZstdCompressorStream.java": [
                70,
                0
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/codec/ZstdDecompressorStream.java": [
                62,
                0
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/example/ExampleInputFormat.java": [
                35,
                0
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/example/ExampleOutputFormat.java": [
                58,
                0
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/example/ExampleParquetWriter.java": [
                118,
                0
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/example/GroupReadSupport.java": [
                49,
                0
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/example/GroupWriteSupport.java": [
                88,
                0
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/mapred/Container.java": [
                37,
                0
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/mapred/DeprecatedParquetInputFormat.java": [
                209,
                0
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/mapred/DeprecatedParquetOutputFormat.java": [
                119,
                0
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/mapred/MapredParquetOutputCommitter.java": [
                42,
                0
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/metadata/BlockMetaData.java": [
                153,
                0
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/metadata/ColumnChunkMetaData.java": [
                683,
                0
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/metadata/ColumnChunkProperties.java": [
                118,
                0
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/metadata/ConcatenatingKeyValueMetadataMergeStrategy.java": [
                61,
                0
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/metadata/EncodingList.java": [
                81,
                0
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/metadata/FileMetaData.java": [
                108,
                0
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/metadata/GlobalMetaData.java": [
                110,
                0
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/metadata/KeyValueMetadataMergeStrategy.java": [
                42,
                0
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/metadata/ParquetMetadata.java": [
                134,
                0
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/metadata/StrictKeyValueMetadataMergeStrategy.java": [
                42,
                0
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/package-info.java": [
                33,
                0
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/rewrite/MaskMode.java": [
                38,
                0
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/rewrite/ParquetRewriter.java": [
                819,
                0
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/rewrite/RewriteOptions.java": [
                262,
                0
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/util/ColumnEncryptor.java": [
                90,
                0
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/util/ColumnMasker.java": [
                98,
                0
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/util/ColumnPruner.java": [
                42,
                0
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/util/CompressionConverter.java": [
                81,
                0
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/util/ConfigurationUtil.java": [
                44,
                0
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/util/ContextUtil.java": [
                315,
                0
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/util/H1SeekableInputStream.java": [
                59,
                0
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/util/H2SeekableInputStream.java": [
                99,
                0
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/util/HadoopCodecs.java": [
                39,
                0
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/util/HadoopInputFile.java": [
                76,
                0
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/util/HadoopOutputFile.java": [
                105,
                0
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/util/HadoopPositionOutputStream.java": [
                66,
                0
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/util/HadoopStreams.java": [
                148,
                0
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/util/HiddenFileFilter.java": [
                39,
                0
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/util/SerializationUtil.java": [
                93,
                0
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/util/counters/BenchmarkCounter.java": [
                112,
                0
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/util/counters/CounterLoader.java": [
                27,
                0
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/util/counters/ICounter.java": [
                28,
                0
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/util/counters/mapred/MapRedCounterAdapter.java": [
                43,
                0
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/util/counters/mapred/MapRedCounterLoader.java": [
                51,
                0
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/util/counters/mapreduce/MapReduceCounterAdapter.java": [
                44,
                0
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/util/counters/mapreduce/MapReduceCounterLoader.java": [
                47,
                0
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/internal/hadoop/metadata/IndexReference.java": [
                41,
                0
            ],
            "parquet-hadoop/src/main/resources/META-INF/LICENSE": null,
            "parquet-hadoop/src/test/java/org/apache/parquet/DirectWriterTest.java": [
                102,
                0
            ],
            "parquet-hadoop/src/test/java/org/apache/parquet/crypto/DecryptionKeyRetrieverMock.java": [
                41,
                0
            ],
            "parquet-hadoop/src/test/java/org/apache/parquet/crypto/DecryptionPropertiesFactoryTest.java": [
                43,
                0
            ],
            "parquet-hadoop/src/test/java/org/apache/parquet/crypto/EncryptionPropertiesFactoryTest.java": [
                45,
                0
            ],
            "parquet-hadoop/src/test/java/org/apache/parquet/crypto/SampleDecryptionPropertiesFactory.java": [
                57,
                0
            ],
            "parquet-hadoop/src/test/java/org/apache/parquet/crypto/SampleEncryptionPropertiesFactory.java": [
                58,
                0
            ],
            "parquet-hadoop/src/test/java/org/apache/parquet/crypto/SingleRow.java": [
                139,
                0
            ],
            "parquet-hadoop/src/test/java/org/apache/parquet/crypto/TestPropertiesDrivenEncryption.java": [
                705,
                0
            ],
            "parquet-hadoop/src/test/java/org/apache/parquet/crypto/keytools/mocks/InMemoryKMS.java": [
                116,
                0
            ],
            "parquet-hadoop/src/test/java/org/apache/parquet/crypto/keytools/mocks/LocalWrapInMemoryKMS.java": [
                79,
                0
            ],
            "parquet-hadoop/src/test/java/org/apache/parquet/crypto/keytools/samples/VaultClient.java": [
                184,
                0
            ],
            "parquet-hadoop/src/test/java/org/apache/parquet/crypto/propertiesfactory/SchemaControlEncryptionTest.java": [
                250,
                0
            ],
            "parquet-hadoop/src/test/java/org/apache/parquet/crypto/propertiesfactory/SchemaCryptoPropertiesFactory.java": [
                137,
                0
            ],
            "parquet-hadoop/src/test/java/org/apache/parquet/encodings/FileEncodingsIT.java": [
                564,
                0
            ],
            "parquet-hadoop/src/test/java/org/apache/parquet/filter2/TestFiltersWithMissingColumns.java": [
                275,
                0
            ],
            "parquet-hadoop/src/test/java/org/apache/parquet/filter2/compat/TestRowGroupFilter.java": [
                128,
                0
            ],
            "parquet-hadoop/src/test/java/org/apache/parquet/filter2/dictionarylevel/DictionaryFilterTest.java": [
                839,
                0
            ],
            "parquet-hadoop/src/test/java/org/apache/parquet/filter2/recordlevel/PhoneBookWriter.java": [
                373,
                0
            ],
            "parquet-hadoop/src/test/java/org/apache/parquet/filter2/recordlevel/TestRecordLevelFilters.java": [
                310,
                0
            ],
            "parquet-hadoop/src/test/java/org/apache/parquet/filter2/statisticslevel/TestStatisticsFilter.java": [
                561,
                0
            ],
            "parquet-hadoop/src/test/java/org/apache/parquet/format/converter/TestParquetMetadataConverter.java": [
                1389,
                0
            ],
            "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/DeprecatedInputFormatTest.java": [
                346,
                0
            ],
            "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/DeprecatedOutputFormatTest.java": [
                108,
                0
            ],
            "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/ITTestEncryptionOptions.java": [
                50,
                0
            ],
            "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/TestAdaptiveBlockSplitBloomFiltering.java": [
                78,
                0
            ],
            "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/TestBloomFiltering.java": [
                421,
                0
            ],
            "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/TestColumnChunkPageWriteStore.java": [
                288,
                0
            ],
            "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/TestColumnIndexFiltering.java": [
                617,
                0
            ],
            "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/TestDataPageV1Checksums.java": [
                563,
                0
            ],
            "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/TestDirectCodecFactory.java": [
                178,
                0
            ],
            "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/TestEncryptionOptions.java": [
                752,
                0
            ],
            "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/TestInputFormat.java": [
                555,
                0
            ],
            "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/TestInputFormatColumnProjection.java": [
                180,
                0
            ],
            "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/TestInputOutputFormatWithPadding.java": [
                214,
                0
            ],
            "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/TestLargeColumnChunk.java": [
                145,
                0
            ],
            "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/TestLruCache.java": [
                162,
                0
            ],
            "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/TestMemoryManager.java": [
                189,
                0
            ],
            "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/TestMergeMetadataFiles.java": [
                221,
                0
            ],
            "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/TestMultipleWriteRead.java": [
                250,
                0
            ],
            "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/TestParquetFileWriter.java": [
                1218,
                0
            ],
            "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/TestParquetOutputFormatJobSummaryLevel.java": [
                69,
                0
            ],
            "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/TestParquetReader.java": [
                198,
                0
            ],
            "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/TestParquetReaderEmptyBlock.java": [
                170,
                0
            ],
            "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/TestParquetReaderRandomAccess.java": [
                387,
                0
            ],
            "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/TestParquetWriter.java": [
                431,
                0
            ],
            "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/TestParquetWriterAppendBlocks.java": [
                361,
                0
            ],
            "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/TestParquetWriterNewPage.java": [
                136,
                0
            ],
            "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/TestParquetWriterTruncation.java": [
                125,
                0
            ],
            "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/TestReadWriteEncodingStats.java": [
                122,
                0
            ],
            "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/TestSnappyCodec.java": [
                140,
                0
            ],
            "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/TestStoreBloomFilter.java": [
                132,
                0
            ],
            "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/TestUtils.java": [
                85,
                0
            ],
            "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/TestZstandardCodec.java": [
                173,
                0
            ],
            "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/codec/CodecConfigTest.java": [
                77,
                0
            ],
            "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/codec/TestCompressionCodec.java": [
                177,
                0
            ],
            "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/codec/TestInteropReadLz4RawCodec.java": [
                129,
                0
            ],
            "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/example/GroupReadSupportTest.java": [
                65,
                0
            ],
            "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/example/TestInputOutputFormat.java": [
                364,
                0
            ],
            "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/metadata/TestColumnChunkMetaData.java": [
                83,
                0
            ],
            "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/rewrite/ParquetRewriterTest.java": [
                772,
                0
            ],
            "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/util/ColumnEncryptorTest.java": [
                315,
                0
            ],
            "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/util/ColumnMaskerTest.java": [
                223,
                0
            ],
            "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/util/ColumnPrunerTest.java": [
                246,
                0
            ],
            "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/util/CompressionConverterTest.java": [
                312,
                0
            ],
            "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/util/EncDecProperties.java": [
                94,
                0
            ],
            "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/util/EncryptionTestFile.java": [
                38,
                0
            ],
            "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/util/MockHadoopInputStream.java": [
                87,
                0
            ],
            "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/util/TestFileBuilder.java": [
                198,
                0
            ],
            "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/util/TestHadoop2ByteBufferReads.java": [
                446,
                0
            ],
            "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/util/TestSerializationUtil.java": [
                71,
                0
            ],
            "parquet-hadoop/src/test/java/org/apache/parquet/statistics/DataGenerationContext.java": [
                85,
                0
            ],
            "parquet-hadoop/src/test/java/org/apache/parquet/statistics/RandomValues.java": [
                383,
                0
            ],
            "parquet-hadoop/src/test/java/org/apache/parquet/statistics/TestColumnIndexes.java": [
                304,
                0
            ],
            "parquet-hadoop/src/test/java/org/apache/parquet/statistics/TestStatistics.java": [
                459,
                0
            ],
            "parquet-hadoop/src/test/resources/log4j.properties": null,
            "parquet-hadoop/src/test/resources/test-append_1.parquet": null,
            "parquet-hadoop/src/test/resources/test-append_2.parquet": null,
            "parquet-hadoop/src/test/resources/test-empty-row-group_1.parquet": null,
            "parquet-hadoop/src/test/resources/test-empty-row-group_2.parquet": null,
            "parquet-hadoop/src/test/resources/test-empty-row-group_3.parquet": null,
            "parquet-hadoop/src/test/resources/test-file-with-no-column-indexes-1.parquet": null,
            "parquet-jackson/README.md": null,
            "parquet-jackson/pom.xml": null,
            "parquet-jackson/src/main/resources/META-INF/LICENSE": null,
            "parquet-pig-bundle/pom.xml": null,
            "parquet-pig-bundle/src/main/resources/META-INF/LICENSE": null,
            "parquet-pig-bundle/src/main/resources/org/apache/parquet/bundle": null,
            "parquet-pig/REVIEWERS.md": null,
            "parquet-pig/pom.xml": null,
            "parquet-pig/src/main/java/org/apache/parquet/pig/ParquetLoader.java": [
                575,
                0
            ],
            "parquet-pig/src/main/java/org/apache/parquet/pig/ParquetStorer.java": [
                152,
                0
            ],
            "parquet-pig/src/main/java/org/apache/parquet/pig/PigMetaData.java": [
                91,
                0
            ],
            "parquet-pig/src/main/java/org/apache/parquet/pig/PigSchemaConverter.java": [
                551,
                0
            ],
            "parquet-pig/src/main/java/org/apache/parquet/pig/SchemaConversionException.java": [
                44,
                0
            ],
            "parquet-pig/src/main/java/org/apache/parquet/pig/TupleConversionException.java": [
                42,
                0
            ],
            "parquet-pig/src/main/java/org/apache/parquet/pig/TupleReadSupport.java": [
                191,
                0
            ],
            "parquet-pig/src/main/java/org/apache/parquet/pig/TupleWriteSupport.java": [
                209,
                0
            ],
            "parquet-pig/src/main/java/org/apache/parquet/pig/convert/DecimalUtils.java": [
                65,
                0
            ],
            "parquet-pig/src/main/java/org/apache/parquet/pig/convert/MapConverter.java": [
                190,
                0
            ],
            "parquet-pig/src/main/java/org/apache/parquet/pig/convert/ParentValueContainer.java": [
                32,
                0
            ],
            "parquet-pig/src/main/java/org/apache/parquet/pig/convert/TupleConverter.java": [
                592,
                0
            ],
            "parquet-pig/src/main/java/org/apache/parquet/pig/convert/TupleRecordMaterializer.java": [
                50,
                0
            ],
            "parquet-pig/src/main/java/org/apache/parquet/pig/summary/BagSummaryData.java": [
                72,
                0
            ],
            "parquet-pig/src/main/java/org/apache/parquet/pig/summary/EnumStat.java": [
                115,
                0
            ],
            "parquet-pig/src/main/java/org/apache/parquet/pig/summary/FieldSummaryData.java": [
                178,
                0
            ],
            "parquet-pig/src/main/java/org/apache/parquet/pig/summary/MapSummaryData.java": [
                85,
                0
            ],
            "parquet-pig/src/main/java/org/apache/parquet/pig/summary/NumberSummaryData.java": [
                47,
                0
            ],
            "parquet-pig/src/main/java/org/apache/parquet/pig/summary/StringSummaryData.java": [
                82,
                0
            ],
            "parquet-pig/src/main/java/org/apache/parquet/pig/summary/Summary.java": [
                224,
                0
            ],
            "parquet-pig/src/main/java/org/apache/parquet/pig/summary/SummaryData.java": [
                135,
                0
            ],
            "parquet-pig/src/main/java/org/apache/parquet/pig/summary/TupleSummaryData.java": [
                98,
                0
            ],
            "parquet-pig/src/main/java/org/apache/parquet/pig/summary/ValueStat.java": [
                64,
                0
            ],
            "parquet-pig/src/test/java/org/apache/parquet/pig/PerfTest.java": [
                104,
                0
            ],
            "parquet-pig/src/test/java/org/apache/parquet/pig/PerfTest2.java": [
                185,
                0
            ],
            "parquet-pig/src/test/java/org/apache/parquet/pig/PerfTestReadAllCols.java": [
                47,
                0
            ],
            "parquet-pig/src/test/java/org/apache/parquet/pig/TestDecimalUtils.java": [
                79,
                0
            ],
            "parquet-pig/src/test/java/org/apache/parquet/pig/TestParquetLoader.java": [
                367,
                0
            ],
            "parquet-pig/src/test/java/org/apache/parquet/pig/TestParquetStorer.java": [
                264,
                0
            ],
            "parquet-pig/src/test/java/org/apache/parquet/pig/TestPigSchemaConverter.java": [
                291,
                0
            ],
            "parquet-pig/src/test/java/org/apache/parquet/pig/TestTupleRecordConsumer.java": [
                210,
                0
            ],
            "parquet-pig/src/test/java/org/apache/parquet/pig/TupleConsumerPerfTest.java": [
                206,
                0
            ],
            "parquet-pig/src/test/java/org/apache/parquet/pig/summary/TestSummary.java": [
                158,
                0
            ],
            "parquet-pig/src/test/resources/log4j.properties": null,
            "parquet-plugins/parquet-encoding-vector/pom.xml": null,
            "parquet-plugins/parquet-encoding-vector/src/main/java/org/apache/parquet/column/values/bitpacking/ByteBitPacking512VectorLE.java": [
                3010,
                0
            ],
            "parquet-plugins/parquet-encoding-vector/src/main/java/org/apache/parquet/column/values/bitpacking/ParquetReadRouter.java": [
                133,
                0
            ],
            "parquet-plugins/parquet-encoding-vector/src/main/java/org/apache/parquet/column/values/bitpacking/VectorSupport.java": [
                27,
                0
            ],
            "parquet-plugins/parquet-encoding-vector/src/test/java/org/apache/parquet/column/values/bitpacking/TestByteBitPacking512VectorLE.java": [
                169,
                0
            ],
            "parquet-plugins/parquet-encoding-vector/src/test/java/org/apache/parquet/column/values/bitpacking/TestParquetReadRouter.java": [
                59,
                0
            ],
            "parquet-plugins/parquet-plugins-benchmarks/pom.xml": null,
            "parquet-plugins/parquet-plugins-benchmarks/src/main/java/org/apache/parquet/plugins/benchmarks/ByteBitPackingVectorBenchmarks.java": [
                92,
                0
            ],
            "parquet-plugins/parquet-plugins-benchmarks/src/main/resources/log4j.properties": null,
            "parquet-protobuf/README.md": null,
            "parquet-protobuf/REVIEWERS.md": null,
            "parquet-protobuf/pom.xml": null,
            "parquet-protobuf/src/main/java/org/apache/parquet/proto/ProtoConstants.java": [
                46,
                0
            ],
            "parquet-protobuf/src/main/java/org/apache/parquet/proto/ProtoMessageConverter.java": [
                599,
                0
            ],
            "parquet-protobuf/src/main/java/org/apache/parquet/proto/ProtoParquetInputFormat.java": [
                38,
                0
            ],
            "parquet-protobuf/src/main/java/org/apache/parquet/proto/ProtoParquetOutputFormat.java": [
                52,
                0
            ],
            "parquet-protobuf/src/main/java/org/apache/parquet/proto/ProtoParquetReader.java": [
                101,
                0
            ],
            "parquet-protobuf/src/main/java/org/apache/parquet/proto/ProtoParquetWriter.java": [
                127,
                0
            ],
            "parquet-protobuf/src/main/java/org/apache/parquet/proto/ProtoReadSupport.java": [
                97,
                0
            ],
            "parquet-protobuf/src/main/java/org/apache/parquet/proto/ProtoRecordConverter.java": [
                100,
                0
            ],
            "parquet-protobuf/src/main/java/org/apache/parquet/proto/ProtoRecordMaterializer.java": [
                47,
                0
            ],
            "parquet-protobuf/src/main/java/org/apache/parquet/proto/ProtoSchemaConverter.java": [
                297,
                0
            ],
            "parquet-protobuf/src/main/java/org/apache/parquet/proto/ProtoWriteSupport.java": [
                586,
                0
            ],
            "parquet-protobuf/src/main/resources/META-INF/NOTICE": null,
            "parquet-protobuf/src/test/java/org/apache/parquet/proto/ProtoInputOutputFormatTest.java": [
                618,
                0
            ],
            "parquet-protobuf/src/test/java/org/apache/parquet/proto/ProtoRecordConverterTest.java": [
                363,
                0
            ],
            "parquet-protobuf/src/test/java/org/apache/parquet/proto/ProtoSchemaConverterTest.java": [
                539,
                0
            ],
            "parquet-protobuf/src/test/java/org/apache/parquet/proto/ProtoSchemaEvolutionTest.java": [
                133,
                0
            ],
            "parquet-protobuf/src/test/java/org/apache/parquet/proto/ProtoWriteSupportTest.java": [
                1204,
                0
            ],
            "parquet-protobuf/src/test/java/org/apache/parquet/proto/TestUtils.java": [
                232,
                0
            ],
            "parquet-protobuf/src/test/java/org/apache/parquet/proto/utils/ReadUsingMR.java": [
                94,
                0
            ],
            "parquet-protobuf/src/test/java/org/apache/parquet/proto/utils/WriteUsingMR.java": [
                121,
                0
            ],
            "parquet-protobuf/src/test/resources/BinaryTree.par": null,
            "parquet-protobuf/src/test/resources/Struct.par": null,
            "parquet-protobuf/src/test/resources/TestProto3.proto": null,
            "parquet-protobuf/src/test/resources/TestProto3SchemaV1.proto": null,
            "parquet-protobuf/src/test/resources/TestProto3SchemaV2.proto": null,
            "parquet-protobuf/src/test/resources/TestProto3SchemaV3.proto": null,
            "parquet-protobuf/src/test/resources/TestProtobuf.proto": null,
            "parquet-protobuf/src/test/resources/Trees.proto": null,
            "parquet-protobuf/src/test/resources/Value.par": null,
            "parquet-protobuf/src/test/resources/WideTree.par": null,
            "parquet-protobuf/src/test/resources/log4j.properties": null,
            "parquet-scala/pom.xml": null,
            "parquet-scala/src/main/scala/org/apache/parquet/filter2/dsl/Dsl.scala": null,
            "parquet-scala/src/test/scala/org/apache/parquet/filter2/dsl/DslTest.scala": null,
            "parquet-thrift/README.md": null,
            "parquet-thrift/REVIEWERS.md": null,
            "parquet-thrift/pom.xml": null,
            "parquet-thrift/src/main/java/org/apache/parquet/hadoop/thrift/AbstractThriftWriteSupport.java": [
                129,
                0
            ],
            "parquet-thrift/src/main/java/org/apache/parquet/hadoop/thrift/ParquetThriftBytesOutputFormat.java": [
                96,
                0
            ],
            "parquet-thrift/src/main/java/org/apache/parquet/hadoop/thrift/ParquetThriftInputFormat.java": [
                66,
                0
            ],
            "parquet-thrift/src/main/java/org/apache/parquet/hadoop/thrift/ParquetThriftOutputFormat.java": [
                43,
                0
            ],
            "parquet-thrift/src/main/java/org/apache/parquet/hadoop/thrift/TBaseWriteSupport.java": [
                70,
                0
            ],
            "parquet-thrift/src/main/java/org/apache/parquet/hadoop/thrift/ThriftBytesWriteSupport.java": [
                196,
                0
            ],
            "parquet-thrift/src/main/java/org/apache/parquet/hadoop/thrift/ThriftReadSupport.java": [
                289,
                0
            ],
            "parquet-thrift/src/main/java/org/apache/parquet/hadoop/thrift/ThriftToParquetFileWriter.java": [
                125,
                0
            ],
            "parquet-thrift/src/main/java/org/apache/parquet/hadoop/thrift/ThriftWriteSupport.java": [
                80,
                0
            ],
            "parquet-thrift/src/main/java/org/apache/parquet/thrift/BufferedProtocolReadToWrite.java": [
                738,
                0
            ],
            "parquet-thrift/src/main/java/org/apache/parquet/thrift/ConvertedField.java": [
                169,
                0
            ],
            "parquet-thrift/src/main/java/org/apache/parquet/thrift/DecodingSchemaMismatchException.java": [
                30,
                0
            ],
            "parquet-thrift/src/main/java/org/apache/parquet/thrift/FieldIgnoredHandler.java": [
                45,
                0
            ],
            "parquet-thrift/src/main/java/org/apache/parquet/thrift/KeepOnlyFirstPrimitiveFilter.java": [
                44,
                0
            ],
            "parquet-thrift/src/main/java/org/apache/parquet/thrift/ParquetProtocol.java": [
                282,
                0
            ],
            "parquet-thrift/src/main/java/org/apache/parquet/thrift/ParquetReadProtocol.java": [
                164,
                0
            ],
            "parquet-thrift/src/main/java/org/apache/parquet/thrift/ParquetWriteProtocol.java": [
                778,
                0
            ],
            "parquet-thrift/src/main/java/org/apache/parquet/thrift/ProtocolPipe.java": [
                29,
                0
            ],
            "parquet-thrift/src/main/java/org/apache/parquet/thrift/ProtocolReadToWrite.java": [
                142,
                0
            ],
            "parquet-thrift/src/main/java/org/apache/parquet/thrift/SkippableException.java": [
                47,
                0
            ],
            "parquet-thrift/src/main/java/org/apache/parquet/thrift/TBaseRecordConverter.java": [
                61,
                0
            ],
            "parquet-thrift/src/main/java/org/apache/parquet/thrift/ThriftMetaData.java": [
                147,
                0
            ],
            "parquet-thrift/src/main/java/org/apache/parquet/thrift/ThriftParquetReader.java": [
                139,
                0
            ],
            "parquet-thrift/src/main/java/org/apache/parquet/thrift/ThriftParquetWriter.java": [
                52,
                0
            ],
            "parquet-thrift/src/main/java/org/apache/parquet/thrift/ThriftReader.java": [
                28,
                0
            ],
            "parquet-thrift/src/main/java/org/apache/parquet/thrift/ThriftRecordConverter.java": [
                954,
                0
            ],
            "parquet-thrift/src/main/java/org/apache/parquet/thrift/ThriftSchemaConvertVisitor.java": [
                409,
                0
            ],
            "parquet-thrift/src/main/java/org/apache/parquet/thrift/ThriftSchemaConverter.java": [
                226,
                0
            ],
            "parquet-thrift/src/main/java/org/apache/parquet/thrift/pig/ParquetThriftStorer.java": [
                90,
                0
            ],
            "parquet-thrift/src/main/java/org/apache/parquet/thrift/pig/TupleToThriftWriteSupport.java": [
                79,
                0
            ],
            "parquet-thrift/src/main/java/org/apache/parquet/thrift/projection/FieldProjectionFilter.java": [
                62,
                0
            ],
            "parquet-thrift/src/main/java/org/apache/parquet/thrift/projection/FieldsPath.java": [
                87,
                0
            ],
            "parquet-thrift/src/main/java/org/apache/parquet/thrift/projection/StrictFieldProjectionFilter.java": [
                187,
                0
            ],
            "parquet-thrift/src/main/java/org/apache/parquet/thrift/projection/ThriftProjectionException.java": [
                45,
                0
            ],
            "parquet-thrift/src/main/java/org/apache/parquet/thrift/projection/amend/DefaultEventsVisitor.java": [
                228,
                0
            ],
            "parquet-thrift/src/main/java/org/apache/parquet/thrift/projection/amend/DefaultProtocolEventsGenerator.java": [
                68,
                0
            ],
            "parquet-thrift/src/main/java/org/apache/parquet/thrift/projection/amend/ProtocolEventsAmender.java": [
                171,
                0
            ],
            "parquet-thrift/src/main/java/org/apache/parquet/thrift/projection/amend/ReadFieldBeginProtocol.java": [
                44,
                0
            ],
            "parquet-thrift/src/main/java/org/apache/parquet/thrift/projection/deprecated/DeprecatedFieldProjectionFilter.java": [
                106,
                0
            ],
            "parquet-thrift/src/main/java/org/apache/parquet/thrift/projection/deprecated/PathGlobPattern.java": [
                173,
                0
            ],
            "parquet-thrift/src/main/java/org/apache/parquet/thrift/struct/CompatibilityChecker.java": [
                265,
                0
            ],
            "parquet-thrift/src/main/java/org/apache/parquet/thrift/struct/CompatibilityRunner.java": [
                104,
                0
            ],
            "parquet-thrift/src/main/java/org/apache/parquet/thrift/struct/JSON.java": [
                50,
                0
            ],
            "parquet-thrift/src/main/java/org/apache/parquet/thrift/struct/ThriftField.java": [
                121,
                0
            ],
            "parquet-thrift/src/main/java/org/apache/parquet/thrift/struct/ThriftType.java": [
                698,
                0
            ],
            "parquet-thrift/src/main/java/org/apache/parquet/thrift/struct/ThriftTypeID.java": [
                108,
                0
            ],
            "parquet-thrift/src/test/java/org/apache/parquet/hadoop/thrift/TestArrayCompatibility.java": [
                779,
                0
            ],
            "parquet-thrift/src/test/java/org/apache/parquet/hadoop/thrift/TestBinary.java": [
                86,
                0
            ],
            "parquet-thrift/src/test/java/org/apache/parquet/hadoop/thrift/TestCorruptThriftRecords.java": [
                213,
                0
            ],
            "parquet-thrift/src/test/java/org/apache/parquet/hadoop/thrift/TestInputOutputFormat.java": [
                258,
                0
            ],
            "parquet-thrift/src/test/java/org/apache/parquet/hadoop/thrift/TestParquetToThriftReadWriteAndProjection.java": [
                385,
                0
            ],
            "parquet-thrift/src/test/java/org/apache/parquet/hadoop/thrift/TestThriftToParquetFileWriter.java": [
                360,
                0
            ],
            "parquet-thrift/src/test/java/org/apache/parquet/thrift/TestParquetReadProtocol.java": [
                173,
                0
            ],
            "parquet-thrift/src/test/java/org/apache/parquet/thrift/TestParquetWriteProtocol.java": [
                719,
                0
            ],
            "parquet-thrift/src/test/java/org/apache/parquet/thrift/TestProtocolReadToWrite.java": [
                384,
                0
            ],
            "parquet-thrift/src/test/java/org/apache/parquet/thrift/TestThriftMetaData.java": [
                56,
                0
            ],
            "parquet-thrift/src/test/java/org/apache/parquet/thrift/TestThriftParquetReaderWriter.java": [
                83,
                0
            ],
            "parquet-thrift/src/test/java/org/apache/parquet/thrift/TestThriftRecordConverter.java": [
                101,
                0
            ],
            "parquet-thrift/src/test/java/org/apache/parquet/thrift/TestThriftSchemaConvertVisitor.java": [
                178,
                0
            ],
            "parquet-thrift/src/test/java/org/apache/parquet/thrift/TestThriftSchemaConverter.java": [
                353,
                0
            ],
            "parquet-thrift/src/test/java/org/apache/parquet/thrift/TestThriftSchemaConverterProjectUnion.java": [
                480,
                0
            ],
            "parquet-thrift/src/test/java/org/apache/parquet/thrift/TestThriftToPigCompatibility.java": [
                171,
                0
            ],
            "parquet-thrift/src/test/java/org/apache/parquet/thrift/pig/TestParquetThriftStorer.java": [
                82,
                0
            ],
            "parquet-thrift/src/test/java/org/apache/parquet/thrift/projection/TestFieldsPath.java": [
                162,
                0
            ],
            "parquet-thrift/src/test/java/org/apache/parquet/thrift/projection/TestStrictFieldProjectionFilter.java": [
                119,
                0
            ],
            "parquet-thrift/src/test/java/org/apache/parquet/thrift/projection/deprecated/PathGlobPatternTest.java": [
                59,
                0
            ],
            "parquet-thrift/src/test/java/org/apache/parquet/thrift/struct/CompatibilityCheckerTest.java": [
                132,
                0
            ],
            "parquet-thrift/src/test/java/org/apache/parquet/thrift/struct/TestThriftType.java": [
                70,
                0
            ],
            "parquet-thrift/src/test/resources/org/apache/parquet/hadoop/thrift/AddressBook.json": null,
            "parquet-thrift/src/test/resources/org/apache/parquet/thrift/StructWithUnionV1NoStructOrUnionMeta.json": null,
            "parquet-thrift/src/test/thrift/array_compat.thrift": null,
            "parquet-thrift/src/test/thrift/binary.thrift": null,
            "parquet-thrift/src/test/thrift/compat.thrift": null,
            "parquet-thrift/src/test/thrift/test.thrift": null,
            "pom.xml": null,
            "src/license.txt": null
        }
    },
    "a8c10efccf35977193cab80b0f17d6a2f7d066d9": {
        "datetime": "2012-08-31T15:37:32-07:00",
        "summary": "initial commit",
        "message": "initial commit\n",
        "diff": {
            ".gitignore": null,
            "pom.xml": null,
            "redelm-column/pom.xml": null,
            "redelm-column/src/main/java/redelm/Log.java": [
                0,
                10
            ],
            "redelm-column/src/main/java/redelm/column/ColumnDescriptor.java": [
                0,
                51
            ],
            "redelm-column/src/main/java/redelm/column/ColumnReader.java": [
                0,
                22
            ],
            "redelm-column/src/main/java/redelm/column/ColumnWriter.java": [
                0,
                15
            ],
            "redelm-column/src/main/java/redelm/column/ColumnsStore.java": [
                0,
                13
            ],
            "redelm-column/src/main/java/redelm/column/mem/MemColumn.java": [
                0,
                186
            ],
            "redelm-column/src/main/java/redelm/column/mem/MemColumnsStore.java": [
                0,
                167
            ],
            "redelm-column/src/main/java/redelm/data/Group.java": [
                0,
                41
            ],
            "redelm-column/src/main/java/redelm/data/GroupFactory.java": [
                0,
                7
            ],
            "redelm-column/src/main/java/redelm/data/GroupValueSource.java": [
                0,
                20
            ],
            "redelm-column/src/main/java/redelm/io/ColumnIO.java": [
                0,
                109
            ],
            "redelm-column/src/main/java/redelm/io/ColumnIOFactory.java": [
                0,
                83
            ],
            "redelm-column/src/main/java/redelm/io/GroupColumnIO.java": [
                0,
                105
            ],
            "redelm-column/src/main/java/redelm/io/MessageColumnIO.java": [
                0,
                47
            ],
            "redelm-column/src/main/java/redelm/io/PrimitiveColumnIO.java": [
                0,
                88
            ],
            "redelm-column/src/main/java/redelm/io/RecordConsumer.java": [
                0,
                17
            ],
            "redelm-column/src/main/java/redelm/io/RecordConsumerWrapper.java": [
                0,
                96
            ],
            "redelm-column/src/main/java/redelm/io/RecordReader.java": [
                0,
                195
            ],
            "redelm-column/src/main/java/redelm/io/RecordWriter.java": [
                0,
                26
            ],
            "redelm-column/src/main/java/redelm/schema/GroupType.java": [
                0,
                92
            ],
            "redelm-column/src/main/java/redelm/schema/MessageType.java": [
                0,
                22
            ],
            "redelm-column/src/main/java/redelm/schema/PrimitiveType.java": [
                0,
                150
            ],
            "redelm-column/src/main/java/redelm/schema/Type.java": [
                0,
                65
            ],
            "redelm-column/src/main/java/redelm/schema/TypeVisitor.java": [
                0,
                7
            ],
            "redelm-column/src/test/java/redelm/column/mem/TestMemColumn.java": [
                0,
                55
            ],
            "redelm-column/src/test/java/redelm/data/simple/BinaryValue.java": [
                0,
                16
            ],
            "redelm-column/src/test/java/redelm/data/simple/BoolValue.java": [
                0,
                19
            ],
            "redelm-column/src/test/java/redelm/data/simple/IntValue.java": [
                0,
                21
            ],
            "redelm-column/src/test/java/redelm/data/simple/Primitive.java": [
                0,
                23
            ],
            "redelm-column/src/test/java/redelm/data/simple/SimpleGroup.java": [
                0,
                141
            ],
            "redelm-column/src/test/java/redelm/data/simple/SimpleGroupFactory.java": [
                0,
                20
            ],
            "redelm-column/src/test/java/redelm/data/simple/StringValue.java": [
                0,
                25
            ],
            "redelm-column/src/test/java/redelm/io/PerfTest.java": [
                0,
                80
            ],
            "redelm-column/src/test/java/redelm/io/TestColumnIO.java": [
                0,
                254
            ],
            "redelm-pig/pom.xml": null,
            "redelm-pig/src/main/java/redelm/pig/RedelmLoader.java": [
                0,
                108
            ],
            "redelm-pig/src/main/java/redelm/pig/TupleRecordConsumer.java": [
                0,
                102
            ],
            "redelm-pig/src/test/java/redelm/pig/TestTupleRecordConsumer.java": [
                0,
                20
            ],
            "redelm-thrift/pom.xml": null,
            "redelm-thrift/src/main/java/redelm/thrift/SchemaConverter.java": [
                0,
                116
            ],
            "redelm-thrift/src/main/java/redelm/thrift/ThriftConverter.java": [
                0,
                82
            ],
            "redelm-thrift/src/main/java/redelm/thrift/ThriftRandomGenerator.java": [
                0,
                102
            ]
        }
    },
    "f3cdad30930c2cd73404804cf4ceeca237509a2c": {
        "datetime": "2012-08-31T15:40:19-07:00",
        "summary": "README.md",
        "message": "README.md\n",
        "diff": {
            "README.md": null
        }
    },
    "24028799609ef606359d6bee39acd34d8d67a067": {
        "datetime": "2012-08-31T16:00:47-07:00",
        "summary": "Update README.md",
        "message": "Update README.md",
        "diff": {
            "README.md": null
        }
    },
    "dbbf9443ffe219862c9744806f34deb2606d21c7": {
        "datetime": "2012-09-05T15:52:01-07:00",
        "summary": "updated name",
        "message": "updated name\n",
        "diff": {
            "README.md": null
        }
    },
    "7ed952872d68eacc02d5a13e6b6ded4cf8babc55": {
        "datetime": "2012-09-05T15:52:09-07:00",
        "summary": "Merge branch 'master' of github.com:julienledem/redelm",
        "message": "Merge branch 'master' of github.com:julienledem/redelm\n",
        "diff": {
            "README.md": null
        }
    },
    "5fb63e9a0743a23735f5b6043abd202a85173202": {
        "datetime": "2012-09-08T11:13:43-07:00",
        "summary": "refactoring tuples to use indices instead of field names",
        "message": "refactoring tuples to use indices instead of field names\n",
        "diff": {
            "redelm-column/src/main/java/redelm/Log.java": [
                1,
                1
            ],
            "redelm-column/src/main/java/redelm/column/ColumnReader.java": [
                0,
                4
            ],
            "redelm-column/src/main/java/redelm/column/mem/MemColumn.java": [
                0,
                2
            ],
            "redelm-column/src/main/java/redelm/data/Group.java": [
                7,
                38
            ],
            "redelm-column/src/main/java/redelm/data/GroupValueSource.java": [
                6,
                30
            ],
            "redelm-column/src/main/java/redelm/io/ColumnIO.java": [
                3,
                9
            ],
            "redelm-column/src/main/java/redelm/io/GroupColumnIO.java": [
                2,
                9
            ],
            "redelm-column/src/main/java/redelm/io/MessageColumnIO.java": [
                1,
                1
            ],
            "redelm-column/src/main/java/redelm/io/PrimitiveColumnIO.java": [
                2,
                2
            ],
            "redelm-column/src/main/java/redelm/io/RecordConsumer.java": [
                3,
                5
            ],
            "redelm-column/src/main/java/redelm/io/RecordConsumerWrapper.java": [
                4,
                16
            ],
            "redelm-column/src/main/java/redelm/io/RecordReader.java": [
                49,
                112
            ],
            "redelm-column/src/main/java/redelm/schema/PrimitiveType.java": [
                27,
                0
            ],
            "redelm-column/src/test/java/redelm/data/simple/SimpleGroup.java": [
                31,
                36
            ],
            "redelm-column/src/test/java/redelm/io/PerfTest.java": [
                2,
                25
            ],
            "redelm-column/src/test/java/redelm/io/TestColumnIO.java": [
                9,
                15
            ]
        }
    },
    "741c6fd77e6ccbebf47eacf021e68379d5063d53": {
        "datetime": "2012-09-08T11:30:01-07:00",
        "summary": "adding push parser test",
        "message": "adding push parser test\n",
        "diff": {
            "redelm-column/src/test/java/redelm/io/TestColumnIO.java": [
                0,
                138
            ]
        }
    },
    "a1a04d51312b169e5f2576c146351c67366a6212": {
        "datetime": "2012-09-10T08:35:12-07:00",
        "summary": "move closing records at the begining of the loop",
        "message": "move closing records at the begining of the loop\n",
        "diff": {
            "redelm-column/src/main/java/redelm/io/RecordReader.java": [
                53,
                41
            ],
            "redelm-column/src/test/java/redelm/io/TestColumnIO.java": [
                63,
                67
            ]
        }
    },
    "9b68b394fa8f8b339db1b85b5eb1ab744c89ca5c": {
        "datetime": "2012-09-11T16:38:32-07:00",
        "summary": "make field started and ended only once when value is repeated, refactor out SimpleGroupRecordConsumer",
        "message": "make field started and ended only once when value is repeated, refactor out SimpleGroupRecordConsumer\n",
        "diff": {
            "redelm-column/src/main/java/redelm/Log.java": [
                1,
                1
            ],
            "redelm-column/src/main/java/redelm/io/RecordReader.java": [
                128,
                82
            ],
            "redelm-column/src/test/java/redelm/data/simple/SimpleGroupRecordConsumer.java": [
                0,
                76
            ],
            "redelm-column/src/test/java/redelm/io/PerfTest.java": [
                103,
                0
            ],
            "redelm-column/src/test/java/redelm/io/TestColumnIO.java": [
                29,
                29
            ]
        }
    },
    "34124edc109127e0819d859fce91df960256571d": {
        "datetime": "2012-09-11T16:42:46-07:00",
        "summary": "remove depedency on Group from RecordReader",
        "message": "remove depedency on Group from RecordReader\n",
        "diff": {
            "redelm-column/src/main/java/redelm/io/ColumnIOFactory.java": [
                5,
                2
            ],
            "redelm-column/src/main/java/redelm/io/MessageColumnIO.java": [
                4,
                2
            ],
            "redelm-column/src/main/java/redelm/io/RecordReader.java": [
                6,
                1
            ],
            "redelm-column/src/test/java/redelm/io/PerfTest.java": [
                0,
                0
            ],
            "redelm-column/src/test/java/redelm/io/TestColumnIO.java": [
                5,
                3
            ]
        }
    },
    "968fd551c58a091b5b13387038c57b15035a198e": {
        "datetime": "2012-09-13T15:41:03-07:00",
        "summary": "remove dependency on group from the io implementation",
        "message": "remove dependency on group from the io implementation\n",
        "diff": {
            "redelm-column/src/main/java/redelm/Log.java": [
                1,
                129
            ],
            "redelm-column/src/main/java/redelm/data/GroupWriter.java": [
                0,
                46
            ],
            "redelm-column/src/main/java/redelm/io/ColumnIO.java": [
                19,
                0
            ],
            "redelm-column/src/main/java/redelm/io/ColumnIOFactory.java": [
                1,
                0
            ],
            "redelm-column/src/main/java/redelm/io/GroupColumnIO.java": [
                17,
                5
            ],
            "redelm-column/src/main/java/redelm/io/MessageColumnIO.java": [
                4,
                140
            ],
            "redelm-column/src/main/java/redelm/io/PrimitiveColumnIO.java": [
                6,
                4
            ],
            "redelm-column/src/main/java/redelm/io/RecordReader.java": [
                1,
                0
            ],
            "redelm-column/src/main/java/redelm/io/RecordWriter.java": [
                26,
                0
            ],
            "redelm-column/src/main/java/redelm/schema/GroupType.java": [
                1,
                1
            ],
            "redelm-column/src/main/java/redelm/schema/PrimitiveType.java": [
                0,
                31
            ],
            "redelm-column/src/test/java/redelm/data/simple/SimpleGroup.java": [
                5,
                0
            ],
            "redelm-column/src/test/java/redelm/data/simple/SimpleGroupRecordConsumer.java": [
                5,
                3
            ],
            "redelm-column/src/test/java/redelm/io/PerfTest.java": [
                0,
                0
            ],
            "redelm-column/src/test/java/redelm/io/TestColumnIO.java": [
                23,
                125
            ]
        }
    },
    "c4109e21cac4743062f15d800dbec8366201e98b": {
        "datetime": "2012-09-14T08:09:38-07:00",
        "summary": "fix compilation and dependency issue",
        "message": "fix compilation and dependency issue\n",
        "diff": {
            "redelm-pig/pom.xml": null,
            "redelm-pig/src/main/java/redelm/pig/TupleRecordConsumer.java": [
                11,
                23
            ]
        }
    },
    "f689f90b485b23c0cc5076088093ec6977358d09": {
        "datetime": "2012-09-14T08:10:48-07:00",
        "summary": "fix compilation issue",
        "message": "fix compilation issue\n",
        "diff": {
            "redelm-pig/src/main/java/redelm/pig/RedelmLoader.java": [
                1,
                1
            ],
            "redelm-pig/src/test/java/redelm/pig/TestTupleRecordConsumer.java": [
                5,
                0
            ]
        }
    },
    "82e0324ec300f370d5416e8d60999c910998dc58": {
        "datetime": "2012-09-15T15:29:07-07:00",
        "summary": "pig Tuple consumer and writer",
        "message": "pig Tuple consumer and writer\n",
        "diff": {
            "pom.xml": null,
            "redelm-column/src/main/java/redelm/Log.java": [
                11,
                3
            ],
            "redelm-column/src/main/java/redelm/data/Group.java": [
                4,
                2
            ],
            "redelm-column/src/main/java/redelm/data/GroupRecordConsumer.java": [
                22,
                22
            ],
            "redelm-column/src/main/java/redelm/data/simple/example/Paper.java": [
                0,
                143
            ],
            "redelm-column/src/main/java/redelm/io/GroupColumnIO.java": [
                2,
                2
            ],
            "redelm-column/src/main/java/redelm/io/MessageColumnIO.java": [
                3,
                2
            ],
            "redelm-column/src/main/java/redelm/io/RecordConsumerWrapper.java": [
                11,
                10
            ],
            "redelm-column/src/test/java/redelm/data/simple/BinaryValue.java": [
                0,
                0
            ],
            "redelm-column/src/test/java/redelm/data/simple/BoolValue.java": [
                0,
                0
            ],
            "redelm-column/src/test/java/redelm/data/simple/IntValue.java": [
                0,
                0
            ],
            "redelm-column/src/test/java/redelm/data/simple/Primitive.java": [
                0,
                0
            ],
            "redelm-column/src/test/java/redelm/data/simple/SimpleGroup.java": [
                0,
                0
            ],
            "redelm-column/src/test/java/redelm/data/simple/SimpleGroupFactory.java": [
                0,
                0
            ],
            "redelm-column/src/test/java/redelm/data/simple/StringValue.java": [
                0,
                0
            ],
            "redelm-column/src/test/java/redelm/io/PerfTest.java": [
                0,
                0
            ],
            "redelm-column/src/test/java/redelm/io/TestColumnIO.java": [
                153,
                17
            ],
            "redelm-pig/src/main/java/redelm/pig/TupleRecordConsumer.java": [
                24,
                25
            ],
            "redelm-pig/src/main/java/redelm/pig/TupleWriter.java": [
                0,
                87
            ],
            "redelm-pig/src/test/java/redelm/pig/TestTupleRecordConsumer.java": [
                5,
                37
            ],
            "redelm-thrift/src/main/java/redelm/thrift/ThriftConverter.java": [
                3,
                3
            ],
            "redelm-thrift/src/main/java/redelm/thrift/ThriftSchemaPrinter.java": [
                0,
                58
            ]
        }
    },
    "5e9556105c37c4fa4073a7680d8132fa5c9f261d": {
        "datetime": "2012-09-15T15:29:52-07:00",
        "summary": "temporarily removing thrift stuff",
        "message": "temporarily removing thrift stuff\n",
        "diff": {
            "redelm-thrift/pom.xml": null,
            "redelm-thrift/src/main/java/redelm/thrift/SchemaConverter.java": [
                116,
                0
            ],
            "redelm-thrift/src/main/java/redelm/thrift/ThriftConverter.java": [
                82,
                0
            ],
            "redelm-thrift/src/main/java/redelm/thrift/ThriftRandomGenerator.java": [
                102,
                0
            ],
            "redelm-thrift/src/main/java/redelm/thrift/ThriftSchemaPrinter.java": [
                58,
                0
            ]
        }
    },
    "f2ea25f2097ea0359e9e4ba0815b6f9a63b3359f": {
        "datetime": "2012-09-15T16:51:08-07:00",
        "summary": "turning off logs",
        "message": "turning off logs\n",
        "diff": {
            "redelm-column/src/main/java/redelm/Log.java": [
                1,
                1
            ],
            "redelm-column/src/test/java/redelm/io/PerfTest.java": [
                0,
                0
            ]
        }
    },
    "d1ceb2609f60f98a38c4710922281325630a8888": {
        "datetime": "2012-09-15T17:44:41-07:00",
        "summary": "Update README.md",
        "message": "Update README.md",
        "diff": {
            "README.md": null
        }
    },
    "da7ec4896ec365c7778223f11d91544afad8f764": {
        "datetime": "2012-09-26T18:23:47-07:00",
        "summary": "adding license header",
        "message": "adding license header\n",
        "diff": {
            "LICENSE": null,
            "NOTICE": null,
            "README.md": null,
            "license.txt": null,
            "pom.xml": null,
            "redelm-column/src/main/java/redelm/Log.java": [
                0,
                15
            ],
            "redelm-column/src/main/java/redelm/column/ColumnDescriptor.java": [
                0,
                15
            ],
            "redelm-column/src/main/java/redelm/column/ColumnReader.java": [
                0,
                15
            ],
            "redelm-column/src/main/java/redelm/column/ColumnWriter.java": [
                0,
                15
            ],
            "redelm-column/src/main/java/redelm/column/ColumnsStore.java": [
                0,
                15
            ],
            "redelm-column/src/main/java/redelm/column/mem/MemColumn.java": [
                0,
                15
            ],
            "redelm-column/src/main/java/redelm/column/mem/MemColumnsStore.java": [
                0,
                15
            ],
            "redelm-column/src/main/java/redelm/data/Group.java": [
                0,
                15
            ],
            "redelm-column/src/main/java/redelm/data/GroupFactory.java": [
                0,
                15
            ],
            "redelm-column/src/main/java/redelm/data/GroupRecordConsumer.java": [
                0,
                15
            ],
            "redelm-column/src/main/java/redelm/data/GroupValueSource.java": [
                0,
                15
            ],
            "redelm-column/src/main/java/redelm/data/GroupWriter.java": [
                0,
                15
            ],
            "redelm-column/src/main/java/redelm/data/simple/BinaryValue.java": [
                0,
                15
            ],
            "redelm-column/src/main/java/redelm/data/simple/BoolValue.java": [
                0,
                15
            ],
            "redelm-column/src/main/java/redelm/data/simple/IntValue.java": [
                0,
                15
            ],
            "redelm-column/src/main/java/redelm/data/simple/Primitive.java": [
                0,
                15
            ],
            "redelm-column/src/main/java/redelm/data/simple/SimpleGroup.java": [
                0,
                15
            ],
            "redelm-column/src/main/java/redelm/data/simple/SimpleGroupFactory.java": [
                0,
                15
            ],
            "redelm-column/src/main/java/redelm/data/simple/StringValue.java": [
                0,
                15
            ],
            "redelm-column/src/main/java/redelm/data/simple/example/Paper.java": [
                0,
                15
            ],
            "redelm-column/src/main/java/redelm/io/ColumnIO.java": [
                0,
                15
            ],
            "redelm-column/src/main/java/redelm/io/ColumnIOFactory.java": [
                0,
                15
            ],
            "redelm-column/src/main/java/redelm/io/GroupColumnIO.java": [
                0,
                15
            ],
            "redelm-column/src/main/java/redelm/io/MessageColumnIO.java": [
                0,
                15
            ],
            "redelm-column/src/main/java/redelm/io/PrimitiveColumnIO.java": [
                0,
                15
            ],
            "redelm-column/src/main/java/redelm/io/RecordConsumer.java": [
                0,
                15
            ],
            "redelm-column/src/main/java/redelm/io/RecordConsumerWrapper.java": [
                0,
                15
            ],
            "redelm-column/src/main/java/redelm/io/RecordReader.java": [
                0,
                15
            ],
            "redelm-column/src/main/java/redelm/schema/GroupType.java": [
                0,
                15
            ],
            "redelm-column/src/main/java/redelm/schema/MessageType.java": [
                0,
                15
            ],
            "redelm-column/src/main/java/redelm/schema/PrimitiveType.java": [
                0,
                15
            ],
            "redelm-column/src/main/java/redelm/schema/Type.java": [
                0,
                15
            ],
            "redelm-column/src/main/java/redelm/schema/TypeVisitor.java": [
                0,
                15
            ],
            "redelm-column/src/test/java/redelm/column/mem/TestMemColumn.java": [
                0,
                15
            ],
            "redelm-column/src/test/java/redelm/io/PerfTest.java": [
                0,
                0
            ],
            "redelm-column/src/test/java/redelm/io/TestColumnIO.java": [
                0,
                15
            ],
            "redelm-pig/src/main/java/redelm/pig/RedelmLoader.java": [
                0,
                15
            ],
            "redelm-pig/src/main/java/redelm/pig/TupleRecordConsumer.java": [
                0,
                15
            ],
            "redelm-pig/src/main/java/redelm/pig/TupleWriter.java": [
                0,
                15
            ],
            "redelm-pig/src/test/java/redelm/pig/TestTupleRecordConsumer.java": [
                0,
                15
            ]
        }
    },
    "0b7396243e0e695dac144d0ddf7a651f58e35e5f": {
        "datetime": "2012-09-27T10:49:50-07:00",
        "summary": "Merge branch 'master' of github.com:julienledem/redelm",
        "message": "Merge branch 'master' of github.com:julienledem/redelm\n\nConflicts:\n\tREADME.md\n",
        "diff": {
            "README.md": null
        }
    },
    "7b988569482df80fc88053e0725ed2668f20644e": {
        "datetime": "2012-09-27T14:41:03-07:00",
        "summary": "adding travis ci conf",
        "message": "adding travis ci conf\n",
        "diff": {
            ".travis.yml": null
        }
    },
    "e6ecdc6c4c2f477cefdfc8fc3c1f4b6a2df1fc0a": {
        "datetime": "2012-09-28T09:22:26-07:00",
        "summary": "fixing source version",
        "message": "fixing source version\n",
        "diff": {
            "pom.xml": null
        }
    },
    "cf5ba988c56a2b5166dfeaf13743b9a99fb4a552": {
        "datetime": "2012-09-28T09:53:11-07:00",
        "summary": "fix source encoding",
        "message": "fix source encoding\n",
        "diff": {
            "pom.xml": null,
            "redelm-column/src/test/java/redelm/io/PerfTest.java": [
                0,
                0
            ]
        }
    },
    "ab7df25a4794a18377d034e7776505bdc7a4eb05": {
        "datetime": "2012-09-28T10:30:07-07:00",
        "summary": "added build info",
        "message": "added build info\n",
        "diff": {
            "README.md": null,
            "pom.xml": null
        }
    },
    "2302fe4656a799d20e7a86aee10459eabdc82a6f": {
        "datetime": "2012-10-04T08:39:36-07:00",
        "summary": "first version of the Loader/Storer",
        "message": "first version of the Loader/Storer\n",
        "diff": {
            ".gitignore": null,
            "pom.xml": null,
            "redelm-column/src/main/java/redelm/column/mem/MemColumn.java": [
                0,
                20
            ],
            "redelm-column/src/main/java/redelm/column/mem/MemColumnsStore.java": [
                0,
                23
            ],
            "redelm-column/src/main/java/redelm/schema/GroupType.java": [
                0,
                4
            ],
            "redelm-column/src/main/java/redelm/schema/MessageType.java": [
                0,
                63
            ],
            "redelm-column/src/main/java/redelm/schema/PrimitiveType.java": [
                0,
                26
            ],
            "redelm-column/src/test/java/redelm/schema/TestMessageType.java": [
                0,
                15
            ],
            "redelm-pig/pom.xml": null,
            "redelm-pig/src/main/java/redelm/pig/BlockMetaData.java": [
                0,
                52
            ],
            "redelm-pig/src/main/java/redelm/pig/ColumnData.java": [
                0,
                28
            ],
            "redelm-pig/src/main/java/redelm/pig/ColumnMetaData.java": [
                0,
                56
            ],
            "redelm-pig/src/main/java/redelm/pig/Footer.java": [
                0,
                80
            ],
            "redelm-pig/src/main/java/redelm/pig/PigSchemaConverter.java": [
                0,
                83
            ],
            "redelm-pig/src/main/java/redelm/pig/RedelmFileReader.java": [
                0,
                65
            ],
            "redelm-pig/src/main/java/redelm/pig/RedelmFileWriter.java": [
                0,
                74
            ],
            "redelm-pig/src/main/java/redelm/pig/RedelmInputFormat.java": [
                0,
                191
            ],
            "redelm-pig/src/main/java/redelm/pig/RedelmInputSplit.java": [
                0,
                103
            ],
            "redelm-pig/src/main/java/redelm/pig/RedelmLoader.java": [
                67,
                29
            ],
            "redelm-pig/src/main/java/redelm/pig/RedelmOutputFormat.java": [
                0,
                92
            ],
            "redelm-pig/src/main/java/redelm/pig/RedelmStorer.java": [
                0,
                87
            ],
            "redelm-pig/src/main/java/redelm/pig/summary/BagSummaryData.java": [
                0,
                64
            ],
            "redelm-pig/src/main/java/redelm/pig/summary/EnumStat.java": [
                0,
                97
            ],
            "redelm-pig/src/main/java/redelm/pig/summary/FieldSummaryData.java": [
                0,
                166
            ],
            "redelm-pig/src/main/java/redelm/pig/summary/MapSummaryData.java": [
                0,
                75
            ],
            "redelm-pig/src/main/java/redelm/pig/summary/NumberSummaryData.java": [
                0,
                32
            ],
            "redelm-pig/src/main/java/redelm/pig/summary/StringSummaryData.java": [
                0,
                66
            ],
            "redelm-pig/src/main/java/redelm/pig/summary/Summary.java": [
                0,
                265
            ],
            "redelm-pig/src/main/java/redelm/pig/summary/SummaryData.java": [
                0,
                141
            ],
            "redelm-pig/src/main/java/redelm/pig/summary/TupleSummaryData.java": [
                0,
                89
            ],
            "redelm-pig/src/main/java/redelm/pig/summary/ValueStat.java": [
                0,
                46
            ],
            "redelm-pig/src/test/java/redelm/pig/TestPigSchemaConverter.java": [
                0,
                27
            ],
            "redelm-pig/src/test/java/redelm/pig/TestRedelmFileWriter.java": [
                0,
                95
            ],
            "redelm-pig/src/test/java/redelm/pig/TestRedelmStorer.java": [
                0,
                112
            ],
            "redelm-pig/src/test/java/redelm/pig/summary/TestSummary.java": [
                0,
                128
            ]
        }
    },
    "575c221dbdc572bac7c6c7219cd172f12f62964e": {
        "datetime": "2012-10-04T22:48:09-07:00",
        "summary": "PrintFooter tool",
        "message": "PrintFooter tool\n",
        "diff": {
            "redelm-pig/src/main/java/redelm/pig/BlockMetaData.java": [
                1,
                0
            ],
            "redelm-pig/src/main/java/redelm/pig/Footer.java": [
                2,
                0
            ],
            "redelm-pig/src/main/java/redelm/pig/PrintFooter.java": [
                0,
                27
            ],
            "redelm-pig/src/main/java/redelm/pig/RedelmFileReader.java": [
                5,
                13
            ],
            "redelm-pig/src/main/java/redelm/pig/RedelmFileWriter.java": [
                5,
                5
            ],
            "redelm-pig/src/main/java/redelm/pig/RedelmInputFormat.java": [
                16,
                19
            ],
            "redelm-pig/src/main/java/redelm/pig/RedelmInputSplit.java": [
                4,
                3
            ],
            "redelm-pig/src/main/java/redelm/pig/RedelmLoader.java": [
                13,
                3
            ],
            "redelm-pig/src/main/java/redelm/pig/RedelmOutputFormat.java": [
                1,
                1
            ]
        }
    },
    "bdd363578611c60a10d970323a0e0e60281fdaa9": {
        "datetime": "2012-10-08T18:46:13-07:00",
        "summary": "Add some comments and tests",
        "message": "Add some comments and tests\n",
        "diff": {
            ".gitignore": null,
            "pom.xml": null,
            "redelm-column/src/main/java/redelm/column/mem/MemColumn.java": [
                0,
                20
            ],
            "redelm-column/src/main/java/redelm/column/mem/MemColumnsStore.java": [
                0,
                23
            ],
            "redelm-column/src/main/java/redelm/schema/GroupType.java": [
                0,
                4
            ],
            "redelm-column/src/main/java/redelm/schema/MessageType.java": [
                0,
                63
            ],
            "redelm-column/src/main/java/redelm/schema/PrimitiveType.java": [
                0,
                26
            ],
            "redelm-column/src/main/java/redelm/schema/Type.java": [
                2,
                2
            ],
            "redelm-column/src/test/java/redelm/io/TestColumnIO.java": [
                14,
                19
            ],
            "redelm-pig/pom.xml": null,
            "redelm-pig/src/main/java/redelm/pig/RedelmLoader.java": [
                76,
                28
            ],
            "redelm-pig/src/main/java/redelm/pig/TupleWriter.java": [
                0,
                5
            ],
            "redelm-pig/src/test/java/redelm/pig/TestTupleRecordConsumer.java": [
                7,
                7
            ]
        }
    },
    "40d512bf0ff7aaba12f6eb13acf37d760535572a": {
        "datetime": "2012-10-10T14:18:07-07:00",
        "summary": "work",
        "message": "work\n",
        "diff": {
            "redelm-column/pom.xml": null,
            "redelm-column/src/main/java/redelm/column/mem/MemColumn.java": [
                1,
                1
            ],
            "redelm-column/src/main/java/redelm/schema/GroupType.java": [
                13,
                23
            ],
            "redelm-column/src/main/java/redelm/schema/MessageType.java": [
                66,
                5
            ],
            "redelm-column/src/main/java/redelm/schema/PrimitiveType.java": [
                3,
                8
            ],
            "redelm-column/src/main/java/redelm/schema/Type.java": [
                3,
                46
            ],
            "redelm-column/src/test/java/redelm/io/TestColumnIO.java": [
                3,
                3
            ]
        }
    },
    "591da70b6153261c1aff895dce6f629e997a2966": {
        "datetime": "2012-10-11T11:27:24-07:00",
        "summary": "adding support for Float and Double",
        "message": "adding support for Float and Double\n",
        "diff": {
            "redelm-column/src/main/java/redelm/column/ColumnReader.java": [
                0,
                4
            ],
            "redelm-column/src/main/java/redelm/column/ColumnWriter.java": [
                0,
                4
            ],
            "redelm-column/src/main/java/redelm/column/mem/MemColumn.java": [
                22,
                80
            ],
            "redelm-column/src/main/java/redelm/column/mem/MemColumnsStore.java": [
                17,
                189
            ],
            "redelm-column/src/main/java/redelm/data/Group.java": [
                0,
                7
            ],
            "redelm-column/src/main/java/redelm/data/GroupRecordConsumer.java": [
                0,
                10
            ],
            "redelm-column/src/main/java/redelm/data/GroupWriter.java": [
                1,
                1
            ],
            "redelm-column/src/main/java/redelm/data/simple/BinaryValue.java": [
                0,
                7
            ],
            "redelm-column/src/main/java/redelm/data/simple/BoolValue.java": [
                0,
                7
            ],
            "redelm-column/src/main/java/redelm/data/simple/DoubleValue.java": [
                0,
                23
            ],
            "redelm-column/src/main/java/redelm/data/simple/FloatValue.java": [
                0,
                23
            ],
            "redelm-column/src/main/java/redelm/data/simple/IntValue.java": [
                0,
                7
            ],
            "redelm-column/src/main/java/redelm/data/simple/Primitive.java": [
                1,
                11
            ],
            "redelm-column/src/main/java/redelm/data/simple/SimpleGroup.java": [
                0,
                16
            ],
            "redelm-column/src/main/java/redelm/data/simple/StringValue.java": [
                0,
                7
            ],
            "redelm-column/src/main/java/redelm/io/GroupColumnIO.java": [
                1,
                3
            ],
            "redelm-column/src/main/java/redelm/io/MessageColumnIO.java": [
                3,
                21
            ],
            "redelm-column/src/main/java/redelm/io/RecordConsumer.java": [
                0,
                2
            ],
            "redelm-column/src/main/java/redelm/io/RecordConsumerWrapper.java": [
                13,
                18
            ],
            "redelm-column/src/main/java/redelm/schema/GroupType.java": [
                10,
                0
            ],
            "redelm-column/src/main/java/redelm/schema/MessageType.java": [
                1,
                0
            ],
            "redelm-column/src/main/java/redelm/schema/PrimitiveType.java": [
                79,
                11
            ],
            "redelm-column/src/main/java/redelm/schema/Type.java": [
                17,
                0
            ],
            "redelm-column/src/test/java/redelm/io/PerfTest.java": [
                64,
                60
            ],
            "redelm-column/src/test/java/redelm/io/TestColumnIO.java": [
                0,
                20
            ],
            "redelm-pig/src/main/java/redelm/pig/PigSchemaConverter.java": [
                3,
                12
            ],
            "redelm-pig/src/main/java/redelm/pig/RedelmFileReader.java": [
                1,
                10
            ],
            "redelm-pig/src/main/java/redelm/pig/RedelmFileWriter.java": [
                1,
                1
            ],
            "redelm-pig/src/main/java/redelm/pig/TupleRecordConsumer.java": [
                1,
                10
            ],
            "redelm-pig/src/test/java/redelm/pig/PerfTest.java": [
                0,
                83
            ],
            "redelm-pig/src/test/java/redelm/pig/PerfTest2.java": [
                0,
                146
            ],
            "redelm-pig/src/test/java/redelm/pig/TestRedelmFileWriter.java": [
                0,
                1
            ]
        }
    },
    "00257682aed55ab3ba05ee798cf38b56d51ecf62": {
        "datetime": "2012-10-11T22:07:17-07:00",
        "summary": "fixed tests",
        "message": "fixed tests\n",
        "diff": {
            "pom.xml": null,
            "redelm-pig/src/test/java/redelm/pig/TestPigSchemaConverter.java": [
                1,
                1
            ]
        }
    },
    "246efae86ecfd6a816c619c501b183a0e6dd9190": {
        "datetime": "2012-10-17T23:46:48-07:00",
        "summary": "refactor of the columns",
        "message": "refactor of the columns\n",
        "diff": {
            "redelm-column/src/main/java/redelm/column/BytesOutput.java": [
                0,
                9
            ],
            "redelm-column/src/main/java/redelm/column/ColumnWriter.java": [
                0,
                11
            ],
            "redelm-column/src/main/java/redelm/column/ColumnsStore.java": [
                3,
                1
            ],
            "redelm-column/src/main/java/redelm/column/RedelmByteArrayOutputStream.java": [
                0,
                16
            ],
            "redelm-column/src/main/java/redelm/column/mem/MemColumn.java": [
                241,
                230
            ],
            "redelm-column/src/main/java/redelm/column/mem/MemColumnReader.java": [
                0,
                123
            ],
            "redelm-column/src/main/java/redelm/column/mem/MemColumnWriter.java": [
                0,
                132
            ],
            "redelm-column/src/main/java/redelm/column/mem/MemColumnsStore.java": [
                274,
                15
            ],
            "redelm-column/src/main/java/redelm/column/primitive/PrimitiveColumnReader.java": [
                0,
                33
            ],
            "redelm-column/src/main/java/redelm/column/primitive/PrimitiveColumnWriter.java": [
                0,
                48
            ],
            "redelm-column/src/main/java/redelm/column/primitive/SimplePrimitiveColumnReader.java": [
                0,
                80
            ],
            "redelm-column/src/main/java/redelm/column/primitive/SimplePrimitiveColumnWriter.java": [
                0,
                113
            ],
            "redelm-column/src/main/java/redelm/io/RecordReader.java": [
                2,
                3
            ],
            "redelm-column/src/test/java/redelm/column/mem/TestMemColumn.java": [
                0,
                2
            ],
            "redelm-column/src/test/java/redelm/io/TestColumnIO.java": [
                10,
                40
            ],
            "redelm-pig/src/main/java/redelm/pig/BlockData.java": [
                0,
                23
            ],
            "redelm-pig/src/main/java/redelm/pig/ColumnData.java": [
                2,
                18
            ],
            "redelm-pig/src/main/java/redelm/pig/ColumnMetaData.java": [
                26,
                80
            ],
            "redelm-pig/src/main/java/redelm/pig/RedelmFileReader.java": [
                13,
                21
            ],
            "redelm-pig/src/main/java/redelm/pig/RedelmFileWriter.java": [
                10,
                94
            ],
            "redelm-pig/src/main/java/redelm/pig/RedelmInputFormat.java": [
                3,
                9
            ],
            "redelm-pig/src/main/java/redelm/pig/RedelmOutputFormat.java": [
                7,
                13
            ],
            "redelm-pig/src/test/java/redelm/pig/TestRedelmFileWriter.java": [
                13,
                37
            ]
        }
    },
    "527beef0aa1a42872eae1c9378b7bc4822468ed0": {
        "datetime": "2012-10-17T23:50:06-07:00",
        "summary": "adding license headers",
        "message": "adding license headers\n",
        "diff": {
            "redelm-column/src/main/java/redelm/column/BytesOutput.java": [
                0,
                15
            ],
            "redelm-column/src/main/java/redelm/column/RedelmByteArrayOutputStream.java": [
                0,
                15
            ],
            "redelm-column/src/main/java/redelm/column/mem/MemColumnReader.java": [
                0,
                15
            ],
            "redelm-column/src/main/java/redelm/column/mem/MemColumnWriter.java": [
                0,
                15
            ],
            "redelm-column/src/main/java/redelm/column/primitive/PrimitiveColumnReader.java": [
                0,
                15
            ],
            "redelm-column/src/main/java/redelm/column/primitive/PrimitiveColumnWriter.java": [
                0,
                15
            ],
            "redelm-column/src/main/java/redelm/column/primitive/SimplePrimitiveColumnReader.java": [
                0,
                15
            ],
            "redelm-column/src/main/java/redelm/column/primitive/SimplePrimitiveColumnWriter.java": [
                0,
                15
            ],
            "redelm-column/src/main/java/redelm/data/simple/DoubleValue.java": [
                0,
                15
            ],
            "redelm-column/src/main/java/redelm/data/simple/FloatValue.java": [
                0,
                15
            ],
            "redelm-column/src/test/java/redelm/schema/TestMessageType.java": [
                0,
                15
            ],
            "redelm-pig/src/main/java/redelm/pig/BlockData.java": [
                0,
                15
            ],
            "redelm-pig/src/main/java/redelm/pig/BlockMetaData.java": [
                0,
                15
            ],
            "redelm-pig/src/main/java/redelm/pig/ColumnData.java": [
                0,
                15
            ],
            "redelm-pig/src/main/java/redelm/pig/ColumnMetaData.java": [
                0,
                15
            ],
            "redelm-pig/src/main/java/redelm/pig/Footer.java": [
                0,
                15
            ],
            "redelm-pig/src/main/java/redelm/pig/PigSchemaConverter.java": [
                0,
                15
            ],
            "redelm-pig/src/main/java/redelm/pig/PrintFooter.java": [
                0,
                15
            ],
            "redelm-pig/src/main/java/redelm/pig/RedelmFileReader.java": [
                0,
                15
            ],
            "redelm-pig/src/main/java/redelm/pig/RedelmFileWriter.java": [
                0,
                15
            ],
            "redelm-pig/src/main/java/redelm/pig/RedelmInputFormat.java": [
                0,
                15
            ],
            "redelm-pig/src/main/java/redelm/pig/RedelmInputSplit.java": [
                0,
                15
            ],
            "redelm-pig/src/main/java/redelm/pig/RedelmOutputFormat.java": [
                0,
                15
            ],
            "redelm-pig/src/main/java/redelm/pig/RedelmStorer.java": [
                0,
                15
            ],
            "redelm-pig/src/main/java/redelm/pig/summary/BagSummaryData.java": [
                0,
                15
            ],
            "redelm-pig/src/main/java/redelm/pig/summary/EnumStat.java": [
                0,
                15
            ],
            "redelm-pig/src/main/java/redelm/pig/summary/FieldSummaryData.java": [
                0,
                15
            ],
            "redelm-pig/src/main/java/redelm/pig/summary/MapSummaryData.java": [
                0,
                15
            ],
            "redelm-pig/src/main/java/redelm/pig/summary/NumberSummaryData.java": [
                0,
                15
            ],
            "redelm-pig/src/main/java/redelm/pig/summary/StringSummaryData.java": [
                0,
                15
            ],
            "redelm-pig/src/main/java/redelm/pig/summary/Summary.java": [
                0,
                15
            ],
            "redelm-pig/src/main/java/redelm/pig/summary/SummaryData.java": [
                0,
                15
            ],
            "redelm-pig/src/main/java/redelm/pig/summary/TupleSummaryData.java": [
                0,
                15
            ],
            "redelm-pig/src/main/java/redelm/pig/summary/ValueStat.java": [
                0,
                15
            ],
            "redelm-pig/src/test/java/redelm/pig/PerfTest.java": [
                0,
                15
            ],
            "redelm-pig/src/test/java/redelm/pig/PerfTest2.java": [
                0,
                15
            ],
            "redelm-pig/src/test/java/redelm/pig/TestPigSchemaConverter.java": [
                0,
                15
            ],
            "redelm-pig/src/test/java/redelm/pig/TestRedelmFileWriter.java": [
                0,
                15
            ],
            "redelm-pig/src/test/java/redelm/pig/TestRedelmStorer.java": [
                0,
                15
            ],
            "redelm-pig/src/test/java/redelm/pig/summary/TestSummary.java": [
                0,
                15
            ]
        }
    },
    "11b8190df05c1ef61a6dc677db378bca62338062": {
        "datetime": "2012-10-17T23:51:46-07:00",
        "summary": "Merge pull request #1 from julienledem/hack_week",
        "message": "Merge pull request #1 from julienledem/hack_week\n\nmerging the PigLoader/Storer from Hack week",
        "diff": {
            ".gitignore": null,
            "pom.xml": null,
            "redelm-column/src/main/java/redelm/column/BytesOutput.java": [
                0,
                24
            ],
            "redelm-column/src/main/java/redelm/column/ColumnReader.java": [
                0,
                4
            ],
            "redelm-column/src/main/java/redelm/column/ColumnWriter.java": [
                0,
                15
            ],
            "redelm-column/src/main/java/redelm/column/ColumnsStore.java": [
                3,
                1
            ],
            "redelm-column/src/main/java/redelm/column/RedelmByteArrayOutputStream.java": [
                0,
                31
            ],
            "redelm-column/src/main/java/redelm/column/mem/MemColumn.java": [
                163,
                230
            ],
            "redelm-column/src/main/java/redelm/column/mem/MemColumnReader.java": [
                0,
                138
            ],
            "redelm-column/src/main/java/redelm/column/mem/MemColumnWriter.java": [
                0,
                147
            ],
            "redelm-column/src/main/java/redelm/column/mem/MemColumnsStore.java": [
                97,
                33
            ],
            "redelm-column/src/main/java/redelm/column/primitive/PrimitiveColumnReader.java": [
                0,
                48
            ],
            "redelm-column/src/main/java/redelm/column/primitive/PrimitiveColumnWriter.java": [
                0,
                63
            ],
            "redelm-column/src/main/java/redelm/column/primitive/SimplePrimitiveColumnReader.java": [
                0,
                95
            ],
            "redelm-column/src/main/java/redelm/column/primitive/SimplePrimitiveColumnWriter.java": [
                0,
                128
            ],
            "redelm-column/src/main/java/redelm/data/Group.java": [
                0,
                7
            ],
            "redelm-column/src/main/java/redelm/data/GroupRecordConsumer.java": [
                0,
                10
            ],
            "redelm-column/src/main/java/redelm/data/GroupWriter.java": [
                1,
                1
            ],
            "redelm-column/src/main/java/redelm/data/simple/BinaryValue.java": [
                0,
                7
            ],
            "redelm-column/src/main/java/redelm/data/simple/BoolValue.java": [
                0,
                7
            ],
            "redelm-column/src/main/java/redelm/data/simple/DoubleValue.java": [
                0,
                38
            ],
            "redelm-column/src/main/java/redelm/data/simple/FloatValue.java": [
                0,
                38
            ],
            "redelm-column/src/main/java/redelm/data/simple/IntValue.java": [
                0,
                7
            ],
            "redelm-column/src/main/java/redelm/data/simple/Primitive.java": [
                1,
                11
            ],
            "redelm-column/src/main/java/redelm/data/simple/SimpleGroup.java": [
                0,
                16
            ],
            "redelm-column/src/main/java/redelm/data/simple/StringValue.java": [
                0,
                7
            ],
            "redelm-column/src/main/java/redelm/io/GroupColumnIO.java": [
                1,
                3
            ],
            "redelm-column/src/main/java/redelm/io/MessageColumnIO.java": [
                3,
                21
            ],
            "redelm-column/src/main/java/redelm/io/RecordConsumer.java": [
                0,
                2
            ],
            "redelm-column/src/main/java/redelm/io/RecordConsumerWrapper.java": [
                13,
                18
            ],
            "redelm-column/src/main/java/redelm/io/RecordReader.java": [
                2,
                3
            ],
            "redelm-column/src/main/java/redelm/schema/GroupType.java": [
                10,
                4
            ],
            "redelm-column/src/main/java/redelm/schema/MessageType.java": [
                1,
                63
            ],
            "redelm-column/src/main/java/redelm/schema/PrimitiveType.java": [
                63,
                21
            ],
            "redelm-column/src/main/java/redelm/schema/Type.java": [
                17,
                0
            ],
            "redelm-column/src/test/java/redelm/column/mem/TestMemColumn.java": [
                0,
                2
            ],
            "redelm-column/src/test/java/redelm/io/PerfTest.java": [
                64,
                60
            ],
            "redelm-column/src/test/java/redelm/io/TestColumnIO.java": [
                10,
                60
            ],
            "redelm-column/src/test/java/redelm/schema/TestMessageType.java": [
                0,
                30
            ],
            "redelm-pig/pom.xml": null,
            "redelm-pig/src/main/java/redelm/pig/BlockData.java": [
                0,
                38
            ],
            "redelm-pig/src/main/java/redelm/pig/BlockMetaData.java": [
                0,
                66
            ],
            "redelm-pig/src/main/java/redelm/pig/ColumnData.java": [
                0,
                59
            ],
            "redelm-pig/src/main/java/redelm/pig/ColumnMetaData.java": [
                0,
                125
            ],
            "redelm-pig/src/main/java/redelm/pig/Footer.java": [
                0,
                93
            ],
            "redelm-pig/src/main/java/redelm/pig/PigSchemaConverter.java": [
                0,
                107
            ],
            "redelm-pig/src/main/java/redelm/pig/PrintFooter.java": [
                0,
                42
            ],
            "redelm-pig/src/main/java/redelm/pig/RedelmFileReader.java": [
                0,
                105
            ],
            "redelm-pig/src/main/java/redelm/pig/RedelmFileWriter.java": [
                0,
                173
            ],
            "redelm-pig/src/main/java/redelm/pig/RedelmInputFormat.java": [
                0,
                215
            ],
            "redelm-pig/src/main/java/redelm/pig/RedelmInputSplit.java": [
                0,
                117
            ],
            "redelm-pig/src/main/java/redelm/pig/RedelmLoader.java": [
                76,
                28
            ],
            "redelm-pig/src/main/java/redelm/pig/RedelmOutputFormat.java": [
                0,
                113
            ],
            "redelm-pig/src/main/java/redelm/pig/RedelmStorer.java": [
                0,
                102
            ],
            "redelm-pig/src/main/java/redelm/pig/TupleRecordConsumer.java": [
                1,
                10
            ],
            "redelm-pig/src/main/java/redelm/pig/summary/BagSummaryData.java": [
                0,
                79
            ],
            "redelm-pig/src/main/java/redelm/pig/summary/EnumStat.java": [
                0,
                112
            ],
            "redelm-pig/src/main/java/redelm/pig/summary/FieldSummaryData.java": [
                0,
                181
            ],
            "redelm-pig/src/main/java/redelm/pig/summary/MapSummaryData.java": [
                0,
                90
            ],
            "redelm-pig/src/main/java/redelm/pig/summary/NumberSummaryData.java": [
                0,
                47
            ],
            "redelm-pig/src/main/java/redelm/pig/summary/StringSummaryData.java": [
                0,
                81
            ],
            "redelm-pig/src/main/java/redelm/pig/summary/Summary.java": [
                0,
                280
            ],
            "redelm-pig/src/main/java/redelm/pig/summary/SummaryData.java": [
                0,
                156
            ],
            "redelm-pig/src/main/java/redelm/pig/summary/TupleSummaryData.java": [
                0,
                104
            ],
            "redelm-pig/src/main/java/redelm/pig/summary/ValueStat.java": [
                0,
                61
            ],
            "redelm-pig/src/test/java/redelm/pig/PerfTest.java": [
                0,
                98
            ],
            "redelm-pig/src/test/java/redelm/pig/PerfTest2.java": [
                0,
                161
            ],
            "redelm-pig/src/test/java/redelm/pig/TestPigSchemaConverter.java": [
                0,
                42
            ],
            "redelm-pig/src/test/java/redelm/pig/TestRedelmFileWriter.java": [
                0,
                135
            ],
            "redelm-pig/src/test/java/redelm/pig/TestRedelmStorer.java": [
                0,
                127
            ],
            "redelm-pig/src/test/java/redelm/pig/summary/TestSummary.java": [
                0,
                143
            ]
        }
    },
    "1e7152b65092572a7bbe7e58dd18e163fce51cc2": {
        "datetime": "2012-10-18T11:38:26-07:00",
        "summary": "work",
        "message": "work\n",
        "diff": {
            "redelm-column/src/main/antlr3/redelm/parser/RedelmMessageLexer.g": null,
            "redelm-column/src/main/antlr3/redelm/parser/RedelmMessageParser.g": null,
            "redelm-column/src/main/java/redelm/parser/RedelmParser.java": [
                0,
                35
            ],
            "redelm-column/src/test/java/redelm/parser/TestRedelmParser.java": [
                0,
                61
            ],
            "redelm-column/src/test/java/redelm/schema/TestMessageType.java": [
                0,
                17
            ],
            "redelm-pig/bin/pom.xml": null,
            "redelm-pig/src/main/java/redelm/pig/BlockMetaData.java": [
                0,
                51
            ],
            "redelm-pig/src/main/java/redelm/pig/ColumnData.java": [
                0,
                28
            ],
            "redelm-pig/src/main/java/redelm/pig/ColumnMetaData.java": [
                0,
                56
            ],
            "redelm-pig/src/main/java/redelm/pig/Footer.java": [
                0,
                78
            ],
            "redelm-pig/src/main/java/redelm/pig/PigSchemaConverter.java": [
                0,
                83
            ],
            "redelm-pig/src/main/java/redelm/pig/PrintFooter.java": [
                0,
                27
            ],
            "redelm-pig/src/main/java/redelm/pig/RedelmFileReader.java": [
                0,
                73
            ],
            "redelm-pig/src/main/java/redelm/pig/RedelmFileWriter.java": [
                0,
                74
            ],
            "redelm-pig/src/main/java/redelm/pig/RedelmInputFormat.java": [
                0,
                205
            ],
            "redelm-pig/src/main/java/redelm/pig/RedelmInputSplit.java": [
                0,
                102
            ],
            "redelm-pig/src/main/java/redelm/pig/RedelmOutputFormat.java": [
                0,
                92
            ],
            "redelm-pig/src/main/java/redelm/pig/RedelmStorer.java": [
                0,
                87
            ],
            "redelm-pig/src/main/java/redelm/pig/summary/BagSummaryData.java": [
                0,
                64
            ],
            "redelm-pig/src/main/java/redelm/pig/summary/EnumStat.java": [
                0,
                97
            ],
            "redelm-pig/src/main/java/redelm/pig/summary/FieldSummaryData.java": [
                0,
                166
            ],
            "redelm-pig/src/main/java/redelm/pig/summary/MapSummaryData.java": [
                0,
                75
            ],
            "redelm-pig/src/main/java/redelm/pig/summary/NumberSummaryData.java": [
                0,
                32
            ],
            "redelm-pig/src/main/java/redelm/pig/summary/StringSummaryData.java": [
                0,
                66
            ],
            "redelm-pig/src/main/java/redelm/pig/summary/Summary.java": [
                0,
                265
            ],
            "redelm-pig/src/main/java/redelm/pig/summary/SummaryData.java": [
                0,
                141
            ],
            "redelm-pig/src/main/java/redelm/pig/summary/TupleSummaryData.java": [
                0,
                89
            ],
            "redelm-pig/src/main/java/redelm/pig/summary/ValueStat.java": [
                0,
                46
            ],
            "redelm-pig/src/test/java/redelm/pig/TestPigSchemaConverter.java": [
                0,
                32
            ],
            "redelm-pig/src/test/java/redelm/pig/TestRedelmFileWriter.java": [
                0,
                98
            ],
            "redelm-pig/src/test/java/redelm/pig/TestRedelmStorer.java": [
                0,
                127
            ],
            "redelm-pig/src/test/java/redelm/pig/summary/TestSummary.java": [
                0,
                128
            ]
        }
    },
    "9da016d3ad52385ba0f99f0ee5290bdae785d584": {
        "datetime": "2012-10-18T11:47:04-07:00",
        "summary": "merged",
        "message": "merged\n",
        "diff": {
            "pom.xml": null,
            "redelm-column/src/main/java/redelm/column/BytesOutput.java": [
                0,
                24
            ],
            "redelm-column/src/main/java/redelm/column/ColumnReader.java": [
                0,
                4
            ],
            "redelm-column/src/main/java/redelm/column/ColumnWriter.java": [
                0,
                15
            ],
            "redelm-column/src/main/java/redelm/column/ColumnsStore.java": [
                3,
                1
            ],
            "redelm-column/src/main/java/redelm/column/RedelmByteArrayOutputStream.java": [
                0,
                31
            ],
            "redelm-column/src/main/java/redelm/column/mem/MemColumn.java": [
                156,
                227
            ],
            "redelm-column/src/main/java/redelm/column/mem/MemColumnReader.java": [
                0,
                138
            ],
            "redelm-column/src/main/java/redelm/column/mem/MemColumnWriter.java": [
                0,
                147
            ],
            "redelm-column/src/main/java/redelm/column/mem/MemColumnsStore.java": [
                102,
                15
            ],
            "redelm-column/src/main/java/redelm/column/primitive/PrimitiveColumnReader.java": [
                0,
                48
            ],
            "redelm-column/src/main/java/redelm/column/primitive/PrimitiveColumnWriter.java": [
                0,
                63
            ],
            "redelm-column/src/main/java/redelm/column/primitive/SimplePrimitiveColumnReader.java": [
                0,
                95
            ],
            "redelm-column/src/main/java/redelm/column/primitive/SimplePrimitiveColumnWriter.java": [
                0,
                128
            ],
            "redelm-column/src/main/java/redelm/data/Group.java": [
                0,
                7
            ],
            "redelm-column/src/main/java/redelm/data/GroupRecordConsumer.java": [
                0,
                10
            ],
            "redelm-column/src/main/java/redelm/data/GroupWriter.java": [
                1,
                1
            ],
            "redelm-column/src/main/java/redelm/data/simple/BinaryValue.java": [
                0,
                7
            ],
            "redelm-column/src/main/java/redelm/data/simple/BoolValue.java": [
                0,
                7
            ],
            "redelm-column/src/main/java/redelm/data/simple/DoubleValue.java": [
                0,
                38
            ],
            "redelm-column/src/main/java/redelm/data/simple/FloatValue.java": [
                0,
                38
            ],
            "redelm-column/src/main/java/redelm/data/simple/IntValue.java": [
                0,
                7
            ],
            "redelm-column/src/main/java/redelm/data/simple/Primitive.java": [
                1,
                11
            ],
            "redelm-column/src/main/java/redelm/data/simple/SimpleGroup.java": [
                0,
                16
            ],
            "redelm-column/src/main/java/redelm/data/simple/StringValue.java": [
                0,
                7
            ],
            "redelm-column/src/main/java/redelm/io/GroupColumnIO.java": [
                1,
                3
            ],
            "redelm-column/src/main/java/redelm/io/MessageColumnIO.java": [
                3,
                21
            ],
            "redelm-column/src/main/java/redelm/io/RecordConsumer.java": [
                0,
                2
            ],
            "redelm-column/src/main/java/redelm/io/RecordConsumerWrapper.java": [
                13,
                18
            ],
            "redelm-column/src/main/java/redelm/io/RecordReader.java": [
                2,
                3
            ],
            "redelm-column/src/main/java/redelm/schema/GroupType.java": [
                10,
                0
            ],
            "redelm-column/src/main/java/redelm/schema/MessageType.java": [
                1,
                70
            ],
            "redelm-column/src/main/java/redelm/schema/PrimitiveType.java": [
                65,
                27
            ],
            "redelm-column/src/main/java/redelm/schema/Type.java": [
                61,
                1
            ],
            "redelm-column/src/test/java/redelm/column/mem/TestMemColumn.java": [
                0,
                2
            ],
            "redelm-column/src/test/java/redelm/io/PerfTest.java": [
                64,
                60
            ],
            "redelm-column/src/test/java/redelm/io/TestColumnIO.java": [
                12,
                60
            ],
            "redelm-column/src/test/java/redelm/schema/TestMessageType.java": [
                8,
                21
            ],
            "redelm-pig/src/main/java/redelm/pig/BlockData.java": [
                0,
                38
            ],
            "redelm-pig/src/main/java/redelm/pig/BlockMetaData.java": [
                0,
                15
            ],
            "redelm-pig/src/main/java/redelm/pig/ColumnData.java": [
                2,
                33
            ],
            "redelm-pig/src/main/java/redelm/pig/ColumnMetaData.java": [
                26,
                95
            ],
            "redelm-pig/src/main/java/redelm/pig/Footer.java": [
                0,
                15
            ],
            "redelm-pig/src/main/java/redelm/pig/PigSchemaConverter.java": [
                5,
                29
            ],
            "redelm-pig/src/main/java/redelm/pig/PrintFooter.java": [
                0,
                15
            ],
            "redelm-pig/src/main/java/redelm/pig/RedelmFileReader.java": [
                6,
                38
            ],
            "redelm-pig/src/main/java/redelm/pig/RedelmFileWriter.java": [
                11,
                110
            ],
            "redelm-pig/src/main/java/redelm/pig/RedelmInputFormat.java": [
                120,
                130
            ],
            "redelm-pig/src/main/java/redelm/pig/RedelmInputSplit.java": [
                0,
                15
            ],
            "redelm-pig/src/main/java/redelm/pig/RedelmOutputFormat.java": [
                7,
                28
            ],
            "redelm-pig/src/main/java/redelm/pig/RedelmStorer.java": [
                0,
                15
            ],
            "redelm-pig/src/main/java/redelm/pig/TupleRecordConsumer.java": [
                1,
                10
            ],
            "redelm-pig/src/main/java/redelm/pig/summary/BagSummaryData.java": [
                0,
                15
            ],
            "redelm-pig/src/main/java/redelm/pig/summary/EnumStat.java": [
                0,
                15
            ],
            "redelm-pig/src/main/java/redelm/pig/summary/FieldSummaryData.java": [
                0,
                15
            ],
            "redelm-pig/src/main/java/redelm/pig/summary/MapSummaryData.java": [
                0,
                15
            ],
            "redelm-pig/src/main/java/redelm/pig/summary/NumberSummaryData.java": [
                0,
                15
            ],
            "redelm-pig/src/main/java/redelm/pig/summary/StringSummaryData.java": [
                0,
                15
            ],
            "redelm-pig/src/main/java/redelm/pig/summary/Summary.java": [
                0,
                15
            ],
            "redelm-pig/src/main/java/redelm/pig/summary/SummaryData.java": [
                0,
                15
            ],
            "redelm-pig/src/main/java/redelm/pig/summary/TupleSummaryData.java": [
                0,
                15
            ],
            "redelm-pig/src/main/java/redelm/pig/summary/ValueStat.java": [
                0,
                15
            ],
            "redelm-pig/src/test/java/redelm/pig/PerfTest.java": [
                0,
                98
            ],
            "redelm-pig/src/test/java/redelm/pig/PerfTest2.java": [
                0,
                161
            ],
            "redelm-pig/src/test/java/redelm/pig/TestPigSchemaConverter.java": [
                17,
                27
            ],
            "redelm-pig/src/test/java/redelm/pig/TestRedelmFileWriter.java": [
                38,
                75
            ],
            "redelm-pig/src/test/java/redelm/pig/TestRedelmStorer.java": [
                37,
                37
            ],
            "redelm-pig/src/test/java/redelm/pig/summary/TestSummary.java": [
                0,
                15
            ]
        }
    },
    "71b7b11456f677e17a6fb7ca5bce862257c12048": {
        "datetime": "2012-10-18T11:54:11-07:00",
        "summary": "work",
        "message": "work\n",
        "diff": {
            "redelm-column/src/main/java/redelm/column/mem/MemColumn.java": [
                24,
                0
            ],
            "redelm-column/src/main/java/redelm/schema/MessageType.java": [
                66,
                0
            ]
        }
    },
    "02b40db07adcb0c382de4b7bfa4fc019d4a06fa0": {
        "datetime": "2012-10-18T14:10:11-07:00",
        "summary": "work",
        "message": "work\n",
        "diff": {
            "redelm-column/src/main/antlr3/redelm/parser/RedelmMessageLexer.g": null,
            "redelm-column/src/main/java/redelm/parser/RedelmParser.java": [
                16,
                16
            ],
            "redelm-column/src/main/java/redelm/schema/GroupType.java": [
                10,
                31
            ],
            "redelm-column/src/main/java/redelm/schema/MessageType.java": [
                7,
                2
            ],
            "redelm-column/src/main/java/redelm/schema/PrimitiveType.java": [
                47,
                32
            ],
            "redelm-column/src/main/java/redelm/schema/Type.java": [
                1,
                17
            ],
            "redelm-column/src/test/java/redelm/io/TestColumnIO.java": [
                4,
                4
            ],
            "redelm-column/src/test/java/redelm/schema/TestMessageType.java": [
                20,
                8
            ],
            "redelm-pig/src/main/java/redelm/pig/PigSchemaConverter.java": [
                2,
                2
            ],
            "redelm-pig/src/main/java/redelm/pig/RedelmInputFormat.java": [
                9,
                19
            ],
            "redelm-pig/src/test/java/redelm/pig/TestPigSchemaConverter.java": [
                11,
                14
            ],
            "redelm-pig/src/test/java/redelm/pig/TestRedelmFileWriter.java": [
                4,
                6
            ],
            "redelm-pig/src/test/java/redelm/pig/TestRedelmStorer.java": [
                38,
                38
            ]
        }
    },
    "38434c66f24ddd47d7a0b3683e3fcfefcadbfedd": {
        "datetime": "2012-10-18T14:23:20-07:00",
        "summary": "work",
        "message": "work\n",
        "diff": {
            "redelm-column/src/test/java/redelm/io/PerfTest.java": [
                1,
                5
            ],
            "redelm-pig/src/test/java/redelm/pig/PerfTest2.java": [
                4,
                3
            ],
            "redelm-pig/src/test/java/redelm/pig/TestRedelmFileWriter.java": [
                18,
                19
            ],
            "redelm-pig/src/test/java/redelm/pig/TestRedelmStorer.java": [
                11,
                11
            ],
            "redelm-pig/src/test/java/redelm/pig/summary/TestSummary.java": [
                12,
                8
            ]
        }
    },
    "f84fa2786b1951b81ab39f62a42b194bccee0dca": {
        "datetime": "2012-10-23T18:11:02-07:00",
        "summary": "work",
        "message": "work\n",
        "diff": {
            "redelm-column/src/main/antlr3/redelm/parser/RedelmMessageLexer.g": null,
            "redelm-column/src/main/antlr3/redelm/parser/RedelmMessageParser.g": null,
            "redelm-column/src/main/java/redelm/parser/RedelmParser.java": [
                7,
                31
            ],
            "redelm-column/src/test/java/redelm/parser/TestRedelmParser.java": [
                4,
                4
            ],
            "redelm-column/src/test/java/redelm/schema/TestMessageType.java": [
                1,
                1
            ],
            "redelm-pig/src/main/java/redelm/pig/RedelmInputFormat.java": [
                6,
                6
            ],
            "redelm-pig/src/main/java/redelm/pig/TupleWriter.java": [
                5,
                0
            ],
            "redelm-pig/src/test/java/redelm/pig/PerfTest.java": [
                3,
                3
            ],
            "redelm-pig/src/test/java/redelm/pig/TestPigSchemaConverter.java": [
                1,
                1
            ],
            "redelm-pig/src/test/java/redelm/pig/TestRedelmFileWriter.java": [
                1,
                1
            ]
        }
    },
    "30e3849451d4734bc776116316ecd547612743d7": {
        "datetime": "2012-10-23T18:36:31-07:00",
        "summary": "work",
        "message": "work\n",
        "diff": {
            "redelm-column/src/main/antlr3/redelm/parser/RedelmMessageLexer.g": null,
            "redelm-column/src/main/antlr3/redelm/parser/RedelmMessageParser.g": null,
            "redelm-column/src/main/java/redelm/column/ColumnReader.java": [
                2,
                2
            ],
            "redelm-column/src/main/java/redelm/column/mem/MemColumn.java": [
                3,
                3
            ],
            "redelm-column/src/main/java/redelm/column/mem/MemColumnReader.java": [
                2,
                2
            ],
            "redelm-column/src/main/java/redelm/data/GroupRecordConsumer.java": [
                1,
                1
            ],
            "redelm-column/src/main/java/redelm/data/simple/IntValue.java": [
                1,
                1
            ],
            "redelm-column/src/main/java/redelm/io/MessageColumnIO.java": [
                1,
                1
            ],
            "redelm-column/src/main/java/redelm/io/RecordConsumer.java": [
                1,
                1
            ],
            "redelm-column/src/main/java/redelm/io/RecordConsumerWrapper.java": [
                2,
                2
            ],
            "redelm-column/src/main/java/redelm/parser/RedelmParser.java": [
                0,
                15
            ],
            "redelm-column/src/main/java/redelm/schema/PrimitiveType.java": [
                5,
                5
            ],
            "redelm-column/src/test/java/redelm/column/mem/TestMemColumn.java": [
                2,
                2
            ],
            "redelm-column/src/test/java/redelm/io/PerfTest.java": [
                1,
                1
            ],
            "redelm-column/src/test/java/redelm/io/TestColumnIO.java": [
                1,
                1
            ],
            "redelm-column/src/test/java/redelm/parser/TestRedelmParser.java": [
                0,
                15
            ],
            "redelm-column/src/test/java/redelm/schema/TestMessageType.java": [
                0,
                15
            ],
            "redelm-pig/src/main/java/redelm/pig/PigSchemaConverter.java": [
                1,
                1
            ],
            "redelm-pig/src/main/java/redelm/pig/TupleRecordConsumer.java": [
                1,
                1
            ],
            "redelm-pig/src/main/java/redelm/pig/TupleWriter.java": [
                2,
                2
            ],
            "redelm-pig/src/test/java/redelm/pig/TestRedelmStorer.java": [
                0,
                15
            ]
        }
    },
    "194cfdb45655637912375271ea1dbb15a2bb24aa": {
        "datetime": "2012-10-24T11:02:37-07:00",
        "summary": "work",
        "message": "work\n",
        "diff": {
            "redelm-pig/bin/pom.xml": null
        }
    },
    "e12b27f08595a0696ac182a81623c78fd8deb8d7": {
        "datetime": "2012-10-24T16:47:13-07:00",
        "summary": "fix support for int/long and map",
        "message": "fix support for int/long and map\n",
        "diff": {
            "redelm-column/src/main/java/redelm/column/ColumnReader.java": [
                0,
                2
            ],
            "redelm-column/src/main/java/redelm/column/ColumnWriter.java": [
                0,
                3
            ],
            "redelm-column/src/main/java/redelm/column/mem/MemColumn.java": [
                2,
                29
            ],
            "redelm-column/src/main/java/redelm/column/mem/MemColumnReader.java": [
                0,
                5
            ],
            "redelm-column/src/main/java/redelm/column/mem/MemColumnWriter.java": [
                0,
                8
            ],
            "redelm-column/src/main/java/redelm/column/primitive/PrimitiveColumnReader.java": [
                0,
                4
            ],
            "redelm-column/src/main/java/redelm/column/primitive/SimplePrimitiveColumnReader.java": [
                0,
                9
            ],
            "redelm-column/src/main/java/redelm/data/Group.java": [
                0,
                11
            ],
            "redelm-column/src/main/java/redelm/data/GroupRecordConsumer.java": [
                0,
                5
            ],
            "redelm-column/src/main/java/redelm/data/simple/Primitive.java": [
                0,
                4
            ],
            "redelm-column/src/main/java/redelm/data/simple/SimpleGroup.java": [
                0,
                5
            ],
            "redelm-column/src/main/java/redelm/data/simple/example/Paper.java": [
                10,
                10
            ],
            "redelm-column/src/main/java/redelm/io/GroupColumnIO.java": [
                1,
                5
            ],
            "redelm-column/src/main/java/redelm/io/MessageColumnIO.java": [
                11,
                30
            ],
            "redelm-column/src/main/java/redelm/io/RecordConsumer.java": [
                0,
                1
            ],
            "redelm-column/src/main/java/redelm/io/RecordConsumerWrapper.java": [
                0,
                6
            ],
            "redelm-column/src/main/java/redelm/schema/PrimitiveType.java": [
                0,
                11
            ],
            "redelm-column/src/test/java/redelm/column/mem/TestMemColumn.java": [
                3,
                3
            ],
            "redelm-column/src/test/java/redelm/io/PerfTest.java": [
                0,
                1
            ],
            "redelm-column/src/test/java/redelm/io/TestColumnIO.java": [
                4,
                14
            ],
            "redelm-pig/src/main/java/redelm/pig/Footer.java": [
                1,
                8
            ],
            "redelm-pig/src/main/java/redelm/pig/PigSchemaConverter.java": [
                2,
                2
            ],
            "redelm-pig/src/main/java/redelm/pig/RedelmFileWriter.java": [
                2,
                4
            ],
            "redelm-pig/src/main/java/redelm/pig/RedelmInputFormat.java": [
                2,
                8
            ],
            "redelm-pig/src/main/java/redelm/pig/RedelmInputSplit.java": [
                2,
                23
            ],
            "redelm-pig/src/main/java/redelm/pig/RedelmOutputFormat.java": [
                2,
                4
            ],
            "redelm-pig/src/main/java/redelm/pig/RedelmStorer.java": [
                2,
                4
            ],
            "redelm-pig/src/main/java/redelm/pig/TupleRecordConsumer.java": [
                25,
                86
            ],
            "redelm-pig/src/main/java/redelm/pig/TupleWriter.java": [
                18,
                54
            ],
            "redelm-pig/src/test/java/redelm/pig/TestRedelmFileWriter.java": [
                1,
                1
            ],
            "redelm-pig/src/test/java/redelm/pig/TestTupleRecordConsumer.java": [
                2,
                41
            ]
        }
    },
    "d0806980aaed917ab5139533446449af33602a30": {
        "datetime": "2012-10-25T14:31:21-07:00",
        "summary": "adding schema validation",
        "message": "adding schema validation\n",
        "diff": {
            "redelm-column/src/main/java/redelm/RedelmRuntimeException.java": [
                0,
                22
            ],
            "redelm-column/src/main/java/redelm/data/simple/LongValue.java": [
                0,
                42
            ],
            "redelm-column/src/main/java/redelm/io/InvalidRecordException.java": [
                0,
                24
            ],
            "redelm-column/src/main/java/redelm/io/ValidatingRecordConsumer.java": [
                0,
                134
            ],
            "redelm-column/src/test/java/redelm/io/TestColumnIO.java": [
                3,
                2
            ]
        }
    },
    "da419bfe8ddb40261da15a88d5dad6520ed91ec2": {
        "datetime": "2012-10-29T16:19:14-07:00",
        "summary": "fix bug regarding null values in message",
        "message": "fix bug regarding null values in message\n",
        "diff": {
            "redelm-column/src/main/java/redelm/io/MessageColumnIO.java": [
                0,
                1
            ],
            "redelm-column/src/main/java/redelm/io/RecordConsumerWrapper.java": [
                3,
                1
            ]
        }
    },
    "9f9b23d3855518e54e88567b88a2998d67247df9": {
        "datetime": "2012-10-30T16:18:26-07:00",
        "summary": "work",
        "message": "work\n",
        "diff": {
            "redelm-column/src/main/java/redelm/RedelmRuntimeException.java": [
                0,
                22
            ],
            "redelm-column/src/main/java/redelm/column/ColumnReader.java": [
                0,
                6
            ],
            "redelm-column/src/main/java/redelm/column/ColumnWriter.java": [
                0,
                3
            ],
            "redelm-column/src/main/java/redelm/column/mem/MemColumn.java": [
                2,
                29
            ],
            "redelm-column/src/main/java/redelm/column/mem/MemColumnReader.java": [
                0,
                4
            ],
            "redelm-column/src/main/java/redelm/column/mem/MemColumnWriter.java": [
                0,
                8
            ],
            "redelm-column/src/main/java/redelm/column/primitive/PrimitiveColumnReader.java": [
                0,
                4
            ],
            "redelm-column/src/main/java/redelm/column/primitive/SimplePrimitiveColumnReader.java": [
                0,
                9
            ],
            "redelm-column/src/main/java/redelm/data/Group.java": [
                0,
                11
            ],
            "redelm-column/src/main/java/redelm/data/GroupRecordConsumer.java": [
                0,
                5
            ],
            "redelm-column/src/main/java/redelm/data/simple/LongValue.java": [
                0,
                42
            ],
            "redelm-column/src/main/java/redelm/data/simple/Primitive.java": [
                0,
                4
            ],
            "redelm-column/src/main/java/redelm/data/simple/SimpleGroup.java": [
                0,
                5
            ],
            "redelm-column/src/main/java/redelm/data/simple/example/Paper.java": [
                10,
                10
            ],
            "redelm-column/src/main/java/redelm/io/GroupColumnIO.java": [
                1,
                5
            ],
            "redelm-column/src/main/java/redelm/io/InvalidRecordException.java": [
                0,
                24
            ],
            "redelm-column/src/main/java/redelm/io/MessageColumnIO.java": [
                11,
                31
            ],
            "redelm-column/src/main/java/redelm/io/RecordConsumer.java": [
                0,
                1
            ],
            "redelm-column/src/main/java/redelm/io/RecordConsumerWrapper.java": [
                3,
                7
            ],
            "redelm-column/src/main/java/redelm/io/ValidatingRecordConsumer.java": [
                0,
                134
            ],
            "redelm-column/src/main/java/redelm/schema/PrimitiveType.java": [
                0,
                11
            ],
            "redelm-column/src/test/java/redelm/column/mem/TestMemColumn.java": [
                3,
                3
            ],
            "redelm-column/src/test/java/redelm/io/PerfTest.java": [
                0,
                1
            ],
            "redelm-column/src/test/java/redelm/io/TestColumnIO.java": [
                7,
                16
            ],
            "redelm-pig/src/main/java/redelm/pig/Footer.java": [
                1,
                8
            ],
            "redelm-pig/src/main/java/redelm/pig/PigSchemaConverter.java": [
                2,
                2
            ],
            "redelm-pig/src/main/java/redelm/pig/RedelmFileWriter.java": [
                2,
                4
            ],
            "redelm-pig/src/main/java/redelm/pig/RedelmInputFormat.java": [
                2,
                7
            ],
            "redelm-pig/src/main/java/redelm/pig/RedelmInputSplit.java": [
                2,
                23
            ],
            "redelm-pig/src/main/java/redelm/pig/RedelmOutputFormat.java": [
                2,
                4
            ],
            "redelm-pig/src/main/java/redelm/pig/RedelmStorer.java": [
                2,
                4
            ],
            "redelm-pig/src/main/java/redelm/pig/TupleRecordConsumer.java": [
                25,
                86
            ],
            "redelm-pig/src/main/java/redelm/pig/TupleWriter.java": [
                18,
                54
            ],
            "redelm-pig/src/test/java/redelm/pig/TestRedelmFileWriter.java": [
                1,
                1
            ],
            "redelm-pig/src/test/java/redelm/pig/TestTupleRecordConsumer.java": [
                2,
                45
            ]
        }
    },
    "9c34678e5cfd2e228664261b25dcce8033ea22bb": {
        "datetime": "2012-10-30T16:52:36-07:00",
        "summary": "work",
        "message": "work\n",
        "diff": {
            "redelm-column/src/main/java/redelm/column/ColumnReader.java": [
                5,
                1
            ],
            "redelm-column/src/main/java/redelm/data/GroupValueSource.java": [
                6,
                6
            ],
            "redelm-column/src/main/java/redelm/data/simple/BoolValue.java": [
                41,
                0
            ],
            "redelm-column/src/main/java/redelm/data/simple/Primitive.java": [
                1,
                1
            ],
            "redelm-column/src/main/java/redelm/data/simple/SimpleGroup.java": [
                4,
                4
            ],
            "redelm-column/src/main/java/redelm/io/ValidatingRecordConsumer.java": [
                3,
                3
            ],
            "redelm-pig/src/main/java/redelm/pig/TupleWriter.java": [
                1,
                1
            ],
            "redelm-pig/src/test/java/redelm/pig/TestTupleRecordConsumer.java": [
                1,
                1
            ]
        }
    },
    "525d3aece83ed9a0d46ab2c0568277f6345bba91": {
        "datetime": "2012-10-31T12:57:44-07:00",
        "summary": "work",
        "message": "work\n",
        "diff": {
            "redelm-column/pom.xml": null,
            "redelm-column/src/main/java/redelm/parser/RedelmParser.java": [
                6,
                67
            ],
            "redelm-pig/src/main/java/redelm/pig/RedelmInputFormat.java": [
                11,
                2
            ]
        }
    },
    "4cd5bc1d011e44d43b3d25d3ab20c3f7d4b7ca83": {
        "datetime": "2012-10-31T12:57:55-07:00",
        "summary": "work",
        "message": "work\n",
        "diff": {
            "redelm-column/src/main/java/redelm/data/simple/BooleanValue.java": [
                0,
                41
            ]
        }
    },
    "063486db8c7112f8790527b6c24e98198760d5ba": {
        "datetime": "2012-10-31T13:07:49-07:00",
        "summary": "work",
        "message": "work\n",
        "diff": {
            "redelm-column/src/main/java/redelm/data/simple/IntValue.java": [
                3,
                3
            ],
            "redelm-column/src/main/java/redelm/data/simple/Primitive.java": [
                1,
                1
            ],
            "redelm-column/src/main/java/redelm/data/simple/SimpleGroup.java": [
                2,
                2
            ]
        }
    },
    "ba06716ed8eecd9ec7d2ac7d8afb3d3f4517533c": {
        "datetime": "2012-10-31T13:38:44-07:00",
        "summary": "remove a use of StringBuffer",
        "message": "remove a use of StringBuffer\n",
        "diff": {
            "redelm-column/src/main/java/redelm/column/mem/MemColumnsStore.java": [
                1,
                1
            ]
        }
    },
    "46a3458add4df4a325d804c37f60f8866041fb4d": {
        "datetime": "2012-10-31T16:37:34-07:00",
        "summary": "first pass at adding compression",
        "message": "first pass at adding compression\n",
        "diff": {
            "redelm-pig/src/main/java/redelm/pig/RedelmFileReader.java": [
                2,
                31
            ],
            "redelm-pig/src/main/java/redelm/pig/RedelmFileWriter.java": [
                5,
                53
            ]
        }
    },
    "4bfca1f14f549a6b116d25fd7aadf257b746296e": {
        "datetime": "2012-11-01T16:47:08-07:00",
        "summary": "make Codec configurable",
        "message": "make Codec configurable\n",
        "diff": {
            "redelm-column/src/main/java/redelm/column/primitive/SimplePrimitiveColumnReader.java": [
                1,
                13
            ],
            "redelm-column/src/main/java/redelm/column/primitive/SimplePrimitiveColumnWriter.java": [
                1,
                7
            ],
            "redelm-pig/src/main/java/redelm/pig/Footer.java": [
                2,
                9
            ],
            "redelm-pig/src/main/java/redelm/pig/RedelmFileReader.java": [
                3,
                2
            ],
            "redelm-pig/src/main/java/redelm/pig/RedelmFileWriter.java": [
                4,
                5
            ],
            "redelm-pig/src/main/java/redelm/pig/RedelmInputFormat.java": [
                2,
                3
            ],
            "redelm-pig/src/main/java/redelm/pig/RedelmInputSplit.java": [
                3,
                10
            ],
            "redelm-pig/src/main/java/redelm/pig/RedelmOutputFormat.java": [
                2,
                4
            ],
            "redelm-pig/src/main/java/redelm/pig/RedelmStorer.java": [
                1,
                11
            ],
            "redelm-pig/src/test/java/redelm/pig/TestRedelmFileWriter.java": [
                3,
                6
            ]
        }
    },
    "1a0284da7ab5fb84644d4066b376bec6f3f582bc": {
        "datetime": "2012-11-01T16:57:16-07:00",
        "summary": "fix empty string bug",
        "message": "fix empty string bug\n",
        "diff": {
            "redelm-column/src/main/java/redelm/column/primitive/SimplePrimitiveColumnReader.java": [
                10,
                14
            ]
        }
    },
    "94781b0e7b3c0e7d8c3e1b642f1fe6cc45fe9628": {
        "datetime": "2012-11-02T16:06:08-07:00",
        "summary": "VarInt for String length",
        "message": "VarInt for String length\n",
        "diff": {
            "redelm-column/src/main/java/redelm/column/primitive/SimplePrimitiveColumnReader.java": [
                1,
                12
            ],
            "redelm-column/src/main/java/redelm/column/primitive/SimplePrimitiveColumnWriter.java": [
                1,
                8
            ]
        }
    },
    "1d40ac2d53558a5306b9fb9425db70dd4c3e6313": {
        "datetime": "2012-11-02T17:28:07-07:00",
        "summary": "add javadoc",
        "message": "add javadoc\n",
        "diff": {
            "redelm-column/src/main/java/redelm/io/RecordConsumer.java": [
                0,
                93
            ]
        }
    },
    "c2ed3ee089da179c16fc49be0078f564a81d973d": {
        "datetime": "2012-11-05T14:44:12-08:00",
        "summary": "work",
        "message": "work\n",
        "diff": {
            "redelm-column/src/main/java/redelm/parser/RedelmParser.java": [
                135,
                0
            ],
            "redelm-column/src/main/java/redelm/schema/GroupType.java": [
                34,
                34
            ],
            "redelm-column/src/main/java/redelm/schema/MessageType.java": [
                7,
                7
            ],
            "redelm-column/src/main/java/redelm/schema/PrimitiveType.java": [
                16,
                24
            ],
            "redelm-column/src/main/java/redelm/schema/Type.java": [
                2,
                2
            ],
            "redelm-column/src/test/java/redelm/parser/TestRedelmParser.java": [
                4,
                4
            ],
            "redelm-column/src/test/java/redelm/schema/TestMessageType.java": [
                2,
                2
            ],
            "redelm-pig/pom.xml": null,
            "redelm-pig/src/main/java/redelm/pig/RedelmInputFormat.java": [
                3,
                3
            ],
            "redelm-pig/src/test/java/redelm/pig/TestPigSchemaConverter.java": [
                2,
                2
            ],
            "redelm-pig/src/test/java/redelm/pig/TestRedelmFileWriter.java": [
                2,
                2
            ]
        }
    },
    "3b447a60e1ba41f06d469dc24979479619bd3d7e": {
        "datetime": "2012-11-06T11:53:27-08:00",
        "summary": "Merge pull request #8 from julienledem/add_column_compression",
        "message": "Merge pull request #8 from julienledem/add_column_compression\n\nfirst pass at adding compression",
        "diff": {
            "redelm-column/src/main/java/redelm/column/primitive/SimplePrimitiveColumnReader.java": [
                1,
                28
            ],
            "redelm-column/src/main/java/redelm/column/primitive/SimplePrimitiveColumnWriter.java": [
                1,
                14
            ],
            "redelm-column/src/main/java/redelm/io/RecordConsumer.java": [
                0,
                93
            ],
            "redelm-pig/src/main/java/redelm/pig/Footer.java": [
                2,
                9
            ],
            "redelm-pig/src/main/java/redelm/pig/RedelmFileReader.java": [
                3,
                31
            ],
            "redelm-pig/src/main/java/redelm/pig/RedelmFileWriter.java": [
                7,
                56
            ],
            "redelm-pig/src/main/java/redelm/pig/RedelmInputFormat.java": [
                2,
                3
            ],
            "redelm-pig/src/main/java/redelm/pig/RedelmInputSplit.java": [
                3,
                10
            ],
            "redelm-pig/src/main/java/redelm/pig/RedelmOutputFormat.java": [
                2,
                4
            ],
            "redelm-pig/src/main/java/redelm/pig/RedelmStorer.java": [
                1,
                11
            ],
            "redelm-pig/src/test/java/redelm/pig/TestRedelmFileWriter.java": [
                3,
                6
            ]
        }
    },
    "32bb525182f3e847ad9714d10f5788b214d7e9bd": {
        "datetime": "2012-11-06T12:05:00-08:00",
        "summary": "work",
        "message": "work\n",
        "diff": {
            "redelm-column/src/main/java/redelm/parser/MessageTypeParser.java": [
                0,
                92
            ]
        }
    },
    "94c10a25b4a72de745b314e6f5655de53f5be6cf": {
        "datetime": "2012-11-06T15:11:07-08:00",
        "summary": "Merge branch 'hack_week_jco' of https://github.com/jcoveney/redelm",
        "message": "Merge branch 'hack_week_jco' of https://github.com/jcoveney/redelm\n\nFixed Conflicts:\n\tredelm-column/src/main/java/redelm/io/RecordConsumer.java\n\tredelm-pig/src/test/java/redelm/pig/TestRedelmFileWriter.java\n",
        "diff": {
            "redelm-column/pom.xml": null,
            "redelm-column/src/main/java/redelm/column/ColumnReader.java": [
                3,
                3
            ],
            "redelm-column/src/main/java/redelm/column/mem/MemColumn.java": [
                3,
                3
            ],
            "redelm-column/src/main/java/redelm/column/mem/MemColumnReader.java": [
                4,
                3
            ],
            "redelm-column/src/main/java/redelm/column/mem/MemColumnsStore.java": [
                1,
                1
            ],
            "redelm-column/src/main/java/redelm/data/GroupRecordConsumer.java": [
                1,
                1
            ],
            "redelm-column/src/main/java/redelm/data/GroupValueSource.java": [
                6,
                6
            ],
            "redelm-column/src/main/java/redelm/data/simple/BoolValue.java": [
                3,
                3
            ],
            "redelm-column/src/main/java/redelm/data/simple/IntValue.java": [
                4,
                4
            ],
            "redelm-column/src/main/java/redelm/data/simple/Primitive.java": [
                2,
                2
            ],
            "redelm-column/src/main/java/redelm/data/simple/SimpleGroup.java": [
                6,
                6
            ],
            "redelm-column/src/main/java/redelm/io/MessageColumnIO.java": [
                1,
                1
            ],
            "redelm-column/src/main/java/redelm/io/RecordConsumer.java": [
                1,
                1
            ],
            "redelm-column/src/main/java/redelm/io/RecordConsumerWrapper.java": [
                2,
                2
            ],
            "redelm-column/src/main/java/redelm/io/ValidatingRecordConsumer.java": [
                3,
                3
            ],
            "redelm-column/src/main/java/redelm/parser/MessageTypeParser.java": [
                0,
                100
            ],
            "redelm-column/src/main/java/redelm/schema/GroupType.java": [
                11,
                42
            ],
            "redelm-column/src/main/java/redelm/schema/MessageType.java": [
                69,
                7
            ],
            "redelm-column/src/main/java/redelm/schema/PrimitiveType.java": [
                18,
                46
            ],
            "redelm-column/src/main/java/redelm/schema/Type.java": [
                4,
                20
            ],
            "redelm-column/src/test/java/redelm/io/PerfTest.java": [
                2,
                6
            ],
            "redelm-column/src/test/java/redelm/io/TestColumnIO.java": [
                20,
                23
            ],
            "redelm-column/src/test/java/redelm/parser/TestRedelmParser.java": [
                0,
                76
            ],
            "redelm-column/src/test/java/redelm/schema/TestMessageType.java": [
                5,
                8
            ],
            "redelm-pig/pom.xml": null,
            "redelm-pig/src/main/java/redelm/pig/PigSchemaConverter.java": [
                3,
                3
            ],
            "redelm-pig/src/main/java/redelm/pig/RedelmInputFormat.java": [
                10,
                10
            ],
            "redelm-pig/src/main/java/redelm/pig/TupleRecordConsumer.java": [
                1,
                1
            ],
            "redelm-pig/src/main/java/redelm/pig/TupleWriter.java": [
                2,
                2
            ],
            "redelm-pig/src/test/java/redelm/pig/PerfTest.java": [
                3,
                3
            ],
            "redelm-pig/src/test/java/redelm/pig/PerfTest2.java": [
                4,
                3
            ],
            "redelm-pig/src/test/java/redelm/pig/TestPigSchemaConverter.java": [
                11,
                14
            ],
            "redelm-pig/src/test/java/redelm/pig/TestRedelmFileWriter.java": [
                22,
                25
            ],
            "redelm-pig/src/test/java/redelm/pig/TestRedelmStorer.java": [
                22,
                37
            ],
            "redelm-pig/src/test/java/redelm/pig/TestTupleRecordConsumer.java": [
                4,
                8
            ],
            "redelm-pig/src/test/java/redelm/pig/summary/TestSummary.java": [
                12,
                8
            ]
        }
    },
    "33525b8c798ececedcf394a265e0bc7250f54706": {
        "datetime": "2012-11-06T15:13:40-08:00",
        "summary": "add JCO",
        "message": "add JCO\n",
        "diff": {
            "README.md": null
        }
    },
    "fd5bd4a8734b9b7bb1ab983ad1d3e61b87069b93": {
        "datetime": "2012-11-07T14:44:32-08:00",
        "summary": "record uncompressed size in footer; add detailed report of size and compression per column",
        "message": "record uncompressed size in footer; add detailed report of size and compression per column\n",
        "diff": {
            "redelm-pig/src/main/java/redelm/pig/ColumnMetaData.java": [
                6,
                36
            ],
            "redelm-pig/src/main/java/redelm/pig/PrintFooter.java": [
                6,
                183
            ],
            "redelm-pig/src/main/java/redelm/pig/RedelmFileReader.java": [
                3,
                4
            ],
            "redelm-pig/src/main/java/redelm/pig/RedelmFileWriter.java": [
                0,
                7
            ],
            "redelm-pig/src/main/java/redelm/pig/RedelmInputFormat.java": [
                2,
                2
            ],
            "redelm-pig/src/test/java/redelm/pig/TestRedelmFileWriter.java": [
                0,
                1
            ]
        }
    },
    "3b8ad08b3c0b40221096f5db00e2b1524dbf9315": {
        "datetime": "2012-11-08T08:16:26-08:00",
        "summary": "cleanup logs",
        "message": "cleanup logs\n",
        "diff": {
            "redelm-pig/src/main/java/redelm/pig/RedelmFileReader.java": [
                2,
                2
            ],
            "redelm-pig/src/main/java/redelm/pig/RedelmInputFormat.java": [
                5,
                2
            ]
        }
    },
    "df97795af630d28c0d884dc21d40a731e9e20d00": {
        "datetime": "2012-11-09T09:51:55-08:00",
        "summary": "javadoc",
        "message": "javadoc\n",
        "diff": {
            "redelm-column/src/main/java/redelm/data/simple/example/Paper.java": [
                0,
                6
            ],
            "redelm-column/src/main/java/redelm/io/RecordConsumerWrapper.java": [
                0,
                50
            ],
            "redelm-column/src/main/java/redelm/io/RecordReader.java": [
                0,
                14
            ],
            "redelm-column/src/main/java/redelm/io/ValidatingRecordConsumer.java": [
                0,
                51
            ],
            "redelm-column/src/main/java/redelm/parser/MessageTypeParser.java": [
                0,
                12
            ],
            "redelm-column/src/main/java/redelm/schema/GroupType.java": [
                11,
                64
            ],
            "redelm-column/src/main/java/redelm/schema/MessageType.java": [
                0,
                18
            ],
            "redelm-column/src/main/java/redelm/schema/PrimitiveType.java": [
                0,
                47
            ],
            "redelm-column/src/main/java/redelm/schema/Type.java": [
                0,
                19
            ],
            "redelm-column/src/main/java/redelm/schema/TypeVisitor.java": [
                0,
                21
            ],
            "redelm-pig/src/main/java/redelm/pig/PigSchemaConverter.java": [
                0,
                17
            ],
            "redelm-pig/src/main/java/redelm/pig/summary/Summary.java": [
                1,
                1
            ]
        }
    },
    "e2e3eeb5c02895d5737556bf96c775e86b740a41": {
        "datetime": "2012-11-12T09:54:41-08:00",
        "summary": "first stab a decoupling the Input/OutputFormat from Pig",
        "message": "first stab a decoupling the Input/OutputFormat from Pig\n",
        "diff": {
            "redelm-pig/src/main/java/redelm/pig/Footer.java": [
                9,
                21
            ],
            "redelm-pig/src/main/java/redelm/pig/MetaDataBlock.java": [
                0,
                22
            ],
            "redelm-pig/src/main/java/redelm/pig/PigMetaData.java": [
                0,
                89
            ],
            "redelm-pig/src/main/java/redelm/pig/PrintFooter.java": [
                1,
                1
            ],
            "redelm-pig/src/main/java/redelm/pig/ReadSupport.java": [
                0,
                14
            ],
            "redelm-pig/src/main/java/redelm/pig/RedelmFileReader.java": [
                7,
                15
            ],
            "redelm-pig/src/main/java/redelm/pig/RedelmFileWriter.java": [
                7,
                17
            ],
            "redelm-pig/src/main/java/redelm/pig/RedelmInputFormat.java": [
                24,
                32
            ],
            "redelm-pig/src/main/java/redelm/pig/RedelmLoader.java": [
                3,
                4
            ],
            "redelm-pig/src/main/java/redelm/pig/RedelmOutputFormat.java": [
                12,
                20
            ],
            "redelm-pig/src/main/java/redelm/pig/RedelmStorer.java": [
                1,
                1
            ],
            "redelm-pig/src/main/java/redelm/pig/TupleReadSupport.java": [
                0,
                34
            ],
            "redelm-pig/src/main/java/redelm/pig/TupleWriter.java": [
                8,
                12
            ],
            "redelm-pig/src/main/java/redelm/pig/WriteSupport.java": [
                0,
                12
            ],
            "redelm-pig/src/test/java/redelm/pig/TestRedelmFileWriter.java": [
                3,
                4
            ],
            "redelm-pig/src/test/java/redelm/pig/TestTupleRecordConsumer.java": [
                2,
                4
            ]
        }
    },
    "76ded4f933f058c4299384cea192dda0677fa18c": {
        "datetime": "2012-11-13T08:20:31-08:00",
        "summary": "store count of metadatablocks in footer",
        "message": "store count of metadatablocks in footer\n",
        "diff": {
            "redelm-pig/src/main/java/redelm/pig/RedelmFileReader.java": [
                3,
                4
            ],
            "redelm-pig/src/main/java/redelm/pig/RedelmFileWriter.java": [
                0,
                4
            ]
        }
    },
    "f9be51e8f8615d5e1b59c3d025cd8b12365c6bed": {
        "datetime": "2012-11-13T10:45:04-08:00",
        "summary": "Merge pull request #9 from julienledem/javadoc",
        "message": "Merge pull request #9 from julienledem/javadoc\n\njavadoc",
        "diff": {
            "redelm-column/src/main/java/redelm/data/simple/example/Paper.java": [
                0,
                6
            ],
            "redelm-column/src/main/java/redelm/io/RecordConsumerWrapper.java": [
                0,
                50
            ],
            "redelm-column/src/main/java/redelm/io/RecordReader.java": [
                0,
                14
            ],
            "redelm-column/src/main/java/redelm/io/ValidatingRecordConsumer.java": [
                0,
                51
            ],
            "redelm-column/src/main/java/redelm/parser/MessageTypeParser.java": [
                0,
                12
            ],
            "redelm-column/src/main/java/redelm/schema/GroupType.java": [
                11,
                64
            ],
            "redelm-column/src/main/java/redelm/schema/MessageType.java": [
                0,
                18
            ],
            "redelm-column/src/main/java/redelm/schema/PrimitiveType.java": [
                0,
                47
            ],
            "redelm-column/src/main/java/redelm/schema/Type.java": [
                0,
                19
            ],
            "redelm-column/src/main/java/redelm/schema/TypeVisitor.java": [
                0,
                21
            ],
            "redelm-pig/src/main/java/redelm/pig/PigSchemaConverter.java": [
                0,
                17
            ],
            "redelm-pig/src/main/java/redelm/pig/summary/Summary.java": [
                1,
                1
            ]
        }
    },
    "f070939c111b00a6dd7178e4d03935ab58caa562": {
        "datetime": "2012-11-13T10:45:22-08:00",
        "summary": "Merge pull request #10 from julienledem/decoupling_InputOutputFormat_from_Pig",
        "message": "Merge pull request #10 from julienledem/decoupling_InputOutputFormat_from_Pig\n\nfirst stab a decoupling the Input/OutputFormat from Pig",
        "diff": {
            "redelm-pig/src/main/java/redelm/pig/Footer.java": [
                9,
                21
            ],
            "redelm-pig/src/main/java/redelm/pig/MetaDataBlock.java": [
                0,
                22
            ],
            "redelm-pig/src/main/java/redelm/pig/PigMetaData.java": [
                0,
                89
            ],
            "redelm-pig/src/main/java/redelm/pig/PrintFooter.java": [
                1,
                1
            ],
            "redelm-pig/src/main/java/redelm/pig/ReadSupport.java": [
                0,
                14
            ],
            "redelm-pig/src/main/java/redelm/pig/RedelmFileReader.java": [
                7,
                16
            ],
            "redelm-pig/src/main/java/redelm/pig/RedelmFileWriter.java": [
                7,
                21
            ],
            "redelm-pig/src/main/java/redelm/pig/RedelmInputFormat.java": [
                24,
                32
            ],
            "redelm-pig/src/main/java/redelm/pig/RedelmLoader.java": [
                3,
                4
            ],
            "redelm-pig/src/main/java/redelm/pig/RedelmOutputFormat.java": [
                12,
                20
            ],
            "redelm-pig/src/main/java/redelm/pig/RedelmStorer.java": [
                1,
                1
            ],
            "redelm-pig/src/main/java/redelm/pig/TupleReadSupport.java": [
                0,
                34
            ],
            "redelm-pig/src/main/java/redelm/pig/TupleWriter.java": [
                8,
                12
            ],
            "redelm-pig/src/main/java/redelm/pig/WriteSupport.java": [
                0,
                12
            ],
            "redelm-pig/src/test/java/redelm/pig/TestRedelmFileWriter.java": [
                3,
                4
            ],
            "redelm-pig/src/test/java/redelm/pig/TestTupleRecordConsumer.java": [
                2,
                4
            ]
        }
    },
    "130e213b8bec04b7691e100450a5bc1d7be169f2": {
        "datetime": "2012-11-13T18:08:52-08:00",
        "summary": "better hadoop layer decoupling",
        "message": "better hadoop layer decoupling\n",
        "diff": {
            "redelm-pig/src/main/java/redelm/hadoop/ReadSupport.java": [
                0,
                15
            ],
            "redelm-pig/src/main/java/redelm/hadoop/RedelmInputFormat.java": [
                0,
                109
            ],
            "redelm-pig/src/main/java/redelm/hadoop/RedelmRecordReader.java": [
                0,
                145
            ],
            "redelm-pig/src/main/java/redelm/pig/BlockData.java": [
                1,
                1
            ],
            "redelm-pig/src/main/java/redelm/pig/BlockMetaData.java": [
                1,
                1
            ],
            "redelm-pig/src/main/java/redelm/pig/ColumnData.java": [
                1,
                1
            ],
            "redelm-pig/src/main/java/redelm/pig/ColumnMetaData.java": [
                1,
                1
            ],
            "redelm-pig/src/main/java/redelm/pig/Footer.java": [
                24,
                39
            ],
            "redelm-pig/src/main/java/redelm/pig/MetaDataBlock.java": [
                1,
                1
            ],
            "redelm-pig/src/main/java/redelm/pig/PigMetaData.java": [
                1,
                2
            ],
            "redelm-pig/src/main/java/redelm/pig/PrintFooter.java": [
                7,
                7
            ],
            "redelm-pig/src/main/java/redelm/pig/ReadSupport.java": [
                14,
                0
            ],
            "redelm-pig/src/main/java/redelm/pig/RedelmFileReader.java": [
                4,
                4
            ],
            "redelm-pig/src/main/java/redelm/pig/RedelmFileWriter.java": [
                2,
                2
            ],
            "redelm-pig/src/main/java/redelm/pig/RedelmInputFormat.java": [
                227,
                0
            ],
            "redelm-pig/src/main/java/redelm/pig/RedelmInputSplit.java": [
                35,
                26
            ],
            "redelm-pig/src/main/java/redelm/pig/RedelmLoader.java": [
                0,
                2
            ],
            "redelm-pig/src/main/java/redelm/pig/RedelmOutputFormat.java": [
                7,
                8
            ],
            "redelm-pig/src/main/java/redelm/pig/RedelmStorer.java": [
                5,
                10
            ],
            "redelm-pig/src/main/java/redelm/pig/TupleReadSupport.java": [
                9,
                15
            ],
            "redelm-pig/src/main/java/redelm/pig/TupleRecordConsumer.java": [
                0,
                7
            ],
            "redelm-pig/src/main/java/redelm/pig/TupleWriteSupport.java": [
                0,
                2
            ],
            "redelm-pig/src/main/java/redelm/pig/WriteSupport.java": [
                1,
                1
            ],
            "redelm-pig/src/main/java/redelm/pig/summary/BagSummaryData.java": [
                3,
                1
            ],
            "redelm-pig/src/main/java/redelm/pig/summary/FieldSummaryData.java": [
                1,
                1
            ],
            "redelm-pig/src/main/java/redelm/pig/summary/MapSummaryData.java": [
                2,
                1
            ],
            "redelm-pig/src/main/java/redelm/pig/summary/NumberSummaryData.java": [
                1,
                1
            ],
            "redelm-pig/src/main/java/redelm/pig/summary/StringSummaryData.java": [
                1,
                1
            ],
            "redelm-pig/src/main/java/redelm/pig/summary/SummaryData.java": [
                1,
                1
            ],
            "redelm-pig/src/main/java/redelm/pig/summary/TupleSummaryData.java": [
                2,
                1
            ],
            "redelm-pig/src/test/java/redelm/pig/PerfTest2.java": [
                7,
                9
            ],
            "redelm-pig/src/test/java/redelm/pig/TestRedelmFileWriter.java": [
                1,
                8
            ],
            "redelm-pig/src/test/java/redelm/pig/TestTupleRecordConsumer.java": [
                4,
                0
            ],
            "redelm-pig/src/test/java/redelm/pig/summary/TestSummary.java": [
                1,
                1
            ]
        }
    },
    "4fb9a480910ab56af1de975e2b48aa4dd0431866": {
        "datetime": "2012-11-14T10:48:30-08:00",
        "summary": "moved hadoop implementation into its own hadoop package without dependencies on pig packages",
        "message": "moved hadoop implementation into its own hadoop package without dependencies on pig packages\n",
        "diff": {
            "redelm-pig/src/main/java/redelm/hadoop/BlockData.java": [
                1,
                15
            ],
            "redelm-pig/src/main/java/redelm/hadoop/BlockMetaData.java": [
                0,
                38
            ],
            "redelm-pig/src/main/java/redelm/hadoop/ColumnData.java": [
                0,
                29
            ],
            "redelm-pig/src/main/java/redelm/hadoop/ColumnMetaData.java": [
                4,
                113
            ],
            "redelm-pig/src/main/java/redelm/hadoop/MetaDataBlock.java": [
                1,
                19
            ],
            "redelm-pig/src/main/java/redelm/hadoop/PrintFooter.java": [
                6,
                11
            ],
            "redelm-pig/src/main/java/redelm/hadoop/ReadSupport.java": [
                0,
                20
            ],
            "redelm-pig/src/main/java/redelm/hadoop/RedElmMetaData.java": [
                9,
                55
            ],
            "redelm-pig/src/main/java/redelm/hadoop/RedelmFileReader.java": [
                0,
                25
            ],
            "redelm-pig/src/main/java/redelm/hadoop/RedelmFileWriter.java": [
                2,
                59
            ],
            "redelm-pig/src/main/java/redelm/hadoop/RedelmInputFormat.java": [
                4,
                28
            ],
            "redelm-pig/src/main/java/redelm/hadoop/RedelmInputSplit.java": [
                2,
                55
            ],
            "redelm-pig/src/main/java/redelm/hadoop/RedelmOutputFormat.java": [
                71,
                33
            ],
            "redelm-pig/src/main/java/redelm/hadoop/RedelmRecordReader.java": [
                2,
                33
            ],
            "redelm-pig/src/main/java/redelm/hadoop/RedelmRecordWriter.java": [
                0,
                110
            ],
            "redelm-pig/src/main/java/redelm/hadoop/WriteSupport.java": [
                1,
                19
            ],
            "redelm-pig/src/main/java/redelm/pig/TupleRecordConsumer.java": [
                0,
                9
            ],
            "redelm-pig/src/main/java/redelm/pig/TupleWriteSupport.java": [
                1,
                2
            ],
            "redelm-pig/src/test/java/redelm/pig/PerfTest.java": [
                0,
                7
            ],
            "redelm-pig/src/test/java/redelm/pig/PerfTest2.java": [
                2,
                12
            ],
            "redelm-pig/src/test/java/redelm/pig/TestRedelmFileWriter.java": [
                3,
                3
            ],
            "redelm-pig/src/test/java/redelm/pig/TestTupleRecordConsumer.java": [
                2,
                5
            ]
        }
    },
    "fe6066bd2defd83af96c6416e1d06273278e1b6c": {
        "datetime": "2012-11-15T10:43:56-08:00",
        "summary": "get the compression codec from Configuration properties",
        "message": "get the compression codec from Configuration properties\n",
        "diff": {
            "redelm-pig/src/main/java/redelm/hadoop/RedelmFileReader.java": [
                16,
                26
            ],
            "redelm-pig/src/main/java/redelm/hadoop/RedelmFileWriter.java": [
                20,
                26
            ],
            "redelm-pig/src/main/java/redelm/hadoop/RedelmOutputFormat.java": [
                5,
                19
            ],
            "redelm-pig/src/main/java/redelm/pig/RedelmStorer.java": [
                10,
                1
            ],
            "redelm-pig/src/test/java/redelm/hadoop/TestRedelmFileWriter.java": [
                1,
                2
            ],
            "redelm-pig/src/test/java/redelm/pig/PerfTest2.java": [
                0,
                10
            ]
        }
    },
    "b507f7dd6f56971f3ba6cbfab786a255e47451c1": {
        "datetime": "2012-11-15T11:56:05-08:00",
        "summary": "make block size configurable",
        "message": "make block size configurable\n",
        "diff": {
            "redelm-pig/src/main/java/redelm/hadoop/RedelmOutputFormat.java": [
                5,
                20
            ],
            "redelm-pig/src/main/java/redelm/hadoop/RedelmRecordWriter.java": [
                2,
                5
            ]
        }
    },
    "5271080cd7c045a0693e5358bdc90d4f34cddd6f": {
        "datetime": "2012-11-15T13:42:53-08:00",
        "summary": "Merge pull request #11 from julienledem/move_hadoop_stuff_into_hadoop_package",
        "message": "Merge pull request #11 from julienledem/move_hadoop_stuff_into_hadoop_package\n\nMove hadoop stuff into hadoop package\r\nreviewed by jcoveney",
        "diff": {
            "redelm-pig/src/main/java/redelm/hadoop/MetaDataBlock.java": [
                0,
                40
            ],
            "redelm-pig/src/main/java/redelm/hadoop/ReadSupport.java": [
                0,
                35
            ],
            "redelm-pig/src/main/java/redelm/hadoop/RedelmInputFormat.java": [
                0,
                133
            ],
            "redelm-pig/src/main/java/redelm/hadoop/RedelmOutputFormat.java": [
                0,
                117
            ],
            "redelm-pig/src/main/java/redelm/hadoop/RedelmRecordReader.java": [
                0,
                176
            ],
            "redelm-pig/src/main/java/redelm/hadoop/RedelmRecordWriter.java": [
                0,
                113
            ],
            "redelm-pig/src/main/java/redelm/hadoop/WriteSupport.java": [
                0,
                30
            ],
            "redelm-pig/src/main/java/redelm/pig/BlockData.java": [
                2,
                16
            ],
            "redelm-pig/src/main/java/redelm/pig/BlockMetaData.java": [
                1,
                39
            ],
            "redelm-pig/src/main/java/redelm/pig/ColumnData.java": [
                1,
                30
            ],
            "redelm-pig/src/main/java/redelm/pig/ColumnMetaData.java": [
                5,
                114
            ],
            "redelm-pig/src/main/java/redelm/pig/Footer.java": [
                24,
                85
            ],
            "redelm-pig/src/main/java/redelm/pig/MetaDataBlock.java": [
                22,
                0
            ],
            "redelm-pig/src/main/java/redelm/pig/PigMetaData.java": [
                1,
                2
            ],
            "redelm-pig/src/main/java/redelm/pig/PrintFooter.java": [
                7,
                12
            ],
            "redelm-pig/src/main/java/redelm/pig/ReadSupport.java": [
                14,
                0
            ],
            "redelm-pig/src/main/java/redelm/pig/RedelmFileReader.java": [
                20,
                55
            ],
            "redelm-pig/src/main/java/redelm/pig/RedelmFileWriter.java": [
                23,
                86
            ],
            "redelm-pig/src/main/java/redelm/pig/RedelmInputFormat.java": [
                227,
                0
            ],
            "redelm-pig/src/main/java/redelm/pig/RedelmInputSplit.java": [
                35,
                79
            ],
            "redelm-pig/src/main/java/redelm/pig/RedelmLoader.java": [
                0,
                2
            ],
            "redelm-pig/src/main/java/redelm/pig/RedelmOutputFormat.java": [
                125,
                0
            ],
            "redelm-pig/src/main/java/redelm/pig/RedelmStorer.java": [
                13,
                9
            ],
            "redelm-pig/src/main/java/redelm/pig/TupleReadSupport.java": [
                9,
                15
            ],
            "redelm-pig/src/main/java/redelm/pig/TupleRecordConsumer.java": [
                0,
                16
            ],
            "redelm-pig/src/main/java/redelm/pig/TupleWriteSupport.java": [
                1,
                4
            ],
            "redelm-pig/src/main/java/redelm/pig/WriteSupport.java": [
                12,
                0
            ],
            "redelm-pig/src/main/java/redelm/pig/summary/BagSummaryData.java": [
                3,
                1
            ],
            "redelm-pig/src/main/java/redelm/pig/summary/FieldSummaryData.java": [
                1,
                1
            ],
            "redelm-pig/src/main/java/redelm/pig/summary/MapSummaryData.java": [
                2,
                1
            ],
            "redelm-pig/src/main/java/redelm/pig/summary/NumberSummaryData.java": [
                1,
                1
            ],
            "redelm-pig/src/main/java/redelm/pig/summary/StringSummaryData.java": [
                1,
                1
            ],
            "redelm-pig/src/main/java/redelm/pig/summary/SummaryData.java": [
                1,
                1
            ],
            "redelm-pig/src/main/java/redelm/pig/summary/TupleSummaryData.java": [
                2,
                1
            ],
            "redelm-pig/src/test/java/redelm/pig/PerfTest.java": [
                0,
                7
            ],
            "redelm-pig/src/test/java/redelm/pig/PerfTest2.java": [
                9,
                31
            ],
            "redelm-pig/src/test/java/redelm/pig/TestRedelmFileWriter.java": [
                3,
                11
            ],
            "redelm-pig/src/test/java/redelm/pig/TestTupleRecordConsumer.java": [
                5,
                4
            ],
            "redelm-pig/src/test/java/redelm/pig/summary/TestSummary.java": [
                1,
                1
            ]
        }
    },
    "1243fcc58e31131e6b13491f9fa1d126d6422e6b": {
        "datetime": "2012-11-15T15:58:51-08:00",
        "summary": "add status header",
        "message": "add status header\n",
        "diff": {
            "redelm-column/src/main/java/redelm/RedelmRuntimeException.java": [
                0,
                15
            ],
            "redelm-column/src/main/java/redelm/io/InvalidRecordException.java": [
                0,
                15
            ],
            "redelm-column/src/main/java/redelm/io/ValidatingRecordConsumer.java": [
                0,
                15
            ],
            "redelm-pig/src/main/java/redelm/hadoop/MetaDataBlock.java": [
                0,
                15
            ],
            "redelm-pig/src/main/java/redelm/hadoop/ReadSupport.java": [
                0,
                15
            ],
            "redelm-pig/src/main/java/redelm/hadoop/RedelmRecordReader.java": [
                0,
                15
            ],
            "redelm-pig/src/main/java/redelm/hadoop/RedelmRecordWriter.java": [
                0,
                15
            ],
            "redelm-pig/src/main/java/redelm/hadoop/WriteSupport.java": [
                0,
                15
            ],
            "redelm-pig/src/main/java/redelm/pig/PigMetaData.java": [
                0,
                15
            ],
            "redelm-pig/src/main/java/redelm/pig/TupleReadSupport.java": [
                0,
                15
            ]
        }
    },
    "06ab2ed602ab7172a7dd55b35830b785ba737eca": {
        "datetime": "2012-11-18T15:57:42-08:00",
        "summary": "implement empty bag != null bag",
        "message": "implement empty bag != null bag\n",
        "diff": {
            "redelm-column/src/main/java/redelm/Log.java": [
                0,
                4
            ],
            "redelm-pig/src/main/java/redelm/pig/PigSchemaConverter.java": [
                34,
                60
            ],
            "redelm-pig/src/main/java/redelm/pig/TupleRecordConsumer.java": [
                38,
                54
            ],
            "redelm-pig/src/main/java/redelm/pig/TupleWriteSupport.java": [
                51,
                78
            ],
            "redelm-pig/src/test/java/redelm/pig/TestPigSchemaConverter.java": [
                13,
                62
            ],
            "redelm-pig/src/test/java/redelm/pig/TestTupleRecordConsumer.java": [
                46,
                123
            ]
        }
    },
    "fbf8333a47d71e054db84334d18747f565ff9731": {
        "datetime": "2012-11-18T16:02:53-08:00",
        "summary": "cleanup unnecessary variables",
        "message": "cleanup unnecessary variables\n",
        "diff": {
            "redelm-pig/src/main/java/redelm/pig/TupleRecordConsumer.java": [
                4,
                1
            ]
        }
    },
    "87744511868c1c68c4ac6468f9eda84bd319d37a": {
        "datetime": "2012-11-19T09:40:04-08:00",
        "summary": "first stab at pregenerated Pig consumer",
        "message": "first stab at pregenerated Pig consumer\n",
        "diff": {
            "redelm-pig/src/main/java/redelm/pig/TupleReadSupport.java": [
                1,
                17
            ],
            "redelm-pig/src/main/java/redelm/pig/converter/BagConverter.java": [
                0,
                53
            ],
            "redelm-pig/src/main/java/redelm/pig/converter/Converter.java": [
                0,
                27
            ],
            "redelm-pig/src/main/java/redelm/pig/converter/MapConverter.java": [
                0,
                53
            ],
            "redelm-pig/src/main/java/redelm/pig/converter/MessageConverter.java": [
                0,
                93
            ],
            "redelm-pig/src/main/java/redelm/pig/converter/TupleConverter.java": [
                0,
                69
            ]
        }
    },
    "0094892b0c7b8466afb50f4296309a83449fb359": {
        "datetime": "2012-11-19T09:46:02-08:00",
        "summary": "use non spillable databag for records",
        "message": "use non spillable databag for records\n",
        "diff": {
            "redelm-pig/src/main/java/redelm/pig/TupleRecordConsumer.java": [
                2,
                8
            ]
        }
    },
    "27c02555d97e41eb635b2441da69a36b940730b4": {
        "datetime": "2012-11-20T09:02:19-08:00",
        "summary": "make Map work",
        "message": "make Map work\n",
        "diff": {
            "redelm-pig/src/main/java/redelm/pig/TupleReadSupport.java": [
                5,
                16
            ],
            "redelm-pig/src/main/java/redelm/pig/converter/BagConverter.java": [
                11,
                13
            ],
            "redelm-pig/src/main/java/redelm/pig/converter/Converter.java": [
                1,
                8
            ],
            "redelm-pig/src/main/java/redelm/pig/converter/MapConverter.java": [
                19,
                23
            ],
            "redelm-pig/src/main/java/redelm/pig/converter/MapKeyValueConverter.java": [
                0,
                63
            ],
            "redelm-pig/src/main/java/redelm/pig/converter/MessageConverter.java": [
                17,
                23
            ],
            "redelm-pig/src/main/java/redelm/pig/converter/TupleConverter.java": [
                11,
                31
            ],
            "redelm-pig/src/test/java/redelm/pig/TestTupleRecordConsumer.java": [
                8,
                13
            ]
        }
    },
    "ffe80dde0f3eb13cc40ec5c3efbe6ee8cb556b84": {
        "datetime": "2012-11-20T09:46:47-08:00",
        "summary": "add summary file",
        "message": "add summary file\n",
        "diff": {
            "redelm-column/src/main/java/redelm/RedelmRuntimeException.java": [
                0,
                15
            ],
            "redelm-column/src/main/java/redelm/io/InvalidRecordException.java": [
                0,
                15
            ],
            "redelm-column/src/main/java/redelm/io/ValidatingRecordConsumer.java": [
                0,
                15
            ],
            "redelm-pig/src/main/java/redelm/hadoop/Footer.java": [
                0,
                50
            ],
            "redelm-pig/src/main/java/redelm/hadoop/MetaDataBlock.java": [
                0,
                15
            ],
            "redelm-pig/src/main/java/redelm/hadoop/ReadSupport.java": [
                0,
                15
            ],
            "redelm-pig/src/main/java/redelm/hadoop/RedelmFileReader.java": [
                4,
                103
            ],
            "redelm-pig/src/main/java/redelm/hadoop/RedelmFileWriter.java": [
                0,
                20
            ],
            "redelm-pig/src/main/java/redelm/hadoop/RedelmInputFormat.java": [
                7,
                10
            ],
            "redelm-pig/src/main/java/redelm/hadoop/RedelmOutputCommitter.java": [
                0,
                52
            ],
            "redelm-pig/src/main/java/redelm/hadoop/RedelmOutputFormat.java": [
                4,
                17
            ],
            "redelm-pig/src/main/java/redelm/hadoop/RedelmRecordReader.java": [
                2,
                19
            ],
            "redelm-pig/src/main/java/redelm/hadoop/RedelmRecordWriter.java": [
                0,
                15
            ],
            "redelm-pig/src/main/java/redelm/hadoop/WriteSupport.java": [
                0,
                15
            ],
            "redelm-pig/src/main/java/redelm/pig/PigMetaData.java": [
                0,
                15
            ],
            "redelm-pig/src/main/java/redelm/pig/TupleReadSupport.java": [
                0,
                15
            ],
            "redelm-pig/src/test/java/redelm/hadoop/TestRedelmFileWriter.java": [
                3,
                4
            ]
        }
    },
    "88ed7fe5cebbef0dd1cafab50fe72354a73e5e86": {
        "datetime": "2012-11-20T09:54:59-08:00",
        "summary": "Support for short int columns by JCoveney  https://github.com/jcoveney/redelm rep_def_column",
        "message": "Support for short int columns by JCoveney  https://github.com/jcoveney/redelm rep_def_column\nadd pig snapshot\n",
        "diff": {
            "redelm-column/pom.xml": null,
            "redelm-column/src/main/java/redelm/column/BytesOutput.java": [
                6,
                8
            ],
            "redelm-column/src/main/java/redelm/column/ColumnDescriptor.java": [
                1,
                14
            ],
            "redelm-column/src/main/java/redelm/column/ColumnWriter.java": [
                5,
                4
            ],
            "redelm-column/src/main/java/redelm/column/RedelmByteArrayOutputStream.java": [
                3,
                2
            ],
            "redelm-column/src/main/java/redelm/column/mem/MemColumn.java": [
                21,
                23
            ],
            "redelm-column/src/main/java/redelm/column/mem/MemColumnReader.java": [
                6,
                23
            ],
            "redelm-column/src/main/java/redelm/column/mem/MemColumnWriter.java": [
                24,
                25
            ],
            "redelm-column/src/main/java/redelm/column/mem/MemColumnsStore.java": [
                5,
                9
            ],
            "redelm-column/src/main/java/redelm/column/primitive/BitReader.java": [
                0,
                102
            ],
            "redelm-column/src/main/java/redelm/column/primitive/BitWriter.java": [
                0,
                115
            ],
            "redelm-column/src/main/java/redelm/column/primitive/BoundedIntColumnReader.java": [
                0,
                66
            ],
            "redelm-column/src/main/java/redelm/column/primitive/BoundedIntColumnWriter.java": [
                0,
                130
            ],
            "redelm-column/src/main/java/redelm/column/primitive/DevNullColumnReader.java": [
                0,
                98
            ],
            "redelm-column/src/main/java/redelm/column/primitive/DevNullColumnWriter.java": [
                0,
                71
            ],
            "redelm-column/src/main/java/redelm/column/primitive/PrimitiveColumnReader.java": [
                2,
                5
            ],
            "redelm-column/src/main/java/redelm/column/primitive/PrimitiveColumnWriter.java": [
                6,
                3
            ],
            "redelm-column/src/main/java/redelm/column/primitive/SimplePrimitiveColumnReader.java": [
                8,
                7
            ],
            "redelm-column/src/main/java/redelm/column/primitive/SimplePrimitiveColumnWriter.java": [
                3,
                3
            ],
            "redelm-column/src/main/java/redelm/data/GroupWriter.java": [
                2,
                0
            ],
            "redelm-column/src/main/java/redelm/io/MessageColumnIO.java": [
                138,
                139
            ],
            "redelm-column/src/main/java/redelm/io/PrimitiveColumnIO.java": [
                1,
                1
            ],
            "redelm-column/src/main/java/redelm/schema/GroupType.java": [
                0,
                26
            ],
            "redelm-column/src/main/java/redelm/schema/MessageType.java": [
                0,
                22
            ],
            "redelm-column/src/main/java/redelm/schema/PrimitiveType.java": [
                0,
                24
            ],
            "redelm-column/src/main/java/redelm/schema/Type.java": [
                0,
                6
            ],
            "redelm-column/src/main/java/redelm/utils/Varint.java": [
                0,
                167
            ],
            "redelm-column/src/test/java/redelm/column/mem/TestMemColumn.java": [
                14,
                18
            ],
            "redelm-column/src/test/java/redelm/column/primitive/TestBoundedColumns.java": [
                0,
                90
            ],
            "redelm-column/src/test/java/redelm/io/PerfTest.java": [
                1,
                1
            ],
            "redelm-column/src/test/java/redelm/io/TestColumnIO.java": [
                7,
                10
            ],
            "redelm-pig/lib/pig-0.11.0-SNAPSHOT.jar": null,
            "redelm-pig/pom.xml": null,
            "redelm-pig/src/main/java/redelm/hadoop/ColumnData.java": [
                3,
                3
            ],
            "redelm-pig/src/main/java/redelm/hadoop/RedelmFileWriter.java": [
                8,
                5
            ],
            "redelm-pig/src/main/java/redelm/hadoop/RedelmRecordReader.java": [
                8,
                8
            ],
            "redelm-pig/src/main/java/redelm/hadoop/RedelmRecordWriter.java": [
                7,
                18
            ],
            "redelm-pig/src/test/java/redelm/hadoop/TestRedelmFileWriter.java": [
                11,
                2
            ]
        }
    },
    "af992f3673cd06e4353354230f78deb674161322": {
        "datetime": "2012-11-20T10:00:41-08:00",
        "summary": "fixed doc based on jco's comments",
        "message": "fixed doc based on jco's comments\n",
        "diff": {
            "redelm-column/src/main/java/redelm/Log.java": [
                1,
                1
            ],
            "redelm-pig/src/main/java/redelm/pig/PigSchemaConverter.java": [
                1,
                1
            ]
        }
    },
    "4a372bce138cce95a72f9d4b69ae37e434d5e27e": {
        "datetime": "2012-11-20T10:13:45-08:00",
        "summary": "Merge branch 'master' into summary_file",
        "message": "Merge branch 'master' into summary_file\n\nConflicts:\n\tredelm-pig/src/main/java/redelm/hadoop/RedelmFileWriter.java\n\tredelm-pig/src/main/java/redelm/hadoop/RedelmRecordReader.java\n",
        "diff": {
            "redelm-column/pom.xml": null,
            "redelm-column/src/main/java/redelm/column/BytesOutput.java": [
                6,
                8
            ],
            "redelm-column/src/main/java/redelm/column/ColumnDescriptor.java": [
                1,
                14
            ],
            "redelm-column/src/main/java/redelm/column/ColumnWriter.java": [
                5,
                4
            ],
            "redelm-column/src/main/java/redelm/column/RedelmByteArrayOutputStream.java": [
                3,
                2
            ],
            "redelm-column/src/main/java/redelm/column/mem/MemColumn.java": [
                21,
                23
            ],
            "redelm-column/src/main/java/redelm/column/mem/MemColumnReader.java": [
                6,
                23
            ],
            "redelm-column/src/main/java/redelm/column/mem/MemColumnWriter.java": [
                24,
                25
            ],
            "redelm-column/src/main/java/redelm/column/mem/MemColumnsStore.java": [
                5,
                9
            ],
            "redelm-column/src/main/java/redelm/column/primitive/BitReader.java": [
                0,
                102
            ],
            "redelm-column/src/main/java/redelm/column/primitive/BitWriter.java": [
                0,
                115
            ],
            "redelm-column/src/main/java/redelm/column/primitive/BoundedIntColumnReader.java": [
                0,
                66
            ],
            "redelm-column/src/main/java/redelm/column/primitive/BoundedIntColumnWriter.java": [
                0,
                130
            ],
            "redelm-column/src/main/java/redelm/column/primitive/DevNullColumnReader.java": [
                0,
                98
            ],
            "redelm-column/src/main/java/redelm/column/primitive/DevNullColumnWriter.java": [
                0,
                71
            ],
            "redelm-column/src/main/java/redelm/column/primitive/PrimitiveColumnReader.java": [
                2,
                5
            ],
            "redelm-column/src/main/java/redelm/column/primitive/PrimitiveColumnWriter.java": [
                6,
                3
            ],
            "redelm-column/src/main/java/redelm/column/primitive/SimplePrimitiveColumnReader.java": [
                8,
                7
            ],
            "redelm-column/src/main/java/redelm/column/primitive/SimplePrimitiveColumnWriter.java": [
                3,
                3
            ],
            "redelm-column/src/main/java/redelm/data/GroupWriter.java": [
                2,
                0
            ],
            "redelm-column/src/main/java/redelm/io/MessageColumnIO.java": [
                138,
                139
            ],
            "redelm-column/src/main/java/redelm/io/PrimitiveColumnIO.java": [
                1,
                1
            ],
            "redelm-column/src/main/java/redelm/schema/GroupType.java": [
                0,
                26
            ],
            "redelm-column/src/main/java/redelm/schema/MessageType.java": [
                0,
                22
            ],
            "redelm-column/src/main/java/redelm/schema/PrimitiveType.java": [
                0,
                24
            ],
            "redelm-column/src/main/java/redelm/schema/Type.java": [
                0,
                6
            ],
            "redelm-column/src/main/java/redelm/utils/Varint.java": [
                0,
                167
            ],
            "redelm-column/src/test/java/redelm/column/mem/TestMemColumn.java": [
                14,
                18
            ],
            "redelm-column/src/test/java/redelm/column/primitive/TestBoundedColumns.java": [
                0,
                90
            ],
            "redelm-column/src/test/java/redelm/io/PerfTest.java": [
                1,
                1
            ],
            "redelm-column/src/test/java/redelm/io/TestColumnIO.java": [
                7,
                10
            ],
            "redelm-pig/lib/pig-0.11.0-SNAPSHOT.jar": null,
            "redelm-pig/pom.xml": null,
            "redelm-pig/src/main/java/redelm/hadoop/ColumnData.java": [
                3,
                3
            ],
            "redelm-pig/src/main/java/redelm/hadoop/RedelmFileWriter.java": [
                7,
                5
            ],
            "redelm-pig/src/main/java/redelm/hadoop/RedelmRecordReader.java": [
                1,
                1
            ],
            "redelm-pig/src/main/java/redelm/hadoop/RedelmRecordWriter.java": [
                7,
                18
            ],
            "redelm-pig/src/test/java/redelm/hadoop/TestRedelmFileWriter.java": [
                11,
                2
            ]
        }
    },
    "ad3b4596d0b84885f0377a0cd9ea6e8d983b3177": {
        "datetime": "2012-11-20T10:15:21-08:00",
        "summary": "Merge branch 'master' into preprocess_pig_schema",
        "message": "Merge branch 'master' into preprocess_pig_schema\n",
        "diff": {
            "redelm-column/pom.xml": null,
            "redelm-column/src/main/java/redelm/column/BytesOutput.java": [
                6,
                8
            ],
            "redelm-column/src/main/java/redelm/column/ColumnDescriptor.java": [
                1,
                14
            ],
            "redelm-column/src/main/java/redelm/column/ColumnWriter.java": [
                5,
                4
            ],
            "redelm-column/src/main/java/redelm/column/RedelmByteArrayOutputStream.java": [
                3,
                2
            ],
            "redelm-column/src/main/java/redelm/column/mem/MemColumn.java": [
                21,
                23
            ],
            "redelm-column/src/main/java/redelm/column/mem/MemColumnReader.java": [
                6,
                23
            ],
            "redelm-column/src/main/java/redelm/column/mem/MemColumnWriter.java": [
                24,
                25
            ],
            "redelm-column/src/main/java/redelm/column/mem/MemColumnsStore.java": [
                5,
                9
            ],
            "redelm-column/src/main/java/redelm/column/primitive/BitReader.java": [
                0,
                102
            ],
            "redelm-column/src/main/java/redelm/column/primitive/BitWriter.java": [
                0,
                115
            ],
            "redelm-column/src/main/java/redelm/column/primitive/BoundedIntColumnReader.java": [
                0,
                66
            ],
            "redelm-column/src/main/java/redelm/column/primitive/BoundedIntColumnWriter.java": [
                0,
                130
            ],
            "redelm-column/src/main/java/redelm/column/primitive/DevNullColumnReader.java": [
                0,
                98
            ],
            "redelm-column/src/main/java/redelm/column/primitive/DevNullColumnWriter.java": [
                0,
                71
            ],
            "redelm-column/src/main/java/redelm/column/primitive/PrimitiveColumnReader.java": [
                2,
                5
            ],
            "redelm-column/src/main/java/redelm/column/primitive/PrimitiveColumnWriter.java": [
                6,
                3
            ],
            "redelm-column/src/main/java/redelm/column/primitive/SimplePrimitiveColumnReader.java": [
                8,
                7
            ],
            "redelm-column/src/main/java/redelm/column/primitive/SimplePrimitiveColumnWriter.java": [
                3,
                3
            ],
            "redelm-column/src/main/java/redelm/data/GroupWriter.java": [
                2,
                0
            ],
            "redelm-column/src/main/java/redelm/io/MessageColumnIO.java": [
                138,
                139
            ],
            "redelm-column/src/main/java/redelm/io/PrimitiveColumnIO.java": [
                1,
                1
            ],
            "redelm-column/src/main/java/redelm/schema/GroupType.java": [
                0,
                26
            ],
            "redelm-column/src/main/java/redelm/schema/MessageType.java": [
                0,
                22
            ],
            "redelm-column/src/main/java/redelm/schema/PrimitiveType.java": [
                0,
                24
            ],
            "redelm-column/src/main/java/redelm/schema/Type.java": [
                0,
                6
            ],
            "redelm-column/src/main/java/redelm/utils/Varint.java": [
                0,
                167
            ],
            "redelm-column/src/test/java/redelm/column/mem/TestMemColumn.java": [
                14,
                18
            ],
            "redelm-column/src/test/java/redelm/column/primitive/TestBoundedColumns.java": [
                0,
                90
            ],
            "redelm-column/src/test/java/redelm/io/PerfTest.java": [
                1,
                1
            ],
            "redelm-column/src/test/java/redelm/io/TestColumnIO.java": [
                7,
                10
            ],
            "redelm-pig/lib/pig-0.11.0-SNAPSHOT.jar": null,
            "redelm-pig/pom.xml": null,
            "redelm-pig/src/main/java/redelm/hadoop/ColumnData.java": [
                3,
                3
            ],
            "redelm-pig/src/main/java/redelm/hadoop/RedelmFileWriter.java": [
                8,
                5
            ],
            "redelm-pig/src/main/java/redelm/hadoop/RedelmRecordReader.java": [
                8,
                8
            ],
            "redelm-pig/src/main/java/redelm/hadoop/RedelmRecordWriter.java": [
                7,
                18
            ],
            "redelm-pig/src/test/java/redelm/hadoop/TestRedelmFileWriter.java": [
                11,
                2
            ]
        }
    },
    "40b0cb333cfff0fd46c0c54cef0723f6acc87277": {
        "datetime": "2012-11-20T10:27:03-08:00",
        "summary": "Merge pull request #13 from julienledem/fix_empty_bag_equals_null_bag",
        "message": "Merge pull request #13 from julienledem/fix_empty_bag_equals_null_bag\n\nFix empty bag equals null bag",
        "diff": {
            "redelm-column/src/main/java/redelm/Log.java": [
                0,
                4
            ],
            "redelm-pig/src/main/java/redelm/pig/PigSchemaConverter.java": [
                34,
                60
            ],
            "redelm-pig/src/main/java/redelm/pig/TupleRecordConsumer.java": [
                40,
                59
            ],
            "redelm-pig/src/main/java/redelm/pig/TupleWriteSupport.java": [
                51,
                78
            ],
            "redelm-pig/src/test/java/redelm/pig/TestPigSchemaConverter.java": [
                13,
                62
            ],
            "redelm-pig/src/test/java/redelm/pig/TestTupleRecordConsumer.java": [
                46,
                123
            ]
        }
    },
    "0c683e1d8b87d73e86255216ed026a4692e0274c": {
        "datetime": "2012-11-21T09:53:00-08:00",
        "summary": "fix build warning",
        "message": "fix build warning\n",
        "diff": {
            "pom.xml": null
        }
    },
    "bdc5a6e184f02ae130bbd345e8fd69b287a42957": {
        "datetime": "2012-11-21T11:13:44-08:00",
        "summary": "fix compression javadoc",
        "message": "fix compression javadoc\n",
        "diff": {
            "redelm-pig/src/main/java/redelm/hadoop/RedelmFileWriter.java": [
                5,
                6
            ],
            "redelm-pig/src/main/java/redelm/hadoop/RedelmOutputFormat.java": [
                2,
                7
            ]
        }
    },
    "60ca3a314385323d4f991c80ba1f49962492d324": {
        "datetime": "2012-11-21T11:22:33-08:00",
        "summary": "add documentation images",
        "message": "add documentation images\n",
        "diff": {
            "doc/dremel_paper/dremel_example.png": null,
            "doc/dremel_paper/schema.png": null,
            "doc/file_format/FileFormat.png": null
        }
    },
    "daea1fdea6fd56cf80cbb59dc4285483f9d89969": {
        "datetime": "2012-11-21T13:16:48-08:00",
        "summary": "updated format diagram",
        "message": "updated format diagram\n",
        "diff": {
            "doc/file_format/FileFormat.png": null
        }
    },
    "bce0f0d01c5ca92ac1f76d741e60701ef87bb12d": {
        "datetime": "2012-11-21T13:19:32-08:00",
        "summary": "fix Codec Logging",
        "message": "fix Codec Logging\n",
        "diff": {
            "redelm-column/src/main/java/redelm/Log.java": [
                1,
                1
            ],
            "redelm-column/src/main/java/redelm/column/mem/MemColumnWriter.java": [
                1,
                1
            ],
            "redelm-column/src/main/java/redelm/data/GroupRecordConsumer.java": [
                2,
                4
            ],
            "redelm-pig/src/main/java/redelm/hadoop/RedelmOutputFormat.java": [
                2,
                7
            ]
        }
    },
    "6f4650ad2149facd860ed6977cdd095f42941159": {
        "datetime": "2012-11-21T14:17:05-08:00",
        "summary": "Merge branch 'master' into preprocess_pig_schema",
        "message": "Merge branch 'master' into preprocess_pig_schema\n",
        "diff": {
            "doc/dremel_paper/dremel_example.png": null,
            "doc/dremel_paper/schema.png": null,
            "doc/file_format/FileFormat.png": null,
            "pom.xml": null,
            "redelm-column/src/main/java/redelm/Log.java": [
                1,
                1
            ],
            "redelm-pig/src/main/java/redelm/hadoop/RedelmFileWriter.java": [
                5,
                6
            ],
            "redelm-pig/src/main/java/redelm/hadoop/RedelmOutputFormat.java": [
                2,
                7
            ],
            "redelm-pig/src/main/java/redelm/pig/PigSchemaConverter.java": [
                1,
                1
            ],
            "redelm-pig/src/main/java/redelm/pig/TupleRecordConsumer.java": [
                2,
                8
            ]
        }
    },
    "48ef66b4dfbdae93218f3886894f3ce4ccb7fc99": {
        "datetime": "2012-11-21T14:25:20-08:00",
        "summary": "fix exception handling",
        "message": "fix exception handling\n",
        "diff": {
            "redelm-pig/src/main/java/redelm/pig/TupleRecordConsumer.java": [
                7,
                7
            ]
        }
    },
    "c73105c4c37bef5618c255b5988ebc29166c7737": {
        "datetime": "2012-11-21T14:33:55-08:00",
        "summary": "fix exceptions in Converters",
        "message": "fix exceptions in Converters\n",
        "diff": {
            "redelm-pig/src/main/java/redelm/pig/TupleConversionException.java": [
                0,
                24
            ],
            "redelm-pig/src/main/java/redelm/pig/TupleRecordConsumer.java": [
                6,
                6
            ],
            "redelm-pig/src/main/java/redelm/pig/converter/BagConverter.java": [
                1,
                2
            ],
            "redelm-pig/src/main/java/redelm/pig/converter/MapConverter.java": [
                1,
                2
            ],
            "redelm-pig/src/main/java/redelm/pig/converter/TupleConverter.java": [
                2,
                7
            ]
        }
    },
    "4c0a1f764024574380636bb612b65e3f6ac9fd12": {
        "datetime": "2012-11-21T16:14:50-08:00",
        "summary": "Merge pull request #14 from julienledem/preprocess_pig_schema",
        "message": "Merge pull request #14 from julienledem/preprocess_pig_schema\n\nPreprocess pig schema",
        "diff": {
            "redelm-pig/src/main/java/redelm/pig/TupleConversionException.java": [
                0,
                24
            ],
            "redelm-pig/src/main/java/redelm/pig/TupleReadSupport.java": [
                4,
                31
            ],
            "redelm-pig/src/main/java/redelm/pig/TupleRecordConsumer.java": [
                7,
                7
            ],
            "redelm-pig/src/main/java/redelm/pig/converter/BagConverter.java": [
                0,
                56
            ],
            "redelm-pig/src/main/java/redelm/pig/converter/Converter.java": [
                0,
                34
            ],
            "redelm-pig/src/main/java/redelm/pig/converter/MapConverter.java": [
                0,
                58
            ],
            "redelm-pig/src/main/java/redelm/pig/converter/MapKeyValueConverter.java": [
                0,
                63
            ],
            "redelm-pig/src/main/java/redelm/pig/converter/MessageConverter.java": [
                0,
                99
            ],
            "redelm-pig/src/main/java/redelm/pig/converter/TupleConverter.java": [
                0,
                94
            ],
            "redelm-pig/src/test/java/redelm/pig/TestTupleRecordConsumer.java": [
                8,
                13
            ]
        }
    },
    "0549961a0e4740d628a493dfeaaad37f6531c73f": {
        "datetime": "2012-11-21T16:15:30-08:00",
        "summary": "Merge pull request #16 from julienledem/fix_Codec_Logging",
        "message": "Merge pull request #16 from julienledem/fix_Codec_Logging\n\nfix Codec Logging",
        "diff": {
            "redelm-column/src/main/java/redelm/Log.java": [
                1,
                1
            ],
            "redelm-column/src/main/java/redelm/column/mem/MemColumnWriter.java": [
                1,
                1
            ],
            "redelm-column/src/main/java/redelm/data/GroupRecordConsumer.java": [
                2,
                4
            ],
            "redelm-pig/src/main/java/redelm/hadoop/RedelmOutputFormat.java": [
                2,
                7
            ]
        }
    },
    "ea3d65e9736d742317b0fc0a3f328478ffd09c00": {
        "datetime": "2012-11-26T10:32:25-08:00",
        "summary": "improve file format diagram",
        "message": "improve file format diagram\n",
        "diff": {
            "doc/file_format/FileFormat.png": null
        }
    },
    "9385a2fca031b0c5dcf681172e151f6aea8e1ac1": {
        "datetime": "2012-11-26T10:37:19-08:00",
        "summary": "Merge branch 'master' of github.com:julienledem/redelm",
        "message": "Merge branch 'master' of github.com:julienledem/redelm\n",
        "diff": {
            "redelm-column/src/main/java/redelm/Log.java": [
                1,
                1
            ],
            "redelm-column/src/main/java/redelm/column/mem/MemColumnWriter.java": [
                1,
                1
            ],
            "redelm-column/src/main/java/redelm/data/GroupRecordConsumer.java": [
                2,
                4
            ],
            "redelm-pig/src/main/java/redelm/hadoop/RedelmOutputFormat.java": [
                2,
                7
            ],
            "redelm-pig/src/main/java/redelm/pig/TupleConversionException.java": [
                0,
                24
            ],
            "redelm-pig/src/main/java/redelm/pig/TupleReadSupport.java": [
                4,
                31
            ],
            "redelm-pig/src/main/java/redelm/pig/TupleRecordConsumer.java": [
                7,
                7
            ],
            "redelm-pig/src/main/java/redelm/pig/converter/BagConverter.java": [
                0,
                56
            ],
            "redelm-pig/src/main/java/redelm/pig/converter/Converter.java": [
                0,
                34
            ],
            "redelm-pig/src/main/java/redelm/pig/converter/MapConverter.java": [
                0,
                58
            ],
            "redelm-pig/src/main/java/redelm/pig/converter/MapKeyValueConverter.java": [
                0,
                63
            ],
            "redelm-pig/src/main/java/redelm/pig/converter/MessageConverter.java": [
                0,
                99
            ],
            "redelm-pig/src/main/java/redelm/pig/converter/TupleConverter.java": [
                0,
                94
            ],
            "redelm-pig/src/test/java/redelm/pig/TestTupleRecordConsumer.java": [
                8,
                13
            ]
        }
    },
    "ee02094ff08af675b619412686ef55dee6c7e09c": {
        "datetime": "2012-11-28T13:59:42-08:00",
        "summary": "better logging and perf tests",
        "message": "better logging and perf tests\n",
        "diff": {
            "redelm-column/src/test/java/redelm/io/PerfTest.java": [
                2,
                5
            ],
            "redelm-pig/src/main/java/redelm/hadoop/RedelmFileReader.java": [
                1,
                6
            ],
            "redelm-pig/src/main/java/redelm/hadoop/RedelmInputSplit.java": [
                1,
                2
            ],
            "redelm-pig/src/main/java/redelm/hadoop/RedelmMetaData.java": [
                2,
                6
            ],
            "redelm-pig/src/main/java/redelm/hadoop/RedelmRecordReader.java": [
                3,
                28
            ],
            "redelm-pig/src/test/java/redelm/pig/PerfTest2.java": [
                27,
                25
            ],
            "redelm-pig/src/test/java/redelm/pig/PerfTestReadAllCols.java": [
                0,
                48
            ],
            "redelm-pig/src/test/java/redelm/pig/TupleConsumerPerfTest.java": [
                0,
                261
            ]
        }
    },
    "9223ad517e9d42434b9ceb388154afb472c325c2": {
        "datetime": "2012-11-28T14:10:21-08:00",
        "summary": "Merge branch 'master' into summary_file",
        "message": "Merge branch 'master' into summary_file\n\nConflicts:\n\tredelm-pig/src/main/java/redelm/hadoop/RedelmFileWriter.java\n\tredelm-pig/src/main/java/redelm/hadoop/RedelmOutputFormat.java\n",
        "diff": {
            "doc/dremel_paper/dremel_example.png": null,
            "doc/dremel_paper/schema.png": null,
            "doc/file_format/FileFormat.png": null,
            "pom.xml": null,
            "redelm-column/src/main/java/redelm/Log.java": [
                1,
                5
            ],
            "redelm-column/src/main/java/redelm/column/mem/MemColumnWriter.java": [
                1,
                1
            ],
            "redelm-column/src/main/java/redelm/data/GroupRecordConsumer.java": [
                2,
                4
            ],
            "redelm-pig/src/main/java/redelm/hadoop/RedelmFileWriter.java": [
                5,
                6
            ],
            "redelm-pig/src/main/java/redelm/hadoop/RedelmOutputFormat.java": [
                3,
                11
            ],
            "redelm-pig/src/main/java/redelm/pig/PigSchemaConverter.java": [
                34,
                60
            ],
            "redelm-pig/src/main/java/redelm/pig/TupleConversionException.java": [
                0,
                24
            ],
            "redelm-pig/src/main/java/redelm/pig/TupleReadSupport.java": [
                4,
                31
            ],
            "redelm-pig/src/main/java/redelm/pig/TupleRecordConsumer.java": [
                45,
                64
            ],
            "redelm-pig/src/main/java/redelm/pig/TupleWriteSupport.java": [
                51,
                78
            ],
            "redelm-pig/src/main/java/redelm/pig/converter/BagConverter.java": [
                0,
                56
            ],
            "redelm-pig/src/main/java/redelm/pig/converter/Converter.java": [
                0,
                34
            ],
            "redelm-pig/src/main/java/redelm/pig/converter/MapConverter.java": [
                0,
                58
            ],
            "redelm-pig/src/main/java/redelm/pig/converter/MapKeyValueConverter.java": [
                0,
                63
            ],
            "redelm-pig/src/main/java/redelm/pig/converter/MessageConverter.java": [
                0,
                99
            ],
            "redelm-pig/src/main/java/redelm/pig/converter/TupleConverter.java": [
                0,
                94
            ],
            "redelm-pig/src/test/java/redelm/pig/TestPigSchemaConverter.java": [
                13,
                62
            ],
            "redelm-pig/src/test/java/redelm/pig/TestTupleRecordConsumer.java": [
                45,
                127
            ]
        }
    },
    "817b54b4cb6bd96e77df5879fdc02fc2f0e73d10": {
        "datetime": "2012-11-28T14:13:41-08:00",
        "summary": "Merge pull request #17 from julienledem/summary_file",
        "message": "Merge pull request #17 from julienledem/summary_file\n\nSummary file",
        "diff": {
            "redelm-pig/src/main/java/redelm/hadoop/Footer.java": [
                0,
                50
            ],
            "redelm-pig/src/main/java/redelm/hadoop/RedelmFileReader.java": [
                4,
                103
            ],
            "redelm-pig/src/main/java/redelm/hadoop/RedelmFileWriter.java": [
                0,
                21
            ],
            "redelm-pig/src/main/java/redelm/hadoop/RedelmInputFormat.java": [
                7,
                10
            ],
            "redelm-pig/src/main/java/redelm/hadoop/RedelmOutputCommitter.java": [
                0,
                52
            ],
            "redelm-pig/src/main/java/redelm/hadoop/RedelmOutputFormat.java": [
                1,
                12
            ],
            "redelm-pig/src/main/java/redelm/hadoop/RedelmRecordReader.java": [
                9,
                11
            ],
            "redelm-pig/src/test/java/redelm/hadoop/TestRedelmFileWriter.java": [
                3,
                4
            ]
        }
    },
    "615c23c3c573109646ffcc5e244e3cb4ff551328": {
        "datetime": "2012-11-29T22:40:42-08:00",
        "summary": "make splits contain all data blocks starting in the same HDFS block",
        "message": "make splits contain all data blocks starting in the same HDFS block\n",
        "diff": {
            "redelm-column/src/main/java/redelm/column/mem/MemColumnWriter.java": [
                3,
                1
            ],
            "redelm-pig/src/main/java/redelm/hadoop/RedelmInputFormat.java": [
                19,
                45
            ],
            "redelm-pig/src/main/java/redelm/hadoop/RedelmInputSplit.java": [
                8,
                9
            ],
            "redelm-pig/src/main/java/redelm/hadoop/RedelmRecordReader.java": [
                9,
                13
            ],
            "redelm-pig/src/main/java/redelm/hadoop/RedelmRecordWriter.java": [
                1,
                1
            ],
            "redelm-pig/src/test/java/redelm/hadoop/TestInputFormat.java": [
                0,
                60
            ]
        }
    },
    "b23e1f64bb362c838dafd18f324e23425e2b25d0": {
        "datetime": "2012-11-29T22:43:18-08:00",
        "summary": "add missing license headers",
        "message": "add missing license headers\n",
        "diff": {
            "redelm-pig/src/main/java/redelm/pig/TupleConversionException.java": [
                0,
                15
            ],
            "redelm-pig/src/main/java/redelm/pig/converter/BagConverter.java": [
                0,
                15
            ],
            "redelm-pig/src/main/java/redelm/pig/converter/Converter.java": [
                0,
                15
            ],
            "redelm-pig/src/main/java/redelm/pig/converter/MapConverter.java": [
                0,
                15
            ],
            "redelm-pig/src/main/java/redelm/pig/converter/MapKeyValueConverter.java": [
                0,
                15
            ],
            "redelm-pig/src/main/java/redelm/pig/converter/MessageConverter.java": [
                0,
                15
            ],
            "redelm-pig/src/main/java/redelm/pig/converter/TupleConverter.java": [
                0,
                15
            ],
            "redelm-pig/src/test/java/redelm/hadoop/TestInputFormat.java": [
                0,
                15
            ]
        }
    },
    "e186b7dcde95264a2dfdd2b179a23e1e2e4861f5": {
        "datetime": "2012-11-30T09:20:57-08:00",
        "summary": "fix UDFContext collision when multiple stores",
        "message": "fix UDFContext collision when multiple stores\n",
        "diff": {
            "redelm-pig/src/main/java/redelm/pig/RedelmStorer.java": [
                15,
                60
            ]
        }
    },
    "73d4fde0e069b31efc63e2a91a1d7c10984d9db1": {
        "datetime": "2012-12-02T22:02:44-08:00",
        "summary": "first stab at record reader compiler",
        "message": "first stab at record reader compiler\n",
        "diff": {
            "redelm-column/src/main/java/redelm/column/mem/MemColumnReader.java": [
                0,
                3
            ],
            "redelm-column/src/main/java/redelm/io/RecordReader.java": [
                3,
                27
            ],
            "redelm-column/src/main/java/redelm/io/RecordReaderCompiler.java": [
                0,
                92
            ],
            "redelm-column/src/test/java/redelm/io/ExpectationValidatingRecordConsumer.java": [
                0,
                86
            ],
            "redelm-column/src/test/java/redelm/io/TestColumnIO.java": [
                130,
                58
            ],
            "redelm-column/src/test/java/redelm/io/TestRecordReaderCompiler.java": [
                0,
                35
            ],
            "redelm-pig/src/test/java/redelm/pig/TupleConsumerPerfTest.java": [
                0,
                3
            ]
        }
    },
    "0f88e2922f930a1c4486dbe8a7aea80df5a4dd7f": {
        "datetime": "2012-12-03T14:57:39-08:00",
        "summary": "simplified record reader; a little more of reader compiler",
        "message": "simplified record reader; a little more of reader compiler\n",
        "diff": {
            "redelm-column/src/main/java/redelm/io/RecordReader.java": [
                8,
                15
            ],
            "redelm-column/src/main/java/redelm/io/RecordReaderCompiler.java": [
                11,
                59
            ]
        }
    },
    "104b21971a95cc16042f7af2df55321ec45d63af": {
        "datetime": "2012-12-03T15:03:15-08:00",
        "summary": "remove currentNodePath from reader and improve perf a lot",
        "message": "remove currentNodePath from reader and improve perf a lot\n",
        "diff": {
            "redelm-column/src/main/java/redelm/io/RecordReader.java": [
                7,
                3
            ],
            "redelm-column/src/test/java/redelm/io/PerfTest.java": [
                0,
                1
            ]
        }
    },
    "7133e58f53697bd544e647de24ba6c2c63a20a68": {
        "datetime": "2012-12-03T15:42:57-08:00",
        "summary": "Merge pull request #19 from julienledem/remove_currentNodePath_from_reader",
        "message": "Merge pull request #19 from julienledem/remove_currentNodePath_from_reader\n\nremove currentNodePath from reader and improve perf a lot",
        "diff": {
            "redelm-column/src/main/java/redelm/io/RecordReader.java": [
                7,
                3
            ],
            "redelm-column/src/test/java/redelm/io/PerfTest.java": [
                0,
                1
            ]
        }
    },
    "c4a41dd9e06334829a3d0ddd8535a8a7fa7ad0e1": {
        "datetime": "2012-12-14T07:58:38-08:00",
        "summary": "more fsa codegen",
        "message": "more fsa codegen\n",
        "diff": {
            "redelm-column/src/main/java/redelm/io/ColumnIO.java": [
                0,
                8
            ],
            "redelm-column/src/main/java/redelm/io/PrimitiveColumnIO.java": [
                0,
                5
            ],
            "redelm-column/src/main/java/redelm/io/RecordReader.java": [
                4,
                9
            ],
            "redelm-column/src/main/java/redelm/io/RecordReaderCompiler.java": [
                37,
                76
            ],
            "redelm-column/src/test/java/redelm/io/TestRecordReaderCompiler.java": [
                0,
                18
            ]
        }
    },
    "072db3ed0a02e5f5476f5366eb4b654e837c3d62": {
        "datetime": "2012-12-14T18:02:20-08:00",
        "summary": "change record reader init lifecycle",
        "message": "change record reader init lifecycle\n",
        "diff": {
            "redelm-column/src/main/java/redelm/data/GroupRecordConsumer.java": [
                7,
                9
            ],
            "redelm-column/src/main/java/redelm/io/MessageColumnIO.java": [
                5,
                11
            ],
            "redelm-column/src/main/java/redelm/io/RecordConsumer.java": [
                1,
                8
            ],
            "redelm-column/src/main/java/redelm/io/RecordConsumerWrapper.java": [
                3,
                9
            ],
            "redelm-column/src/main/java/redelm/io/RecordReader.java": [
                19,
                23
            ],
            "redelm-column/src/main/java/redelm/io/ValidatingRecordConsumer.java": [
                3,
                9
            ],
            "redelm-column/src/test/java/redelm/io/PerfTest.java": [
                65,
                23
            ],
            "redelm-column/src/test/java/redelm/io/TestColumnIO.java": [
                14,
                25
            ],
            "redelm-pig/src/main/java/redelm/hadoop/ReadSupport.java": [
                2,
                1
            ],
            "redelm-pig/src/main/java/redelm/hadoop/RedelmRecordReader.java": [
                24,
                15
            ],
            "redelm-pig/src/main/java/redelm/pig/TupleReadSupport.java": [
                2,
                2
            ],
            "redelm-pig/src/main/java/redelm/pig/TupleRecordConsumer.java": [
                7,
                9
            ],
            "redelm-pig/src/main/java/redelm/pig/converter/MessageConverter.java": [
                11,
                13
            ],
            "redelm-pig/src/test/java/redelm/pig/TestTupleRecordConsumer.java": [
                8,
                13
            ]
        }
    },
    "48f0e8f83705dff3bf85bd4be91309144c7fa0ae": {
        "datetime": "2012-12-14T18:46:46-08:00",
        "summary": "refactor record consumer materializer",
        "message": "refactor record consumer materializer\n",
        "diff": {
            "redelm-column/src/main/java/redelm/data/GroupRecordConsumer.java": [
                2,
                2
            ],
            "redelm-column/src/main/java/redelm/io/ColumnIOFactory.java": [
                4,
                12
            ],
            "redelm-column/src/main/java/redelm/io/MessageColumnIO.java": [
                11,
                13
            ],
            "redelm-column/src/main/java/redelm/io/RecordConsumer.java": [
                8,
                1
            ],
            "redelm-column/src/main/java/redelm/io/RecordConsumerWrapper.java": [
                9,
                3
            ],
            "redelm-column/src/main/java/redelm/io/RecordMaterializer.java": [
                0,
                19
            ],
            "redelm-column/src/main/java/redelm/io/RecordReader.java": [
                5,
                21
            ],
            "redelm-column/src/main/java/redelm/io/ValidatingRecordConsumer.java": [
                9,
                3
            ],
            "redelm-column/src/test/java/redelm/io/PerfTest.java": [
                4,
                1
            ],
            "redelm-column/src/test/java/redelm/io/TestColumnIO.java": [
                7,
                6
            ],
            "redelm-pig/src/main/java/redelm/hadoop/ReadSupport.java": [
                3,
                3
            ],
            "redelm-pig/src/main/java/redelm/pig/TupleReadSupport.java": [
                2,
                2
            ],
            "redelm-pig/src/main/java/redelm/pig/TupleRecordConsumer.java": [
                2,
                2
            ],
            "redelm-pig/src/main/java/redelm/pig/converter/MessageConverter.java": [
                3,
                3
            ],
            "redelm-pig/src/test/java/redelm/pig/TestTupleRecordConsumer.java": [
                13,
                7
            ]
        }
    },
    "b6f0ca6b2b764a5697f05659626206fcdee10954": {
        "datetime": "2012-12-17T08:09:02-08:00",
        "summary": "remove unnecessary constructor param",
        "message": "remove unnecessary constructor param\n",
        "diff": {
            "redelm-column/src/main/java/redelm/io/MessageColumnIO.java": [
                1,
                1
            ],
            "redelm-column/src/main/java/redelm/io/RecordReader.java": [
                5,
                5
            ]
        }
    },
    "eaf317134352cf0c3309f9b747184ebf1400077b": {
        "datetime": "2012-12-17T08:15:35-08:00",
        "summary": "Merge branch 'master' into improve_record_consumer_interface",
        "message": "Merge branch 'master' into improve_record_consumer_interface\n\nConflicts:\n\tredelm-column/src/main/java/redelm/io/RecordReader.java\n\tredelm-pig/src/main/java/redelm/hadoop/RedelmRecordReader.java\n",
        "diff": {
            "redelm-column/src/main/java/redelm/io/RecordReader.java": [
                10,
                3
            ],
            "redelm-pig/src/main/java/redelm/hadoop/Footer.java": [
                0,
                50
            ],
            "redelm-pig/src/main/java/redelm/hadoop/RedelmFileReader.java": [
                4,
                103
            ],
            "redelm-pig/src/main/java/redelm/hadoop/RedelmFileWriter.java": [
                0,
                21
            ],
            "redelm-pig/src/main/java/redelm/hadoop/RedelmInputFormat.java": [
                7,
                10
            ],
            "redelm-pig/src/main/java/redelm/hadoop/RedelmOutputCommitter.java": [
                0,
                52
            ],
            "redelm-pig/src/main/java/redelm/hadoop/RedelmOutputFormat.java": [
                1,
                12
            ],
            "redelm-pig/src/main/java/redelm/hadoop/RedelmRecordReader.java": [
                2,
                4
            ],
            "redelm-pig/src/test/java/redelm/hadoop/TestRedelmFileWriter.java": [
                3,
                4
            ]
        }
    },
    "4e5da20979304e9005f67bb93cca165ef9ed6f56": {
        "datetime": "2012-12-17T15:24:08-08:00",
        "summary": "introduce state object",
        "message": "introduce state object\n",
        "diff": {
            "redelm-column/src/main/java/redelm/io/RecordReader.java": [
                8,
                35
            ]
        }
    },
    "27c93d0622e49ad44d4d1c2a10a0a11c4ae1b241": {
        "datetime": "2012-12-18T09:34:11-08:00",
        "summary": "more use of the state class",
        "message": "more use of the state class\n",
        "diff": {
            "redelm-column/src/main/java/redelm/io/RecordReader.java": [
                53,
                77
            ]
        }
    },
    "8f2c7e598dde293312f6d1894affb7630bb62591": {
        "datetime": "2012-12-19T17:57:14-08:00",
        "summary": "slight improvement to the record reader",
        "message": "slight improvement to the record reader\n",
        "diff": {
            "redelm-column/src/main/java/redelm/io/RecordReader.java": [
                25,
                45
            ],
            "redelm-column/src/test/java/redelm/io/PerfTest.java": [
                3,
                4
            ]
        }
    },
    "7dd9300aa63c3abf783ae5d8046c4bad8f1ccde3": {
        "datetime": "2012-12-19T22:04:41-08:00",
        "summary": "remove dependency of column io on column store",
        "message": "remove dependency of column io on column store\n",
        "diff": {
            "redelm-column/src/main/java/redelm/io/ColumnIO.java": [
                4,
                1
            ],
            "redelm-column/src/main/java/redelm/io/ColumnIOFactory.java": [
                8,
                5
            ],
            "redelm-column/src/main/java/redelm/io/GroupColumnIO.java": [
                12,
                3
            ],
            "redelm-column/src/main/java/redelm/io/MessageColumnIO.java": [
                19,
                44
            ],
            "redelm-column/src/main/java/redelm/io/PrimitiveColumnIO.java": [
                21,
                11
            ],
            "redelm-column/src/main/java/redelm/io/RecordReader.java": [
                2,
                4
            ],
            "redelm-column/src/test/java/redelm/io/PerfTest.java": [
                7,
                6
            ],
            "redelm-column/src/test/java/redelm/io/TestColumnIO.java": [
                12,
                12
            ],
            "redelm-pig/src/main/java/redelm/hadoop/RedelmRecordReader.java": [
                2,
                2
            ],
            "redelm-pig/src/main/java/redelm/hadoop/RedelmRecordWriter.java": [
                2,
                2
            ]
        }
    },
    "e7354598b543a3f86ca304e07596d08c27d1660b": {
        "datetime": "2012-12-19T22:15:56-08:00",
        "summary": "remove unecessary class parameter",
        "message": "remove unecessary class parameter\n",
        "diff": {
            "redelm-column/src/main/java/redelm/io/RecordReader.java": [
                2,
                1
            ],
            "redelm-column/src/main/java/redelm/io/ValidatingRecordConsumer.java": [
                1,
                1
            ]
        }
    },
    "5334a2d7933483d032c914fa2dfeb269513b574e": {
        "datetime": "2012-12-19T22:27:35-08:00",
        "summary": "add missing license headers",
        "message": "add missing license headers\n",
        "diff": {
            "redelm-column/src/main/java/redelm/io/RecordMaterializer.java": [
                0,
                15
            ],
            "redelm-pig/src/main/java/redelm/pig/TupleConversionException.java": [
                0,
                15
            ],
            "redelm-pig/src/main/java/redelm/pig/converter/BagConverter.java": [
                0,
                15
            ],
            "redelm-pig/src/main/java/redelm/pig/converter/Converter.java": [
                0,
                15
            ],
            "redelm-pig/src/main/java/redelm/pig/converter/MapConverter.java": [
                0,
                15
            ],
            "redelm-pig/src/main/java/redelm/pig/converter/MapKeyValueConverter.java": [
                0,
                15
            ],
            "redelm-pig/src/main/java/redelm/pig/converter/MessageConverter.java": [
                0,
                15
            ],
            "redelm-pig/src/main/java/redelm/pig/converter/TupleConverter.java": [
                0,
                15
            ]
        }
    },
    "11b6a8f09923617cd54bb55ad3216972dca00d8e": {
        "datetime": "2012-12-22T17:48:22-08:00",
        "summary": "Merge branch 'improve_record_consumer_interface' into FSA_codegen",
        "message": "Merge branch 'improve_record_consumer_interface' into FSA_codegen\n\nConflicts:\n\tredelm-column/src/main/java/redelm/io/PrimitiveColumnIO.java\n\tredelm-column/src/main/java/redelm/io/RecordReader.java\n\tredelm-column/src/test/java/redelm/io/PerfTest.java\n\tredelm-column/src/test/java/redelm/io/TestColumnIO.java\n\tredelm-pig/src/main/java/redelm/hadoop/RedelmRecordReader.java\n",
        "diff": {
            "redelm-column/src/main/java/redelm/data/GroupRecordConsumer.java": [
                8,
                10
            ],
            "redelm-column/src/main/java/redelm/io/ColumnIO.java": [
                4,
                1
            ],
            "redelm-column/src/main/java/redelm/io/ColumnIOFactory.java": [
                10,
                15
            ],
            "redelm-column/src/main/java/redelm/io/GroupColumnIO.java": [
                12,
                3
            ],
            "redelm-column/src/main/java/redelm/io/MessageColumnIO.java": [
                19,
                52
            ],
            "redelm-column/src/main/java/redelm/io/PrimitiveColumnIO.java": [
                21,
                11
            ],
            "redelm-column/src/main/java/redelm/io/RecordMaterializer.java": [
                0,
                34
            ],
            "redelm-column/src/main/java/redelm/io/RecordReader.java": [
                97,
                156
            ],
            "redelm-column/src/main/java/redelm/io/RecordReaderCompiler.java": [
                136,
                138
            ],
            "redelm-column/src/test/java/redelm/io/ExpectationValidatingRecordConsumer.java": [
                1,
                6
            ],
            "redelm-column/src/test/java/redelm/io/PerfTest.java": [
                87,
                41
            ],
            "redelm-column/src/test/java/redelm/io/TestColumnIO.java": [
                20,
                26
            ],
            "redelm-column/src/test/java/redelm/io/TestRecordReaderCompiler.java": [
                5,
                10
            ],
            "redelm-pig/src/main/java/redelm/hadoop/Footer.java": [
                0,
                50
            ],
            "redelm-pig/src/main/java/redelm/hadoop/ReadSupport.java": [
                4,
                3
            ],
            "redelm-pig/src/main/java/redelm/hadoop/RedelmFileReader.java": [
                4,
                103
            ],
            "redelm-pig/src/main/java/redelm/hadoop/RedelmFileWriter.java": [
                0,
                21
            ],
            "redelm-pig/src/main/java/redelm/hadoop/RedelmInputFormat.java": [
                7,
                10
            ],
            "redelm-pig/src/main/java/redelm/hadoop/RedelmOutputCommitter.java": [
                0,
                52
            ],
            "redelm-pig/src/main/java/redelm/hadoop/RedelmOutputFormat.java": [
                1,
                12
            ],
            "redelm-pig/src/main/java/redelm/hadoop/RedelmRecordReader.java": [
                28,
                21
            ],
            "redelm-pig/src/main/java/redelm/hadoop/RedelmRecordWriter.java": [
                2,
                2
            ],
            "redelm-pig/src/main/java/redelm/pig/TupleReadSupport.java": [
                3,
                3
            ],
            "redelm-pig/src/main/java/redelm/pig/TupleRecordConsumer.java": [
                8,
                10
            ],
            "redelm-pig/src/main/java/redelm/pig/converter/MessageConverter.java": [
                11,
                13
            ],
            "redelm-pig/src/test/java/redelm/hadoop/TestInputFormat.java": [
                1,
                2
            ],
            "redelm-pig/src/test/java/redelm/hadoop/TestRedelmFileWriter.java": [
                3,
                4
            ],
            "redelm-pig/src/test/java/redelm/pig/TestTupleRecordConsumer.java": [
                14,
                13
            ],
            "redelm-pig/src/test/java/redelm/pig/TupleConsumerPerfTest.java": [
                8,
                8
            ]
        }
    },
    "eaeff045457b3e31fd556744b2c134fc9cfaae61": {
        "datetime": "2013-01-02T11:24:40-08:00",
        "summary": "refactor reader",
        "message": "refactor reader\n",
        "diff": {
            "redelm-column/src/main/java/redelm/io/MessageColumnIO.java": [
                1,
                1
            ],
            "redelm-column/src/main/java/redelm/io/RecordReader.java": [
                304,
                3
            ],
            "redelm-column/src/main/java/redelm/io/RecordReaderCompiler.java": [
                29,
                42
            ],
            "redelm-column/src/main/java/redelm/io/RecordReaderImplementation.java": [
                0,
                325
            ],
            "redelm-column/src/test/java/redelm/io/TestColumnIO.java": [
                4,
                4
            ],
            "redelm-column/src/test/java/redelm/io/TestRecordReaderCompiler.java": [
                1,
                1
            ]
        }
    },
    "c4c6991f1afe6b252a96794cb951d66c7890d656": {
        "datetime": "2013-01-05T14:57:43-08:00",
        "summary": "rewrite of the code generation bit (work in progress)",
        "message": "rewrite of the code generation bit (work in progress)\n",
        "diff": {
            "redelm-column/src/main/java/redelm/io/RecordReaderCompiler.java": [
                113,
                165
            ],
            "redelm-column/src/main/java/redelm/io/RecordReaderImplementation.java": [
                17,
                157
            ],
            "redelm-column/src/main/java/redelm/schema/PrimitiveType.java": [
                7,
                16
            ],
            "redelm-column/src/test/java/redelm/io/TestColumnIO.java": [
                1,
                1
            ],
            "redelm-column/src/test/java/redelm/io/TestRecordReaderCompiler.java": [
                1,
                1
            ]
        }
    },
    "180222e874d74fd26322786d612a418866fa020d": {
        "datetime": "2013-01-05T15:12:44-08:00",
        "summary": "rename RecordConsumerWrapper",
        "message": "rename RecordConsumerWrapper\n",
        "diff": {
            "redelm-column/src/main/java/redelm/io/RecordConsumerWrapper.java": [
                3,
                3
            ],
            "redelm-column/src/test/java/redelm/io/PerfTest.java": [
                1,
                1
            ],
            "redelm-column/src/test/java/redelm/io/TestColumnIO.java": [
                2,
                2
            ],
            "redelm-pig/src/test/java/redelm/pig/TestTupleRecordConsumer.java": [
                2,
                2
            ],
            "redelm-pig/src/test/java/redelm/pig/TupleConsumerPerfTest.java": [
                2,
                2
            ]
        }
    },
    "eba3e211269dd85265afcfb9af7d1f753b88b37b": {
        "datetime": "2013-01-05T15:28:00-08:00",
        "summary": "Merge branch 'master' of github.com:julienledem/redelm into better_InputFormat_logs",
        "message": "Merge branch 'master' of github.com:julienledem/redelm into better_InputFormat_logs\n\nConflicts:\n\tredelm-pig/src/main/java/redelm/hadoop/RedelmRecordReader.java\n",
        "diff": {
            "redelm-column/src/main/java/redelm/io/RecordReader.java": [
                7,
                3
            ],
            "redelm-pig/src/main/java/redelm/hadoop/Footer.java": [
                0,
                50
            ],
            "redelm-pig/src/main/java/redelm/hadoop/RedelmFileReader.java": [
                4,
                103
            ],
            "redelm-pig/src/main/java/redelm/hadoop/RedelmFileWriter.java": [
                0,
                21
            ],
            "redelm-pig/src/main/java/redelm/hadoop/RedelmInputFormat.java": [
                7,
                10
            ],
            "redelm-pig/src/main/java/redelm/hadoop/RedelmOutputCommitter.java": [
                0,
                52
            ],
            "redelm-pig/src/main/java/redelm/hadoop/RedelmOutputFormat.java": [
                1,
                12
            ],
            "redelm-pig/src/main/java/redelm/hadoop/RedelmRecordReader.java": [
                2,
                12
            ],
            "redelm-pig/src/test/java/redelm/hadoop/TestRedelmFileWriter.java": [
                3,
                4
            ]
        }
    },
    "f3f02f5bd5b0e36c81ee99ba04fc74a74cd0ba6a": {
        "datetime": "2013-01-05T15:33:41-08:00",
        "summary": "Merge pull request #18 from julienledem/better_InputFormat_logs",
        "message": "Merge pull request #18 from julienledem/better_InputFormat_logs\n\nBetter input format logs and one split per hdfs block",
        "diff": {
            "redelm-column/src/main/java/redelm/column/mem/MemColumnWriter.java": [
                3,
                1
            ],
            "redelm-column/src/main/java/redelm/io/RecordConsumerWrapper.java": [
                3,
                3
            ],
            "redelm-column/src/test/java/redelm/io/PerfTest.java": [
                3,
                5
            ],
            "redelm-column/src/test/java/redelm/io/TestColumnIO.java": [
                2,
                2
            ],
            "redelm-pig/src/main/java/redelm/hadoop/RedelmFileReader.java": [
                1,
                6
            ],
            "redelm-pig/src/main/java/redelm/hadoop/RedelmInputFormat.java": [
                19,
                45
            ],
            "redelm-pig/src/main/java/redelm/hadoop/RedelmInputSplit.java": [
                9,
                11
            ],
            "redelm-pig/src/main/java/redelm/hadoop/RedelmMetaData.java": [
                2,
                6
            ],
            "redelm-pig/src/main/java/redelm/hadoop/RedelmRecordReader.java": [
                7,
                44
            ],
            "redelm-pig/src/main/java/redelm/hadoop/RedelmRecordWriter.java": [
                1,
                1
            ],
            "redelm-pig/src/main/java/redelm/pig/TupleConversionException.java": [
                0,
                15
            ],
            "redelm-pig/src/main/java/redelm/pig/converter/BagConverter.java": [
                0,
                15
            ],
            "redelm-pig/src/main/java/redelm/pig/converter/Converter.java": [
                0,
                15
            ],
            "redelm-pig/src/main/java/redelm/pig/converter/MapConverter.java": [
                0,
                15
            ],
            "redelm-pig/src/main/java/redelm/pig/converter/MapKeyValueConverter.java": [
                0,
                15
            ],
            "redelm-pig/src/main/java/redelm/pig/converter/MessageConverter.java": [
                0,
                15
            ],
            "redelm-pig/src/main/java/redelm/pig/converter/TupleConverter.java": [
                0,
                15
            ],
            "redelm-pig/src/test/java/redelm/hadoop/TestInputFormat.java": [
                0,
                75
            ],
            "redelm-pig/src/test/java/redelm/pig/PerfTest2.java": [
                27,
                25
            ],
            "redelm-pig/src/test/java/redelm/pig/PerfTestReadAllCols.java": [
                0,
                48
            ],
            "redelm-pig/src/test/java/redelm/pig/TestTupleRecordConsumer.java": [
                2,
                2
            ],
            "redelm-pig/src/test/java/redelm/pig/TupleConsumerPerfTest.java": [
                0,
                261
            ]
        }
    },
    "0c3a1d852c60d52073aff296f39f8ad0cd87ec84": {
        "datetime": "2013-01-06T16:34:34-08:00",
        "summary": "Merge branch 'master' of github.com:julienledem/redelm into improve_record_consumer_interface",
        "message": "Merge branch 'master' of github.com:julienledem/redelm into improve_record_consumer_interface\n\nConflicts:\n\tredelm-column/src/test/java/redelm/io/PerfTest.java\n\tredelm-column/src/test/java/redelm/io/TestColumnIO.java\n\tredelm-pig/src/main/java/redelm/hadoop/RedelmRecordReader.java\n\tredelm-pig/src/test/java/redelm/pig/TestTupleRecordConsumer.java\n",
        "diff": {
            "redelm-column/src/main/java/redelm/column/mem/MemColumnWriter.java": [
                3,
                1
            ],
            "redelm-column/src/main/java/redelm/io/RecordConsumerWrapper.java": [
                3,
                3
            ],
            "redelm-column/src/main/java/redelm/io/RecordReader.java": [
                1,
                1
            ],
            "redelm-column/src/test/java/redelm/io/PerfTest.java": [
                1,
                3
            ],
            "redelm-column/src/test/java/redelm/io/TestColumnIO.java": [
                1,
                2
            ],
            "redelm-pig/src/main/java/redelm/hadoop/RedelmFileReader.java": [
                1,
                6
            ],
            "redelm-pig/src/main/java/redelm/hadoop/RedelmInputFormat.java": [
                19,
                45
            ],
            "redelm-pig/src/main/java/redelm/hadoop/RedelmInputSplit.java": [
                9,
                11
            ],
            "redelm-pig/src/main/java/redelm/hadoop/RedelmMetaData.java": [
                2,
                6
            ],
            "redelm-pig/src/main/java/redelm/hadoop/RedelmRecordReader.java": [
                7,
                37
            ],
            "redelm-pig/src/main/java/redelm/hadoop/RedelmRecordWriter.java": [
                1,
                1
            ],
            "redelm-pig/src/test/java/redelm/hadoop/TestInputFormat.java": [
                0,
                76
            ],
            "redelm-pig/src/test/java/redelm/pig/PerfTest2.java": [
                27,
                25
            ],
            "redelm-pig/src/test/java/redelm/pig/PerfTestReadAllCols.java": [
                0,
                48
            ],
            "redelm-pig/src/test/java/redelm/pig/TupleConsumerPerfTest.java": [
                0,
                210
            ]
        }
    },
    "1954277c4ea81c9a748131b206f9df8ba69b9382": {
        "datetime": "2013-01-06T17:11:55-08:00",
        "summary": "removed cheesy comment and hardcoded max depth based on jco's comment",
        "message": "removed cheesy comment and hardcoded max depth based on jco's comment\n",
        "diff": {
            "redelm-column/src/main/java/redelm/io/MessageColumnIO.java": [
                6,
                10
            ]
        }
    },
    "fa4c4ba7f075586b7eed9152bd7ea231c873cfca": {
        "datetime": "2013-01-06T17:12:54-08:00",
        "summary": "removed unnecessary whitespace",
        "message": "removed unnecessary whitespace\n",
        "diff": {
            "redelm-column/src/test/java/redelm/io/TestColumnIO.java": [
                1,
                1
            ]
        }
    },
    "d68307e877b95dd613fd1a6fe4479b87ea86aa90": {
        "datetime": "2013-01-06T17:17:43-08:00",
        "summary": "Merge branch 'master' into fix_schema_passing_when_multiple_stores",
        "message": "Merge branch 'master' into fix_schema_passing_when_multiple_stores\n",
        "diff": {
            "redelm-column/src/main/java/redelm/io/RecordConsumerWrapper.java": [
                3,
                3
            ],
            "redelm-column/src/main/java/redelm/io/RecordReader.java": [
                7,
                3
            ],
            "redelm-column/src/test/java/redelm/io/PerfTest.java": [
                1,
                1
            ],
            "redelm-column/src/test/java/redelm/io/TestColumnIO.java": [
                2,
                2
            ],
            "redelm-pig/src/main/java/redelm/hadoop/Footer.java": [
                0,
                50
            ],
            "redelm-pig/src/main/java/redelm/hadoop/RedelmFileReader.java": [
                4,
                103
            ],
            "redelm-pig/src/main/java/redelm/hadoop/RedelmFileWriter.java": [
                0,
                21
            ],
            "redelm-pig/src/main/java/redelm/hadoop/RedelmInputFormat.java": [
                7,
                10
            ],
            "redelm-pig/src/main/java/redelm/hadoop/RedelmOutputCommitter.java": [
                0,
                52
            ],
            "redelm-pig/src/main/java/redelm/hadoop/RedelmOutputFormat.java": [
                1,
                12
            ],
            "redelm-pig/src/main/java/redelm/hadoop/RedelmRecordReader.java": [
                2,
                12
            ],
            "redelm-pig/src/test/java/redelm/hadoop/TestRedelmFileWriter.java": [
                3,
                4
            ],
            "redelm-pig/src/test/java/redelm/pig/TestTupleRecordConsumer.java": [
                2,
                2
            ],
            "redelm-pig/src/test/java/redelm/pig/TupleConsumerPerfTest.java": [
                2,
                2
            ]
        }
    },
    "448e8c8d09c1b7a01185fa83526c071d2348c564": {
        "datetime": "2013-01-07T08:34:06-08:00",
        "summary": "Merge branch 'master' into FSA_codegen",
        "message": "Merge branch 'master' into FSA_codegen\n\nConflicts:\n\tredelm-column/src/test/java/redelm/io/PerfTest.java\n\tredelm-column/src/test/java/redelm/io/TestColumnIO.java\n\tredelm-pig/src/main/java/redelm/hadoop/RedelmRecordReader.java\n\tredelm-pig/src/test/java/redelm/pig/TestTupleRecordConsumer.java\n",
        "diff": {
            "redelm-column/pom.xml": null,
            "redelm-column/src/main/java/redelm/io/RecordConsumerWrapper.java": [
                3,
                3
            ],
            "redelm-column/src/main/java/redelm/io/RecordReaderImplementation.java": [
                1,
                1
            ],
            "redelm-column/src/test/java/redelm/io/PerfTest.java": [
                4,
                1
            ],
            "redelm-column/src/test/java/redelm/io/TestColumnIO.java": [
                3,
                4
            ],
            "redelm-pig/src/main/java/redelm/hadoop/RedelmRecordReader.java": [
                0,
                1
            ],
            "redelm-pig/src/test/java/redelm/hadoop/TestInputFormat.java": [
                1,
                0
            ],
            "redelm-pig/src/test/java/redelm/pig/TestTupleRecordConsumer.java": [
                0,
                1
            ],
            "redelm-pig/src/test/java/redelm/pig/TupleConsumerPerfTest.java": [
                79,
                4
            ]
        }
    },
    "faf756e88f6faef5526f8b2bf736ec0ba8d0b488": {
        "datetime": "2013-01-07T11:51:12-08:00",
        "summary": "fixed visibility",
        "message": "fixed visibility\n",
        "diff": {
            "redelm-column/src/main/java/redelm/io/RecordReaderCompiler.java": [
                1,
                1
            ]
        }
    },
    "758bb8bb614c5efbbdba87574d23918c93fe01fa": {
        "datetime": "2013-01-07T15:50:39-08:00",
        "summary": "Merge pull request #21 from julienledem/fix_schema_passing_when_multiple_stores",
        "message": "Merge pull request #21 from julienledem/fix_schema_passing_when_multiple_stores\n\nFix schema passing when multiple stores",
        "diff": {
            "redelm-pig/src/main/java/redelm/pig/RedelmStorer.java": [
                15,
                60
            ]
        }
    },
    "d71d754eee3773b072af89330b440bb8dbca01f8": {
        "datetime": "2013-01-07T15:59:57-08:00",
        "summary": "Make PigSchemaConverter Static",
        "message": "Make PigSchemaConverter Static\n",
        "diff": {
            "redelm-pig/src/main/java/redelm/pig/PigSchemaConverter.java": [
                9,
                10
            ],
            "redelm-pig/src/main/java/redelm/pig/RedelmLoader.java": [
                3,
                3
            ],
            "redelm-pig/src/main/java/redelm/pig/RedelmStorer.java": [
                4,
                4
            ],
            "redelm-pig/src/test/java/redelm/pig/TestPigSchemaConverter.java": [
                2,
                1
            ],
            "redelm-pig/src/test/java/redelm/pig/TestTupleRecordConsumer.java": [
                8,
                8
            ],
            "redelm-pig/src/test/java/redelm/pig/TupleConsumerPerfTest.java": [
                12,
                11
            ]
        }
    },
    "19106d078bf2ceaa5217c15fd08e777111f9ec40": {
        "datetime": "2013-01-07T16:13:27-08:00",
        "summary": "Fix merge conflict",
        "message": "Fix merge conflict\n",
        "diff": {
            "redelm-pig/src/main/java/redelm/pig/RedelmStorer.java": [
                15,
                60
            ]
        }
    },
    "676c471db22d895f08c04c240d3eb9616e48b0e2": {
        "datetime": "2013-01-07T17:59:19-08:00",
        "summary": "Make maps work with sigle column case",
        "message": "Make maps work with sigle column case\n",
        "diff": {
            "redelm-pig/src/main/java/redelm/pig/PigSchemaConverter.java": [
                2,
                46
            ],
            "redelm-pig/src/test/java/redelm/pig/TestPigSchemaConverter.java": [
                0,
                48
            ]
        }
    },
    "db75e0be88ce935f290b71ea6198c75c4a6a341a": {
        "datetime": "2013-01-07T21:38:15-08:00",
        "summary": "add missing base implementations",
        "message": "add missing base implementations\n",
        "diff": {
            "redelm-column/src/main/java/redelm/Log.java": [
                1,
                1
            ],
            "redelm-column/src/main/java/redelm/io/RecordReaderCompiler.java": [
                12,
                54
            ],
            "redelm-column/src/main/java/redelm/io/RecordReaderImplementation.java": [
                0,
                7
            ],
            "redelm-column/src/test/java/redelm/io/TestRecordReaderCompiler.java": [
                8,
                8
            ]
        }
    },
    "7aaf6f95908add6f9a0ef0f41290ed82fcee6b9b": {
        "datetime": "2013-01-07T21:44:13-08:00",
        "summary": "removed unecessary readOneRecord() method and commented out old code",
        "message": "removed unecessary readOneRecord() method and commented out old code\n",
        "diff": {
            "redelm-column/src/main/java/redelm/io/RecordReader.java": [
                14,
                9
            ],
            "redelm-column/src/test/java/redelm/io/PerfTest.java": [
                3,
                0
            ]
        }
    },
    "770cf4d97a1cc27f9f07171c3a99bfff547904e8": {
        "datetime": "2013-01-08T16:56:29-08:00",
        "summary": "more optimizations",
        "message": "more optimizations\n",
        "diff": {
            "redelm-column/src/main/java/redelm/Log.java": [
                1,
                1
            ],
            "redelm-column/src/main/java/redelm/io/RecordReaderCompiler.java": [
                113,
                208
            ],
            "redelm-column/src/main/java/redelm/io/RecordReaderImplementation.java": [
                29,
                36
            ],
            "redelm-column/src/test/java/redelm/io/PerfTest.java": [
                18,
                22
            ],
            "redelm-column/src/test/java/redelm/io/TestRecordReaderCompiler.java": [
                5,
                5
            ]
        }
    },
    "e5dec2bf0ca372aa7d4053482cf29c79ed23df7e": {
        "datetime": "2013-01-08T23:48:35-08:00",
        "summary": "optimizations;fix some bugs",
        "message": "optimizations;fix some bugs\n",
        "diff": {
            "redelm-column/src/main/java/redelm/column/mem/MemColumnReader.java": [
                2,
                4
            ],
            "redelm-column/src/main/java/redelm/io/RecordReaderCompiler.java": [
                17,
                20
            ],
            "redelm-column/src/main/java/redelm/io/RecordReaderImplementation.java": [
                4,
                14
            ],
            "redelm-column/src/test/java/redelm/io/PerfTest.java": [
                8,
                18
            ]
        }
    },
    "b896112db485fadc5ca86ee441c7357ed1ef3931": {
        "datetime": "2013-01-09T00:03:23-08:00",
        "summary": "trigger full gc before starting",
        "message": "trigger full gc before starting\n",
        "diff": {
            "redelm-column/src/test/java/redelm/io/PerfTest.java": [
                1,
                1
            ]
        }
    },
    "48d9105d1b5e845a1af037968c88dad6aa374b4c": {
        "datetime": "2013-01-09T09:57:47-08:00",
        "summary": "Revert PigSchemaConverter to static",
        "message": "Revert PigSchemaConverter to static\n",
        "diff": {
            "redelm-pig/src/main/java/redelm/pig/PigSchemaConverter.java": [
                10,
                9
            ],
            "redelm-pig/src/main/java/redelm/pig/RedelmLoader.java": [
                3,
                3
            ],
            "redelm-pig/src/main/java/redelm/pig/RedelmStorer.java": [
                4,
                4
            ],
            "redelm-pig/src/test/java/redelm/pig/TestPigSchemaConverter.java": [
                1,
                2
            ],
            "redelm-pig/src/test/java/redelm/pig/TestTupleRecordConsumer.java": [
                8,
                8
            ],
            "redelm-pig/src/test/java/redelm/pig/TupleConsumerPerfTest.java": [
                11,
                12
            ]
        }
    },
    "ba0f9adeafb5891b3235bf52d518693047e9ce9b": {
        "datetime": "2013-01-09T10:17:54-08:00",
        "summary": "Update gitignore",
        "message": "Update gitignore\n",
        "diff": {
            ".gitignore": null
        }
    },
    "d2025609870d1fb68c0e75ded650906dbde00c29": {
        "datetime": "2013-01-09T13:38:26-08:00",
        "summary": "Incorporate Julien's comments",
        "message": "Incorporate Julien's comments\n",
        "diff": {
            "redelm-pig/src/main/java/redelm/pig/PigSchemaConverter.java": [
                40,
                23
            ]
        }
    },
    "d18ec37597717e0d50fa1ffb9a57b5be3875ab7f": {
        "datetime": "2013-01-09T13:38:53-08:00",
        "summary": "Merge pull request #23 from jcoveney/fix_simple_maps",
        "message": "Merge pull request #23 from jcoveney/fix_simple_maps\n\nFix simple maps",
        "diff": {
            ".gitignore": null,
            "redelm-pig/src/main/java/redelm/pig/PigSchemaConverter.java": [
                19,
                46
            ],
            "redelm-pig/src/test/java/redelm/pig/TestPigSchemaConverter.java": [
                0,
                48
            ]
        }
    },
    "78cff39a42d414c1cd6b5b04cda6a92296b9f6fc": {
        "datetime": "2013-01-09T14:49:33-08:00",
        "summary": "Merge pull request #20 from julienledem/improve_record_consumer_interface",
        "message": "Merge pull request #20 from julienledem/improve_record_consumer_interface\n\nImprove record consumer interface",
        "diff": {
            "redelm-column/src/main/java/redelm/data/GroupRecordConsumer.java": [
                8,
                10
            ],
            "redelm-column/src/main/java/redelm/io/ColumnIO.java": [
                4,
                1
            ],
            "redelm-column/src/main/java/redelm/io/ColumnIOFactory.java": [
                10,
                15
            ],
            "redelm-column/src/main/java/redelm/io/GroupColumnIO.java": [
                12,
                3
            ],
            "redelm-column/src/main/java/redelm/io/MessageColumnIO.java": [
                21,
                58
            ],
            "redelm-column/src/main/java/redelm/io/PrimitiveColumnIO.java": [
                21,
                11
            ],
            "redelm-column/src/main/java/redelm/io/RecordMaterializer.java": [
                0,
                34
            ],
            "redelm-column/src/main/java/redelm/io/RecordReader.java": [
                69,
                153
            ],
            "redelm-column/src/test/java/redelm/io/PerfTest.java": [
                87,
                38
            ],
            "redelm-column/src/test/java/redelm/io/TestColumnIO.java": [
                20,
                31
            ],
            "redelm-pig/src/main/java/redelm/hadoop/Footer.java": [
                2,
                2
            ],
            "redelm-pig/src/main/java/redelm/hadoop/ReadSupport.java": [
                4,
                3
            ],
            "redelm-pig/src/main/java/redelm/hadoop/RedelmRecordReader.java": [
                24,
                8
            ],
            "redelm-pig/src/main/java/redelm/hadoop/RedelmRecordWriter.java": [
                2,
                2
            ],
            "redelm-pig/src/main/java/redelm/pig/TupleReadSupport.java": [
                3,
                3
            ],
            "redelm-pig/src/main/java/redelm/pig/TupleRecordConsumer.java": [
                8,
                10
            ],
            "redelm-pig/src/main/java/redelm/pig/converter/MessageConverter.java": [
                11,
                13
            ],
            "redelm-pig/src/test/java/redelm/hadoop/TestInputFormat.java": [
                1,
                2
            ],
            "redelm-pig/src/test/java/redelm/pig/TestTupleRecordConsumer.java": [
                14,
                13
            ],
            "redelm-pig/src/test/java/redelm/pig/TupleConsumerPerfTest.java": [
                77,
                26
            ]
        }
    },
    "cd7117b691ab04ce75b5ac0835ab278ae6bf7766": {
        "datetime": "2013-01-09T14:50:58-08:00",
        "summary": "some modification to understand better impact of gc",
        "message": "some modification to understand better impact of gc\n",
        "diff": {
            "redelm-column/src/test/java/redelm/io/PerfTest.java": [
                2,
                4
            ]
        }
    },
    "fd93ec2d73451333100e1f06714daf76945e38ab": {
        "datetime": "2013-01-09T15:52:43-08:00",
        "summary": "Merge branch 'master' into FSA_codegen",
        "message": "Merge branch 'master' into FSA_codegen\n\nConflicts:\n\tredelm-column/src/main/java/redelm/io/RecordReader.java\n\tredelm-column/src/test/java/redelm/io/PerfTest.java\n\tredelm-column/src/test/java/redelm/io/TestColumnIO.java\n\tredelm-pig/src/test/java/redelm/hadoop/TestInputFormat.java\n\tredelm-pig/src/test/java/redelm/pig/TestTupleRecordConsumer.java\n\tredelm-pig/src/test/java/redelm/pig/TupleConsumerPerfTest.java\n",
        "diff": {
            ".gitignore": null,
            "redelm-column/src/main/java/redelm/io/MessageColumnIO.java": [
                6,
                10
            ],
            "redelm-column/src/main/java/redelm/io/RecordReader.java": [
                0,
                0
            ],
            "redelm-column/src/main/java/redelm/io/RecordReaderImplementation.java": [
                16,
                9
            ],
            "redelm-column/src/test/java/redelm/io/PerfTest.java": [
                1,
                0
            ],
            "redelm-column/src/test/java/redelm/io/TestColumnIO.java": [
                1,
                0
            ],
            "redelm-pig/src/main/java/redelm/pig/PigSchemaConverter.java": [
                19,
                46
            ],
            "redelm-pig/src/test/java/redelm/pig/TestPigSchemaConverter.java": [
                0,
                48
            ],
            "redelm-pig/src/test/java/redelm/pig/TestTupleRecordConsumer.java": [
                1,
                0
            ],
            "redelm-pig/src/test/java/redelm/pig/TupleConsumerPerfTest.java": [
                2,
                22
            ]
        }
    },
    "d5ea0450fa81f6f5950d3924c5282d55ddace35b": {
        "datetime": "2013-01-09T16:01:18-08:00",
        "summary": "cleanup unused import",
        "message": "cleanup unused import\n",
        "diff": {
            "redelm-column/src/test/java/redelm/io/TestRecordReaderCompiler.java": [
                1,
                0
            ]
        }
    },
    "da4b03430c42cd6148006a1fa68b979f36d0789b": {
        "datetime": "2013-01-10T08:08:16-08:00",
        "summary": "add license headers",
        "message": "add license headers\n",
        "diff": {
            "redelm-column/src/main/java/redelm/io/RecordReader.java": [
                0,
                15
            ],
            "redelm-column/src/main/java/redelm/io/RecordReaderCompiler.java": [
                0,
                15
            ],
            "redelm-column/src/test/java/redelm/io/ExpectationValidatingRecordConsumer.java": [
                0,
                15
            ],
            "redelm-column/src/test/java/redelm/io/TestRecordReaderCompiler.java": [
                0,
                15
            ]
        }
    },
    "2a3d6af012ffcb649704e5d1b177322e261f5e05": {
        "datetime": "2013-01-10T08:19:38-08:00",
        "summary": "make BaseRecordReader its own class",
        "message": "make BaseRecordReader its own class\n",
        "diff": {
            "redelm-column/src/main/java/redelm/io/BaseRecordReader.java": [
                0,
                151
            ],
            "redelm-column/src/main/java/redelm/io/RecordReaderCompiler.java": [
                134,
                0
            ]
        }
    },
    "2883f89341e2d29b33fc1687d07d6f965eaee796": {
        "datetime": "2013-01-14T18:24:29-08:00",
        "summary": "merge both switch statements to optimize",
        "message": "merge both switch statements to optimize\n",
        "diff": {
            "redelm-column/src/main/java/redelm/io/RecordReaderCompiler.java": [
                46,
                26
            ],
            "redelm-column/src/main/java/redelm/io/RecordReaderImplementation.java": [
                14,
                30
            ]
        }
    },
    "b89750bfe652dd83c8feed49cb55e0e6b47c31dd": {
        "datetime": "2013-01-17T14:24:38-08:00",
        "summary": "some cleanup based on Jco's comments",
        "message": "some cleanup based on Jco's comments\n",
        "diff": {
            "redelm-column/src/main/java/redelm/column/mem/MemColumnReader.java": [
                6,
                3
            ],
            "redelm-column/src/main/java/redelm/io/BaseRecordReader.java": [
                1,
                1
            ],
            "redelm-column/src/main/java/redelm/io/RecordReaderCompiler.java": [
                17,
                43
            ],
            "redelm-column/src/main/java/redelm/io/RecordReaderImplementation.java": [
                7,
                30
            ],
            "redelm-column/src/test/java/redelm/io/PerfTest.java": [
                1,
                0
            ]
        }
    },
    "17271e7299de20b95b88140753b6e6685ecf7c6e": {
        "datetime": "2013-02-01T18:21:11-08:00",
        "summary": "initial integration with the new metadata",
        "message": "initial integration with the new metadata\n",
        "diff": {
            "redelm-column/src/main/java/redelm/Log.java": [
                1,
                1
            ],
            "redelm-column/src/main/java/redelm/bytes/BytesInput.java": [
                0,
                213
            ],
            "redelm-column/src/main/java/redelm/bytes/BytesUtils.java": [
                0,
                37
            ],
            "redelm-column/src/main/java/redelm/column/ColumnWriter.java": [
                9,
                3
            ],
            "redelm-column/src/main/java/redelm/column/ColumnsStore.java": [
                1,
                1
            ],
            "redelm-column/src/main/java/redelm/column/RedelmByteArrayOutputStream.java": [
                11,
                5
            ],
            "redelm-column/src/main/java/redelm/column/mem/MemColumn.java": [
                80,
                30
            ],
            "redelm-column/src/main/java/redelm/column/mem/MemColumnReader.java": [
                45,
                56
            ],
            "redelm-column/src/main/java/redelm/column/mem/MemColumnWriter.java": [
                40,
                41
            ],
            "redelm-column/src/main/java/redelm/column/mem/MemColumnsStore.java": [
                40,
                21
            ],
            "redelm-column/src/main/java/redelm/column/mem/MemPageReader.java": [
                0,
                52
            ],
            "redelm-column/src/main/java/redelm/column/mem/MemPageStore.java": [
                0,
                52
            ],
            "redelm-column/src/main/java/redelm/column/mem/MemPageWriter.java": [
                0,
                55
            ],
            "redelm-column/src/main/java/redelm/column/mem/Page.java": [
                0,
                51
            ],
            "redelm-column/src/main/java/redelm/column/mem/PageStore.java": [
                0,
                27
            ],
            "redelm-column/src/main/java/redelm/column/mem/PageWriter.java": [
                0,
                26
            ],
            "redelm-column/src/main/java/redelm/column/primitive/BitPacking.java": [
                0,
                615
            ],
            "redelm-column/src/main/java/redelm/column/primitive/BitReader.java": [
                3,
                6
            ],
            "redelm-column/src/main/java/redelm/column/primitive/BitWriter.java": [
                9,
                25
            ],
            "redelm-column/src/main/java/redelm/column/primitive/BoundedIntColumnReader.java": [
                8,
                15
            ],
            "redelm-column/src/main/java/redelm/column/primitive/BoundedIntColumnWriter.java": [
                17,
                17
            ],
            "redelm-column/src/main/java/redelm/column/primitive/DevNullColumnReader.java": [
                2,
                5
            ],
            "redelm-column/src/main/java/redelm/column/primitive/DevNullColumnWriter.java": [
                5,
                8
            ],
            "redelm-column/src/main/java/redelm/column/primitive/PrimitiveColumnReader.java": [
                2,
                10
            ],
            "redelm-column/src/main/java/redelm/column/primitive/PrimitiveColumnWriter.java": [
                4,
                3
            ],
            "redelm-column/src/main/java/redelm/column/primitive/SimplePrimitiveColumnReader.java": [
                2,
                14
            ],
            "redelm-column/src/main/java/redelm/column/primitive/SimplePrimitiveColumnWriter.java": [
                7,
                16
            ],
            "redelm-column/src/main/java/redelm/schema/GroupType.java": [
                0,
                15
            ],
            "redelm-column/src/main/java/redelm/schema/MessageType.java": [
                0,
                13
            ],
            "redelm-column/src/main/java/redelm/schema/PrimitiveType.java": [
                1,
                9
            ],
            "redelm-column/src/main/java/redelm/schema/Type.java": [
                0,
                4
            ],
            "redelm-column/src/test/java/redelm/bytes/TestBytesUtil.java": [
                0,
                54
            ],
            "redelm-column/src/test/java/redelm/column/mem/TestMemColumn.java": [
                22,
                86
            ],
            "redelm-column/src/test/java/redelm/column/mem/TestMemPageStore.java": [
                0,
                48
            ],
            "redelm-column/src/test/java/redelm/column/primitive/TestBitPacking.java": [
                0,
                215
            ],
            "redelm-column/src/test/java/redelm/column/primitive/TestBoundedColumns.java": [
                11,
                91
            ],
            "redelm-column/src/test/java/redelm/io/PerfTest.java": [
                2,
                2
            ],
            "redelm-column/src/test/java/redelm/io/TestColumnIO.java": [
                43,
                33
            ],
            "redelm-pig/pom.xml": null,
            "redelm-pig/src/main/java/redelm/hadoop/BlockData.java": [
                3,
                3
            ],
            "redelm-pig/src/main/java/redelm/hadoop/BlockMetaData.java": [
                49,
                33
            ],
            "redelm-pig/src/main/java/redelm/hadoop/CodecFactory.java": [
                0,
                52
            ],
            "redelm-pig/src/main/java/redelm/hadoop/ColumnMetaData.java": [
                264,
                0
            ],
            "redelm-pig/src/main/java/redelm/hadoop/Footer.java": [
                8,
                7
            ],
            "redelm-pig/src/main/java/redelm/hadoop/MetaDataBlock.java": [
                27,
                12
            ],
            "redelm-pig/src/main/java/redelm/hadoop/PageConsumer.java": [
                0,
                24
            ],
            "redelm-pig/src/main/java/redelm/hadoop/PrintFooter.java": [
                55,
                40
            ],
            "redelm-pig/src/main/java/redelm/hadoop/ReadSupport.java": [
                1,
                2
            ],
            "redelm-pig/src/main/java/redelm/hadoop/RedelmFileReader.java": [
                83,
                72
            ],
            "redelm-pig/src/main/java/redelm/hadoop/RedelmFileWriter.java": [
                136,
                72
            ],
            "redelm-pig/src/main/java/redelm/hadoop/RedelmInputFormat.java": [
                11,
                14
            ],
            "redelm-pig/src/main/java/redelm/hadoop/RedelmInputSplit.java": [
                1,
                2
            ],
            "redelm-pig/src/main/java/redelm/hadoop/RedelmMetaData.java": [
                60,
                16
            ],
            "redelm-pig/src/main/java/redelm/hadoop/RedelmOutputFormat.java": [
                11,
                10
            ],
            "redelm-pig/src/main/java/redelm/hadoop/RedelmRecordReader.java": [
                25,
                24
            ],
            "redelm-pig/src/main/java/redelm/hadoop/RedelmRecordWriter.java": [
                24,
                31
            ],
            "redelm-pig/src/main/java/redelm/hadoop/WriteSupport.java": [
                2,
                2
            ],
            "redelm-pig/src/main/java/redelm/hadoop/metadata/ColumnChunkMetaData.java": [
                0,
                138
            ],
            "redelm-pig/src/main/java/redelm/hadoop/metadata/ColumnMetaData.java": [
                0,
                37
            ],
            "redelm-pig/src/main/java/redelm/hadoop/metadata/CompressionCodecName.java": [
                0,
                69
            ],
            "redelm-pig/src/main/java/redelm/hadoop/metadata/FileMetaData.java": [
                0,
                49
            ],
            "redelm-pig/src/main/java/redelm/pig/PigMetaData.java": [
                11,
                6
            ],
            "redelm-pig/src/main/java/redelm/pig/RedelmStorer.java": [
                1,
                5
            ],
            "redelm-pig/src/main/java/redelm/pig/TupleReadSupport.java": [
                4,
                3
            ],
            "redelm-pig/src/main/java/redelm/pig/TupleWriteSupport.java": [
                2,
                3
            ],
            "redelm-pig/src/main/java/redelm/redfile/RedFileMetadataConverter.java": [
                0,
                220
            ],
            "redelm-pig/src/test/java/redelm/hadoop/TestInputFormat.java": [
                9,
                14
            ],
            "redelm-pig/src/test/java/redelm/hadoop/TestRedelmFileWriter.java": [
                82,
                95
            ],
            "redelm-pig/src/test/java/redelm/pig/TestTupleRecordConsumer.java": [
                4,
                6
            ],
            "redelm-pig/src/test/java/redelm/pig/TupleConsumerPerfTest.java": [
                9,
                13
            ],
            "redelm-pig/src/test/java/redelm/redfile/TestRedFileMetadataConverter.java": [
                0,
                44
            ]
        }
    },
    "f25dfdcc0302f29349e6ad85ea4341320268b86d": {
        "datetime": "2013-02-04T10:48:25-08:00",
        "summary": "fix row count per rowgroup persistence",
        "message": "fix row count per rowgroup persistence\n",
        "diff": {
            "redelm-pig/src/main/java/redelm/redfile/RedFileMetadataConverter.java": [
                2,
                3
            ]
        }
    },
    "8ec8a9dae12484273453a57defba7cac80b82f58": {
        "datetime": "2013-02-04T15:19:28-08:00",
        "summary": "fix storer problem with page storage",
        "message": "fix storer problem with page storage\n",
        "diff": {
            "redelm-column/src/main/java/redelm/column/mem/MemColumnReader.java": [
                0,
                9
            ],
            "redelm-column/src/main/java/redelm/column/mem/MemPageReader.java": [
                0,
                3
            ],
            "redelm-column/src/main/java/redelm/column/mem/MemPageStore.java": [
                1,
                4
            ],
            "redelm-column/src/main/java/redelm/column/mem/MemPageWriter.java": [
                0,
                3
            ],
            "redelm-pig/src/main/java/redelm/hadoop/RedelmFileReader.java": [
                1,
                4
            ],
            "redelm-pig/src/main/java/redelm/hadoop/RedelmRecordReader.java": [
                3,
                6
            ],
            "redelm-pig/src/test/java/redelm/pig/TestRedelmStorer.java": [
                2,
                3
            ]
        }
    },
    "d63ded4da366c4d81f5044c07f087ada719055f4": {
        "datetime": "2013-02-05T17:18:25-08:00",
        "summary": "remove string type; make schema in footer use object model; make ints little endian",
        "message": "remove string type; make schema in footer use object model; make ints little endian\n",
        "diff": {
            "redelm-column/src/main/java/redelm/Log.java": [
                1,
                1
            ],
            "redelm-column/src/main/java/redelm/bytes/BytesInput.java": [
                1,
                1
            ],
            "redelm-column/src/main/java/redelm/bytes/BytesUtils.java": [
                3,
                27
            ],
            "redelm-column/src/main/java/redelm/column/ColumnWriter.java": [
                1,
                1
            ],
            "redelm-column/src/main/java/redelm/column/mem/MemColumn.java": [
                2,
                2
            ],
            "redelm-column/src/main/java/redelm/column/mem/MemColumnWriter.java": [
                8,
                8
            ],
            "redelm-column/src/main/java/redelm/column/primitive/BoundedIntColumnReader.java": [
                1,
                1
            ],
            "redelm-column/src/main/java/redelm/data/Group.java": [
                1,
                1
            ],
            "redelm-column/src/main/java/redelm/data/GroupRecordConsumer.java": [
                5,
                5
            ],
            "redelm-column/src/main/java/redelm/data/simple/BinaryValue.java": [
                0,
                5
            ],
            "redelm-column/src/main/java/redelm/data/simple/SimpleGroup.java": [
                1,
                1
            ],
            "redelm-column/src/main/java/redelm/data/simple/StringValue.java": [
                3,
                5
            ],
            "redelm-column/src/main/java/redelm/data/simple/example/Paper.java": [
                5,
                5
            ],
            "redelm-column/src/main/java/redelm/io/MessageColumnIO.java": [
                9,
                9
            ],
            "redelm-column/src/main/java/redelm/io/RecordConsumer.java": [
                5,
                5
            ],
            "redelm-column/src/main/java/redelm/io/RecordConsumerLoggingWrapper.java": [
                8,
                8
            ],
            "redelm-column/src/main/java/redelm/io/ValidatingRecordConsumer.java": [
                8,
                8
            ],
            "redelm-column/src/main/java/redelm/schema/MessageType.java": [
                0,
                4
            ],
            "redelm-column/src/main/java/redelm/schema/PrimitiveType.java": [
                12,
                12
            ],
            "redelm-column/src/test/java/redelm/bytes/TestBytesUtil.java": [
                4,
                4
            ],
            "redelm-column/src/test/java/redelm/column/mem/TestMemColumn.java": [
                4,
                4
            ],
            "redelm-column/src/test/java/redelm/io/PerfTest.java": [
                1,
                1
            ],
            "redelm-column/src/test/java/redelm/io/TestColumnIO.java": [
                24,
                22
            ],
            "redelm-column/src/test/java/redelm/parser/TestRedelmParser.java": [
                12,
                11
            ],
            "redelm-pig/pom.xml": null,
            "redelm-pig/src/main/java/redelm/hadoop/RedelmFileReader.java": [
                16,
                20
            ],
            "redelm-pig/src/main/java/redelm/hadoop/RedelmFileWriter.java": [
                5,
                6
            ],
            "redelm-pig/src/main/java/redelm/hadoop/RedelmInputFormat.java": [
                5,
                5
            ],
            "redelm-pig/src/main/java/redelm/hadoop/RedelmInputSplit.java": [
                8,
                9
            ],
            "redelm-pig/src/main/java/redelm/hadoop/metadata/FileMetaData.java": [
                3,
                5
            ],
            "redelm-pig/src/main/java/redelm/pig/PigSchemaConverter.java": [
                2,
                2
            ],
            "redelm-pig/src/main/java/redelm/pig/TupleRecordConsumer.java": [
                5,
                5
            ],
            "redelm-pig/src/main/java/redelm/pig/TupleWriteSupport.java": [
                4,
                9
            ],
            "redelm-pig/src/main/java/redelm/pig/converter/MapKeyValueConverter.java": [
                1,
                7
            ],
            "redelm-pig/src/main/java/redelm/pig/converter/MessageConverter.java": [
                4,
                4
            ],
            "redelm-pig/src/main/java/redelm/pig/converter/TupleConverter.java": [
                1,
                17
            ],
            "redelm-pig/src/main/java/redelm/redfile/RedFileMetadataConverter.java": [
                12,
                123
            ],
            "redelm-pig/src/test/java/redelm/hadoop/TestInputFormat.java": [
                2,
                3
            ],
            "redelm-pig/src/test/java/redelm/hadoop/TestRedelmFileWriter.java": [
                1,
                1
            ],
            "redelm-pig/src/test/java/redelm/pig/TestPigSchemaConverter.java": [
                15,
                15
            ],
            "redelm-pig/src/test/java/redelm/redfile/TestRedFileMetadataConverter.java": [
                0,
                12
            ]
        }
    },
    "cd9e8fe1b7aa65b65f71b0b2c297c49e6ad45321": {
        "datetime": "2013-02-05T18:00:01-08:00",
        "summary": "integrate the schema change from children to parent",
        "message": "integrate the schema change from children to parent\n",
        "diff": {
            "redelm-column/src/main/java/redelm/schema/MessageType.java": [
                0,
                9
            ],
            "redelm-pig/src/main/java/redelm/redfile/RedFileMetadataConverter.java": [
                54,
                49
            ]
        }
    },
    "3043e759f82d447ffe236f07722ae9800259bdd9": {
        "datetime": "2013-02-06T16:59:21-08:00",
        "summary": "optimize buffer copy; revert parent",
        "message": "optimize buffer copy; revert parent\n",
        "diff": {
            "redelm-column/src/main/java/redelm/bytes/BytesInput.java": [
                2,
                12
            ],
            "redelm-pig/src/main/java/redelm/redfile/RedFileMetadataConverter.java": [
                47,
                52
            ]
        }
    },
    "2e09b42cbdbc2a4a903c7fdf4989b6635f4bc9eb": {
        "datetime": "2013-02-06T18:12:15-08:00",
        "summary": "cleanup string type",
        "message": "cleanup string type\n",
        "diff": {
            "redelm-column/src/main/java/redelm/column/ColumnWriter.java": [
                2,
                0
            ],
            "redelm-column/src/main/java/redelm/column/mem/MemColumn.java": [
                28,
                0
            ],
            "redelm-column/src/main/java/redelm/column/mem/MemColumnWriter.java": [
                9,
                0
            ],
            "redelm-column/src/main/java/redelm/column/primitive/DevNullColumnReader.java": [
                11,
                0
            ],
            "redelm-column/src/main/java/redelm/column/primitive/DevNullColumnWriter.java": [
                7,
                0
            ],
            "redelm-column/src/main/java/redelm/column/primitive/PrimitiveColumnReader.java": [
                4,
                0
            ],
            "redelm-column/src/main/java/redelm/column/primitive/PrimitiveColumnWriter.java": [
                4,
                0
            ],
            "redelm-column/src/main/java/redelm/column/primitive/SimplePrimitiveColumnReader.java": [
                23,
                0
            ],
            "redelm-column/src/main/java/redelm/column/primitive/SimplePrimitiveColumnWriter.java": [
                12,
                0
            ],
            "redelm-column/src/main/java/redelm/data/GroupRecordConsumer.java": [
                5,
                0
            ],
            "redelm-column/src/main/java/redelm/data/simple/BinaryValue.java": [
                0,
                5
            ],
            "redelm-column/src/main/java/redelm/data/simple/SimpleGroup.java": [
                1,
                1
            ],
            "redelm-column/src/main/java/redelm/data/simple/StringValue.java": [
                49,
                0
            ],
            "redelm-column/src/main/java/redelm/io/MessageColumnIO.java": [
                10,
                0
            ],
            "redelm-column/src/main/java/redelm/io/RecordConsumer.java": [
                6,
                0
            ],
            "redelm-column/src/main/java/redelm/io/RecordConsumerLoggingWrapper.java": [
                9,
                0
            ],
            "redelm-column/src/main/java/redelm/io/ValidatingRecordConsumer.java": [
                8,
                0
            ],
            "redelm-column/src/main/java/redelm/schema/PrimitiveType.java": [
                12,
                0
            ],
            "redelm-column/src/test/java/redelm/io/TestColumnIO.java": [
                10,
                0
            ],
            "redelm-pig/src/main/java/redelm/pig/TupleRecordConsumer.java": [
                5,
                0
            ],
            "redelm-pig/src/main/java/redelm/pig/converter/MessageConverter.java": [
                5,
                0
            ],
            "redelm-pig/src/main/java/redelm/redfile/RedFileMetadataConverter.java": [
                1,
                0
            ]
        }
    },
    "be0088631c6253e2f8ee7ba3715f3ea8d6dd001f": {
        "datetime": "2013-02-08T11:30:34-08:00",
        "summary": "better support for plain encoding",
        "message": "better support for plain encoding\n",
        "diff": {
            "redelm-column/src/main/java/redelm/bytes/BytesUtils.java": [
                0,
                23
            ],
            "redelm-column/src/main/java/redelm/bytes/LittleEndianDataInputStream.java": [
                0,
                400
            ],
            "redelm-column/src/main/java/redelm/bytes/LittleEndianDataOutputStream.java": [
                0,
                192
            ],
            "redelm-column/src/main/java/redelm/column/mem/MemColumnReader.java": [
                6,
                14
            ],
            "redelm-column/src/main/java/redelm/column/mem/MemColumnWriter.java": [
                2,
                10
            ],
            "redelm-column/src/main/java/redelm/column/primitive/BitPacking.java": [
                2,
                5
            ],
            "redelm-column/src/main/java/redelm/column/primitive/BitPackingColumnReader.java": [
                0,
                39
            ],
            "redelm-column/src/main/java/redelm/column/primitive/BitPackingColumnWriter.java": [
                0,
                58
            ],
            "redelm-column/src/main/java/redelm/column/primitive/BooleanPlainColumnReader.java": [
                0,
                53
            ],
            "redelm-column/src/main/java/redelm/column/primitive/BooleanPlainColumnWriter.java": [
                0,
                75
            ],
            "redelm-column/src/main/java/redelm/column/primitive/BoundedIntColumnReader.java": [
                1,
                1
            ],
            "redelm-column/src/main/java/redelm/column/primitive/DevNullColumnReader.java": [
                1,
                1
            ],
            "redelm-column/src/main/java/redelm/column/primitive/PrimitiveColumnReader.java": [
                1,
                1
            ],
            "redelm-column/src/main/java/redelm/column/primitive/SimplePrimitiveColumnReader.java": [
                17,
                6
            ],
            "redelm-column/src/main/java/redelm/column/primitive/SimplePrimitiveColumnWriter.java": [
                12,
                5
            ],
            "redelm-column/src/test/java/redelm/column/primitive/TestBitPacking.java": [
                4,
                2
            ],
            "redelm-column/src/test/java/redelm/column/primitive/TestBoundedColumns.java": [
                6,
                4
            ],
            "redelm-pig/src/main/java/redelm/hadoop/RedelmFileReader.java": [
                5,
                2
            ],
            "redelm-pig/src/main/java/redelm/redfile/RedFileMetadataConverter.java": [
                0,
                15
            ]
        }
    },
    "6cdf6aaabbc05e2b693dbb7a1688e908ffe98e09": {
        "datetime": "2013-02-08T11:31:02-08:00",
        "summary": "generator for the int_test_file",
        "message": "generator for the int_test_file\n",
        "diff": {
            "redelm-pig/src/test/java/redelm/pig/GenerateIntTestFile.java": [
                0,
                104
            ]
        }
    },
    "f3adb6e39ada1ee15879295d1379e890045d37f1": {
        "datetime": "2013-02-08T11:32:45-08:00",
        "summary": "renamed to Plain to match the Encoding name",
        "message": "renamed to Plain to match the Encoding name\n",
        "diff": {
            "redelm-column/src/main/java/redelm/column/mem/MemColumnReader.java": [
                3,
                3
            ],
            "redelm-column/src/main/java/redelm/column/mem/MemColumnWriter.java": [
                2,
                2
            ],
            "redelm-column/src/main/java/redelm/column/primitive/SimplePrimitiveColumnReader.java": [
                2,
                2
            ],
            "redelm-column/src/main/java/redelm/column/primitive/SimplePrimitiveColumnWriter.java": [
                3,
                3
            ]
        }
    },
    "781f40f97c09807ed21be2c00dbd708708d5ad43": {
        "datetime": "2013-02-08T11:37:07-08:00",
        "summary": "PLAIN encoding comformance",
        "message": "PLAIN encoding comformance\n",
        "diff": {
            "redelm-column/src/main/java/redelm/column/primitive/PlainColumnReader.java": [
                10,
                8
            ],
            "redelm-column/src/main/java/redelm/column/primitive/PlainColumnWriter.java": [
                11,
                3
            ]
        }
    },
    "1bd47c349d5416bd2fdfd62ad603ea581622de09": {
        "datetime": "2013-02-08T15:47:53-08:00",
        "summary": "generate TPCH customer",
        "message": "generate TPCH customer\n",
        "diff": {
            "redelm-column/src/main/java/redelm/Log.java": [
                1,
                13
            ],
            "redelm-column/src/main/java/redelm/bytes/BytesInput.java": [
                1,
                1
            ],
            "redelm-column/src/main/java/redelm/column/ColumnDescriptor.java": [
                4,
                4
            ],
            "redelm-column/src/main/java/redelm/data/simple/example/Paper.java": [
                2,
                2
            ],
            "redelm-column/src/main/java/redelm/io/MessageColumnIO.java": [
                2,
                2
            ],
            "redelm-column/src/main/java/redelm/io/PrimitiveColumnIO.java": [
                1,
                1
            ],
            "redelm-column/src/main/java/redelm/io/RecordReader.java": [
                4,
                4
            ],
            "redelm-column/src/main/java/redelm/io/ValidatingRecordConsumer.java": [
                9,
                9
            ],
            "redelm-column/src/main/java/redelm/parser/MessageTypeParser.java": [
                2,
                2
            ],
            "redelm-column/src/main/java/redelm/schema/MessageType.java": [
                3,
                3
            ],
            "redelm-column/src/main/java/redelm/schema/PrimitiveType.java": [
                6,
                6
            ],
            "redelm-column/src/test/java/redelm/column/mem/TestMemPageStore.java": [
                2,
                2
            ],
            "redelm-column/src/test/java/redelm/parser/TestRedelmParser.java": [
                2,
                2
            ],
            "redelm-pig/src/main/java/redelm/hadoop/RedelmFileReader.java": [
                1,
                3
            ],
            "redelm-pig/src/main/java/redelm/hadoop/RedelmFileWriter.java": [
                1,
                1
            ],
            "redelm-pig/src/main/java/redelm/hadoop/metadata/ColumnChunkMetaData.java": [
                4,
                4
            ],
            "redelm-pig/src/main/java/redelm/pig/PigSchemaConverter.java": [
                10,
                10
            ],
            "redelm-pig/src/main/java/redelm/pig/TupleWriteSupport.java": [
                2,
                2
            ],
            "redelm-pig/src/main/java/redelm/redfile/RedFileMetadataConverter.java": [
                11,
                11
            ],
            "redelm-pig/src/test/java/redelm/hadoop/TestInputFormat.java": [
                2,
                2
            ],
            "redelm-pig/src/test/java/redelm/pig/GenerateIntTestFile.java": [
                37,
                62
            ],
            "redelm-pig/src/test/java/redelm/pig/GenerateTPCH.java": [
                0,
                93
            ]
        }
    },
    "07d7aa0f26044e95cef3749454e6f16fcf6c2bf7": {
        "datetime": "2013-02-08T15:56:58-08:00",
        "summary": "change children_indices for children_count in schema representation",
        "message": "change children_indices for children_count in schema representation\n",
        "diff": {
            "redelm-pig/src/main/java/redelm/redfile/RedFileMetadataConverter.java": [
                13,
                11
            ]
        }
    },
    "867e24b84c57f768949aa385553c76f442993dda": {
        "datetime": "2013-02-08T16:06:09-08:00",
        "summary": "fix repetition for root",
        "message": "fix repetition for root\n",
        "diff": {
            "redelm-pig/src/main/java/redelm/redfile/RedFileMetadataConverter.java": [
                5,
                8
            ]
        }
    },
    "9c7e5f57e92419cc255e4597444afe7acb2c92aa": {
        "datetime": "2013-02-11T14:45:28-08:00",
        "summary": "add compression back; make page size configurable; rename children_count to num_children",
        "message": "add compression back; make page size configurable; rename children_count to num_children\n",
        "diff": {
            "redelm-column/src/main/java/redelm/Log.java": [
                1,
                1
            ],
            "redelm-pig/src/main/java/redelm/hadoop/CodecFactory.java": [
                0,
                5
            ],
            "redelm-pig/src/main/java/redelm/hadoop/RedelmFileWriter.java": [
                15,
                9
            ],
            "redelm-pig/src/main/java/redelm/hadoop/RedelmOutputFormat.java": [
                10,
                40
            ],
            "redelm-pig/src/main/java/redelm/hadoop/RedelmRecordWriter.java": [
                18,
                41
            ],
            "redelm-pig/src/main/java/redelm/hadoop/metadata/CompressionCodecName.java": [
                0,
                7
            ],
            "redelm-pig/src/main/java/redelm/redfile/RedFileMetadataConverter.java": [
                7,
                6
            ],
            "redelm-pig/src/test/java/redelm/hadoop/TestRedelmFileWriter.java": [
                12,
                7
            ],
            "redelm-pig/src/test/java/redelm/pig/GenerateIntTestFile.java": [
                1,
                1
            ]
        }
    },
    "18d5082bb927a3f55717a2ffeafa304e0d921386": {
        "datetime": "2013-02-11T16:59:03-08:00",
        "summary": "fix decompression",
        "message": "fix decompression\n",
        "diff": {
            "redelm-column/src/main/java/redelm/bytes/BytesInput.java": [
                7,
                3
            ],
            "redelm-column/src/main/java/redelm/column/mem/MemColumnReader.java": [
                2,
                2
            ],
            "redelm-column/src/main/java/redelm/column/mem/MemColumnWriter.java": [
                1,
                8
            ],
            "redelm-column/src/main/java/redelm/column/mem/MemPageWriter.java": [
                1,
                2
            ],
            "redelm-column/src/main/java/redelm/column/mem/PageWriter.java": [
                1,
                3
            ],
            "redelm-column/src/test/java/redelm/column/mem/TestMemPageStore.java": [
                1,
                3
            ],
            "redelm-pig/src/main/java/redelm/hadoop/PageConsumer.java": [
                1,
                1
            ],
            "redelm-pig/src/main/java/redelm/hadoop/RedelmFileReader.java": [
                1,
                20
            ],
            "redelm-pig/src/main/java/redelm/hadoop/RedelmOutputFormat.java": [
                2,
                3
            ],
            "redelm-pig/src/main/java/redelm/hadoop/RedelmRecordReader.java": [
                1,
                6
            ],
            "redelm-pig/src/main/java/redelm/hadoop/RedelmRecordWriter.java": [
                1,
                4
            ],
            "redelm-pig/src/main/java/redelm/hadoop/metadata/CompressionCodecName.java": [
                1,
                1
            ],
            "redelm-pig/src/test/java/redelm/hadoop/TestRedelmFileWriter.java": [
                10,
                15
            ],
            "redelm-pig/src/test/java/redelm/pig/GenerateIntTestFile.java": [
                1,
                5
            ],
            "redelm-pig/src/test/java/redelm/pig/TestRedelmStorer.java": [
                0,
                38
            ]
        }
    },
    "04b60eebb2be71b8253b011d64dbc0601ca85de3": {
        "datetime": "2013-02-12T11:45:50-08:00",
        "summary": "rework compression",
        "message": "rework compression\n",
        "diff": {
            "redelm-column/src/main/java/redelm/column/mem/MemColumn.java": [
                2,
                2
            ],
            "redelm-column/src/main/java/redelm/column/mem/MemColumnWriter.java": [
                3,
                3
            ],
            "redelm-column/src/main/java/redelm/column/mem/MemColumnsStore.java": [
                4,
                2
            ],
            "redelm-column/src/test/java/redelm/column/mem/TestMemColumn.java": [
                1,
                1
            ],
            "redelm-column/src/test/java/redelm/io/PerfTest.java": [
                1,
                1
            ],
            "redelm-column/src/test/java/redelm/io/TestColumnIO.java": [
                2,
                2
            ],
            "redelm-pig/src/main/java/redelm/hadoop/CodecFactory.java": [
                0,
                103
            ],
            "redelm-pig/src/main/java/redelm/hadoop/ColumnChunkPageStore.java": [
                0,
                96
            ],
            "redelm-pig/src/main/java/redelm/hadoop/PageConsumer.java": [
                2,
                2
            ],
            "redelm-pig/src/main/java/redelm/hadoop/RedelmFileReader.java": [
                22,
                26
            ],
            "redelm-pig/src/main/java/redelm/hadoop/RedelmFileWriter.java": [
                4,
                25
            ],
            "redelm-pig/src/main/java/redelm/hadoop/RedelmOutputFormat.java": [
                1,
                1
            ],
            "redelm-pig/src/main/java/redelm/hadoop/RedelmRecordReader.java": [
                4,
                4
            ],
            "redelm-pig/src/main/java/redelm/hadoop/RedelmRecordWriter.java": [
                36,
                11
            ],
            "redelm-pig/src/test/java/redelm/hadoop/TestRedelmFileWriter.java": [
                4,
                2
            ],
            "redelm-pig/src/test/java/redelm/pig/GenerateIntTestFile.java": [
                9,
                7
            ],
            "redelm-pig/src/test/java/redelm/pig/GenerateTPCH.java": [
                1,
                1
            ],
            "redelm-pig/src/test/java/redelm/pig/TestRedelmStorer.java": [
                4,
                8
            ],
            "redelm-pig/src/test/java/redelm/pig/TupleConsumerPerfTest.java": [
                1,
                1
            ]
        }
    },
    "d8a18ce3cf48509ffda49f4838603037118894ba": {
        "datetime": "2013-02-12T18:24:54-08:00",
        "summary": "fix PrintFooter; fix string encoding; rewrite split generation; fix block reading logic",
        "message": "fix PrintFooter; fix string encoding; rewrite split generation; fix block reading logic\n",
        "diff": {
            "redelm-pig/src/main/java/redelm/hadoop/PrintFooter.java": [
                62,
                110
            ],
            "redelm-pig/src/main/java/redelm/hadoop/RedelmFileReader.java": [
                2,
                2
            ],
            "redelm-pig/src/main/java/redelm/hadoop/RedelmFileWriter.java": [
                1,
                5
            ],
            "redelm-pig/src/main/java/redelm/hadoop/RedelmInputFormat.java": [
                22,
                45
            ],
            "redelm-pig/src/main/java/redelm/hadoop/RedelmRecordReader.java": [
                20,
                7
            ],
            "redelm-pig/src/main/java/redelm/hadoop/metadata/CompressionCodecName.java": [
                3,
                4
            ],
            "redelm-pig/src/main/java/redelm/pig/TupleWriteSupport.java": [
                1,
                1
            ],
            "redelm-pig/src/main/java/redelm/pig/converter/MessageConverter.java": [
                1,
                5
            ]
        }
    },
    "2ea29543f34e957cbdbee77ce1795c9ecf2150a3": {
        "datetime": "2013-02-13T15:18:38-08:00",
        "summary": "split stores",
        "message": "split stores\n",
        "diff": {
            "redelm-column/src/main/java/redelm/column/ColumnReadStore.java": [
                0,
                22
            ],
            "redelm-column/src/main/java/redelm/column/ColumnsStore.java": [
                3,
                1
            ],
            "redelm-column/src/main/java/redelm/column/mem/MemColumn.java": [
                27,
                10
            ],
            "redelm-column/src/main/java/redelm/column/mem/MemColumnsStore.java": [
                31,
                21
            ],
            "redelm-column/src/main/java/redelm/column/mem/MemPageStore.java": [
                1,
                1
            ],
            "redelm-column/src/main/java/redelm/column/mem/PageStore.java": [
                5,
                2
            ],
            "redelm-column/src/main/java/redelm/column/mem/PageWriteStore.java": [
                0,
                24
            ],
            "redelm-column/src/main/java/redelm/io/MessageColumnIO.java": [
                5,
                8
            ],
            "redelm-column/src/main/java/redelm/io/RecordReader.java": [
                3,
                4
            ],
            "redelm-column/src/test/java/redelm/column/mem/TestMemColumn.java": [
                12,
                12
            ],
            "redelm-column/src/test/java/redelm/io/PerfTest.java": [
                14,
                16
            ],
            "redelm-column/src/test/java/redelm/io/TestColumnIO.java": [
                14,
                15
            ],
            "redelm-pig/src/main/java/redelm/hadoop/ColumnChunkPageReadStore.java": [
                0,
                94
            ],
            "redelm-pig/src/main/java/redelm/hadoop/ColumnChunkPageStore.java": [
                19,
                8
            ],
            "redelm-pig/src/main/java/redelm/hadoop/RedelmRecordReader.java": [
                9,
                3
            ],
            "redelm-pig/src/main/java/redelm/hadoop/RedelmRecordWriter.java": [
                3,
                3
            ],
            "redelm-pig/src/test/java/redelm/pig/GenerateIntTestFile.java": [
                2,
                2
            ],
            "redelm-pig/src/test/java/redelm/pig/GenerateTPCH.java": [
                3,
                4
            ],
            "redelm-pig/src/test/java/redelm/pig/TupleConsumerPerfTest.java": [
                7,
                8
            ]
        }
    },
    "4b060586ee79815e4cec5923ec211db9dda3e8bb": {
        "datetime": "2013-02-14T08:26:24-08:00",
        "summary": "move compression to decode time and fix compressor init overhead",
        "message": "move compression to decode time and fix compressor init overhead\n",
        "diff": {
            "redelm-column/src/main/java/redelm/column/mem/MemPageReader.java": [
                3,
                3
            ],
            "redelm-column/src/main/java/redelm/column/mem/MemPageStore.java": [
                0,
                5
            ],
            "redelm-column/src/main/java/redelm/column/mem/MemPageWriter.java": [
                3,
                3
            ],
            "redelm-column/src/main/java/redelm/column/mem/Page.java": [
                1,
                7
            ],
            "redelm-column/src/main/java/redelm/column/mem/PageReadStore.java": [
                0,
                2
            ],
            "redelm-column/src/main/java/redelm/column/mem/PageReader.java": [
                1,
                1
            ],
            "redelm-column/src/test/java/redelm/column/mem/TestMemPageStore.java": [
                1,
                1
            ],
            "redelm-pig/src/main/java/redelm/hadoop/CodecFactory.java": [
                8,
                33
            ],
            "redelm-pig/src/main/java/redelm/hadoop/ColumnChunkPageReadStore.java": [
                47,
                38
            ],
            "redelm-pig/src/main/java/redelm/hadoop/ColumnChunkPageWriteStore.java": [
                2,
                9
            ],
            "redelm-pig/src/main/java/redelm/hadoop/RedelmFileReader.java": [
                30,
                29
            ],
            "redelm-pig/src/main/java/redelm/hadoop/RedelmFileWriter.java": [
                2,
                2
            ],
            "redelm-pig/src/main/java/redelm/hadoop/RedelmOutputFormat.java": [
                1,
                1
            ],
            "redelm-pig/src/main/java/redelm/hadoop/RedelmRecordReader.java": [
                30,
                21
            ],
            "redelm-pig/src/main/java/redelm/hadoop/RedelmRecordWriter.java": [
                27,
                4
            ],
            "redelm-pig/src/test/java/redelm/hadoop/TestRedelmFileWriter.java": [
                55,
                31
            ],
            "redelm-pig/src/test/java/redelm/pig/GenerateIntTestFile.java": [
                13,
                5
            ]
        }
    },
    "113f8b8509072ebf978cf3934ebafa2239503530": {
        "datetime": "2013-02-14T12:00:11-08:00",
        "summary": "reworked converter framework",
        "message": "reworked converter framework\n",
        "diff": {
            "redelm-column/src/main/java/redelm/bytes/BytesUtils.java": [
                0,
                3
            ],
            "redelm-column/src/main/java/redelm/io/convert/GroupConverter.java": [
                0,
                39
            ],
            "redelm-column/src/main/java/redelm/io/convert/PrimitiveConverter.java": [
                0,
                48
            ],
            "redelm-pig/src/main/java/redelm/pig/convert/MapConverter.java": [
                0,
                152
            ],
            "redelm-pig/src/main/java/redelm/pig/convert/TupleConverter.java": [
                0,
                223
            ]
        }
    },
    "372b9f3e6a61054528393bb4c4e7630fb17abeab": {
        "datetime": "2013-02-14T16:24:19-08:00",
        "summary": "fix projection using pig schema",
        "message": "fix projection using pig schema\n",
        "diff": {
            "redelm-column/src/main/java/redelm/io/MessageColumnIO.java": [
                1,
                1
            ],
            "redelm-column/src/main/java/redelm/schema/GroupType.java": [
                0,
                13
            ],
            "redelm-column/src/main/java/redelm/schema/MessageType.java": [
                0,
                8
            ],
            "redelm-column/src/main/java/redelm/schema/PrimitiveType.java": [
                0,
                13
            ],
            "redelm-column/src/main/java/redelm/schema/Type.java": [
                0,
                7
            ],
            "redelm-pig/src/main/java/redelm/hadoop/PrintFooter.java": [
                9,
                13
            ],
            "redelm-pig/src/main/java/redelm/hadoop/RedelmFileReader.java": [
                1,
                51
            ],
            "redelm-pig/src/main/java/redelm/hadoop/RedelmInputFormat.java": [
                3,
                12
            ],
            "redelm-pig/src/main/java/redelm/hadoop/RedelmRecordReader.java": [
                0,
                1
            ],
            "redelm-pig/src/main/java/redelm/pig/PigSchemaConverter.java": [
                14,
                95
            ],
            "redelm-pig/src/main/java/redelm/pig/TupleReadSupport.java": [
                5,
                9
            ],
            "redelm-pig/src/main/java/redelm/pig/converter/BagConverter.java": [
                0,
                9
            ],
            "redelm-pig/src/main/java/redelm/pig/converter/Converter.java": [
                0,
                8
            ],
            "redelm-pig/src/main/java/redelm/pig/converter/MapConverter.java": [
                0,
                7
            ],
            "redelm-pig/src/main/java/redelm/pig/converter/MapKeyValueConverter.java": [
                0,
                6
            ],
            "redelm-pig/src/main/java/redelm/pig/converter/MessageConverter.java": [
                0,
                1
            ],
            "redelm-pig/src/main/java/redelm/pig/converter/TupleConverter.java": [
                0,
                13
            ],
            "redelm-pig/src/test/java/redelm/pig/TestPigSchemaConverter.java": [
                0,
                3
            ]
        }
    },
    "b38de8abc55fb2ee9068760c38d7e0e809c1c8bd": {
        "datetime": "2013-02-19T07:57:17-08:00",
        "summary": "add allocated usage monitoring",
        "message": "add allocated usage monitoring\n",
        "diff": {
            "redelm-column/src/main/java/redelm/bytes/CapacityByteArrayOutputStream.java": [
                0,
                21
            ],
            "redelm-column/src/main/java/redelm/column/mem/MemColumnWriteStore.java": [
                2,
                11
            ],
            "redelm-column/src/main/java/redelm/column/mem/MemColumnWriter.java": [
                0,
                7
            ],
            "redelm-column/src/main/java/redelm/column/mem/MemPageWriter.java": [
                0,
                6
            ],
            "redelm-column/src/main/java/redelm/column/mem/PageWriter.java": [
                0,
                2
            ],
            "redelm-column/src/main/java/redelm/column/primitive/BitPackingColumnWriter.java": [
                3,
                8
            ],
            "redelm-column/src/main/java/redelm/column/primitive/BitWriter.java": [
                4,
                7
            ],
            "redelm-column/src/main/java/redelm/column/primitive/BooleanPlainColumnWriter.java": [
                2,
                8
            ],
            "redelm-column/src/main/java/redelm/column/primitive/BoundedIntColumnWriter.java": [
                0,
                5
            ],
            "redelm-column/src/main/java/redelm/column/primitive/DevNullColumnWriter.java": [
                0,
                5
            ],
            "redelm-column/src/main/java/redelm/column/primitive/PlainColumnWriter.java": [
                4,
                8
            ],
            "redelm-column/src/main/java/redelm/column/primitive/PrimitiveColumnWriter.java": [
                0,
                3
            ],
            "redelm-pig/src/main/java/redelm/hadoop/ColumnChunkPageWriteStore.java": [
                7,
                15
            ],
            "redelm-pig/src/main/java/redelm/hadoop/RedelmFileReader.java": [
                6,
                3
            ],
            "redelm-pig/src/main/java/redelm/hadoop/RedelmFileWriter.java": [
                2,
                2
            ],
            "redelm-pig/src/main/java/redelm/hadoop/RedelmRecordReader.java": [
                6,
                11
            ],
            "redelm-pig/src/main/java/redelm/hadoop/RedelmRecordWriter.java": [
                4,
                15
            ],
            "redelm-pig/src/main/java/redelm/pig/TupleReadSupport.java": [
                1,
                1
            ],
            "redelm-pig/src/main/java/redelm/pig/converter/TupleConverter.java": [
                1,
                2
            ],
            "redelm-pig/src/test/java/redelm/pig/GenerateIntTestFile.java": [
                2,
                0
            ]
        }
    },
    "a62af63205961bffb3d9559454b9c289808333e6": {
        "datetime": "2013-02-19T16:20:30-08:00",
        "summary": "fix bit packing",
        "message": "fix bit packing\n",
        "diff": {
            "redelm-column/src/main/java/redelm/column/primitive/BitPacking.java": [
                69,
                171
            ],
            "redelm-column/src/main/java/redelm/column/primitive/BitPackingColumnReader.java": [
                1,
                1
            ],
            "redelm-column/src/main/java/redelm/column/primitive/BooleanPlainColumnReader.java": [
                1,
                1
            ],
            "redelm-column/src/test/java/redelm/column/primitive/TestBitPacking.java": [
                7,
                7
            ],
            "redelm-column/src/test/java/redelm/column/primitive/TestBitPackingColumn.java": [
                0,
                159
            ]
        }
    },
    "15f6bebccc09b2af0908b34eb8769ddfd25b3795": {
        "datetime": "2013-02-19T17:17:18-08:00",
        "summary": "expose schema to pig",
        "message": "expose schema to pig\n",
        "diff": {
            "redelm-pig/src/main/java/redelm/hadoop/RedelmInputFormat.java": [
                6,
                13
            ],
            "redelm-pig/src/main/java/redelm/pig/RedelmLoader.java": [
                5,
                82
            ],
            "redelm-pig/src/test/java/redelm/pig/TestRedelmStorer.java": [
                1,
                3
            ]
        }
    },
    "1823220da70a749b88f97d7fc7f06eb7c1d67176": {
        "datetime": "2013-02-20T10:44:16-08:00",
        "summary": "rename the metadata package",
        "message": "rename the metadata package\n",
        "diff": {
            "redelm-pig/pom.xml": null,
            "redelm-pig/src/main/java/redelm/hadoop/ColumnChunkPageWriteStore.java": [
                4,
                4
            ],
            "redelm-pig/src/main/java/redelm/hadoop/RedelmFileReader.java": [
                3,
                3
            ],
            "redelm-pig/src/main/java/redelm/hadoop/RedelmFileWriter.java": [
                6,
                7
            ],
            "redelm-pig/src/main/java/redelm/hadoop/metadata/CompressionCodecName.java": [
                1,
                1
            ],
            "redelm-pig/src/main/java/redelm/redfile/RedFileMetadataConverter.java": [
                18,
                19
            ],
            "redelm-pig/src/test/java/redelm/redfile/TestRedFileMetadataConverter.java": [
                3,
                4
            ]
        }
    },
    "b598378e02af0d862bf27b985bc62ebd2d24b9e0": {
        "datetime": "2013-02-20T10:56:20-08:00",
        "summary": "removed reference to red file",
        "message": "removed reference to red file\n",
        "diff": {
            "redelm-pig/src/main/java/redelm/hadoop/ColumnChunkPageWriteStore.java": [
                3,
                3
            ],
            "redelm-pig/src/main/java/redelm/hadoop/RedelmFileReader.java": [
                7,
                7
            ],
            "redelm-pig/src/main/java/redelm/hadoop/RedelmFileWriter.java": [
                7,
                7
            ],
            "redelm-pig/src/main/java/redelm/hadoop/metadata/CompressionCodecName.java": [
                7,
                7
            ],
            "redelm-pig/src/main/java/redelm/redfile/RedFileMetadataConverter.java": [
                20,
                20
            ],
            "redelm-pig/src/test/java/redelm/redfile/TestRedFileMetadataConverter.java": [
                8,
                9
            ]
        }
    },
    "90f027efe123343a663e51e12d485ef7b302b093": {
        "datetime": "2013-02-20T11:04:53-08:00",
        "summary": "change magic number to PAR1",
        "message": "change magic number to PAR1\n",
        "diff": {
            "redelm-pig/src/main/java/redelm/hadoop/RedelmFileWriter.java": [
                2,
                2
            ]
        }
    },
    "e6ca25c0fec5fbf85a190092ea5094b0b10c0f13": {
        "datetime": "2013-02-20T11:10:11-08:00",
        "summary": "adding license header",
        "message": "adding license header\n",
        "diff": {
            "redelm-column/src/main/java/redelm/bytes/CapacityByteArrayOutputStream.java": [
                0,
                15
            ],
            "redelm-column/src/main/java/redelm/bytes/LittleEndianDataInputStream.java": [
                0,
                15
            ],
            "redelm-column/src/main/java/redelm/bytes/LittleEndianDataOutputStream.java": [
                0,
                15
            ],
            "redelm-column/src/main/java/redelm/column/primitive/BitPackingColumnReader.java": [
                0,
                15
            ],
            "redelm-column/src/main/java/redelm/column/primitive/BitPackingColumnWriter.java": [
                0,
                15
            ],
            "redelm-column/src/main/java/redelm/io/convert/GroupConverter.java": [
                0,
                15
            ],
            "redelm-column/src/main/java/redelm/io/convert/PrimitiveConverter.java": [
                0,
                15
            ],
            "redelm-column/src/test/java/redelm/column/primitive/TestBitPackingColumn.java": [
                0,
                15
            ],
            "redelm-pig/src/main/java/redelm/hadoop/ColumnChunkPageReadStore.java": [
                0,
                15
            ],
            "redelm-pig/src/main/java/redelm/hadoop/ColumnChunkPageWriteStore.java": [
                0,
                15
            ],
            "redelm-pig/src/main/java/redelm/pig/convert/MapConverter.java": [
                0,
                15
            ],
            "redelm-pig/src/main/java/redelm/pig/convert/TupleConverter.java": [
                0,
                15
            ],
            "redelm-pig/src/test/java/redelm/pig/GenerateIntTestFile.java": [
                0,
                15
            ],
            "redelm-pig/src/test/java/redelm/pig/GenerateTPCH.java": [
                0,
                15
            ]
        }
    },
    "08df187f82f3b3c0863c1bfb1096f0fb45ec599b": {
        "datetime": "2013-02-20T11:10:54-08:00",
        "summary": "Merge pull request #25 from julienledem/integrate_format_changes",
        "message": "Merge pull request #25 from julienledem/integrate_format_changes\n\nIntegrate format changes for Parquet",
        "diff": {
            "redelm-column/src/main/java/redelm/Log.java": [
                0,
                12
            ],
            "redelm-column/src/main/java/redelm/bytes/BytesInput.java": [
                0,
                219
            ],
            "redelm-column/src/main/java/redelm/bytes/BytesUtils.java": [
                0,
                87
            ],
            "redelm-column/src/main/java/redelm/bytes/LittleEndianDataInputStream.java": [
                0,
                415
            ],
            "redelm-column/src/main/java/redelm/bytes/LittleEndianDataOutputStream.java": [
                0,
                207
            ],
            "redelm-column/src/main/java/redelm/column/ColumnDescriptor.java": [
                4,
                4
            ],
            "redelm-column/src/main/java/redelm/column/ColumnReadStore.java": [
                0,
                22
            ],
            "redelm-column/src/main/java/redelm/column/ColumnWriter.java": [
                11,
                3
            ],
            "redelm-column/src/main/java/redelm/column/ColumnsStore.java": [
                4,
                2
            ],
            "redelm-column/src/main/java/redelm/column/RedelmByteArrayOutputStream.java": [
                7,
                13
            ],
            "redelm-column/src/main/java/redelm/column/mem/MemColumn.java": [
                299,
                0
            ],
            "redelm-column/src/main/java/redelm/column/mem/MemColumnReadStore.java": [
                0,
                204
            ],
            "redelm-column/src/main/java/redelm/column/mem/MemColumnReader.java": [
                46,
                74
            ],
            "redelm-column/src/main/java/redelm/column/mem/MemColumnWriteStore.java": [
                0,
                100
            ],
            "redelm-column/src/main/java/redelm/column/mem/MemColumnWriter.java": [
                47,
                61
            ],
            "redelm-column/src/main/java/redelm/column/mem/MemColumnsStore.java": [
                122,
                0
            ],
            "redelm-column/src/main/java/redelm/column/mem/MemPageReader.java": [
                0,
                55
            ],
            "redelm-column/src/main/java/redelm/column/mem/MemPageStore.java": [
                0,
                60
            ],
            "redelm-column/src/main/java/redelm/column/mem/MemPageWriter.java": [
                0,
                65
            ],
            "redelm-column/src/main/java/redelm/column/mem/Page.java": [
                0,
                57
            ],
            "redelm-column/src/main/java/redelm/column/mem/PageReadStore.java": [
                0,
                26
            ],
            "redelm-column/src/main/java/redelm/column/mem/PageReader.java": [
                0,
                24
            ],
            "redelm-column/src/main/java/redelm/column/mem/PageWriteStore.java": [
                0,
                24
            ],
            "redelm-column/src/main/java/redelm/column/mem/PageWriter.java": [
                0,
                30
            ],
            "redelm-column/src/main/java/redelm/column/primitive/BitPacking.java": [
                0,
                720
            ],
            "redelm-column/src/main/java/redelm/column/primitive/BitPackingColumnReader.java": [
                0,
                54
            ],
            "redelm-column/src/main/java/redelm/column/primitive/BitPackingColumnWriter.java": [
                0,
                78
            ],
            "redelm-column/src/main/java/redelm/column/primitive/BitReader.java": [
                3,
                6
            ],
            "redelm-column/src/main/java/redelm/column/primitive/BitWriter.java": [
                12,
                31
            ],
            "redelm-column/src/main/java/redelm/column/primitive/BooleanPlainColumnReader.java": [
                0,
                53
            ],
            "redelm-column/src/main/java/redelm/column/primitive/BooleanPlainColumnWriter.java": [
                0,
                81
            ],
            "redelm-column/src/main/java/redelm/column/primitive/BoundedIntColumnReader.java": [
                8,
                15
            ],
            "redelm-column/src/main/java/redelm/column/primitive/BoundedIntColumnWriter.java": [
                17,
                22
            ],
            "redelm-column/src/main/java/redelm/column/primitive/DevNullColumnReader.java": [
                11,
                3
            ],
            "redelm-column/src/main/java/redelm/column/primitive/DevNullColumnWriter.java": [
                9,
                10
            ],
            "redelm-column/src/main/java/redelm/column/primitive/PrimitiveColumnReader.java": [
                6,
                10
            ],
            "redelm-column/src/main/java/redelm/column/primitive/PrimitiveColumnWriter.java": [
                8,
                6
            ],
            "redelm-column/src/main/java/redelm/column/primitive/SimplePrimitiveColumnReader.java": [
                49,
                25
            ],
            "redelm-column/src/main/java/redelm/column/primitive/SimplePrimitiveColumnWriter.java": [
                40,
                26
            ],
            "redelm-column/src/main/java/redelm/data/Group.java": [
                1,
                1
            ],
            "redelm-column/src/main/java/redelm/data/GroupRecordConsumer.java": [
                5,
                0
            ],
            "redelm-column/src/main/java/redelm/data/simple/BinaryValue.java": [
                0,
                10
            ],
            "redelm-column/src/main/java/redelm/data/simple/SimpleGroup.java": [
                2,
                2
            ],
            "redelm-column/src/main/java/redelm/data/simple/StringValue.java": [
                22,
                12
            ],
            "redelm-column/src/main/java/redelm/data/simple/example/Paper.java": [
                6,
                6
            ],
            "redelm-column/src/main/java/redelm/io/MessageColumnIO.java": [
                16,
                9
            ],
            "redelm-column/src/main/java/redelm/io/PrimitiveColumnIO.java": [
                1,
                1
            ],
            "redelm-column/src/main/java/redelm/io/RecordConsumer.java": [
                6,
                0
            ],
            "redelm-column/src/main/java/redelm/io/RecordConsumerLoggingWrapper.java": [
                9,
                0
            ],
            "redelm-column/src/main/java/redelm/io/RecordReader.java": [
                7,
                8
            ],
            "redelm-column/src/main/java/redelm/io/ValidatingRecordConsumer.java": [
                17,
                9
            ],
            "redelm-column/src/main/java/redelm/io/convert/GroupConverter.java": [
                0,
                54
            ],
            "redelm-column/src/main/java/redelm/io/convert/PrimitiveConverter.java": [
                0,
                63
            ],
            "redelm-column/src/main/java/redelm/parser/MessageTypeParser.java": [
                2,
                2
            ],
            "redelm-column/src/main/java/redelm/schema/GroupType.java": [
                0,
                28
            ],
            "redelm-column/src/main/java/redelm/schema/MessageType.java": [
                2,
                36
            ],
            "redelm-column/src/main/java/redelm/schema/PrimitiveType.java": [
                19,
                28
            ],
            "redelm-column/src/main/java/redelm/schema/Type.java": [
                0,
                11
            ],
            "redelm-column/src/test/java/redelm/bytes/TestBytesUtil.java": [
                0,
                54
            ],
            "redelm-column/src/test/java/redelm/column/mem/TestMemColumn.java": [
                27,
                91
            ],
            "redelm-column/src/test/java/redelm/column/mem/TestMemPageStore.java": [
                0,
                50
            ],
            "redelm-column/src/test/java/redelm/column/primitive/TestBitPacking.java": [
                0,
                213
            ],
            "redelm-column/src/test/java/redelm/column/primitive/TestBitPackingColumn.java": [
                0,
                174
            ],
            "redelm-column/src/test/java/redelm/column/primitive/TestBoundedColumns.java": [
                13,
                91
            ],
            "redelm-column/src/test/java/redelm/io/PerfTest.java": [
                15,
                17
            ],
            "redelm-column/src/test/java/redelm/io/TestColumnIO.java": [
                79,
                58
            ],
            "redelm-column/src/test/java/redelm/parser/TestRedelmParser.java": [
                13,
                12
            ],
            "redelm-pig/pom.xml": null,
            "redelm-pig/src/main/java/redelm/format/converter/ParquetMetadataConverter.java": [
                0,
                347
            ],
            "redelm-pig/src/main/java/redelm/hadoop/BlockData.java": [
                3,
                3
            ],
            "redelm-pig/src/main/java/redelm/hadoop/BlockMetaData.java": [
                49,
                33
            ],
            "redelm-pig/src/main/java/redelm/hadoop/CodecFactory.java": [
                0,
                185
            ],
            "redelm-pig/src/main/java/redelm/hadoop/ColumnChunkPageReadStore.java": [
                0,
                100
            ],
            "redelm-pig/src/main/java/redelm/hadoop/ColumnChunkPageWriteStore.java": [
                0,
                115
            ],
            "redelm-pig/src/main/java/redelm/hadoop/ColumnMetaData.java": [
                264,
                0
            ],
            "redelm-pig/src/main/java/redelm/hadoop/Footer.java": [
                8,
                7
            ],
            "redelm-pig/src/main/java/redelm/hadoop/MetaDataBlock.java": [
                27,
                12
            ],
            "redelm-pig/src/main/java/redelm/hadoop/PageConsumer.java": [
                0,
                24
            ],
            "redelm-pig/src/main/java/redelm/hadoop/PrintFooter.java": [
                101,
                138
            ],
            "redelm-pig/src/main/java/redelm/hadoop/ReadSupport.java": [
                1,
                2
            ],
            "redelm-pig/src/main/java/redelm/hadoop/RedelmFileReader.java": [
                115,
                179
            ],
            "redelm-pig/src/main/java/redelm/hadoop/RedelmFileWriter.java": [
                148,
                105
            ],
            "redelm-pig/src/main/java/redelm/hadoop/RedelmInputFormat.java": [
                35,
                77
            ],
            "redelm-pig/src/main/java/redelm/hadoop/RedelmInputSplit.java": [
                9,
                11
            ],
            "redelm-pig/src/main/java/redelm/hadoop/RedelmMetaData.java": [
                60,
                16
            ],
            "redelm-pig/src/main/java/redelm/hadoop/RedelmOutputFormat.java": [
                20,
                50
            ],
            "redelm-pig/src/main/java/redelm/hadoop/RedelmRecordReader.java": [
                61,
                46
            ],
            "redelm-pig/src/main/java/redelm/hadoop/RedelmRecordWriter.java": [
                46,
                42
            ],
            "redelm-pig/src/main/java/redelm/hadoop/WriteSupport.java": [
                2,
                2
            ],
            "redelm-pig/src/main/java/redelm/hadoop/metadata/ColumnChunkMetaData.java": [
                0,
                138
            ],
            "redelm-pig/src/main/java/redelm/hadoop/metadata/CompressionCodecName.java": [
                0,
                77
            ],
            "redelm-pig/src/main/java/redelm/hadoop/metadata/FileMetaData.java": [
                0,
                51
            ],
            "redelm-pig/src/main/java/redelm/pig/PigMetaData.java": [
                11,
                6
            ],
            "redelm-pig/src/main/java/redelm/pig/PigSchemaConverter.java": [
                17,
                98
            ],
            "redelm-pig/src/main/java/redelm/pig/RedelmLoader.java": [
                5,
                82
            ],
            "redelm-pig/src/main/java/redelm/pig/RedelmStorer.java": [
                1,
                5
            ],
            "redelm-pig/src/main/java/redelm/pig/TupleReadSupport.java": [
                9,
                12
            ],
            "redelm-pig/src/main/java/redelm/pig/TupleRecordConsumer.java": [
                5,
                0
            ],
            "redelm-pig/src/main/java/redelm/pig/TupleWriteSupport.java": [
                8,
                14
            ],
            "redelm-pig/src/main/java/redelm/pig/convert/MapConverter.java": [
                0,
                167
            ],
            "redelm-pig/src/main/java/redelm/pig/convert/TupleConverter.java": [
                0,
                238
            ],
            "redelm-pig/src/main/java/redelm/pig/converter/BagConverter.java": [
                0,
                9
            ],
            "redelm-pig/src/main/java/redelm/pig/converter/Converter.java": [
                0,
                8
            ],
            "redelm-pig/src/main/java/redelm/pig/converter/MapConverter.java": [
                0,
                7
            ],
            "redelm-pig/src/main/java/redelm/pig/converter/MapKeyValueConverter.java": [
                1,
                13
            ],
            "redelm-pig/src/main/java/redelm/pig/converter/MessageConverter.java": [
                6,
                6
            ],
            "redelm-pig/src/main/java/redelm/pig/converter/TupleConverter.java": [
                1,
                31
            ],
            "redelm-pig/src/test/java/redelm/format/converter/TestParquetMetadataConverter.java": [
                0,
                58
            ],
            "redelm-pig/src/test/java/redelm/hadoop/TestInputFormat.java": [
                9,
                15
            ],
            "redelm-pig/src/test/java/redelm/hadoop/TestRedelmFileWriter.java": [
                83,
                70
            ],
            "redelm-pig/src/test/java/redelm/pig/GenerateIntTestFile.java": [
                0,
                136
            ],
            "redelm-pig/src/test/java/redelm/pig/GenerateTPCH.java": [
                0,
                109
            ],
            "redelm-pig/src/test/java/redelm/pig/TestPigSchemaConverter.java": [
                15,
                18
            ],
            "redelm-pig/src/test/java/redelm/pig/TestRedelmStorer.java": [
                4,
                49
            ],
            "redelm-pig/src/test/java/redelm/pig/TestTupleRecordConsumer.java": [
                4,
                6
            ],
            "redelm-pig/src/test/java/redelm/pig/TupleConsumerPerfTest.java": [
                15,
                20
            ]
        }
    },
    "951cd2f95aee57fff6ab84594669aad12e8f4e8e": {
        "datetime": "2013-02-20T12:01:44-08:00",
        "summary": "Merge branch 'master' into FSA_codegen",
        "message": "Merge branch 'master' into FSA_codegen\n\nConflicts:\n\tredelm-column/src/main/java/redelm/io/MessageColumnIO.java\n\tredelm-column/src/main/java/redelm/io/RecordReader.java\n\tredelm-column/src/main/java/redelm/schema/PrimitiveType.java\n\tredelm-column/src/test/java/redelm/io/PerfTest.java\n\tredelm-column/src/test/java/redelm/io/TestColumnIO.java\n\tredelm-pig/src/test/java/redelm/hadoop/TestInputFormat.java\n\tredelm-pig/src/test/java/redelm/pig/TupleConsumerPerfTest.java\n",
        "diff": {
            "redelm-column/src/main/java/redelm/Log.java": [
                0,
                12
            ],
            "redelm-column/src/main/java/redelm/bytes/BytesInput.java": [
                0,
                219
            ],
            "redelm-column/src/main/java/redelm/bytes/BytesUtils.java": [
                0,
                87
            ],
            "redelm-column/src/main/java/redelm/bytes/LittleEndianDataInputStream.java": [
                0,
                415
            ],
            "redelm-column/src/main/java/redelm/bytes/LittleEndianDataOutputStream.java": [
                0,
                207
            ],
            "redelm-column/src/main/java/redelm/column/ColumnDescriptor.java": [
                4,
                4
            ],
            "redelm-column/src/main/java/redelm/column/ColumnReadStore.java": [
                0,
                22
            ],
            "redelm-column/src/main/java/redelm/column/ColumnWriter.java": [
                11,
                3
            ],
            "redelm-column/src/main/java/redelm/column/ColumnsStore.java": [
                4,
                2
            ],
            "redelm-column/src/main/java/redelm/column/RedelmByteArrayOutputStream.java": [
                7,
                13
            ],
            "redelm-column/src/main/java/redelm/column/mem/MemColumn.java": [
                299,
                0
            ],
            "redelm-column/src/main/java/redelm/column/mem/MemColumnReadStore.java": [
                0,
                204
            ],
            "redelm-column/src/main/java/redelm/column/mem/MemColumnReader.java": [
                46,
                74
            ],
            "redelm-column/src/main/java/redelm/column/mem/MemColumnWriteStore.java": [
                0,
                100
            ],
            "redelm-column/src/main/java/redelm/column/mem/MemColumnWriter.java": [
                47,
                61
            ],
            "redelm-column/src/main/java/redelm/column/mem/MemColumnsStore.java": [
                122,
                0
            ],
            "redelm-column/src/main/java/redelm/column/mem/MemPageReader.java": [
                0,
                55
            ],
            "redelm-column/src/main/java/redelm/column/mem/MemPageStore.java": [
                0,
                60
            ],
            "redelm-column/src/main/java/redelm/column/mem/MemPageWriter.java": [
                0,
                65
            ],
            "redelm-column/src/main/java/redelm/column/mem/Page.java": [
                0,
                57
            ],
            "redelm-column/src/main/java/redelm/column/mem/PageReadStore.java": [
                0,
                26
            ],
            "redelm-column/src/main/java/redelm/column/mem/PageReader.java": [
                0,
                24
            ],
            "redelm-column/src/main/java/redelm/column/mem/PageWriteStore.java": [
                0,
                24
            ],
            "redelm-column/src/main/java/redelm/column/mem/PageWriter.java": [
                0,
                30
            ],
            "redelm-column/src/main/java/redelm/column/primitive/BitPacking.java": [
                0,
                720
            ],
            "redelm-column/src/main/java/redelm/column/primitive/BitPackingColumnReader.java": [
                0,
                54
            ],
            "redelm-column/src/main/java/redelm/column/primitive/BitPackingColumnWriter.java": [
                0,
                78
            ],
            "redelm-column/src/main/java/redelm/column/primitive/BitReader.java": [
                3,
                6
            ],
            "redelm-column/src/main/java/redelm/column/primitive/BitWriter.java": [
                12,
                31
            ],
            "redelm-column/src/main/java/redelm/column/primitive/BooleanPlainColumnReader.java": [
                0,
                53
            ],
            "redelm-column/src/main/java/redelm/column/primitive/BooleanPlainColumnWriter.java": [
                0,
                81
            ],
            "redelm-column/src/main/java/redelm/column/primitive/BoundedIntColumnReader.java": [
                8,
                15
            ],
            "redelm-column/src/main/java/redelm/column/primitive/BoundedIntColumnWriter.java": [
                17,
                22
            ],
            "redelm-column/src/main/java/redelm/column/primitive/DevNullColumnReader.java": [
                11,
                3
            ],
            "redelm-column/src/main/java/redelm/column/primitive/DevNullColumnWriter.java": [
                9,
                10
            ],
            "redelm-column/src/main/java/redelm/column/primitive/PrimitiveColumnReader.java": [
                6,
                10
            ],
            "redelm-column/src/main/java/redelm/column/primitive/PrimitiveColumnWriter.java": [
                8,
                6
            ],
            "redelm-column/src/main/java/redelm/column/primitive/SimplePrimitiveColumnReader.java": [
                49,
                25
            ],
            "redelm-column/src/main/java/redelm/column/primitive/SimplePrimitiveColumnWriter.java": [
                40,
                26
            ],
            "redelm-column/src/main/java/redelm/data/Group.java": [
                1,
                1
            ],
            "redelm-column/src/main/java/redelm/data/GroupRecordConsumer.java": [
                5,
                0
            ],
            "redelm-column/src/main/java/redelm/data/simple/BinaryValue.java": [
                0,
                10
            ],
            "redelm-column/src/main/java/redelm/data/simple/SimpleGroup.java": [
                2,
                2
            ],
            "redelm-column/src/main/java/redelm/data/simple/StringValue.java": [
                22,
                12
            ],
            "redelm-column/src/main/java/redelm/data/simple/example/Paper.java": [
                6,
                6
            ],
            "redelm-column/src/main/java/redelm/io/BaseRecordReader.java": [
                19,
                5
            ],
            "redelm-column/src/main/java/redelm/io/MessageColumnIO.java": [
                16,
                9
            ],
            "redelm-column/src/main/java/redelm/io/PrimitiveColumnIO.java": [
                4,
                4
            ],
            "redelm-column/src/main/java/redelm/io/RecordConsumer.java": [
                6,
                0
            ],
            "redelm-column/src/main/java/redelm/io/RecordConsumerLoggingWrapper.java": [
                9,
                0
            ],
            "redelm-column/src/main/java/redelm/io/RecordReader.java": [
                7,
                7
            ],
            "redelm-column/src/main/java/redelm/io/RecordReaderImplementation.java": [
                19,
                6
            ],
            "redelm-column/src/main/java/redelm/io/ValidatingRecordConsumer.java": [
                17,
                9
            ],
            "redelm-column/src/main/java/redelm/io/convert/GroupConverter.java": [
                0,
                54
            ],
            "redelm-column/src/main/java/redelm/io/convert/PrimitiveConverter.java": [
                0,
                63
            ],
            "redelm-column/src/main/java/redelm/parser/MessageTypeParser.java": [
                2,
                2
            ],
            "redelm-column/src/main/java/redelm/schema/GroupType.java": [
                0,
                28
            ],
            "redelm-column/src/main/java/redelm/schema/MessageType.java": [
                2,
                36
            ],
            "redelm-column/src/main/java/redelm/schema/PrimitiveType.java": [
                21,
                31
            ],
            "redelm-column/src/main/java/redelm/schema/Type.java": [
                0,
                11
            ],
            "redelm-column/src/test/java/redelm/bytes/TestBytesUtil.java": [
                0,
                54
            ],
            "redelm-column/src/test/java/redelm/column/mem/TestMemColumn.java": [
                27,
                91
            ],
            "redelm-column/src/test/java/redelm/column/mem/TestMemPageStore.java": [
                0,
                50
            ],
            "redelm-column/src/test/java/redelm/column/primitive/TestBitPacking.java": [
                0,
                213
            ],
            "redelm-column/src/test/java/redelm/column/primitive/TestBitPackingColumn.java": [
                0,
                174
            ],
            "redelm-column/src/test/java/redelm/column/primitive/TestBoundedColumns.java": [
                13,
                91
            ],
            "redelm-column/src/test/java/redelm/io/ExpectationValidatingRecordConsumer.java": [
                6,
                1
            ],
            "redelm-column/src/test/java/redelm/io/PerfTest.java": [
                21,
                27
            ],
            "redelm-column/src/test/java/redelm/io/TestColumnIO.java": [
                71,
                62
            ],
            "redelm-column/src/test/java/redelm/io/TestRecordReaderCompiler.java": [
                18,
                19
            ],
            "redelm-column/src/test/java/redelm/parser/TestRedelmParser.java": [
                13,
                12
            ],
            "redelm-pig/pom.xml": null,
            "redelm-pig/src/main/java/redelm/format/converter/ParquetMetadataConverter.java": [
                0,
                347
            ],
            "redelm-pig/src/main/java/redelm/hadoop/BlockData.java": [
                3,
                3
            ],
            "redelm-pig/src/main/java/redelm/hadoop/BlockMetaData.java": [
                49,
                33
            ],
            "redelm-pig/src/main/java/redelm/hadoop/CodecFactory.java": [
                0,
                185
            ],
            "redelm-pig/src/main/java/redelm/hadoop/ColumnChunkPageReadStore.java": [
                0,
                100
            ],
            "redelm-pig/src/main/java/redelm/hadoop/ColumnChunkPageWriteStore.java": [
                0,
                115
            ],
            "redelm-pig/src/main/java/redelm/hadoop/ColumnMetaData.java": [
                264,
                0
            ],
            "redelm-pig/src/main/java/redelm/hadoop/Footer.java": [
                8,
                7
            ],
            "redelm-pig/src/main/java/redelm/hadoop/MetaDataBlock.java": [
                27,
                12
            ],
            "redelm-pig/src/main/java/redelm/hadoop/PageConsumer.java": [
                0,
                24
            ],
            "redelm-pig/src/main/java/redelm/hadoop/PrintFooter.java": [
                101,
                138
            ],
            "redelm-pig/src/main/java/redelm/hadoop/ReadSupport.java": [
                1,
                2
            ],
            "redelm-pig/src/main/java/redelm/hadoop/RedelmFileReader.java": [
                115,
                179
            ],
            "redelm-pig/src/main/java/redelm/hadoop/RedelmFileWriter.java": [
                148,
                105
            ],
            "redelm-pig/src/main/java/redelm/hadoop/RedelmInputFormat.java": [
                35,
                77
            ],
            "redelm-pig/src/main/java/redelm/hadoop/RedelmInputSplit.java": [
                9,
                11
            ],
            "redelm-pig/src/main/java/redelm/hadoop/RedelmMetaData.java": [
                60,
                16
            ],
            "redelm-pig/src/main/java/redelm/hadoop/RedelmOutputFormat.java": [
                20,
                50
            ],
            "redelm-pig/src/main/java/redelm/hadoop/RedelmRecordReader.java": [
                61,
                46
            ],
            "redelm-pig/src/main/java/redelm/hadoop/RedelmRecordWriter.java": [
                46,
                42
            ],
            "redelm-pig/src/main/java/redelm/hadoop/WriteSupport.java": [
                2,
                2
            ],
            "redelm-pig/src/main/java/redelm/hadoop/metadata/ColumnChunkMetaData.java": [
                0,
                138
            ],
            "redelm-pig/src/main/java/redelm/hadoop/metadata/CompressionCodecName.java": [
                0,
                77
            ],
            "redelm-pig/src/main/java/redelm/hadoop/metadata/FileMetaData.java": [
                0,
                51
            ],
            "redelm-pig/src/main/java/redelm/pig/PigMetaData.java": [
                11,
                6
            ],
            "redelm-pig/src/main/java/redelm/pig/PigSchemaConverter.java": [
                17,
                98
            ],
            "redelm-pig/src/main/java/redelm/pig/RedelmLoader.java": [
                5,
                82
            ],
            "redelm-pig/src/main/java/redelm/pig/RedelmStorer.java": [
                1,
                5
            ],
            "redelm-pig/src/main/java/redelm/pig/TupleReadSupport.java": [
                9,
                12
            ],
            "redelm-pig/src/main/java/redelm/pig/TupleRecordConsumer.java": [
                5,
                0
            ],
            "redelm-pig/src/main/java/redelm/pig/TupleWriteSupport.java": [
                8,
                14
            ],
            "redelm-pig/src/main/java/redelm/pig/convert/MapConverter.java": [
                0,
                167
            ],
            "redelm-pig/src/main/java/redelm/pig/convert/TupleConverter.java": [
                0,
                238
            ],
            "redelm-pig/src/main/java/redelm/pig/converter/BagConverter.java": [
                0,
                9
            ],
            "redelm-pig/src/main/java/redelm/pig/converter/Converter.java": [
                0,
                8
            ],
            "redelm-pig/src/main/java/redelm/pig/converter/MapConverter.java": [
                0,
                7
            ],
            "redelm-pig/src/main/java/redelm/pig/converter/MapKeyValueConverter.java": [
                1,
                13
            ],
            "redelm-pig/src/main/java/redelm/pig/converter/MessageConverter.java": [
                6,
                6
            ],
            "redelm-pig/src/main/java/redelm/pig/converter/TupleConverter.java": [
                1,
                31
            ],
            "redelm-pig/src/test/java/redelm/format/converter/TestParquetMetadataConverter.java": [
                0,
                58
            ],
            "redelm-pig/src/test/java/redelm/hadoop/TestInputFormat.java": [
                8,
                15
            ],
            "redelm-pig/src/test/java/redelm/hadoop/TestRedelmFileWriter.java": [
                83,
                70
            ],
            "redelm-pig/src/test/java/redelm/pig/GenerateIntTestFile.java": [
                0,
                136
            ],
            "redelm-pig/src/test/java/redelm/pig/GenerateTPCH.java": [
                0,
                109
            ],
            "redelm-pig/src/test/java/redelm/pig/TestPigSchemaConverter.java": [
                15,
                18
            ],
            "redelm-pig/src/test/java/redelm/pig/TestRedelmStorer.java": [
                4,
                49
            ],
            "redelm-pig/src/test/java/redelm/pig/TestTupleRecordConsumer.java": [
                4,
                6
            ],
            "redelm-pig/src/test/java/redelm/pig/TupleConsumerPerfTest.java": [
                11,
                20
            ]
        }
    },
    "adcab26d8a80a6fcb6a069efa774b141e3eb19bf": {
        "datetime": "2013-02-20T12:06:16-08:00",
        "summary": "Merge pull request #24 from julienledem/FSA_codegen",
        "message": "Merge pull request #24 from julienledem/FSA_codegen\n\nFirst stab at doing codegen for the FSA",
        "diff": {
            "redelm-column/pom.xml": null,
            "redelm-column/src/main/java/redelm/column/mem/MemColumnReader.java": [
                0,
                2
            ],
            "redelm-column/src/main/java/redelm/io/BaseRecordReader.java": [
                0,
                137
            ],
            "redelm-column/src/main/java/redelm/io/ColumnIO.java": [
                0,
                8
            ],
            "redelm-column/src/main/java/redelm/io/MessageColumnIO.java": [
                1,
                1
            ],
            "redelm-column/src/main/java/redelm/io/PrimitiveColumnIO.java": [
                0,
                5
            ],
            "redelm-column/src/main/java/redelm/io/RecordReader.java": [
                274,
                2
            ],
            "redelm-column/src/main/java/redelm/io/RecordReaderCompiler.java": [
                0,
                273
            ],
            "redelm-column/src/main/java/redelm/io/RecordReaderImplementation.java": [
                0,
                508
            ],
            "redelm-column/src/main/java/redelm/schema/PrimitiveType.java": [
                6,
                16
            ],
            "redelm-column/src/test/java/redelm/io/ExpectationValidatingRecordConsumer.java": [
                0,
                101
            ],
            "redelm-column/src/test/java/redelm/io/PerfTest.java": [
                24,
                42
            ],
            "redelm-column/src/test/java/redelm/io/TestColumnIO.java": [
                138,
                73
            ],
            "redelm-column/src/test/java/redelm/io/TestRecordReaderCompiler.java": [
                0,
                73
            ],
            "redelm-pig/src/test/java/redelm/pig/TupleConsumerPerfTest.java": [
                1,
                4
            ]
        }
    },
    "33aad25b805a927f4ead3c7cbcfad39a518a87a0": {
        "datetime": "2013-02-20T12:16:33-08:00",
        "summary": "rename package to parquet",
        "message": "rename package to parquet\n",
        "diff": {
            "redelm-pig/src/main/java/redelm/format/converter/ParquetMetadataConverter.java": [
                6,
                6
            ],
            "redelm-pig/src/main/java/redelm/hadoop/BlockData.java": [
                1,
                1
            ],
            "redelm-pig/src/main/java/redelm/hadoop/CodecFactory.java": [
                2,
                3
            ],
            "redelm-pig/src/main/java/redelm/hadoop/ColumnChunkPageReadStore.java": [
                2,
                3
            ],
            "redelm-pig/src/main/java/redelm/hadoop/ColumnChunkPageWriteStore.java": [
                3,
                3
            ],
            "redelm-pig/src/main/java/redelm/hadoop/ColumnData.java": [
                1,
                1
            ],
            "redelm-pig/src/main/java/redelm/hadoop/Footer.java": [
                2,
                3
            ],
            "redelm-pig/src/main/java/redelm/hadoop/PageConsumer.java": [
                1,
                1
            ],
            "redelm-pig/src/main/java/redelm/hadoop/PrintFooter.java": [
                5,
                6
            ],
            "redelm-pig/src/main/java/redelm/hadoop/ReadSupport.java": [
                1,
                1
            ],
            "redelm-pig/src/main/java/redelm/hadoop/RedelmFileReader.java": [
                9,
                9
            ],
            "redelm-pig/src/main/java/redelm/hadoop/RedelmFileWriter.java": [
                7,
                7
            ],
            "redelm-pig/src/main/java/redelm/hadoop/RedelmInputFormat.java": [
                5,
                6
            ],
            "redelm-pig/src/main/java/redelm/hadoop/RedelmInputSplit.java": [
                3,
                4
            ],
            "redelm-pig/src/main/java/redelm/hadoop/RedelmOutputCommitter.java": [
                1,
                1
            ],
            "redelm-pig/src/main/java/redelm/hadoop/RedelmOutputFormat.java": [
                2,
                3
            ],
            "redelm-pig/src/main/java/redelm/hadoop/RedelmRecordReader.java": [
                3,
                4
            ],
            "redelm-pig/src/main/java/redelm/hadoop/RedelmRecordWriter.java": [
                2,
                3
            ],
            "redelm-pig/src/main/java/redelm/hadoop/WriteSupport.java": [
                1,
                1
            ],
            "redelm-pig/src/main/java/redelm/hadoop/metadata/BlockMetaData.java": [
                1,
                1
            ],
            "redelm-pig/src/main/java/redelm/hadoop/metadata/ColumnChunkMetaData.java": [
                1,
                1
            ],
            "redelm-pig/src/main/java/redelm/hadoop/metadata/ColumnMetaData.java": [
                1,
                1
            ],
            "redelm-pig/src/main/java/redelm/hadoop/metadata/CompressionCodecName.java": [
                1,
                1
            ],
            "redelm-pig/src/main/java/redelm/hadoop/metadata/FileMetaData.java": [
                1,
                1
            ],
            "redelm-pig/src/main/java/redelm/hadoop/metadata/RedelmMetaData.java": [
                1,
                1
            ],
            "redelm-pig/src/main/java/redelm/pig/PigMetaData.java": [
                1,
                1
            ],
            "redelm-pig/src/main/java/redelm/pig/PigSchemaConverter.java": [
                1,
                1
            ],
            "redelm-pig/src/main/java/redelm/pig/RedelmLoader.java": [
                4,
                5
            ],
            "redelm-pig/src/main/java/redelm/pig/RedelmStorer.java": [
                2,
                3
            ],
            "redelm-pig/src/main/java/redelm/pig/TupleConversionException.java": [
                1,
                1
            ],
            "redelm-pig/src/main/java/redelm/pig/TupleReadSupport.java": [
                3,
                4
            ],
            "redelm-pig/src/main/java/redelm/pig/TupleRecordConsumer.java": [
                1,
                1
            ],
            "redelm-pig/src/main/java/redelm/pig/TupleWriteSupport.java": [
                2,
                3
            ],
            "redelm-pig/src/main/java/redelm/pig/convert/MapConverter.java": [
                1,
                1
            ],
            "redelm-pig/src/main/java/redelm/pig/convert/TupleConverter.java": [
                2,
                3
            ],
            "redelm-pig/src/main/java/redelm/pig/converter/BagConverter.java": [
                2,
                3
            ],
            "redelm-pig/src/main/java/redelm/pig/converter/Converter.java": [
                1,
                1
            ],
            "redelm-pig/src/main/java/redelm/pig/converter/MapConverter.java": [
                2,
                3
            ],
            "redelm-pig/src/main/java/redelm/pig/converter/MapKeyValueConverter.java": [
                1,
                1
            ],
            "redelm-pig/src/main/java/redelm/pig/converter/MessageConverter.java": [
                1,
                1
            ],
            "redelm-pig/src/main/java/redelm/pig/converter/TupleConverter.java": [
                2,
                3
            ],
            "redelm-pig/src/main/java/redelm/pig/summary/BagSummaryData.java": [
                1,
                1
            ],
            "redelm-pig/src/main/java/redelm/pig/summary/EnumStat.java": [
                1,
                1
            ],
            "redelm-pig/src/main/java/redelm/pig/summary/FieldSummaryData.java": [
                1,
                1
            ],
            "redelm-pig/src/main/java/redelm/pig/summary/MapSummaryData.java": [
                1,
                1
            ],
            "redelm-pig/src/main/java/redelm/pig/summary/NumberSummaryData.java": [
                1,
                1
            ],
            "redelm-pig/src/main/java/redelm/pig/summary/StringSummaryData.java": [
                2,
                3
            ],
            "redelm-pig/src/main/java/redelm/pig/summary/Summary.java": [
                1,
                1
            ],
            "redelm-pig/src/main/java/redelm/pig/summary/SummaryData.java": [
                1,
                1
            ],
            "redelm-pig/src/main/java/redelm/pig/summary/TupleSummaryData.java": [
                1,
                1
            ],
            "redelm-pig/src/main/java/redelm/pig/summary/ValueStat.java": [
                1,
                1
            ],
            "redelm-pig/src/test/java/redelm/format/converter/TestParquetMetadataConverter.java": [
                2,
                2
            ],
            "redelm-pig/src/test/java/redelm/hadoop/TestInputFormat.java": [
                5,
                9
            ],
            "redelm-pig/src/test/java/redelm/hadoop/TestRedelmFileWriter.java": [
                3,
                7
            ],
            "redelm-pig/src/test/java/redelm/pig/GenerateIntTestFile.java": [
                5,
                6
            ],
            "redelm-pig/src/test/java/redelm/pig/GenerateTPCH.java": [
                3,
                3
            ],
            "redelm-pig/src/test/java/redelm/pig/PerfTest.java": [
                1,
                4
            ],
            "redelm-pig/src/test/java/redelm/pig/PerfTest2.java": [
                1,
                4
            ],
            "redelm-pig/src/test/java/redelm/pig/PerfTestReadAllCols.java": [
                1,
                1
            ],
            "redelm-pig/src/test/java/redelm/pig/TestPigSchemaConverter.java": [
                1,
                3
            ],
            "redelm-pig/src/test/java/redelm/pig/TestRedelmStorer.java": [
                1,
                4
            ],
            "redelm-pig/src/test/java/redelm/pig/TestTupleRecordConsumer.java": [
                1,
                6
            ],
            "redelm-pig/src/test/java/redelm/pig/TupleConsumerPerfTest.java": [
                1,
                6
            ],
            "redelm-pig/src/test/java/redelm/pig/summary/TestSummary.java": [
                1,
                6
            ]
        }
    },
    "73f69973d78bf1fae7c1aad661421b8bc955d20f": {
        "datetime": "2013-02-20T12:21:09-08:00",
        "summary": "rename package to parquet",
        "message": "rename package to parquet\n",
        "diff": {
            "redelm-column/src/main/java/redelm/Log.java": [
                1,
                1
            ],
            "redelm-column/src/main/java/redelm/RedelmRuntimeException.java": [
                1,
                1
            ],
            "redelm-column/src/main/java/redelm/bytes/BytesInput.java": [
                2,
                3
            ],
            "redelm-column/src/main/java/redelm/bytes/BytesUtils.java": [
                2,
                3
            ],
            "redelm-column/src/main/java/redelm/bytes/CapacityByteArrayOutputStream.java": [
                1,
                1
            ],
            "redelm-column/src/main/java/redelm/bytes/LittleEndianDataInputStream.java": [
                1,
                1
            ],
            "redelm-column/src/main/java/redelm/bytes/LittleEndianDataOutputStream.java": [
                1,
                1
            ],
            "redelm-column/src/main/java/redelm/column/ColumnDescriptor.java": [
                2,
                3
            ],
            "redelm-column/src/main/java/redelm/column/ColumnReadStore.java": [
                1,
                1
            ],
            "redelm-column/src/main/java/redelm/column/ColumnReader.java": [
                1,
                1
            ],
            "redelm-column/src/main/java/redelm/column/ColumnWriteStore.java": [
                1,
                1
            ],
            "redelm-column/src/main/java/redelm/column/ColumnWriter.java": [
                1,
                1
            ],
            "redelm-column/src/main/java/redelm/column/UnknownColumnException.java": [
                2,
                2
            ],
            "redelm-column/src/main/java/redelm/column/mem/MemColumnReadStore.java": [
                4,
                5
            ],
            "redelm-column/src/main/java/redelm/column/mem/MemColumnReader.java": [
                13,
                14
            ],
            "redelm-column/src/main/java/redelm/column/mem/MemColumnWriteStore.java": [
                4,
                5
            ],
            "redelm-column/src/main/java/redelm/column/mem/MemColumnWriter.java": [
                11,
                12
            ],
            "redelm-column/src/main/java/redelm/column/mem/MemPageReader.java": [
                3,
                4
            ],
            "redelm-column/src/main/java/redelm/column/mem/MemPageStore.java": [
                4,
                5
            ],
            "redelm-column/src/main/java/redelm/column/mem/MemPageWriter.java": [
                4,
                5
            ],
            "redelm-column/src/main/java/redelm/column/mem/Page.java": [
                3,
                3
            ],
            "redelm-column/src/main/java/redelm/column/mem/PageReadStore.java": [
                2,
                2
            ],
            "redelm-column/src/main/java/redelm/column/mem/PageReader.java": [
                1,
                1
            ],
            "redelm-column/src/main/java/redelm/column/mem/PageWriteStore.java": [
                2,
                2
            ],
            "redelm-column/src/main/java/redelm/column/mem/PageWriter.java": [
                2,
                3
            ],
            "redelm-column/src/main/java/redelm/column/primitive/BitPacking.java": [
                3,
                4
            ],
            "redelm-column/src/main/java/redelm/column/primitive/BitPackingColumnReader.java": [
                4,
                5
            ],
            "redelm-column/src/main/java/redelm/column/primitive/BitPackingColumnWriter.java": [
                6,
                7
            ],
            "redelm-column/src/main/java/redelm/column/primitive/BitReader.java": [
                1,
                1
            ],
            "redelm-column/src/main/java/redelm/column/primitive/BitWriter.java": [
                3,
                3
            ],
            "redelm-column/src/main/java/redelm/column/primitive/BooleanPlainColumnReader.java": [
                6,
                7
            ],
            "redelm-column/src/main/java/redelm/column/primitive/BooleanPlainColumnWriter.java": [
                6,
                7
            ],
            "redelm-column/src/main/java/redelm/column/primitive/BoundedColumnFactory.java": [
                1,
                1
            ],
            "redelm-column/src/main/java/redelm/column/primitive/BoundedIntColumnReader.java": [
                4,
                5
            ],
            "redelm-column/src/main/java/redelm/column/primitive/BoundedIntColumnWriter.java": [
                3,
                3
            ],
            "redelm-column/src/main/java/redelm/column/primitive/DevNullColumnReader.java": [
                1,
                1
            ],
            "redelm-column/src/main/java/redelm/column/primitive/DevNullColumnWriter.java": [
                2,
                2
            ],
            "redelm-column/src/main/java/redelm/column/primitive/PlainColumnReader.java": [
                6,
                7
            ],
            "redelm-column/src/main/java/redelm/column/primitive/PlainColumnWriter.java": [
                5,
                6
            ],
            "redelm-column/src/main/java/redelm/column/primitive/PrimitiveColumnReader.java": [
                1,
                1
            ],
            "redelm-column/src/main/java/redelm/column/primitive/PrimitiveColumnWriter.java": [
                2,
                2
            ],
            "redelm-column/src/main/java/redelm/data/Group.java": [
                3,
                3
            ],
            "redelm-column/src/main/java/redelm/data/GroupFactory.java": [
                1,
                1
            ],
            "redelm-column/src/main/java/redelm/data/GroupRecordConsumer.java": [
                3,
                4
            ],
            "redelm-column/src/main/java/redelm/data/GroupValueSource.java": [
                2,
                2
            ],
            "redelm-column/src/main/java/redelm/data/GroupWriter.java": [
                4,
                4
            ],
            "redelm-column/src/main/java/redelm/data/simple/BinaryValue.java": [
                2,
                2
            ],
            "redelm-column/src/main/java/redelm/data/simple/BooleanValue.java": [
                2,
                2
            ],
            "redelm-column/src/main/java/redelm/data/simple/DoubleValue.java": [
                2,
                2
            ],
            "redelm-column/src/main/java/redelm/data/simple/FloatValue.java": [
                2,
                2
            ],
            "redelm-column/src/main/java/redelm/data/simple/IntegerValue.java": [
                2,
                2
            ],
            "redelm-column/src/main/java/redelm/data/simple/LongValue.java": [
                2,
                2
            ],
            "redelm-column/src/main/java/redelm/data/simple/Primitive.java": [
                2,
                2
            ],
            "redelm-column/src/main/java/redelm/data/simple/SimpleGroup.java": [
                5,
                6
            ],
            "redelm-column/src/main/java/redelm/data/simple/SimpleGroupFactory.java": [
                4,
                4
            ],
            "redelm-column/src/main/java/redelm/data/simple/example/Paper.java": [
                11,
                11
            ],
            "redelm-column/src/main/java/redelm/io/BaseRecordReader.java": [
                5,
                5
            ],
            "redelm-column/src/main/java/redelm/io/ColumnIO.java": [
                4,
                5
            ],
            "redelm-column/src/main/java/redelm/io/ColumnIOFactory.java": [
                7,
                8
            ],
            "redelm-column/src/main/java/redelm/io/GroupColumnIO.java": [
                5,
                6
            ],
            "redelm-column/src/main/java/redelm/io/InvalidRecordException.java": [
                2,
                2
            ],
            "redelm-column/src/main/java/redelm/io/MessageColumnIO.java": [
                8,
                9
            ],
            "redelm-column/src/main/java/redelm/io/PrimitiveColumnIO.java": [
                4,
                5
            ],
            "redelm-column/src/main/java/redelm/io/RecordConsumer.java": [
                1,
                1
            ],
            "redelm-column/src/main/java/redelm/io/RecordConsumerLoggingWrapper.java": [
                2,
                2
            ],
            "redelm-column/src/main/java/redelm/io/RecordMaterializer.java": [
                1,
                1
            ],
            "redelm-column/src/main/java/redelm/io/RecordReader.java": [
                1,
                1
            ],
            "redelm-column/src/main/java/redelm/io/RecordReaderCompiler.java": [
                5,
                6
            ],
            "redelm-column/src/main/java/redelm/io/RecordReaderImplementation.java": [
                7,
                8
            ],
            "redelm-column/src/main/java/redelm/io/ValidatingRecordConsumer.java": [
                6,
                7
            ],
            "redelm-column/src/main/java/redelm/io/convert/GroupConverter.java": [
                1,
                1
            ],
            "redelm-column/src/main/java/redelm/io/convert/PrimitiveConverter.java": [
                1,
                1
            ],
            "redelm-column/src/main/java/redelm/parser/MessageTypeParser.java": [
                8,
                9
            ],
            "redelm-column/src/main/java/redelm/schema/GroupType.java": [
                1,
                1
            ],
            "redelm-column/src/main/java/redelm/schema/MessageType.java": [
                3,
                4
            ],
            "redelm-column/src/main/java/redelm/schema/PrimitiveType.java": [
                3,
                4
            ],
            "redelm-column/src/main/java/redelm/schema/Type.java": [
                1,
                1
            ],
            "redelm-column/src/main/java/redelm/schema/TypeVisitor.java": [
                1,
                1
            ],
            "redelm-column/src/main/java/redelm/utils/Varint.java": [
                1,
                1
            ],
            "redelm-column/src/test/java/redelm/bytes/TestBytesUtil.java": [
                1,
                3
            ],
            "redelm-column/src/test/java/redelm/column/mem/TestMemColumn.java": [
                7,
                11
            ],
            "redelm-column/src/test/java/redelm/column/mem/TestMemPageStore.java": [
                4,
                9
            ],
            "redelm-column/src/test/java/redelm/column/primitive/TestBitPacking.java": [
                3,
                5
            ],
            "redelm-column/src/test/java/redelm/column/primitive/TestBitPackingColumn.java": [
                1,
                4
            ],
            "redelm-column/src/test/java/redelm/column/primitive/TestBoundedColumns.java": [
                1,
                4
            ],
            "redelm-column/src/test/java/redelm/io/ExpectationValidatingRecordConsumer.java": [
                1,
                3
            ],
            "redelm-column/src/test/java/redelm/io/PerfTest.java": [
                12,
                19
            ],
            "redelm-column/src/test/java/redelm/io/TestColumnIO.java": [
                22,
                30
            ],
            "redelm-column/src/test/java/redelm/io/TestRecordReaderCompiler.java": [
                7,
                13
            ],
            "redelm-column/src/test/java/redelm/parser/TestRedelmParser.java": [
                9,
                11
            ],
            "redelm-column/src/test/java/redelm/schema/TestMessageType.java": [
                3,
                5
            ],
            "redelm-pig/src/main/java/parquet/format/converter/ParquetMetadataConverter.java": [
                10,
                10
            ],
            "redelm-pig/src/main/java/parquet/hadoop/CodecFactory.java": [
                1,
                1
            ],
            "redelm-pig/src/main/java/parquet/hadoop/ColumnChunkPageReadStore.java": [
                5,
                5
            ],
            "redelm-pig/src/main/java/parquet/hadoop/ColumnChunkPageWriteStore.java": [
                6,
                6
            ],
            "redelm-pig/src/main/java/parquet/hadoop/PageConsumer.java": [
                1,
                1
            ],
            "redelm-pig/src/main/java/parquet/hadoop/PrintFooter.java": [
                2,
                2
            ],
            "redelm-pig/src/main/java/parquet/hadoop/ReadSupport.java": [
                1,
                2
            ],
            "redelm-pig/src/main/java/parquet/hadoop/RedelmFileReader.java": [
                7,
                7
            ],
            "redelm-pig/src/main/java/parquet/hadoop/RedelmFileWriter.java": [
                7,
                7
            ],
            "redelm-pig/src/main/java/parquet/hadoop/RedelmInputFormat.java": [
                3,
                3
            ],
            "redelm-pig/src/main/java/parquet/hadoop/RedelmOutputCommitter.java": [
                1,
                2
            ],
            "redelm-pig/src/main/java/parquet/hadoop/RedelmOutputFormat.java": [
                3,
                3
            ],
            "redelm-pig/src/main/java/parquet/hadoop/RedelmRecordReader.java": [
                15,
                15
            ],
            "redelm-pig/src/main/java/parquet/hadoop/RedelmRecordWriter.java": [
                5,
                5
            ],
            "redelm-pig/src/main/java/parquet/hadoop/WriteSupport.java": [
                2,
                3
            ],
            "redelm-pig/src/main/java/parquet/hadoop/metadata/ColumnChunkMetaData.java": [
                1,
                2
            ],
            "redelm-pig/src/main/java/parquet/hadoop/metadata/FileMetaData.java": [
                1,
                2
            ],
            "redelm-pig/src/main/java/parquet/pig/PigSchemaConverter.java": [
                8,
                9
            ],
            "redelm-pig/src/main/java/parquet/pig/RedelmLoader.java": [
                1,
                1
            ],
            "redelm-pig/src/main/java/parquet/pig/RedelmStorer.java": [
                1,
                1
            ],
            "redelm-pig/src/main/java/parquet/pig/TupleConversionException.java": [
                1,
                1
            ],
            "redelm-pig/src/main/java/parquet/pig/TupleReadSupport.java": [
                4,
                4
            ],
            "redelm-pig/src/main/java/parquet/pig/TupleRecordConsumer.java": [
                6,
                7
            ],
            "redelm-pig/src/main/java/parquet/pig/TupleWriteSupport.java": [
                4,
                4
            ],
            "redelm-pig/src/main/java/parquet/pig/convert/MapConverter.java": [
                4,
                5
            ],
            "redelm-pig/src/main/java/parquet/pig/convert/TupleConverter.java": [
                5,
                5
            ],
            "redelm-pig/src/main/java/parquet/pig/converter/BagConverter.java": [
                1,
                1
            ],
            "redelm-pig/src/main/java/parquet/pig/converter/MapConverter.java": [
                1,
                1
            ],
            "redelm-pig/src/main/java/parquet/pig/converter/MapKeyValueConverter.java": [
                1,
                2
            ],
            "redelm-pig/src/main/java/parquet/pig/converter/MessageConverter.java": [
                2,
                3
            ],
            "redelm-pig/src/main/java/parquet/pig/converter/TupleConverter.java": [
                2,
                2
            ],
            "redelm-pig/src/test/java/parquet/format/converter/TestParquetMetadataConverter.java": [
                2,
                2
            ],
            "redelm-pig/src/test/java/parquet/hadoop/TestInputFormat.java": [
                3,
                3
            ],
            "redelm-pig/src/test/java/parquet/hadoop/TestRedelmFileWriter.java": [
                8,
                8
            ],
            "redelm-pig/src/test/java/parquet/pig/GenerateIntTestFile.java": [
                15,
                15
            ],
            "redelm-pig/src/test/java/parquet/pig/GenerateTPCH.java": [
                10,
                11
            ],
            "redelm-pig/src/test/java/parquet/pig/PerfTest2.java": [
                1,
                1
            ],
            "redelm-pig/src/test/java/parquet/pig/TestPigSchemaConverter.java": [
                2,
                2
            ],
            "redelm-pig/src/test/java/parquet/pig/TestTupleRecordConsumer.java": [
                8,
                8
            ],
            "redelm-pig/src/test/java/parquet/pig/TupleConsumerPerfTest.java": [
                12,
                12
            ]
        }
    },
    "24c85c7746f26aceb17ffdf7394e620a079523e3": {
        "datetime": "2013-02-20T12:33:45-08:00",
        "summary": "renaming maven artifacts",
        "message": "renaming maven artifacts\n",
        "diff": {
            "README.md": null,
            "pom.xml": null,
            "redelm-column/pom.xml": null,
            "redelm-column/src/main/java/parquet/Log.java": [
                0,
                0
            ],
            "redelm-column/src/main/java/parquet/RedelmRuntimeException.java": [
                0,
                0
            ],
            "redelm-column/src/main/java/parquet/bytes/BytesInput.java": [
                0,
                0
            ],
            "redelm-column/src/main/java/parquet/bytes/BytesUtils.java": [
                0,
                0
            ],
            "redelm-column/src/main/java/parquet/bytes/CapacityByteArrayOutputStream.java": [
                0,
                0
            ],
            "redelm-column/src/main/java/parquet/bytes/LittleEndianDataInputStream.java": [
                0,
                0
            ],
            "redelm-column/src/main/java/parquet/bytes/LittleEndianDataOutputStream.java": [
                0,
                0
            ],
            "redelm-column/src/main/java/parquet/column/ColumnDescriptor.java": [
                0,
                0
            ],
            "redelm-column/src/main/java/parquet/column/ColumnReadStore.java": [
                0,
                0
            ],
            "redelm-column/src/main/java/parquet/column/ColumnReader.java": [
                0,
                0
            ],
            "redelm-column/src/main/java/parquet/column/ColumnWriteStore.java": [
                0,
                0
            ],
            "redelm-column/src/main/java/parquet/column/ColumnWriter.java": [
                0,
                0
            ],
            "redelm-column/src/main/java/parquet/column/UnknownColumnException.java": [
                0,
                0
            ],
            "redelm-column/src/main/java/parquet/column/mem/MemColumnReadStore.java": [
                0,
                0
            ],
            "redelm-column/src/main/java/parquet/column/mem/MemColumnReader.java": [
                0,
                0
            ],
            "redelm-column/src/main/java/parquet/column/mem/MemColumnWriteStore.java": [
                0,
                0
            ],
            "redelm-column/src/main/java/parquet/column/mem/MemColumnWriter.java": [
                0,
                0
            ],
            "redelm-column/src/main/java/parquet/column/mem/MemPageReader.java": [
                0,
                0
            ],
            "redelm-column/src/main/java/parquet/column/mem/MemPageStore.java": [
                0,
                0
            ],
            "redelm-column/src/main/java/parquet/column/mem/MemPageWriter.java": [
                0,
                0
            ],
            "redelm-column/src/main/java/parquet/column/mem/Page.java": [
                0,
                0
            ],
            "redelm-column/src/main/java/parquet/column/mem/PageReadStore.java": [
                0,
                0
            ],
            "redelm-column/src/main/java/parquet/column/mem/PageReader.java": [
                0,
                0
            ],
            "redelm-column/src/main/java/parquet/column/mem/PageWriteStore.java": [
                0,
                0
            ],
            "redelm-column/src/main/java/parquet/column/mem/PageWriter.java": [
                0,
                0
            ],
            "redelm-column/src/main/java/parquet/column/primitive/BitPacking.java": [
                0,
                0
            ],
            "redelm-column/src/main/java/parquet/column/primitive/BitPackingColumnReader.java": [
                0,
                0
            ],
            "redelm-column/src/main/java/parquet/column/primitive/BitPackingColumnWriter.java": [
                0,
                0
            ],
            "redelm-column/src/main/java/parquet/column/primitive/BitReader.java": [
                0,
                0
            ],
            "redelm-column/src/main/java/parquet/column/primitive/BitWriter.java": [
                0,
                0
            ],
            "redelm-column/src/main/java/parquet/column/primitive/BooleanPlainColumnReader.java": [
                0,
                0
            ],
            "redelm-column/src/main/java/parquet/column/primitive/BooleanPlainColumnWriter.java": [
                0,
                0
            ],
            "redelm-column/src/main/java/parquet/column/primitive/BoundedColumnFactory.java": [
                0,
                0
            ],
            "redelm-column/src/main/java/parquet/column/primitive/BoundedIntColumnReader.java": [
                0,
                0
            ],
            "redelm-column/src/main/java/parquet/column/primitive/BoundedIntColumnWriter.java": [
                0,
                0
            ],
            "redelm-column/src/main/java/parquet/column/primitive/DevNullColumnReader.java": [
                0,
                0
            ],
            "redelm-column/src/main/java/parquet/column/primitive/DevNullColumnWriter.java": [
                0,
                0
            ],
            "redelm-column/src/main/java/parquet/column/primitive/PlainColumnReader.java": [
                0,
                0
            ],
            "redelm-column/src/main/java/parquet/column/primitive/PlainColumnWriter.java": [
                0,
                0
            ],
            "redelm-column/src/main/java/parquet/column/primitive/PrimitiveColumnReader.java": [
                0,
                0
            ],
            "redelm-column/src/main/java/parquet/column/primitive/PrimitiveColumnWriter.java": [
                0,
                0
            ],
            "redelm-column/src/main/java/parquet/data/Group.java": [
                0,
                0
            ],
            "redelm-column/src/main/java/parquet/data/GroupFactory.java": [
                0,
                0
            ],
            "redelm-column/src/main/java/parquet/data/GroupRecordConsumer.java": [
                0,
                0
            ],
            "redelm-column/src/main/java/parquet/data/GroupValueSource.java": [
                0,
                0
            ],
            "redelm-column/src/main/java/parquet/data/GroupWriter.java": [
                0,
                0
            ],
            "redelm-column/src/main/java/parquet/data/simple/BinaryValue.java": [
                0,
                0
            ],
            "redelm-column/src/main/java/parquet/data/simple/BooleanValue.java": [
                0,
                0
            ],
            "redelm-column/src/main/java/parquet/data/simple/DoubleValue.java": [
                0,
                0
            ],
            "redelm-column/src/main/java/parquet/data/simple/FloatValue.java": [
                0,
                0
            ],
            "redelm-column/src/main/java/parquet/data/simple/IntegerValue.java": [
                0,
                0
            ],
            "redelm-column/src/main/java/parquet/data/simple/LongValue.java": [
                0,
                0
            ],
            "redelm-column/src/main/java/parquet/data/simple/Primitive.java": [
                0,
                0
            ],
            "redelm-column/src/main/java/parquet/data/simple/SimpleGroup.java": [
                0,
                0
            ],
            "redelm-column/src/main/java/parquet/data/simple/SimpleGroupFactory.java": [
                0,
                0
            ],
            "redelm-column/src/main/java/parquet/data/simple/example/Paper.java": [
                0,
                0
            ],
            "redelm-column/src/main/java/parquet/io/BaseRecordReader.java": [
                0,
                0
            ],
            "redelm-column/src/main/java/parquet/io/ColumnIO.java": [
                0,
                0
            ],
            "redelm-column/src/main/java/parquet/io/ColumnIOFactory.java": [
                0,
                0
            ],
            "redelm-column/src/main/java/parquet/io/GroupColumnIO.java": [
                0,
                0
            ],
            "redelm-column/src/main/java/parquet/io/InvalidRecordException.java": [
                0,
                0
            ],
            "redelm-column/src/main/java/parquet/io/MessageColumnIO.java": [
                0,
                0
            ],
            "redelm-column/src/main/java/parquet/io/PrimitiveColumnIO.java": [
                0,
                0
            ],
            "redelm-column/src/main/java/parquet/io/RecordConsumer.java": [
                0,
                0
            ],
            "redelm-column/src/main/java/parquet/io/RecordConsumerLoggingWrapper.java": [
                0,
                0
            ],
            "redelm-column/src/main/java/parquet/io/RecordMaterializer.java": [
                0,
                0
            ],
            "redelm-column/src/main/java/parquet/io/RecordReader.java": [
                0,
                0
            ],
            "redelm-column/src/main/java/parquet/io/RecordReaderCompiler.java": [
                0,
                0
            ],
            "redelm-column/src/main/java/parquet/io/RecordReaderImplementation.java": [
                0,
                0
            ],
            "redelm-column/src/main/java/parquet/io/ValidatingRecordConsumer.java": [
                0,
                0
            ],
            "redelm-column/src/main/java/parquet/io/convert/GroupConverter.java": [
                0,
                0
            ],
            "redelm-column/src/main/java/parquet/io/convert/PrimitiveConverter.java": [
                0,
                0
            ],
            "redelm-column/src/main/java/parquet/parser/MessageTypeParser.java": [
                0,
                0
            ],
            "redelm-column/src/main/java/parquet/schema/GroupType.java": [
                0,
                0
            ],
            "redelm-column/src/main/java/parquet/schema/MessageType.java": [
                0,
                0
            ],
            "redelm-column/src/main/java/parquet/schema/PrimitiveType.java": [
                0,
                0
            ],
            "redelm-column/src/main/java/parquet/schema/Type.java": [
                0,
                0
            ],
            "redelm-column/src/main/java/parquet/schema/TypeVisitor.java": [
                0,
                0
            ],
            "redelm-column/src/main/java/parquet/utils/Varint.java": [
                0,
                0
            ],
            "redelm-column/src/test/java/parquet/bytes/TestBytesUtil.java": [
                0,
                0
            ],
            "redelm-column/src/test/java/parquet/column/mem/TestMemColumn.java": [
                0,
                0
            ],
            "redelm-column/src/test/java/parquet/column/mem/TestMemPageStore.java": [
                0,
                0
            ],
            "redelm-column/src/test/java/parquet/column/primitive/TestBitPacking.java": [
                0,
                0
            ],
            "redelm-column/src/test/java/parquet/column/primitive/TestBitPackingColumn.java": [
                0,
                0
            ],
            "redelm-column/src/test/java/parquet/column/primitive/TestBoundedColumns.java": [
                0,
                0
            ],
            "redelm-column/src/test/java/parquet/io/ExpectationValidatingRecordConsumer.java": [
                0,
                0
            ],
            "redelm-column/src/test/java/parquet/io/PerfTest.java": [
                0,
                0
            ],
            "redelm-column/src/test/java/parquet/io/TestColumnIO.java": [
                0,
                0
            ],
            "redelm-column/src/test/java/parquet/io/TestRecordReaderCompiler.java": [
                0,
                0
            ],
            "redelm-column/src/test/java/parquet/parser/TestRedelmParser.java": [
                0,
                0
            ],
            "redelm-column/src/test/java/parquet/schema/TestMessageType.java": [
                0,
                0
            ],
            "redelm-pig/lib/pig-0.11.0-SNAPSHOT.jar": null,
            "redelm-pig/pom.xml": null,
            "redelm-pig/src/main/java/parquet/format/converter/ParquetMetadataConverter.java": [
                0,
                0
            ],
            "redelm-pig/src/main/java/parquet/hadoop/BlockData.java": [
                0,
                0
            ],
            "redelm-pig/src/main/java/parquet/hadoop/CodecFactory.java": [
                0,
                0
            ],
            "redelm-pig/src/main/java/parquet/hadoop/ColumnChunkPageReadStore.java": [
                0,
                0
            ],
            "redelm-pig/src/main/java/parquet/hadoop/ColumnChunkPageWriteStore.java": [
                0,
                0
            ],
            "redelm-pig/src/main/java/parquet/hadoop/ColumnData.java": [
                0,
                0
            ],
            "redelm-pig/src/main/java/parquet/hadoop/Footer.java": [
                0,
                0
            ],
            "redelm-pig/src/main/java/parquet/hadoop/PageConsumer.java": [
                0,
                0
            ],
            "redelm-pig/src/main/java/parquet/hadoop/PrintFooter.java": [
                0,
                0
            ],
            "redelm-pig/src/main/java/parquet/hadoop/ReadSupport.java": [
                0,
                0
            ],
            "redelm-pig/src/main/java/parquet/hadoop/RedelmFileReader.java": [
                0,
                0
            ],
            "redelm-pig/src/main/java/parquet/hadoop/RedelmFileWriter.java": [
                0,
                0
            ],
            "redelm-pig/src/main/java/parquet/hadoop/RedelmInputFormat.java": [
                0,
                0
            ],
            "redelm-pig/src/main/java/parquet/hadoop/RedelmInputSplit.java": [
                0,
                0
            ],
            "redelm-pig/src/main/java/parquet/hadoop/RedelmOutputCommitter.java": [
                0,
                0
            ],
            "redelm-pig/src/main/java/parquet/hadoop/RedelmOutputFormat.java": [
                0,
                0
            ],
            "redelm-pig/src/main/java/parquet/hadoop/RedelmRecordReader.java": [
                0,
                0
            ],
            "redelm-pig/src/main/java/parquet/hadoop/RedelmRecordWriter.java": [
                0,
                0
            ],
            "redelm-pig/src/main/java/parquet/hadoop/WriteSupport.java": [
                0,
                0
            ],
            "redelm-pig/src/main/java/parquet/hadoop/metadata/BlockMetaData.java": [
                0,
                0
            ],
            "redelm-pig/src/main/java/parquet/hadoop/metadata/ColumnChunkMetaData.java": [
                0,
                0
            ],
            "redelm-pig/src/main/java/parquet/hadoop/metadata/ColumnMetaData.java": [
                0,
                0
            ],
            "redelm-pig/src/main/java/parquet/hadoop/metadata/CompressionCodecName.java": [
                0,
                0
            ],
            "redelm-pig/src/main/java/parquet/hadoop/metadata/FileMetaData.java": [
                0,
                0
            ],
            "redelm-pig/src/main/java/parquet/hadoop/metadata/RedelmMetaData.java": [
                0,
                0
            ],
            "redelm-pig/src/main/java/parquet/pig/PigMetaData.java": [
                0,
                0
            ],
            "redelm-pig/src/main/java/parquet/pig/PigSchemaConverter.java": [
                0,
                0
            ],
            "redelm-pig/src/main/java/parquet/pig/RedelmLoader.java": [
                0,
                0
            ],
            "redelm-pig/src/main/java/parquet/pig/RedelmStorer.java": [
                0,
                0
            ],
            "redelm-pig/src/main/java/parquet/pig/TupleConversionException.java": [
                0,
                0
            ],
            "redelm-pig/src/main/java/parquet/pig/TupleReadSupport.java": [
                0,
                0
            ],
            "redelm-pig/src/main/java/parquet/pig/TupleRecordConsumer.java": [
                0,
                0
            ],
            "redelm-pig/src/main/java/parquet/pig/TupleWriteSupport.java": [
                0,
                0
            ],
            "redelm-pig/src/main/java/parquet/pig/convert/MapConverter.java": [
                0,
                0
            ],
            "redelm-pig/src/main/java/parquet/pig/convert/TupleConverter.java": [
                0,
                0
            ],
            "redelm-pig/src/main/java/parquet/pig/converter/BagConverter.java": [
                0,
                0
            ],
            "redelm-pig/src/main/java/parquet/pig/converter/Converter.java": [
                0,
                0
            ],
            "redelm-pig/src/main/java/parquet/pig/converter/MapConverter.java": [
                0,
                0
            ],
            "redelm-pig/src/main/java/parquet/pig/converter/MapKeyValueConverter.java": [
                0,
                0
            ],
            "redelm-pig/src/main/java/parquet/pig/converter/MessageConverter.java": [
                0,
                0
            ],
            "redelm-pig/src/main/java/parquet/pig/converter/TupleConverter.java": [
                0,
                0
            ],
            "redelm-pig/src/main/java/parquet/pig/summary/BagSummaryData.java": [
                0,
                0
            ],
            "redelm-pig/src/main/java/parquet/pig/summary/EnumStat.java": [
                0,
                0
            ],
            "redelm-pig/src/main/java/parquet/pig/summary/FieldSummaryData.java": [
                0,
                0
            ],
            "redelm-pig/src/main/java/parquet/pig/summary/MapSummaryData.java": [
                0,
                0
            ],
            "redelm-pig/src/main/java/parquet/pig/summary/NumberSummaryData.java": [
                0,
                0
            ],
            "redelm-pig/src/main/java/parquet/pig/summary/StringSummaryData.java": [
                0,
                0
            ],
            "redelm-pig/src/main/java/parquet/pig/summary/Summary.java": [
                0,
                0
            ],
            "redelm-pig/src/main/java/parquet/pig/summary/SummaryData.java": [
                0,
                0
            ],
            "redelm-pig/src/main/java/parquet/pig/summary/TupleSummaryData.java": [
                0,
                0
            ],
            "redelm-pig/src/main/java/parquet/pig/summary/ValueStat.java": [
                0,
                0
            ],
            "redelm-pig/src/test/java/parquet/format/converter/TestParquetMetadataConverter.java": [
                0,
                0
            ],
            "redelm-pig/src/test/java/parquet/hadoop/TestInputFormat.java": [
                0,
                0
            ],
            "redelm-pig/src/test/java/parquet/hadoop/TestRedelmFileWriter.java": [
                0,
                0
            ],
            "redelm-pig/src/test/java/parquet/pig/GenerateIntTestFile.java": [
                0,
                0
            ],
            "redelm-pig/src/test/java/parquet/pig/GenerateTPCH.java": [
                0,
                0
            ],
            "redelm-pig/src/test/java/parquet/pig/PerfTest.java": [
                0,
                0
            ],
            "redelm-pig/src/test/java/parquet/pig/PerfTest2.java": [
                0,
                0
            ],
            "redelm-pig/src/test/java/parquet/pig/PerfTestReadAllCols.java": [
                0,
                0
            ],
            "redelm-pig/src/test/java/parquet/pig/TestPigSchemaConverter.java": [
                0,
                0
            ],
            "redelm-pig/src/test/java/parquet/pig/TestRedelmStorer.java": [
                0,
                0
            ],
            "redelm-pig/src/test/java/parquet/pig/TestTupleRecordConsumer.java": [
                0,
                0
            ],
            "redelm-pig/src/test/java/parquet/pig/TupleConsumerPerfTest.java": [
                0,
                0
            ],
            "redelm-pig/src/test/java/parquet/pig/summary/TestSummary.java": [
                0,
                0
            ]
        }
    },
    "ac3a80616248e6facf9c756ac8d831bcf5e978a1": {
        "datetime": "2013-02-20T14:22:16-08:00",
        "summary": "renamed to parquet",
        "message": "renamed to parquet\n",
        "diff": {
            "parquet-column/src/main/java/parquet/RedelmRuntimeException.java": [
                5,
                5
            ],
            "parquet-column/src/main/java/parquet/column/UnknownColumnException.java": [
                2,
                2
            ],
            "parquet-column/src/main/java/parquet/io/InvalidRecordException.java": [
                2,
                2
            ],
            "parquet-column/src/main/java/parquet/io/RecordReaderCompiler.java": [
                1,
                1
            ],
            "parquet-column/src/test/java/parquet/parser/TestRedelmParser.java": [
                1,
                1
            ],
            "parquet-pig/src/main/java/parquet/format/converter/ParquetMetadataConverter.java": [
                9,
                9
            ],
            "parquet-pig/src/main/java/parquet/hadoop/ColumnChunkPageWriteStore.java": [
                2,
                2
            ],
            "parquet-pig/src/main/java/parquet/hadoop/Footer.java": [
                6,
                6
            ],
            "parquet-pig/src/main/java/parquet/hadoop/PrintFooter.java": [
                14,
                12
            ],
            "parquet-pig/src/main/java/parquet/hadoop/ReadSupport.java": [
                3,
                1
            ],
            "parquet-pig/src/main/java/parquet/hadoop/RedelmFileReader.java": [
                25,
                23
            ],
            "parquet-pig/src/main/java/parquet/hadoop/RedelmFileWriter.java": [
                10,
                10
            ],
            "parquet-pig/src/main/java/parquet/hadoop/RedelmInputFormat.java": [
                17,
                14
            ],
            "parquet-pig/src/main/java/parquet/hadoop/RedelmInputSplit.java": [
                9,
                6
            ],
            "parquet-pig/src/main/java/parquet/hadoop/RedelmOutputCommitter.java": [
                5,
                5
            ],
            "parquet-pig/src/main/java/parquet/hadoop/RedelmOutputFormat.java": [
                19,
                19
            ],
            "parquet-pig/src/main/java/parquet/hadoop/RedelmRecordReader.java": [
                20,
                11
            ],
            "parquet-pig/src/main/java/parquet/hadoop/RedelmRecordWriter.java": [
                6,
                6
            ],
            "parquet-pig/src/main/java/parquet/hadoop/WriteSupport.java": [
                1,
                1
            ],
            "parquet-pig/src/main/java/parquet/hadoop/metadata/RedelmMetaData.java": [
                13,
                13
            ],
            "parquet-pig/src/main/java/parquet/pig/PigSchemaConverter.java": [
                3,
                3
            ],
            "parquet-pig/src/main/java/parquet/pig/RedelmLoader.java": [
                16,
                13
            ],
            "parquet-pig/src/main/java/parquet/pig/RedelmStorer.java": [
                8,
                8
            ],
            "parquet-pig/src/main/java/parquet/pig/TupleConversionException.java": [
                2,
                2
            ],
            "parquet-pig/src/main/java/parquet/pig/TupleReadSupport.java": [
                5,
                5
            ],
            "parquet-pig/src/main/java/parquet/pig/convert/MapConverter.java": [
                10,
                10
            ],
            "parquet-pig/src/main/java/parquet/pig/convert/TupleConverter.java": [
                12,
                12
            ],
            "parquet-pig/src/main/java/parquet/pig/converter/BagConverter.java": [
                5,
                2
            ],
            "parquet-pig/src/main/java/parquet/pig/converter/MapConverter.java": [
                2,
                2
            ],
            "parquet-pig/src/main/java/parquet/pig/converter/MapKeyValueConverter.java": [
                5,
                5
            ],
            "parquet-pig/src/main/java/parquet/pig/converter/MessageConverter.java": [
                2,
                2
            ],
            "parquet-pig/src/main/java/parquet/pig/converter/TupleConverter.java": [
                7,
                3
            ],
            "parquet-pig/src/test/java/parquet/hadoop/TestInputFormat.java": [
                8,
                8
            ],
            "parquet-pig/src/test/java/parquet/hadoop/TestReadIntTestFile.java": [
                0,
                59
            ],
            "parquet-pig/src/test/java/parquet/hadoop/TestRedelmFileWriter.java": [
                10,
                10
            ],
            "parquet-pig/src/test/java/parquet/pig/GenerateIntTestFile.java": [
                11,
                11
            ],
            "parquet-pig/src/test/java/parquet/pig/PerfTest.java": [
                4,
                4
            ],
            "parquet-pig/src/test/java/parquet/pig/PerfTest2.java": [
                4,
                4
            ],
            "parquet-pig/src/test/java/parquet/pig/TestPigSchemaConverter.java": [
                4,
                4
            ],
            "parquet-pig/src/test/java/parquet/pig/TestRedelmStorer.java": [
                14,
                14
            ],
            "parquet-pig/src/test/java/parquet/pig/TestTupleRecordConsumer.java": [
                7,
                7
            ]
        }
    },
    "bd1fde90f05a3aec05f7cad24d90633ea680d9f9": {
        "datetime": "2013-02-20T14:42:54-08:00",
        "summary": "cleanup",
        "message": "cleanup\n",
        "diff": {
            "parquet-column/src/main/java/parquet/column/ColumnDescriptor.java": [
                1,
                0
            ],
            "parquet-column/src/main/java/parquet/column/mem/MemColumnReader.java": [
                5,
                1
            ],
            "parquet-column/src/main/java/parquet/column/mem/MemColumnWriter.java": [
                3,
                1
            ],
            "parquet-column/src/main/java/parquet/column/mem/ParquetDecodingException.java": [
                0,
                23
            ],
            "parquet-column/src/main/java/parquet/column/mem/ParquetEncodingException.java": [
                0,
                23
            ],
            "parquet-column/src/main/java/parquet/column/primitive/BooleanPlainColumnWriter.java": [
                1,
                0
            ],
            "parquet-column/src/main/java/parquet/column/primitive/PlainColumnReader.java": [
                2,
                0
            ],
            "parquet-column/src/main/java/parquet/io/MessageColumnIO.java": [
                4,
                0
            ],
            "parquet-column/src/test/java/parquet/column/primitive/TestBitPackingColumn.java": [
                4,
                0
            ],
            "parquet-column/src/test/java/parquet/io/ExpectationValidatingRecordConsumer.java": [
                3,
                0
            ],
            "parquet-column/src/test/java/parquet/io/PerfTest.java": [
                7,
                0
            ],
            "parquet-column/src/test/java/parquet/io/TestColumnIO.java": [
                16,
                0
            ],
            "parquet-pig/src/main/java/parquet/hadoop/metadata/FileMetaData.java": [
                5,
                0
            ],
            "parquet-pig/src/main/java/parquet/hadoop/metadata/ParquetMetadata.java": [
                1,
                0
            ],
            "parquet-pig/src/main/java/parquet/pig/ParquetStorer.java": [
                2,
                0
            ],
            "parquet-pig/src/main/java/parquet/pig/PigSchemaConverter.java": [
                3,
                1
            ],
            "parquet-pig/src/test/java/parquet/hadoop/TestParquetFileWriter.java": [
                7,
                3
            ],
            "parquet-pig/src/test/java/parquet/hadoop/TestReadIntTestFile.java": [
                3,
                0
            ],
            "parquet-pig/src/test/java/parquet/pig/TestTupleRecordConsumer.java": [
                5,
                0
            ]
        }
    },
    "51649183bf4c40f40b46bbcf04adb379094d7fda": {
        "datetime": "2013-02-20T16:11:05-08:00",
        "summary": "Merge pull request #26 from julienledem/rename_to_parquet",
        "message": "Merge pull request #26 from julienledem/rename_to_parquet\n\nRename to parquet",
        "diff": {
            "README.md": null,
            "parquet-column/src/main/java/parquet/column/mem/ParquetDecodingException.java": [
                0,
                23
            ],
            "parquet-column/src/main/java/parquet/column/mem/ParquetEncodingException.java": [
                0,
                23
            ],
            "parquet-pig/src/test/java/parquet/hadoop/TestReadIntTestFile.java": [
                0,
                56
            ],
            "pom.xml": null,
            "redelm-column/pom.xml": null,
            "redelm-column/src/main/java/redelm/Log.java": [
                1,
                1
            ],
            "redelm-column/src/main/java/redelm/RedelmRuntimeException.java": [
                6,
                6
            ],
            "redelm-column/src/main/java/redelm/bytes/BytesInput.java": [
                2,
                3
            ],
            "redelm-column/src/main/java/redelm/bytes/BytesUtils.java": [
                2,
                3
            ],
            "redelm-column/src/main/java/redelm/bytes/CapacityByteArrayOutputStream.java": [
                1,
                1
            ],
            "redelm-column/src/main/java/redelm/bytes/LittleEndianDataInputStream.java": [
                1,
                1
            ],
            "redelm-column/src/main/java/redelm/bytes/LittleEndianDataOutputStream.java": [
                1,
                1
            ],
            "redelm-column/src/main/java/redelm/column/ColumnDescriptor.java": [
                3,
                3
            ],
            "redelm-column/src/main/java/redelm/column/ColumnReadStore.java": [
                1,
                1
            ],
            "redelm-column/src/main/java/redelm/column/ColumnReader.java": [
                1,
                1
            ],
            "redelm-column/src/main/java/redelm/column/ColumnWriteStore.java": [
                1,
                1
            ],
            "redelm-column/src/main/java/redelm/column/ColumnWriter.java": [
                1,
                1
            ],
            "redelm-column/src/main/java/redelm/column/UnknownColumnException.java": [
                3,
                3
            ],
            "redelm-column/src/main/java/redelm/column/mem/MemColumnReadStore.java": [
                4,
                5
            ],
            "redelm-column/src/main/java/redelm/column/mem/MemColumnReader.java": [
                15,
                12
            ],
            "redelm-column/src/main/java/redelm/column/mem/MemColumnWriteStore.java": [
                4,
                5
            ],
            "redelm-column/src/main/java/redelm/column/mem/MemColumnWriter.java": [
                13,
                12
            ],
            "redelm-column/src/main/java/redelm/column/mem/MemPageReader.java": [
                3,
                4
            ],
            "redelm-column/src/main/java/redelm/column/mem/MemPageStore.java": [
                4,
                5
            ],
            "redelm-column/src/main/java/redelm/column/mem/MemPageWriter.java": [
                4,
                5
            ],
            "redelm-column/src/main/java/redelm/column/mem/Page.java": [
                3,
                3
            ],
            "redelm-column/src/main/java/redelm/column/mem/PageReadStore.java": [
                2,
                2
            ],
            "redelm-column/src/main/java/redelm/column/mem/PageReader.java": [
                1,
                1
            ],
            "redelm-column/src/main/java/redelm/column/mem/PageWriteStore.java": [
                2,
                2
            ],
            "redelm-column/src/main/java/redelm/column/mem/PageWriter.java": [
                2,
                3
            ],
            "redelm-column/src/main/java/redelm/column/primitive/BitPacking.java": [
                3,
                4
            ],
            "redelm-column/src/main/java/redelm/column/primitive/BitPackingColumnReader.java": [
                4,
                5
            ],
            "redelm-column/src/main/java/redelm/column/primitive/BitPackingColumnWriter.java": [
                6,
                7
            ],
            "redelm-column/src/main/java/redelm/column/primitive/BitReader.java": [
                1,
                1
            ],
            "redelm-column/src/main/java/redelm/column/primitive/BitWriter.java": [
                3,
                3
            ],
            "redelm-column/src/main/java/redelm/column/primitive/BooleanPlainColumnReader.java": [
                6,
                7
            ],
            "redelm-column/src/main/java/redelm/column/primitive/BooleanPlainColumnWriter.java": [
                7,
                7
            ],
            "redelm-column/src/main/java/redelm/column/primitive/BoundedColumnFactory.java": [
                1,
                1
            ],
            "redelm-column/src/main/java/redelm/column/primitive/BoundedIntColumnReader.java": [
                4,
                5
            ],
            "redelm-column/src/main/java/redelm/column/primitive/BoundedIntColumnWriter.java": [
                3,
                3
            ],
            "redelm-column/src/main/java/redelm/column/primitive/DevNullColumnReader.java": [
                1,
                1
            ],
            "redelm-column/src/main/java/redelm/column/primitive/DevNullColumnWriter.java": [
                2,
                2
            ],
            "redelm-column/src/main/java/redelm/column/primitive/PlainColumnReader.java": [
                7,
                6
            ],
            "redelm-column/src/main/java/redelm/column/primitive/PlainColumnWriter.java": [
                5,
                6
            ],
            "redelm-column/src/main/java/redelm/column/primitive/PrimitiveColumnReader.java": [
                1,
                1
            ],
            "redelm-column/src/main/java/redelm/column/primitive/PrimitiveColumnWriter.java": [
                2,
                2
            ],
            "redelm-column/src/main/java/redelm/data/Group.java": [
                3,
                3
            ],
            "redelm-column/src/main/java/redelm/data/GroupFactory.java": [
                1,
                1
            ],
            "redelm-column/src/main/java/redelm/data/GroupRecordConsumer.java": [
                3,
                4
            ],
            "redelm-column/src/main/java/redelm/data/GroupValueSource.java": [
                2,
                2
            ],
            "redelm-column/src/main/java/redelm/data/GroupWriter.java": [
                4,
                4
            ],
            "redelm-column/src/main/java/redelm/data/simple/BinaryValue.java": [
                2,
                2
            ],
            "redelm-column/src/main/java/redelm/data/simple/BooleanValue.java": [
                2,
                2
            ],
            "redelm-column/src/main/java/redelm/data/simple/DoubleValue.java": [
                2,
                2
            ],
            "redelm-column/src/main/java/redelm/data/simple/FloatValue.java": [
                2,
                2
            ],
            "redelm-column/src/main/java/redelm/data/simple/IntegerValue.java": [
                2,
                2
            ],
            "redelm-column/src/main/java/redelm/data/simple/LongValue.java": [
                2,
                2
            ],
            "redelm-column/src/main/java/redelm/data/simple/Primitive.java": [
                2,
                2
            ],
            "redelm-column/src/main/java/redelm/data/simple/SimpleGroup.java": [
                5,
                6
            ],
            "redelm-column/src/main/java/redelm/data/simple/SimpleGroupFactory.java": [
                4,
                4
            ],
            "redelm-column/src/main/java/redelm/data/simple/example/Paper.java": [
                11,
                11
            ],
            "redelm-column/src/main/java/redelm/io/BaseRecordReader.java": [
                5,
                5
            ],
            "redelm-column/src/main/java/redelm/io/ColumnIO.java": [
                4,
                5
            ],
            "redelm-column/src/main/java/redelm/io/ColumnIOFactory.java": [
                7,
                8
            ],
            "redelm-column/src/main/java/redelm/io/GroupColumnIO.java": [
                5,
                6
            ],
            "redelm-column/src/main/java/redelm/io/InvalidRecordException.java": [
                3,
                3
            ],
            "redelm-column/src/main/java/redelm/io/MessageColumnIO.java": [
                10,
                7
            ],
            "redelm-column/src/main/java/redelm/io/PrimitiveColumnIO.java": [
                4,
                5
            ],
            "redelm-column/src/main/java/redelm/io/RecordConsumer.java": [
                1,
                1
            ],
            "redelm-column/src/main/java/redelm/io/RecordConsumerLoggingWrapper.java": [
                2,
                2
            ],
            "redelm-column/src/main/java/redelm/io/RecordMaterializer.java": [
                1,
                1
            ],
            "redelm-column/src/main/java/redelm/io/RecordReader.java": [
                1,
                1
            ],
            "redelm-column/src/main/java/redelm/io/RecordReaderCompiler.java": [
                6,
                7
            ],
            "redelm-column/src/main/java/redelm/io/RecordReaderImplementation.java": [
                7,
                8
            ],
            "redelm-column/src/main/java/redelm/io/ValidatingRecordConsumer.java": [
                6,
                7
            ],
            "redelm-column/src/main/java/redelm/io/convert/GroupConverter.java": [
                1,
                1
            ],
            "redelm-column/src/main/java/redelm/io/convert/PrimitiveConverter.java": [
                1,
                1
            ],
            "redelm-column/src/main/java/redelm/parser/MessageTypeParser.java": [
                8,
                9
            ],
            "redelm-column/src/main/java/redelm/schema/GroupType.java": [
                1,
                1
            ],
            "redelm-column/src/main/java/redelm/schema/MessageType.java": [
                3,
                4
            ],
            "redelm-column/src/main/java/redelm/schema/PrimitiveType.java": [
                3,
                4
            ],
            "redelm-column/src/main/java/redelm/schema/Type.java": [
                1,
                1
            ],
            "redelm-column/src/main/java/redelm/schema/TypeVisitor.java": [
                1,
                1
            ],
            "redelm-column/src/main/java/redelm/utils/Varint.java": [
                1,
                1
            ],
            "redelm-column/src/test/java/redelm/bytes/TestBytesUtil.java": [
                1,
                3
            ],
            "redelm-column/src/test/java/redelm/column/mem/TestMemColumn.java": [
                7,
                11
            ],
            "redelm-column/src/test/java/redelm/column/mem/TestMemPageStore.java": [
                4,
                9
            ],
            "redelm-column/src/test/java/redelm/column/primitive/TestBitPacking.java": [
                3,
                5
            ],
            "redelm-column/src/test/java/redelm/column/primitive/TestBitPackingColumn.java": [
                2,
                1
            ],
            "redelm-column/src/test/java/redelm/column/primitive/TestBoundedColumns.java": [
                1,
                4
            ],
            "redelm-column/src/test/java/redelm/io/ExpectationValidatingRecordConsumer.java": [
                2,
                1
            ],
            "redelm-column/src/test/java/redelm/io/PerfTest.java": [
                12,
                12
            ],
            "redelm-column/src/test/java/redelm/io/TestColumnIO.java": [
                28,
                20
            ],
            "redelm-column/src/test/java/redelm/io/TestRecordReaderCompiler.java": [
                7,
                13
            ],
            "redelm-column/src/test/java/redelm/parser/TestRedelmParser.java": [
                10,
                12
            ],
            "redelm-column/src/test/java/redelm/schema/TestMessageType.java": [
                3,
                5
            ],
            "redelm-pig/lib/pig-0.11.0-SNAPSHOT.jar": null,
            "redelm-pig/pom.xml": null,
            "redelm-pig/src/main/java/redelm/format/converter/ParquetMetadataConverter.java": [
                24,
                24
            ],
            "redelm-pig/src/main/java/redelm/hadoop/BlockData.java": [
                1,
                1
            ],
            "redelm-pig/src/main/java/redelm/hadoop/CodecFactory.java": [
                3,
                4
            ],
            "redelm-pig/src/main/java/redelm/hadoop/ColumnChunkPageReadStore.java": [
                7,
                8
            ],
            "redelm-pig/src/main/java/redelm/hadoop/ColumnChunkPageWriteStore.java": [
                11,
                11
            ],
            "redelm-pig/src/main/java/redelm/hadoop/ColumnData.java": [
                1,
                1
            ],
            "redelm-pig/src/main/java/redelm/hadoop/Footer.java": [
                7,
                8
            ],
            "redelm-pig/src/main/java/redelm/hadoop/PageConsumer.java": [
                2,
                2
            ],
            "redelm-pig/src/main/java/redelm/hadoop/PrintFooter.java": [
                19,
                18
            ],
            "redelm-pig/src/main/java/redelm/hadoop/ReadSupport.java": [
                5,
                4
            ],
            "redelm-pig/src/main/java/redelm/hadoop/RedelmFileReader.java": [
                38,
                36
            ],
            "redelm-pig/src/main/java/redelm/hadoop/RedelmFileWriter.java": [
                23,
                23
            ],
            "redelm-pig/src/main/java/redelm/hadoop/RedelmInputFormat.java": [
                23,
                21
            ],
            "redelm-pig/src/main/java/redelm/hadoop/RedelmInputSplit.java": [
                11,
                9
            ],
            "redelm-pig/src/main/java/redelm/hadoop/RedelmOutputCommitter.java": [
                7,
                8
            ],
            "redelm-pig/src/main/java/redelm/hadoop/RedelmOutputFormat.java": [
                24,
                25
            ],
            "redelm-pig/src/main/java/redelm/hadoop/RedelmRecordReader.java": [
                33,
                25
            ],
            "redelm-pig/src/main/java/redelm/hadoop/RedelmRecordWriter.java": [
                13,
                14
            ],
            "redelm-pig/src/main/java/redelm/hadoop/WriteSupport.java": [
                4,
                5
            ],
            "redelm-pig/src/main/java/redelm/hadoop/metadata/BlockMetaData.java": [
                1,
                1
            ],
            "redelm-pig/src/main/java/redelm/hadoop/metadata/ColumnChunkMetaData.java": [
                2,
                3
            ],
            "redelm-pig/src/main/java/redelm/hadoop/metadata/ColumnMetaData.java": [
                1,
                1
            ],
            "redelm-pig/src/main/java/redelm/hadoop/metadata/CompressionCodecName.java": [
                1,
                1
            ],
            "redelm-pig/src/main/java/redelm/hadoop/metadata/FileMetaData.java": [
                7,
                3
            ],
            "redelm-pig/src/main/java/redelm/hadoop/metadata/RedelmMetaData.java": [
                15,
                14
            ],
            "redelm-pig/src/main/java/redelm/pig/PigMetaData.java": [
                1,
                1
            ],
            "redelm-pig/src/main/java/redelm/pig/PigSchemaConverter.java": [
                14,
                13
            ],
            "redelm-pig/src/main/java/redelm/pig/RedelmLoader.java": [
                19,
                17
            ],
            "redelm-pig/src/main/java/redelm/pig/RedelmStorer.java": [
                12,
                11
            ],
            "redelm-pig/src/main/java/redelm/pig/TupleConversionException.java": [
                3,
                3
            ],
            "redelm-pig/src/main/java/redelm/pig/TupleReadSupport.java": [
                12,
                13
            ],
            "redelm-pig/src/main/java/redelm/pig/TupleRecordConsumer.java": [
                7,
                8
            ],
            "redelm-pig/src/main/java/redelm/pig/TupleWriteSupport.java": [
                6,
                7
            ],
            "redelm-pig/src/main/java/redelm/pig/convert/MapConverter.java": [
                15,
                16
            ],
            "redelm-pig/src/main/java/redelm/pig/convert/TupleConverter.java": [
                19,
                20
            ],
            "redelm-pig/src/main/java/redelm/pig/converter/BagConverter.java": [
                8,
                6
            ],
            "redelm-pig/src/main/java/redelm/pig/converter/Converter.java": [
                1,
                1
            ],
            "redelm-pig/src/main/java/redelm/pig/converter/MapConverter.java": [
                5,
                6
            ],
            "redelm-pig/src/main/java/redelm/pig/converter/MapKeyValueConverter.java": [
                7,
                8
            ],
            "redelm-pig/src/main/java/redelm/pig/converter/MessageConverter.java": [
                5,
                6
            ],
            "redelm-pig/src/main/java/redelm/pig/converter/TupleConverter.java": [
                11,
                8
            ],
            "redelm-pig/src/main/java/redelm/pig/summary/BagSummaryData.java": [
                1,
                1
            ],
            "redelm-pig/src/main/java/redelm/pig/summary/EnumStat.java": [
                1,
                1
            ],
            "redelm-pig/src/main/java/redelm/pig/summary/FieldSummaryData.java": [
                1,
                1
            ],
            "redelm-pig/src/main/java/redelm/pig/summary/MapSummaryData.java": [
                1,
                1
            ],
            "redelm-pig/src/main/java/redelm/pig/summary/NumberSummaryData.java": [
                1,
                1
            ],
            "redelm-pig/src/main/java/redelm/pig/summary/StringSummaryData.java": [
                2,
                3
            ],
            "redelm-pig/src/main/java/redelm/pig/summary/Summary.java": [
                1,
                1
            ],
            "redelm-pig/src/main/java/redelm/pig/summary/SummaryData.java": [
                1,
                1
            ],
            "redelm-pig/src/main/java/redelm/pig/summary/TupleSummaryData.java": [
                1,
                1
            ],
            "redelm-pig/src/main/java/redelm/pig/summary/ValueStat.java": [
                1,
                1
            ],
            "redelm-pig/src/test/java/redelm/format/converter/TestParquetMetadataConverter.java": [
                4,
                4
            ],
            "redelm-pig/src/test/java/redelm/hadoop/TestInputFormat.java": [
                14,
                18
            ],
            "redelm-pig/src/test/java/redelm/hadoop/TestRedelmFileWriter.java": [
                22,
                22
            ],
            "redelm-pig/src/test/java/redelm/pig/GenerateIntTestFile.java": [
                28,
                29
            ],
            "redelm-pig/src/test/java/redelm/pig/GenerateTPCH.java": [
                13,
                14
            ],
            "redelm-pig/src/test/java/redelm/pig/PerfTest.java": [
                3,
                6
            ],
            "redelm-pig/src/test/java/redelm/pig/PerfTest2.java": [
                4,
                7
            ],
            "redelm-pig/src/test/java/redelm/pig/PerfTestReadAllCols.java": [
                1,
                1
            ],
            "redelm-pig/src/test/java/redelm/pig/TestPigSchemaConverter.java": [
                7,
                9
            ],
            "redelm-pig/src/test/java/redelm/pig/TestRedelmStorer.java": [
                13,
                16
            ],
            "redelm-pig/src/test/java/redelm/pig/TestTupleRecordConsumer.java": [
                17,
                17
            ],
            "redelm-pig/src/test/java/redelm/pig/TupleConsumerPerfTest.java": [
                13,
                18
            ],
            "redelm-pig/src/test/java/redelm/pig/summary/TestSummary.java": [
                1,
                6
            ]
        }
    },
    "4a0bb74123d353df85e4a29a26e5d439bd1a5993": {
        "datetime": "2013-02-20T16:39:47-08:00",
        "summary": "cleanup exceptions",
        "message": "cleanup exceptions\n",
        "diff": {
            "parquet-column/src/main/java/parquet/column/mem/MemColumnReadStore.java": [
                1,
                1
            ],
            "parquet-column/src/main/java/parquet/column/mem/MemColumnReader.java": [
                1,
                1
            ],
            "parquet-column/src/main/java/parquet/column/mem/MemPageReader.java": [
                1,
                1
            ],
            "parquet-column/src/main/java/parquet/column/mem/MemPageWriter.java": [
                1,
                1
            ],
            "parquet-column/src/main/java/parquet/column/primitive/BitPackingColumnReader.java": [
                1,
                2
            ],
            "parquet-column/src/main/java/parquet/column/primitive/BitPackingColumnWriter.java": [
                2,
                3
            ],
            "parquet-column/src/main/java/parquet/column/primitive/BitReader.java": [
                1,
                3
            ],
            "parquet-column/src/main/java/parquet/column/primitive/BooleanPlainColumnReader.java": [
                1,
                2
            ],
            "parquet-column/src/main/java/parquet/column/primitive/BooleanPlainColumnWriter.java": [
                2,
                3
            ],
            "parquet-column/src/main/java/parquet/column/primitive/BoundedIntColumnReader.java": [
                2,
                3
            ],
            "parquet-column/src/main/java/parquet/column/primitive/BoundedIntColumnWriter.java": [
                1,
                2
            ],
            "parquet-column/src/main/java/parquet/column/primitive/PlainColumnReader.java": [
                6,
                7
            ],
            "parquet-column/src/main/java/parquet/column/primitive/PlainColumnWriter.java": [
                8,
                8
            ],
            "parquet-column/src/main/java/parquet/io/BaseRecordReader.java": [
                1,
                2
            ],
            "parquet-column/src/main/java/parquet/io/ColumnIO.java": [
                1,
                1
            ],
            "parquet-column/src/main/java/parquet/io/CompilationException.java": [
                0,
                23
            ],
            "parquet-column/src/main/java/parquet/io/GroupColumnIO.java": [
                1,
                1
            ],
            "parquet-column/src/main/java/parquet/io/MessageColumnIO.java": [
                3,
                4
            ],
            "parquet-column/src/main/java/parquet/io/RecordReaderCompiler.java": [
                8,
                8
            ],
            "parquet-column/src/main/java/parquet/io/RecordReaderImplementation.java": [
                1,
                2
            ],
            "parquet-column/src/main/java/parquet/schema/GroupType.java": [
                2,
                4
            ],
            "parquet-column/src/main/java/parquet/schema/MessageType.java": [
                1,
                2
            ],
            "parquet-column/src/main/java/parquet/schema/PrimitiveType.java": [
                5,
                6
            ],
            "parquet-column/src/main/java/parquet/schema/Type.java": [
                1,
                3
            ]
        }
    },
    "85d8f09fa96ec16d413bd5bc01269fff6ed595f4": {
        "datetime": "2013-02-20T16:51:00-08:00",
        "summary": "removed brennus dependency (for now)",
        "message": "removed brennus dependency (for now)\n",
        "diff": {
            "parquet-column/pom.xml": null,
            "parquet-column/src/main/java/parquet/io/RecordReaderCompiler.java": [
                274,
                0
            ],
            "parquet-column/src/test/java/parquet/io/PerfTest.java": [
                13,
                5
            ],
            "parquet-column/src/test/java/parquet/io/TestRecordReaderCompiler.java": [
                79,
                0
            ]
        }
    },
    "5141722756ae6a9f10924242f5d89cd9afebedad": {
        "datetime": "2013-02-20T17:30:11-08:00",
        "summary": "integrate thrift changes",
        "message": "integrate thrift changes\n",
        "diff": {
            "parquet-pig/src/main/java/parquet/hadoop/ColumnChunkPageWriteStore.java": [
                1,
                1
            ],
            "parquet-pig/src/main/java/parquet/hadoop/ParquetFileReader.java": [
                2,
                2
            ],
            "parquet-pig/src/main/java/parquet/hadoop/ParquetFileWriter.java": [
                1,
                1
            ]
        }
    },
    "cfdcdffee41711ba91109378605265200b2d9a25": {
        "datetime": "2013-02-20T17:32:39-08:00",
        "summary": "turn off customer test",
        "message": "turn off customer test\n",
        "diff": {
            "parquet-pig/src/test/java/parquet/hadoop/TestReadIntTestFile.java": [
                2,
                2
            ]
        }
    },
    "c5a894a12d326350c7b169b85704d3b183283057": {
        "datetime": "2013-02-20T18:03:22-08:00",
        "summary": "split hadoop; add thrift",
        "message": "split hadoop; add thrift\n",
        "diff": {
            "parquet-hadoop/pom.xml": null,
            "parquet-pig/pom.xml": null,
            "parquet-pig/src/main/java/parquet/format/converter/ParquetMetadataConverter.java": [
                0,
                0
            ],
            "parquet-pig/src/main/java/parquet/hadoop/BlockData.java": [
                0,
                0
            ],
            "parquet-pig/src/main/java/parquet/hadoop/CodecFactory.java": [
                0,
                0
            ],
            "parquet-pig/src/main/java/parquet/hadoop/ColumnChunkPageReadStore.java": [
                0,
                0
            ],
            "parquet-pig/src/main/java/parquet/hadoop/ColumnChunkPageWriteStore.java": [
                0,
                0
            ],
            "parquet-pig/src/main/java/parquet/hadoop/ColumnData.java": [
                0,
                0
            ],
            "parquet-pig/src/main/java/parquet/hadoop/Footer.java": [
                0,
                0
            ],
            "parquet-pig/src/main/java/parquet/hadoop/PageConsumer.java": [
                0,
                0
            ],
            "parquet-pig/src/main/java/parquet/hadoop/ParquetFileReader.java": [
                0,
                0
            ],
            "parquet-pig/src/main/java/parquet/hadoop/ParquetFileWriter.java": [
                0,
                0
            ],
            "parquet-pig/src/main/java/parquet/hadoop/ParquetInputFormat.java": [
                0,
                0
            ],
            "parquet-pig/src/main/java/parquet/hadoop/ParquetInputSplit.java": [
                0,
                0
            ],
            "parquet-pig/src/main/java/parquet/hadoop/ParquetOutputCommitter.java": [
                0,
                0
            ],
            "parquet-pig/src/main/java/parquet/hadoop/ParquetOutputFormat.java": [
                0,
                0
            ],
            "parquet-pig/src/main/java/parquet/hadoop/ParquetRecordReader.java": [
                0,
                0
            ],
            "parquet-pig/src/main/java/parquet/hadoop/ParquetRecordWriter.java": [
                0,
                0
            ],
            "parquet-pig/src/main/java/parquet/hadoop/PrintFooter.java": [
                0,
                0
            ],
            "parquet-pig/src/main/java/parquet/hadoop/ReadSupport.java": [
                0,
                0
            ],
            "parquet-pig/src/main/java/parquet/hadoop/WriteSupport.java": [
                0,
                0
            ],
            "parquet-pig/src/main/java/parquet/hadoop/metadata/BlockMetaData.java": [
                0,
                0
            ],
            "parquet-pig/src/main/java/parquet/hadoop/metadata/ColumnChunkMetaData.java": [
                0,
                0
            ],
            "parquet-pig/src/main/java/parquet/hadoop/metadata/ColumnMetaData.java": [
                0,
                0
            ],
            "parquet-pig/src/main/java/parquet/hadoop/metadata/CompressionCodecName.java": [
                0,
                0
            ],
            "parquet-pig/src/main/java/parquet/hadoop/metadata/FileMetaData.java": [
                0,
                0
            ],
            "parquet-pig/src/main/java/parquet/hadoop/metadata/ParquetMetadata.java": [
                0,
                0
            ],
            "parquet-pig/src/test/java/parquet/format/converter/TestParquetMetadataConverter.java": [
                0,
                0
            ],
            "parquet-pig/src/test/java/parquet/hadoop/TestInputFormat.java": [
                0,
                0
            ],
            "parquet-pig/src/test/java/parquet/hadoop/TestParquetFileWriter.java": [
                0,
                0
            ],
            "parquet-pig/src/test/java/parquet/hadoop/TestReadIntTestFile.java": [
                0,
                0
            ],
            "parquet-thrift/pom.xml": null,
            "pom.xml": null
        }
    },
    "f6adf0b5e678b5aff29cc3eeef9b3e9b240c0385": {
        "datetime": "2013-02-21T12:18:11-08:00",
        "summary": "integrate new converter; cleanup",
        "message": "integrate new converter; cleanup\n",
        "diff": {
            "parquet-column/pom.xml": null,
            "parquet-column/src/main/java/parquet/column/mem/MemColumnReadStore.java": [
                0,
                1
            ],
            "parquet-column/src/main/java/parquet/column/mem/MemColumnReader.java": [
                0,
                1
            ],
            "parquet-column/src/main/java/parquet/column/mem/MemColumnWriter.java": [
                0,
                1
            ],
            "parquet-column/src/main/java/parquet/column/mem/MemPageReader.java": [
                0,
                1
            ],
            "parquet-column/src/main/java/parquet/column/mem/MemPageWriter.java": [
                0,
                1
            ],
            "parquet-column/src/main/java/parquet/column/mem/ParquetDecodingException.java": [
                1,
                1
            ],
            "parquet-column/src/main/java/parquet/column/mem/ParquetEncodingException.java": [
                1,
                1
            ],
            "parquet-column/src/main/java/parquet/column/primitive/BitPackingColumnReader.java": [
                1,
                1
            ],
            "parquet-column/src/main/java/parquet/column/primitive/BitPackingColumnWriter.java": [
                1,
                1
            ],
            "parquet-column/src/main/java/parquet/column/primitive/BitReader.java": [
                1,
                1
            ],
            "parquet-column/src/main/java/parquet/column/primitive/BooleanPlainColumnReader.java": [
                1,
                1
            ],
            "parquet-column/src/main/java/parquet/column/primitive/BooleanPlainColumnWriter.java": [
                1,
                1
            ],
            "parquet-column/src/main/java/parquet/column/primitive/BoundedIntColumnReader.java": [
                1,
                1
            ],
            "parquet-column/src/main/java/parquet/column/primitive/BoundedIntColumnWriter.java": [
                1,
                1
            ],
            "parquet-column/src/main/java/parquet/column/primitive/PlainColumnReader.java": [
                1,
                1
            ],
            "parquet-column/src/main/java/parquet/column/primitive/PlainColumnWriter.java": [
                1,
                1
            ],
            "parquet-column/src/main/java/parquet/data/Group.java": [
                1,
                1
            ],
            "parquet-column/src/main/java/parquet/data/GroupFactory.java": [
                1,
                1
            ],
            "parquet-column/src/main/java/parquet/data/GroupRecordConsumer.java": [
                1,
                1
            ],
            "parquet-column/src/main/java/parquet/data/GroupValueSource.java": [
                1,
                1
            ],
            "parquet-column/src/main/java/parquet/data/GroupWriter.java": [
                1,
                1
            ],
            "parquet-column/src/main/java/parquet/data/simple/BinaryValue.java": [
                1,
                1
            ],
            "parquet-column/src/main/java/parquet/data/simple/BooleanValue.java": [
                1,
                1
            ],
            "parquet-column/src/main/java/parquet/data/simple/DoubleValue.java": [
                1,
                1
            ],
            "parquet-column/src/main/java/parquet/data/simple/FloatValue.java": [
                1,
                1
            ],
            "parquet-column/src/main/java/parquet/data/simple/IntegerValue.java": [
                1,
                1
            ],
            "parquet-column/src/main/java/parquet/data/simple/LongValue.java": [
                1,
                1
            ],
            "parquet-column/src/main/java/parquet/data/simple/Primitive.java": [
                1,
                1
            ],
            "parquet-column/src/main/java/parquet/data/simple/SimpleGroup.java": [
                2,
                2
            ],
            "parquet-column/src/main/java/parquet/data/simple/SimpleGroupFactory.java": [
                3,
                3
            ],
            "parquet-column/src/main/java/parquet/data/simple/example/Paper.java": [
                3,
                3
            ],
            "parquet-column/src/main/java/parquet/example/DummyRecordConverter.java": [
                0,
                55
            ],
            "parquet-column/src/main/java/parquet/example/data/simple/convert/GroupRecordConverter.java": [
                0,
                32
            ],
            "parquet-column/src/main/java/parquet/example/data/simple/convert/SimpleGroupConverter.java": [
                0,
                58
            ],
            "parquet-column/src/main/java/parquet/example/data/simple/convert/SimplePrimitiveConverter.java": [
                0,
                70
            ],
            "parquet-column/src/main/java/parquet/io/BaseRecordReader.java": [
                2,
                2
            ],
            "parquet-column/src/main/java/parquet/io/GroupColumnIO.java": [
                1,
                1
            ],
            "parquet-column/src/main/java/parquet/io/MessageColumnIO.java": [
                2,
                2
            ],
            "parquet-column/src/main/java/parquet/io/RecordConsumerLoggingWrapper.java": [
                1,
                1
            ],
            "parquet-column/src/main/java/parquet/io/RecordReaderImplementation.java": [
                92,
                30
            ],
            "parquet-column/src/main/java/parquet/io/convert/RecordConverter.java": [
                0,
                7
            ],
            "parquet-column/src/main/java/parquet/schema/PrimitiveType.java": [
                0,
                40
            ],
            "parquet-column/src/main/java/parquet/utils/Varint.java": [
                167,
                0
            ],
            "parquet-column/src/test/java/parquet/io/ExpectationValidatingConverter.java": [
                0,
                135
            ],
            "parquet-column/src/test/java/parquet/io/PerfTest.java": [
                24,
                11
            ],
            "parquet-column/src/test/java/parquet/io/TestColumnIO.java": [
                67,
                44
            ],
            "parquet-column/src/test/java/parquet/schema/TestMessageType.java": [
                1,
                1
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/ReadSupport.java": [
                2,
                2
            ],
            "parquet-hadoop/src/test/java/parquet/format/converter/TestParquetMetadataConverter.java": [
                1,
                1
            ],
            "parquet-hadoop/src/test/java/parquet/hadoop/TestInputFormat.java": [
                1,
                2
            ],
            "parquet-hadoop/src/test/java/parquet/hadoop/TestReadIntTestFile.java": [
                4,
                5
            ],
            "parquet-pig/src/main/java/parquet/pig/TupleReadSupport.java": [
                14,
                4
            ],
            "parquet-pig/src/main/java/parquet/pig/convert/MapConverter.java": [
                3,
                3
            ],
            "parquet-pig/src/main/java/parquet/pig/convert/TupleConverter.java": [
                40,
                53
            ],
            "parquet-pig/src/test/java/parquet/pig/ConverterConsumer.java": [
                0,
                98
            ],
            "parquet-pig/src/test/java/parquet/pig/TestTupleRecordConsumer.java": [
                14,
                17
            ],
            "parquet-pig/src/test/java/parquet/pig/TupleConsumerPerfTest.java": [
                29,
                19
            ],
            "pom.xml": null
        }
    },
    "78ff38c7e17cd5349bc92ccda18e7310c8e0274c": {
        "datetime": "2013-02-21T14:37:36-08:00",
        "summary": "improve logs",
        "message": "improve logs\n",
        "diff": {
            "parquet-hadoop/src/main/java/parquet/hadoop/ParquetFileReader.java": [
                0,
                2
            ],
            "parquet-pig/src/main/java/parquet/pig/ParquetLoader.java": [
                3,
                7
            ],
            "pom.xml": null
        }
    },
    "9058bae13942bb17e96ee5ba371b0013a58d473f": {
        "datetime": "2013-02-21T16:23:12-08:00",
        "summary": "improve use of summary file",
        "message": "improve use of summary file\n",
        "diff": {
            "parquet-hadoop/src/main/java/parquet/hadoop/ParquetFileReader.java": [
                10,
                14
            ],
            "parquet-pig/src/main/java/parquet/pig/ParquetLoader.java": [
                28,
                30
            ]
        }
    },
    "b2efb50d011d65644ad00fbbc7511731d9f8c47d": {
        "datetime": "2013-02-22T14:50:10-08:00",
        "summary": "refactor the read/write support",
        "message": "refactor the read/write support\n",
        "diff": {
            "parquet-hadoop/src/main/java/parquet/hadoop/BadConfigurationException.java": [
                0,
                29
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/ParquetInputFormat.java": [
                23,
                55
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/ParquetInputSplit.java": [
                23,
                35
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/ParquetOutputFormat.java": [
                22,
                51
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/ParquetRecordReader.java": [
                4,
                22
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/ParquetRecordWriter.java": [
                1,
                1
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/ReadSupport.java": [
                13,
                14
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/WriteSupport.java": [
                6,
                45
            ],
            "parquet-hadoop/src/test/java/parquet/hadoop/TestInputFormat.java": [
                18,
                2
            ],
            "parquet-pig/src/main/java/parquet/pig/ParquetLoader.java": [
                1,
                1
            ],
            "parquet-pig/src/main/java/parquet/pig/ParquetStorer.java": [
                10,
                1
            ],
            "parquet-pig/src/main/java/parquet/pig/PigMetaData.java": [
                47,
                5
            ],
            "parquet-pig/src/main/java/parquet/pig/TupleReadSupport.java": [
                22,
                10
            ],
            "parquet-pig/src/main/java/parquet/pig/TupleWriteSupport.java": [
                8,
                16
            ],
            "parquet-pig/src/test/java/parquet/pig/TestTupleRecordConsumer.java": [
                8,
                6
            ],
            "parquet-pig/src/test/java/parquet/pig/TupleConsumerPerfTest.java": [
                4,
                4
            ]
        }
    },
    "bbf7932d062125317c20f98e204a5d231ee491c8": {
        "datetime": "2013-02-22T15:26:59-08:00",
        "summary": "move to official pig release",
        "message": "move to official pig release\n",
        "diff": {
            "parquet-pig/lib/pig-0.11.0-SNAPSHOT.jar": null,
            "parquet-pig/pom.xml": null,
            "parquet-thrift/pom.xml": null
        }
    },
    "ad9dcbe0a0dcf3b94de5e7be868a273c076c52ba": {
        "datetime": "2013-02-26T13:57:52-08:00",
        "summary": "javadoc; original type support",
        "message": "javadoc; original type support\n",
        "diff": {
            "parquet-column/src/main/java/parquet/Log.java": [
                0,
                41
            ],
            "parquet-column/src/main/java/parquet/ParquetRuntimeException.java": [
                0,
                6
            ],
            "parquet-column/src/main/java/parquet/bytes/BytesInput.java": [
                0,
                48
            ],
            "parquet-column/src/main/java/parquet/bytes/CapacityByteArrayOutputStream.java": [
                0,
                4
            ],
            "parquet-column/src/main/java/parquet/column/ColumnDescriptor.java": [
                2,
                49
            ],
            "parquet-column/src/main/java/parquet/column/ColumnReadStore.java": [
                0,
                10
            ],
            "parquet-column/src/main/java/parquet/column/ColumnReader.java": [
                2,
                47
            ],
            "parquet-column/src/main/java/parquet/column/ColumnWriteStore.java": [
                0,
                14
            ],
            "parquet-column/src/main/java/parquet/column/ColumnWriter.java": [
                1,
                54
            ],
            "parquet-column/src/main/java/parquet/column/mem/MemColumnReader.java": [
                1,
                74
            ],
            "parquet-column/src/main/java/parquet/column/mem/Page.java": [
                0,
                18
            ],
            "parquet-column/src/main/java/parquet/column/mem/PageReadStore.java": [
                0,
                15
            ],
            "parquet-column/src/main/java/parquet/column/mem/PageReader.java": [
                1,
                14
            ],
            "parquet-column/src/main/java/parquet/column/mem/PageWriteStore.java": [
                0,
                11
            ],
            "parquet-column/src/main/java/parquet/column/mem/PageWriter.java": [
                1,
                20
            ],
            "parquet-column/src/main/java/parquet/column/primitive/BitPackingColumnReader.java": [
                1,
                21
            ],
            "parquet-column/src/main/java/parquet/column/primitive/BitPackingColumnWriter.java": [
                1,
                36
            ],
            "parquet-column/src/main/java/parquet/column/primitive/BooleanPlainColumnReader.java": [
                1,
                11
            ],
            "parquet-column/src/main/java/parquet/column/primitive/PrimitiveColumnReader.java": [
                0,
                6
            ],
            "parquet-column/src/main/java/parquet/column/primitive/PrimitiveColumnWriter.java": [
                0,
                42
            ],
            "parquet-column/src/main/java/parquet/example/DummyRecordConverter.java": [
                0,
                15
            ],
            "parquet-column/src/main/java/parquet/example/data/simple/convert/GroupRecordConverter.java": [
                0,
                15
            ],
            "parquet-column/src/main/java/parquet/example/data/simple/convert/SimpleGroupConverter.java": [
                0,
                15
            ],
            "parquet-column/src/main/java/parquet/example/data/simple/convert/SimplePrimitiveConverter.java": [
                0,
                15
            ],
            "parquet-column/src/main/java/parquet/io/ColumnIOFactory.java": [
                1,
                17
            ],
            "parquet-column/src/main/java/parquet/io/CompilationException.java": [
                0,
                21
            ],
            "parquet-column/src/main/java/parquet/io/GroupColumnIO.java": [
                1,
                7
            ],
            "parquet-column/src/main/java/parquet/io/InvalidRecordException.java": [
                0,
                6
            ],
            "parquet-column/src/main/java/parquet/io/MessageColumnIO.java": [
                0,
                7
            ],
            "parquet-column/src/main/java/parquet/io/ParquetDecodingException.java": [
                0,
                21
            ],
            "parquet-column/src/main/java/parquet/io/ParquetEncodingException.java": [
                0,
                21
            ],
            "parquet-column/src/main/java/parquet/io/PrimitiveColumnIO.java": [
                1,
                7
            ],
            "parquet-column/src/main/java/parquet/io/convert/RecordConverter.java": [
                0,
                28
            ],
            "parquet-column/src/main/java/parquet/parser/MessageTypeParser.java": [
                36,
                79
            ],
            "parquet-column/src/main/java/parquet/schema/ConversionPatterns.java": [
                0,
                72
            ],
            "parquet-column/src/main/java/parquet/schema/GroupType.java": [
                8,
                17
            ],
            "parquet-column/src/main/java/parquet/schema/MessageType.java": [
                2,
                2
            ],
            "parquet-column/src/main/java/parquet/schema/OriginalType.java": [
                0,
                24
            ],
            "parquet-column/src/main/java/parquet/schema/PrimitiveType.java": [
                1,
                8
            ],
            "parquet-column/src/main/java/parquet/schema/Type.java": [
                0,
                10
            ],
            "parquet-column/src/test/java/parquet/io/ExpectationValidatingConverter.java": [
                0,
                15
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/BadConfigurationException.java": [
                0,
                15
            ],
            "parquet-pig/src/main/java/parquet/pig/PigSchemaConverter.java": [
                5,
                14
            ],
            "parquet-pig/src/test/java/parquet/pig/ConverterConsumer.java": [
                0,
                15
            ]
        }
    },
    "42c418c56fcea3a6da2471fbadabdb77f085b6a7": {
        "datetime": "2013-02-26T15:35:15-08:00",
        "summary": "javadoc",
        "message": "javadoc\n",
        "diff": {
            "parquet-column/src/main/java/parquet/bytes/BytesUtils.java": [
                1,
                18
            ],
            "parquet-column/src/main/java/parquet/io/ColumnIO.java": [
                1,
                6
            ]
        }
    },
    "f2746e71fa579f5b56e055e8304ca292392e1ebb": {
        "datetime": "2013-02-28T10:27:23-08:00",
        "summary": "adding example output/input formats",
        "message": "adding example output/input formats\n",
        "diff": {
            "parquet-column/src/main/java/parquet/Log.java": [
                0,
                1
            ],
            "parquet-column/src/main/java/parquet/io/ColumnIO.java": [
                2,
                15
            ],
            "parquet-column/src/main/java/parquet/io/ColumnIOFactory.java": [
                3,
                3
            ],
            "parquet-column/src/main/java/parquet/io/GroupColumnIO.java": [
                2,
                2
            ],
            "parquet-column/src/main/java/parquet/io/MessageColumnIO.java": [
                2,
                2
            ],
            "parquet-column/src/main/java/parquet/io/PrimitiveColumnIO.java": [
                2,
                2
            ],
            "parquet-column/src/test/java/parquet/io/ExpectationValidatingRecordConsumer.java": [
                2,
                3
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/ReadSupport.java": [
                1,
                1
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/example/ExampleInputFormat.java": [
                0,
                20
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/example/ExampleOutputFormat.java": [
                0,
                43
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/example/GroupReadSupport.java": [
                0,
                24
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/example/GroupWriteSupport.java": [
                0,
                45
            ],
            "parquet-hadoop/src/test/java/parquet/hadoop/example/TestInputOutputFormat.java": [
                0,
                119
            ],
            "parquet-pig/src/main/java/parquet/pig/TupleWriteSupport.java": [
                2,
                2
            ]
        }
    },
    "77097b63b08eb366a2d667b41a73e87b401dccdd": {
        "datetime": "2013-02-28T10:30:20-08:00",
        "summary": "ThriftParquetOutputFormat",
        "message": "ThriftParquetOutputFormat\n",
        "diff": {
            "parquet-thrift/pom.xml": null,
            "parquet-thrift/src/main/java/parquet/hadoop/thrift/ParquetProtocol.java": [
                0,
                244
            ],
            "parquet-thrift/src/main/java/parquet/hadoop/thrift/ParquetReadProtocol.java": [
                0,
                210
            ],
            "parquet-thrift/src/main/java/parquet/hadoop/thrift/ParquetThriftInputFormat.java": [
                0,
                25
            ],
            "parquet-thrift/src/main/java/parquet/hadoop/thrift/ParquetThriftOutputFormat.java": [
                0,
                33
            ],
            "parquet-thrift/src/main/java/parquet/hadoop/thrift/ParquetWriteProtocol.java": [
                0,
                652
            ],
            "parquet-thrift/src/main/java/parquet/hadoop/thrift/ThriftMetaData.java": [
                0,
                62
            ],
            "parquet-thrift/src/main/java/parquet/hadoop/thrift/ThriftReadSupport.java": [
                0,
                38
            ],
            "parquet-thrift/src/main/java/parquet/hadoop/thrift/ThriftSchemaConverter.java": [
                0,
                235
            ],
            "parquet-thrift/src/main/java/parquet/hadoop/thrift/ThriftWriteSupport.java": [
                0,
                73
            ],
            "parquet-thrift/src/main/java/parquet/hadoop/thrift/struct/JSON.java": [
                0,
                33
            ],
            "parquet-thrift/src/main/java/parquet/hadoop/thrift/struct/ThriftField.java": [
                0,
                86
            ],
            "parquet-thrift/src/main/java/parquet/hadoop/thrift/struct/ThriftType.java": [
                0,
                372
            ],
            "parquet-thrift/src/main/java/parquet/hadoop/thrift/struct/ThriftTypeID.java": [
                0,
                89
            ],
            "parquet-thrift/src/test/java/parquet/hadoop/thrift/TestParquetProtocol.java": [
                0,
                264
            ],
            "parquet-thrift/src/test/java/parquet/hadoop/thrift/TestThriftSchemaConverter.java": [
                0,
                67
            ],
            "parquet-thrift/src/test/resources/parquet/hadoop/thrift/AddressBook.json": null,
            "pom.xml": null
        }
    },
    "92e93b16aefa348eebbcce6869746271d7b8b716": {
        "datetime": "2013-02-28T10:32:09-08:00",
        "summary": "license header",
        "message": "license header\n",
        "diff": {
            "parquet-hadoop/src/main/java/parquet/hadoop/example/ExampleInputFormat.java": [
                0,
                15
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/example/ExampleOutputFormat.java": [
                0,
                15
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/example/GroupReadSupport.java": [
                0,
                15
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/example/GroupWriteSupport.java": [
                0,
                15
            ],
            "parquet-hadoop/src/test/java/parquet/hadoop/example/TestInputOutputFormat.java": [
                0,
                15
            ],
            "parquet-thrift/src/main/java/parquet/hadoop/thrift/struct/JSON.java": [
                0,
                15
            ],
            "parquet-thrift/src/main/java/parquet/hadoop/thrift/struct/ThriftType.java": [
                0,
                15
            ],
            "parquet-thrift/src/test/java/parquet/hadoop/thrift/TestParquetProtocol.java": [
                0,
                15
            ]
        }
    },
    "c5ce15e0a29b83566fc445d0d17dc40163949b62": {
        "datetime": "2013-02-28T10:32:38-08:00",
        "summary": "license header",
        "message": "license header\n",
        "diff": {
            "parquet-hadoop/src/main/java/parquet/hadoop/example/ExampleInputFormat.java": [
                0,
                15
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/example/ExampleOutputFormat.java": [
                0,
                15
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/example/GroupReadSupport.java": [
                0,
                15
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/example/GroupWriteSupport.java": [
                0,
                15
            ],
            "parquet-hadoop/src/test/java/parquet/hadoop/example/TestInputOutputFormat.java": [
                0,
                15
            ]
        }
    },
    "6bf2661e6548a0d048c62c34564062598df43bc4": {
        "datetime": "2013-02-28T10:33:04-08:00",
        "summary": "Merge branch 'master' of github.com:julienledem/redelm into parquet_thrift",
        "message": "Merge branch 'master' of github.com:julienledem/redelm into parquet_thrift\n",
        "diff": {}
    },
    "af20471a423684375533774320b874a49195d4f8": {
        "datetime": "2013-03-01T16:32:46-08:00",
        "summary": "javadoc; bug fixes; thrift support; refactoring",
        "message": "javadoc; bug fixes; thrift support; refactoring\n",
        "diff": {
            "parquet-column/src/main/java/parquet/Log.java": [
                1,
                1
            ],
            "parquet-column/src/main/java/parquet/bytes/BytesUtils.java": [
                1,
                1
            ],
            "parquet-column/src/main/java/parquet/column/primitive/PrimitiveColumnReader.java": [
                5,
                38
            ],
            "parquet-column/src/main/java/parquet/example/DummyRecordConverter.java": [
                35,
                69
            ],
            "parquet-column/src/main/java/parquet/example/data/simple/convert/GroupRecordConverter.java": [
                8,
                17
            ],
            "parquet-column/src/main/java/parquet/example/data/simple/convert/SimpleGroupConverter.java": [
                18,
                9
            ],
            "parquet-column/src/main/java/parquet/io/RecordReaderImplementation.java": [
                5,
                6
            ],
            "parquet-column/src/main/java/parquet/io/convert/Converter.java": [
                0,
                37
            ],
            "parquet-column/src/main/java/parquet/io/convert/GroupConverter.java": [
                30,
                15
            ],
            "parquet-column/src/main/java/parquet/io/convert/PrimitiveConverter.java": [
                22,
                28
            ],
            "parquet-column/src/main/java/parquet/io/convert/RecordConverter.java": [
                3,
                5
            ],
            "parquet-column/src/main/java/parquet/schema/GroupType.java": [
                0,
                15
            ],
            "parquet-column/src/main/java/parquet/schema/MessageType.java": [
                0,
                6
            ],
            "parquet-column/src/main/java/parquet/schema/PrimitiveType.java": [
                0,
                5
            ],
            "parquet-column/src/main/java/parquet/schema/Type.java": [
                0,
                8
            ],
            "parquet-column/src/main/java/parquet/schema/TypeConverter.java": [
                0,
                37
            ],
            "parquet-column/src/test/java/parquet/io/ExpectationValidatingConverter.java": [
                111,
                118
            ],
            "parquet-column/src/test/java/parquet/io/PerfTest.java": [
                1,
                1
            ],
            "parquet-column/src/test/java/parquet/io/TestColumnIO.java": [
                1,
                1
            ],
            "parquet-pig/src/main/java/parquet/pig/TupleReadSupport.java": [
                1,
                2
            ],
            "parquet-pig/src/main/java/parquet/pig/convert/MapConverter.java": [
                19,
                9
            ],
            "parquet-pig/src/main/java/parquet/pig/convert/TupleConverter.java": [
                37,
                13
            ],
            "parquet-pig/src/main/java/parquet/pig/convert/TupleRecordConverter.java": [
                0,
                28
            ],
            "parquet-pig/src/main/java/parquet/pig/converter/BagConverter.java": [
                78,
                0
            ],
            "parquet-pig/src/main/java/parquet/pig/converter/Converter.java": [
                57,
                0
            ],
            "parquet-pig/src/main/java/parquet/pig/converter/MapConverter.java": [
                81,
                0
            ],
            "parquet-pig/src/main/java/parquet/pig/converter/MapKeyValueConverter.java": [
                91,
                0
            ],
            "parquet-pig/src/main/java/parquet/pig/converter/MessageConverter.java": [
                117,
                0
            ],
            "parquet-pig/src/main/java/parquet/pig/converter/TupleConverter.java": [
                136,
                0
            ],
            "parquet-pig/src/test/java/parquet/pig/ConverterConsumer.java": [
                4,
                3
            ],
            "parquet-pig/src/test/java/parquet/pig/TestTupleRecordConsumer.java": [
                2,
                3
            ],
            "parquet-thrift/src/main/java/parquet/hadoop/thrift/ParquetProtocol.java": [
                42,
                50
            ],
            "parquet-thrift/src/main/java/parquet/hadoop/thrift/ParquetReadProtocol.java": [
                210,
                0
            ],
            "parquet-thrift/src/main/java/parquet/hadoop/thrift/ParquetThriftOutputFormat.java": [
                2,
                11
            ],
            "parquet-thrift/src/main/java/parquet/hadoop/thrift/ParquetWriteProtocol.java": [
                29,
                29
            ],
            "parquet-thrift/src/main/java/parquet/hadoop/thrift/ThriftMetaData.java": [
                1,
                1
            ],
            "parquet-thrift/src/main/java/parquet/hadoop/thrift/ThriftSchemaConverter.java": [
                5,
                5
            ],
            "parquet-thrift/src/main/java/parquet/hadoop/thrift/ThriftWriteSupport.java": [
                12,
                23
            ],
            "parquet-thrift/src/main/java/parquet/hadoop/thrift/struct/JSON.java": [
                1,
                1
            ],
            "parquet-thrift/src/main/java/parquet/hadoop/thrift/struct/ThriftField.java": [
                1,
                1
            ],
            "parquet-thrift/src/main/java/parquet/hadoop/thrift/struct/ThriftType.java": [
                13,
                13
            ],
            "parquet-thrift/src/main/java/parquet/hadoop/thrift/struct/ThriftTypeID.java": [
                13,
                13
            ],
            "parquet-thrift/src/main/java/parquet/thrift/ParquetReadProtocol.java": [
                0,
                159
            ],
            "parquet-thrift/src/main/java/parquet/thrift/ThriftReader.java": [
                0,
                10
            ],
            "parquet-thrift/src/main/java/parquet/thrift/ThriftRecordConverter.java": [
                0,
                441
            ],
            "parquet-thrift/src/test/java/parquet/hadoop/thrift/TestInputOutputFormat.java": [
                0,
                134
            ],
            "parquet-thrift/src/test/java/parquet/hadoop/thrift/TestParquetProtocol.java": [
                2,
                4
            ],
            "parquet-thrift/src/test/java/parquet/hadoop/thrift/TestParquetReadProtocol.java": [
                0,
                91
            ],
            "parquet-thrift/src/test/java/parquet/hadoop/thrift/TestThriftSchemaConverter.java": [
                2,
                3
            ]
        }
    },
    "25b755958b1906dd3d4f6767a2008d8566746062": {
        "datetime": "2013-03-04T11:02:05-08:00",
        "summary": "thrift read protocol; fix repetition level size in little endian",
        "message": "thrift read protocol; fix repetition level size in little endian\n",
        "diff": {
            "parquet-column/src/main/java/parquet/Log.java": [
                1,
                1
            ],
            "parquet-column/src/main/java/parquet/bytes/BytesInput.java": [
                2,
                2
            ],
            "parquet-column/src/main/java/parquet/bytes/BytesUtils.java": [
                13,
                6
            ],
            "parquet-column/src/main/java/parquet/column/mem/MemColumnReader.java": [
                0,
                3
            ],
            "parquet-column/src/main/java/parquet/column/primitive/BitPackingColumnReader.java": [
                0,
                3
            ],
            "parquet-column/src/main/java/parquet/column/primitive/BoundedIntColumnReader.java": [
                2,
                3
            ],
            "parquet-column/src/main/java/parquet/example/data/GroupValueSource.java": [
                0,
                2
            ],
            "parquet-column/src/main/java/parquet/example/data/simple/BinaryValue.java": [
                1,
                2
            ],
            "parquet-column/src/main/java/parquet/example/data/simple/DoubleValue.java": [
                0,
                4
            ],
            "parquet-column/src/main/java/parquet/example/data/simple/FloatValue.java": [
                0,
                4
            ],
            "parquet-column/src/main/java/parquet/example/data/simple/SimpleGroup.java": [
                0,
                5
            ],
            "parquet-column/src/main/java/parquet/example/data/simple/convert/GroupRecordConverter.java": [
                5,
                3
            ],
            "parquet-column/src/main/java/parquet/example/data/simple/convert/SimpleGroupConverter.java": [
                1,
                1
            ],
            "parquet-column/src/main/java/parquet/schema/GroupType.java": [
                3,
                3
            ],
            "parquet-column/src/test/java/parquet/bytes/TestBytesUtil.java": [
                31,
                21
            ],
            "parquet-column/src/test/java/parquet/io/ExpectationValidatingConverter.java": [
                3,
                5
            ],
            "parquet-column/src/test/java/parquet/io/TestColumnIO.java": [
                25,
                25
            ],
            "parquet-hadoop/src/main/java/parquet/format/converter/ParquetMetadataConverter.java": [
                0,
                1
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/ParquetFileWriter.java": [
                0,
                1
            ],
            "parquet-hadoop/src/test/java/parquet/hadoop/TestReadIntTestFile.java": [
                5,
                32
            ],
            "parquet-pig/pom.xml": null,
            "parquet-thrift/pom.xml": null,
            "parquet-thrift/src/main/java/parquet/thrift/TBaseRecordConverter.java": [
                0,
                29
            ],
            "parquet-thrift/src/main/java/parquet/thrift/ThriftRecordConverter.java": [
                177,
                395
            ],
            "parquet-thrift/src/test/java/parquet/hadoop/thrift/TestParquetReadProtocol.java": [
                14,
                30
            ]
        }
    },
    "9c79b0876401264707d3bfae37362afc72445df5": {
        "datetime": "2013-03-04T11:37:30-08:00",
        "summary": "thrift input/output format support",
        "message": "thrift input/output format support\n",
        "diff": {
            "parquet-thrift/src/main/java/parquet/hadoop/thrift/ThriftReadSupport.java": [
                2,
                9
            ],
            "parquet-thrift/src/main/java/parquet/hadoop/thrift/ThriftWriteSupport.java": [
                1,
                1
            ],
            "parquet-thrift/src/main/java/parquet/thrift/ThriftMetaData.java": [
                3,
                20
            ],
            "parquet-thrift/src/main/java/parquet/thrift/struct/ThriftType.java": [
                12,
                0
            ],
            "parquet-thrift/src/test/java/parquet/hadoop/thrift/TestInputOutputFormat.java": [
                11,
                23
            ]
        }
    },
    "ecf19dc3d917d124c33d463d662a1fb885bfb243": {
        "datetime": "2013-03-04T12:09:31-08:00",
        "summary": "add encoding information for the column reader; allow column writer to specify the encoding",
        "message": "add encoding information for the column reader; allow column writer to specify the encoding\n",
        "diff": {
            "parquet-column/src/main/java/parquet/column/Encoding.java": [
                0,
                20
            ],
            "parquet-column/src/main/java/parquet/column/mem/MemColumnReader.java": [
                1,
                7
            ],
            "parquet-column/src/main/java/parquet/column/mem/MemColumnWriter.java": [
                2,
                3
            ],
            "parquet-column/src/main/java/parquet/column/mem/MemPageWriter.java": [
                2,
                3
            ],
            "parquet-column/src/main/java/parquet/column/mem/Page.java": [
                2,
                19
            ],
            "parquet-column/src/main/java/parquet/column/mem/PageWriter.java": [
                1,
                2
            ],
            "parquet-column/src/main/java/parquet/column/primitive/BooleanPlainColumnWriter.java": [
                1,
                8
            ],
            "parquet-column/src/main/java/parquet/column/primitive/DataColumnWriter.java": [
                0,
                33
            ],
            "parquet-column/src/main/java/parquet/column/primitive/PlainColumnWriter.java": [
                1,
                7
            ],
            "parquet-column/src/main/java/parquet/column/primitive/PrimitiveColumnWriter.java": [
                0,
                1
            ],
            "parquet-column/src/main/java/parquet/io/convert/GroupConverter.java": [
                0,
                15
            ],
            "parquet-column/src/main/java/parquet/io/convert/PrimitiveConverter.java": [
                0,
                15
            ],
            "parquet-column/src/main/java/parquet/schema/TypeConverter.java": [
                0,
                15
            ],
            "parquet-column/src/test/java/parquet/column/mem/TestMemPageStore.java": [
                9,
                6
            ],
            "parquet-hadoop/src/main/java/parquet/format/converter/ParquetMetadataConverter.java": [
                0,
                19
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/ColumnChunkPageReadStore.java": [
                1,
                2
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/ColumnChunkPageWriteStore.java": [
                3,
                2
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/ParquetFileReader.java": [
                1,
                2
            ],
            "parquet-pig/src/main/java/parquet/pig/convert/TupleRecordConverter.java": [
                0,
                15
            ],
            "parquet-thrift/src/main/java/parquet/thrift/TBaseRecordConverter.java": [
                0,
                15
            ],
            "parquet-thrift/src/main/java/parquet/thrift/ThriftReader.java": [
                0,
                15
            ],
            "parquet-thrift/src/main/java/parquet/thrift/ThriftRecordConverter.java": [
                0,
                15
            ],
            "parquet-thrift/src/test/java/parquet/hadoop/thrift/TestParquetReadProtocol.java": [
                0,
                15
            ]
        }
    },
    "e8f8429e11372c04afffdcd133199ff87872eebf": {
        "datetime": "2013-03-04T16:15:54-08:00",
        "summary": "populate encodings in column metadata",
        "message": "populate encodings in column metadata\n",
        "diff": {
            "parquet-hadoop/src/main/java/parquet/format/converter/ParquetMetadataConverter.java": [
                3,
                22
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/ColumnChunkPageWriteStore.java": [
                3,
                10
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/ParquetFileWriter.java": [
                5,
                12
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/metadata/ColumnChunkMetaData.java": [
                1,
                15
            ],
            "parquet-hadoop/src/test/java/parquet/hadoop/TestInputFormat.java": [
                2,
                3
            ],
            "parquet-hadoop/src/test/java/parquet/hadoop/TestParquetFileWriter.java": [
                7,
                8
            ],
            "parquet-pig/src/test/java/parquet/pig/GenerateIntTestFile.java": [
                1,
                4
            ]
        }
    },
    "d35c264e8f922667d9d04263df2e3b18ec9205cc": {
        "datetime": "2013-03-05T10:15:13-08:00",
        "summary": "turn byte[] into Binary object in the api",
        "message": "turn byte[] into Binary object in the api\n",
        "diff": {
            "parquet-column/src/main/java/parquet/column/ColumnReader.java": [
                1,
                3
            ],
            "parquet-column/src/main/java/parquet/column/ColumnWriter.java": [
                1,
                3
            ],
            "parquet-column/src/main/java/parquet/column/mem/MemColumnReadStore.java": [
                2,
                3
            ],
            "parquet-column/src/main/java/parquet/column/mem/MemColumnReader.java": [
                1,
                2
            ],
            "parquet-column/src/main/java/parquet/column/mem/MemColumnWriter.java": [
                1,
                2
            ],
            "parquet-column/src/main/java/parquet/column/primitive/DevNullColumnReader.java": [
                3,
                5
            ],
            "parquet-column/src/main/java/parquet/column/primitive/DevNullColumnWriter.java": [
                1,
                2
            ],
            "parquet-column/src/main/java/parquet/column/primitive/PlainColumnReader.java": [
                2,
                4
            ],
            "parquet-column/src/main/java/parquet/column/primitive/PlainColumnWriter.java": [
                3,
                4
            ],
            "parquet-column/src/main/java/parquet/column/primitive/PrimitiveColumnReader.java": [
                1,
                3
            ],
            "parquet-column/src/main/java/parquet/column/primitive/PrimitiveColumnWriter.java": [
                1,
                2
            ],
            "parquet-column/src/main/java/parquet/example/data/Group.java": [
                4,
                5
            ],
            "parquet-column/src/main/java/parquet/example/data/GroupRecordConsumer.java": [
                1,
                2
            ],
            "parquet-column/src/main/java/parquet/example/data/GroupValueSource.java": [
                2,
                3
            ],
            "parquet-column/src/main/java/parquet/example/data/simple/BinaryValue.java": [
                5,
                6
            ],
            "parquet-column/src/main/java/parquet/example/data/simple/Primitive.java": [
                1,
                2
            ],
            "parquet-column/src/main/java/parquet/example/data/simple/SimpleGroup.java": [
                3,
                4
            ],
            "parquet-column/src/main/java/parquet/example/data/simple/convert/SimplePrimitiveConverter.java": [
                1,
                2
            ],
            "parquet-column/src/main/java/parquet/io/BaseRecordReader.java": [
                1,
                1
            ],
            "parquet-column/src/main/java/parquet/io/Binary.java": [
                0,
                99
            ],
            "parquet-column/src/main/java/parquet/io/ConverterConsumer.java": [
                1,
                1
            ],
            "parquet-column/src/main/java/parquet/io/MessageColumnIO.java": [
                2,
                2
            ],
            "parquet-column/src/main/java/parquet/io/RecordConsumer.java": [
                1,
                1
            ],
            "parquet-column/src/main/java/parquet/io/RecordConsumerLoggingWrapper.java": [
                2,
                2
            ],
            "parquet-column/src/main/java/parquet/io/ValidatingRecordConsumer.java": [
                1,
                1
            ],
            "parquet-column/src/main/java/parquet/io/convert/PrimitiveConverter.java": [
                1,
                3
            ],
            "parquet-column/src/test/java/parquet/column/mem/TestMemColumn.java": [
                2,
                3
            ],
            "parquet-column/src/test/java/parquet/io/ExpectationValidatingConverter.java": [
                2,
                2
            ],
            "parquet-column/src/test/java/parquet/io/ExpectationValidatingRecordConsumer.java": [
                2,
                2
            ],
            "parquet-column/src/test/java/parquet/io/TestColumnIO.java": [
                2,
                2
            ],
            "parquet-pig/src/main/java/parquet/pig/TupleRecordConsumer.java": [
                2,
                3
            ],
            "parquet-pig/src/main/java/parquet/pig/TupleWriteSupport.java": [
                1,
                2
            ],
            "parquet-pig/src/main/java/parquet/pig/convert/MapConverter.java": [
                2,
                3
            ],
            "parquet-pig/src/main/java/parquet/pig/convert/TupleConverter.java": [
                4,
                5
            ],
            "parquet-pig/src/test/java/parquet/pig/GenerateTPCH.java": [
                1,
                2
            ],
            "parquet-thrift/src/main/java/parquet/thrift/ParquetWriteProtocol.java": [
                3,
                4
            ],
            "parquet-thrift/src/main/java/parquet/thrift/ThriftRecordConverter.java": [
                19,
                5
            ]
        }
    },
    "932695cbb394dcc005ccbff07ef9ab8c0f6cf5c4": {
        "datetime": "2013-03-05T10:15:38-08:00",
        "summary": "update dependency on elephant-bird",
        "message": "update dependency on elephant-bird\n",
        "diff": {
            "parquet-thrift/pom.xml": null
        }
    },
    "07ea133db57bdfa32fdcc03b370f0ac89d35fd0d": {
        "datetime": "2013-03-05T10:16:54-08:00",
        "summary": "license headers",
        "message": "license headers\n",
        "diff": {
            "parquet-column/src/main/java/parquet/io/Binary.java": [
                0,
                15
            ],
            "parquet-thrift/src/main/java/parquet/thrift/ThriftRecordConverter.java": [
                0,
                15
            ]
        }
    },
    "ee8ec11a25ede3279df609ee1e402476d8b6d028": {
        "datetime": "2013-03-05T11:41:50-08:00",
        "summary": "javadoc; turn off the compatibility test for now",
        "message": "javadoc; turn off the compatibility test for now\n",
        "diff": {
            "parquet-hadoop/src/test/java/parquet/hadoop/TestReadIntTestFile.java": [
                5,
                52
            ],
            "parquet-thrift/src/main/java/parquet/thrift/ThriftRecordConverter.java": [
                24,
                103
            ]
        }
    },
    "54dd652ef68572c3796efbbe636699bf00d3fc6c": {
        "datetime": "2013-03-05T13:47:25-08:00",
        "summary": "integrate the thrift changes",
        "message": "integrate the thrift changes\n",
        "diff": {
            "parquet-hadoop/src/main/java/parquet/format/converter/ParquetMetadataConverter.java": [
                15,
                27
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/ColumnChunkPageWriteStore.java": [
                7,
                6
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/ParquetFileWriter.java": [
                9,
                5
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/metadata/ParquetMetadata.java": [
                1,
                1
            ],
            "parquet-hadoop/src/test/java/parquet/hadoop/TestReadIntTestFile.java": [
                1,
                0
            ]
        }
    },
    "0973e7dd05799d75a3907c0e27415b68310c90ea": {
        "datetime": "2013-03-05T14:56:57-08:00",
        "summary": "removed outdated comment",
        "message": "removed outdated comment\n",
        "diff": {
            "parquet-thrift/src/main/java/parquet/thrift/ThriftSchemaConverter.java": [
                1,
                1
            ]
        }
    },
    "c3c22a050d91af4b80974a6290f055d8ff49b401": {
        "datetime": "2013-03-05T14:58:15-08:00",
        "summary": "Merge pull request #1 from Parquet/parquet_thrift",
        "message": "Merge pull request #1 from Parquet/parquet_thrift\n\nParquet thrift support and some related refactoring",
        "diff": {
            "parquet-column/src/main/java/parquet/bytes/BytesInput.java": [
                2,
                2
            ],
            "parquet-column/src/main/java/parquet/bytes/BytesUtils.java": [
                14,
                7
            ],
            "parquet-column/src/main/java/parquet/column/ColumnReader.java": [
                1,
                3
            ],
            "parquet-column/src/main/java/parquet/column/ColumnWriter.java": [
                1,
                3
            ],
            "parquet-column/src/main/java/parquet/column/Encoding.java": [
                0,
                20
            ],
            "parquet-column/src/main/java/parquet/column/mem/MemColumnReadStore.java": [
                2,
                3
            ],
            "parquet-column/src/main/java/parquet/column/mem/MemColumnReader.java": [
                2,
                12
            ],
            "parquet-column/src/main/java/parquet/column/mem/MemColumnWriter.java": [
                3,
                5
            ],
            "parquet-column/src/main/java/parquet/column/mem/MemPageWriter.java": [
                2,
                3
            ],
            "parquet-column/src/main/java/parquet/column/mem/Page.java": [
                2,
                19
            ],
            "parquet-column/src/main/java/parquet/column/mem/PageWriter.java": [
                1,
                2
            ],
            "parquet-column/src/main/java/parquet/column/primitive/BitPackingColumnReader.java": [
                0,
                3
            ],
            "parquet-column/src/main/java/parquet/column/primitive/BooleanPlainColumnWriter.java": [
                1,
                8
            ],
            "parquet-column/src/main/java/parquet/column/primitive/BoundedIntColumnReader.java": [
                2,
                3
            ],
            "parquet-column/src/main/java/parquet/column/primitive/DataColumnWriter.java": [
                0,
                33
            ],
            "parquet-column/src/main/java/parquet/column/primitive/DevNullColumnReader.java": [
                3,
                5
            ],
            "parquet-column/src/main/java/parquet/column/primitive/DevNullColumnWriter.java": [
                1,
                2
            ],
            "parquet-column/src/main/java/parquet/column/primitive/PlainColumnReader.java": [
                2,
                4
            ],
            "parquet-column/src/main/java/parquet/column/primitive/PlainColumnWriter.java": [
                4,
                11
            ],
            "parquet-column/src/main/java/parquet/column/primitive/PrimitiveColumnReader.java": [
                6,
                41
            ],
            "parquet-column/src/main/java/parquet/column/primitive/PrimitiveColumnWriter.java": [
                1,
                3
            ],
            "parquet-column/src/main/java/parquet/example/DummyRecordConverter.java": [
                35,
                69
            ],
            "parquet-column/src/main/java/parquet/example/data/Group.java": [
                4,
                5
            ],
            "parquet-column/src/main/java/parquet/example/data/GroupRecordConsumer.java": [
                1,
                2
            ],
            "parquet-column/src/main/java/parquet/example/data/GroupValueSource.java": [
                2,
                5
            ],
            "parquet-column/src/main/java/parquet/example/data/simple/BinaryValue.java": [
                5,
                7
            ],
            "parquet-column/src/main/java/parquet/example/data/simple/DoubleValue.java": [
                0,
                4
            ],
            "parquet-column/src/main/java/parquet/example/data/simple/FloatValue.java": [
                0,
                4
            ],
            "parquet-column/src/main/java/parquet/example/data/simple/Primitive.java": [
                1,
                2
            ],
            "parquet-column/src/main/java/parquet/example/data/simple/SimpleGroup.java": [
                3,
                9
            ],
            "parquet-column/src/main/java/parquet/example/data/simple/convert/GroupRecordConverter.java": [
                10,
                17
            ],
            "parquet-column/src/main/java/parquet/example/data/simple/convert/SimpleGroupConverter.java": [
                19,
                10
            ],
            "parquet-column/src/main/java/parquet/example/data/simple/convert/SimplePrimitiveConverter.java": [
                1,
                2
            ],
            "parquet-column/src/main/java/parquet/io/BaseRecordReader.java": [
                1,
                1
            ],
            "parquet-column/src/main/java/parquet/io/Binary.java": [
                0,
                114
            ],
            "parquet-column/src/main/java/parquet/io/MessageColumnIO.java": [
                2,
                2
            ],
            "parquet-column/src/main/java/parquet/io/RecordConsumer.java": [
                1,
                1
            ],
            "parquet-column/src/main/java/parquet/io/RecordConsumerLoggingWrapper.java": [
                2,
                2
            ],
            "parquet-column/src/main/java/parquet/io/RecordReaderImplementation.java": [
                5,
                6
            ],
            "parquet-column/src/main/java/parquet/io/ValidatingRecordConsumer.java": [
                1,
                1
            ],
            "parquet-column/src/main/java/parquet/io/convert/Converter.java": [
                0,
                37
            ],
            "parquet-column/src/main/java/parquet/io/convert/GroupConverter.java": [
                15,
                15
            ],
            "parquet-column/src/main/java/parquet/io/convert/PrimitiveConverter.java": [
                8,
                31
            ],
            "parquet-column/src/main/java/parquet/io/convert/RecordConverter.java": [
                3,
                5
            ],
            "parquet-column/src/main/java/parquet/schema/GroupType.java": [
                0,
                15
            ],
            "parquet-column/src/main/java/parquet/schema/MessageType.java": [
                0,
                6
            ],
            "parquet-column/src/main/java/parquet/schema/PrimitiveType.java": [
                0,
                5
            ],
            "parquet-column/src/main/java/parquet/schema/Type.java": [
                0,
                8
            ],
            "parquet-column/src/main/java/parquet/schema/TypeConverter.java": [
                0,
                52
            ],
            "parquet-column/src/test/java/parquet/bytes/TestBytesUtil.java": [
                31,
                21
            ],
            "parquet-column/src/test/java/parquet/column/mem/TestMemColumn.java": [
                2,
                3
            ],
            "parquet-column/src/test/java/parquet/column/mem/TestMemPageStore.java": [
                9,
                6
            ],
            "parquet-column/src/test/java/parquet/io/ExpectationValidatingConverter.java": [
                111,
                120
            ],
            "parquet-column/src/test/java/parquet/io/ExpectationValidatingRecordConsumer.java": [
                2,
                2
            ],
            "parquet-column/src/test/java/parquet/io/PerfTest.java": [
                1,
                1
            ],
            "parquet-column/src/test/java/parquet/io/TestColumnIO.java": [
                28,
                28
            ],
            "parquet-hadoop/src/main/java/parquet/format/converter/ParquetMetadataConverter.java": [
                15,
                66
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/ColumnChunkPageReadStore.java": [
                1,
                2
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/ColumnChunkPageWriteStore.java": [
                11,
                16
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/ParquetFileReader.java": [
                1,
                2
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/ParquetFileWriter.java": [
                12,
                16
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/metadata/ColumnChunkMetaData.java": [
                1,
                15
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/metadata/ParquetMetadata.java": [
                1,
                1
            ],
            "parquet-hadoop/src/test/java/parquet/hadoop/TestInputFormat.java": [
                2,
                3
            ],
            "parquet-hadoop/src/test/java/parquet/hadoop/TestParquetFileWriter.java": [
                7,
                8
            ],
            "parquet-hadoop/src/test/java/parquet/hadoop/TestReadIntTestFile.java": [
                7,
                80
            ],
            "parquet-pig/pom.xml": null,
            "parquet-pig/src/main/java/parquet/pig/TupleReadSupport.java": [
                1,
                2
            ],
            "parquet-pig/src/main/java/parquet/pig/TupleRecordConsumer.java": [
                2,
                3
            ],
            "parquet-pig/src/main/java/parquet/pig/TupleWriteSupport.java": [
                1,
                2
            ],
            "parquet-pig/src/main/java/parquet/pig/convert/MapConverter.java": [
                21,
                12
            ],
            "parquet-pig/src/main/java/parquet/pig/convert/TupleConverter.java": [
                41,
                18
            ],
            "parquet-pig/src/main/java/parquet/pig/convert/TupleRecordConverter.java": [
                0,
                43
            ],
            "parquet-pig/src/main/java/parquet/pig/converter/BagConverter.java": [
                78,
                0
            ],
            "parquet-pig/src/main/java/parquet/pig/converter/Converter.java": [
                57,
                0
            ],
            "parquet-pig/src/main/java/parquet/pig/converter/MapConverter.java": [
                81,
                0
            ],
            "parquet-pig/src/main/java/parquet/pig/converter/MapKeyValueConverter.java": [
                91,
                0
            ],
            "parquet-pig/src/main/java/parquet/pig/converter/MessageConverter.java": [
                117,
                0
            ],
            "parquet-pig/src/main/java/parquet/pig/converter/TupleConverter.java": [
                136,
                0
            ],
            "parquet-pig/src/test/java/parquet/pig/ConverterConsumer.java": [
                5,
                4
            ],
            "parquet-pig/src/test/java/parquet/pig/GenerateIntTestFile.java": [
                1,
                4
            ],
            "parquet-pig/src/test/java/parquet/pig/GenerateTPCH.java": [
                1,
                2
            ],
            "parquet-pig/src/test/java/parquet/pig/TestTupleRecordConsumer.java": [
                2,
                3
            ],
            "parquet-thrift/pom.xml": null,
            "parquet-thrift/src/main/java/parquet/hadoop/thrift/ParquetThriftInputFormat.java": [
                0,
                25
            ],
            "parquet-thrift/src/main/java/parquet/hadoop/thrift/ParquetThriftOutputFormat.java": [
                0,
                42
            ],
            "parquet-thrift/src/main/java/parquet/hadoop/thrift/ThriftReadSupport.java": [
                0,
                45
            ],
            "parquet-thrift/src/main/java/parquet/hadoop/thrift/ThriftWriteSupport.java": [
                0,
                84
            ],
            "parquet-thrift/src/main/java/parquet/thrift/ParquetProtocol.java": [
                0,
                252
            ],
            "parquet-thrift/src/main/java/parquet/thrift/ParquetReadProtocol.java": [
                0,
                159
            ],
            "parquet-thrift/src/main/java/parquet/thrift/ParquetWriteProtocol.java": [
                0,
                653
            ],
            "parquet-thrift/src/main/java/parquet/thrift/TBaseRecordConverter.java": [
                0,
                44
            ],
            "parquet-thrift/src/main/java/parquet/thrift/ThriftMetaData.java": [
                0,
                79
            ],
            "parquet-thrift/src/main/java/parquet/thrift/ThriftReader.java": [
                0,
                25
            ],
            "parquet-thrift/src/main/java/parquet/thrift/ThriftRecordConverter.java": [
                0,
                754
            ],
            "parquet-thrift/src/main/java/parquet/thrift/ThriftSchemaConverter.java": [
                0,
                235
            ],
            "parquet-thrift/src/main/java/parquet/thrift/struct/JSON.java": [
                0,
                48
            ],
            "parquet-thrift/src/main/java/parquet/thrift/struct/ThriftField.java": [
                0,
                86
            ],
            "parquet-thrift/src/main/java/parquet/thrift/struct/ThriftType.java": [
                0,
                375
            ],
            "parquet-thrift/src/main/java/parquet/thrift/struct/ThriftTypeID.java": [
                0,
                89
            ],
            "parquet-thrift/src/test/java/parquet/hadoop/thrift/TestInputOutputFormat.java": [
                0,
                146
            ],
            "parquet-thrift/src/test/java/parquet/hadoop/thrift/TestParquetReadProtocol.java": [
                0,
                122
            ],
            "parquet-thrift/src/test/java/parquet/hadoop/thrift/TestParquetWriteProtocol.java": [
                0,
                281
            ],
            "parquet-thrift/src/test/java/parquet/hadoop/thrift/TestThriftSchemaConverter.java": [
                0,
                68
            ],
            "parquet-thrift/src/test/resources/parquet/hadoop/thrift/AddressBook.json": null,
            "pom.xml": null
        }
    },
    "003299e4240a1f131c4d1b9d3fe5f3b4ff9fd0e6": {
        "datetime": "2013-03-05T15:24:20-08:00",
        "summary": "Style cleanup and other miscellanea (javadoc, etc)",
        "message": "Style cleanup and other miscellanea (javadoc, etc)\n\nAdded other review comments as TODOs\n",
        "diff": {
            "parquet-column/src/main/java/parquet/bytes/BytesUtils.java": [
                0,
                4
            ],
            "parquet-column/src/main/java/parquet/bytes/LittleEndianDataInputStream.java": [
                0,
                6
            ],
            "parquet-column/src/main/java/parquet/bytes/LittleEndianDataOutputStream.java": [
                0,
                3
            ],
            "parquet-column/src/main/java/parquet/column/ColumnDescriptor.java": [
                27,
                5
            ],
            "parquet-column/src/main/java/parquet/column/ColumnReadStore.java": [
                3,
                2
            ],
            "parquet-column/src/main/java/parquet/column/ColumnReader.java": [
                16,
                9
            ],
            "parquet-column/src/main/java/parquet/column/ColumnWriteStore.java": [
                5,
                3
            ],
            "parquet-column/src/main/java/parquet/column/ColumnWriter.java": [
                3,
                4
            ],
            "parquet-column/src/main/java/parquet/column/UnknownColumnException.java": [
                3,
                2
            ],
            "parquet-column/src/main/java/parquet/column/mem/MemColumnReader.java": [
                4,
                3
            ],
            "parquet-column/src/main/java/parquet/column/mem/MemColumnWriteStore.java": [
                3,
                3
            ],
            "parquet-column/src/main/java/parquet/column/mem/MemColumnWriter.java": [
                12,
                12
            ],
            "parquet-column/src/main/java/parquet/column/mem/MemPageStore.java": [
                4,
                2
            ],
            "parquet-column/src/main/java/parquet/column/primitive/BitPacking.java": [
                1,
                1
            ],
            "parquet-column/src/main/java/parquet/column/primitive/BitPackingColumnReader.java": [
                2,
                3
            ],
            "parquet-column/src/main/java/parquet/column/primitive/BitPackingColumnWriter.java": [
                4,
                4
            ],
            "parquet-column/src/main/java/parquet/column/primitive/BitReader.java": [
                5,
                18
            ],
            "parquet-column/src/main/java/parquet/column/primitive/BitWriter.java": [
                6,
                20
            ],
            "parquet-column/src/main/java/parquet/column/primitive/BooleanPlainColumnReader.java": [
                2,
                2
            ],
            "parquet-column/src/main/java/parquet/column/primitive/BooleanPlainColumnWriter.java": [
                2,
                2
            ],
            "parquet-column/src/main/java/parquet/column/primitive/BoundedColumnFactory.java": [
                1,
                1
            ],
            "parquet-column/src/main/java/parquet/column/primitive/BoundedIntColumnReader.java": [
                4,
                6
            ],
            "parquet-column/src/main/java/parquet/column/primitive/BoundedIntColumnWriter.java": [
                5,
                9
            ],
            "parquet-column/src/main/java/parquet/column/primitive/DevNullColumnReader.java": [
                0,
                7
            ],
            "parquet-column/src/main/java/parquet/column/primitive/DevNullColumnWriter.java": [
                3,
                3
            ],
            "parquet-column/src/main/java/parquet/column/primitive/PlainColumnReader.java": [
                1,
                0
            ],
            "parquet-column/src/main/java/parquet/column/primitive/PlainColumnWriter.java": [
                2,
                2
            ],
            "parquet-column/src/main/java/parquet/column/primitive/PrimitiveColumnReader.java": [
                10,
                17
            ],
            "parquet-column/src/main/java/parquet/column/primitive/PrimitiveColumnWriter.java": [
                4,
                4
            ],
            "parquet-column/src/main/java/parquet/io/BaseRecordReader.java": [
                0,
                1
            ],
            "parquet-column/src/main/java/parquet/io/RecordReaderImplementation.java": [
                5,
                5
            ],
            "parquet-column/src/main/java/parquet/io/convert/RecordConverter.java": [
                3,
                6
            ],
            "parquet-column/src/main/java/parquet/parser/MessageTypeParser.java": [
                4,
                1
            ],
            "parquet-column/src/main/java/parquet/schema/ConversionPatterns.java": [
                1,
                7
            ],
            "parquet-column/src/main/java/parquet/schema/GroupType.java": [
                9,
                9
            ],
            "parquet-column/src/main/java/parquet/schema/MessageType.java": [
                8,
                16
            ],
            "parquet-column/src/main/java/parquet/schema/PrimitiveType.java": [
                5,
                4
            ],
            "parquet-column/src/main/java/parquet/schema/Type.java": [
                5,
                11
            ],
            "parquet-column/src/test/java/parquet/column/primitive/TestBitPacking.java": [
                1,
                1
            ],
            "parquet-column/src/test/java/parquet/io/TestColumnIO.java": [
                1,
                1
            ],
            "parquet-column/src/test/java/parquet/schema/TestMessageType.java": [
                0,
                15
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/ParquetInputFormat.java": [
                2,
                2
            ]
        }
    },
    "591c2b9d2bb8c428597091698f762155d6fdee4f": {
        "datetime": "2013-03-05T15:27:37-08:00",
        "summary": "move compatibility test to the appropriate repo",
        "message": "move compatibility test to the appropriate repo\n",
        "diff": {
            "parquet-hadoop/src/test/java/parquet/hadoop/TestReadIntTestFile.java": [
                130,
                0
            ]
        }
    },
    "76fd1d8011bf4f125118e28f11f5aa5539f06fbd": {
        "datetime": "2013-03-05T16:09:59-08:00",
        "summary": "cleanup",
        "message": "cleanup\n",
        "diff": {
            "parquet-hadoop/pom.xml": null,
            "parquet-hadoop/src/main/java/parquet/hadoop/BlockData.java": [
                52,
                0
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/ColumnData.java": [
                88,
                0
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/PageConsumer.java": [
                24,
                0
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/metadata/ColumnMetaData.java": [
                37,
                0
            ],
            "parquet-pig/pom.xml": null,
            "parquet-thrift/pom.xml": null,
            "pom.xml": null
        }
    },
    "962dd9e8bbacab7f86159da53f165fe8c569fd3b": {
        "datetime": "2013-03-05T16:15:31-08:00",
        "summary": "More cleanup/renames",
        "message": "More cleanup/renames\n",
        "diff": {
            "parquet-column/src/main/java/parquet/column/mem/PageReadStore.java": [
                0,
                2
            ],
            "parquet-hadoop/src/main/java/parquet/format/converter/ParquetMetadataConverter.java": [
                3,
                3
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/CodecFactory.java": [
                18,
                24
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/ColumnChunkPageReadStore.java": [
                23,
                34
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/ColumnChunkPageWriteStore.java": [
                1,
                1
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/ColumnData.java": [
                1,
                1
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/Footer.java": [
                1,
                1
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/PageConsumer.java": [
                1,
                1
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/ParquetFileReader.java": [
                23,
                48
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/ParquetFileWriter.java": [
                1,
                1
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/ParquetInputFormat.java": [
                1,
                1
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/ParquetRecordReader.java": [
                1,
                1
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/metadata/ColumnChunkMetaData.java": [
                2,
                2
            ],
            "parquet-hadoop/src/test/java/parquet/hadoop/TestInputFormat.java": [
                1,
                1
            ],
            "parquet-hadoop/src/test/java/parquet/hadoop/TestParquetFileWriter.java": [
                5,
                5
            ],
            "parquet-hadoop/src/test/java/parquet/hadoop/TestReadIntTestFile.java": [
                1,
                1
            ],
            "parquet-pig/src/test/java/parquet/pig/GenerateIntTestFile.java": [
                1,
                1
            ]
        }
    },
    "7ea3721c8559b96683854edf1594059eb6deda35": {
        "datetime": "2013-03-05T17:40:04-08:00",
        "summary": "Merge remote-tracking branch 'origin/master'",
        "message": "Merge remote-tracking branch 'origin/master'\n\nConflicts:\n\tparquet-column/src/main/java/parquet/column/primitive/DevNullColumnReader.java\n\tparquet-column/src/main/java/parquet/column/primitive/PrimitiveColumnWriter.java\n\tparquet-hadoop/src/main/java/parquet/format/converter/ParquetMetadataConverter.java\n\tparquet-hadoop/src/main/java/parquet/hadoop/ColumnData.java\n\tparquet-hadoop/src/main/java/parquet/hadoop/PageConsumer.java\n\tparquet-hadoop/src/test/java/parquet/hadoop/TestInputFormat.java\n\tparquet-hadoop/src/test/java/parquet/hadoop/TestReadIntTestFile.java\n",
        "diff": {
            "parquet-column/src/main/java/parquet/column/ColumnReader.java": [
                1,
                3
            ],
            "parquet-column/src/main/java/parquet/column/ColumnWriter.java": [
                1,
                3
            ],
            "parquet-column/src/main/java/parquet/column/mem/MemColumnReadStore.java": [
                2,
                3
            ],
            "parquet-column/src/main/java/parquet/column/mem/MemColumnReader.java": [
                1,
                2
            ],
            "parquet-column/src/main/java/parquet/column/mem/MemColumnWriter.java": [
                1,
                2
            ],
            "parquet-column/src/main/java/parquet/column/primitive/DevNullColumnReader.java": [
                3,
                4
            ],
            "parquet-column/src/main/java/parquet/column/primitive/DevNullColumnWriter.java": [
                1,
                2
            ],
            "parquet-column/src/main/java/parquet/column/primitive/PlainColumnReader.java": [
                2,
                4
            ],
            "parquet-column/src/main/java/parquet/column/primitive/PlainColumnWriter.java": [
                3,
                4
            ],
            "parquet-column/src/main/java/parquet/column/primitive/PrimitiveColumnReader.java": [
                1,
                3
            ],
            "parquet-column/src/main/java/parquet/column/primitive/PrimitiveColumnWriter.java": [
                1,
                3
            ],
            "parquet-column/src/main/java/parquet/example/data/Group.java": [
                4,
                5
            ],
            "parquet-column/src/main/java/parquet/example/data/GroupRecordConsumer.java": [
                1,
                2
            ],
            "parquet-column/src/main/java/parquet/example/data/GroupValueSource.java": [
                2,
                3
            ],
            "parquet-column/src/main/java/parquet/example/data/simple/BinaryValue.java": [
                5,
                6
            ],
            "parquet-column/src/main/java/parquet/example/data/simple/Primitive.java": [
                1,
                2
            ],
            "parquet-column/src/main/java/parquet/example/data/simple/SimpleGroup.java": [
                3,
                4
            ],
            "parquet-column/src/main/java/parquet/example/data/simple/convert/SimplePrimitiveConverter.java": [
                1,
                2
            ],
            "parquet-column/src/main/java/parquet/io/BaseRecordReader.java": [
                1,
                1
            ],
            "parquet-column/src/main/java/parquet/io/Binary.java": [
                0,
                114
            ],
            "parquet-column/src/main/java/parquet/io/ConverterConsumer.java": [
                1,
                1
            ],
            "parquet-column/src/main/java/parquet/io/MessageColumnIO.java": [
                2,
                2
            ],
            "parquet-column/src/main/java/parquet/io/RecordConsumer.java": [
                1,
                1
            ],
            "parquet-column/src/main/java/parquet/io/RecordConsumerLoggingWrapper.java": [
                2,
                2
            ],
            "parquet-column/src/main/java/parquet/io/ValidatingRecordConsumer.java": [
                1,
                1
            ],
            "parquet-column/src/main/java/parquet/io/convert/PrimitiveConverter.java": [
                1,
                3
            ],
            "parquet-column/src/test/java/parquet/column/mem/TestMemColumn.java": [
                2,
                3
            ],
            "parquet-column/src/test/java/parquet/io/ExpectationValidatingConverter.java": [
                2,
                2
            ],
            "parquet-column/src/test/java/parquet/io/ExpectationValidatingRecordConsumer.java": [
                2,
                2
            ],
            "parquet-column/src/test/java/parquet/io/TestColumnIO.java": [
                2,
                2
            ],
            "parquet-hadoop/pom.xml": null,
            "parquet-hadoop/src/main/java/parquet/format/converter/ParquetMetadataConverter.java": [
                18,
                49
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/BlockData.java": [
                52,
                0
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/ColumnChunkPageWriteStore.java": [
                10,
                16
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/ColumnData.java": [
                88,
                0
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/Footer.java": [
                1,
                1
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/PageConsumer.java": [
                24,
                0
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/ParquetFileWriter.java": [
                13,
                16
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/metadata/ColumnChunkMetaData.java": [
                1,
                15
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/metadata/ColumnMetaData.java": [
                37,
                0
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/metadata/ParquetMetadata.java": [
                1,
                1
            ],
            "parquet-hadoop/src/test/java/parquet/hadoop/TestInputFormat.java": [
                2,
                3
            ],
            "parquet-hadoop/src/test/java/parquet/hadoop/TestParquetFileWriter.java": [
                7,
                8
            ],
            "parquet-hadoop/src/test/java/parquet/hadoop/TestReadIntTestFile.java": [
                84,
                0
            ],
            "parquet-pig/pom.xml": null,
            "parquet-pig/src/main/java/parquet/pig/TupleRecordConsumer.java": [
                2,
                3
            ],
            "parquet-pig/src/main/java/parquet/pig/TupleWriteSupport.java": [
                1,
                2
            ],
            "parquet-pig/src/main/java/parquet/pig/convert/MapConverter.java": [
                2,
                3
            ],
            "parquet-pig/src/main/java/parquet/pig/convert/TupleConverter.java": [
                4,
                5
            ],
            "parquet-pig/src/test/java/parquet/pig/GenerateIntTestFile.java": [
                1,
                4
            ],
            "parquet-pig/src/test/java/parquet/pig/GenerateTPCH.java": [
                1,
                2
            ],
            "parquet-thrift/pom.xml": null,
            "parquet-thrift/src/main/java/parquet/thrift/ParquetWriteProtocol.java": [
                3,
                4
            ],
            "parquet-thrift/src/main/java/parquet/thrift/ThriftRecordConverter.java": [
                33,
                113
            ],
            "parquet-thrift/src/main/java/parquet/thrift/ThriftSchemaConverter.java": [
                1,
                1
            ],
            "pom.xml": null
        }
    },
    "d4a7da550acff516086cf0984fb4b3a3edde1b24": {
        "datetime": "2013-03-05T17:55:18-08:00",
        "summary": "Merge pull request #3 from toddlipcon/master",
        "message": "Merge pull request #3 from toddlipcon/master\n\nSome misc cleanups, review comments for Julien",
        "diff": {
            "parquet-column/src/main/java/parquet/bytes/BytesUtils.java": [
                0,
                4
            ],
            "parquet-column/src/main/java/parquet/bytes/LittleEndianDataInputStream.java": [
                0,
                6
            ],
            "parquet-column/src/main/java/parquet/bytes/LittleEndianDataOutputStream.java": [
                0,
                3
            ],
            "parquet-column/src/main/java/parquet/column/ColumnDescriptor.java": [
                27,
                5
            ],
            "parquet-column/src/main/java/parquet/column/ColumnReadStore.java": [
                3,
                2
            ],
            "parquet-column/src/main/java/parquet/column/ColumnReader.java": [
                16,
                9
            ],
            "parquet-column/src/main/java/parquet/column/ColumnWriteStore.java": [
                5,
                3
            ],
            "parquet-column/src/main/java/parquet/column/ColumnWriter.java": [
                3,
                4
            ],
            "parquet-column/src/main/java/parquet/column/UnknownColumnException.java": [
                3,
                2
            ],
            "parquet-column/src/main/java/parquet/column/mem/MemColumnReader.java": [
                4,
                3
            ],
            "parquet-column/src/main/java/parquet/column/mem/MemColumnWriteStore.java": [
                3,
                3
            ],
            "parquet-column/src/main/java/parquet/column/mem/MemColumnWriter.java": [
                12,
                12
            ],
            "parquet-column/src/main/java/parquet/column/mem/MemPageStore.java": [
                4,
                2
            ],
            "parquet-column/src/main/java/parquet/column/mem/PageReadStore.java": [
                0,
                2
            ],
            "parquet-column/src/main/java/parquet/column/primitive/BitPacking.java": [
                1,
                1
            ],
            "parquet-column/src/main/java/parquet/column/primitive/BitPackingColumnReader.java": [
                2,
                3
            ],
            "parquet-column/src/main/java/parquet/column/primitive/BitPackingColumnWriter.java": [
                4,
                4
            ],
            "parquet-column/src/main/java/parquet/column/primitive/BitReader.java": [
                5,
                18
            ],
            "parquet-column/src/main/java/parquet/column/primitive/BitWriter.java": [
                6,
                20
            ],
            "parquet-column/src/main/java/parquet/column/primitive/BooleanPlainColumnReader.java": [
                2,
                2
            ],
            "parquet-column/src/main/java/parquet/column/primitive/BooleanPlainColumnWriter.java": [
                2,
                2
            ],
            "parquet-column/src/main/java/parquet/column/primitive/BoundedColumnFactory.java": [
                1,
                1
            ],
            "parquet-column/src/main/java/parquet/column/primitive/BoundedIntColumnReader.java": [
                4,
                6
            ],
            "parquet-column/src/main/java/parquet/column/primitive/BoundedIntColumnWriter.java": [
                5,
                9
            ],
            "parquet-column/src/main/java/parquet/column/primitive/DevNullColumnReader.java": [
                1,
                7
            ],
            "parquet-column/src/main/java/parquet/column/primitive/DevNullColumnWriter.java": [
                3,
                3
            ],
            "parquet-column/src/main/java/parquet/column/primitive/PlainColumnReader.java": [
                1,
                0
            ],
            "parquet-column/src/main/java/parquet/column/primitive/PlainColumnWriter.java": [
                2,
                2
            ],
            "parquet-column/src/main/java/parquet/column/primitive/PrimitiveColumnReader.java": [
                10,
                17
            ],
            "parquet-column/src/main/java/parquet/column/primitive/PrimitiveColumnWriter.java": [
                3,
                4
            ],
            "parquet-column/src/main/java/parquet/io/BaseRecordReader.java": [
                0,
                1
            ],
            "parquet-column/src/main/java/parquet/io/RecordReaderImplementation.java": [
                5,
                5
            ],
            "parquet-column/src/main/java/parquet/io/convert/RecordConverter.java": [
                3,
                6
            ],
            "parquet-column/src/main/java/parquet/parser/MessageTypeParser.java": [
                4,
                1
            ],
            "parquet-column/src/main/java/parquet/schema/ConversionPatterns.java": [
                1,
                7
            ],
            "parquet-column/src/main/java/parquet/schema/GroupType.java": [
                9,
                9
            ],
            "parquet-column/src/main/java/parquet/schema/MessageType.java": [
                8,
                16
            ],
            "parquet-column/src/main/java/parquet/schema/PrimitiveType.java": [
                5,
                4
            ],
            "parquet-column/src/main/java/parquet/schema/Type.java": [
                5,
                11
            ],
            "parquet-column/src/test/java/parquet/column/primitive/TestBitPacking.java": [
                1,
                1
            ],
            "parquet-column/src/test/java/parquet/io/TestColumnIO.java": [
                1,
                1
            ],
            "parquet-column/src/test/java/parquet/schema/TestMessageType.java": [
                0,
                15
            ],
            "parquet-hadoop/src/main/java/parquet/format/converter/ParquetMetadataConverter.java": [
                3,
                3
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/CodecFactory.java": [
                18,
                24
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/ColumnChunkPageReadStore.java": [
                23,
                34
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/ColumnChunkPageWriteStore.java": [
                1,
                1
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/ParquetFileReader.java": [
                23,
                48
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/ParquetFileWriter.java": [
                1,
                1
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/ParquetInputFormat.java": [
                3,
                3
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/ParquetRecordReader.java": [
                1,
                1
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/metadata/ColumnChunkMetaData.java": [
                2,
                2
            ],
            "parquet-hadoop/src/test/java/parquet/hadoop/TestInputFormat.java": [
                1,
                1
            ],
            "parquet-hadoop/src/test/java/parquet/hadoop/TestParquetFileWriter.java": [
                5,
                5
            ],
            "parquet-pig/src/test/java/parquet/pig/GenerateIntTestFile.java": [
                1,
                1
            ]
        }
    },
    "25608ae6eb4088a81a7fe4969409c30ecc81a7a1": {
        "datetime": "2013-03-05T18:04:19-08:00",
        "summary": "cleanup",
        "message": "cleanup\n",
        "diff": {
            "parquet-column/src/main/java/parquet/io/ConverterConsumer.java": [
                0,
                0
            ],
            "parquet-column/src/main/java/parquet/io/MessageColumnIO.java": [
                1,
                3
            ],
            "parquet-column/src/main/java/parquet/io/RecordReaderImplementation.java": [
                3,
                0
            ],
            "parquet-pig/pom.xml": null
        }
    },
    "ca1f11a04355eb7ea268492e9b9508e97f8aaf33": {
        "datetime": "2013-03-05T18:04:31-08:00",
        "summary": "Merge branch 'master' of github.com:Parquet/parquet-mr",
        "message": "Merge branch 'master' of github.com:Parquet/parquet-mr\n",
        "diff": {
            "parquet-column/src/main/java/parquet/bytes/BytesUtils.java": [
                0,
                4
            ],
            "parquet-column/src/main/java/parquet/bytes/LittleEndianDataInputStream.java": [
                0,
                6
            ],
            "parquet-column/src/main/java/parquet/bytes/LittleEndianDataOutputStream.java": [
                0,
                3
            ],
            "parquet-column/src/main/java/parquet/column/ColumnDescriptor.java": [
                27,
                5
            ],
            "parquet-column/src/main/java/parquet/column/ColumnReadStore.java": [
                3,
                2
            ],
            "parquet-column/src/main/java/parquet/column/ColumnReader.java": [
                16,
                9
            ],
            "parquet-column/src/main/java/parquet/column/ColumnWriteStore.java": [
                5,
                3
            ],
            "parquet-column/src/main/java/parquet/column/ColumnWriter.java": [
                3,
                4
            ],
            "parquet-column/src/main/java/parquet/column/UnknownColumnException.java": [
                3,
                2
            ],
            "parquet-column/src/main/java/parquet/column/mem/MemColumnReader.java": [
                4,
                3
            ],
            "parquet-column/src/main/java/parquet/column/mem/MemColumnWriteStore.java": [
                3,
                3
            ],
            "parquet-column/src/main/java/parquet/column/mem/MemColumnWriter.java": [
                12,
                12
            ],
            "parquet-column/src/main/java/parquet/column/mem/MemPageStore.java": [
                4,
                2
            ],
            "parquet-column/src/main/java/parquet/column/mem/PageReadStore.java": [
                0,
                2
            ],
            "parquet-column/src/main/java/parquet/column/primitive/BitPacking.java": [
                1,
                1
            ],
            "parquet-column/src/main/java/parquet/column/primitive/BitPackingColumnReader.java": [
                2,
                3
            ],
            "parquet-column/src/main/java/parquet/column/primitive/BitPackingColumnWriter.java": [
                4,
                4
            ],
            "parquet-column/src/main/java/parquet/column/primitive/BitReader.java": [
                5,
                18
            ],
            "parquet-column/src/main/java/parquet/column/primitive/BitWriter.java": [
                6,
                20
            ],
            "parquet-column/src/main/java/parquet/column/primitive/BooleanPlainColumnReader.java": [
                2,
                2
            ],
            "parquet-column/src/main/java/parquet/column/primitive/BooleanPlainColumnWriter.java": [
                2,
                2
            ],
            "parquet-column/src/main/java/parquet/column/primitive/BoundedColumnFactory.java": [
                1,
                1
            ],
            "parquet-column/src/main/java/parquet/column/primitive/BoundedIntColumnReader.java": [
                4,
                6
            ],
            "parquet-column/src/main/java/parquet/column/primitive/BoundedIntColumnWriter.java": [
                5,
                9
            ],
            "parquet-column/src/main/java/parquet/column/primitive/DevNullColumnReader.java": [
                1,
                7
            ],
            "parquet-column/src/main/java/parquet/column/primitive/DevNullColumnWriter.java": [
                3,
                3
            ],
            "parquet-column/src/main/java/parquet/column/primitive/PlainColumnReader.java": [
                1,
                0
            ],
            "parquet-column/src/main/java/parquet/column/primitive/PlainColumnWriter.java": [
                2,
                2
            ],
            "parquet-column/src/main/java/parquet/column/primitive/PrimitiveColumnReader.java": [
                10,
                17
            ],
            "parquet-column/src/main/java/parquet/column/primitive/PrimitiveColumnWriter.java": [
                3,
                4
            ],
            "parquet-column/src/main/java/parquet/io/BaseRecordReader.java": [
                0,
                1
            ],
            "parquet-column/src/main/java/parquet/io/RecordReaderImplementation.java": [
                5,
                5
            ],
            "parquet-column/src/main/java/parquet/io/convert/RecordConverter.java": [
                3,
                6
            ],
            "parquet-column/src/main/java/parquet/parser/MessageTypeParser.java": [
                4,
                1
            ],
            "parquet-column/src/main/java/parquet/schema/ConversionPatterns.java": [
                1,
                7
            ],
            "parquet-column/src/main/java/parquet/schema/GroupType.java": [
                9,
                9
            ],
            "parquet-column/src/main/java/parquet/schema/MessageType.java": [
                8,
                16
            ],
            "parquet-column/src/main/java/parquet/schema/PrimitiveType.java": [
                5,
                4
            ],
            "parquet-column/src/main/java/parquet/schema/Type.java": [
                5,
                11
            ],
            "parquet-column/src/test/java/parquet/column/primitive/TestBitPacking.java": [
                1,
                1
            ],
            "parquet-column/src/test/java/parquet/io/TestColumnIO.java": [
                1,
                1
            ],
            "parquet-column/src/test/java/parquet/schema/TestMessageType.java": [
                0,
                15
            ],
            "parquet-hadoop/src/main/java/parquet/format/converter/ParquetMetadataConverter.java": [
                3,
                3
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/CodecFactory.java": [
                18,
                24
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/ColumnChunkPageReadStore.java": [
                23,
                34
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/ColumnChunkPageWriteStore.java": [
                1,
                1
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/ParquetFileReader.java": [
                23,
                48
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/ParquetFileWriter.java": [
                1,
                1
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/ParquetInputFormat.java": [
                3,
                3
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/ParquetRecordReader.java": [
                1,
                1
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/metadata/ColumnChunkMetaData.java": [
                2,
                2
            ],
            "parquet-hadoop/src/test/java/parquet/hadoop/TestInputFormat.java": [
                1,
                1
            ],
            "parquet-hadoop/src/test/java/parquet/hadoop/TestParquetFileWriter.java": [
                5,
                5
            ],
            "parquet-pig/src/test/java/parquet/pig/GenerateIntTestFile.java": [
                1,
                1
            ]
        }
    },
    "bf0bd5748dc5bd5a3bee3ad4c9445b5232ee7fde": {
        "datetime": "2013-03-06T14:48:16-08:00",
        "summary": "Update README.md",
        "message": "Update README.md",
        "diff": {
            "README.md": null
        }
    },
    "b9463550d01f4b0118f725ed957e6e4354b0e4ba": {
        "datetime": "2013-03-06T15:32:07-08:00",
        "summary": "thrift enum and list fixes; ParquetReadToWrite",
        "message": "thrift enum and list fixes; ParquetReadToWrite\n",
        "diff": {
            "parquet-column/src/main/java/parquet/io/Binary.java": [
                21,
                83
            ],
            "parquet-column/src/main/java/parquet/schema/ConversionPatterns.java": [
                21,
                19
            ],
            "parquet-pig/src/main/java/parquet/pig/PigSchemaConverter.java": [
                26,
                17
            ],
            "parquet-thrift/src/main/java/parquet/thrift/ParquetReadToWriteProtocol.java": [
                0,
                122
            ],
            "parquet-thrift/src/main/java/parquet/thrift/ParquetWriteProtocol.java": [
                3,
                19
            ],
            "parquet-thrift/src/main/java/parquet/thrift/ThriftRecordConverter.java": [
                7,
                49
            ],
            "parquet-thrift/src/main/java/parquet/thrift/ThriftSchemaConverter.java": [
                2,
                2
            ],
            "parquet-thrift/src/test/java/parquet/hadoop/thrift/TestParquetReadProtocol.java": [
                2,
                6
            ],
            "parquet-thrift/src/test/java/parquet/hadoop/thrift/TestParquetWriteProtocol.java": [
                281,
                0
            ],
            "parquet-thrift/src/test/java/parquet/hadoop/thrift/TestThriftSchemaConverter.java": [
                1,
                1
            ],
            "parquet-thrift/src/test/java/parquet/thrift/TestParquetReadWriteProtocol.java": [
                0,
                64
            ],
            "parquet-thrift/src/test/java/parquet/thrift/TestParquetWriteProtocol.java": [
                0,
                424
            ]
        }
    },
    "5daf06892b533a06fa0d80c83006f84b74e429f8": {
        "datetime": "2013-03-06T17:29:16-08:00",
        "summary": "more thrift bug fixes",
        "message": "more thrift bug fixes\n",
        "diff": {
            "parquet-column/src/main/java/parquet/column/mem/MemColumnReader.java": [
                1,
                2
            ],
            "parquet-column/src/main/java/parquet/column/mem/MemColumnWriter.java": [
                0,
                1
            ],
            "parquet-column/src/main/java/parquet/column/primitive/PrimitiveColumnWriter.java": [
                7,
                7
            ],
            "parquet-column/src/main/java/parquet/io/Binary.java": [
                0,
                13
            ],
            "parquet-thrift/src/main/java/parquet/thrift/ParquetReadToWriteProtocol.java": [
                2,
                2
            ],
            "parquet-thrift/src/main/java/parquet/thrift/ParquetWriteProtocol.java": [
                4,
                0
            ],
            "parquet-thrift/src/main/java/parquet/thrift/ThriftRecordConverter.java": [
                8,
                38
            ],
            "parquet-thrift/src/test/java/parquet/thrift/TestParquetReadProtocol.java": [
                7,
                42
            ],
            "parquet-thrift/src/test/java/parquet/thrift/TestParquetReadWriteProtocol.java": [
                4,
                37
            ],
            "parquet-thrift/src/test/java/parquet/thrift/TestParquetWriteProtocol.java": [
                0,
                65
            ]
        }
    },
    "668d74df8addad24ad0bd2e53a23a4ad07e5ad47": {
        "datetime": "2013-03-07T16:55:07-08:00",
        "summary": "exception cleanup; creation of parquet.hadoop.api package; thrift from bytes support; bug fixes",
        "message": "exception cleanup; creation of parquet.hadoop.api package; thrift from bytes support; bug fixes\n",
        "diff": {
            "parquet-hadoop/src/main/java/parquet/hadoop/CodecFactory.java": [
                2,
                2
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/ColumnChunkPageReadStore.java": [
                4,
                3
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/ParquetFileWriter.java": [
                5,
                0
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/ParquetInputFormat.java": [
                0,
                1
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/ParquetOutputFormat.java": [
                7,
                11
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/ParquetRecordReader.java": [
                0,
                1
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/ParquetRecordWriter.java": [
                1,
                2
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/PrintFooter.java": [
                1,
                2
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/ReadSupport.java": [
                4,
                3
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/WriteSupport.java": [
                2,
                2
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/example/GroupReadSupport.java": [
                1,
                1
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/example/GroupWriteSupport.java": [
                2,
                2
            ],
            "parquet-hadoop/src/test/java/parquet/hadoop/TestInputFormat.java": [
                0,
                1
            ],
            "parquet-pig/src/main/java/parquet/pig/ParquetLoader.java": [
                1,
                2
            ],
            "parquet-pig/src/main/java/parquet/pig/ParquetStorer.java": [
                2,
                3
            ],
            "parquet-pig/src/main/java/parquet/pig/PigSchemaConverter.java": [
                3,
                3
            ],
            "parquet-pig/src/main/java/parquet/pig/SchemaConversionException.java": [
                0,
                44
            ],
            "parquet-pig/src/main/java/parquet/pig/TupleReadSupport.java": [
                2,
                2
            ],
            "parquet-pig/src/main/java/parquet/pig/TupleWriteSupport.java": [
                2,
                3
            ],
            "parquet-thrift/src/main/java/parquet/hadoop/thrift/ParquetThriftBytesOutputFormat.java": [
                0,
                48
            ],
            "parquet-thrift/src/main/java/parquet/hadoop/thrift/ParquetThriftInputFormat.java": [
                0,
                1
            ],
            "parquet-thrift/src/main/java/parquet/hadoop/thrift/ParquetThriftOutputFormat.java": [
                2,
                2
            ],
            "parquet-thrift/src/main/java/parquet/hadoop/thrift/ThriftBytesWriteSupport.java": [
                0,
                122
            ],
            "parquet-thrift/src/main/java/parquet/hadoop/thrift/ThriftReadSupport.java": [
                1,
                1
            ],
            "parquet-thrift/src/main/java/parquet/hadoop/thrift/ThriftToParquetFileWriter.java": [
                0,
                58
            ],
            "parquet-thrift/src/main/java/parquet/hadoop/thrift/ThriftWriteSupport.java": [
                5,
                5
            ],
            "parquet-thrift/src/main/java/parquet/thrift/ParquetProtocol.java": [
                0,
                9
            ],
            "parquet-thrift/src/main/java/parquet/thrift/ParquetReadProtocol.java": [
                2,
                1
            ],
            "parquet-thrift/src/main/java/parquet/thrift/ParquetReadToWriteProtocol.java": [
                14,
                32
            ],
            "parquet-thrift/src/main/java/parquet/thrift/ParquetWriteProtocol.java": [
                19,
                37
            ],
            "parquet-thrift/src/main/java/parquet/thrift/ThriftSchemaConverter.java": [
                4,
                17
            ],
            "parquet-thrift/src/main/java/parquet/thrift/struct/ThriftType.java": [
                11,
                7
            ],
            "parquet-thrift/src/main/java/parquet/thrift/struct/ThriftTypeID.java": [
                1,
                6
            ],
            "parquet-thrift/src/test/java/parquet/hadoop/thrift/TestThriftToParquetFileWriter.java": [
                0,
                109
            ],
            "parquet-thrift/src/test/java/parquet/thrift/TestParquetReadWriteProtocol.java": [
                14,
                32
            ]
        }
    },
    "e1b2f29577a8f8a8b806c2e902ca65154f83eef3": {
        "datetime": "2013-03-08T17:56:50+01:00",
        "summary": "Fix pom.xml",
        "message": "Fix pom.xml\n\n - GroupId for parquet-format is now com.twitter\n",
        "diff": {
            "parquet-hadoop/pom.xml": null,
            "parquet-pig/pom.xml": null
        }
    },
    "70abea69a509708c3e0a51b9bc37f8d907617100": {
        "datetime": "2013-03-08T09:58:12-08:00",
        "summary": "Merge pull request #5 from mickaellcr/fix_pom",
        "message": "Merge pull request #5 from mickaellcr/fix_pom\n\nFix pom.xml",
        "diff": {
            "parquet-hadoop/pom.xml": null,
            "parquet-pig/pom.xml": null
        }
    },
    "ed7a0673ab7beacb398f8250a9f21863f7ce424d": {
        "datetime": "2013-03-08T10:34:14-08:00",
        "summary": "move to groupId com.twitter so that we can publish to maven central",
        "message": "move to groupId com.twitter so that we can publish to maven central\n",
        "diff": {
            "parquet-column/pom.xml": null,
            "parquet-hadoop/pom.xml": null,
            "parquet-pig/pom.xml": null,
            "parquet-thrift/pom.xml": null,
            "pom.xml": null
        }
    },
    "0703f014894119c2f6b488d821c4409c8c0519e2": {
        "datetime": "2013-03-08T10:36:31-08:00",
        "summary": "Merge pull request #4 from Parquet/thrift_fixes",
        "message": "Merge pull request #4 from Parquet/thrift_fixes\n\nThrift fixes",
        "diff": {
            "parquet-column/src/main/java/parquet/column/mem/MemColumnReader.java": [
                1,
                2
            ],
            "parquet-column/src/main/java/parquet/column/mem/MemColumnWriter.java": [
                0,
                1
            ],
            "parquet-column/src/main/java/parquet/column/primitive/PrimitiveColumnWriter.java": [
                7,
                7
            ],
            "parquet-column/src/main/java/parquet/io/Binary.java": [
                21,
                96
            ],
            "parquet-column/src/main/java/parquet/io/ConverterConsumer.java": [
                0,
                0
            ],
            "parquet-column/src/main/java/parquet/io/MessageColumnIO.java": [
                1,
                3
            ],
            "parquet-column/src/main/java/parquet/io/RecordReaderImplementation.java": [
                3,
                0
            ],
            "parquet-column/src/main/java/parquet/schema/ConversionPatterns.java": [
                21,
                19
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/CodecFactory.java": [
                2,
                2
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/ColumnChunkPageReadStore.java": [
                4,
                3
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/ParquetFileWriter.java": [
                5,
                0
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/ParquetInputFormat.java": [
                0,
                1
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/ParquetOutputFormat.java": [
                7,
                11
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/ParquetRecordReader.java": [
                0,
                1
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/ParquetRecordWriter.java": [
                1,
                2
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/PrintFooter.java": [
                1,
                2
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/ReadSupport.java": [
                4,
                3
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/WriteSupport.java": [
                2,
                2
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/example/GroupReadSupport.java": [
                1,
                1
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/example/GroupWriteSupport.java": [
                2,
                2
            ],
            "parquet-hadoop/src/test/java/parquet/hadoop/TestInputFormat.java": [
                0,
                1
            ],
            "parquet-pig/pom.xml": null,
            "parquet-pig/src/main/java/parquet/pig/ParquetLoader.java": [
                1,
                2
            ],
            "parquet-pig/src/main/java/parquet/pig/ParquetStorer.java": [
                2,
                3
            ],
            "parquet-pig/src/main/java/parquet/pig/PigSchemaConverter.java": [
                28,
                19
            ],
            "parquet-pig/src/main/java/parquet/pig/SchemaConversionException.java": [
                0,
                44
            ],
            "parquet-pig/src/main/java/parquet/pig/TupleReadSupport.java": [
                2,
                2
            ],
            "parquet-pig/src/main/java/parquet/pig/TupleWriteSupport.java": [
                2,
                3
            ],
            "parquet-thrift/src/main/java/parquet/hadoop/thrift/ParquetThriftBytesOutputFormat.java": [
                0,
                48
            ],
            "parquet-thrift/src/main/java/parquet/hadoop/thrift/ParquetThriftInputFormat.java": [
                0,
                1
            ],
            "parquet-thrift/src/main/java/parquet/hadoop/thrift/ParquetThriftOutputFormat.java": [
                2,
                2
            ],
            "parquet-thrift/src/main/java/parquet/hadoop/thrift/ThriftBytesWriteSupport.java": [
                0,
                122
            ],
            "parquet-thrift/src/main/java/parquet/hadoop/thrift/ThriftReadSupport.java": [
                1,
                1
            ],
            "parquet-thrift/src/main/java/parquet/hadoop/thrift/ThriftToParquetFileWriter.java": [
                0,
                58
            ],
            "parquet-thrift/src/main/java/parquet/hadoop/thrift/ThriftWriteSupport.java": [
                5,
                5
            ],
            "parquet-thrift/src/main/java/parquet/thrift/ParquetProtocol.java": [
                0,
                9
            ],
            "parquet-thrift/src/main/java/parquet/thrift/ParquetReadProtocol.java": [
                2,
                1
            ],
            "parquet-thrift/src/main/java/parquet/thrift/ParquetWriteProtocol.java": [
                28,
                58
            ],
            "parquet-thrift/src/main/java/parquet/thrift/ProtocolReadToWrite.java": [
                0,
                140
            ],
            "parquet-thrift/src/main/java/parquet/thrift/ThriftRecordConverter.java": [
                14,
                86
            ],
            "parquet-thrift/src/main/java/parquet/thrift/ThriftSchemaConverter.java": [
                6,
                19
            ],
            "parquet-thrift/src/main/java/parquet/thrift/struct/ThriftType.java": [
                11,
                7
            ],
            "parquet-thrift/src/main/java/parquet/thrift/struct/ThriftTypeID.java": [
                1,
                6
            ],
            "parquet-thrift/src/test/java/parquet/hadoop/thrift/TestParquetReadProtocol.java": [
                8,
                47
            ],
            "parquet-thrift/src/test/java/parquet/hadoop/thrift/TestParquetWriteProtocol.java": [
                281,
                0
            ],
            "parquet-thrift/src/test/java/parquet/hadoop/thrift/TestThriftSchemaConverter.java": [
                1,
                1
            ],
            "parquet-thrift/src/test/java/parquet/hadoop/thrift/TestThriftToParquetFileWriter.java": [
                0,
                109
            ],
            "parquet-thrift/src/test/java/parquet/thrift/TestParquetWriteProtocol.java": [
                0,
                489
            ],
            "parquet-thrift/src/test/java/parquet/thrift/TestProtocolReadToWrite.java": [
                0,
                115
            ]
        }
    },
    "45138bb6736ef986f493b2c72fb0e9a61531bee7": {
        "datetime": "2013-03-08T11:22:50-08:00",
        "summary": "integrating feedback from Todd; renaming PrimitiveColumnW/R to ValuesW/R",
        "message": "integrating feedback from Todd; renaming PrimitiveColumnW/R to ValuesW/R\n",
        "diff": {
            "parquet-column/src/main/java/parquet/column/mem/MemColumnReadStore.java": [
                4,
                3
            ],
            "parquet-column/src/main/java/parquet/column/mem/MemColumnReader.java": [
                13,
                13
            ],
            "parquet-column/src/main/java/parquet/column/mem/MemColumnWriteStore.java": [
                4,
                3
            ],
            "parquet-column/src/main/java/parquet/column/mem/MemColumnWriter.java": [
                14,
                13
            ],
            "parquet-column/src/main/java/parquet/column/mem/MemPageReader.java": [
                1,
                3
            ],
            "parquet-column/src/main/java/parquet/column/mem/MemPageStore.java": [
                1,
                6
            ],
            "parquet-column/src/main/java/parquet/column/mem/MemPageWriter.java": [
                1,
                3
            ],
            "parquet-column/src/main/java/parquet/column/mem/Page.java": [
                1,
                1
            ],
            "parquet-column/src/main/java/parquet/column/mem/PageReadStore.java": [
                1,
                1
            ],
            "parquet-column/src/main/java/parquet/column/mem/PageReader.java": [
                1,
                1
            ],
            "parquet-column/src/main/java/parquet/column/mem/PageWriteStore.java": [
                1,
                1
            ],
            "parquet-column/src/main/java/parquet/column/mem/PageWriter.java": [
                1,
                1
            ],
            "parquet-column/src/main/java/parquet/column/primitive/BitPackingColumnReader.java": [
                5,
                5
            ],
            "parquet-column/src/main/java/parquet/column/primitive/BitPackingColumnWriter.java": [
                7,
                7
            ],
            "parquet-column/src/main/java/parquet/column/primitive/BooleanPlainColumnReader.java": [
                3,
                3
            ],
            "parquet-column/src/main/java/parquet/column/primitive/BooleanPlainColumnWriter.java": [
                1,
                1
            ],
            "parquet-column/src/main/java/parquet/column/primitive/BoundedColumnFactory.java": [
                5,
                5
            ],
            "parquet-column/src/main/java/parquet/column/primitive/BoundedIntColumnReader.java": [
                4,
                4
            ],
            "parquet-column/src/main/java/parquet/column/primitive/BoundedIntColumnWriter.java": [
                4,
                4
            ],
            "parquet-column/src/main/java/parquet/column/primitive/DataColumnWriter.java": [
                1,
                1
            ],
            "parquet-column/src/main/java/parquet/column/primitive/DevNullColumnReader.java": [
                98,
                0
            ],
            "parquet-column/src/main/java/parquet/column/primitive/DevNullColumnWriter.java": [
                1,
                1
            ],
            "parquet-column/src/main/java/parquet/column/primitive/PlainColumnReader.java": [
                3,
                3
            ],
            "parquet-column/src/main/java/parquet/column/primitive/PlainColumnWriter.java": [
                3,
                3
            ],
            "parquet-column/src/main/java/parquet/column/primitive/PrimitiveColumnReader.java": [
                1,
                1
            ],
            "parquet-column/src/main/java/parquet/column/primitive/PrimitiveColumnWriter.java": [
                2,
                1
            ],
            "parquet-column/src/main/java/parquet/column/primitive/ZeroIntegerValuesReader.java": [
                0,
                36
            ],
            "parquet-column/src/main/java/parquet/io/MessageColumnIO.java": [
                2,
                2
            ],
            "parquet-column/src/main/java/parquet/io/RecordReaderImplementation.java": [
                1,
                1
            ],
            "parquet-column/src/test/java/parquet/column/mem/TestMemColumn.java": [
                3,
                3
            ],
            "parquet-column/src/test/java/parquet/column/mem/TestMemPageStore.java": [
                0,
                4
            ],
            "parquet-column/src/test/java/parquet/column/primitive/TestBitPackingColumn.java": [
                2,
                2
            ],
            "parquet-column/src/test/java/parquet/column/primitive/TestBoundedColumns.java": [
                6,
                6
            ],
            "parquet-column/src/test/java/parquet/io/PerfTest.java": [
                2,
                2
            ],
            "parquet-column/src/test/java/parquet/io/TestColumnIO.java": [
                3,
                3
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/ColumnChunkPageReadStore.java": [
                3,
                3
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/ColumnChunkPageWriteStore.java": [
                2,
                2
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/ParquetFileReader.java": [
                2,
                2
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/ParquetRecordReader.java": [
                1,
                1
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/ParquetRecordWriter.java": [
                1,
                1
            ],
            "parquet-hadoop/src/test/java/parquet/hadoop/TestParquetFileWriter.java": [
                3,
                3
            ],
            "parquet-pig/src/test/java/parquet/pig/GenerateIntTestFile.java": [
                5,
                5
            ],
            "parquet-pig/src/test/java/parquet/pig/GenerateTPCH.java": [
                2,
                2
            ],
            "parquet-pig/src/test/java/parquet/pig/TupleConsumerPerfTest.java": [
                3,
                3
            ],
            "parquet-thrift/src/test/java/parquet/thrift/TestParquetReadProtocol.java": [
                2,
                2
            ]
        }
    },
    "6b9366b1978f236f68e8bd8bf555fbdb5c82c8a9": {
        "datetime": "2013-03-08T11:51:25-08:00",
        "summary": "renaming classes and packages based on feedback",
        "message": "renaming classes and packages based on feedback\n",
        "diff": {
            "parquet-column/src/main/java/parquet/column/Encoding.java": [
                0,
                6
            ],
            "parquet-column/src/main/java/parquet/column/MemColumnReadStore.java": [
                10,
                13
            ],
            "parquet-column/src/main/java/parquet/column/MemColumnReader.java": [
                10,
                12
            ],
            "parquet-column/src/main/java/parquet/column/MemColumnWriteStore.java": [
                16,
                19
            ],
            "parquet-column/src/main/java/parquet/column/MemColumnWriter.java": [
                11,
                13
            ],
            "parquet-column/src/main/java/parquet/column/page/mem/MemPageReader.java": [
                0,
                0
            ],
            "parquet-column/src/main/java/parquet/column/page/mem/MemPageStore.java": [
                0,
                0
            ],
            "parquet-column/src/main/java/parquet/column/page/mem/MemPageWriter.java": [
                0,
                0
            ],
            "parquet-column/src/main/java/parquet/column/primitive/BitPacking.java": [
                3,
                3
            ],
            "parquet-column/src/main/java/parquet/column/primitive/BitPackingValuesReader.java": [
                5,
                6
            ],
            "parquet-column/src/main/java/parquet/column/primitive/BitPackingValuesWriter.java": [
                8,
                9
            ],
            "parquet-column/src/main/java/parquet/column/primitive/BitReader.java": [
                1,
                1
            ],
            "parquet-column/src/main/java/parquet/column/primitive/BitWriter.java": [
                1,
                1
            ],
            "parquet-column/src/main/java/parquet/column/primitive/BooleanPlainColumnReader.java": [
                7,
                8
            ],
            "parquet-column/src/main/java/parquet/column/primitive/BooleanPlainColumnWriter.java": [
                6,
                7
            ],
            "parquet-column/src/main/java/parquet/column/primitive/BoundedIntValuesFactory.java": [
                1,
                4
            ],
            "parquet-column/src/main/java/parquet/column/primitive/BoundedIntValuesReader.java": [
                1,
                2
            ],
            "parquet-column/src/main/java/parquet/column/primitive/BoundedIntValuesWriter.java": [
                1,
                3
            ],
            "parquet-column/src/main/java/parquet/column/primitive/DataValuesWriter.java": [
                1,
                1
            ],
            "parquet-column/src/main/java/parquet/column/primitive/DevNullValuesWriter.java": [
                1,
                2
            ],
            "parquet-column/src/main/java/parquet/column/primitive/PlainValuesReader.java": [
                2,
                3
            ],
            "parquet-column/src/main/java/parquet/column/primitive/PlainValuesWriter.java": [
                1,
                2
            ],
            "parquet-column/src/main/java/parquet/column/primitive/ValuesReader.java": [
                1,
                1
            ],
            "parquet-column/src/main/java/parquet/column/primitive/ValuesWriter.java": [
                1,
                1
            ],
            "parquet-column/src/main/java/parquet/column/primitive/ZeroIntegerValuesReader.java": [
                1,
                3
            ],
            "parquet-column/src/main/java/parquet/io/MessageColumnIO.java": [
                2,
                2
            ],
            "parquet-column/src/main/java/parquet/io/RecordReaderImplementation.java": [
                2,
                2
            ],
            "parquet-column/src/test/java/parquet/column/mem/TestMemColumn.java": [
                10,
                10
            ],
            "parquet-column/src/test/java/parquet/column/primitive/TestBitPacking.java": [
                3,
                3
            ],
            "parquet-column/src/test/java/parquet/column/primitive/TestBitPackingColumn.java": [
                0,
                3
            ],
            "parquet-column/src/test/java/parquet/column/primitive/TestBoundedColumns.java": [
                3,
                3
            ],
            "parquet-column/src/test/java/parquet/io/PerfTest.java": [
                2,
                2
            ],
            "parquet-column/src/test/java/parquet/io/TestColumnIO.java": [
                3,
                3
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/ParquetRecordWriter.java": [
                3,
                3
            ],
            "parquet-pig/src/test/java/parquet/pig/GenerateIntTestFile.java": [
                2,
                2
            ],
            "parquet-pig/src/test/java/parquet/pig/GenerateTPCH.java": [
                2,
                2
            ],
            "parquet-pig/src/test/java/parquet/pig/TupleConsumerPerfTest.java": [
                3,
                3
            ],
            "parquet-thrift/src/test/java/parquet/thrift/TestParquetReadProtocol.java": [
                2,
                2
            ]
        }
    },
    "e0dc2f324e555d3fe46665f2c02530b55a3d0060": {
        "datetime": "2013-03-08T12:14:18-08:00",
        "summary": "reorganizing packages and deleting old classes",
        "message": "reorganizing packages and deleting old classes\n",
        "diff": {
            "parquet-column/src/main/java/parquet/column/ColumnReader.java": [
                1,
                1
            ],
            "parquet-column/src/main/java/parquet/column/ColumnWriter.java": [
                1,
                1
            ],
            "parquet-column/src/main/java/parquet/column/impl/ColumnReadStoreImpl.java": [
                1,
                1
            ],
            "parquet-column/src/main/java/parquet/column/impl/ColumnReaderImpl.java": [
                1,
                1
            ],
            "parquet-column/src/main/java/parquet/column/impl/ColumnWriterImpl.java": [
                1,
                1
            ],
            "parquet-column/src/main/java/parquet/column/values/ValuesReader.java": [
                1,
                1
            ],
            "parquet-column/src/main/java/parquet/column/values/ValuesWriter.java": [
                1,
                1
            ],
            "parquet-column/src/main/java/parquet/column/values/boundedint/DevNullValuesWriter.java": [
                1,
                1
            ],
            "parquet-column/src/main/java/parquet/column/values/plain/PlainValuesReader.java": [
                1,
                1
            ],
            "parquet-column/src/main/java/parquet/column/values/plain/PlainValuesWriter.java": [
                1,
                1
            ],
            "parquet-column/src/main/java/parquet/example/DummyRecordConverter.java": [
                5,
                5
            ],
            "parquet-column/src/main/java/parquet/example/data/Group.java": [
                2,
                2
            ],
            "parquet-column/src/main/java/parquet/example/data/GroupRecordConsumer.java": [
                105,
                0
            ],
            "parquet-column/src/main/java/parquet/example/data/GroupValueSource.java": [
                1,
                1
            ],
            "parquet-column/src/main/java/parquet/example/data/GroupWriter.java": [
                1,
                1
            ],
            "parquet-column/src/main/java/parquet/example/data/simple/BinaryValue.java": [
                2,
                2
            ],
            "parquet-column/src/main/java/parquet/example/data/simple/BooleanValue.java": [
                1,
                1
            ],
            "parquet-column/src/main/java/parquet/example/data/simple/DoubleValue.java": [
                1,
                1
            ],
            "parquet-column/src/main/java/parquet/example/data/simple/FloatValue.java": [
                1,
                1
            ],
            "parquet-column/src/main/java/parquet/example/data/simple/IntegerValue.java": [
                1,
                1
            ],
            "parquet-column/src/main/java/parquet/example/data/simple/LongValue.java": [
                1,
                1
            ],
            "parquet-column/src/main/java/parquet/example/data/simple/Primitive.java": [
                2,
                2
            ],
            "parquet-column/src/main/java/parquet/example/data/simple/SimpleGroup.java": [
                2,
                2
            ],
            "parquet-column/src/main/java/parquet/example/data/simple/convert/GroupRecordConverter.java": [
                3,
                3
            ],
            "parquet-column/src/main/java/parquet/example/data/simple/convert/SimpleGroupConverter.java": [
                2,
                2
            ],
            "parquet-column/src/main/java/parquet/example/data/simple/convert/SimplePrimitiveConverter.java": [
                8,
                8
            ],
            "parquet-column/src/main/java/parquet/io/BaseRecordReader.java": [
                2,
                4
            ],
            "parquet-column/src/main/java/parquet/io/Binary.java": [
                1,
                1
            ],
            "parquet-column/src/main/java/parquet/io/MessageColumnIO.java": [
                2,
                4
            ],
            "parquet-column/src/main/java/parquet/io/RecordConsumer.java": [
                3,
                4
            ],
            "parquet-column/src/main/java/parquet/io/RecordConsumerLoggingWrapper.java": [
                0,
                2
            ],
            "parquet-column/src/main/java/parquet/io/RecordMaterializer.java": [
                34,
                0
            ],
            "parquet-column/src/main/java/parquet/io/RecordReaderImplementation.java": [
                10,
                10
            ],
            "parquet-column/src/main/java/parquet/io/ValidatingRecordConsumer.java": [
                1,
                3
            ],
            "parquet-column/src/main/java/parquet/io/convert/Converter.java": [
                1,
                1
            ],
            "parquet-column/src/main/java/parquet/io/convert/GroupConverter.java": [
                11,
                11
            ],
            "parquet-column/src/main/java/parquet/io/convert/PrimitiveConverter.java": [
                12,
                13
            ],
            "parquet-column/src/main/java/parquet/io/convert/RecordConverter.java": [
                2,
                2
            ],
            "parquet-column/src/main/java/parquet/parser/MessageTypeParser.java": [
                6,
                1
            ],
            "parquet-column/src/main/java/parquet/schema/PrimitiveType.java": [
                2,
                2
            ],
            "parquet-column/src/test/java/parquet/column/mem/TestMemColumn.java": [
                2,
                2
            ],
            "parquet-column/src/test/java/parquet/io/ConverterConsumer.java": [
                2,
                4
            ],
            "parquet-column/src/test/java/parquet/io/ExpectationValidatingConverter.java": [
                5,
                6
            ],
            "parquet-column/src/test/java/parquet/io/ExpectationValidatingRecordConsumer.java": [
                5,
                4
            ],
            "parquet-column/src/test/java/parquet/io/PerfTest.java": [
                2,
                2
            ],
            "parquet-column/src/test/java/parquet/io/TestColumnIO.java": [
                7,
                8
            ],
            "parquet-column/src/test/java/parquet/parser/TestParquetParser.java": [
                1,
                1
            ],
            "parquet-column/src/test/java/parquet/schema/TestMessageType.java": [
                1,
                0
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/ParquetInputFormat.java": [
                1,
                1
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/ParquetRecordReader.java": [
                3,
                3
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/api/ReadSupport.java": [
                2,
                2
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/api/WriteSupport.java": [
                1,
                1
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/example/GroupReadSupport.java": [
                2,
                2
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/example/GroupWriteSupport.java": [
                2,
                2
            ],
            "parquet-hadoop/src/test/java/parquet/hadoop/TestParquetFileWriter.java": [
                1,
                1
            ],
            "parquet-hadoop/src/test/java/parquet/hadoop/example/TestInputOutputFormat.java": [
                1,
                1
            ],
            "parquet-pig/src/main/java/parquet/pig/PigMetaData.java": [
                9,
                0
            ],
            "parquet-pig/src/main/java/parquet/pig/TupleReadSupport.java": [
                3,
                2
            ],
            "parquet-pig/src/main/java/parquet/pig/TupleRecordConsumer.java": [
                234,
                0
            ],
            "parquet-pig/src/main/java/parquet/pig/TupleWriteSupport.java": [
                5,
                2
            ],
            "parquet-pig/src/main/java/parquet/pig/convert/MapConverter.java": [
                4,
                4
            ],
            "parquet-pig/src/main/java/parquet/pig/convert/TupleConverter.java": [
                4,
                4
            ],
            "parquet-pig/src/main/java/parquet/pig/convert/TupleRecordConverter.java": [
                3,
                3
            ],
            "parquet-pig/src/test/java/parquet/pig/GenerateIntTestFile.java": [
                1,
                1
            ],
            "parquet-pig/src/test/java/parquet/pig/GenerateTPCH.java": [
                2,
                2
            ],
            "parquet-pig/src/test/java/parquet/pig/TestPigSchemaConverter.java": [
                1,
                1
            ],
            "parquet-pig/src/test/java/parquet/pig/TestTupleRecordConsumer.java": [
                5,
                5
            ],
            "parquet-pig/src/test/java/parquet/pig/TupleConsumerPerfTest.java": [
                13,
                2
            ],
            "parquet-thrift/src/main/java/parquet/hadoop/thrift/ThriftBytesWriteSupport.java": [
                1,
                1
            ],
            "parquet-thrift/src/main/java/parquet/hadoop/thrift/ThriftReadSupport.java": [
                2,
                2
            ],
            "parquet-thrift/src/main/java/parquet/hadoop/thrift/ThriftWriteSupport.java": [
                1,
                1
            ],
            "parquet-thrift/src/main/java/parquet/thrift/ParquetWriteProtocol.java": [
                2,
                2
            ],
            "parquet-thrift/src/main/java/parquet/thrift/ThriftRecordConverter.java": [
                8,
                8
            ],
            "parquet-thrift/src/test/java/parquet/thrift/TestParquetReadProtocol.java": [
                1,
                1
            ],
            "parquet-thrift/src/test/java/parquet/thrift/TestThriftSchemaConverter.java": [
                1,
                1
            ]
        }
    },
    "6dff626ec8ad6715ee6cb085541e8cacd600e1d0": {
        "datetime": "2013-03-08T12:59:51-08:00",
        "summary": "Merge pull request #6 from Parquet/move_to_twitter_group",
        "message": "Merge pull request #6 from Parquet/move_to_twitter_group\n\nmove to groupId com.twitter so that we can publish to maven central",
        "diff": {
            "parquet-column/pom.xml": null,
            "parquet-hadoop/pom.xml": null,
            "parquet-pig/pom.xml": null,
            "parquet-thrift/pom.xml": null,
            "pom.xml": null
        }
    },
    "63949a321cda2c03f3b54ae74589c4b43d439ffa": {
        "datetime": "2013-03-08T13:35:22-08:00",
        "summary": "Merge pull request #7 from Parquet/renaming_classes",
        "message": "Merge pull request #7 from Parquet/renaming_classes\n\nRenaming and moving classes",
        "diff": {
            "parquet-column/src/main/java/parquet/column/ColumnReader.java": [
                1,
                1
            ],
            "parquet-column/src/main/java/parquet/column/ColumnWriter.java": [
                1,
                1
            ],
            "parquet-column/src/main/java/parquet/column/Encoding.java": [
                0,
                6
            ],
            "parquet-column/src/main/java/parquet/column/mem/MemColumnReadStore.java": [
                11,
                13
            ],
            "parquet-column/src/main/java/parquet/column/mem/MemColumnReader.java": [
                17,
                19
            ],
            "parquet-column/src/main/java/parquet/column/mem/MemColumnWriteStore.java": [
                16,
                18
            ],
            "parquet-column/src/main/java/parquet/column/mem/MemColumnWriter.java": [
                18,
                19
            ],
            "parquet-column/src/main/java/parquet/column/mem/MemPageReader.java": [
                1,
                3
            ],
            "parquet-column/src/main/java/parquet/column/mem/MemPageStore.java": [
                1,
                6
            ],
            "parquet-column/src/main/java/parquet/column/mem/MemPageWriter.java": [
                1,
                3
            ],
            "parquet-column/src/main/java/parquet/column/mem/Page.java": [
                1,
                1
            ],
            "parquet-column/src/main/java/parquet/column/mem/PageReadStore.java": [
                1,
                1
            ],
            "parquet-column/src/main/java/parquet/column/mem/PageReader.java": [
                1,
                1
            ],
            "parquet-column/src/main/java/parquet/column/mem/PageWriteStore.java": [
                1,
                1
            ],
            "parquet-column/src/main/java/parquet/column/mem/PageWriter.java": [
                1,
                1
            ],
            "parquet-column/src/main/java/parquet/column/primitive/BitPacking.java": [
                3,
                3
            ],
            "parquet-column/src/main/java/parquet/column/primitive/BitPackingColumnReader.java": [
                8,
                9
            ],
            "parquet-column/src/main/java/parquet/column/primitive/BitPackingColumnWriter.java": [
                10,
                11
            ],
            "parquet-column/src/main/java/parquet/column/primitive/BitReader.java": [
                1,
                1
            ],
            "parquet-column/src/main/java/parquet/column/primitive/BitWriter.java": [
                1,
                1
            ],
            "parquet-column/src/main/java/parquet/column/primitive/BooleanPlainColumnReader.java": [
                7,
                8
            ],
            "parquet-column/src/main/java/parquet/column/primitive/BooleanPlainColumnWriter.java": [
                6,
                7
            ],
            "parquet-column/src/main/java/parquet/column/primitive/BoundedColumnFactory.java": [
                26,
                0
            ],
            "parquet-column/src/main/java/parquet/column/primitive/BoundedIntColumnReader.java": [
                5,
                6
            ],
            "parquet-column/src/main/java/parquet/column/primitive/BoundedIntColumnWriter.java": [
                5,
                7
            ],
            "parquet-column/src/main/java/parquet/column/primitive/DataColumnWriter.java": [
                2,
                2
            ],
            "parquet-column/src/main/java/parquet/column/primitive/DevNullColumnReader.java": [
                98,
                0
            ],
            "parquet-column/src/main/java/parquet/column/primitive/DevNullColumnWriter.java": [
                3,
                4
            ],
            "parquet-column/src/main/java/parquet/column/primitive/PlainColumnReader.java": [
                5,
                6
            ],
            "parquet-column/src/main/java/parquet/column/primitive/PlainColumnWriter.java": [
                5,
                6
            ],
            "parquet-column/src/main/java/parquet/column/primitive/PrimitiveColumnReader.java": [
                3,
                3
            ],
            "parquet-column/src/main/java/parquet/column/primitive/PrimitiveColumnWriter.java": [
                4,
                3
            ],
            "parquet-column/src/main/java/parquet/column/values/boundedint/BoundedIntValuesFactory.java": [
                0,
                29
            ],
            "parquet-column/src/main/java/parquet/column/values/boundedint/ZeroIntegerValuesReader.java": [
                0,
                38
            ],
            "parquet-column/src/main/java/parquet/example/DummyRecordConverter.java": [
                5,
                5
            ],
            "parquet-column/src/main/java/parquet/example/data/Group.java": [
                2,
                2
            ],
            "parquet-column/src/main/java/parquet/example/data/GroupRecordConsumer.java": [
                105,
                0
            ],
            "parquet-column/src/main/java/parquet/example/data/GroupValueSource.java": [
                1,
                1
            ],
            "parquet-column/src/main/java/parquet/example/data/GroupWriter.java": [
                1,
                1
            ],
            "parquet-column/src/main/java/parquet/example/data/simple/BinaryValue.java": [
                2,
                2
            ],
            "parquet-column/src/main/java/parquet/example/data/simple/BooleanValue.java": [
                1,
                1
            ],
            "parquet-column/src/main/java/parquet/example/data/simple/DoubleValue.java": [
                1,
                1
            ],
            "parquet-column/src/main/java/parquet/example/data/simple/FloatValue.java": [
                1,
                1
            ],
            "parquet-column/src/main/java/parquet/example/data/simple/IntegerValue.java": [
                1,
                1
            ],
            "parquet-column/src/main/java/parquet/example/data/simple/LongValue.java": [
                1,
                1
            ],
            "parquet-column/src/main/java/parquet/example/data/simple/Primitive.java": [
                2,
                2
            ],
            "parquet-column/src/main/java/parquet/example/data/simple/SimpleGroup.java": [
                2,
                2
            ],
            "parquet-column/src/main/java/parquet/example/data/simple/convert/GroupRecordConverter.java": [
                3,
                3
            ],
            "parquet-column/src/main/java/parquet/example/data/simple/convert/SimpleGroupConverter.java": [
                2,
                2
            ],
            "parquet-column/src/main/java/parquet/example/data/simple/convert/SimplePrimitiveConverter.java": [
                8,
                8
            ],
            "parquet-column/src/main/java/parquet/io/BaseRecordReader.java": [
                2,
                4
            ],
            "parquet-column/src/main/java/parquet/io/Binary.java": [
                1,
                1
            ],
            "parquet-column/src/main/java/parquet/io/MessageColumnIO.java": [
                5,
                7
            ],
            "parquet-column/src/main/java/parquet/io/RecordConsumer.java": [
                3,
                4
            ],
            "parquet-column/src/main/java/parquet/io/RecordConsumerLoggingWrapper.java": [
                0,
                2
            ],
            "parquet-column/src/main/java/parquet/io/RecordMaterializer.java": [
                34,
                0
            ],
            "parquet-column/src/main/java/parquet/io/RecordReaderImplementation.java": [
                11,
                11
            ],
            "parquet-column/src/main/java/parquet/io/ValidatingRecordConsumer.java": [
                1,
                3
            ],
            "parquet-column/src/main/java/parquet/io/convert/Converter.java": [
                1,
                1
            ],
            "parquet-column/src/main/java/parquet/io/convert/GroupConverter.java": [
                11,
                11
            ],
            "parquet-column/src/main/java/parquet/io/convert/PrimitiveConverter.java": [
                12,
                13
            ],
            "parquet-column/src/main/java/parquet/io/convert/RecordConverter.java": [
                2,
                2
            ],
            "parquet-column/src/main/java/parquet/parser/MessageTypeParser.java": [
                6,
                1
            ],
            "parquet-column/src/main/java/parquet/schema/PrimitiveType.java": [
                2,
                2
            ],
            "parquet-column/src/test/java/parquet/column/mem/TestMemColumn.java": [
                13,
                13
            ],
            "parquet-column/src/test/java/parquet/column/mem/TestMemPageStore.java": [
                0,
                4
            ],
            "parquet-column/src/test/java/parquet/column/primitive/TestBitPacking.java": [
                3,
                3
            ],
            "parquet-column/src/test/java/parquet/column/primitive/TestBitPackingColumn.java": [
                2,
                5
            ],
            "parquet-column/src/test/java/parquet/column/primitive/TestBoundedColumns.java": [
                7,
                7
            ],
            "parquet-column/src/test/java/parquet/io/ConverterConsumer.java": [
                2,
                4
            ],
            "parquet-column/src/test/java/parquet/io/ExpectationValidatingConverter.java": [
                5,
                6
            ],
            "parquet-column/src/test/java/parquet/io/ExpectationValidatingRecordConsumer.java": [
                5,
                4
            ],
            "parquet-column/src/test/java/parquet/io/PerfTest.java": [
                5,
                5
            ],
            "parquet-column/src/test/java/parquet/io/TestColumnIO.java": [
                12,
                13
            ],
            "parquet-column/src/test/java/parquet/parser/TestParquetParser.java": [
                1,
                1
            ],
            "parquet-column/src/test/java/parquet/schema/TestMessageType.java": [
                1,
                0
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/ColumnChunkPageReadStore.java": [
                3,
                3
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/ColumnChunkPageWriteStore.java": [
                2,
                2
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/ParquetFileReader.java": [
                2,
                2
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/ParquetInputFormat.java": [
                1,
                1
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/ParquetRecordReader.java": [
                4,
                4
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/ParquetRecordWriter.java": [
                3,
                3
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/api/ReadSupport.java": [
                2,
                2
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/api/WriteSupport.java": [
                1,
                1
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/example/GroupReadSupport.java": [
                2,
                2
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/example/GroupWriteSupport.java": [
                2,
                2
            ],
            "parquet-hadoop/src/test/java/parquet/hadoop/TestParquetFileWriter.java": [
                4,
                4
            ],
            "parquet-hadoop/src/test/java/parquet/hadoop/example/TestInputOutputFormat.java": [
                1,
                1
            ],
            "parquet-pig/src/main/java/parquet/pig/PigMetaData.java": [
                9,
                0
            ],
            "parquet-pig/src/main/java/parquet/pig/TupleReadSupport.java": [
                3,
                2
            ],
            "parquet-pig/src/main/java/parquet/pig/TupleRecordConsumer.java": [
                234,
                0
            ],
            "parquet-pig/src/main/java/parquet/pig/TupleWriteSupport.java": [
                5,
                2
            ],
            "parquet-pig/src/main/java/parquet/pig/convert/MapConverter.java": [
                4,
                4
            ],
            "parquet-pig/src/main/java/parquet/pig/convert/TupleConverter.java": [
                4,
                4
            ],
            "parquet-pig/src/main/java/parquet/pig/convert/TupleRecordConverter.java": [
                3,
                3
            ],
            "parquet-pig/src/test/java/parquet/pig/GenerateIntTestFile.java": [
                7,
                7
            ],
            "parquet-pig/src/test/java/parquet/pig/GenerateTPCH.java": [
                5,
                5
            ],
            "parquet-pig/src/test/java/parquet/pig/TestPigSchemaConverter.java": [
                1,
                1
            ],
            "parquet-pig/src/test/java/parquet/pig/TestTupleRecordConsumer.java": [
                5,
                5
            ],
            "parquet-pig/src/test/java/parquet/pig/TupleConsumerPerfTest.java": [
                18,
                7
            ],
            "parquet-thrift/src/main/java/parquet/hadoop/thrift/ThriftBytesWriteSupport.java": [
                1,
                1
            ],
            "parquet-thrift/src/main/java/parquet/hadoop/thrift/ThriftReadSupport.java": [
                2,
                2
            ],
            "parquet-thrift/src/main/java/parquet/hadoop/thrift/ThriftWriteSupport.java": [
                1,
                1
            ],
            "parquet-thrift/src/main/java/parquet/thrift/ParquetWriteProtocol.java": [
                2,
                2
            ],
            "parquet-thrift/src/main/java/parquet/thrift/ThriftRecordConverter.java": [
                8,
                8
            ],
            "parquet-thrift/src/test/java/parquet/thrift/TestParquetReadProtocol.java": [
                4,
                4
            ],
            "parquet-thrift/src/test/java/parquet/thrift/TestThriftSchemaConverter.java": [
                1,
                1
            ]
        }
    },
    "ef6b02c38f37005bd41cbbf1ff8d4dbe6f699b5c": {
        "datetime": "2013-03-08T14:07:20-08:00",
        "summary": "fixed merge issue",
        "message": "fixed merge issue\n",
        "diff": {
            "parquet-pig/pom.xml": null
        }
    },
    "6e33c3d317965c8a26a98b79e6595a6b2062beb4": {
        "datetime": "2013-03-08T14:35:12-08:00",
        "summary": "fix Filesystem access issues mentioned by Dmitriy",
        "message": "fix Filesystem access issues mentioned by Dmitriy\n",
        "diff": {
            "parquet-hadoop/src/main/java/parquet/hadoop/ParquetFileReader.java": [
                3,
                3
            ]
        }
    },
    "5a52fe124ab877876f5c884ee295d14d6573bd7d": {
        "datetime": "2013-03-08T17:56:43-08:00",
        "summary": "fix Filesystem access issues mentioned by Dmitriy",
        "message": "fix Filesystem access issues mentioned by Dmitriy\n",
        "diff": {
            "parquet-hadoop/src/main/java/parquet/hadoop/ParquetInputFormat.java": [
                3,
                5
            ]
        }
    },
    "12b99b1a78478999ef8da2c5617d65a5b0e687ac": {
        "datetime": "2013-03-11T08:25:52-07:00",
        "summary": "metadata file in parquet format",
        "message": "metadata file in parquet format\n",
        "diff": {
            "parquet-hadoop/src/main/java/parquet/format/converter/ParquetMetadataConverter.java": [
                1,
                8
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/ParquetFileReader.java": [
                12,
                21
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/ParquetFileWriter.java": [
                17,
                55
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/PrintFooter.java": [
                2,
                2
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/metadata/BlockMetaData.java": [
                0,
                16
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/metadata/FileMetaData.java": [
                0,
                8
            ],
            "pom.xml": null
        }
    },
    "251855be5bf1000d00371f4be7a04f3c83b438e4": {
        "datetime": "2013-03-11T09:49:42-07:00",
        "summary": "better metadata file tests",
        "message": "better metadata file tests\n",
        "diff": {
            "parquet-hadoop/src/test/java/parquet/hadoop/TestParquetFileWriter.java": [
                2,
                61
            ],
            "parquet-hadoop/src/test/java/parquet/hadoop/example/TestInputOutputFormat.java": [
                0,
                9
            ]
        }
    },
    "37ad86c2349391a1af3a90f933d53dcd33e93370": {
        "datetime": "2013-03-11T09:50:35-07:00",
        "summary": "removed old doc",
        "message": "removed old doc\n",
        "diff": {
            "doc/file_format/FileFormat.png": null
        }
    },
    "f7ba78a79be91e1d2ce1e47ff9fae9c071eea394": {
        "datetime": "2013-03-11T10:03:37-07:00",
        "summary": "Update README.md",
        "message": "Update README.md",
        "diff": {
            "README.md": null
        }
    },
    "dfd872b669c80ee2954ca77dbb95a019667d4f55": {
        "datetime": "2013-03-11T10:14:56-07:00",
        "summary": "javadoc",
        "message": "javadoc\n",
        "diff": {
            "parquet-pig/src/main/java/parquet/pig/ParquetLoader.java": [
                0,
                15
            ]
        }
    },
    "a4c107e78e24455702e73ff431a72d24f4402d12": {
        "datetime": "2013-03-11T12:17:32-07:00",
        "summary": "Updated file description.",
        "message": "Updated file description.\n",
        "diff": {
            ".editorconfig": null,
            ".github/PULL_REQUEST_TEMPLATE.md": null,
            ".github/dependabot.yml": null,
            ".github/workflows/ci-hadoop2.yml": null,
            ".github/workflows/ci-hadoop3.yml": null,
            ".github/workflows/vector-plugins.yml": null,
            ".gitignore": null,
            "CHANGES.md": null,
            "LICENSE": null,
            "NOTICE": null,
            "PoweredBy.md": null,
            "README.md": null,
            "changelog.sh": null,
            "dev/COMMITTERS.md": null,
            "dev/README.md": null,
            "dev/ci-before_install-master.sh": null,
            "dev/ci-before_install.sh": null,
            "dev/finalize-release": null,
            "dev/merge_parquet_pr.py": [
                393,
                0
            ],
            "dev/prepare-release.sh": null,
            "dev/source-release.sh": null,
            "doc/dremel_paper/dremel_example.png": null,
            "doc/dremel_paper/schema.png": null,
            "parquet-arrow/pom.xml": null,
            "parquet-arrow/src/main/java/org/apache/parquet/arrow/schema/List3Levels.java": [
                77,
                0
            ],
            "parquet-arrow/src/main/java/org/apache/parquet/arrow/schema/SchemaConverter.java": [
                705,
                0
            ],
            "parquet-arrow/src/main/java/org/apache/parquet/arrow/schema/SchemaMapping.java": [
                201,
                0
            ],
            "parquet-arrow/src/test/java/org/apache/parquet/arrow/schema/TestSchemaConverter.java": [
                530,
                0
            ],
            "parquet-avro/README.md": null,
            "parquet-avro/REVIEWERS.md": null,
            "parquet-avro/pom.xml": null,
            "parquet-avro/src/main/java/org/apache/parquet/avro/AvroCompatRecordMaterializer.java": [
                46,
                0
            ],
            "parquet-avro/src/main/java/org/apache/parquet/avro/AvroConverters.java": [
                333,
                0
            ],
            "parquet-avro/src/main/java/org/apache/parquet/avro/AvroDataSupplier.java": [
                31,
                0
            ],
            "parquet-avro/src/main/java/org/apache/parquet/avro/AvroIndexedRecordConverter.java": [
                535,
                0
            ],
            "parquet-avro/src/main/java/org/apache/parquet/avro/AvroParquetInputFormat.java": [
                86,
                0
            ],
            "parquet-avro/src/main/java/org/apache/parquet/avro/AvroParquetOutputFormat.java": [
                63,
                0
            ],
            "parquet-avro/src/main/java/org/apache/parquet/avro/AvroParquetReader.java": [
                178,
                0
            ],
            "parquet-avro/src/main/java/org/apache/parquet/avro/AvroParquetWriter.java": [
                193,
                0
            ],
            "parquet-avro/src/main/java/org/apache/parquet/avro/AvroReadSupport.java": [
                180,
                0
            ],
            "parquet-avro/src/main/java/org/apache/parquet/avro/AvroRecordConverter.java": [
                1093,
                0
            ],
            "parquet-avro/src/main/java/org/apache/parquet/avro/AvroRecordMaterializer.java": [
                45,
                0
            ],
            "parquet-avro/src/main/java/org/apache/parquet/avro/AvroSchemaConverter.java": [
                565,
                0
            ],
            "parquet-avro/src/main/java/org/apache/parquet/avro/AvroWriteSupport.java": [
                711,
                0
            ],
            "parquet-avro/src/main/java/org/apache/parquet/avro/GenericDataSupplier.java": [
                28,
                0
            ],
            "parquet-avro/src/main/java/org/apache/parquet/avro/ParentValueContainer.java": [
                238,
                0
            ],
            "parquet-avro/src/main/java/org/apache/parquet/avro/ReflectDataSupplier.java": [
                29,
                0
            ],
            "parquet-avro/src/main/java/org/apache/parquet/avro/SpecificDataSupplier.java": [
                29,
                0
            ],
            "parquet-avro/src/main/java/org/apache/parquet/avro/package-info.java": [
                174,
                0
            ],
            "parquet-avro/src/main/resources/META-INF/LICENSE": null,
            "parquet-avro/src/main/resources/META-INF/NOTICE": null,
            "parquet-avro/src/test/avro/logicalType.avsc": null,
            "parquet-avro/src/test/avro/stringBehavior.avsc": null,
            "parquet-avro/src/test/java/org/apache/parquet/avro/AvroTestUtil.java": [
                136,
                0
            ],
            "parquet-avro/src/test/java/org/apache/parquet/avro/TestArrayCompatibility.java": [
                1164,
                0
            ],
            "parquet-avro/src/test/java/org/apache/parquet/avro/TestAvroDataSupplier.java": [
                43,
                0
            ],
            "parquet-avro/src/test/java/org/apache/parquet/avro/TestAvroRecordConverter.java": [
                202,
                0
            ],
            "parquet-avro/src/test/java/org/apache/parquet/avro/TestAvroSchemaConverter.java": [
                942,
                0
            ],
            "parquet-avro/src/test/java/org/apache/parquet/avro/TestAvroWriteSupport.java": [
                61,
                0
            ],
            "parquet-avro/src/test/java/org/apache/parquet/avro/TestBackwardCompatibility.java": [
                68,
                0
            ],
            "parquet-avro/src/test/java/org/apache/parquet/avro/TestByteStreamSplitE2E.java": [
                114,
                0
            ],
            "parquet-avro/src/test/java/org/apache/parquet/avro/TestCircularReferences.java": [
                387,
                0
            ],
            "parquet-avro/src/test/java/org/apache/parquet/avro/TestGenericLogicalTypes.java": [
                296,
                0
            ],
            "parquet-avro/src/test/java/org/apache/parquet/avro/TestInputOutputFormat.java": [
                145,
                0
            ],
            "parquet-avro/src/test/java/org/apache/parquet/avro/TestReadWrite.java": [
                900,
                0
            ],
            "parquet-avro/src/test/java/org/apache/parquet/avro/TestReadWriteOldListBehavior.java": [
                584,
                0
            ],
            "parquet-avro/src/test/java/org/apache/parquet/avro/TestReflectInputOutputFormat.java": [
                496,
                0
            ],
            "parquet-avro/src/test/java/org/apache/parquet/avro/TestReflectLogicalTypes.java": [
                999,
                0
            ],
            "parquet-avro/src/test/java/org/apache/parquet/avro/TestReflectReadWrite.java": [
                240,
                0
            ],
            "parquet-avro/src/test/java/org/apache/parquet/avro/TestSpecificInputOutputFormat.java": [
                287,
                0
            ],
            "parquet-avro/src/test/java/org/apache/parquet/avro/TestSpecificReadWrite.java": [
                360,
                0
            ],
            "parquet-avro/src/test/java/org/apache/parquet/avro/TestStringBehavior.java": [
                330,
                0
            ],
            "parquet-avro/src/test/resources/all.avsc": null,
            "parquet-avro/src/test/resources/allFromParquetNewBehavior.avsc": null,
            "parquet-avro/src/test/resources/allFromParquetOldBehavior.avsc": null,
            "parquet-avro/src/test/resources/array.avsc": null,
            "parquet-avro/src/test/resources/car.avdl": null,
            "parquet-avro/src/test/resources/fixedToInt96.avsc": null,
            "parquet-avro/src/test/resources/list_with_nulls.avsc": null,
            "parquet-avro/src/test/resources/map.avsc": null,
            "parquet-avro/src/test/resources/map_with_nulls.avsc": null,
            "parquet-avro/src/test/resources/nested_array.avsc": null,
            "parquet-avro/src/test/resources/strings-2.parquet": null,
            "parquet-benchmarks/README.md": null,
            "parquet-benchmarks/pom.xml": null,
            "parquet-benchmarks/run.sh": null,
            "parquet-benchmarks/src/main/java/org/apache/parquet/benchmarks/BenchmarkConstants.java": [
                42,
                0
            ],
            "parquet-benchmarks/src/main/java/org/apache/parquet/benchmarks/BenchmarkFiles.java": [
                64,
                0
            ],
            "parquet-benchmarks/src/main/java/org/apache/parquet/benchmarks/BenchmarkUtils.java": [
                46,
                0
            ],
            "parquet-benchmarks/src/main/java/org/apache/parquet/benchmarks/DataGenerator.java": [
                137,
                0
            ],
            "parquet-benchmarks/src/main/java/org/apache/parquet/benchmarks/FilteringBenchmarks.java": [
                430,
                0
            ],
            "parquet-benchmarks/src/main/java/org/apache/parquet/benchmarks/NestedNullWritingBenchmarks.java": [
                156,
                0
            ],
            "parquet-benchmarks/src/main/java/org/apache/parquet/benchmarks/PageChecksumDataGenerator.java": [
                106,
                0
            ],
            "parquet-benchmarks/src/main/java/org/apache/parquet/benchmarks/PageChecksumReadBenchmarks.java": [
                196,
                0
            ],
            "parquet-benchmarks/src/main/java/org/apache/parquet/benchmarks/PageChecksumWriteBenchmarks.java": [
                178,
                0
            ],
            "parquet-benchmarks/src/main/java/org/apache/parquet/benchmarks/ReadBenchmarks.java": [
                131,
                0
            ],
            "parquet-benchmarks/src/main/java/org/apache/parquet/benchmarks/WriteBenchmarks.java": [
                168,
                0
            ],
            "parquet-benchmarks/src/main/resources/log4j.properties": null,
            "parquet-cli/README.md": null,
            "parquet-cli/pom.xml": null,
            "parquet-cli/src/main/java/org/apache/parquet/cli/BaseCommand.java": [
                428,
                0
            ],
            "parquet-cli/src/main/java/org/apache/parquet/cli/Command.java": [
                40,
                0
            ],
            "parquet-cli/src/main/java/org/apache/parquet/cli/HadoopFileSystemURLStreamHandler.java": [
                79,
                0
            ],
            "parquet-cli/src/main/java/org/apache/parquet/cli/Help.java": [
                153,
                0
            ],
            "parquet-cli/src/main/java/org/apache/parquet/cli/Main.java": [
                196,
                0
            ],
            "parquet-cli/src/main/java/org/apache/parquet/cli/Util.java": [
                272,
                0
            ],
            "parquet-cli/src/main/java/org/apache/parquet/cli/commands/CSVSchemaCommand.java": [
                131,
                0
            ],
            "parquet-cli/src/main/java/org/apache/parquet/cli/commands/CatCommand.java": [
                106,
                0
            ],
            "parquet-cli/src/main/java/org/apache/parquet/cli/commands/CheckParquet251Command.java": [
                352,
                0
            ],
            "parquet-cli/src/main/java/org/apache/parquet/cli/commands/ColumnMaskingCommand.java": [
                115,
                0
            ],
            "parquet-cli/src/main/java/org/apache/parquet/cli/commands/ColumnSizeCommand.java": [
                137,
                0
            ],
            "parquet-cli/src/main/java/org/apache/parquet/cli/commands/ConvertCSVCommand.java": [
                204,
                0
            ],
            "parquet-cli/src/main/java/org/apache/parquet/cli/commands/ConvertCommand.java": [
                165,
                0
            ],
            "parquet-cli/src/main/java/org/apache/parquet/cli/commands/ParquetMetadataCommand.java": [
                183,
                0
            ],
            "parquet-cli/src/main/java/org/apache/parquet/cli/commands/PruneColumnsCommand.java": [
                82,
                0
            ],
            "parquet-cli/src/main/java/org/apache/parquet/cli/commands/RewriteCommand.java": [
                131,
                0
            ],
            "parquet-cli/src/main/java/org/apache/parquet/cli/commands/ScanCommand.java": [
                91,
                0
            ],
            "parquet-cli/src/main/java/org/apache/parquet/cli/commands/SchemaCommand.java": [
                132,
                0
            ],
            "parquet-cli/src/main/java/org/apache/parquet/cli/commands/ShowBloomFilterCommand.java": [
                133,
                0
            ],
            "parquet-cli/src/main/java/org/apache/parquet/cli/commands/ShowColumnIndexCommand.java": [
                157,
                0
            ],
            "parquet-cli/src/main/java/org/apache/parquet/cli/commands/ShowDictionaryCommand.java": [
                139,
                0
            ],
            "parquet-cli/src/main/java/org/apache/parquet/cli/commands/ShowFooterCommand.java": [
                101,
                0
            ],
            "parquet-cli/src/main/java/org/apache/parquet/cli/commands/ShowPagesCommand.java": [
                234,
                0
            ],
            "parquet-cli/src/main/java/org/apache/parquet/cli/commands/ToAvroCommand.java": [
                134,
                0
            ],
            "parquet-cli/src/main/java/org/apache/parquet/cli/commands/TransCompressionCommand.java": [
                101,
                0
            ],
            "parquet-cli/src/main/java/org/apache/parquet/cli/csv/AvroCSV.java": [
                258,
                0
            ],
            "parquet-cli/src/main/java/org/apache/parquet/cli/csv/AvroCSVReader.java": [
                121,
                0
            ],
            "parquet-cli/src/main/java/org/apache/parquet/cli/csv/CSVProperties.java": [
                120,
                0
            ],
            "parquet-cli/src/main/java/org/apache/parquet/cli/csv/RecordBuilder.java": [
                200,
                0
            ],
            "parquet-cli/src/main/java/org/apache/parquet/cli/json/AvroJson.java": [
                631,
                0
            ],
            "parquet-cli/src/main/java/org/apache/parquet/cli/json/AvroJsonReader.java": [
                77,
                0
            ],
            "parquet-cli/src/main/java/org/apache/parquet/cli/rawpages/RawPagesReader.java": [
                92,
                0
            ],
            "parquet-cli/src/main/java/org/apache/parquet/cli/util/Codecs.java": [
                52,
                0
            ],
            "parquet-cli/src/main/java/org/apache/parquet/cli/util/Expressions.java": [
                395,
                0
            ],
            "parquet-cli/src/main/java/org/apache/parquet/cli/util/Formats.java": [
                47,
                0
            ],
            "parquet-cli/src/main/java/org/apache/parquet/cli/util/GetClassLoader.java": [
                39,
                0
            ],
            "parquet-cli/src/main/java/org/apache/parquet/cli/util/RawUtils.java": [
                85,
                0
            ],
            "parquet-cli/src/main/java/org/apache/parquet/cli/util/RecordException.java": [
                55,
                0
            ],
            "parquet-cli/src/main/java/org/apache/parquet/cli/util/RuntimeIOException.java": [
                31,
                0
            ],
            "parquet-cli/src/main/java/org/apache/parquet/cli/util/Schemas.java": [
                501,
                0
            ],
            "parquet-cli/src/main/java/org/apache/parquet/cli/util/SeekableFSDataInputStream.java": [
                76,
                0
            ],
            "parquet-cli/src/main/resources/META-INF/LICENSE": null,
            "parquet-cli/src/main/resources/META-INF/NOTICE": null,
            "parquet-cli/src/main/resources/cli-logging.properties": null,
            "parquet-cli/src/test/java/org/apache/parquet/cli/BaseCommandTest.java": [
                100,
                0
            ],
            "parquet-cli/src/test/java/org/apache/parquet/cli/MainTest.java": [
                34,
                0
            ],
            "parquet-cli/src/test/java/org/apache/parquet/cli/commands/AvroFileTest.java": [
                53,
                0
            ],
            "parquet-cli/src/test/java/org/apache/parquet/cli/commands/CSVFileTest.java": [
                51,
                0
            ],
            "parquet-cli/src/test/java/org/apache/parquet/cli/commands/CSVSchemaCommandTest.java": [
                39,
                0
            ],
            "parquet-cli/src/test/java/org/apache/parquet/cli/commands/CatCommandTest.java": [
                38,
                0
            ],
            "parquet-cli/src/test/java/org/apache/parquet/cli/commands/CheckParquet251CommandTest.java": [
                38,
                0
            ],
            "parquet-cli/src/test/java/org/apache/parquet/cli/commands/ColumnSizeCommandTest.java": [
                91,
                0
            ],
            "parquet-cli/src/test/java/org/apache/parquet/cli/commands/ConvertCSVCommandTest.java": [
                41,
                0
            ],
            "parquet-cli/src/test/java/org/apache/parquet/cli/commands/ConvertCommandTest.java": [
                41,
                0
            ],
            "parquet-cli/src/test/java/org/apache/parquet/cli/commands/FileTest.java": [
                58,
                0
            ],
            "parquet-cli/src/test/java/org/apache/parquet/cli/commands/ParquetFileTest.java": [
                117,
                0
            ],
            "parquet-cli/src/test/java/org/apache/parquet/cli/commands/ParquetMetadataCommandTest.java": [
                38,
                0
            ],
            "parquet-cli/src/test/java/org/apache/parquet/cli/commands/RewriteCommandTest.java": [
                41,
                0
            ],
            "parquet-cli/src/test/java/org/apache/parquet/cli/commands/ScanCommandTest.java": [
                38,
                0
            ],
            "parquet-cli/src/test/java/org/apache/parquet/cli/commands/SchemaCommandTest.java": [
                68,
                0
            ],
            "parquet-cli/src/test/java/org/apache/parquet/cli/commands/ShowBloomFilterCommandTest.java": [
                41,
                0
            ],
            "parquet-cli/src/test/java/org/apache/parquet/cli/commands/ShowColumnIndexTest.java": [
                38,
                0
            ],
            "parquet-cli/src/test/java/org/apache/parquet/cli/commands/ShowDictionaryCommandTest.java": [
                50,
                0
            ],
            "parquet-cli/src/test/java/org/apache/parquet/cli/commands/ShowFooterCommandTest.java": [
                43,
                0
            ],
            "parquet-cli/src/test/java/org/apache/parquet/cli/commands/ShowPagesCommandTest.java": [
                38,
                0
            ],
            "parquet-cli/src/test/java/org/apache/parquet/cli/commands/ToAvroCommandTest.java": [
                113,
                0
            ],
            "parquet-cli/src/test/java/org/apache/parquet/cli/commands/TransCompressionCommandTest.java": [
                45,
                0
            ],
            "parquet-column/REVIEWERS.md": null,
            "parquet-column/pom.xml": null,
            "parquet-column/src/main/java/org/apache/parquet/CorruptDeltaByteArrays.java": [
                97,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/CorruptStatistics.java": [
                116,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/ColumnDescriptor.java": [
                156,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/ColumnProperty.java": [
                137,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/ColumnReadStore.java": [
                32,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/ColumnReader.java": [
                117,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/ColumnWriteStore.java": [
                75,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/ColumnWriter.java": [
                96,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/Dictionary.java": [
                63,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/Encoding.java": [
                309,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/EncodingStats.java": [
                157,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/MinMax.java": [
                56,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/ParquetProperties.java": [
                589,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/UnknownColumnException.java": [
                40,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/UnknownColumnTypeException.java": [
                41,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/ValuesType.java": [
                26,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/impl/ColumnReadStoreImpl.java": [
                104,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/impl/ColumnReaderBase.java": [
                790,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/impl/ColumnReaderImpl.java": [
                58,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/impl/ColumnWriteStoreBase.java": [
                273,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/impl/ColumnWriteStoreV1.java": [
                52,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/impl/ColumnWriteStoreV2.java": [
                46,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/impl/ColumnWriterBase.java": [
                408,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/impl/ColumnWriterV1.java": [
                68,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/impl/ColumnWriterV2.java": [
                94,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/impl/SynchronizingColumnReader.java": [
                111,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/page/DataPage.java": [
                72,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/page/DataPageV1.java": [
                127,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/page/DataPageV2.java": [
                207,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/page/DictionaryPage.java": [
                83,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/page/DictionaryPageReadStore.java": [
                36,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/page/Page.java": [
                62,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/page/PageReadStore.java": [
                64,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/page/PageReader.java": [
                40,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/page/PageWriteStore.java": [
                35,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/page/PageWriter.java": [
                102,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/statistics/BinaryStatistics.java": [
                188,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/statistics/BooleanStatistics.java": [
                147,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/statistics/DoubleStatistics.java": [
                147,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/statistics/FloatStatistics.java": [
                148,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/statistics/IntStatistics.java": [
                147,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/statistics/LongStatistics.java": [
                147,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/statistics/Statistics.java": [
                539,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/statistics/StatisticsClassException.java": [
                44,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/values/RequiresFallback.java": [
                51,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/values/RequiresPreviousReader.java": [
                23,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/values/ValuesReader.java": [
                205,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/values/ValuesWriter.java": [
                136,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/values/bitpacking/BitPackingValuesReader.java": [
                84,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/values/bitpacking/BitPackingValuesWriter.java": [
                130,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/values/bitpacking/ByteBitPackingValuesReader.java": [
                99,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/values/bitpacking/ByteBitPackingValuesWriter.java": [
                86,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/values/bitpacking/DevNullValuesWriter.java": [
                89,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/values/bloomfilter/AdaptiveBlockSplitBloomFilter.java": [
                305,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/values/bloomfilter/BlockSplitBloomFilter.java": [
                424,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/values/bloomfilter/BloomFilter.java": [
                203,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/values/bloomfilter/BloomFilterWriteStore.java": [
                35,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/values/bloomfilter/BloomFilterWriter.java": [
                31,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/values/bloomfilter/HashFunction.java": [
                41,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/values/bloomfilter/XxHash.java": [
                40,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/values/bytestreamsplit/ByteStreamSplitValuesReader.java": [
                111,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/values/bytestreamsplit/ByteStreamSplitValuesReaderForDouble.java": [
                37,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/values/bytestreamsplit/ByteStreamSplitValuesReaderForFloat.java": [
                37,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/values/bytestreamsplit/ByteStreamSplitValuesWriter.java": [
                142,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/values/delta/DeltaBinaryPackingConfig.java": [
                55,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/values/delta/DeltaBinaryPackingValuesReader.java": [
                171,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/values/delta/DeltaBinaryPackingValuesWriter.java": [
                136,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/values/delta/DeltaBinaryPackingValuesWriterForInteger.java": [
                196,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/values/delta/DeltaBinaryPackingValuesWriterForLong.java": [
                198,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/values/deltalengthbytearray/DeltaLengthByteArrayValuesReader.java": [
                80,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/values/deltalengthbytearray/DeltaLengthByteArrayValuesWriter.java": [
                115,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/values/deltastrings/DeltaByteArrayReader.java": [
                96,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/values/deltastrings/DeltaByteArrayWriter.java": [
                100,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/values/dictionary/DictionaryValuesReader.java": [
                131,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/values/dictionary/DictionaryValuesWriter.java": [
                597,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/values/dictionary/IntList.java": [
                159,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/values/dictionary/PlainValuesDictionary.java": [
                313,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/values/factory/DefaultV1ValuesWriterFactory.java": [
                122,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/values/factory/DefaultV2ValuesWriterFactory.java": [
                126,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/values/factory/DefaultValuesWriterFactory.java": [
                87,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/values/factory/ValuesWriterFactory.java": [
                52,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/values/fallback/FallbackValuesWriter.java": [
                204,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/values/plain/BinaryPlainValuesReader.java": [
                63,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/values/plain/BooleanPlainValuesReader.java": [
                73,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/values/plain/BooleanPlainValuesWriter.java": [
                81,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/values/plain/FixedLenByteArrayPlainValuesReader.java": [
                72,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/values/plain/FixedLenByteArrayPlainValuesWriter.java": [
                106,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/values/plain/PlainValuesReader.java": [
                139,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/values/plain/PlainValuesWriter.java": [
                148,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/values/rle/RunLengthBitPackingHybridDecoder.java": [
                107,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/values/rle/RunLengthBitPackingHybridEncoder.java": [
                293,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/values/rle/RunLengthBitPackingHybridValuesReader.java": [
                68,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/values/rle/RunLengthBitPackingHybridValuesWriter.java": [
                95,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/values/rle/ZeroIntegerValuesReader.java": [
                50,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/example/DummyRecordConverter.java": [
                114,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/example/Paper.java": [
                164,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/example/data/Group.java": [
                147,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/example/data/GroupFactory.java": [
                25,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/example/data/GroupValueSource.java": [
                89,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/example/data/GroupWriter.java": [
                62,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/example/data/simple/BinaryValue.java": [
                52,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/example/data/simple/BooleanValue.java": [
                44,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/example/data/simple/DoubleValue.java": [
                45,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/example/data/simple/FloatValue.java": [
                45,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/example/data/simple/Int96Value.java": [
                46,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/example/data/simple/IntegerValue.java": [
                46,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/example/data/simple/LongValue.java": [
                45,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/example/data/simple/NanoTime.java": [
                80,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/example/data/simple/Primitive.java": [
                60,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/example/data/simple/SimpleGroup.java": [
                236,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/example/data/simple/SimpleGroupFactory.java": [
                38,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/example/data/simple/convert/GroupRecordConverter.java": [
                57,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/example/data/simple/convert/SimpleGroupConverter.java": [
                67,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/example/data/simple/convert/SimplePrimitiveConverter.java": [
                88,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/filter/AndRecordFilter.java": [
                65,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/filter/ColumnPredicates.java": [
                191,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/filter/ColumnRecordFilter.java": [
                76,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/filter/NotRecordFilter.java": [
                60,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/filter/OrRecordFilter.java": [
                62,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/filter/PagedRecordFilter.java": [
                65,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/filter/RecordFilter.java": [
                33,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/filter/UnboundRecordFilter.java": [
                37,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/filter2/compat/FilterCompat.java": [
                181,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/filter2/predicate/FilterApi.java": [
                328,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/filter2/predicate/FilterPredicate.java": [
                84,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/filter2/predicate/LogicalInverseRewriter.java": [
                126,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/filter2/predicate/LogicalInverter.java": [
                120,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/filter2/predicate/Operators.java": [
                587,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/filter2/predicate/PrimitiveToBoxedClass.java": [
                50,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/filter2/predicate/SchemaCompatibilityValidator.java": [
                204,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/filter2/predicate/Statistics.java": [
                93,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/filter2/predicate/UserDefinedPredicate.java": [
                131,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/filter2/predicate/ValidTypeMap.java": [
                128,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/filter2/recordlevel/FilteringGroupConverter.java": [
                112,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/filter2/recordlevel/FilteringPrimitiveConverter.java": [
                109,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/filter2/recordlevel/FilteringRecordMaterializer.java": [
                116,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/filter2/recordlevel/IncrementallyUpdatedFilterPredicate.java": [
                166,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/filter2/recordlevel/IncrementallyUpdatedFilterPredicateBuilderBase.java": [
                116,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/filter2/recordlevel/IncrementallyUpdatedFilterPredicateEvaluator.java": [
                62,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/filter2/recordlevel/IncrementallyUpdatedFilterPredicateResetter.java": [
                59,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/internal/column/columnindex/BinaryColumnIndexBuilder.java": [
                140,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/internal/column/columnindex/BinaryTruncator.java": [
                221,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/internal/column/columnindex/BooleanColumnIndexBuilder.java": [
                133,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/internal/column/columnindex/BoundaryOrder.java": [
                384,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/internal/column/columnindex/ColumnIndex.java": [
                60,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/internal/column/columnindex/ColumnIndexBuilder.java": [
                686,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/internal/column/columnindex/DoubleColumnIndexBuilder.java": [
                155,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/internal/column/columnindex/FloatColumnIndexBuilder.java": [
                155,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/internal/column/columnindex/IndexIterator.java": [
                89,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/internal/column/columnindex/IntColumnIndexBuilder.java": [
                136,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/internal/column/columnindex/LongColumnIndexBuilder.java": [
                136,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/internal/column/columnindex/OffsetIndex.java": [
                73,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/internal/column/columnindex/OffsetIndexBuilder.java": [
                193,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/internal/filter2/columnindex/ColumnIndexFilter.java": [
                217,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/internal/filter2/columnindex/ColumnIndexStore.java": [
                55,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/internal/filter2/columnindex/RowRanges.java": [
                318,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/io/BaseRecordReader.java": [
                149,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/io/ColumnIO.java": [
                138,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/io/ColumnIOFactory.java": [
                174,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/io/CompilationException.java": [
                44,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/io/EmptyRecordReader.java": [
                48,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/io/FilteredRecordReader.java": [
                97,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/io/GroupColumnIO.java": [
                121,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/io/InvalidFileOffsetException.java": [
                29,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/io/InvalidRecordException.java": [
                45,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/io/MessageColumnIO.java": [
                534,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/io/ParquetDecodingException.java": [
                44,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/io/ParquetEncodingException.java": [
                44,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/io/PrimitiveColumnIO.java": [
                108,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/io/RecordConsumerLoggingWrapper.java": [
                187,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/io/RecordReader.java": [
                43,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/io/RecordReaderImplementation.java": [
                474,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/io/ValidatingRecordConsumer.java": [
                247,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/io/api/Binary.java": [
                737,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/io/api/Converter.java": [
                37,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/io/api/GroupConverter.java": [
                55,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/io/api/PrimitiveConverter.java": [
                108,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/io/api/RecordConsumer.java": [
                134,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/io/api/RecordMaterializer.java": [
                73,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/schema/ColumnOrder.java": [
                97,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/schema/ConversionPatterns.java": [
                133,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/schema/DecimalMetadata.java": [
                62,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/schema/GroupType.java": [
                421,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/schema/IncompatibleSchemaModificationException.java": [
                46,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/schema/InvalidSchemaException.java": [
                31,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/schema/LogicalTypeAnnotation.java": [
                1064,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/schema/MessageType.java": [
                145,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/schema/MessageTypeParser.java": [
                243,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/schema/OriginalType.java": [
                48,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/schema/PrimitiveComparator.java": [
                279,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/schema/PrimitiveStringifier.java": [
                451,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/schema/PrimitiveType.java": [
                797,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/schema/Type.java": [
                366,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/schema/TypeConverter.java": [
                53,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/schema/TypeUtil.java": [
                45,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/schema/TypeVisitor.java": [
                43,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/schema/Types.java": [
                1542,
                0
            ],
            "parquet-column/src/main/resources/META-INF/LICENSE": null,
            "parquet-column/src/test/java/org/apache/parquet/CorruptStatisticsTest.java": [
                92,
                0
            ],
            "parquet-column/src/test/java/org/apache/parquet/FixedBinaryTestUtils.java": [
                96,
                0
            ],
            "parquet-column/src/test/java/org/apache/parquet/ResourceIntensiveTestRule.java": [
                58,
                0
            ],
            "parquet-column/src/test/java/org/apache/parquet/column/TestColumnDescriptor.java": [
                52,
                0
            ],
            "parquet-column/src/test/java/org/apache/parquet/column/TestEncodingStats.java": [
                202,
                0
            ],
            "parquet-column/src/test/java/org/apache/parquet/column/impl/TestColumnReaderImpl.java": [
                131,
                0
            ],
            "parquet-column/src/test/java/org/apache/parquet/column/impl/TestCorruptDeltaByteArrays.java": [
                269,
                0
            ],
            "parquet-column/src/test/java/org/apache/parquet/column/mem/TestMemColumn.java": [
                246,
                0
            ],
            "parquet-column/src/test/java/org/apache/parquet/column/mem/TestMemPageStore.java": [
                61,
                0
            ],
            "parquet-column/src/test/java/org/apache/parquet/column/page/mem/MemPageReader.java": [
                67,
                0
            ],
            "parquet-column/src/test/java/org/apache/parquet/column/page/mem/MemPageStore.java": [
                78,
                0
            ],
            "parquet-column/src/test/java/org/apache/parquet/column/page/mem/MemPageWriter.java": [
                117,
                0
            ],
            "parquet-column/src/test/java/org/apache/parquet/column/statistics/TestStatistics.java": [
                789,
                0
            ],
            "parquet-column/src/test/java/org/apache/parquet/column/values/TestValuesReaderImpl.java": [
                148,
                0
            ],
            "parquet-column/src/test/java/org/apache/parquet/column/values/Utils.java": [
                76,
                0
            ],
            "parquet-column/src/test/java/org/apache/parquet/column/values/bitpacking/BitPackingPerfTest.java": [
                103,
                0
            ],
            "parquet-column/src/test/java/org/apache/parquet/column/values/bitpacking/TestBitPackingColumn.java": [
                232,
                0
            ],
            "parquet-column/src/test/java/org/apache/parquet/column/values/bloomfilter/TestBlockSplitBloomFilter.java": [
                325,
                0
            ],
            "parquet-column/src/test/java/org/apache/parquet/column/values/bytestreamsplit/ByteStreamSplitValuesEndToEndTest.java": [
                111,
                0
            ],
            "parquet-column/src/test/java/org/apache/parquet/column/values/bytestreamsplit/ByteStreamSplitValuesReaderTest.java": [
                193,
                0
            ],
            "parquet-column/src/test/java/org/apache/parquet/column/values/bytestreamsplit/ByteStreamSplitValuesWriterTest.java": [
                189,
                0
            ],
            "parquet-column/src/test/java/org/apache/parquet/column/values/delta/DeltaBinaryPackingValuesWriterForIntegerTest.java": [
                294,
                0
            ],
            "parquet-column/src/test/java/org/apache/parquet/column/values/delta/DeltaBinaryPackingValuesWriterForLongTest.java": [
                291,
                0
            ],
            "parquet-column/src/test/java/org/apache/parquet/column/values/delta/benchmark/BenchMarkTest.java": [
                41,
                0
            ],
            "parquet-column/src/test/java/org/apache/parquet/column/values/delta/benchmark/BenchmarkIntegerOutputSize.java": [
                107,
                0
            ],
            "parquet-column/src/test/java/org/apache/parquet/column/values/delta/benchmark/BenchmarkReadingRandomIntegers.java": [
                102,
                0
            ],
            "parquet-column/src/test/java/org/apache/parquet/column/values/delta/benchmark/RandomWritingBenchmarkTest.java": [
                76,
                0
            ],
            "parquet-column/src/test/java/org/apache/parquet/column/values/delta/benchmark/SmallRangeWritingBenchmarkTest.java": [
                49,
                0
            ],
            "parquet-column/src/test/java/org/apache/parquet/column/values/deltalengthbytearray/TestDeltaLengthByteArray.java": [
                103,
                0
            ],
            "parquet-column/src/test/java/org/apache/parquet/column/values/deltalengthbytearray/benchmark/BenchmarkDeltaLengthByteArray.java": [
                73,
                0
            ],
            "parquet-column/src/test/java/org/apache/parquet/column/values/deltastrings/TestDeltaByteArray.java": [
                130,
                0
            ],
            "parquet-column/src/test/java/org/apache/parquet/column/values/deltastrings/benchmark/BenchmarkDeltaByteArray.java": [
                103,
                0
            ],
            "parquet-column/src/test/java/org/apache/parquet/column/values/dictionary/IntListTest.java": [
                84,
                0
            ],
            "parquet-column/src/test/java/org/apache/parquet/column/values/dictionary/TestDictionary.java": [
                661,
                0
            ],
            "parquet-column/src/test/java/org/apache/parquet/column/values/factory/DefaultValuesWriterFactoryTest.java": [
                546,
                0
            ],
            "parquet-column/src/test/java/org/apache/parquet/column/values/rle/RunLengthBitPackingHybridIntegrationTest.java": [
                86,
                0
            ],
            "parquet-column/src/test/java/org/apache/parquet/column/values/rle/TestRunLengthBitPackingHybridEncoder.java": [
                329,
                0
            ],
            "parquet-column/src/test/java/org/apache/parquet/filter2/predicate/DummyUdp.java": [
                37,
                0
            ],
            "parquet-column/src/test/java/org/apache/parquet/filter2/predicate/TestFilterApiMethods.java": [
                172,
                0
            ],
            "parquet-column/src/test/java/org/apache/parquet/filter2/predicate/TestLogicalInverseRewriter.java": [
                103,
                0
            ],
            "parquet-column/src/test/java/org/apache/parquet/filter2/predicate/TestLogicalInverter.java": [
                94,
                0
            ],
            "parquet-column/src/test/java/org/apache/parquet/filter2/predicate/TestSchemaCompatibilityValidator.java": [
                142,
                0
            ],
            "parquet-column/src/test/java/org/apache/parquet/filter2/predicate/TestValidTypeMap.java": [
                98,
                0
            ],
            "parquet-column/src/test/java/org/apache/parquet/filter2/recordlevel/TestIncrementallyUpdatedFilterPredicateEvaluator.java": [
                209,
                0
            ],
            "parquet-column/src/test/java/org/apache/parquet/filter2/recordlevel/TestIncrementallyUpdatedFilterPredicateResetter.java": [
                69,
                0
            ],
            "parquet-column/src/test/java/org/apache/parquet/filter2/recordlevel/TestValueInspector.java": [
                97,
                0
            ],
            "parquet-column/src/test/java/org/apache/parquet/internal/column/columnindex/TestBinaryTruncator.java": [
                285,
                0
            ],
            "parquet-column/src/test/java/org/apache/parquet/internal/column/columnindex/TestBoundaryOrder.java": [
                543,
                0
            ],
            "parquet-column/src/test/java/org/apache/parquet/internal/column/columnindex/TestColumnIndexBuilder.java": [
                1728,
                0
            ],
            "parquet-column/src/test/java/org/apache/parquet/internal/column/columnindex/TestIndexIterator.java": [
                63,
                0
            ],
            "parquet-column/src/test/java/org/apache/parquet/internal/column/columnindex/TestOffsetIndexBuilder.java": [
                111,
                0
            ],
            "parquet-column/src/test/java/org/apache/parquet/internal/filter2/columnindex/TestColumnIndexFilter.java": [
                555,
                0
            ],
            "parquet-column/src/test/java/org/apache/parquet/internal/filter2/columnindex/TestRowRanges.java": [
                155,
                0
            ],
            "parquet-column/src/test/java/org/apache/parquet/io/ConverterConsumer.java": [
                125,
                0
            ],
            "parquet-column/src/test/java/org/apache/parquet/io/ExpectationValidatingConverter.java": [
                169,
                0
            ],
            "parquet-column/src/test/java/org/apache/parquet/io/ExpectationValidatingRecordConsumer.java": [
                112,
                0
            ],
            "parquet-column/src/test/java/org/apache/parquet/io/PerfTest.java": [
                128,
                0
            ],
            "parquet-column/src/test/java/org/apache/parquet/io/TestColumnIO.java": [
                709,
                0
            ],
            "parquet-column/src/test/java/org/apache/parquet/io/TestFiltered.java": [
                278,
                0
            ],
            "parquet-column/src/test/java/org/apache/parquet/io/api/TestBinary.java": [
                271,
                0
            ],
            "parquet-column/src/test/java/org/apache/parquet/parser/TestParquetParser.java": [
                374,
                0
            ],
            "parquet-column/src/test/java/org/apache/parquet/schema/TestMessageType.java": [
                247,
                0
            ],
            "parquet-column/src/test/java/org/apache/parquet/schema/TestPrimitiveComparator.java": [
                330,
                0
            ],
            "parquet-column/src/test/java/org/apache/parquet/schema/TestPrimitiveStringifier.java": [
                391,
                0
            ],
            "parquet-column/src/test/java/org/apache/parquet/schema/TestRepetitionType.java": [
                36,
                0
            ],
            "parquet-column/src/test/java/org/apache/parquet/schema/TestTypeBuilders.java": [
                1372,
                0
            ],
            "parquet-column/src/test/java/org/apache/parquet/schema/TestTypeBuildersWithLogicalTypes.java": [
                422,
                0
            ],
            "parquet-column/src/test/java/org/apache/parquet/schema/TestTypeUtil.java": [
                80,
                0
            ],
            "parquet-common/REVIEWERS.md": null,
            "parquet-common/pom.xml": null,
            "parquet-common/src/main/java/org/apache/parquet/Closeables.java": [
                60,
                0
            ],
            "parquet-common/src/main/java/org/apache/parquet/Exceptions.java": [
                39,
                0
            ],
            "parquet-common/src/main/java/org/apache/parquet/Files.java": [
                54,
                0
            ],
            "parquet-common/src/main/java/org/apache/parquet/IOExceptionUtils.java": [
                45,
                0
            ],
            "parquet-common/src/main/java/org/apache/parquet/Ints.java": [
                44,
                0
            ],
            "parquet-common/src/main/java/org/apache/parquet/Log.java": [
                146,
                0
            ],
            "parquet-common/src/main/java/org/apache/parquet/OutputStreamCloseException.java": [
                46,
                0
            ],
            "parquet-common/src/main/java/org/apache/parquet/ParquetRuntimeException.java": [
                42,
                0
            ],
            "parquet-common/src/main/java/org/apache/parquet/Preconditions.java": [
                251,
                0
            ],
            "parquet-common/src/main/java/org/apache/parquet/SemanticVersion.java": [
                293,
                0
            ],
            "parquet-common/src/main/java/org/apache/parquet/ShouldNeverHappenException.java": [
                40,
                0
            ],
            "parquet-common/src/main/java/org/apache/parquet/Strings.java": [
                132,
                0
            ],
            "parquet-common/src/main/java/org/apache/parquet/VersionParser.java": [
                129,
                0
            ],
            "parquet-common/src/main/java/org/apache/parquet/bytes/ByteBufferAllocator.java": [
                40,
                0
            ],
            "parquet-common/src/main/java/org/apache/parquet/bytes/ByteBufferInputStream.java": [
                160,
                0
            ],
            "parquet-common/src/main/java/org/apache/parquet/bytes/BytesInput.java": [
                545,
                0
            ],
            "parquet-common/src/main/java/org/apache/parquet/bytes/BytesUtils.java": [
                335,
                0
            ],
            "parquet-common/src/main/java/org/apache/parquet/bytes/CapacityByteArrayOutputStream.java": [
                352,
                0
            ],
            "parquet-common/src/main/java/org/apache/parquet/bytes/ConcatenatingByteArrayCollector.java": [
                63,
                0
            ],
            "parquet-common/src/main/java/org/apache/parquet/bytes/DirectByteBufferAllocator.java": [
                43,
                0
            ],
            "parquet-common/src/main/java/org/apache/parquet/bytes/HeapByteBufferAllocator.java": [
                44,
                0
            ],
            "parquet-common/src/main/java/org/apache/parquet/bytes/LittleEndianDataInputStream.java": [
                421,
                0
            ],
            "parquet-common/src/main/java/org/apache/parquet/bytes/LittleEndianDataOutputStream.java": [
                218,
                0
            ],
            "parquet-common/src/main/java/org/apache/parquet/bytes/MultiBufferInputStream.java": [
                382,
                0
            ],
            "parquet-common/src/main/java/org/apache/parquet/bytes/SingleBufferInputStream.java": [
                177,
                0
            ],
            "parquet-common/src/main/java/org/apache/parquet/compression/CompressionCodecFactory.java": [
                47,
                0
            ],
            "parquet-common/src/main/java/org/apache/parquet/glob/GlobExpander.java": [
                129,
                0
            ],
            "parquet-common/src/main/java/org/apache/parquet/glob/GlobNode.java": [
                157,
                0
            ],
            "parquet-common/src/main/java/org/apache/parquet/glob/GlobParser.java": [
                224,
                0
            ],
            "parquet-common/src/main/java/org/apache/parquet/glob/WildcardPath.java": [
                121,
                0
            ],
            "parquet-common/src/main/java/org/apache/parquet/hadoop/codec/CompressionCodecNotSupportedException.java": [
                38,
                0
            ],
            "parquet-common/src/main/java/org/apache/parquet/hadoop/metadata/Canonicalizer.java": [
                61,
                0
            ],
            "parquet-common/src/main/java/org/apache/parquet/hadoop/metadata/ColumnPath.java": [
                88,
                0
            ],
            "parquet-common/src/main/java/org/apache/parquet/hadoop/metadata/CompressionCodecName.java": [
                99,
                0
            ],
            "parquet-common/src/main/java/org/apache/parquet/io/DelegatingPositionOutputStream.java": [
                63,
                0
            ],
            "parquet-common/src/main/java/org/apache/parquet/io/DelegatingSeekableInputStream.java": [
                171,
                0
            ],
            "parquet-common/src/main/java/org/apache/parquet/io/InputFile.java": [
                44,
                0
            ],
            "parquet-common/src/main/java/org/apache/parquet/io/LocalInputFile.java": [
                102,
                0
            ],
            "parquet-common/src/main/java/org/apache/parquet/io/LocalOutputFile.java": [
                107,
                0
            ],
            "parquet-common/src/main/java/org/apache/parquet/io/OutputFile.java": [
                62,
                0
            ],
            "parquet-common/src/main/java/org/apache/parquet/io/PositionOutputStream.java": [
                39,
                0
            ],
            "parquet-common/src/main/java/org/apache/parquet/io/SeekableInputStream.java": [
                108,
                0
            ],
            "parquet-common/src/main/java/org/apache/parquet/util/DynConstructors.java": [
                263,
                0
            ],
            "parquet-common/src/main/java/org/apache/parquet/util/DynMethods.java": [
                506,
                0
            ],
            "parquet-common/src/test/java/org/apache/parquet/SemanticVersionTest.java": [
                114,
                0
            ],
            "parquet-common/src/test/java/org/apache/parquet/TestPreconditions.java": [
                246,
                0
            ],
            "parquet-common/src/test/java/org/apache/parquet/TestUtils.java": [
                70,
                0
            ],
            "parquet-common/src/test/java/org/apache/parquet/VersionTest.java": [
                100,
                0
            ],
            "parquet-common/src/test/java/org/apache/parquet/bytes/TestByteBufferInputStreams.java": [
                589,
                0
            ],
            "parquet-common/src/test/java/org/apache/parquet/bytes/TestBytesUtil.java": [
                49,
                0
            ],
            "parquet-common/src/test/java/org/apache/parquet/bytes/TestDeprecatedBufferInputStream.java": [
                152,
                0
            ],
            "parquet-common/src/test/java/org/apache/parquet/bytes/TestMultiBufferInputStream.java": [
                141,
                0
            ],
            "parquet-common/src/test/java/org/apache/parquet/bytes/TestSingleBufferInputStream.java": [
                130,
                0
            ],
            "parquet-common/src/test/java/org/apache/parquet/glob/TestGlob.java": [
                144,
                0
            ],
            "parquet-common/src/test/java/org/apache/parquet/glob/TestWildcardPath.java": [
                125,
                0
            ],
            "parquet-common/src/test/java/org/apache/parquet/io/MockInputStream.java": [
                56,
                0
            ],
            "parquet-common/src/test/java/org/apache/parquet/io/TestDelegatingSeekableInputStream.java": [
                844,
                0
            ],
            "parquet-common/src/test/java/org/apache/parquet/io/TestLocalInputOutput.java": [
                92,
                0
            ],
            "parquet-common/src/test/java/org/apache/parquet/util/Concatenator.java": [
                82,
                0
            ],
            "parquet-common/src/test/java/org/apache/parquet/util/TestDynConstructors.java": [
                165,
                0
            ],
            "parquet-common/src/test/java/org/apache/parquet/util/TestDynMethods.java": [
                315,
                0
            ],
            "parquet-encoding/REVIEWERS.md": null,
            "parquet-encoding/pom.xml": null,
            "parquet-encoding/src/main/java/org/apache/parquet/column/values/bitpacking/BitPacking.java": [
                717,
                0
            ],
            "parquet-encoding/src/main/java/org/apache/parquet/column/values/bitpacking/ByteBasedBitPackingEncoder.java": [
                142,
                0
            ],
            "parquet-encoding/src/main/java/org/apache/parquet/column/values/bitpacking/BytePacker.java": [
                141,
                0
            ],
            "parquet-encoding/src/main/java/org/apache/parquet/column/values/bitpacking/BytePackerFactory.java": [
                25,
                0
            ],
            "parquet-encoding/src/main/java/org/apache/parquet/column/values/bitpacking/BytePackerForLong.java": [
                109,
                0
            ],
            "parquet-encoding/src/main/java/org/apache/parquet/column/values/bitpacking/BytePackerForLongFactory.java": [
                25,
                0
            ],
            "parquet-encoding/src/main/java/org/apache/parquet/column/values/bitpacking/IntPacker.java": [
                63,
                0
            ],
            "parquet-encoding/src/main/java/org/apache/parquet/column/values/bitpacking/IntPackerFactory.java": [
                25,
                0
            ],
            "parquet-encoding/src/main/java/org/apache/parquet/column/values/bitpacking/Packer.java": [
                137,
                0
            ],
            "parquet-encoding/src/main/resources/META-INF/LICENSE": null,
            "parquet-encoding/src/test/java/org/apache/parquet/bytes/TestBytesInput.java": [
                42,
                0
            ],
            "parquet-encoding/src/test/java/org/apache/parquet/bytes/TestCapacityByteArrayOutputStream.java": [
                242,
                0
            ],
            "parquet-encoding/src/test/java/org/apache/parquet/column/values/bitpacking/TestBitPacking.java": [
                233,
                0
            ],
            "parquet-encoding/src/test/java/org/apache/parquet/column/values/bitpacking/TestByteBasedBitPackingEncoder.java": [
                46,
                0
            ],
            "parquet-encoding/src/test/java/org/apache/parquet/column/values/bitpacking/TestByteBitPacking.java": [
                198,
                0
            ],
            "parquet-encoding/src/test/java/org/apache/parquet/column/values/bitpacking/TestLemireBitPacking.java": [
                125,
                0
            ],
            "parquet-format-structures/pom.xml": null,
            "parquet-format-structures/src/main/java/org/apache/parquet/format/BlockCipher.java": [
                76,
                0
            ],
            "parquet-format-structures/src/main/java/org/apache/parquet/format/CliUtils.java": [
                55,
                0
            ],
            "parquet-format-structures/src/main/java/org/apache/parquet/format/InterningProtocol.java": [
                236,
                0
            ],
            "parquet-format-structures/src/main/java/org/apache/parquet/format/InvalidParquetMetadataException.java": [
                30,
                0
            ],
            "parquet-format-structures/src/main/java/org/apache/parquet/format/LogicalTypes.java": [
                55,
                0
            ],
            "parquet-format-structures/src/main/java/org/apache/parquet/format/MetadataValidator.java": [
                44,
                0
            ],
            "parquet-format-structures/src/main/java/org/apache/parquet/format/Util.java": [
                389,
                0
            ],
            "parquet-format-structures/src/main/java/org/apache/parquet/format/event/Consumers.java": [
                191,
                0
            ],
            "parquet-format-structures/src/main/java/org/apache/parquet/format/event/EventBasedThriftReader.java": [
                126,
                0
            ],
            "parquet-format-structures/src/main/java/org/apache/parquet/format/event/FieldConsumer.java": [
                39,
                0
            ],
            "parquet-format-structures/src/main/java/org/apache/parquet/format/event/TypedConsumer.java": [
                205,
                0
            ],
            "parquet-format-structures/src/test/java/org/apache/parquet/format/TestUtil.java": [
                101,
                0
            ],
            "parquet-generator/REVIEWERS.md": null,
            "parquet-generator/pom.xml": null,
            "parquet-generator/src/main/java/org/apache/parquet/encoding/Generator.java": [
                34,
                0
            ],
            "parquet-generator/src/main/java/org/apache/parquet/encoding/bitpacking/ByteBasedBitPackingGenerator.java": [
                319,
                0
            ],
            "parquet-generator/src/main/java/org/apache/parquet/encoding/bitpacking/IntBasedBitPackingGenerator.java": [
                208,
                0
            ],
            "parquet-generator/src/main/java/org/apache/parquet/filter2/Generator.java": [
                28,
                0
            ],
            "parquet-generator/src/main/java/org/apache/parquet/filter2/IncrementallyUpdatedFilterPredicateGenerator.java": [
                335,
                0
            ],
            "parquet-generator/src/main/java/org/apache/parquet/version/Generator.java": [
                28,
                0
            ],
            "parquet-generator/src/main/java/org/apache/parquet/version/VersionGenerator.java": [
                87,
                0
            ],
            "parquet-generator/src/main/resources/META-INF/LICENSE": null,
            "parquet-generator/src/main/resources/parquet-version.properties": null,
            "parquet-hadoop-bundle/README": null,
            "parquet-hadoop-bundle/pom.xml": null,
            "parquet-hadoop-bundle/src/main/resources/META-INF/LICENSE": null,
            "parquet-hadoop-bundle/src/main/resources/org/apache/parquet/bundle": null,
            "parquet-hadoop/README.md": null,
            "parquet-hadoop/REVIEWERS.md": null,
            "parquet-hadoop/pom.xml": null,
            "parquet-hadoop/src/main/java/org/apache/parquet/HadoopReadOptions.java": [
                143,
                0
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/ParquetReadOptions.java": [
                345,
                0
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/crypto/AADPrefixVerifier.java": [
                32,
                0
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/crypto/AesCipher.java": [
                164,
                0
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/crypto/AesCtrDecryptor.java": [
                170,
                0
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/crypto/AesCtrEncryptor.java": [
                104,
                0
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/crypto/AesGcmDecryptor.java": [
                151,
                0
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/crypto/AesGcmEncryptor.java": [
                91,
                0
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/crypto/AesMode.java": [
                35,
                0
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/crypto/ColumnDecryptionProperties.java": [
                104,
                0
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/crypto/ColumnEncryptionProperties.java": [
                195,
                0
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/crypto/DecryptionKeyRetriever.java": [
                39,
                0
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/crypto/DecryptionPropertiesFactory.java": [
                88,
                0
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/crypto/EncryptionPropertiesFactory.java": [
                93,
                0
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/crypto/FileDecryptionProperties.java": [
                254,
                0
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/crypto/FileEncryptionProperties.java": [
                278,
                0
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/crypto/InternalColumnDecryptionSetup.java": [
                74,
                0
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/crypto/InternalColumnEncryptionSetup.java": [
                82,
                0
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/crypto/InternalFileDecryptor.java": [
                312,
                0
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/crypto/InternalFileEncryptor.java": [
                200,
                0
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/crypto/KeyAccessDeniedException.java": [
                39,
                0
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/crypto/ModuleCipherFactory.java": [
                73,
                0
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/crypto/ParquetCipher.java": [
                42,
                0
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/crypto/ParquetCryptoRuntimeException.java": [
                42,
                0
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/crypto/TagVerificationException.java": [
                39,
                0
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/crypto/keytools/FileKeyMaterialStore.java": [
                72,
                0
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/crypto/keytools/FileKeyUnwrapper.java": [
                178,
                0
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/crypto/keytools/FileKeyWrapper.java": [
                177,
                0
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/crypto/keytools/HadoopFSKeyMaterialStore.java": [
                136,
                0
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/crypto/keytools/KeyMaterial.java": [
                210,
                0
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/crypto/keytools/KeyMetadata.java": [
                130,
                0
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/crypto/keytools/KeyToolkit.java": [
                394,
                0
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/crypto/keytools/KmsClient.java": [
                72,
                0
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/crypto/keytools/LocalWrapKmsClient.java": [
                181,
                0
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/crypto/keytools/PropertiesDrivenCryptoFactory.java": [
                258,
                0
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/crypto/keytools/TwoLevelCacheWithExpiration.java": [
                105,
                0
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/filter2/bloomfilterlevel/BloomFilterImpl.java": [
                187,
                0
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/filter2/compat/RowGroupFilter.java": [
                131,
                0
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/filter2/dictionarylevel/DictionaryFilter.java": [
                570,
                0
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/filter2/statisticslevel/StatisticsFilter.java": [
                485,
                0
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/format/converter/ParquetMetadataConverter.java": [
                2080,
                0
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/BadConfigurationException.java": [
                44,
                0
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/BloomFilterReader.java": [
                70,
                0
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/CodecFactory.java": [
                289,
                0
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ColumnChunkPageReadStore.java": [
                364,
                0
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ColumnChunkPageWriteStore.java": [
                462,
                0
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ColumnConfigParser.java": [
                72,
                0
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ColumnIndexFilterUtils.java": [
                162,
                0
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ColumnIndexStoreImpl.java": [
                155,
                0
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ColumnIndexValidator.java": [
                613,
                0
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/DictionaryPageReader.java": [
                115,
                0
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/DirectCodecFactory.java": [
                528,
                0
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/DirectZstd.java": [
                144,
                0
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/Footer.java": [
                53,
                0
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/InternalParquetRecordReader.java": [
                321,
                0
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/InternalParquetRecordWriter.java": [
                209,
                0
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/LruCache.java": [
                195,
                0
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/MemoryManager.java": [
                199,
                0
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/Offsets.java": [
                94,
                0
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ParquetEmptyBlockException.java": [
                41,
                0
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ParquetFileReader.java": [
                1869,
                0
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ParquetFileWriter.java": [
                1731,
                0
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ParquetInputFormat.java": [
                837,
                0
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ParquetInputSplit.java": [
                295,
                0
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ParquetMemoryManagerRuntimeException.java": [
                38,
                0
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ParquetOutputCommitter.java": [
                112,
                0
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ParquetOutputFormat.java": [
                570,
                0
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ParquetReader.java": [
                379,
                0
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ParquetRecordReader.java": [
                233,
                0
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ParquetRecordWriter.java": [
                184,
                0
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ParquetWriter.java": [
                744,
                0
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/PrintFooter.java": [
                265,
                0
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/UnmaterializableRecordCounter.java": [
                103,
                0
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/api/DelegatingReadSupport.java": [
                60,
                0
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/api/DelegatingWriteSupport.java": [
                69,
                0
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/api/InitContext.java": [
                99,
                0
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/api/ReadSupport.java": [
                145,
                0
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/api/WriteSupport.java": [
                140,
                0
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/api/package-info.java": [
                27,
                0
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/codec/CleanUtil.java": [
                111,
                0
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/codec/CodecConfig.java": [
                167,
                0
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/codec/Lz4RawCodec.java": [
                112,
                0
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/codec/Lz4RawCompressor.java": [
                44,
                0
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/codec/Lz4RawDecompressor.java": [
                46,
                0
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/codec/NonBlockedCompressor.java": [
                192,
                0
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/codec/NonBlockedCompressorStream.java": [
                50,
                0
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/codec/NonBlockedDecompressor.java": [
                180,
                0
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/codec/NonBlockedDecompressorStream.java": [
                57,
                0
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/codec/SnappyCodec.java": [
                105,
                0
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/codec/SnappyCompressor.java": [
                38,
                0
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/codec/SnappyDecompressor.java": [
                38,
                0
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/codec/SnappyUtil.java": [
                33,
                0
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/codec/ZstandardCodec.java": [
                130,
                0
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/codec/ZstdCompressorStream.java": [
                70,
                0
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/codec/ZstdDecompressorStream.java": [
                62,
                0
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/example/ExampleInputFormat.java": [
                35,
                0
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/example/ExampleOutputFormat.java": [
                58,
                0
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/example/ExampleParquetWriter.java": [
                118,
                0
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/example/GroupReadSupport.java": [
                49,
                0
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/example/GroupWriteSupport.java": [
                88,
                0
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/mapred/Container.java": [
                37,
                0
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/mapred/DeprecatedParquetInputFormat.java": [
                209,
                0
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/mapred/DeprecatedParquetOutputFormat.java": [
                119,
                0
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/mapred/MapredParquetOutputCommitter.java": [
                42,
                0
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/metadata/BlockMetaData.java": [
                153,
                0
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/metadata/ColumnChunkMetaData.java": [
                683,
                0
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/metadata/ColumnChunkProperties.java": [
                118,
                0
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/metadata/ConcatenatingKeyValueMetadataMergeStrategy.java": [
                61,
                0
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/metadata/EncodingList.java": [
                81,
                0
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/metadata/FileMetaData.java": [
                108,
                0
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/metadata/GlobalMetaData.java": [
                110,
                0
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/metadata/KeyValueMetadataMergeStrategy.java": [
                42,
                0
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/metadata/ParquetMetadata.java": [
                134,
                0
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/metadata/StrictKeyValueMetadataMergeStrategy.java": [
                42,
                0
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/package-info.java": [
                33,
                0
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/rewrite/MaskMode.java": [
                38,
                0
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/rewrite/ParquetRewriter.java": [
                819,
                0
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/rewrite/RewriteOptions.java": [
                262,
                0
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/util/ColumnEncryptor.java": [
                90,
                0
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/util/ColumnMasker.java": [
                98,
                0
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/util/ColumnPruner.java": [
                42,
                0
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/util/CompressionConverter.java": [
                81,
                0
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/util/ConfigurationUtil.java": [
                44,
                0
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/util/ContextUtil.java": [
                315,
                0
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/util/H1SeekableInputStream.java": [
                59,
                0
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/util/H2SeekableInputStream.java": [
                99,
                0
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/util/HadoopCodecs.java": [
                39,
                0
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/util/HadoopInputFile.java": [
                76,
                0
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/util/HadoopOutputFile.java": [
                105,
                0
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/util/HadoopPositionOutputStream.java": [
                66,
                0
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/util/HadoopStreams.java": [
                148,
                0
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/util/HiddenFileFilter.java": [
                39,
                0
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/util/SerializationUtil.java": [
                93,
                0
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/util/counters/BenchmarkCounter.java": [
                112,
                0
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/util/counters/CounterLoader.java": [
                27,
                0
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/util/counters/ICounter.java": [
                28,
                0
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/util/counters/mapred/MapRedCounterAdapter.java": [
                43,
                0
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/util/counters/mapred/MapRedCounterLoader.java": [
                51,
                0
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/util/counters/mapreduce/MapReduceCounterAdapter.java": [
                44,
                0
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/util/counters/mapreduce/MapReduceCounterLoader.java": [
                47,
                0
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/internal/hadoop/metadata/IndexReference.java": [
                41,
                0
            ],
            "parquet-hadoop/src/main/resources/META-INF/LICENSE": null,
            "parquet-hadoop/src/test/java/org/apache/parquet/DirectWriterTest.java": [
                102,
                0
            ],
            "parquet-hadoop/src/test/java/org/apache/parquet/crypto/DecryptionKeyRetrieverMock.java": [
                41,
                0
            ],
            "parquet-hadoop/src/test/java/org/apache/parquet/crypto/DecryptionPropertiesFactoryTest.java": [
                43,
                0
            ],
            "parquet-hadoop/src/test/java/org/apache/parquet/crypto/EncryptionPropertiesFactoryTest.java": [
                45,
                0
            ],
            "parquet-hadoop/src/test/java/org/apache/parquet/crypto/SampleDecryptionPropertiesFactory.java": [
                57,
                0
            ],
            "parquet-hadoop/src/test/java/org/apache/parquet/crypto/SampleEncryptionPropertiesFactory.java": [
                58,
                0
            ],
            "parquet-hadoop/src/test/java/org/apache/parquet/crypto/SingleRow.java": [
                139,
                0
            ],
            "parquet-hadoop/src/test/java/org/apache/parquet/crypto/TestPropertiesDrivenEncryption.java": [
                705,
                0
            ],
            "parquet-hadoop/src/test/java/org/apache/parquet/crypto/keytools/mocks/InMemoryKMS.java": [
                116,
                0
            ],
            "parquet-hadoop/src/test/java/org/apache/parquet/crypto/keytools/mocks/LocalWrapInMemoryKMS.java": [
                79,
                0
            ],
            "parquet-hadoop/src/test/java/org/apache/parquet/crypto/keytools/samples/VaultClient.java": [
                184,
                0
            ],
            "parquet-hadoop/src/test/java/org/apache/parquet/crypto/propertiesfactory/SchemaControlEncryptionTest.java": [
                250,
                0
            ],
            "parquet-hadoop/src/test/java/org/apache/parquet/crypto/propertiesfactory/SchemaCryptoPropertiesFactory.java": [
                137,
                0
            ],
            "parquet-hadoop/src/test/java/org/apache/parquet/encodings/FileEncodingsIT.java": [
                564,
                0
            ],
            "parquet-hadoop/src/test/java/org/apache/parquet/filter2/TestFiltersWithMissingColumns.java": [
                275,
                0
            ],
            "parquet-hadoop/src/test/java/org/apache/parquet/filter2/compat/TestRowGroupFilter.java": [
                128,
                0
            ],
            "parquet-hadoop/src/test/java/org/apache/parquet/filter2/dictionarylevel/DictionaryFilterTest.java": [
                839,
                0
            ],
            "parquet-hadoop/src/test/java/org/apache/parquet/filter2/recordlevel/PhoneBookWriter.java": [
                373,
                0
            ],
            "parquet-hadoop/src/test/java/org/apache/parquet/filter2/recordlevel/TestRecordLevelFilters.java": [
                310,
                0
            ],
            "parquet-hadoop/src/test/java/org/apache/parquet/filter2/statisticslevel/TestStatisticsFilter.java": [
                561,
                0
            ],
            "parquet-hadoop/src/test/java/org/apache/parquet/format/converter/TestParquetMetadataConverter.java": [
                1389,
                0
            ],
            "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/DeprecatedInputFormatTest.java": [
                346,
                0
            ],
            "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/DeprecatedOutputFormatTest.java": [
                108,
                0
            ],
            "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/ITTestEncryptionOptions.java": [
                50,
                0
            ],
            "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/TestAdaptiveBlockSplitBloomFiltering.java": [
                78,
                0
            ],
            "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/TestBloomFiltering.java": [
                421,
                0
            ],
            "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/TestColumnChunkPageWriteStore.java": [
                288,
                0
            ],
            "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/TestColumnIndexFiltering.java": [
                617,
                0
            ],
            "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/TestDataPageV1Checksums.java": [
                563,
                0
            ],
            "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/TestDirectCodecFactory.java": [
                178,
                0
            ],
            "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/TestEncryptionOptions.java": [
                752,
                0
            ],
            "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/TestInputFormat.java": [
                555,
                0
            ],
            "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/TestInputFormatColumnProjection.java": [
                180,
                0
            ],
            "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/TestInputOutputFormatWithPadding.java": [
                214,
                0
            ],
            "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/TestLargeColumnChunk.java": [
                145,
                0
            ],
            "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/TestLruCache.java": [
                162,
                0
            ],
            "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/TestMemoryManager.java": [
                189,
                0
            ],
            "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/TestMergeMetadataFiles.java": [
                221,
                0
            ],
            "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/TestMultipleWriteRead.java": [
                250,
                0
            ],
            "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/TestParquetFileWriter.java": [
                1218,
                0
            ],
            "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/TestParquetOutputFormatJobSummaryLevel.java": [
                69,
                0
            ],
            "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/TestParquetReader.java": [
                198,
                0
            ],
            "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/TestParquetReaderEmptyBlock.java": [
                170,
                0
            ],
            "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/TestParquetReaderRandomAccess.java": [
                387,
                0
            ],
            "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/TestParquetWriter.java": [
                431,
                0
            ],
            "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/TestParquetWriterAppendBlocks.java": [
                361,
                0
            ],
            "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/TestParquetWriterNewPage.java": [
                136,
                0
            ],
            "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/TestParquetWriterTruncation.java": [
                125,
                0
            ],
            "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/TestReadWriteEncodingStats.java": [
                122,
                0
            ],
            "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/TestSnappyCodec.java": [
                140,
                0
            ],
            "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/TestStoreBloomFilter.java": [
                132,
                0
            ],
            "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/TestUtils.java": [
                85,
                0
            ],
            "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/TestZstandardCodec.java": [
                173,
                0
            ],
            "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/codec/CodecConfigTest.java": [
                77,
                0
            ],
            "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/codec/TestCompressionCodec.java": [
                177,
                0
            ],
            "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/codec/TestInteropReadLz4RawCodec.java": [
                129,
                0
            ],
            "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/example/GroupReadSupportTest.java": [
                65,
                0
            ],
            "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/example/TestInputOutputFormat.java": [
                364,
                0
            ],
            "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/metadata/TestColumnChunkMetaData.java": [
                83,
                0
            ],
            "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/rewrite/ParquetRewriterTest.java": [
                772,
                0
            ],
            "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/util/ColumnEncryptorTest.java": [
                315,
                0
            ],
            "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/util/ColumnMaskerTest.java": [
                223,
                0
            ],
            "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/util/ColumnPrunerTest.java": [
                246,
                0
            ],
            "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/util/CompressionConverterTest.java": [
                312,
                0
            ],
            "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/util/EncDecProperties.java": [
                94,
                0
            ],
            "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/util/EncryptionTestFile.java": [
                38,
                0
            ],
            "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/util/MockHadoopInputStream.java": [
                87,
                0
            ],
            "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/util/TestFileBuilder.java": [
                198,
                0
            ],
            "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/util/TestHadoop2ByteBufferReads.java": [
                446,
                0
            ],
            "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/util/TestSerializationUtil.java": [
                71,
                0
            ],
            "parquet-hadoop/src/test/java/org/apache/parquet/statistics/DataGenerationContext.java": [
                85,
                0
            ],
            "parquet-hadoop/src/test/java/org/apache/parquet/statistics/RandomValues.java": [
                383,
                0
            ],
            "parquet-hadoop/src/test/java/org/apache/parquet/statistics/TestColumnIndexes.java": [
                304,
                0
            ],
            "parquet-hadoop/src/test/java/org/apache/parquet/statistics/TestStatistics.java": [
                459,
                0
            ],
            "parquet-hadoop/src/test/resources/log4j.properties": null,
            "parquet-hadoop/src/test/resources/test-append_1.parquet": null,
            "parquet-hadoop/src/test/resources/test-append_2.parquet": null,
            "parquet-hadoop/src/test/resources/test-empty-row-group_1.parquet": null,
            "parquet-hadoop/src/test/resources/test-empty-row-group_2.parquet": null,
            "parquet-hadoop/src/test/resources/test-empty-row-group_3.parquet": null,
            "parquet-hadoop/src/test/resources/test-file-with-no-column-indexes-1.parquet": null,
            "parquet-jackson/README.md": null,
            "parquet-jackson/pom.xml": null,
            "parquet-jackson/src/main/resources/META-INF/LICENSE": null,
            "parquet-pig-bundle/pom.xml": null,
            "parquet-pig-bundle/src/main/resources/META-INF/LICENSE": null,
            "parquet-pig-bundle/src/main/resources/org/apache/parquet/bundle": null,
            "parquet-pig/REVIEWERS.md": null,
            "parquet-pig/pom.xml": null,
            "parquet-pig/src/main/java/org/apache/parquet/pig/ParquetLoader.java": [
                575,
                0
            ],
            "parquet-pig/src/main/java/org/apache/parquet/pig/ParquetStorer.java": [
                152,
                0
            ],
            "parquet-pig/src/main/java/org/apache/parquet/pig/PigMetaData.java": [
                91,
                0
            ],
            "parquet-pig/src/main/java/org/apache/parquet/pig/PigSchemaConverter.java": [
                551,
                0
            ],
            "parquet-pig/src/main/java/org/apache/parquet/pig/SchemaConversionException.java": [
                44,
                0
            ],
            "parquet-pig/src/main/java/org/apache/parquet/pig/TupleConversionException.java": [
                42,
                0
            ],
            "parquet-pig/src/main/java/org/apache/parquet/pig/TupleReadSupport.java": [
                191,
                0
            ],
            "parquet-pig/src/main/java/org/apache/parquet/pig/TupleWriteSupport.java": [
                209,
                0
            ],
            "parquet-pig/src/main/java/org/apache/parquet/pig/convert/DecimalUtils.java": [
                65,
                0
            ],
            "parquet-pig/src/main/java/org/apache/parquet/pig/convert/MapConverter.java": [
                190,
                0
            ],
            "parquet-pig/src/main/java/org/apache/parquet/pig/convert/ParentValueContainer.java": [
                32,
                0
            ],
            "parquet-pig/src/main/java/org/apache/parquet/pig/convert/TupleConverter.java": [
                592,
                0
            ],
            "parquet-pig/src/main/java/org/apache/parquet/pig/convert/TupleRecordMaterializer.java": [
                50,
                0
            ],
            "parquet-pig/src/main/java/org/apache/parquet/pig/summary/BagSummaryData.java": [
                72,
                0
            ],
            "parquet-pig/src/main/java/org/apache/parquet/pig/summary/EnumStat.java": [
                115,
                0
            ],
            "parquet-pig/src/main/java/org/apache/parquet/pig/summary/FieldSummaryData.java": [
                178,
                0
            ],
            "parquet-pig/src/main/java/org/apache/parquet/pig/summary/MapSummaryData.java": [
                85,
                0
            ],
            "parquet-pig/src/main/java/org/apache/parquet/pig/summary/NumberSummaryData.java": [
                47,
                0
            ],
            "parquet-pig/src/main/java/org/apache/parquet/pig/summary/StringSummaryData.java": [
                82,
                0
            ],
            "parquet-pig/src/main/java/org/apache/parquet/pig/summary/Summary.java": [
                224,
                0
            ],
            "parquet-pig/src/main/java/org/apache/parquet/pig/summary/SummaryData.java": [
                135,
                0
            ],
            "parquet-pig/src/main/java/org/apache/parquet/pig/summary/TupleSummaryData.java": [
                98,
                0
            ],
            "parquet-pig/src/main/java/org/apache/parquet/pig/summary/ValueStat.java": [
                64,
                0
            ],
            "parquet-pig/src/test/java/org/apache/parquet/pig/PerfTest.java": [
                104,
                0
            ],
            "parquet-pig/src/test/java/org/apache/parquet/pig/PerfTest2.java": [
                185,
                0
            ],
            "parquet-pig/src/test/java/org/apache/parquet/pig/PerfTestReadAllCols.java": [
                47,
                0
            ],
            "parquet-pig/src/test/java/org/apache/parquet/pig/TestDecimalUtils.java": [
                79,
                0
            ],
            "parquet-pig/src/test/java/org/apache/parquet/pig/TestParquetLoader.java": [
                367,
                0
            ],
            "parquet-pig/src/test/java/org/apache/parquet/pig/TestParquetStorer.java": [
                264,
                0
            ],
            "parquet-pig/src/test/java/org/apache/parquet/pig/TestPigSchemaConverter.java": [
                291,
                0
            ],
            "parquet-pig/src/test/java/org/apache/parquet/pig/TestTupleRecordConsumer.java": [
                210,
                0
            ],
            "parquet-pig/src/test/java/org/apache/parquet/pig/TupleConsumerPerfTest.java": [
                206,
                0
            ],
            "parquet-pig/src/test/java/org/apache/parquet/pig/summary/TestSummary.java": [
                158,
                0
            ],
            "parquet-pig/src/test/resources/log4j.properties": null,
            "parquet-plugins/parquet-encoding-vector/pom.xml": null,
            "parquet-plugins/parquet-encoding-vector/src/main/java/org/apache/parquet/column/values/bitpacking/ByteBitPacking512VectorLE.java": [
                3010,
                0
            ],
            "parquet-plugins/parquet-encoding-vector/src/main/java/org/apache/parquet/column/values/bitpacking/ParquetReadRouter.java": [
                133,
                0
            ],
            "parquet-plugins/parquet-encoding-vector/src/main/java/org/apache/parquet/column/values/bitpacking/VectorSupport.java": [
                27,
                0
            ],
            "parquet-plugins/parquet-encoding-vector/src/test/java/org/apache/parquet/column/values/bitpacking/TestByteBitPacking512VectorLE.java": [
                169,
                0
            ],
            "parquet-plugins/parquet-encoding-vector/src/test/java/org/apache/parquet/column/values/bitpacking/TestParquetReadRouter.java": [
                59,
                0
            ],
            "parquet-plugins/parquet-plugins-benchmarks/pom.xml": null,
            "parquet-plugins/parquet-plugins-benchmarks/src/main/java/org/apache/parquet/plugins/benchmarks/ByteBitPackingVectorBenchmarks.java": [
                92,
                0
            ],
            "parquet-plugins/parquet-plugins-benchmarks/src/main/resources/log4j.properties": null,
            "parquet-protobuf/README.md": null,
            "parquet-protobuf/REVIEWERS.md": null,
            "parquet-protobuf/pom.xml": null,
            "parquet-protobuf/src/main/java/org/apache/parquet/proto/ProtoConstants.java": [
                46,
                0
            ],
            "parquet-protobuf/src/main/java/org/apache/parquet/proto/ProtoMessageConverter.java": [
                599,
                0
            ],
            "parquet-protobuf/src/main/java/org/apache/parquet/proto/ProtoParquetInputFormat.java": [
                38,
                0
            ],
            "parquet-protobuf/src/main/java/org/apache/parquet/proto/ProtoParquetOutputFormat.java": [
                52,
                0
            ],
            "parquet-protobuf/src/main/java/org/apache/parquet/proto/ProtoParquetReader.java": [
                101,
                0
            ],
            "parquet-protobuf/src/main/java/org/apache/parquet/proto/ProtoParquetWriter.java": [
                127,
                0
            ],
            "parquet-protobuf/src/main/java/org/apache/parquet/proto/ProtoReadSupport.java": [
                97,
                0
            ],
            "parquet-protobuf/src/main/java/org/apache/parquet/proto/ProtoRecordConverter.java": [
                100,
                0
            ],
            "parquet-protobuf/src/main/java/org/apache/parquet/proto/ProtoRecordMaterializer.java": [
                47,
                0
            ],
            "parquet-protobuf/src/main/java/org/apache/parquet/proto/ProtoSchemaConverter.java": [
                297,
                0
            ],
            "parquet-protobuf/src/main/java/org/apache/parquet/proto/ProtoWriteSupport.java": [
                586,
                0
            ],
            "parquet-protobuf/src/main/resources/META-INF/NOTICE": null,
            "parquet-protobuf/src/test/java/org/apache/parquet/proto/ProtoInputOutputFormatTest.java": [
                618,
                0
            ],
            "parquet-protobuf/src/test/java/org/apache/parquet/proto/ProtoRecordConverterTest.java": [
                363,
                0
            ],
            "parquet-protobuf/src/test/java/org/apache/parquet/proto/ProtoSchemaConverterTest.java": [
                539,
                0
            ],
            "parquet-protobuf/src/test/java/org/apache/parquet/proto/ProtoSchemaEvolutionTest.java": [
                133,
                0
            ],
            "parquet-protobuf/src/test/java/org/apache/parquet/proto/ProtoWriteSupportTest.java": [
                1204,
                0
            ],
            "parquet-protobuf/src/test/java/org/apache/parquet/proto/TestUtils.java": [
                232,
                0
            ],
            "parquet-protobuf/src/test/java/org/apache/parquet/proto/utils/ReadUsingMR.java": [
                94,
                0
            ],
            "parquet-protobuf/src/test/java/org/apache/parquet/proto/utils/WriteUsingMR.java": [
                121,
                0
            ],
            "parquet-protobuf/src/test/resources/BinaryTree.par": null,
            "parquet-protobuf/src/test/resources/Struct.par": null,
            "parquet-protobuf/src/test/resources/TestProto3.proto": null,
            "parquet-protobuf/src/test/resources/TestProto3SchemaV1.proto": null,
            "parquet-protobuf/src/test/resources/TestProto3SchemaV2.proto": null,
            "parquet-protobuf/src/test/resources/TestProto3SchemaV3.proto": null,
            "parquet-protobuf/src/test/resources/TestProtobuf.proto": null,
            "parquet-protobuf/src/test/resources/Trees.proto": null,
            "parquet-protobuf/src/test/resources/Value.par": null,
            "parquet-protobuf/src/test/resources/WideTree.par": null,
            "parquet-protobuf/src/test/resources/log4j.properties": null,
            "parquet-scala/pom.xml": null,
            "parquet-scala/src/main/scala/org/apache/parquet/filter2/dsl/Dsl.scala": null,
            "parquet-scala/src/test/scala/org/apache/parquet/filter2/dsl/DslTest.scala": null,
            "parquet-thrift/README.md": null,
            "parquet-thrift/REVIEWERS.md": null,
            "parquet-thrift/pom.xml": null,
            "parquet-thrift/src/main/java/org/apache/parquet/hadoop/thrift/AbstractThriftWriteSupport.java": [
                129,
                0
            ],
            "parquet-thrift/src/main/java/org/apache/parquet/hadoop/thrift/ParquetThriftBytesOutputFormat.java": [
                96,
                0
            ],
            "parquet-thrift/src/main/java/org/apache/parquet/hadoop/thrift/ParquetThriftInputFormat.java": [
                66,
                0
            ],
            "parquet-thrift/src/main/java/org/apache/parquet/hadoop/thrift/ParquetThriftOutputFormat.java": [
                43,
                0
            ],
            "parquet-thrift/src/main/java/org/apache/parquet/hadoop/thrift/TBaseWriteSupport.java": [
                70,
                0
            ],
            "parquet-thrift/src/main/java/org/apache/parquet/hadoop/thrift/ThriftBytesWriteSupport.java": [
                196,
                0
            ],
            "parquet-thrift/src/main/java/org/apache/parquet/hadoop/thrift/ThriftReadSupport.java": [
                289,
                0
            ],
            "parquet-thrift/src/main/java/org/apache/parquet/hadoop/thrift/ThriftToParquetFileWriter.java": [
                125,
                0
            ],
            "parquet-thrift/src/main/java/org/apache/parquet/hadoop/thrift/ThriftWriteSupport.java": [
                80,
                0
            ],
            "parquet-thrift/src/main/java/org/apache/parquet/thrift/BufferedProtocolReadToWrite.java": [
                738,
                0
            ],
            "parquet-thrift/src/main/java/org/apache/parquet/thrift/ConvertedField.java": [
                169,
                0
            ],
            "parquet-thrift/src/main/java/org/apache/parquet/thrift/DecodingSchemaMismatchException.java": [
                30,
                0
            ],
            "parquet-thrift/src/main/java/org/apache/parquet/thrift/FieldIgnoredHandler.java": [
                45,
                0
            ],
            "parquet-thrift/src/main/java/org/apache/parquet/thrift/KeepOnlyFirstPrimitiveFilter.java": [
                44,
                0
            ],
            "parquet-thrift/src/main/java/org/apache/parquet/thrift/ParquetProtocol.java": [
                282,
                0
            ],
            "parquet-thrift/src/main/java/org/apache/parquet/thrift/ParquetReadProtocol.java": [
                164,
                0
            ],
            "parquet-thrift/src/main/java/org/apache/parquet/thrift/ParquetWriteProtocol.java": [
                778,
                0
            ],
            "parquet-thrift/src/main/java/org/apache/parquet/thrift/ProtocolPipe.java": [
                29,
                0
            ],
            "parquet-thrift/src/main/java/org/apache/parquet/thrift/ProtocolReadToWrite.java": [
                142,
                0
            ],
            "parquet-thrift/src/main/java/org/apache/parquet/thrift/SkippableException.java": [
                47,
                0
            ],
            "parquet-thrift/src/main/java/org/apache/parquet/thrift/TBaseRecordConverter.java": [
                61,
                0
            ],
            "parquet-thrift/src/main/java/org/apache/parquet/thrift/ThriftMetaData.java": [
                147,
                0
            ],
            "parquet-thrift/src/main/java/org/apache/parquet/thrift/ThriftParquetReader.java": [
                139,
                0
            ],
            "parquet-thrift/src/main/java/org/apache/parquet/thrift/ThriftParquetWriter.java": [
                52,
                0
            ],
            "parquet-thrift/src/main/java/org/apache/parquet/thrift/ThriftReader.java": [
                28,
                0
            ],
            "parquet-thrift/src/main/java/org/apache/parquet/thrift/ThriftRecordConverter.java": [
                954,
                0
            ],
            "parquet-thrift/src/main/java/org/apache/parquet/thrift/ThriftSchemaConvertVisitor.java": [
                409,
                0
            ],
            "parquet-thrift/src/main/java/org/apache/parquet/thrift/ThriftSchemaConverter.java": [
                226,
                0
            ],
            "parquet-thrift/src/main/java/org/apache/parquet/thrift/pig/ParquetThriftStorer.java": [
                90,
                0
            ],
            "parquet-thrift/src/main/java/org/apache/parquet/thrift/pig/TupleToThriftWriteSupport.java": [
                79,
                0
            ],
            "parquet-thrift/src/main/java/org/apache/parquet/thrift/projection/FieldProjectionFilter.java": [
                62,
                0
            ],
            "parquet-thrift/src/main/java/org/apache/parquet/thrift/projection/FieldsPath.java": [
                87,
                0
            ],
            "parquet-thrift/src/main/java/org/apache/parquet/thrift/projection/StrictFieldProjectionFilter.java": [
                187,
                0
            ],
            "parquet-thrift/src/main/java/org/apache/parquet/thrift/projection/ThriftProjectionException.java": [
                45,
                0
            ],
            "parquet-thrift/src/main/java/org/apache/parquet/thrift/projection/amend/DefaultEventsVisitor.java": [
                228,
                0
            ],
            "parquet-thrift/src/main/java/org/apache/parquet/thrift/projection/amend/DefaultProtocolEventsGenerator.java": [
                68,
                0
            ],
            "parquet-thrift/src/main/java/org/apache/parquet/thrift/projection/amend/ProtocolEventsAmender.java": [
                171,
                0
            ],
            "parquet-thrift/src/main/java/org/apache/parquet/thrift/projection/amend/ReadFieldBeginProtocol.java": [
                44,
                0
            ],
            "parquet-thrift/src/main/java/org/apache/parquet/thrift/projection/deprecated/DeprecatedFieldProjectionFilter.java": [
                106,
                0
            ],
            "parquet-thrift/src/main/java/org/apache/parquet/thrift/projection/deprecated/PathGlobPattern.java": [
                173,
                0
            ],
            "parquet-thrift/src/main/java/org/apache/parquet/thrift/struct/CompatibilityChecker.java": [
                265,
                0
            ],
            "parquet-thrift/src/main/java/org/apache/parquet/thrift/struct/CompatibilityRunner.java": [
                104,
                0
            ],
            "parquet-thrift/src/main/java/org/apache/parquet/thrift/struct/JSON.java": [
                50,
                0
            ],
            "parquet-thrift/src/main/java/org/apache/parquet/thrift/struct/ThriftField.java": [
                121,
                0
            ],
            "parquet-thrift/src/main/java/org/apache/parquet/thrift/struct/ThriftType.java": [
                698,
                0
            ],
            "parquet-thrift/src/main/java/org/apache/parquet/thrift/struct/ThriftTypeID.java": [
                108,
                0
            ],
            "parquet-thrift/src/test/java/org/apache/parquet/hadoop/thrift/TestArrayCompatibility.java": [
                779,
                0
            ],
            "parquet-thrift/src/test/java/org/apache/parquet/hadoop/thrift/TestBinary.java": [
                86,
                0
            ],
            "parquet-thrift/src/test/java/org/apache/parquet/hadoop/thrift/TestCorruptThriftRecords.java": [
                213,
                0
            ],
            "parquet-thrift/src/test/java/org/apache/parquet/hadoop/thrift/TestInputOutputFormat.java": [
                258,
                0
            ],
            "parquet-thrift/src/test/java/org/apache/parquet/hadoop/thrift/TestParquetToThriftReadWriteAndProjection.java": [
                385,
                0
            ],
            "parquet-thrift/src/test/java/org/apache/parquet/hadoop/thrift/TestThriftToParquetFileWriter.java": [
                360,
                0
            ],
            "parquet-thrift/src/test/java/org/apache/parquet/thrift/TestParquetReadProtocol.java": [
                173,
                0
            ],
            "parquet-thrift/src/test/java/org/apache/parquet/thrift/TestParquetWriteProtocol.java": [
                719,
                0
            ],
            "parquet-thrift/src/test/java/org/apache/parquet/thrift/TestProtocolReadToWrite.java": [
                384,
                0
            ],
            "parquet-thrift/src/test/java/org/apache/parquet/thrift/TestThriftMetaData.java": [
                56,
                0
            ],
            "parquet-thrift/src/test/java/org/apache/parquet/thrift/TestThriftParquetReaderWriter.java": [
                83,
                0
            ],
            "parquet-thrift/src/test/java/org/apache/parquet/thrift/TestThriftRecordConverter.java": [
                101,
                0
            ],
            "parquet-thrift/src/test/java/org/apache/parquet/thrift/TestThriftSchemaConvertVisitor.java": [
                178,
                0
            ],
            "parquet-thrift/src/test/java/org/apache/parquet/thrift/TestThriftSchemaConverter.java": [
                353,
                0
            ],
            "parquet-thrift/src/test/java/org/apache/parquet/thrift/TestThriftSchemaConverterProjectUnion.java": [
                480,
                0
            ],
            "parquet-thrift/src/test/java/org/apache/parquet/thrift/TestThriftToPigCompatibility.java": [
                171,
                0
            ],
            "parquet-thrift/src/test/java/org/apache/parquet/thrift/pig/TestParquetThriftStorer.java": [
                82,
                0
            ],
            "parquet-thrift/src/test/java/org/apache/parquet/thrift/projection/TestFieldsPath.java": [
                162,
                0
            ],
            "parquet-thrift/src/test/java/org/apache/parquet/thrift/projection/TestStrictFieldProjectionFilter.java": [
                119,
                0
            ],
            "parquet-thrift/src/test/java/org/apache/parquet/thrift/projection/deprecated/PathGlobPatternTest.java": [
                59,
                0
            ],
            "parquet-thrift/src/test/java/org/apache/parquet/thrift/struct/CompatibilityCheckerTest.java": [
                132,
                0
            ],
            "parquet-thrift/src/test/java/org/apache/parquet/thrift/struct/TestThriftType.java": [
                70,
                0
            ],
            "parquet-thrift/src/test/resources/org/apache/parquet/hadoop/thrift/AddressBook.json": null,
            "parquet-thrift/src/test/resources/org/apache/parquet/thrift/StructWithUnionV1NoStructOrUnionMeta.json": null,
            "parquet-thrift/src/test/thrift/array_compat.thrift": null,
            "parquet-thrift/src/test/thrift/binary.thrift": null,
            "parquet-thrift/src/test/thrift/compat.thrift": null,
            "parquet-thrift/src/test/thrift/test.thrift": null,
            "pom.xml": null,
            "src/license.txt": null
        }
    },
    "cb175881473f9a76ff3b7f0b66f4b6bab0baf8df": {
        "datetime": "2013-03-11T12:17:37-07:00",
        "summary": "comments on the thrift file; diagram for the metadata",
        "message": "comments on the thrift file; diagram for the metadata\n\nMake it possible to build\n\nCleaned up the POM and README. Also ensured that we\ntake the steps so we can build on Travis CI and deploy\nto oss.sonatype.org (maven central) in the future.\n\nSigned-off-by: Chris Aniszczyk <zx@twitter.com>\n",
        "diff": {
            "pom.xml": null
        }
    },
    "f848e45f37ab8c1a1641ea4eddf08dca036e2594": {
        "datetime": "2013-03-11T12:17:46-07:00",
        "summary": "Fix description in POM and more README cleanup",
        "message": "Fix description in POM and more README cleanup\n",
        "diff": {
            "pom.xml": null
        }
    },
    "c619db109cc682eaa27e3cd10f8ff4af32a7f881": {
        "datetime": "2013-03-11T12:18:10-07:00",
        "summary": "Add bool description and miscellaneous cleanup.",
        "message": "Add bool description and miscellaneous cleanup.\n",
        "diff": {
            "pom.xml": null
        }
    },
    "06627f049a13c20502f94f286ce296a06f8f2e4d": {
        "datetime": "2013-03-11T12:18:28-07:00",
        "summary": "Thrift file updates.",
        "message": "Thrift file updates.\n",
        "diff": {
            "pom.xml": null
        }
    },
    "01b195b4dccbf61d38eb7f3be76492a9232b712a": {
        "datetime": "2013-03-11T12:18:34-07:00",
        "summary": "Update readme",
        "message": "Update readme\n\nadd repo for maven-thrift-plugin\nAdd 'sonatype-oss-release' maven profile\nChange groupId to com.twitter\n",
        "diff": {
            "pom.xml": null
        }
    },
    "37b704153bc2bf50129b9e0a6ada3e2530876114": {
        "datetime": "2013-03-11T13:53:01-07:00",
        "summary": "better tests for new summary file",
        "message": "better tests for new summary file\n",
        "diff": {
            "parquet-hadoop/src/main/java/parquet/hadoop/Footer.java": [
                0,
                4
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/ParquetFileReader.java": [
                2,
                3
            ],
            "parquet-hadoop/src/test/java/parquet/hadoop/TestParquetFileWriter.java": [
                12,
                57
            ],
            "pom.xml": null
        }
    },
    "aa6dca8666b7f05e02c09f424e29f6f964c5a273": {
        "datetime": "2013-03-11T14:19:02-07:00",
        "summary": "integrate thrift format changes",
        "message": "integrate thrift format changes\n",
        "diff": {
            "parquet-hadoop/src/main/java/parquet/format/converter/ParquetMetadataConverter.java": [
                6,
                3
            ],
            "parquet-hadoop/src/test/java/parquet/hadoop/example/TestInputOutputFormat.java": [
                4,
                0
            ]
        }
    },
    "dabb797e22c21f49f58fce64ad536d45b529efb1": {
        "datetime": "2013-03-11T14:19:47-07:00",
        "summary": "Merge pull request #8 from Parquet/metadata_file",
        "message": "Merge pull request #8 from Parquet/metadata_file\n\nMetadata file in parquet format",
        "diff": {
            "parquet-hadoop/src/main/java/parquet/format/converter/ParquetMetadataConverter.java": [
                7,
                11
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/Footer.java": [
                0,
                4
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/ParquetFileReader.java": [
                12,
                22
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/ParquetFileWriter.java": [
                17,
                55
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/PrintFooter.java": [
                2,
                2
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/metadata/BlockMetaData.java": [
                0,
                16
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/metadata/FileMetaData.java": [
                0,
                8
            ],
            "parquet-hadoop/src/test/java/parquet/hadoop/TestParquetFileWriter.java": [
                3,
                107
            ],
            "parquet-hadoop/src/test/java/parquet/hadoop/example/TestInputOutputFormat.java": [
                0,
                5
            ],
            "pom.xml": null
        }
    },
    "11c34bf287a5eb78b5878355c6d5ad2dfe1689fe": {
        "datetime": "2013-03-11T14:21:04-07:00",
        "summary": "Merge branch 'master' of github.com:Parquet/parquet-mr",
        "message": "Merge branch 'master' of github.com:Parquet/parquet-mr\n",
        "diff": {
            "README.md": null,
            "parquet-hadoop/src/main/java/parquet/format/converter/ParquetMetadataConverter.java": [
                7,
                11
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/Footer.java": [
                0,
                4
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/ParquetFileReader.java": [
                12,
                22
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/ParquetFileWriter.java": [
                17,
                55
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/PrintFooter.java": [
                2,
                2
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/metadata/BlockMetaData.java": [
                0,
                16
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/metadata/FileMetaData.java": [
                0,
                8
            ],
            "parquet-hadoop/src/test/java/parquet/hadoop/TestParquetFileWriter.java": [
                3,
                107
            ],
            "parquet-hadoop/src/test/java/parquet/hadoop/example/TestInputOutputFormat.java": [
                0,
                5
            ],
            "pom.xml": null
        }
    },
    "bb7d9f66c3613100213de0a5031918fe87bb9978": {
        "datetime": "2013-03-11T14:37:43-07:00",
        "summary": "Update README.md",
        "message": "Update README.md",
        "diff": {
            "README.md": null
        }
    },
    "bdec17ea2af932e60db3133d3d13cad7fa6e74f6": {
        "datetime": "2013-03-11T15:01:50-07:00",
        "summary": "integrate Todd's feedback",
        "message": "integrate Todd's feedback\n",
        "diff": {
            "parquet-column/src/main/java/parquet/bytes/BytesUtils.java": [
                3,
                1
            ]
        }
    },
    "4b45e24724aaf8dd3efff6f81ffe821e32194172": {
        "datetime": "2013-03-11T15:02:08-07:00",
        "summary": "Merge branch 'master' of github.com:Parquet/parquet-mr",
        "message": "Merge branch 'master' of github.com:Parquet/parquet-mr\n",
        "diff": {
            "README.md": null
        }
    },
    "d07c10ec29a7362c4b7368cb4a95205c4f63f1ed": {
        "datetime": "2013-03-11T18:59:02-05:00",
        "summary": "Fix LICENSE",
        "message": "Fix LICENSE",
        "diff": {
            "license.txt": null
        }
    },
    "7a6c78460ba78a290333fb9df58d42b0ed965f2f": {
        "datetime": "2013-03-11T19:00:29-05:00",
        "summary": "Update README.md",
        "message": "Update README.md",
        "diff": {
            "README.md": null
        }
    },
    "a5249795799317be00c454ac880be6c064e2a1c6": {
        "datetime": "2013-03-11T19:02:43-05:00",
        "summary": "Remove the old license.txt",
        "message": "Remove the old license.txt\n\nSigned-off-by: Chris Aniszczyk <zx@twitter.com>\n",
        "diff": {
            "license.txt": null
        }
    },
    "7bd223aba6584ea4caa3b40180c2c414be9e185f": {
        "datetime": "2013-03-12T08:15:51-07:00",
        "summary": "improved OutputFormat javadoc and defaults",
        "message": "improved OutputFormat javadoc and defaults\n",
        "diff": {
            "parquet-hadoop/src/main/java/parquet/hadoop/ParquetOutputFormat.java": [
                8,
                22
            ]
        }
    },
    "7d901763e147341048497638c566d355a65db878": {
        "datetime": "2013-03-12T08:24:44-07:00",
        "summary": "Merge branch 'master' of github.com:Parquet/parquet-mr",
        "message": "Merge branch 'master' of github.com:Parquet/parquet-mr\n",
        "diff": {
            "README.md": null,
            "license.txt": null
        }
    },
    "408785a1e16643f41530e3e81ef7bedab919f265": {
        "datetime": "2013-03-12T08:39:57-07:00",
        "summary": "adding back the license header used by the maven plugin",
        "message": "adding back the license header used by the maven plugin\n",
        "diff": {
            "pom.xml": null,
            "src/license.txt": null
        }
    },
    "7a9a750089b6989b5e5d632918d2340f34225550": {
        "datetime": "2013-03-12T10:55:35-07:00",
        "summary": "Update NOTICE",
        "message": "Update NOTICE",
        "diff": {
            "NOTICE": null
        }
    },
    "68f4a5d3598d3ce16bd6ccce032e35d38a8eb5be": {
        "datetime": "2013-03-12T11:00:10-07:00",
        "summary": "Update README.md",
        "message": "Update README.md",
        "diff": {
            "README.md": null
        }
    },
    "c502c2171ad9b47d177cc580bf3f9966774d6006": {
        "datetime": "2013-03-12T11:24:48-07:00",
        "summary": "add deploy configuration",
        "message": "add deploy configuration\n",
        "diff": {
            "pom.xml": null
        }
    },
    "bf1b4944a447de2bf5c39f9f910204da89ad1032": {
        "datetime": "2013-03-12T11:30:31-07:00",
        "summary": "Merge pull request #10 from Parquet/allow_deploy",
        "message": "Merge pull request #10 from Parquet/allow_deploy\n\nadd deploy configuration",
        "diff": {
            "pom.xml": null
        }
    },
    "241634e6990bb929236863b985d362e6cc8698a7": {
        "datetime": "2013-03-12T18:14:34-07:00",
        "summary": "better exception when reading unknown field",
        "message": "better exception when reading unknown field\n",
        "diff": {
            "parquet-thrift/src/main/java/parquet/thrift/ParquetWriteProtocol.java": [
                6,
                9
            ]
        }
    },
    "de8bc0d11b0834aca31f65159c641e4051844ac1": {
        "datetime": "2013-03-12T21:19:18-07:00",
        "summary": "fix java 6 compiler compatibility",
        "message": "fix java 6 compiler compatibility\n",
        "diff": {
            "parquet-column/src/main/java/parquet/io/api/Binary.java": [
                2,
                2
            ]
        }
    },
    "5fe97c8b3a293cd37e7dfc2f611a370bab6a9b0f": {
        "datetime": "2013-03-12T21:20:07-07:00",
        "summary": "add pig schema in thrift metadata",
        "message": "add pig schema in thrift metadata\n",
        "diff": {
            "parquet-pig/src/main/java/parquet/pig/PigMetaData.java": [
                0,
                7
            ],
            "parquet-pig/src/main/java/parquet/pig/TupleWriteSupport.java": [
                2,
                1
            ],
            "parquet-thrift/pom.xml": null,
            "parquet-thrift/src/main/java/parquet/hadoop/thrift/ThriftWriteSupport.java": [
                1,
                9
            ]
        }
    },
    "65364a46bc72bb99fbdc4f19cb51a0db2ab8030e": {
        "datetime": "2013-03-14T11:12:18-07:00",
        "summary": "fix map of primitive; add thrift to pig compat",
        "message": "fix map of primitive; add thrift to pig compat\n",
        "diff": {
            "parquet-pig/src/main/java/parquet/pig/PigSchemaConverter.java": [
                1,
                1
            ],
            "parquet-pig/src/main/java/parquet/pig/TupleReadSupport.java": [
                2,
                2
            ],
            "parquet-pig/src/main/java/parquet/pig/convert/MapConverter.java": [
                22,
                25
            ],
            "parquet-pig/src/main/java/parquet/pig/convert/TupleConverter.java": [
                77,
                161
            ],
            "parquet-pig/src/main/java/parquet/pig/convert/TupleRecordConverter.java": [
                2,
                2
            ],
            "parquet-pig/src/main/java/parquet/pig/convert/ValueContainer.java": [
                0,
                28
            ],
            "parquet-thrift/src/test/java/parquet/thrift/TestParquetWriteProtocol.java": [
                4,
                9
            ],
            "parquet-thrift/src/test/java/parquet/thrift/TestThriftToPigCompatibility.java": [
                0,
                165
            ]
        }
    },
    "c44ff2de4cb9ddc8d8ae42f4cf8336902d7208a3": {
        "datetime": "2013-03-14T11:23:55-07:00",
        "summary": "cleanup",
        "message": "cleanup\n",
        "diff": {
            "parquet-pig/src/main/java/parquet/pig/convert/MapConverter.java": [
                1,
                1
            ],
            "parquet-pig/src/main/java/parquet/pig/convert/TupleConverter.java": [
                2,
                1
            ],
            "parquet-thrift/src/test/java/parquet/thrift/TestThriftToPigCompatibility.java": [
                2,
                0
            ]
        }
    },
    "511b1f5954347079155cea577efc578577714fe4": {
        "datetime": "2013-03-14T15:35:49-07:00",
        "summary": "embed thrift to avoid dependency",
        "message": "embed thrift to avoid dependency\n",
        "diff": {
            "pom.xml": null
        }
    },
    "ef0069eecb6448270b5ca60fb82caf8ab77811b0": {
        "datetime": "2013-03-14T15:58:32-07:00",
        "summary": "incorporate feddback; more tests",
        "message": "incorporate feddback; more tests\n",
        "diff": {
            "parquet-column/src/main/java/parquet/example/data/Group.java": [
                0,
                18
            ],
            "parquet-column/src/test/java/parquet/io/TestColumnIO.java": [
                0,
                41
            ],
            "parquet-pig/src/main/java/parquet/pig/convert/MapConverter.java": [
                3,
                26
            ],
            "parquet-pig/src/main/java/parquet/pig/convert/TupleConverter.java": [
                22,
                70
            ],
            "parquet-pig/src/main/java/parquet/pig/convert/ValueContainer.java": [
                1,
                5
            ]
        }
    },
    "82d5d85e9c5483a124c8436ae403219262006878": {
        "datetime": "2013-03-14T16:00:01-07:00",
        "summary": "Merge pull request #13 from Parquet/thrift_to_pig_compat",
        "message": "Merge pull request #13 from Parquet/thrift_to_pig_compat\n\nfix map of primitive; add thrift to pig compat",
        "diff": {
            "parquet-column/src/main/java/parquet/example/data/Group.java": [
                0,
                18
            ],
            "parquet-column/src/test/java/parquet/io/TestColumnIO.java": [
                0,
                41
            ],
            "parquet-pig/src/main/java/parquet/pig/PigSchemaConverter.java": [
                1,
                1
            ],
            "parquet-pig/src/main/java/parquet/pig/TupleReadSupport.java": [
                2,
                2
            ],
            "parquet-pig/src/main/java/parquet/pig/convert/MapConverter.java": [
                22,
                48
            ],
            "parquet-pig/src/main/java/parquet/pig/convert/ParentValueContainer.java": [
                0,
                32
            ],
            "parquet-pig/src/main/java/parquet/pig/convert/TupleConverter.java": [
                78,
                209
            ],
            "parquet-pig/src/main/java/parquet/pig/convert/TupleRecordConverter.java": [
                2,
                2
            ],
            "parquet-thrift/src/test/java/parquet/thrift/TestParquetWriteProtocol.java": [
                4,
                9
            ],
            "parquet-thrift/src/test/java/parquet/thrift/TestThriftToPigCompatibility.java": [
                0,
                163
            ]
        }
    },
    "e93e35cfe4e102b9b98deb171065509fe6668ba9": {
        "datetime": "2013-03-15T13:26:45-07:00",
        "summary": "fix metadata file in mr mode",
        "message": "fix metadata file in mr mode\n",
        "diff": {
            "parquet-hadoop/src/main/java/parquet/hadoop/ParquetFileReader.java": [
                1,
                1
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/ParquetFileWriter.java": [
                0,
                1
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/ParquetOutputCommitter.java": [
                2,
                12
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/ParquetRecordWriter.java": [
                5,
                5
            ]
        }
    },
    "df3e94ad9e4d6cd87f487087616d220e90cf192e": {
        "datetime": "2013-03-15T15:36:45-07:00",
        "summary": "change default level encoding to bit packed; instanciate reader from page header encoding",
        "message": "change default level encoding to bit packed; instanciate reader from page header encoding\n",
        "diff": {
            "parquet-column/src/main/java/parquet/column/Encoding.java": [
                1,
                56
            ],
            "parquet-column/src/main/java/parquet/column/impl/ColumnReaderImpl.java": [
                18,
                4
            ],
            "parquet-column/src/main/java/parquet/column/impl/ColumnWriterImpl.java": [
                5,
                8
            ],
            "parquet-column/src/main/java/parquet/column/page/Page.java": [
                9,
                29
            ],
            "parquet-column/src/main/java/parquet/column/page/PageWriter.java": [
                1,
                4
            ],
            "parquet-column/src/main/java/parquet/column/values/DataValuesWriter.java": [
                10,
                3
            ],
            "parquet-column/src/main/java/parquet/column/values/ValuesWriter.java": [
                0,
                7
            ],
            "parquet-column/src/main/java/parquet/column/values/bitpacking/BitPackingValuesWriter.java": [
                0,
                7
            ],
            "parquet-column/src/main/java/parquet/column/values/boundedint/BoundedIntValuesWriter.java": [
                1,
                8
            ],
            "parquet-column/src/main/java/parquet/column/values/boundedint/DevNullValuesWriter.java": [
                0,
                7
            ],
            "parquet-column/src/main/java/parquet/column/values/plain/BooleanPlainValuesWriter.java": [
                2,
                2
            ],
            "parquet-column/src/main/java/parquet/column/values/plain/PlainValuesWriter.java": [
                2,
                2
            ],
            "parquet-column/src/test/java/parquet/column/mem/TestMemPageStore.java": [
                5,
                5
            ],
            "parquet-column/src/test/java/parquet/column/page/mem/MemPageWriter.java": [
                2,
                3
            ],
            "parquet-hadoop/src/main/java/parquet/format/converter/ParquetMetadataConverter.java": [
                6,
                18
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/ColumnChunkPageReadStore.java": [
                1,
                3
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/ColumnChunkPageWriteStore.java": [
                3,
                7
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/ParquetFileReader.java": [
                1,
                2
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/ParquetFileWriter.java": [
                4,
                10
            ],
            "parquet-hadoop/src/test/java/parquet/hadoop/TestParquetFileWriter.java": [
                15,
                17
            ],
            "parquet-pig/src/test/java/parquet/pig/GenerateIntTestFile.java": [
                1,
                8
            ]
        }
    },
    "4828f1dcf1dc1fa2d1b33617469885acf632af69": {
        "datetime": "2013-03-18T08:33:56-07:00",
        "summary": "fix metadata conversion",
        "message": "fix metadata conversion\n",
        "diff": {
            "parquet-hadoop/src/main/java/parquet/format/converter/ParquetMetadataConverter.java": [
                34,
                5
            ]
        }
    },
    "d81380a358cbb8100d99ac0e0f9ea1fdcd144738": {
        "datetime": "2013-03-18T10:13:54-07:00",
        "summary": "add test to ensure enums are equivalent",
        "message": "add test to ensure enums are equivalent\n",
        "diff": {
            "parquet-column/src/main/java/parquet/column/Encoding.java": [
                0,
                20
            ],
            "parquet-column/src/main/java/parquet/schema/PrimitiveType.java": [
                3,
                39
            ],
            "parquet-hadoop/src/main/java/parquet/format/converter/ParquetMetadataConverter.java": [
                7,
                15
            ],
            "parquet-hadoop/src/test/java/parquet/format/converter/TestParquetMetadataConverter.java": [
                2,
                29
            ]
        }
    },
    "e0879089422d33387d25acce29d5cc39e29cfcfd": {
        "datetime": "2013-03-18T10:50:34-07:00",
        "summary": "integrate elaphantbird 3.0.8",
        "message": "integrate elaphantbird 3.0.8\n",
        "diff": {
            "parquet-thrift/pom.xml": null,
            "parquet-thrift/src/main/java/parquet/thrift/ThriftSchemaConverter.java": [
                48,
                32
            ],
            "parquet-thrift/src/main/java/parquet/thrift/struct/ThriftField.java": [
                0,
                9
            ],
            "parquet-thrift/src/test/java/parquet/thrift/TestParquetReadProtocol.java": [
                1,
                1
            ],
            "parquet-thrift/src/test/java/parquet/thrift/TestProtocolReadToWrite.java": [
                2,
                1
            ],
            "parquet-thrift/src/test/java/parquet/thrift/TestThriftSchemaConverter.java": [
                3,
                2
            ]
        }
    },
    "071b8f4626f125c81a01a5c07111d4d52102dbdf": {
        "datetime": "2013-03-19T11:14:56-07:00",
        "summary": "change ReadSupport api to fix projection support",
        "message": "change ReadSupport api to fix projection support\n",
        "diff": {
            "parquet-column/src/main/java/parquet/schema/MessageType.java": [
                3,
                3
            ],
            "parquet-column/src/main/java/parquet/schema/PrimitiveType.java": [
                1,
                1
            ],
            "parquet-column/src/main/java/parquet/schema/Type.java": [
                2,
                2
            ],
            "parquet-hadoop/src/main/java/parquet/format/converter/ParquetMetadataConverter.java": [
                3,
                4
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/ParquetFileReader.java": [
                1,
                1
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/ParquetFileWriter.java": [
                18,
                28
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/ParquetInputFormat.java": [
                23,
                53
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/ParquetInputSplit.java": [
                13,
                15
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/ParquetOutputCommitter.java": [
                1,
                1
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/ParquetRecordReader.java": [
                22,
                14
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/api/ReadSupport.java": [
                4,
                42
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/api/WriteSupport.java": [
                1,
                7
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/example/GroupReadSupport.java": [
                6,
                12
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/metadata/FileMetaData.java": [
                8,
                25
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/metadata/ParquetMetadata.java": [
                11,
                1
            ],
            "parquet-hadoop/src/test/java/parquet/hadoop/TestInputFormat.java": [
                3,
                3
            ],
            "parquet-hadoop/src/test/java/parquet/hadoop/TestParquetFileWriter.java": [
                8,
                10
            ],
            "parquet-pig/src/main/java/parquet/pig/ParquetLoader.java": [
                20,
                15
            ],
            "parquet-pig/src/main/java/parquet/pig/PigSchemaConverter.java": [
                75,
                87
            ],
            "parquet-pig/src/main/java/parquet/pig/TupleReadSupport.java": [
                13,
                50
            ],
            "parquet-pig/src/main/java/parquet/pig/convert/TupleConverter.java": [
                1,
                1
            ],
            "parquet-pig/src/test/java/parquet/pig/TestPigSchemaConverter.java": [
                2,
                2
            ],
            "parquet-pig/src/test/java/parquet/pig/TestTupleRecordConsumer.java": [
                1,
                6
            ],
            "parquet-pig/src/test/java/parquet/pig/TupleConsumerPerfTest.java": [
                1,
                4
            ],
            "parquet-thrift/src/main/java/parquet/hadoop/thrift/ThriftReadSupport.java": [
                5,
                11
            ],
            "parquet-thrift/src/test/java/parquet/thrift/TestThriftToPigCompatibility.java": [
                0,
                3
            ]
        }
    },
    "cf6dbc38f4f2aa7756bd393e3607d05d32c53912": {
        "datetime": "2013-03-19T11:25:55-07:00",
        "summary": "Merge pull request #16 from Parquet/update_encodings",
        "message": "Merge pull request #16 from Parquet/update_encodings\n\nUpdate encodings",
        "diff": {
            "parquet-column/src/main/java/parquet/column/Encoding.java": [
                1,
                76
            ],
            "parquet-column/src/main/java/parquet/column/impl/ColumnReaderImpl.java": [
                18,
                4
            ],
            "parquet-column/src/main/java/parquet/column/impl/ColumnWriterImpl.java": [
                5,
                8
            ],
            "parquet-column/src/main/java/parquet/column/page/Page.java": [
                9,
                29
            ],
            "parquet-column/src/main/java/parquet/column/page/PageWriter.java": [
                1,
                4
            ],
            "parquet-column/src/main/java/parquet/column/values/DataValuesWriter.java": [
                10,
                3
            ],
            "parquet-column/src/main/java/parquet/column/values/ValuesWriter.java": [
                0,
                7
            ],
            "parquet-column/src/main/java/parquet/column/values/bitpacking/BitPackingValuesWriter.java": [
                0,
                7
            ],
            "parquet-column/src/main/java/parquet/column/values/boundedint/BoundedIntValuesWriter.java": [
                1,
                8
            ],
            "parquet-column/src/main/java/parquet/column/values/boundedint/DevNullValuesWriter.java": [
                0,
                7
            ],
            "parquet-column/src/main/java/parquet/column/values/plain/BooleanPlainValuesWriter.java": [
                2,
                2
            ],
            "parquet-column/src/main/java/parquet/column/values/plain/PlainValuesWriter.java": [
                2,
                2
            ],
            "parquet-column/src/main/java/parquet/schema/PrimitiveType.java": [
                3,
                39
            ],
            "parquet-column/src/test/java/parquet/column/mem/TestMemPageStore.java": [
                5,
                5
            ],
            "parquet-column/src/test/java/parquet/column/page/mem/MemPageWriter.java": [
                2,
                3
            ],
            "parquet-hadoop/src/main/java/parquet/format/converter/ParquetMetadataConverter.java": [
                39,
                30
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/ColumnChunkPageReadStore.java": [
                1,
                3
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/ColumnChunkPageWriteStore.java": [
                3,
                7
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/ParquetFileReader.java": [
                2,
                3
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/ParquetFileWriter.java": [
                4,
                11
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/ParquetOutputCommitter.java": [
                2,
                12
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/ParquetRecordWriter.java": [
                5,
                5
            ],
            "parquet-hadoop/src/test/java/parquet/format/converter/TestParquetMetadataConverter.java": [
                2,
                29
            ],
            "parquet-hadoop/src/test/java/parquet/hadoop/TestParquetFileWriter.java": [
                15,
                17
            ],
            "parquet-pig/src/test/java/parquet/pig/GenerateIntTestFile.java": [
                1,
                8
            ],
            "parquet-thrift/pom.xml": null,
            "parquet-thrift/src/main/java/parquet/thrift/ThriftSchemaConverter.java": [
                48,
                32
            ],
            "parquet-thrift/src/main/java/parquet/thrift/struct/ThriftField.java": [
                0,
                9
            ],
            "parquet-thrift/src/test/java/parquet/thrift/TestParquetReadProtocol.java": [
                1,
                1
            ],
            "parquet-thrift/src/test/java/parquet/thrift/TestProtocolReadToWrite.java": [
                2,
                1
            ],
            "parquet-thrift/src/test/java/parquet/thrift/TestThriftSchemaConverter.java": [
                3,
                2
            ]
        }
    },
    "5dfa1b22e5eb7f07c64f3d78bdee67fa07e5980e": {
        "datetime": "2013-03-19T15:06:41-07:00",
        "summary": "deal with elephantbird handling of numbers",
        "message": "deal with elephantbird handling of numbers\n",
        "diff": {
            "parquet-pig/src/main/java/parquet/pig/TupleReadSupport.java": [
                4,
                12
            ],
            "parquet-pig/src/main/java/parquet/pig/convert/MapConverter.java": [
                4,
                4
            ],
            "parquet-pig/src/main/java/parquet/pig/convert/TupleConverter.java": [
                8,
                49
            ],
            "parquet-pig/src/main/java/parquet/pig/convert/TupleRecordMaterializer.java": [
                2,
                2
            ],
            "parquet-thrift/src/test/java/parquet/thrift/TestThriftToPigCompatibility.java": [
                2,
                2
            ]
        }
    },
    "696bce4436dcfbe5bb6aec164932bd2195f69128": {
        "datetime": "2013-03-19T15:13:40-07:00",
        "summary": "use constant for settings",
        "message": "use constant for settings\n",
        "diff": {
            "parquet-pig/src/main/java/parquet/pig/ParquetLoader.java": [
                1,
                3
            ]
        }
    },
    "f9c25b690457cc5788142feba2c31ee169b1736e": {
        "datetime": "2013-03-21T09:10:37-07:00",
        "summary": "Merge pull request #17 from Parquet/thrift_to_pig_compat2",
        "message": "Merge pull request #17 from Parquet/thrift_to_pig_compat2\n\nSlight change in ReadSupport API",
        "diff": {
            "parquet-column/src/main/java/parquet/schema/MessageType.java": [
                3,
                3
            ],
            "parquet-column/src/main/java/parquet/schema/PrimitiveType.java": [
                1,
                1
            ],
            "parquet-column/src/main/java/parquet/schema/Type.java": [
                2,
                2
            ],
            "parquet-hadoop/src/main/java/parquet/format/converter/ParquetMetadataConverter.java": [
                3,
                4
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/ParquetFileReader.java": [
                1,
                1
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/ParquetFileWriter.java": [
                18,
                28
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/ParquetInputFormat.java": [
                23,
                53
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/ParquetInputSplit.java": [
                13,
                15
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/ParquetOutputCommitter.java": [
                1,
                1
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/ParquetRecordReader.java": [
                22,
                14
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/api/ReadSupport.java": [
                4,
                42
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/api/WriteSupport.java": [
                1,
                7
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/example/GroupReadSupport.java": [
                6,
                12
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/metadata/FileMetaData.java": [
                8,
                25
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/metadata/ParquetMetadata.java": [
                11,
                1
            ],
            "parquet-hadoop/src/test/java/parquet/hadoop/TestInputFormat.java": [
                3,
                3
            ],
            "parquet-hadoop/src/test/java/parquet/hadoop/TestParquetFileWriter.java": [
                8,
                10
            ],
            "parquet-pig/src/main/java/parquet/pig/ParquetLoader.java": [
                20,
                17
            ],
            "parquet-pig/src/main/java/parquet/pig/PigSchemaConverter.java": [
                75,
                87
            ],
            "parquet-pig/src/main/java/parquet/pig/TupleReadSupport.java": [
                13,
                58
            ],
            "parquet-pig/src/main/java/parquet/pig/convert/MapConverter.java": [
                4,
                4
            ],
            "parquet-pig/src/main/java/parquet/pig/convert/TupleConverter.java": [
                9,
                50
            ],
            "parquet-pig/src/main/java/parquet/pig/convert/TupleRecordMaterializer.java": [
                2,
                2
            ],
            "parquet-pig/src/test/java/parquet/pig/TestPigSchemaConverter.java": [
                2,
                2
            ],
            "parquet-pig/src/test/java/parquet/pig/TestTupleRecordConsumer.java": [
                1,
                6
            ],
            "parquet-pig/src/test/java/parquet/pig/TupleConsumerPerfTest.java": [
                1,
                4
            ],
            "parquet-thrift/src/main/java/parquet/hadoop/thrift/ThriftReadSupport.java": [
                5,
                11
            ],
            "parquet-thrift/src/test/java/parquet/thrift/TestThriftToPigCompatibility.java": [
                2,
                5
            ]
        }
    },
    "a4e5f028ceb00eefb8b07ad2c59f01d163a0dbb0": {
        "datetime": "2013-03-21T09:12:10-07:00",
        "summary": "Update README.md",
        "message": "Update README.md",
        "diff": {
            "README.md": null
        }
    },
    "cc5cd632c024dca7d2806a2114ebd29ca73130f1": {
        "datetime": "2013-03-21T10:56:46-07:00",
        "summary": "Update README.md",
        "message": "Update README.md",
        "diff": {
            "README.md": null
        }
    },
    "fce6998edbebee642c8194d8d74f90e6ab887fca": {
        "datetime": "2013-03-21T16:43:00-07:00",
        "summary": "avoid string decoding recoding",
        "message": "avoid string decoding recoding\n",
        "diff": {
            "parquet-thrift/src/main/java/parquet/thrift/ProtocolReadToWrite.java": [
                1,
                1
            ]
        }
    },
    "c625aa6a83800bf4cd648edca2ffc3c8271a2a6a": {
        "datetime": "2013-03-27T13:48:43-07:00",
        "summary": "Merge pull request #19 from Parquet/improve_thrift_perf",
        "message": "Merge pull request #19 from Parquet/improve_thrift_perf\n\navoid string decoding recoding",
        "diff": {
            "parquet-thrift/src/main/java/parquet/thrift/ProtocolReadToWrite.java": [
                1,
                1
            ]
        }
    },
    "f5b2cb8e8bfd75f65b31b8dcb153f3cd094e762c": {
        "datetime": "2013-03-27T17:58:03-07:00",
        "summary": "add better Bytes plain decoder",
        "message": "add better Bytes plain decoder\n",
        "diff": {
            "parquet-column/src/main/java/parquet/column/Encoding.java": [
                0,
                3
            ],
            "parquet-column/src/main/java/parquet/column/values/plain/BinaryPlainValuesReader.java": [
                0,
                38
            ],
            "parquet-column/src/main/java/parquet/column/values/plain/PlainValuesReader.java": [
                12,
                0
            ]
        }
    },
    "56faa1be0d3334fab7366c454c08da300d726e25": {
        "datetime": "2013-03-27T17:59:08-07:00",
        "summary": "first stab at dict encoding",
        "message": "first stab at dict encoding\n",
        "diff": {
            "parquet-column/src/main/java/parquet/column/values/dictionary/DictionaryColumnWriter.java": [
                0,
                58
            ],
            "parquet-column/src/test/java/parquet/column/values/dictionary/TestDictionary.java": [
                0,
                11
            ]
        }
    },
    "cf5ba492d2c4acc00305c880dddc661909e66ff4": {
        "datetime": "2013-03-27T18:09:01-07:00",
        "summary": "fix perf test",
        "message": "fix perf test\n",
        "diff": {
            "parquet-column/src/main/java/parquet/example/DummyRecordConverter.java": [
                1,
                8
            ],
            "parquet-column/src/test/java/parquet/io/PerfTest.java": [
                3,
                3
            ]
        }
    },
    "1b2694e462abaff27a134a2ebaed837f8a306aef": {
        "datetime": "2013-03-27T18:16:55-07:00",
        "summary": "fix offset",
        "message": "fix offset\n",
        "diff": {
            "parquet-column/src/main/java/parquet/column/values/plain/BinaryPlainValuesReader.java": [
                2,
                3
            ]
        }
    },
    "8246e0bbb229f54bf8fcb03f6133d7c5f8f4036c": {
        "datetime": "2013-03-28T11:26:13-07:00",
        "summary": "fix perf problem with new String(bytes, offset, length, encoding)",
        "message": "fix perf problem with new String(bytes, offset, length, encoding)\n",
        "diff": {
            "parquet-column/src/main/java/parquet/io/api/Binary.java": [
                1,
                5
            ]
        }
    },
    "5c60ed8459b88d44eb6c555fff8c3cd1b3e26d17": {
        "datetime": "2013-03-28T13:06:05-07:00",
        "summary": "remove one array copy",
        "message": "remove one array copy\n",
        "diff": {
            "parquet-column/src/main/java/parquet/bytes/BytesInput.java": [
                1,
                6
            ],
            "parquet-column/src/main/java/parquet/column/values/plain/PlainValuesReader.java": [
                1,
                0
            ]
        }
    },
    "60a2925533d852627cdc1de26c4e973acbfbf407": {
        "datetime": "2013-03-29T17:40:38-07:00",
        "summary": "Merge pull request #20 from Parquet/perf_improvement",
        "message": "Merge pull request #20 from Parquet/perf_improvement\n\nPerf improvement",
        "diff": {
            "parquet-column/src/main/java/parquet/bytes/BytesInput.java": [
                1,
                6
            ],
            "parquet-column/src/main/java/parquet/column/Encoding.java": [
                0,
                3
            ],
            "parquet-column/src/main/java/parquet/column/values/plain/BinaryPlainValuesReader.java": [
                0,
                39
            ],
            "parquet-column/src/main/java/parquet/column/values/plain/PlainValuesReader.java": [
                13,
                0
            ],
            "parquet-column/src/main/java/parquet/example/DummyRecordConverter.java": [
                1,
                8
            ],
            "parquet-column/src/main/java/parquet/io/api/Binary.java": [
                1,
                5
            ],
            "parquet-column/src/test/java/parquet/io/PerfTest.java": [
                3,
                3
            ]
        }
    },
    "e18d38bc1d6527439919e61fb19c429921acdadc": {
        "datetime": "2013-04-02T18:30:35-07:00",
        "summary": "dictionary encoding",
        "message": "dictionary encoding\n",
        "diff": {
            "parquet-column/src/main/java/parquet/bytes/BytesInput.java": [
                2,
                6
            ],
            "parquet-column/src/main/java/parquet/column/Dictionary.java": [
                0,
                25
            ],
            "parquet-column/src/main/java/parquet/column/Encoding.java": [
                9,
                33
            ],
            "parquet-column/src/main/java/parquet/column/impl/ColumnReaderImpl.java": [
                12,
                21
            ],
            "parquet-column/src/main/java/parquet/column/impl/ColumnWriterImpl.java": [
                0,
                24
            ],
            "parquet-column/src/main/java/parquet/column/page/DictionaryPage.java": [
                0,
                54
            ],
            "parquet-column/src/main/java/parquet/column/page/PageReader.java": [
                2,
                5
            ],
            "parquet-column/src/main/java/parquet/column/page/PageWriter.java": [
                2,
                6
            ],
            "parquet-column/src/main/java/parquet/column/values/ValuesReader.java": [
                3,
                13
            ],
            "parquet-column/src/main/java/parquet/column/values/ValuesWriter.java": [
                0,
                14
            ],
            "parquet-column/src/main/java/parquet/column/values/dictionary/DictionaryColumnWriter.java": [
                58,
                0
            ],
            "parquet-column/src/main/java/parquet/column/values/dictionary/DictionaryValuesReader.java": [
                0,
                44
            ],
            "parquet-column/src/main/java/parquet/column/values/dictionary/DictionaryValuesWriter.java": [
                0,
                82
            ],
            "parquet-column/src/main/java/parquet/column/values/dictionary/PlainDictionary.java": [
                0,
                42
            ],
            "parquet-column/src/test/java/parquet/column/page/mem/MemPageReader.java": [
                1,
                15
            ],
            "parquet-column/src/test/java/parquet/column/page/mem/MemPageStore.java": [
                1,
                1
            ],
            "parquet-column/src/test/java/parquet/column/page/mem/MemPageWriter.java": [
                0,
                13
            ],
            "parquet-column/src/test/java/parquet/column/values/dictionary/TestDictionary.java": [
                2,
                43
            ],
            "parquet-hadoop/src/main/java/parquet/format/converter/ParquetMetadataConverter.java": [
                1,
                10
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/ColumnChunkPageReadStore.java": [
                1,
                21
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/ColumnChunkPageWriteStore.java": [
                0,
                14
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/ParquetFileReader.java": [
                35,
                34
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/ParquetFileWriter.java": [
                0,
                26
            ]
        }
    },
    "827a5bc4a7a00c624dd6062804ae7f4f42be16a8": {
        "datetime": "2013-04-03T08:21:08-07:00",
        "summary": "fix dictionary encoding",
        "message": "fix dictionary encoding\n",
        "diff": {
            "parquet-column/src/main/java/parquet/column/impl/ColumnWriterImpl.java": [
                1,
                0
            ],
            "parquet-column/src/main/java/parquet/column/page/DictionaryPage.java": [
                0,
                17
            ],
            "parquet-column/src/main/java/parquet/column/values/ValuesReader.java": [
                1,
                1
            ],
            "parquet-column/src/test/java/parquet/column/page/mem/MemPageReader.java": [
                3,
                6
            ],
            "parquet-column/src/test/java/parquet/column/values/dictionary/TestDictionary.java": [
                1,
                1
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/ColumnChunkPageReadStore.java": [
                1,
                0
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/ParquetFileWriter.java": [
                3,
                5
            ]
        }
    },
    "4a69511fea03a2f4051df3f90e1fd0f982d7def0": {
        "datetime": "2013-04-03T14:52:27-07:00",
        "summary": "dictionary encoding",
        "message": "dictionary encoding\n",
        "diff": {
            "parquet-column/src/main/java/parquet/column/impl/ColumnWriterImpl.java": [
                2,
                3
            ],
            "parquet-column/src/main/java/parquet/column/values/BinaryEncodingPickerValuesWriter.java": [
                0,
                95
            ],
            "parquet-column/src/main/java/parquet/column/values/ValuesWriter.java": [
                0,
                11
            ],
            "parquet-column/src/main/java/parquet/column/values/dictionary/DictionaryValuesWriter.java": [
                0,
                4
            ],
            "parquet-column/src/test/java/parquet/column/values/dictionary/TestDictionary.java": [
                0,
                41
            ],
            "parquet-hadoop/src/main/java/parquet/format/converter/ParquetMetadataConverter.java": [
                0,
                2
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/ColumnChunkPageWriteStore.java": [
                0,
                8
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/ParquetFileReader.java": [
                1,
                6
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/ParquetFileWriter.java": [
                1,
                2
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/ParquetRecordWriter.java": [
                1,
                1
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/metadata/ColumnChunkMetaData.java": [
                7,
                16
            ],
            "parquet-thrift/src/test/java/parquet/thrift/TestThriftSchemaConverter.java": [
                0,
                1
            ]
        }
    },
    "b41e6e2b411a718141307b198de1fc49ccabc4d8": {
        "datetime": "2013-04-03T15:57:28-07:00",
        "summary": "relocating jackson inside the parquet-thrift jar",
        "message": "relocating jackson inside the parquet-thrift jar\n",
        "diff": {
            "parquet-thrift/pom.xml": null,
            "pom.xml": null
        }
    },
    "90b5eae8ba0e7230dc5c379c14ebda076b4dd283": {
        "datetime": "2013-04-03T16:01:41-07:00",
        "summary": "add scrooge and cascading support",
        "message": "add scrooge and cascading support\n",
        "diff": {
            "parquet-cascading/.cache": null,
            "parquet-cascading/pom.xml": null,
            "parquet-cascading/src/main/java/parquet/cascading/ParquetTBaseScheme.java": [
                0,
                53
            ],
            "parquet-cascading/src/main/java/parquet/cascading/ParquetValueScheme.java": [
                0,
                41
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/ParquetInputFormat.java": [
                0,
                5
            ],
            "parquet-scrooge/pom.xml": null,
            "parquet-scrooge/src/main/java/parquet/scrooge/ParquetScroogeScheme.java": [
                0,
                61
            ],
            "parquet-scrooge/src/main/java/parquet/scrooge/ScroogeRecordConverter.java": [
                0,
                38
            ],
            "parquet-scrooge/src/test/java/parquet/scrooge/TestScroogeIOFormats.java": [
                0,
                5
            ],
            "parquet-thrift/pom.xml": null,
            "parquet-thrift/src/main/java/parquet/hadoop/thrift/ParquetThriftInputFormat.java": [
                0,
                27
            ],
            "parquet-thrift/src/main/java/parquet/hadoop/thrift/ThriftReadSupport.java": [
                5,
                51
            ],
            "parquet-thrift/src/main/java/parquet/thrift/TBaseRecordConverter.java": [
                3,
                1
            ],
            "parquet-thrift/src/main/java/parquet/thrift/ThriftMetaData.java": [
                13,
                30
            ],
            "pom.xml": null
        }
    },
    "9025c87ea005d90cf8aea926c78f222875f260d2": {
        "datetime": "2013-04-03T16:05:27-07:00",
        "summary": "add indirect jackson jar dep",
        "message": "add indirect jackson jar dep\n",
        "diff": {
            "parquet-thrift/pom.xml": null
        }
    },
    "dd057cf9fb15ec964efdc7594808850f6e397393": {
        "datetime": "2013-04-03T16:07:56-07:00",
        "summary": "merge shade_jackson, fix compilation errors",
        "message": "merge shade_jackson, fix compilation errors\n",
        "diff": {
            "parquet-thrift/pom.xml": null,
            "parquet-thrift/src/main/java/parquet/hadoop/thrift/ThriftWriteSupport.java": [
                1,
                1
            ],
            "pom.xml": null
        }
    },
    "3d63626797fe4e67ca03546478f74166ecdde57f": {
        "datetime": "2013-04-03T16:08:07-07:00",
        "summary": "Merge branch 'shade_jackson' of github.com:Parquet/parquet-mr into scrooge_scalding",
        "message": "Merge branch 'shade_jackson' of github.com:Parquet/parquet-mr into scrooge_scalding\n",
        "diff": {
            "parquet-thrift/pom.xml": null
        }
    },
    "d73218318fe9cd9e6bafb83a3d62ebb1feb76532": {
        "datetime": "2013-04-03T16:28:06-07:00",
        "summary": "apply jackson shading to all modules",
        "message": "apply jackson shading to all modules\n",
        "diff": {
            "parquet-hadoop/pom.xml": null,
            "parquet-pig/pom.xml": null,
            "parquet-thrift/pom.xml": null,
            "pom.xml": null
        }
    },
    "dd8077e57ea2ac96ba23a31e569ef66104a79689": {
        "datetime": "2013-04-03T16:49:30-07:00",
        "summary": "adding utility classe to completely hide Thrift",
        "message": "adding utility classe to completely hide Thrift\n",
        "diff": {
            "src/main/java/parquet/format/Util.java": [
                0,
                61
            ]
        }
    },
    "d006b51f08a43c2a8fd2662a3abea5671d2a437b": {
        "datetime": "2013-04-03T17:01:19-07:00",
        "summary": "Merge branch 'shade_jackson' of github.com:Parquet/parquet-mr into scrooge_scalding",
        "message": "Merge branch 'shade_jackson' of github.com:Parquet/parquet-mr into scrooge_scalding\n",
        "diff": {
            "parquet-hadoop/pom.xml": null,
            "parquet-pig/pom.xml": null,
            "parquet-thrift/pom.xml": null,
            "pom.xml": null
        }
    },
    "efb93bf0ed82a625e1a893bacfbe27a440a84100": {
        "datetime": "2013-04-03T17:11:37-07:00",
        "summary": "Merge pull request #35 from Parquet/shading_jar",
        "message": "Merge pull request #35 from Parquet/shading_jar\n\nthis embeds and renames the thrift dependency in the jar, allowing people to use a different version of thrift in parallel",
        "diff": {
            "pom.xml": null,
            "src/main/java/parquet/format/Util.java": [
                0,
                61
            ]
        }
    },
    "8f9f0c77ab4e2972192ca76a6ee7b5228fe10b7b": {
        "datetime": "2013-04-03T17:48:04-07:00",
        "summary": "integrate thrift change in format",
        "message": "integrate thrift change in format\n",
        "diff": {
            "parquet-hadoop/src/main/java/parquet/format/converter/ParquetMetadataConverter.java": [
                60,
                17
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/ParquetFileReader.java": [
                1,
                1
            ]
        }
    },
    "a4f133aab1e6908f9c7244d755df0b90a9d12a38": {
        "datetime": "2013-04-03T18:03:19-07:00",
        "summary": "cleaning methods",
        "message": "cleaning methods\n",
        "diff": {
            "parquet-hadoop/src/main/java/parquet/format/converter/ParquetMetadataConverter.java": [
                17,
                13
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/ParquetFileReader.java": [
                11,
                3
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/ParquetFileWriter.java": [
                1,
                2
            ],
            "parquet-hadoop/src/test/java/parquet/format/converter/TestParquetMetadataConverter.java": [
                5,
                5
            ],
            "parquet-hadoop/src/test/java/parquet/hadoop/example/TestInputOutputFormat.java": [
                5,
                0
            ],
            "parquet-pig/src/main/java/parquet/pig/ParquetLoader.java": [
                3,
                0
            ],
            "parquet-pig/src/main/java/parquet/pig/convert/TupleConverter.java": [
                1,
                0
            ]
        }
    },
    "7025ede295ff4960b9ae72f1cb6ca0d0140a490c": {
        "datetime": "2013-04-03T18:09:51-07:00",
        "summary": "Merge branch 'integrate_format_changes' into dictionary_encoding",
        "message": "Merge branch 'integrate_format_changes' into dictionary_encoding\n\nConflicts:\n\tparquet-column/src/main/java/parquet/column/Encoding.java\n\tparquet-hadoop/src/main/java/parquet/hadoop/ParquetFileReader.java\n",
        "diff": {
            "parquet-column/src/main/java/parquet/bytes/BytesInput.java": [
                1,
                6
            ],
            "parquet-column/src/main/java/parquet/column/Encoding.java": [
                0,
                3
            ],
            "parquet-column/src/main/java/parquet/column/values/plain/BinaryPlainValuesReader.java": [
                0,
                39
            ],
            "parquet-column/src/main/java/parquet/column/values/plain/PlainValuesReader.java": [
                13,
                0
            ],
            "parquet-column/src/main/java/parquet/example/DummyRecordConverter.java": [
                1,
                8
            ],
            "parquet-column/src/main/java/parquet/io/api/Binary.java": [
                1,
                5
            ],
            "parquet-column/src/test/java/parquet/io/PerfTest.java": [
                3,
                3
            ],
            "parquet-hadoop/src/main/java/parquet/format/converter/ParquetMetadataConverter.java": [
                60,
                13
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/ParquetFileReader.java": [
                11,
                3
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/ParquetFileWriter.java": [
                1,
                2
            ],
            "parquet-hadoop/src/test/java/parquet/format/converter/TestParquetMetadataConverter.java": [
                5,
                5
            ],
            "parquet-hadoop/src/test/java/parquet/hadoop/example/TestInputOutputFormat.java": [
                5,
                0
            ],
            "parquet-pig/src/main/java/parquet/pig/ParquetLoader.java": [
                3,
                0
            ],
            "parquet-pig/src/main/java/parquet/pig/convert/TupleConverter.java": [
                1,
                0
            ],
            "parquet-thrift/src/main/java/parquet/thrift/ProtocolReadToWrite.java": [
                1,
                1
            ]
        }
    },
    "8fc53c49b9c0ea287e131b30a975e1ecbb8cc3ff": {
        "datetime": "2013-04-04T11:21:28-07:00",
        "summary": "improve logging",
        "message": "improve logging\n",
        "diff": {
            "parquet-column/src/test/java/parquet/column/values/dictionary/TestDictionary.java": [
                1,
                1
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/ColumnChunkPageWriteStore.java": [
                1,
                13
            ]
        }
    },
    "5d16042083f0385ae3d860172992c819fe88cb99": {
        "datetime": "2013-04-04T11:28:30-07:00",
        "summary": "Merge pull request #21 from Parquet/shade_jackson",
        "message": "Merge pull request #21 from Parquet/shade_jackson\n\nrelocating jackson inside the parquet-thrift jar",
        "diff": {
            "parquet-hadoop/pom.xml": null,
            "parquet-pig/pom.xml": null,
            "parquet-thrift/pom.xml": null,
            "pom.xml": null
        }
    },
    "e9aa5d5591590b17dc592f7349ad5bd9a8bf4ed4": {
        "datetime": "2013-04-04T13:07:06-07:00",
        "summary": "Merge pull request #22 from Parquet/integrate_format_changes",
        "message": "Merge pull request #22 from Parquet/integrate_format_changes\n\nIntegrate format changes",
        "diff": {
            "parquet-hadoop/src/main/java/parquet/format/converter/ParquetMetadataConverter.java": [
                60,
                13
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/ParquetFileReader.java": [
                11,
                3
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/ParquetFileWriter.java": [
                1,
                2
            ],
            "parquet-hadoop/src/test/java/parquet/format/converter/TestParquetMetadataConverter.java": [
                5,
                5
            ],
            "parquet-hadoop/src/test/java/parquet/hadoop/example/TestInputOutputFormat.java": [
                5,
                0
            ],
            "parquet-pig/src/main/java/parquet/pig/ParquetLoader.java": [
                3,
                0
            ],
            "parquet-pig/src/main/java/parquet/pig/convert/TupleConverter.java": [
                1,
                0
            ]
        }
    },
    "6864d2e3e5fbe3347a27ab875f5544b42466ac3a": {
        "datetime": "2013-04-04T15:06:45-07:00",
        "summary": "Merge branch 'master' into dictionary_encoding",
        "message": "Merge branch 'master' into dictionary_encoding\n",
        "diff": {
            "parquet-hadoop/pom.xml": null,
            "parquet-pig/pom.xml": null,
            "parquet-thrift/pom.xml": null,
            "pom.xml": null
        }
    },
    "dc585ac131d8a276d81152415b269fdedbc3f882": {
        "datetime": "2013-04-04T22:11:30-07:00",
        "summary": "Merge branch 'master' of github.com:Parquet/parquet-mr into scrooge_scalding",
        "message": "Merge branch 'master' of github.com:Parquet/parquet-mr into scrooge_scalding\n",
        "diff": {
            "parquet-hadoop/src/main/java/parquet/format/converter/ParquetMetadataConverter.java": [
                60,
                13
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/ParquetFileReader.java": [
                11,
                3
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/ParquetFileWriter.java": [
                1,
                2
            ],
            "parquet-hadoop/src/test/java/parquet/format/converter/TestParquetMetadataConverter.java": [
                5,
                5
            ],
            "parquet-hadoop/src/test/java/parquet/hadoop/example/TestInputOutputFormat.java": [
                5,
                0
            ],
            "parquet-pig/src/main/java/parquet/pig/ParquetLoader.java": [
                3,
                0
            ],
            "parquet-pig/src/main/java/parquet/pig/convert/TupleConverter.java": [
                1,
                0
            ]
        }
    },
    "9c62f41d3b4e4294d3d7a009e2bceda19d854c75": {
        "datetime": "2013-04-04T22:15:53-07:00",
        "summary": "improve dictionary",
        "message": "improve dictionary\n",
        "diff": {
            "parquet-column/src/main/java/parquet/column/impl/ColumnWriterImpl.java": [
                13,
                4
            ],
            "parquet-column/src/main/java/parquet/column/values/BinaryEncodingPickerValuesWriter.java": [
                95,
                0
            ],
            "parquet-column/src/main/java/parquet/column/values/ValuesWriter.java": [
                14,
                6
            ],
            "parquet-column/src/main/java/parquet/column/values/dictionary/DictionaryValuesReader.java": [
                4,
                10
            ],
            "parquet-column/src/main/java/parquet/column/values/dictionary/DictionaryValuesWriter.java": [
                41,
                139
            ],
            "parquet-column/src/test/java/parquet/column/values/dictionary/TestDictionary.java": [
                18,
                37
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/ColumnChunkPageWriteStore.java": [
                5,
                14
            ]
        }
    },
    "073421762e172b68af81c97374b5c45234ce4f17": {
        "datetime": "2013-04-04T23:09:54-07:00",
        "summary": "add license headers",
        "message": "add license headers\n",
        "diff": {
            "parquet-cascading/src/main/java/parquet/cascading/ParquetTBaseScheme.java": [
                3,
                17
            ],
            "parquet-cascading/src/main/java/parquet/cascading/ParquetValueScheme.java": [
                4,
                20
            ],
            "parquet-scrooge/src/main/java/parquet/scrooge/ParquetScroogeScheme.java": [
                4,
                20
            ],
            "parquet-scrooge/src/main/java/parquet/scrooge/ScroogeRecordConverter.java": [
                0,
                15
            ],
            "parquet-thrift/pom.xml": null,
            "parquet-thrift/src/main/java/parquet/hadoop/thrift/Container.java": [
                0,
                34
            ],
            "parquet-thrift/src/main/java/parquet/hadoop/thrift/DeprecatedContainerInputFormat.java": [
                0,
                367
            ]
        }
    },
    "9656ef2806fc4a35e7754eee8b1a742e921bf9eb": {
        "datetime": "2013-04-05T09:58:27-07:00",
        "summary": "improve api; improve logs;improve PrintFooter",
        "message": "improve api; improve logs;improve PrintFooter\n",
        "diff": {
            "parquet-column/src/main/java/parquet/column/values/ValuesWriter.java": [
                15,
                14
            ],
            "parquet-column/src/main/java/parquet/column/values/dictionary/DictionaryValuesWriter.java": [
                1,
                1
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/ColumnChunkPageWriteStore.java": [
                12,
                8
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/PrintFooter.java": [
                5,
                10
            ]
        }
    },
    "08c8f82011925d3ba083f8b23b8f1c0af29c0d7e": {
        "datetime": "2013-04-08T15:36:50-07:00",
        "summary": "use published EB, fix NPE in ThriftMetaData",
        "message": "use published EB, fix NPE in ThriftMetaData\n",
        "diff": {
            "parquet-thrift/pom.xml": null,
            "parquet-thrift/src/main/java/parquet/thrift/ThriftMetaData.java": [
                1,
                1
            ]
        }
    },
    "d5b3b7d836638a9f29f7798aee5da3c289a5cad4": {
        "datetime": "2013-04-09T15:20:57-07:00",
        "summary": "better logging",
        "message": "better logging\n",
        "diff": {
            "parquet-hadoop/src/main/java/parquet/hadoop/ColumnChunkPageWriteStore.java": [
                1,
                1
            ]
        }
    },
    "0bb5e93507c0725f3f938b38605c67bcaa507b1a": {
        "datetime": "2013-04-10T11:10:25-07:00",
        "summary": "first stab at rle encoding",
        "message": "first stab at rle encoding\n",
        "diff": {
            "parquet-column/src/main/java/parquet/column/values/rle/RLEDecoder.java": [
                0,
                70
            ],
            "parquet-column/src/main/java/parquet/column/values/rle/RLESimpleEncoder.java": [
                0,
                41
            ],
            "parquet-column/src/test/java/parquet/column/values/rle/TestRLE.java": [
                0,
                33
            ]
        }
    },
    "4fe082c513d9388a3eddd6a857ba576b908b54da": {
        "datetime": "2013-04-11T15:06:22-07:00",
        "summary": "BitPacking up to 31 bits",
        "message": "BitPacking up to 31 bits\n",
        "diff": {
            "parquet-column/src/main/java/parquet/bytes/BytesUtils.java": [
                1,
                24
            ],
            "parquet-column/src/main/java/parquet/column/values/bitpacking/BitPackingGenerator.java": [
                0,
                119
            ],
            "parquet-column/src/main/java/parquet/column/values/bitpacking/LemireBitPacking.java": [
                0,
                3176
            ],
            "parquet-column/src/main/java/parquet/column/values/rle/RLEDecoder.java": [
                2,
                22
            ],
            "parquet-column/src/test/java/parquet/column/values/bitpacking/TestLemireBitPacking.java": [
                0,
                87
            ],
            "parquet-column/src/test/java/parquet/column/values/rle/TestRLE.java": [
                0,
                6
            ]
        }
    },
    "f7a47d3572ccae6467a27503dda2664bb7bd424f": {
        "datetime": "2013-04-12T11:20:52-07:00",
        "summary": "adapt Lemire's scheme to our value ordering",
        "message": "adapt Lemire's scheme to our value ordering\n",
        "diff": {
            "parquet-column/src/main/java/parquet/column/values/bitpacking/BitPackingGenerator.java": [
                12,
                25
            ],
            "parquet-column/src/main/java/parquet/column/values/bitpacking/LemireBitPacking.java": [
                2400,
                2400
            ],
            "parquet-column/src/test/java/parquet/column/values/bitpacking/TestLemireBitPacking.java": [
                1,
                1
            ]
        }
    },
    "f2ff9e854bb8d787203a85fb311c3ae0a9af52c5": {
        "datetime": "2013-04-12T11:22:17-07:00",
        "summary": "add license headers",
        "message": "add license headers\n",
        "diff": {
            "parquet-column/src/main/java/parquet/column/values/bitpacking/BitPackingGenerator.java": [
                0,
                15
            ],
            "parquet-column/src/main/java/parquet/column/values/bitpacking/LemireBitPacking.java": [
                0,
                15
            ],
            "parquet-column/src/main/java/parquet/column/values/plain/BinaryPlainValuesReader.java": [
                0,
                15
            ],
            "parquet-column/src/main/java/parquet/column/values/rle/RLEDecoder.java": [
                0,
                15
            ],
            "parquet-column/src/main/java/parquet/column/values/rle/RLESimpleEncoder.java": [
                0,
                15
            ],
            "parquet-column/src/test/java/parquet/column/values/bitpacking/TestLemireBitPacking.java": [
                0,
                15
            ],
            "parquet-column/src/test/java/parquet/column/values/rle/TestRLE.java": [
                0,
                15
            ]
        }
    },
    "07c56fcb2c8448701d1542c25c9ac2afa28aba5c": {
        "datetime": "2013-04-12T13:31:02-07:00",
        "summary": "add notice",
        "message": "add notice\n",
        "diff": {
            "NOTICE": null,
            "parquet-column/src/main/java/parquet/column/values/bitpacking/BitPackingGenerator.java": [
                0,
                6
            ],
            "parquet-column/src/main/java/parquet/column/values/bitpacking/LemireBitPacking.java": [
                0,
                6
            ]
        }
    },
    "4611c4778027a167f474c777573bbf30aa4a08fa": {
        "datetime": "2013-04-15T11:27:52-07:00",
        "summary": "writer readers for int based packing",
        "message": "writer readers for int based packing\n",
        "diff": {
            "parquet-column/src/main/java/parquet/bytes/BytesInput.java": [
                5,
                15
            ],
            "parquet-column/src/main/java/parquet/column/values/bitpacking/BitPackingGenerator.java": [
                12,
                20
            ],
            "parquet-column/src/main/java/parquet/column/values/bitpacking/BitPackingValuesReader.java": [
                3,
                0
            ],
            "parquet-column/src/main/java/parquet/column/values/bitpacking/BitPackingValuesWriter.java": [
                7,
                1
            ],
            "parquet-column/src/main/java/parquet/column/values/bitpacking/IntBasedBitPackingValuesReader.java": [
                0,
                63
            ],
            "parquet-column/src/main/java/parquet/column/values/bitpacking/IntBasedBitPackingValuesWriter.java": [
                0,
                91
            ],
            "parquet-column/src/main/java/parquet/column/values/bitpacking/IntPacker.java": [
                0,
                19
            ],
            "parquet-column/src/main/java/parquet/column/values/bitpacking/LemireBitPacking.java": [
                54,
                196
            ],
            "parquet-column/src/test/java/parquet/column/values/bitpacking/TestLemireBitPacking.java": [
                4,
                2
            ]
        }
    },
    "a0926f380bacc3eca8afcaa208b8c4734a1e2d45": {
        "datetime": "2013-04-15T12:02:40-07:00",
        "summary": "add both orders as we might want to change our encoding in the future",
        "message": "add both orders as we might want to change our encoding in the future\n",
        "diff": {
            "parquet-column/src/main/java/parquet/column/values/bitpacking/BitPackingGenerator.java": [
                23,
                60
            ],
            "parquet-column/src/main/java/parquet/column/values/bitpacking/IntBasedBitPackingValuesReader.java": [
                0,
                15
            ],
            "parquet-column/src/main/java/parquet/column/values/bitpacking/IntBasedBitPackingValuesWriter.java": [
                0,
                15
            ],
            "parquet-column/src/main/java/parquet/column/values/bitpacking/IntPacker.java": [
                2,
                46
            ],
            "parquet-column/src/main/java/parquet/column/values/bitpacking/LemireBitPackingBE.java": [
                0,
                15
            ],
            "parquet-column/src/main/java/parquet/column/values/bitpacking/LemireBitPackingLE.java": [
                0,
                3353
            ],
            "parquet-column/src/test/java/parquet/column/values/bitpacking/TestLemireBitPacking.java": [
                5,
                14
            ]
        }
    },
    "b0e9609e4850fcf8e0e79a427aa0f079aaf04b10": {
        "datetime": "2013-04-16T10:31:06-07:00",
        "summary": "more tests and bug fixing the Bit packing",
        "message": "more tests and bug fixing the Bit packing\n",
        "diff": {
            "parquet-column/src/main/java/parquet/bytes/BytesInput.java": [
                4,
                13
            ],
            "parquet-column/src/main/java/parquet/column/values/bitpacking/IntBasedBitPackingValuesReader.java": [
                4,
                29
            ],
            "parquet-column/src/main/java/parquet/column/values/bitpacking/IntBasedBitPackingValuesWriter.java": [
                14,
                26
            ],
            "parquet-column/src/main/java/parquet/column/values/bitpacking/LemireBitPackingBE.java": [
                15,
                0
            ],
            "parquet-column/src/main/java/parquet/column/values/bitpacking/LemireBitPackingLE.java": [
                15,
                0
            ],
            "parquet-column/src/test/java/parquet/column/primitive/TestBitPacking.java": [
                3,
                1
            ],
            "parquet-column/src/test/java/parquet/column/primitive/TestBitPackingColumn.java": [
                19,
                43
            ],
            "parquet-column/src/test/java/parquet/column/values/bitpacking/TestLemireBitPacking.java": [
                18,
                19
            ]
        }
    },
    "e3e81597fc03c12515adabfe9c69419024b9403f": {
        "datetime": "2013-04-16T14:40:39-07:00",
        "summary": "make things that look like closeables implement Closeable",
        "message": "make things that look like closeables implement Closeable\n",
        "diff": {
            "parquet-hadoop/src/main/java/parquet/hadoop/ParquetFileReader.java": [
                1,
                3
            ],
            "parquet-thrift/src/main/java/parquet/hadoop/thrift/ThriftToParquetFileWriter.java": [
                3,
                10
            ]
        }
    },
    "ee8c25ea3a73b068c7523bdfd1c4cdddf156e26c": {
        "datetime": "2013-04-16T14:55:50-07:00",
        "summary": "Merge pull request #27 from Parquet/make_closeable",
        "message": "Merge pull request #27 from Parquet/make_closeable\n\nmake things that look like closeables implement Closeable",
        "diff": {
            "parquet-hadoop/src/main/java/parquet/hadoop/ParquetFileReader.java": [
                1,
                3
            ],
            "parquet-thrift/src/main/java/parquet/hadoop/thrift/ThriftToParquetFileWriter.java": [
                3,
                10
            ]
        }
    },
    "bca0411428def0c2abe792d882e8d23461c6a097": {
        "datetime": "2013-04-18T09:21:31-07:00",
        "summary": "Merge branch 'master' of github.com:Parquet/parquet-mr into scrooge_scalding",
        "message": "Merge branch 'master' of github.com:Parquet/parquet-mr into scrooge_scalding\n",
        "diff": {
            "parquet-hadoop/src/main/java/parquet/hadoop/ParquetFileReader.java": [
                1,
                3
            ],
            "parquet-thrift/src/main/java/parquet/hadoop/thrift/ThriftToParquetFileWriter.java": [
                3,
                10
            ]
        }
    },
    "bcdddf76bb16436a62167e82664b1e8bc4f2e0ed": {
        "datetime": "2013-04-19T11:24:23-07:00",
        "summary": "implement byte based batch bit packing",
        "message": "implement byte based batch bit packing\n",
        "diff": {
            "parquet-column/src/main/java/parquet/column/values/bitpacking/BitPackingGenerator.java": [
                2,
                2
            ],
            "parquet-column/src/main/java/parquet/column/values/bitpacking/ByteBasedBitPackingGenerator.java": [
                0,
                229
            ],
            "parquet-column/src/main/java/parquet/column/values/bitpacking/ByteBitPacking.java": [
                0,
                25636
            ],
            "parquet-column/src/main/java/parquet/column/values/bitpacking/BytePacker.java": [
                0,
                83
            ],
            "parquet-column/src/main/java/parquet/column/values/bitpacking/LemireBitPackingBE.java": [
                1,
                16
            ],
            "parquet-column/src/main/java/parquet/column/values/bitpacking/LemireBitPackingLE.java": [
                1,
                16
            ],
            "parquet-column/src/test/java/parquet/column/values/bitpacking/TestByteBitPacking.java": [
                0,
                134
            ]
        }
    },
    "c2bdea0d004103fe74585d42abe3643a62d3da0a": {
        "datetime": "2013-04-19T14:22:09-07:00",
        "summary": "address comments from alex l.",
        "message": "address comments from alex l.\n",
        "diff": {
            "parquet-cascading/src/main/java/parquet/cascading/ParquetTBaseScheme.java": [
                4,
                4
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/ParquetInputFormat.java": [
                5,
                6
            ],
            "parquet-scrooge/src/main/java/parquet/scrooge/ParquetScroogeScheme.java": [
                7,
                4
            ],
            "parquet-scrooge/src/main/java/parquet/scrooge/ScroogeRecordConverter.java": [
                1,
                1
            ],
            "parquet-scrooge/src/test/java/parquet/scrooge/TestScroogeIOFormats.java": [
                5,
                0
            ],
            "parquet-thrift/src/main/java/parquet/hadoop/thrift/ThriftReadSupport.java": [
                1,
                1
            ],
            "parquet-thrift/src/main/java/parquet/thrift/TBaseRecordConverter.java": [
                1,
                1
            ]
        }
    },
    "9942ce175d35708cc7f0586b075bc3467a6a5224": {
        "datetime": "2013-04-19T14:29:42-07:00",
        "summary": "move simple RLE to generated bit packing",
        "message": "move simple RLE to generated bit packing\n",
        "diff": {
            "parquet-column/src/main/java/parquet/column/values/bitpacking/ByteBasedBitPackingEncoder.java": [
                0,
                84
            ],
            "parquet-column/src/main/java/parquet/column/values/bitpacking/ByteBasedBitPackingGenerator.java": [
                1,
                1
            ],
            "parquet-column/src/main/java/parquet/column/values/bitpacking/ByteBitPacking.java": [
                1,
                1
            ],
            "parquet-column/src/main/java/parquet/column/values/rle/RLEDecoder.java": [
                20,
                19
            ],
            "parquet-column/src/main/java/parquet/column/values/rle/RLESimpleEncoder.java": [
                13,
                11
            ],
            "parquet-column/src/test/java/parquet/column/values/bitpacking/TestBitPackingColumn.java": [
                10,
                12
            ],
            "parquet-column/src/test/java/parquet/column/values/rle/TestRLE.java": [
                2,
                10
            ]
        }
    },
    "aa851eb7ca9edd0c364bfe39ec2c2f99c4914d01": {
        "datetime": "2013-04-19T14:35:01-07:00",
        "summary": "remove broken reader/writer",
        "message": "remove broken reader/writer\n",
        "diff": {
            "parquet-column/src/main/java/parquet/column/values/bitpacking/IntBasedBitPackingValuesReader.java": [
                103,
                0
            ],
            "parquet-column/src/main/java/parquet/column/values/bitpacking/IntBasedBitPackingValuesWriter.java": [
                118,
                0
            ],
            "parquet-column/src/test/java/parquet/column/values/bitpacking/TestBitPackingColumn.java": [
                5,
                6
            ]
        }
    },
    "61d5170844aaf611555a0dd63c5e24af08acf1c8": {
        "datetime": "2013-04-19T16:47:58-07:00",
        "summary": "fix bug where a required field would not be created at the right level",
        "message": "fix bug where a required field would not be created at the right level\n",
        "diff": {
            "parquet-column/src/main/java/parquet/io/RecordReaderImplementation.java": [
                3,
                4
            ],
            "parquet-column/src/test/java/parquet/io/TestColumnIO.java": [
                0,
                34
            ]
        }
    },
    "8b69ad5d107946d0a52a30f879ef3f932ba72a32": {
        "datetime": "2013-04-19T23:08:53-07:00",
        "summary": "address comments from @J_",
        "message": "address comments from @J_\n",
        "diff": {
            "parquet-scrooge/pom.xml": null,
            "parquet-scrooge/src/main/java/parquet/scrooge/ScroogeRecordConverter.java": [
                0,
                1
            ],
            "parquet-thrift/src/main/java/parquet/hadoop/thrift/DeprecatedContainerInputFormat.java": [
                0,
                5
            ],
            "parquet-thrift/src/main/java/parquet/hadoop/thrift/ThriftReadSupport.java": [
                1,
                1
            ]
        }
    },
    "1d2164671889e4af8a0a73c36e0290ab75ea7e3e": {
        "datetime": "2013-04-20T01:19:18-07:00",
        "summary": "Merge pull request #29 from Parquet/fix_definition_level_for_nested_required",
        "message": "Merge pull request #29 from Parquet/fix_definition_level_for_nested_required\n\nfix bug where a required field would not be created at the right level",
        "diff": {
            "parquet-column/src/main/java/parquet/io/RecordReaderImplementation.java": [
                3,
                4
            ],
            "parquet-column/src/test/java/parquet/io/TestColumnIO.java": [
                0,
                34
            ]
        }
    },
    "f866bb844c8534c3c14975c185c3df627f640b24": {
        "datetime": "2013-04-22T14:48:01-07:00",
        "summary": "more tests for optional vs required",
        "message": "more tests for optional vs required\n",
        "diff": {
            "parquet-column/src/test/java/parquet/io/TestColumnIO.java": [
                40,
                93
            ]
        }
    },
    "ee4a1b84351ea152a90a5075e29834bbd78521e8": {
        "datetime": "2013-04-22T15:11:55-07:00",
        "summary": "Merge pull request #30 from Parquet/fix_definition_level_for_nested_required",
        "message": "Merge pull request #30 from Parquet/fix_definition_level_for_nested_required\n\nmore tests for optional vs required",
        "diff": {
            "parquet-column/src/test/java/parquet/io/TestColumnIO.java": [
                40,
                93
            ]
        }
    },
    "9d2df1361fb131c21ed5ec7c2a33eb098ae2d5ce": {
        "datetime": "2013-04-22T16:22:56-07:00",
        "summary": "Merge branch 'master' into dictionary_encoding",
        "message": "Merge branch 'master' into dictionary_encoding\n\nConflicts:\n\tparquet-hadoop/src/main/java/parquet/hadoop/ParquetFileReader.java\n",
        "diff": {
            "parquet-column/src/main/java/parquet/io/RecordReaderImplementation.java": [
                3,
                4
            ],
            "parquet-column/src/test/java/parquet/io/TestColumnIO.java": [
                0,
                34
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/ParquetFileReader.java": [
                1,
                3
            ],
            "parquet-thrift/src/main/java/parquet/hadoop/thrift/ThriftToParquetFileWriter.java": [
                3,
                10
            ]
        }
    },
    "d64c883beb9197500ce0922b60462a686435916d": {
        "datetime": "2013-04-23T08:52:31-07:00",
        "summary": "mae dictionary more generic; allow converters to understand dictionaries",
        "message": "mae dictionary more generic; allow converters to understand dictionaries\n",
        "diff": {
            "parquet-column/src/main/java/parquet/column/Dictionary.java": [
                1,
                24
            ],
            "parquet-column/src/main/java/parquet/column/Encoding.java": [
                4,
                8
            ],
            "parquet-column/src/main/java/parquet/column/impl/ColumnReadStoreImpl.java": [
                19,
                73
            ],
            "parquet-column/src/main/java/parquet/column/impl/ColumnReaderImpl.java": [
                2,
                8
            ],
            "parquet-column/src/main/java/parquet/column/values/ValuesReader.java": [
                18,
                11
            ],
            "parquet-column/src/main/java/parquet/column/values/dictionary/DictionaryValuesReader.java": [
                1,
                1
            ],
            "parquet-column/src/main/java/parquet/column/values/dictionary/PlainDictionary.java": [
                3,
                8
            ],
            "parquet-column/src/main/java/parquet/column/values/plain/PlainValuesReader.java": [
                9,
                0
            ],
            "parquet-column/src/main/java/parquet/io/MessageColumnIO.java": [
                1,
                6
            ],
            "parquet-column/src/main/java/parquet/io/api/GroupConverter.java": [
                1,
                22
            ],
            "parquet-column/src/main/java/parquet/io/api/PrimitiveConverter.java": [
                0,
                1
            ],
            "parquet-column/src/test/java/parquet/column/mem/TestMemColumn.java": [
                19,
                30
            ],
            "parquet-column/src/test/java/parquet/column/values/dictionary/TestDictionary.java": [
                2,
                6
            ]
        }
    },
    "feadc9effe3e2814774f128177817f7ffa4f031b": {
        "datetime": "2013-04-23T14:13:56-07:00",
        "summary": "Merge pull request #24 from Parquet/scrooge_scalding",
        "message": "Merge pull request #24 from Parquet/scrooge_scalding\n\nCascading Thrift and Scrooge support",
        "diff": {
            "parquet-cascading/.cache": null,
            "parquet-cascading/pom.xml": null,
            "parquet-cascading/src/main/java/parquet/cascading/ParquetTBaseScheme.java": [
                0,
                67
            ],
            "parquet-cascading/src/main/java/parquet/cascading/ParquetValueScheme.java": [
                0,
                57
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/ParquetInputFormat.java": [
                4,
                10
            ],
            "parquet-scrooge/pom.xml": null,
            "parquet-scrooge/src/main/java/parquet/scrooge/ParquetScroogeScheme.java": [
                0,
                74
            ],
            "parquet-scrooge/src/main/java/parquet/scrooge/ScroogeRecordConverter.java": [
                0,
                54
            ],
            "parquet-thrift/pom.xml": null,
            "parquet-thrift/src/main/java/parquet/hadoop/thrift/Container.java": [
                0,
                34
            ],
            "parquet-thrift/src/main/java/parquet/hadoop/thrift/DeprecatedContainerInputFormat.java": [
                0,
                372
            ],
            "parquet-thrift/src/main/java/parquet/hadoop/thrift/ParquetThriftInputFormat.java": [
                0,
                27
            ],
            "parquet-thrift/src/main/java/parquet/hadoop/thrift/ThriftReadSupport.java": [
                5,
                51
            ],
            "parquet-thrift/src/main/java/parquet/hadoop/thrift/ThriftWriteSupport.java": [
                1,
                1
            ],
            "parquet-thrift/src/main/java/parquet/thrift/TBaseRecordConverter.java": [
                3,
                1
            ],
            "parquet-thrift/src/main/java/parquet/thrift/ThriftMetaData.java": [
                14,
                31
            ],
            "pom.xml": null
        }
    },
    "31b91eec339fccb0d041b80ac6b0a260a0e054c7": {
        "datetime": "2013-04-23T16:55:27-07:00",
        "summary": "address review comments by @squarecog",
        "message": "address review comments by @squarecog\n",
        "diff": {
            "parquet-column/src/main/java/parquet/column/values/bitpacking/IntBasedBitPackingGenerator.java": [
                14,
                17
            ],
            "parquet-column/src/main/java/parquet/column/values/bitpacking/LemireBitPackingBE.java": [
                70,
                69
            ],
            "parquet-column/src/main/java/parquet/column/values/bitpacking/LemireBitPackingLE.java": [
                70,
                69
            ]
        }
    },
    "64c45cbe585d6be1fdc0c4f87e4ac977b5df5eb7": {
        "datetime": "2013-04-24T10:03:03+01:00",
        "summary": "Add test for nested records following fix in 61d5170844aaf611555a0dd63c5e24af08acf1c8",
        "message": "Add test for nested records following fix in 61d5170844aaf611555a0dd63c5e24af08acf1c8\n",
        "diff": {
            "parquet-avro/src/test/java/parquet/avro/TestReadWrite.java": [
                6,
                5
            ],
            "parquet-avro/src/test/resources/all-minus-fixed.avsc": null
        }
    },
    "5121cd599c259d9eda51585a66ca680591398c65": {
        "datetime": "2013-04-24T10:03:03+01:00",
        "summary": "Avoid double conversion of bytes for Avro Utf8 instances.",
        "message": "Avoid double conversion of bytes for Avro Utf8 instances.\n",
        "diff": {
            "parquet-avro/src/main/java/parquet/avro/AvroWriteSupport.java": [
                1,
                10
            ]
        }
    },
    "1605cda914e596b90cd95d1adbc7001ad0557da8": {
        "datetime": "2013-04-24T10:03:03+01:00",
        "summary": "Avoid copying bytes if ByteBuffer is array-based.",
        "message": "Avoid copying bytes if ByteBuffer is array-based.\n",
        "diff": {
            "parquet-column/src/main/java/parquet/io/api/Binary.java": [
                0,
                12
            ]
        }
    },
    "e365840ea62f29a6cca472772bf96bee8b1a4e3c": {
        "datetime": "2013-04-24T10:03:03+01:00",
        "summary": "Create generic Parquet reader and writer for object records.",
        "message": "Create generic Parquet reader and writer for object records.\n",
        "diff": {
            "parquet-avro/src/main/java/parquet/avro/AvroParquetReader.java": [
                52,
                18
            ],
            "parquet-avro/src/main/java/parquet/avro/AvroParquetWriter.java": [
                42,
                19
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/CodecFactory.java": [
                1,
                1
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/ParquetReader.java": [
                0,
                75
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/ParquetWriter.java": [
                0,
                66
            ]
        }
    },
    "58d8c52e91ae45252e388747f0bf17ebc859930e": {
        "datetime": "2013-04-24T10:03:03+01:00",
        "summary": "Remove incorrect record initialization to compensate for broken support for nested records (not yet fixed).",
        "message": "Remove incorrect record initialization to compensate for broken support for nested records (not yet fixed).\n",
        "diff": {
            "parquet-avro/src/main/java/parquet/avro/AvroGenericRecordConverter.java": [
                1,
                0
            ],
            "parquet-avro/src/test/java/parquet/avro/TestReadWrite.java": [
                5,
                5
            ],
            "parquet-avro/src/test/resources/all-minus-fixed.avsc": null
        }
    },
    "e47f3b13a69672bebecb6928360dcd38aa8657b6": {
        "datetime": "2013-04-24T10:03:03+01:00",
        "summary": "Fix creation of arrays and maps in converters.",
        "message": "Fix creation of arrays and maps in converters.\n",
        "diff": {
            "parquet-avro/src/main/java/parquet/avro/AvroGenericRecordConverter.java": [
                7,
                14
            ]
        }
    },
    "11bb824716f757ed1d69405fb0c5821975a606fd": {
        "datetime": "2013-04-24T10:03:03+01:00",
        "summary": "Remove unnecessary level of grouping for array.",
        "message": "Remove unnecessary level of grouping for array.\n",
        "diff": {
            "parquet-avro/src/main/java/parquet/avro/AvroGenericRecordConverter.java": [
                10,
                2
            ],
            "parquet-avro/src/main/java/parquet/avro/AvroSchemaConverter.java": [
                2,
                1
            ],
            "parquet-avro/src/main/java/parquet/avro/AvroWriteSupport.java": [
                8,
                1
            ],
            "parquet-avro/src/test/java/parquet/avro/TestAvroSchemaConverter.java": [
                3,
                1
            ]
        }
    },
    "568bd7f60ffa0fa75071c4ac1675bcc1519c0c00": {
        "datetime": "2013-04-24T10:03:03+01:00",
        "summary": "Add Binary.fromByteBuffer method.",
        "message": "Add Binary.fromByteBuffer method.\n",
        "diff": {
            "parquet-avro/src/main/java/parquet/avro/AvroWriteSupport.java": [
                4,
                1
            ],
            "parquet-column/src/main/java/parquet/io/api/Binary.java": [
                0,
                49
            ]
        }
    },
    "61a163d31b1fd9aac7443fc547aeb6cc73089e62": {
        "datetime": "2013-04-24T10:03:03+01:00",
        "summary": "Honor repetitions correctly.",
        "message": "Honor repetitions correctly.\n",
        "diff": {
            "parquet-avro/src/main/java/parquet/avro/AvroSchemaConverter.java": [
                25,
                8
            ]
        }
    },
    "42c38a1e016b9fc7d280012a237101a1a2d5a0be": {
        "datetime": "2013-04-24T10:03:03+01:00",
        "summary": "Remove unchecked generics warnings.",
        "message": "Remove unchecked generics warnings.\n",
        "diff": {
            "parquet-avro/src/main/java/parquet/avro/AvroGenericRecordConverter.java": [
                11,
                12
            ],
            "parquet-avro/src/main/java/parquet/avro/AvroWriteSupport.java": [
                6,
                8
            ],
            "parquet-avro/src/test/java/parquet/avro/TestReadWrite.java": [
                2,
                2
            ],
            "pom.xml": null
        }
    },
    "02b283dbd3c44206ca31e2fcd0bfebe6949ef4be": {
        "datetime": "2013-04-24T10:03:03+01:00",
        "summary": "Initial support for Avro.",
        "message": "Initial support for Avro.\n",
        "diff": {
            "parquet-avro/pom.xml": null,
            "parquet-avro/src/main/java/parquet/avro/AvroGenericRecordConverter.java": [
                0,
                358
            ],
            "parquet-avro/src/main/java/parquet/avro/AvroParquetInputFormat.java": [
                0,
                14
            ],
            "parquet-avro/src/main/java/parquet/avro/AvroParquetOutputFormat.java": [
                0,
                22
            ],
            "parquet-avro/src/main/java/parquet/avro/AvroParquetReader.java": [
                0,
                65
            ],
            "parquet-avro/src/main/java/parquet/avro/AvroParquetWriter.java": [
                0,
                57
            ],
            "parquet-avro/src/main/java/parquet/avro/AvroReadSupport.java": [
                0,
                28
            ],
            "parquet-avro/src/main/java/parquet/avro/AvroRecordMaterializer.java": [
                0,
                26
            ],
            "parquet-avro/src/main/java/parquet/avro/AvroSchemaConverter.java": [
                0,
                136
            ],
            "parquet-avro/src/main/java/parquet/avro/AvroWriteSupport.java": [
                0,
                163
            ],
            "parquet-avro/src/main/java/parquet/avro/package-info.java": [
                0,
                74
            ],
            "parquet-avro/src/test/java/parquet/avro/TestAvroSchemaConverter.java": [
                0,
                89
            ],
            "parquet-avro/src/test/java/parquet/avro/TestInputOutputFormat.java": [
                0,
                137
            ],
            "parquet-avro/src/test/java/parquet/avro/TestReadWrite.java": [
                0,
                78
            ],
            "parquet-avro/src/test/resources/all-minus-fixed.avsc": null,
            "parquet-avro/src/test/resources/all.avsc": null,
            "parquet-hadoop/src/main/java/parquet/hadoop/CodecFactory.java": [
                1,
                1
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/ParquetRecordReader.java": [
                1,
                1
            ],
            "pom.xml": null
        }
    },
    "80adbcd69eae03a1f206264654afba9dffb5abe3": {
        "datetime": "2013-04-24T10:03:04+01:00",
        "summary": "Remove -Xlint:unchecked flag from the build for the moment as it causes CI to fail.",
        "message": "Remove -Xlint:unchecked flag from the build for the moment as it causes CI to fail.\n",
        "diff": {
            "pom.xml": null
        }
    },
    "d3c1a34f3297146695c6cf30a67e56e8b8fbdbc7": {
        "datetime": "2013-04-24T10:39:21+01:00",
        "summary": "Fix compilation with Java 6.",
        "message": "Fix compilation with Java 6.\n",
        "diff": {
            "parquet-cascading/src/main/java/parquet/cascading/ParquetTBaseScheme.java": [
                1,
                1
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/ParquetInputFormat.java": [
                5,
                4
            ],
            "parquet-scrooge/src/main/java/parquet/scrooge/ParquetScroogeScheme.java": [
                1,
                1
            ]
        }
    },
    "34ce9248f9db1f2fb819b66927acfddd138b0626": {
        "datetime": "2013-04-24T09:55:26-07:00",
        "summary": "Merge pull request #26 from tomwhite/avro",
        "message": "Merge pull request #26 from tomwhite/avro\n\nInitial support for Avro.\r\nThanks @tomwhite ",
        "diff": {
            "parquet-avro/pom.xml": null,
            "parquet-avro/src/main/java/parquet/avro/AvroGenericRecordConverter.java": [
                0,
                357
            ],
            "parquet-avro/src/main/java/parquet/avro/AvroParquetInputFormat.java": [
                0,
                14
            ],
            "parquet-avro/src/main/java/parquet/avro/AvroParquetOutputFormat.java": [
                0,
                22
            ],
            "parquet-avro/src/main/java/parquet/avro/AvroParquetReader.java": [
                0,
                31
            ],
            "parquet-avro/src/main/java/parquet/avro/AvroParquetWriter.java": [
                0,
                34
            ],
            "parquet-avro/src/main/java/parquet/avro/AvroReadSupport.java": [
                0,
                28
            ],
            "parquet-avro/src/main/java/parquet/avro/AvroRecordMaterializer.java": [
                0,
                26
            ],
            "parquet-avro/src/main/java/parquet/avro/AvroSchemaConverter.java": [
                0,
                118
            ],
            "parquet-avro/src/main/java/parquet/avro/AvroWriteSupport.java": [
                0,
                164
            ],
            "parquet-avro/src/main/java/parquet/avro/package-info.java": [
                0,
                74
            ],
            "parquet-avro/src/test/java/parquet/avro/TestAvroSchemaConverter.java": [
                0,
                87
            ],
            "parquet-avro/src/test/java/parquet/avro/TestInputOutputFormat.java": [
                0,
                137
            ],
            "parquet-avro/src/test/java/parquet/avro/TestReadWrite.java": [
                0,
                77
            ],
            "parquet-avro/src/test/resources/all-minus-fixed.avsc": null,
            "parquet-avro/src/test/resources/all.avsc": null,
            "parquet-column/src/main/java/parquet/io/api/Binary.java": [
                0,
                61
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/ParquetReader.java": [
                0,
                75
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/ParquetRecordReader.java": [
                1,
                1
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/ParquetWriter.java": [
                0,
                66
            ],
            "pom.xml": null
        }
    },
    "a5d72a44117e7263c0e39be8ffcf5992f4e45b89": {
        "datetime": "2013-04-24T09:55:54-07:00",
        "summary": "Merge pull request #31 from tomwhite/java6-compilation-fixes",
        "message": "Merge pull request #31 from tomwhite/java6-compilation-fixes\n\nFix compilation with Java 6.\r\nThanks @tomwhite",
        "diff": {
            "parquet-cascading/src/main/java/parquet/cascading/ParquetTBaseScheme.java": [
                1,
                1
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/ParquetInputFormat.java": [
                5,
                4
            ],
            "parquet-scrooge/src/main/java/parquet/scrooge/ParquetScroogeScheme.java": [
                1,
                1
            ]
        }
    },
    "19e0902b3c17ef1e163b429d114f8541139863ac": {
        "datetime": "2013-04-25T12:44:41-07:00",
        "summary": "make converters dictionary aware",
        "message": "make converters dictionary aware\n",
        "diff": {
            "parquet-column/src/main/java/parquet/Log.java": [
                1,
                1
            ],
            "parquet-column/src/main/java/parquet/column/ColumnReader.java": [
                3,
                8
            ],
            "parquet-column/src/main/java/parquet/column/Dictionary.java": [
                1,
                1
            ],
            "parquet-column/src/main/java/parquet/column/Encoding.java": [
                3,
                21
            ],
            "parquet-column/src/main/java/parquet/column/impl/ColumnReadStoreImpl.java": [
                194,
                1
            ],
            "parquet-column/src/main/java/parquet/column/impl/ColumnReaderImpl.java": [
                36,
                225
            ],
            "parquet-column/src/main/java/parquet/column/page/DictionaryPage.java": [
                0,
                7
            ],
            "parquet-column/src/main/java/parquet/column/page/PageReader.java": [
                1,
                1
            ],
            "parquet-column/src/main/java/parquet/column/values/ValuesReader.java": [
                7,
                6
            ],
            "parquet-column/src/main/java/parquet/column/values/ValuesWriter.java": [
                1,
                0
            ],
            "parquet-column/src/main/java/parquet/column/values/dictionary/DictionaryValuesReader.java": [
                3,
                18
            ],
            "parquet-column/src/main/java/parquet/column/values/dictionary/DictionaryValuesWriter.java": [
                2,
                8
            ],
            "parquet-column/src/main/java/parquet/io/RecordReaderImplementation.java": [
                1,
                1
            ],
            "parquet-column/src/main/java/parquet/io/api/GroupConverter.java": [
                20,
                0
            ],
            "parquet-column/src/main/java/parquet/io/api/PrimitiveConverter.java": [
                7,
                27
            ],
            "parquet-column/src/main/java/parquet/schema/PrimitiveType.java": [
                7,
                68
            ],
            "parquet-column/src/test/java/parquet/column/page/mem/MemPageReader.java": [
                14,
                5
            ],
            "parquet-column/src/test/java/parquet/column/page/mem/MemPageStore.java": [
                1,
                1
            ],
            "parquet-column/src/test/java/parquet/column/page/mem/MemPageWriter.java": [
                5,
                8
            ],
            "parquet-column/src/test/java/parquet/column/values/dictionary/TestDictionary.java": [
                10,
                10
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/ColumnChunkPageReadStore.java": [
                8,
                7
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/ColumnChunkPageWriteStore.java": [
                13,
                10
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/ParquetFileReader.java": [
                3,
                6
            ],
            "parquet-pig/src/main/java/parquet/pig/convert/TupleConverter.java": [
                1,
                25
            ]
        }
    },
    "aed56c954fba19095fd622cfaa39341b9a22c9c6": {
        "datetime": "2013-04-25T14:30:47-07:00",
        "summary": "integrate the new bit packing for perf",
        "message": "integrate the new bit packing for perf\n",
        "diff": {
            "parquet-column/src/main/java/parquet/bytes/BytesUtils.java": [
                0,
                8
            ],
            "parquet-column/src/main/java/parquet/column/Encoding.java": [
                2,
                2
            ],
            "parquet-column/src/main/java/parquet/column/impl/ColumnWriterImpl.java": [
                3,
                3
            ],
            "parquet-column/src/main/java/parquet/column/values/bitpacking/BitPackingValuesReader.java": [
                2,
                1
            ],
            "parquet-column/src/main/java/parquet/column/values/bitpacking/ByteBasedBitPackingEncoder.java": [
                2,
                35
            ],
            "parquet-column/src/main/java/parquet/column/values/bitpacking/ByteBasedBitPackingGenerator.java": [
                1,
                2
            ],
            "parquet-column/src/main/java/parquet/column/values/bitpacking/ByteBitPackingValuesReader.java": [
                0,
                54
            ],
            "parquet-column/src/main/java/parquet/column/values/bitpacking/ByteBitPackingValuesWriter.java": [
                0,
                61
            ],
            "parquet-column/src/main/java/parquet/column/values/bitpacking/BytePacker.java": [
                1,
                1
            ],
            "parquet-column/src/main/java/parquet/column/values/bitpacking/IntBasedBitPackingGenerator.java": [
                0,
                1
            ],
            "parquet-column/src/main/java/parquet/column/values/bitpacking/IntPacker.java": [
                0,
                0
            ],
            "parquet-column/src/test/java/parquet/TestLog.java": [
                0,
                13
            ],
            "parquet-column/src/test/java/parquet/column/values/bitpacking/BitPackingPerfTest.java": [
                0,
                85
            ],
            "parquet-column/src/test/java/parquet/column/values/bitpacking/TestBitPackingColumn.java": [
                10,
                9
            ]
        }
    },
    "133d845b497c6b9cc662a06405128c7ccf06a110": {
        "datetime": "2013-04-25T14:54:52-07:00",
        "summary": "Merge branch 'master' into rle",
        "message": "Merge branch 'master' into rle\n",
        "diff": {
            "parquet-cascading/.cache": null,
            "parquet-cascading/pom.xml": null,
            "parquet-cascading/src/main/java/parquet/cascading/ParquetTBaseScheme.java": [
                0,
                67
            ],
            "parquet-cascading/src/main/java/parquet/cascading/ParquetValueScheme.java": [
                0,
                57
            ],
            "parquet-column/src/main/java/parquet/io/RecordReaderImplementation.java": [
                3,
                4
            ],
            "parquet-column/src/test/java/parquet/io/TestColumnIO.java": [
                22,
                109
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/ParquetFileReader.java": [
                1,
                3
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/ParquetInputFormat.java": [
                4,
                10
            ],
            "parquet-scrooge/pom.xml": null,
            "parquet-scrooge/src/main/java/parquet/scrooge/ParquetScroogeScheme.java": [
                0,
                74
            ],
            "parquet-scrooge/src/main/java/parquet/scrooge/ScroogeRecordConverter.java": [
                0,
                54
            ],
            "parquet-thrift/pom.xml": null,
            "parquet-thrift/src/main/java/parquet/hadoop/thrift/Container.java": [
                0,
                34
            ],
            "parquet-thrift/src/main/java/parquet/hadoop/thrift/DeprecatedContainerInputFormat.java": [
                0,
                372
            ],
            "parquet-thrift/src/main/java/parquet/hadoop/thrift/ParquetThriftInputFormat.java": [
                0,
                27
            ],
            "parquet-thrift/src/main/java/parquet/hadoop/thrift/ThriftReadSupport.java": [
                5,
                51
            ],
            "parquet-thrift/src/main/java/parquet/hadoop/thrift/ThriftToParquetFileWriter.java": [
                3,
                10
            ],
            "parquet-thrift/src/main/java/parquet/hadoop/thrift/ThriftWriteSupport.java": [
                1,
                1
            ],
            "parquet-thrift/src/main/java/parquet/thrift/TBaseRecordConverter.java": [
                3,
                1
            ],
            "parquet-thrift/src/main/java/parquet/thrift/ThriftMetaData.java": [
                14,
                31
            ],
            "pom.xml": null
        }
    },
    "a3e8963cb4ea88523a74105491a7db59f30b034c": {
        "datetime": "2013-04-25T14:56:14-07:00",
        "summary": "Merge branch 'rle' into dictionary_encoding",
        "message": "Merge branch 'rle' into dictionary_encoding\n\nConflicts:\n\tparquet-column/src/main/java/parquet/column/impl/ColumnWriterImpl.java\n",
        "diff": {
            "NOTICE": null,
            "parquet-cascading/.cache": null,
            "parquet-cascading/pom.xml": null,
            "parquet-cascading/src/main/java/parquet/cascading/ParquetTBaseScheme.java": [
                0,
                67
            ],
            "parquet-cascading/src/main/java/parquet/cascading/ParquetValueScheme.java": [
                0,
                57
            ],
            "parquet-column/src/main/java/parquet/bytes/BytesInput.java": [
                11,
                30
            ],
            "parquet-column/src/main/java/parquet/bytes/BytesUtils.java": [
                1,
                32
            ],
            "parquet-column/src/main/java/parquet/column/Encoding.java": [
                2,
                2
            ],
            "parquet-column/src/main/java/parquet/column/impl/ColumnWriterImpl.java": [
                3,
                3
            ],
            "parquet-column/src/main/java/parquet/column/values/bitpacking/BitPackingValuesReader.java": [
                5,
                1
            ],
            "parquet-column/src/main/java/parquet/column/values/bitpacking/BitPackingValuesWriter.java": [
                7,
                1
            ],
            "parquet-column/src/main/java/parquet/column/values/bitpacking/ByteBasedBitPackingEncoder.java": [
                0,
                117
            ],
            "parquet-column/src/main/java/parquet/column/values/bitpacking/ByteBasedBitPackingGenerator.java": [
                0,
                230
            ],
            "parquet-column/src/main/java/parquet/column/values/bitpacking/ByteBitPacking.java": [
                0,
                25636
            ],
            "parquet-column/src/main/java/parquet/column/values/bitpacking/ByteBitPackingValuesReader.java": [
                0,
                54
            ],
            "parquet-column/src/main/java/parquet/column/values/bitpacking/ByteBitPackingValuesWriter.java": [
                0,
                61
            ],
            "parquet-column/src/main/java/parquet/column/values/bitpacking/BytePacker.java": [
                0,
                83
            ],
            "parquet-column/src/main/java/parquet/column/values/bitpacking/IntBasedBitPackingGenerator.java": [
                0,
                202
            ],
            "parquet-column/src/main/java/parquet/column/values/bitpacking/IntPacker.java": [
                0,
                63
            ],
            "parquet-column/src/main/java/parquet/column/values/bitpacking/LemireBitPackingBE.java": [
                0,
                3353
            ],
            "parquet-column/src/main/java/parquet/column/values/bitpacking/LemireBitPackingLE.java": [
                0,
                3352
            ],
            "parquet-column/src/main/java/parquet/column/values/plain/BinaryPlainValuesReader.java": [
                0,
                15
            ],
            "parquet-column/src/main/java/parquet/column/values/rle/RLEDecoder.java": [
                0,
                104
            ],
            "parquet-column/src/main/java/parquet/column/values/rle/RLESimpleEncoder.java": [
                0,
                54
            ],
            "parquet-column/src/test/java/parquet/TestLog.java": [
                0,
                13
            ],
            "parquet-column/src/test/java/parquet/column/primitive/TestBitPacking.java": [
                3,
                1
            ],
            "parquet-column/src/test/java/parquet/column/primitive/TestBitPackingColumn.java": [
                18,
                44
            ],
            "parquet-column/src/test/java/parquet/column/values/bitpacking/BitPackingPerfTest.java": [
                0,
                85
            ],
            "parquet-column/src/test/java/parquet/column/values/bitpacking/TestByteBitPacking.java": [
                0,
                134
            ],
            "parquet-column/src/test/java/parquet/column/values/bitpacking/TestLemireBitPacking.java": [
                0,
                110
            ],
            "parquet-column/src/test/java/parquet/column/values/rle/TestRLE.java": [
                0,
                62
            ],
            "parquet-column/src/test/java/parquet/io/TestColumnIO.java": [
                40,
                93
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/ParquetInputFormat.java": [
                4,
                10
            ],
            "parquet-scrooge/pom.xml": null,
            "parquet-scrooge/src/main/java/parquet/scrooge/ParquetScroogeScheme.java": [
                0,
                74
            ],
            "parquet-scrooge/src/main/java/parquet/scrooge/ScroogeRecordConverter.java": [
                0,
                54
            ],
            "parquet-thrift/pom.xml": null,
            "parquet-thrift/src/main/java/parquet/hadoop/thrift/Container.java": [
                0,
                34
            ],
            "parquet-thrift/src/main/java/parquet/hadoop/thrift/DeprecatedContainerInputFormat.java": [
                0,
                372
            ],
            "parquet-thrift/src/main/java/parquet/hadoop/thrift/ParquetThriftInputFormat.java": [
                0,
                27
            ],
            "parquet-thrift/src/main/java/parquet/hadoop/thrift/ThriftReadSupport.java": [
                5,
                51
            ],
            "parquet-thrift/src/main/java/parquet/hadoop/thrift/ThriftWriteSupport.java": [
                1,
                1
            ],
            "parquet-thrift/src/main/java/parquet/thrift/TBaseRecordConverter.java": [
                3,
                1
            ],
            "parquet-thrift/src/main/java/parquet/thrift/ThriftMetaData.java": [
                14,
                31
            ],
            "pom.xml": null
        }
    },
    "67a357741b65cd087836cc2230ded57c1f4850d7": {
        "datetime": "2013-04-25T15:07:38-07:00",
        "summary": "make field private; add braces for one line if statements",
        "message": "make field private; add braces for one line if statements\n",
        "diff": {
            "parquet-column/src/main/java/parquet/bytes/BytesInput.java": [
                1,
                1
            ],
            "parquet-column/src/main/java/parquet/bytes/BytesUtils.java": [
                4,
                8
            ]
        }
    },
    "999b214297a9ce4cb7558fe598de04b5a2e9bb16": {
        "datetime": "2013-04-25T15:23:23-07:00",
        "summary": "use BytesUtils.paddedByteCountFromBits everywhere",
        "message": "use BytesUtils.paddedByteCountFromBits everywhere\n",
        "diff": {
            "parquet-column/src/main/java/parquet/column/values/bitpacking/BitPacking.java": [
                1,
                2
            ],
            "parquet-column/src/main/java/parquet/column/values/bitpacking/BitPackingValuesReader.java": [
                1,
                2
            ],
            "parquet-column/src/main/java/parquet/column/values/bitpacking/ByteBasedBitPackingEncoder.java": [
                2,
                3
            ],
            "parquet-column/src/main/java/parquet/column/values/bitpacking/ByteBasedBitPackingGenerator.java": [
                1,
                3
            ],
            "parquet-column/src/main/java/parquet/column/values/bitpacking/ByteBitPackingValuesReader.java": [
                0,
                15
            ],
            "parquet-column/src/main/java/parquet/column/values/bitpacking/ByteBitPackingValuesWriter.java": [
                0,
                15
            ],
            "parquet-column/src/main/java/parquet/column/values/rle/RLEDecoder.java": [
                1,
                1
            ],
            "parquet-column/src/main/java/parquet/column/values/rle/RLESimpleEncoder.java": [
                1,
                1
            ],
            "parquet-column/src/test/java/parquet/TestLog.java": [
                0,
                15
            ],
            "parquet-column/src/test/java/parquet/column/values/bitpacking/BitPackingPerfTest.java": [
                0,
                15
            ]
        }
    },
    "b125deea4849d3001616f426e4fa770e7e8d020e": {
        "datetime": "2013-04-25T15:27:58-07:00",
        "summary": "make initial capacity a constant",
        "message": "make initial capacity a constant\n",
        "diff": {
            "parquet-column/src/main/java/parquet/column/values/bitpacking/BitPackingValuesWriter.java": [
                1,
                3
            ]
        }
    },
    "7cb782c35ea463da541f94576634850c58a50f34": {
        "datetime": "2013-04-25T16:33:31-07:00",
        "summary": "make a constant for constant value; remove outragous System.out.println()",
        "message": "make a constant for constant value; remove outragous System.out.println()\n",
        "diff": {
            "parquet-column/src/main/java/parquet/column/values/bitpacking/ByteBitPackingValuesReader.java": [
                4,
                5
            ]
        }
    },
    "e5484323922826f66c22e5d5d4b2dae0fe521b42": {
        "datetime": "2013-04-25T16:38:35-07:00",
        "summary": "add new line",
        "message": "add new line\n",
        "diff": {
            "parquet-column/src/main/java/parquet/column/values/bitpacking/BytePacker.java": [
                0,
                0
            ]
        }
    },
    "4c11b6625d1098345f2180aaba0efaa9cec6c69d": {
        "datetime": "2013-04-26T08:27:06-07:00",
        "summary": "typo",
        "message": "typo\n",
        "diff": {
            "parquet-column/src/main/java/parquet/column/values/dictionary/DictionaryValuesWriter.java": [
                1,
                1
            ]
        }
    },
    "280cea3b157181f4cad8cef9ddb69618caa3f5a8": {
        "datetime": "2013-04-26T10:57:30-07:00",
        "summary": "make the API treat empty fields the same as missing fields to avoid confusion",
        "message": "make the API treat empty fields the same as missing fields to avoid confusion\n",
        "diff": {
            "parquet-column/src/main/java/parquet/io/MessageColumnIO.java": [
                23,
                29
            ],
            "parquet-column/src/test/java/parquet/io/ExpectationValidatingConverter.java": [
                0,
                6
            ],
            "parquet-column/src/test/java/parquet/io/TestColumnIO.java": [
                5,
                33
            ]
        }
    },
    "1db1018e696a3be8ea4167b966b774ae87386578": {
        "datetime": "2013-04-26T11:01:06-07:00",
        "summary": "turn on validation for generate TPCH",
        "message": "turn on validation for generate TPCH\n",
        "diff": {
            "parquet-pig/src/test/java/parquet/pig/GenerateTPCH.java": [
                1,
                1
            ]
        }
    },
    "3f0975142a81b681e61195b4df7aa372d8c16ee9": {
        "datetime": "2013-04-26T14:21:13-07:00",
        "summary": "making empty fields illegal",
        "message": "making empty fields illegal\n",
        "diff": {
            "parquet-column/src/main/java/parquet/io/MessageColumnIO.java": [
                2,
                2
            ],
            "parquet-column/src/test/java/parquet/io/TestColumnIO.java": [
                15,
                7
            ],
            "parquet-pig/src/test/java/parquet/pig/GenerateTPCH.java": [
                2,
                2
            ],
            "parquet-thrift/src/main/java/parquet/thrift/ParquetProtocol.java": [
                42,
                56
            ],
            "parquet-thrift/src/main/java/parquet/thrift/TBaseRecordConverter.java": [
                7,
                10
            ],
            "parquet-thrift/src/test/java/parquet/hadoop/thrift/TestInputOutputFormat.java": [
                1,
                1
            ],
            "parquet-thrift/src/test/java/parquet/thrift/TestParquetReadProtocol.java": [
                1,
                1
            ]
        }
    },
    "7c0f1a6779e49166d2925b6afebabb58cb81bb9e": {
        "datetime": "2013-04-26T14:41:19-07:00",
        "summary": "rename fromSequence to concat",
        "message": "rename fromSequence to concat\n",
        "diff": {
            "parquet-column/src/main/java/parquet/bytes/BytesInput.java": [
                2,
                2
            ],
            "parquet-column/src/main/java/parquet/column/impl/ColumnWriterImpl.java": [
                1,
                3
            ],
            "parquet-column/src/main/java/parquet/column/values/bitpacking/ByteBasedBitPackingEncoder.java": [
                4,
                3
            ],
            "parquet-column/src/main/java/parquet/column/values/boundedint/BoundedIntValuesWriter.java": [
                1,
                2
            ],
            "parquet-column/src/main/java/parquet/column/values/rle/RLESimpleEncoder.java": [
                4,
                3
            ]
        }
    },
    "5db276f1a6b5132b9c19936bc17f9aa73c36012e": {
        "datetime": "2013-04-26T14:43:39-07:00",
        "summary": "cleanup import",
        "message": "cleanup import\n",
        "diff": {
            "parquet-column/src/main/java/parquet/column/impl/ColumnWriterImpl.java": [
                1,
                0
            ]
        }
    },
    "05505456e6db07603559c2d02233077889a249cf": {
        "datetime": "2013-04-26T14:43:44-07:00",
        "summary": "Merge branch 'master' into rle",
        "message": "Merge branch 'master' into rle\n",
        "diff": {
            "parquet-avro/pom.xml": null,
            "parquet-avro/src/main/java/parquet/avro/AvroGenericRecordConverter.java": [
                0,
                357
            ],
            "parquet-avro/src/main/java/parquet/avro/AvroParquetInputFormat.java": [
                0,
                14
            ],
            "parquet-avro/src/main/java/parquet/avro/AvroParquetOutputFormat.java": [
                0,
                22
            ],
            "parquet-avro/src/main/java/parquet/avro/AvroParquetReader.java": [
                0,
                31
            ],
            "parquet-avro/src/main/java/parquet/avro/AvroParquetWriter.java": [
                0,
                34
            ],
            "parquet-avro/src/main/java/parquet/avro/AvroReadSupport.java": [
                0,
                28
            ],
            "parquet-avro/src/main/java/parquet/avro/AvroRecordMaterializer.java": [
                0,
                26
            ],
            "parquet-avro/src/main/java/parquet/avro/AvroSchemaConverter.java": [
                0,
                118
            ],
            "parquet-avro/src/main/java/parquet/avro/AvroWriteSupport.java": [
                0,
                164
            ],
            "parquet-avro/src/main/java/parquet/avro/package-info.java": [
                0,
                74
            ],
            "parquet-avro/src/test/java/parquet/avro/TestAvroSchemaConverter.java": [
                0,
                87
            ],
            "parquet-avro/src/test/java/parquet/avro/TestInputOutputFormat.java": [
                0,
                137
            ],
            "parquet-avro/src/test/java/parquet/avro/TestReadWrite.java": [
                0,
                77
            ],
            "parquet-avro/src/test/resources/all-minus-fixed.avsc": null,
            "parquet-avro/src/test/resources/all.avsc": null,
            "parquet-cascading/src/main/java/parquet/cascading/ParquetTBaseScheme.java": [
                1,
                1
            ],
            "parquet-column/src/main/java/parquet/io/api/Binary.java": [
                0,
                61
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/ParquetInputFormat.java": [
                5,
                4
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/ParquetReader.java": [
                0,
                75
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/ParquetRecordReader.java": [
                1,
                1
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/ParquetWriter.java": [
                0,
                66
            ],
            "parquet-scrooge/src/main/java/parquet/scrooge/ParquetScroogeScheme.java": [
                1,
                1
            ],
            "pom.xml": null
        }
    },
    "43dcb039476577743c62a0cb8f1ba18b0fff225c": {
        "datetime": "2013-04-26T15:49:17-07:00",
        "summary": "Merge branch 'master' into dictionary_encoding",
        "message": "Merge branch 'master' into dictionary_encoding\n",
        "diff": {
            "parquet-avro/pom.xml": null,
            "parquet-avro/src/main/java/parquet/avro/AvroGenericRecordConverter.java": [
                0,
                357
            ],
            "parquet-avro/src/main/java/parquet/avro/AvroParquetInputFormat.java": [
                0,
                14
            ],
            "parquet-avro/src/main/java/parquet/avro/AvroParquetOutputFormat.java": [
                0,
                22
            ],
            "parquet-avro/src/main/java/parquet/avro/AvroParquetReader.java": [
                0,
                31
            ],
            "parquet-avro/src/main/java/parquet/avro/AvroParquetWriter.java": [
                0,
                34
            ],
            "parquet-avro/src/main/java/parquet/avro/AvroReadSupport.java": [
                0,
                28
            ],
            "parquet-avro/src/main/java/parquet/avro/AvroRecordMaterializer.java": [
                0,
                26
            ],
            "parquet-avro/src/main/java/parquet/avro/AvroSchemaConverter.java": [
                0,
                118
            ],
            "parquet-avro/src/main/java/parquet/avro/AvroWriteSupport.java": [
                0,
                164
            ],
            "parquet-avro/src/main/java/parquet/avro/package-info.java": [
                0,
                74
            ],
            "parquet-avro/src/test/java/parquet/avro/TestAvroSchemaConverter.java": [
                0,
                87
            ],
            "parquet-avro/src/test/java/parquet/avro/TestInputOutputFormat.java": [
                0,
                137
            ],
            "parquet-avro/src/test/java/parquet/avro/TestReadWrite.java": [
                0,
                77
            ],
            "parquet-avro/src/test/resources/all-minus-fixed.avsc": null,
            "parquet-avro/src/test/resources/all.avsc": null,
            "parquet-cascading/src/main/java/parquet/cascading/ParquetTBaseScheme.java": [
                1,
                1
            ],
            "parquet-column/src/main/java/parquet/io/api/Binary.java": [
                0,
                61
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/ParquetInputFormat.java": [
                5,
                4
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/ParquetReader.java": [
                0,
                75
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/ParquetRecordReader.java": [
                1,
                1
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/ParquetWriter.java": [
                0,
                66
            ],
            "parquet-scrooge/src/main/java/parquet/scrooge/ParquetScroogeScheme.java": [
                1,
                1
            ],
            "pom.xml": null
        }
    },
    "6b867e502c1b9cfe6b10e1e7387d93ef2969e7e4": {
        "datetime": "2013-04-27T17:08:48-07:00",
        "summary": "skeleton for an efficient converter from groups to cascading tuples",
        "message": "skeleton for an efficient converter from groups to cascading tuples\n",
        "diff": {
            "parquet-cascading/src/main/java/parquet/cascading/FilterSchema.java": [
                0,
                16
            ],
            "parquet-cascading/src/main/java/parquet/cascading/ParquetTupleScheme.java": [
                0,
                95
            ],
            "parquet-cascading/src/main/java/parquet/cascading/TupleReadSupport.java": [
                0,
                58
            ],
            "parquet-cascading/src/main/java/parquet/cascading/convert/TupleConverter.java": [
                0,
                97
            ],
            "parquet-cascading/src/main/java/parquet/cascading/convert/TupleRecordMaterializer.java": [
                0,
                28
            ]
        }
    },
    "065a3c90673a7b3eae9165db0c4f0786372153dd": {
        "datetime": "2013-04-27T22:06:25-07:00",
        "summary": "working selective tuple materialization for cascading",
        "message": "working selective tuple materialization for cascading\n",
        "diff": {
            "parquet-cascading/pom.xml": null,
            "parquet-cascading/src/main/java/parquet/cascading/FilterSchema.java": [
                16,
                0
            ],
            "parquet-cascading/src/main/java/parquet/cascading/ParquetTupleScheme.java": [
                9,
                18
            ],
            "parquet-cascading/src/main/java/parquet/cascading/SchemaIntersection.java": [
                0,
                42
            ],
            "parquet-cascading/src/main/java/parquet/cascading/TupleReadSupport.java": [
                16,
                20
            ],
            "parquet-cascading/src/main/java/parquet/cascading/convert/TupleConverter.java": [
                1,
                1
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/ParquetFileReader.java": [
                0,
                14
            ]
        }
    },
    "593a105cea2faa01849240e140a6f9fd03bd31f7": {
        "datetime": "2013-04-27T22:14:34-07:00",
        "summary": "short class comment for the TupleScheme",
        "message": "short class comment for the TupleScheme\n",
        "diff": {
            "parquet-cascading/src/main/java/parquet/cascading/ParquetTupleScheme.java": [
                0,
                15
            ]
        }
    },
    "1f0a8a25ad7d3b2683f0f8b10449db3ff1c2de13": {
        "datetime": "2013-04-28T16:05:04-07:00",
        "summary": "replace DeprecatedContainerInputFormat with DeprecatedParquetInputFormat, should build under MR2",
        "message": "replace DeprecatedContainerInputFormat with DeprecatedParquetInputFormat, should build under MR2\n",
        "diff": {
            "parquet-hadoop/src/main/java/parquet/hadoop/ParquetInputFormat.java": [
                12,
                22
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/ParquetRecordReader.java": [
                2,
                6
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/mapred/DeprecatedParquetInputFormat.java": [
                0,
                204
            ],
            "parquet-hadoop/src/test/java/parquet/hadoop/TestInputFormat.java": [
                2,
                2
            ],
            "parquet-thrift/src/main/java/parquet/hadoop/thrift/Container.java": [
                1,
                1
            ],
            "parquet-thrift/src/main/java/parquet/hadoop/thrift/DeprecatedContainerInputFormat.java": [
                372,
                0
            ]
        }
    },
    "5e82439eb8f99d20a5bbc55fdeaa0840b0cac90f": {
        "datetime": "2013-04-28T16:20:06-07:00",
        "summary": "fix up cascading and scrooge to use DeprecatedParquetInputFormat",
        "message": "fix up cascading and scrooge to use DeprecatedParquetInputFormat\n",
        "diff": {
            "parquet-cascading/src/main/java/parquet/cascading/ParquetTBaseScheme.java": [
                5,
                4
            ],
            "parquet-cascading/src/main/java/parquet/cascading/ParquetValueScheme.java": [
                1,
                1
            ],
            "parquet-scrooge/src/main/java/parquet/scrooge/ParquetScroogeScheme.java": [
                4,
                4
            ]
        }
    },
    "20a4bf72e9e64e317c9167eea88303b4f4e16f31": {
        "datetime": "2013-04-28T21:20:13-07:00",
        "summary": "DeprecatedParquetInputFormat is not abstract",
        "message": "DeprecatedParquetInputFormat is not abstract\n",
        "diff": {
            "parquet-hadoop/src/main/java/parquet/hadoop/mapred/DeprecatedParquetInputFormat.java": [
                1,
                1
            ]
        }
    },
    "2676de9bf340c2b97d1df6ac4208eba8e1cc28dd": {
        "datetime": "2013-04-28T21:35:31-07:00",
        "summary": "Treat Fields.UNKNOWN as Fields.ALL",
        "message": "Treat Fields.UNKNOWN as Fields.ALL\n",
        "diff": {
            "parquet-cascading/src/main/java/parquet/cascading/SchemaIntersection.java": [
                0,
                3
            ]
        }
    },
    "a49a0e929d6404d2291bc8959682ac6f8eadefa4": {
        "datetime": "2013-04-28T21:47:42-07:00",
        "summary": "don't create a TaskAttemptContext in ParquetReader",
        "message": "don't create a TaskAttemptContext in ParquetReader\n",
        "diff": {
            "parquet-hadoop/src/main/java/parquet/hadoop/ParquetReader.java": [
                6,
                1
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/ParquetRecordReader.java": [
                1,
                1
            ]
        }
    },
    "74157a052de90b429000a16809db73f1edaa82b1": {
        "datetime": "2013-04-29T15:50:27+04:00",
        "summary": "Fixed potential Integer overflow.",
        "message": "Fixed potential Integer overflow.\n",
        "diff": {
            "parquet-column/src/main/java/parquet/column/impl/ColumnWriterImpl.java": [
                2,
                2
            ]
        }
    },
    "fc0c7cdd92c703784b9dfa4f891ee2be59f4d7b0": {
        "datetime": "2013-04-29T08:23:47-07:00",
        "summary": "integrate RLE into dictionary encoding",
        "message": "integrate RLE into dictionary encoding\n",
        "diff": {
            "parquet-column/src/main/java/parquet/bytes/BytesInput.java": [
                0,
                2
            ],
            "parquet-column/src/main/java/parquet/column/values/bitpacking/ByteBasedBitPackingEncoder.java": [
                0,
                5
            ],
            "parquet-column/src/main/java/parquet/column/values/dictionary/DictionaryValuesReader.java": [
                13,
                14
            ],
            "parquet-column/src/main/java/parquet/column/values/dictionary/DictionaryValuesWriter.java": [
                10,
                25
            ],
            "parquet-column/src/main/java/parquet/column/values/dictionary/IntList.java": [
                0,
                68
            ],
            "parquet-column/src/main/java/parquet/column/values/rle/RLEDecoder.java": [
                0,
                7
            ],
            "parquet-column/src/main/java/parquet/column/values/rle/RLESimpleEncoder.java": [
                2,
                19
            ],
            "parquet-pig/src/test/java/parquet/pig/GenerateIntTestFile.java": [
                5,
                0
            ]
        }
    },
    "7cb711c27df1b4c0b1fdc7ae28837f4051c814da": {
        "datetime": "2013-04-29T08:32:59-07:00",
        "summary": "Merge branch 'rle' into dictionary_encoding",
        "message": "Merge branch 'rle' into dictionary_encoding\n\nConflicts:\n\tparquet-column/src/main/java/parquet/column/values/bitpacking/ByteBasedBitPackingEncoder.java\n\tparquet-column/src/main/java/parquet/column/values/rle/RLESimpleEncoder.java\n",
        "diff": {
            "parquet-column/src/main/java/parquet/bytes/BytesInput.java": [
                3,
                3
            ],
            "parquet-column/src/main/java/parquet/bytes/BytesUtils.java": [
                4,
                8
            ],
            "parquet-column/src/main/java/parquet/column/impl/ColumnWriterImpl.java": [
                2,
                3
            ],
            "parquet-column/src/main/java/parquet/column/values/bitpacking/BitPacking.java": [
                1,
                2
            ],
            "parquet-column/src/main/java/parquet/column/values/bitpacking/BitPackingValuesReader.java": [
                1,
                2
            ],
            "parquet-column/src/main/java/parquet/column/values/bitpacking/BitPackingValuesWriter.java": [
                1,
                3
            ],
            "parquet-column/src/main/java/parquet/column/values/bitpacking/ByteBasedBitPackingEncoder.java": [
                6,
                6
            ],
            "parquet-column/src/main/java/parquet/column/values/bitpacking/ByteBasedBitPackingGenerator.java": [
                1,
                3
            ],
            "parquet-column/src/main/java/parquet/column/values/bitpacking/ByteBitPackingValuesReader.java": [
                4,
                20
            ],
            "parquet-column/src/main/java/parquet/column/values/bitpacking/ByteBitPackingValuesWriter.java": [
                0,
                15
            ],
            "parquet-column/src/main/java/parquet/column/values/bitpacking/BytePacker.java": [
                0,
                0
            ],
            "parquet-column/src/main/java/parquet/column/values/boundedint/BoundedIntValuesWriter.java": [
                1,
                2
            ],
            "parquet-column/src/main/java/parquet/column/values/dictionary/DictionaryValuesWriter.java": [
                1,
                2
            ],
            "parquet-column/src/main/java/parquet/column/values/rle/RLEDecoder.java": [
                1,
                1
            ],
            "parquet-column/src/main/java/parquet/column/values/rle/RLESimpleEncoder.java": [
                4,
                5
            ],
            "parquet-column/src/test/java/parquet/TestLog.java": [
                0,
                15
            ],
            "parquet-column/src/test/java/parquet/column/values/bitpacking/BitPackingPerfTest.java": [
                0,
                15
            ]
        }
    },
    "4a8913e0f28a9fdea6eb37b1990cbe851e3edfac": {
        "datetime": "2013-04-29T08:33:18-07:00",
        "summary": "update git ignore",
        "message": "update git ignore\n",
        "diff": {
            ".gitignore": null
        }
    },
    "249e88935a203cda47483f7c73696000abd615e8": {
        "datetime": "2013-04-29T10:01:49-07:00",
        "summary": "Use a simpler serialization for cascading Fields to be compatible with older cascading versions",
        "message": "Use a simpler serialization for cascading Fields to be compatible with older cascading versions\n",
        "diff": {
            "parquet-cascading/src/main/java/parquet/cascading/TupleReadSupport.java": [
                13,
                9
            ]
        }
    },
    "8cb82ee8c8bc9f558fc16a0f8f41f1334e5c5dc0": {
        "datetime": "2013-04-29T10:06:38-07:00",
        "summary": "javadoc",
        "message": "javadoc\n",
        "diff": {
            "parquet-column/src/main/java/parquet/column/ColumnReader.java": [
                0,
                1
            ]
        }
    },
    "c96e7949a85b5327b348c587dfc9906707e18d4b": {
        "datetime": "2013-04-29T10:11:05-07:00",
        "summary": "+ needs space",
        "message": "+ needs space\n",
        "diff": {
            "parquet-column/src/main/java/parquet/io/MessageColumnIO.java": [
                13,
                13
            ]
        }
    },
    "d6e3866964a91a7c8d2b809215a2a4cf27fd308a": {
        "datetime": "2013-04-29T10:13:16-07:00",
        "summary": "Merge pull request #36 from 0xh3x/master",
        "message": "Merge pull request #36 from 0xh3x/master\n\nPotential Integer overflow in ColumnWriterImpl",
        "diff": {
            "parquet-column/src/main/java/parquet/column/impl/ColumnWriterImpl.java": [
                2,
                2
            ]
        }
    },
    "d822ef5a75567f75d7c5ceeb2958166bb5e99e92": {
        "datetime": "2013-04-29T10:19:55-07:00",
        "summary": "Merge pull request #35 from avibryant/deprecated-mr2",
        "message": "Merge pull request #35 from avibryant/deprecated-mr2\n\nHadoop 2 compatible DeprecatedParquetInputFormat",
        "diff": {
            "parquet-cascading/src/main/java/parquet/cascading/ParquetTBaseScheme.java": [
                5,
                4
            ],
            "parquet-cascading/src/main/java/parquet/cascading/ParquetValueScheme.java": [
                1,
                1
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/ParquetInputFormat.java": [
                12,
                22
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/ParquetReader.java": [
                6,
                1
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/ParquetRecordReader.java": [
                2,
                6
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/mapred/DeprecatedParquetInputFormat.java": [
                0,
                204
            ],
            "parquet-hadoop/src/test/java/parquet/hadoop/TestInputFormat.java": [
                2,
                2
            ],
            "parquet-scrooge/src/main/java/parquet/scrooge/ParquetScroogeScheme.java": [
                4,
                4
            ],
            "parquet-thrift/src/main/java/parquet/hadoop/thrift/Container.java": [
                1,
                1
            ],
            "parquet-thrift/src/main/java/parquet/hadoop/thrift/DeprecatedContainerInputFormat.java": [
                372,
                0
            ]
        }
    },
    "f2ab7a27d9dbe8ec9cfa407bcaee4d4f99d3ea83": {
        "datetime": "2013-04-29T10:35:04-07:00",
        "summary": "Use a simpler serialization for cascading Fields to be compatible with older cascading versions",
        "message": "Use a simpler serialization for cascading Fields to be compatible with older cascading versions\n",
        "diff": {
            "parquet-cascading/src/main/java/parquet/cascading/TupleReadSupport.java": [
                13,
                9
            ]
        }
    },
    "1ee87d8ff65e58396a14b407e96c140fde030f77": {
        "datetime": "2013-04-29T10:35:04-07:00",
        "summary": "Treat Fields.UNKNOWN as Fields.ALL",
        "message": "Treat Fields.UNKNOWN as Fields.ALL\n",
        "diff": {
            "parquet-cascading/src/main/java/parquet/cascading/SchemaIntersection.java": [
                0,
                3
            ]
        }
    },
    "2f0a779ba2db69649591ab2663cafe6bc0ce09f5": {
        "datetime": "2013-04-29T10:35:04-07:00",
        "summary": "short class comment for the TupleScheme",
        "message": "short class comment for the TupleScheme\n",
        "diff": {
            "parquet-cascading/src/main/java/parquet/cascading/ParquetTupleScheme.java": [
                0,
                15
            ]
        }
    },
    "62df1234e87094cc0965f04fa7444fd3ea136938": {
        "datetime": "2013-04-29T10:35:04-07:00",
        "summary": "working selective tuple materialization for cascading",
        "message": "working selective tuple materialization for cascading\n",
        "diff": {
            "parquet-cascading/pom.xml": null,
            "parquet-cascading/src/main/java/parquet/cascading/FilterSchema.java": [
                16,
                0
            ],
            "parquet-cascading/src/main/java/parquet/cascading/ParquetTupleScheme.java": [
                9,
                18
            ],
            "parquet-cascading/src/main/java/parquet/cascading/SchemaIntersection.java": [
                0,
                42
            ],
            "parquet-cascading/src/main/java/parquet/cascading/TupleReadSupport.java": [
                16,
                20
            ],
            "parquet-cascading/src/main/java/parquet/cascading/convert/TupleConverter.java": [
                1,
                1
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/ParquetFileReader.java": [
                0,
                14
            ]
        }
    },
    "30b461eabcdcb19708468159db8edba18ff31047": {
        "datetime": "2013-04-29T10:35:04-07:00",
        "summary": "skeleton for an efficient converter from groups to cascading tuples",
        "message": "skeleton for an efficient converter from groups to cascading tuples\n",
        "diff": {
            "parquet-cascading/src/main/java/parquet/cascading/FilterSchema.java": [
                0,
                16
            ],
            "parquet-cascading/src/main/java/parquet/cascading/ParquetTupleScheme.java": [
                0,
                95
            ],
            "parquet-cascading/src/main/java/parquet/cascading/TupleReadSupport.java": [
                0,
                58
            ],
            "parquet-cascading/src/main/java/parquet/cascading/convert/TupleConverter.java": [
                0,
                97
            ],
            "parquet-cascading/src/main/java/parquet/cascading/convert/TupleRecordMaterializer.java": [
                0,
                28
            ]
        }
    },
    "ffebada1455a96e22fd24dc961ba432087ded7ba": {
        "datetime": "2013-04-29T10:40:11-07:00",
        "summary": "update ParquetTupleScheme to use DeprecatedParquetInputFormat",
        "message": "update ParquetTupleScheme to use DeprecatedParquetInputFormat\n",
        "diff": {
            "parquet-cascading/src/main/java/parquet/cascading/ParquetTupleScheme.java": [
                3,
                3
            ]
        }
    },
    "9222396f31606f90b0706d767e9f169ad3c7e297": {
        "datetime": "2013-04-29T10:42:18-07:00",
        "summary": "merge",
        "message": "merge\n",
        "diff": {}
    },
    "3c96e97867b406411b7152d0ddd4374729b3f5d1": {
        "datetime": "2013-04-29T14:35:38-07:00",
        "summary": "Merge pull request #33 from Parquet/handle_empty_fields_as_nulls",
        "message": "Merge pull request #33 from Parquet/handle_empty_fields_as_nulls\n\nmake the API refuse empty fields and require missing fields",
        "diff": {
            "parquet-column/src/main/java/parquet/io/MessageColumnIO.java": [
                35,
                41
            ],
            "parquet-column/src/test/java/parquet/io/ExpectationValidatingConverter.java": [
                0,
                6
            ],
            "parquet-column/src/test/java/parquet/io/TestColumnIO.java": [
                6,
                26
            ],
            "parquet-pig/src/test/java/parquet/pig/GenerateTPCH.java": [
                3,
                3
            ],
            "parquet-thrift/src/main/java/parquet/thrift/ParquetProtocol.java": [
                42,
                56
            ],
            "parquet-thrift/src/main/java/parquet/thrift/TBaseRecordConverter.java": [
                7,
                10
            ],
            "parquet-thrift/src/test/java/parquet/hadoop/thrift/TestInputOutputFormat.java": [
                1,
                1
            ],
            "parquet-thrift/src/test/java/parquet/thrift/TestParquetReadProtocol.java": [
                1,
                1
            ]
        }
    },
    "634cb777c22ee7d4b03b3c35c85f3d198e7c1691": {
        "datetime": "2013-04-30T08:08:08-07:00",
        "summary": "fix bug when printing a ByteBuffer based binary would consume the buffer",
        "message": "fix bug when printing a ByteBuffer based binary would consume the buffer\n",
        "diff": {
            "parquet-column/src/main/java/parquet/io/api/Binary.java": [
                1,
                6
            ]
        }
    },
    "aaa58d36317c6242fb086efd3a161d5aee0c85db": {
        "datetime": "2013-04-30T13:38:16-07:00",
        "summary": "code formating and license headers",
        "message": "code formating and license headers\n",
        "diff": {
            "parquet-avro/src/main/java/parquet/avro/AvroGenericRecordConverter.java": [
                0,
                15
            ],
            "parquet-avro/src/main/java/parquet/avro/AvroParquetInputFormat.java": [
                0,
                15
            ],
            "parquet-avro/src/main/java/parquet/avro/AvroParquetOutputFormat.java": [
                0,
                15
            ],
            "parquet-avro/src/main/java/parquet/avro/AvroReadSupport.java": [
                0,
                15
            ],
            "parquet-avro/src/main/java/parquet/avro/AvroRecordMaterializer.java": [
                0,
                15
            ],
            "parquet-avro/src/main/java/parquet/avro/AvroWriteSupport.java": [
                0,
                15
            ],
            "parquet-avro/src/main/java/parquet/avro/package-info.java": [
                0,
                15
            ],
            "parquet-avro/src/test/java/parquet/avro/TestAvroSchemaConverter.java": [
                0,
                15
            ],
            "parquet-avro/src/test/java/parquet/avro/TestReadWrite.java": [
                0,
                15
            ],
            "parquet-column/src/main/java/parquet/column/values/bitpacking/ByteBasedBitPackingGenerator.java": [
                2,
                2
            ],
            "parquet-column/src/main/java/parquet/column/values/bitpacking/ByteBitPacking.java": [
                132,
                132
            ]
        }
    },
    "3dbccbaeeb1e6928287cad8e08689941e4b449fa": {
        "datetime": "2013-04-30T15:10:21-07:00",
        "summary": "add git hash in jar",
        "message": "add git hash in jar\n",
        "diff": {
            "parquet-avro/pom.xml": null,
            "parquet-cascading/pom.xml": null,
            "parquet-column/pom.xml": null,
            "parquet-hadoop/pom.xml": null,
            "parquet-pig/pom.xml": null,
            "parquet-scrooge/pom.xml": null,
            "parquet-thrift/pom.xml": null,
            "pom.xml": null
        }
    },
    "9ec356579b26efe4a5d3aa8993e049bf67066e86": {
        "datetime": "2013-04-30T15:26:09-07:00",
        "summary": "Merge pull request #39 from Parquet/add_git_hash_in_jar",
        "message": "Merge pull request #39 from Parquet/add_git_hash_in_jar\n\nadd git hash in jar",
        "diff": {
            "parquet-avro/pom.xml": null,
            "parquet-cascading/pom.xml": null,
            "parquet-column/pom.xml": null,
            "parquet-hadoop/pom.xml": null,
            "parquet-pig/pom.xml": null,
            "parquet-scrooge/pom.xml": null,
            "parquet-thrift/pom.xml": null,
            "pom.xml": null
        }
    },
    "68551780a069bfa7dc8741f125aaf69c2c9078f7": {
        "datetime": "2013-04-30T15:43:21-07:00",
        "summary": "Update README.md",
        "message": "Update README.md",
        "diff": {
            "README.md": null
        }
    },
    "2d4be4391e17612fbfec132adf6b5b1dc1b40802": {
        "datetime": "2013-04-30T18:13:09-07:00",
        "summary": "Merge pull request #25 from Parquet/rle",
        "message": "Merge pull request #25 from Parquet/rle\n\nRLE and Bitpacking improvement",
        "diff": {
            "NOTICE": null,
            "parquet-avro/src/main/java/parquet/avro/AvroGenericRecordConverter.java": [
                0,
                15
            ],
            "parquet-avro/src/main/java/parquet/avro/AvroParquetInputFormat.java": [
                0,
                15
            ],
            "parquet-avro/src/main/java/parquet/avro/AvroParquetOutputFormat.java": [
                0,
                15
            ],
            "parquet-avro/src/main/java/parquet/avro/AvroReadSupport.java": [
                0,
                15
            ],
            "parquet-avro/src/main/java/parquet/avro/AvroRecordMaterializer.java": [
                0,
                15
            ],
            "parquet-avro/src/main/java/parquet/avro/AvroWriteSupport.java": [
                0,
                15
            ],
            "parquet-avro/src/main/java/parquet/avro/package-info.java": [
                0,
                15
            ],
            "parquet-avro/src/test/java/parquet/avro/TestAvroSchemaConverter.java": [
                0,
                15
            ],
            "parquet-avro/src/test/java/parquet/avro/TestReadWrite.java": [
                0,
                15
            ],
            "parquet-column/src/main/java/parquet/bytes/BytesInput.java": [
                12,
                31
            ],
            "parquet-column/src/main/java/parquet/bytes/BytesUtils.java": [
                2,
                37
            ],
            "parquet-column/src/main/java/parquet/column/Encoding.java": [
                2,
                2
            ],
            "parquet-column/src/main/java/parquet/column/impl/ColumnWriterImpl.java": [
                5,
                6
            ],
            "parquet-column/src/main/java/parquet/column/values/bitpacking/BitPacking.java": [
                1,
                2
            ],
            "parquet-column/src/main/java/parquet/column/values/bitpacking/BitPackingValuesReader.java": [
                5,
                2
            ],
            "parquet-column/src/main/java/parquet/column/values/bitpacking/BitPackingValuesWriter.java": [
                7,
                3
            ],
            "parquet-column/src/main/java/parquet/column/values/bitpacking/ByteBasedBitPackingEncoder.java": [
                0,
                117
            ],
            "parquet-column/src/main/java/parquet/column/values/bitpacking/ByteBasedBitPackingGenerator.java": [
                0,
                232
            ],
            "parquet-column/src/main/java/parquet/column/values/bitpacking/ByteBitPacking.java": [
                0,
                25636
            ],
            "parquet-column/src/main/java/parquet/column/values/bitpacking/ByteBitPackingValuesReader.java": [
                0,
                70
            ],
            "parquet-column/src/main/java/parquet/column/values/bitpacking/ByteBitPackingValuesWriter.java": [
                0,
                76
            ],
            "parquet-column/src/main/java/parquet/column/values/bitpacking/BytePacker.java": [
                0,
                83
            ],
            "parquet-column/src/main/java/parquet/column/values/bitpacking/IntBasedBitPackingGenerator.java": [
                0,
                202
            ],
            "parquet-column/src/main/java/parquet/column/values/bitpacking/IntPacker.java": [
                0,
                63
            ],
            "parquet-column/src/main/java/parquet/column/values/bitpacking/LemireBitPackingBE.java": [
                0,
                3353
            ],
            "parquet-column/src/main/java/parquet/column/values/bitpacking/LemireBitPackingLE.java": [
                0,
                3352
            ],
            "parquet-column/src/main/java/parquet/column/values/boundedint/BoundedIntValuesWriter.java": [
                1,
                2
            ],
            "parquet-column/src/main/java/parquet/column/values/plain/BinaryPlainValuesReader.java": [
                0,
                15
            ],
            "parquet-column/src/main/java/parquet/column/values/rle/RLEDecoder.java": [
                0,
                104
            ],
            "parquet-column/src/main/java/parquet/column/values/rle/RLESimpleEncoder.java": [
                0,
                53
            ],
            "parquet-column/src/test/java/parquet/TestLog.java": [
                0,
                28
            ],
            "parquet-column/src/test/java/parquet/column/primitive/TestBitPacking.java": [
                3,
                1
            ],
            "parquet-column/src/test/java/parquet/column/primitive/TestBitPackingColumn.java": [
                18,
                44
            ],
            "parquet-column/src/test/java/parquet/column/values/bitpacking/BitPackingPerfTest.java": [
                0,
                100
            ],
            "parquet-column/src/test/java/parquet/column/values/bitpacking/TestByteBitPacking.java": [
                0,
                134
            ],
            "parquet-column/src/test/java/parquet/column/values/bitpacking/TestLemireBitPacking.java": [
                0,
                110
            ],
            "parquet-column/src/test/java/parquet/column/values/rle/TestRLE.java": [
                0,
                62
            ]
        }
    },
    "59f4b102517c472f26ea2138d353b33ee8146380": {
        "datetime": "2013-05-01T09:45:04-07:00",
        "summary": "Use the standard readFooters in ParquetTupleScheme",
        "message": "Use the standard readFooters in ParquetTupleScheme\n",
        "diff": {
            "parquet-cascading/src/main/java/parquet/cascading/ParquetTupleScheme.java": [
                4,
                10
            ],
            "parquet-cascading/src/main/java/parquet/cascading/TupleReadSupport.java": [
                0,
                4
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/ParquetFileReader.java": [
                10,
                2
            ]
        }
    },
    "88690f97f3aba9112b25337512d1e82e9034793d": {
        "datetime": "2013-05-01T09:58:33-07:00",
        "summary": "Fix Avro Read/Write support to work with the union-null optional value pattern",
        "message": "Fix Avro Read/Write support to work with the union-null optional value pattern\n",
        "diff": {
            "parquet-avro/src/main/java/parquet/avro/AvroGenericRecordConverter.java": [
                1,
                2
            ],
            "parquet-avro/src/main/java/parquet/avro/AvroSchemaHelper.java": [
                0,
                51
            ],
            "parquet-avro/src/main/java/parquet/avro/AvroWriteSupport.java": [
                5,
                10
            ],
            "parquet-avro/src/test/java/parquet/avro/TestInputOutputFormat.java": [
                4,
                8
            ]
        }
    },
    "5ed616243b81f61e12e45d4e4b67f312f85d5289": {
        "datetime": "2013-05-01T11:29:10-07:00",
        "summary": "mvn license:headers",
        "message": "mvn license:headers\n",
        "diff": {
            "parquet-cascading/src/main/java/parquet/cascading/ParquetTupleScheme.java": [
                0,
                15
            ],
            "parquet-cascading/src/main/java/parquet/cascading/SchemaIntersection.java": [
                0,
                15
            ],
            "parquet-cascading/src/main/java/parquet/cascading/TupleReadSupport.java": [
                0,
                15
            ],
            "parquet-cascading/src/main/java/parquet/cascading/convert/TupleConverter.java": [
                0,
                15
            ],
            "parquet-cascading/src/main/java/parquet/cascading/convert/TupleRecordMaterializer.java": [
                0,
                15
            ]
        }
    },
    "c7ebfbb14a1147b8c34d176821000140d2ec8bfc": {
        "datetime": "2013-05-01T11:35:40-07:00",
        "summary": "Fixes based on Julian's feedback",
        "message": "Fixes based on Julian's feedback\n",
        "diff": {
            "parquet-avro/src/main/java/parquet/avro/AvroGenericRecordConverter.java": [
                1,
                1
            ],
            "parquet-avro/src/main/java/parquet/avro/AvroSchemaConverter.java": [
                0,
                26
            ],
            "parquet-avro/src/main/java/parquet/avro/AvroSchemaHelper.java": [
                51,
                0
            ],
            "parquet-avro/src/main/java/parquet/avro/AvroWriteSupport.java": [
                3,
                3
            ]
        }
    },
    "f3ee0c9b2380aefc2b9d861a9e721bfce755bde0": {
        "datetime": "2013-05-01T11:51:58-07:00",
        "summary": "Merge pull request #37 from avibryant/cascading-tuples",
        "message": "Merge pull request #37 from avibryant/cascading-tuples\n\nCascading tuple support",
        "diff": {
            "parquet-cascading/pom.xml": null,
            "parquet-cascading/src/main/java/parquet/cascading/ParquetTupleScheme.java": [
                0,
                140
            ],
            "parquet-cascading/src/main/java/parquet/cascading/SchemaIntersection.java": [
                0,
                60
            ],
            "parquet-cascading/src/main/java/parquet/cascading/TupleReadSupport.java": [
                0,
                77
            ],
            "parquet-cascading/src/main/java/parquet/cascading/convert/TupleConverter.java": [
                0,
                112
            ],
            "parquet-cascading/src/main/java/parquet/cascading/convert/TupleRecordMaterializer.java": [
                0,
                43
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/ParquetFileReader.java": [
                0,
                6
            ]
        }
    },
    "cec7b39ea182757d43e247241c2a4f64e1b04a24": {
        "datetime": "2013-05-01T11:56:10-07:00",
        "summary": "Merge pull request #41 from jwills/avro-null-unions",
        "message": "Merge pull request #41 from jwills/avro-null-unions\n\nFix Avro Read/Write support to work with union-null optional values",
        "diff": {
            "parquet-avro/src/main/java/parquet/avro/AvroGenericRecordConverter.java": [
                1,
                2
            ],
            "parquet-avro/src/main/java/parquet/avro/AvroSchemaConverter.java": [
                0,
                26
            ],
            "parquet-avro/src/main/java/parquet/avro/AvroWriteSupport.java": [
                5,
                10
            ],
            "parquet-avro/src/test/java/parquet/avro/TestInputOutputFormat.java": [
                4,
                8
            ]
        }
    },
    "a1fbcfb1fd229f77222fabae54a97f3b161f4d26": {
        "datetime": "2013-05-01T16:05:25-07:00",
        "summary": "make total size include header size",
        "message": "make total size include header size\n",
        "diff": {
            "parquet-column/src/main/java/parquet/Log.java": [
                1,
                1
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/ParquetFileWriter.java": [
                5,
                16
            ],
            "parquet-hadoop/src/test/java/parquet/hadoop/TestParquetFileWriter.java": [
                0,
                7
            ]
        }
    },
    "75ead0a3ed59c4b821fc2973b8917a856d3067dc": {
        "datetime": "2013-05-01T16:08:06-07:00",
        "summary": "turn LOGs back to INFO",
        "message": "turn LOGs back to INFO\n",
        "diff": {
            "parquet-column/src/main/java/parquet/Log.java": [
                1,
                1
            ]
        }
    },
    "6c26ece97fc5d13a0ea68c23f52ca7ee6f671516": {
        "datetime": "2013-05-01T17:35:59-07:00",
        "summary": "Merge pull request #42 from Parquet/make_total_size_include_headers",
        "message": "Merge pull request #42 from Parquet/make_total_size_include_headers\n\nmake total size include header size",
        "diff": {
            "parquet-hadoop/src/main/java/parquet/hadoop/ParquetFileWriter.java": [
                5,
                16
            ],
            "parquet-hadoop/src/test/java/parquet/hadoop/TestParquetFileWriter.java": [
                0,
                7
            ]
        }
    },
    "f5ab5ebd5e3c9e3a63f2dcc124b60fb3349679b3": {
        "datetime": "2013-05-03T09:45:03-07:00",
        "summary": "better error message when schema is unknown",
        "message": "better error message when schema is unknown\n",
        "diff": {
            "parquet-pig/src/main/java/parquet/pig/ParquetStorer.java": [
                1,
                5
            ]
        }
    },
    "6c1ccb7e155319faa58ff7add19f87315ab5a3d1": {
        "datetime": "2013-05-03T14:37:51-07:00",
        "summary": "Merge pull request #45 from Parquet/no_schema_error",
        "message": "Merge pull request #45 from Parquet/no_schema_error\n\nbetter error message when schema is unknown",
        "diff": {
            "parquet-pig/src/main/java/parquet/pig/ParquetStorer.java": [
                1,
                5
            ]
        }
    },
    "0c250380bd15e6491857108b9463e4b9ba3c00c9": {
        "datetime": "2013-05-03T18:30:57-07:00",
        "summary": "read version information from META-INF",
        "message": "read version information from META-INF\n",
        "diff": {
            "parquet-column/src/main/java/parquet/Version.java": [
                0,
                66
            ]
        }
    },
    "a20750a87d69823e4048d954627494505d508e2e": {
        "datetime": "2013-05-07T16:03:16+01:00",
        "summary": "Replace JobContext#getConfiguration calls with reflective call.",
        "message": "Replace JobContext#getConfiguration calls with reflective call.\n",
        "diff": {
            "parquet-avro/src/main/java/parquet/avro/AvroParquetOutputFormat.java": [
                1,
                2
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/ParquetInputFormat.java": [
                4,
                5
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/ParquetOutputCommitter.java": [
                1,
                2
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/ParquetOutputFormat.java": [
                10,
                11
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/ParquetRecordReader.java": [
                1,
                2
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/example/ExampleOutputFormat.java": [
                2,
                3
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/util/ContextUtil.java": [
                0,
                245
            ],
            "parquet-hadoop/src/test/java/parquet/hadoop/example/TestInputOutputFormat.java": [
                1,
                2
            ],
            "parquet-pig/src/main/java/parquet/pig/ParquetLoader.java": [
                1,
                2
            ],
            "parquet-pig/src/test/java/parquet/pig/PerfTest2.java": [
                5,
                6
            ],
            "parquet-thrift/src/main/java/parquet/hadoop/thrift/ParquetThriftBytesOutputFormat.java": [
                3,
                4
            ],
            "parquet-thrift/src/main/java/parquet/hadoop/thrift/ParquetThriftOutputFormat.java": [
                2,
                3
            ],
            "parquet-thrift/src/test/java/parquet/hadoop/thrift/TestThriftToParquetFileWriter.java": [
                2,
                3
            ]
        }
    },
    "a67ea4ea283481abd324a0a799d6a09cc8002545": {
        "datetime": "2013-05-07T16:03:49+01:00",
        "summary": "add test for hadoop2",
        "message": "add test for hadoop2\n",
        "diff": {
            "parquet-avro/pom.xml": null,
            "parquet-cascading/pom.xml": null,
            "parquet-hadoop/pom.xml": null,
            "parquet-pig/pom.xml": null,
            "parquet-scrooge/pom.xml": null,
            "parquet-test-hadoop2/pom.xml": null,
            "parquet-test-hadoop2/src/test/java/parquet/hadoop2/TestInputOutputFormat.java": [
                0,
                137
            ],
            "parquet-thrift/pom.xml": null,
            "pom.xml": null
        }
    },
    "5ab09189cf32c76a3bdd8fecedaf337735c1ea24": {
        "datetime": "2013-05-07T21:30:47+01:00",
        "summary": "update dependencies to hadoop-client",
        "message": "update dependencies to hadoop-client\n",
        "diff": {
            "parquet-avro/pom.xml": null,
            "parquet-cascading/pom.xml": null,
            "parquet-hadoop/pom.xml": null,
            "parquet-pig/pom.xml": null,
            "parquet-scrooge/pom.xml": null,
            "parquet-test-hadoop2/pom.xml": null,
            "parquet-test-hadoop2/src/test/java/parquet/hadoop2/TestInputOutputFormat.java": [
                2,
                4
            ],
            "parquet-thrift/pom.xml": null,
            "pom.xml": null
        }
    },
    "fae4c56c0526db232d5d4e98f9587c549ed50e27": {
        "datetime": "2013-05-07T17:22:47-07:00",
        "summary": "Merge pull request #32 from tomwhite/hadoop2",
        "message": "Merge pull request #32 from tomwhite/hadoop2\n\nAdd a build profile for Hadoop 2.",
        "diff": {
            "parquet-avro/pom.xml": null,
            "parquet-avro/src/main/java/parquet/avro/AvroParquetOutputFormat.java": [
                1,
                2
            ],
            "parquet-cascading/pom.xml": null,
            "parquet-hadoop/pom.xml": null,
            "parquet-hadoop/src/main/java/parquet/hadoop/ParquetInputFormat.java": [
                4,
                5
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/ParquetOutputCommitter.java": [
                1,
                2
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/ParquetOutputFormat.java": [
                10,
                11
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/ParquetRecordReader.java": [
                1,
                2
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/example/ExampleOutputFormat.java": [
                2,
                3
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/util/ContextUtil.java": [
                0,
                245
            ],
            "parquet-hadoop/src/test/java/parquet/hadoop/example/TestInputOutputFormat.java": [
                1,
                2
            ],
            "parquet-pig/pom.xml": null,
            "parquet-pig/src/main/java/parquet/pig/ParquetLoader.java": [
                1,
                2
            ],
            "parquet-pig/src/test/java/parquet/pig/PerfTest2.java": [
                5,
                6
            ],
            "parquet-scrooge/pom.xml": null,
            "parquet-test-hadoop2/pom.xml": null,
            "parquet-test-hadoop2/src/test/java/parquet/hadoop2/TestInputOutputFormat.java": [
                0,
                139
            ],
            "parquet-thrift/pom.xml": null,
            "parquet-thrift/src/main/java/parquet/hadoop/thrift/ParquetThriftBytesOutputFormat.java": [
                3,
                4
            ],
            "parquet-thrift/src/main/java/parquet/hadoop/thrift/ParquetThriftOutputFormat.java": [
                2,
                3
            ],
            "parquet-thrift/src/test/java/parquet/hadoop/thrift/TestThriftToParquetFileWriter.java": [
                2,
                3
            ],
            "pom.xml": null
        }
    },
    "647825b5a7b317dfb6d1a6ef61eca87c75e6bfd2": {
        "datetime": "2013-05-07T18:55:15-07:00",
        "summary": "Changed two utility classes to public",
        "message": "Changed two utility classes to public\n\nAvroSchemaConverter\nCodecFactory\n",
        "diff": {
            "parquet-avro/src/main/java/parquet/avro/AvroSchemaConverter.java": [
                1,
                1
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/CodecFactory.java": [
                1,
                1
            ]
        }
    },
    "09a54d6c786d7258cb1baf03f821882058ea62c6": {
        "datetime": "2013-05-08T18:12:20-07:00",
        "summary": "Rolled back one of the public classes",
        "message": "Rolled back one of the public classes\n",
        "diff": {
            "parquet-hadoop/src/main/java/parquet/hadoop/CodecFactory.java": [
                1,
                1
            ]
        }
    },
    "3e4561b5a15d234d9a9f2331ef55dba7eb44773c": {
        "datetime": "2013-05-08T21:25:56-07:00",
        "summary": "Merge pull request #46 from laserson/public_utils",
        "message": "Merge pull request #46 from laserson/public_utils\n\nChanged `AvroSchemaConverter` to `public`",
        "diff": {
            "parquet-avro/src/main/java/parquet/avro/AvroSchemaConverter.java": [
                1,
                1
            ]
        }
    },
    "45b893c67f67a83c9ba5d5143829794eb7932b65": {
        "datetime": "2013-05-08T21:36:13-07:00",
        "summary": "add maven-jar-plugin version",
        "message": "add maven-jar-plugin version\n",
        "diff": {
            "parquet-avro/pom.xml": null,
            "parquet-cascading/pom.xml": null,
            "parquet-column/pom.xml": null,
            "parquet-hadoop/pom.xml": null,
            "parquet-pig/pom.xml": null,
            "parquet-scrooge/pom.xml": null,
            "parquet-test-hadoop2/pom.xml": null,
            "parquet-thrift/pom.xml": null,
            "pom.xml": null
        }
    },
    "306868de79ff9d092aeedcbcf0a358f95826675f": {
        "datetime": "2013-05-08T21:36:24-07:00",
        "summary": "Merge branch 'master' into version",
        "message": "Merge branch 'master' into version\n",
        "diff": {
            "parquet-avro/pom.xml": null,
            "parquet-avro/src/main/java/parquet/avro/AvroParquetOutputFormat.java": [
                1,
                2
            ],
            "parquet-avro/src/main/java/parquet/avro/AvroSchemaConverter.java": [
                1,
                1
            ],
            "parquet-cascading/pom.xml": null,
            "parquet-column/pom.xml": null,
            "parquet-hadoop/pom.xml": null,
            "parquet-hadoop/src/main/java/parquet/hadoop/ParquetFileWriter.java": [
                5,
                16
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/ParquetInputFormat.java": [
                4,
                5
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/ParquetOutputCommitter.java": [
                1,
                2
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/ParquetOutputFormat.java": [
                10,
                11
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/ParquetRecordReader.java": [
                1,
                2
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/example/ExampleOutputFormat.java": [
                2,
                3
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/util/ContextUtil.java": [
                0,
                245
            ],
            "parquet-hadoop/src/test/java/parquet/hadoop/TestParquetFileWriter.java": [
                0,
                7
            ],
            "parquet-hadoop/src/test/java/parquet/hadoop/example/TestInputOutputFormat.java": [
                1,
                2
            ],
            "parquet-pig/pom.xml": null,
            "parquet-pig/src/main/java/parquet/pig/ParquetLoader.java": [
                1,
                2
            ],
            "parquet-pig/src/main/java/parquet/pig/ParquetStorer.java": [
                1,
                5
            ],
            "parquet-pig/src/test/java/parquet/pig/PerfTest2.java": [
                5,
                6
            ],
            "parquet-scrooge/pom.xml": null,
            "parquet-test-hadoop2/pom.xml": null,
            "parquet-test-hadoop2/src/test/java/parquet/hadoop2/TestInputOutputFormat.java": [
                0,
                139
            ],
            "parquet-thrift/pom.xml": null,
            "parquet-thrift/src/main/java/parquet/hadoop/thrift/ParquetThriftBytesOutputFormat.java": [
                3,
                4
            ],
            "parquet-thrift/src/main/java/parquet/hadoop/thrift/ParquetThriftOutputFormat.java": [
                2,
                3
            ],
            "parquet-thrift/src/test/java/parquet/hadoop/thrift/TestThriftToParquetFileWriter.java": [
                2,
                3
            ],
            "pom.xml": null
        }
    },
    "cd2535980e715b00d43ee47b2aa138167016aed3": {
        "datetime": "2013-05-08T21:48:35-07:00",
        "summary": "add library version to metadata",
        "message": "add library version to metadata\n",
        "diff": {
            "parquet-column/src/main/java/parquet/Version.java": [
                2,
                9
            ],
            "parquet-hadoop/src/main/java/parquet/format/converter/ParquetMetadataConverter.java": [
                1,
                3
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/ParquetFileWriter.java": [
                2,
                4
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/metadata/FileMetaData.java": [
                1,
                12
            ],
            "parquet-hadoop/src/test/java/parquet/hadoop/TestInputFormat.java": [
                2,
                1
            ]
        }
    },
    "be136d2cd827814523f383d5aa7e1738aef1f654": {
        "datetime": "2013-05-08T23:04:20-06:00",
        "summary": "Update README.md",
        "message": "Update README.md",
        "diff": {
            "README.md": null
        }
    },
    "f0c42cac547243950fb1a47f8bdf9c5aefd69fbb": {
        "datetime": "2013-05-09T14:15:51-07:00",
        "summary": "Merge pull request #49 from Parquet/version",
        "message": "Merge pull request #49 from Parquet/version\n\nadd Version in footer",
        "diff": {
            "parquet-avro/pom.xml": null,
            "parquet-cascading/pom.xml": null,
            "parquet-column/pom.xml": null,
            "parquet-column/src/main/java/parquet/Version.java": [
                0,
                73
            ],
            "parquet-hadoop/pom.xml": null,
            "parquet-hadoop/src/main/java/parquet/format/converter/ParquetMetadataConverter.java": [
                1,
                3
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/ParquetFileWriter.java": [
                2,
                4
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/metadata/FileMetaData.java": [
                1,
                12
            ],
            "parquet-hadoop/src/test/java/parquet/hadoop/TestInputFormat.java": [
                2,
                1
            ],
            "parquet-pig/pom.xml": null,
            "parquet-scrooge/pom.xml": null,
            "parquet-test-hadoop2/pom.xml": null,
            "parquet-thrift/pom.xml": null,
            "pom.xml": null
        }
    },
    "e1aa79849714d189727155ad9937436b66595256": {
        "datetime": "2013-05-10T15:07:35-07:00",
        "summary": "improve memory consumption in write",
        "message": "improve memory consumption in write\n",
        "diff": {
            "parquet-column/src/main/java/parquet/bytes/BytesInput.java": [
                2,
                30
            ],
            "parquet-column/src/main/java/parquet/bytes/CapacityByteArrayOutputStream.java": [
                5,
                142
            ],
            "parquet-column/src/main/java/parquet/column/impl/ColumnWriteStoreImpl.java": [
                2,
                14
            ],
            "parquet-column/src/main/java/parquet/column/impl/ColumnWriterImpl.java": [
                8,
                28
            ],
            "parquet-column/src/main/java/parquet/column/page/PageWriter.java": [
                0,
                2
            ],
            "parquet-column/src/main/java/parquet/column/values/ValuesWriter.java": [
                0,
                2
            ],
            "parquet-column/src/main/java/parquet/column/values/bitpacking/BitPackingValuesWriter.java": [
                5,
                7
            ],
            "parquet-column/src/main/java/parquet/column/values/bitpacking/ByteBasedBitPackingEncoder.java": [
                1,
                5
            ],
            "parquet-column/src/main/java/parquet/column/values/bitpacking/ByteBitPackingValuesWriter.java": [
                0,
                5
            ],
            "parquet-column/src/main/java/parquet/column/values/boundedint/BitWriter.java": [
                5,
                13
            ],
            "parquet-column/src/main/java/parquet/column/values/boundedint/BoundedIntValuesFactory.java": [
                2,
                2
            ],
            "parquet-column/src/main/java/parquet/column/values/boundedint/BoundedIntValuesWriter.java": [
                5,
                11
            ],
            "parquet-column/src/main/java/parquet/column/values/boundedint/DevNullValuesWriter.java": [
                0,
                5
            ],
            "parquet-column/src/main/java/parquet/column/values/plain/BooleanPlainValuesWriter.java": [
                0,
                5
            ],
            "parquet-column/src/main/java/parquet/column/values/plain/PlainValuesWriter.java": [
                0,
                5
            ],
            "parquet-column/src/test/java/parquet/bytes/TestCapacityByteArrayOutputStream.java": [
                0,
                78
            ],
            "parquet-column/src/test/java/parquet/column/mem/TestMemColumn.java": [
                4,
                4
            ],
            "parquet-column/src/test/java/parquet/column/page/mem/MemPageWriter.java": [
                0,
                5
            ],
            "parquet-column/src/test/java/parquet/column/values/bitpacking/TestBitPackingColumn.java": [
                1,
                1
            ],
            "parquet-column/src/test/java/parquet/column/values/boundedint/TestBoundedColumns.java": [
                2,
                2
            ],
            "parquet-column/src/test/java/parquet/io/PerfTest.java": [
                1,
                1
            ],
            "parquet-column/src/test/java/parquet/io/TestColumnIO.java": [
                4,
                4
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/ParquetRecordWriter.java": [
                1,
                10
            ],
            "parquet-pig/src/test/java/parquet/pig/GenerateIntTestFile.java": [
                1,
                1
            ],
            "parquet-pig/src/test/java/parquet/pig/GenerateTPCH.java": [
                2,
                3
            ],
            "parquet-pig/src/test/java/parquet/pig/TupleConsumerPerfTest.java": [
                1,
                1
            ],
            "parquet-thrift/src/test/java/parquet/thrift/TestParquetReadProtocol.java": [
                1,
                1
            ]
        }
    },
    "b30d7fe08d26346da07c3ac873fea3f174785362": {
        "datetime": "2013-05-10T15:09:31-07:00",
        "summary": "reduce rep and def level buffer size. 8MB * 2 * #cols is way too much",
        "message": "reduce rep and def level buffer size. 8MB * 2 * #cols is way too much\n",
        "diff": {
            "parquet-column/src/main/java/parquet/column/values/bitpacking/ByteBasedBitPackingEncoder.java": [
                1,
                1
            ]
        }
    },
    "f334966c806491771eba06af44eb0abbc07ace64": {
        "datetime": "2013-05-10T15:28:18-07:00",
        "summary": "Merge pull request #50 from Parquet/scale_down_overly_enthusiastic_buffer_size",
        "message": "Merge pull request #50 from Parquet/scale_down_overly_enthusiastic_buffer_size\n\nreduce rep and def level buffer size. 8MB * 2 * #cols is way too much",
        "diff": {
            "parquet-column/src/main/java/parquet/column/values/bitpacking/ByteBasedBitPackingEncoder.java": [
                1,
                1
            ]
        }
    },
    "90aca3cd361d0cb1f99aa5f8152af912f4602e0c": {
        "datetime": "2013-05-10T15:32:02-07:00",
        "summary": "Merge branch 'master' into improve_mem_usage_in_write",
        "message": "Merge branch 'master' into improve_mem_usage_in_write\n",
        "diff": {}
    },
    "a0e82a878547701b0259cf9c2211f721c1fca172": {
        "datetime": "2013-05-10T16:09:36-07:00",
        "summary": "add improved memory management in hadoop layer",
        "message": "add improved memory management in hadoop layer\n",
        "diff": {
            "parquet-hadoop/src/main/java/parquet/hadoop/ColumnChunkPageWriteStore.java": [
                2,
                9
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/ParquetRecordWriter.java": [
                7,
                7
            ]
        }
    },
    "922f6c5098f8d58708e79f9640ea06c73d255519": {
        "datetime": "2013-05-10T18:20:59-07:00",
        "summary": "add setting to turn dictionary on",
        "message": "add setting to turn dictionary on\n",
        "diff": {
            "parquet-column/src/main/java/parquet/column/impl/ColumnWriteStoreImpl.java": [
                2,
                4
            ],
            "parquet-column/src/main/java/parquet/column/impl/ColumnWriterImpl.java": [
                2,
                6
            ],
            "parquet-column/src/test/java/parquet/column/mem/TestMemColumn.java": [
                4,
                4
            ],
            "parquet-column/src/test/java/parquet/io/PerfTest.java": [
                1,
                1
            ],
            "parquet-column/src/test/java/parquet/io/TestColumnIO.java": [
                3,
                3
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/ParquetOutputFormat.java": [
                1,
                21
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/ParquetRecordWriter.java": [
                2,
                5
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/ParquetWriter.java": [
                1,
                1
            ]
        }
    },
    "6a4f8d03f38cddc1d62a6fa240b601816738af33": {
        "datetime": "2013-05-10T18:36:08-07:00",
        "summary": "handle case when value is bigger than slab size",
        "message": "handle case when value is bigger than slab size\n",
        "diff": {
            "parquet-column/src/main/java/parquet/bytes/CapacityByteArrayOutputStream.java": [
                3,
                14
            ]
        }
    },
    "0347e7b2b3d722a63ade36077ef02b5e22d66f5b": {
        "datetime": "2013-05-10T21:29:34-07:00",
        "summary": "adjust initial column size",
        "message": "adjust initial column size\n",
        "diff": {
            "parquet-hadoop/src/main/java/parquet/hadoop/ParquetRecordWriter.java": [
                2,
                3
            ]
        }
    },
    "f7e7dd7685fb0e10ab3ad30201b80a995cd7b3ed": {
        "datetime": "2013-05-11T15:37:36-07:00",
        "summary": "more unit tests for CapacityByteArrayOutputStream",
        "message": "more unit tests for CapacityByteArrayOutputStream\n",
        "diff": {
            "parquet-column/src/main/java/parquet/bytes/CapacityByteArrayOutputStream.java": [
                1,
                5
            ],
            "parquet-column/src/test/java/parquet/bytes/TestCapacityByteArrayOutputStream.java": [
                23,
                79
            ]
        }
    },
    "21bb59da12bf497113f3fc2ec1b60aa0c7f2d2cc": {
        "datetime": "2013-05-13T13:22:00-07:00",
        "summary": "Oops, forgot about default compression",
        "message": "Oops, forgot about default compression\n",
        "diff": {
            "parquet-avro/src/main/java/parquet/avro/AvroParquetWriter.java": [
                1,
                1
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/ParquetWriter.java": [
                1,
                1
            ]
        }
    },
    "11d8e0ebf0c8c3f0f9c17217269e36152003c476": {
        "datetime": "2013-05-13T13:22:00-07:00",
        "summary": "Added javadocs",
        "message": "Added javadocs\n",
        "diff": {
            "parquet-avro/src/main/java/parquet/avro/AvroParquetWriter.java": [
                1,
                21
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/ParquetWriter.java": [
                1,
                19
            ]
        }
    },
    "d636d60611371643b3ffe5c7494e9d1b315d2ac0": {
        "datetime": "2013-05-13T13:22:00-07:00",
        "summary": "Allow setting compressor, block/page size for ParquetWriter",
        "message": "Allow setting compressor, block/page size for ParquetWriter\n",
        "diff": {
            "parquet-avro/src/main/java/parquet/avro/AvroParquetWriter.java": [
                2,
                10
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/ParquetWriter.java": [
                4,
                10
            ]
        }
    },
    "34a8fb00cf205de05f350496b20e721104119fdf": {
        "datetime": "2013-05-13T16:13:30-07:00",
        "summary": "Propagated default sizes to the OutputFormat",
        "message": "Propagated default sizes to the OutputFormat\n",
        "diff": {
            "parquet-avro/src/main/java/parquet/avro/AvroParquetWriter.java": [
                4,
                1
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/ParquetOutputFormat.java": [
                2,
                2
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/ParquetWriter.java": [
                2,
                3
            ]
        }
    },
    "0add8d86e367ec01a3e8fe5813e53151dd6aa28a": {
        "datetime": "2013-05-13T16:27:18-07:00",
        "summary": "add constant and override annotations",
        "message": "add constant and override annotations\n",
        "diff": {
            "parquet-column/src/main/java/parquet/bytes/CapacityByteArrayOutputStream.java": [
                15,
                6
            ]
        }
    },
    "7f7fa72169cfbfc15b2cee3040222a3cb6158926": {
        "datetime": "2013-05-13T16:44:39-07:00",
        "summary": "Merge pull request #48 from laserson/choose_compression",
        "message": "Merge pull request #48 from laserson/choose_compression\n\nAllow setting compressor, block/page size for ParquetWriter",
        "diff": {
            "parquet-avro/src/main/java/parquet/avro/AvroParquetWriter.java": [
                2,
                27
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/ParquetOutputFormat.java": [
                2,
                2
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/ParquetWriter.java": [
                4,
                29
            ]
        }
    },
    "d0cc3a96ee61e132ab109c2cacd1289d372f10ca": {
        "datetime": "2013-05-13T16:52:10-07:00",
        "summary": "check initial size",
        "message": "check initial size\n",
        "diff": {
            "parquet-column/src/main/java/parquet/bytes/CapacityByteArrayOutputStream.java": [
                0,
                3
            ]
        }
    },
    "ea3eb7b23cc36d69709824b41c8222a1c8652c68": {
        "datetime": "2013-05-14T02:07:16-07:00",
        "summary": "Removed getCounter for compatibility",
        "message": "Removed getCounter for compatibility\n",
        "diff": {
            "parquet-hadoop/src/main/java/parquet/hadoop/util/ContextUtil.java": [
                20,
                0
            ]
        }
    },
    "a53dde1c7bebc1f7242f574973afa71699076cd8": {
        "datetime": "2013-05-14T08:45:08-07:00",
        "summary": "javadoc and constants",
        "message": "javadoc and constants\n",
        "diff": {
            "parquet-column/src/main/java/parquet/bytes/CapacityByteArrayOutputStream.java": [
                7,
                36
            ]
        }
    },
    "34d0b5d32689b8ebc1ba4a6f4988bc3637f55e6c": {
        "datetime": "2013-05-14T10:12:53-07:00",
        "summary": "Merge pull request #52 from laserson/getCounter_compat",
        "message": "Merge pull request #52 from laserson/getCounter_compat\n\nRemoved getCounter for compatibility",
        "diff": {
            "parquet-hadoop/src/main/java/parquet/hadoop/util/ContextUtil.java": [
                20,
                0
            ]
        }
    },
    "5b25bb57fc1f68dbf46e6cedab67f25120aec070": {
        "datetime": "2013-05-14T11:09:23-07:00",
        "summary": "add constants and doc",
        "message": "add constants and doc\n",
        "diff": {
            "parquet-column/src/main/java/parquet/column/impl/ColumnWriterImpl.java": [
                3,
                20
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/ParquetRecordWriter.java": [
                2,
                4
            ]
        }
    },
    "4f4c5c47f82ea063825bf654cc2053e5c9625810": {
        "datetime": "2013-05-14T14:33:21-07:00",
        "summary": "Merge pull request #51 from Parquet/improve_mem_usage_in_write",
        "message": "Merge pull request #51 from Parquet/improve_mem_usage_in_write\n\nimprove memory consumption in write path",
        "diff": {
            "parquet-column/src/main/java/parquet/bytes/BytesInput.java": [
                2,
                30
            ],
            "parquet-column/src/main/java/parquet/bytes/CapacityByteArrayOutputStream.java": [
                4,
                179
            ],
            "parquet-column/src/main/java/parquet/column/impl/ColumnWriteStoreImpl.java": [
                2,
                14
            ],
            "parquet-column/src/main/java/parquet/column/impl/ColumnWriterImpl.java": [
                9,
                46
            ],
            "parquet-column/src/main/java/parquet/column/page/PageWriter.java": [
                0,
                2
            ],
            "parquet-column/src/main/java/parquet/column/values/ValuesWriter.java": [
                0,
                2
            ],
            "parquet-column/src/main/java/parquet/column/values/bitpacking/BitPackingValuesWriter.java": [
                5,
                7
            ],
            "parquet-column/src/main/java/parquet/column/values/bitpacking/ByteBasedBitPackingEncoder.java": [
                0,
                4
            ],
            "parquet-column/src/main/java/parquet/column/values/bitpacking/ByteBitPackingValuesWriter.java": [
                0,
                5
            ],
            "parquet-column/src/main/java/parquet/column/values/boundedint/BitWriter.java": [
                5,
                13
            ],
            "parquet-column/src/main/java/parquet/column/values/boundedint/BoundedIntValuesFactory.java": [
                2,
                2
            ],
            "parquet-column/src/main/java/parquet/column/values/boundedint/BoundedIntValuesWriter.java": [
                5,
                11
            ],
            "parquet-column/src/main/java/parquet/column/values/boundedint/DevNullValuesWriter.java": [
                0,
                5
            ],
            "parquet-column/src/main/java/parquet/column/values/plain/BooleanPlainValuesWriter.java": [
                0,
                5
            ],
            "parquet-column/src/main/java/parquet/column/values/plain/PlainValuesWriter.java": [
                0,
                5
            ],
            "parquet-column/src/test/java/parquet/bytes/TestCapacityByteArrayOutputStream.java": [
                0,
                134
            ],
            "parquet-column/src/test/java/parquet/column/mem/TestMemColumn.java": [
                4,
                4
            ],
            "parquet-column/src/test/java/parquet/column/page/mem/MemPageWriter.java": [
                0,
                5
            ],
            "parquet-column/src/test/java/parquet/column/values/bitpacking/TestBitPackingColumn.java": [
                1,
                1
            ],
            "parquet-column/src/test/java/parquet/column/values/boundedint/TestBoundedColumns.java": [
                2,
                2
            ],
            "parquet-column/src/test/java/parquet/io/PerfTest.java": [
                1,
                1
            ],
            "parquet-column/src/test/java/parquet/io/TestColumnIO.java": [
                4,
                4
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/ColumnChunkPageWriteStore.java": [
                2,
                9
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/ParquetRecordWriter.java": [
                2,
                14
            ],
            "parquet-pig/src/test/java/parquet/pig/GenerateIntTestFile.java": [
                1,
                1
            ],
            "parquet-pig/src/test/java/parquet/pig/GenerateTPCH.java": [
                2,
                3
            ],
            "parquet-pig/src/test/java/parquet/pig/TupleConsumerPerfTest.java": [
                1,
                1
            ],
            "parquet-thrift/src/test/java/parquet/thrift/TestParquetReadProtocol.java": [
                1,
                1
            ]
        }
    },
    "b6d1cb046418da4de3f35e5109a87df29e2cc42c": {
        "datetime": "2013-05-17T16:28:29-07:00",
        "summary": "add a validation setting to OutputFormat",
        "message": "add a validation setting to OutputFormat\n",
        "diff": {
            "parquet-column/src/main/java/parquet/column/impl/ColumnReaderImpl.java": [
                4,
                13
            ],
            "parquet-column/src/main/java/parquet/column/values/plain/BinaryPlainValuesReader.java": [
                0,
                2
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/ParquetOutputFormat.java": [
                12,
                27
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/ParquetReader.java": [
                2,
                2
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/ParquetRecordReader.java": [
                7,
                12
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/ParquetRecordWriter.java": [
                2,
                5
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/ParquetWriter.java": [
                14,
                36
            ]
        }
    },
    "05f103b33abc8c8191a2aeb59f688ddd5c41d319": {
        "datetime": "2013-05-18T22:42:14-07:00",
        "summary": "Fix bug that prevented writing optional Avro records, arrays or maps",
        "message": "Fix bug that prevented writing optional Avro records, arrays or maps\n\nThe writeValue method in AvroWriteSupport would correct resolve\nthe non-null type but would incorrectly try to write records,\narrays and maps with the original union schema triggering e.g.\nAvroRuntimeException: Not an array: [\"null\",{\"type\":\"array\",\"items\":\"int\"}]\n",
        "diff": {
            "parquet-avro/src/main/java/parquet/avro/AvroWriteSupport.java": [
                4,
                5
            ],
            "parquet-avro/src/test/java/parquet/avro/TestReadWrite.java": [
                3,
                10
            ],
            "parquet-avro/src/test/resources/all-minus-fixed.avsc": null
        }
    },
    "427137de9ccc343d3559a1e02a47488b7204f62b": {
        "datetime": "2013-05-20T12:09:29-07:00",
        "summary": "Merge pull request #54 from massie/master",
        "message": "Merge pull request #54 from massie/master\n\nFix bug that prevented writing optional Avro records, arrays or maps",
        "diff": {
            "parquet-avro/src/main/java/parquet/avro/AvroWriteSupport.java": [
                4,
                5
            ],
            "parquet-avro/src/test/java/parquet/avro/TestReadWrite.java": [
                3,
                10
            ],
            "parquet-avro/src/test/resources/all-minus-fixed.avsc": null
        }
    },
    "a5b478edbb89e7f168d12b7ee2b38c93cdca4a0c": {
        "datetime": "2013-05-21T10:15:28-07:00",
        "summary": "standard ordering of keywords",
        "message": "standard ordering of keywords\n",
        "diff": {
            "parquet-column/src/main/java/parquet/column/Dictionary.java": [
                2,
                2
            ]
        }
    },
    "19b369b8a7f5514c346206801773425cc333a796": {
        "datetime": "2013-05-21T11:04:30-07:00",
        "summary": "use checkNotNull",
        "message": "use checkNotNull\n",
        "diff": {
            "parquet-column/src/main/java/parquet/Preconditions.java": [
                0,
                23
            ],
            "parquet-column/src/main/java/parquet/bytes/BytesInput.java": [
                2,
                0
            ],
            "parquet-column/src/main/java/parquet/column/impl/ColumnReadStoreImpl.java": [
                4,
                0
            ],
            "parquet-column/src/main/java/parquet/column/impl/ColumnReaderImpl.java": [
                15,
                4
            ],
            "parquet-column/src/main/java/parquet/column/page/DictionaryPage.java": [
                8,
                4
            ],
            "parquet-column/src/test/java/parquet/column/page/mem/MemPageReader.java": [
                3,
                2
            ]
        }
    },
    "e85b3c20ad3fd4da72cd368359f62b19dfcb078a": {
        "datetime": "2013-05-21T11:06:44-07:00",
        "summary": "interfaces have public members",
        "message": "interfaces have public members\n",
        "diff": {
            "parquet-column/src/main/java/parquet/column/page/PageReader.java": [
                3,
                3
            ]
        }
    },
    "df1ab6f8413cf9b9b1fa33e024483cde229dc4cf": {
        "datetime": "2013-05-21T11:30:19-07:00",
        "summary": "introduce contants",
        "message": "introduce contants\n",
        "diff": {
            "parquet-column/src/main/java/parquet/Preconditions.java": [
                0,
                1
            ],
            "parquet-column/src/main/java/parquet/column/impl/ColumnWriterImpl.java": [
                4,
                15
            ],
            "parquet-column/src/main/java/parquet/column/values/dictionary/DictionaryValuesWriter.java": [
                4,
                12
            ],
            "parquet-pig/src/test/java/parquet/pig/GenerateIntTestFile.java": [
                1,
                1
            ],
            "parquet-pig/src/test/java/parquet/pig/GenerateTPCH.java": [
                1,
                1
            ],
            "parquet-pig/src/test/java/parquet/pig/TupleConsumerPerfTest.java": [
                1,
                1
            ],
            "parquet-thrift/src/test/java/parquet/thrift/TestParquetReadProtocol.java": [
                1,
                1
            ]
        }
    },
    "70d3eeba642a103c0a1d50d70086402ecec3350f": {
        "datetime": "2013-05-21T14:43:56-07:00",
        "summary": "better javadoc",
        "message": "better javadoc\n",
        "diff": {
            "parquet-column/src/main/java/parquet/column/ColumnReader.java": [
                2,
                10
            ]
        }
    },
    "f9784bf70bae3540dca2606b83fab08b1966cc04": {
        "datetime": "2013-05-21T14:48:31-07:00",
        "summary": "remove unnecessary keywords",
        "message": "remove unnecessary keywords\n",
        "diff": {
            "parquet-column/src/main/java/parquet/column/page/PageReader.java": [
                3,
                3
            ],
            "parquet-column/src/main/java/parquet/column/page/PageWriter.java": [
                4,
                4
            ]
        }
    },
    "25d8ff20756281d170ea9d26334cef0862bbac2e": {
        "datetime": "2013-05-22T18:37:51-07:00",
        "summary": "javadoc and cleanup",
        "message": "javadoc and cleanup\n",
        "diff": {
            "parquet-column/src/main/java/parquet/column/impl/ColumnReadStoreImpl.java": [
                1,
                14
            ],
            "parquet-column/src/main/java/parquet/column/page/PageReader.java": [
                2,
                2
            ],
            "parquet-column/src/main/java/parquet/column/values/dictionary/DictionaryValuesWriter.java": [
                0,
                7
            ],
            "parquet-column/src/main/java/parquet/column/values/dictionary/IntList.java": [
                4,
                41
            ],
            "parquet-column/src/main/java/parquet/column/values/dictionary/PlainBinaryDictionary.java": [
                1,
                22
            ],
            "parquet-column/src/main/java/parquet/column/values/rle/RLESimpleEncoder.java": [
                10,
                11
            ],
            "parquet-column/src/main/java/parquet/io/api/PrimitiveConverter.java": [
                3,
                3
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/ParquetFileWriter.java": [
                3,
                1
            ]
        }
    },
    "5c2034a0601384cc93258c27f8a68d60a71babb9": {
        "datetime": "2013-05-22T18:40:36-07:00",
        "summary": "license headers",
        "message": "license headers\n",
        "diff": {
            "parquet-column/src/main/java/parquet/Preconditions.java": [
                0,
                15
            ],
            "parquet-column/src/main/java/parquet/column/Dictionary.java": [
                0,
                15
            ],
            "parquet-column/src/main/java/parquet/column/page/DictionaryPage.java": [
                0,
                15
            ],
            "parquet-column/src/main/java/parquet/column/values/dictionary/DictionaryValuesReader.java": [
                0,
                15
            ],
            "parquet-column/src/main/java/parquet/column/values/dictionary/DictionaryValuesWriter.java": [
                0,
                15
            ],
            "parquet-column/src/main/java/parquet/column/values/dictionary/IntList.java": [
                0,
                15
            ],
            "parquet-column/src/main/java/parquet/column/values/dictionary/PlainBinaryDictionary.java": [
                0,
                15
            ],
            "parquet-column/src/test/java/parquet/column/values/dictionary/TestDictionary.java": [
                0,
                15
            ]
        }
    },
    "38d8a68beadb7335dd52dc10f872d96b635dfc2d": {
        "datetime": "2013-05-23T09:51:39-07:00",
        "summary": "Merge branch 'master' of github.com:Parquet/parquet-mr into dictionary_encoding",
        "message": "Merge branch 'master' of github.com:Parquet/parquet-mr into dictionary_encoding\n\nConflicts:\n\tparquet-column/src/main/java/parquet/column/impl/ColumnWriteStoreImpl.java\n\tparquet-column/src/main/java/parquet/column/impl/ColumnWriterImpl.java\n\tparquet-column/src/test/java/parquet/column/mem/TestMemColumn.java\n\tparquet-column/src/test/java/parquet/column/page/mem/MemPageWriter.java\n\tparquet-column/src/test/java/parquet/io/PerfTest.java\n\tparquet-column/src/test/java/parquet/io/TestColumnIO.java\n\tparquet-hadoop/src/main/java/parquet/hadoop/ColumnChunkPageWriteStore.java\n\tparquet-hadoop/src/main/java/parquet/hadoop/ParquetRecordWriter.java\n\tparquet-hadoop/src/main/java/parquet/hadoop/ParquetWriter.java\n\tparquet-pig/src/test/java/parquet/pig/GenerateIntTestFile.java\n\tparquet-pig/src/test/java/parquet/pig/GenerateTPCH.java\n\tparquet-pig/src/test/java/parquet/pig/TupleConsumerPerfTest.java\n\tparquet-thrift/src/test/java/parquet/thrift/TestParquetReadProtocol.java\n",
        "diff": {
            "README.md": null,
            "parquet-avro/pom.xml": null,
            "parquet-avro/src/main/java/parquet/avro/AvroGenericRecordConverter.java": [
                1,
                17
            ],
            "parquet-avro/src/main/java/parquet/avro/AvroParquetInputFormat.java": [
                0,
                15
            ],
            "parquet-avro/src/main/java/parquet/avro/AvroParquetOutputFormat.java": [
                1,
                17
            ],
            "parquet-avro/src/main/java/parquet/avro/AvroParquetWriter.java": [
                2,
                27
            ],
            "parquet-avro/src/main/java/parquet/avro/AvroReadSupport.java": [
                0,
                15
            ],
            "parquet-avro/src/main/java/parquet/avro/AvroRecordMaterializer.java": [
                0,
                15
            ],
            "parquet-avro/src/main/java/parquet/avro/AvroSchemaConverter.java": [
                1,
                27
            ],
            "parquet-avro/src/main/java/parquet/avro/AvroWriteSupport.java": [
                8,
                29
            ],
            "parquet-avro/src/main/java/parquet/avro/package-info.java": [
                0,
                15
            ],
            "parquet-avro/src/test/java/parquet/avro/TestAvroSchemaConverter.java": [
                0,
                15
            ],
            "parquet-avro/src/test/java/parquet/avro/TestInputOutputFormat.java": [
                4,
                8
            ],
            "parquet-avro/src/test/java/parquet/avro/TestReadWrite.java": [
                3,
                25
            ],
            "parquet-avro/src/test/resources/all-minus-fixed.avsc": null,
            "parquet-cascading/pom.xml": null,
            "parquet-cascading/src/main/java/parquet/cascading/ParquetTBaseScheme.java": [
                5,
                4
            ],
            "parquet-cascading/src/main/java/parquet/cascading/ParquetTupleScheme.java": [
                0,
                140
            ],
            "parquet-cascading/src/main/java/parquet/cascading/ParquetValueScheme.java": [
                1,
                1
            ],
            "parquet-cascading/src/main/java/parquet/cascading/SchemaIntersection.java": [
                0,
                60
            ],
            "parquet-cascading/src/main/java/parquet/cascading/TupleReadSupport.java": [
                0,
                77
            ],
            "parquet-cascading/src/main/java/parquet/cascading/convert/TupleConverter.java": [
                0,
                112
            ],
            "parquet-cascading/src/main/java/parquet/cascading/convert/TupleRecordMaterializer.java": [
                0,
                43
            ],
            "parquet-column/pom.xml": null,
            "parquet-column/src/main/java/parquet/Version.java": [
                0,
                73
            ],
            "parquet-column/src/main/java/parquet/bytes/BytesInput.java": [
                2,
                30
            ],
            "parquet-column/src/main/java/parquet/bytes/CapacityByteArrayOutputStream.java": [
                4,
                179
            ],
            "parquet-column/src/main/java/parquet/column/impl/ColumnWriteStoreImpl.java": [
                2,
                14
            ],
            "parquet-column/src/main/java/parquet/column/impl/ColumnWriterImpl.java": [
                14,
                48
            ],
            "parquet-column/src/main/java/parquet/column/page/PageWriter.java": [
                0,
                2
            ],
            "parquet-column/src/main/java/parquet/column/values/ValuesWriter.java": [
                0,
                2
            ],
            "parquet-column/src/main/java/parquet/column/values/bitpacking/BitPackingValuesWriter.java": [
                5,
                7
            ],
            "parquet-column/src/main/java/parquet/column/values/bitpacking/ByteBasedBitPackingEncoder.java": [
                1,
                5
            ],
            "parquet-column/src/main/java/parquet/column/values/bitpacking/ByteBasedBitPackingGenerator.java": [
                2,
                2
            ],
            "parquet-column/src/main/java/parquet/column/values/bitpacking/ByteBitPacking.java": [
                132,
                132
            ],
            "parquet-column/src/main/java/parquet/column/values/bitpacking/ByteBitPackingValuesWriter.java": [
                0,
                5
            ],
            "parquet-column/src/main/java/parquet/column/values/boundedint/BitWriter.java": [
                5,
                13
            ],
            "parquet-column/src/main/java/parquet/column/values/boundedint/BoundedIntValuesFactory.java": [
                2,
                2
            ],
            "parquet-column/src/main/java/parquet/column/values/boundedint/BoundedIntValuesWriter.java": [
                5,
                11
            ],
            "parquet-column/src/main/java/parquet/column/values/boundedint/DevNullValuesWriter.java": [
                0,
                5
            ],
            "parquet-column/src/main/java/parquet/column/values/dictionary/DictionaryValuesWriter.java": [
                0,
                11
            ],
            "parquet-column/src/main/java/parquet/column/values/plain/BooleanPlainValuesWriter.java": [
                0,
                5
            ],
            "parquet-column/src/main/java/parquet/column/values/plain/PlainValuesWriter.java": [
                0,
                5
            ],
            "parquet-column/src/main/java/parquet/io/MessageColumnIO.java": [
                35,
                41
            ],
            "parquet-column/src/test/java/parquet/bytes/TestCapacityByteArrayOutputStream.java": [
                0,
                134
            ],
            "parquet-column/src/test/java/parquet/column/mem/TestMemColumn.java": [
                6,
                6
            ],
            "parquet-column/src/test/java/parquet/column/page/mem/MemPageWriter.java": [
                0,
                6
            ],
            "parquet-column/src/test/java/parquet/column/values/bitpacking/TestBitPackingColumn.java": [
                1,
                1
            ],
            "parquet-column/src/test/java/parquet/column/values/boundedint/TestBoundedColumns.java": [
                2,
                2
            ],
            "parquet-column/src/test/java/parquet/io/ExpectationValidatingConverter.java": [
                0,
                6
            ],
            "parquet-column/src/test/java/parquet/io/PerfTest.java": [
                1,
                1
            ],
            "parquet-column/src/test/java/parquet/io/TestColumnIO.java": [
                11,
                24
            ],
            "parquet-hadoop/pom.xml": null,
            "parquet-hadoop/src/main/java/parquet/format/converter/ParquetMetadataConverter.java": [
                1,
                3
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/ColumnChunkPageWriteStore.java": [
                3,
                9
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/ParquetFileReader.java": [
                0,
                6
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/ParquetFileWriter.java": [
                7,
                20
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/ParquetInputFormat.java": [
                14,
                25
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/ParquetOutputCommitter.java": [
                1,
                2
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/ParquetOutputFormat.java": [
                12,
                13
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/ParquetReader.java": [
                6,
                1
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/ParquetRecordReader.java": [
                2,
                7
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/ParquetRecordWriter.java": [
                2,
                14
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/ParquetWriter.java": [
                6,
                40
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/example/ExampleOutputFormat.java": [
                2,
                3
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/mapred/DeprecatedParquetInputFormat.java": [
                0,
                204
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/metadata/FileMetaData.java": [
                1,
                12
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/util/ContextUtil.java": [
                0,
                221
            ],
            "parquet-hadoop/src/test/java/parquet/hadoop/TestInputFormat.java": [
                4,
                3
            ],
            "parquet-hadoop/src/test/java/parquet/hadoop/TestParquetFileWriter.java": [
                0,
                7
            ],
            "parquet-hadoop/src/test/java/parquet/hadoop/example/TestInputOutputFormat.java": [
                1,
                2
            ],
            "parquet-pig/pom.xml": null,
            "parquet-pig/src/main/java/parquet/pig/ParquetLoader.java": [
                1,
                2
            ],
            "parquet-pig/src/main/java/parquet/pig/ParquetStorer.java": [
                1,
                5
            ],
            "parquet-pig/src/test/java/parquet/pig/GenerateIntTestFile.java": [
                2,
                1
            ],
            "parquet-pig/src/test/java/parquet/pig/GenerateTPCH.java": [
                6,
                6
            ],
            "parquet-pig/src/test/java/parquet/pig/PerfTest2.java": [
                5,
                6
            ],
            "parquet-pig/src/test/java/parquet/pig/TupleConsumerPerfTest.java": [
                1,
                1
            ],
            "parquet-scrooge/pom.xml": null,
            "parquet-scrooge/src/main/java/parquet/scrooge/ParquetScroogeScheme.java": [
                4,
                4
            ],
            "parquet-test-hadoop2/pom.xml": null,
            "parquet-test-hadoop2/src/test/java/parquet/hadoop2/TestInputOutputFormat.java": [
                0,
                139
            ],
            "parquet-thrift/pom.xml": null,
            "parquet-thrift/src/main/java/parquet/hadoop/thrift/Container.java": [
                1,
                1
            ],
            "parquet-thrift/src/main/java/parquet/hadoop/thrift/DeprecatedContainerInputFormat.java": [
                372,
                0
            ],
            "parquet-thrift/src/main/java/parquet/hadoop/thrift/ParquetThriftBytesOutputFormat.java": [
                3,
                4
            ],
            "parquet-thrift/src/main/java/parquet/hadoop/thrift/ParquetThriftOutputFormat.java": [
                2,
                3
            ],
            "parquet-thrift/src/main/java/parquet/thrift/ParquetProtocol.java": [
                42,
                56
            ],
            "parquet-thrift/src/main/java/parquet/thrift/TBaseRecordConverter.java": [
                7,
                10
            ],
            "parquet-thrift/src/test/java/parquet/hadoop/thrift/TestInputOutputFormat.java": [
                1,
                1
            ],
            "parquet-thrift/src/test/java/parquet/hadoop/thrift/TestThriftToParquetFileWriter.java": [
                2,
                3
            ],
            "parquet-thrift/src/test/java/parquet/thrift/TestParquetReadProtocol.java": [
                2,
                2
            ],
            "pom.xml": null
        }
    },
    "5cedb4afb0065fe9dbf3f4bd7cf8e4c953689780": {
        "datetime": "2013-05-23T10:00:26-07:00",
        "summary": "license headers",
        "message": "license headers\n",
        "diff": {
            "parquet-column/src/main/java/parquet/Version.java": [
                0,
                15
            ],
            "parquet-column/src/test/java/parquet/bytes/TestCapacityByteArrayOutputStream.java": [
                0,
                15
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/util/ContextUtil.java": [
                0,
                15
            ]
        }
    },
    "9a30c8fdbe0c7850cb5cac9d5778217e7a026e36": {
        "datetime": "2013-05-23T16:12:16-07:00",
        "summary": "Merge pull request #40 from Parquet/dictionary_encoding",
        "message": "Merge pull request #40 from Parquet/dictionary_encoding\n\nDictionary encoding",
        "diff": {
            ".gitignore": null,
            "parquet-column/src/main/java/parquet/Log.java": [
                1,
                1
            ],
            "parquet-column/src/main/java/parquet/Preconditions.java": [
                0,
                39
            ],
            "parquet-column/src/main/java/parquet/Version.java": [
                0,
                15
            ],
            "parquet-column/src/main/java/parquet/bytes/BytesInput.java": [
                2,
                6
            ],
            "parquet-column/src/main/java/parquet/column/ColumnReader.java": [
                5,
                19
            ],
            "parquet-column/src/main/java/parquet/column/Dictionary.java": [
                0,
                63
            ],
            "parquet-column/src/main/java/parquet/column/Encoding.java": [
                10,
                56
            ],
            "parquet-column/src/main/java/parquet/column/impl/ColumnReadStoreImpl.java": [
                171,
                41
            ],
            "parquet-column/src/main/java/parquet/column/impl/ColumnReaderImpl.java": [
                41,
                234
            ],
            "parquet-column/src/main/java/parquet/column/impl/ColumnWriteStoreImpl.java": [
                2,
                4
            ],
            "parquet-column/src/main/java/parquet/column/impl/ColumnWriterImpl.java": [
                1,
                28
            ],
            "parquet-column/src/main/java/parquet/column/page/DictionaryPage.java": [
                0,
                89
            ],
            "parquet-column/src/main/java/parquet/column/page/PageReader.java": [
                8,
                11
            ],
            "parquet-column/src/main/java/parquet/column/page/PageWriter.java": [
                5,
                9
            ],
            "parquet-column/src/main/java/parquet/column/values/ValuesReader.java": [
                23,
                25
            ],
            "parquet-column/src/main/java/parquet/column/values/ValuesWriter.java": [
                1,
                16
            ],
            "parquet-column/src/main/java/parquet/column/values/bitpacking/ByteBasedBitPackingEncoder.java": [
                0,
                5
            ],
            "parquet-column/src/main/java/parquet/column/values/dictionary/DictionaryValuesReader.java": [
                0,
                81
            ],
            "parquet-column/src/main/java/parquet/column/values/dictionary/DictionaryValuesWriter.java": [
                0,
                247
            ],
            "parquet-column/src/main/java/parquet/column/values/dictionary/IntList.java": [
                0,
                120
            ],
            "parquet-column/src/main/java/parquet/column/values/dictionary/PlainBinaryDictionary.java": [
                0,
                83
            ],
            "parquet-column/src/main/java/parquet/column/values/plain/PlainValuesReader.java": [
                9,
                0
            ],
            "parquet-column/src/main/java/parquet/column/values/rle/RLEDecoder.java": [
                0,
                7
            ],
            "parquet-column/src/main/java/parquet/column/values/rle/RLESimpleEncoder.java": [
                6,
                26
            ],
            "parquet-column/src/main/java/parquet/io/MessageColumnIO.java": [
                1,
                6
            ],
            "parquet-column/src/main/java/parquet/io/RecordReaderImplementation.java": [
                1,
                1
            ],
            "parquet-column/src/main/java/parquet/io/api/Binary.java": [
                1,
                6
            ],
            "parquet-column/src/main/java/parquet/io/api/GroupConverter.java": [
                1,
                2
            ],
            "parquet-column/src/main/java/parquet/io/api/PrimitiveConverter.java": [
                6,
                27
            ],
            "parquet-column/src/main/java/parquet/schema/PrimitiveType.java": [
                7,
                68
            ],
            "parquet-column/src/test/java/parquet/bytes/TestCapacityByteArrayOutputStream.java": [
                0,
                15
            ],
            "parquet-column/src/test/java/parquet/column/mem/TestMemColumn.java": [
                22,
                33
            ],
            "parquet-column/src/test/java/parquet/column/page/mem/MemPageReader.java": [
                6,
                13
            ],
            "parquet-column/src/test/java/parquet/column/page/mem/MemPageStore.java": [
                1,
                1
            ],
            "parquet-column/src/test/java/parquet/column/page/mem/MemPageWriter.java": [
                0,
                17
            ],
            "parquet-column/src/test/java/parquet/column/values/dictionary/TestDictionary.java": [
                0,
                131
            ],
            "parquet-column/src/test/java/parquet/io/PerfTest.java": [
                1,
                1
            ],
            "parquet-column/src/test/java/parquet/io/TestColumnIO.java": [
                11,
                4
            ],
            "parquet-hadoop/src/main/java/parquet/format/converter/ParquetMetadataConverter.java": [
                1,
                12
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/ColumnChunkPageReadStore.java": [
                1,
                19
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/ColumnChunkPageWriteStore.java": [
                0,
                35
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/ParquetFileReader.java": [
                37,
                44
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/ParquetFileWriter.java": [
                1,
                28
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/ParquetOutputFormat.java": [
                1,
                21
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/ParquetRecordWriter.java": [
                3,
                6
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/ParquetWriter.java": [
                19,
                28
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/PrintFooter.java": [
                5,
                10
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/metadata/ColumnChunkMetaData.java": [
                7,
                16
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/util/ContextUtil.java": [
                4,
                15
            ],
            "parquet-pig/src/main/java/parquet/pig/convert/TupleConverter.java": [
                1,
                25
            ],
            "parquet-pig/src/test/java/parquet/pig/GenerateIntTestFile.java": [
                7,
                1
            ],
            "parquet-pig/src/test/java/parquet/pig/GenerateTPCH.java": [
                2,
                1
            ],
            "parquet-pig/src/test/java/parquet/pig/TupleConsumerPerfTest.java": [
                1,
                1
            ],
            "parquet-thrift/src/test/java/parquet/thrift/TestParquetReadProtocol.java": [
                1,
                1
            ],
            "parquet-thrift/src/test/java/parquet/thrift/TestThriftSchemaConverter.java": [
                0,
                1
            ]
        }
    },
    "0a7c59aac0bc55999d768ffbef4d503e1282e6ca": {
        "datetime": "2013-05-29T15:48:54-07:00",
        "summary": "Speed up Avro string parsing",
        "message": "Speed up Avro string parsing\n",
        "diff": {
            "parquet-column/src/main/java/parquet/io/api/Binary.java": [
                1,
                7
            ]
        }
    },
    "b3e94326c9488270af209f0cc978b956fb2a5380": {
        "datetime": "2013-05-29T15:53:55-07:00",
        "summary": "First pass at RLE hybrid",
        "message": "First pass at RLE hybrid\n",
        "diff": {
            ".gitignore": null,
            "parquet-column/src/main/java/parquet/Preconditions.java": [
                1,
                14
            ],
            "parquet-column/src/main/java/parquet/bytes/BytesUtils.java": [
                0,
                38
            ],
            "parquet-column/src/main/java/parquet/bytes/CapacityByteArrayOutputStream.java": [
                3,
                26
            ],
            "parquet-column/src/main/java/parquet/column/values/rle/RunLengthBitPackingHybridEncoder.java": [
                0,
                260
            ]
        }
    },
    "0f9eee5ff50ea7475e34bea444ea0de2d877862f": {
        "datetime": "2013-05-29T16:00:47-07:00",
        "summary": "Cleanup",
        "message": "Cleanup\n",
        "diff": {
            "parquet-column/src/main/java/parquet/bytes/CapacityByteArrayOutputStream.java": [
                5,
                12
            ]
        }
    },
    "2ffdab725e039a33d2c34196bbbcd52fb4fb005c": {
        "datetime": "2013-05-29T16:25:37-07:00",
        "summary": "Add test for setByte()",
        "message": "Add test for setByte()\n",
        "diff": {
            "parquet-column/src/main/java/parquet/bytes/CapacityByteArrayOutputStream.java": [
                1,
                1
            ],
            "parquet-column/src/test/java/parquet/bytes/TestCapacityByteArrayOutputStream.java": [
                0,
                86
            ]
        }
    },
    "d29eeb570d0b5e3c07cbd85152349c72a0f976dd": {
        "datetime": "2013-05-29T16:28:38-07:00",
        "summary": "cleanup preconditions",
        "message": "cleanup preconditions\n",
        "diff": {
            "parquet-column/src/main/java/parquet/Preconditions.java": [
                3,
                12
            ]
        }
    },
    "27d1c2c4fb4b0af707cae81d003bbb83e47a9382": {
        "datetime": "2013-05-29T16:31:04-07:00",
        "summary": "Add javadoc to ByteUtils",
        "message": "Add javadoc to ByteUtils\n",
        "diff": {
            "parquet-column/src/main/java/parquet/bytes/BytesUtils.java": [
                0,
                4
            ]
        }
    },
    "c71cb25c988f31893a1258faf9d5c086c03216ed": {
        "datetime": "2013-05-29T16:36:20-07:00",
        "summary": "Merge pull request #55 from laserson/fastavro",
        "message": "Merge pull request #55 from laserson/fastavro\n\nWrite Avro objects to Parquet files 30x faster",
        "diff": {
            "parquet-column/src/main/java/parquet/io/api/Binary.java": [
                1,
                7
            ]
        }
    },
    "71bd4e2ee5e64d726e6978e4f595f9d281413301": {
        "datetime": "2013-05-29T17:31:45-07:00",
        "summary": "bit packing support for LE",
        "message": "bit packing support for LE\n",
        "diff": {
            "parquet-column/src/main/java/parquet/column/Encoding.java": [
                1,
                4
            ],
            "parquet-column/src/main/java/parquet/column/impl/ColumnWriterImpl.java": [
                3,
                4
            ],
            "parquet-column/src/main/java/parquet/column/values/bitpacking/ByteBasedBitPackingEncoder.java": [
                2,
                2
            ],
            "parquet-column/src/main/java/parquet/column/values/bitpacking/ByteBasedBitPackingGenerator.java": [
                78,
                96
            ],
            "parquet-column/src/main/java/parquet/column/values/bitpacking/ByteBitPacking.java": [
                1,
                1
            ],
            "parquet-column/src/main/java/parquet/column/values/bitpacking/ByteBitPackingLE.java": [
                0,
                25636
            ],
            "parquet-column/src/main/java/parquet/column/values/bitpacking/ByteBitPackingValuesReader.java": [
                2,
                2
            ],
            "parquet-column/src/main/java/parquet/column/values/bitpacking/ByteBitPackingValuesWriter.java": [
                4,
                6
            ],
            "parquet-column/src/main/java/parquet/column/values/bitpacking/Packer.java": [
                0,
                67
            ],
            "parquet-column/src/main/java/parquet/column/values/plain/BooleanPlainValuesReader.java": [
                12,
                5
            ],
            "parquet-column/src/main/java/parquet/column/values/plain/BooleanPlainValuesWriter.java": [
                31,
                11
            ],
            "parquet-column/src/main/java/parquet/column/values/rle/RLEDecoder.java": [
                2,
                2
            ],
            "parquet-column/src/main/java/parquet/column/values/rle/RLESimpleEncoder.java": [
                2,
                2
            ],
            "parquet-column/src/test/java/parquet/column/values/bitpacking/BitPackingPerfTest.java": [
                1,
                1
            ],
            "parquet-column/src/test/java/parquet/column/values/bitpacking/TestBitPackingColumn.java": [
                2,
                3
            ],
            "parquet-column/src/test/java/parquet/column/values/bitpacking/TestByteBitPacking.java": [
                32,
                44
            ],
            "parquet-column/src/test/java/parquet/column/values/bitpacking/TestLemireBitPacking.java": [
                15,
                23
            ]
        }
    },
    "cd3a1238950c7821e1505396270335fab989d9b3": {
        "datetime": "2013-05-29T17:45:33-07:00",
        "summary": "Start tests for rle hybrid",
        "message": "Start tests for rle hybrid\n",
        "diff": {
            "parquet-column/src/main/java/parquet/column/values/rle/RunLengthBitPackingHybridEncoder.java": [
                2,
                4
            ],
            "parquet-column/src/test/java/parquet/column/values/rle/TestRunLengthBitPackingHybridEncoder.java": [
                0,
                85
            ]
        }
    },
    "c9c1080bebb2173585ac55e1d118a58be80d968f": {
        "datetime": "2013-05-30T17:32:08-07:00",
        "summary": "Add bit packing overflow test",
        "message": "Add bit packing overflow test\n",
        "diff": {
            "parquet-column/src/test/java/parquet/column/values/rle/TestRunLengthBitPackingHybridEncoder.java": [
                10,
                44
            ]
        }
    },
    "24f652409db7ee67faea791e896cca4c97e184b6": {
        "datetime": "2013-05-30T20:51:57-07:00",
        "summary": "End to end test",
        "message": "End to end test\n",
        "diff": {
            "parquet-column/src/main/java/parquet/column/values/rle/RunLengthBitPackingHybridEncoder.java": [
                11,
                2
            ],
            "parquet-column/src/test/java/parquet/column/values/rle/TestRunLengthBitPackingHybridEncoder.java": [
                0,
                152
            ]
        }
    },
    "65fb8d3e069b321d6b6bd551e4d1c652546d37f8": {
        "datetime": "2013-05-31T01:23:36-07:00",
        "summary": "move unpack",
        "message": "move unpack\n",
        "diff": {
            "parquet-column/src/test/java/parquet/column/values/rle/TestRunLengthBitPackingHybridEncoder.java": [
                24,
                25
            ]
        }
    },
    "63ed7191384053817b91910a428a028fe1ad0336": {
        "datetime": "2013-05-31T13:50:03-07:00",
        "summary": "Fixup / rename RLEDecoder, fix tests",
        "message": "Fixup / rename RLEDecoder, fix tests\n",
        "diff": {
            "parquet-column/src/main/java/parquet/bytes/BytesUtils.java": [
                0,
                19
            ],
            "parquet-column/src/main/java/parquet/column/values/dictionary/DictionaryValuesReader.java": [
                4,
                3
            ],
            "parquet-column/src/main/java/parquet/column/values/dictionary/DictionaryValuesWriter.java": [
                8,
                9
            ],
            "parquet-column/src/main/java/parquet/column/values/rle/RLEDecoder.java": [
                26,
                18
            ],
            "parquet-column/src/main/java/parquet/column/values/rle/RLESimpleEncoder.java": [
                73,
                0
            ],
            "parquet-column/src/main/java/parquet/column/values/rle/RunLengthBitPackingHybridEncoder.java": [
                0,
                10
            ],
            "parquet-column/src/test/java/parquet/column/values/rle/RunLengthBitPackingHybridIntegrationTest.java": [
                0,
                75
            ],
            "parquet-column/src/test/java/parquet/column/values/rle/TestRLE.java": [
                62,
                0
            ]
        }
    },
    "99853be93af6457b2989f57b063e7b6c053aeb0a": {
        "datetime": "2013-05-31T13:50:46-07:00",
        "summary": "Merge branch 'master' into alexlevenson/RLE-bit-packing-hybrid",
        "message": "Merge branch 'master' into alexlevenson/RLE-bit-packing-hybrid\n",
        "diff": {
            "parquet-column/src/main/java/parquet/io/api/Binary.java": [
                1,
                7
            ]
        }
    },
    "ded5bec1da026c6f994238d3ff72cdb5383cb9e7": {
        "datetime": "2013-05-31T14:01:03-07:00",
        "summary": "cleanup comments",
        "message": "cleanup comments\n",
        "diff": {
            "parquet-column/src/main/java/parquet/column/values/rle/RunLengthBitPackingHybridEncoder.java": [
                2,
                5
            ]
        }
    },
    "14e05746ee12bcc484feab28a65e128763980b69": {
        "datetime": "2013-06-03T01:15:30-07:00",
        "summary": "Merge pull request #57 from Parquet/bit_packing_lsb_first",
        "message": "Merge pull request #57 from Parquet/bit_packing_lsb_first\n\nbit packing support for LE",
        "diff": {
            "parquet-column/src/main/java/parquet/column/Encoding.java": [
                1,
                4
            ],
            "parquet-column/src/main/java/parquet/column/impl/ColumnWriterImpl.java": [
                3,
                4
            ],
            "parquet-column/src/main/java/parquet/column/values/bitpacking/ByteBasedBitPackingEncoder.java": [
                2,
                2
            ],
            "parquet-column/src/main/java/parquet/column/values/bitpacking/ByteBasedBitPackingGenerator.java": [
                78,
                96
            ],
            "parquet-column/src/main/java/parquet/column/values/bitpacking/ByteBitPacking.java": [
                1,
                1
            ],
            "parquet-column/src/main/java/parquet/column/values/bitpacking/ByteBitPackingLE.java": [
                0,
                25636
            ],
            "parquet-column/src/main/java/parquet/column/values/bitpacking/ByteBitPackingValuesReader.java": [
                2,
                2
            ],
            "parquet-column/src/main/java/parquet/column/values/bitpacking/ByteBitPackingValuesWriter.java": [
                4,
                6
            ],
            "parquet-column/src/main/java/parquet/column/values/bitpacking/Packer.java": [
                0,
                67
            ],
            "parquet-column/src/main/java/parquet/column/values/plain/BooleanPlainValuesReader.java": [
                12,
                5
            ],
            "parquet-column/src/main/java/parquet/column/values/plain/BooleanPlainValuesWriter.java": [
                31,
                11
            ],
            "parquet-column/src/main/java/parquet/column/values/rle/RLEDecoder.java": [
                2,
                2
            ],
            "parquet-column/src/main/java/parquet/column/values/rle/RLESimpleEncoder.java": [
                2,
                2
            ],
            "parquet-column/src/test/java/parquet/column/values/bitpacking/BitPackingPerfTest.java": [
                1,
                1
            ],
            "parquet-column/src/test/java/parquet/column/values/bitpacking/TestBitPackingColumn.java": [
                2,
                3
            ],
            "parquet-column/src/test/java/parquet/column/values/bitpacking/TestByteBitPacking.java": [
                32,
                44
            ],
            "parquet-column/src/test/java/parquet/column/values/bitpacking/TestLemireBitPacking.java": [
                15,
                23
            ]
        }
    },
    "abb6e3644ad6104980831ecd12815d8fcff4acfd": {
        "datetime": "2013-06-03T08:22:08-07:00",
        "summary": "Address first round of comments",
        "message": "Address first round of comments\n",
        "diff": {
            "parquet-column/src/main/java/parquet/Preconditions.java": [
                11,
                0
            ],
            "parquet-column/src/main/java/parquet/bytes/BytesUtils.java": [
                1,
                5
            ],
            "parquet-column/src/main/java/parquet/column/Encoding.java": [
                4,
                11
            ],
            "parquet-column/src/main/java/parquet/column/values/dictionary/DictionaryValuesWriter.java": [
                1,
                2
            ],
            "parquet-column/src/main/java/parquet/column/values/rle/RunLengthBitPackingHybridDecoder.java": [
                2,
                2
            ],
            "parquet-column/src/main/java/parquet/column/values/rle/RunLengthBitPackingHybridEncoder.java": [
                8,
                1
            ],
            "parquet-column/src/main/java/parquet/column/values/rle/RunLengthBitPackingHybridValuesReader.java": [
                0,
                36
            ],
            "parquet-column/src/test/java/parquet/column/values/rle/RunLengthBitPackingHybridIntegrationTest.java": [
                1,
                1
            ],
            "parquet-column/src/test/java/parquet/column/values/rle/TestRunLengthBitPackingHybridEncoder.java": [
                0,
                16
            ]
        }
    },
    "cd6a02d27bf20f601d8109ddbd756d7f665f2281": {
        "datetime": "2013-06-03T08:27:00-07:00",
        "summary": "Merge branch 'master' into alexlevenson/RLE-bit-packing-hybrid",
        "message": "Merge branch 'master' into alexlevenson/RLE-bit-packing-hybrid\n\nConflicts:\n\tparquet-column/src/main/java/parquet/column/Encoding.java\n\tparquet-column/src/main/java/parquet/column/values/rle/RLESimpleEncoder.java\n\tparquet-column/src/main/java/parquet/column/values/rle/RunLengthBitPackingHybridDecoder.java\n",
        "diff": {
            "parquet-column/src/main/java/parquet/column/Encoding.java": [
                1,
                3
            ],
            "parquet-column/src/main/java/parquet/column/impl/ColumnWriterImpl.java": [
                3,
                4
            ],
            "parquet-column/src/main/java/parquet/column/values/bitpacking/ByteBasedBitPackingEncoder.java": [
                2,
                2
            ],
            "parquet-column/src/main/java/parquet/column/values/bitpacking/ByteBasedBitPackingGenerator.java": [
                78,
                96
            ],
            "parquet-column/src/main/java/parquet/column/values/bitpacking/ByteBitPacking.java": [
                1,
                1
            ],
            "parquet-column/src/main/java/parquet/column/values/bitpacking/ByteBitPackingLE.java": [
                0,
                25636
            ],
            "parquet-column/src/main/java/parquet/column/values/bitpacking/ByteBitPackingValuesReader.java": [
                2,
                2
            ],
            "parquet-column/src/main/java/parquet/column/values/bitpacking/ByteBitPackingValuesWriter.java": [
                4,
                6
            ],
            "parquet-column/src/main/java/parquet/column/values/bitpacking/Packer.java": [
                0,
                67
            ],
            "parquet-column/src/main/java/parquet/column/values/plain/BooleanPlainValuesReader.java": [
                12,
                5
            ],
            "parquet-column/src/main/java/parquet/column/values/plain/BooleanPlainValuesWriter.java": [
                31,
                11
            ],
            "parquet-column/src/main/java/parquet/column/values/rle/RunLengthBitPackingHybridDecoder.java": [
                2,
                2
            ],
            "parquet-column/src/test/java/parquet/column/values/bitpacking/BitPackingPerfTest.java": [
                1,
                1
            ],
            "parquet-column/src/test/java/parquet/column/values/bitpacking/TestBitPackingColumn.java": [
                2,
                3
            ],
            "parquet-column/src/test/java/parquet/column/values/bitpacking/TestByteBitPacking.java": [
                32,
                44
            ],
            "parquet-column/src/test/java/parquet/column/values/bitpacking/TestLemireBitPacking.java": [
                15,
                23
            ]
        }
    },
    "d7fe1a5d2b2129c53a5d8425f9e3ca14f42522f9": {
        "datetime": "2013-06-03T08:50:41-07:00",
        "summary": "Use RLE for repetition / definition levels",
        "message": "Use RLE for repetition / definition levels\n",
        "diff": {
            "parquet-column/src/main/java/parquet/column/impl/ColumnWriterImpl.java": [
                6,
                15
            ],
            "parquet-column/src/main/java/parquet/column/values/ValuesReader.java": [
                1,
                1
            ],
            "parquet-column/src/main/java/parquet/column/values/ValuesWriter.java": [
                1,
                1
            ],
            "parquet-column/src/main/java/parquet/column/values/rle/RunLengthBitPackingHybridEncoder.java": [
                2,
                10
            ],
            "parquet-column/src/main/java/parquet/column/values/rle/RunLengthBitPackingHybridValuesWriter.java": [
                0,
                62
            ],
            "parquet-column/src/test/java/parquet/column/values/rle/TestRunLengthBitPackingHybridEncoder.java": [
                2,
                2
            ]
        }
    },
    "47824efda9cb7d027138981672d569a042b4af06": {
        "datetime": "2013-06-03T12:21:39-07:00",
        "summary": "Merge branch 'master' of github.com:Parquet/parquet-mr into add_validation_setting",
        "message": "Merge branch 'master' of github.com:Parquet/parquet-mr into add_validation_setting\n\nConflicts:\n\tparquet-hadoop/src/main/java/parquet/hadoop/ParquetOutputFormat.java\n\tparquet-hadoop/src/main/java/parquet/hadoop/ParquetRecordWriter.java\n\tparquet-hadoop/src/main/java/parquet/hadoop/ParquetWriter.java\n",
        "diff": {
            ".gitignore": null,
            "parquet-avro/src/main/java/parquet/avro/AvroWriteSupport.java": [
                4,
                5
            ],
            "parquet-avro/src/test/java/parquet/avro/TestReadWrite.java": [
                3,
                10
            ],
            "parquet-avro/src/test/resources/all-minus-fixed.avsc": null,
            "parquet-column/src/main/java/parquet/Log.java": [
                1,
                1
            ],
            "parquet-column/src/main/java/parquet/Preconditions.java": [
                0,
                39
            ],
            "parquet-column/src/main/java/parquet/Version.java": [
                0,
                15
            ],
            "parquet-column/src/main/java/parquet/bytes/BytesInput.java": [
                2,
                6
            ],
            "parquet-column/src/main/java/parquet/column/ColumnReader.java": [
                5,
                19
            ],
            "parquet-column/src/main/java/parquet/column/Dictionary.java": [
                0,
                63
            ],
            "parquet-column/src/main/java/parquet/column/Encoding.java": [
                11,
                60
            ],
            "parquet-column/src/main/java/parquet/column/impl/ColumnReadStoreImpl.java": [
                171,
                41
            ],
            "parquet-column/src/main/java/parquet/column/impl/ColumnReaderImpl.java": [
                41,
                234
            ],
            "parquet-column/src/main/java/parquet/column/impl/ColumnWriteStoreImpl.java": [
                2,
                4
            ],
            "parquet-column/src/main/java/parquet/column/impl/ColumnWriterImpl.java": [
                4,
                32
            ],
            "parquet-column/src/main/java/parquet/column/page/DictionaryPage.java": [
                0,
                89
            ],
            "parquet-column/src/main/java/parquet/column/page/PageReader.java": [
                8,
                11
            ],
            "parquet-column/src/main/java/parquet/column/page/PageWriter.java": [
                5,
                9
            ],
            "parquet-column/src/main/java/parquet/column/values/ValuesReader.java": [
                23,
                25
            ],
            "parquet-column/src/main/java/parquet/column/values/ValuesWriter.java": [
                1,
                16
            ],
            "parquet-column/src/main/java/parquet/column/values/bitpacking/ByteBasedBitPackingEncoder.java": [
                2,
                7
            ],
            "parquet-column/src/main/java/parquet/column/values/bitpacking/ByteBasedBitPackingGenerator.java": [
                78,
                96
            ],
            "parquet-column/src/main/java/parquet/column/values/bitpacking/ByteBitPacking.java": [
                1,
                1
            ],
            "parquet-column/src/main/java/parquet/column/values/bitpacking/ByteBitPackingLE.java": [
                0,
                25636
            ],
            "parquet-column/src/main/java/parquet/column/values/bitpacking/ByteBitPackingValuesReader.java": [
                2,
                2
            ],
            "parquet-column/src/main/java/parquet/column/values/bitpacking/ByteBitPackingValuesWriter.java": [
                4,
                6
            ],
            "parquet-column/src/main/java/parquet/column/values/bitpacking/Packer.java": [
                0,
                67
            ],
            "parquet-column/src/main/java/parquet/column/values/dictionary/DictionaryValuesReader.java": [
                0,
                81
            ],
            "parquet-column/src/main/java/parquet/column/values/dictionary/DictionaryValuesWriter.java": [
                0,
                247
            ],
            "parquet-column/src/main/java/parquet/column/values/dictionary/IntList.java": [
                0,
                120
            ],
            "parquet-column/src/main/java/parquet/column/values/dictionary/PlainBinaryDictionary.java": [
                0,
                83
            ],
            "parquet-column/src/main/java/parquet/column/values/plain/BooleanPlainValuesReader.java": [
                12,
                5
            ],
            "parquet-column/src/main/java/parquet/column/values/plain/BooleanPlainValuesWriter.java": [
                31,
                11
            ],
            "parquet-column/src/main/java/parquet/column/values/plain/PlainValuesReader.java": [
                9,
                0
            ],
            "parquet-column/src/main/java/parquet/column/values/rle/RLEDecoder.java": [
                2,
                9
            ],
            "parquet-column/src/main/java/parquet/column/values/rle/RLESimpleEncoder.java": [
                7,
                27
            ],
            "parquet-column/src/main/java/parquet/io/MessageColumnIO.java": [
                1,
                6
            ],
            "parquet-column/src/main/java/parquet/io/RecordReaderImplementation.java": [
                1,
                1
            ],
            "parquet-column/src/main/java/parquet/io/api/Binary.java": [
                2,
                13
            ],
            "parquet-column/src/main/java/parquet/io/api/GroupConverter.java": [
                1,
                2
            ],
            "parquet-column/src/main/java/parquet/io/api/PrimitiveConverter.java": [
                6,
                27
            ],
            "parquet-column/src/main/java/parquet/schema/PrimitiveType.java": [
                7,
                68
            ],
            "parquet-column/src/test/java/parquet/bytes/TestCapacityByteArrayOutputStream.java": [
                0,
                15
            ],
            "parquet-column/src/test/java/parquet/column/mem/TestMemColumn.java": [
                22,
                33
            ],
            "parquet-column/src/test/java/parquet/column/page/mem/MemPageReader.java": [
                6,
                13
            ],
            "parquet-column/src/test/java/parquet/column/page/mem/MemPageStore.java": [
                1,
                1
            ],
            "parquet-column/src/test/java/parquet/column/page/mem/MemPageWriter.java": [
                0,
                17
            ],
            "parquet-column/src/test/java/parquet/column/values/bitpacking/BitPackingPerfTest.java": [
                1,
                1
            ],
            "parquet-column/src/test/java/parquet/column/values/bitpacking/TestBitPackingColumn.java": [
                2,
                3
            ],
            "parquet-column/src/test/java/parquet/column/values/bitpacking/TestByteBitPacking.java": [
                32,
                44
            ],
            "parquet-column/src/test/java/parquet/column/values/bitpacking/TestLemireBitPacking.java": [
                15,
                23
            ],
            "parquet-column/src/test/java/parquet/column/values/dictionary/TestDictionary.java": [
                0,
                131
            ],
            "parquet-column/src/test/java/parquet/io/PerfTest.java": [
                1,
                1
            ],
            "parquet-column/src/test/java/parquet/io/TestColumnIO.java": [
                11,
                4
            ],
            "parquet-hadoop/src/main/java/parquet/format/converter/ParquetMetadataConverter.java": [
                1,
                12
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/ColumnChunkPageReadStore.java": [
                1,
                19
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/ColumnChunkPageWriteStore.java": [
                0,
                35
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/ParquetFileReader.java": [
                37,
                44
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/ParquetFileWriter.java": [
                1,
                28
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/ParquetOutputFormat.java": [
                1,
                22
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/ParquetRecordWriter.java": [
                3,
                5
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/ParquetWriter.java": [
                22,
                23
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/PrintFooter.java": [
                5,
                10
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/metadata/ColumnChunkMetaData.java": [
                7,
                16
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/util/ContextUtil.java": [
                4,
                15
            ],
            "parquet-pig/src/main/java/parquet/pig/convert/TupleConverter.java": [
                1,
                25
            ],
            "parquet-pig/src/test/java/parquet/pig/GenerateIntTestFile.java": [
                7,
                1
            ],
            "parquet-pig/src/test/java/parquet/pig/GenerateTPCH.java": [
                2,
                1
            ],
            "parquet-pig/src/test/java/parquet/pig/TupleConsumerPerfTest.java": [
                1,
                1
            ],
            "parquet-thrift/src/test/java/parquet/thrift/TestParquetReadProtocol.java": [
                1,
                1
            ],
            "parquet-thrift/src/test/java/parquet/thrift/TestThriftSchemaConverter.java": [
                0,
                1
            ]
        }
    },
    "af0ccf9cd78d49436fedadd9b4dd32d1b8dc9bad": {
        "datetime": "2013-06-03T12:25:52-07:00",
        "summary": "better error message and javadoc",
        "message": "better error message and javadoc\n",
        "diff": {
            "parquet-column/src/main/java/parquet/column/impl/ColumnReaderImpl.java": [
                1,
                1
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/ParquetWriter.java": [
                2,
                4
            ]
        }
    },
    "c2115825b690aba1f2cf6a48fde96c9aea489e26": {
        "datetime": "2013-06-03T14:25:21-07:00",
        "summary": "Merge pull request #53 from Parquet/add_validation_setting",
        "message": "Merge pull request #53 from Parquet/add_validation_setting\n\nadd a validation setting to OutputFormat",
        "diff": {
            "parquet-column/src/main/java/parquet/column/impl/ColumnReaderImpl.java": [
                4,
                13
            ],
            "parquet-column/src/main/java/parquet/column/values/plain/BinaryPlainValuesReader.java": [
                0,
                2
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/ParquetOutputFormat.java": [
                14,
                30
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/ParquetReader.java": [
                2,
                2
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/ParquetRecordReader.java": [
                7,
                12
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/ParquetRecordWriter.java": [
                2,
                4
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/ParquetWriter.java": [
                9,
                25
            ]
        }
    },
    "aed1dca4522647aa525b97cca13df75fb5feb751": {
        "datetime": "2013-06-04T13:52:09-07:00",
        "summary": "dictionary encoding header is now bitWidth instead of max dictionary entry id",
        "message": "dictionary encoding header is now bitWidth instead of max dictionary entry id\n",
        "diff": {
            "parquet-column/src/main/java/parquet/column/values/dictionary/DictionaryValuesReader.java": [
                3,
                3
            ],
            "parquet-column/src/main/java/parquet/column/values/dictionary/DictionaryValuesWriter.java": [
                13,
                7
            ]
        }
    },
    "7cf85cb4e0ea7d25223b9a2773c7a8d629830ea5": {
        "datetime": "2013-06-04T15:08:40-07:00",
        "summary": "Fix RunLengthBitPackingHybridValuesReader",
        "message": "Fix RunLengthBitPackingHybridValuesReader\n",
        "diff": {
            "parquet-column/src/main/java/parquet/column/values/rle/RunLengthBitPackingHybridValuesReader.java": [
                10,
                88
            ]
        }
    },
    "e70652e22cedab7440b477970fffb058fd888d5a": {
        "datetime": "2013-06-05T13:57:10-07:00",
        "summary": "Merge pull request #59 from Parquet/dictionary_encoding_format_adjustment",
        "message": "Merge pull request #59 from Parquet/dictionary_encoding_format_adjustment\n\ndictionary encoding header is now bitWidth instead of max dictionary entry id",
        "diff": {
            "parquet-column/src/main/java/parquet/column/values/dictionary/DictionaryValuesReader.java": [
                3,
                3
            ],
            "parquet-column/src/main/java/parquet/column/values/dictionary/DictionaryValuesWriter.java": [
                13,
                7
            ]
        }
    },
    "2dbd0d232e11dde8944b5cc41486aabcee6dc7d1": {
        "datetime": "2013-06-05T14:35:38-07:00",
        "summary": "Remove logic for valueCount > Integer.MAX_VALUE",
        "message": "Remove logic for valueCount > Integer.MAX_VALUE\n",
        "diff": {
            "parquet-column/src/main/java/parquet/column/values/rle/RunLengthBitPackingHybridValuesReader.java": [
                49,
                16
            ]
        }
    },
    "3ff63fd2f9de8dd0f4cfa68b7a7e40195f230a5d": {
        "datetime": "2013-06-05T15:05:09-07:00",
        "summary": "Merge branch 'master' into alexlevenson/RLE-bit-packing-hybrid",
        "message": "Merge branch 'master' into alexlevenson/RLE-bit-packing-hybrid\n\nConflicts:\n\tparquet-column/src/main/java/parquet/column/values/dictionary/DictionaryValuesReader.java\n\tparquet-column/src/main/java/parquet/column/values/dictionary/DictionaryValuesWriter.java\n",
        "diff": {
            "parquet-column/src/main/java/parquet/column/impl/ColumnReaderImpl.java": [
                4,
                13
            ],
            "parquet-column/src/main/java/parquet/column/values/dictionary/DictionaryValuesReader.java": [
                3,
                3
            ],
            "parquet-column/src/main/java/parquet/column/values/dictionary/DictionaryValuesWriter.java": [
                13,
                8
            ],
            "parquet-column/src/main/java/parquet/column/values/plain/BinaryPlainValuesReader.java": [
                0,
                2
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/ParquetOutputFormat.java": [
                14,
                30
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/ParquetReader.java": [
                2,
                2
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/ParquetRecordReader.java": [
                7,
                12
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/ParquetRecordWriter.java": [
                2,
                4
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/ParquetWriter.java": [
                9,
                25
            ]
        }
    },
    "6e6516622b26450d2030442c9a794e3d021e262f": {
        "datetime": "2013-06-06T07:55:02-07:00",
        "summary": "fix bit packing encoding bug",
        "message": "fix bit packing encoding bug\n",
        "diff": {
            "parquet-column/src/main/java/parquet/column/values/bitpacking/ByteBasedBitPackingEncoder.java": [
                6,
                7
            ],
            "parquet-column/src/main/java/parquet/column/values/dictionary/DictionaryValuesReader.java": [
                1,
                0
            ],
            "parquet-column/src/main/java/parquet/column/values/dictionary/DictionaryValuesWriter.java": [
                1,
                1
            ],
            "parquet-column/src/test/java/parquet/column/values/bitpacking/TestByteBasedBitPackingEncoder.java": [
                0,
                22
            ]
        }
    },
    "1d13a61a1eec58e105defaa0731281f6aa8a7107": {
        "datetime": "2013-06-06T13:32:25-07:00",
        "summary": "create and use checkedCast()",
        "message": "create and use checkedCast()\n",
        "diff": {
            "parquet-column/src/main/java/parquet/Ints.java": [
                0,
                26
            ],
            "parquet-column/src/main/java/parquet/column/values/rle/RunLengthBitPackingHybridValuesReader.java": [
                4,
                2
            ]
        }
    },
    "b7f694613b862710be79211f181974c9478145b5": {
        "datetime": "2013-06-06T14:22:58-07:00",
        "summary": "Merge pull request #58 from Parquet/alexlevenson/RLE-bit-packing-hybrid",
        "message": "Merge pull request #58 from Parquet/alexlevenson/RLE-bit-packing-hybrid\n\nAdds rle / bitpacking hybrid encoding",
        "diff": {
            ".gitignore": null,
            "parquet-column/src/main/java/parquet/Ints.java": [
                0,
                26
            ],
            "parquet-column/src/main/java/parquet/Preconditions.java": [
                2,
                13
            ],
            "parquet-column/src/main/java/parquet/bytes/BytesUtils.java": [
                0,
                65
            ],
            "parquet-column/src/main/java/parquet/bytes/CapacityByteArrayOutputStream.java": [
                3,
                33
            ],
            "parquet-column/src/main/java/parquet/column/Encoding.java": [
                7,
                13
            ],
            "parquet-column/src/main/java/parquet/column/impl/ColumnWriterImpl.java": [
                6,
                15
            ],
            "parquet-column/src/main/java/parquet/column/values/ValuesReader.java": [
                1,
                1
            ],
            "parquet-column/src/main/java/parquet/column/values/ValuesWriter.java": [
                1,
                1
            ],
            "parquet-column/src/main/java/parquet/column/values/dictionary/DictionaryValuesReader.java": [
                4,
                3
            ],
            "parquet-column/src/main/java/parquet/column/values/dictionary/DictionaryValuesWriter.java": [
                11,
                14
            ],
            "parquet-column/src/main/java/parquet/column/values/rle/RLEDecoder.java": [
                27,
                19
            ],
            "parquet-column/src/main/java/parquet/column/values/rle/RLESimpleEncoder.java": [
                73,
                0
            ],
            "parquet-column/src/main/java/parquet/column/values/rle/RunLengthBitPackingHybridEncoder.java": [
                0,
                267
            ],
            "parquet-column/src/main/java/parquet/column/values/rle/RunLengthBitPackingHybridValuesReader.java": [
                0,
                79
            ],
            "parquet-column/src/main/java/parquet/column/values/rle/RunLengthBitPackingHybridValuesWriter.java": [
                0,
                62
            ],
            "parquet-column/src/test/java/parquet/bytes/TestCapacityByteArrayOutputStream.java": [
                0,
                86
            ],
            "parquet-column/src/test/java/parquet/column/values/rle/RunLengthBitPackingHybridIntegrationTest.java": [
                0,
                75
            ],
            "parquet-column/src/test/java/parquet/column/values/rle/TestRLE.java": [
                62,
                0
            ],
            "parquet-column/src/test/java/parquet/column/values/rle/TestRunLengthBitPackingHybridEncoder.java": [
                0,
                288
            ]
        }
    },
    "e0a5920b0e0074aa2129beda7be49dcd35c62e3e": {
        "datetime": "2013-06-07T23:51:53-07:00",
        "summary": "Merge branch 'master' of github.com:Parquet/parquet-mr into fix_bit_packing_encoding_bug",
        "message": "Merge branch 'master' of github.com:Parquet/parquet-mr into fix_bit_packing_encoding_bug\n\nConflicts:\n\tparquet-column/src/main/java/parquet/column/values/dictionary/DictionaryValuesWriter.java\n",
        "diff": {
            ".gitignore": null,
            "parquet-column/src/main/java/parquet/Ints.java": [
                0,
                26
            ],
            "parquet-column/src/main/java/parquet/Preconditions.java": [
                2,
                13
            ],
            "parquet-column/src/main/java/parquet/bytes/BytesUtils.java": [
                0,
                65
            ],
            "parquet-column/src/main/java/parquet/bytes/CapacityByteArrayOutputStream.java": [
                3,
                33
            ],
            "parquet-column/src/main/java/parquet/column/Encoding.java": [
                7,
                13
            ],
            "parquet-column/src/main/java/parquet/column/impl/ColumnWriterImpl.java": [
                6,
                15
            ],
            "parquet-column/src/main/java/parquet/column/values/ValuesReader.java": [
                1,
                1
            ],
            "parquet-column/src/main/java/parquet/column/values/ValuesWriter.java": [
                1,
                1
            ],
            "parquet-column/src/main/java/parquet/column/values/dictionary/DictionaryValuesReader.java": [
                3,
                3
            ],
            "parquet-column/src/main/java/parquet/column/values/dictionary/DictionaryValuesWriter.java": [
                8,
                11
            ],
            "parquet-column/src/main/java/parquet/column/values/rle/RLEDecoder.java": [
                27,
                19
            ],
            "parquet-column/src/main/java/parquet/column/values/rle/RLESimpleEncoder.java": [
                73,
                0
            ],
            "parquet-column/src/main/java/parquet/column/values/rle/RunLengthBitPackingHybridEncoder.java": [
                0,
                267
            ],
            "parquet-column/src/main/java/parquet/column/values/rle/RunLengthBitPackingHybridValuesReader.java": [
                0,
                79
            ],
            "parquet-column/src/main/java/parquet/column/values/rle/RunLengthBitPackingHybridValuesWriter.java": [
                0,
                62
            ],
            "parquet-column/src/test/java/parquet/bytes/TestCapacityByteArrayOutputStream.java": [
                0,
                86
            ],
            "parquet-column/src/test/java/parquet/column/values/rle/RunLengthBitPackingHybridIntegrationTest.java": [
                0,
                75
            ],
            "parquet-column/src/test/java/parquet/column/values/rle/TestRLE.java": [
                62,
                0
            ],
            "parquet-column/src/test/java/parquet/column/values/rle/TestRunLengthBitPackingHybridEncoder.java": [
                0,
                288
            ]
        }
    },
    "7e3ef9febfb49d8ace1715665ba3d7ac640434a0": {
        "datetime": "2013-06-08T07:26:26-07:00",
        "summary": "Merge pull request #60 from Parquet/fix_bit_packing_encoding_bug",
        "message": "Merge pull request #60 from Parquet/fix_bit_packing_encoding_bug\n\nfix bit packing encoding bug",
        "diff": {
            "parquet-column/src/main/java/parquet/column/values/bitpacking/ByteBasedBitPackingEncoder.java": [
                6,
                7
            ],
            "parquet-column/src/main/java/parquet/column/values/dictionary/DictionaryValuesWriter.java": [
                4,
                4
            ],
            "parquet-column/src/test/java/parquet/column/values/bitpacking/TestByteBasedBitPackingEncoder.java": [
                0,
                22
            ]
        }
    },
    "c773446264808dc0fc50a495cfb24f8e4c6140d0": {
        "datetime": "2013-06-17T11:13:57-07:00",
        "summary": "ability to read version number from parquet jar Version utility",
        "message": "ability to read version number from parquet jar Version utility\n",
        "diff": {
            "parquet-column/src/main/java/parquet/Version.java": [
                6,
                18
            ]
        }
    },
    "a2b7a657c51d68bcea32396ed58b3fda77ba0e17": {
        "datetime": "2013-06-17T13:50:34-07:00",
        "summary": "when there is more than one row group the converter will get multiple dictionaries set",
        "message": "when there is more than one row group the converter will get multiple dictionaries set\n",
        "diff": {
            "parquet-pig/src/main/java/parquet/pig/convert/TupleConverter.java": [
                3,
                0
            ]
        }
    },
    "c3596a9ddd0093890cc39e49fb15b11996f451ff": {
        "datetime": "2013-06-17T17:44:39-07:00",
        "summary": "Add support for 4 byte length written at the beginning of rle columns",
        "message": "Add support for 4 byte length written at the beginning of rle columns\n",
        "diff": {
            "parquet-column/src/main/java/parquet/column/values/rle/RunLengthBitPackingHybridEncoder.java": [
                1,
                4
            ],
            "parquet-column/src/main/java/parquet/column/values/rle/RunLengthBitPackingHybridValuesReader.java": [
                36,
                12
            ],
            "parquet-column/src/main/java/parquet/column/values/rle/RunLengthBitPackingHybridValuesWriter.java": [
                1,
                10
            ]
        }
    },
    "c4c77ba08da97d4d4da656898a6f82506b240bea": {
        "datetime": "2013-06-18T09:45:36-07:00",
        "summary": "add support for ReadSupport specific info in split",
        "message": "add support for ReadSupport specific info in split\n",
        "diff": {
            "parquet-hadoop/src/main/java/parquet/hadoop/ParquetInputFormat.java": [
                7,
                16
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/ParquetInputSplit.java": [
                2,
                15
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/ParquetReader.java": [
                4,
                13
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/ParquetRecordReader.java": [
                1,
                1
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/api/ReadSupport.java": [
                0,
                21
            ],
            "parquet-hadoop/src/test/java/parquet/hadoop/TestInputFormat.java": [
                1,
                4
            ]
        }
    },
    "4950149fb60a055f2e99d0a2b016d9f61d9121b7": {
        "datetime": "2013-06-18T10:59:25-07:00",
        "summary": "Merge pull request #61 from aniket486/master",
        "message": "Merge pull request #61 from aniket486/master\n\nability to read version number from parquet jar Version utility",
        "diff": {
            "parquet-column/src/main/java/parquet/Version.java": [
                6,
                18
            ]
        }
    },
    "e27f8719ec2d8f406ce47695856e271caf4cc4f1": {
        "datetime": "2013-06-18T10:59:48-07:00",
        "summary": "Merge pull request #63 from Parquet/alexlevenson/fix-rle-4byte-length",
        "message": "Merge pull request #63 from Parquet/alexlevenson/fix-rle-4byte-length\n\nAdd support for 4 byte length written at the beginning of rle columns",
        "diff": {
            "parquet-column/src/main/java/parquet/column/values/rle/RunLengthBitPackingHybridEncoder.java": [
                1,
                4
            ],
            "parquet-column/src/main/java/parquet/column/values/rle/RunLengthBitPackingHybridValuesReader.java": [
                36,
                12
            ],
            "parquet-column/src/main/java/parquet/column/values/rle/RunLengthBitPackingHybridValuesWriter.java": [
                1,
                10
            ]
        }
    },
    "f7fbed18312d8e39f33e156310d7e635d4c8434a": {
        "datetime": "2013-06-18T14:16:30-07:00",
        "summary": "fix comments",
        "message": "fix comments\n",
        "diff": {
            "parquet-column/src/main/java/parquet/column/values/rle/RunLengthBitPackingHybridEncoder.java": [
                8,
                11
            ]
        }
    },
    "04ac202ccb95ce27b132c3638e6838d642587072": {
        "datetime": "2013-06-18T14:28:53-07:00",
        "summary": "Merge pull request #62 from Parquet/fix_dic_decoding_bug",
        "message": "Merge pull request #62 from Parquet/fix_dic_decoding_bug\n\nwhen there is more than one row group the converter will get multiple dictionaries set",
        "diff": {
            "parquet-pig/src/main/java/parquet/pig/convert/TupleConverter.java": [
                3,
                0
            ]
        }
    },
    "1a30dcce72b45e0f3e6cb8722ed07087b9b9fb11": {
        "datetime": "2013-06-18T18:36:33-07:00",
        "summary": "Merge pull request #66 from Parquet/alexlevenson/fix-rle-comments",
        "message": "Merge pull request #66 from Parquet/alexlevenson/fix-rle-comments\n\nFix the comments in RunLengthBitPackingHybridEncoder.java",
        "diff": {
            "parquet-column/src/main/java/parquet/column/values/rle/RunLengthBitPackingHybridEncoder.java": [
                8,
                11
            ]
        }
    },
    "ff109bc92b5bd488e54249445be997a9a577e280": {
        "datetime": "2013-06-19T23:42:30-07:00",
        "summary": "Merge pull request #65 from Parquet/ReadSupport_specific_info_in_split",
        "message": "Merge pull request #65 from Parquet/ReadSupport_specific_info_in_split\n\nadd support for ReadSupport specific info in split",
        "diff": {
            "parquet-hadoop/src/main/java/parquet/hadoop/ParquetInputFormat.java": [
                7,
                16
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/ParquetInputSplit.java": [
                2,
                15
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/ParquetReader.java": [
                4,
                13
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/ParquetRecordReader.java": [
                1,
                1
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/api/ReadSupport.java": [
                0,
                21
            ],
            "parquet-hadoop/src/test/java/parquet/hadoop/TestInputFormat.java": [
                1,
                4
            ]
        }
    },
    "5f0f929e42c9a0a8cf3a7bf418a252aa7e4a1168": {
        "datetime": "2013-06-22T12:48:11+01:00",
        "summary": "Added filtering functionality",
        "message": "Added filtering functionality\n",
        "diff": {
            "parquet-avro/src/main/java/parquet/avro/AvroParquetReader.java": [
                0,
                5
            ],
            "parquet-column/pom.xml": null,
            "parquet-column/src/main/java/parquet/column/ColumnReader.java": [
                0,
                10
            ],
            "parquet-column/src/main/java/parquet/column/impl/ColumnReaderImpl.java": [
                0,
                18
            ],
            "parquet-column/src/main/java/parquet/filter/AndRecordFilter.java": [
                0,
                51
            ],
            "parquet-column/src/main/java/parquet/filter/ColumnRecordFilter.java": [
                0,
                92
            ],
            "parquet-column/src/main/java/parquet/filter/NullRecordFilter.java": [
                0,
                30
            ],
            "parquet-column/src/main/java/parquet/filter/PagedRecordFilter.java": [
                0,
                55
            ],
            "parquet-column/src/main/java/parquet/filter/RecordFilter.java": [
                0,
                26
            ],
            "parquet-column/src/main/java/parquet/filter/UnboundRecordFilter.java": [
                0,
                19
            ],
            "parquet-column/src/main/java/parquet/io/MessageColumnIO.java": [
                2,
                15
            ],
            "parquet-column/src/main/java/parquet/io/RecordReaderImplementation.java": [
                32,
                59
            ],
            "parquet-column/src/test/java/parquet/io/TestFiltered.java": [
                0,
                122
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/ParquetReader.java": [
                1,
                7
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/ParquetRecordReader.java": [
                4,
                15
            ]
        }
    },
    "ef5c143d0ce9fc825a0ef418c584f1c3a491435d": {
        "datetime": "2013-06-22T16:05:50+01:00",
        "summary": "Added avro specific functionality",
        "message": "Added avro specific functionality\n",
        "diff": {
            "parquet-avro/src/main/java/parquet/avro/AvroGenericRecordConverter.java": [
                8,
                12
            ],
            "parquet-avro/src/main/java/parquet/avro/AvroParquetInputFormat.java": [
                1,
                2
            ],
            "parquet-avro/src/main/java/parquet/avro/AvroParquetOutputFormat.java": [
                1,
                2
            ],
            "parquet-avro/src/main/java/parquet/avro/AvroParquetReader.java": [
                1,
                3
            ],
            "parquet-avro/src/main/java/parquet/avro/AvroParquetWriter.java": [
                1,
                19
            ],
            "parquet-avro/src/main/java/parquet/avro/AvroReadSupport.java": [
                2,
                3
            ],
            "parquet-avro/src/main/java/parquet/avro/AvroRecordMaterializer.java": [
                4,
                5
            ],
            "parquet-avro/src/main/java/parquet/avro/AvroWriteSupport.java": [
                4,
                5
            ]
        }
    },
    "61239a0aa5d41e731b6b2a53df4da2b953abe1dd": {
        "datetime": "2013-06-22T16:47:27+01:00",
        "summary": "Added avro specific functionality",
        "message": "Added avro specific functionality\n",
        "diff": {
            "parquet-avro/pom.xml": null,
            "parquet-avro/src/test/java/parquet/avro/TestSpecificReadWrite.java": [
                0,
                104
            ],
            "parquet-avro/src/test/resources/car.avdl": null
        }
    },
    "48bb48e6dfb9328e6071af68dd19b76aa8ab74a9": {
        "datetime": "2013-06-22T18:24:41+01:00",
        "summary": "Added avro specific functionality",
        "message": "Added avro specific functionality\n",
        "diff": {
            "parquet-avro/pom.xml": null
        }
    },
    "f3ed65beddc41314fc19fa2a237d3379d1bdf557": {
        "datetime": "2013-06-23T00:32:00+02:00",
        "summary": "fix ValueStat max value",
        "message": "fix ValueStat max value\n",
        "diff": {
            "parquet-pig/src/main/java/parquet/pig/summary/ValueStat.java": [
                2,
                2
            ],
            "parquet-pig/src/test/java/parquet/pig/summary/TestSummary.java": [
                0,
                18
            ]
        }
    },
    "8285b62ceafe3fe096ebe1836142445acf0a9586": {
        "datetime": "2013-06-23T14:13:12+01:00",
        "summary": "Fixed bug querying on Name,Url",
        "message": "Fixed bug querying on Name,Url\n",
        "diff": {
            "parquet-column/src/main/java/parquet/column/impl/ColumnReaderImpl.java": [
                1,
                1
            ],
            "parquet-column/src/main/java/parquet/filter/ColumnRecordFilter.java": [
                0,
                4
            ],
            "parquet-column/src/main/java/parquet/io/RecordReaderImplementation.java": [
                36,
                51
            ],
            "parquet-column/src/test/java/parquet/io/TestFiltered.java": [
                4,
                19
            ]
        }
    },
    "ac5cbd1a48f12a0a431af07c9867b0b0ae04eceb": {
        "datetime": "2013-06-23T16:13:48+01:00",
        "summary": "Implmented more efficient skip algorithm",
        "message": "Implmented more efficient skip algorithm\n",
        "diff": {
            "parquet-column/src/main/java/parquet/column/impl/ColumnReaderImpl.java": [
                20,
                57
            ],
            "parquet-column/src/main/java/parquet/column/values/ValuesReader.java": [
                0,
                41
            ],
            "parquet-column/src/main/java/parquet/column/values/dictionary/DictionaryValuesReader.java": [
                0,
                8
            ],
            "parquet-column/src/main/java/parquet/column/values/plain/BinaryPlainValuesReader.java": [
                0,
                12
            ],
            "parquet-column/src/main/java/parquet/column/values/plain/BooleanPlainValuesReader.java": [
                0,
                8
            ],
            "parquet-column/src/main/java/parquet/column/values/plain/PlainValuesReader.java": [
                0,
                36
            ]
        }
    },
    "483dd9f3a906fc0d87fbb3652efcc90ae01e0321": {
        "datetime": "2013-06-23T19:08:21-07:00",
        "summary": "Merge pull request #67 from svzdvd/master",
        "message": "Merge pull request #67 from svzdvd/master\n\nValueStat max value",
        "diff": {
            "parquet-pig/src/main/java/parquet/pig/summary/ValueStat.java": [
                2,
                2
            ],
            "parquet-pig/src/test/java/parquet/pig/summary/TestSummary.java": [
                0,
                18
            ]
        }
    },
    "080b9533b1cedf301943131685361f563b87bd98": {
        "datetime": "2013-06-24T14:12:09-07:00",
        "summary": "[maven-release-plugin] prepare release parquet-format-1.0.0-t2",
        "message": "[maven-release-plugin] prepare release parquet-format-1.0.0-t2\n",
        "diff": {
            "pom.xml": null
        }
    },
    "8463ba1418802c3672efcd6cf78efa38a4e6d4dd": {
        "datetime": "2013-06-24T14:12:22-07:00",
        "summary": "[maven-release-plugin] prepare for next development iteration",
        "message": "[maven-release-plugin] prepare for next development iteration\n",
        "diff": {
            "pom.xml": null
        }
    },
    "3848f32b44ea9182d61402573962264fc847bf5b": {
        "datetime": "2013-06-24T17:28:20-07:00",
        "summary": "undo release changes",
        "message": "undo release changes\n",
        "diff": {
            "pom.xml": null
        }
    },
    "2925244323e1c30d29741911087ec6ea5677127c": {
        "datetime": "2013-06-25T14:11:46-07:00",
        "summary": "Merge pull request #46 from Parquet/alexlevenson/update-readme-rle-4bytes",
        "message": "Merge pull request #46 from Parquet/alexlevenson/update-readme-rle-4bytes\n\nUpdate readme to include 4 byte length in rle columns",
        "diff": {}
    },
    "e440108de57199c12d66801ca93804086e7f7632": {
        "datetime": "2013-06-28T14:37:11-07:00",
        "summary": "Add support for snappy compression.",
        "message": "Add support for snappy compression.\n",
        "diff": {
            "parquet-hadoop/pom.xml": null,
            "parquet-hadoop/src/main/java/parquet/hadoop/ParquetOutputFormat.java": [
                1,
                1
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/codec/SnappyCodec.java": [
                0,
                89
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/codec/SnappyCompressor.java": [
                0,
                141
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/codec/SnappyDecompressor.java": [
                0,
                134
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/codec/SnappyUtil.java": [
                0,
                14
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/metadata/CompressionCodecName.java": [
                1,
                1
            ],
            "parquet-hadoop/src/test/java/parquet/hadoop/TestSnappyCodec.java": [
                0,
                65
            ],
            "parquet-hadoop/src/test/java/parquet/hadoop/example/TestInputOutputFormat.java": [
                4,
                9
            ]
        }
    },
    "7b742900d565271408c87df6b995d9157b9c4354": {
        "datetime": "2013-06-28T14:55:17-07:00",
        "summary": "Fixed test case.",
        "message": "Fixed test case.\n",
        "diff": {
            "parquet-hadoop/src/test/java/parquet/hadoop/TestSnappyCodec.java": [
                5,
                7
            ]
        }
    },
    "2519b95f9e1f458bd3b47f75b4f83eb6a4c55930": {
        "datetime": "2013-06-29T09:51:22-07:00",
        "summary": "Merge pull request #70 from Parquet/snappy",
        "message": "Merge pull request #70 from Parquet/snappy\n\nAdd support for snappy compression.",
        "diff": {
            "parquet-hadoop/pom.xml": null,
            "parquet-hadoop/src/main/java/parquet/hadoop/ParquetOutputFormat.java": [
                1,
                1
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/codec/SnappyCodec.java": [
                0,
                89
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/codec/SnappyCompressor.java": [
                0,
                141
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/codec/SnappyDecompressor.java": [
                0,
                134
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/codec/SnappyUtil.java": [
                0,
                14
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/metadata/CompressionCodecName.java": [
                1,
                1
            ],
            "parquet-hadoop/src/test/java/parquet/hadoop/TestSnappyCodec.java": [
                0,
                67
            ],
            "parquet-hadoop/src/test/java/parquet/hadoop/example/TestInputOutputFormat.java": [
                4,
                9
            ]
        }
    },
    "be8e4e953b98400426b801793da9c66f95f68881": {
        "datetime": "2013-06-30T19:35:30+01:00",
        "summary": "Merge remote-tracking branch 'upstream/master'",
        "message": "Merge remote-tracking branch 'upstream/master'\n",
        "diff": {
            "parquet-hadoop/pom.xml": null,
            "parquet-hadoop/src/main/java/parquet/hadoop/ParquetOutputFormat.java": [
                1,
                1
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/codec/SnappyCodec.java": [
                0,
                89
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/codec/SnappyCompressor.java": [
                0,
                141
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/codec/SnappyDecompressor.java": [
                0,
                134
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/codec/SnappyUtil.java": [
                0,
                14
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/metadata/CompressionCodecName.java": [
                1,
                1
            ],
            "parquet-hadoop/src/test/java/parquet/hadoop/TestSnappyCodec.java": [
                0,
                67
            ],
            "parquet-hadoop/src/test/java/parquet/hadoop/example/TestInputOutputFormat.java": [
                4,
                9
            ],
            "parquet-pig/src/main/java/parquet/pig/summary/ValueStat.java": [
                2,
                2
            ],
            "parquet-pig/src/test/java/parquet/pig/summary/TestSummary.java": [
                0,
                18
            ]
        }
    },
    "1d7a5c33c935710ac8e5fa722d77e23fe55d5c5e": {
        "datetime": "2013-07-01T01:06:05+01:00",
        "summary": "Fixing after code reviews",
        "message": "Fixing after code reviews\n",
        "diff": {
            "parquet-avro/src/main/java/parquet/avro/AvroIndexedRecordConverter.java": [
                6,
                77
            ],
            "parquet-avro/src/main/java/parquet/avro/AvroParquetInputFormat.java": [
                1,
                0
            ],
            "parquet-avro/src/main/java/parquet/avro/AvroParquetOutputFormat.java": [
                1,
                0
            ],
            "parquet-avro/src/main/java/parquet/avro/AvroParquetWriter.java": [
                13,
                13
            ],
            "parquet-avro/src/main/java/parquet/avro/AvroReadSupport.java": [
                3,
                2
            ],
            "parquet-avro/src/main/java/parquet/avro/AvroRecordMaterializer.java": [
                1,
                0
            ],
            "parquet-avro/src/main/java/parquet/avro/AvroSchemaConverter.java": [
                11,
                31
            ],
            "parquet-avro/src/main/java/parquet/avro/AvroWriteSupport.java": [
                6,
                35
            ],
            "parquet-avro/src/test/java/parquet/avro/TestAvroSchemaConverter.java": [
                11,
                0
            ],
            "parquet-avro/src/test/java/parquet/avro/TestSpecificReadWrite.java": [
                26,
                87
            ],
            "parquet-avro/src/test/resources/car.avdl": null,
            "parquet-column/pom.xml": null,
            "parquet-column/src/main/java/parquet/column/impl/ColumnReaderImpl.java": [
                1,
                1
            ],
            "parquet-column/src/main/java/parquet/filter/ColumnPredicates.java": [
                0,
                82
            ],
            "parquet-column/src/main/java/parquet/filter/ColumnRecordFilter.java": [
                37,
                6
            ],
            "parquet-column/src/main/java/parquet/filter/NullRecordFilter.java": [
                30,
                0
            ],
            "parquet-column/src/main/java/parquet/filter/PagedRecordFilter.java": [
                2,
                1
            ],
            "parquet-column/src/main/java/parquet/filter/RecordFilter.java": [
                5,
                0
            ],
            "parquet-column/src/main/java/parquet/filter/UnboundRecordFilter.java": [
                1,
                0
            ],
            "parquet-column/src/main/java/parquet/io/FilteredRecordReader.java": [
                0,
                77
            ],
            "parquet-column/src/main/java/parquet/io/MessageColumnIO.java": [
                5,
                7
            ],
            "parquet-column/src/main/java/parquet/io/RecordReaderImplementation.java": [
                46,
                12
            ],
            "parquet-column/src/test/java/parquet/io/TestFiltered.java": [
                7,
                3
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/ParquetReader.java": [
                2,
                2
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/ParquetRecordReader.java": [
                1,
                1
            ]
        }
    },
    "e2e8edb6c42e0fe48faf36c6166115cecc42922c": {
        "datetime": "2013-06-30T18:44:22-07:00",
        "summary": "small updates to README with feature matrix and other improvements",
        "message": "small updates to README with feature matrix and other improvements\n",
        "diff": {
            "README.md": null
        }
    },
    "6a0dffd6c6b20259c580e90e0e6579f487ea5c6d": {
        "datetime": "2013-06-30T18:54:34-07:00",
        "summary": "fix readme links",
        "message": "fix readme links\n",
        "diff": {
            "README.md": null
        }
    },
    "08b7aebb91af31cea3f143b4c464e853d97ad82e": {
        "datetime": "2013-07-01T10:27:49-07:00",
        "summary": "support for schema compatibility",
        "message": "support for schema compatibility\n",
        "diff": {
            "parquet-column/src/main/java/parquet/io/ColumnIOFactory.java": [
                27,
                59
            ],
            "parquet-column/src/main/java/parquet/schema/Type.java": [
                3,
                22
            ],
            "parquet-column/src/test/java/parquet/io/TestColumnIO.java": [
                0,
                102
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/ParquetInputFormat.java": [
                0,
                1
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/ParquetInputSplit.java": [
                1,
                14
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/ParquetReader.java": [
                0,
                1
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/ParquetRecordReader.java": [
                1,
                3
            ]
        }
    },
    "7b470794cde3f488f863b276721c930ab50a3c58": {
        "datetime": "2013-07-01T14:17:33-07:00",
        "summary": "Should not write data if the RL/DL is all zeroes",
        "message": "Should not write data if the RL/DL is all zeroes\n",
        "diff": {
            "parquet-column/src/main/java/parquet/column/Encoding.java": [
                0,
                4
            ],
            "parquet-column/src/main/java/parquet/column/impl/ColumnWriterImpl.java": [
                8,
                16
            ]
        }
    },
    "29ba92cea1e943433be7d309f46a475c3a65b396": {
        "datetime": "2013-07-01T14:26:21-07:00",
        "summary": "add a bit more pig detail",
        "message": "add a bit more pig detail\n",
        "diff": {
            "README.md": null
        }
    },
    "c98f4670b8467d6e15c9ecdff4dad88331302775": {
        "datetime": "2013-07-01T14:40:12-07:00",
        "summary": "Merge pull request #73 from aniket486/write_no_data_for_no_RL_DL",
        "message": "Merge pull request #73 from aniket486/write_no_data_for_no_RL_DL\n\nShould not write data if the RL/DL is all zeroes",
        "diff": {
            "parquet-column/src/main/java/parquet/column/Encoding.java": [
                0,
                4
            ],
            "parquet-column/src/main/java/parquet/column/impl/ColumnWriterImpl.java": [
                8,
                16
            ]
        }
    },
    "94afb195dfae10fc40699f3c0efc31bb8f23f51a": {
        "datetime": "2013-07-02T15:53:13-07:00",
        "summary": "fix dictionary decoding bug when more than one encoding is used",
        "message": "fix dictionary decoding bug when more than one encoding is used\n",
        "diff": {
            "parquet-column/src/main/java/parquet/column/Encoding.java": [
                0,
                12
            ],
            "parquet-column/src/main/java/parquet/column/impl/ColumnReaderImpl.java": [
                3,
                7
            ],
            "parquet-hadoop/pom.xml": null
        }
    },
    "96bf78d81ee57397658428abda422a1edff01d03": {
        "datetime": "2013-07-02T15:56:34-07:00",
        "summary": "Merge pull request #71 from Parquet/update_readme",
        "message": "Merge pull request #71 from Parquet/update_readme\n\nUpdate Readme",
        "diff": {
            "README.md": null
        }
    },
    "707bdf04d31fea4174c8078ed449121899dfc01c": {
        "datetime": "2013-07-02T16:07:14-07:00",
        "summary": "add negative tests",
        "message": "add negative tests\n",
        "diff": {
            "parquet-column/src/test/java/parquet/io/TestColumnIO.java": [
                0,
                21
            ]
        }
    },
    "364b4a03e9899004399ef401e3a7b8a5174de8c0": {
        "datetime": "2013-07-02T16:13:47-07:00",
        "summary": "Merge pull request #72 from Parquet/schema_compatibility",
        "message": "Merge pull request #72 from Parquet/schema_compatibility\n\nsupport for schema compatibility",
        "diff": {
            "parquet-column/src/main/java/parquet/io/ColumnIOFactory.java": [
                27,
                59
            ],
            "parquet-column/src/main/java/parquet/schema/Type.java": [
                3,
                22
            ],
            "parquet-column/src/test/java/parquet/io/TestColumnIO.java": [
                0,
                123
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/ParquetInputFormat.java": [
                0,
                1
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/ParquetInputSplit.java": [
                1,
                14
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/ParquetReader.java": [
                0,
                1
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/ParquetRecordReader.java": [
                1,
                3
            ]
        }
    },
    "efc59829cfbf19de248c9fdadb39486382c2a457": {
        "datetime": "2013-07-02T18:26:08-07:00",
        "summary": "fix schema compat",
        "message": "fix schema compat\n",
        "diff": {
            "parquet-column/src/main/java/parquet/column/page/Page.java": [
                0,
                3
            ],
            "parquet-column/src/main/java/parquet/io/ColumnIOFactory.java": [
                23,
                22
            ],
            "parquet-column/src/test/java/parquet/io/TestColumnIO.java": [
                1,
                1
            ]
        }
    },
    "18122b433e6301d6c1ca61148102c8e964ee21f3": {
        "datetime": "2013-07-02T18:26:13-07:00",
        "summary": "Merge branch 'master' into schema_compatibility",
        "message": "Merge branch 'master' into schema_compatibility\n",
        "diff": {
            "README.md": null,
            "parquet-column/src/main/java/parquet/column/Encoding.java": [
                0,
                4
            ],
            "parquet-column/src/main/java/parquet/column/impl/ColumnWriterImpl.java": [
                8,
                16
            ]
        }
    },
    "3afe6477da895f394bb34f5d3195102b1cbf1e2e": {
        "datetime": "2013-07-02T18:38:06-07:00",
        "summary": "Merge pull request #75 from Parquet/schema_compatibility",
        "message": "Merge pull request #75 from Parquet/schema_compatibility\n\nSchema compatibility fix",
        "diff": {
            "parquet-column/src/main/java/parquet/column/page/Page.java": [
                0,
                3
            ],
            "parquet-column/src/main/java/parquet/io/ColumnIOFactory.java": [
                23,
                22
            ],
            "parquet-column/src/test/java/parquet/io/TestColumnIO.java": [
                1,
                1
            ]
        }
    },
    "992a47e512a077ac95fcb265e7ee05236a788f6e": {
        "datetime": "2013-07-03T09:31:39-07:00",
        "summary": "fix call to converter",
        "message": "fix call to converter\n",
        "diff": {
            "parquet-column/src/main/java/parquet/column/impl/ColumnReaderImpl.java": [
                1,
                1
            ]
        }
    },
    "5fc67280aa0d58a4ad1ff4c31d320d215f092695": {
        "datetime": "2013-07-03T14:18:28-07:00",
        "summary": "Merge pull request #74 from Parquet/fix_dictionary_decoding",
        "message": "Merge pull request #74 from Parquet/fix_dictionary_decoding\n\nfix dictionary decoding bug when more than one encoding is used",
        "diff": {
            "parquet-column/src/main/java/parquet/column/Encoding.java": [
                0,
                12
            ],
            "parquet-column/src/main/java/parquet/column/impl/ColumnReaderImpl.java": [
                4,
                8
            ],
            "parquet-hadoop/pom.xml": null
        }
    },
    "c4b14fbc4d20034596ad56825349976e4805f456": {
        "datetime": "2013-07-06T15:05:15+01:00",
        "summary": "Adding APL headers and test for union schema creation.",
        "message": "Adding APL headers and test for union schema creation.\n",
        "diff": {
            "parquet-avro/src/test/java/parquet/avro/TestAvroSchemaConverter.java": [
                0,
                22
            ],
            "parquet-avro/src/test/java/parquet/avro/TestSpecificReadWrite.java": [
                0,
                15
            ],
            "parquet-column/src/main/java/parquet/Ints.java": [
                0,
                15
            ],
            "parquet-column/src/main/java/parquet/column/values/rle/RunLengthBitPackingHybridEncoder.java": [
                0,
                15
            ],
            "parquet-column/src/main/java/parquet/column/values/rle/RunLengthBitPackingHybridValuesReader.java": [
                0,
                15
            ],
            "parquet-column/src/main/java/parquet/column/values/rle/RunLengthBitPackingHybridValuesWriter.java": [
                0,
                15
            ],
            "parquet-column/src/main/java/parquet/filter/AndRecordFilter.java": [
                0,
                15
            ],
            "parquet-column/src/main/java/parquet/filter/ColumnPredicates.java": [
                0,
                15
            ],
            "parquet-column/src/main/java/parquet/filter/ColumnRecordFilter.java": [
                0,
                15
            ],
            "parquet-column/src/main/java/parquet/filter/PagedRecordFilter.java": [
                0,
                15
            ],
            "parquet-column/src/main/java/parquet/filter/RecordFilter.java": [
                0,
                15
            ],
            "parquet-column/src/main/java/parquet/filter/UnboundRecordFilter.java": [
                0,
                15
            ],
            "parquet-column/src/main/java/parquet/io/FilteredRecordReader.java": [
                0,
                15
            ],
            "parquet-column/src/test/java/parquet/column/values/bitpacking/TestByteBasedBitPackingEncoder.java": [
                0,
                15
            ],
            "parquet-column/src/test/java/parquet/column/values/rle/RunLengthBitPackingHybridIntegrationTest.java": [
                0,
                15
            ],
            "parquet-column/src/test/java/parquet/column/values/rle/TestRunLengthBitPackingHybridEncoder.java": [
                0,
                15
            ],
            "parquet-column/src/test/java/parquet/io/TestFiltered.java": [
                0,
                15
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/codec/SnappyCodec.java": [
                0,
                15
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/codec/SnappyCompressor.java": [
                0,
                15
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/codec/SnappyDecompressor.java": [
                0,
                15
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/codec/SnappyUtil.java": [
                0,
                15
            ],
            "parquet-hadoop/src/test/java/parquet/hadoop/TestSnappyCodec.java": [
                0,
                15
            ]
        }
    },
    "f52a26e1a32aadf4ec6713ae12ad0d5cedeca9ed": {
        "datetime": "2013-07-06T15:14:14+01:00",
        "summary": "Renamed checkValueRead.",
        "message": "Renamed checkValueRead.\n",
        "diff": {
            "parquet-column/src/main/java/parquet/column/impl/ColumnReaderImpl.java": [
                10,
                10
            ]
        }
    },
    "80a449d1c1e4212d612fdada6d1f5c6e7e622e2c": {
        "datetime": "2013-07-06T15:40:23+01:00",
        "summary": "Updated from master",
        "message": "Updated from master\n",
        "diff": {
            "README.md": null,
            "parquet-avro/src/test/java/parquet/avro/TestSpecificReadWrite.java": [
                6,
                6
            ],
            "parquet-column/src/main/java/parquet/column/Encoding.java": [
                0,
                16
            ],
            "parquet-column/src/main/java/parquet/column/impl/ColumnReaderImpl.java": [
                4,
                8
            ],
            "parquet-column/src/main/java/parquet/column/impl/ColumnWriterImpl.java": [
                8,
                16
            ],
            "parquet-column/src/main/java/parquet/column/page/Page.java": [
                0,
                3
            ],
            "parquet-column/src/main/java/parquet/io/ColumnIOFactory.java": [
                29,
                60
            ],
            "parquet-column/src/main/java/parquet/schema/Type.java": [
                3,
                22
            ],
            "parquet-column/src/test/java/parquet/io/TestColumnIO.java": [
                0,
                123
            ],
            "parquet-hadoop/pom.xml": null,
            "parquet-hadoop/src/main/java/parquet/hadoop/ParquetInputFormat.java": [
                0,
                1
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/ParquetInputSplit.java": [
                1,
                14
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/ParquetReader.java": [
                0,
                1
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/ParquetRecordReader.java": [
                7,
                9
            ]
        }
    },
    "caa8e5113f56af3e186925668da2a78dc8640380": {
        "datetime": "2013-07-08T12:44:40-07:00",
        "summary": "split Plain reader so that the reader knows what type it's reading",
        "message": "split Plain reader so that the reader knows what type it's reading\n",
        "diff": {
            "parquet-column/src/main/java/parquet/column/Encoding.java": [
                2,
                13
            ],
            "parquet-column/src/main/java/parquet/column/values/plain/DoublePlainValuesReader.java": [
                0,
                39
            ],
            "parquet-column/src/main/java/parquet/column/values/plain/FloatPlainValuesReader.java": [
                0,
                39
            ],
            "parquet-column/src/main/java/parquet/column/values/plain/IntegerPlainValuesReader.java": [
                0,
                39
            ],
            "parquet-column/src/main/java/parquet/column/values/plain/LongPlainValuesReader.java": [
                0,
                39
            ],
            "parquet-column/src/main/java/parquet/column/values/plain/PlainValuesReader.java": [
                38,
                1
            ]
        }
    },
    "653a4cf53bd9ed4fd4002c8f5d87a11577747a6d": {
        "datetime": "2013-07-08T15:08:22-07:00",
        "summary": "collapse small classes into one class",
        "message": "collapse small classes into one class\n",
        "diff": {
            "parquet-column/src/main/java/parquet/column/Encoding.java": [
                4,
                4
            ],
            "parquet-column/src/main/java/parquet/column/values/plain/DoublePlainValuesReader.java": [
                39,
                0
            ],
            "parquet-column/src/main/java/parquet/column/values/plain/FloatPlainValuesReader.java": [
                39,
                0
            ],
            "parquet-column/src/main/java/parquet/column/values/plain/IntegerPlainValuesReader.java": [
                39,
                0
            ],
            "parquet-column/src/main/java/parquet/column/values/plain/LongPlainValuesReader.java": [
                39,
                0
            ],
            "parquet-column/src/main/java/parquet/column/values/plain/PlainValuesReader.java": [
                1,
                45
            ]
        }
    },
    "89d6b171f1d45bac178fb638da63a85004d68086": {
        "datetime": "2013-07-09T08:54:39-07:00",
        "summary": "refactored bit packing",
        "message": "refactored bit packing\n",
        "diff": {
            "parquet-column/pom.xml": null,
            "parquet-column/src/main/java/parquet/Ints.java": [
                0,
                15
            ],
            "parquet-column/src/main/java/parquet/Log.java": [
                0,
                0
            ],
            "parquet-column/src/main/java/parquet/ParquetRuntimeException.java": [
                0,
                0
            ],
            "parquet-column/src/main/java/parquet/Preconditions.java": [
                0,
                0
            ],
            "parquet-column/src/main/java/parquet/Version.java": [
                0,
                0
            ],
            "parquet-column/src/main/java/parquet/bytes/BytesInput.java": [
                0,
                1
            ],
            "parquet-column/src/main/java/parquet/bytes/BytesUtils.java": [
                0,
                0
            ],
            "parquet-column/src/main/java/parquet/bytes/CapacityByteArrayOutputStream.java": [
                0,
                0
            ],
            "parquet-column/src/main/java/parquet/bytes/LittleEndianDataInputStream.java": [
                0,
                0
            ],
            "parquet-column/src/main/java/parquet/bytes/LittleEndianDataOutputStream.java": [
                0,
                0
            ],
            "parquet-column/src/main/java/parquet/column/Encoding.java": [
                1,
                0
            ],
            "parquet-column/src/main/java/parquet/column/impl/ColumnReaderImpl.java": [
                1,
                1
            ],
            "parquet-column/src/main/java/parquet/column/impl/ColumnWriterImpl.java": [
                4,
                3
            ],
            "parquet-column/src/main/java/parquet/column/page/Page.java": [
                3,
                0
            ],
            "parquet-column/src/main/java/parquet/column/values/ValuesType.java": [
                1,
                1
            ],
            "parquet-column/src/main/java/parquet/column/values/bitpacking/BitPacking.java": [
                0,
                0
            ],
            "parquet-column/src/main/java/parquet/column/values/bitpacking/ByteBasedBitPackingEncoder.java": [
                0,
                0
            ],
            "parquet-column/src/main/java/parquet/column/values/bitpacking/ByteBasedBitPackingGenerator.java": [
                8,
                14
            ],
            "parquet-column/src/main/java/parquet/column/values/bitpacking/ByteBitPackingBE.java": [
                25636,
                0
            ],
            "parquet-column/src/main/java/parquet/column/values/bitpacking/ByteBitPackingLE.java": [
                25636,
                0
            ],
            "parquet-column/src/main/java/parquet/column/values/bitpacking/BytePacker.java": [
                0,
                0
            ],
            "parquet-column/src/main/java/parquet/column/values/bitpacking/IntBasedBitPackingGenerator.java": [
                8,
                14
            ],
            "parquet-column/src/main/java/parquet/column/values/bitpacking/IntPacker.java": [
                0,
                0
            ],
            "parquet-column/src/main/java/parquet/column/values/bitpacking/LemireBitPackingBE.java": [
                3353,
                0
            ],
            "parquet-column/src/main/java/parquet/column/values/bitpacking/LemireBitPackingLE.java": [
                3352,
                0
            ],
            "parquet-column/src/main/java/parquet/column/values/bitpacking/Packer.java": [
                67,
                0
            ],
            "parquet-column/src/main/java/parquet/column/values/dictionary/PlainBinaryDictionary.java": [
                1,
                0
            ],
            "parquet-column/src/main/java/parquet/column/values/rle/RunLengthBitPackingHybridDecoder.java": [
                2,
                2
            ],
            "parquet-column/src/main/java/parquet/column/values/rle/RunLengthBitPackingHybridEncoder.java": [
                2,
                17
            ],
            "parquet-column/src/main/java/parquet/column/values/rle/RunLengthBitPackingHybridValuesReader.java": [
                1,
                15
            ],
            "parquet-column/src/main/java/parquet/column/values/rle/RunLengthBitPackingHybridValuesWriter.java": [
                0,
                15
            ],
            "parquet-column/src/main/java/parquet/example/data/simple/BinaryValue.java": [
                1,
                0
            ],
            "parquet-column/src/main/java/parquet/schema/Type.java": [
                1,
                0
            ],
            "parquet-column/src/test/java/parquet/TestLog.java": [
                0,
                0
            ],
            "parquet-column/src/test/java/parquet/bytes/TestBytesUtil.java": [
                0,
                0
            ],
            "parquet-column/src/test/java/parquet/bytes/TestCapacityByteArrayOutputStream.java": [
                0,
                0
            ],
            "parquet-column/src/test/java/parquet/column/values/bitpacking/TestBitPacking.java": [
                0,
                0
            ],
            "parquet-column/src/test/java/parquet/column/values/bitpacking/TestByteBasedBitPackingEncoder.java": [
                22,
                0
            ],
            "parquet-column/src/test/java/parquet/column/values/bitpacking/TestByteBitPacking.java": [
                2,
                2
            ],
            "parquet-column/src/test/java/parquet/column/values/bitpacking/TestLemireBitPacking.java": [
                1,
                1
            ],
            "parquet-column/src/test/java/parquet/column/values/rle/RunLengthBitPackingHybridIntegrationTest.java": [
                0,
                15
            ],
            "parquet-column/src/test/java/parquet/column/values/rle/TestRunLengthBitPackingHybridEncoder.java": [
                4,
                19
            ],
            "parquet-common/pom.xml": null,
            "parquet-encoding/pom.xml": null,
            "parquet-encoding/src/main/java/parquet/column/values/bitpacking/BytePackerFactory.java": [
                0,
                22
            ],
            "parquet-encoding/src/main/java/parquet/column/values/bitpacking/IntPackerFactory.java": [
                0,
                22
            ],
            "parquet-encoding/src/main/java/parquet/column/values/bitpacking/Packer.java": [
                0,
                96
            ],
            "parquet-encoding/src/test/java/parquet/column/values/bitpacking/TestByteBasedBitPackingEncoder.java": [
                0,
                37
            ],
            "parquet-generator/pom.xml": null,
            "parquet-generator/src/main/java/parquet/encoding/Generator.java": [
                0,
                34
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/codec/SnappyCodec.java": [
                0,
                15
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/codec/SnappyCompressor.java": [
                0,
                15
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/codec/SnappyDecompressor.java": [
                0,
                15
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/codec/SnappyUtil.java": [
                0,
                15
            ],
            "parquet-hadoop/src/test/java/parquet/hadoop/TestSnappyCodec.java": [
                0,
                15
            ],
            "pom.xml": null
        }
    },
    "f1da1c71ef4cb270368530a1c899c6802790a99d": {
        "datetime": "2013-07-09T11:49:54-07:00",
        "summary": "Merge pull request #79 from Parquet/split_plain_reader",
        "message": "Merge pull request #79 from Parquet/split_plain_reader\n\nsplit Plain reader so that the reader knows what type it's reading",
        "diff": {
            "parquet-column/src/main/java/parquet/column/Encoding.java": [
                2,
                13
            ],
            "parquet-column/src/main/java/parquet/column/values/plain/PlainValuesReader.java": [
                38,
                45
            ]
        }
    },
    "806b548153532021d80de45741e51e0d2622f3e3": {
        "datetime": "2013-07-10T10:23:42-07:00",
        "summary": "fix for schema compatibility",
        "message": "fix for schema compatibility\n",
        "diff": {
            "parquet-column/src/main/java/parquet/io/ColumnIOFactory.java": [
                2,
                2
            ],
            "parquet-column/src/main/java/parquet/io/GroupColumnIO.java": [
                2,
                2
            ]
        }
    },
    "33c8dc5d1cb56710f3e7ec2f58255ef86c39ebe9": {
        "datetime": "2013-07-10T10:30:49-07:00",
        "summary": "Merge pull request #81 from Parquet/fix_schema_compatibility",
        "message": "Merge pull request #81 from Parquet/fix_schema_compatibility\n\nfix for schema compatibility",
        "diff": {
            "parquet-column/src/main/java/parquet/io/ColumnIOFactory.java": [
                2,
                2
            ],
            "parquet-column/src/main/java/parquet/io/GroupColumnIO.java": [
                2,
                2
            ]
        }
    },
    "ab5d3a18bf6611df8f49df0d8e63932f444b1ef2": {
        "datetime": "2013-07-10T18:17:32-07:00",
        "summary": "[maven-release-plugin] prepare release parquet-format-1.0.0-t2",
        "message": "[maven-release-plugin] prepare release parquet-format-1.0.0-t2\n",
        "diff": {
            "pom.xml": null
        }
    },
    "43dc88d41e345cfd5eb2c4e62dfa0cca183bdf4e": {
        "datetime": "2013-07-11T16:10:48+01:00",
        "summary": "adding projection support for thrift types",
        "message": "adding projection support for thrift types\n",
        "diff": {
            "parquet-hadoop/src/main/java/parquet/hadoop/ParquetInputFormat.java": [
                12,
                0
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/api/ReadSupport.java": [
                1,
                22
            ],
            "parquet-thrift/src/main/java/parquet/hadoop/thrift/ThriftReadSupport.java": [
                5,
                5
            ],
            "parquet-thrift/src/main/java/parquet/thrift/ThriftRecordConverter.java": [
                8,
                17
            ],
            "parquet-thrift/src/test/java/parquet/hadoop/thrift/TestParquetToThriftReadProjection.java": [
                0,
                123
            ]
        }
    },
    "adb46b694e94dc906922591f439997e7246d36eb": {
        "datetime": "2013-07-11T09:27:02-07:00",
        "summary": "make splits report actual length",
        "message": "make splits report actual length\n",
        "diff": {
            "parquet-column/src/main/java/parquet/schema/GroupType.java": [
                0,
                8
            ],
            "parquet-column/src/main/java/parquet/schema/MessageType.java": [
                0,
                4
            ],
            "parquet-column/src/main/java/parquet/schema/PrimitiveType.java": [
                0,
                5
            ],
            "parquet-column/src/main/java/parquet/schema/Type.java": [
                0,
                2
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/ParquetInputFormat.java": [
                1,
                12
            ],
            "parquet-hadoop/src/test/java/parquet/hadoop/TestInputFormat.java": [
                3,
                6
            ]
        }
    },
    "9a5d5978f6e645c2e581e0b7075978088b2595eb": {
        "datetime": "2013-07-11T09:28:40-07:00",
        "summary": "Merge pull request #83 from atkeano/thrift_read_projections",
        "message": "Merge pull request #83 from atkeano/thrift_read_projections\n\nProjection support for Thrift ",
        "diff": {
            "parquet-hadoop/src/main/java/parquet/hadoop/ParquetInputFormat.java": [
                12,
                0
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/api/ReadSupport.java": [
                1,
                22
            ],
            "parquet-thrift/src/main/java/parquet/hadoop/thrift/ThriftReadSupport.java": [
                5,
                5
            ],
            "parquet-thrift/src/main/java/parquet/thrift/ThriftRecordConverter.java": [
                8,
                17
            ],
            "parquet-thrift/src/test/java/parquet/hadoop/thrift/TestParquetToThriftReadProjection.java": [
                0,
                123
            ]
        }
    },
    "6bf0597970fd9421a98f2625c9ae2ee221d04acd": {
        "datetime": "2013-07-11T09:29:06-07:00",
        "summary": "Merge pull request #80 from Parquet/encodings",
        "message": "Merge pull request #80 from Parquet/encodings\n\ncreate an encodings module to facilitate encoding sharing",
        "diff": {
            "parquet-column/pom.xml": null,
            "parquet-column/src/main/java/parquet/Ints.java": [
                0,
                15
            ],
            "parquet-column/src/main/java/parquet/Log.java": [
                0,
                0
            ],
            "parquet-column/src/main/java/parquet/ParquetRuntimeException.java": [
                0,
                0
            ],
            "parquet-column/src/main/java/parquet/Preconditions.java": [
                0,
                0
            ],
            "parquet-column/src/main/java/parquet/Version.java": [
                0,
                0
            ],
            "parquet-column/src/main/java/parquet/bytes/BytesInput.java": [
                0,
                1
            ],
            "parquet-column/src/main/java/parquet/bytes/BytesUtils.java": [
                0,
                0
            ],
            "parquet-column/src/main/java/parquet/bytes/CapacityByteArrayOutputStream.java": [
                0,
                0
            ],
            "parquet-column/src/main/java/parquet/bytes/LittleEndianDataInputStream.java": [
                0,
                0
            ],
            "parquet-column/src/main/java/parquet/bytes/LittleEndianDataOutputStream.java": [
                0,
                0
            ],
            "parquet-column/src/main/java/parquet/column/Encoding.java": [
                1,
                0
            ],
            "parquet-column/src/main/java/parquet/column/impl/ColumnReaderImpl.java": [
                1,
                1
            ],
            "parquet-column/src/main/java/parquet/column/impl/ColumnWriterImpl.java": [
                4,
                3
            ],
            "parquet-column/src/main/java/parquet/column/page/Page.java": [
                3,
                0
            ],
            "parquet-column/src/main/java/parquet/column/values/ValuesType.java": [
                1,
                1
            ],
            "parquet-column/src/main/java/parquet/column/values/bitpacking/BitPacking.java": [
                0,
                0
            ],
            "parquet-column/src/main/java/parquet/column/values/bitpacking/ByteBasedBitPackingEncoder.java": [
                0,
                0
            ],
            "parquet-column/src/main/java/parquet/column/values/bitpacking/ByteBasedBitPackingGenerator.java": [
                8,
                14
            ],
            "parquet-column/src/main/java/parquet/column/values/bitpacking/ByteBitPackingBE.java": [
                25636,
                0
            ],
            "parquet-column/src/main/java/parquet/column/values/bitpacking/ByteBitPackingLE.java": [
                25636,
                0
            ],
            "parquet-column/src/main/java/parquet/column/values/bitpacking/BytePacker.java": [
                0,
                0
            ],
            "parquet-column/src/main/java/parquet/column/values/bitpacking/IntBasedBitPackingGenerator.java": [
                8,
                14
            ],
            "parquet-column/src/main/java/parquet/column/values/bitpacking/IntPacker.java": [
                0,
                0
            ],
            "parquet-column/src/main/java/parquet/column/values/bitpacking/LemireBitPackingBE.java": [
                3353,
                0
            ],
            "parquet-column/src/main/java/parquet/column/values/bitpacking/LemireBitPackingLE.java": [
                3352,
                0
            ],
            "parquet-column/src/main/java/parquet/column/values/bitpacking/Packer.java": [
                67,
                0
            ],
            "parquet-column/src/main/java/parquet/column/values/dictionary/PlainBinaryDictionary.java": [
                1,
                0
            ],
            "parquet-column/src/main/java/parquet/column/values/rle/RunLengthBitPackingHybridDecoder.java": [
                2,
                2
            ],
            "parquet-column/src/main/java/parquet/column/values/rle/RunLengthBitPackingHybridEncoder.java": [
                2,
                17
            ],
            "parquet-column/src/main/java/parquet/column/values/rle/RunLengthBitPackingHybridValuesReader.java": [
                1,
                15
            ],
            "parquet-column/src/main/java/parquet/column/values/rle/RunLengthBitPackingHybridValuesWriter.java": [
                0,
                15
            ],
            "parquet-column/src/main/java/parquet/example/data/simple/BinaryValue.java": [
                1,
                0
            ],
            "parquet-column/src/main/java/parquet/schema/Type.java": [
                1,
                0
            ],
            "parquet-column/src/test/java/parquet/TestLog.java": [
                0,
                0
            ],
            "parquet-column/src/test/java/parquet/bytes/TestBytesUtil.java": [
                0,
                0
            ],
            "parquet-column/src/test/java/parquet/bytes/TestCapacityByteArrayOutputStream.java": [
                0,
                0
            ],
            "parquet-column/src/test/java/parquet/column/values/bitpacking/TestBitPacking.java": [
                0,
                0
            ],
            "parquet-column/src/test/java/parquet/column/values/bitpacking/TestByteBasedBitPackingEncoder.java": [
                22,
                0
            ],
            "parquet-column/src/test/java/parquet/column/values/bitpacking/TestByteBitPacking.java": [
                2,
                2
            ],
            "parquet-column/src/test/java/parquet/column/values/bitpacking/TestLemireBitPacking.java": [
                1,
                1
            ],
            "parquet-column/src/test/java/parquet/column/values/rle/RunLengthBitPackingHybridIntegrationTest.java": [
                0,
                15
            ],
            "parquet-column/src/test/java/parquet/column/values/rle/TestRunLengthBitPackingHybridEncoder.java": [
                4,
                19
            ],
            "parquet-common/pom.xml": null,
            "parquet-encoding/pom.xml": null,
            "parquet-encoding/src/main/java/parquet/column/values/bitpacking/BytePackerFactory.java": [
                0,
                22
            ],
            "parquet-encoding/src/main/java/parquet/column/values/bitpacking/IntPackerFactory.java": [
                0,
                22
            ],
            "parquet-encoding/src/main/java/parquet/column/values/bitpacking/Packer.java": [
                0,
                96
            ],
            "parquet-encoding/src/test/java/parquet/column/values/bitpacking/TestByteBasedBitPackingEncoder.java": [
                0,
                37
            ],
            "parquet-generator/pom.xml": null,
            "parquet-generator/src/main/java/parquet/encoding/Generator.java": [
                0,
                34
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/codec/SnappyCodec.java": [
                0,
                15
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/codec/SnappyCompressor.java": [
                0,
                15
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/codec/SnappyDecompressor.java": [
                0,
                15
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/codec/SnappyUtil.java": [
                0,
                15
            ],
            "parquet-hadoop/src/test/java/parquet/hadoop/TestSnappyCodec.java": [
                0,
                15
            ],
            "pom.xml": null
        }
    },
    "6030c9ec92049c9cc883e6fe2ad54e1fda1b0ab2": {
        "datetime": "2013-07-11T10:23:54-07:00",
        "summary": "Merge pull request #84 from Parquet/splits_report_actual_length",
        "message": "Merge pull request #84 from Parquet/splits_report_actual_length\n\nmake splits report actual length",
        "diff": {
            "parquet-column/src/main/java/parquet/schema/GroupType.java": [
                0,
                8
            ],
            "parquet-column/src/main/java/parquet/schema/MessageType.java": [
                0,
                4
            ],
            "parquet-column/src/main/java/parquet/schema/PrimitiveType.java": [
                0,
                5
            ],
            "parquet-column/src/main/java/parquet/schema/Type.java": [
                0,
                2
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/ParquetInputFormat.java": [
                1,
                12
            ],
            "parquet-hadoop/src/test/java/parquet/hadoop/TestInputFormat.java": [
                3,
                6
            ]
        }
    },
    "4de27444249d45f9fd4e57297f04025b66609ea1": {
        "datetime": "2013-07-11T10:54:00-07:00",
        "summary": "fix bad merge",
        "message": "fix bad merge\n",
        "diff": {
            "parquet-hadoop/src/main/java/parquet/hadoop/ParquetInputFormat.java": [
                0,
                2
            ]
        }
    },
    "79a310624f843cdcd59dd27aa41ec72c8527d8b6": {
        "datetime": "2013-07-11T11:35:25-07:00",
        "summary": "reduce memory usage of metadata",
        "message": "reduce memory usage of metadata\n",
        "diff": {
            "parquet-hadoop/src/main/java/parquet/format/converter/ParquetMetadataConverter.java": [
                2,
                85
            ]
        }
    },
    "fc56631a84c4dfe20300698153a86a53cc6af603": {
        "datetime": "2013-07-11T14:58:19-07:00",
        "summary": "Initial checkin for load pushdown",
        "message": "Initial checkin for load pushdown\n",
        "diff": {
            "parquet-hadoop/src/main/java/parquet/hadoop/ParquetInputFormat.java": [
                13,
                57
            ],
            "parquet-pig/src/main/java/parquet/pig/ParquetLoader.java": [
                9,
                73
            ],
            "parquet-pig/src/test/java/parquet/pig/TestParquetLoader.java": [
                0,
                49
            ]
        }
    },
    "5214a653c0aad2bd2dea023a2aaf9b5fc1295bc3": {
        "datetime": "2013-07-11T16:09:19-07:00",
        "summary": "minor fixes and refactor",
        "message": "minor fixes and refactor\n",
        "diff": {
            "parquet-pig/src/main/java/parquet/pig/ParquetLoader.java": [
                9,
                9
            ],
            "parquet-pig/src/main/java/parquet/pig/TupleReadSupport.java": [
                2,
                15
            ]
        }
    },
    "64814a6e48f2f68a0f7b7bb6f3ff0deb7fe8007a": {
        "datetime": "2013-07-11T21:38:04-07:00",
        "summary": "make fields final",
        "message": "make fields final\n",
        "diff": {
            "parquet-hadoop/src/main/java/parquet/format/converter/ParquetMetadataConverter.java": [
                2,
                2
            ]
        }
    },
    "80e72a5af3ba300e4ff880c6468b29f1e08b7e5f": {
        "datetime": "2013-07-11T22:10:22-07:00",
        "summary": "Merge pull request #85 from Parquet/reduce_memory_usage_of_metadata",
        "message": "Merge pull request #85 from Parquet/reduce_memory_usage_of_metadata\n\nreduce memory usage of metadata",
        "diff": {
            "parquet-hadoop/src/main/java/parquet/format/converter/ParquetMetadataConverter.java": [
                2,
                85
            ]
        }
    },
    "feecf58ff8c992ba0ebbaad688e427de8cec93ef": {
        "datetime": "2013-07-12T15:19:03-07:00",
        "summary": "adding tests and removing comments",
        "message": "adding tests and removing comments\n",
        "diff": {
            "parquet-pig/src/main/java/parquet/pig/ParquetLoader.java": [
                4,
                0
            ],
            "parquet-pig/src/main/java/parquet/pig/TupleReadSupport.java": [
                2,
                0
            ],
            "parquet-pig/src/test/java/parquet/pig/TestParquetLoader.java": [
                23,
                156
            ]
        }
    },
    "ef2aa8e526bf724a8308703495dfa0b240921ed3": {
        "datetime": "2013-07-12T21:31:22-07:00",
        "summary": "Merge branch 'master' into filtered_reader",
        "message": "Merge branch 'master' into filtered_reader\n\nConflicts:\n\tparquet-column/src/main/java/parquet/column/values/plain/PlainValuesReader.java\n\tparquet-column/src/test/java/parquet/column/values/bitpacking/TestByteBasedBitPackingEncoder.java\n",
        "diff": {
            "parquet-column/pom.xml": null,
            "parquet-column/src/main/java/parquet/Ints.java": [
                0,
                0
            ],
            "parquet-column/src/main/java/parquet/Log.java": [
                0,
                0
            ],
            "parquet-column/src/main/java/parquet/ParquetRuntimeException.java": [
                0,
                0
            ],
            "parquet-column/src/main/java/parquet/Preconditions.java": [
                0,
                0
            ],
            "parquet-column/src/main/java/parquet/Version.java": [
                0,
                0
            ],
            "parquet-column/src/main/java/parquet/bytes/BytesInput.java": [
                0,
                1
            ],
            "parquet-column/src/main/java/parquet/bytes/BytesUtils.java": [
                0,
                0
            ],
            "parquet-column/src/main/java/parquet/bytes/CapacityByteArrayOutputStream.java": [
                0,
                0
            ],
            "parquet-column/src/main/java/parquet/bytes/LittleEndianDataInputStream.java": [
                0,
                0
            ],
            "parquet-column/src/main/java/parquet/bytes/LittleEndianDataOutputStream.java": [
                0,
                0
            ],
            "parquet-column/src/main/java/parquet/column/Encoding.java": [
                3,
                13
            ],
            "parquet-column/src/main/java/parquet/column/impl/ColumnReaderImpl.java": [
                9,
                8
            ],
            "parquet-column/src/main/java/parquet/column/impl/ColumnWriterImpl.java": [
                4,
                3
            ],
            "parquet-column/src/main/java/parquet/column/page/Page.java": [
                3,
                0
            ],
            "parquet-column/src/main/java/parquet/column/values/ValuesReader.java": [
                39,
                2
            ],
            "parquet-column/src/main/java/parquet/column/values/ValuesType.java": [
                1,
                1
            ],
            "parquet-column/src/main/java/parquet/column/values/bitpacking/BitPacking.java": [
                0,
                0
            ],
            "parquet-column/src/main/java/parquet/column/values/bitpacking/BitPackingValuesReader.java": [
                0,
                5
            ],
            "parquet-column/src/main/java/parquet/column/values/bitpacking/ByteBasedBitPackingEncoder.java": [
                0,
                0
            ],
            "parquet-column/src/main/java/parquet/column/values/bitpacking/ByteBasedBitPackingGenerator.java": [
                8,
                14
            ],
            "parquet-column/src/main/java/parquet/column/values/bitpacking/ByteBitPackingBE.java": [
                25636,
                0
            ],
            "parquet-column/src/main/java/parquet/column/values/bitpacking/ByteBitPackingLE.java": [
                25636,
                0
            ],
            "parquet-column/src/main/java/parquet/column/values/bitpacking/ByteBitPackingValuesReader.java": [
                0,
                5
            ],
            "parquet-column/src/main/java/parquet/column/values/bitpacking/BytePacker.java": [
                0,
                0
            ],
            "parquet-column/src/main/java/parquet/column/values/bitpacking/IntBasedBitPackingGenerator.java": [
                8,
                14
            ],
            "parquet-column/src/main/java/parquet/column/values/bitpacking/IntPacker.java": [
                0,
                0
            ],
            "parquet-column/src/main/java/parquet/column/values/bitpacking/LemireBitPackingBE.java": [
                3353,
                0
            ],
            "parquet-column/src/main/java/parquet/column/values/bitpacking/LemireBitPackingLE.java": [
                3352,
                0
            ],
            "parquet-column/src/main/java/parquet/column/values/bitpacking/Packer.java": [
                67,
                0
            ],
            "parquet-column/src/main/java/parquet/column/values/boundedint/BoundedIntValuesReader.java": [
                0,
                5
            ],
            "parquet-column/src/main/java/parquet/column/values/boundedint/ZeroIntegerValuesReader.java": [
                0,
                4
            ],
            "parquet-column/src/main/java/parquet/column/values/dictionary/DictionaryValuesReader.java": [
                1,
                1
            ],
            "parquet-column/src/main/java/parquet/column/values/dictionary/PlainBinaryDictionary.java": [
                1,
                0
            ],
            "parquet-column/src/main/java/parquet/column/values/plain/BinaryPlainValuesReader.java": [
                1,
                1
            ],
            "parquet-column/src/main/java/parquet/column/values/plain/BooleanPlainValuesReader.java": [
                1,
                1
            ],
            "parquet-column/src/main/java/parquet/column/values/plain/PlainValuesReader.java": [
                75,
                88
            ],
            "parquet-column/src/main/java/parquet/column/values/rle/RunLengthBitPackingHybridDecoder.java": [
                2,
                2
            ],
            "parquet-column/src/main/java/parquet/column/values/rle/RunLengthBitPackingHybridEncoder.java": [
                2,
                2
            ],
            "parquet-column/src/main/java/parquet/column/values/rle/RunLengthBitPackingHybridValuesReader.java": [
                1,
                5
            ],
            "parquet-column/src/main/java/parquet/example/data/simple/BinaryValue.java": [
                1,
                0
            ],
            "parquet-column/src/main/java/parquet/io/ColumnIOFactory.java": [
                2,
                2
            ],
            "parquet-column/src/main/java/parquet/io/GroupColumnIO.java": [
                2,
                2
            ],
            "parquet-column/src/main/java/parquet/schema/GroupType.java": [
                0,
                8
            ],
            "parquet-column/src/main/java/parquet/schema/MessageType.java": [
                0,
                4
            ],
            "parquet-column/src/main/java/parquet/schema/PrimitiveType.java": [
                0,
                5
            ],
            "parquet-column/src/main/java/parquet/schema/Type.java": [
                1,
                2
            ],
            "parquet-column/src/test/java/parquet/TestLog.java": [
                0,
                0
            ],
            "parquet-column/src/test/java/parquet/bytes/TestBytesUtil.java": [
                0,
                0
            ],
            "parquet-column/src/test/java/parquet/bytes/TestCapacityByteArrayOutputStream.java": [
                0,
                0
            ],
            "parquet-column/src/test/java/parquet/column/values/bitpacking/TestBitPacking.java": [
                0,
                0
            ],
            "parquet-column/src/test/java/parquet/column/values/bitpacking/TestByteBasedBitPackingEncoder.java": [
                0,
                0
            ],
            "parquet-column/src/test/java/parquet/column/values/bitpacking/TestByteBitPacking.java": [
                2,
                2
            ],
            "parquet-column/src/test/java/parquet/column/values/bitpacking/TestLemireBitPacking.java": [
                1,
                1
            ],
            "parquet-column/src/test/java/parquet/column/values/rle/TestRunLengthBitPackingHybridEncoder.java": [
                4,
                4
            ],
            "parquet-common/pom.xml": null,
            "parquet-encoding/pom.xml": null,
            "parquet-encoding/src/main/java/parquet/column/values/bitpacking/BytePackerFactory.java": [
                0,
                22
            ],
            "parquet-encoding/src/main/java/parquet/column/values/bitpacking/IntPackerFactory.java": [
                0,
                22
            ],
            "parquet-encoding/src/main/java/parquet/column/values/bitpacking/Packer.java": [
                0,
                96
            ],
            "parquet-generator/pom.xml": null,
            "parquet-generator/src/main/java/parquet/encoding/Generator.java": [
                0,
                34
            ],
            "parquet-hadoop/src/main/java/parquet/format/converter/ParquetMetadataConverter.java": [
                2,
                85
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/ParquetInputFormat.java": [
                11,
                12
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/api/ReadSupport.java": [
                1,
                22
            ],
            "parquet-hadoop/src/test/java/parquet/hadoop/TestInputFormat.java": [
                3,
                6
            ],
            "parquet-thrift/src/main/java/parquet/hadoop/thrift/ThriftReadSupport.java": [
                5,
                5
            ],
            "parquet-thrift/src/main/java/parquet/thrift/ThriftRecordConverter.java": [
                8,
                17
            ],
            "parquet-thrift/src/test/java/parquet/hadoop/thrift/TestParquetToThriftReadProjection.java": [
                0,
                123
            ],
            "pom.xml": null
        }
    },
    "7e31eecc65f5328049373add2dd41def4d2caad8": {
        "datetime": "2013-07-12T21:42:58-07:00",
        "summary": "Merge pull request #89 from Parquet/filtered_reader",
        "message": "Merge pull request #89 from Parquet/filtered_reader\n\nFiltered Reader Implementation, Avro Specific Support",
        "diff": {
            "parquet-avro/pom.xml": null,
            "parquet-avro/src/main/java/parquet/avro/AvroGenericRecordConverter.java": [
                12,
                87
            ],
            "parquet-avro/src/main/java/parquet/avro/AvroParquetInputFormat.java": [
                2,
                2
            ],
            "parquet-avro/src/main/java/parquet/avro/AvroParquetOutputFormat.java": [
                2,
                2
            ],
            "parquet-avro/src/main/java/parquet/avro/AvroParquetReader.java": [
                1,
                8
            ],
            "parquet-avro/src/main/java/parquet/avro/AvroParquetWriter.java": [
                6,
                24
            ],
            "parquet-avro/src/main/java/parquet/avro/AvroReadSupport.java": [
                5,
                5
            ],
            "parquet-avro/src/main/java/parquet/avro/AvroRecordMaterializer.java": [
                5,
                5
            ],
            "parquet-avro/src/main/java/parquet/avro/AvroSchemaConverter.java": [
                11,
                31
            ],
            "parquet-avro/src/main/java/parquet/avro/AvroWriteSupport.java": [
                10,
                40
            ],
            "parquet-avro/src/test/java/parquet/avro/TestAvroSchemaConverter.java": [
                7,
                18
            ],
            "parquet-avro/src/test/java/parquet/avro/TestSpecificReadWrite.java": [
                0,
                180
            ],
            "parquet-avro/src/test/resources/car.avdl": null,
            "parquet-column/src/main/java/parquet/column/ColumnReader.java": [
                0,
                10
            ],
            "parquet-column/src/main/java/parquet/column/impl/ColumnReaderImpl.java": [
                11,
                65
            ],
            "parquet-column/src/main/java/parquet/column/values/ValuesReader.java": [
                0,
                4
            ],
            "parquet-column/src/main/java/parquet/column/values/bitpacking/BitPackingValuesReader.java": [
                0,
                5
            ],
            "parquet-column/src/main/java/parquet/column/values/bitpacking/ByteBitPackingValuesReader.java": [
                0,
                5
            ],
            "parquet-column/src/main/java/parquet/column/values/boundedint/BoundedIntValuesReader.java": [
                0,
                5
            ],
            "parquet-column/src/main/java/parquet/column/values/boundedint/ZeroIntegerValuesReader.java": [
                0,
                4
            ],
            "parquet-column/src/main/java/parquet/column/values/dictionary/DictionaryValuesReader.java": [
                0,
                8
            ],
            "parquet-column/src/main/java/parquet/column/values/plain/BinaryPlainValuesReader.java": [
                0,
                12
            ],
            "parquet-column/src/main/java/parquet/column/values/plain/BooleanPlainValuesReader.java": [
                0,
                8
            ],
            "parquet-column/src/main/java/parquet/column/values/plain/PlainValuesReader.java": [
                1,
                43
            ],
            "parquet-column/src/main/java/parquet/column/values/rle/RunLengthBitPackingHybridValuesReader.java": [
                0,
                5
            ],
            "parquet-column/src/main/java/parquet/filter/AndRecordFilter.java": [
                0,
                66
            ],
            "parquet-column/src/main/java/parquet/filter/ColumnPredicates.java": [
                0,
                97
            ],
            "parquet-column/src/main/java/parquet/filter/ColumnRecordFilter.java": [
                0,
                80
            ],
            "parquet-column/src/main/java/parquet/filter/PagedRecordFilter.java": [
                0,
                69
            ],
            "parquet-column/src/main/java/parquet/filter/RecordFilter.java": [
                0,
                36
            ],
            "parquet-column/src/main/java/parquet/filter/UnboundRecordFilter.java": [
                0,
                33
            ],
            "parquet-column/src/main/java/parquet/io/FilteredRecordReader.java": [
                0,
                92
            ],
            "parquet-column/src/main/java/parquet/io/MessageColumnIO.java": [
                1,
                16
            ],
            "parquet-column/src/main/java/parquet/io/RecordReaderImplementation.java": [
                3,
                11
            ],
            "parquet-column/src/test/java/parquet/io/TestFiltered.java": [
                0,
                148
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/ParquetReader.java": [
                1,
                7
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/ParquetRecordReader.java": [
                3,
                14
            ]
        }
    },
    "3b9e6d8d7eb782bd7a1351d3f90f6109b00ab12e": {
        "datetime": "2013-07-12T22:47:41-07:00",
        "summary": "Update README.md",
        "message": "Update README.md",
        "diff": {
            "README.md": null
        }
    },
    "91fa2c4102c3a0f31986b89e5400d10a9573a013": {
        "datetime": "2013-07-12T22:48:23-07:00",
        "summary": "Update README.md",
        "message": "Update README.md",
        "diff": {
            "README.md": null
        }
    },
    "d8e6ba34048a1c9eeb8613aa538b976616b3a58f": {
        "datetime": "2013-07-14T22:51:56-07:00",
        "summary": "added code review changes",
        "message": "added code review changes\n",
        "diff": {
            "parquet-pig/src/main/java/parquet/pig/ParquetLoader.java": [
                9,
                6
            ],
            "parquet-pig/src/main/java/parquet/pig/TupleReadSupport.java": [
                4,
                1
            ],
            "parquet-pig/src/test/java/parquet/pig/TestParquetLoader.java": [
                151,
                4
            ]
        }
    },
    "5a5bb7f26efe4a31d0de99e6b4c81199752cc118": {
        "datetime": "2013-07-15T12:11:35-07:00",
        "summary": "initial commit for recursive listing",
        "message": "initial commit for recursive listing\n",
        "diff": {
            "parquet-hadoop/src/main/java/parquet/hadoop/ParquetInputFormat.java": [
                1,
                59
            ]
        }
    },
    "39217427aefa710e4543cd6e5310b84d14246453": {
        "datetime": "2013-07-15T17:09:50-07:00",
        "summary": "small fixes for hadoop2 failure",
        "message": "small fixes for hadoop2 failure\n",
        "diff": {
            "parquet-hadoop/src/main/java/parquet/hadoop/ParquetInputFormat.java": [
                13,
                3
            ]
        }
    },
    "61f2c86a40fa9904ede235f10fc02f6818504346": {
        "datetime": "2013-07-17T11:07:16-07:00",
        "summary": "add buffer to protocol pipe",
        "message": "add buffer to protocol pipe\n",
        "diff": {
            "parquet-thrift/src/main/java/parquet/hadoop/thrift/ParquetThriftBytesOutputFormat.java": [
                2,
                21
            ],
            "parquet-thrift/src/main/java/parquet/hadoop/thrift/ThriftBytesWriteSupport.java": [
                3,
                10
            ],
            "parquet-thrift/src/main/java/parquet/hadoop/thrift/ThriftToParquetFileWriter.java": [
                3,
                38
            ],
            "parquet-thrift/src/main/java/parquet/thrift/BufferedProtocolReadToWrite.java": [
                0,
                257
            ],
            "parquet-thrift/src/main/java/parquet/thrift/ProtocolPipe.java": [
                0,
                29
            ],
            "parquet-thrift/src/main/java/parquet/thrift/ProtocolReadToWrite.java": [
                2,
                4
            ],
            "parquet-thrift/src/test/java/parquet/thrift/TestProtocolReadToWrite.java": [
                7,
                10
            ]
        }
    },
    "c2ad76471996bf21da7860a005acc559b7e4437d": {
        "datetime": "2013-07-17T11:14:00-07:00",
        "summary": "Merge pull request #90 from aniket486/list_recursive",
        "message": "Merge pull request #90 from aniket486/list_recursive\n\nAllow ParquetInputFormat to list files recursively in a directory",
        "diff": {
            "parquet-hadoop/src/main/java/parquet/hadoop/ParquetInputFormat.java": [
                1,
                49
            ]
        }
    },
    "9f41d31a313359c6b72b5094cb717d243edd6d00": {
        "datetime": "2013-07-17T11:16:24-07:00",
        "summary": "Merge pull request #86 from aniket486/load_pushdown",
        "message": "Merge pull request #86 from aniket486/load_pushdown\n\nAdding LoadPushdown to ParquetLoader for column pruning",
        "diff": {
            "parquet-hadoop/src/main/java/parquet/hadoop/ParquetInputFormat.java": [
                13,
                56
            ],
            "parquet-pig/src/main/java/parquet/pig/ParquetLoader.java": [
                9,
                66
            ],
            "parquet-pig/src/main/java/parquet/pig/TupleReadSupport.java": [
                2,
                10
            ],
            "parquet-pig/src/test/java/parquet/pig/TestParquetLoader.java": [
                0,
                35
            ]
        }
    },
    "02d5ed256de093ccd8a6c3705dfae6cff9ae22c6": {
        "datetime": "2013-07-17T11:24:53-07:00",
        "summary": "fix merge conflict",
        "message": "fix merge conflict\n",
        "diff": {
            "parquet-hadoop/src/main/java/parquet/hadoop/ParquetInputFormat.java": [
                54,
                11
            ]
        }
    },
    "aa0bc1396bdbbc736f062be9a07675c021380b5b": {
        "datetime": "2013-07-17T12:10:39-07:00",
        "summary": "Add Avro specific support to AvroParquet{Input,Output}Format",
        "message": "Add Avro specific support to AvroParquet{Input,Output}Format\n\nThis commit generalizes AvroIndexedRecordConverter, AvroReadSupport and\nAvroRecordMaterializer to enable Parquet to read/write Avro specific\nobjects.\n",
        "diff": {
            "parquet-avro/src/main/java/parquet/avro/AvroIndexedRecordConverter.java": [
                6,
                6
            ],
            "parquet-avro/src/main/java/parquet/avro/AvroReadSupport.java": [
                3,
                3
            ],
            "parquet-avro/src/main/java/parquet/avro/AvroRecordMaterializer.java": [
                4,
                4
            ],
            "parquet-avro/src/test/java/parquet/avro/TestSpecificInputOutputFormat.java": [
                0,
                147
            ],
            "parquet-avro/src/test/resources/car.avdl": null
        }
    },
    "de0d0cbe83a5310b4978549475722eb6d5485906": {
        "datetime": "2013-07-17T13:30:03-07:00",
        "summary": "Merge pull request #94 from massie/avro-specific",
        "message": "Merge pull request #94 from massie/avro-specific\n\nAdd Avro specific support to AvroParquet{Input,Output}Format",
        "diff": {
            "parquet-avro/src/main/java/parquet/avro/AvroIndexedRecordConverter.java": [
                6,
                6
            ],
            "parquet-avro/src/main/java/parquet/avro/AvroReadSupport.java": [
                3,
                3
            ],
            "parquet-avro/src/main/java/parquet/avro/AvroRecordMaterializer.java": [
                4,
                4
            ],
            "parquet-avro/src/test/java/parquet/avro/TestSpecificInputOutputFormat.java": [
                0,
                147
            ],
            "parquet-avro/src/test/resources/car.avdl": null
        }
    },
    "3f19ce3df0f46399ae8c6fead520dd27049ca3d6": {
        "datetime": "2013-07-17T13:39:08-07:00",
        "summary": "reduce size of splits",
        "message": "reduce size of splits\n",
        "diff": {
            "parquet-hadoop/src/main/java/parquet/hadoop/ParquetInputFormat.java": [
                11,
                11
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/ParquetInputSplit.java": [
                42,
                132
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/ParquetReader.java": [
                1,
                0
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/ParquetRecordReader.java": [
                1,
                1
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/metadata/BlockMetaData.java": [
                3,
                1
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/metadata/ColumnChunkMetaData.java": [
                3,
                1
            ]
        }
    },
    "dd20df13934cac620a35d7161cd24fdf66653ced": {
        "datetime": "2013-07-17T15:32:32-07:00",
        "summary": "Merge pull request #87 from Parquet/reduce_size_of_split",
        "message": "Merge pull request #87 from Parquet/reduce_size_of_split\n\nreduce size of splits",
        "diff": {
            "parquet-hadoop/src/main/java/parquet/hadoop/ParquetInputFormat.java": [
                11,
                11
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/ParquetInputSplit.java": [
                42,
                132
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/ParquetReader.java": [
                1,
                0
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/ParquetRecordReader.java": [
                1,
                1
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/metadata/BlockMetaData.java": [
                3,
                1
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/metadata/ColumnChunkMetaData.java": [
                3,
                1
            ]
        }
    },
    "f46bdafe245db2f6f010ff3ff56858ada695d0f3": {
        "datetime": "2013-07-17T15:37:54-07:00",
        "summary": "Merge pull request #93 from Parquet/add_buffer_to_protocol_pipe_in_master",
        "message": "Merge pull request #93 from Parquet/add_buffer_to_protocol_pipe_in_master\n\nadd buffer to protocol pipe",
        "diff": {
            "parquet-thrift/src/main/java/parquet/hadoop/thrift/ParquetThriftBytesOutputFormat.java": [
                2,
                21
            ],
            "parquet-thrift/src/main/java/parquet/hadoop/thrift/ThriftBytesWriteSupport.java": [
                3,
                10
            ],
            "parquet-thrift/src/main/java/parquet/hadoop/thrift/ThriftToParquetFileWriter.java": [
                3,
                38
            ],
            "parquet-thrift/src/main/java/parquet/thrift/BufferedProtocolReadToWrite.java": [
                0,
                257
            ],
            "parquet-thrift/src/main/java/parquet/thrift/ProtocolPipe.java": [
                0,
                29
            ],
            "parquet-thrift/src/main/java/parquet/thrift/ProtocolReadToWrite.java": [
                2,
                4
            ],
            "parquet-thrift/src/test/java/parquet/thrift/TestProtocolReadToWrite.java": [
                7,
                10
            ]
        }
    },
    "a80029eee06a0d4b18027359f318fd4bd02c6f32": {
        "datetime": "2013-07-17T15:40:39-07:00",
        "summary": "try github site integration",
        "message": "try github site integration\n",
        "diff": {
            "pom.xml": null
        }
    },
    "aedcddec715c998190f8809f03dab413a2540706": {
        "datetime": "2013-07-17T17:09:36-07:00",
        "summary": "fix pom conf for github pages",
        "message": "fix pom conf for github pages\n",
        "diff": {
            "pom.xml": null
        }
    },
    "4643a5cfa257a2b43501882d085a9d98f438df46": {
        "datetime": "2013-07-18T09:20:27-07:00",
        "summary": "add coverage report to site",
        "message": "add coverage report to site\n",
        "diff": {
            "pom.xml": null
        }
    },
    "6b5b8b214ebb6cc8ec3f7dd521bc072e973b5378": {
        "datetime": "2013-07-19T23:27:08-07:00",
        "summary": "improve memory usage of metadata",
        "message": "improve memory usage of metadata\n",
        "diff": {
            "parquet-hadoop/src/main/java/parquet/format/converter/ParquetMetadataConverter.java": [
                65,
                25
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/ColumnChunkPageReadStore.java": [
                1,
                1
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/ParquetFileReader.java": [
                4,
                5
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/ParquetFileWriter.java": [
                9,
                25
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/ParquetInputFormat.java": [
                1,
                1
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/ParquetInputSplit.java": [
                8,
                8
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/PrintFooter.java": [
                3,
                4
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/metadata/ColumnChunkMetaData.java": [
                69,
                171
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/metadata/ColumnChunkProperties.java": [
                0,
                78
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/metadata/ColumnPath.java": [
                0,
                61
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/metadata/EncodingList.java": [
                0,
                72
            ],
            "parquet-hadoop/src/test/java/parquet/hadoop/TestInputFormat.java": [
                3,
                5
            ],
            "parquet-pig/pom.xml": null,
            "parquet-pig/src/main/java/parquet/pig/ParquetLoader.java": [
                6,
                29
            ]
        }
    },
    "54ac6b4098e5afebb3e404894a423cf00ef80295": {
        "datetime": "2013-07-19T23:30:11-07:00",
        "summary": "license headers",
        "message": "license headers\n",
        "diff": {
            "parquet-hadoop/src/main/java/parquet/hadoop/metadata/ColumnChunkProperties.java": [
                0,
                15
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/metadata/ColumnPath.java": [
                0,
                15
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/metadata/EncodingList.java": [
                0,
                15
            ],
            "parquet-pig/src/test/java/parquet/pig/TestParquetLoader.java": [
                0,
                15
            ]
        }
    },
    "f7d098778fbb7b484e1f0c20f14b2260ec625a72": {
        "datetime": "2013-07-19T23:45:47-07:00",
        "summary": "fix compilation issue with 1.6",
        "message": "fix compilation issue with 1.6\n",
        "diff": {
            "parquet-pig/src/main/java/parquet/pig/ParquetLoader.java": [
                10,
                20
            ]
        }
    },
    "964e5da655a184a939eac7770f20acd4ef565ef6": {
        "datetime": "2013-07-22T10:12:26-07:00",
        "summary": "Add support for schema projection in Avro",
        "message": "Add support for schema projection in Avro\n\nThis commit updates the AvroReadSupport and AvroParquetInputFormat\nclasses to allow users to request a schema projection.\n",
        "diff": {
            "parquet-avro/src/main/java/parquet/avro/AvroIndexedRecordConverter.java": [
                14,
                17
            ],
            "parquet-avro/src/main/java/parquet/avro/AvroParquetInputFormat.java": [
                1,
                8
            ],
            "parquet-avro/src/main/java/parquet/avro/AvroReadSupport.java": [
                1,
                15
            ],
            "parquet-avro/src/test/java/parquet/avro/TestSpecificInputOutputFormat.java": [
                18,
                28
            ]
        }
    },
    "62c3155acf4385e907c6eb4a0bb903ae1f41fdc3": {
        "datetime": "2013-07-22T13:58:27-07:00",
        "summary": "Merge pull request #96 from massie/master",
        "message": "Merge pull request #96 from massie/master\n\nAdd support for schema projection in Avro",
        "diff": {
            "parquet-avro/src/main/java/parquet/avro/AvroIndexedRecordConverter.java": [
                14,
                17
            ],
            "parquet-avro/src/main/java/parquet/avro/AvroParquetInputFormat.java": [
                1,
                8
            ],
            "parquet-avro/src/main/java/parquet/avro/AvroReadSupport.java": [
                1,
                15
            ],
            "parquet-avro/src/test/java/parquet/avro/TestSpecificInputOutputFormat.java": [
                18,
                28
            ]
        }
    },
    "c1d67ee581df3581882efbb875d65bd063ec6d33": {
        "datetime": "2013-07-22T14:13:21-07:00",
        "summary": "Add support for predicate pushdown in ParquetInputFormat",
        "message": "Add support for predicate pushdown in ParquetInputFormat\n\nThis commit allows users to define an UnboundRecordFilter to be\nused when reading Parquet records from the ParquetInputFormat.\n",
        "diff": {
            "parquet-avro/src/test/java/parquet/avro/TestSpecificInputOutputFormat.java": [
                21,
                56
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/ParquetInputFormat.java": [
                24,
                32
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/util/ConfigurationUtil.java": [
                0,
                40
            ]
        }
    },
    "435b13bc8a8871c255e7a0f7f2fe2d9ec1a89254": {
        "datetime": "2013-07-22T15:09:03-07:00",
        "summary": "Merge pull request #98 from massie/matt-pushdown",
        "message": "Merge pull request #98 from massie/matt-pushdown\n\nAdd support for predicate pushdown in ParquetInputFormat",
        "diff": {
            "parquet-avro/src/test/java/parquet/avro/TestSpecificInputOutputFormat.java": [
                21,
                56
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/ParquetInputFormat.java": [
                24,
                32
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/util/ConfigurationUtil.java": [
                0,
                40
            ]
        }
    },
    "8c1032d889cc332a73790c5fe08499c18e519f25": {
        "datetime": "2013-07-22T16:00:43-07:00",
        "summary": "Merge pull request #97 from Parquet/improve_memory_usage_of_metadata",
        "message": "Merge pull request #97 from Parquet/improve_memory_usage_of_metadata\n\nimprove memory usage of metadata",
        "diff": {
            "parquet-hadoop/src/main/java/parquet/format/converter/ParquetMetadataConverter.java": [
                65,
                25
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/ColumnChunkPageReadStore.java": [
                1,
                1
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/ParquetFileReader.java": [
                4,
                5
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/ParquetFileWriter.java": [
                9,
                25
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/ParquetInputFormat.java": [
                1,
                1
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/ParquetInputSplit.java": [
                8,
                8
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/PrintFooter.java": [
                3,
                4
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/metadata/ColumnChunkMetaData.java": [
                69,
                171
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/metadata/ColumnChunkProperties.java": [
                0,
                93
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/metadata/ColumnPath.java": [
                0,
                76
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/metadata/EncodingList.java": [
                0,
                87
            ],
            "parquet-hadoop/src/test/java/parquet/hadoop/TestInputFormat.java": [
                3,
                5
            ],
            "parquet-pig/pom.xml": null,
            "parquet-pig/src/main/java/parquet/pig/ParquetLoader.java": [
                6,
                39
            ],
            "parquet-pig/src/test/java/parquet/pig/TestParquetLoader.java": [
                0,
                15
            ]
        }
    },
    "bd826ec880bc2ecda69b2bfb0b89d8dbe3c08845": {
        "datetime": "2013-07-23T11:11:44+02:00",
        "summary": "Add a simple unit test for ParquetSerDe",
        "message": "Add a simple unit test for ParquetSerDe\n",
        "diff": {
            "parquet-hive/src/test/java/parquet/hive/TestParquetSerDe.java": [
                0,
                130
            ]
        }
    },
    "6c219a5f1c5a18f1d7391db20245a1981c5587c6": {
        "datetime": "2013-07-23T11:11:44+02:00",
        "summary": "Fix Short object for Hive (use short for short instead of byte :))",
        "message": "Fix Short object for Hive (use short for short instead of byte :))\n",
        "diff": {
            "parquet-hive/src/main/java/parquet/hive/serde/MapWritableObjectInspector.java": [
                0,
                7
            ],
            "parquet-hive/src/main/java/parquet/hive/serde/ParquetHiveSerDe.java": [
                2,
                3
            ]
        }
    },
    "7f534d5259ff71d8c77b9fbeb4c381b4007b188b": {
        "datetime": "2013-07-23T11:11:44+02:00",
        "summary": "Implement a basic version of the SerDeStats object for ParquetHiveSerDe",
        "message": "Implement a basic version of the SerDeStats object for ParquetHiveSerDe\n",
        "diff": {
            "parquet-hive/src/main/java/parquet/hive/serde/ParquetHiveSerDe.java": [
                5,
                32
            ]
        }
    },
    "910e7cd962f2a516e353214a32cc1e5ceb910d0a": {
        "datetime": "2013-07-23T11:11:44+02:00",
        "summary": "Add equals and hashcode methods to BinaryWritable",
        "message": "Add equals and hashcode methods to BinaryWritable\n",
        "diff": {
            "parquet-hive/src/main/java/parquet/hive/writable/BinaryWritable.java": [
                4,
                38
            ]
        }
    },
    "126da3cad286d441f6638ba94ba9d201c4081231": {
        "datetime": "2013-07-23T11:11:44+02:00",
        "summary": "Give selected columns to ParquetInputFormat : Done",
        "message": "Give selected columns to ParquetInputFormat : Done\n\n - no more hack\n - works with HiveInputFormat and HiveCombine\n",
        "diff": {
            "parquet-hive/src/main/java/parquet/hive/DeprecatedParquetInputFormat.java": [
                16,
                11
            ],
            "parquet-hive/src/main/java/parquet/hive/ManageJobConfig.java": [
                47,
                12
            ],
            "parquet-hive/src/main/java/parquet/hive/convert/ETypeConverter.java": [
                9,
                8
            ],
            "parquet-hive/src/main/java/parquet/hive/convert/MapWritableGroupConverter.java": [
                4,
                3
            ],
            "parquet-hive/src/main/java/parquet/hive/read/MapWritableReadSupport.java": [
                11,
                2
            ],
            "parquet-hive/src/main/java/parquet/hive/serde/MapWritableObjectInspector.java": [
                1,
                3
            ],
            "parquet-hive/src/main/java/parquet/hive/serde/ParquetHiveSerDe.java": [
                3,
                1
            ]
        }
    },
    "ebf76d4dfca1e1bf6d69f0f6c64e4860452c866e": {
        "datetime": "2013-07-23T11:11:44+02:00",
        "summary": "Indentation : retab to 2 spaces. Nothing else.",
        "message": "Indentation : retab to 2 spaces. Nothing else.\n",
        "diff": {
            "parquet-hive/src/main/java/parquet/hive/DeprecatedParquetInputFormat.java": [
                263,
                264
            ],
            "parquet-hive/src/main/java/parquet/hive/DeprecatedParquetOutputFormat.java": [
                97,
                98
            ],
            "parquet-hive/src/main/java/parquet/hive/ManageJobConfig.java": [
                111,
                111
            ],
            "parquet-hive/src/main/java/parquet/hive/convert/ArrayWritableGroupConverter.java": [
                47,
                48
            ],
            "parquet-hive/src/main/java/parquet/hive/convert/ETypeConverter.java": [
                232,
                232
            ],
            "parquet-hive/src/main/java/parquet/hive/convert/HiveGroupConverter.java": [
                18,
                18
            ],
            "parquet-hive/src/main/java/parquet/hive/convert/HiveSchemaConverter.java": [
                67,
                68
            ],
            "parquet-hive/src/main/java/parquet/hive/convert/MapWritableGroupConverter.java": [
                49,
                51
            ],
            "parquet-hive/src/main/java/parquet/hive/convert/MapWritableRecordConverter.java": [
                12,
                13
            ],
            "parquet-hive/src/main/java/parquet/hive/read/MapWritableReadSupport.java": [
                25,
                25
            ],
            "parquet-hive/src/main/java/parquet/hive/serde/MapWritableObjectInspector.java": [
                123,
                123
            ],
            "parquet-hive/src/main/java/parquet/hive/serde/ParquetHiveArrayInspector.java": [
                55,
                55
            ],
            "parquet-hive/src/main/java/parquet/hive/serde/ParquetHiveMapInspector.java": [
                59,
                59
            ],
            "parquet-hive/src/main/java/parquet/hive/serde/ParquetHiveSerDe.java": [
                166,
                168
            ],
            "parquet-hive/src/main/java/parquet/hive/writable/BigDecimalWritable.java": [
                86,
                86
            ],
            "parquet-hive/src/main/java/parquet/hive/writable/BinaryWritable.java": [
                26,
                26
            ],
            "parquet-hive/src/main/java/parquet/hive/write/MapWritableWriteSupport.java": [
                22,
                22
            ],
            "parquet-hive/src/main/java/parquet/hive/write/MapWritableWriter.java": [
                93,
                93
            ],
            "parquet-hive/src/test/java/parquet/hive/TestHiveInputFormat.java": [
                78,
                78
            ],
            "parquet-hive/src/test/java/parquet/hive/TestHiveSchemaConverter.java": [
                37,
                37
            ]
        }
    },
    "1ada3d2b48778378763985124fe66c759e288b92": {
        "datetime": "2013-07-23T11:11:44+02:00",
        "summary": "Some improvements on the hive implementation :",
        "message": "Some improvements on the hive implementation :\n\n - start to read complex type (struct done !, other in progress)\n - start to write complex type (struct done !, other maybe done :) )\n - try to give only the requested schema to parquet objects but\nwe have some troubles with the way readsupport object is initialized. Trying few\nwork around with hive to force the jobConf to be updated (like they do for\nRCFile in HiveInputFormat). Not working when getSplits is called because\nwe have no path (in progress).\n\nUnit test :\n\n - Just a start only one very very tiny small is working to test hiveschemaconverter\n - working on the SerDe testing (trying to create a parquet file first in unit test)\n\nThe code is not clean, neither optimize. 'Make it work, Make it right, Make it fast'\nonly on the first step :p\n",
        "diff": {
            "parquet-hive/src/main/java/parquet/hive/DeprecatedParquetInputFormat.java": [
                14,
                24
            ],
            "parquet-hive/src/main/java/parquet/hive/DeprecatedParquetOutputFormat.java": [
                1,
                1
            ],
            "parquet-hive/src/main/java/parquet/hive/ManageJobConfig.java": [
                32,
                45
            ],
            "parquet-hive/src/main/java/parquet/hive/convert/ArrayWritableGroupConverter.java": [
                16,
                23
            ],
            "parquet-hive/src/main/java/parquet/hive/convert/HiveGroupConverter.java": [
                0,
                15
            ],
            "parquet-hive/src/main/java/parquet/hive/read/MapWritableReadSupport.java": [
                24,
                6
            ],
            "parquet-hive/src/main/java/parquet/hive/serde/MapWritableObjectInspector.java": [
                4,
                2
            ],
            "parquet-hive/src/main/java/parquet/hive/serde/ParquetHiveArrayInspector.java": [
                0,
                15
            ],
            "parquet-hive/src/main/java/parquet/hive/serde/ParquetHiveMapInspector.java": [
                0,
                15
            ],
            "parquet-hive/src/test/java/parquet/hive/TestHiveInputFormat.java": [
                0,
                143
            ],
            "parquet-hive/src/test/java/parquet/hive/TestHiveOuputFormat.java": [
                0,
                27
            ],
            "parquet-hive/src/test/java/parquet/hive/TestHiveSchemaConverter.java": [
                0,
                87
            ]
        }
    },
    "07e54a534ab872191a247270f281de7bdc3f803a": {
        "datetime": "2013-07-23T11:11:44+02:00",
        "summary": "rename one parameter",
        "message": "rename one parameter\n",
        "diff": {
            "parquet-hive/src/main/java/parquet/hive/convert/MapWritableRecordConverter.java": [
                2,
                2
            ]
        }
    },
    "b4d1c7149f861377e8b776f0d82a6b0a86dfd7d0": {
        "datetime": "2013-07-23T11:11:44+02:00",
        "summary": "Can read some complex types",
        "message": "Can read some complex types\n\n- Structs should be entirely good\n- Array and maps do not seem to work correctly\n",
        "diff": {
            "parquet-hive/src/main/java/parquet/hive/DeprecatedParquetInputFormat.java": [
                23,
                4
            ],
            "parquet-hive/src/main/java/parquet/hive/convert/ArrayWritableGroupConverter.java": [
                0,
                87
            ],
            "parquet-hive/src/main/java/parquet/hive/convert/ETypeConverter.java": [
                24,
                34
            ],
            "parquet-hive/src/main/java/parquet/hive/convert/HiveGroupConverter.java": [
                0,
                33
            ],
            "parquet-hive/src/main/java/parquet/hive/convert/HiveSchemaConverter.java": [
                18,
                20
            ],
            "parquet-hive/src/main/java/parquet/hive/convert/MapWritableGroupConverter.java": [
                34,
                30
            ],
            "parquet-hive/src/main/java/parquet/hive/convert/MapWritableRecordConverter.java": [
                1,
                1
            ],
            "parquet-hive/src/main/java/parquet/hive/serde/MapWritableObjectInspector.java": [
                9,
                9
            ],
            "parquet-hive/src/main/java/parquet/hive/serde/ParquetHiveArrayInspector.java": [
                0,
                87
            ],
            "parquet-hive/src/main/java/parquet/hive/serde/ParquetHiveMapInspector.java": [
                0,
                83
            ],
            "parquet-hive/src/main/java/parquet/hive/serde/ParquetHiveSerDe.java": [
                31,
                35
            ],
            "parquet-hive/src/main/java/parquet/hive/write/MapWritableWriter.java": [
                37,
                42
            ]
        }
    },
    "4fe18c5386af73952c7c4d090ea4c5c8b9bcf85d": {
        "datetime": "2013-07-23T11:11:44+02:00",
        "summary": "Can write complex types",
        "message": "Can write complex types\n",
        "diff": {
            "parquet-hive/src/main/java/parquet/hive/convert/HiveSchemaConverter.java": [
                16,
                54
            ],
            "parquet-hive/src/main/java/parquet/hive/convert/MapWritableGroupConverter.java": [
                3,
                4
            ],
            "parquet-hive/src/main/java/parquet/hive/serde/MapWritableObjectInspector.java": [
                20,
                32
            ],
            "parquet-hive/src/main/java/parquet/hive/serde/ParquetHiveSerDe.java": [
                27,
                89
            ],
            "parquet-hive/src/main/java/parquet/hive/write/MapWritableWriteSupport.java": [
                0,
                1
            ],
            "parquet-hive/src/main/java/parquet/hive/write/MapWritableWriter.java": [
                17,
                82
            ]
        }
    },
    "f5ca27b0cef7902203035319887fbe792fe36459": {
        "datetime": "2013-07-23T11:11:44+02:00",
        "summary": "Improve column reading",
        "message": "Improve column reading\n\n - Trying to only read the right column (work in progress)\n",
        "diff": {
            "parquet-hive/src/main/java/parquet/hive/DeprecatedParquetInputFormat.java": [
                45,
                87
            ],
            "parquet-hive/src/main/java/parquet/hive/DeprecatedParquetOutputFormat.java": [
                25,
                28
            ],
            "parquet-hive/src/main/java/parquet/hive/ManageJobConfig.java": [
                0,
                165
            ],
            "parquet-hive/src/main/java/parquet/hive/convert/ETypeConverter.java": [
                29,
                29
            ],
            "parquet-hive/src/main/java/parquet/hive/convert/HiveSchemaConverter.java": [
                21,
                25
            ],
            "parquet-hive/src/main/java/parquet/hive/convert/MapWritableGroupConverter.java": [
                21,
                29
            ],
            "parquet-hive/src/main/java/parquet/hive/convert/MapWritableRecordConverter.java": [
                9,
                9
            ],
            "parquet-hive/src/main/java/parquet/hive/read/MapWritableReadSupport.java": [
                11,
                56
            ],
            "parquet-hive/src/main/java/parquet/hive/serde/MapWritableObjectInspector.java": [
                28,
                31
            ],
            "parquet-hive/src/main/java/parquet/hive/serde/ParquetHiveSerDe.java": [
                24,
                33
            ],
            "parquet-hive/src/main/java/parquet/hive/writable/BigDecimalWritable.java": [
                17,
                17
            ],
            "parquet-hive/src/main/java/parquet/hive/writable/BinaryWritable.java": [
                15,
                15
            ],
            "parquet-hive/src/main/java/parquet/hive/write/MapWritableWriteSupport.java": [
                13,
                13
            ],
            "parquet-hive/src/main/java/parquet/hive/write/MapWritableWriter.java": [
                20,
                21
            ]
        }
    },
    "fcc88f3e81b9b29f0bb46772f0c8f944fe531ce3": {
        "datetime": "2013-07-23T11:11:44+02:00",
        "summary": "Add support for CombineHiveInputFormat",
        "message": "Add support for CombineHiveInputFormat\n\n- This recreates the input splits by reading each file's metadata\n- This is slower than being able to get our InputSplits directly,\nbut still faster than calling getSplits over and over again\n",
        "diff": {
            "parquet-hive/src/main/java/parquet/hive/DeprecatedParquetInputFormat.java": [
                18,
                21
            ]
        }
    },
    "2471e518729a84d6800c8b7b5abf0566f5bf8bec": {
        "datetime": "2013-07-23T11:11:44+02:00",
        "summary": "Remove any K,V from DeprecatedXXFormat",
        "message": "Remove any K,V from DeprecatedXXFormat\n",
        "diff": {
            "parquet-hive/src/main/java/parquet/hive/DeprecatedParquetInputFormat.java": [
                14,
                15
            ],
            "parquet-hive/src/main/java/parquet/hive/DeprecatedParquetOutputFormat.java": [
                23,
                15
            ]
        }
    },
    "c7a8eafa62be64a12a7f6f518e43733a67e6f39f": {
        "datetime": "2013-07-23T11:11:44+02:00",
        "summary": "Start implementation parquet for hive :",
        "message": "Start implementation parquet for hive :\n\n - Read simple data (INT32, INT64, DOUBLE, FLOAT, BOOLEAN, BINARY -String)\n - Write simple data (INT32, INT64, FLOAT, DOUBLE, BOOLEAN, BINARY -String)\n - Read data works only if HiveInputFormat is set (not CombineHive)\n\nTODO :\n\n - Support complex type (struct, map, array)\n - Support CombineHive\n - Unit test :)\n",
        "diff": {
            "parquet-hive/pom.xml": null,
            "parquet-hive/src/main/java/parquet/hive/DeprecatedParquetInputFormat.java": [
                0,
                347
            ],
            "parquet-hive/src/main/java/parquet/hive/DeprecatedParquetOutputFormat.java": [
                0,
                177
            ],
            "parquet-hive/src/main/java/parquet/hive/convert/ETypeConverter.java": [
                0,
                277
            ],
            "parquet-hive/src/main/java/parquet/hive/convert/HiveSchemaConverter.java": [
                0,
                81
            ],
            "parquet-hive/src/main/java/parquet/hive/convert/MapWritableGroupConverter.java": [
                0,
                94
            ],
            "parquet-hive/src/main/java/parquet/hive/convert/MapWritableRecordConverter.java": [
                0,
                54
            ],
            "parquet-hive/src/main/java/parquet/hive/read/MapWritableReadSupport.java": [
                0,
                48
            ],
            "parquet-hive/src/main/java/parquet/hive/serde/MapWritableObjectInspector.java": [
                0,
                185
            ],
            "parquet-hive/src/main/java/parquet/hive/serde/ParquetHiveSerDe.java": [
                0,
                201
            ],
            "parquet-hive/src/main/java/parquet/hive/writable/BigDecimalWritable.java": [
                0,
                147
            ],
            "parquet-hive/src/main/java/parquet/hive/writable/BinaryWritable.java": [
                0,
                70
            ],
            "parquet-hive/src/main/java/parquet/hive/write/MapWritableWriteSupport.java": [
                0,
                67
            ],
            "parquet-hive/src/main/java/parquet/hive/write/MapWritableWriter.java": [
                0,
                81
            ],
            "pom.xml": null
        }
    },
    "543cdc2c1027a858f6d431293a496014adf53bbe": {
        "datetime": "2013-07-23T11:11:45+02:00",
        "summary": "Fix the size of the value array",
        "message": "Fix the size of the value array\n\n- Give the list of columns to the ReadSupport via the split\n- The ReadSupport then gives the GroupConverter the Hive schema\nconverted in Parquet format\n",
        "diff": {
            "parquet-hive/src/main/java/parquet/hive/DeprecatedParquetInputFormat.java": [
                14,
                15
            ],
            "parquet-hive/src/main/java/parquet/hive/ManageJobConfig.java": [
                5,
                17
            ],
            "parquet-hive/src/main/java/parquet/hive/convert/DataWritableGroupConverter.java": [
                14,
                22
            ],
            "parquet-hive/src/main/java/parquet/hive/convert/DataWritableRecordConverter.java": [
                4,
                2
            ],
            "parquet-hive/src/main/java/parquet/hive/convert/HiveSchemaConverter.java": [
                2,
                2
            ],
            "parquet-hive/src/main/java/parquet/hive/read/DataWritableReadSupport.java": [
                6,
                21
            ],
            "parquet-hive/src/main/java/parquet/hive/serde/ParquetHiveArrayInspector.java": [
                1,
                1
            ],
            "parquet-hive/src/main/java/parquet/hive/serde/ParquetHiveMapInspector.java": [
                1,
                1
            ]
        }
    },
    "8234945c40078a911ba7a9e83fc5fd534126182b": {
        "datetime": "2013-07-23T11:11:45+02:00",
        "summary": "Remove unused parameters",
        "message": "Remove unused parameters\n",
        "diff": {
            "parquet-hive/src/main/java/parquet/hive/serde/ParquetHiveSerDe.java": [
                7,
                6
            ]
        }
    },
    "3ee49a5e6c52b374431dfdeeb7b01546625bbfdd": {
        "datetime": "2013-07-23T11:11:45+02:00",
        "summary": "Change MapWritable to ArrayWritable (perfomance improved !)",
        "message": "Change MapWritable to ArrayWritable (perfomance improved !)\n\nFix the ugly fix in case trouble while reading with combine hive\nRefactor the unit test\nAdd more unit test\nSpecify all the unsupported format (next : refactor this, because we have like 4 methods for it)\nFix the fact that we were reading twice the data ( sorry :) )\nDid some profiling with the unit test\n",
        "diff": {
            "parquet-hive/src/main/java/parquet/hive/DeprecatedParquetInputFormat.java": [
                30,
                40
            ],
            "parquet-hive/src/main/java/parquet/hive/DeprecatedParquetOutputFormat.java": [
                17,
                18
            ],
            "parquet-hive/src/main/java/parquet/hive/ManageJobConfig.java": [
                9,
                13
            ],
            "parquet-hive/src/main/java/parquet/hive/convert/ArrayWritableGroupConverter.java": [
                1,
                1
            ],
            "parquet-hive/src/main/java/parquet/hive/convert/DataWritableGroupConverter.java": [
                0,
                132
            ],
            "parquet-hive/src/main/java/parquet/hive/convert/DataWritableRecordConverter.java": [
                0,
                46
            ],
            "parquet-hive/src/main/java/parquet/hive/convert/HiveGroupConverter.java": [
                1,
                1
            ],
            "parquet-hive/src/main/java/parquet/hive/convert/HiveSchemaConverter.java": [
                2,
                14
            ],
            "parquet-hive/src/main/java/parquet/hive/convert/MapWritableGroupConverter.java": [
                128,
                0
            ],
            "parquet-hive/src/main/java/parquet/hive/convert/MapWritableRecordConverter.java": [
                54,
                0
            ],
            "parquet-hive/src/main/java/parquet/hive/read/MapWritableReadSupport.java": [
                14,
                30
            ],
            "parquet-hive/src/main/java/parquet/hive/serde/MapWritableObjectInspector.java": [
                19,
                22
            ],
            "parquet-hive/src/main/java/parquet/hive/serde/ParquetHiveArrayInspector.java": [
                5,
                3
            ],
            "parquet-hive/src/main/java/parquet/hive/serde/ParquetHiveMapInspector.java": [
                7,
                8
            ],
            "parquet-hive/src/main/java/parquet/hive/serde/ParquetHiveSerDe.java": [
                37,
                25
            ],
            "parquet-hive/src/main/java/parquet/hive/writable/BinaryWritable.java": [
                4,
                15
            ],
            "parquet-hive/src/main/java/parquet/hive/write/MapWritableWriteSupport.java": [
                15,
                9
            ],
            "parquet-hive/src/main/java/parquet/hive/write/MapWritableWriter.java": [
                23,
                27
            ],
            "parquet-hive/src/test/java/parquet/hive/TestDeprecatedParquetInputFormat.java": [
                31,
                85
            ],
            "parquet-hive/src/test/java/parquet/hive/TestDeprecatedParquetOuputFormat.java": [
                15,
                19
            ],
            "parquet-hive/src/test/java/parquet/hive/TestDeprecatedParquetOuputFormatComplexType.java": [
                192,
                0
            ],
            "parquet-hive/src/test/java/parquet/hive/TestParquetSerDe.java": [
                20,
                22
            ],
            "parquet-hive/src/test/java/parquet/hive/UtilitiesTestMethods.java": [
                42,
                42
            ]
        }
    },
    "174c26ae4648ca2554942008905c303be851d5b3": {
        "datetime": "2013-07-23T11:11:45+02:00",
        "summary": "Correct fix to CombineHive",
        "message": "Correct fix to CombineHive\n",
        "diff": {
            "parquet-hive/src/main/java/parquet/hive/DeprecatedParquetInputFormat.java": [
                11,
                48
            ]
        }
    },
    "cee774c357a4af5f404249eaf1681efa0f5e085e": {
        "datetime": "2013-07-23T11:11:45+02:00",
        "summary": "Fix more combine stuff",
        "message": "Fix more combine stuff\n",
        "diff": {
            "parquet-hive/src/main/java/parquet/hive/DeprecatedParquetInputFormat.java": [
                22,
                37
            ]
        }
    },
    "cc6754ceb89421859afa0e9ab8e7bc9d9ad7dd10": {
        "datetime": "2013-07-23T11:11:45+02:00",
        "summary": "Fix CombineHive bug",
        "message": "Fix CombineHive bug\n\n- When getting splits from CombineHive, recalculate all possible\nsplits for the path, and only keep the correct one, to keep only\nthe correct blocks\n",
        "diff": {
            "parquet-hive/src/main/java/parquet/hive/DeprecatedParquetInputFormat.java": [
                24,
                22
            ]
        }
    },
    "41981533138c845508fe05253f81c78d90083b03": {
        "datetime": "2013-07-23T11:11:45+02:00",
        "summary": "Fix compile with abstract methods",
        "message": "Fix compile with abstract methods\n",
        "diff": {
            "parquet-hive/src/test/java/parquet/hive/TestDeprecatedParquetOuputFormat.java": [
                7,
                12
            ],
            "parquet-hive/src/test/java/parquet/hive/TestDeprecatedParquetOuputFormatComplexType.java": [
                7,
                12
            ]
        }
    },
    "f2d9e81bf69d3c0f4bbf3ff2b148ff04c1187289": {
        "datetime": "2013-07-23T11:11:45+02:00",
        "summary": "update hadoop version",
        "message": "update hadoop version\n",
        "diff": {
            "parquet-hive/pom.xml": null,
            "parquet-hive/src/main/java/parquet/hive/DeprecatedParquetInputFormat.java": [
                5,
                9
            ],
            "parquet-hive/src/test/java/parquet/hive/TestDeprecatedParquetInputFormat.java": [
                3,
                2
            ]
        }
    },
    "d6157297fb3533139b98d5ceaf0ab6311c5ed724": {
        "datetime": "2013-07-23T11:11:45+02:00",
        "summary": "Add unit test for storage",
        "message": "Add unit test for storage\n",
        "diff": {
            "parquet-hive/src/test/java/parquet/hive/TestDeprecatedParquetOuputFormat.java": [
                17,
                61
            ],
            "parquet-hive/src/test/java/parquet/hive/TestDeprecatedParquetOuputFormatComplexType.java": [
                0,
                187
            ]
        }
    },
    "74be52851bbb1d0bed6af746eb7a83d8113bb555": {
        "datetime": "2013-07-23T11:11:45+02:00",
        "summary": "Add full support for array and map reading",
        "message": "Add full support for array and map reading\n",
        "diff": {
            "parquet-hive/src/main/java/parquet/hive/DeprecatedParquetInputFormat.java": [
                23,
                26
            ],
            "parquet-hive/src/main/java/parquet/hive/DeprecatedParquetOutputFormat.java": [
                1,
                1
            ],
            "parquet-hive/src/main/java/parquet/hive/convert/ArrayWritableGroupConverter.java": [
                21,
                9
            ],
            "parquet-hive/src/main/java/parquet/hive/convert/ETypeConverter.java": [
                8,
                0
            ],
            "parquet-hive/src/main/java/parquet/hive/convert/HiveGroupConverter.java": [
                3,
                2
            ],
            "parquet-hive/src/main/java/parquet/hive/convert/HiveSchemaConverter.java": [
                3,
                6
            ],
            "parquet-hive/src/main/java/parquet/hive/convert/MapWritableGroupConverter.java": [
                7,
                35
            ],
            "parquet-hive/src/main/java/parquet/hive/convert/MapWritableRecordConverter.java": [
                1,
                0
            ],
            "parquet-hive/src/main/java/parquet/hive/read/MapWritableReadSupport.java": [
                3,
                3
            ],
            "parquet-hive/src/main/java/parquet/hive/serde/MapWritableObjectInspector.java": [
                3,
                0
            ],
            "parquet-hive/src/main/java/parquet/hive/serde/ParquetHiveSerDe.java": [
                4,
                1
            ],
            "parquet-hive/src/main/java/parquet/hive/write/MapWritableWriter.java": [
                1,
                0
            ]
        }
    },
    "1dc42f0bf123219d03107ff64954705fe1b104d8": {
        "datetime": "2013-07-23T11:11:45+02:00",
        "summary": "Improve the pull request following advices from Julien",
        "message": "Improve the pull request following advices from Julien\n",
        "diff": {
            "parquet-hive/src/main/java/parquet/hive/convert/ArrayWritableGroupConverter.java": [
                2,
                2
            ],
            "parquet-hive/src/main/java/parquet/hive/convert/HiveSchemaConverter.java": [
                2,
                2
            ],
            "parquet-hive/src/main/java/parquet/hive/serde/ParquetHiveSerDe.java": [
                4,
                1
            ],
            "parquet-hive/src/main/java/parquet/hive/write/MapWritableWriter.java": [
                1,
                2
            ],
            "parquet-hive/src/test/java/parquet/hive/TestDeprecatedParquetInputFormat.java": [
                41,
                32
            ],
            "parquet-hive/src/test/java/parquet/hive/TestDeprecatedParquetOuputFormat.java": [
                31,
                26
            ]
        }
    },
    "33e0131ff0cd7c282b6af17bc82f74155eb761a8": {
        "datetime": "2013-07-23T11:11:45+02:00",
        "summary": "Add some unit test in order to test :",
        "message": "Add some unit test in order to test :\n\n - HiveSerDe : fix some bugs about long and byte datas\n - DeprecatedParquetInputFormat : add StatsSerDe method\n - MapWritableWriter : fix bug if we start and close without adding values\n - UtilitiesTestMethods : almost everything is from parquet-pig. Very useful\n - TestDeprecated{Input,Output}Format : in order to test the hive stuff\n\nUpdate pom.xml :\n\n - Hive-* 0.10 version\n - Add column for test purpose\n",
        "diff": {
            "parquet-hive/pom.xml": null,
            "parquet-hive/src/main/java/parquet/hive/DeprecatedParquetInputFormat.java": [
                23,
                13
            ],
            "parquet-hive/src/main/java/parquet/hive/DeprecatedParquetOutputFormat.java": [
                13,
                7
            ],
            "parquet-hive/src/main/java/parquet/hive/serde/ParquetHiveSerDe.java": [
                1,
                2
            ],
            "parquet-hive/src/main/java/parquet/hive/write/MapWritableWriter.java": [
                10,
                9
            ],
            "parquet-hive/src/test/java/parquet/hive/TestDeprecatedParquetInputFormat.java": [
                0,
                207
            ],
            "parquet-hive/src/test/java/parquet/hive/TestDeprecatedParquetOuputFormat.java": [
                0,
                148
            ],
            "parquet-hive/src/test/java/parquet/hive/TestHiveInputFormat.java": [
                143,
                0
            ],
            "parquet-hive/src/test/java/parquet/hive/TestHiveOuputFormat.java": [
                27,
                0
            ],
            "parquet-hive/src/test/java/parquet/hive/TestParquetSerDe.java": [
                37,
                15
            ],
            "parquet-hive/src/test/java/parquet/hive/UtilitiesTestMethods.java": [
                0,
                158
            ]
        }
    },
    "bb6e2ff89644690e363a31078e94b17e76b590a9": {
        "datetime": "2013-07-23T11:51:58+02:00",
        "summary": "Hadoop 2.0 compatibility, hive 0.10",
        "message": "Hadoop 2.0 compatibility, hive 0.10\n\n - Using ContextUtils to be able to launch with hadoop 2.0\n - Working with hive 0.10\n - Fix some issues with ArrayWritable to be able to reach any columns\nwith objectInspector\n",
        "diff": {
            "parquet-hive/src/main/java/parquet/hive/DeprecatedParquetInputFormat.java": [
                23,
                11
            ],
            "parquet-hive/src/main/java/parquet/hive/serde/ArrayWritableObjectInspector.java": [
                3,
                37
            ],
            "parquet-hive/src/main/java/parquet/hive/serde/ParquetHiveArrayInspector.java": [
                2,
                47
            ],
            "parquet-hive/src/main/java/parquet/hive/writable/BinaryWritable.java": [
                0,
                4
            ],
            "parquet-hive/src/test/java/parquet/hive/TestDeprecatedParquetInputFormat.java": [
                4,
                8
            ],
            "parquet-hive/src/test/java/parquet/hive/TestDeprecatedParquetOuputFormat.java": [
                1,
                5
            ],
            "parquet-hive/src/test/java/parquet/hive/UtilitiesTestMethods.java": [
                3,
                2
            ]
        }
    },
    "4cf6ae1b5de1293eaed6e409a7a69c1ce2aac316": {
        "datetime": "2013-07-23T11:52:05+02:00",
        "summary": "Code review",
        "message": "Code review\n\n - Add todo\n - Add javadoc\n - Rename class\n - Rename method\n - Improve tests\n",
        "diff": {
            "parquet-column/src/main/java/parquet/io/MessageColumnIO.java": [
                1,
                1
            ],
            "parquet-column/src/main/java/parquet/io/RecordReaderEmpty.java": [
                2,
                2
            ],
            "parquet-hive/pom.xml": null,
            "parquet-hive/src/main/java/parquet/hive/DeprecatedParquetOutputFormat.java": [
                1,
                7
            ],
            "parquet-hive/src/main/java/parquet/hive/ManageJobConfig.java": [
                5,
                29
            ],
            "parquet-hive/src/main/java/parquet/hive/convert/ETypeConverter.java": [
                24,
                29
            ],
            "parquet-hive/src/main/java/parquet/hive/convert/HiveSchemaConverter.java": [
                4,
                2
            ],
            "parquet-hive/src/main/java/parquet/hive/serde/ArrayWritableObjectInspector.java": [
                1,
                2
            ],
            "parquet-hive/src/main/java/parquet/hive/writable/BinaryWritable.java": [
                80,
                7
            ],
            "parquet-hive/src/test/java/parquet/hive/TestDeprecatedParquetInputFormat.java": [
                17,
                11
            ],
            "parquet-hive/src/test/java/parquet/hive/TestDeprecatedParquetOuputFormat.java": [
                1,
                1
            ],
            "parquet-hive/src/test/java/parquet/hive/UtilitiesTestMethods.java": [
                32,
                16
            ]
        }
    },
    "2525587f8290908229c4582a2c3b0ea54067428d": {
        "datetime": "2013-07-23T11:52:05+02:00",
        "summary": "Update getSplits in DeprecatedParquetInputFormat",
        "message": "Update getSplits in DeprecatedParquetInputFormat\n\n- In the case of a FileSplit, do not get the blocks, and instead\ncompute directly from the split offset/length\n- Add javadoc\n",
        "diff": {
            "parquet-hive/src/main/java/parquet/hive/DeprecatedParquetInputFormat.java": [
                13,
                20
            ]
        }
    },
    "26360f35ee52811ea5cb320813848a79aa4b8047": {
        "datetime": "2013-07-23T11:52:05+02:00",
        "summary": "Minor changes",
        "message": "Minor changes\n\n - Documentation\n - Change the name of a method\n",
        "diff": {
            "parquet-hive/src/main/java/parquet/hive/DeprecatedParquetInputFormat.java": [
                0,
                2
            ],
            "parquet-hive/src/main/java/parquet/hive/ManageJobConfig.java": [
                2,
                3
            ],
            "parquet-hive/src/main/java/parquet/hive/writable/BigDecimalWritable.java": [
                2,
                7
            ],
            "parquet-hive/src/main/java/parquet/hive/writable/BinaryWritable.java": [
                3,
                3
            ],
            "parquet-hive/src/main/java/parquet/hive/write/DataWritableWriteSupport.java": [
                2,
                1
            ],
            "parquet-hive/src/main/java/parquet/hive/write/DataWritableWriter.java": [
                2,
                3
            ]
        }
    },
    "bf7263b03783653a9d3899ea30e805bbe24de6bf": {
        "datetime": "2013-07-23T11:52:05+02:00",
        "summary": "Try to fix travis build",
        "message": "Try to fix travis build\n",
        "diff": {
            "parquet-hive/pom.xml": null
        }
    },
    "eccbba1c124d1b22553cb3ef64a883f23e7dbe84": {
        "datetime": "2013-07-23T11:52:05+02:00",
        "summary": "Improve speed for queries like count(0), in which we only need the number of lines",
        "message": "Improve speed for queries like count(0), in which we only need the number of lines\n",
        "diff": {
            "parquet-column/src/main/java/parquet/io/MessageColumnIO.java": [
                3,
                8
            ],
            "parquet-column/src/main/java/parquet/io/RecordReaderEmpty.java": [
                0,
                47
            ],
            "parquet-column/src/main/java/parquet/io/RecordReaderImplementation.java": [
                1,
                1
            ]
        }
    },
    "21b0d9787694f3d87e4068cfce01b51749854495": {
        "datetime": "2013-07-23T11:52:05+02:00",
        "summary": "Update with advices from Julien",
        "message": "Update with advices from Julien\n",
        "diff": {
            "parquet-hive/src/main/java/parquet/hive/DeprecatedParquetInputFormat.java": [
                13,
                12
            ],
            "parquet-hive/src/main/java/parquet/hive/serde/ArrayWritableObjectInspector.java": [
                1,
                1
            ],
            "parquet-hive/src/main/java/parquet/hive/serde/ParquetHiveSerDe.java": [
                12,
                16
            ],
            "parquet-hive/src/test/java/parquet/hive/TestParquetSerDe.java": [
                5,
                5
            ]
        }
    },
    "3089e834ae9bfbd212a77e12c9f9b9cf8917d63d": {
        "datetime": "2013-07-23T11:52:05+02:00",
        "summary": "Manage count 0",
        "message": "Manage count 0\n",
        "diff": {
            "parquet-hive/src/main/java/parquet/hive/read/DataWritableReadSupport.java": [
                10,
                14
            ]
        }
    },
    "82fff8c856abc84159c09aff4670fc7c76489be5": {
        "datetime": "2013-07-23T11:52:05+02:00",
        "summary": "Clean up ReadSupport init",
        "message": "Clean up ReadSupport init\n",
        "diff": {
            "parquet-hive/src/main/java/parquet/hive/DeprecatedParquetInputFormat.java": [
                1,
                2
            ],
            "parquet-hive/src/main/java/parquet/hive/ManageJobConfig.java": [
                1,
                2
            ],
            "parquet-hive/src/main/java/parquet/hive/read/DataWritableReadSupport.java": [
                23,
                24
            ],
            "parquet-hive/src/test/java/parquet/hive/TestDeprecatedParquetInputFormat.java": [
                2,
                13
            ],
            "parquet-hive/src/test/java/parquet/hive/TestDeprecatedParquetOuputFormat.java": [
                2,
                13
            ]
        }
    },
    "0ec089dcaa6246e08b069a1770484e52b1e05357": {
        "datetime": "2013-07-23T11:52:05+02:00",
        "summary": "Add metadata in ReadContext instead of Split",
        "message": "Add metadata in ReadContext instead of Split\n\n- Fix TaskAttemptContext in the deprecated output format\n- Clean up a bit how we get the split in the deprecated input format\n",
        "diff": {
            "parquet-hive/src/main/java/parquet/hive/DeprecatedParquetInputFormat.java": [
                119,
                50
            ],
            "parquet-hive/src/main/java/parquet/hive/DeprecatedParquetOutputFormat.java": [
                20,
                8
            ],
            "parquet-hive/src/main/java/parquet/hive/read/DataWritableReadSupport.java": [
                9,
                13
            ],
            "parquet-hive/src/main/java/parquet/hive/serde/ArrayWritableObjectInspector.java": [
                5,
                5
            ],
            "parquet-hive/src/main/java/parquet/hive/serde/ParquetHiveArrayInspector.java": [
                8,
                7
            ],
            "parquet-hive/src/test/java/parquet/hive/TestDeprecatedParquetInputFormat.java": [
                3,
                3
            ],
            "parquet-hive/src/test/java/parquet/hive/TestDeprecatedParquetOuputFormat.java": [
                7,
                7
            ]
        }
    },
    "ed9eec87295e66a7bdf4575726034573b767b908": {
        "datetime": "2013-07-23T11:30:41-07:00",
        "summary": "Add \"how to contribute\" to README.md",
        "message": "Add \"how to contribute\" to README.md",
        "diff": {
            "README.md": null
        }
    },
    "a2ec5cb9d5a11ba59356b66f3b7bc4e3ee3a14a4": {
        "datetime": "2013-07-23T12:20:37-07:00",
        "summary": "Merge pull request #102 from Parquet/how_to_contribute",
        "message": "Merge pull request #102 from Parquet/how_to_contribute\n\nAdd \"how to contribute\" to README.md",
        "diff": {
            "README.md": null
        }
    },
    "61f226020e1b5e8b55d4c1d347ea1722ae67b28f": {
        "datetime": "2013-07-23T17:24:32-07:00",
        "summary": "Merge pull request #95 from Parquet/doc",
        "message": "Merge pull request #95 from Parquet/doc\n\nautomated publication of documentation on parquet.io",
        "diff": {
            "pom.xml": null
        }
    },
    "92c450a9783cfed62bc1b7bf1f99a6d641ec72a4": {
        "datetime": "2013-07-23T18:02:40-07:00",
        "summary": "Merge pull request #28 from mickaellcr/parquet-hive",
        "message": "Merge pull request #28 from mickaellcr/parquet-hive\n\nParquet hive implementation",
        "diff": {
            "parquet-column/src/main/java/parquet/io/EmptyRecordReader.java": [
                0,
                47
            ],
            "parquet-column/src/main/java/parquet/io/MessageColumnIO.java": [
                3,
                8
            ],
            "parquet-column/src/main/java/parquet/io/RecordReaderImplementation.java": [
                1,
                1
            ],
            "parquet-hive/pom.xml": null,
            "parquet-hive/src/main/java/parquet/hive/DeprecatedParquetInputFormat.java": [
                0,
                366
            ],
            "parquet-hive/src/main/java/parquet/hive/DeprecatedParquetOutputFormat.java": [
                0,
                162
            ],
            "parquet-hive/src/main/java/parquet/hive/ManageJobConfig.java": [
                0,
                185
            ],
            "parquet-hive/src/main/java/parquet/hive/convert/ArrayWritableGroupConverter.java": [
                0,
                83
            ],
            "parquet-hive/src/main/java/parquet/hive/convert/DataWritableGroupConverter.java": [
                0,
                140
            ],
            "parquet-hive/src/main/java/parquet/hive/convert/DataWritableRecordConverter.java": [
                0,
                44
            ],
            "parquet-hive/src/main/java/parquet/hive/convert/ETypeConverter.java": [
                0,
                283
            ],
            "parquet-hive/src/main/java/parquet/hive/convert/HiveGroupConverter.java": [
                0,
                47
            ],
            "parquet-hive/src/main/java/parquet/hive/convert/HiveSchemaConverter.java": [
                0,
                139
            ],
            "parquet-hive/src/main/java/parquet/hive/read/DataWritableReadSupport.java": [
                0,
                106
            ],
            "parquet-hive/src/main/java/parquet/hive/serde/ArrayWritableObjectInspector.java": [
                0,
                242
            ],
            "parquet-hive/src/main/java/parquet/hive/serde/ParquetHiveArrayInspector.java": [
                0,
                144
            ],
            "parquet-hive/src/main/java/parquet/hive/serde/ParquetHiveMapInspector.java": [
                0,
                99
            ],
            "parquet-hive/src/main/java/parquet/hive/serde/ParquetHiveSerDe.java": [
                0,
                290
            ],
            "parquet-hive/src/main/java/parquet/hive/writable/BigDecimalWritable.java": [
                0,
                152
            ],
            "parquet-hive/src/main/java/parquet/hive/writable/BinaryWritable.java": [
                0,
                46
            ],
            "parquet-hive/src/main/java/parquet/hive/write/DataWritableWriteSupport.java": [
                0,
                61
            ],
            "parquet-hive/src/main/java/parquet/hive/write/DataWritableWriter.java": [
                0,
                156
            ],
            "parquet-hive/src/test/java/parquet/hive/TestDeprecatedParquetInputFormat.java": [
                0,
                260
            ],
            "parquet-hive/src/test/java/parquet/hive/TestDeprecatedParquetOuputFormat.java": [
                0,
                211
            ],
            "parquet-hive/src/test/java/parquet/hive/TestHiveSchemaConverter.java": [
                0,
                87
            ],
            "parquet-hive/src/test/java/parquet/hive/TestParquetSerDe.java": [
                0,
                110
            ],
            "parquet-hive/src/test/java/parquet/hive/UtilitiesTestMethods.java": [
                0,
                141
            ],
            "pom.xml": null
        }
    },
    "273ecd40b48f8013851edf5f07f3a60e85f8ce95": {
        "datetime": "2013-07-23T18:08:36-07:00",
        "summary": "Update Hive support status",
        "message": "Update Hive support status",
        "diff": {
            "README.md": null
        }
    },
    "67b8423a653fbd4c191b2c886b5c5b71143698a3": {
        "datetime": "2013-07-24T09:33:26-07:00",
        "summary": "ThriftParquetReader and ThriftParquetWriter",
        "message": "ThriftParquetReader and ThriftParquetWriter\n",
        "diff": {
            "parquet-thrift/src/main/java/parquet/hadoop/thrift/ThriftReadSupport.java": [
                0,
                19
            ],
            "parquet-thrift/src/main/java/parquet/hadoop/thrift/ThriftWriteSupport.java": [
                5,
                27
            ],
            "parquet-thrift/src/main/java/parquet/thrift/ThriftParquetReader.java": [
                0,
                52
            ],
            "parquet-thrift/src/main/java/parquet/thrift/ThriftParquetWriter.java": [
                0,
                44
            ],
            "parquet-thrift/src/test/java/parquet/thrift/TestThriftParquetReaderWriter.java": [
                0,
                70
            ]
        }
    },
    "be49204476dbf293cadc35528d3eaec5ce384678": {
        "datetime": "2013-07-25T09:44:26-07:00",
        "summary": "change default page size and add some doc",
        "message": "change default page size and add some doc\n",
        "diff": {
            "parquet-hadoop/src/main/java/parquet/hadoop/ParquetFileReader.java": [
                1,
                1
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/ParquetFileWriter.java": [
                1,
                2
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/ParquetOutputFormat.java": [
                1,
                1
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/ParquetReader.java": [
                1,
                0
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/ParquetRecordReader.java": [
                2,
                2
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/ParquetWriter.java": [
                2,
                2
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/api/package-info.java": [
                0,
                31
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/package-info.java": [
                0,
                31
            ]
        }
    },
    "0fbd026714e3f2f3e0ab8e5a2080af4da3329f84": {
        "datetime": "2013-07-25T09:46:02-07:00",
        "summary": "Merge pull request #105 from Parquet/ThriftParquetWriter",
        "message": "Merge pull request #105 from Parquet/ThriftParquetWriter\n\nThriftParquetReader and ThriftParquetWriter",
        "diff": {
            "parquet-thrift/src/main/java/parquet/hadoop/thrift/ThriftReadSupport.java": [
                0,
                19
            ],
            "parquet-thrift/src/main/java/parquet/hadoop/thrift/ThriftWriteSupport.java": [
                5,
                27
            ],
            "parquet-thrift/src/main/java/parquet/thrift/ThriftParquetReader.java": [
                0,
                52
            ],
            "parquet-thrift/src/main/java/parquet/thrift/ThriftParquetWriter.java": [
                0,
                44
            ],
            "parquet-thrift/src/test/java/parquet/thrift/TestThriftParquetReaderWriter.java": [
                0,
                70
            ]
        }
    },
    "b7fe532ff5e4e8f56fffd9d18e04d105d92c8a1f": {
        "datetime": "2013-07-25T09:46:33-07:00",
        "summary": "Merge branch 'master' of github.com:Parquet/parquet-mr into change_default_block_size",
        "message": "Merge branch 'master' of github.com:Parquet/parquet-mr into change_default_block_size\n",
        "diff": {
            "parquet-thrift/src/main/java/parquet/hadoop/thrift/ThriftReadSupport.java": [
                0,
                19
            ],
            "parquet-thrift/src/main/java/parquet/hadoop/thrift/ThriftWriteSupport.java": [
                5,
                27
            ],
            "parquet-thrift/src/main/java/parquet/thrift/ThriftParquetReader.java": [
                0,
                52
            ],
            "parquet-thrift/src/main/java/parquet/thrift/ThriftParquetWriter.java": [
                0,
                44
            ],
            "parquet-thrift/src/test/java/parquet/thrift/TestThriftParquetReaderWriter.java": [
                0,
                70
            ]
        }
    },
    "8a62bb35a5aac83340f968467c438a01563c6d79": {
        "datetime": "2013-07-25T09:47:18-07:00",
        "summary": "fix doc",
        "message": "fix doc\n",
        "diff": {
            "parquet-hadoop/src/main/java/parquet/hadoop/api/package-info.java": [
                9,
                1
            ]
        }
    },
    "b8576b9c06f1322603ba974394d6c9673ae93935": {
        "datetime": "2013-07-25T09:58:25-07:00",
        "summary": "Update README.md",
        "message": "Update README.md",
        "diff": {
            "README.md": null
        }
    },
    "4bc24334231a0565fcd6bc1126c6f1f7e16c3f3f": {
        "datetime": "2013-07-25T11:21:57-07:00",
        "summary": "[fix validation script] when boolean value is null, set it to 0 for being compatible.",
        "message": "[fix validation script] when boolean value is null, set it to 0 for being compatible.\n",
        "diff": {
            "parquet-pig/src/main/java/parquet/pig/convert/TupleConverter.java": [
                0,
                3
            ]
        }
    },
    "265ef240e67029fe94dcfffd3393344c0601dc1c": {
        "datetime": "2013-07-25T11:22:19-07:00",
        "summary": "Merge branch 'master' of https://github.com/Parquet/parquet-mr into fix_boolean_default_value_for_tuple_converter",
        "message": "Merge branch 'master' of https://github.com/Parquet/parquet-mr into fix_boolean_default_value_for_tuple_converter\n",
        "diff": {
            "README.md": null,
            "parquet-column/src/main/java/parquet/io/EmptyRecordReader.java": [
                0,
                47
            ],
            "parquet-column/src/main/java/parquet/io/MessageColumnIO.java": [
                3,
                8
            ],
            "parquet-column/src/main/java/parquet/io/RecordReaderImplementation.java": [
                1,
                1
            ],
            "parquet-hive/pom.xml": null,
            "parquet-hive/src/main/java/parquet/hive/DeprecatedParquetInputFormat.java": [
                0,
                366
            ],
            "parquet-hive/src/main/java/parquet/hive/DeprecatedParquetOutputFormat.java": [
                0,
                162
            ],
            "parquet-hive/src/main/java/parquet/hive/ManageJobConfig.java": [
                0,
                185
            ],
            "parquet-hive/src/main/java/parquet/hive/convert/ArrayWritableGroupConverter.java": [
                0,
                83
            ],
            "parquet-hive/src/main/java/parquet/hive/convert/DataWritableGroupConverter.java": [
                0,
                140
            ],
            "parquet-hive/src/main/java/parquet/hive/convert/DataWritableRecordConverter.java": [
                0,
                44
            ],
            "parquet-hive/src/main/java/parquet/hive/convert/ETypeConverter.java": [
                0,
                283
            ],
            "parquet-hive/src/main/java/parquet/hive/convert/HiveGroupConverter.java": [
                0,
                47
            ],
            "parquet-hive/src/main/java/parquet/hive/convert/HiveSchemaConverter.java": [
                0,
                139
            ],
            "parquet-hive/src/main/java/parquet/hive/read/DataWritableReadSupport.java": [
                0,
                106
            ],
            "parquet-hive/src/main/java/parquet/hive/serde/ArrayWritableObjectInspector.java": [
                0,
                242
            ],
            "parquet-hive/src/main/java/parquet/hive/serde/ParquetHiveArrayInspector.java": [
                0,
                144
            ],
            "parquet-hive/src/main/java/parquet/hive/serde/ParquetHiveMapInspector.java": [
                0,
                99
            ],
            "parquet-hive/src/main/java/parquet/hive/serde/ParquetHiveSerDe.java": [
                0,
                290
            ],
            "parquet-hive/src/main/java/parquet/hive/writable/BigDecimalWritable.java": [
                0,
                152
            ],
            "parquet-hive/src/main/java/parquet/hive/writable/BinaryWritable.java": [
                0,
                46
            ],
            "parquet-hive/src/main/java/parquet/hive/write/DataWritableWriteSupport.java": [
                0,
                61
            ],
            "parquet-hive/src/main/java/parquet/hive/write/DataWritableWriter.java": [
                0,
                156
            ],
            "parquet-hive/src/test/java/parquet/hive/TestDeprecatedParquetInputFormat.java": [
                0,
                260
            ],
            "parquet-hive/src/test/java/parquet/hive/TestDeprecatedParquetOuputFormat.java": [
                0,
                211
            ],
            "parquet-hive/src/test/java/parquet/hive/TestHiveSchemaConverter.java": [
                0,
                87
            ],
            "parquet-hive/src/test/java/parquet/hive/TestParquetSerDe.java": [
                0,
                110
            ],
            "parquet-hive/src/test/java/parquet/hive/UtilitiesTestMethods.java": [
                0,
                141
            ],
            "parquet-thrift/src/main/java/parquet/hadoop/thrift/ThriftReadSupport.java": [
                0,
                19
            ],
            "parquet-thrift/src/main/java/parquet/hadoop/thrift/ThriftWriteSupport.java": [
                5,
                27
            ],
            "parquet-thrift/src/main/java/parquet/thrift/ThriftParquetReader.java": [
                0,
                52
            ],
            "parquet-thrift/src/main/java/parquet/thrift/ThriftParquetWriter.java": [
                0,
                44
            ],
            "parquet-thrift/src/test/java/parquet/thrift/TestThriftParquetReaderWriter.java": [
                0,
                70
            ],
            "pom.xml": null
        }
    },
    "0e8f1f7a6d33a2141c5b45a4f0518b7747678f2e": {
        "datetime": "2013-07-25T14:52:40-07:00",
        "summary": "Merge pull request #107 from Parquet/change_default_block_size",
        "message": "Merge pull request #107 from Parquet/change_default_block_size\n\nChange default block size and clarify some doc",
        "diff": {
            "README.md": null,
            "parquet-hadoop/src/main/java/parquet/hadoop/ParquetFileReader.java": [
                1,
                1
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/ParquetFileWriter.java": [
                1,
                2
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/ParquetOutputFormat.java": [
                1,
                1
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/ParquetReader.java": [
                1,
                0
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/ParquetRecordReader.java": [
                2,
                2
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/ParquetWriter.java": [
                2,
                2
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/api/package-info.java": [
                0,
                23
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/package-info.java": [
                0,
                31
            ]
        }
    },
    "eac5aecfa40273edab7645ba81eb4816ceac9d98": {
        "datetime": "2013-07-25T15:52:30-07:00",
        "summary": "1. return compatible schema when compatible flag is set. 2. tupleConverter set to return IntegerConverter when flag is set",
        "message": "1. return compatible schema when compatible flag is set. 2. tupleConverter set to return IntegerConverter when flag is set\n",
        "diff": {
            "parquet-pig/src/main/java/parquet/pig/ParquetLoader.java": [
                0,
                16
            ],
            "parquet-pig/src/main/java/parquet/pig/TupleReadSupport.java": [
                3,
                2
            ],
            "parquet-pig/src/main/java/parquet/pig/convert/TupleConverter.java": [
                9,
                12
            ]
        }
    },
    "c4e8d261c322aca17c8789c61b4e4289dfd3b675": {
        "datetime": "2013-07-25T16:50:09-07:00",
        "summary": "optimize code format, add log info to indicate boolean will be convert",
        "message": "optimize code format, add log info to indicate boolean will be convert\nto int when compatible mode is on\n",
        "diff": {
            "parquet-pig/src/main/java/parquet/pig/ParquetLoader.java": [
                4,
                4
            ],
            "parquet-pig/src/main/java/parquet/pig/TupleReadSupport.java": [
                5,
                5
            ]
        }
    },
    "7a4b5626cbdfad9b4429e47fc4b6da37516a09b9": {
        "datetime": "2013-07-25T19:47:32-07:00",
        "summary": "add if debug statements to parquetloader",
        "message": "add if debug statements to parquetloader\n",
        "diff": {
            "parquet-pig/src/main/java/parquet/pig/ParquetLoader.java": [
                7,
                8
            ]
        }
    },
    "a7c42f93d0a2278970beaddaec26071efc4436ad": {
        "datetime": "2013-07-26T15:21:00+01:00",
        "summary": "Make writer independent",
        "message": "Make writer independent\n",
        "diff": {
            "parquet-hadoop/src/main/java/parquet/hadoop/InternalParquetRecordWriter.java": [
                0,
                135
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/ParquetRecordWriter.java": [
                92,
                6
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/ParquetWriter.java": [
                4,
                4
            ]
        }
    },
    "504833e34a16b58c60fd1e43e771c258b2bebeb9": {
        "datetime": "2013-07-26T16:00:13+01:00",
        "summary": "Make reader independent",
        "message": "Make reader independent\n",
        "diff": {
            "parquet-hadoop/src/main/java/parquet/hadoop/InternalParquetRecordReader.java": [
                0,
                178
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/InternalParquetRecordWriter.java": [
                2,
                0
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/ParquetReader.java": [
                10,
                4
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/ParquetRecordReader.java": [
                123,
                13
            ]
        }
    },
    "7d1fe7846a7973cccb683ecb8201c2b03fbc7e60": {
        "datetime": "2013-07-26T09:55:21-07:00",
        "summary": "remove space, add braces for readability",
        "message": "remove space, add braces for readability\n",
        "diff": {
            "parquet-pig/src/main/java/parquet/pig/ParquetLoader.java": [
                2,
                2
            ],
            "parquet-pig/src/main/java/parquet/pig/convert/TupleConverter.java": [
                4,
                5
            ]
        }
    },
    "82579c96a03a3c97812d621087f3a44e69e4ea0d": {
        "datetime": "2013-07-26T10:14:20-07:00",
        "summary": "Merge pull request #108 from Parquet/elephant_bird_compatible",
        "message": "Merge pull request #108 from Parquet/elephant_bird_compatible\n\nset elephantbird compatible flag to get compatible schema and  value converter",
        "diff": {
            "parquet-pig/src/main/java/parquet/pig/ParquetLoader.java": [
                0,
                16
            ],
            "parquet-pig/src/main/java/parquet/pig/TupleReadSupport.java": [
                6,
                5
            ],
            "parquet-pig/src/main/java/parquet/pig/convert/TupleConverter.java": [
                10,
                14
            ]
        }
    },
    "09ba2fb2fdccbd7f79b2b5d3fa42f80d46546581": {
        "datetime": "2013-07-26T11:30:46-07:00",
        "summary": "Merge pull request #111 from aniket486/master",
        "message": "Merge pull request #111 from aniket486/master\n\nadd if debug statements to parquetloader",
        "diff": {
            "parquet-pig/src/main/java/parquet/pig/ParquetLoader.java": [
                7,
                8
            ]
        }
    },
    "3c55f589708eb25a870c6669806b7e465446c0ae": {
        "datetime": "2013-07-26T11:31:46-07:00",
        "summary": "Merge pull request #112 from tomwhite/issue-64-mr-indept",
        "message": "Merge pull request #112 from tomwhite/issue-64-mr-indept\n\nMake Parquet{Reader,Writer} independent of MapReduce APIs",
        "diff": {
            "parquet-hadoop/src/main/java/parquet/hadoop/InternalParquetRecordReader.java": [
                0,
                178
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/InternalParquetRecordWriter.java": [
                0,
                133
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/ParquetReader.java": [
                10,
                4
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/ParquetRecordReader.java": [
                123,
                13
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/ParquetRecordWriter.java": [
                92,
                6
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/ParquetWriter.java": [
                4,
                4
            ]
        }
    },
    "a6e3fe7ef9af4f017fd030b311d096861ab40196": {
        "datetime": "2013-07-28T21:07:12-07:00",
        "summary": "upgrading scrooge runtime version to 3.1.1",
        "message": "upgrading scrooge runtime version to 3.1.1\n",
        "diff": {
            "parquet-scrooge/pom.xml": null
        }
    },
    "228914103e4559f3c4f11e2b64617ea25c91ef02": {
        "datetime": "2013-07-29T08:11:08-07:00",
        "summary": "Merge pull request #113 from aniket486/master",
        "message": "Merge pull request #113 from aniket486/master\n\nupgrading scrooge runtime version to 3.1.1",
        "diff": {
            "parquet-scrooge/pom.xml": null
        }
    },
    "46aa59c9db0308725120c0b924f00bf33a067182": {
        "datetime": "2013-07-29T15:30:32-07:00",
        "summary": "revert back to SNAPSHOT",
        "message": "revert back to SNAPSHOT\n",
        "diff": {
            "pom.xml": null
        }
    },
    "32dbb4a1087dc28656b565720d42485c27162aa4": {
        "datetime": "2013-07-29T15:32:12-07:00",
        "summary": "[maven-release-plugin] prepare release parquet-format-1.0.0",
        "message": "[maven-release-plugin] prepare release parquet-format-1.0.0\n",
        "diff": {
            "pom.xml": null
        }
    },
    "97cf75f87b6df20a92de70f44c567d755fac4eb3": {
        "datetime": "2013-07-29T15:32:17-07:00",
        "summary": "[maven-release-plugin] prepare for next development iteration",
        "message": "[maven-release-plugin] prepare for next development iteration\n",
        "diff": {
            "pom.xml": null
        }
    },
    "62180722e038c81f7e460e4f39d61a4b1c79b268": {
        "datetime": "2013-07-29T19:02:24-07:00",
        "summary": "move github site to profile",
        "message": "move github site to profile\n",
        "diff": {
            "pom.xml": null
        }
    },
    "bb74d3d13fd246c9769ff4e8b97ba22e935c1d49": {
        "datetime": "2013-07-29T20:49:59-07:00",
        "summary": "add description",
        "message": "add description\n",
        "diff": {
            "pom.xml": null
        }
    },
    "6eec81d8abab0644e8c2df00544f73828ee0e219": {
        "datetime": "2013-07-29T21:24:31-07:00",
        "summary": "[maven-release-plugin] prepare release parquet-1.0.0",
        "message": "[maven-release-plugin] prepare release parquet-1.0.0\n",
        "diff": {
            "parquet-avro/pom.xml": null,
            "parquet-cascading/pom.xml": null,
            "parquet-column/pom.xml": null,
            "parquet-common/pom.xml": null,
            "parquet-encoding/pom.xml": null,
            "parquet-generator/pom.xml": null,
            "parquet-hadoop/pom.xml": null,
            "parquet-hive/pom.xml": null,
            "parquet-pig/pom.xml": null,
            "parquet-scrooge/pom.xml": null,
            "parquet-test-hadoop2/pom.xml": null,
            "parquet-thrift/pom.xml": null,
            "pom.xml": null
        }
    },
    "78481ad03d3d830f5b18b16441ebade435764175": {
        "datetime": "2013-07-29T21:24:37-07:00",
        "summary": "[maven-release-plugin] prepare for next development iteration",
        "message": "[maven-release-plugin] prepare for next development iteration\n",
        "diff": {
            "parquet-avro/pom.xml": null,
            "parquet-cascading/pom.xml": null,
            "parquet-column/pom.xml": null,
            "parquet-common/pom.xml": null,
            "parquet-encoding/pom.xml": null,
            "parquet-generator/pom.xml": null,
            "parquet-hadoop/pom.xml": null,
            "parquet-hive/pom.xml": null,
            "parquet-pig/pom.xml": null,
            "parquet-scrooge/pom.xml": null,
            "parquet-test-hadoop2/pom.xml": null,
            "parquet-thrift/pom.xml": null,
            "pom.xml": null
        }
    },
    "aca5615695e56be9af627f48b0fad8212fc4cd78": {
        "datetime": "2013-07-30T09:27:09-07:00",
        "summary": "Update README.md",
        "message": "Update README.md",
        "diff": {
            "README.md": null
        }
    },
    "ac0caa0f4fae463886676d3a4212009c9648eb22": {
        "datetime": "2013-07-30T17:19:45-07:00",
        "summary": "Update README.md",
        "message": "Update README.md",
        "diff": {
            "README.md": null
        }
    },
    "ecb2daca5bd6e2828e2a5079d0f2f326737415c9": {
        "datetime": "2013-08-03T10:01:03-07:00",
        "summary": "refactro column reader",
        "message": "refactro column reader\n",
        "diff": {
            "parquet-column/src/main/java/parquet/column/ColumnReader.java": [
                6,
                7
            ],
            "parquet-column/src/main/java/parquet/column/impl/ColumnReaderImpl.java": [
                46,
                82
            ],
            "parquet-column/src/main/java/parquet/filter/AndRecordFilter.java": [
                5,
                0
            ],
            "parquet-column/src/main/java/parquet/filter/ColumnRecordFilter.java": [
                9,
                1
            ],
            "parquet-column/src/main/java/parquet/filter/PagedRecordFilter.java": [
                8,
                0
            ],
            "parquet-column/src/main/java/parquet/filter/RecordFilter.java": [
                5,
                0
            ],
            "parquet-column/src/main/java/parquet/io/FilteredRecordReader.java": [
                13,
                11
            ],
            "parquet-column/src/main/java/parquet/io/MessageColumnIO.java": [
                3,
                3
            ],
            "parquet-column/src/main/java/parquet/io/RecordReaderImplementation.java": [
                0,
                1
            ],
            "parquet-column/src/test/java/parquet/column/mem/TestMemColumn.java": [
                8,
                8
            ],
            "parquet-column/src/test/java/parquet/column/mem/TestMemPageStore.java": [
                1,
                1
            ],
            "parquet-column/src/test/java/parquet/column/page/mem/MemPageStore.java": [
                1,
                11
            ],
            "parquet-column/src/test/java/parquet/io/PerfTest.java": [
                9,
                10
            ],
            "parquet-column/src/test/java/parquet/io/TestColumnIO.java": [
                7,
                7
            ],
            "parquet-column/src/test/java/parquet/io/TestFiltered.java": [
                33,
                43
            ],
            "parquet-hive/src/test/java/parquet/hive/TestDeprecatedParquetInputFormat.java": [
                1,
                1
            ],
            "parquet-pig/src/test/java/parquet/pig/GenerateIntTestFile.java": [
                1,
                1
            ],
            "parquet-pig/src/test/java/parquet/pig/GenerateTPCH.java": [
                1,
                1
            ],
            "parquet-pig/src/test/java/parquet/pig/TupleConsumerPerfTest.java": [
                11,
                12
            ],
            "parquet-thrift/src/test/java/parquet/thrift/TestParquetReadProtocol.java": [
                1,
                1
            ]
        }
    },
    "f8dd20889316262aaf2d8c73eeca092e27faad0e": {
        "datetime": "2013-08-03T10:10:05-07:00",
        "summary": "simplify end of page count",
        "message": "simplify end of page count\n",
        "diff": {
            "parquet-column/src/main/java/parquet/column/impl/ColumnReaderImpl.java": [
                5,
                4
            ]
        }
    },
    "aa530c19c2b1c7253b1dec3d29fd7abc1762dde8": {
        "datetime": "2013-08-03T10:18:16-07:00",
        "summary": "Merge branch 'master' of github.com:Parquet/parquet-mr into refactor_column_reader",
        "message": "Merge branch 'master' of github.com:Parquet/parquet-mr into refactor_column_reader\n",
        "diff": {
            "README.md": null,
            "parquet-avro/pom.xml": null,
            "parquet-cascading/pom.xml": null,
            "parquet-column/pom.xml": null,
            "parquet-common/pom.xml": null,
            "parquet-encoding/pom.xml": null,
            "parquet-generator/pom.xml": null,
            "parquet-hadoop/pom.xml": null,
            "parquet-hadoop/src/main/java/parquet/hadoop/InternalParquetRecordReader.java": [
                0,
                178
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/InternalParquetRecordWriter.java": [
                0,
                133
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/ParquetFileReader.java": [
                1,
                1
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/ParquetFileWriter.java": [
                1,
                2
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/ParquetOutputFormat.java": [
                1,
                1
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/ParquetReader.java": [
                11,
                4
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/ParquetRecordReader.java": [
                125,
                15
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/ParquetRecordWriter.java": [
                92,
                6
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/ParquetWriter.java": [
                6,
                6
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/api/package-info.java": [
                0,
                23
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/package-info.java": [
                0,
                31
            ],
            "parquet-hive/pom.xml": null,
            "parquet-pig/pom.xml": null,
            "parquet-pig/src/main/java/parquet/pig/ParquetLoader.java": [
                7,
                24
            ],
            "parquet-pig/src/main/java/parquet/pig/TupleReadSupport.java": [
                6,
                5
            ],
            "parquet-pig/src/main/java/parquet/pig/convert/TupleConverter.java": [
                10,
                17
            ],
            "parquet-scrooge/pom.xml": null,
            "parquet-test-hadoop2/pom.xml": null,
            "parquet-thrift/pom.xml": null,
            "parquet-thrift/src/main/java/parquet/hadoop/thrift/ThriftReadSupport.java": [
                0,
                19
            ],
            "parquet-thrift/src/main/java/parquet/hadoop/thrift/ThriftWriteSupport.java": [
                5,
                27
            ],
            "parquet-thrift/src/main/java/parquet/thrift/ThriftParquetReader.java": [
                0,
                52
            ],
            "parquet-thrift/src/main/java/parquet/thrift/ThriftParquetWriter.java": [
                0,
                44
            ],
            "parquet-thrift/src/test/java/parquet/thrift/TestThriftParquetReaderWriter.java": [
                0,
                70
            ],
            "pom.xml": null
        }
    },
    "26932a5498ad3d66614563b4024c2f81c4ffbd20": {
        "datetime": "2013-08-05T07:12:37-07:00",
        "summary": "Minor README.md fix",
        "message": "Minor README.md fix\n\nremoved a duplicate row in the feature table.",
        "diff": {
            "README.md": null
        }
    },
    "c126179781821c1aba1140184be1e28b3d1924c9": {
        "datetime": "2013-08-06T13:16:02-07:00",
        "summary": "remove raw type for ParquetTbaseScheme to support thrift0.5; remove scalding dependency",
        "message": "remove raw type for ParquetTbaseScheme to support thrift0.5; remove scalding dependency\n",
        "diff": {
            "parquet-cascading/src/main/java/parquet/cascading/ParquetTBaseScheme.java": [
                1,
                1
            ],
            "parquet-scrooge/pom.xml": null
        }
    },
    "2a32f349586e6d224b13089a74bdf46f36ee48ac": {
        "datetime": "2013-08-06T13:29:03-07:00",
        "summary": "Merge pull request #119 from Parquet/thrift_05_compatible",
        "message": "Merge pull request #119 from Parquet/thrift_05_compatible\n\nfix compatibility with thrift, remove unused dependency",
        "diff": {
            "parquet-cascading/src/main/java/parquet/cascading/ParquetTBaseScheme.java": [
                1,
                1
            ],
            "parquet-scrooge/pom.xml": null
        }
    },
    "86ae4f87c4254a74006f807aed8199d3138cc4ad": {
        "datetime": "2013-08-07T15:12:48-07:00",
        "summary": "fix wrong converter: use TBaseRecordConverter for ParquetTBaseScheme; Add unit test for getting correct record converter",
        "message": "fix wrong converter: use TBaseRecordConverter for ParquetTBaseScheme; Add unit test for getting correct record converter\n",
        "diff": {
            "parquet-cascading/src/main/java/parquet/cascading/ParquetTBaseScheme.java": [
                2,
                2
            ],
            "parquet-cascading/src/test/java/parquet/cascading/ParquetTBaseSchemeTest.java": [
                0,
                44
            ]
        }
    },
    "a54414c908d68125994c9d3199f95000dc53db02": {
        "datetime": "2013-08-07T15:41:48-07:00",
        "summary": "use Mockito to mock varibles in test, fix format and variable name",
        "message": "use Mockito to mock varibles in test, fix format and variable name\n",
        "diff": {
            "parquet-cascading/pom.xml": null,
            "parquet-cascading/src/test/java/parquet/cascading/ParquetTBaseSchemeTest.java": [
                8,
                8
            ]
        }
    },
    "5a259265afa62b5117cfa969c735b5e36e416050": {
        "datetime": "2013-08-07T16:47:55-07:00",
        "summary": "Merge pull request #121 from Parquet/fix_wrong_record_converter_class",
        "message": "Merge pull request #121 from Parquet/fix_wrong_record_converter_class\n\nfix wrong RecordConverter for ParquetTBaseScheme",
        "diff": {
            "parquet-cascading/pom.xml": null,
            "parquet-cascading/src/main/java/parquet/cascading/ParquetTBaseScheme.java": [
                2,
                2
            ],
            "parquet-cascading/src/test/java/parquet/cascading/ParquetTBaseSchemeTest.java": [
                0,
                44
            ]
        }
    },
    "6232dafaeeea874433a1a735c96f856293514f20": {
        "datetime": "2013-08-07T17:32:27-07:00",
        "summary": "fix javadoc",
        "message": "fix javadoc\n",
        "diff": {
            "parquet-column/src/main/java/parquet/io/RecordReaderImplementation.java": [
                4,
                3
            ]
        }
    },
    "1fc0698ed64514c9e30de7892c3a1d142f3f5469": {
        "datetime": "2013-08-07T19:19:39-07:00",
        "summary": "Fix RLE bug with partial literal groups at end of stream.",
        "message": "Fix RLE bug with partial literal groups at end of stream.\n",
        "diff": {
            "parquet-column/src/main/java/parquet/column/values/dictionary/DictionaryValuesReader.java": [
                1,
                1
            ],
            "parquet-column/src/main/java/parquet/column/values/rle/RunLengthBitPackingHybridDecoder.java": [
                3,
                12
            ],
            "parquet-column/src/main/java/parquet/column/values/rle/RunLengthBitPackingHybridValuesReader.java": [
                1,
                1
            ],
            "parquet-column/src/test/java/parquet/column/values/rle/RunLengthBitPackingHybridIntegrationTest.java": [
                1,
                7
            ],
            "parquet-column/src/test/java/parquet/column/values/rle/TestRunLengthBitPackingHybridEncoder.java": [
                1,
                17
            ]
        }
    },
    "a9e2c7d5fc862fe422624e29b7bcb6a8dafdb2da": {
        "datetime": "2013-08-07T23:34:42-07:00",
        "summary": "Fix Short and Byte types in Hive SerDe.",
        "message": "Fix Short and Byte types in Hive SerDe.\n",
        "diff": {
            "parquet-hive/src/main/java/parquet/hive/serde/ArrayWritableObjectInspector.java": [
                2,
                73
            ],
            "parquet-hive/src/main/java/parquet/hive/write/DataWritableWriter.java": [
                0,
                6
            ]
        }
    },
    "35c6dc69bc7dc3338723d2614b45088aa42dc09a": {
        "datetime": "2013-08-09T10:52:40-07:00",
        "summary": "removing github-pages-site target before releasing",
        "message": "removing github-pages-site target before releasing\n",
        "diff": {
            "pom.xml": null
        }
    },
    "8ffe30de1e89f04bcbfbe0bf197f3e214d2f104e": {
        "datetime": "2013-08-09T10:55:34-07:00",
        "summary": "[maven-release-plugin] prepare release parquet-1.0.1",
        "message": "[maven-release-plugin] prepare release parquet-1.0.1\n",
        "diff": {
            "parquet-avro/pom.xml": null,
            "parquet-cascading/pom.xml": null,
            "parquet-column/pom.xml": null,
            "parquet-common/pom.xml": null,
            "parquet-encoding/pom.xml": null,
            "parquet-generator/pom.xml": null,
            "parquet-hadoop/pom.xml": null,
            "parquet-hive/pom.xml": null,
            "parquet-pig/pom.xml": null,
            "parquet-scrooge/pom.xml": null,
            "parquet-test-hadoop2/pom.xml": null,
            "parquet-thrift/pom.xml": null,
            "pom.xml": null
        }
    },
    "05c73c484c8a5c61a5d665427102fbebf786de9a": {
        "datetime": "2013-08-09T10:55:39-07:00",
        "summary": "[maven-release-plugin] prepare for next development iteration",
        "message": "[maven-release-plugin] prepare for next development iteration\n",
        "diff": {
            "parquet-avro/pom.xml": null,
            "parquet-cascading/pom.xml": null,
            "parquet-column/pom.xml": null,
            "parquet-common/pom.xml": null,
            "parquet-encoding/pom.xml": null,
            "parquet-generator/pom.xml": null,
            "parquet-hadoop/pom.xml": null,
            "parquet-hive/pom.xml": null,
            "parquet-pig/pom.xml": null,
            "parquet-scrooge/pom.xml": null,
            "parquet-test-hadoop2/pom.xml": null,
            "parquet-thrift/pom.xml": null,
            "pom.xml": null
        }
    },
    "f17b83c6a6a84a5462263593bdf106804390c648": {
        "datetime": "2013-08-09T13:54:11-07:00",
        "summary": "added unit tests for parquet cascading",
        "message": "added unit tests for parquet cascading\n",
        "diff": {
            "parquet-cascading/src/test/java/parquet/cascading/ParquetTBaseSchemeTest.java": [
                2,
                25
            ],
            "parquet-cascading/src/test/java/parquet/cascading/ParquetTupleSchemeTest.java": [
                0,
                87
            ],
            "parquet-cascading/src/test/resources/part-m-00000.gz.parquet": null,
            "parquet-scrooge/src/test/parquet/scrooge/ParquetScroogeSchemeTest.java": [
                0,
                11
            ]
        }
    },
    "7e16d31a2729e06c9c9f753af2bbe47b3751fa44": {
        "datetime": "2013-08-09T13:58:58-07:00",
        "summary": "better format",
        "message": "better format\n",
        "diff": {
            "parquet-cascading/src/test/java/parquet/cascading/ParquetTupleSchemeTest.java": [
                32,
                27
            ],
            "parquet-cascading/src/test/java/parquet/cascading/TestParquetTBaseScheme.java": [
                8,
                10
            ]
        }
    },
    "f327ecff9dceb2013237a89a0b0740ffea558a0c": {
        "datetime": "2013-08-09T14:11:35-07:00",
        "summary": "format",
        "message": "format\n",
        "diff": {
            "parquet-cascading/src/test/java/parquet/cascading/ParquetTupleSchemeTest.java": [
                1,
                1
            ],
            "parquet-scrooge/src/test/parquet/scrooge/ParquetScroogeSchemeTest.java": [
                11,
                0
            ]
        }
    },
    "e4269e64a18f18c9fa83e39d9ca3a9c7479a8245": {
        "datetime": "2013-08-09T14:14:29-07:00",
        "summary": "remove blank lines",
        "message": "remove blank lines\n",
        "diff": {
            "parquet-cascading/src/test/java/parquet/cascading/TestParquetTupleScheme.java": [
                3,
                0
            ]
        }
    },
    "3a3b73a68d3c50e86e4d2372511b9ee99d9b9fe3": {
        "datetime": "2013-08-09T17:42:49-07:00",
        "summary": "Merge pull request #126 from Parquet/unit_tests_for_parquet_cascading",
        "message": "Merge pull request #126 from Parquet/unit_tests_for_parquet_cascading\n\nUnit tests for parquet cascading",
        "diff": {
            "parquet-cascading/src/test/java/parquet/cascading/ParquetTBaseSchemeTest.java": [
                2,
                27
            ],
            "parquet-cascading/src/test/java/parquet/cascading/TestParquetTupleScheme.java": [
                0,
                79
            ],
            "parquet-cascading/src/test/resources/part-m-00000.gz.parquet": null
        }
    },
    "3c869369c31f7b5111144e20eada313877fdf78e": {
        "datetime": "2013-08-09T17:44:54-07:00",
        "summary": "Merge pull request #120 from Parquet/rle_fix",
        "message": "Merge pull request #120 from Parquet/rle_fix\n\nFix RLE bug with partial literal groups at end of stream.",
        "diff": {
            "parquet-column/src/main/java/parquet/column/values/dictionary/DictionaryValuesReader.java": [
                1,
                1
            ],
            "parquet-column/src/main/java/parquet/column/values/rle/RunLengthBitPackingHybridDecoder.java": [
                3,
                12
            ],
            "parquet-column/src/main/java/parquet/column/values/rle/RunLengthBitPackingHybridValuesReader.java": [
                1,
                1
            ],
            "parquet-column/src/test/java/parquet/column/values/rle/RunLengthBitPackingHybridIntegrationTest.java": [
                1,
                7
            ],
            "parquet-column/src/test/java/parquet/column/values/rle/TestRunLengthBitPackingHybridEncoder.java": [
                1,
                17
            ]
        }
    },
    "8d6661106c2511b0b9525016278d5f2ec3947956": {
        "datetime": "2013-08-12T17:17:26+01:00",
        "summary": "adding dictionary encoding for long,double,int,float",
        "message": "adding dictionary encoding for long,double,int,float\n",
        "diff": {
            "parquet-column/pom.xml": null,
            "parquet-column/src/main/java/parquet/column/Encoding.java": [
                7,
                17
            ],
            "parquet-column/src/main/java/parquet/column/impl/ColumnWriterImpl.java": [
                2,
                6
            ],
            "parquet-column/src/main/java/parquet/column/values/dictionary/DictionaryValuesReader.java": [
                0,
                36
            ],
            "parquet-column/src/main/java/parquet/column/values/dictionary/DictionaryValuesWriter.java": [
                98,
                275
            ],
            "parquet-column/src/main/java/parquet/column/values/dictionary/PlainBinaryDictionary.java": [
                82,
                0
            ],
            "parquet-column/src/main/java/parquet/column/values/dictionary/PlainValuesDictionary.java": [
                0,
                208
            ],
            "parquet-column/src/test/java/parquet/column/values/dictionary/TestDictionary.java": [
                16,
                373
            ]
        }
    },
    "28da58cd571f5c23397f3865333c24d434e7aa89": {
        "datetime": "2013-08-12T13:50:27-07:00",
        "summary": "Fix Snappy compressor in parquet-hadoop.",
        "message": "Fix Snappy compressor in parquet-hadoop.\n",
        "diff": {
            "parquet-hadoop/src/main/java/parquet/hadoop/codec/NonBlockedCompressorStream.java": [
                0,
                32
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/codec/NonBlockedDecompressorStream.java": [
                0,
                39
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/codec/SnappyCodec.java": [
                4,
                2
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/codec/SnappyCompressor.java": [
                5,
                7
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/codec/SnappyDecompressor.java": [
                16,
                14
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/codec/SnappyUtil.java": [
                1,
                2
            ],
            "parquet-hadoop/src/test/java/parquet/hadoop/TestSnappyCodec.java": [
                0,
                55
            ]
        }
    },
    "393485573a6fa08ee5737b61542299c6d010eb75": {
        "datetime": "2013-08-13T10:43:00+01:00",
        "summary": "update plugin versions for maven aether migration - fixes #125",
        "message": "update plugin versions for maven aether migration - fixes #125\n",
        "diff": {
            "parquet-avro/pom.xml": null,
            "parquet-hadoop/pom.xml": null,
            "parquet-pig/pom.xml": null,
            "parquet-thrift/pom.xml": null,
            "pom.xml": null
        }
    },
    "3fad4bd1d80da4ca7da5ef532ea5f60b4d898c6a": {
        "datetime": "2013-08-13T09:33:21-07:00",
        "summary": "Merge pull request #133 from atkeano/maven_build_errors",
        "message": "Merge pull request #133 from atkeano/maven_build_errors\n\nUpdate plugin versions for maven aether migration - fixes #125",
        "diff": {
            "parquet-avro/pom.xml": null,
            "parquet-hadoop/pom.xml": null,
            "parquet-pig/pom.xml": null,
            "parquet-thrift/pom.xml": null,
            "pom.xml": null
        }
    },
    "87228ebd3a778ec4abacd9288a4872d7ec2c95f0": {
        "datetime": "2013-08-13T23:33:12+01:00",
        "summary": "refactoring dictionary encoding for non string types after comments #127",
        "message": "refactoring dictionary encoding for non string types after comments #127\n",
        "diff": {
            "parquet-column/src/main/java/parquet/column/Encoding.java": [
                2,
                10
            ],
            "parquet-column/src/main/java/parquet/column/impl/ColumnWriterImpl.java": [
                18,
                38
            ],
            "parquet-column/src/main/java/parquet/column/values/dictionary/DictionaryValuesWriter.java": [
                239,
                322
            ],
            "parquet-column/src/main/java/parquet/column/values/dictionary/PlainValuesDictionary.java": [
                122,
                183
            ],
            "parquet-column/src/test/java/parquet/column/values/dictionary/TestDictionary.java": [
                11,
                17
            ]
        }
    },
    "12bc29a405b6e0bcf25c7412f1b3b6649c6819c6": {
        "datetime": "2013-08-13T15:43:15-07:00",
        "summary": "split out method to facilitate the inliner job",
        "message": "split out method to facilitate the inliner job\n",
        "diff": {
            "parquet-column/src/main/java/parquet/column/impl/ColumnReaderImpl.java": [
                38,
                42
            ],
            "parquet-column/src/test/java/parquet/io/PerfTest.java": [
                0,
                1
            ]
        }
    },
    "99673f2fa7b36ad2fae41cbb2eb2cd27424e9883": {
        "datetime": "2013-08-13T16:36:05-07:00",
        "summary": "Merge pull request #127 from atkeano/dictionary_encodings",
        "message": "Merge pull request #127 from atkeano/dictionary_encodings\n\nAdding dictionary encoding for non string types.. #99",
        "diff": {
            "parquet-column/pom.xml": null,
            "parquet-column/src/main/java/parquet/column/Encoding.java": [
                7,
                25
            ],
            "parquet-column/src/main/java/parquet/column/impl/ColumnWriterImpl.java": [
                14,
                38
            ],
            "parquet-column/src/main/java/parquet/column/values/dictionary/DictionaryValuesReader.java": [
                0,
                36
            ],
            "parquet-column/src/main/java/parquet/column/values/dictionary/DictionaryValuesWriter.java": [
                132,
                392
            ],
            "parquet-column/src/main/java/parquet/column/values/dictionary/PlainBinaryDictionary.java": [
                82,
                0
            ],
            "parquet-column/src/main/java/parquet/column/values/dictionary/PlainValuesDictionary.java": [
                0,
                269
            ],
            "parquet-column/src/test/java/parquet/column/values/dictionary/TestDictionary.java": [
                15,
                378
            ]
        }
    },
    "ce8c1a42849e3022b38807d3c597615925bf8544": {
        "datetime": "2013-08-13T16:39:18-07:00",
        "summary": "Merge pull request #118 from Parquet/refactor_column_reader",
        "message": "Merge pull request #118 from Parquet/refactor_column_reader\n\nRefactor column reader",
        "diff": {
            "parquet-column/src/main/java/parquet/column/ColumnReader.java": [
                6,
                7
            ],
            "parquet-column/src/main/java/parquet/column/impl/ColumnReaderImpl.java": [
                88,
                127
            ],
            "parquet-column/src/main/java/parquet/filter/AndRecordFilter.java": [
                5,
                0
            ],
            "parquet-column/src/main/java/parquet/filter/ColumnRecordFilter.java": [
                9,
                1
            ],
            "parquet-column/src/main/java/parquet/filter/PagedRecordFilter.java": [
                8,
                0
            ],
            "parquet-column/src/main/java/parquet/filter/RecordFilter.java": [
                5,
                0
            ],
            "parquet-column/src/main/java/parquet/io/FilteredRecordReader.java": [
                13,
                11
            ],
            "parquet-column/src/main/java/parquet/io/MessageColumnIO.java": [
                3,
                3
            ],
            "parquet-column/src/main/java/parquet/io/RecordReaderImplementation.java": [
                3,
                3
            ],
            "parquet-column/src/test/java/parquet/column/mem/TestMemColumn.java": [
                8,
                8
            ],
            "parquet-column/src/test/java/parquet/column/mem/TestMemPageStore.java": [
                1,
                1
            ],
            "parquet-column/src/test/java/parquet/column/page/mem/MemPageStore.java": [
                1,
                11
            ],
            "parquet-column/src/test/java/parquet/io/PerfTest.java": [
                9,
                11
            ],
            "parquet-column/src/test/java/parquet/io/TestColumnIO.java": [
                7,
                7
            ],
            "parquet-column/src/test/java/parquet/io/TestFiltered.java": [
                33,
                43
            ],
            "parquet-hive/src/test/java/parquet/hive/TestDeprecatedParquetInputFormat.java": [
                1,
                1
            ],
            "parquet-pig/src/test/java/parquet/pig/GenerateIntTestFile.java": [
                1,
                1
            ],
            "parquet-pig/src/test/java/parquet/pig/GenerateTPCH.java": [
                1,
                1
            ],
            "parquet-pig/src/test/java/parquet/pig/TupleConsumerPerfTest.java": [
                11,
                12
            ],
            "parquet-thrift/src/test/java/parquet/thrift/TestParquetReadProtocol.java": [
                1,
                1
            ]
        }
    },
    "af45d9cc20d31f5fd103dac3de8b850d00b18f17": {
        "datetime": "2013-08-14T17:41:36-07:00",
        "summary": "fix bug of wrong column metadata size",
        "message": "fix bug of wrong column metadata size\n",
        "diff": {
            "parquet-hadoop/src/main/java/parquet/format/converter/ParquetMetadataConverter.java": [
                2,
                2
            ]
        }
    },
    "3fb938b9e09271c5e8919e4cdff671ba7d6a0593": {
        "datetime": "2013-08-14T18:15:39-07:00",
        "summary": "Merge pull request #138 from Parquet/fix_column_metadata_size",
        "message": "Merge pull request #138 from Parquet/fix_column_metadata_size\n\nfix bug of wrong column metadata size",
        "diff": {
            "parquet-hadoop/src/main/java/parquet/format/converter/ParquetMetadataConverter.java": [
                2,
                2
            ]
        }
    },
    "6ff02643a66b1e25ac3edca94433ac7c7e781f7d": {
        "datetime": "2013-08-15T09:23:01-07:00",
        "summary": "Implemented partial schema for GroupReadSupport",
        "message": "Implemented partial schema for GroupReadSupport\n",
        "diff": {
            "parquet-hadoop/src/main/java/parquet/hadoop/example/GroupReadSupport.java": [
                2,
                3
            ]
        }
    },
    "c9b213cfce3d7d24fdd23471ce5b9dd970f7fc3d": {
        "datetime": "2013-08-15T11:43:56-07:00",
        "summary": "Merge pull request #123 from Parquet/snappy_codec",
        "message": "Merge pull request #123 from Parquet/snappy_codec\n\nFix Snappy compressor in parquet-hadoop.",
        "diff": {
            "parquet-hadoop/src/main/java/parquet/hadoop/codec/NonBlockedCompressorStream.java": [
                0,
                32
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/codec/NonBlockedDecompressorStream.java": [
                0,
                39
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/codec/SnappyCodec.java": [
                4,
                2
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/codec/SnappyCompressor.java": [
                5,
                7
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/codec/SnappyDecompressor.java": [
                16,
                14
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/codec/SnappyUtil.java": [
                1,
                2
            ],
            "parquet-hadoop/src/test/java/parquet/hadoop/TestSnappyCodec.java": [
                0,
                55
            ]
        }
    },
    "a274684f2257aecb27404130a938758cd36504e9": {
        "datetime": "2013-08-15T12:03:15-07:00",
        "summary": "added 3 counters to parquet for benchmarking bytes read and time spent",
        "message": "added 3 counters to parquet for benchmarking bytes read and time spent\n",
        "diff": {
            "parquet-hadoop/src/main/java/parquet/hadoop/InternalParquetRecordReader.java": [
                0,
                2
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/ParquetFileReader.java": [
                0,
                3
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/ParquetRecordReader.java": [
                0,
                5
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/util/BenchmarkCounter.java": [
                0,
                59
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/util/ContextUtil.java": [
                1,
                22
            ],
            "parquet-hadoop/src/test/java/parquet/hadoop/example/TestInputOutputFormat.java": [
                34,
                69
            ]
        }
    },
    "43ad5e5257e03e8fb6ad738d61bf1e4ae132b6fc": {
        "datetime": "2013-08-15T12:04:39-07:00",
        "summary": "fix test",
        "message": "fix test\n",
        "diff": {
            "parquet-hadoop/src/test/java/parquet/hadoop/example/TestInputOutputFormat.java": [
                1,
                1
            ]
        }
    },
    "2cc9321b41806955d55358e361d454d31f4f0627": {
        "datetime": "2013-08-15T12:13:15-07:00",
        "summary": "add test for no benchmark counters",
        "message": "add test for no benchmark counters\n",
        "diff": {
            "parquet-hadoop/src/test/java/parquet/hadoop/example/TestInputOutputFormat.java": [
                6,
                18
            ]
        }
    },
    "ccf32c7ce4cd85556336fe769389f3f257668ecb": {
        "datetime": "2013-08-15T14:54:16-07:00",
        "summary": "remove comments",
        "message": "remove comments\n",
        "diff": {
            "parquet-hadoop/src/main/java/parquet/hadoop/util/BenchmarkCounter.java": [
                3,
                0
            ]
        }
    },
    "ea62ffe142871844b605d5300bd2a07dff785f17": {
        "datetime": "2013-08-15T15:25:41-07:00",
        "summary": "add unit test",
        "message": "add unit test\n",
        "diff": {
            "parquet-hadoop/src/test/java/parquet/hadoop/example/GroupReadSupportTest.java": [
                0,
                47
            ]
        }
    },
    "9394c097b9c19070fffd8143dcdcb4c60765be2d": {
        "datetime": "2013-08-15T15:55:47-07:00",
        "summary": "fix test",
        "message": "fix test\n",
        "diff": {
            "parquet-hadoop/src/test/java/parquet/hadoop/example/GroupReadSupportTest.java": [
                14,
                15
            ]
        }
    },
    "c2697261fdd7ebc10badaf89563ec4c2ed0c4804": {
        "datetime": "2013-08-15T15:57:29-07:00",
        "summary": "formatting",
        "message": "formatting\n",
        "diff": {
            "parquet-hadoop/src/test/java/parquet/hadoop/example/GroupReadSupportTest.java": [
                2,
                0
            ]
        }
    },
    "4288aa65dc642c23dd90110209653c4033f9dbe1": {
        "datetime": "2013-08-15T15:58:45-07:00",
        "summary": "formatting",
        "message": "formatting\n",
        "diff": {
            "parquet-hadoop/src/test/java/parquet/hadoop/example/GroupReadSupportTest.java": [
                1,
                2
            ]
        }
    },
    "d4ef8d958c1a0dfbda0334d183ed5843e2fb9496": {
        "datetime": "2013-08-15T16:06:05-07:00",
        "summary": "Merge pull request #140 from Parquet/partial_schema_for_group_read_support",
        "message": "Merge pull request #140 from Parquet/partial_schema_for_group_read_support\n\nImplemented partial schema for GroupReadSupport",
        "diff": {
            "parquet-hadoop/src/main/java/parquet/hadoop/example/GroupReadSupport.java": [
                2,
                3
            ],
            "parquet-hadoop/src/test/java/parquet/hadoop/example/GroupReadSupportTest.java": [
                0,
                47
            ]
        }
    },
    "1323e4f80184c79dc5bd7cee642bbf8c398c8cf0": {
        "datetime": "2013-08-15T16:07:22-07:00",
        "summary": "Merge branch 'master' of https://github.com/Parquet/parquet-mr into hraven_counters",
        "message": "Merge branch 'master' of https://github.com/Parquet/parquet-mr into hraven_counters\n",
        "diff": {
            "parquet-hadoop/src/main/java/parquet/hadoop/codec/NonBlockedCompressorStream.java": [
                0,
                32
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/codec/NonBlockedDecompressorStream.java": [
                0,
                39
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/codec/SnappyCodec.java": [
                4,
                2
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/codec/SnappyCompressor.java": [
                5,
                7
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/codec/SnappyDecompressor.java": [
                16,
                14
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/codec/SnappyUtil.java": [
                1,
                2
            ],
            "parquet-hadoop/src/test/java/parquet/hadoop/TestSnappyCodec.java": [
                0,
                55
            ],
            "parquet-hadoop/src/test/java/parquet/hadoop/example/GroupReadSupportTest.java": [
                0,
                47
            ]
        }
    },
    "397b4c9b59855db9ef4e27f3c72df1e043340cb4": {
        "datetime": "2013-08-15T16:28:01-07:00",
        "summary": "formatting",
        "message": "formatting\n",
        "diff": {
            "parquet-hadoop/src/main/java/parquet/hadoop/util/BenchmarkCounter.java": [
                11,
                7
            ],
            "parquet-hadoop/src/test/java/parquet/hadoop/example/TestInputOutputFormat.java": [
                28,
                32
            ]
        }
    },
    "f8e2658581d8291281969aac53793b921ba49476": {
        "datetime": "2013-08-16T10:14:49-07:00",
        "summary": "fix incrementCounter getConfiguration method to support 2.0",
        "message": "fix incrementCounter getConfiguration method to support 2.0\n",
        "diff": {
            "parquet-hadoop/src/main/java/parquet/hadoop/util/BenchmarkCounter.java": [
                4,
                4
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/util/ContextUtil.java": [
                1,
                16
            ]
        }
    },
    "3bebb9a160a3e181445f425a0b04f01f7818c649": {
        "datetime": "2013-08-16T14:04:00-07:00",
        "summary": "fix",
        "message": "fix\n",
        "diff": {
            "parquet-hadoop/src/main/java/parquet/hadoop/ParquetFileWriter.java": [
                0,
                1
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/util/BenchmarkCounter.java": [
                3,
                4
            ],
            "parquet-hadoop/src/test/java/parquet/hadoop/example/TestInputOutputFormat.java": [
                1,
                1
            ]
        }
    },
    "35c419cd8346b7db368bf1dbcfa7836ed32a9544": {
        "datetime": "2013-08-16T14:41:31-07:00",
        "summary": "remove public Constants",
        "message": "remove public Constants\n",
        "diff": {
            "parquet-hadoop/src/main/java/parquet/hadoop/util/BenchmarkCounter.java": [
                10,
                10
            ],
            "parquet-hadoop/src/test/java/parquet/hadoop/example/TestInputOutputFormat.java": [
                11,
                11
            ]
        }
    },
    "cb6d3d2347762f50c277d3fcfef236af7b2cee52": {
        "datetime": "2013-08-18T22:00:44-07:00",
        "summary": "Merge pull request #141 from Parquet/hraven_counters",
        "message": "Merge pull request #141 from Parquet/hraven_counters\n\nadd parquet counters for benchmark",
        "diff": {
            "parquet-hadoop/src/main/java/parquet/hadoop/InternalParquetRecordReader.java": [
                0,
                2
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/ParquetFileReader.java": [
                0,
                3
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/ParquetRecordReader.java": [
                0,
                5
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/util/BenchmarkCounter.java": [
                0,
                52
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/util/ContextUtil.java": [
                1,
                37
            ],
            "parquet-hadoop/src/test/java/parquet/hadoop/example/TestInputOutputFormat.java": [
                43,
                94
            ]
        }
    },
    "9ef85a0e14279e30775f7f77754952740306bda9": {
        "datetime": "2013-08-19T09:44:49-07:00",
        "summary": "merge",
        "message": "merge\n",
        "diff": {
            "parquet-hadoop/src/main/java/parquet/hadoop/util/BenchmarkCounter.java": [
                10,
                10
            ],
            "parquet-hadoop/src/test/java/parquet/hadoop/example/TestInputOutputFormat.java": [
                11,
                11
            ]
        }
    },
    "42ad7014390491ace28ac2fc3a36ed6959ee4dbc": {
        "datetime": "2013-08-19T09:46:16-07:00",
        "summary": "fix test file path",
        "message": "fix test file path\n",
        "diff": {
            "parquet-hadoop/src/test/java/parquet/hadoop/example/TestInputOutputFormat.java": [
                1,
                1
            ]
        }
    },
    "4d1b3e06819eb3e2cde75b915115ce22a6580729": {
        "datetime": "2013-08-19T09:52:32-07:00",
        "summary": "add unit test",
        "message": "add unit test\n",
        "diff": {
            "parquet-hadoop/src/test/java/parquet/hadoop/TestParquetFileWriter.java": [
                0,
                1
            ]
        }
    },
    "09bfe990ea6951a7a03e42b825ab6734c89c4c58": {
        "datetime": "2013-08-19T10:10:05-07:00",
        "summary": "Merge pull request #124 from Parquet/serde",
        "message": "Merge pull request #124 from Parquet/serde\n\nFix Short and Byte types in Hive SerDe.",
        "diff": {
            "parquet-hive/src/main/java/parquet/hive/serde/ArrayWritableObjectInspector.java": [
                2,
                73
            ],
            "parquet-hive/src/main/java/parquet/hive/write/DataWritableWriter.java": [
                0,
                6
            ]
        }
    },
    "92ce68dd021242974417c385a7e7288684f5dab7": {
        "datetime": "2013-08-19T10:20:40-07:00",
        "summary": "fixed",
        "message": "fixed\n",
        "diff": {
            "parquet-hadoop/src/main/java/parquet/hadoop/ParquetFileWriter.java": [
                1,
                0
            ]
        }
    },
    "77bede5537e89d83291f90f1a181d3342bd6b463": {
        "datetime": "2013-08-19T10:30:41-07:00",
        "summary": "add test",
        "message": "add test\n",
        "diff": {
            "parquet-hadoop/src/test/java/parquet/hadoop/TestParquetFileWriter.java": [
                5,
                6
            ]
        }
    },
    "fb670693ff737e2914f47943181f97ad11a12d5f": {
        "datetime": "2013-08-19T12:08:52-07:00",
        "summary": "fix space format",
        "message": "fix space format\n",
        "diff": {
            "parquet-hadoop/src/main/java/parquet/hadoop/ParquetFileWriter.java": [
                1,
                1
            ]
        }
    },
    "37bd05d266c9dc06b4c0a6e808eed256f7f2fa09": {
        "datetime": "2013-08-19T14:12:02-07:00",
        "summary": "Merge pull request #142 from Parquet/fix_total_size_row_group",
        "message": "Merge pull request #142 from Parquet/fix_total_size_row_group\n\nFix total size row group",
        "diff": {
            "parquet-hadoop/src/main/java/parquet/hadoop/ParquetFileWriter.java": [
                0,
                1
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/util/BenchmarkCounter.java": [
                2,
                3
            ],
            "parquet-hadoop/src/test/java/parquet/hadoop/TestParquetFileWriter.java": [
                0,
                1
            ]
        }
    },
    "f61a123dbbe21d060f7fa21342cc402b83a81805": {
        "datetime": "2013-08-20T09:39:40-07:00",
        "summary": "Merge branch 'master' of https://github.com/Parquet/parquet-mr into fix_empty_encoding_col_metadata",
        "message": "Merge branch 'master' of https://github.com/Parquet/parquet-mr into fix_empty_encoding_col_metadata\n",
        "diff": {
            "parquet-hadoop/src/main/java/parquet/hadoop/ParquetFileWriter.java": [
                1,
                1
            ],
            "parquet-hive/src/main/java/parquet/hive/serde/ArrayWritableObjectInspector.java": [
                2,
                73
            ],
            "parquet-hive/src/main/java/parquet/hive/write/DataWritableWriter.java": [
                0,
                6
            ]
        }
    },
    "d2878f8b134f64afe6c6179d56e1f30df36ea958": {
        "datetime": "2013-08-20T17:57:32-07:00",
        "summary": "Merge pull request #143 from Parquet/fix_empty_encoding_col_metadata",
        "message": "Merge pull request #143 from Parquet/fix_empty_encoding_col_metadata\n\nFix empty encoding col metadata",
        "diff": {
            "parquet-hadoop/src/main/java/parquet/hadoop/ParquetFileWriter.java": [
                1,
                0
            ],
            "parquet-hadoop/src/test/java/parquet/hadoop/TestParquetFileWriter.java": [
                5,
                6
            ]
        }
    },
    "8f93adfd0020939b9a58f092b88a5f62fd14b834": {
        "datetime": "2013-08-20T18:13:50-07:00",
        "summary": "Map key fields should allow other types than strings",
        "message": "Map key fields should allow other types than strings\n",
        "diff": {
            "parquet-avro/src/main/java/parquet/avro/AvroSchemaConverter.java": [
                4,
                7
            ],
            "parquet-avro/src/main/java/parquet/avro/AvroWriteSupport.java": [
                1,
                1
            ],
            "parquet-column/src/main/java/parquet/example/data/simple/SimpleGroup.java": [
                1,
                1
            ],
            "parquet-column/src/main/java/parquet/io/ColumnIO.java": [
                1,
                1
            ],
            "parquet-column/src/main/java/parquet/io/ColumnIOFactory.java": [
                1,
                1
            ],
            "parquet-column/src/main/java/parquet/io/GroupColumnIO.java": [
                3,
                3
            ],
            "parquet-column/src/main/java/parquet/io/ValidatingRecordConsumer.java": [
                1,
                1
            ],
            "parquet-column/src/main/java/parquet/schema/ConversionPatterns.java": [
                5,
                17
            ],
            "parquet-column/src/main/java/parquet/schema/GroupType.java": [
                2,
                2
            ],
            "parquet-column/src/main/java/parquet/schema/PrimitiveType.java": [
                2,
                2
            ],
            "parquet-column/src/main/java/parquet/schema/Type.java": [
                0,
                4
            ],
            "parquet-pig/src/main/java/parquet/pig/ParquetLoader.java": [
                1,
                0
            ],
            "parquet-pig/src/main/java/parquet/pig/PigSchemaConverter.java": [
                24,
                110
            ],
            "parquet-pig/src/main/java/parquet/pig/TupleReadSupport.java": [
                6,
                9
            ],
            "parquet-pig/src/main/java/parquet/pig/convert/MapConverter.java": [
                3,
                15
            ],
            "parquet-pig/src/main/java/parquet/pig/convert/TupleConverter.java": [
                1,
                1
            ],
            "parquet-pig/src/test/java/parquet/pig/TestPigSchemaConverter.java": [
                1,
                34
            ],
            "parquet-pig/src/test/java/parquet/pig/TupleConsumerPerfTest.java": [
                2,
                1
            ],
            "parquet-thrift/pom.xml": null,
            "parquet-thrift/src/main/java/parquet/thrift/ThriftSchemaConverter.java": [
                5,
                3
            ],
            "parquet-thrift/src/test/java/parquet/hadoop/thrift/TestThriftToParquetFileWriter.java": [
                34,
                121
            ],
            "parquet-thrift/src/test/thrift/test.thrift": null,
            "pom.xml": null
        }
    },
    "9adb8e24baa3909d91691de2ee7faf2a41e6d7d6": {
        "datetime": "2013-08-21T15:23:44-07:00",
        "summary": "code review changes",
        "message": "code review changes\n",
        "diff": {
            ".travis.yml": null,
            "parquet-column/src/main/java/parquet/column/impl/ColumnReaderImpl.java": [
                9,
                9
            ],
            "parquet-column/src/main/java/parquet/schema/PrimitiveType.java": [
                18,
                18
            ],
            "parquet-pig/src/main/java/parquet/pig/PigSchemaConverter.java": [
                41,
                63
            ]
        }
    },
    "c22a357252cdbac4b92af8ebb72f224d6f686508": {
        "datetime": "2013-08-21T16:23:00-07:00",
        "summary": "Merge pull request #144 from aniket486/map_support",
        "message": "Merge pull request #144 from aniket486/map_support\n\nMap key fields should allow other types than strings",
        "diff": {
            ".travis.yml": null,
            "parquet-avro/src/main/java/parquet/avro/AvroSchemaConverter.java": [
                4,
                7
            ],
            "parquet-avro/src/main/java/parquet/avro/AvroWriteSupport.java": [
                1,
                1
            ],
            "parquet-column/src/main/java/parquet/column/impl/ColumnReaderImpl.java": [
                9,
                9
            ],
            "parquet-column/src/main/java/parquet/example/data/simple/SimpleGroup.java": [
                1,
                1
            ],
            "parquet-column/src/main/java/parquet/io/ColumnIO.java": [
                1,
                1
            ],
            "parquet-column/src/main/java/parquet/io/ColumnIOFactory.java": [
                1,
                1
            ],
            "parquet-column/src/main/java/parquet/io/GroupColumnIO.java": [
                3,
                3
            ],
            "parquet-column/src/main/java/parquet/io/ValidatingRecordConsumer.java": [
                1,
                1
            ],
            "parquet-column/src/main/java/parquet/schema/ConversionPatterns.java": [
                5,
                17
            ],
            "parquet-column/src/main/java/parquet/schema/GroupType.java": [
                2,
                2
            ],
            "parquet-column/src/main/java/parquet/schema/PrimitiveType.java": [
                20,
                20
            ],
            "parquet-column/src/main/java/parquet/schema/Type.java": [
                0,
                4
            ],
            "parquet-pig/src/main/java/parquet/pig/ParquetLoader.java": [
                1,
                0
            ],
            "parquet-pig/src/main/java/parquet/pig/PigSchemaConverter.java": [
                31,
                139
            ],
            "parquet-pig/src/main/java/parquet/pig/TupleReadSupport.java": [
                6,
                9
            ],
            "parquet-pig/src/main/java/parquet/pig/convert/MapConverter.java": [
                3,
                15
            ],
            "parquet-pig/src/main/java/parquet/pig/convert/TupleConverter.java": [
                1,
                1
            ],
            "parquet-pig/src/test/java/parquet/pig/TestPigSchemaConverter.java": [
                1,
                34
            ],
            "parquet-pig/src/test/java/parquet/pig/TupleConsumerPerfTest.java": [
                2,
                1
            ],
            "parquet-thrift/pom.xml": null,
            "parquet-thrift/src/main/java/parquet/thrift/ThriftSchemaConverter.java": [
                5,
                3
            ],
            "parquet-thrift/src/test/java/parquet/hadoop/thrift/TestThriftToParquetFileWriter.java": [
                34,
                121
            ],
            "parquet-thrift/src/test/thrift/test.thrift": null,
            "pom.xml": null
        }
    },
    "b500681226f4a87bed01cdbd99d69e603836cd6d": {
        "datetime": "2013-08-21T23:52:19-07:00",
        "summary": "add getStatistics method to parquetloader",
        "message": "add getStatistics method to parquetloader\n",
        "diff": {
            "parquet-pig/src/main/java/parquet/pig/ParquetLoader.java": [
                2,
                14
            ]
        }
    },
    "e5b767ab75e8cb09fe18d2e83d061a0a285f54c8": {
        "datetime": "2013-08-22T10:56:44+02:00",
        "summary": "Add some nested type tests and fix Map handling",
        "message": "Add some nested type tests and fix Map handling\n\n- Add nested type unit tests to hive-parquet schema converter\n- Add map and list to the serde unit test\n",
        "diff": {
            "parquet-hive/src/main/java/parquet/hive/DeprecatedParquetInputFormat.java": [
                1,
                1
            ],
            "parquet-hive/src/main/java/parquet/hive/convert/ArrayWritableGroupConverter.java": [
                7,
                22
            ],
            "parquet-hive/src/main/java/parquet/hive/serde/ParquetHiveMapInspector.java": [
                3,
                6
            ],
            "parquet-hive/src/test/java/parquet/hive/TestDeprecatedParquetInputFormat.java": [
                6,
                1
            ],
            "parquet-hive/src/test/java/parquet/hive/TestDeprecatedParquetOuputFormat.java": [
                9,
                10
            ],
            "parquet-hive/src/test/java/parquet/hive/TestHiveSchemaConverter.java": [
                9,
                47
            ],
            "parquet-hive/src/test/java/parquet/hive/TestParquetSerDe.java": [
                21,
                55
            ],
            "parquet-hive/src/test/java/parquet/hive/UtilitiesTestMethods.java": [
                3,
                3
            ]
        }
    },
    "8cc147b37b85f22cd6a79d5d8508a1b34e91d679": {
        "datetime": "2013-08-22T10:56:52+02:00",
        "summary": "Add map and list to in/outputformat unit tests",
        "message": "Add map and list to in/outputformat unit tests\n",
        "diff": {
            "parquet-hive/src/test/java/parquet/hive/TestDeprecatedParquetInputFormat.java": [
                7,
                44
            ],
            "parquet-hive/src/test/java/parquet/hive/TestDeprecatedParquetOuputFormat.java": [
                6,
                27
            ],
            "parquet-hive/src/test/java/parquet/hive/TestParquetSerDe.java": [
                27,
                1
            ],
            "parquet-hive/src/test/java/parquet/hive/UtilitiesTestMethods.java": [
                3,
                75
            ]
        }
    },
    "c76880d8d94a7666ab5456be370928e3500efa5c": {
        "datetime": "2013-08-22T11:37:58-07:00",
        "summary": "Merge pull request #146 from Parquet/hive_nested_types",
        "message": "Merge pull request #146 from Parquet/hive_nested_types\n\nFix and add unit tests for Hive nested types",
        "diff": {
            "parquet-hive/src/main/java/parquet/hive/DeprecatedParquetInputFormat.java": [
                1,
                1
            ],
            "parquet-hive/src/main/java/parquet/hive/convert/ArrayWritableGroupConverter.java": [
                7,
                22
            ],
            "parquet-hive/src/main/java/parquet/hive/serde/ParquetHiveMapInspector.java": [
                3,
                6
            ],
            "parquet-hive/src/test/java/parquet/hive/TestDeprecatedParquetInputFormat.java": [
                13,
                45
            ],
            "parquet-hive/src/test/java/parquet/hive/TestDeprecatedParquetOuputFormat.java": [
                15,
                37
            ],
            "parquet-hive/src/test/java/parquet/hive/TestHiveSchemaConverter.java": [
                9,
                47
            ],
            "parquet-hive/src/test/java/parquet/hive/TestParquetSerDe.java": [
                21,
                29
            ],
            "parquet-hive/src/test/java/parquet/hive/UtilitiesTestMethods.java": [
                5,
                77
            ]
        }
    },
    "808a90d9a11a3f17caf3dcdbd461d5b6bfda15e7": {
        "datetime": "2013-08-25T12:59:58-07:00",
        "summary": "changing default block size to 128mb",
        "message": "changing default block size to 128mb\n",
        "diff": {
            "README.md": null,
            "parquet-hadoop/src/main/java/parquet/hadoop/ParquetOutputFormat.java": [
                1,
                1
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/ParquetWriter.java": [
                1,
                1
            ]
        }
    },
    "4202efbe7bf5373539f18a8b7c08ebefeda7f755": {
        "datetime": "2013-08-25T14:30:10-07:00",
        "summary": "Merge pull request #149 from aniket486/change_block_size",
        "message": "Merge pull request #149 from aniket486/change_block_size\n\nchanging default block size to 128mb",
        "diff": {
            "README.md": null,
            "parquet-hadoop/src/main/java/parquet/hadoop/ParquetOutputFormat.java": [
                1,
                1
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/ParquetWriter.java": [
                1,
                1
            ]
        }
    },
    "aab7b4b672915fd587bf47640b3a82873ef7aef9": {
        "datetime": "2013-08-26T16:08:23-07:00",
        "summary": "code review comments for stats",
        "message": "code review comments for stats\n",
        "diff": {
            "parquet-pig/src/main/java/parquet/pig/ParquetLoader.java": [
                8,
                9
            ]
        }
    },
    "4b4fb0e59ad2d804d8e0344a7ef695aeb2c9a175": {
        "datetime": "2013-08-26T16:26:29-07:00",
        "summary": "Merge pull request #145 from aniket486/stats_loader",
        "message": "Merge pull request #145 from aniket486/stats_loader\n\nadd getStatistics method to parquetloader",
        "diff": {
            "parquet-pig/src/main/java/parquet/pig/ParquetLoader.java": [
                4,
                17
            ]
        }
    },
    "bee8378a90bee9657526cd872c9173309b0bafc2": {
        "datetime": "2013-08-26T16:40:59-07:00",
        "summary": "[maven-release-plugin] prepare release parquet-1.1.0",
        "message": "[maven-release-plugin] prepare release parquet-1.1.0\n",
        "diff": {
            "parquet-avro/pom.xml": null,
            "parquet-cascading/pom.xml": null,
            "parquet-column/pom.xml": null,
            "parquet-common/pom.xml": null,
            "parquet-encoding/pom.xml": null,
            "parquet-generator/pom.xml": null,
            "parquet-hadoop/pom.xml": null,
            "parquet-hive/pom.xml": null,
            "parquet-pig/pom.xml": null,
            "parquet-scrooge/pom.xml": null,
            "parquet-test-hadoop2/pom.xml": null,
            "parquet-thrift/pom.xml": null,
            "pom.xml": null
        }
    },
    "62cc2c291c88e4385071cbb943f24ff6c68a611b": {
        "datetime": "2013-08-26T16:41:03-07:00",
        "summary": "[maven-release-plugin] prepare for next development iteration",
        "message": "[maven-release-plugin] prepare for next development iteration\n",
        "diff": {
            "parquet-avro/pom.xml": null,
            "parquet-cascading/pom.xml": null,
            "parquet-column/pom.xml": null,
            "parquet-common/pom.xml": null,
            "parquet-encoding/pom.xml": null,
            "parquet-generator/pom.xml": null,
            "parquet-hadoop/pom.xml": null,
            "parquet-hive/pom.xml": null,
            "parquet-pig/pom.xml": null,
            "parquet-scrooge/pom.xml": null,
            "parquet-test-hadoop2/pom.xml": null,
            "parquet-thrift/pom.xml": null,
            "pom.xml": null
        }
    },
    "bbae83da5eb41fb1dd97aff0852b10d386e4c6a7": {
        "datetime": "2013-08-27T11:48:28-07:00",
        "summary": "Create CHANGES.md",
        "message": "Create CHANGES.md",
        "diff": {
            "CHANGES.md": null
        }
    },
    "7b2ef26003ab455bb03a696ea6583bcf73c8a9ad": {
        "datetime": "2013-08-27T15:21:27-07:00",
        "summary": "add thrift validation on read",
        "message": "add thrift validation on read\n",
        "diff": {
            "parquet-thrift/src/main/java/parquet/hadoop/thrift/ThriftBytesWriteSupport.java": [
                7,
                9
            ],
            "parquet-thrift/src/main/java/parquet/thrift/BufferedProtocolReadToWrite.java": [
                17,
                35
            ],
            "parquet-thrift/src/main/java/parquet/thrift/struct/ThriftType.java": [
                1,
                19
            ],
            "parquet-thrift/src/main/java/parquet/thrift/struct/ThriftTypeID.java": [
                3,
                17
            ],
            "parquet-thrift/src/test/java/parquet/hadoop/thrift/TestThriftToParquetFileWriter.java": [
                17,
                9
            ],
            "parquet-thrift/src/test/java/parquet/thrift/TestProtocolReadToWrite.java": [
                1,
                1
            ]
        }
    },
    "8a8354b73f61e1aad5a04ced61be5d7fcb26caf5": {
        "datetime": "2013-08-27T21:23:25-07:00",
        "summary": "add better error message",
        "message": "add better error message\n",
        "diff": {
            "parquet-thrift/src/main/java/parquet/thrift/BufferedProtocolReadToWrite.java": [
                3,
                87
            ]
        }
    },
    "71a6d880fb98903240b4bf996ac9d51f9c11a663": {
        "datetime": "2013-08-27T22:20:15-07:00",
        "summary": "add better error message",
        "message": "add better error message\n",
        "diff": {
            "parquet-thrift/src/main/java/parquet/thrift/BufferedProtocolReadToWrite.java": [
                1,
                5
            ]
        }
    },
    "c8ba085bffbe0a4a9f56fdd249e0b5945cf4c832": {
        "datetime": "2013-08-27T23:16:05-07:00",
        "summary": "Merge pull request #150 from Parquet/add_thrift_validation",
        "message": "Merge pull request #150 from Parquet/add_thrift_validation\n\nadd thrift validation on read",
        "diff": {
            "parquet-thrift/src/main/java/parquet/hadoop/thrift/ThriftBytesWriteSupport.java": [
                7,
                9
            ],
            "parquet-thrift/src/main/java/parquet/thrift/BufferedProtocolReadToWrite.java": [
                23,
                129
            ],
            "parquet-thrift/src/main/java/parquet/thrift/struct/ThriftType.java": [
                1,
                19
            ],
            "parquet-thrift/src/main/java/parquet/thrift/struct/ThriftTypeID.java": [
                3,
                17
            ],
            "parquet-thrift/src/test/java/parquet/hadoop/thrift/TestThriftToParquetFileWriter.java": [
                17,
                9
            ],
            "parquet-thrift/src/test/java/parquet/thrift/TestProtocolReadToWrite.java": [
                1,
                1
            ]
        }
    },
    "945d1bd5a91a873dbe63c7d6cd720bc680aeae73": {
        "datetime": "2013-08-27T23:33:55-07:00",
        "summary": "[maven-release-plugin] prepare release parquet-1.1.1",
        "message": "[maven-release-plugin] prepare release parquet-1.1.1\n",
        "diff": {
            "parquet-avro/pom.xml": null,
            "parquet-cascading/pom.xml": null,
            "parquet-column/pom.xml": null,
            "parquet-common/pom.xml": null,
            "parquet-encoding/pom.xml": null,
            "parquet-generator/pom.xml": null,
            "parquet-hadoop/pom.xml": null,
            "parquet-hive/pom.xml": null,
            "parquet-pig/pom.xml": null,
            "parquet-scrooge/pom.xml": null,
            "parquet-test-hadoop2/pom.xml": null,
            "parquet-thrift/pom.xml": null,
            "pom.xml": null
        }
    },
    "0784dc9c555147cdb3673fce2fefa6f5d9bd25dd": {
        "datetime": "2013-08-27T23:34:01-07:00",
        "summary": "[maven-release-plugin] prepare for next development iteration",
        "message": "[maven-release-plugin] prepare for next development iteration\n",
        "diff": {
            "parquet-avro/pom.xml": null,
            "parquet-cascading/pom.xml": null,
            "parquet-column/pom.xml": null,
            "parquet-common/pom.xml": null,
            "parquet-encoding/pom.xml": null,
            "parquet-generator/pom.xml": null,
            "parquet-hadoop/pom.xml": null,
            "parquet-hive/pom.xml": null,
            "parquet-pig/pom.xml": null,
            "parquet-scrooge/pom.xml": null,
            "parquet-test-hadoop2/pom.xml": null,
            "parquet-thrift/pom.xml": null,
            "pom.xml": null
        }
    },
    "91c17112f18ecae914c7f670439a81dcd4041456": {
        "datetime": "2013-08-28T10:51:19-07:00",
        "summary": "fix projection on required fields and refactored unit tests for column IO",
        "message": "fix projection on required fields and refactored unit tests for column IO\n",
        "diff": {
            "parquet-column/src/main/java/parquet/io/ColumnIOFactory.java": [
                4,
                0
            ],
            "parquet-column/src/test/java/parquet/io/TestColumnIO.java": [
                57,
                77
            ],
            "parquet-hadoop/src/test/java/parquet/hadoop/example/TestInputOutputFormat.java": [
                4,
                26
            ]
        }
    },
    "69ef1f447b4fbebcc528eab9cb782272eff9cb30": {
        "datetime": "2013-08-28T10:52:27-07:00",
        "summary": "fix file path",
        "message": "fix file path\n",
        "diff": {
            "parquet-hadoop/src/test/java/parquet/hadoop/example/TestInputOutputFormat.java": [
                1,
                1
            ]
        }
    },
    "413418e36a517f7c811ea6eebe8fffa743cf2fe6": {
        "datetime": "2013-08-28T15:08:37-07:00",
        "summary": "added release 1.1.1",
        "message": "added release 1.1.1",
        "diff": {
            "CHANGES.md": null
        }
    },
    "c023d63eaf92b4a9f35c134c81f0fee31de1f6d0": {
        "datetime": "2013-08-28T17:31:49-07:00",
        "summary": "improve thrift error message",
        "message": "improve thrift error message\n",
        "diff": {
            "parquet-thrift/src/main/java/parquet/thrift/BufferedProtocolReadToWrite.java": [
                5,
                14
            ],
            "parquet-thrift/src/test/java/parquet/thrift/TestProtocolReadToWrite.java": [
                6,
                24
            ]
        }
    },
    "bde6493d920178d1966c11d7ae5a97e4413d9feb": {
        "datetime": "2013-08-29T10:46:51-07:00",
        "summary": "Merge pull request #153 from Parquet/fix_projection_required_field",
        "message": "Merge pull request #153 from Parquet/fix_projection_required_field\n\nFix projection required field",
        "diff": {
            "parquet-column/src/main/java/parquet/io/ColumnIOFactory.java": [
                4,
                0
            ],
            "parquet-column/src/test/java/parquet/io/TestColumnIO.java": [
                57,
                77
            ],
            "parquet-hadoop/src/test/java/parquet/hadoop/example/TestInputOutputFormat.java": [
                3,
                25
            ]
        }
    },
    "ec4632917549fe10e4cc26c2d6b9064a9b06e5cd": {
        "datetime": "2013-08-29T15:26:55-07:00",
        "summary": "use globbing syntax to specify manual pushdown in ThriftReadSupport",
        "message": "use globbing syntax to specify manual pushdown in ThriftReadSupport\n",
        "diff": {
            "parquet-hadoop/src/main/java/parquet/hadoop/api/ReadSupport.java": [
                46,
                49
            ],
            "parquet-thrift/src/main/java/parquet/hadoop/thrift/ThriftReadSupport.java": [
                5,
                27
            ],
            "parquet-thrift/src/main/java/parquet/thrift/TBaseRecordConverter.java": [
                2,
                2
            ],
            "parquet-thrift/src/main/java/parquet/thrift/ThriftRecordConverter.java": [
                3,
                3
            ],
            "parquet-thrift/src/main/java/parquet/thrift/ThriftSchemaConverter.java": [
                42,
                97
            ],
            "parquet-thrift/src/main/java/parquet/thrift/projection/FieldProjectionFilter.java": [
                0,
                71
            ],
            "parquet-thrift/src/main/java/parquet/thrift/projection/PathGlobPattern.java": [
                0,
                161
            ],
            "parquet-thrift/src/main/java/parquet/thrift/projection/ThriftProjectionException.java": [
                0,
                30
            ],
            "parquet-thrift/src/test/java/parquet/hadoop/thrift/TestParquetToThriftReadProjection.java": [
                26,
                38
            ],
            "parquet-thrift/src/test/java/parquet/thrift/TestThriftSchemaConverter.java": [
                24,
                173
            ],
            "parquet-thrift/src/test/java/parquet/thrift/projection/PathGlobPatternTest.java": [
                0,
                39
            ]
        }
    },
    "17e251145f9e388de73b112694fb966a2d964ee7": {
        "datetime": "2013-08-29T15:27:03-07:00",
        "summary": "Merge branch 'master' of https://github.com/Parquet/parquet-mr into manual_pushdown_for_thrift_read_support",
        "message": "Merge branch 'master' of https://github.com/Parquet/parquet-mr into manual_pushdown_for_thrift_read_support\n",
        "diff": {
            "CHANGES.md": null,
            "parquet-avro/pom.xml": null,
            "parquet-cascading/pom.xml": null,
            "parquet-column/pom.xml": null,
            "parquet-common/pom.xml": null,
            "parquet-encoding/pom.xml": null,
            "parquet-generator/pom.xml": null,
            "parquet-hadoop/pom.xml": null,
            "parquet-hive/pom.xml": null,
            "parquet-pig/pom.xml": null,
            "parquet-scrooge/pom.xml": null,
            "parquet-test-hadoop2/pom.xml": null,
            "parquet-thrift/pom.xml": null,
            "parquet-thrift/src/main/java/parquet/hadoop/thrift/ThriftBytesWriteSupport.java": [
                7,
                9
            ],
            "parquet-thrift/src/main/java/parquet/thrift/BufferedProtocolReadToWrite.java": [
                23,
                129
            ],
            "parquet-thrift/src/main/java/parquet/thrift/struct/ThriftType.java": [
                1,
                19
            ],
            "parquet-thrift/src/main/java/parquet/thrift/struct/ThriftTypeID.java": [
                3,
                17
            ],
            "parquet-thrift/src/test/java/parquet/hadoop/thrift/TestThriftToParquetFileWriter.java": [
                17,
                9
            ],
            "parquet-thrift/src/test/java/parquet/thrift/TestProtocolReadToWrite.java": [
                1,
                1
            ],
            "pom.xml": null
        }
    },
    "30359b46fd6873defd71d5d3a224cb8675b67339": {
        "datetime": "2013-08-29T16:19:24-07:00",
        "summary": "remove TODOs and fix format",
        "message": "remove TODOs and fix format\n",
        "diff": {
            "parquet-thrift/src/main/java/parquet/hadoop/thrift/ThriftReadSupport.java": [
                1,
                5
            ],
            "parquet-thrift/src/main/java/parquet/thrift/ThriftSchemaConverter.java": [
                11,
                7
            ],
            "parquet-thrift/src/test/java/parquet/hadoop/thrift/TestParquetToThriftReadProjection.java": [
                4,
                1
            ]
        }
    },
    "3553c0255f86c5e303c200415e96d15d6ac4677e": {
        "datetime": "2013-08-30T10:37:11-07:00",
        "summary": "add site target to update-github-site profile",
        "message": "add site target to update-github-site profile\n",
        "diff": {
            "pom.xml": null
        }
    },
    "874e4702731ffc4f256268dee8b7bd999fb9e313": {
        "datetime": "2013-08-30T10:41:48-07:00",
        "summary": "indent fix, remove tabs",
        "message": "indent fix, remove tabs\n",
        "diff": {
            "pom.xml": null
        }
    },
    "57b1e0faa736477a0d7dac3c28f3342caed61f6a": {
        "datetime": "2013-08-30T12:07:05-07:00",
        "summary": "Merge pull request #156 from Parquet/fix_site",
        "message": "Merge pull request #156 from Parquet/fix_site\n\nFix site",
        "diff": {
            "pom.xml": null
        }
    },
    "459a8a193f8a61e92f6fbc5dbc079b194f25ae3c": {
        "datetime": "2013-09-04T12:02:30-07:00",
        "summary": "make counter works in DeprecatedInputFormat, which is used by cascading",
        "message": "make counter works in DeprecatedInputFormat, which is used by cascading\n",
        "diff": {
            "parquet-hadoop/src/main/java/parquet/hadoop/InternalParquetRecordReader.java": [
                1,
                1
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/ParquetFileReader.java": [
                1,
                1
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/ParquetRecordReader.java": [
                4,
                13
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/mapred/DeprecatedParquetInputFormat.java": [
                1,
                1
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/util/BenchmarkCounter.java": [
                53,
                0
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/util/counters/BenchmarkCounter.java": [
                0,
                112
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/util/counters/CounterLoader.java": [
                0,
                25
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/util/counters/ICounter.java": [
                0,
                11
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/util/counters/mapred/MapRedCounterAdapter.java": [
                0,
                41
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/util/counters/mapred/MapRedCounterLoader.java": [
                0,
                46
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/util/counters/mapreduce/MapReduceCounterAdapter.java": [
                0,
                42
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/util/counters/mapreduce/MapReduceCounterLoader.java": [
                0,
                44
            ],
            "parquet-hadoop/src/test/java/parquet/hadoop/DeprecatedInputFormatTest.java": [
                0,
                179
            ]
        }
    },
    "d20e5f2c01cd770babbca030f9bec5b2549c78b2": {
        "datetime": "2013-09-04T14:03:28-07:00",
        "summary": "fix tests",
        "message": "fix tests\n",
        "diff": {
            "parquet-hadoop/src/main/java/parquet/hadoop/ParquetRecordReader.java": [
                1,
                4
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/util/counters/BenchmarkCounter.java": [
                1,
                0
            ],
            "parquet-hadoop/src/test/java/parquet/hadoop/DeprecatedInputFormatTest.java": [
                1,
                1
            ],
            "parquet-hadoop/src/test/java/parquet/hadoop/example/TestInputOutputFormat.java": [
                1,
                1
            ]
        }
    },
    "00065cd7c76df68e0c85476880476f44e5e5e36c": {
        "datetime": "2013-09-04T15:03:35-07:00",
        "summary": "change filter key name to parquet.thrift.column.filter, remove extra filter parameter from ThriftSchemaConverter",
        "message": "change filter key name to parquet.thrift.column.filter, remove extra filter parameter from ThriftSchemaConverter\n",
        "diff": {
            "parquet-thrift/src/main/java/parquet/hadoop/thrift/ThriftReadSupport.java": [
                3,
                3
            ],
            "parquet-thrift/src/main/java/parquet/thrift/ThriftSchemaConverter.java": [
                9,
                9
            ],
            "parquet-thrift/src/test/java/parquet/hadoop/thrift/TestParquetToThriftReadProjection.java": [
                1,
                1
            ]
        }
    },
    "bb06859085679798bca20b8c54f20f2e9e006082": {
        "datetime": "2013-09-04T15:20:52-07:00",
        "summary": "add license and comment",
        "message": "add license and comment\n",
        "diff": {
            "parquet-thrift/src/main/java/parquet/thrift/projection/ThriftProjectionException.java": [
                0,
                16
            ],
            "parquet-thrift/src/test/java/parquet/thrift/projection/PathGlobPatternTest.java": [
                1,
                19
            ]
        }
    },
    "e371fbb247bdfe462e3b7ad2fd0fb4b788e23ce4": {
        "datetime": "2013-09-04T15:49:25-07:00",
        "summary": "add comment",
        "message": "add comment\n",
        "diff": {
            "parquet-hadoop/src/main/java/parquet/hadoop/util/counters/BenchmarkCounter.java": [
                1,
                1
            ]
        }
    },
    "6dfd97551fc1b8606704dcf656b185b34ceffcd4": {
        "datetime": "2013-09-04T16:52:39-07:00",
        "summary": "Merge pull request #159 from Parquet/counter_for_mapred",
        "message": "Merge pull request #159 from Parquet/counter_for_mapred\n\nCounter for mapred",
        "diff": {
            "parquet-hadoop/src/main/java/parquet/hadoop/InternalParquetRecordReader.java": [
                1,
                1
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/ParquetFileReader.java": [
                1,
                1
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/ParquetRecordReader.java": [
                4,
                16
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/mapred/DeprecatedParquetInputFormat.java": [
                1,
                1
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/util/BenchmarkCounter.java": [
                53,
                0
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/util/counters/BenchmarkCounter.java": [
                0,
                111
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/util/counters/CounterLoader.java": [
                0,
                25
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/util/counters/ICounter.java": [
                0,
                11
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/util/counters/mapred/MapRedCounterAdapter.java": [
                0,
                41
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/util/counters/mapred/MapRedCounterLoader.java": [
                0,
                46
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/util/counters/mapreduce/MapReduceCounterAdapter.java": [
                0,
                42
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/util/counters/mapreduce/MapReduceCounterLoader.java": [
                0,
                44
            ],
            "parquet-hadoop/src/test/java/parquet/hadoop/DeprecatedInputFormatTest.java": [
                0,
                179
            ],
            "parquet-hadoop/src/test/java/parquet/hadoop/example/TestInputOutputFormat.java": [
                1,
                1
            ]
        }
    },
    "6b96924e855e8b74a43c0170185cafd4a81d4df8": {
        "datetime": "2013-09-04T16:53:35-07:00",
        "summary": "Merge pull request #155 from Parquet/manual_pushdown_for_thrift_read_support",
        "message": "Merge pull request #155 from Parquet/manual_pushdown_for_thrift_read_support\n\nManual pushdown for thrift read support",
        "diff": {
            "parquet-hadoop/src/main/java/parquet/hadoop/api/ReadSupport.java": [
                46,
                49
            ],
            "parquet-thrift/src/main/java/parquet/hadoop/thrift/ThriftReadSupport.java": [
                5,
                31
            ],
            "parquet-thrift/src/main/java/parquet/thrift/TBaseRecordConverter.java": [
                2,
                2
            ],
            "parquet-thrift/src/main/java/parquet/thrift/ThriftRecordConverter.java": [
                3,
                3
            ],
            "parquet-thrift/src/main/java/parquet/thrift/ThriftSchemaConverter.java": [
                42,
                93
            ],
            "parquet-thrift/src/main/java/parquet/thrift/projection/FieldProjectionFilter.java": [
                0,
                71
            ],
            "parquet-thrift/src/main/java/parquet/thrift/projection/PathGlobPattern.java": [
                0,
                161
            ],
            "parquet-thrift/src/main/java/parquet/thrift/projection/ThriftProjectionException.java": [
                0,
                46
            ],
            "parquet-thrift/src/test/java/parquet/hadoop/thrift/TestParquetToThriftReadProjection.java": [
                28,
                37
            ],
            "parquet-thrift/src/test/java/parquet/thrift/TestThriftSchemaConverter.java": [
                24,
                173
            ],
            "parquet-thrift/src/test/java/parquet/thrift/projection/PathGlobPatternTest.java": [
                0,
                57
            ]
        }
    },
    "b045ac18d613e226bf14ff9e3e1b6a0f93c26bae": {
        "datetime": "2013-09-04T17:30:48-07:00",
        "summary": "Resource leak in parquet.hadoop.ParquetFileReader.readFooter(Configuration, FileStatus)",
        "message": "Resource leak in parquet.hadoop.ParquetFileReader.readFooter(Configuration, FileStatus)\n",
        "diff": {
            "parquet-hadoop/src/main/java/parquet/hadoop/ParquetFileReader.java": [
                23,
                26
            ]
        }
    },
    "848fa8e1cca99ddf38b6f9827ffa73fefcdc1929": {
        "datetime": "2013-09-05T15:41:57-07:00",
        "summary": "support schema evolution",
        "message": "support schema evolution\n",
        "diff": {
            "parquet-column/src/main/java/parquet/schema/GroupType.java": [
                0,
                33
            ],
            "parquet-column/src/main/java/parquet/schema/IncompatibleSchemaModificationException.java": [
                0,
                31
            ],
            "parquet-column/src/main/java/parquet/schema/MessageType.java": [
                0,
                5
            ],
            "parquet-column/src/main/java/parquet/schema/PrimitiveType.java": [
                0,
                8
            ],
            "parquet-column/src/main/java/parquet/schema/Type.java": [
                1,
                4
            ],
            "parquet-column/src/test/java/parquet/schema/TestMessageType.java": [
                2,
                66
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/ParquetFileWriter.java": [
                27,
                50
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/ParquetInputFormat.java": [
                15,
                9
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/ParquetReader.java": [
                14,
                47
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/api/InitContext.java": [
                0,
                57
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/api/ReadSupport.java": [
                2,
                12
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/metadata/FileMetaData.java": [
                1,
                2
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/metadata/GlobalMetaData.java": [
                0,
                79
            ],
            "parquet-hadoop/src/test/java/parquet/hadoop/TestParquetFileWriter.java": [
                0,
                19
            ],
            "parquet-pig/src/main/java/parquet/pig/ParquetLoader.java": [
                33,
                25
            ],
            "parquet-pig/src/main/java/parquet/pig/PigMetaData.java": [
                2,
                8
            ],
            "parquet-pig/src/main/java/parquet/pig/PigSchemaConverter.java": [
                4,
                19
            ],
            "parquet-pig/src/main/java/parquet/pig/TupleReadSupport.java": [
                26,
                71
            ],
            "parquet-pig/src/test/java/parquet/pig/TestParquetLoader.java": [
                6,
                6
            ],
            "parquet-pig/src/test/java/parquet/pig/TestParquetStorer.java": [
                1,
                63
            ],
            "parquet-pig/src/test/java/parquet/pig/TestTupleRecordConsumer.java": [
                1,
                13
            ]
        }
    },
    "c32be9e4ef2169be9267dc4ef17c0b7f06db4927": {
        "datetime": "2013-09-05T16:51:18-07:00",
        "summary": "thrift schema evolution support",
        "message": "thrift schema evolution support\n",
        "diff": {
            "parquet-column/src/main/java/parquet/schema/GroupType.java": [
                0,
                4
            ],
            "parquet-column/src/main/java/parquet/schema/MessageType.java": [
                1,
                1
            ],
            "parquet-thrift/src/main/java/parquet/hadoop/thrift/ThriftReadSupport.java": [
                11,
                34
            ],
            "parquet-thrift/src/main/java/parquet/thrift/ThriftMetaData.java": [
                8,
                23
            ],
            "parquet-thrift/src/main/java/parquet/thrift/ThriftRecordConverter.java": [
                1,
                4
            ],
            "parquet-thrift/src/test/java/parquet/hadoop/thrift/TestInputOutputFormat.java": [
                0,
                97
            ],
            "parquet-thrift/src/test/thrift/compat.thrift": null
        }
    },
    "f369a13e0500604a7cd7276e6290fbae70ecb08c": {
        "datetime": "2013-09-05T17:02:51-07:00",
        "summary": "validate output",
        "message": "validate output\n",
        "diff": {
            "parquet-thrift/src/test/java/parquet/hadoop/thrift/TestInputOutputFormat.java": [
                5,
                16
            ]
        }
    },
    "f0d30dfb2274ef430d805d900f53ba8252f496ad": {
        "datetime": "2013-09-06T09:34:32-07:00",
        "summary": "refactor schema converter",
        "message": "refactor schema converter\n",
        "diff": {
            "parquet-thrift/src/main/java/parquet/thrift/ThriftSchemaConverter.java": [
                80,
                102
            ],
            "parquet-thrift/src/main/java/parquet/thrift/projection/FieldProjectionFilter.java": [
                9,
                3
            ],
            "parquet-thrift/src/main/java/parquet/thrift/projection/FieldsPath.java": [
                0,
                73
            ]
        }
    },
    "8faaaf087ceb7c3827e1e4d0c4ff7eefd9935ed0": {
        "datetime": "2013-09-06T11:12:55-07:00",
        "summary": "support projection on only key of a map",
        "message": "support projection on only key of a map\n",
        "diff": {
            "parquet-column/src/main/java/parquet/schema/ConversionPatterns.java": [
                0,
                14
            ],
            "parquet-thrift/src/main/java/parquet/thrift/ThriftSchemaConverter.java": [
                3,
                0
            ],
            "parquet-thrift/src/test/java/parquet/thrift/TestThriftSchemaConverter.java": [
                2,
                9
            ]
        }
    },
    "2043741be98735aeea75c2f6eb04c78220811c0a": {
        "datetime": "2013-09-06T11:27:25-07:00",
        "summary": "add thrift idl for testing",
        "message": "add thrift idl for testing\n",
        "diff": {
            "parquet-thrift/src/test/thrift/test.thrift": null
        }
    },
    "7f08eeed1ee16d2bec0b1caa7eee8cd664f3675b": {
        "datetime": "2013-09-06T11:56:41-07:00",
        "summary": "add license headers",
        "message": "add license headers\n",
        "diff": {
            "parquet-cascading/src/test/java/parquet/cascading/TestParquetTBaseScheme.java": [
                0,
                15
            ],
            "parquet-cascading/src/test/java/parquet/cascading/TestParquetTupleScheme.java": [
                0,
                15
            ],
            "parquet-column/src/main/java/parquet/column/values/dictionary/PlainValuesDictionary.java": [
                1,
                2
            ],
            "parquet-column/src/main/java/parquet/schema/IncompatibleSchemaModificationException.java": [
                0,
                15
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/api/InitContext.java": [
                0,
                15
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/codec/NonBlockedCompressorStream.java": [
                0,
                15
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/codec/NonBlockedDecompressorStream.java": [
                0,
                15
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/metadata/GlobalMetaData.java": [
                0,
                15
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/util/counters/ICounter.java": [
                0,
                15
            ],
            "parquet-hadoop/src/test/java/parquet/hadoop/example/GroupReadSupportTest.java": [
                0,
                15
            ]
        }
    },
    "1a711f05d5ba1f8579efeac5b0652b3efecf27d4": {
        "datetime": "2013-09-06T15:40:35-07:00",
        "summary": "turn off projection from scrooge",
        "message": "turn off projection from scrooge\n",
        "diff": {
            "parquet-thrift/src/main/java/parquet/hadoop/thrift/ThriftReadSupport.java": [
                3,
                11
            ]
        }
    },
    "eb156658b9514548a005561b0c4d3642be3034fa": {
        "datetime": "2013-09-06T16:33:21-07:00",
        "summary": "Add test cases for reading/writing Avro records with empty arrays and maps.",
        "message": "Add test cases for reading/writing Avro records with empty arrays and maps.\n",
        "diff": {
            "parquet-avro/src/test/java/parquet/avro/TestReadWrite.java": [
                0,
                55
            ],
            "parquet-avro/src/test/resources/array.avsc": null,
            "parquet-avro/src/test/resources/map.avsc": null
        }
    },
    "50feb3363f202dabde35e749367e00348b3af3ee": {
        "datetime": "2013-09-06T16:33:51-07:00",
        "summary": "Fix tests for reading and writing Avro records with empty arrays and maps.",
        "message": "Fix tests for reading and writing Avro records with empty arrays and maps.\n",
        "diff": {
            "parquet-avro/src/test/java/parquet/avro/TestReadWrite.java": [
                6,
                6
            ]
        }
    },
    "0cedaf25e758c223ad54429c1e7bc991eb846c0a": {
        "datetime": "2013-09-06T17:51:59-07:00",
        "summary": "remove debugging code from hot path",
        "message": "remove debugging code from hot path\n",
        "diff": {
            "parquet-thrift/src/main/java/parquet/thrift/ParquetProtocol.java": [
                4,
                6
            ]
        }
    },
    "9594bba425ecd16e7a65021a4c5b0ec08921bd82": {
        "datetime": "2013-09-06T18:19:55-07:00",
        "summary": "address review comments",
        "message": "address review comments\n",
        "diff": {
            "parquet-column/src/main/java/parquet/schema/GroupType.java": [
                3,
                3
            ],
            "parquet-column/src/main/java/parquet/schema/Type.java": [
                0,
                4
            ],
            "parquet-column/src/test/java/parquet/schema/TestMessageType.java": [
                16,
                36
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/ParquetFileWriter.java": [
                1,
                18
            ],
            "parquet-hadoop/src/test/java/parquet/hadoop/TestParquetFileWriter.java": [
                3,
                13
            ],
            "parquet-pig/src/main/java/parquet/pig/TupleReadSupport.java": [
                1,
                2
            ]
        }
    },
    "6f25a0f2e68adc13d8c2caaf87a864bba8fd8be5": {
        "datetime": "2013-09-07T04:41:48-07:00",
        "summary": "Correctly handle Avro records with empty maps and arrays.",
        "message": "Correctly handle Avro records with empty maps and arrays.\n",
        "diff": {
            "parquet-avro/src/main/java/parquet/avro/AvroWriteSupport.java": [
                33,
                41
            ]
        }
    },
    "26d09f4b150c49d36d7933c92651689622828f7c": {
        "datetime": "2013-09-07T11:29:20-07:00",
        "summary": "javadoc",
        "message": "javadoc\n",
        "diff": {
            "parquet-column/src/main/java/parquet/schema/GroupType.java": [
                4,
                25
            ],
            "parquet-column/src/main/java/parquet/schema/PrimitiveType.java": [
                2,
                7
            ],
            "parquet-column/src/main/java/parquet/schema/Type.java": [
                3,
                54
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/ParquetFileWriter.java": [
                4,
                7
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/ParquetInputFormat.java": [
                0,
                24
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/ParquetReader.java": [
                0,
                15
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/api/InitContext.java": [
                0,
                12
            ]
        }
    },
    "8c51a420a73241036ed28563c6a0ec5f905d133d": {
        "datetime": "2013-09-07T11:34:16-07:00",
        "summary": "better error message",
        "message": "better error message\n",
        "diff": {
            "parquet-hadoop/src/main/java/parquet/hadoop/InternalParquetRecordReader.java": [
                1,
                4
            ]
        }
    },
    "8fa09f0f74af3834ddceae3d36b8f2f286085d6d": {
        "datetime": "2013-09-07T11:39:18-07:00",
        "summary": "Merge pull request #163 from Parquet/thrift_perf",
        "message": "Merge pull request #163 from Parquet/thrift_perf\n\nremove debugging code from hot path",
        "diff": {
            "parquet-thrift/src/main/java/parquet/thrift/ParquetProtocol.java": [
                4,
                6
            ]
        }
    },
    "80c3a2a7c3fb4c691cbd2b66a467b6383d175e88": {
        "datetime": "2013-09-07T11:42:03-07:00",
        "summary": "Merge branch 'master' into schema_evolution",
        "message": "Merge branch 'master' into schema_evolution\n",
        "diff": {
            "parquet-thrift/src/main/java/parquet/thrift/ParquetProtocol.java": [
                4,
                6
            ]
        }
    },
    "60a3468f8266eeca965c4dd3906afca7f3001300": {
        "datetime": "2013-09-07T12:19:39-07:00",
        "summary": "fix test",
        "message": "fix test\n",
        "diff": {
            "parquet-column/src/test/java/parquet/schema/TestMessageType.java": [
                1,
                1
            ]
        }
    },
    "cfc91fc79e13bd640dcb6b6605750c92d11ccb64": {
        "datetime": "2013-09-08T18:09:40-07:00",
        "summary": "almost there... now working on not to use thrift class, so it's compatible with scrooge",
        "message": "almost there... now working on not to use thrift class, so it's compatible with scrooge\n",
        "diff": {
            "parquet-hadoop/src/test/java/parquet/hadoop/example/TestInputOutputFormat.java": [
                1,
                1
            ],
            "parquet-thrift/src/main/java/parquet/hadoop/thrift/ThriftReadSupport.java": [
                5,
                3
            ],
            "parquet-thrift/src/main/java/parquet/thrift/ThriftSchemaConverter.java": [
                39,
                92
            ],
            "parquet-thrift/src/test/java/parquet/thrift/TestThriftSchemaConverter.java": [
                0,
                19
            ],
            "parquet-thrift/src/test/thrift/test.thrift": null
        }
    },
    "00a5d5b55eac3c869291a5f6359af97a880ddfd4": {
        "datetime": "2013-09-08T19:01:03-07:00",
        "summary": "migrated to using ThriftStruct for schemaConverter, do not use thriftClass",
        "message": "migrated to using ThriftStruct for schemaConverter, do not use thriftClass\n",
        "diff": {
            "parquet-thrift/src/main/java/parquet/hadoop/thrift/ThriftReadSupport.java": [
                1,
                1
            ],
            "parquet-thrift/src/main/java/parquet/thrift/ThriftSchemaConverter.java": [
                180,
                175
            ],
            "parquet-thrift/src/main/java/parquet/thrift/projection/FieldsPath.java": [
                11,
                20
            ],
            "parquet-thrift/src/test/java/parquet/thrift/TestThriftSchemaConverter.java": [
                29,
                30
            ]
        }
    },
    "7387a615dd3b9ae89a63e052f11e36e91244728e": {
        "datetime": "2013-09-08T19:21:58-07:00",
        "summary": "passed all test, fix map, removed tests for pull in required fields",
        "message": "passed all test, fix map, removed tests for pull in required fields\n",
        "diff": {
            "parquet-thrift/src/main/java/parquet/thrift/ThriftSchemaConverter.java": [
                8,
                15
            ],
            "parquet-thrift/src/test/java/parquet/thrift/TestThriftSchemaConverter.java": [
                21,
                21
            ]
        }
    },
    "147a3f023f68a321dad8fb55bc8b09d4f9b088ae": {
        "datetime": "2013-09-08T19:26:31-07:00",
        "summary": "start! do not check required field, failing test",
        "message": "start! do not check required field, failing test\n",
        "diff": {
            "parquet-thrift/src/main/java/parquet/thrift/ThriftSchemaConverter.java": [
                4,
                4
            ],
            "parquet-thrift/src/test/java/parquet/hadoop/thrift/TestParquetToThriftReadProjection.java": [
                1,
                1
            ]
        }
    },
    "55c14bf93275371dbd4f4c3368dce00389be25cc": {
        "datetime": "2013-09-09T08:27:00-07:00",
        "summary": "javadoc",
        "message": "javadoc\n",
        "diff": {
            "parquet-hadoop/src/main/java/parquet/hadoop/api/InitContext.java": [
                2,
                17
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/api/ReadSupport.java": [
                1,
                6
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/metadata/FileMetaData.java": [
                9,
                5
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/metadata/GlobalMetaData.java": [
                11,
                20
            ],
            "parquet-pig/src/main/java/parquet/pig/ParquetLoader.java": [
                7,
                11
            ],
            "parquet-pig/src/main/java/parquet/pig/PigMetaData.java": [
                0,
                29
            ],
            "parquet-pig/src/main/java/parquet/pig/PigSchemaConverter.java": [
                1,
                23
            ],
            "parquet-thrift/src/main/java/parquet/thrift/ThriftMetaData.java": [
                2,
                26
            ]
        }
    },
    "e5cb3c8fec0991942a12d3d97ef9e60329a5eba3": {
        "datetime": "2013-09-09T08:37:25-07:00",
        "summary": "fix test",
        "message": "fix test\n",
        "diff": {
            "parquet-thrift/src/test/java/parquet/thrift/TestProtocolReadToWrite.java": [
                1,
                1
            ]
        }
    },
    "e9f2550a40a51ff383283a88e1f8e847ad091d8c": {
        "datetime": "2013-09-09T15:29:10-07:00",
        "summary": "parameterize dictionary",
        "message": "parameterize dictionary\n",
        "diff": {
            "parquet-column/src/main/java/parquet/column/impl/ColumnWriteStoreImpl.java": [
                2,
                4
            ],
            "parquet-column/src/main/java/parquet/column/impl/ColumnWriterImpl.java": [
                20,
                17
            ],
            "parquet-column/src/main/java/parquet/column/values/dictionary/DictionaryValuesWriter.java": [
                14,
                14
            ],
            "parquet-column/src/test/java/parquet/column/mem/TestMemColumn.java": [
                4,
                8
            ],
            "parquet-column/src/test/java/parquet/column/values/dictionary/TestDictionary.java": [
                50,
                50
            ],
            "parquet-column/src/test/java/parquet/io/PerfTest.java": [
                1,
                1
            ],
            "parquet-column/src/test/java/parquet/io/TestColumnIO.java": [
                5,
                9
            ],
            "parquet-column/src/test/java/parquet/io/TestFiltered.java": [
                16,
                14
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/InternalParquetRecordWriter.java": [
                14,
                20
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/ParquetOutputFormat.java": [
                9,
                25
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/ParquetRecordWriter.java": [
                2,
                15
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/ParquetWriter.java": [
                4,
                39
            ],
            "parquet-thrift/src/test/java/parquet/thrift/TestParquetReadProtocol.java": [
                1,
                1
            ]
        }
    },
    "12d1ac423bc3ae4b8270c4732601262f5296c553": {
        "datetime": "2013-09-09T15:30:50-07:00",
        "summary": "fix noisy warning",
        "message": "fix noisy warning\n",
        "diff": {
            "parquet-hadoop/src/main/java/parquet/hadoop/ParquetInputFormat.java": [
                3,
                1
            ]
        }
    },
    "47116ad7ac86c001c2e68bca0e3f75f51488c462": {
        "datetime": "2013-09-09T15:55:18-07:00",
        "summary": "fix schema merging",
        "message": "fix schema merging\n",
        "diff": {
            "parquet-pig/src/main/java/parquet/pig/TupleReadSupport.java": [
                5,
                9
            ],
            "parquet-pig/src/test/java/parquet/pig/TestPigSchemaConverter.java": [
                8,
                30
            ]
        }
    },
    "d4dbf0b254c19d8af81fca680ed41f7df61fe8e2": {
        "datetime": "2013-09-09T16:22:56-07:00",
        "summary": "Merge pull request #160 from adityakishore/master",
        "message": "Merge pull request #160 from adityakishore/master\n\nResource leak in parquet.hadoop.ParquetFileReader.readFooter(Configurati...",
        "diff": {
            "parquet-hadoop/src/main/java/parquet/hadoop/ParquetFileReader.java": [
                23,
                26
            ]
        }
    },
    "05a01060ffd72fca1b96e7e342cdedecc4889987": {
        "datetime": "2013-09-09T17:04:41-07:00",
        "summary": "Merge pull request #161 from Parquet/schema_evolution",
        "message": "Merge pull request #161 from Parquet/schema_evolution\n\nsupport schema evolution",
        "diff": {
            "parquet-cascading/src/test/java/parquet/cascading/TestParquetTBaseScheme.java": [
                0,
                15
            ],
            "parquet-cascading/src/test/java/parquet/cascading/TestParquetTupleScheme.java": [
                0,
                15
            ],
            "parquet-column/src/main/java/parquet/column/values/dictionary/PlainValuesDictionary.java": [
                1,
                2
            ],
            "parquet-column/src/main/java/parquet/schema/GroupType.java": [
                4,
                62
            ],
            "parquet-column/src/main/java/parquet/schema/IncompatibleSchemaModificationException.java": [
                0,
                46
            ],
            "parquet-column/src/main/java/parquet/schema/MessageType.java": [
                1,
                6
            ],
            "parquet-column/src/main/java/parquet/schema/PrimitiveType.java": [
                2,
                15
            ],
            "parquet-column/src/main/java/parquet/schema/Type.java": [
                4,
                62
            ],
            "parquet-column/src/test/java/parquet/schema/TestMessageType.java": [
                2,
                86
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/InternalParquetRecordReader.java": [
                1,
                4
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/ParquetFileWriter.java": [
                27,
                70
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/ParquetInputFormat.java": [
                18,
                34
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/ParquetReader.java": [
                14,
                62
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/api/InitContext.java": [
                0,
                99
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/api/ReadSupport.java": [
                2,
                17
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/codec/NonBlockedCompressorStream.java": [
                0,
                15
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/codec/NonBlockedDecompressorStream.java": [
                0,
                15
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/metadata/FileMetaData.java": [
                8,
                5
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/metadata/GlobalMetaData.java": [
                0,
                103
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/util/counters/ICounter.java": [
                0,
                15
            ],
            "parquet-hadoop/src/test/java/parquet/hadoop/TestParquetFileWriter.java": [
                0,
                29
            ],
            "parquet-hadoop/src/test/java/parquet/hadoop/example/GroupReadSupportTest.java": [
                0,
                15
            ],
            "parquet-pig/src/main/java/parquet/pig/ParquetLoader.java": [
                37,
                33
            ],
            "parquet-pig/src/main/java/parquet/pig/PigMetaData.java": [
                5,
                40
            ],
            "parquet-pig/src/main/java/parquet/pig/PigSchemaConverter.java": [
                5,
                42
            ],
            "parquet-pig/src/main/java/parquet/pig/TupleReadSupport.java": [
                26,
                76
            ],
            "parquet-pig/src/test/java/parquet/pig/TestParquetLoader.java": [
                6,
                6
            ],
            "parquet-pig/src/test/java/parquet/pig/TestParquetStorer.java": [
                1,
                63
            ],
            "parquet-pig/src/test/java/parquet/pig/TestPigSchemaConverter.java": [
                8,
                30
            ],
            "parquet-pig/src/test/java/parquet/pig/TestTupleRecordConsumer.java": [
                1,
                13
            ],
            "parquet-thrift/src/main/java/parquet/hadoop/thrift/ThriftReadSupport.java": [
                13,
                44
            ],
            "parquet-thrift/src/main/java/parquet/thrift/ThriftMetaData.java": [
                10,
                49
            ],
            "parquet-thrift/src/main/java/parquet/thrift/ThriftRecordConverter.java": [
                1,
                4
            ],
            "parquet-thrift/src/test/java/parquet/hadoop/thrift/TestInputOutputFormat.java": [
                0,
                108
            ],
            "parquet-thrift/src/test/thrift/compat.thrift": null
        }
    },
    "5b36d9c5d89fac4b346ad0ee4fe49805c8d9b748": {
        "datetime": "2013-09-09T17:07:30-07:00",
        "summary": "make buffered by default",
        "message": "make buffered by default\n",
        "diff": {
            "parquet-thrift/src/main/java/parquet/hadoop/thrift/ThriftBytesWriteSupport.java": [
                1,
                1
            ]
        }
    },
    "2de256778d396bec5fe4fbe73a072f72a71f6642": {
        "datetime": "2013-09-09T17:32:35-07:00",
        "summary": "Merge pull request #154 from Parquet/add_thrift_validation",
        "message": "Merge pull request #154 from Parquet/add_thrift_validation\n\nimprove thrift error message",
        "diff": {
            "parquet-thrift/src/main/java/parquet/hadoop/thrift/ThriftBytesWriteSupport.java": [
                1,
                1
            ],
            "parquet-thrift/src/main/java/parquet/thrift/BufferedProtocolReadToWrite.java": [
                5,
                14
            ],
            "parquet-thrift/src/test/java/parquet/thrift/TestProtocolReadToWrite.java": [
                6,
                24
            ]
        }
    },
    "4170539b9a9bca97e4f3159113606855a41c3b0f": {
        "datetime": "2013-09-09T17:56:08-07:00",
        "summary": "[maven-release-plugin] prepare release parquet-1.2.0",
        "message": "[maven-release-plugin] prepare release parquet-1.2.0\n",
        "diff": {
            "parquet-avro/pom.xml": null,
            "parquet-cascading/pom.xml": null,
            "parquet-column/pom.xml": null,
            "parquet-common/pom.xml": null,
            "parquet-encoding/pom.xml": null,
            "parquet-generator/pom.xml": null,
            "parquet-hadoop/pom.xml": null,
            "parquet-hive/pom.xml": null,
            "parquet-pig/pom.xml": null,
            "parquet-scrooge/pom.xml": null,
            "parquet-test-hadoop2/pom.xml": null,
            "parquet-thrift/pom.xml": null,
            "pom.xml": null
        }
    },
    "c4515dbd1534bd4d74a4704e46a5a40b5970ff11": {
        "datetime": "2013-09-09T17:56:18-07:00",
        "summary": "[maven-release-plugin] prepare for next development iteration",
        "message": "[maven-release-plugin] prepare for next development iteration\n",
        "diff": {
            "parquet-avro/pom.xml": null,
            "parquet-cascading/pom.xml": null,
            "parquet-column/pom.xml": null,
            "parquet-common/pom.xml": null,
            "parquet-encoding/pom.xml": null,
            "parquet-generator/pom.xml": null,
            "parquet-hadoop/pom.xml": null,
            "parquet-hive/pom.xml": null,
            "parquet-pig/pom.xml": null,
            "parquet-scrooge/pom.xml": null,
            "parquet-test-hadoop2/pom.xml": null,
            "parquet-thrift/pom.xml": null,
            "pom.xml": null
        }
    },
    "b3efce20048307c7b7dd6aec2dcb08529c62320f": {
        "datetime": "2013-09-09T18:09:47-07:00",
        "summary": "fix compilation problems",
        "message": "fix compilation problems\n",
        "diff": {
            "parquet-column/src/test/java/parquet/column/values/dictionary/TestDictionary.java": [
                1,
                1
            ],
            "parquet-hive/src/test/java/parquet/hive/TestDeprecatedParquetInputFormat.java": [
                1,
                1
            ],
            "parquet-pig/src/test/java/parquet/pig/GenerateIntTestFile.java": [
                1,
                1
            ],
            "parquet-pig/src/test/java/parquet/pig/GenerateTPCH.java": [
                1,
                1
            ],
            "parquet-pig/src/test/java/parquet/pig/TupleConsumerPerfTest.java": [
                1,
                1
            ]
        }
    },
    "3c274d179ac08da51e89b0db5aecd80928031041": {
        "datetime": "2013-09-09T18:21:24-07:00",
        "summary": "Merge branch 'master' into fix_avro_empty_maps_arrays",
        "message": "Merge branch 'master' into fix_avro_empty_maps_arrays\n",
        "diff": {
            "parquet-avro/pom.xml": null,
            "parquet-cascading/pom.xml": null,
            "parquet-cascading/src/test/java/parquet/cascading/TestParquetTBaseScheme.java": [
                0,
                15
            ],
            "parquet-cascading/src/test/java/parquet/cascading/TestParquetTupleScheme.java": [
                0,
                15
            ],
            "parquet-column/pom.xml": null,
            "parquet-column/src/main/java/parquet/column/values/dictionary/PlainValuesDictionary.java": [
                1,
                2
            ],
            "parquet-column/src/main/java/parquet/schema/GroupType.java": [
                4,
                62
            ],
            "parquet-column/src/main/java/parquet/schema/IncompatibleSchemaModificationException.java": [
                0,
                46
            ],
            "parquet-column/src/main/java/parquet/schema/MessageType.java": [
                1,
                6
            ],
            "parquet-column/src/main/java/parquet/schema/PrimitiveType.java": [
                2,
                15
            ],
            "parquet-column/src/main/java/parquet/schema/Type.java": [
                4,
                62
            ],
            "parquet-column/src/test/java/parquet/schema/TestMessageType.java": [
                2,
                86
            ],
            "parquet-common/pom.xml": null,
            "parquet-encoding/pom.xml": null,
            "parquet-generator/pom.xml": null,
            "parquet-hadoop/pom.xml": null,
            "parquet-hadoop/src/main/java/parquet/hadoop/InternalParquetRecordReader.java": [
                1,
                4
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/ParquetFileReader.java": [
                23,
                26
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/ParquetFileWriter.java": [
                27,
                70
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/ParquetInputFormat.java": [
                18,
                34
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/ParquetReader.java": [
                14,
                62
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/api/InitContext.java": [
                0,
                99
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/api/ReadSupport.java": [
                2,
                17
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/codec/NonBlockedCompressorStream.java": [
                0,
                15
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/codec/NonBlockedDecompressorStream.java": [
                0,
                15
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/metadata/FileMetaData.java": [
                8,
                5
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/metadata/GlobalMetaData.java": [
                0,
                103
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/util/counters/ICounter.java": [
                0,
                15
            ],
            "parquet-hadoop/src/test/java/parquet/hadoop/TestParquetFileWriter.java": [
                0,
                29
            ],
            "parquet-hadoop/src/test/java/parquet/hadoop/example/GroupReadSupportTest.java": [
                0,
                15
            ],
            "parquet-hive/pom.xml": null,
            "parquet-pig/pom.xml": null,
            "parquet-pig/src/main/java/parquet/pig/ParquetLoader.java": [
                37,
                33
            ],
            "parquet-pig/src/main/java/parquet/pig/PigMetaData.java": [
                5,
                40
            ],
            "parquet-pig/src/main/java/parquet/pig/PigSchemaConverter.java": [
                5,
                42
            ],
            "parquet-pig/src/main/java/parquet/pig/TupleReadSupport.java": [
                26,
                76
            ],
            "parquet-pig/src/test/java/parquet/pig/TestParquetLoader.java": [
                6,
                6
            ],
            "parquet-pig/src/test/java/parquet/pig/TestParquetStorer.java": [
                1,
                63
            ],
            "parquet-pig/src/test/java/parquet/pig/TestPigSchemaConverter.java": [
                8,
                30
            ],
            "parquet-pig/src/test/java/parquet/pig/TestTupleRecordConsumer.java": [
                1,
                13
            ],
            "parquet-scrooge/pom.xml": null,
            "parquet-test-hadoop2/pom.xml": null,
            "parquet-thrift/pom.xml": null,
            "parquet-thrift/src/main/java/parquet/hadoop/thrift/ThriftBytesWriteSupport.java": [
                1,
                1
            ],
            "parquet-thrift/src/main/java/parquet/hadoop/thrift/ThriftReadSupport.java": [
                13,
                44
            ],
            "parquet-thrift/src/main/java/parquet/thrift/BufferedProtocolReadToWrite.java": [
                5,
                14
            ],
            "parquet-thrift/src/main/java/parquet/thrift/ParquetProtocol.java": [
                4,
                6
            ],
            "parquet-thrift/src/main/java/parquet/thrift/ThriftMetaData.java": [
                10,
                49
            ],
            "parquet-thrift/src/main/java/parquet/thrift/ThriftRecordConverter.java": [
                1,
                4
            ],
            "parquet-thrift/src/test/java/parquet/hadoop/thrift/TestInputOutputFormat.java": [
                0,
                108
            ],
            "parquet-thrift/src/test/java/parquet/thrift/TestProtocolReadToWrite.java": [
                6,
                24
            ],
            "parquet-thrift/src/test/thrift/compat.thrift": null,
            "pom.xml": null
        }
    },
    "70226b9a97dd2ade359cb76a320727e20892b881": {
        "datetime": "2013-09-10T08:37:32-07:00",
        "summary": "distinguish recoverable errors",
        "message": "distinguish recoverable errors\n",
        "diff": {
            "parquet-thrift/src/main/java/parquet/thrift/BufferedProtocolReadToWrite.java": [
                9,
                12
            ]
        }
    },
    "68fa6cd26b473d8d1592fbd51b31d5a0c5af53ad": {
        "datetime": "2013-09-10T10:08:46-07:00",
        "summary": "fill in missing fields, only for str now, will refactor to visitor pattern",
        "message": "fill in missing fields, only for str now, will refactor to visitor pattern\n",
        "diff": {
            "parquet-thrift/src/main/java/parquet/thrift/ParquetProtocol.java": [
                2,
                2
            ],
            "parquet-thrift/src/main/java/parquet/thrift/ParquetReadProtocol.java": [
                10,
                4
            ],
            "parquet-thrift/src/main/java/parquet/thrift/ThriftRecordConverter.java": [
                203,
                180
            ],
            "parquet-thrift/src/main/java/parquet/thrift/projection/ProtocolEventsAmender.java": [
                0,
                184
            ],
            "parquet-thrift/src/main/java/parquet/thrift/projection/ProtocolEventsGenerator.java": [
                0,
                132
            ],
            "parquet-thrift/src/test/java/parquet/hadoop/thrift/TestParquetToThriftReadProjection.java": [
                1,
                1
            ]
        }
    },
    "7dfa864c3382f3223a9331672b0f77ef874e6ca0": {
        "datetime": "2013-09-10T10:26:11-07:00",
        "summary": "visitor pattern for string, test passed",
        "message": "visitor pattern for string, test passed\n",
        "diff": {
            "parquet-thrift/src/main/java/parquet/thrift/ThriftRecordConverter.java": [
                1,
                1
            ],
            "parquet-thrift/src/main/java/parquet/thrift/projection/ProtocolEventsAmender.java": [
                1,
                2
            ],
            "parquet-thrift/src/main/java/parquet/thrift/projection/ProtocolEventsGenerator.java": [
                132,
                0
            ],
            "parquet-thrift/src/main/java/parquet/thrift/projection/amend/ProtocolEventsGenerator.java": [
                0,
                167
            ],
            "parquet-thrift/src/main/java/parquet/thrift/projection/amend/StructBeginProtocol.java": [
                0,
                25
            ]
        }
    },
    "1bf9d5f350bba42490e40d2312f2879ee0caf82e": {
        "datetime": "2013-09-10T10:34:27-07:00",
        "summary": "extracted inner classes from ProtocolEventsGenerator",
        "message": "extracted inner classes from ProtocolEventsGenerator\n",
        "diff": {
            "parquet-thrift/src/main/java/parquet/thrift/projection/amend/DummyCreatorVisitor.java": [
                0,
                91
            ],
            "parquet-thrift/src/main/java/parquet/thrift/projection/amend/ProtocolEventsGenerator.java": [
                118,
                2
            ],
            "parquet-thrift/src/main/java/parquet/thrift/projection/amend/ReadFieldBeginProtocol.java": [
                0,
                33
            ],
            "parquet-thrift/src/main/java/parquet/thrift/projection/amend/StringProtocol.java": [
                0,
                33
            ]
        }
    },
    "c59e82f53fde512934a3fa37bccdfa12f915c349": {
        "datetime": "2013-09-10T11:01:36-07:00",
        "summary": "implemented all dummy values",
        "message": "implemented all dummy values\n",
        "diff": {
            "parquet-thrift/src/main/java/parquet/thrift/projection/amend/DummyCreatorVisitor.java": [
                11,
                70
            ],
            "parquet-thrift/src/main/java/parquet/thrift/projection/amend/ProtocolEventsGenerator.java": [
                1,
                0
            ]
        }
    },
    "9a1e2953b3234395b211481644d17857f52b803e": {
        "datetime": "2013-09-10T11:06:46-07:00",
        "summary": "merge master",
        "message": "merge master\n",
        "diff": {
            "parquet-avro/pom.xml": null,
            "parquet-cascading/pom.xml": null,
            "parquet-cascading/src/test/java/parquet/cascading/TestParquetTBaseScheme.java": [
                0,
                15
            ],
            "parquet-cascading/src/test/java/parquet/cascading/TestParquetTupleScheme.java": [
                0,
                15
            ],
            "parquet-column/pom.xml": null,
            "parquet-column/src/main/java/parquet/column/values/dictionary/PlainValuesDictionary.java": [
                1,
                2
            ],
            "parquet-column/src/main/java/parquet/schema/GroupType.java": [
                4,
                62
            ],
            "parquet-column/src/main/java/parquet/schema/IncompatibleSchemaModificationException.java": [
                0,
                46
            ],
            "parquet-column/src/main/java/parquet/schema/MessageType.java": [
                1,
                6
            ],
            "parquet-column/src/main/java/parquet/schema/PrimitiveType.java": [
                2,
                15
            ],
            "parquet-column/src/main/java/parquet/schema/Type.java": [
                4,
                62
            ],
            "parquet-column/src/test/java/parquet/schema/TestMessageType.java": [
                2,
                86
            ],
            "parquet-common/pom.xml": null,
            "parquet-encoding/pom.xml": null,
            "parquet-generator/pom.xml": null,
            "parquet-hadoop/pom.xml": null,
            "parquet-hadoop/src/main/java/parquet/hadoop/InternalParquetRecordReader.java": [
                2,
                5
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/ParquetFileReader.java": [
                24,
                27
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/ParquetFileWriter.java": [
                27,
                70
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/ParquetInputFormat.java": [
                18,
                34
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/ParquetReader.java": [
                14,
                62
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/ParquetRecordReader.java": [
                4,
                16
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/api/InitContext.java": [
                0,
                99
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/api/ReadSupport.java": [
                2,
                17
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/codec/NonBlockedCompressorStream.java": [
                0,
                15
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/codec/NonBlockedDecompressorStream.java": [
                0,
                15
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/mapred/DeprecatedParquetInputFormat.java": [
                1,
                1
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/metadata/FileMetaData.java": [
                8,
                5
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/metadata/GlobalMetaData.java": [
                0,
                103
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/util/BenchmarkCounter.java": [
                53,
                0
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/util/counters/BenchmarkCounter.java": [
                0,
                111
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/util/counters/CounterLoader.java": [
                0,
                25
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/util/counters/ICounter.java": [
                0,
                26
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/util/counters/mapred/MapRedCounterAdapter.java": [
                0,
                41
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/util/counters/mapred/MapRedCounterLoader.java": [
                0,
                46
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/util/counters/mapreduce/MapReduceCounterAdapter.java": [
                0,
                42
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/util/counters/mapreduce/MapReduceCounterLoader.java": [
                0,
                44
            ],
            "parquet-hadoop/src/test/java/parquet/hadoop/DeprecatedInputFormatTest.java": [
                0,
                179
            ],
            "parquet-hadoop/src/test/java/parquet/hadoop/TestParquetFileWriter.java": [
                0,
                29
            ],
            "parquet-hadoop/src/test/java/parquet/hadoop/example/GroupReadSupportTest.java": [
                0,
                15
            ],
            "parquet-hadoop/src/test/java/parquet/hadoop/example/TestInputOutputFormat.java": [
                1,
                1
            ],
            "parquet-hive/pom.xml": null,
            "parquet-pig/pom.xml": null,
            "parquet-pig/src/main/java/parquet/pig/ParquetLoader.java": [
                37,
                33
            ],
            "parquet-pig/src/main/java/parquet/pig/PigMetaData.java": [
                5,
                40
            ],
            "parquet-pig/src/main/java/parquet/pig/PigSchemaConverter.java": [
                5,
                42
            ],
            "parquet-pig/src/main/java/parquet/pig/TupleReadSupport.java": [
                26,
                76
            ],
            "parquet-pig/src/test/java/parquet/pig/TestParquetLoader.java": [
                6,
                6
            ],
            "parquet-pig/src/test/java/parquet/pig/TestParquetStorer.java": [
                1,
                63
            ],
            "parquet-pig/src/test/java/parquet/pig/TestPigSchemaConverter.java": [
                8,
                30
            ],
            "parquet-pig/src/test/java/parquet/pig/TestTupleRecordConsumer.java": [
                1,
                13
            ],
            "parquet-scrooge/pom.xml": null,
            "parquet-test-hadoop2/pom.xml": null,
            "parquet-thrift/pom.xml": null,
            "parquet-thrift/src/main/java/parquet/hadoop/thrift/ThriftBytesWriteSupport.java": [
                1,
                1
            ],
            "parquet-thrift/src/main/java/parquet/hadoop/thrift/ThriftReadSupport.java": [
                15,
                48
            ],
            "parquet-thrift/src/main/java/parquet/thrift/BufferedProtocolReadToWrite.java": [
                5,
                14
            ],
            "parquet-thrift/src/main/java/parquet/thrift/ParquetProtocol.java": [
                4,
                6
            ],
            "parquet-thrift/src/main/java/parquet/thrift/ThriftMetaData.java": [
                10,
                49
            ],
            "parquet-thrift/src/main/java/parquet/thrift/ThriftRecordConverter.java": [
                180,
                206
            ],
            "parquet-thrift/src/test/java/parquet/hadoop/thrift/TestInputOutputFormat.java": [
                0,
                108
            ],
            "parquet-thrift/src/test/java/parquet/thrift/TestProtocolReadToWrite.java": [
                6,
                24
            ],
            "parquet-thrift/src/test/thrift/compat.thrift": null,
            "pom.xml": null
        }
    },
    "6f374b74e3766da468e1b481247070cd7c7593d1": {
        "datetime": "2013-09-10T11:14:46-07:00",
        "summary": "store thriftType in converter[fix merge error]",
        "message": "store thriftType in converter[fix merge error]\n",
        "diff": {
            "parquet-thrift/src/main/java/parquet/thrift/ThriftRecordConverter.java": [
                1,
                5
            ]
        }
    },
    "3e160d9c95ac9cdb058f9f917dae1276f462c82f": {
        "datetime": "2013-09-10T11:23:12-07:00",
        "summary": "add license headers",
        "message": "add license headers\n",
        "diff": {
            "parquet-thrift/src/main/java/parquet/thrift/projection/amend/DummyCreatorVisitor.java": [
                8,
                18
            ],
            "parquet-thrift/src/main/java/parquet/thrift/projection/amend/ProtocolEventsAmender.java": [
                35,
                25
            ],
            "parquet-thrift/src/main/java/parquet/thrift/projection/amend/ProtocolEventsGenerator.java": [
                1,
                15
            ],
            "parquet-thrift/src/main/java/parquet/thrift/projection/amend/ReadFieldBeginProtocol.java": [
                7,
                15
            ],
            "parquet-thrift/src/main/java/parquet/thrift/projection/amend/StringProtocol.java": [
                8,
                1
            ],
            "parquet-thrift/src/main/java/parquet/thrift/projection/amend/StructBeginProtocol.java": [
                7,
                0
            ]
        }
    },
    "b4a8eb1e95ca30db1c14eb17e08bf2ca8fd200cf": {
        "datetime": "2013-09-10T11:25:31-07:00",
        "summary": "fix test",
        "message": "fix test\n",
        "diff": {
            "parquet-thrift/src/test/java/parquet/thrift/TestProtocolReadToWrite.java": [
                2,
                2
            ]
        }
    },
    "3060f85cd096bd75c25cad72f27f65b239c95e14": {
        "datetime": "2013-09-10T14:12:17-07:00",
        "summary": "added unit tests",
        "message": "added unit tests\n",
        "diff": {
            "parquet-thrift/src/main/java/parquet/thrift/projection/amend/DummyCreatorVisitor.java": [
                4,
                23
            ],
            "parquet-thrift/src/test/java/parquet/hadoop/thrift/TestParquetToThriftReadProjection.java": [
                26,
                124
            ],
            "parquet-thrift/src/test/thrift/test.thrift": null
        }
    },
    "8aadc0ac6ef8e229baee584385002c488c042207": {
        "datetime": "2013-09-10T14:25:39-07:00",
        "summary": "fix bug, use a new list for fixed events",
        "message": "fix bug, use a new list for fixed events\n",
        "diff": {
            "parquet-thrift/src/main/java/parquet/thrift/ThriftRecordConverter.java": [
                2,
                2
            ],
            "parquet-thrift/src/main/java/parquet/thrift/projection/amend/DummyCreatorVisitor.java": [
                1,
                1
            ],
            "parquet-thrift/src/main/java/parquet/thrift/projection/amend/ProtocolEventsGenerator.java": [
                1,
                1
            ]
        }
    },
    "b81238938165d7179357041bad40ca510cb9c687": {
        "datetime": "2013-09-10T14:48:24-07:00",
        "summary": "inline some classes",
        "message": "inline some classes\n",
        "diff": {
            "parquet-thrift/src/main/java/parquet/thrift/projection/amend/DefaultEventsVisitor.java": [
                0,
                35
            ],
            "parquet-thrift/src/main/java/parquet/thrift/projection/amend/ProtocolEventsAmender.java": [
                5,
                0
            ],
            "parquet-thrift/src/main/java/parquet/thrift/projection/amend/ProtocolEventsGenerator.java": [
                0,
                1
            ],
            "parquet-thrift/src/main/java/parquet/thrift/projection/amend/ReadFieldBeginProtocol.java": [
                1,
                1
            ],
            "parquet-thrift/src/main/java/parquet/thrift/projection/amend/StringProtocol.java": [
                26,
                0
            ],
            "parquet-thrift/src/main/java/parquet/thrift/projection/amend/StructBeginProtocol.java": [
                18,
                0
            ]
        }
    },
    "f702fdfb5b8b46e90ef14daa58d80cb59f1d26a4": {
        "datetime": "2013-09-10T14:51:56-07:00",
        "summary": "better naming",
        "message": "better naming\n",
        "diff": {
            "parquet-thrift/src/main/java/parquet/thrift/projection/amend/DefaultEventsVisitor.java": [
                6,
                4
            ],
            "parquet-thrift/src/main/java/parquet/thrift/projection/amend/ProtocolEventsAmender.java": [
                2,
                2
            ],
            "parquet-thrift/src/main/java/parquet/thrift/projection/amend/ProtocolEventsGenerator.java": [
                1,
                1
            ]
        }
    },
    "133b2528a56c06ea5c3bd16fa50963edaf76f644": {
        "datetime": "2013-09-10T15:38:10-07:00",
        "summary": "add missing file",
        "message": "add missing file\n",
        "diff": {
            "parquet-thrift/src/main/java/parquet/thrift/SkippableException.java": [
                0,
                32
            ]
        }
    },
    "073e20295c0620c3cb7374bc822c267e34296300": {
        "datetime": "2013-09-10T15:42:24-07:00",
        "summary": "fix test path",
        "message": "fix test path\n",
        "diff": {
            "parquet-hadoop/src/test/java/parquet/hadoop/example/TestInputOutputFormat.java": [
                1,
                1
            ]
        }
    },
    "eff7237c798a1057c9be4148dbd555a790bea3bb": {
        "datetime": "2013-09-10T16:06:03-07:00",
        "summary": "remove converted Type",
        "message": "remove converted Type\n",
        "diff": {
            "parquet-thrift/src/main/java/parquet/thrift/ParquetReadProtocol.java": [
                4,
                10
            ],
            "parquet-thrift/src/main/java/parquet/thrift/ThriftRecordConverter.java": [
                1,
                1
            ],
            "parquet-thrift/src/main/java/parquet/thrift/ThriftSchemaConverter.java": [
                98,
                52
            ]
        }
    },
    "d7b00834098a7f3b705656e9c0e12b077084e8c0": {
        "datetime": "2013-09-10T16:12:14-07:00",
        "summary": "Add empty map and array to test Avro schema all-minus-fixed and add empty map and array fields to parquet-avro test that tests fields of all (except fixed) types.",
        "message": "Add empty map and array to test Avro schema all-minus-fixed and add empty map and array fields to parquet-avro test that tests fields of all (except fixed) types.\n",
        "diff": {
            "parquet-avro/src/test/java/parquet/avro/TestReadWrite.java": [
                62,
                70
            ],
            "parquet-avro/src/test/resources/all-minus-fixed.avsc": null
        }
    },
    "365d84ef8706aae8aaabeb6062dd24357ececbd5": {
        "datetime": "2013-09-10T16:57:47-07:00",
        "summary": "prepare for commit, remove format diff",
        "message": "prepare for commit, remove format diff\n",
        "diff": {
            "parquet-thrift/src/main/java/parquet/thrift/ThriftSchemaConverter.java": [
                74,
                54
            ]
        }
    },
    "5ca767137557e8a54040f35481a3041245783417": {
        "datetime": "2013-09-10T18:27:10-07:00",
        "summary": "Re-enable test for fixed type fields in Avro TestReadWrite.",
        "message": "Re-enable test for fixed type fields in Avro TestReadWrite.\n",
        "diff": {
            "parquet-avro/src/test/java/parquet/avro/TestReadWrite.java": [
                5,
                4
            ],
            "parquet-avro/src/test/resources/all-minus-fixed.avsc": null,
            "parquet-avro/src/test/resources/all.avsc": null
        }
    },
    "ffbdf6dd649775eff7a26ce78244395a934902a0": {
        "datetime": "2013-09-11T10:28:56-07:00",
        "summary": "visitor pattern for schemaConverter",
        "message": "visitor pattern for schemaConverter\n",
        "diff": {
            "parquet-thrift/src/main/java/parquet/thrift/SchemaConvertVisitor.java": [
                0,
                263
            ],
            "parquet-thrift/src/main/java/parquet/thrift/ThriftSchemaConverter.java": [
                149,
                5
            ]
        }
    },
    "2b2837f55ad92211c1da450195672ae02230b82c": {
        "datetime": "2013-09-11T10:39:49-07:00",
        "summary": "refactor matching filter",
        "message": "refactor matching filter\n",
        "diff": {
            "parquet-thrift/src/main/java/parquet/thrift/SchemaConvertVisitor.java": [
                52,
                46
            ],
            "parquet-thrift/src/main/java/parquet/thrift/ThriftSchemaConverter.java": [
                2,
                0
            ]
        }
    },
    "079e295072516c46fff087d3d38ee3310f6a1b5b": {
        "datetime": "2013-09-11T10:40:52-07:00",
        "summary": "rename",
        "message": "rename\n",
        "diff": {
            "parquet-thrift/src/main/java/parquet/thrift/SchemaConvertVisitor.java": [
                2,
                2
            ],
            "parquet-thrift/src/main/java/parquet/thrift/ThriftSchemaConverter.java": [
                9,
                1
            ]
        }
    },
    "7b68b4738d50f1ca12f9ebf048d28db20682b984": {
        "datetime": "2013-09-12T09:37:06-07:00",
        "summary": "sucess: compile scrooge generated classes in parquet-thrift",
        "message": "sucess: compile scrooge generated classes in parquet-thrift\n",
        "diff": {
            "parquet-thrift/pom.xml": null,
            "parquet-thrift/src/main/java/parquet/hadoop/thrift/ThriftReadSupport.java": [
                0,
                1
            ],
            "parquet-thrift/src/main/java/parquet/thrift/ThriftMetaData.java": [
                9,
                19
            ],
            "parquet-thrift/src/test/java/parquet/hadoop/thrift/TestParquetToThriftReadProjection.java": [
                5,
                5
            ],
            "parquet-thrift/src/test/java/parquet/thrift/TestThriftSchemaConverter.java": [
                18,
                6
            ]
        }
    },
    "5393833758daf1bc67e759f03de3507fca0aca65": {
        "datetime": "2013-09-12T12:33:50-07:00",
        "summary": "migrated tests to parquet-scrooge [tests passed]",
        "message": "migrated tests to parquet-scrooge [tests passed]\n",
        "diff": {
            "parquet-scrooge/pom.xml": null,
            "parquet-scrooge/src/test/java/parquet/scrooge/ParquetScroogeSchemeTest.java": [
                0,
                216
            ],
            "parquet-scrooge/src/test/thrift/compat.thrift": null,
            "parquet-scrooge/src/test/thrift/test.thrift": null
        }
    },
    "d9ce72660790484784897905f34ebbd2a6a278d9": {
        "datetime": "2013-09-12T12:56:45-07:00",
        "summary": "add test in scrooge [only maven passed]",
        "message": "add test in scrooge [only maven passed]\n",
        "diff": {
            "parquet-scrooge/src/test/java/parquet/scrooge/ParquetScroogeSchemeTest.java": [
                3,
                50
            ]
        }
    },
    "0570f46ce688f9361f4264c36cc3723074e459e8": {
        "datetime": "2013-09-12T21:55:14-07:00",
        "summary": "better fallback mechanism",
        "message": "better fallback mechanism\n",
        "diff": {
            "parquet-column/src/main/java/parquet/column/values/dictionary/DictionaryValuesWriter.java": [
                21,
                31
            ],
            "parquet-column/src/test/java/parquet/column/values/dictionary/TestDictionary.java": [
                8,
                74
            ]
        }
    },
    "015ed30d5b681a8a082166d4692f0a813dd31fa0": {
        "datetime": "2013-09-12T23:13:04-07:00",
        "summary": "fix oom error dues to bad estimation",
        "message": "fix oom error dues to bad estimation\n",
        "diff": {
            "parquet-hadoop/src/main/java/parquet/hadoop/InternalParquetRecordWriter.java": [
                4,
                13
            ]
        }
    },
    "1e472d2d8dcacdca52fdda81443703484974ca93": {
        "datetime": "2013-09-12T23:21:19-07:00",
        "summary": "Merge pull request #167 from Parquet/fix_oom",
        "message": "Merge pull request #167 from Parquet/fix_oom\n\nfix oom error dues to bad estimation",
        "diff": {
            "parquet-hadoop/src/main/java/parquet/hadoop/InternalParquetRecordWriter.java": [
                4,
                13
            ]
        }
    },
    "92f58ac1a61a0d974b4159b1535a4464c52b1c0e": {
        "datetime": "2013-09-12T23:26:43-07:00",
        "summary": "[maven-release-plugin] prepare release parquet-1.2.1",
        "message": "[maven-release-plugin] prepare release parquet-1.2.1\n",
        "diff": {
            "parquet-avro/pom.xml": null,
            "parquet-cascading/pom.xml": null,
            "parquet-column/pom.xml": null,
            "parquet-common/pom.xml": null,
            "parquet-encoding/pom.xml": null,
            "parquet-generator/pom.xml": null,
            "parquet-hadoop/pom.xml": null,
            "parquet-hive/pom.xml": null,
            "parquet-pig/pom.xml": null,
            "parquet-scrooge/pom.xml": null,
            "parquet-test-hadoop2/pom.xml": null,
            "parquet-thrift/pom.xml": null,
            "pom.xml": null
        }
    },
    "dae37cf2d95ccffc89357777e7f0d1fb1b62f066": {
        "datetime": "2013-09-12T23:26:49-07:00",
        "summary": "[maven-release-plugin] prepare for next development iteration",
        "message": "[maven-release-plugin] prepare for next development iteration\n",
        "diff": {
            "parquet-avro/pom.xml": null,
            "parquet-cascading/pom.xml": null,
            "parquet-column/pom.xml": null,
            "parquet-common/pom.xml": null,
            "parquet-encoding/pom.xml": null,
            "parquet-generator/pom.xml": null,
            "parquet-hadoop/pom.xml": null,
            "parquet-hive/pom.xml": null,
            "parquet-pig/pom.xml": null,
            "parquet-scrooge/pom.xml": null,
            "parquet-test-hadoop2/pom.xml": null,
            "parquet-thrift/pom.xml": null,
            "pom.xml": null
        }
    },
    "1d928046faec8f83fd0ed112e602eefbca396d31": {
        "datetime": "2013-09-13T11:00:21-07:00",
        "summary": "Add typeLength to ColumnDescriptor.",
        "message": "Add typeLength to ColumnDescriptor.\n",
        "diff": {
            "parquet-avro/src/main/java/parquet/avro/AvroWriteSupport.java": [
                1,
                0
            ],
            "parquet-column/src/main/java/parquet/column/ColumnDescriptor.java": [
                2,
                29
            ],
            "parquet-column/src/main/java/parquet/column/impl/ColumnWriterImpl.java": [
                10,
                7
            ],
            "parquet-hadoop/src/main/java/parquet/format/converter/ParquetMetadataConverter.java": [
                7,
                7
            ]
        }
    },
    "a7ba48ba7caf2ef58868dca8bc710f66eac199f5": {
        "datetime": "2013-09-13T11:29:19-07:00",
        "summary": "created ScroogeSchemaConverter",
        "message": "created ScroogeSchemaConverter\n",
        "diff": {
            "parquet-scrooge/pom.xml": null,
            "parquet-scrooge/src/main/java/parquet/scrooge/ScroogeRecordConverter.java": [
                1,
                1
            ],
            "parquet-scrooge/src/main/java/parquet/scrooge/ScroogeSchemaConverter.java": [
                0,
                113
            ],
            "parquet-scrooge/src/test/java/parquet/scrooge/ParquetScroogeSchemeTest.java": [
                0,
                34
            ],
            "parquet-scrooge/src/test/thrift/test.thrift": null,
            "parquet-thrift/pom.xml": null,
            "parquet-thrift/src/main/java/parquet/thrift/ThriftSchemaConverter.java": [
                2,
                1
            ],
            "parquet-thrift/src/test/java/parquet/thrift/TestThriftSchemaConverter.java": [
                5,
                0
            ]
        }
    },
    "e2d3bb299a29b7df44cef06a555bd1e5c5b775f5": {
        "datetime": "2013-09-13T11:33:08-07:00",
        "summary": "[style]fix if...else in ConversionPatterns",
        "message": "[style]fix if...else in ConversionPatterns\n",
        "diff": {
            "parquet-column/src/main/java/parquet/schema/ConversionPatterns.java": [
                31,
                32
            ]
        }
    },
    "64e6d82f69249c0e3a2747b3f6b59d39cd2df873": {
        "datetime": "2013-09-13T11:42:09-07:00",
        "summary": "[style] add spaces around =",
        "message": "[style] add spaces around =\n",
        "diff": {
            "parquet-column/src/main/java/parquet/schema/ConversionPatterns.java": [
                2,
                0
            ],
            "parquet-thrift/src/main/java/parquet/thrift/ThriftRecordConverter.java": [
                2,
                2
            ]
        }
    },
    "99b6dfcc7c82c09e098fa8583442bafc1d8a3151": {
        "datetime": "2013-09-13T11:44:44-07:00",
        "summary": "remove julien's TODO",
        "message": "remove julien's TODO\n",
        "diff": {
            "parquet-thrift/src/main/java/parquet/thrift/ThriftSchemaConvertVisitor.java": [
                3,
                2
            ]
        }
    },
    "bbc0aa71677b4d9f3c20c41b710b0f55250025a1": {
        "datetime": "2013-09-13T12:07:06-07:00",
        "summary": "Merge pull request #166 from Parquet/avoid_pruning_required_fields",
        "message": "Merge pull request #166 from Parquet/avoid_pruning_required_fields\n\nAvoid pruning required fields in projection pushdown for thrift",
        "diff": {
            "parquet-column/src/main/java/parquet/schema/ConversionPatterns.java": [
                29,
                42
            ],
            "parquet-thrift/src/main/java/parquet/thrift/ParquetProtocol.java": [
                2,
                2
            ],
            "parquet-thrift/src/main/java/parquet/thrift/ThriftRecordConverter.java": [
                1,
                5
            ],
            "parquet-thrift/src/main/java/parquet/thrift/ThriftSchemaConvertVisitor.java": [
                0,
                256
            ],
            "parquet-thrift/src/main/java/parquet/thrift/ThriftSchemaConverter.java": [
                166,
                20
            ],
            "parquet-thrift/src/main/java/parquet/thrift/projection/FieldProjectionFilter.java": [
                9,
                3
            ],
            "parquet-thrift/src/main/java/parquet/thrift/projection/FieldsPath.java": [
                0,
                82
            ],
            "parquet-thrift/src/main/java/parquet/thrift/projection/amend/DefaultEventsVisitor.java": [
                0,
                212
            ],
            "parquet-thrift/src/main/java/parquet/thrift/projection/amend/DefaultProtocolEventsGenerator.java": [
                0,
                65
            ],
            "parquet-thrift/src/main/java/parquet/thrift/projection/amend/ProtocolEventsAmender.java": [
                0,
                170
            ],
            "parquet-thrift/src/main/java/parquet/thrift/projection/amend/ReadFieldBeginProtocol.java": [
                0,
                41
            ],
            "parquet-thrift/src/test/java/parquet/hadoop/thrift/TestParquetToThriftReadProjection.java": [
                27,
                125
            ],
            "parquet-thrift/src/test/java/parquet/thrift/TestThriftSchemaConverter.java": [
                34,
                61
            ],
            "parquet-thrift/src/test/thrift/test.thrift": null
        }
    },
    "9d84697a0b1759b7b4dccaa3278c4836bad011ef": {
        "datetime": "2013-09-13T13:19:59-07:00",
        "summary": "merge master",
        "message": "merge master\n",
        "diff": {
            "parquet-avro/pom.xml": null,
            "parquet-cascading/pom.xml": null,
            "parquet-column/pom.xml": null,
            "parquet-column/src/main/java/parquet/schema/ConversionPatterns.java": [
                32,
                31
            ],
            "parquet-common/pom.xml": null,
            "parquet-encoding/pom.xml": null,
            "parquet-generator/pom.xml": null,
            "parquet-hadoop/pom.xml": null,
            "parquet-hadoop/src/main/java/parquet/hadoop/InternalParquetRecordWriter.java": [
                4,
                13
            ],
            "parquet-hive/pom.xml": null,
            "parquet-pig/pom.xml": null,
            "parquet-scrooge/pom.xml": null,
            "parquet-test-hadoop2/pom.xml": null,
            "parquet-thrift/pom.xml": null,
            "parquet-thrift/src/main/java/parquet/thrift/ThriftRecordConverter.java": [
                2,
                2
            ],
            "parquet-thrift/src/main/java/parquet/thrift/ThriftSchemaConvertVisitor.java": [
                3,
                2
            ],
            "pom.xml": null
        }
    },
    "f6f3eaa01e0a503d78eb028be64554ca0a0f85c3": {
        "datetime": "2013-09-13T14:12:35-07:00",
        "summary": "broken tests for scroogeRead",
        "message": "broken tests for scroogeRead\n",
        "diff": {
            "parquet-scrooge/src/main/java/parquet/scrooge/ScroogeSchemaConverter.java": [
                9,
                37
            ],
            "parquet-scrooge/src/test/java/parquet/scrooge/ParquetScroogeSchemeTest.java": [
                13,
                13
            ],
            "parquet-scrooge/src/test/thrift/test.thrift": null
        }
    },
    "3803d2d478ef73e1bccc2d887daad4b30647d854": {
        "datetime": "2013-09-16T05:47:09-07:00",
        "summary": "Plumb FIXED type length from Avro schema through to Parquet metadata.",
        "message": "Plumb FIXED type length from Avro schema through to Parquet metadata.\n",
        "diff": {
            "parquet-avro/src/main/java/parquet/avro/AvroSchemaConverter.java": [
                5,
                14
            ],
            "parquet-column/src/main/java/parquet/schema/PrimitiveType.java": [
                2,
                19
            ],
            "parquet-hadoop/src/main/java/parquet/format/converter/ParquetMetadataConverter.java": [
                1,
                6
            ]
        }
    },
    "b4c45d3a5fa2972a0fbb214179350c55a7051927": {
        "datetime": "2013-09-16T10:31:59-07:00",
        "summary": "fix bug, missing break in thriftSchemaConverter",
        "message": "fix bug, missing break in thriftSchemaConverter\n",
        "diff": {
            "parquet-scrooge/pom.xml": null,
            "parquet-thrift/src/main/java/parquet/thrift/ThriftSchemaConverter.java": [
                0,
                1
            ]
        }
    },
    "dcc0d81849c4064fee779844b2b39737c75fd230": {
        "datetime": "2013-09-16T11:10:11-07:00",
        "summary": "Merge branch 'master' into fixed_len_byte_array",
        "message": "Merge branch 'master' into fixed_len_byte_array\n",
        "diff": {
            "parquet-avro/pom.xml": null,
            "parquet-cascading/pom.xml": null,
            "parquet-column/pom.xml": null,
            "parquet-column/src/main/java/parquet/schema/ConversionPatterns.java": [
                29,
                42
            ],
            "parquet-common/pom.xml": null,
            "parquet-encoding/pom.xml": null,
            "parquet-generator/pom.xml": null,
            "parquet-hadoop/pom.xml": null,
            "parquet-hadoop/src/main/java/parquet/hadoop/InternalParquetRecordWriter.java": [
                4,
                13
            ],
            "parquet-hive/pom.xml": null,
            "parquet-pig/pom.xml": null,
            "parquet-scrooge/pom.xml": null,
            "parquet-test-hadoop2/pom.xml": null,
            "parquet-thrift/pom.xml": null,
            "parquet-thrift/src/main/java/parquet/thrift/ParquetProtocol.java": [
                2,
                2
            ],
            "parquet-thrift/src/main/java/parquet/thrift/ThriftRecordConverter.java": [
                1,
                5
            ],
            "parquet-thrift/src/main/java/parquet/thrift/ThriftSchemaConvertVisitor.java": [
                0,
                256
            ],
            "parquet-thrift/src/main/java/parquet/thrift/ThriftSchemaConverter.java": [
                166,
                20
            ],
            "parquet-thrift/src/main/java/parquet/thrift/projection/FieldProjectionFilter.java": [
                9,
                3
            ],
            "parquet-thrift/src/main/java/parquet/thrift/projection/FieldsPath.java": [
                0,
                82
            ],
            "parquet-thrift/src/main/java/parquet/thrift/projection/amend/DefaultEventsVisitor.java": [
                0,
                212
            ],
            "parquet-thrift/src/main/java/parquet/thrift/projection/amend/DefaultProtocolEventsGenerator.java": [
                0,
                65
            ],
            "parquet-thrift/src/main/java/parquet/thrift/projection/amend/ProtocolEventsAmender.java": [
                0,
                170
            ],
            "parquet-thrift/src/main/java/parquet/thrift/projection/amend/ReadFieldBeginProtocol.java": [
                0,
                41
            ],
            "parquet-thrift/src/test/java/parquet/hadoop/thrift/TestParquetToThriftReadProjection.java": [
                27,
                125
            ],
            "parquet-thrift/src/test/java/parquet/thrift/TestThriftSchemaConverter.java": [
                34,
                61
            ],
            "parquet-thrift/src/test/thrift/test.thrift": null,
            "pom.xml": null
        }
    },
    "04784c2e024cd3db1165150448f19ef4532793d6": {
        "datetime": "2013-09-16T13:30:10-07:00",
        "summary": "test pass",
        "message": "test pass\n",
        "diff": {
            "parquet-scrooge/src/test/java/parquet/scrooge/ParquetScroogeSchemeTest.java": [
                208,
                24
            ]
        }
    },
    "ceef971637184db5079499d3cefc2e1035822a30": {
        "datetime": "2013-09-16T13:34:05-07:00",
        "summary": "remove unused compat.thrift",
        "message": "remove unused compat.thrift\n",
        "diff": {
            "parquet-scrooge/src/test/thrift/compat.thrift": null
        }
    },
    "2a2696dcee58fb7fd6d9072b97f0411b5ceb9470": {
        "datetime": "2013-09-16T13:36:30-07:00",
        "summary": "format",
        "message": "format\n",
        "diff": {
            "parquet-scrooge/src/test/java/parquet/scrooge/ParquetScroogeSchemeTest.java": [
                43,
                23
            ]
        }
    },
    "78b3f86774685d5d8beb1b12880fd127de9a6222": {
        "datetime": "2013-09-16T13:40:23-07:00",
        "summary": "update scrooge denepdency, add unit tests for reading in scrooge",
        "message": "update scrooge denepdency, add unit tests for reading in scrooge\n",
        "diff": {
            "parquet-scrooge/pom.xml": null,
            "parquet-scrooge/src/test/java/parquet/scrooge/ParquetScroogeSchemeTest.java": [
                0,
                93
            ],
            "parquet-scrooge/src/test/thrift/test.thrift": null
        }
    },
    "249581dd38d82e5b36f39a25e45e84f109c12e69": {
        "datetime": "2013-09-16T13:49:08-07:00",
        "summary": "add TestCase for scrooge schema converter",
        "message": "add TestCase for scrooge schema converter\n",
        "diff": {
            "parquet-scrooge/src/test/java/parquet/scrooge/ScroogeSchemaConverterTest.java": [
                0,
                15
            ]
        }
    },
    "c1f3512b1e78137f01cdc11221ab64242a6fe1b6": {
        "datetime": "2013-09-16T13:56:18-07:00",
        "summary": "change some ParquetOutputFormat interfaces to mirror ParquetInputFormat (and be useful for writing a DeprecatedOutputFormat)",
        "message": "change some ParquetOutputFormat interfaces to mirror ParquetInputFormat (and be useful for writing a DeprecatedOutputFormat)\n",
        "diff": {
            "parquet-hadoop/src/main/java/parquet/hadoop/ParquetOutputFormat.java": [
                76,
                93
            ]
        }
    },
    "93d6770be153472c0da28dd2b9b3fc8797604703": {
        "datetime": "2013-09-16T13:56:28-07:00",
        "summary": "add a simple test for DeprecatedOutputFormat",
        "message": "add a simple test for DeprecatedOutputFormat\n",
        "diff": {
            "parquet-hadoop/src/test/java/parquet/hadoop/DeprecatedOutputFormatTest.java": [
                0,
                106
            ]
        }
    },
    "521d08127d3355273fa00d2d0a4819069813f0c8": {
        "datetime": "2013-09-16T13:56:28-07:00",
        "summary": "add some convenience methods (from ParquetOutputFormat)",
        "message": "add some convenience methods (from ParquetOutputFormat)\n",
        "diff": {
            "parquet-hadoop/src/main/java/parquet/hadoop/mapred/DeprecatedParquetOutputFormat.java": [
                5,
                26
            ]
        }
    },
    "a00fd5e21b94692d4e3daf59946589fe1f6b16b4": {
        "datetime": "2013-09-16T13:56:28-07:00",
        "summary": "remove tests that check that TBaseScheme doesn't support writes",
        "message": "remove tests that check that TBaseScheme doesn't support writes\n",
        "diff": {
            "parquet-cascading/src/test/java/parquet/cascading/TestParquetTBaseScheme.java": [
                20,
                0
            ]
        }
    },
    "9ae1d88da88554b643e201c04484c4b5177157ad": {
        "datetime": "2013-09-16T13:56:28-07:00",
        "summary": "add Sink functionality to parquet.cascading.ParquetTBaseScheme",
        "message": "add Sink functionality to parquet.cascading.ParquetTBaseScheme\n",
        "diff": {
            "parquet-cascading/src/main/java/parquet/cascading/ParquetTBaseScheme.java": [
                17,
                11
            ],
            "parquet-cascading/src/main/java/parquet/cascading/ParquetValueScheme.java": [
                0,
                16
            ],
            "parquet-cascading/src/test/java/parquet/cascading/TestParquetTBaseScheme.java": [
                4,
                4
            ]
        }
    },
    "7adc26426d67cb3046a4db4c5f265f02ea2d420a": {
        "datetime": "2013-09-16T13:56:28-07:00",
        "summary": "add another getRecordWriter overload",
        "message": "add another getRecordWriter overload\n",
        "diff": {
            "parquet-hadoop/src/main/java/parquet/hadoop/ParquetOutputFormat.java": [
                1,
                5
            ]
        }
    },
    "ce6bfcc103e94a3c2f9f62eea588805ffe59bc2c": {
        "datetime": "2013-09-16T13:56:28-07:00",
        "summary": "add a DeprecatedParquetOutputFormat to mirror DeprecatedParquetInputFormat",
        "message": "add a DeprecatedParquetOutputFormat to mirror DeprecatedParquetInputFormat\n",
        "diff": {
            "parquet-hadoop/src/main/java/parquet/hadoop/mapred/DeprecatedParquetOutputFormat.java": [
                0,
                94
            ]
        }
    },
    "bba977549ca72f92b89cb0a72d16d93fe46621cb": {
        "datetime": "2013-09-16T13:56:29-07:00",
        "summary": "two unused imports",
        "message": "two unused imports\n",
        "diff": {
            "parquet-cascading/src/main/java/parquet/cascading/ParquetTBaseScheme.java": [
                3,
                0
            ]
        }
    },
    "34bbb9072b93e1770dc3bf6369a7312d476d8bb0": {
        "datetime": "2013-09-16T13:56:29-07:00",
        "summary": "missing copyright notice",
        "message": "missing copyright notice\n",
        "diff": {
            "parquet-hadoop/src/main/java/parquet/hadoop/mapred/DeprecatedParquetOutputFormat.java": [
                0,
                15
            ]
        }
    },
    "3c65205c5056c51d912dd7297be90eb3feb7165e": {
        "datetime": "2013-09-16T14:08:32-07:00",
        "summary": "field requirement depends on if the getter returns option",
        "message": "field requirement depends on if the getter returns option\n",
        "diff": {
            "parquet-scrooge/src/main/java/parquet/scrooge/ScroogeSchemaConverter.java": [
                3,
                3
            ]
        }
    },
    "e2fec1c3c1840645a26943c918292a621e91f3f1": {
        "datetime": "2013-09-16T14:30:36-07:00",
        "summary": "add optional map field to thrift file",
        "message": "add optional map field to thrift file\n",
        "diff": {
            "parquet-scrooge/src/main/java/parquet/scrooge/ScroogeSchemaConverter.java": [
                13,
                6
            ],
            "parquet-scrooge/src/test/thrift/test.thrift": null
        }
    },
    "234a1cbfcfd2dc0af57be4091f82b28acee4d0db": {
        "datetime": "2013-09-16T14:37:59-07:00",
        "summary": "extracted key and value type from map and optional map",
        "message": "extracted key and value type from map and optional map\n",
        "diff": {
            "parquet-scrooge/src/main/java/parquet/scrooge/ScroogeSchemaConverter.java": [
                11,
                23
            ]
        }
    },
    "9a5eea0cbaf1083412b2a057c6190814f196292c": {
        "datetime": "2013-09-16T14:52:37-07:00",
        "summary": "working on map",
        "message": "working on map\n",
        "diff": {
            "parquet-scrooge/src/main/java/parquet/scrooge/ScroogeSchemaConverter.java": [
                3,
                8
            ]
        }
    },
    "d32e65e72ad7bb47dfb37c1e2ba592181d93a6e8": {
        "datetime": "2013-09-16T14:55:39-07:00",
        "summary": "downgrade scrooge version to 3.6.0, which is the latest version on maven central",
        "message": "downgrade scrooge version to 3.6.0, which is the latest version on maven central\n",
        "diff": {
            "parquet-scrooge/pom.xml": null
        }
    },
    "dd02df03c3ed08d03a0333af68f43c7f2b59df6d": {
        "datetime": "2013-09-16T15:49:18-07:00",
        "summary": "added map test",
        "message": "added map test\n",
        "diff": {
            "parquet-scrooge/src/main/java/parquet/scrooge/ScroogeSchemaConverter.java": [
                1,
                17
            ],
            "parquet-scrooge/src/test/java/parquet/scrooge/ScroogeSchemaConverterTest.java": [
                1,
                2
            ],
            "parquet-scrooge/src/test/thrift/test.thrift": null
        }
    },
    "8b84a9eca1ec63c6e187c770071f4090043877af": {
        "datetime": "2013-09-16T15:50:06-07:00",
        "summary": "specify scala version for scrooge",
        "message": "specify scala version for scrooge\n",
        "diff": {
            "parquet-scrooge/pom.xml": null
        }
    },
    "5aa7a682910bd138511aac0191b13fed9716f1e0": {
        "datetime": "2013-09-16T17:22:32-07:00",
        "summary": "accidentally deleted a space",
        "message": "accidentally deleted a space\n",
        "diff": {
            "parquet-hadoop/src/main/java/parquet/hadoop/ParquetOutputFormat.java": [
                1,
                1
            ]
        }
    },
    "b11e2a005014ecd827855dde9ce4d50b1f58aa4b": {
        "datetime": "2013-09-16T19:02:18-07:00",
        "summary": "Plumb type_length for FIXED types through to reading pages.",
        "message": "Plumb type_length for FIXED types through to reading pages.\n",
        "diff": {
            "parquet-avro/src/main/java/parquet/avro/AvroParquetReader.java": [
                1,
                1
            ],
            "parquet-avro/src/main/java/parquet/avro/AvroReadSupport.java": [
                0,
                1
            ],
            "parquet-avro/src/main/java/parquet/avro/AvroSchemaConverter.java": [
                1,
                1
            ],
            "parquet-avro/src/test/java/parquet/avro/TestReadWrite.java": [
                0,
                4
            ],
            "parquet-column/src/main/java/parquet/column/ColumnDescriptor.java": [
                6,
                1
            ],
            "parquet-column/src/main/java/parquet/column/Encoding.java": [
                0,
                6
            ],
            "parquet-column/src/main/java/parquet/column/impl/ColumnReaderImpl.java": [
                1,
                18
            ],
            "parquet-column/src/main/java/parquet/column/values/ValuesWriter.java": [
                0,
                7
            ],
            "parquet-column/src/main/java/parquet/column/values/plain/FixedLenByteArrayPlainValuesReader.java": [
                0,
                59
            ],
            "parquet-column/src/main/java/parquet/column/values/plain/PlainValuesWriter.java": [
                0,
                10
            ],
            "parquet-column/src/main/java/parquet/io/PrimitiveColumnIO.java": [
                1,
                8
            ],
            "parquet-column/src/main/java/parquet/schema/MessageType.java": [
                3,
                10
            ],
            "parquet-column/src/main/java/parquet/schema/PrimitiveType.java": [
                5,
                21
            ],
            "parquet-hadoop/src/main/java/parquet/format/converter/ParquetMetadataConverter.java": [
                7,
                15
            ]
        }
    },
    "4e82ab632d39b236d302ff4283cae0a94f7cdbc0": {
        "datetime": "2013-09-17T03:59:46-07:00",
        "summary": "Add methods to write fixed Binary without prepending length.",
        "message": "Add methods to write fixed Binary without prepending length.\n",
        "diff": {
            "parquet-avro/src/main/java/parquet/avro/AvroWriteSupport.java": [
                1,
                1
            ],
            "parquet-column/src/main/java/parquet/column/ColumnWriter.java": [
                0,
                8
            ],
            "parquet-column/src/main/java/parquet/column/impl/ColumnWriterImpl.java": [
                0,
                9
            ],
            "parquet-column/src/main/java/parquet/io/MessageColumnIO.java": [
                0,
                10
            ],
            "parquet-column/src/main/java/parquet/io/RecordConsumerLoggingWrapper.java": [
                0,
                9
            ],
            "parquet-column/src/main/java/parquet/io/ValidatingRecordConsumer.java": [
                0,
                8
            ],
            "parquet-column/src/main/java/parquet/io/api/PrimitiveConverter.java": [
                0,
                7
            ],
            "parquet-column/src/main/java/parquet/io/api/RecordConsumer.java": [
                0,
                6
            ],
            "parquet-column/src/test/java/parquet/io/ConverterConsumer.java": [
                0,
                5
            ],
            "parquet-column/src/test/java/parquet/io/ExpectationValidatingRecordConsumer.java": [
                0,
                5
            ],
            "parquet-column/src/test/java/parquet/io/TestColumnIO.java": [
                0,
                5
            ]
        }
    },
    "1f630137267fed0b81871bd8eb0b315a6f009a35": {
        "datetime": "2013-09-17T09:42:02-07:00",
        "summary": "Added two boolean options for record filters.",
        "message": "Added two boolean options for record filters.\n",
        "diff": {
            "parquet-column/src/main/java/parquet/filter/NotRecordFilter.java": [
                0,
                55
            ],
            "parquet-column/src/main/java/parquet/filter/OrRecordFilter.java": [
                0,
                59
            ]
        }
    },
    "58051d0629121332a8f96e00d2e9603583cbd564": {
        "datetime": "2013-09-17T10:17:51-07:00",
        "summary": "Added functionality to allow users to implement functions to be used as predicates.",
        "message": "Added functionality to allow users to implement functions to be used as predicates.\n",
        "diff": {
            "parquet-column/src/main/java/parquet/filter/ColumnPredicates.java": [
                1,
                58
            ]
        }
    },
    "232d521dc0860e0e657970d5bbab241d7a58d283": {
        "datetime": "2013-09-17T11:00:59-07:00",
        "summary": "use class.getName",
        "message": "use class.getName\n",
        "diff": {
            "parquet-scrooge/src/test/java/parquet/scrooge/ParquetScroogeSchemeTest.java": [
                1,
                1
            ]
        }
    },
    "038a40022a2184cb2c406d3bf6773bcdbb8db0e8": {
        "datetime": "2013-09-17T11:04:10-07:00",
        "summary": "update scrooge to 3.8.0",
        "message": "update scrooge to 3.8.0\n",
        "diff": {
            "parquet-scrooge/pom.xml": null
        }
    },
    "0f9e39b7fc3743ed641c9c28dbc0f0f26493f476": {
        "datetime": "2013-09-17T13:47:52-07:00",
        "summary": "Merge pull request #165 from Parquet/distinguish_recoverable_exception",
        "message": "Merge pull request #165 from Parquet/distinguish_recoverable_exception\n\ndistinguish recoverable errors",
        "diff": {
            "parquet-thrift/src/main/java/parquet/thrift/BufferedProtocolReadToWrite.java": [
                9,
                12
            ],
            "parquet-thrift/src/main/java/parquet/thrift/SkippableException.java": [
                0,
                32
            ],
            "parquet-thrift/src/test/java/parquet/thrift/TestProtocolReadToWrite.java": [
                2,
                2
            ]
        }
    },
    "f8ac0f01deb15cf7b54ec9355dd57f6b96471b0d": {
        "datetime": "2013-09-17T14:41:09-07:00",
        "summary": "Initial end-to-end write and read support for Avro FIXED fields without runtime exceptions, but still with data representation issues.",
        "message": "Initial end-to-end write and read support for Avro FIXED fields without runtime exceptions, but still with data representation issues.\n",
        "diff": {
            "parquet-avro/src/main/java/parquet/avro/AvroIndexedRecordConverter.java": [
                2,
                1
            ],
            "parquet-column/src/main/java/parquet/column/Encoding.java": [
                2,
                2
            ],
            "parquet-column/src/main/java/parquet/column/impl/ColumnReaderImpl.java": [
                2,
                1
            ],
            "parquet-column/src/main/java/parquet/column/values/plain/FixedLenByteArrayPlainValuesReader.java": [
                1,
                4
            ]
        }
    },
    "4f1493b0aa663111871404b026064ea35a5234e2": {
        "datetime": "2013-09-17T18:04:30-07:00",
        "summary": "Fix broken tests. Test failures encountered previously were due to broken tests.",
        "message": "Fix broken tests. Test failures encountered previously were due to broken tests.\n",
        "diff": {
            "parquet-avro/src/test/java/parquet/avro/TestAvroSchemaConverter.java": [
                0,
                3
            ],
            "parquet-avro/src/test/java/parquet/avro/TestReadWrite.java": [
                10,
                11
            ]
        }
    },
    "08b45b0c1c5a8b7766544ba01dd9861d8b0fbfb4": {
        "datetime": "2013-09-18T03:14:08-07:00",
        "summary": "Add fixed_len_byte_array to oneOfEach in TestColumnIO.",
        "message": "Add fixed_len_byte_array to oneOfEach in TestColumnIO.\n",
        "diff": {
            "parquet-column/src/test/java/parquet/io/TestColumnIO.java": [
                13,
                9
            ]
        }
    },
    "201d80c57a711c232539732df1c109f045ec09a1": {
        "datetime": "2013-09-18T03:14:23-07:00",
        "summary": "Merge branch 'fixed_len_byte_array' of https://github.com/davidzchen/parquet-mr into fixed_len_byte_array",
        "message": "Merge branch 'fixed_len_byte_array' of https://github.com/davidzchen/parquet-mr into fixed_len_byte_array\n",
        "diff": {
            "parquet-avro/src/main/java/parquet/avro/AvroIndexedRecordConverter.java": [
                2,
                1
            ],
            "parquet-avro/src/test/java/parquet/avro/TestAvroSchemaConverter.java": [
                0,
                3
            ],
            "parquet-avro/src/test/java/parquet/avro/TestReadWrite.java": [
                10,
                11
            ],
            "parquet-column/src/main/java/parquet/column/Encoding.java": [
                2,
                2
            ],
            "parquet-column/src/main/java/parquet/column/impl/ColumnReaderImpl.java": [
                2,
                1
            ],
            "parquet-column/src/main/java/parquet/column/values/plain/FixedLenByteArrayPlainValuesReader.java": [
                1,
                4
            ]
        }
    },
    "e8c2a399a79cfd2905dd8d8e7c0e58bec68ece7b": {
        "datetime": "2013-09-18T10:02:16-07:00",
        "summary": "better log messages",
        "message": "better log messages\n",
        "diff": {
            "parquet-hadoop/src/main/java/parquet/hadoop/InternalParquetRecordWriter.java": [
                3,
                4
            ]
        }
    },
    "562e8111552be8fbbe701c02dddfa3a3496a5f47": {
        "datetime": "2013-09-18T11:13:39-07:00",
        "summary": "make binary dictionary encoding use fastutils; fix tests",
        "message": "make binary dictionary encoding use fastutils; fix tests\n",
        "diff": {
            "parquet-column/src/main/java/parquet/column/values/dictionary/DictionaryValuesWriter.java": [
                7,
                8
            ],
            "parquet-column/src/test/java/parquet/column/values/dictionary/TestDictionary.java": [
                365,
                94
            ]
        }
    },
    "f98cd399f6c1f416835814fb17ec6a3d3080a389": {
        "datetime": "2013-09-18T11:24:38-07:00",
        "summary": "shade fastutil and keep only used classes",
        "message": "shade fastutil and keep only used classes\n",
        "diff": {
            "parquet-column/pom.xml": null
        }
    },
    "1c9c19cf08dc6aae5e82dc96a6b945f0b140eec3": {
        "datetime": "2013-09-18T14:12:38-07:00",
        "summary": "Merge pull request #171 from Parquet/scrooge_tests",
        "message": "Merge pull request #171 from Parquet/scrooge_tests\n\nupdate scrooge denepdency, add unit tests for reading in scrooge",
        "diff": {
            "parquet-scrooge/pom.xml": null,
            "parquet-scrooge/src/test/java/parquet/scrooge/ParquetScroogeSchemeTest.java": [
                0,
                93
            ],
            "parquet-scrooge/src/test/thrift/test.thrift": null
        }
    },
    "bce04ebcb32180813bd1de7d300c1fc79a9fccb8": {
        "datetime": "2013-09-18T16:20:11-07:00",
        "summary": "add 1.2.0 and 1.2.1",
        "message": "add 1.2.0 and 1.2.1",
        "diff": {
            "CHANGES.md": null
        }
    },
    "8305bdb1937a24bc7e778ec497ceafb8b883be42": {
        "datetime": "2013-09-19T03:01:24-07:00",
        "summary": "Add FixedBinary type by creating a wrapper class around Binary and plumb FixedBinary through for read and write support for FIXED_LEN_BYTE_ARRAY. Undo change to add FIXED field to oneOfEach schema for parquet-column TestColumnIO for now.",
        "message": "Add FixedBinary type by creating a wrapper class around Binary and plumb FixedBinary through for read and write support for FIXED_LEN_BYTE_ARRAY. Undo change to add FIXED field to oneOfEach schema for parquet-column TestColumnIO for now.\n",
        "diff": {
            "parquet-avro/src/main/java/parquet/avro/AvroIndexedRecordConverter.java": [
                1,
                2
            ],
            "parquet-avro/src/main/java/parquet/avro/AvroWriteSupport.java": [
                1,
                3
            ],
            "parquet-column/src/main/java/parquet/column/ColumnReader.java": [
                0,
                6
            ],
            "parquet-column/src/main/java/parquet/column/ColumnWriter.java": [
                1,
                2
            ],
            "parquet-column/src/main/java/parquet/column/impl/ColumnReaderImpl.java": [
                4,
                22
            ],
            "parquet-column/src/main/java/parquet/column/impl/ColumnWriterImpl.java": [
                1,
                2
            ],
            "parquet-column/src/main/java/parquet/column/values/ValuesReader.java": [
                0,
                8
            ],
            "parquet-column/src/main/java/parquet/column/values/ValuesWriter.java": [
                1,
                2
            ],
            "parquet-column/src/main/java/parquet/column/values/plain/FixedLenByteArrayPlainValuesReader.java": [
                4,
                4
            ],
            "parquet-column/src/main/java/parquet/column/values/plain/PlainValuesWriter.java": [
                1,
                2
            ],
            "parquet-column/src/main/java/parquet/io/MessageColumnIO.java": [
                2,
                3
            ],
            "parquet-column/src/main/java/parquet/io/RecordConsumerLoggingWrapper.java": [
                1,
                2
            ],
            "parquet-column/src/main/java/parquet/io/ValidatingRecordConsumer.java": [
                1,
                2
            ],
            "parquet-column/src/main/java/parquet/io/api/Binary.java": [
                1,
                0
            ],
            "parquet-column/src/main/java/parquet/io/api/FixedBinary.java": [
                0,
                117
            ],
            "parquet-column/src/main/java/parquet/io/api/PrimitiveConverter.java": [
                1,
                1
            ],
            "parquet-column/src/main/java/parquet/io/api/RecordConsumer.java": [
                1,
                1
            ],
            "parquet-column/src/test/java/parquet/io/ConverterConsumer.java": [
                1,
                2
            ],
            "parquet-column/src/test/java/parquet/io/ExpectationValidatingRecordConsumer.java": [
                1,
                2
            ],
            "parquet-column/src/test/java/parquet/io/TestColumnIO.java": [
                4,
                3
            ]
        }
    },
    "a48f56f85ab758796ba072b8140fed6f712dd8fb": {
        "datetime": "2013-09-19T06:23:53-07:00",
        "summary": "Re-add FIXED_LEN_BYTE_ARRAY to oneOfEach and plumb through FIXED support for example Group. Test still fails and need to solve read issues.",
        "message": "Re-add FIXED_LEN_BYTE_ARRAY to oneOfEach and plumb through FIXED support for example Group. Test still fails and need to solve read issues.\n",
        "diff": {
            "parquet-column/src/main/java/parquet/example/data/Group.java": [
                0,
                12
            ],
            "parquet-column/src/main/java/parquet/example/data/GroupValueSource.java": [
                0,
                7
            ],
            "parquet-column/src/main/java/parquet/example/data/simple/FixedBinaryValue.java": [
                0,
                48
            ],
            "parquet-column/src/main/java/parquet/example/data/simple/Primitive.java": [
                0,
                5
            ],
            "parquet-column/src/main/java/parquet/example/data/simple/SimpleGroup.java": [
                1,
                11
            ],
            "parquet-column/src/main/java/parquet/example/data/simple/convert/SimplePrimitiveConverter.java": [
                4,
                13
            ],
            "parquet-column/src/main/java/parquet/io/ValidatingRecordConsumer.java": [
                1,
                1
            ],
            "parquet-column/src/test/java/parquet/io/TestColumnIO.java": [
                7,
                14
            ]
        }
    },
    "1c99a117f1d4860891d4ad04242cf71581ef7137": {
        "datetime": "2013-09-19T11:02:51-07:00",
        "summary": "rename variables for readability",
        "message": "rename variables for readability\n",
        "diff": {
            "parquet-column/src/main/java/parquet/io/RecordReaderImplementation.java": [
                36,
                39
            ]
        }
    },
    "108509fc30a01c1e52a9a02f44a00f5be1398622": {
        "datetime": "2013-09-19T11:13:40-07:00",
        "summary": "Merge pull request #173 from Parquet/better_log_messages",
        "message": "Merge pull request #173 from Parquet/better_log_messages\n\nbetter log messages",
        "diff": {
            "parquet-hadoop/src/main/java/parquet/hadoop/InternalParquetRecordWriter.java": [
                3,
                4
            ]
        }
    },
    "bbf34480888124fd875150e15ac4064067675600": {
        "datetime": "2013-09-19T13:14:48-05:00",
        "summary": "add overloaded getFooConfiguration(JobContext) methods to ParquetOutputFormat",
        "message": "add overloaded getFooConfiguration(JobContext) methods to ParquetOutputFormat\n",
        "diff": {
            "parquet-hadoop/src/main/java/parquet/hadoop/ParquetOutputFormat.java": [
                0,
                29
            ]
        }
    },
    "310e55170d1cea2846fcdc5ecd56c394b70c799c": {
        "datetime": "2013-09-19T13:16:14-05:00",
        "summary": "throw the writeSupportClass as part of the exception message if instantiation fails",
        "message": "throw the writeSupportClass as part of the exception message if instantiation fails\n",
        "diff": {
            "parquet-hadoop/src/main/java/parquet/hadoop/ParquetOutputFormat.java": [
                3,
                4
            ]
        }
    },
    "20f3f46cbd9c6fe3e162690802a6696a64ca7232": {
        "datetime": "2013-09-19T11:21:01-07:00",
        "summary": "continue renaming",
        "message": "continue renaming\n",
        "diff": {
            "parquet-column/src/main/java/parquet/io/RecordReaderImplementation.java": [
                20,
                20
            ]
        }
    },
    "6da759455251c47813202cfac29056a8e3f6e834": {
        "datetime": "2013-09-19T17:07:14-07:00",
        "summary": "fix problem with projection pushdown in parquetloader",
        "message": "fix problem with projection pushdown in parquetloader\n",
        "diff": {
            "parquet-pig/src/main/java/parquet/pig/ParquetLoader.java": [
                14,
                43
            ],
            "parquet-pig/src/main/java/parquet/pig/PigSchemaConverter.java": [
                1,
                1
            ],
            "parquet-pig/src/test/java/parquet/pig/TestParquetLoader.java": [
                1,
                67
            ]
        }
    },
    "cc59cb82675499870e9b0433c350f01a3522c2c9": {
        "datetime": "2013-09-19T17:54:27-07:00",
        "summary": "Use ValuesWriter and ValuesReader specific to FIXED_LEN_BYTE_ARRAY rather than overloading on a FixedBinary class.",
        "message": "Use ValuesWriter and ValuesReader specific to FIXED_LEN_BYTE_ARRAY rather than overloading on a FixedBinary class.\n",
        "diff": {
            "parquet-avro/src/main/java/parquet/avro/AvroIndexedRecordConverter.java": [
                2,
                1
            ],
            "parquet-avro/src/main/java/parquet/avro/AvroWriteSupport.java": [
                3,
                1
            ],
            "parquet-column/src/main/java/parquet/column/ColumnReader.java": [
                6,
                0
            ],
            "parquet-column/src/main/java/parquet/column/ColumnWriter.java": [
                9,
                0
            ],
            "parquet-column/src/main/java/parquet/column/Encoding.java": [
                3,
                0
            ],
            "parquet-column/src/main/java/parquet/column/impl/ColumnReaderImpl.java": [
                22,
                4
            ],
            "parquet-column/src/main/java/parquet/column/impl/ColumnWriterImpl.java": [
                10,
                4
            ],
            "parquet-column/src/main/java/parquet/column/values/ValuesReader.java": [
                8,
                0
            ],
            "parquet-column/src/main/java/parquet/column/values/ValuesWriter.java": [
                8,
                0
            ],
            "parquet-column/src/main/java/parquet/column/values/plain/FixedLenByteArrayPlainValuesReader.java": [
                3,
                3
            ],
            "parquet-column/src/main/java/parquet/column/values/plain/FixedLenByteArrayPlainValuesWriter.java": [
                0,
                90
            ],
            "parquet-column/src/main/java/parquet/column/values/plain/PlainValuesWriter.java": [
                12,
                0
            ],
            "parquet-column/src/main/java/parquet/example/data/Group.java": [
                12,
                0
            ],
            "parquet-column/src/main/java/parquet/example/data/GroupValueSource.java": [
                7,
                0
            ],
            "parquet-column/src/main/java/parquet/example/data/simple/FixedBinaryValue.java": [
                48,
                0
            ],
            "parquet-column/src/main/java/parquet/example/data/simple/Primitive.java": [
                5,
                0
            ],
            "parquet-column/src/main/java/parquet/example/data/simple/SimpleGroup.java": [
                11,
                0
            ],
            "parquet-column/src/main/java/parquet/example/data/simple/convert/SimplePrimitiveConverter.java": [
                10,
                0
            ],
            "parquet-column/src/main/java/parquet/io/MessageColumnIO.java": [
                11,
                0
            ],
            "parquet-column/src/main/java/parquet/io/RecordConsumerLoggingWrapper.java": [
                10,
                0
            ],
            "parquet-column/src/main/java/parquet/io/ValidatingRecordConsumer.java": [
                9,
                0
            ],
            "parquet-column/src/main/java/parquet/io/api/FixedBinary.java": [
                117,
                0
            ],
            "parquet-column/src/main/java/parquet/io/api/PrimitiveConverter.java": [
                7,
                0
            ],
            "parquet-column/src/main/java/parquet/io/api/RecordConsumer.java": [
                6,
                0
            ],
            "parquet-column/src/test/java/parquet/io/ConverterConsumer.java": [
                6,
                0
            ],
            "parquet-column/src/test/java/parquet/io/ExpectationValidatingRecordConsumer.java": [
                6,
                0
            ],
            "parquet-column/src/test/java/parquet/io/TestColumnIO.java": [
                9,
                1
            ]
        }
    },
    "3e02a841bb37f17d6218c23255e254db990846bd": {
        "datetime": "2013-09-19T18:30:51-07:00",
        "summary": "Merge branch 'master' into fixed_len_byte_array",
        "message": "Merge branch 'master' into fixed_len_byte_array\n",
        "diff": {
            "CHANGES.md": null,
            "parquet-hadoop/src/main/java/parquet/hadoop/InternalParquetRecordWriter.java": [
                3,
                4
            ],
            "parquet-scrooge/pom.xml": null,
            "parquet-scrooge/src/test/java/parquet/scrooge/ParquetScroogeSchemeTest.java": [
                0,
                93
            ],
            "parquet-scrooge/src/test/thrift/test.thrift": null,
            "parquet-thrift/src/main/java/parquet/thrift/BufferedProtocolReadToWrite.java": [
                9,
                12
            ],
            "parquet-thrift/src/main/java/parquet/thrift/SkippableException.java": [
                0,
                32
            ],
            "parquet-thrift/src/test/java/parquet/thrift/TestProtocolReadToWrite.java": [
                2,
                2
            ]
        }
    },
    "e37cd2b70fcc8471451f134e37d2b25a5b36464f": {
        "datetime": "2013-09-19T21:42:30-07:00",
        "summary": "Add fixed field to parquet-avro TestSpecificReadWrite.",
        "message": "Add fixed field to parquet-avro TestSpecificReadWrite.\n",
        "diff": {
            "parquet-avro/src/test/java/parquet/avro/TestSpecificReadWrite.java": [
                6,
                9
            ],
            "parquet-avro/src/test/resources/car.avdl": null
        }
    },
    "ebe07c6fb3f3ea3a50511fac4bd71ba683043b73": {
        "datetime": "2013-09-20T08:55:59-07:00",
        "summary": "changes as per code review comments",
        "message": "changes as per code review comments\n",
        "diff": {
            "parquet-pig/src/main/java/parquet/pig/ParquetLoader.java": [
                3,
                2
            ]
        }
    },
    "a73e73c8c0f5314aed0bc7f8ccd9454f461e28be": {
        "datetime": "2013-09-20T09:24:37-07:00",
        "summary": "changes as per code review comments for test",
        "message": "changes as per code review comments for test\n",
        "diff": {
            "parquet-pig/src/test/java/parquet/pig/TestParquetLoader.java": [
                3,
                1
            ]
        }
    },
    "469400156f8e85bad333f48730b9160cecba7df0": {
        "datetime": "2013-09-20T09:25:21-07:00",
        "summary": "Merge pull request #175 from Parquet/pig_projection_pushdown",
        "message": "Merge pull request #175 from Parquet/pig_projection_pushdown\n\nfix problem with projection pushdown in parquetloader",
        "diff": {
            "parquet-pig/src/main/java/parquet/pig/ParquetLoader.java": [
                15,
                43
            ],
            "parquet-pig/src/main/java/parquet/pig/PigSchemaConverter.java": [
                1,
                1
            ],
            "parquet-pig/src/test/java/parquet/pig/TestParquetLoader.java": [
                1,
                65
            ]
        }
    },
    "51d33328b3d6b503d1366b7a683b5a4520d814d2": {
        "datetime": "2013-09-20T09:38:22-07:00",
        "summary": "Merge pull request #174 from Parquet/readability",
        "message": "Merge pull request #174 from Parquet/readability\n\nrename variables for readability",
        "diff": {
            "parquet-column/src/main/java/parquet/io/RecordReaderImplementation.java": [
                42,
                45
            ]
        }
    },
    "b7a39c54915e9e5b72056439bd7c2f88363d1881": {
        "datetime": "2013-09-20T11:33:21-07:00",
        "summary": "[maven-release-plugin] prepare release parquet-1.2.2",
        "message": "[maven-release-plugin] prepare release parquet-1.2.2\n",
        "diff": {
            "parquet-avro/pom.xml": null,
            "parquet-cascading/pom.xml": null,
            "parquet-column/pom.xml": null,
            "parquet-common/pom.xml": null,
            "parquet-encoding/pom.xml": null,
            "parquet-generator/pom.xml": null,
            "parquet-hadoop/pom.xml": null,
            "parquet-hive/pom.xml": null,
            "parquet-pig/pom.xml": null,
            "parquet-scrooge/pom.xml": null,
            "parquet-test-hadoop2/pom.xml": null,
            "parquet-thrift/pom.xml": null,
            "pom.xml": null
        }
    },
    "0688404494696eb59ad8598326edbfa648f60436": {
        "datetime": "2013-09-20T11:33:25-07:00",
        "summary": "[maven-release-plugin] prepare for next development iteration",
        "message": "[maven-release-plugin] prepare for next development iteration\n",
        "diff": {
            "parquet-avro/pom.xml": null,
            "parquet-cascading/pom.xml": null,
            "parquet-column/pom.xml": null,
            "parquet-common/pom.xml": null,
            "parquet-encoding/pom.xml": null,
            "parquet-generator/pom.xml": null,
            "parquet-hadoop/pom.xml": null,
            "parquet-hive/pom.xml": null,
            "parquet-pig/pom.xml": null,
            "parquet-scrooge/pom.xml": null,
            "parquet-test-hadoop2/pom.xml": null,
            "parquet-thrift/pom.xml": null,
            "pom.xml": null
        }
    },
    "3b5d32bcab01886a5a4b3c1378809fc5af9cc434": {
        "datetime": "2013-09-20T12:35:12-07:00",
        "summary": "Add new Vin field to Avro TestSpecificInputOutputFormat.",
        "message": "Add new Vin field to Avro TestSpecificInputOutputFormat.\n",
        "diff": {
            "parquet-avro/src/test/java/parquet/avro/TestSpecificInputOutputFormat.java": [
                0,
                2
            ]
        }
    },
    "e6ebda9524f909072548b0da0903f0cc6415603c": {
        "datetime": "2013-09-20T14:06:12-07:00",
        "summary": "Update CHANGES.md",
        "message": "Update CHANGES.md",
        "diff": {
            "CHANGES.md": null
        }
    },
    "bc31bdab2d85ea7bff3d76ea57da5f9b067f5baf": {
        "datetime": "2013-09-20T14:06:33-07:00",
        "summary": "Update CHANGES.md",
        "message": "Update CHANGES.md",
        "diff": {
            "CHANGES.md": null
        }
    },
    "e6fab0681a31aa60af07136aba65b3e69c8f45e3": {
        "datetime": "2013-09-20T17:33:37-07:00",
        "summary": "Document why FIXED_LEN_BYTE_ARRAY is not supported with Avro specific schema right now.",
        "message": "Document why FIXED_LEN_BYTE_ARRAY is not supported with Avro specific schema right now.\n",
        "diff": {
            "parquet-avro/src/main/java/parquet/avro/AvroIndexedRecordConverter.java": [
                0,
                6
            ],
            "parquet-avro/src/test/java/parquet/avro/TestSpecificInputOutputFormat.java": [
                2,
                2
            ],
            "parquet-avro/src/test/java/parquet/avro/TestSpecificReadWrite.java": [
                27,
                25
            ],
            "parquet-avro/src/test/resources/car.avdl": null
        }
    },
    "e242085ac3f79d377ed62fd2620fbeaf9a61c969": {
        "datetime": "2013-09-20T21:54:38-05:00",
        "summary": "add an empty constructor for ParquetTBaseScheme (which only works for reads)",
        "message": "add an empty constructor for ParquetTBaseScheme (which only works for reads)\n",
        "diff": {
            "parquet-cascading/src/main/java/parquet/cascading/ParquetTBaseScheme.java": [
                1,
                15
            ]
        }
    },
    "3105009fe85cb78922e9f70ac52297cccc9101c9": {
        "datetime": "2013-09-20T22:55:47-05:00",
        "summary": "add read and write tests for ParquetTBaseScheme",
        "message": "add read and write tests for ParquetTBaseScheme\n",
        "diff": {
            "parquet-cascading/pom.xml": null,
            "parquet-cascading/src/test/java/parquet/cascading/TestParquetTBaseScheme.java": [
                5,
                148
            ]
        }
    },
    "458dd70f1820f5bac10bda10f9b47cb14d31246f": {
        "datetime": "2013-09-20T22:55:59-05:00",
        "summary": "remove redundant test",
        "message": "remove redundant test\n",
        "diff": {
            "parquet-cascading/src/test/java/parquet/cascading/TestParquetTBaseScheme.java": [
                39,
                0
            ]
        }
    },
    "3b7359b347edb1d3ed780e7872f6bdf3efc2e2c7": {
        "datetime": "2013-09-22T22:29:30-07:00",
        "summary": "Re-enable tests for writing FIXED for Avro Specific records. Preliminary end-to-end for writing FIXED but write is still not completely correct yet.",
        "message": "Re-enable tests for writing FIXED for Avro Specific records. Preliminary end-to-end for writing FIXED but write is still not completely correct yet.\n",
        "diff": {
            "parquet-avro/src/main/java/parquet/avro/AvroIndexedRecordConverter.java": [
                7,
                5
            ],
            "parquet-avro/src/test/java/parquet/avro/TestSpecificInputOutputFormat.java": [
                2,
                2
            ],
            "parquet-avro/src/test/java/parquet/avro/TestSpecificReadWrite.java": [
                6,
                6
            ],
            "parquet-avro/src/test/resources/car.avdl": null
        }
    },
    "8e4278b4c11e333b853120b1a2df860be006ecdc": {
        "datetime": "2013-09-22T23:47:53-07:00",
        "summary": "missing test resources",
        "message": "missing test resources\n",
        "diff": {
            "parquet-cascading/src/test/resources/names.txt": null,
            "parquet-cascading/src/test/thrift/test.thrift": null
        }
    },
    "1b326b7fee6616cb63016dbce2a07daf2b0213b1": {
        "datetime": "2013-09-23T04:29:01-07:00",
        "summary": "Fix reflection for converting fixed Binary to Avro SpecificFixed. Ensure that FIXED values are written using the FLBA PlainValuesReader when dictionary is enabled.",
        "message": "Fix reflection for converting fixed Binary to Avro SpecificFixed. Ensure that FIXED values are written using the FLBA PlainValuesReader when dictionary is enabled.\n",
        "diff": {
            "parquet-avro/src/main/java/parquet/avro/AvroIndexedRecordConverter.java": [
                2,
                13
            ],
            "parquet-avro/src/main/java/parquet/avro/AvroReadSupport.java": [
                1,
                0
            ],
            "parquet-avro/src/main/java/parquet/avro/AvroWriteSupport.java": [
                0,
                1
            ],
            "parquet-avro/src/test/java/parquet/avro/TestSpecificInputOutputFormat.java": [
                0,
                2
            ],
            "parquet-avro/src/test/java/parquet/avro/TestSpecificReadWrite.java": [
                8,
                4
            ],
            "parquet-column/src/main/java/parquet/column/impl/ColumnWriterImpl.java": [
                0,
                3
            ]
        }
    },
    "12d41ac61f6d3a18c9f00634cc3fde0a7a295cf9": {
        "datetime": "2013-09-23T04:36:34-07:00",
        "summary": "De-fluffify inadvertently added whitespace changes.",
        "message": "De-fluffify inadvertently added whitespace changes.\n",
        "diff": {
            "parquet-avro/src/main/java/parquet/avro/AvroWriteSupport.java": [
                1,
                1
            ],
            "parquet-column/src/main/java/parquet/column/ColumnWriter.java": [
                1,
                2
            ],
            "parquet-column/src/main/java/parquet/column/values/ValuesReader.java": [
                1,
                2
            ],
            "parquet-column/src/main/java/parquet/column/values/plain/PlainValuesWriter.java": [
                0,
                1
            ],
            "parquet-column/src/main/java/parquet/example/data/simple/SimpleGroup.java": [
                0,
                1
            ],
            "parquet-column/src/main/java/parquet/io/MessageColumnIO.java": [
                1,
                1
            ],
            "parquet-column/src/main/java/parquet/io/api/Binary.java": [
                0,
                1
            ],
            "parquet-column/src/main/java/parquet/io/api/PrimitiveConverter.java": [
                1,
                1
            ],
            "parquet-column/src/test/java/parquet/io/ExpectationValidatingRecordConsumer.java": [
                0,
                1
            ]
        }
    },
    "e31d46c428a332d7aec53f35029a5774d039676d": {
        "datetime": "2013-09-24T17:45:58-07:00",
        "summary": "merge master",
        "message": "merge master\n",
        "diff": {
            "CHANGES.md": null,
            "parquet-avro/pom.xml": null,
            "parquet-cascading/pom.xml": null,
            "parquet-column/pom.xml": null,
            "parquet-column/src/main/java/parquet/io/RecordReaderImplementation.java": [
                42,
                45
            ],
            "parquet-common/pom.xml": null,
            "parquet-encoding/pom.xml": null,
            "parquet-generator/pom.xml": null,
            "parquet-hadoop/pom.xml": null,
            "parquet-hadoop/src/main/java/parquet/hadoop/InternalParquetRecordWriter.java": [
                3,
                4
            ],
            "parquet-hive/pom.xml": null,
            "parquet-pig/pom.xml": null,
            "parquet-pig/src/main/java/parquet/pig/ParquetLoader.java": [
                15,
                43
            ],
            "parquet-pig/src/main/java/parquet/pig/PigSchemaConverter.java": [
                1,
                1
            ],
            "parquet-pig/src/test/java/parquet/pig/TestParquetLoader.java": [
                1,
                65
            ],
            "parquet-scrooge/pom.xml": null,
            "parquet-scrooge/src/test/java/parquet/scrooge/ParquetScroogeSchemeTest.java": [
                1,
                1
            ],
            "parquet-scrooge/src/test/thrift/test.thrift": null,
            "parquet-test-hadoop2/pom.xml": null,
            "parquet-thrift/pom.xml": null,
            "parquet-thrift/src/main/java/parquet/thrift/BufferedProtocolReadToWrite.java": [
                9,
                12
            ],
            "parquet-thrift/src/main/java/parquet/thrift/SkippableException.java": [
                0,
                32
            ],
            "parquet-thrift/src/test/java/parquet/thrift/TestProtocolReadToWrite.java": [
                2,
                2
            ],
            "pom.xml": null
        }
    },
    "a79eab750d002eb91efbe4cc02abb009b9db1ee9": {
        "datetime": "2013-09-25T03:58:39-07:00",
        "summary": "Complete support for supporting FIXED_LEN_BYTE_ARRAY for Avro SpecificRecord. Add syntax to specify type length for FLBA type fields to MessageTypeParser.",
        "message": "Complete support for supporting FIXED_LEN_BYTE_ARRAY for Avro SpecificRecord. Add syntax to specify type length for FLBA type fields to MessageTypeParser.\n",
        "diff": {
            "parquet-avro/src/test/java/parquet/avro/TestAvroSchemaConverter.java": [
                8,
                7
            ],
            "parquet-column/src/main/java/parquet/schema/MessageTypeParser.java": [
                1,
                11
            ],
            "parquet-column/src/main/java/parquet/schema/PrimitiveType.java": [
                15,
                17
            ]
        }
    },
    "24d72673d1ae3cba9cf90312550b32f954e343ec": {
        "datetime": "2013-09-25T04:08:39-07:00",
        "summary": "Remove print statements.",
        "message": "Remove print statements.\n",
        "diff": {
            "parquet-avro/src/main/java/parquet/avro/AvroIndexedRecordConverter.java": [
                1,
                0
            ],
            "parquet-column/src/main/java/parquet/column/impl/ColumnWriterImpl.java": [
                1,
                0
            ],
            "parquet-column/src/main/java/parquet/io/api/RecordConsumer.java": [
                1,
                1
            ],
            "parquet-hadoop/src/main/java/parquet/format/converter/ParquetMetadataConverter.java": [
                7,
                0
            ]
        }
    },
    "976c68acb31b590bb8b2b509da05164b23c529ad": {
        "datetime": "2013-09-25T04:25:15-07:00",
        "summary": "Merge branch 'master' into fixed_len_byte_array",
        "message": "Merge branch 'master' into fixed_len_byte_array\n",
        "diff": {
            "CHANGES.md": null,
            "parquet-avro/pom.xml": null,
            "parquet-cascading/pom.xml": null,
            "parquet-column/pom.xml": null,
            "parquet-column/src/main/java/parquet/io/RecordReaderImplementation.java": [
                42,
                45
            ],
            "parquet-common/pom.xml": null,
            "parquet-encoding/pom.xml": null,
            "parquet-generator/pom.xml": null,
            "parquet-hadoop/pom.xml": null,
            "parquet-hive/pom.xml": null,
            "parquet-pig/pom.xml": null,
            "parquet-pig/src/main/java/parquet/pig/ParquetLoader.java": [
                15,
                43
            ],
            "parquet-pig/src/main/java/parquet/pig/PigSchemaConverter.java": [
                1,
                1
            ],
            "parquet-pig/src/test/java/parquet/pig/TestParquetLoader.java": [
                1,
                65
            ],
            "parquet-scrooge/pom.xml": null,
            "parquet-test-hadoop2/pom.xml": null,
            "parquet-thrift/pom.xml": null,
            "pom.xml": null
        }
    },
    "5e0dba75cb58e6cecf6b5aeafb4f32cd19600aec": {
        "datetime": "2013-09-25T09:05:15-07:00",
        "summary": "upgrade scrooge to 3.9",
        "message": "upgrade scrooge to 3.9\n",
        "diff": {
            "parquet-scrooge/pom.xml": null
        }
    },
    "ca7da658ca18ef6775557ebba9776ece5a21554f": {
        "datetime": "2013-09-25T14:04:49-07:00",
        "summary": "basic support for map",
        "message": "basic support for map\n",
        "diff": {
            "parquet-scrooge/src/main/java/parquet/scrooge/ScroogeSchemaConverter.java": [
                9,
                37
            ],
            "parquet-scrooge/src/test/java/parquet/scrooge/ScroogeSchemaConverterTest.java": [
                2,
                7
            ]
        }
    },
    "6a6613fc746bf409eff1372fa7d92cb556db9f44": {
        "datetime": "2013-09-25T14:11:32-07:00",
        "summary": "tests all primitive key types in map",
        "message": "tests all primitive key types in map\n",
        "diff": {
            "parquet-scrooge/src/test/java/parquet/scrooge/ScroogeSchemaConverterTest.java": [
                2,
                1
            ],
            "parquet-scrooge/src/test/thrift/test.thrift": null
        }
    },
    "49f3ad17a066dde80e9d7f84fc859a1afb791c02": {
        "datetime": "2013-09-25T14:21:58-07:00",
        "summary": "Add support for reading FIXED_LEN_BYTE_ARRAY to Pig support.",
        "message": "Add support for reading FIXED_LEN_BYTE_ARRAY to Pig support.\n",
        "diff": {
            "parquet-avro/src/test/java/parquet/avro/TestSpecificInputOutputFormat.java": [
                13,
                11
            ],
            "parquet-pig/src/main/java/parquet/pig/PigSchemaConverter.java": [
                90,
                109
            ],
            "parquet-pig/src/test/java/parquet/pig/TestParquetLoader.java": [
                1,
                4
            ],
            "parquet-pig/src/test/java/parquet/pig/TestPigSchemaConverter.java": [
                0,
                27
            ]
        }
    },
    "5ab6cccf9fcd280680f8ffdb74a17a5a71a327a7": {
        "datetime": "2013-09-25T14:33:27-07:00",
        "summary": "Merge pull request #169 from davidzchen/fix_avro_empty_maps_arrays",
        "message": "Merge pull request #169 from davidzchen/fix_avro_empty_maps_arrays\n\nSupport avro records with empty maps and arrays",
        "diff": {
            "parquet-avro/src/main/java/parquet/avro/AvroWriteSupport.java": [
                33,
                41
            ],
            "parquet-avro/src/test/java/parquet/avro/TestReadWrite.java": [
                1,
                64
            ],
            "parquet-avro/src/test/resources/all-minus-fixed.avsc": null,
            "parquet-avro/src/test/resources/array.avsc": null,
            "parquet-avro/src/test/resources/map.avsc": null
        }
    },
    "0822e32631e50c751f4b1a8b33111d6f2a50a56f": {
        "datetime": "2013-09-25T14:42:11-07:00",
        "summary": "add unit test for primitive value for maps",
        "message": "add unit test for primitive value for maps\n",
        "diff": {
            "parquet-scrooge/src/test/java/parquet/scrooge/ScroogeSchemaConverterTest.java": [
                3,
                11
            ],
            "parquet-scrooge/src/test/thrift/test.thrift": null
        }
    },
    "9cd67375d2d64eaf9e1ae4021885f9130881a325": {
        "datetime": "2013-09-25T14:46:37-07:00",
        "summary": "Add comments to new files.",
        "message": "Add comments to new files.\n",
        "diff": {
            "parquet-column/src/main/java/parquet/column/values/plain/FixedLenByteArrayPlainValuesReader.java": [
                0,
                5
            ],
            "parquet-column/src/main/java/parquet/column/values/plain/FixedLenByteArrayPlainValuesWriter.java": [
                0,
                5
            ]
        }
    },
    "d9ced33ef44c87b11b1bee0808de2e2362bd5323": {
        "datetime": "2013-09-25T15:03:39-07:00",
        "summary": "test optional map",
        "message": "test optional map\n",
        "diff": {
            "parquet-scrooge/src/test/java/parquet/scrooge/ScroogeSchemaConverterTest.java": [
                0,
                173
            ],
            "parquet-scrooge/src/test/thrift/test.thrift": null
        }
    },
    "f45b384e7d0d2d9d501f0dfd278c247dec31a369": {
        "datetime": "2013-09-25T16:40:24-07:00",
        "summary": "convert list and unit tests",
        "message": "convert list and unit tests\n",
        "diff": {
            "parquet-scrooge/src/main/java/parquet/scrooge/ScroogeSchemaConverter.java": [
                1,
                8
            ],
            "parquet-scrooge/src/test/java/parquet/scrooge/ScroogeSchemaConverterTest.java": [
                0,
                8
            ],
            "parquet-scrooge/src/test/thrift/test.thrift": null,
            "parquet-thrift/src/main/java/parquet/thrift/struct/ThriftField.java": [
                0,
                23
            ],
            "parquet-thrift/src/main/java/parquet/thrift/struct/ThriftType.java": [
                0,
                96
            ]
        }
    },
    "5410381c14187990675c62b6627eb0adcc45193c": {
        "datetime": "2013-09-25T16:47:19-07:00",
        "summary": "convert set and unit tests",
        "message": "convert set and unit tests\n",
        "diff": {
            "parquet-scrooge/src/main/java/parquet/scrooge/ScroogeSchemaConverter.java": [
                0,
                8
            ],
            "parquet-scrooge/src/test/java/parquet/scrooge/ScroogeSchemaConverterTest.java": [
                0,
                10
            ],
            "parquet-scrooge/src/test/thrift/test.thrift": null
        }
    },
    "d0fc6a0d16d89f903859f69be3d08666f2fa50ed": {
        "datetime": "2013-09-25T18:37:12-07:00",
        "summary": "Correct schema syntaxes for TestHiveSchemaConverter.",
        "message": "Correct schema syntaxes for TestHiveSchemaConverter.\n",
        "diff": {
            "parquet-hive/src/test/java/parquet/hive/TestHiveSchemaConverter.java": [
                3,
                2
            ]
        }
    },
    "6ffc1b9fe17309b409b54c7b053bf511768a29e4": {
        "datetime": "2013-09-26T09:20:35-07:00",
        "summary": "implemented conversion for enum",
        "message": "implemented conversion for enum\n",
        "diff": {
            "parquet-scrooge/src/main/java/parquet/scrooge/ScroogeSchemaConverter.java": [
                1,
                63
            ],
            "parquet-scrooge/src/test/java/parquet/scrooge/ScroogeSchemaConverterTest.java": [
                1,
                10
            ],
            "parquet-scrooge/src/test/thrift/test.thrift": null,
            "parquet-thrift/src/main/java/parquet/thrift/struct/ThriftType.java": [
                0,
                40
            ]
        }
    },
    "bfcb120889ce52409093536f24000d75da0594d3": {
        "datetime": "2013-09-26T10:17:51-07:00",
        "summary": "implemented map with nested structure, TODO: tests failing since the default requirement can not be determined",
        "message": "implemented map with nested structure, TODO: tests failing since the default requirement can not be determined\n",
        "diff": {
            "parquet-scrooge/src/main/java/parquet/scrooge/ScroogeSchemaConverter.java": [
                39,
                11
            ],
            "parquet-scrooge/src/test/java/parquet/scrooge/ScroogeSchemaConverterTest.java": [
                0,
                19
            ],
            "parquet-scrooge/src/test/thrift/test.thrift": null
        }
    },
    "835f12eae78c762322dd6b77481a5aca47637ec7": {
        "datetime": "2013-09-26T17:07:46-07:00",
        "summary": "refactor code",
        "message": "refactor code\n",
        "diff": {
            "parquet-scrooge/src/main/java/parquet/scrooge/EnumConverter.java": [
                0,
                44
            ],
            "parquet-scrooge/src/main/java/parquet/scrooge/ScroogeEnumDesc.java": [
                0,
                34
            ],
            "parquet-scrooge/src/main/java/parquet/scrooge/ScroogeSchemaConverter.java": [
                108,
                44
            ]
        }
    },
    "4b2cb26341eefb679cd599c75952509aa76af55a": {
        "datetime": "2013-09-26T18:07:08-07:00",
        "summary": "Added unit tests for predicates. Got predicates compiling, and passing on tests.",
        "message": "Added unit tests for predicates. Got predicates compiling, and passing on tests.\n",
        "diff": {
            "parquet-column/src/main/java/parquet/filter/ColumnPredicates.java": [
                16,
                16
            ],
            "parquet-column/src/main/java/parquet/filter/NotRecordFilter.java": [
                2,
                2
            ],
            "parquet-column/src/main/java/parquet/filter/OrRecordFilter.java": [
                1,
                1
            ],
            "parquet-column/src/test/java/parquet/io/TestFiltered.java": [
                0,
                38
            ]
        }
    },
    "1ee42327bbde2513edb48a22a207da36623d000d": {
        "datetime": "2013-09-27T06:14:29-07:00",
        "summary": "Merge changes from master that fix handling empty Avro arrays and maps.",
        "message": "Merge changes from master that fix handling empty Avro arrays and maps.\n",
        "diff": {
            "parquet-avro/src/main/java/parquet/avro/AvroWriteSupport.java": [
                33,
                41
            ],
            "parquet-avro/src/test/java/parquet/avro/TestAvroSchemaConverter.java": [
                0,
                9
            ],
            "parquet-avro/src/test/java/parquet/avro/TestReadWrite.java": [
                1,
                65
            ],
            "parquet-avro/src/test/resources/all.avsc": null,
            "parquet-avro/src/test/resources/array.avsc": null,
            "parquet-avro/src/test/resources/map.avsc": null
        }
    },
    "52c32a3a296892a4fa94a040f242313620518258": {
        "datetime": "2013-09-27T08:31:11-07:00",
        "summary": "Removing predicate functions to prepare for pushing or/not filters. Limits number of features pushed.",
        "message": "Removing predicate functions to prepare for pushing or/not filters. Limits number of features pushed.\n",
        "diff": {
            "parquet-column/src/main/java/parquet/filter/ColumnPredicates.java": [
                58,
                1
            ]
        }
    },
    "b49018bb7908610533a6d3f60140d884a891c3a9": {
        "datetime": "2013-09-27T08:42:02-07:00",
        "summary": "Merging in changes from main repository that I have forked from to minimize work after pull request.",
        "message": "Merging in changes from main repository that I have forked from to minimize work after pull request.\n",
        "diff": {
            "CHANGES.md": null,
            "parquet-avro/pom.xml": null,
            "parquet-avro/src/main/java/parquet/avro/AvroWriteSupport.java": [
                33,
                41
            ],
            "parquet-avro/src/test/java/parquet/avro/TestReadWrite.java": [
                1,
                64
            ],
            "parquet-avro/src/test/resources/all-minus-fixed.avsc": null,
            "parquet-avro/src/test/resources/array.avsc": null,
            "parquet-avro/src/test/resources/map.avsc": null,
            "parquet-cascading/pom.xml": null,
            "parquet-column/pom.xml": null,
            "parquet-column/src/main/java/parquet/io/RecordReaderImplementation.java": [
                42,
                45
            ],
            "parquet-common/pom.xml": null,
            "parquet-encoding/pom.xml": null,
            "parquet-generator/pom.xml": null,
            "parquet-hadoop/pom.xml": null,
            "parquet-hadoop/src/main/java/parquet/hadoop/InternalParquetRecordWriter.java": [
                3,
                4
            ],
            "parquet-hive/pom.xml": null,
            "parquet-pig/pom.xml": null,
            "parquet-pig/src/main/java/parquet/pig/ParquetLoader.java": [
                15,
                43
            ],
            "parquet-pig/src/main/java/parquet/pig/PigSchemaConverter.java": [
                1,
                1
            ],
            "parquet-pig/src/test/java/parquet/pig/TestParquetLoader.java": [
                1,
                65
            ],
            "parquet-scrooge/pom.xml": null,
            "parquet-scrooge/src/test/java/parquet/scrooge/ParquetScroogeSchemeTest.java": [
                0,
                93
            ],
            "parquet-scrooge/src/test/thrift/test.thrift": null,
            "parquet-test-hadoop2/pom.xml": null,
            "parquet-thrift/pom.xml": null,
            "parquet-thrift/src/main/java/parquet/thrift/BufferedProtocolReadToWrite.java": [
                9,
                12
            ],
            "parquet-thrift/src/main/java/parquet/thrift/SkippableException.java": [
                0,
                32
            ],
            "parquet-thrift/src/test/java/parquet/thrift/TestProtocolReadToWrite.java": [
                2,
                2
            ],
            "pom.xml": null
        }
    },
    "2c5e07f02fd8edbfcabfab5813e486f9a192ba6b": {
        "datetime": "2013-09-27T17:22:15-07:00",
        "summary": "Add support to AvroWriteSupport for writing out records with maps containing Utf8-type keys.",
        "message": "Add support to AvroWriteSupport for writing out records with maps containing Utf8-type keys.\n",
        "diff": {
            "parquet-avro/src/main/java/parquet/avro/AvroWriteSupport.java": [
                3,
                3
            ],
            "parquet-avro/src/test/java/parquet/avro/TestReadWrite.java": [
                0,
                28
            ]
        }
    },
    "3778e45fcc084f0559ea1d43deb36cf4c6a1527b": {
        "datetime": "2013-09-29T10:41:15-07:00",
        "summary": "Pulling in clean modifications for adding ColumnPredicate functions.",
        "message": "Pulling in clean modifications for adding ColumnPredicate functions.\n",
        "diff": {
            "parquet-column/src/main/java/parquet/filter/ColumnPredicates.java": [
                1,
                58
            ],
            "parquet-column/src/test/java/parquet/io/TestFiltered.java": [
                1,
                72
            ]
        }
    },
    "a2895bfe6ea0f3289739d63d3715b775108a607c": {
        "datetime": "2013-09-30T13:48:52-07:00",
        "summary": "Remove print statement.",
        "message": "Remove print statement.\n",
        "diff": {
            "parquet-avro/src/main/java/parquet/avro/AvroIndexedRecordConverter.java": [
                1,
                0
            ]
        }
    },
    "0ad94f9583d1ca47b39363510cf294396706f74d": {
        "datetime": "2013-10-01T13:58:16-05:00",
        "summary": "Fix a maven warning about a missing version number.",
        "message": "Fix a maven warning about a missing version number.\n\nThis change follows the POM structure seen in other modules by setting\nthe version to ${maven-jar-plugin.version}.\n",
        "diff": {
            "parquet-hive/pom.xml": null
        }
    },
    "6ec199d4333a5aea8db5777c3d35da36a922f93c": {
        "datetime": "2013-10-01T14:00:34-05:00",
        "summary": "Disable the time read counter check in DeprecatedInputFormatTest.",
        "message": "Disable the time read counter check in DeprecatedInputFormatTest.\n\nThis mirrors the commit 6dfd97551fc1b8606704dcf656b185b34ceffcd4\nwhich disabled the check in TestInputOutputFormat.\n",
        "diff": {
            "parquet-hadoop/src/test/java/parquet/hadoop/DeprecatedInputFormatTest.java": [
                1,
                1
            ]
        }
    },
    "7802a9ab00a81853cbc95e04a46cc2eb721046e2": {
        "datetime": "2013-10-01T14:04:04-05:00",
        "summary": "Update ParquetReader to take Configuration as a constructor argument.",
        "message": "Update ParquetReader to take Configuration as a constructor argument.\n\nThis enables schema projection for both AvroParquetReader and\nThriftParquetReader by allowing configuration of\nAVRO_REQUESTED_PROJECTION, THRIFT_COLUMN_FILTER_KEY, and\nPARQUET_READ_SCHEMA.\n",
        "diff": {
            "parquet-avro/src/main/java/parquet/avro/AvroParquetReader.java": [
                0,
                12
            ],
            "parquet-avro/src/test/java/parquet/avro/TestSpecificReadWrite.java": [
                0,
                47
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/ParquetReader.java": [
                1,
                22
            ],
            "parquet-thrift/src/main/java/parquet/thrift/ThriftParquetReader.java": [
                0,
                21
            ]
        }
    },
    "bb52d33b3ebcd2c4df30b790c82db17879c97e63": {
        "datetime": "2013-10-01T13:22:39-07:00",
        "summary": "Merge pull request #179 from fnothaft/master",
        "message": "Merge pull request #179 from fnothaft/master\n\nAdded Or/Not logical filters for column predicates",
        "diff": {
            "parquet-column/src/main/java/parquet/filter/NotRecordFilter.java": [
                0,
                55
            ],
            "parquet-column/src/main/java/parquet/filter/OrRecordFilter.java": [
                0,
                59
            ],
            "parquet-column/src/test/java/parquet/io/TestFiltered.java": [
                0,
                38
            ]
        }
    },
    "a258aae65d402560cabd2f0213327081b148f718": {
        "datetime": "2013-10-01T13:22:59-07:00",
        "summary": "Merge pull request #182 from wesleypeck/fix_maven_version",
        "message": "Merge pull request #182 from wesleypeck/fix_maven_version\n\nFix a maven warning about a missing version number.",
        "diff": {
            "parquet-hive/pom.xml": null
        }
    },
    "a146ebb1885f11a47c613d2be9001a545e659829": {
        "datetime": "2013-10-01T13:52:05-07:00",
        "summary": "Merge pull request #183 from wesleypeck/fix_timeread",
        "message": "Merge pull request #183 from wesleypeck/fix_timeread\n\nDisable the time read counter check in DeprecatedInputFormatTest.",
        "diff": {
            "parquet-hadoop/src/test/java/parquet/hadoop/DeprecatedInputFormatTest.java": [
                1,
                1
            ]
        }
    },
    "e20c490b6949bf1451c6da79472691d8b72a625c": {
        "datetime": "2013-10-01T13:53:56-07:00",
        "summary": "Merge pull request #184 from wesleypeck/parquet_reader_projection",
        "message": "Merge pull request #184 from wesleypeck/parquet_reader_projection\n\nUpdate ParquetReader to take Configuration as a constructor argument.",
        "diff": {
            "parquet-avro/src/main/java/parquet/avro/AvroParquetReader.java": [
                0,
                12
            ],
            "parquet-avro/src/test/java/parquet/avro/TestSpecificReadWrite.java": [
                0,
                47
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/ParquetReader.java": [
                1,
                22
            ],
            "parquet-thrift/src/main/java/parquet/thrift/ThriftParquetReader.java": [
                0,
                21
            ]
        }
    },
    "753473cdc63a4105e0f74cd8b747a1a705710dff": {
        "datetime": "2013-10-01T14:07:33-07:00",
        "summary": "Change syntax for fixed_len_byte_array to placing length parameter after type name rather after field name.",
        "message": "Change syntax for fixed_len_byte_array to placing length parameter after type name rather after field name.\n",
        "diff": {
            "parquet-avro/src/test/java/parquet/avro/TestAvroSchemaConverter.java": [
                1,
                1
            ],
            "parquet-column/src/main/java/parquet/schema/MessageTypeParser.java": [
                1,
                8
            ],
            "parquet-column/src/main/java/parquet/schema/PrimitiveType.java": [
                3,
                2
            ],
            "parquet-pig/src/test/java/parquet/pig/TestPigSchemaConverter.java": [
                2,
                2
            ]
        }
    },
    "9aad6416a4c7448727bcb71db739d7a1bc8a392f": {
        "datetime": "2013-10-01T14:42:44-07:00",
        "summary": "Move reflection checks for specific Avro Fixed type into FieldFixedConverter constructor.",
        "message": "Move reflection checks for specific Avro Fixed type into FieldFixedConverter constructor.\n",
        "diff": {
            "parquet-avro/src/main/java/parquet/avro/AvroIndexedRecordConverter.java": [
                3,
                18
            ]
        }
    },
    "a8d99d9be812e17e86cfad2a13966c754ce7c287": {
        "datetime": "2013-10-01T14:50:34-07:00",
        "summary": "add an assertion to check the output created by reading with ParquetTBaseScheme",
        "message": "add an assertion to check the output created by reading with ParquetTBaseScheme\n",
        "diff": {
            "parquet-cascading/src/test/java/parquet/cascading/TestParquetTBaseScheme.java": [
                0,
                5
            ]
        }
    },
    "2ffde6adbd5588d98838e3fd12ca8c4dcab3e367": {
        "datetime": "2013-10-01T16:55:01-07:00",
        "summary": "Merge pull request #172 from colinmarc/cascading-tbase-write-support",
        "message": "Merge pull request #172 from colinmarc/cascading-tbase-write-support\n\nAdd sink support for parquet.cascading.ParquetTBaseScheme",
        "diff": {
            "parquet-cascading/pom.xml": null,
            "parquet-cascading/src/main/java/parquet/cascading/ParquetTBaseScheme.java": [
                19,
                24
            ],
            "parquet-cascading/src/main/java/parquet/cascading/ParquetValueScheme.java": [
                0,
                16
            ],
            "parquet-cascading/src/test/java/parquet/cascading/TestParquetTBaseScheme.java": [
                46,
                135
            ],
            "parquet-cascading/src/test/resources/names.txt": null,
            "parquet-cascading/src/test/thrift/test.thrift": null,
            "parquet-hadoop/src/main/java/parquet/hadoop/ParquetOutputFormat.java": [
                68,
                119
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/mapred/DeprecatedParquetOutputFormat.java": [
                0,
                130
            ],
            "parquet-hadoop/src/test/java/parquet/hadoop/DeprecatedOutputFormatTest.java": [
                0,
                106
            ]
        }
    },
    "d24f4a7add1855675a3c2d19f7c9ab435ccfb028": {
        "datetime": "2013-10-02T14:17:42-07:00",
        "summary": "fix",
        "message": "fix\n",
        "diff": {
            "parquet-scrooge/src/main/java/parquet/scrooge/ScroogeSchemaConverter.java": [
                15,
                8
            ],
            "parquet-scrooge/src/test/java/parquet/scrooge/ScroogeSchemaConverterTest.java": [
                0,
                12
            ]
        }
    },
    "4e6863aaeb765f62322ed79bb7e82c930cb6e364": {
        "datetime": "2013-10-02T14:18:52-07:00",
        "summary": "add checker",
        "message": "add checker\n",
        "diff": {
            "parquet-thrift/src/main/java/parquet/thrift/struct/CompatibilityChecker.java": [
                0,
                7
            ]
        }
    },
    "6d9d2b334db9db4896599f07e9a545961422db5f": {
        "datetime": "2013-10-02T14:19:25-07:00",
        "summary": "add test",
        "message": "add test\n",
        "diff": {
            "parquet-thrift/src/test/java/parquet/thrift/struct/CompatibilityCheckerTest.java": [
                0,
                28
            ]
        }
    },
    "f325418daa9ebb103eda6a08e8f16522267f56a7": {
        "datetime": "2013-10-02T15:15:51-07:00",
        "summary": "generate_json",
        "message": "generate_json\n",
        "diff": {
            "parquet-thrift/src/main/java/parquet/thrift/struct/CompatibilityChecker.java": [
                0,
                3
            ],
            "parquet-thrift/src/main/java/parquet/thrift/struct/CompatibilityRunner.java": [
                0,
                35
            ],
            "parquet-thrift/src/test/java/parquet/thrift/struct/CompatibilityCheckerTest.java": [
                1,
                0
            ]
        }
    },
    "5bd87b1c579017ebd76382335bf258f51598bae8": {
        "datetime": "2013-10-02T15:37:48-07:00",
        "summary": "check compatible",
        "message": "check compatible\n",
        "diff": {
            "parquet-thrift/src/main/java/parquet/thrift/struct/CompatibilityChecker.java": [
                0,
                12
            ],
            "parquet-thrift/src/main/java/parquet/thrift/struct/CompatibilityRunner.java": [
                0,
                32
            ]
        }
    },
    "8856e45178a8ed73a7f7ac1aab5fe45e367bf4be": {
        "datetime": "2013-10-02T15:39:19-07:00",
        "summary": "todos",
        "message": "todos\n",
        "diff": {
            "parquet-thrift/src/main/java/parquet/thrift/struct/CompatibilityChecker.java": [
                0,
                1
            ]
        }
    },
    "bd311f54b0c7b043a4164413e35d014e3cc41683": {
        "datetime": "2013-10-02T15:52:17-07:00",
        "summary": "fix_test",
        "message": "fix_test\n",
        "diff": {
            "parquet-thrift/src/main/java/parquet/thrift/struct/CompatibilityChecker.java": [
                0,
                92
            ],
            "parquet-thrift/src/test/java/parquet/thrift/struct/CompatibilityCheckerTest.java": [
                1,
                1
            ]
        }
    },
    "001e3deef9c2f3f8e6f257b3e497da2934e6b1bf": {
        "datetime": "2013-10-02T16:04:29-07:00",
        "summary": "map checker",
        "message": "map checker\n",
        "diff": {
            "parquet-thrift/src/main/java/parquet/thrift/struct/CompatibilityChecker.java": [
                19,
                29
            ]
        }
    },
    "5bf612787838361fa2922d07aaa6833a4ee595a3": {
        "datetime": "2013-10-02T16:07:09-07:00",
        "summary": "SetChecker",
        "message": "SetChecker\n",
        "diff": {
            "parquet-thrift/src/main/java/parquet/thrift/struct/CompatibilityChecker.java": [
                0,
                8
            ]
        }
    },
    "5427f4434ee24062c83f35fe154b071491a322be": {
        "datetime": "2013-10-02T16:08:12-07:00",
        "summary": "list checker",
        "message": "list checker\n",
        "diff": {
            "parquet-thrift/src/main/java/parquet/thrift/struct/CompatibilityChecker.java": [
                0,
                5
            ]
        }
    },
    "2fb1f7d79693fea18933092c8993be60b476f265": {
        "datetime": "2013-10-02T16:09:59-07:00",
        "summary": "accept visitor",
        "message": "accept visitor\n",
        "diff": {
            "parquet-thrift/src/main/java/parquet/thrift/struct/CompatibilityChecker.java": [
                14,
                2
            ]
        }
    },
    "64b2f7268878cc19d246383f62900c8c2a275e27": {
        "datetime": "2013-10-02T16:10:46-07:00",
        "summary": "fix",
        "message": "fix\n",
        "diff": {
            "parquet-thrift/src/main/java/parquet/thrift/struct/CompatibilityChecker.java": [
                0,
                1
            ]
        }
    },
    "0d39e1ce31a0a0d6e94032bcd4f07ef2fae2fd48": {
        "datetime": "2013-10-02T16:38:17-07:00",
        "summary": "add compatibility report",
        "message": "add compatibility report\n",
        "diff": {
            "parquet-thrift/src/main/java/parquet/thrift/struct/CompatibilityChecker.java": [
                12,
                48
            ],
            "parquet-thrift/src/test/java/parquet/thrift/struct/CompatibilityCheckerTest.java": [
                0,
                23
            ]
        }
    },
    "6f0f23627674edcef5cd4d816dbe2816a5ce0edf": {
        "datetime": "2013-10-02T16:41:24-07:00",
        "summary": "fix tests",
        "message": "fix tests\n",
        "diff": {
            "parquet-thrift/src/main/java/parquet/thrift/struct/CompatibilityChecker.java": [
                1,
                1
            ],
            "parquet-thrift/src/test/java/parquet/thrift/struct/CompatibilityCheckerTest.java": [
                2,
                4
            ]
        }
    },
    "2b62da3e29716295d87a31bbc497a9a8217e4fc2": {
        "datetime": "2013-10-02T17:03:58-07:00",
        "summary": "requirement check",
        "message": "requirement check\n",
        "diff": {
            "parquet-thrift/src/main/java/parquet/thrift/struct/CompatibilityChecker.java": [
                50,
                67
            ],
            "parquet-thrift/src/test/java/parquet/thrift/struct/CompatibilityCheckerTest.java": [
                2,
                30
            ],
            "parquet-thrift/src/test/thrift/compat.thrift": null
        }
    },
    "2731c0fe26ebae217f8616d4e1cedf9e3b765d78": {
        "datetime": "2013-10-02T17:11:39-07:00",
        "summary": "refactor tests",
        "message": "refactor tests\n",
        "diff": {
            "parquet-thrift/src/main/java/parquet/thrift/struct/CompatibilityChecker.java": [
                2,
                2
            ],
            "parquet-thrift/src/test/java/parquet/thrift/struct/CompatibilityCheckerTest.java": [
                27,
                17
            ]
        }
    },
    "2ed9b5037a1a4b9e5ad704d9d0b5c783b9882ec1": {
        "datetime": "2013-10-02T17:53:55-07:00",
        "summary": "fail when required field is added",
        "message": "fail when required field is added\n",
        "diff": {
            "parquet-thrift/src/main/java/parquet/thrift/struct/CompatibilityChecker.java": [
                4,
                22
            ],
            "parquet-thrift/src/test/java/parquet/thrift/struct/CompatibilityCheckerTest.java": [
                14,
                6
            ],
            "parquet-thrift/src/test/thrift/compat.thrift": null
        }
    },
    "fdb07254ca5ab8698653a7adb9ea2a74e2b09c06": {
        "datetime": "2013-10-02T18:09:29-07:00",
        "summary": "add tests for list set map",
        "message": "add tests for list set map\n",
        "diff": {
            "parquet-thrift/src/main/java/parquet/thrift/struct/CompatibilityChecker.java": [
                1,
                1
            ],
            "parquet-thrift/src/test/java/parquet/thrift/struct/CompatibilityCheckerTest.java": [
                24,
                47
            ],
            "parquet-thrift/src/test/thrift/compat.thrift": null
        }
    },
    "9652d97f63a05d410fae941f14d684b8dfcedd44": {
        "datetime": "2013-10-03T10:37:40-07:00",
        "summary": "add parquet-pig-bundle",
        "message": "add parquet-pig-bundle\n",
        "diff": {
            "parquet-avro/pom.xml": null,
            "parquet-cascading/pom.xml": null,
            "parquet-column/pom.xml": null,
            "parquet-common/pom.xml": null,
            "parquet-encoding/pom.xml": null,
            "parquet-hadoop/pom.xml": null,
            "parquet-hive/pom.xml": null,
            "parquet-pig-bundle/pom.xml": null,
            "parquet-pig/pom.xml": null,
            "parquet-scrooge/pom.xml": null,
            "parquet-test-hadoop2/pom.xml": null,
            "parquet-thrift/pom.xml": null,
            "pom.xml": null
        }
    },
    "e3292ed203d2e5a1b7aa4643a3c628cc76745e3f": {
        "datetime": "2013-10-03T10:41:27-07:00",
        "summary": "Merge branch 'master' of github.com:Parquet/parquet-mr into pig_BUNDLE",
        "message": "Merge branch 'master' of github.com:Parquet/parquet-mr into pig_BUNDLE\n\nConflicts:\n\tparquet-hive/pom.xml\n",
        "diff": {
            "CHANGES.md": null,
            "parquet-avro/pom.xml": null,
            "parquet-avro/src/main/java/parquet/avro/AvroParquetReader.java": [
                0,
                12
            ],
            "parquet-avro/src/main/java/parquet/avro/AvroWriteSupport.java": [
                33,
                41
            ],
            "parquet-avro/src/test/java/parquet/avro/TestReadWrite.java": [
                1,
                64
            ],
            "parquet-avro/src/test/java/parquet/avro/TestSpecificReadWrite.java": [
                0,
                47
            ],
            "parquet-avro/src/test/resources/all-minus-fixed.avsc": null,
            "parquet-avro/src/test/resources/array.avsc": null,
            "parquet-avro/src/test/resources/map.avsc": null,
            "parquet-cascading/pom.xml": null,
            "parquet-cascading/src/main/java/parquet/cascading/ParquetTBaseScheme.java": [
                19,
                24
            ],
            "parquet-cascading/src/main/java/parquet/cascading/ParquetValueScheme.java": [
                0,
                16
            ],
            "parquet-cascading/src/test/java/parquet/cascading/TestParquetTBaseScheme.java": [
                46,
                135
            ],
            "parquet-cascading/src/test/resources/names.txt": null,
            "parquet-cascading/src/test/thrift/test.thrift": null,
            "parquet-column/pom.xml": null,
            "parquet-column/src/main/java/parquet/filter/NotRecordFilter.java": [
                0,
                55
            ],
            "parquet-column/src/main/java/parquet/filter/OrRecordFilter.java": [
                0,
                59
            ],
            "parquet-column/src/main/java/parquet/io/RecordReaderImplementation.java": [
                42,
                45
            ],
            "parquet-column/src/test/java/parquet/io/TestFiltered.java": [
                0,
                38
            ],
            "parquet-common/pom.xml": null,
            "parquet-encoding/pom.xml": null,
            "parquet-generator/pom.xml": null,
            "parquet-hadoop/pom.xml": null,
            "parquet-hadoop/src/main/java/parquet/hadoop/InternalParquetRecordWriter.java": [
                3,
                4
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/ParquetOutputFormat.java": [
                68,
                119
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/ParquetReader.java": [
                1,
                22
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/mapred/DeprecatedParquetOutputFormat.java": [
                0,
                130
            ],
            "parquet-hadoop/src/test/java/parquet/hadoop/DeprecatedInputFormatTest.java": [
                1,
                1
            ],
            "parquet-hadoop/src/test/java/parquet/hadoop/DeprecatedOutputFormatTest.java": [
                0,
                106
            ],
            "parquet-hive/pom.xml": null,
            "parquet-pig/pom.xml": null,
            "parquet-pig/src/main/java/parquet/pig/ParquetLoader.java": [
                15,
                43
            ],
            "parquet-pig/src/main/java/parquet/pig/PigSchemaConverter.java": [
                1,
                1
            ],
            "parquet-pig/src/test/java/parquet/pig/TestParquetLoader.java": [
                1,
                65
            ],
            "parquet-scrooge/pom.xml": null,
            "parquet-scrooge/src/test/java/parquet/scrooge/ParquetScroogeSchemeTest.java": [
                0,
                93
            ],
            "parquet-scrooge/src/test/thrift/test.thrift": null,
            "parquet-test-hadoop2/pom.xml": null,
            "parquet-thrift/pom.xml": null,
            "parquet-thrift/src/main/java/parquet/thrift/ThriftParquetReader.java": [
                0,
                21
            ],
            "pom.xml": null
        }
    },
    "ff4d13a771565d307a803098fe0c7e9a5b91e820": {
        "datetime": "2013-10-03T10:47:54-07:00",
        "summary": "add null check",
        "message": "add null check\n",
        "diff": {
            "parquet-column/src/main/java/parquet/column/values/dictionary/DictionaryValuesWriter.java": [
                1,
                1
            ]
        }
    },
    "5adf79f33884b3564360c0cf431160e86984c712": {
        "datetime": "2013-10-03T10:50:15-07:00",
        "summary": "Merge pull request #180 from davidzchen/fix_avro_utf8_map_keys",
        "message": "Merge pull request #180 from davidzchen/fix_avro_utf8_map_keys\n\nSupport writing Avro records with maps with Utf8 keys",
        "diff": {
            "parquet-avro/src/main/java/parquet/avro/AvroWriteSupport.java": [
                3,
                3
            ],
            "parquet-avro/src/test/java/parquet/avro/TestReadWrite.java": [
                0,
                28
            ]
        }
    },
    "7247538c6bb70f608eb408e02f196211f65bef5b": {
        "datetime": "2013-10-03T10:55:16-07:00",
        "summary": "compatibility runner print more detailed info",
        "message": "compatibility runner print more detailed info\n",
        "diff": {
            "parquet-thrift/src/main/java/parquet/thrift/struct/CompatibilityChecker.java": [
                0,
                4
            ],
            "parquet-thrift/src/main/java/parquet/thrift/struct/CompatibilityRunner.java": [
                3,
                5
            ]
        }
    },
    "b3b0bbb67490d9a2a15c5307fec60c831e94de60": {
        "datetime": "2013-10-03T11:05:50-07:00",
        "summary": "fix indent",
        "message": "fix indent\n",
        "diff": {
            "parquet-column/src/main/java/parquet/column/values/dictionary/DictionaryValuesWriter.java": [
                1,
                2
            ]
        }
    },
    "1e61b401455f71053be9b52454916d07d8912a92": {
        "datetime": "2013-10-03T11:17:50-07:00",
        "summary": "fix version",
        "message": "fix version\n",
        "diff": {
            "parquet-pig-bundle/pom.xml": null
        }
    },
    "7c6ba3e752bcda02a13a1f85d904e583ae936655": {
        "datetime": "2013-10-03T11:46:54-07:00",
        "summary": "Merge changes from master.",
        "message": "Merge changes from master.\n",
        "diff": {
            "parquet-avro/src/main/java/parquet/avro/AvroParquetReader.java": [
                0,
                12
            ],
            "parquet-avro/src/main/java/parquet/avro/AvroWriteSupport.java": [
                3,
                3
            ],
            "parquet-avro/src/test/java/parquet/avro/TestReadWrite.java": [
                0,
                28
            ],
            "parquet-avro/src/test/java/parquet/avro/TestSpecificReadWrite.java": [
                1,
                48
            ],
            "parquet-cascading/pom.xml": null,
            "parquet-cascading/src/main/java/parquet/cascading/ParquetTBaseScheme.java": [
                19,
                24
            ],
            "parquet-cascading/src/main/java/parquet/cascading/ParquetValueScheme.java": [
                0,
                16
            ],
            "parquet-cascading/src/test/java/parquet/cascading/TestParquetTBaseScheme.java": [
                46,
                135
            ],
            "parquet-cascading/src/test/resources/names.txt": null,
            "parquet-cascading/src/test/thrift/test.thrift": null,
            "parquet-column/src/main/java/parquet/filter/NotRecordFilter.java": [
                0,
                55
            ],
            "parquet-column/src/main/java/parquet/filter/OrRecordFilter.java": [
                0,
                59
            ],
            "parquet-column/src/test/java/parquet/io/TestFiltered.java": [
                0,
                38
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/ParquetOutputFormat.java": [
                68,
                119
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/ParquetReader.java": [
                1,
                22
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/mapred/DeprecatedParquetOutputFormat.java": [
                0,
                130
            ],
            "parquet-hadoop/src/test/java/parquet/hadoop/DeprecatedInputFormatTest.java": [
                1,
                1
            ],
            "parquet-hadoop/src/test/java/parquet/hadoop/DeprecatedOutputFormatTest.java": [
                0,
                106
            ],
            "parquet-hive/pom.xml": null,
            "parquet-thrift/src/main/java/parquet/thrift/ThriftParquetReader.java": [
                0,
                21
            ]
        }
    },
    "989e9dc13556213acf92758caaa7093679b4d52d": {
        "datetime": "2013-10-03T11:57:59-07:00",
        "summary": "Plumb OriginalType through to ConvertedType in file in ParquetMetadataConverter.",
        "message": "Plumb OriginalType through to ConvertedType in file in ParquetMetadataConverter.\n",
        "diff": {
            "parquet-hadoop/src/main/java/parquet/format/converter/ParquetMetadataConverter.java": [
                4,
                54
            ]
        }
    },
    "e40dcfb9ffaab5735097a5cc71a6ec79aa36e46f": {
        "datetime": "2013-10-03T13:35:59-07:00",
        "summary": "Merge pull request #181 from davidzchen/fixed_len_byte_array",
        "message": "Merge pull request #181 from davidzchen/fixed_len_byte_array\n\nFIXED_LEN_BYTE_ARRAY support",
        "diff": {
            "parquet-avro/src/main/java/parquet/avro/AvroIndexedRecordConverter.java": [
                3,
                30
            ],
            "parquet-avro/src/main/java/parquet/avro/AvroParquetReader.java": [
                1,
                1
            ],
            "parquet-avro/src/main/java/parquet/avro/AvroSchemaConverter.java": [
                5,
                14
            ],
            "parquet-avro/src/test/java/parquet/avro/TestAvroSchemaConverter.java": [
                8,
                19
            ],
            "parquet-avro/src/test/java/parquet/avro/TestReadWrite.java": [
                10,
                15
            ],
            "parquet-avro/src/test/java/parquet/avro/TestSpecificInputOutputFormat.java": [
                10,
                12
            ],
            "parquet-avro/src/test/java/parquet/avro/TestSpecificReadWrite.java": [
                32,
                29
            ],
            "parquet-avro/src/test/resources/all-minus-fixed.avsc": null,
            "parquet-avro/src/test/resources/all.avsc": null,
            "parquet-avro/src/test/resources/car.avdl": null,
            "parquet-column/src/main/java/parquet/column/ColumnDescriptor.java": [
                2,
                24
            ],
            "parquet-column/src/main/java/parquet/column/ColumnWriter.java": [
                0,
                1
            ],
            "parquet-column/src/main/java/parquet/column/Encoding.java": [
                0,
                3
            ],
            "parquet-column/src/main/java/parquet/column/impl/ColumnReaderImpl.java": [
                3,
                19
            ],
            "parquet-column/src/main/java/parquet/column/impl/ColumnWriterImpl.java": [
                10,
                13
            ],
            "parquet-column/src/main/java/parquet/column/values/ValuesReader.java": [
                0,
                1
            ],
            "parquet-column/src/main/java/parquet/column/values/plain/FixedLenByteArrayPlainValuesReader.java": [
                0,
                67
            ],
            "parquet-column/src/main/java/parquet/column/values/plain/FixedLenByteArrayPlainValuesWriter.java": [
                0,
                95
            ],
            "parquet-column/src/main/java/parquet/example/data/simple/convert/SimplePrimitiveConverter.java": [
                5,
                4
            ],
            "parquet-column/src/main/java/parquet/io/PrimitiveColumnIO.java": [
                1,
                8
            ],
            "parquet-column/src/main/java/parquet/schema/MessageType.java": [
                3,
                10
            ],
            "parquet-column/src/main/java/parquet/schema/MessageTypeParser.java": [
                1,
                18
            ],
            "parquet-column/src/main/java/parquet/schema/PrimitiveType.java": [
                17,
                51
            ],
            "parquet-column/src/test/java/parquet/io/ExpectationValidatingRecordConsumer.java": [
                0,
                1
            ],
            "parquet-column/src/test/java/parquet/io/TestColumnIO.java": [
                20,
                19
            ],
            "parquet-hadoop/src/main/java/parquet/format/converter/ParquetMetadataConverter.java": [
                12,
                18
            ],
            "parquet-hive/src/test/java/parquet/hive/TestHiveSchemaConverter.java": [
                3,
                2
            ],
            "parquet-pig/src/main/java/parquet/pig/PigSchemaConverter.java": [
                90,
                109
            ],
            "parquet-pig/src/test/java/parquet/pig/TestParquetLoader.java": [
                1,
                4
            ],
            "parquet-pig/src/test/java/parquet/pig/TestPigSchemaConverter.java": [
                0,
                27
            ]
        }
    },
    "5303197f00a46d5d6bd133e330dbbc6af0897126": {
        "datetime": "2013-10-03T13:59:08-07:00",
        "summary": "Merge changes from master.",
        "message": "Merge changes from master.\n",
        "diff": {
            "parquet-avro/src/main/java/parquet/avro/AvroIndexedRecordConverter.java": [
                3,
                30
            ],
            "parquet-avro/src/main/java/parquet/avro/AvroParquetReader.java": [
                1,
                1
            ],
            "parquet-avro/src/main/java/parquet/avro/AvroSchemaConverter.java": [
                5,
                14
            ],
            "parquet-avro/src/test/java/parquet/avro/TestAvroSchemaConverter.java": [
                8,
                19
            ],
            "parquet-avro/src/test/java/parquet/avro/TestReadWrite.java": [
                10,
                15
            ],
            "parquet-avro/src/test/java/parquet/avro/TestSpecificInputOutputFormat.java": [
                10,
                12
            ],
            "parquet-avro/src/test/java/parquet/avro/TestSpecificReadWrite.java": [
                32,
                29
            ],
            "parquet-avro/src/test/resources/all-minus-fixed.avsc": null,
            "parquet-avro/src/test/resources/all.avsc": null,
            "parquet-avro/src/test/resources/car.avdl": null,
            "parquet-column/src/main/java/parquet/column/ColumnDescriptor.java": [
                2,
                24
            ],
            "parquet-column/src/main/java/parquet/column/ColumnWriter.java": [
                0,
                1
            ],
            "parquet-column/src/main/java/parquet/column/Encoding.java": [
                0,
                3
            ],
            "parquet-column/src/main/java/parquet/column/impl/ColumnReaderImpl.java": [
                3,
                19
            ],
            "parquet-column/src/main/java/parquet/column/impl/ColumnWriterImpl.java": [
                10,
                13
            ],
            "parquet-column/src/main/java/parquet/column/values/ValuesReader.java": [
                0,
                1
            ],
            "parquet-column/src/main/java/parquet/column/values/plain/FixedLenByteArrayPlainValuesReader.java": [
                0,
                67
            ],
            "parquet-column/src/main/java/parquet/column/values/plain/FixedLenByteArrayPlainValuesWriter.java": [
                0,
                95
            ],
            "parquet-column/src/main/java/parquet/example/data/simple/convert/SimplePrimitiveConverter.java": [
                5,
                4
            ],
            "parquet-column/src/main/java/parquet/io/PrimitiveColumnIO.java": [
                1,
                8
            ],
            "parquet-column/src/main/java/parquet/schema/MessageType.java": [
                3,
                10
            ],
            "parquet-column/src/main/java/parquet/schema/MessageTypeParser.java": [
                1,
                18
            ],
            "parquet-column/src/main/java/parquet/schema/PrimitiveType.java": [
                17,
                51
            ],
            "parquet-column/src/test/java/parquet/io/ExpectationValidatingRecordConsumer.java": [
                0,
                1
            ],
            "parquet-column/src/test/java/parquet/io/TestColumnIO.java": [
                20,
                19
            ],
            "parquet-hadoop/src/main/java/parquet/format/converter/ParquetMetadataConverter.java": [
                13,
                20
            ],
            "parquet-hive/src/test/java/parquet/hive/TestHiveSchemaConverter.java": [
                3,
                2
            ],
            "parquet-pig/src/main/java/parquet/pig/PigSchemaConverter.java": [
                90,
                109
            ],
            "parquet-pig/src/test/java/parquet/pig/TestParquetLoader.java": [
                1,
                4
            ],
            "parquet-pig/src/test/java/parquet/pig/TestPigSchemaConverter.java": [
                0,
                27
            ]
        }
    },
    "c1ac1af425fe7c2ef69adf018d58af57811b0252": {
        "datetime": "2013-10-03T15:15:41-07:00",
        "summary": "Merge pull request #186 from Parquet/pig_BUNDLE",
        "message": "Merge pull request #186 from Parquet/pig_BUNDLE\n\nadd parquet-pig-bundle",
        "diff": {
            "parquet-avro/pom.xml": null,
            "parquet-cascading/pom.xml": null,
            "parquet-column/pom.xml": null,
            "parquet-common/pom.xml": null,
            "parquet-encoding/pom.xml": null,
            "parquet-hadoop/pom.xml": null,
            "parquet-hive/pom.xml": null,
            "parquet-pig-bundle/pom.xml": null,
            "parquet-pig/pom.xml": null,
            "parquet-scrooge/pom.xml": null,
            "parquet-test-hadoop2/pom.xml": null,
            "parquet-thrift/pom.xml": null,
            "pom.xml": null
        }
    },
    "1ae67725f669beeba2fb867a3c2ef4f5722c0c64": {
        "datetime": "2013-10-03T16:54:26-07:00",
        "summary": "add dummy file to generate source jar",
        "message": "add dummy file to generate source jar\n",
        "diff": {
            "parquet-pig-bundle/src/main/resources/parquet/bundle": null
        }
    },
    "b168fd1c1b0b79bac4dd5fe9b23fa618b711bd72": {
        "datetime": "2013-10-03T17:03:47-07:00",
        "summary": "[maven-release-plugin] prepare release parquet-1.2.3",
        "message": "[maven-release-plugin] prepare release parquet-1.2.3\n",
        "diff": {
            "parquet-avro/pom.xml": null,
            "parquet-cascading/pom.xml": null,
            "parquet-column/pom.xml": null,
            "parquet-common/pom.xml": null,
            "parquet-encoding/pom.xml": null,
            "parquet-generator/pom.xml": null,
            "parquet-hadoop/pom.xml": null,
            "parquet-hive/pom.xml": null,
            "parquet-pig-bundle/pom.xml": null,
            "parquet-pig/pom.xml": null,
            "parquet-scrooge/pom.xml": null,
            "parquet-test-hadoop2/pom.xml": null,
            "parquet-thrift/pom.xml": null,
            "pom.xml": null
        }
    },
    "1326c003369e95da80e9e11b19e31d440e4e503b": {
        "datetime": "2013-10-03T17:03:58-07:00",
        "summary": "[maven-release-plugin] prepare for next development iteration",
        "message": "[maven-release-plugin] prepare for next development iteration\n",
        "diff": {
            "parquet-avro/pom.xml": null,
            "parquet-cascading/pom.xml": null,
            "parquet-column/pom.xml": null,
            "parquet-common/pom.xml": null,
            "parquet-encoding/pom.xml": null,
            "parquet-generator/pom.xml": null,
            "parquet-hadoop/pom.xml": null,
            "parquet-hive/pom.xml": null,
            "parquet-pig-bundle/pom.xml": null,
            "parquet-pig/pom.xml": null,
            "parquet-scrooge/pom.xml": null,
            "parquet-test-hadoop2/pom.xml": null,
            "parquet-thrift/pom.xml": null,
            "pom.xml": null
        }
    },
    "fd3b05cf4d62cd098f85510fd6ed05469911cba2": {
        "datetime": "2013-10-03T17:34:05-07:00",
        "summary": "release 1.2.3",
        "message": "release 1.2.3",
        "diff": {
            "CHANGES.md": null
        }
    },
    "cfd63fd61cb8b05a61b65fbd8021f19d6d19a493": {
        "datetime": "2013-10-03T18:23:50-07:00",
        "summary": "Fixed issue with test case that was causing runtime error. Was trying to call getInteger on long...",
        "message": "Fixed issue with test case that was causing runtime error. Was trying to call getInteger on long...\n",
        "diff": {
            "parquet-column/src/test/java/parquet/io/TestFiltered.java": [
                6,
                6
            ]
        }
    },
    "c6a4d18717ca05c9cc4f169a3c2a3098f0e0a967": {
        "datetime": "2013-10-03T18:28:29-07:00",
        "summary": "Added unit tests for predicates. Got predicates compiling, and passing on tests.",
        "message": "Added unit tests for predicates. Got predicates compiling, and passing on tests.\n",
        "diff": {
            "parquet-column/src/main/java/parquet/filter/ColumnPredicates.java": [
                16,
                16
            ],
            "parquet-column/src/main/java/parquet/filter/NotRecordFilter.java": [
                2,
                2
            ],
            "parquet-column/src/main/java/parquet/filter/OrRecordFilter.java": [
                1,
                1
            ],
            "parquet-column/src/test/java/parquet/io/TestFiltered.java": [
                0,
                38
            ]
        }
    },
    "eb35ba800654231865401503f971d19183257f30": {
        "datetime": "2013-10-03T18:28:29-07:00",
        "summary": "Added functionality to allow users to implement functions to be used as predicates.",
        "message": "Added functionality to allow users to implement functions to be used as predicates.\n",
        "diff": {
            "parquet-column/src/main/java/parquet/filter/ColumnPredicates.java": [
                1,
                58
            ]
        }
    },
    "308c1b41960e5c430a60b02db74ad4f03567b855": {
        "datetime": "2013-10-03T18:28:29-07:00",
        "summary": "Added two boolean options for record filters.",
        "message": "Added two boolean options for record filters.\n",
        "diff": {
            "parquet-column/src/main/java/parquet/filter/NotRecordFilter.java": [
                0,
                55
            ],
            "parquet-column/src/main/java/parquet/filter/OrRecordFilter.java": [
                0,
                59
            ]
        }
    },
    "8be341f6bc9e7a64ceee86a570bc84c0e6787d76": {
        "datetime": "2013-10-03T18:28:30-07:00",
        "summary": "Removing predicate functions to prepare for pushing or/not filters. Limits number of features pushed.",
        "message": "Removing predicate functions to prepare for pushing or/not filters. Limits number of features pushed.\n",
        "diff": {
            "parquet-column/src/main/java/parquet/filter/ColumnPredicates.java": [
                58,
                1
            ]
        }
    },
    "64921da05fb28a28d1c25c5e850b1954aa2ba71f": {
        "datetime": "2013-10-03T18:35:49-07:00",
        "summary": "Merge branch 'master' of github.com:fnothaft/parquet-mr",
        "message": "Merge branch 'master' of github.com:fnothaft/parquet-mr\n",
        "diff": {}
    },
    "3edf60dcbd90968d3b94f7f2669b485da649ee0d": {
        "datetime": "2013-10-03T18:40:54-07:00",
        "summary": "Manually merged in conflicts in TestFiltered.java.",
        "message": "Manually merged in conflicts in TestFiltered.java.\n",
        "diff": {
            "parquet-column/src/main/java/parquet/filter/ColumnPredicates.java": [
                1,
                58
            ],
            "parquet-column/src/test/java/parquet/io/TestFiltered.java": [
                0,
                71
            ]
        }
    },
    "0a36e35cf6c52a9e79fdfbbb8584a8adc3a17b6c": {
        "datetime": "2013-10-07T12:17:20-05:00",
        "summary": "Fixes #189: NPE in DictionaryValuesWriter.",
        "message": "Fixes #189: NPE in DictionaryValuesWriter.\n",
        "diff": {
            "parquet-column/src/main/java/parquet/column/values/dictionary/DictionaryValuesWriter.java": [
                1,
                1
            ]
        }
    },
    "fd2935b02c89cbb9b55b9b411b1159f578b7f915": {
        "datetime": "2013-10-07T13:00:05-07:00",
        "summary": "Merge branch 'master' into plumb_original_type",
        "message": "Merge branch 'master' into plumb_original_type\n",
        "diff": {
            "CHANGES.md": null,
            "parquet-avro/pom.xml": null,
            "parquet-cascading/pom.xml": null,
            "parquet-column/pom.xml": null,
            "parquet-common/pom.xml": null,
            "parquet-encoding/pom.xml": null,
            "parquet-generator/pom.xml": null,
            "parquet-hadoop/pom.xml": null,
            "parquet-hive/pom.xml": null,
            "parquet-pig-bundle/pom.xml": null,
            "parquet-pig-bundle/src/main/resources/parquet/bundle": null,
            "parquet-pig/pom.xml": null,
            "parquet-scrooge/pom.xml": null,
            "parquet-test-hadoop2/pom.xml": null,
            "parquet-thrift/pom.xml": null,
            "pom.xml": null
        }
    },
    "714335de4ba559645408adf692a6a90aceb8adae": {
        "datetime": "2013-10-07T13:06:51-07:00",
        "summary": "compare json",
        "message": "compare json\n",
        "diff": {
            "parquet-thrift/src/main/java/parquet/thrift/struct/CompatibilityRunner.java": [
                0,
                32
            ],
            "parquet-thrift/src/test/java/parquet/thrift/struct/CompatibilityCheckerTest.java": [
                0,
                25
            ]
        }
    },
    "0d2597965153c164eed55129596a06344ec74705": {
        "datetime": "2013-10-07T13:16:51-07:00",
        "summary": "Merge branch 'master' of https://github.com/Parquet/parquet-mr into compatibility_checker",
        "message": "Merge branch 'master' of https://github.com/Parquet/parquet-mr into compatibility_checker\n",
        "diff": {
            "CHANGES.md": null,
            "parquet-avro/pom.xml": null,
            "parquet-avro/src/main/java/parquet/avro/AvroIndexedRecordConverter.java": [
                3,
                30
            ],
            "parquet-avro/src/main/java/parquet/avro/AvroParquetReader.java": [
                1,
                1
            ],
            "parquet-avro/src/main/java/parquet/avro/AvroSchemaConverter.java": [
                5,
                14
            ],
            "parquet-avro/src/main/java/parquet/avro/AvroWriteSupport.java": [
                3,
                3
            ],
            "parquet-avro/src/test/java/parquet/avro/TestAvroSchemaConverter.java": [
                8,
                19
            ],
            "parquet-avro/src/test/java/parquet/avro/TestReadWrite.java": [
                9,
                42
            ],
            "parquet-avro/src/test/java/parquet/avro/TestSpecificInputOutputFormat.java": [
                10,
                12
            ],
            "parquet-avro/src/test/java/parquet/avro/TestSpecificReadWrite.java": [
                32,
                29
            ],
            "parquet-avro/src/test/resources/all-minus-fixed.avsc": null,
            "parquet-avro/src/test/resources/all.avsc": null,
            "parquet-avro/src/test/resources/car.avdl": null,
            "parquet-cascading/pom.xml": null,
            "parquet-column/pom.xml": null,
            "parquet-column/src/main/java/parquet/column/ColumnDescriptor.java": [
                2,
                24
            ],
            "parquet-column/src/main/java/parquet/column/ColumnWriter.java": [
                0,
                1
            ],
            "parquet-column/src/main/java/parquet/column/Encoding.java": [
                0,
                3
            ],
            "parquet-column/src/main/java/parquet/column/impl/ColumnReaderImpl.java": [
                3,
                19
            ],
            "parquet-column/src/main/java/parquet/column/impl/ColumnWriterImpl.java": [
                10,
                13
            ],
            "parquet-column/src/main/java/parquet/column/values/ValuesReader.java": [
                0,
                1
            ],
            "parquet-column/src/main/java/parquet/column/values/plain/FixedLenByteArrayPlainValuesReader.java": [
                0,
                67
            ],
            "parquet-column/src/main/java/parquet/column/values/plain/FixedLenByteArrayPlainValuesWriter.java": [
                0,
                95
            ],
            "parquet-column/src/main/java/parquet/example/data/simple/convert/SimplePrimitiveConverter.java": [
                5,
                4
            ],
            "parquet-column/src/main/java/parquet/io/PrimitiveColumnIO.java": [
                1,
                8
            ],
            "parquet-column/src/main/java/parquet/schema/MessageType.java": [
                3,
                10
            ],
            "parquet-column/src/main/java/parquet/schema/MessageTypeParser.java": [
                1,
                18
            ],
            "parquet-column/src/main/java/parquet/schema/PrimitiveType.java": [
                17,
                51
            ],
            "parquet-column/src/test/java/parquet/io/ExpectationValidatingRecordConsumer.java": [
                0,
                1
            ],
            "parquet-column/src/test/java/parquet/io/TestColumnIO.java": [
                20,
                19
            ],
            "parquet-common/pom.xml": null,
            "parquet-encoding/pom.xml": null,
            "parquet-generator/pom.xml": null,
            "parquet-hadoop/pom.xml": null,
            "parquet-hadoop/src/main/java/parquet/format/converter/ParquetMetadataConverter.java": [
                12,
                18
            ],
            "parquet-hive/pom.xml": null,
            "parquet-hive/src/test/java/parquet/hive/TestHiveSchemaConverter.java": [
                3,
                2
            ],
            "parquet-pig-bundle/pom.xml": null,
            "parquet-pig-bundle/src/main/resources/parquet/bundle": null,
            "parquet-pig/pom.xml": null,
            "parquet-pig/src/main/java/parquet/pig/PigSchemaConverter.java": [
                90,
                109
            ],
            "parquet-pig/src/test/java/parquet/pig/TestParquetLoader.java": [
                1,
                4
            ],
            "parquet-pig/src/test/java/parquet/pig/TestPigSchemaConverter.java": [
                0,
                27
            ],
            "parquet-scrooge/pom.xml": null,
            "parquet-test-hadoop2/pom.xml": null,
            "parquet-thrift/pom.xml": null,
            "pom.xml": null
        }
    },
    "820fb75108627f93af56e4d62b47730a12af27ba": {
        "datetime": "2013-10-07T13:19:39-07:00",
        "summary": "remove unused test",
        "message": "remove unused test\n",
        "diff": {
            "parquet-thrift/src/main/java/parquet/thrift/struct/CompatibilityChecker.java": [
                3,
                0
            ],
            "parquet-thrift/src/test/java/parquet/thrift/struct/CompatibilityCheckerTest.java": [
                19,
                0
            ]
        }
    },
    "dc425e481b3a833d83317258b7d00f04a9afe3b0": {
        "datetime": "2013-10-07T14:27:11-07:00",
        "summary": "show field name when they are not compatible",
        "message": "show field name when they are not compatible\n",
        "diff": {
            "parquet-thrift/src/main/java/parquet/thrift/struct/CompatibilityChecker.java": [
                1,
                1
            ]
        }
    },
    "5cad37ba0be6dcbc6ede9ee31007022a9e0ff362": {
        "datetime": "2013-10-08T10:17:51-07:00",
        "summary": "remove unused command from CompatibilityRunner, add comment for rules used in compatibility checking, add license header",
        "message": "remove unused command from CompatibilityRunner, add comment for rules used in compatibility checking, add license header\n",
        "diff": {
            "parquet-thrift/src/main/java/parquet/thrift/struct/CompatibilityChecker.java": [
                18,
                39
            ],
            "parquet-thrift/src/main/java/parquet/thrift/struct/CompatibilityRunner.java": [
                53,
                48
            ],
            "parquet-thrift/src/test/java/parquet/thrift/struct/CompatibilityCheckerTest.java": [
                7,
                33
            ]
        }
    },
    "82052b89de0816b36713f281b2861549e7562e74": {
        "datetime": "2013-10-08T11:13:48-07:00",
        "summary": "Merge pull request #191 from Parquet/compatibility_checker",
        "message": "Merge pull request #191 from Parquet/compatibility_checker\n\nThrift compatibility checker",
        "diff": {
            "parquet-thrift/src/main/java/parquet/thrift/struct/CompatibilityChecker.java": [
                0,
                220
            ],
            "parquet-thrift/src/main/java/parquet/thrift/struct/CompatibilityRunner.java": [
                0,
                96
            ],
            "parquet-thrift/src/test/java/parquet/thrift/struct/CompatibilityCheckerTest.java": [
                0,
                117
            ],
            "parquet-thrift/src/test/thrift/compat.thrift": null
        }
    },
    "09bcb1bf6d860cbbc0153861597a4e0df6a24ff4": {
        "datetime": "2013-10-08T11:37:21-07:00",
        "summary": "fix comment",
        "message": "fix comment\n",
        "diff": {
            "parquet-thrift/src/main/java/parquet/thrift/struct/CompatibilityRunner.java": [
                1,
                1
            ]
        }
    },
    "eff1e5f915f4714c32fae1ff7d0e9e540344d803": {
        "datetime": "2013-10-08T11:41:36-07:00",
        "summary": "Merge pull request #192 from Parquet/comment_fix",
        "message": "Merge pull request #192 from Parquet/comment_fix\n\nfix comment",
        "diff": {
            "parquet-thrift/src/main/java/parquet/thrift/struct/CompatibilityRunner.java": [
                1,
                1
            ]
        }
    },
    "da05b136daf4a74f4cdcc1b6742b8fb3182a03c4": {
        "datetime": "2013-10-08T11:53:25-07:00",
        "summary": "[maven-release-plugin] prepare release parquet-1.2.4",
        "message": "[maven-release-plugin] prepare release parquet-1.2.4\n",
        "diff": {
            "parquet-avro/pom.xml": null,
            "parquet-cascading/pom.xml": null,
            "parquet-column/pom.xml": null,
            "parquet-common/pom.xml": null,
            "parquet-encoding/pom.xml": null,
            "parquet-generator/pom.xml": null,
            "parquet-hadoop/pom.xml": null,
            "parquet-hive/pom.xml": null,
            "parquet-pig-bundle/pom.xml": null,
            "parquet-pig/pom.xml": null,
            "parquet-scrooge/pom.xml": null,
            "parquet-test-hadoop2/pom.xml": null,
            "parquet-thrift/pom.xml": null,
            "pom.xml": null
        }
    },
    "6dc4732ce461d29f488b81687bc3b93090f732ff": {
        "datetime": "2013-10-08T11:53:29-07:00",
        "summary": "[maven-release-plugin] prepare for next development iteration",
        "message": "[maven-release-plugin] prepare for next development iteration\n",
        "diff": {
            "parquet-avro/pom.xml": null,
            "parquet-cascading/pom.xml": null,
            "parquet-column/pom.xml": null,
            "parquet-common/pom.xml": null,
            "parquet-encoding/pom.xml": null,
            "parquet-generator/pom.xml": null,
            "parquet-hadoop/pom.xml": null,
            "parquet-hive/pom.xml": null,
            "parquet-pig-bundle/pom.xml": null,
            "parquet-pig/pom.xml": null,
            "parquet-scrooge/pom.xml": null,
            "parquet-test-hadoop2/pom.xml": null,
            "parquet-thrift/pom.xml": null,
            "pom.xml": null
        }
    },
    "ff55567cf448df98bafe3a3512349bf7d9f4d78a": {
        "datetime": "2013-10-08T12:12:27-07:00",
        "summary": "Update CHANGES.md",
        "message": "Update CHANGES.md",
        "diff": {
            "CHANGES.md": null
        }
    },
    "04ad0c4461f75fec456e2e61fa4b68d960a088b5": {
        "datetime": "2013-10-08T15:16:56-07:00",
        "summary": "Merge pull request #190 from wesleypeck/fix_dvw_npe",
        "message": "Merge pull request #190 from wesleypeck/fix_dvw_npe\n\nFixes #189: NPE in DictionaryValuesWriter.",
        "diff": {
            "parquet-column/src/main/java/parquet/column/values/dictionary/DictionaryValuesWriter.java": [
                1,
                1
            ]
        }
    },
    "20201427905781726ebf946a0840b19cddf88bbb": {
        "datetime": "2013-10-09T10:28:47-07:00",
        "summary": "refactor serde to remove some unecessary boxing and include dictionary awareness",
        "message": "refactor serde to remove some unecessary boxing and include dictionary awareness\n",
        "diff": {
            "parquet-column/src/main/java/parquet/io/api/Binary.java": [
                0,
                20
            ],
            "parquet-hive/src/main/java/parquet/hive/convert/DataWritableGroupConverter.java": [
                3,
                1
            ],
            "parquet-hive/src/main/java/parquet/hive/convert/ETypeConverter.java": [
                172,
                54
            ],
            "parquet-hive/src/main/java/parquet/hive/serde/ArrayWritableObjectInspector.java": [
                23,
                7
            ],
            "parquet-hive/src/main/java/parquet/hive/serde/ParquetHiveArrayInspector.java": [
                2,
                2
            ],
            "parquet-hive/src/main/java/parquet/hive/serde/ParquetHiveSerDe.java": [
                1,
                2
            ],
            "parquet-hive/src/main/java/parquet/hive/writable/BinaryWritable.java": [
                7,
                59
            ],
            "parquet-hive/src/main/java/parquet/hive/write/DataWritableWriter.java": [
                1,
                1
            ],
            "parquet-hive/src/test/java/parquet/hive/TestParquetSerDe.java": [
                3,
                4
            ],
            "parquet-hive/src/test/java/parquet/hive/UtilitiesTestMethods.java": [
                11,
                11
            ]
        }
    },
    "50bd1448a7b9df63c0fe6dbe0a60e97989fc2daa": {
        "datetime": "2013-10-10T07:56:55-07:00",
        "summary": "Merge pull request #194 from Parquet/hive_perf",
        "message": "Merge pull request #194 from Parquet/hive_perf\n\nrefactor serde to remove some unecessary boxing and include dictionary awareness",
        "diff": {
            "parquet-column/src/main/java/parquet/io/api/Binary.java": [
                0,
                20
            ],
            "parquet-hive/src/main/java/parquet/hive/convert/DataWritableGroupConverter.java": [
                3,
                1
            ],
            "parquet-hive/src/main/java/parquet/hive/convert/ETypeConverter.java": [
                172,
                54
            ],
            "parquet-hive/src/main/java/parquet/hive/serde/ArrayWritableObjectInspector.java": [
                23,
                7
            ],
            "parquet-hive/src/main/java/parquet/hive/serde/ParquetHiveArrayInspector.java": [
                2,
                2
            ],
            "parquet-hive/src/main/java/parquet/hive/serde/ParquetHiveSerDe.java": [
                1,
                2
            ],
            "parquet-hive/src/main/java/parquet/hive/writable/BinaryWritable.java": [
                7,
                59
            ],
            "parquet-hive/src/main/java/parquet/hive/write/DataWritableWriter.java": [
                1,
                1
            ],
            "parquet-hive/src/test/java/parquet/hive/TestParquetSerDe.java": [
                3,
                4
            ],
            "parquet-hive/src/test/java/parquet/hive/UtilitiesTestMethods.java": [
                11,
                11
            ]
        }
    },
    "763dfde36cd67c9f539cbd0db54b4dcdf3d15b77": {
        "datetime": "2013-10-10T16:59:14+02:00",
        "summary": "Fix for columns list missing from the conf",
        "message": "Fix for columns list missing from the conf\n\n- In this case, assume that the schema and requested schema\ncorrespond to the file schema\n",
        "diff": {
            "parquet-hive/src/main/java/parquet/hive/read/DataWritableReadSupport.java": [
                28,
                34
            ]
        }
    },
    "26605981a09ef95864293af202c123a5e40fc913": {
        "datetime": "2013-10-10T14:19:43-07:00",
        "summary": "Update README.md",
        "message": "Update README.md",
        "diff": {
            "README.md": null
        }
    },
    "422dfe05d5583318cc5116a688fc7e5676cafd89": {
        "datetime": "2013-10-11T09:07:28-07:00",
        "summary": "Updated files to add applyFunctionToBinary, and add specific interfaces for primitive types.",
        "message": "Updated files to add applyFunctionToBinary, and add specific interfaces for primitive types.\n",
        "diff": {
            "parquet-column/src/main/java/parquet/filter/ColumnPredicates.java": [
                11,
                43
            ],
            "parquet-column/src/test/java/parquet/io/TestFiltered.java": [
                2,
                3
            ]
        }
    },
    "82f882f14c5815a809428e950c4c94a04221e9e3": {
        "datetime": "2013-10-12T08:29:01-07:00",
        "summary": "Merge branch 'master' into plumb_original_type",
        "message": "Merge branch 'master' into plumb_original_type\n",
        "diff": {
            "CHANGES.md": null,
            "README.md": null,
            "parquet-avro/pom.xml": null,
            "parquet-cascading/pom.xml": null,
            "parquet-column/pom.xml": null,
            "parquet-column/src/main/java/parquet/column/values/dictionary/DictionaryValuesWriter.java": [
                1,
                1
            ],
            "parquet-column/src/main/java/parquet/io/api/Binary.java": [
                0,
                20
            ],
            "parquet-common/pom.xml": null,
            "parquet-encoding/pom.xml": null,
            "parquet-generator/pom.xml": null,
            "parquet-hadoop/pom.xml": null,
            "parquet-hive/pom.xml": null,
            "parquet-hive/src/main/java/parquet/hive/convert/DataWritableGroupConverter.java": [
                3,
                1
            ],
            "parquet-hive/src/main/java/parquet/hive/convert/ETypeConverter.java": [
                172,
                54
            ],
            "parquet-hive/src/main/java/parquet/hive/serde/ArrayWritableObjectInspector.java": [
                23,
                7
            ],
            "parquet-hive/src/main/java/parquet/hive/serde/ParquetHiveArrayInspector.java": [
                2,
                2
            ],
            "parquet-hive/src/main/java/parquet/hive/serde/ParquetHiveSerDe.java": [
                1,
                2
            ],
            "parquet-hive/src/main/java/parquet/hive/writable/BinaryWritable.java": [
                7,
                59
            ],
            "parquet-hive/src/main/java/parquet/hive/write/DataWritableWriter.java": [
                1,
                1
            ],
            "parquet-hive/src/test/java/parquet/hive/TestParquetSerDe.java": [
                3,
                4
            ],
            "parquet-hive/src/test/java/parquet/hive/UtilitiesTestMethods.java": [
                11,
                11
            ],
            "parquet-pig-bundle/pom.xml": null,
            "parquet-pig/pom.xml": null,
            "parquet-scrooge/pom.xml": null,
            "parquet-test-hadoop2/pom.xml": null,
            "parquet-thrift/pom.xml": null,
            "parquet-thrift/src/main/java/parquet/thrift/struct/CompatibilityChecker.java": [
                0,
                220
            ],
            "parquet-thrift/src/main/java/parquet/thrift/struct/CompatibilityRunner.java": [
                0,
                96
            ],
            "parquet-thrift/src/test/java/parquet/thrift/struct/CompatibilityCheckerTest.java": [
                0,
                117
            ],
            "parquet-thrift/src/test/thrift/compat.thrift": null,
            "pom.xml": null
        }
    },
    "10f266aef9faf78fb8cd07f488674c67f3bbf3a3": {
        "datetime": "2013-10-14T08:53:43-07:00",
        "summary": "Cleaning method signature for binary case.",
        "message": "Cleaning method signature for binary case.\n",
        "diff": {
            "parquet-column/src/main/java/parquet/filter/ColumnPredicates.java": [
                2,
                2
            ]
        }
    },
    "73c86295a70e6ce98ed22ab213aafb105365e475": {
        "datetime": "2013-10-14T15:43:22-07:00",
        "summary": "Misunderstood previous comment. Fixed binary predicate.",
        "message": "Misunderstood previous comment. Fixed binary predicate.\n",
        "diff": {
            "parquet-column/src/main/java/parquet/filter/ColumnPredicates.java": [
                1,
                2
            ]
        }
    },
    "cf0ee72e21df7afa17edea77d6894d40b73da4de": {
        "datetime": "2013-10-14T16:05:35-07:00",
        "summary": "Merge pull request #188 from fnothaft/master",
        "message": "Merge pull request #188 from fnothaft/master\n\nAdded ability to define arbitrary predicate functions",
        "diff": {
            "parquet-column/src/main/java/parquet/filter/ColumnPredicates.java": [
                0,
                90
            ],
            "parquet-column/src/test/java/parquet/io/TestFiltered.java": [
                0,
                72
            ]
        }
    },
    "256a3a1eb328e6f02eebc82eb37d91ad69e475d5": {
        "datetime": "2013-10-15T16:20:15-07:00",
        "summary": "Fix issue 193: RLE decoder reading past the end of the stream.",
        "message": "Fix issue 193: RLE decoder reading past the end of the stream.\n\nIf literal groups are not padded to groups of 8, the decoder reads past the end.\n",
        "diff": {
            "parquet-column/src/main/java/parquet/column/values/dictionary/DictionaryValuesReader.java": [
                2,
                2
            ],
            "parquet-column/src/main/java/parquet/column/values/rle/RunLengthBitPackingHybridDecoder.java": [
                13,
                8
            ],
            "parquet-column/src/main/java/parquet/column/values/rle/RunLengthBitPackingHybridValuesReader.java": [
                1,
                1
            ],
            "parquet-column/src/test/java/parquet/column/values/rle/RunLengthBitPackingHybridIntegrationTest.java": [
                2,
                3
            ],
            "parquet-column/src/test/java/parquet/column/values/rle/TestRunLengthBitPackingHybridEncoder.java": [
                1,
                1
            ]
        }
    },
    "d4eeeccfa3f85155b0ca2892a30cba990c22a25e": {
        "datetime": "2013-10-16T16:27:01-07:00",
        "summary": "Merge pull request #197 from Parquet/issue-193",
        "message": "Merge pull request #197 from Parquet/issue-193\n\nFix issue 193: RLE decoder reading past the end of the stream.",
        "diff": {
            "parquet-column/src/main/java/parquet/column/values/dictionary/DictionaryValuesReader.java": [
                2,
                2
            ],
            "parquet-column/src/main/java/parquet/column/values/rle/RunLengthBitPackingHybridDecoder.java": [
                13,
                8
            ],
            "parquet-column/src/main/java/parquet/column/values/rle/RunLengthBitPackingHybridValuesReader.java": [
                1,
                1
            ],
            "parquet-column/src/test/java/parquet/column/values/rle/RunLengthBitPackingHybridIntegrationTest.java": [
                2,
                3
            ],
            "parquet-column/src/test/java/parquet/column/values/rle/TestRunLengthBitPackingHybridEncoder.java": [
                1,
                1
            ]
        }
    },
    "22cf7fe9d8ef12e33b3fa43fae86fc7e8680271f": {
        "datetime": "2013-10-18T17:39:12+02:00",
        "summary": "Inspect keys only for a few types in parquet hive maps",
        "message": "Inspect keys only for a few types in parquet hive maps\n",
        "diff": {
            "parquet-hive/src/main/java/parquet/hive/serde/ArrayWritableObjectInspector.java": [
                1,
                6
            ],
            "parquet-hive/src/main/java/parquet/hive/serde/DeepParquetHiveMapInspector.java": [
                0,
                77
            ],
            "parquet-hive/src/main/java/parquet/hive/serde/ParquetHiveMapInspector.java": [
                52,
                30
            ],
            "parquet-hive/src/main/java/parquet/hive/serde/StandardParquetHiveMapInspector.java": [
                0,
                60
            ]
        }
    },
    "90645004606cfbb33c79a385bc594854edce138e": {
        "datetime": "2013-10-18T17:39:12+02:00",
        "summary": "Add some javadoc to clarify",
        "message": "Add some javadoc to clarify\n",
        "diff": {
            "parquet-hive/src/main/java/parquet/hive/serde/ArrayWritableObjectInspector.java": [
                2,
                2
            ],
            "parquet-hive/src/main/java/parquet/hive/serde/ParquetHiveArrayInspector.java": [
                0,
                6
            ],
            "parquet-hive/src/main/java/parquet/hive/serde/ParquetHiveMapInspector.java": [
                0,
                6
            ],
            "parquet-hive/src/main/java/parquet/hive/serde/primitive/ParquetByteInspector.java": [
                0,
                1
            ],
            "parquet-hive/src/main/java/parquet/hive/serde/primitive/ParquetPrimitiveInspectorFactory.java": [
                0,
                2
            ],
            "parquet-hive/src/main/java/parquet/hive/serde/primitive/ParquetShortInspector.java": [
                0,
                1
            ],
            "parquet-hive/src/main/java/parquet/hive/serde/primitive/ParquetStringInspector.java": [
                1,
                3
            ]
        }
    },
    "4bdaec06595f35d4b7bb4c1baf35ca0d16b25619": {
        "datetime": "2013-10-18T17:39:12+02:00",
        "summary": "Fix #177: Inspect key when accessing maps",
        "message": "Fix #177: Inspect key when accessing maps\n",
        "diff": {
            "parquet-hive/src/main/java/parquet/hive/serde/ParquetHiveMapInspector.java": [
                4,
                19
            ]
        }
    },
    "c5f68c51cb72503e7f9c483e009d94ed66aac335": {
        "datetime": "2013-10-18T17:39:12+02:00",
        "summary": "Extract primitive inspectors and instantiate them only once",
        "message": "Extract primitive inspectors and instantiate them only once\n",
        "diff": {
            "parquet-hive/src/main/java/parquet/hive/serde/ArrayWritableObjectInspector.java": [
                126,
                4
            ],
            "parquet-hive/src/main/java/parquet/hive/serde/primitive/ParquetByteInspector.java": [
                0,
                58
            ],
            "parquet-hive/src/main/java/parquet/hive/serde/primitive/ParquetPrimitiveInspectorFactory.java": [
                0,
                30
            ],
            "parquet-hive/src/main/java/parquet/hive/serde/primitive/ParquetShortInspector.java": [
                0,
                58
            ],
            "parquet-hive/src/main/java/parquet/hive/serde/primitive/ParquetStringInspector.java": [
                0,
                98
            ]
        }
    },
    "d9e5f0bc2d7482062db72bddcb3eeefda05b2143": {
        "datetime": "2013-10-18T17:39:12+02:00",
        "summary": "Implement correctly Settable inspectors",
        "message": "Implement correctly Settable inspectors\n\n- Array inspector implements correctly set and resize\n- Map inspector implements settable\n- Root (and struct) inspector implements settable\n- Inspectors will now inspect basic objects because Hive sometimes\ndoes that\n",
        "diff": {
            "parquet-hive/src/main/java/parquet/hive/serde/ArrayWritableObjectInspector.java": [
                28,
                73
            ],
            "parquet-hive/src/main/java/parquet/hive/serde/ParquetHiveArrayInspector.java": [
                33,
                50
            ],
            "parquet-hive/src/main/java/parquet/hive/serde/ParquetHiveMapInspector.java": [
                28,
                80
            ]
        }
    },
    "c9146a6eaa854499a5d099edf48d0b961d3a60a3": {
        "datetime": "2013-10-18T09:53:34-07:00",
        "summary": "Merge pull request #196 from Parquet/hive_fixes",
        "message": "Merge pull request #196 from Parquet/hive_fixes\n\nFixes to the Hive SerDe",
        "diff": {
            "parquet-hive/src/main/java/parquet/hive/read/DataWritableReadSupport.java": [
                28,
                34
            ],
            "parquet-hive/src/main/java/parquet/hive/serde/AbstractParquetMapInspector.java": [
                0,
                153
            ],
            "parquet-hive/src/main/java/parquet/hive/serde/ArrayWritableObjectInspector.java": [
                144,
                72
            ],
            "parquet-hive/src/main/java/parquet/hive/serde/DeepParquetHiveMapInspector.java": [
                0,
                77
            ],
            "parquet-hive/src/main/java/parquet/hive/serde/ParquetHiveArrayInspector.java": [
                33,
                56
            ],
            "parquet-hive/src/main/java/parquet/hive/serde/ParquetHiveMapInspector.java": [
                102,
                0
            ],
            "parquet-hive/src/main/java/parquet/hive/serde/StandardParquetHiveMapInspector.java": [
                0,
                60
            ],
            "parquet-hive/src/main/java/parquet/hive/serde/primitive/ParquetByteInspector.java": [
                0,
                59
            ],
            "parquet-hive/src/main/java/parquet/hive/serde/primitive/ParquetPrimitiveInspectorFactory.java": [
                0,
                32
            ],
            "parquet-hive/src/main/java/parquet/hive/serde/primitive/ParquetShortInspector.java": [
                0,
                59
            ],
            "parquet-hive/src/main/java/parquet/hive/serde/primitive/ParquetStringInspector.java": [
                0,
                100
            ]
        }
    },
    "a991eff830f3c384396c1eba152462c6e6d1e6c6": {
        "datetime": "2013-10-18T10:19:40-07:00",
        "summary": "Merge branch 'master' into dictionary_changes",
        "message": "Merge branch 'master' into dictionary_changes\n\nConflicts:\n\tparquet-column/src/main/java/parquet/column/impl/ColumnWriterImpl.java\n\tparquet-column/src/main/java/parquet/column/values/dictionary/DictionaryValuesWriter.java\n\tparquet-column/src/test/java/parquet/io/TestColumnIO.java\n\tparquet-column/src/test/java/parquet/io/TestFiltered.java\n\tparquet-hadoop/src/main/java/parquet/hadoop/InternalParquetRecordWriter.java\n\tparquet-hadoop/src/main/java/parquet/hadoop/ParquetOutputFormat.java\n",
        "diff": {
            "CHANGES.md": null,
            "README.md": null,
            "parquet-avro/pom.xml": null,
            "parquet-avro/src/main/java/parquet/avro/AvroIndexedRecordConverter.java": [
                3,
                30
            ],
            "parquet-avro/src/main/java/parquet/avro/AvroParquetReader.java": [
                1,
                13
            ],
            "parquet-avro/src/main/java/parquet/avro/AvroSchemaConverter.java": [
                5,
                14
            ],
            "parquet-avro/src/main/java/parquet/avro/AvroWriteSupport.java": [
                34,
                42
            ],
            "parquet-avro/src/test/java/parquet/avro/TestAvroSchemaConverter.java": [
                8,
                19
            ],
            "parquet-avro/src/test/java/parquet/avro/TestReadWrite.java": [
                9,
                105
            ],
            "parquet-avro/src/test/java/parquet/avro/TestSpecificInputOutputFormat.java": [
                10,
                12
            ],
            "parquet-avro/src/test/java/parquet/avro/TestSpecificReadWrite.java": [
                31,
                75
            ],
            "parquet-avro/src/test/resources/all-minus-fixed.avsc": null,
            "parquet-avro/src/test/resources/all.avsc": null,
            "parquet-avro/src/test/resources/array.avsc": null,
            "parquet-avro/src/test/resources/car.avdl": null,
            "parquet-avro/src/test/resources/map.avsc": null,
            "parquet-cascading/pom.xml": null,
            "parquet-cascading/src/main/java/parquet/cascading/ParquetTBaseScheme.java": [
                19,
                24
            ],
            "parquet-cascading/src/main/java/parquet/cascading/ParquetValueScheme.java": [
                0,
                16
            ],
            "parquet-cascading/src/test/java/parquet/cascading/TestParquetTBaseScheme.java": [
                46,
                150
            ],
            "parquet-cascading/src/test/java/parquet/cascading/TestParquetTupleScheme.java": [
                0,
                15
            ],
            "parquet-cascading/src/test/resources/names.txt": null,
            "parquet-cascading/src/test/thrift/test.thrift": null,
            "parquet-column/pom.xml": null,
            "parquet-column/src/main/java/parquet/column/ColumnDescriptor.java": [
                2,
                24
            ],
            "parquet-column/src/main/java/parquet/column/ColumnWriter.java": [
                0,
                1
            ],
            "parquet-column/src/main/java/parquet/column/Encoding.java": [
                0,
                3
            ],
            "parquet-column/src/main/java/parquet/column/impl/ColumnReaderImpl.java": [
                3,
                19
            ],
            "parquet-column/src/main/java/parquet/column/impl/ColumnWriterImpl.java": [
                9,
                13
            ],
            "parquet-column/src/main/java/parquet/column/values/ValuesReader.java": [
                0,
                1
            ],
            "parquet-column/src/main/java/parquet/column/values/dictionary/DictionaryValuesReader.java": [
                2,
                2
            ],
            "parquet-column/src/main/java/parquet/column/values/dictionary/PlainValuesDictionary.java": [
                1,
                2
            ],
            "parquet-column/src/main/java/parquet/column/values/plain/FixedLenByteArrayPlainValuesReader.java": [
                0,
                67
            ],
            "parquet-column/src/main/java/parquet/column/values/plain/FixedLenByteArrayPlainValuesWriter.java": [
                0,
                95
            ],
            "parquet-column/src/main/java/parquet/column/values/rle/RunLengthBitPackingHybridDecoder.java": [
                13,
                8
            ],
            "parquet-column/src/main/java/parquet/column/values/rle/RunLengthBitPackingHybridValuesReader.java": [
                1,
                1
            ],
            "parquet-column/src/main/java/parquet/example/data/simple/convert/SimplePrimitiveConverter.java": [
                5,
                4
            ],
            "parquet-column/src/main/java/parquet/filter/ColumnPredicates.java": [
                0,
                90
            ],
            "parquet-column/src/main/java/parquet/filter/NotRecordFilter.java": [
                0,
                55
            ],
            "parquet-column/src/main/java/parquet/filter/OrRecordFilter.java": [
                0,
                59
            ],
            "parquet-column/src/main/java/parquet/io/PrimitiveColumnIO.java": [
                1,
                8
            ],
            "parquet-column/src/main/java/parquet/io/RecordReaderImplementation.java": [
                42,
                45
            ],
            "parquet-column/src/main/java/parquet/io/api/Binary.java": [
                0,
                20
            ],
            "parquet-column/src/main/java/parquet/schema/ConversionPatterns.java": [
                29,
                42
            ],
            "parquet-column/src/main/java/parquet/schema/GroupType.java": [
                4,
                62
            ],
            "parquet-column/src/main/java/parquet/schema/IncompatibleSchemaModificationException.java": [
                0,
                46
            ],
            "parquet-column/src/main/java/parquet/schema/MessageType.java": [
                4,
                16
            ],
            "parquet-column/src/main/java/parquet/schema/MessageTypeParser.java": [
                1,
                18
            ],
            "parquet-column/src/main/java/parquet/schema/PrimitiveType.java": [
                19,
                66
            ],
            "parquet-column/src/main/java/parquet/schema/Type.java": [
                4,
                62
            ],
            "parquet-column/src/test/java/parquet/column/values/rle/RunLengthBitPackingHybridIntegrationTest.java": [
                2,
                3
            ],
            "parquet-column/src/test/java/parquet/column/values/rle/TestRunLengthBitPackingHybridEncoder.java": [
                1,
                1
            ],
            "parquet-column/src/test/java/parquet/io/ExpectationValidatingRecordConsumer.java": [
                0,
                1
            ],
            "parquet-column/src/test/java/parquet/io/TestColumnIO.java": [
                18,
                16
            ],
            "parquet-column/src/test/java/parquet/io/TestFiltered.java": [
                0,
                110
            ],
            "parquet-column/src/test/java/parquet/schema/TestMessageType.java": [
                2,
                86
            ],
            "parquet-common/pom.xml": null,
            "parquet-encoding/pom.xml": null,
            "parquet-generator/pom.xml": null,
            "parquet-hadoop/pom.xml": null,
            "parquet-hadoop/src/main/java/parquet/format/converter/ParquetMetadataConverter.java": [
                12,
                18
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/InternalParquetRecordReader.java": [
                1,
                4
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/InternalParquetRecordWriter.java": [
                6,
                16
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/ParquetFileReader.java": [
                23,
                26
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/ParquetFileWriter.java": [
                27,
                70
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/ParquetInputFormat.java": [
                18,
                34
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/ParquetOutputFormat.java": [
                71,
                125
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/ParquetReader.java": [
                14,
                83
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/api/InitContext.java": [
                0,
                99
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/api/ReadSupport.java": [
                2,
                17
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/codec/NonBlockedCompressorStream.java": [
                0,
                15
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/codec/NonBlockedDecompressorStream.java": [
                0,
                15
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/mapred/DeprecatedParquetOutputFormat.java": [
                0,
                130
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/metadata/FileMetaData.java": [
                8,
                5
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/metadata/GlobalMetaData.java": [
                0,
                103
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/util/counters/ICounter.java": [
                0,
                15
            ],
            "parquet-hadoop/src/test/java/parquet/hadoop/DeprecatedInputFormatTest.java": [
                1,
                1
            ],
            "parquet-hadoop/src/test/java/parquet/hadoop/DeprecatedOutputFormatTest.java": [
                0,
                106
            ],
            "parquet-hadoop/src/test/java/parquet/hadoop/TestParquetFileWriter.java": [
                0,
                29
            ],
            "parquet-hadoop/src/test/java/parquet/hadoop/example/GroupReadSupportTest.java": [
                0,
                15
            ],
            "parquet-hive/pom.xml": null,
            "parquet-hive/src/main/java/parquet/hive/convert/DataWritableGroupConverter.java": [
                3,
                1
            ],
            "parquet-hive/src/main/java/parquet/hive/convert/ETypeConverter.java": [
                172,
                54
            ],
            "parquet-hive/src/main/java/parquet/hive/read/DataWritableReadSupport.java": [
                28,
                34
            ],
            "parquet-hive/src/main/java/parquet/hive/serde/AbstractParquetMapInspector.java": [
                0,
                153
            ],
            "parquet-hive/src/main/java/parquet/hive/serde/ArrayWritableObjectInspector.java": [
                160,
                72
            ],
            "parquet-hive/src/main/java/parquet/hive/serde/DeepParquetHiveMapInspector.java": [
                0,
                77
            ],
            "parquet-hive/src/main/java/parquet/hive/serde/ParquetHiveArrayInspector.java": [
                33,
                56
            ],
            "parquet-hive/src/main/java/parquet/hive/serde/ParquetHiveMapInspector.java": [
                102,
                0
            ],
            "parquet-hive/src/main/java/parquet/hive/serde/ParquetHiveSerDe.java": [
                1,
                2
            ],
            "parquet-hive/src/main/java/parquet/hive/serde/StandardParquetHiveMapInspector.java": [
                0,
                60
            ],
            "parquet-hive/src/main/java/parquet/hive/serde/primitive/ParquetByteInspector.java": [
                0,
                59
            ],
            "parquet-hive/src/main/java/parquet/hive/serde/primitive/ParquetPrimitiveInspectorFactory.java": [
                0,
                32
            ],
            "parquet-hive/src/main/java/parquet/hive/serde/primitive/ParquetShortInspector.java": [
                0,
                59
            ],
            "parquet-hive/src/main/java/parquet/hive/serde/primitive/ParquetStringInspector.java": [
                0,
                100
            ],
            "parquet-hive/src/main/java/parquet/hive/writable/BinaryWritable.java": [
                7,
                59
            ],
            "parquet-hive/src/main/java/parquet/hive/write/DataWritableWriter.java": [
                1,
                1
            ],
            "parquet-hive/src/test/java/parquet/hive/TestHiveSchemaConverter.java": [
                3,
                2
            ],
            "parquet-hive/src/test/java/parquet/hive/TestParquetSerDe.java": [
                3,
                4
            ],
            "parquet-hive/src/test/java/parquet/hive/UtilitiesTestMethods.java": [
                11,
                11
            ],
            "parquet-pig-bundle/pom.xml": null,
            "parquet-pig-bundle/src/main/resources/parquet/bundle": null,
            "parquet-pig/pom.xml": null,
            "parquet-pig/src/main/java/parquet/pig/ParquetLoader.java": [
                41,
                65
            ],
            "parquet-pig/src/main/java/parquet/pig/PigMetaData.java": [
                5,
                40
            ],
            "parquet-pig/src/main/java/parquet/pig/PigSchemaConverter.java": [
                94,
                150
            ],
            "parquet-pig/src/main/java/parquet/pig/TupleReadSupport.java": [
                26,
                76
            ],
            "parquet-pig/src/test/java/parquet/pig/TestParquetLoader.java": [
                8,
                75
            ],
            "parquet-pig/src/test/java/parquet/pig/TestParquetStorer.java": [
                1,
                63
            ],
            "parquet-pig/src/test/java/parquet/pig/TestPigSchemaConverter.java": [
                8,
                57
            ],
            "parquet-pig/src/test/java/parquet/pig/TestTupleRecordConsumer.java": [
                1,
                13
            ],
            "parquet-scrooge/pom.xml": null,
            "parquet-scrooge/src/test/java/parquet/scrooge/ParquetScroogeSchemeTest.java": [
                0,
                93
            ],
            "parquet-scrooge/src/test/thrift/test.thrift": null,
            "parquet-test-hadoop2/pom.xml": null,
            "parquet-thrift/pom.xml": null,
            "parquet-thrift/src/main/java/parquet/hadoop/thrift/ThriftBytesWriteSupport.java": [
                1,
                1
            ],
            "parquet-thrift/src/main/java/parquet/hadoop/thrift/ThriftReadSupport.java": [
                13,
                44
            ],
            "parquet-thrift/src/main/java/parquet/thrift/BufferedProtocolReadToWrite.java": [
                14,
                26
            ],
            "parquet-thrift/src/main/java/parquet/thrift/ParquetProtocol.java": [
                2,
                2
            ],
            "parquet-thrift/src/main/java/parquet/thrift/SkippableException.java": [
                0,
                32
            ],
            "parquet-thrift/src/main/java/parquet/thrift/ThriftMetaData.java": [
                10,
                49
            ],
            "parquet-thrift/src/main/java/parquet/thrift/ThriftParquetReader.java": [
                0,
                21
            ],
            "parquet-thrift/src/main/java/parquet/thrift/ThriftRecordConverter.java": [
                2,
                9
            ],
            "parquet-thrift/src/main/java/parquet/thrift/ThriftSchemaConvertVisitor.java": [
                0,
                256
            ],
            "parquet-thrift/src/main/java/parquet/thrift/ThriftSchemaConverter.java": [
                166,
                20
            ],
            "parquet-thrift/src/main/java/parquet/thrift/projection/FieldProjectionFilter.java": [
                9,
                3
            ],
            "parquet-thrift/src/main/java/parquet/thrift/projection/FieldsPath.java": [
                0,
                82
            ],
            "parquet-thrift/src/main/java/parquet/thrift/projection/amend/DefaultEventsVisitor.java": [
                0,
                212
            ],
            "parquet-thrift/src/main/java/parquet/thrift/projection/amend/DefaultProtocolEventsGenerator.java": [
                0,
                65
            ],
            "parquet-thrift/src/main/java/parquet/thrift/projection/amend/ProtocolEventsAmender.java": [
                0,
                170
            ],
            "parquet-thrift/src/main/java/parquet/thrift/projection/amend/ReadFieldBeginProtocol.java": [
                0,
                41
            ],
            "parquet-thrift/src/main/java/parquet/thrift/struct/CompatibilityChecker.java": [
                0,
                220
            ],
            "parquet-thrift/src/main/java/parquet/thrift/struct/CompatibilityRunner.java": [
                0,
                96
            ],
            "parquet-thrift/src/test/java/parquet/hadoop/thrift/TestInputOutputFormat.java": [
                0,
                108
            ],
            "parquet-thrift/src/test/java/parquet/hadoop/thrift/TestParquetToThriftReadProjection.java": [
                27,
                125
            ],
            "parquet-thrift/src/test/java/parquet/thrift/TestProtocolReadToWrite.java": [
                6,
                24
            ],
            "parquet-thrift/src/test/java/parquet/thrift/TestThriftSchemaConverter.java": [
                34,
                61
            ],
            "parquet-thrift/src/test/java/parquet/thrift/struct/CompatibilityCheckerTest.java": [
                0,
                117
            ],
            "parquet-thrift/src/test/thrift/compat.thrift": null,
            "parquet-thrift/src/test/thrift/test.thrift": null,
            "pom.xml": null
        }
    },
    "0a76cc29b703fc95949736910a5a63ce9c1c0814": {
        "datetime": "2013-10-18T10:36:52-07:00",
        "summary": "Fix #198: simplify TupleWriteSupport constructor",
        "message": "Fix #198: simplify TupleWriteSupport constructor\n",
        "diff": {
            "parquet-pig/src/main/java/parquet/pig/ParquetStorer.java": [
                3,
                1
            ],
            "parquet-pig/src/main/java/parquet/pig/TupleWriteSupport.java": [
                2,
                20
            ],
            "parquet-pig/src/test/java/parquet/pig/TestTupleRecordConsumer.java": [
                11,
                9
            ],
            "parquet-pig/src/test/java/parquet/pig/TupleConsumerPerfTest.java": [
                1,
                1
            ],
            "parquet-thrift/src/test/java/parquet/thrift/TestParquetWriteProtocol.java": [
                1,
                1
            ]
        }
    },
    "f52d35ba6c33efe824fc59dc1fa33d23bfec85bb": {
        "datetime": "2013-10-18T10:38:23-07:00",
        "summary": "Merge pull request #164 from Parquet/dictionary_changes",
        "message": "Merge pull request #164 from Parquet/dictionary_changes\n\nDictionary changes",
        "diff": {
            "parquet-column/pom.xml": null,
            "parquet-column/src/main/java/parquet/column/impl/ColumnWriteStoreImpl.java": [
                2,
                4
            ],
            "parquet-column/src/main/java/parquet/column/impl/ColumnWriterImpl.java": [
                18,
                16
            ],
            "parquet-column/src/main/java/parquet/column/values/dictionary/DictionaryValuesWriter.java": [
                42,
                54
            ],
            "parquet-column/src/test/java/parquet/column/mem/TestMemColumn.java": [
                4,
                8
            ],
            "parquet-column/src/test/java/parquet/column/values/dictionary/TestDictionary.java": [
                324,
                119
            ],
            "parquet-column/src/test/java/parquet/io/PerfTest.java": [
                1,
                1
            ],
            "parquet-column/src/test/java/parquet/io/TestColumnIO.java": [
                11,
                14
            ],
            "parquet-column/src/test/java/parquet/io/TestFiltered.java": [
                29,
                27
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/InternalParquetRecordWriter.java": [
                16,
                22
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/ParquetOutputFormat.java": [
                10,
                29
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/ParquetRecordWriter.java": [
                2,
                15
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/ParquetWriter.java": [
                4,
                39
            ],
            "parquet-hive/src/test/java/parquet/hive/TestDeprecatedParquetInputFormat.java": [
                1,
                1
            ],
            "parquet-pig/src/test/java/parquet/pig/GenerateIntTestFile.java": [
                1,
                1
            ],
            "parquet-pig/src/test/java/parquet/pig/GenerateTPCH.java": [
                1,
                1
            ],
            "parquet-pig/src/test/java/parquet/pig/TupleConsumerPerfTest.java": [
                1,
                1
            ],
            "parquet-thrift/src/test/java/parquet/thrift/TestParquetReadProtocol.java": [
                1,
                1
            ]
        }
    },
    "5601394e85387a69f171884792ad683a39c7eec1": {
        "datetime": "2013-10-18T15:18:50-07:00",
        "summary": "make static field final",
        "message": "make static field final\n",
        "diff": {
            "parquet-pig/src/main/java/parquet/pig/TupleWriteSupport.java": [
                1,
                1
            ]
        }
    },
    "a905704ee5dcaed9d42af0598782e96172ab45c1": {
        "datetime": "2013-10-18T17:20:51-07:00",
        "summary": "Merge pull request #199 from Parquet/simplify_tuple_write",
        "message": "Merge pull request #199 from Parquet/simplify_tuple_write\n\nFix #198: simplify TupleWriteSupport constructor",
        "diff": {
            "parquet-pig/src/main/java/parquet/pig/ParquetStorer.java": [
                3,
                1
            ],
            "parquet-pig/src/main/java/parquet/pig/TupleWriteSupport.java": [
                2,
                20
            ],
            "parquet-pig/src/test/java/parquet/pig/TestTupleRecordConsumer.java": [
                11,
                9
            ],
            "parquet-pig/src/test/java/parquet/pig/TupleConsumerPerfTest.java": [
                1,
                1
            ],
            "parquet-thrift/src/test/java/parquet/thrift/TestParquetWriteProtocol.java": [
                1,
                1
            ]
        }
    },
    "a736c62888e59783efc68bb480de3b8cf61fedf8": {
        "datetime": "2013-10-18T17:55:13-07:00",
        "summary": "Merge branch 'master' into plumb_original_type",
        "message": "Merge branch 'master' into plumb_original_type\n",
        "diff": {
            "parquet-column/pom.xml": null,
            "parquet-column/src/main/java/parquet/column/impl/ColumnWriteStoreImpl.java": [
                2,
                4
            ],
            "parquet-column/src/main/java/parquet/column/impl/ColumnWriterImpl.java": [
                18,
                16
            ],
            "parquet-column/src/main/java/parquet/column/values/dictionary/DictionaryValuesReader.java": [
                2,
                2
            ],
            "parquet-column/src/main/java/parquet/column/values/dictionary/DictionaryValuesWriter.java": [
                42,
                54
            ],
            "parquet-column/src/main/java/parquet/column/values/rle/RunLengthBitPackingHybridDecoder.java": [
                13,
                8
            ],
            "parquet-column/src/main/java/parquet/column/values/rle/RunLengthBitPackingHybridValuesReader.java": [
                1,
                1
            ],
            "parquet-column/src/main/java/parquet/filter/ColumnPredicates.java": [
                0,
                90
            ],
            "parquet-column/src/test/java/parquet/column/mem/TestMemColumn.java": [
                4,
                8
            ],
            "parquet-column/src/test/java/parquet/column/values/dictionary/TestDictionary.java": [
                324,
                119
            ],
            "parquet-column/src/test/java/parquet/column/values/rle/RunLengthBitPackingHybridIntegrationTest.java": [
                2,
                3
            ],
            "parquet-column/src/test/java/parquet/column/values/rle/TestRunLengthBitPackingHybridEncoder.java": [
                1,
                1
            ],
            "parquet-column/src/test/java/parquet/io/PerfTest.java": [
                1,
                1
            ],
            "parquet-column/src/test/java/parquet/io/TestColumnIO.java": [
                11,
                14
            ],
            "parquet-column/src/test/java/parquet/io/TestFiltered.java": [
                21,
                91
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/InternalParquetRecordWriter.java": [
                16,
                22
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/ParquetOutputFormat.java": [
                10,
                29
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/ParquetRecordWriter.java": [
                2,
                15
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/ParquetWriter.java": [
                4,
                39
            ],
            "parquet-hive/src/main/java/parquet/hive/read/DataWritableReadSupport.java": [
                28,
                34
            ],
            "parquet-hive/src/main/java/parquet/hive/serde/AbstractParquetMapInspector.java": [
                0,
                153
            ],
            "parquet-hive/src/main/java/parquet/hive/serde/ArrayWritableObjectInspector.java": [
                144,
                72
            ],
            "parquet-hive/src/main/java/parquet/hive/serde/DeepParquetHiveMapInspector.java": [
                0,
                77
            ],
            "parquet-hive/src/main/java/parquet/hive/serde/ParquetHiveArrayInspector.java": [
                33,
                56
            ],
            "parquet-hive/src/main/java/parquet/hive/serde/ParquetHiveMapInspector.java": [
                102,
                0
            ],
            "parquet-hive/src/main/java/parquet/hive/serde/StandardParquetHiveMapInspector.java": [
                0,
                60
            ],
            "parquet-hive/src/main/java/parquet/hive/serde/primitive/ParquetByteInspector.java": [
                0,
                59
            ],
            "parquet-hive/src/main/java/parquet/hive/serde/primitive/ParquetPrimitiveInspectorFactory.java": [
                0,
                32
            ],
            "parquet-hive/src/main/java/parquet/hive/serde/primitive/ParquetShortInspector.java": [
                0,
                59
            ],
            "parquet-hive/src/main/java/parquet/hive/serde/primitive/ParquetStringInspector.java": [
                0,
                100
            ],
            "parquet-hive/src/test/java/parquet/hive/TestDeprecatedParquetInputFormat.java": [
                1,
                1
            ],
            "parquet-pig/src/main/java/parquet/pig/ParquetStorer.java": [
                3,
                1
            ],
            "parquet-pig/src/main/java/parquet/pig/TupleWriteSupport.java": [
                2,
                20
            ],
            "parquet-pig/src/test/java/parquet/pig/GenerateIntTestFile.java": [
                1,
                1
            ],
            "parquet-pig/src/test/java/parquet/pig/GenerateTPCH.java": [
                1,
                1
            ],
            "parquet-pig/src/test/java/parquet/pig/TestTupleRecordConsumer.java": [
                11,
                9
            ],
            "parquet-pig/src/test/java/parquet/pig/TupleConsumerPerfTest.java": [
                2,
                2
            ],
            "parquet-thrift/src/test/java/parquet/thrift/TestParquetReadProtocol.java": [
                1,
                1
            ],
            "parquet-thrift/src/test/java/parquet/thrift/TestParquetWriteProtocol.java": [
                1,
                1
            ]
        }
    },
    "943591829c87898788558ec323a38c6946b7eb6e": {
        "datetime": "2013-10-23T18:59:56+02:00",
        "summary": "Fix requested schema when recreating splits in hive",
        "message": "Fix requested schema when recreating splits in hive\n",
        "diff": {
            "parquet-hive/src/main/java/parquet/hive/DeprecatedParquetInputFormat.java": [
                1,
                1
            ]
        }
    },
    "005bc68b000ad37cff5c0f0400d4ef18fe8af80f": {
        "datetime": "2013-10-23T11:14:09-07:00",
        "summary": "add null check for EnumWriteProtocol",
        "message": "add null check for EnumWriteProtocol\n",
        "diff": {
            "parquet-thrift/src/main/java/parquet/thrift/ParquetWriteProtocol.java": [
                2,
                7
            ]
        }
    },
    "8edc893e60e584a03369b6ac71800232bc13f7d6": {
        "datetime": "2013-10-23T12:16:27-07:00",
        "summary": "Initial commit",
        "message": "Initial commit\n",
        "diff": {
            ".editorconfig": null,
            ".github/PULL_REQUEST_TEMPLATE.md": null,
            ".github/dependabot.yml": null,
            ".github/workflows/ci-hadoop2.yml": null,
            ".github/workflows/ci-hadoop3.yml": null,
            ".github/workflows/vector-plugins.yml": null,
            ".gitignore": null,
            "CHANGES.md": null,
            "LICENSE": null,
            "NOTICE": null,
            "PoweredBy.md": null,
            "README.md": null,
            "changelog.sh": null,
            "dev/COMMITTERS.md": null,
            "dev/README.md": null,
            "dev/ci-before_install-master.sh": null,
            "dev/ci-before_install.sh": null,
            "dev/finalize-release": null,
            "dev/merge_parquet_pr.py": [
                393,
                0
            ],
            "dev/prepare-release.sh": null,
            "dev/source-release.sh": null,
            "doc/dremel_paper/dremel_example.png": null,
            "doc/dremel_paper/schema.png": null,
            "parquet-arrow/pom.xml": null,
            "parquet-arrow/src/main/java/org/apache/parquet/arrow/schema/List3Levels.java": [
                77,
                0
            ],
            "parquet-arrow/src/main/java/org/apache/parquet/arrow/schema/SchemaConverter.java": [
                705,
                0
            ],
            "parquet-arrow/src/main/java/org/apache/parquet/arrow/schema/SchemaMapping.java": [
                201,
                0
            ],
            "parquet-arrow/src/test/java/org/apache/parquet/arrow/schema/TestSchemaConverter.java": [
                530,
                0
            ],
            "parquet-avro/README.md": null,
            "parquet-avro/REVIEWERS.md": null,
            "parquet-avro/pom.xml": null,
            "parquet-avro/src/main/java/org/apache/parquet/avro/AvroCompatRecordMaterializer.java": [
                46,
                0
            ],
            "parquet-avro/src/main/java/org/apache/parquet/avro/AvroConverters.java": [
                333,
                0
            ],
            "parquet-avro/src/main/java/org/apache/parquet/avro/AvroDataSupplier.java": [
                31,
                0
            ],
            "parquet-avro/src/main/java/org/apache/parquet/avro/AvroIndexedRecordConverter.java": [
                535,
                0
            ],
            "parquet-avro/src/main/java/org/apache/parquet/avro/AvroParquetInputFormat.java": [
                86,
                0
            ],
            "parquet-avro/src/main/java/org/apache/parquet/avro/AvroParquetOutputFormat.java": [
                63,
                0
            ],
            "parquet-avro/src/main/java/org/apache/parquet/avro/AvroParquetReader.java": [
                178,
                0
            ],
            "parquet-avro/src/main/java/org/apache/parquet/avro/AvroParquetWriter.java": [
                193,
                0
            ],
            "parquet-avro/src/main/java/org/apache/parquet/avro/AvroReadSupport.java": [
                180,
                0
            ],
            "parquet-avro/src/main/java/org/apache/parquet/avro/AvroRecordConverter.java": [
                1093,
                0
            ],
            "parquet-avro/src/main/java/org/apache/parquet/avro/AvroRecordMaterializer.java": [
                45,
                0
            ],
            "parquet-avro/src/main/java/org/apache/parquet/avro/AvroSchemaConverter.java": [
                565,
                0
            ],
            "parquet-avro/src/main/java/org/apache/parquet/avro/AvroWriteSupport.java": [
                711,
                0
            ],
            "parquet-avro/src/main/java/org/apache/parquet/avro/GenericDataSupplier.java": [
                28,
                0
            ],
            "parquet-avro/src/main/java/org/apache/parquet/avro/ParentValueContainer.java": [
                238,
                0
            ],
            "parquet-avro/src/main/java/org/apache/parquet/avro/ReflectDataSupplier.java": [
                29,
                0
            ],
            "parquet-avro/src/main/java/org/apache/parquet/avro/SpecificDataSupplier.java": [
                29,
                0
            ],
            "parquet-avro/src/main/java/org/apache/parquet/avro/package-info.java": [
                174,
                0
            ],
            "parquet-avro/src/main/resources/META-INF/LICENSE": null,
            "parquet-avro/src/main/resources/META-INF/NOTICE": null,
            "parquet-avro/src/test/avro/logicalType.avsc": null,
            "parquet-avro/src/test/avro/stringBehavior.avsc": null,
            "parquet-avro/src/test/java/org/apache/parquet/avro/AvroTestUtil.java": [
                136,
                0
            ],
            "parquet-avro/src/test/java/org/apache/parquet/avro/TestArrayCompatibility.java": [
                1164,
                0
            ],
            "parquet-avro/src/test/java/org/apache/parquet/avro/TestAvroDataSupplier.java": [
                43,
                0
            ],
            "parquet-avro/src/test/java/org/apache/parquet/avro/TestAvroRecordConverter.java": [
                202,
                0
            ],
            "parquet-avro/src/test/java/org/apache/parquet/avro/TestAvroSchemaConverter.java": [
                942,
                0
            ],
            "parquet-avro/src/test/java/org/apache/parquet/avro/TestAvroWriteSupport.java": [
                61,
                0
            ],
            "parquet-avro/src/test/java/org/apache/parquet/avro/TestBackwardCompatibility.java": [
                68,
                0
            ],
            "parquet-avro/src/test/java/org/apache/parquet/avro/TestByteStreamSplitE2E.java": [
                114,
                0
            ],
            "parquet-avro/src/test/java/org/apache/parquet/avro/TestCircularReferences.java": [
                387,
                0
            ],
            "parquet-avro/src/test/java/org/apache/parquet/avro/TestGenericLogicalTypes.java": [
                296,
                0
            ],
            "parquet-avro/src/test/java/org/apache/parquet/avro/TestInputOutputFormat.java": [
                145,
                0
            ],
            "parquet-avro/src/test/java/org/apache/parquet/avro/TestReadWrite.java": [
                900,
                0
            ],
            "parquet-avro/src/test/java/org/apache/parquet/avro/TestReadWriteOldListBehavior.java": [
                584,
                0
            ],
            "parquet-avro/src/test/java/org/apache/parquet/avro/TestReflectInputOutputFormat.java": [
                496,
                0
            ],
            "parquet-avro/src/test/java/org/apache/parquet/avro/TestReflectLogicalTypes.java": [
                999,
                0
            ],
            "parquet-avro/src/test/java/org/apache/parquet/avro/TestReflectReadWrite.java": [
                240,
                0
            ],
            "parquet-avro/src/test/java/org/apache/parquet/avro/TestSpecificInputOutputFormat.java": [
                287,
                0
            ],
            "parquet-avro/src/test/java/org/apache/parquet/avro/TestSpecificReadWrite.java": [
                360,
                0
            ],
            "parquet-avro/src/test/java/org/apache/parquet/avro/TestStringBehavior.java": [
                330,
                0
            ],
            "parquet-avro/src/test/resources/all.avsc": null,
            "parquet-avro/src/test/resources/allFromParquetNewBehavior.avsc": null,
            "parquet-avro/src/test/resources/allFromParquetOldBehavior.avsc": null,
            "parquet-avro/src/test/resources/array.avsc": null,
            "parquet-avro/src/test/resources/car.avdl": null,
            "parquet-avro/src/test/resources/fixedToInt96.avsc": null,
            "parquet-avro/src/test/resources/list_with_nulls.avsc": null,
            "parquet-avro/src/test/resources/map.avsc": null,
            "parquet-avro/src/test/resources/map_with_nulls.avsc": null,
            "parquet-avro/src/test/resources/nested_array.avsc": null,
            "parquet-avro/src/test/resources/strings-2.parquet": null,
            "parquet-benchmarks/README.md": null,
            "parquet-benchmarks/pom.xml": null,
            "parquet-benchmarks/run.sh": null,
            "parquet-benchmarks/src/main/java/org/apache/parquet/benchmarks/BenchmarkConstants.java": [
                42,
                0
            ],
            "parquet-benchmarks/src/main/java/org/apache/parquet/benchmarks/BenchmarkFiles.java": [
                64,
                0
            ],
            "parquet-benchmarks/src/main/java/org/apache/parquet/benchmarks/BenchmarkUtils.java": [
                46,
                0
            ],
            "parquet-benchmarks/src/main/java/org/apache/parquet/benchmarks/DataGenerator.java": [
                137,
                0
            ],
            "parquet-benchmarks/src/main/java/org/apache/parquet/benchmarks/FilteringBenchmarks.java": [
                430,
                0
            ],
            "parquet-benchmarks/src/main/java/org/apache/parquet/benchmarks/NestedNullWritingBenchmarks.java": [
                156,
                0
            ],
            "parquet-benchmarks/src/main/java/org/apache/parquet/benchmarks/PageChecksumDataGenerator.java": [
                106,
                0
            ],
            "parquet-benchmarks/src/main/java/org/apache/parquet/benchmarks/PageChecksumReadBenchmarks.java": [
                196,
                0
            ],
            "parquet-benchmarks/src/main/java/org/apache/parquet/benchmarks/PageChecksumWriteBenchmarks.java": [
                178,
                0
            ],
            "parquet-benchmarks/src/main/java/org/apache/parquet/benchmarks/ReadBenchmarks.java": [
                131,
                0
            ],
            "parquet-benchmarks/src/main/java/org/apache/parquet/benchmarks/WriteBenchmarks.java": [
                168,
                0
            ],
            "parquet-benchmarks/src/main/resources/log4j.properties": null,
            "parquet-cli/README.md": null,
            "parquet-cli/pom.xml": null,
            "parquet-cli/src/main/java/org/apache/parquet/cli/BaseCommand.java": [
                428,
                0
            ],
            "parquet-cli/src/main/java/org/apache/parquet/cli/Command.java": [
                40,
                0
            ],
            "parquet-cli/src/main/java/org/apache/parquet/cli/HadoopFileSystemURLStreamHandler.java": [
                79,
                0
            ],
            "parquet-cli/src/main/java/org/apache/parquet/cli/Help.java": [
                153,
                0
            ],
            "parquet-cli/src/main/java/org/apache/parquet/cli/Main.java": [
                196,
                0
            ],
            "parquet-cli/src/main/java/org/apache/parquet/cli/Util.java": [
                272,
                0
            ],
            "parquet-cli/src/main/java/org/apache/parquet/cli/commands/CSVSchemaCommand.java": [
                131,
                0
            ],
            "parquet-cli/src/main/java/org/apache/parquet/cli/commands/CatCommand.java": [
                106,
                0
            ],
            "parquet-cli/src/main/java/org/apache/parquet/cli/commands/CheckParquet251Command.java": [
                352,
                0
            ],
            "parquet-cli/src/main/java/org/apache/parquet/cli/commands/ColumnMaskingCommand.java": [
                115,
                0
            ],
            "parquet-cli/src/main/java/org/apache/parquet/cli/commands/ColumnSizeCommand.java": [
                137,
                0
            ],
            "parquet-cli/src/main/java/org/apache/parquet/cli/commands/ConvertCSVCommand.java": [
                204,
                0
            ],
            "parquet-cli/src/main/java/org/apache/parquet/cli/commands/ConvertCommand.java": [
                165,
                0
            ],
            "parquet-cli/src/main/java/org/apache/parquet/cli/commands/ParquetMetadataCommand.java": [
                183,
                0
            ],
            "parquet-cli/src/main/java/org/apache/parquet/cli/commands/PruneColumnsCommand.java": [
                82,
                0
            ],
            "parquet-cli/src/main/java/org/apache/parquet/cli/commands/RewriteCommand.java": [
                131,
                0
            ],
            "parquet-cli/src/main/java/org/apache/parquet/cli/commands/ScanCommand.java": [
                91,
                0
            ],
            "parquet-cli/src/main/java/org/apache/parquet/cli/commands/SchemaCommand.java": [
                132,
                0
            ],
            "parquet-cli/src/main/java/org/apache/parquet/cli/commands/ShowBloomFilterCommand.java": [
                133,
                0
            ],
            "parquet-cli/src/main/java/org/apache/parquet/cli/commands/ShowColumnIndexCommand.java": [
                157,
                0
            ],
            "parquet-cli/src/main/java/org/apache/parquet/cli/commands/ShowDictionaryCommand.java": [
                139,
                0
            ],
            "parquet-cli/src/main/java/org/apache/parquet/cli/commands/ShowFooterCommand.java": [
                101,
                0
            ],
            "parquet-cli/src/main/java/org/apache/parquet/cli/commands/ShowPagesCommand.java": [
                234,
                0
            ],
            "parquet-cli/src/main/java/org/apache/parquet/cli/commands/ToAvroCommand.java": [
                134,
                0
            ],
            "parquet-cli/src/main/java/org/apache/parquet/cli/commands/TransCompressionCommand.java": [
                101,
                0
            ],
            "parquet-cli/src/main/java/org/apache/parquet/cli/csv/AvroCSV.java": [
                258,
                0
            ],
            "parquet-cli/src/main/java/org/apache/parquet/cli/csv/AvroCSVReader.java": [
                121,
                0
            ],
            "parquet-cli/src/main/java/org/apache/parquet/cli/csv/CSVProperties.java": [
                120,
                0
            ],
            "parquet-cli/src/main/java/org/apache/parquet/cli/csv/RecordBuilder.java": [
                200,
                0
            ],
            "parquet-cli/src/main/java/org/apache/parquet/cli/json/AvroJson.java": [
                631,
                0
            ],
            "parquet-cli/src/main/java/org/apache/parquet/cli/json/AvroJsonReader.java": [
                77,
                0
            ],
            "parquet-cli/src/main/java/org/apache/parquet/cli/rawpages/RawPagesReader.java": [
                92,
                0
            ],
            "parquet-cli/src/main/java/org/apache/parquet/cli/util/Codecs.java": [
                52,
                0
            ],
            "parquet-cli/src/main/java/org/apache/parquet/cli/util/Expressions.java": [
                395,
                0
            ],
            "parquet-cli/src/main/java/org/apache/parquet/cli/util/Formats.java": [
                47,
                0
            ],
            "parquet-cli/src/main/java/org/apache/parquet/cli/util/GetClassLoader.java": [
                39,
                0
            ],
            "parquet-cli/src/main/java/org/apache/parquet/cli/util/RawUtils.java": [
                85,
                0
            ],
            "parquet-cli/src/main/java/org/apache/parquet/cli/util/RecordException.java": [
                55,
                0
            ],
            "parquet-cli/src/main/java/org/apache/parquet/cli/util/RuntimeIOException.java": [
                31,
                0
            ],
            "parquet-cli/src/main/java/org/apache/parquet/cli/util/Schemas.java": [
                501,
                0
            ],
            "parquet-cli/src/main/java/org/apache/parquet/cli/util/SeekableFSDataInputStream.java": [
                76,
                0
            ],
            "parquet-cli/src/main/resources/META-INF/LICENSE": null,
            "parquet-cli/src/main/resources/META-INF/NOTICE": null,
            "parquet-cli/src/main/resources/cli-logging.properties": null,
            "parquet-cli/src/test/java/org/apache/parquet/cli/BaseCommandTest.java": [
                100,
                0
            ],
            "parquet-cli/src/test/java/org/apache/parquet/cli/MainTest.java": [
                34,
                0
            ],
            "parquet-cli/src/test/java/org/apache/parquet/cli/commands/AvroFileTest.java": [
                53,
                0
            ],
            "parquet-cli/src/test/java/org/apache/parquet/cli/commands/CSVFileTest.java": [
                51,
                0
            ],
            "parquet-cli/src/test/java/org/apache/parquet/cli/commands/CSVSchemaCommandTest.java": [
                39,
                0
            ],
            "parquet-cli/src/test/java/org/apache/parquet/cli/commands/CatCommandTest.java": [
                38,
                0
            ],
            "parquet-cli/src/test/java/org/apache/parquet/cli/commands/CheckParquet251CommandTest.java": [
                38,
                0
            ],
            "parquet-cli/src/test/java/org/apache/parquet/cli/commands/ColumnSizeCommandTest.java": [
                91,
                0
            ],
            "parquet-cli/src/test/java/org/apache/parquet/cli/commands/ConvertCSVCommandTest.java": [
                41,
                0
            ],
            "parquet-cli/src/test/java/org/apache/parquet/cli/commands/ConvertCommandTest.java": [
                41,
                0
            ],
            "parquet-cli/src/test/java/org/apache/parquet/cli/commands/FileTest.java": [
                58,
                0
            ],
            "parquet-cli/src/test/java/org/apache/parquet/cli/commands/ParquetFileTest.java": [
                117,
                0
            ],
            "parquet-cli/src/test/java/org/apache/parquet/cli/commands/ParquetMetadataCommandTest.java": [
                38,
                0
            ],
            "parquet-cli/src/test/java/org/apache/parquet/cli/commands/RewriteCommandTest.java": [
                41,
                0
            ],
            "parquet-cli/src/test/java/org/apache/parquet/cli/commands/ScanCommandTest.java": [
                38,
                0
            ],
            "parquet-cli/src/test/java/org/apache/parquet/cli/commands/SchemaCommandTest.java": [
                68,
                0
            ],
            "parquet-cli/src/test/java/org/apache/parquet/cli/commands/ShowBloomFilterCommandTest.java": [
                41,
                0
            ],
            "parquet-cli/src/test/java/org/apache/parquet/cli/commands/ShowColumnIndexTest.java": [
                38,
                0
            ],
            "parquet-cli/src/test/java/org/apache/parquet/cli/commands/ShowDictionaryCommandTest.java": [
                50,
                0
            ],
            "parquet-cli/src/test/java/org/apache/parquet/cli/commands/ShowFooterCommandTest.java": [
                43,
                0
            ],
            "parquet-cli/src/test/java/org/apache/parquet/cli/commands/ShowPagesCommandTest.java": [
                38,
                0
            ],
            "parquet-cli/src/test/java/org/apache/parquet/cli/commands/ToAvroCommandTest.java": [
                113,
                0
            ],
            "parquet-cli/src/test/java/org/apache/parquet/cli/commands/TransCompressionCommandTest.java": [
                45,
                0
            ],
            "parquet-column/REVIEWERS.md": null,
            "parquet-column/pom.xml": null,
            "parquet-column/src/main/java/org/apache/parquet/CorruptDeltaByteArrays.java": [
                97,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/CorruptStatistics.java": [
                116,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/ColumnDescriptor.java": [
                156,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/ColumnProperty.java": [
                137,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/ColumnReadStore.java": [
                32,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/ColumnReader.java": [
                117,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/ColumnWriteStore.java": [
                75,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/ColumnWriter.java": [
                96,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/Dictionary.java": [
                63,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/Encoding.java": [
                309,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/EncodingStats.java": [
                157,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/MinMax.java": [
                56,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/ParquetProperties.java": [
                589,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/UnknownColumnException.java": [
                40,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/UnknownColumnTypeException.java": [
                41,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/ValuesType.java": [
                26,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/impl/ColumnReadStoreImpl.java": [
                104,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/impl/ColumnReaderBase.java": [
                790,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/impl/ColumnReaderImpl.java": [
                58,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/impl/ColumnWriteStoreBase.java": [
                273,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/impl/ColumnWriteStoreV1.java": [
                52,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/impl/ColumnWriteStoreV2.java": [
                46,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/impl/ColumnWriterBase.java": [
                408,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/impl/ColumnWriterV1.java": [
                68,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/impl/ColumnWriterV2.java": [
                94,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/impl/SynchronizingColumnReader.java": [
                111,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/page/DataPage.java": [
                72,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/page/DataPageV1.java": [
                127,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/page/DataPageV2.java": [
                207,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/page/DictionaryPage.java": [
                83,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/page/DictionaryPageReadStore.java": [
                36,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/page/Page.java": [
                62,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/page/PageReadStore.java": [
                64,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/page/PageReader.java": [
                40,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/page/PageWriteStore.java": [
                35,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/page/PageWriter.java": [
                102,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/statistics/BinaryStatistics.java": [
                188,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/statistics/BooleanStatistics.java": [
                147,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/statistics/DoubleStatistics.java": [
                147,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/statistics/FloatStatistics.java": [
                148,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/statistics/IntStatistics.java": [
                147,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/statistics/LongStatistics.java": [
                147,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/statistics/Statistics.java": [
                539,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/statistics/StatisticsClassException.java": [
                44,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/values/RequiresFallback.java": [
                51,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/values/RequiresPreviousReader.java": [
                23,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/values/ValuesReader.java": [
                205,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/values/ValuesWriter.java": [
                136,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/values/bitpacking/BitPackingValuesReader.java": [
                84,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/values/bitpacking/BitPackingValuesWriter.java": [
                130,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/values/bitpacking/ByteBitPackingValuesReader.java": [
                99,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/values/bitpacking/ByteBitPackingValuesWriter.java": [
                86,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/values/bitpacking/DevNullValuesWriter.java": [
                89,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/values/bloomfilter/AdaptiveBlockSplitBloomFilter.java": [
                305,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/values/bloomfilter/BlockSplitBloomFilter.java": [
                424,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/values/bloomfilter/BloomFilter.java": [
                203,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/values/bloomfilter/BloomFilterWriteStore.java": [
                35,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/values/bloomfilter/BloomFilterWriter.java": [
                31,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/values/bloomfilter/HashFunction.java": [
                41,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/values/bloomfilter/XxHash.java": [
                40,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/values/bytestreamsplit/ByteStreamSplitValuesReader.java": [
                111,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/values/bytestreamsplit/ByteStreamSplitValuesReaderForDouble.java": [
                37,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/values/bytestreamsplit/ByteStreamSplitValuesReaderForFloat.java": [
                37,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/values/bytestreamsplit/ByteStreamSplitValuesWriter.java": [
                142,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/values/delta/DeltaBinaryPackingConfig.java": [
                55,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/values/delta/DeltaBinaryPackingValuesReader.java": [
                171,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/values/delta/DeltaBinaryPackingValuesWriter.java": [
                136,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/values/delta/DeltaBinaryPackingValuesWriterForInteger.java": [
                196,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/values/delta/DeltaBinaryPackingValuesWriterForLong.java": [
                198,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/values/deltalengthbytearray/DeltaLengthByteArrayValuesReader.java": [
                80,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/values/deltalengthbytearray/DeltaLengthByteArrayValuesWriter.java": [
                115,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/values/deltastrings/DeltaByteArrayReader.java": [
                96,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/values/deltastrings/DeltaByteArrayWriter.java": [
                100,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/values/dictionary/DictionaryValuesReader.java": [
                131,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/values/dictionary/DictionaryValuesWriter.java": [
                597,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/values/dictionary/IntList.java": [
                159,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/values/dictionary/PlainValuesDictionary.java": [
                313,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/values/factory/DefaultV1ValuesWriterFactory.java": [
                122,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/values/factory/DefaultV2ValuesWriterFactory.java": [
                126,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/values/factory/DefaultValuesWriterFactory.java": [
                87,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/values/factory/ValuesWriterFactory.java": [
                52,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/values/fallback/FallbackValuesWriter.java": [
                204,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/values/plain/BinaryPlainValuesReader.java": [
                63,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/values/plain/BooleanPlainValuesReader.java": [
                73,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/values/plain/BooleanPlainValuesWriter.java": [
                81,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/values/plain/FixedLenByteArrayPlainValuesReader.java": [
                72,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/values/plain/FixedLenByteArrayPlainValuesWriter.java": [
                106,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/values/plain/PlainValuesReader.java": [
                139,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/values/plain/PlainValuesWriter.java": [
                148,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/values/rle/RunLengthBitPackingHybridDecoder.java": [
                107,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/values/rle/RunLengthBitPackingHybridEncoder.java": [
                293,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/values/rle/RunLengthBitPackingHybridValuesReader.java": [
                68,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/values/rle/RunLengthBitPackingHybridValuesWriter.java": [
                95,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/values/rle/ZeroIntegerValuesReader.java": [
                50,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/example/DummyRecordConverter.java": [
                114,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/example/Paper.java": [
                164,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/example/data/Group.java": [
                147,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/example/data/GroupFactory.java": [
                25,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/example/data/GroupValueSource.java": [
                89,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/example/data/GroupWriter.java": [
                62,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/example/data/simple/BinaryValue.java": [
                52,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/example/data/simple/BooleanValue.java": [
                44,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/example/data/simple/DoubleValue.java": [
                45,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/example/data/simple/FloatValue.java": [
                45,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/example/data/simple/Int96Value.java": [
                46,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/example/data/simple/IntegerValue.java": [
                46,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/example/data/simple/LongValue.java": [
                45,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/example/data/simple/NanoTime.java": [
                80,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/example/data/simple/Primitive.java": [
                60,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/example/data/simple/SimpleGroup.java": [
                236,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/example/data/simple/SimpleGroupFactory.java": [
                38,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/example/data/simple/convert/GroupRecordConverter.java": [
                57,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/example/data/simple/convert/SimpleGroupConverter.java": [
                67,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/example/data/simple/convert/SimplePrimitiveConverter.java": [
                88,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/filter/AndRecordFilter.java": [
                65,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/filter/ColumnPredicates.java": [
                191,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/filter/ColumnRecordFilter.java": [
                76,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/filter/NotRecordFilter.java": [
                60,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/filter/OrRecordFilter.java": [
                62,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/filter/PagedRecordFilter.java": [
                65,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/filter/RecordFilter.java": [
                33,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/filter/UnboundRecordFilter.java": [
                37,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/filter2/compat/FilterCompat.java": [
                181,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/filter2/predicate/FilterApi.java": [
                328,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/filter2/predicate/FilterPredicate.java": [
                84,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/filter2/predicate/LogicalInverseRewriter.java": [
                126,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/filter2/predicate/LogicalInverter.java": [
                120,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/filter2/predicate/Operators.java": [
                587,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/filter2/predicate/PrimitiveToBoxedClass.java": [
                50,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/filter2/predicate/SchemaCompatibilityValidator.java": [
                204,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/filter2/predicate/Statistics.java": [
                93,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/filter2/predicate/UserDefinedPredicate.java": [
                131,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/filter2/predicate/ValidTypeMap.java": [
                128,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/filter2/recordlevel/FilteringGroupConverter.java": [
                112,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/filter2/recordlevel/FilteringPrimitiveConverter.java": [
                109,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/filter2/recordlevel/FilteringRecordMaterializer.java": [
                116,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/filter2/recordlevel/IncrementallyUpdatedFilterPredicate.java": [
                166,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/filter2/recordlevel/IncrementallyUpdatedFilterPredicateBuilderBase.java": [
                116,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/filter2/recordlevel/IncrementallyUpdatedFilterPredicateEvaluator.java": [
                62,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/filter2/recordlevel/IncrementallyUpdatedFilterPredicateResetter.java": [
                59,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/internal/column/columnindex/BinaryColumnIndexBuilder.java": [
                140,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/internal/column/columnindex/BinaryTruncator.java": [
                221,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/internal/column/columnindex/BooleanColumnIndexBuilder.java": [
                133,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/internal/column/columnindex/BoundaryOrder.java": [
                384,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/internal/column/columnindex/ColumnIndex.java": [
                60,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/internal/column/columnindex/ColumnIndexBuilder.java": [
                686,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/internal/column/columnindex/DoubleColumnIndexBuilder.java": [
                155,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/internal/column/columnindex/FloatColumnIndexBuilder.java": [
                155,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/internal/column/columnindex/IndexIterator.java": [
                89,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/internal/column/columnindex/IntColumnIndexBuilder.java": [
                136,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/internal/column/columnindex/LongColumnIndexBuilder.java": [
                136,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/internal/column/columnindex/OffsetIndex.java": [
                73,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/internal/column/columnindex/OffsetIndexBuilder.java": [
                193,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/internal/filter2/columnindex/ColumnIndexFilter.java": [
                217,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/internal/filter2/columnindex/ColumnIndexStore.java": [
                55,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/internal/filter2/columnindex/RowRanges.java": [
                318,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/io/BaseRecordReader.java": [
                149,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/io/ColumnIO.java": [
                138,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/io/ColumnIOFactory.java": [
                174,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/io/CompilationException.java": [
                44,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/io/EmptyRecordReader.java": [
                48,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/io/FilteredRecordReader.java": [
                97,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/io/GroupColumnIO.java": [
                121,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/io/InvalidFileOffsetException.java": [
                29,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/io/InvalidRecordException.java": [
                45,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/io/MessageColumnIO.java": [
                534,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/io/ParquetDecodingException.java": [
                44,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/io/ParquetEncodingException.java": [
                44,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/io/PrimitiveColumnIO.java": [
                108,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/io/RecordConsumerLoggingWrapper.java": [
                187,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/io/RecordReader.java": [
                43,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/io/RecordReaderImplementation.java": [
                474,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/io/ValidatingRecordConsumer.java": [
                247,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/io/api/Binary.java": [
                737,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/io/api/Converter.java": [
                37,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/io/api/GroupConverter.java": [
                55,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/io/api/PrimitiveConverter.java": [
                108,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/io/api/RecordConsumer.java": [
                134,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/io/api/RecordMaterializer.java": [
                73,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/schema/ColumnOrder.java": [
                97,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/schema/ConversionPatterns.java": [
                133,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/schema/DecimalMetadata.java": [
                62,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/schema/GroupType.java": [
                421,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/schema/IncompatibleSchemaModificationException.java": [
                46,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/schema/InvalidSchemaException.java": [
                31,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/schema/LogicalTypeAnnotation.java": [
                1064,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/schema/MessageType.java": [
                145,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/schema/MessageTypeParser.java": [
                243,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/schema/OriginalType.java": [
                48,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/schema/PrimitiveComparator.java": [
                279,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/schema/PrimitiveStringifier.java": [
                451,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/schema/PrimitiveType.java": [
                797,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/schema/Type.java": [
                366,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/schema/TypeConverter.java": [
                53,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/schema/TypeUtil.java": [
                45,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/schema/TypeVisitor.java": [
                43,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/schema/Types.java": [
                1542,
                0
            ],
            "parquet-column/src/main/resources/META-INF/LICENSE": null,
            "parquet-column/src/test/java/org/apache/parquet/CorruptStatisticsTest.java": [
                92,
                0
            ],
            "parquet-column/src/test/java/org/apache/parquet/FixedBinaryTestUtils.java": [
                96,
                0
            ],
            "parquet-column/src/test/java/org/apache/parquet/ResourceIntensiveTestRule.java": [
                58,
                0
            ],
            "parquet-column/src/test/java/org/apache/parquet/column/TestColumnDescriptor.java": [
                52,
                0
            ],
            "parquet-column/src/test/java/org/apache/parquet/column/TestEncodingStats.java": [
                202,
                0
            ],
            "parquet-column/src/test/java/org/apache/parquet/column/impl/TestColumnReaderImpl.java": [
                131,
                0
            ],
            "parquet-column/src/test/java/org/apache/parquet/column/impl/TestCorruptDeltaByteArrays.java": [
                269,
                0
            ],
            "parquet-column/src/test/java/org/apache/parquet/column/mem/TestMemColumn.java": [
                246,
                0
            ],
            "parquet-column/src/test/java/org/apache/parquet/column/mem/TestMemPageStore.java": [
                61,
                0
            ],
            "parquet-column/src/test/java/org/apache/parquet/column/page/mem/MemPageReader.java": [
                67,
                0
            ],
            "parquet-column/src/test/java/org/apache/parquet/column/page/mem/MemPageStore.java": [
                78,
                0
            ],
            "parquet-column/src/test/java/org/apache/parquet/column/page/mem/MemPageWriter.java": [
                117,
                0
            ],
            "parquet-column/src/test/java/org/apache/parquet/column/statistics/TestStatistics.java": [
                789,
                0
            ],
            "parquet-column/src/test/java/org/apache/parquet/column/values/TestValuesReaderImpl.java": [
                148,
                0
            ],
            "parquet-column/src/test/java/org/apache/parquet/column/values/Utils.java": [
                76,
                0
            ],
            "parquet-column/src/test/java/org/apache/parquet/column/values/bitpacking/BitPackingPerfTest.java": [
                103,
                0
            ],
            "parquet-column/src/test/java/org/apache/parquet/column/values/bitpacking/TestBitPackingColumn.java": [
                232,
                0
            ],
            "parquet-column/src/test/java/org/apache/parquet/column/values/bloomfilter/TestBlockSplitBloomFilter.java": [
                325,
                0
            ],
            "parquet-column/src/test/java/org/apache/parquet/column/values/bytestreamsplit/ByteStreamSplitValuesEndToEndTest.java": [
                111,
                0
            ],
            "parquet-column/src/test/java/org/apache/parquet/column/values/bytestreamsplit/ByteStreamSplitValuesReaderTest.java": [
                193,
                0
            ],
            "parquet-column/src/test/java/org/apache/parquet/column/values/bytestreamsplit/ByteStreamSplitValuesWriterTest.java": [
                189,
                0
            ],
            "parquet-column/src/test/java/org/apache/parquet/column/values/delta/DeltaBinaryPackingValuesWriterForIntegerTest.java": [
                294,
                0
            ],
            "parquet-column/src/test/java/org/apache/parquet/column/values/delta/DeltaBinaryPackingValuesWriterForLongTest.java": [
                291,
                0
            ],
            "parquet-column/src/test/java/org/apache/parquet/column/values/delta/benchmark/BenchMarkTest.java": [
                41,
                0
            ],
            "parquet-column/src/test/java/org/apache/parquet/column/values/delta/benchmark/BenchmarkIntegerOutputSize.java": [
                107,
                0
            ],
            "parquet-column/src/test/java/org/apache/parquet/column/values/delta/benchmark/BenchmarkReadingRandomIntegers.java": [
                102,
                0
            ],
            "parquet-column/src/test/java/org/apache/parquet/column/values/delta/benchmark/RandomWritingBenchmarkTest.java": [
                76,
                0
            ],
            "parquet-column/src/test/java/org/apache/parquet/column/values/delta/benchmark/SmallRangeWritingBenchmarkTest.java": [
                49,
                0
            ],
            "parquet-column/src/test/java/org/apache/parquet/column/values/deltalengthbytearray/TestDeltaLengthByteArray.java": [
                103,
                0
            ],
            "parquet-column/src/test/java/org/apache/parquet/column/values/deltalengthbytearray/benchmark/BenchmarkDeltaLengthByteArray.java": [
                73,
                0
            ],
            "parquet-column/src/test/java/org/apache/parquet/column/values/deltastrings/TestDeltaByteArray.java": [
                130,
                0
            ],
            "parquet-column/src/test/java/org/apache/parquet/column/values/deltastrings/benchmark/BenchmarkDeltaByteArray.java": [
                103,
                0
            ],
            "parquet-column/src/test/java/org/apache/parquet/column/values/dictionary/IntListTest.java": [
                84,
                0
            ],
            "parquet-column/src/test/java/org/apache/parquet/column/values/dictionary/TestDictionary.java": [
                661,
                0
            ],
            "parquet-column/src/test/java/org/apache/parquet/column/values/factory/DefaultValuesWriterFactoryTest.java": [
                546,
                0
            ],
            "parquet-column/src/test/java/org/apache/parquet/column/values/rle/RunLengthBitPackingHybridIntegrationTest.java": [
                86,
                0
            ],
            "parquet-column/src/test/java/org/apache/parquet/column/values/rle/TestRunLengthBitPackingHybridEncoder.java": [
                329,
                0
            ],
            "parquet-column/src/test/java/org/apache/parquet/filter2/predicate/DummyUdp.java": [
                37,
                0
            ],
            "parquet-column/src/test/java/org/apache/parquet/filter2/predicate/TestFilterApiMethods.java": [
                172,
                0
            ],
            "parquet-column/src/test/java/org/apache/parquet/filter2/predicate/TestLogicalInverseRewriter.java": [
                103,
                0
            ],
            "parquet-column/src/test/java/org/apache/parquet/filter2/predicate/TestLogicalInverter.java": [
                94,
                0
            ],
            "parquet-column/src/test/java/org/apache/parquet/filter2/predicate/TestSchemaCompatibilityValidator.java": [
                142,
                0
            ],
            "parquet-column/src/test/java/org/apache/parquet/filter2/predicate/TestValidTypeMap.java": [
                98,
                0
            ],
            "parquet-column/src/test/java/org/apache/parquet/filter2/recordlevel/TestIncrementallyUpdatedFilterPredicateEvaluator.java": [
                209,
                0
            ],
            "parquet-column/src/test/java/org/apache/parquet/filter2/recordlevel/TestIncrementallyUpdatedFilterPredicateResetter.java": [
                69,
                0
            ],
            "parquet-column/src/test/java/org/apache/parquet/filter2/recordlevel/TestValueInspector.java": [
                97,
                0
            ],
            "parquet-column/src/test/java/org/apache/parquet/internal/column/columnindex/TestBinaryTruncator.java": [
                285,
                0
            ],
            "parquet-column/src/test/java/org/apache/parquet/internal/column/columnindex/TestBoundaryOrder.java": [
                543,
                0
            ],
            "parquet-column/src/test/java/org/apache/parquet/internal/column/columnindex/TestColumnIndexBuilder.java": [
                1728,
                0
            ],
            "parquet-column/src/test/java/org/apache/parquet/internal/column/columnindex/TestIndexIterator.java": [
                63,
                0
            ],
            "parquet-column/src/test/java/org/apache/parquet/internal/column/columnindex/TestOffsetIndexBuilder.java": [
                111,
                0
            ],
            "parquet-column/src/test/java/org/apache/parquet/internal/filter2/columnindex/TestColumnIndexFilter.java": [
                555,
                0
            ],
            "parquet-column/src/test/java/org/apache/parquet/internal/filter2/columnindex/TestRowRanges.java": [
                155,
                0
            ],
            "parquet-column/src/test/java/org/apache/parquet/io/ConverterConsumer.java": [
                125,
                0
            ],
            "parquet-column/src/test/java/org/apache/parquet/io/ExpectationValidatingConverter.java": [
                169,
                0
            ],
            "parquet-column/src/test/java/org/apache/parquet/io/ExpectationValidatingRecordConsumer.java": [
                112,
                0
            ],
            "parquet-column/src/test/java/org/apache/parquet/io/PerfTest.java": [
                128,
                0
            ],
            "parquet-column/src/test/java/org/apache/parquet/io/TestColumnIO.java": [
                709,
                0
            ],
            "parquet-column/src/test/java/org/apache/parquet/io/TestFiltered.java": [
                278,
                0
            ],
            "parquet-column/src/test/java/org/apache/parquet/io/api/TestBinary.java": [
                271,
                0
            ],
            "parquet-column/src/test/java/org/apache/parquet/parser/TestParquetParser.java": [
                374,
                0
            ],
            "parquet-column/src/test/java/org/apache/parquet/schema/TestMessageType.java": [
                247,
                0
            ],
            "parquet-column/src/test/java/org/apache/parquet/schema/TestPrimitiveComparator.java": [
                330,
                0
            ],
            "parquet-column/src/test/java/org/apache/parquet/schema/TestPrimitiveStringifier.java": [
                391,
                0
            ],
            "parquet-column/src/test/java/org/apache/parquet/schema/TestRepetitionType.java": [
                36,
                0
            ],
            "parquet-column/src/test/java/org/apache/parquet/schema/TestTypeBuilders.java": [
                1372,
                0
            ],
            "parquet-column/src/test/java/org/apache/parquet/schema/TestTypeBuildersWithLogicalTypes.java": [
                422,
                0
            ],
            "parquet-column/src/test/java/org/apache/parquet/schema/TestTypeUtil.java": [
                80,
                0
            ],
            "parquet-common/REVIEWERS.md": null,
            "parquet-common/pom.xml": null,
            "parquet-common/src/main/java/org/apache/parquet/Closeables.java": [
                60,
                0
            ],
            "parquet-common/src/main/java/org/apache/parquet/Exceptions.java": [
                39,
                0
            ],
            "parquet-common/src/main/java/org/apache/parquet/Files.java": [
                54,
                0
            ],
            "parquet-common/src/main/java/org/apache/parquet/IOExceptionUtils.java": [
                45,
                0
            ],
            "parquet-common/src/main/java/org/apache/parquet/Ints.java": [
                44,
                0
            ],
            "parquet-common/src/main/java/org/apache/parquet/Log.java": [
                146,
                0
            ],
            "parquet-common/src/main/java/org/apache/parquet/OutputStreamCloseException.java": [
                46,
                0
            ],
            "parquet-common/src/main/java/org/apache/parquet/ParquetRuntimeException.java": [
                42,
                0
            ],
            "parquet-common/src/main/java/org/apache/parquet/Preconditions.java": [
                251,
                0
            ],
            "parquet-common/src/main/java/org/apache/parquet/SemanticVersion.java": [
                293,
                0
            ],
            "parquet-common/src/main/java/org/apache/parquet/ShouldNeverHappenException.java": [
                40,
                0
            ],
            "parquet-common/src/main/java/org/apache/parquet/Strings.java": [
                132,
                0
            ],
            "parquet-common/src/main/java/org/apache/parquet/VersionParser.java": [
                129,
                0
            ],
            "parquet-common/src/main/java/org/apache/parquet/bytes/ByteBufferAllocator.java": [
                40,
                0
            ],
            "parquet-common/src/main/java/org/apache/parquet/bytes/ByteBufferInputStream.java": [
                160,
                0
            ],
            "parquet-common/src/main/java/org/apache/parquet/bytes/BytesInput.java": [
                545,
                0
            ],
            "parquet-common/src/main/java/org/apache/parquet/bytes/BytesUtils.java": [
                335,
                0
            ],
            "parquet-common/src/main/java/org/apache/parquet/bytes/CapacityByteArrayOutputStream.java": [
                352,
                0
            ],
            "parquet-common/src/main/java/org/apache/parquet/bytes/ConcatenatingByteArrayCollector.java": [
                63,
                0
            ],
            "parquet-common/src/main/java/org/apache/parquet/bytes/DirectByteBufferAllocator.java": [
                43,
                0
            ],
            "parquet-common/src/main/java/org/apache/parquet/bytes/HeapByteBufferAllocator.java": [
                44,
                0
            ],
            "parquet-common/src/main/java/org/apache/parquet/bytes/LittleEndianDataInputStream.java": [
                421,
                0
            ],
            "parquet-common/src/main/java/org/apache/parquet/bytes/LittleEndianDataOutputStream.java": [
                218,
                0
            ],
            "parquet-common/src/main/java/org/apache/parquet/bytes/MultiBufferInputStream.java": [
                382,
                0
            ],
            "parquet-common/src/main/java/org/apache/parquet/bytes/SingleBufferInputStream.java": [
                177,
                0
            ],
            "parquet-common/src/main/java/org/apache/parquet/compression/CompressionCodecFactory.java": [
                47,
                0
            ],
            "parquet-common/src/main/java/org/apache/parquet/glob/GlobExpander.java": [
                129,
                0
            ],
            "parquet-common/src/main/java/org/apache/parquet/glob/GlobNode.java": [
                157,
                0
            ],
            "parquet-common/src/main/java/org/apache/parquet/glob/GlobParser.java": [
                224,
                0
            ],
            "parquet-common/src/main/java/org/apache/parquet/glob/WildcardPath.java": [
                121,
                0
            ],
            "parquet-common/src/main/java/org/apache/parquet/hadoop/codec/CompressionCodecNotSupportedException.java": [
                38,
                0
            ],
            "parquet-common/src/main/java/org/apache/parquet/hadoop/metadata/Canonicalizer.java": [
                61,
                0
            ],
            "parquet-common/src/main/java/org/apache/parquet/hadoop/metadata/ColumnPath.java": [
                88,
                0
            ],
            "parquet-common/src/main/java/org/apache/parquet/hadoop/metadata/CompressionCodecName.java": [
                99,
                0
            ],
            "parquet-common/src/main/java/org/apache/parquet/io/DelegatingPositionOutputStream.java": [
                63,
                0
            ],
            "parquet-common/src/main/java/org/apache/parquet/io/DelegatingSeekableInputStream.java": [
                171,
                0
            ],
            "parquet-common/src/main/java/org/apache/parquet/io/InputFile.java": [
                44,
                0
            ],
            "parquet-common/src/main/java/org/apache/parquet/io/LocalInputFile.java": [
                102,
                0
            ],
            "parquet-common/src/main/java/org/apache/parquet/io/LocalOutputFile.java": [
                107,
                0
            ],
            "parquet-common/src/main/java/org/apache/parquet/io/OutputFile.java": [
                62,
                0
            ],
            "parquet-common/src/main/java/org/apache/parquet/io/PositionOutputStream.java": [
                39,
                0
            ],
            "parquet-common/src/main/java/org/apache/parquet/io/SeekableInputStream.java": [
                108,
                0
            ],
            "parquet-common/src/main/java/org/apache/parquet/util/DynConstructors.java": [
                263,
                0
            ],
            "parquet-common/src/main/java/org/apache/parquet/util/DynMethods.java": [
                506,
                0
            ],
            "parquet-common/src/test/java/org/apache/parquet/SemanticVersionTest.java": [
                114,
                0
            ],
            "parquet-common/src/test/java/org/apache/parquet/TestPreconditions.java": [
                246,
                0
            ],
            "parquet-common/src/test/java/org/apache/parquet/TestUtils.java": [
                70,
                0
            ],
            "parquet-common/src/test/java/org/apache/parquet/VersionTest.java": [
                100,
                0
            ],
            "parquet-common/src/test/java/org/apache/parquet/bytes/TestByteBufferInputStreams.java": [
                589,
                0
            ],
            "parquet-common/src/test/java/org/apache/parquet/bytes/TestBytesUtil.java": [
                49,
                0
            ],
            "parquet-common/src/test/java/org/apache/parquet/bytes/TestDeprecatedBufferInputStream.java": [
                152,
                0
            ],
            "parquet-common/src/test/java/org/apache/parquet/bytes/TestMultiBufferInputStream.java": [
                141,
                0
            ],
            "parquet-common/src/test/java/org/apache/parquet/bytes/TestSingleBufferInputStream.java": [
                130,
                0
            ],
            "parquet-common/src/test/java/org/apache/parquet/glob/TestGlob.java": [
                144,
                0
            ],
            "parquet-common/src/test/java/org/apache/parquet/glob/TestWildcardPath.java": [
                125,
                0
            ],
            "parquet-common/src/test/java/org/apache/parquet/io/MockInputStream.java": [
                56,
                0
            ],
            "parquet-common/src/test/java/org/apache/parquet/io/TestDelegatingSeekableInputStream.java": [
                844,
                0
            ],
            "parquet-common/src/test/java/org/apache/parquet/io/TestLocalInputOutput.java": [
                92,
                0
            ],
            "parquet-common/src/test/java/org/apache/parquet/util/Concatenator.java": [
                82,
                0
            ],
            "parquet-common/src/test/java/org/apache/parquet/util/TestDynConstructors.java": [
                165,
                0
            ],
            "parquet-common/src/test/java/org/apache/parquet/util/TestDynMethods.java": [
                315,
                0
            ],
            "parquet-encoding/REVIEWERS.md": null,
            "parquet-encoding/pom.xml": null,
            "parquet-encoding/src/main/java/org/apache/parquet/column/values/bitpacking/BitPacking.java": [
                717,
                0
            ],
            "parquet-encoding/src/main/java/org/apache/parquet/column/values/bitpacking/ByteBasedBitPackingEncoder.java": [
                142,
                0
            ],
            "parquet-encoding/src/main/java/org/apache/parquet/column/values/bitpacking/BytePacker.java": [
                141,
                0
            ],
            "parquet-encoding/src/main/java/org/apache/parquet/column/values/bitpacking/BytePackerFactory.java": [
                25,
                0
            ],
            "parquet-encoding/src/main/java/org/apache/parquet/column/values/bitpacking/BytePackerForLong.java": [
                109,
                0
            ],
            "parquet-encoding/src/main/java/org/apache/parquet/column/values/bitpacking/BytePackerForLongFactory.java": [
                25,
                0
            ],
            "parquet-encoding/src/main/java/org/apache/parquet/column/values/bitpacking/IntPacker.java": [
                63,
                0
            ],
            "parquet-encoding/src/main/java/org/apache/parquet/column/values/bitpacking/IntPackerFactory.java": [
                25,
                0
            ],
            "parquet-encoding/src/main/java/org/apache/parquet/column/values/bitpacking/Packer.java": [
                137,
                0
            ],
            "parquet-encoding/src/main/resources/META-INF/LICENSE": null,
            "parquet-encoding/src/test/java/org/apache/parquet/bytes/TestBytesInput.java": [
                42,
                0
            ],
            "parquet-encoding/src/test/java/org/apache/parquet/bytes/TestCapacityByteArrayOutputStream.java": [
                242,
                0
            ],
            "parquet-encoding/src/test/java/org/apache/parquet/column/values/bitpacking/TestBitPacking.java": [
                233,
                0
            ],
            "parquet-encoding/src/test/java/org/apache/parquet/column/values/bitpacking/TestByteBasedBitPackingEncoder.java": [
                46,
                0
            ],
            "parquet-encoding/src/test/java/org/apache/parquet/column/values/bitpacking/TestByteBitPacking.java": [
                198,
                0
            ],
            "parquet-encoding/src/test/java/org/apache/parquet/column/values/bitpacking/TestLemireBitPacking.java": [
                125,
                0
            ],
            "parquet-format-structures/pom.xml": null,
            "parquet-format-structures/src/main/java/org/apache/parquet/format/BlockCipher.java": [
                76,
                0
            ],
            "parquet-format-structures/src/main/java/org/apache/parquet/format/CliUtils.java": [
                55,
                0
            ],
            "parquet-format-structures/src/main/java/org/apache/parquet/format/InterningProtocol.java": [
                236,
                0
            ],
            "parquet-format-structures/src/main/java/org/apache/parquet/format/InvalidParquetMetadataException.java": [
                30,
                0
            ],
            "parquet-format-structures/src/main/java/org/apache/parquet/format/LogicalTypes.java": [
                55,
                0
            ],
            "parquet-format-structures/src/main/java/org/apache/parquet/format/MetadataValidator.java": [
                44,
                0
            ],
            "parquet-format-structures/src/main/java/org/apache/parquet/format/Util.java": [
                389,
                0
            ],
            "parquet-format-structures/src/main/java/org/apache/parquet/format/event/Consumers.java": [
                191,
                0
            ],
            "parquet-format-structures/src/main/java/org/apache/parquet/format/event/EventBasedThriftReader.java": [
                126,
                0
            ],
            "parquet-format-structures/src/main/java/org/apache/parquet/format/event/FieldConsumer.java": [
                39,
                0
            ],
            "parquet-format-structures/src/main/java/org/apache/parquet/format/event/TypedConsumer.java": [
                205,
                0
            ],
            "parquet-format-structures/src/test/java/org/apache/parquet/format/TestUtil.java": [
                101,
                0
            ],
            "parquet-generator/REVIEWERS.md": null,
            "parquet-generator/pom.xml": null,
            "parquet-generator/src/main/java/org/apache/parquet/encoding/Generator.java": [
                34,
                0
            ],
            "parquet-generator/src/main/java/org/apache/parquet/encoding/bitpacking/ByteBasedBitPackingGenerator.java": [
                319,
                0
            ],
            "parquet-generator/src/main/java/org/apache/parquet/encoding/bitpacking/IntBasedBitPackingGenerator.java": [
                208,
                0
            ],
            "parquet-generator/src/main/java/org/apache/parquet/filter2/Generator.java": [
                28,
                0
            ],
            "parquet-generator/src/main/java/org/apache/parquet/filter2/IncrementallyUpdatedFilterPredicateGenerator.java": [
                335,
                0
            ],
            "parquet-generator/src/main/java/org/apache/parquet/version/Generator.java": [
                28,
                0
            ],
            "parquet-generator/src/main/java/org/apache/parquet/version/VersionGenerator.java": [
                87,
                0
            ],
            "parquet-generator/src/main/resources/META-INF/LICENSE": null,
            "parquet-generator/src/main/resources/parquet-version.properties": null,
            "parquet-hadoop-bundle/README": null,
            "parquet-hadoop-bundle/pom.xml": null,
            "parquet-hadoop-bundle/src/main/resources/META-INF/LICENSE": null,
            "parquet-hadoop-bundle/src/main/resources/org/apache/parquet/bundle": null,
            "parquet-hadoop/README.md": null,
            "parquet-hadoop/REVIEWERS.md": null,
            "parquet-hadoop/pom.xml": null,
            "parquet-hadoop/src/main/java/org/apache/parquet/HadoopReadOptions.java": [
                143,
                0
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/ParquetReadOptions.java": [
                345,
                0
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/crypto/AADPrefixVerifier.java": [
                32,
                0
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/crypto/AesCipher.java": [
                164,
                0
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/crypto/AesCtrDecryptor.java": [
                170,
                0
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/crypto/AesCtrEncryptor.java": [
                104,
                0
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/crypto/AesGcmDecryptor.java": [
                151,
                0
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/crypto/AesGcmEncryptor.java": [
                91,
                0
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/crypto/AesMode.java": [
                35,
                0
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/crypto/ColumnDecryptionProperties.java": [
                104,
                0
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/crypto/ColumnEncryptionProperties.java": [
                195,
                0
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/crypto/DecryptionKeyRetriever.java": [
                39,
                0
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/crypto/DecryptionPropertiesFactory.java": [
                88,
                0
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/crypto/EncryptionPropertiesFactory.java": [
                93,
                0
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/crypto/FileDecryptionProperties.java": [
                254,
                0
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/crypto/FileEncryptionProperties.java": [
                278,
                0
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/crypto/InternalColumnDecryptionSetup.java": [
                74,
                0
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/crypto/InternalColumnEncryptionSetup.java": [
                82,
                0
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/crypto/InternalFileDecryptor.java": [
                312,
                0
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/crypto/InternalFileEncryptor.java": [
                200,
                0
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/crypto/KeyAccessDeniedException.java": [
                39,
                0
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/crypto/ModuleCipherFactory.java": [
                73,
                0
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/crypto/ParquetCipher.java": [
                42,
                0
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/crypto/ParquetCryptoRuntimeException.java": [
                42,
                0
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/crypto/TagVerificationException.java": [
                39,
                0
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/crypto/keytools/FileKeyMaterialStore.java": [
                72,
                0
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/crypto/keytools/FileKeyUnwrapper.java": [
                178,
                0
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/crypto/keytools/FileKeyWrapper.java": [
                177,
                0
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/crypto/keytools/HadoopFSKeyMaterialStore.java": [
                136,
                0
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/crypto/keytools/KeyMaterial.java": [
                210,
                0
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/crypto/keytools/KeyMetadata.java": [
                130,
                0
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/crypto/keytools/KeyToolkit.java": [
                394,
                0
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/crypto/keytools/KmsClient.java": [
                72,
                0
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/crypto/keytools/LocalWrapKmsClient.java": [
                181,
                0
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/crypto/keytools/PropertiesDrivenCryptoFactory.java": [
                258,
                0
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/crypto/keytools/TwoLevelCacheWithExpiration.java": [
                105,
                0
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/filter2/bloomfilterlevel/BloomFilterImpl.java": [
                187,
                0
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/filter2/compat/RowGroupFilter.java": [
                131,
                0
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/filter2/dictionarylevel/DictionaryFilter.java": [
                570,
                0
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/filter2/statisticslevel/StatisticsFilter.java": [
                485,
                0
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/format/converter/ParquetMetadataConverter.java": [
                2080,
                0
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/BadConfigurationException.java": [
                44,
                0
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/BloomFilterReader.java": [
                70,
                0
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/CodecFactory.java": [
                289,
                0
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ColumnChunkPageReadStore.java": [
                364,
                0
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ColumnChunkPageWriteStore.java": [
                462,
                0
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ColumnConfigParser.java": [
                72,
                0
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ColumnIndexFilterUtils.java": [
                162,
                0
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ColumnIndexStoreImpl.java": [
                155,
                0
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ColumnIndexValidator.java": [
                613,
                0
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/DictionaryPageReader.java": [
                115,
                0
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/DirectCodecFactory.java": [
                528,
                0
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/DirectZstd.java": [
                144,
                0
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/Footer.java": [
                53,
                0
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/InternalParquetRecordReader.java": [
                321,
                0
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/InternalParquetRecordWriter.java": [
                209,
                0
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/LruCache.java": [
                195,
                0
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/MemoryManager.java": [
                199,
                0
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/Offsets.java": [
                94,
                0
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ParquetEmptyBlockException.java": [
                41,
                0
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ParquetFileReader.java": [
                1869,
                0
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ParquetFileWriter.java": [
                1731,
                0
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ParquetInputFormat.java": [
                837,
                0
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ParquetInputSplit.java": [
                295,
                0
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ParquetMemoryManagerRuntimeException.java": [
                38,
                0
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ParquetOutputCommitter.java": [
                112,
                0
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ParquetOutputFormat.java": [
                570,
                0
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ParquetReader.java": [
                379,
                0
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ParquetRecordReader.java": [
                233,
                0
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ParquetRecordWriter.java": [
                184,
                0
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ParquetWriter.java": [
                744,
                0
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/PrintFooter.java": [
                265,
                0
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/UnmaterializableRecordCounter.java": [
                103,
                0
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/api/DelegatingReadSupport.java": [
                60,
                0
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/api/DelegatingWriteSupport.java": [
                69,
                0
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/api/InitContext.java": [
                99,
                0
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/api/ReadSupport.java": [
                145,
                0
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/api/WriteSupport.java": [
                140,
                0
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/api/package-info.java": [
                27,
                0
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/codec/CleanUtil.java": [
                111,
                0
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/codec/CodecConfig.java": [
                167,
                0
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/codec/Lz4RawCodec.java": [
                112,
                0
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/codec/Lz4RawCompressor.java": [
                44,
                0
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/codec/Lz4RawDecompressor.java": [
                46,
                0
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/codec/NonBlockedCompressor.java": [
                192,
                0
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/codec/NonBlockedCompressorStream.java": [
                50,
                0
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/codec/NonBlockedDecompressor.java": [
                180,
                0
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/codec/NonBlockedDecompressorStream.java": [
                57,
                0
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/codec/SnappyCodec.java": [
                105,
                0
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/codec/SnappyCompressor.java": [
                38,
                0
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/codec/SnappyDecompressor.java": [
                38,
                0
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/codec/SnappyUtil.java": [
                33,
                0
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/codec/ZstandardCodec.java": [
                130,
                0
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/codec/ZstdCompressorStream.java": [
                70,
                0
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/codec/ZstdDecompressorStream.java": [
                62,
                0
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/example/ExampleInputFormat.java": [
                35,
                0
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/example/ExampleOutputFormat.java": [
                58,
                0
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/example/ExampleParquetWriter.java": [
                118,
                0
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/example/GroupReadSupport.java": [
                49,
                0
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/example/GroupWriteSupport.java": [
                88,
                0
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/mapred/Container.java": [
                37,
                0
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/mapred/DeprecatedParquetInputFormat.java": [
                209,
                0
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/mapred/DeprecatedParquetOutputFormat.java": [
                119,
                0
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/mapred/MapredParquetOutputCommitter.java": [
                42,
                0
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/metadata/BlockMetaData.java": [
                153,
                0
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/metadata/ColumnChunkMetaData.java": [
                683,
                0
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/metadata/ColumnChunkProperties.java": [
                118,
                0
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/metadata/ConcatenatingKeyValueMetadataMergeStrategy.java": [
                61,
                0
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/metadata/EncodingList.java": [
                81,
                0
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/metadata/FileMetaData.java": [
                108,
                0
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/metadata/GlobalMetaData.java": [
                110,
                0
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/metadata/KeyValueMetadataMergeStrategy.java": [
                42,
                0
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/metadata/ParquetMetadata.java": [
                134,
                0
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/metadata/StrictKeyValueMetadataMergeStrategy.java": [
                42,
                0
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/package-info.java": [
                33,
                0
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/rewrite/MaskMode.java": [
                38,
                0
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/rewrite/ParquetRewriter.java": [
                819,
                0
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/rewrite/RewriteOptions.java": [
                262,
                0
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/util/ColumnEncryptor.java": [
                90,
                0
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/util/ColumnMasker.java": [
                98,
                0
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/util/ColumnPruner.java": [
                42,
                0
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/util/CompressionConverter.java": [
                81,
                0
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/util/ConfigurationUtil.java": [
                44,
                0
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/util/ContextUtil.java": [
                315,
                0
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/util/H1SeekableInputStream.java": [
                59,
                0
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/util/H2SeekableInputStream.java": [
                99,
                0
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/util/HadoopCodecs.java": [
                39,
                0
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/util/HadoopInputFile.java": [
                76,
                0
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/util/HadoopOutputFile.java": [
                105,
                0
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/util/HadoopPositionOutputStream.java": [
                66,
                0
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/util/HadoopStreams.java": [
                148,
                0
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/util/HiddenFileFilter.java": [
                39,
                0
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/util/SerializationUtil.java": [
                93,
                0
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/util/counters/BenchmarkCounter.java": [
                112,
                0
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/util/counters/CounterLoader.java": [
                27,
                0
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/util/counters/ICounter.java": [
                28,
                0
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/util/counters/mapred/MapRedCounterAdapter.java": [
                43,
                0
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/util/counters/mapred/MapRedCounterLoader.java": [
                51,
                0
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/util/counters/mapreduce/MapReduceCounterAdapter.java": [
                44,
                0
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/util/counters/mapreduce/MapReduceCounterLoader.java": [
                47,
                0
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/internal/hadoop/metadata/IndexReference.java": [
                41,
                0
            ],
            "parquet-hadoop/src/main/resources/META-INF/LICENSE": null,
            "parquet-hadoop/src/test/java/org/apache/parquet/DirectWriterTest.java": [
                102,
                0
            ],
            "parquet-hadoop/src/test/java/org/apache/parquet/crypto/DecryptionKeyRetrieverMock.java": [
                41,
                0
            ],
            "parquet-hadoop/src/test/java/org/apache/parquet/crypto/DecryptionPropertiesFactoryTest.java": [
                43,
                0
            ],
            "parquet-hadoop/src/test/java/org/apache/parquet/crypto/EncryptionPropertiesFactoryTest.java": [
                45,
                0
            ],
            "parquet-hadoop/src/test/java/org/apache/parquet/crypto/SampleDecryptionPropertiesFactory.java": [
                57,
                0
            ],
            "parquet-hadoop/src/test/java/org/apache/parquet/crypto/SampleEncryptionPropertiesFactory.java": [
                58,
                0
            ],
            "parquet-hadoop/src/test/java/org/apache/parquet/crypto/SingleRow.java": [
                139,
                0
            ],
            "parquet-hadoop/src/test/java/org/apache/parquet/crypto/TestPropertiesDrivenEncryption.java": [
                705,
                0
            ],
            "parquet-hadoop/src/test/java/org/apache/parquet/crypto/keytools/mocks/InMemoryKMS.java": [
                116,
                0
            ],
            "parquet-hadoop/src/test/java/org/apache/parquet/crypto/keytools/mocks/LocalWrapInMemoryKMS.java": [
                79,
                0
            ],
            "parquet-hadoop/src/test/java/org/apache/parquet/crypto/keytools/samples/VaultClient.java": [
                184,
                0
            ],
            "parquet-hadoop/src/test/java/org/apache/parquet/crypto/propertiesfactory/SchemaControlEncryptionTest.java": [
                250,
                0
            ],
            "parquet-hadoop/src/test/java/org/apache/parquet/crypto/propertiesfactory/SchemaCryptoPropertiesFactory.java": [
                137,
                0
            ],
            "parquet-hadoop/src/test/java/org/apache/parquet/encodings/FileEncodingsIT.java": [
                564,
                0
            ],
            "parquet-hadoop/src/test/java/org/apache/parquet/filter2/TestFiltersWithMissingColumns.java": [
                275,
                0
            ],
            "parquet-hadoop/src/test/java/org/apache/parquet/filter2/compat/TestRowGroupFilter.java": [
                128,
                0
            ],
            "parquet-hadoop/src/test/java/org/apache/parquet/filter2/dictionarylevel/DictionaryFilterTest.java": [
                839,
                0
            ],
            "parquet-hadoop/src/test/java/org/apache/parquet/filter2/recordlevel/PhoneBookWriter.java": [
                373,
                0
            ],
            "parquet-hadoop/src/test/java/org/apache/parquet/filter2/recordlevel/TestRecordLevelFilters.java": [
                310,
                0
            ],
            "parquet-hadoop/src/test/java/org/apache/parquet/filter2/statisticslevel/TestStatisticsFilter.java": [
                561,
                0
            ],
            "parquet-hadoop/src/test/java/org/apache/parquet/format/converter/TestParquetMetadataConverter.java": [
                1389,
                0
            ],
            "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/DeprecatedInputFormatTest.java": [
                346,
                0
            ],
            "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/DeprecatedOutputFormatTest.java": [
                108,
                0
            ],
            "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/ITTestEncryptionOptions.java": [
                50,
                0
            ],
            "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/TestAdaptiveBlockSplitBloomFiltering.java": [
                78,
                0
            ],
            "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/TestBloomFiltering.java": [
                421,
                0
            ],
            "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/TestColumnChunkPageWriteStore.java": [
                288,
                0
            ],
            "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/TestColumnIndexFiltering.java": [
                617,
                0
            ],
            "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/TestDataPageV1Checksums.java": [
                563,
                0
            ],
            "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/TestDirectCodecFactory.java": [
                178,
                0
            ],
            "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/TestEncryptionOptions.java": [
                752,
                0
            ],
            "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/TestInputFormat.java": [
                555,
                0
            ],
            "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/TestInputFormatColumnProjection.java": [
                180,
                0
            ],
            "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/TestInputOutputFormatWithPadding.java": [
                214,
                0
            ],
            "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/TestLargeColumnChunk.java": [
                145,
                0
            ],
            "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/TestLruCache.java": [
                162,
                0
            ],
            "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/TestMemoryManager.java": [
                189,
                0
            ],
            "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/TestMergeMetadataFiles.java": [
                221,
                0
            ],
            "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/TestMultipleWriteRead.java": [
                250,
                0
            ],
            "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/TestParquetFileWriter.java": [
                1218,
                0
            ],
            "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/TestParquetOutputFormatJobSummaryLevel.java": [
                69,
                0
            ],
            "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/TestParquetReader.java": [
                198,
                0
            ],
            "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/TestParquetReaderEmptyBlock.java": [
                170,
                0
            ],
            "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/TestParquetReaderRandomAccess.java": [
                387,
                0
            ],
            "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/TestParquetWriter.java": [
                431,
                0
            ],
            "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/TestParquetWriterAppendBlocks.java": [
                361,
                0
            ],
            "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/TestParquetWriterNewPage.java": [
                136,
                0
            ],
            "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/TestParquetWriterTruncation.java": [
                125,
                0
            ],
            "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/TestReadWriteEncodingStats.java": [
                122,
                0
            ],
            "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/TestSnappyCodec.java": [
                140,
                0
            ],
            "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/TestStoreBloomFilter.java": [
                132,
                0
            ],
            "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/TestUtils.java": [
                85,
                0
            ],
            "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/TestZstandardCodec.java": [
                173,
                0
            ],
            "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/codec/CodecConfigTest.java": [
                77,
                0
            ],
            "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/codec/TestCompressionCodec.java": [
                177,
                0
            ],
            "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/codec/TestInteropReadLz4RawCodec.java": [
                129,
                0
            ],
            "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/example/GroupReadSupportTest.java": [
                65,
                0
            ],
            "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/example/TestInputOutputFormat.java": [
                364,
                0
            ],
            "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/metadata/TestColumnChunkMetaData.java": [
                83,
                0
            ],
            "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/rewrite/ParquetRewriterTest.java": [
                772,
                0
            ],
            "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/util/ColumnEncryptorTest.java": [
                315,
                0
            ],
            "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/util/ColumnMaskerTest.java": [
                223,
                0
            ],
            "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/util/ColumnPrunerTest.java": [
                246,
                0
            ],
            "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/util/CompressionConverterTest.java": [
                312,
                0
            ],
            "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/util/EncDecProperties.java": [
                94,
                0
            ],
            "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/util/EncryptionTestFile.java": [
                38,
                0
            ],
            "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/util/MockHadoopInputStream.java": [
                87,
                0
            ],
            "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/util/TestFileBuilder.java": [
                198,
                0
            ],
            "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/util/TestHadoop2ByteBufferReads.java": [
                446,
                0
            ],
            "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/util/TestSerializationUtil.java": [
                71,
                0
            ],
            "parquet-hadoop/src/test/java/org/apache/parquet/statistics/DataGenerationContext.java": [
                85,
                0
            ],
            "parquet-hadoop/src/test/java/org/apache/parquet/statistics/RandomValues.java": [
                383,
                0
            ],
            "parquet-hadoop/src/test/java/org/apache/parquet/statistics/TestColumnIndexes.java": [
                304,
                0
            ],
            "parquet-hadoop/src/test/java/org/apache/parquet/statistics/TestStatistics.java": [
                459,
                0
            ],
            "parquet-hadoop/src/test/resources/log4j.properties": null,
            "parquet-hadoop/src/test/resources/test-append_1.parquet": null,
            "parquet-hadoop/src/test/resources/test-append_2.parquet": null,
            "parquet-hadoop/src/test/resources/test-empty-row-group_1.parquet": null,
            "parquet-hadoop/src/test/resources/test-empty-row-group_2.parquet": null,
            "parquet-hadoop/src/test/resources/test-empty-row-group_3.parquet": null,
            "parquet-hadoop/src/test/resources/test-file-with-no-column-indexes-1.parquet": null,
            "parquet-jackson/README.md": null,
            "parquet-jackson/pom.xml": null,
            "parquet-jackson/src/main/resources/META-INF/LICENSE": null,
            "parquet-pig-bundle/pom.xml": null,
            "parquet-pig-bundle/src/main/resources/META-INF/LICENSE": null,
            "parquet-pig-bundle/src/main/resources/org/apache/parquet/bundle": null,
            "parquet-pig/REVIEWERS.md": null,
            "parquet-pig/pom.xml": null,
            "parquet-pig/src/main/java/org/apache/parquet/pig/ParquetLoader.java": [
                575,
                0
            ],
            "parquet-pig/src/main/java/org/apache/parquet/pig/ParquetStorer.java": [
                152,
                0
            ],
            "parquet-pig/src/main/java/org/apache/parquet/pig/PigMetaData.java": [
                91,
                0
            ],
            "parquet-pig/src/main/java/org/apache/parquet/pig/PigSchemaConverter.java": [
                551,
                0
            ],
            "parquet-pig/src/main/java/org/apache/parquet/pig/SchemaConversionException.java": [
                44,
                0
            ],
            "parquet-pig/src/main/java/org/apache/parquet/pig/TupleConversionException.java": [
                42,
                0
            ],
            "parquet-pig/src/main/java/org/apache/parquet/pig/TupleReadSupport.java": [
                191,
                0
            ],
            "parquet-pig/src/main/java/org/apache/parquet/pig/TupleWriteSupport.java": [
                209,
                0
            ],
            "parquet-pig/src/main/java/org/apache/parquet/pig/convert/DecimalUtils.java": [
                65,
                0
            ],
            "parquet-pig/src/main/java/org/apache/parquet/pig/convert/MapConverter.java": [
                190,
                0
            ],
            "parquet-pig/src/main/java/org/apache/parquet/pig/convert/ParentValueContainer.java": [
                32,
                0
            ],
            "parquet-pig/src/main/java/org/apache/parquet/pig/convert/TupleConverter.java": [
                592,
                0
            ],
            "parquet-pig/src/main/java/org/apache/parquet/pig/convert/TupleRecordMaterializer.java": [
                50,
                0
            ],
            "parquet-pig/src/main/java/org/apache/parquet/pig/summary/BagSummaryData.java": [
                72,
                0
            ],
            "parquet-pig/src/main/java/org/apache/parquet/pig/summary/EnumStat.java": [
                115,
                0
            ],
            "parquet-pig/src/main/java/org/apache/parquet/pig/summary/FieldSummaryData.java": [
                178,
                0
            ],
            "parquet-pig/src/main/java/org/apache/parquet/pig/summary/MapSummaryData.java": [
                85,
                0
            ],
            "parquet-pig/src/main/java/org/apache/parquet/pig/summary/NumberSummaryData.java": [
                47,
                0
            ],
            "parquet-pig/src/main/java/org/apache/parquet/pig/summary/StringSummaryData.java": [
                82,
                0
            ],
            "parquet-pig/src/main/java/org/apache/parquet/pig/summary/Summary.java": [
                224,
                0
            ],
            "parquet-pig/src/main/java/org/apache/parquet/pig/summary/SummaryData.java": [
                135,
                0
            ],
            "parquet-pig/src/main/java/org/apache/parquet/pig/summary/TupleSummaryData.java": [
                98,
                0
            ],
            "parquet-pig/src/main/java/org/apache/parquet/pig/summary/ValueStat.java": [
                64,
                0
            ],
            "parquet-pig/src/test/java/org/apache/parquet/pig/PerfTest.java": [
                104,
                0
            ],
            "parquet-pig/src/test/java/org/apache/parquet/pig/PerfTest2.java": [
                185,
                0
            ],
            "parquet-pig/src/test/java/org/apache/parquet/pig/PerfTestReadAllCols.java": [
                47,
                0
            ],
            "parquet-pig/src/test/java/org/apache/parquet/pig/TestDecimalUtils.java": [
                79,
                0
            ],
            "parquet-pig/src/test/java/org/apache/parquet/pig/TestParquetLoader.java": [
                367,
                0
            ],
            "parquet-pig/src/test/java/org/apache/parquet/pig/TestParquetStorer.java": [
                264,
                0
            ],
            "parquet-pig/src/test/java/org/apache/parquet/pig/TestPigSchemaConverter.java": [
                291,
                0
            ],
            "parquet-pig/src/test/java/org/apache/parquet/pig/TestTupleRecordConsumer.java": [
                210,
                0
            ],
            "parquet-pig/src/test/java/org/apache/parquet/pig/TupleConsumerPerfTest.java": [
                206,
                0
            ],
            "parquet-pig/src/test/java/org/apache/parquet/pig/summary/TestSummary.java": [
                158,
                0
            ],
            "parquet-pig/src/test/resources/log4j.properties": null,
            "parquet-plugins/parquet-encoding-vector/pom.xml": null,
            "parquet-plugins/parquet-encoding-vector/src/main/java/org/apache/parquet/column/values/bitpacking/ByteBitPacking512VectorLE.java": [
                3010,
                0
            ],
            "parquet-plugins/parquet-encoding-vector/src/main/java/org/apache/parquet/column/values/bitpacking/ParquetReadRouter.java": [
                133,
                0
            ],
            "parquet-plugins/parquet-encoding-vector/src/main/java/org/apache/parquet/column/values/bitpacking/VectorSupport.java": [
                27,
                0
            ],
            "parquet-plugins/parquet-encoding-vector/src/test/java/org/apache/parquet/column/values/bitpacking/TestByteBitPacking512VectorLE.java": [
                169,
                0
            ],
            "parquet-plugins/parquet-encoding-vector/src/test/java/org/apache/parquet/column/values/bitpacking/TestParquetReadRouter.java": [
                59,
                0
            ],
            "parquet-plugins/parquet-plugins-benchmarks/pom.xml": null,
            "parquet-plugins/parquet-plugins-benchmarks/src/main/java/org/apache/parquet/plugins/benchmarks/ByteBitPackingVectorBenchmarks.java": [
                92,
                0
            ],
            "parquet-plugins/parquet-plugins-benchmarks/src/main/resources/log4j.properties": null,
            "parquet-protobuf/README.md": null,
            "parquet-protobuf/REVIEWERS.md": null,
            "parquet-protobuf/pom.xml": null,
            "parquet-protobuf/src/main/java/org/apache/parquet/proto/ProtoConstants.java": [
                46,
                0
            ],
            "parquet-protobuf/src/main/java/org/apache/parquet/proto/ProtoMessageConverter.java": [
                599,
                0
            ],
            "parquet-protobuf/src/main/java/org/apache/parquet/proto/ProtoParquetInputFormat.java": [
                38,
                0
            ],
            "parquet-protobuf/src/main/java/org/apache/parquet/proto/ProtoParquetOutputFormat.java": [
                52,
                0
            ],
            "parquet-protobuf/src/main/java/org/apache/parquet/proto/ProtoParquetReader.java": [
                101,
                0
            ],
            "parquet-protobuf/src/main/java/org/apache/parquet/proto/ProtoParquetWriter.java": [
                127,
                0
            ],
            "parquet-protobuf/src/main/java/org/apache/parquet/proto/ProtoReadSupport.java": [
                97,
                0
            ],
            "parquet-protobuf/src/main/java/org/apache/parquet/proto/ProtoRecordConverter.java": [
                100,
                0
            ],
            "parquet-protobuf/src/main/java/org/apache/parquet/proto/ProtoRecordMaterializer.java": [
                47,
                0
            ],
            "parquet-protobuf/src/main/java/org/apache/parquet/proto/ProtoSchemaConverter.java": [
                297,
                0
            ],
            "parquet-protobuf/src/main/java/org/apache/parquet/proto/ProtoWriteSupport.java": [
                586,
                0
            ],
            "parquet-protobuf/src/main/resources/META-INF/NOTICE": null,
            "parquet-protobuf/src/test/java/org/apache/parquet/proto/ProtoInputOutputFormatTest.java": [
                618,
                0
            ],
            "parquet-protobuf/src/test/java/org/apache/parquet/proto/ProtoRecordConverterTest.java": [
                363,
                0
            ],
            "parquet-protobuf/src/test/java/org/apache/parquet/proto/ProtoSchemaConverterTest.java": [
                539,
                0
            ],
            "parquet-protobuf/src/test/java/org/apache/parquet/proto/ProtoSchemaEvolutionTest.java": [
                133,
                0
            ],
            "parquet-protobuf/src/test/java/org/apache/parquet/proto/ProtoWriteSupportTest.java": [
                1204,
                0
            ],
            "parquet-protobuf/src/test/java/org/apache/parquet/proto/TestUtils.java": [
                232,
                0
            ],
            "parquet-protobuf/src/test/java/org/apache/parquet/proto/utils/ReadUsingMR.java": [
                94,
                0
            ],
            "parquet-protobuf/src/test/java/org/apache/parquet/proto/utils/WriteUsingMR.java": [
                121,
                0
            ],
            "parquet-protobuf/src/test/resources/BinaryTree.par": null,
            "parquet-protobuf/src/test/resources/Struct.par": null,
            "parquet-protobuf/src/test/resources/TestProto3.proto": null,
            "parquet-protobuf/src/test/resources/TestProto3SchemaV1.proto": null,
            "parquet-protobuf/src/test/resources/TestProto3SchemaV2.proto": null,
            "parquet-protobuf/src/test/resources/TestProto3SchemaV3.proto": null,
            "parquet-protobuf/src/test/resources/TestProtobuf.proto": null,
            "parquet-protobuf/src/test/resources/Trees.proto": null,
            "parquet-protobuf/src/test/resources/Value.par": null,
            "parquet-protobuf/src/test/resources/WideTree.par": null,
            "parquet-protobuf/src/test/resources/log4j.properties": null,
            "parquet-scala/pom.xml": null,
            "parquet-scala/src/main/scala/org/apache/parquet/filter2/dsl/Dsl.scala": null,
            "parquet-scala/src/test/scala/org/apache/parquet/filter2/dsl/DslTest.scala": null,
            "parquet-thrift/README.md": null,
            "parquet-thrift/REVIEWERS.md": null,
            "parquet-thrift/pom.xml": null,
            "parquet-thrift/src/main/java/org/apache/parquet/hadoop/thrift/AbstractThriftWriteSupport.java": [
                129,
                0
            ],
            "parquet-thrift/src/main/java/org/apache/parquet/hadoop/thrift/ParquetThriftBytesOutputFormat.java": [
                96,
                0
            ],
            "parquet-thrift/src/main/java/org/apache/parquet/hadoop/thrift/ParquetThriftInputFormat.java": [
                66,
                0
            ],
            "parquet-thrift/src/main/java/org/apache/parquet/hadoop/thrift/ParquetThriftOutputFormat.java": [
                43,
                0
            ],
            "parquet-thrift/src/main/java/org/apache/parquet/hadoop/thrift/TBaseWriteSupport.java": [
                70,
                0
            ],
            "parquet-thrift/src/main/java/org/apache/parquet/hadoop/thrift/ThriftBytesWriteSupport.java": [
                196,
                0
            ],
            "parquet-thrift/src/main/java/org/apache/parquet/hadoop/thrift/ThriftReadSupport.java": [
                289,
                0
            ],
            "parquet-thrift/src/main/java/org/apache/parquet/hadoop/thrift/ThriftToParquetFileWriter.java": [
                125,
                0
            ],
            "parquet-thrift/src/main/java/org/apache/parquet/hadoop/thrift/ThriftWriteSupport.java": [
                80,
                0
            ],
            "parquet-thrift/src/main/java/org/apache/parquet/thrift/BufferedProtocolReadToWrite.java": [
                738,
                0
            ],
            "parquet-thrift/src/main/java/org/apache/parquet/thrift/ConvertedField.java": [
                169,
                0
            ],
            "parquet-thrift/src/main/java/org/apache/parquet/thrift/DecodingSchemaMismatchException.java": [
                30,
                0
            ],
            "parquet-thrift/src/main/java/org/apache/parquet/thrift/FieldIgnoredHandler.java": [
                45,
                0
            ],
            "parquet-thrift/src/main/java/org/apache/parquet/thrift/KeepOnlyFirstPrimitiveFilter.java": [
                44,
                0
            ],
            "parquet-thrift/src/main/java/org/apache/parquet/thrift/ParquetProtocol.java": [
                282,
                0
            ],
            "parquet-thrift/src/main/java/org/apache/parquet/thrift/ParquetReadProtocol.java": [
                164,
                0
            ],
            "parquet-thrift/src/main/java/org/apache/parquet/thrift/ParquetWriteProtocol.java": [
                778,
                0
            ],
            "parquet-thrift/src/main/java/org/apache/parquet/thrift/ProtocolPipe.java": [
                29,
                0
            ],
            "parquet-thrift/src/main/java/org/apache/parquet/thrift/ProtocolReadToWrite.java": [
                142,
                0
            ],
            "parquet-thrift/src/main/java/org/apache/parquet/thrift/SkippableException.java": [
                47,
                0
            ],
            "parquet-thrift/src/main/java/org/apache/parquet/thrift/TBaseRecordConverter.java": [
                61,
                0
            ],
            "parquet-thrift/src/main/java/org/apache/parquet/thrift/ThriftMetaData.java": [
                147,
                0
            ],
            "parquet-thrift/src/main/java/org/apache/parquet/thrift/ThriftParquetReader.java": [
                139,
                0
            ],
            "parquet-thrift/src/main/java/org/apache/parquet/thrift/ThriftParquetWriter.java": [
                52,
                0
            ],
            "parquet-thrift/src/main/java/org/apache/parquet/thrift/ThriftReader.java": [
                28,
                0
            ],
            "parquet-thrift/src/main/java/org/apache/parquet/thrift/ThriftRecordConverter.java": [
                954,
                0
            ],
            "parquet-thrift/src/main/java/org/apache/parquet/thrift/ThriftSchemaConvertVisitor.java": [
                409,
                0
            ],
            "parquet-thrift/src/main/java/org/apache/parquet/thrift/ThriftSchemaConverter.java": [
                226,
                0
            ],
            "parquet-thrift/src/main/java/org/apache/parquet/thrift/pig/ParquetThriftStorer.java": [
                90,
                0
            ],
            "parquet-thrift/src/main/java/org/apache/parquet/thrift/pig/TupleToThriftWriteSupport.java": [
                79,
                0
            ],
            "parquet-thrift/src/main/java/org/apache/parquet/thrift/projection/FieldProjectionFilter.java": [
                62,
                0
            ],
            "parquet-thrift/src/main/java/org/apache/parquet/thrift/projection/FieldsPath.java": [
                87,
                0
            ],
            "parquet-thrift/src/main/java/org/apache/parquet/thrift/projection/StrictFieldProjectionFilter.java": [
                187,
                0
            ],
            "parquet-thrift/src/main/java/org/apache/parquet/thrift/projection/ThriftProjectionException.java": [
                45,
                0
            ],
            "parquet-thrift/src/main/java/org/apache/parquet/thrift/projection/amend/DefaultEventsVisitor.java": [
                228,
                0
            ],
            "parquet-thrift/src/main/java/org/apache/parquet/thrift/projection/amend/DefaultProtocolEventsGenerator.java": [
                68,
                0
            ],
            "parquet-thrift/src/main/java/org/apache/parquet/thrift/projection/amend/ProtocolEventsAmender.java": [
                171,
                0
            ],
            "parquet-thrift/src/main/java/org/apache/parquet/thrift/projection/amend/ReadFieldBeginProtocol.java": [
                44,
                0
            ],
            "parquet-thrift/src/main/java/org/apache/parquet/thrift/projection/deprecated/DeprecatedFieldProjectionFilter.java": [
                106,
                0
            ],
            "parquet-thrift/src/main/java/org/apache/parquet/thrift/projection/deprecated/PathGlobPattern.java": [
                173,
                0
            ],
            "parquet-thrift/src/main/java/org/apache/parquet/thrift/struct/CompatibilityChecker.java": [
                265,
                0
            ],
            "parquet-thrift/src/main/java/org/apache/parquet/thrift/struct/CompatibilityRunner.java": [
                104,
                0
            ],
            "parquet-thrift/src/main/java/org/apache/parquet/thrift/struct/JSON.java": [
                50,
                0
            ],
            "parquet-thrift/src/main/java/org/apache/parquet/thrift/struct/ThriftField.java": [
                121,
                0
            ],
            "parquet-thrift/src/main/java/org/apache/parquet/thrift/struct/ThriftType.java": [
                698,
                0
            ],
            "parquet-thrift/src/main/java/org/apache/parquet/thrift/struct/ThriftTypeID.java": [
                108,
                0
            ],
            "parquet-thrift/src/test/java/org/apache/parquet/hadoop/thrift/TestArrayCompatibility.java": [
                779,
                0
            ],
            "parquet-thrift/src/test/java/org/apache/parquet/hadoop/thrift/TestBinary.java": [
                86,
                0
            ],
            "parquet-thrift/src/test/java/org/apache/parquet/hadoop/thrift/TestCorruptThriftRecords.java": [
                213,
                0
            ],
            "parquet-thrift/src/test/java/org/apache/parquet/hadoop/thrift/TestInputOutputFormat.java": [
                258,
                0
            ],
            "parquet-thrift/src/test/java/org/apache/parquet/hadoop/thrift/TestParquetToThriftReadWriteAndProjection.java": [
                385,
                0
            ],
            "parquet-thrift/src/test/java/org/apache/parquet/hadoop/thrift/TestThriftToParquetFileWriter.java": [
                360,
                0
            ],
            "parquet-thrift/src/test/java/org/apache/parquet/thrift/TestParquetReadProtocol.java": [
                173,
                0
            ],
            "parquet-thrift/src/test/java/org/apache/parquet/thrift/TestParquetWriteProtocol.java": [
                719,
                0
            ],
            "parquet-thrift/src/test/java/org/apache/parquet/thrift/TestProtocolReadToWrite.java": [
                384,
                0
            ],
            "parquet-thrift/src/test/java/org/apache/parquet/thrift/TestThriftMetaData.java": [
                56,
                0
            ],
            "parquet-thrift/src/test/java/org/apache/parquet/thrift/TestThriftParquetReaderWriter.java": [
                83,
                0
            ],
            "parquet-thrift/src/test/java/org/apache/parquet/thrift/TestThriftRecordConverter.java": [
                101,
                0
            ],
            "parquet-thrift/src/test/java/org/apache/parquet/thrift/TestThriftSchemaConvertVisitor.java": [
                178,
                0
            ],
            "parquet-thrift/src/test/java/org/apache/parquet/thrift/TestThriftSchemaConverter.java": [
                353,
                0
            ],
            "parquet-thrift/src/test/java/org/apache/parquet/thrift/TestThriftSchemaConverterProjectUnion.java": [
                480,
                0
            ],
            "parquet-thrift/src/test/java/org/apache/parquet/thrift/TestThriftToPigCompatibility.java": [
                171,
                0
            ],
            "parquet-thrift/src/test/java/org/apache/parquet/thrift/pig/TestParquetThriftStorer.java": [
                82,
                0
            ],
            "parquet-thrift/src/test/java/org/apache/parquet/thrift/projection/TestFieldsPath.java": [
                162,
                0
            ],
            "parquet-thrift/src/test/java/org/apache/parquet/thrift/projection/TestStrictFieldProjectionFilter.java": [
                119,
                0
            ],
            "parquet-thrift/src/test/java/org/apache/parquet/thrift/projection/deprecated/PathGlobPatternTest.java": [
                59,
                0
            ],
            "parquet-thrift/src/test/java/org/apache/parquet/thrift/struct/CompatibilityCheckerTest.java": [
                132,
                0
            ],
            "parquet-thrift/src/test/java/org/apache/parquet/thrift/struct/TestThriftType.java": [
                70,
                0
            ],
            "parquet-thrift/src/test/resources/org/apache/parquet/hadoop/thrift/AddressBook.json": null,
            "parquet-thrift/src/test/resources/org/apache/parquet/thrift/StructWithUnionV1NoStructOrUnionMeta.json": null,
            "parquet-thrift/src/test/thrift/array_compat.thrift": null,
            "parquet-thrift/src/test/thrift/binary.thrift": null,
            "parquet-thrift/src/test/thrift/compat.thrift": null,
            "parquet-thrift/src/test/thrift/test.thrift": null,
            "pom.xml": null,
            "src/license.txt": null
        }
    },
    "5c46f055890eb86652e9b573c686190769599c29": {
        "datetime": "2013-10-23T21:48:16+02:00",
        "summary": "initial commit",
        "message": "initial commit\n",
        "diff": {
            ".editorconfig": null,
            ".github/PULL_REQUEST_TEMPLATE.md": null,
            ".github/dependabot.yml": null,
            ".github/workflows/ci-hadoop2.yml": null,
            ".github/workflows/ci-hadoop3.yml": null,
            ".github/workflows/vector-plugins.yml": null,
            ".gitignore": null,
            "CHANGES.md": null,
            "LICENSE": null,
            "NOTICE": null,
            "PoweredBy.md": null,
            "README.md": null,
            "changelog.sh": null,
            "dev/COMMITTERS.md": null,
            "dev/README.md": null,
            "dev/ci-before_install-master.sh": null,
            "dev/ci-before_install.sh": null,
            "dev/finalize-release": null,
            "dev/merge_parquet_pr.py": [
                393,
                0
            ],
            "dev/prepare-release.sh": null,
            "dev/source-release.sh": null,
            "doc/dremel_paper/dremel_example.png": null,
            "doc/dremel_paper/schema.png": null,
            "parquet-arrow/pom.xml": null,
            "parquet-arrow/src/main/java/org/apache/parquet/arrow/schema/List3Levels.java": [
                77,
                0
            ],
            "parquet-arrow/src/main/java/org/apache/parquet/arrow/schema/SchemaConverter.java": [
                705,
                0
            ],
            "parquet-arrow/src/main/java/org/apache/parquet/arrow/schema/SchemaMapping.java": [
                201,
                0
            ],
            "parquet-arrow/src/test/java/org/apache/parquet/arrow/schema/TestSchemaConverter.java": [
                530,
                0
            ],
            "parquet-avro/README.md": null,
            "parquet-avro/REVIEWERS.md": null,
            "parquet-avro/pom.xml": null,
            "parquet-avro/src/main/java/org/apache/parquet/avro/AvroCompatRecordMaterializer.java": [
                46,
                0
            ],
            "parquet-avro/src/main/java/org/apache/parquet/avro/AvroConverters.java": [
                333,
                0
            ],
            "parquet-avro/src/main/java/org/apache/parquet/avro/AvroDataSupplier.java": [
                31,
                0
            ],
            "parquet-avro/src/main/java/org/apache/parquet/avro/AvroIndexedRecordConverter.java": [
                535,
                0
            ],
            "parquet-avro/src/main/java/org/apache/parquet/avro/AvroParquetInputFormat.java": [
                86,
                0
            ],
            "parquet-avro/src/main/java/org/apache/parquet/avro/AvroParquetOutputFormat.java": [
                63,
                0
            ],
            "parquet-avro/src/main/java/org/apache/parquet/avro/AvroParquetReader.java": [
                178,
                0
            ],
            "parquet-avro/src/main/java/org/apache/parquet/avro/AvroParquetWriter.java": [
                193,
                0
            ],
            "parquet-avro/src/main/java/org/apache/parquet/avro/AvroReadSupport.java": [
                180,
                0
            ],
            "parquet-avro/src/main/java/org/apache/parquet/avro/AvroRecordConverter.java": [
                1093,
                0
            ],
            "parquet-avro/src/main/java/org/apache/parquet/avro/AvroRecordMaterializer.java": [
                45,
                0
            ],
            "parquet-avro/src/main/java/org/apache/parquet/avro/AvroSchemaConverter.java": [
                565,
                0
            ],
            "parquet-avro/src/main/java/org/apache/parquet/avro/AvroWriteSupport.java": [
                711,
                0
            ],
            "parquet-avro/src/main/java/org/apache/parquet/avro/GenericDataSupplier.java": [
                28,
                0
            ],
            "parquet-avro/src/main/java/org/apache/parquet/avro/ParentValueContainer.java": [
                238,
                0
            ],
            "parquet-avro/src/main/java/org/apache/parquet/avro/ReflectDataSupplier.java": [
                29,
                0
            ],
            "parquet-avro/src/main/java/org/apache/parquet/avro/SpecificDataSupplier.java": [
                29,
                0
            ],
            "parquet-avro/src/main/java/org/apache/parquet/avro/package-info.java": [
                174,
                0
            ],
            "parquet-avro/src/main/resources/META-INF/LICENSE": null,
            "parquet-avro/src/main/resources/META-INF/NOTICE": null,
            "parquet-avro/src/test/avro/logicalType.avsc": null,
            "parquet-avro/src/test/avro/stringBehavior.avsc": null,
            "parquet-avro/src/test/java/org/apache/parquet/avro/AvroTestUtil.java": [
                136,
                0
            ],
            "parquet-avro/src/test/java/org/apache/parquet/avro/TestArrayCompatibility.java": [
                1164,
                0
            ],
            "parquet-avro/src/test/java/org/apache/parquet/avro/TestAvroDataSupplier.java": [
                43,
                0
            ],
            "parquet-avro/src/test/java/org/apache/parquet/avro/TestAvroRecordConverter.java": [
                202,
                0
            ],
            "parquet-avro/src/test/java/org/apache/parquet/avro/TestAvroSchemaConverter.java": [
                942,
                0
            ],
            "parquet-avro/src/test/java/org/apache/parquet/avro/TestAvroWriteSupport.java": [
                61,
                0
            ],
            "parquet-avro/src/test/java/org/apache/parquet/avro/TestBackwardCompatibility.java": [
                68,
                0
            ],
            "parquet-avro/src/test/java/org/apache/parquet/avro/TestByteStreamSplitE2E.java": [
                114,
                0
            ],
            "parquet-avro/src/test/java/org/apache/parquet/avro/TestCircularReferences.java": [
                387,
                0
            ],
            "parquet-avro/src/test/java/org/apache/parquet/avro/TestGenericLogicalTypes.java": [
                296,
                0
            ],
            "parquet-avro/src/test/java/org/apache/parquet/avro/TestInputOutputFormat.java": [
                145,
                0
            ],
            "parquet-avro/src/test/java/org/apache/parquet/avro/TestReadWrite.java": [
                900,
                0
            ],
            "parquet-avro/src/test/java/org/apache/parquet/avro/TestReadWriteOldListBehavior.java": [
                584,
                0
            ],
            "parquet-avro/src/test/java/org/apache/parquet/avro/TestReflectInputOutputFormat.java": [
                496,
                0
            ],
            "parquet-avro/src/test/java/org/apache/parquet/avro/TestReflectLogicalTypes.java": [
                999,
                0
            ],
            "parquet-avro/src/test/java/org/apache/parquet/avro/TestReflectReadWrite.java": [
                240,
                0
            ],
            "parquet-avro/src/test/java/org/apache/parquet/avro/TestSpecificInputOutputFormat.java": [
                287,
                0
            ],
            "parquet-avro/src/test/java/org/apache/parquet/avro/TestSpecificReadWrite.java": [
                360,
                0
            ],
            "parquet-avro/src/test/java/org/apache/parquet/avro/TestStringBehavior.java": [
                330,
                0
            ],
            "parquet-avro/src/test/resources/all.avsc": null,
            "parquet-avro/src/test/resources/allFromParquetNewBehavior.avsc": null,
            "parquet-avro/src/test/resources/allFromParquetOldBehavior.avsc": null,
            "parquet-avro/src/test/resources/array.avsc": null,
            "parquet-avro/src/test/resources/car.avdl": null,
            "parquet-avro/src/test/resources/fixedToInt96.avsc": null,
            "parquet-avro/src/test/resources/list_with_nulls.avsc": null,
            "parquet-avro/src/test/resources/map.avsc": null,
            "parquet-avro/src/test/resources/map_with_nulls.avsc": null,
            "parquet-avro/src/test/resources/nested_array.avsc": null,
            "parquet-avro/src/test/resources/strings-2.parquet": null,
            "parquet-benchmarks/README.md": null,
            "parquet-benchmarks/pom.xml": null,
            "parquet-benchmarks/run.sh": null,
            "parquet-benchmarks/src/main/java/org/apache/parquet/benchmarks/BenchmarkConstants.java": [
                42,
                0
            ],
            "parquet-benchmarks/src/main/java/org/apache/parquet/benchmarks/BenchmarkFiles.java": [
                64,
                0
            ],
            "parquet-benchmarks/src/main/java/org/apache/parquet/benchmarks/BenchmarkUtils.java": [
                46,
                0
            ],
            "parquet-benchmarks/src/main/java/org/apache/parquet/benchmarks/DataGenerator.java": [
                137,
                0
            ],
            "parquet-benchmarks/src/main/java/org/apache/parquet/benchmarks/FilteringBenchmarks.java": [
                430,
                0
            ],
            "parquet-benchmarks/src/main/java/org/apache/parquet/benchmarks/NestedNullWritingBenchmarks.java": [
                156,
                0
            ],
            "parquet-benchmarks/src/main/java/org/apache/parquet/benchmarks/PageChecksumDataGenerator.java": [
                106,
                0
            ],
            "parquet-benchmarks/src/main/java/org/apache/parquet/benchmarks/PageChecksumReadBenchmarks.java": [
                196,
                0
            ],
            "parquet-benchmarks/src/main/java/org/apache/parquet/benchmarks/PageChecksumWriteBenchmarks.java": [
                178,
                0
            ],
            "parquet-benchmarks/src/main/java/org/apache/parquet/benchmarks/ReadBenchmarks.java": [
                131,
                0
            ],
            "parquet-benchmarks/src/main/java/org/apache/parquet/benchmarks/WriteBenchmarks.java": [
                168,
                0
            ],
            "parquet-benchmarks/src/main/resources/log4j.properties": null,
            "parquet-cli/README.md": null,
            "parquet-cli/pom.xml": null,
            "parquet-cli/src/main/java/org/apache/parquet/cli/BaseCommand.java": [
                428,
                0
            ],
            "parquet-cli/src/main/java/org/apache/parquet/cli/Command.java": [
                40,
                0
            ],
            "parquet-cli/src/main/java/org/apache/parquet/cli/HadoopFileSystemURLStreamHandler.java": [
                79,
                0
            ],
            "parquet-cli/src/main/java/org/apache/parquet/cli/Help.java": [
                153,
                0
            ],
            "parquet-cli/src/main/java/org/apache/parquet/cli/Main.java": [
                196,
                0
            ],
            "parquet-cli/src/main/java/org/apache/parquet/cli/Util.java": [
                272,
                0
            ],
            "parquet-cli/src/main/java/org/apache/parquet/cli/commands/CSVSchemaCommand.java": [
                131,
                0
            ],
            "parquet-cli/src/main/java/org/apache/parquet/cli/commands/CatCommand.java": [
                106,
                0
            ],
            "parquet-cli/src/main/java/org/apache/parquet/cli/commands/CheckParquet251Command.java": [
                352,
                0
            ],
            "parquet-cli/src/main/java/org/apache/parquet/cli/commands/ColumnMaskingCommand.java": [
                115,
                0
            ],
            "parquet-cli/src/main/java/org/apache/parquet/cli/commands/ColumnSizeCommand.java": [
                137,
                0
            ],
            "parquet-cli/src/main/java/org/apache/parquet/cli/commands/ConvertCSVCommand.java": [
                204,
                0
            ],
            "parquet-cli/src/main/java/org/apache/parquet/cli/commands/ConvertCommand.java": [
                165,
                0
            ],
            "parquet-cli/src/main/java/org/apache/parquet/cli/commands/ParquetMetadataCommand.java": [
                183,
                0
            ],
            "parquet-cli/src/main/java/org/apache/parquet/cli/commands/PruneColumnsCommand.java": [
                82,
                0
            ],
            "parquet-cli/src/main/java/org/apache/parquet/cli/commands/RewriteCommand.java": [
                131,
                0
            ],
            "parquet-cli/src/main/java/org/apache/parquet/cli/commands/ScanCommand.java": [
                91,
                0
            ],
            "parquet-cli/src/main/java/org/apache/parquet/cli/commands/SchemaCommand.java": [
                132,
                0
            ],
            "parquet-cli/src/main/java/org/apache/parquet/cli/commands/ShowBloomFilterCommand.java": [
                133,
                0
            ],
            "parquet-cli/src/main/java/org/apache/parquet/cli/commands/ShowColumnIndexCommand.java": [
                157,
                0
            ],
            "parquet-cli/src/main/java/org/apache/parquet/cli/commands/ShowDictionaryCommand.java": [
                139,
                0
            ],
            "parquet-cli/src/main/java/org/apache/parquet/cli/commands/ShowFooterCommand.java": [
                101,
                0
            ],
            "parquet-cli/src/main/java/org/apache/parquet/cli/commands/ShowPagesCommand.java": [
                234,
                0
            ],
            "parquet-cli/src/main/java/org/apache/parquet/cli/commands/ToAvroCommand.java": [
                134,
                0
            ],
            "parquet-cli/src/main/java/org/apache/parquet/cli/commands/TransCompressionCommand.java": [
                101,
                0
            ],
            "parquet-cli/src/main/java/org/apache/parquet/cli/csv/AvroCSV.java": [
                258,
                0
            ],
            "parquet-cli/src/main/java/org/apache/parquet/cli/csv/AvroCSVReader.java": [
                121,
                0
            ],
            "parquet-cli/src/main/java/org/apache/parquet/cli/csv/CSVProperties.java": [
                120,
                0
            ],
            "parquet-cli/src/main/java/org/apache/parquet/cli/csv/RecordBuilder.java": [
                200,
                0
            ],
            "parquet-cli/src/main/java/org/apache/parquet/cli/json/AvroJson.java": [
                631,
                0
            ],
            "parquet-cli/src/main/java/org/apache/parquet/cli/json/AvroJsonReader.java": [
                77,
                0
            ],
            "parquet-cli/src/main/java/org/apache/parquet/cli/rawpages/RawPagesReader.java": [
                92,
                0
            ],
            "parquet-cli/src/main/java/org/apache/parquet/cli/util/Codecs.java": [
                52,
                0
            ],
            "parquet-cli/src/main/java/org/apache/parquet/cli/util/Expressions.java": [
                395,
                0
            ],
            "parquet-cli/src/main/java/org/apache/parquet/cli/util/Formats.java": [
                47,
                0
            ],
            "parquet-cli/src/main/java/org/apache/parquet/cli/util/GetClassLoader.java": [
                39,
                0
            ],
            "parquet-cli/src/main/java/org/apache/parquet/cli/util/RawUtils.java": [
                85,
                0
            ],
            "parquet-cli/src/main/java/org/apache/parquet/cli/util/RecordException.java": [
                55,
                0
            ],
            "parquet-cli/src/main/java/org/apache/parquet/cli/util/RuntimeIOException.java": [
                31,
                0
            ],
            "parquet-cli/src/main/java/org/apache/parquet/cli/util/Schemas.java": [
                501,
                0
            ],
            "parquet-cli/src/main/java/org/apache/parquet/cli/util/SeekableFSDataInputStream.java": [
                76,
                0
            ],
            "parquet-cli/src/main/resources/META-INF/LICENSE": null,
            "parquet-cli/src/main/resources/META-INF/NOTICE": null,
            "parquet-cli/src/main/resources/cli-logging.properties": null,
            "parquet-cli/src/test/java/org/apache/parquet/cli/BaseCommandTest.java": [
                100,
                0
            ],
            "parquet-cli/src/test/java/org/apache/parquet/cli/MainTest.java": [
                34,
                0
            ],
            "parquet-cli/src/test/java/org/apache/parquet/cli/commands/AvroFileTest.java": [
                53,
                0
            ],
            "parquet-cli/src/test/java/org/apache/parquet/cli/commands/CSVFileTest.java": [
                51,
                0
            ],
            "parquet-cli/src/test/java/org/apache/parquet/cli/commands/CSVSchemaCommandTest.java": [
                39,
                0
            ],
            "parquet-cli/src/test/java/org/apache/parquet/cli/commands/CatCommandTest.java": [
                38,
                0
            ],
            "parquet-cli/src/test/java/org/apache/parquet/cli/commands/CheckParquet251CommandTest.java": [
                38,
                0
            ],
            "parquet-cli/src/test/java/org/apache/parquet/cli/commands/ColumnSizeCommandTest.java": [
                91,
                0
            ],
            "parquet-cli/src/test/java/org/apache/parquet/cli/commands/ConvertCSVCommandTest.java": [
                41,
                0
            ],
            "parquet-cli/src/test/java/org/apache/parquet/cli/commands/ConvertCommandTest.java": [
                41,
                0
            ],
            "parquet-cli/src/test/java/org/apache/parquet/cli/commands/FileTest.java": [
                58,
                0
            ],
            "parquet-cli/src/test/java/org/apache/parquet/cli/commands/ParquetFileTest.java": [
                117,
                0
            ],
            "parquet-cli/src/test/java/org/apache/parquet/cli/commands/ParquetMetadataCommandTest.java": [
                38,
                0
            ],
            "parquet-cli/src/test/java/org/apache/parquet/cli/commands/RewriteCommandTest.java": [
                41,
                0
            ],
            "parquet-cli/src/test/java/org/apache/parquet/cli/commands/ScanCommandTest.java": [
                38,
                0
            ],
            "parquet-cli/src/test/java/org/apache/parquet/cli/commands/SchemaCommandTest.java": [
                68,
                0
            ],
            "parquet-cli/src/test/java/org/apache/parquet/cli/commands/ShowBloomFilterCommandTest.java": [
                41,
                0
            ],
            "parquet-cli/src/test/java/org/apache/parquet/cli/commands/ShowColumnIndexTest.java": [
                38,
                0
            ],
            "parquet-cli/src/test/java/org/apache/parquet/cli/commands/ShowDictionaryCommandTest.java": [
                50,
                0
            ],
            "parquet-cli/src/test/java/org/apache/parquet/cli/commands/ShowFooterCommandTest.java": [
                43,
                0
            ],
            "parquet-cli/src/test/java/org/apache/parquet/cli/commands/ShowPagesCommandTest.java": [
                38,
                0
            ],
            "parquet-cli/src/test/java/org/apache/parquet/cli/commands/ToAvroCommandTest.java": [
                113,
                0
            ],
            "parquet-cli/src/test/java/org/apache/parquet/cli/commands/TransCompressionCommandTest.java": [
                45,
                0
            ],
            "parquet-column/REVIEWERS.md": null,
            "parquet-column/pom.xml": null,
            "parquet-column/src/main/java/org/apache/parquet/CorruptDeltaByteArrays.java": [
                97,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/CorruptStatistics.java": [
                116,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/ColumnDescriptor.java": [
                156,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/ColumnProperty.java": [
                137,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/ColumnReadStore.java": [
                32,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/ColumnReader.java": [
                117,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/ColumnWriteStore.java": [
                75,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/ColumnWriter.java": [
                96,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/Dictionary.java": [
                63,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/Encoding.java": [
                309,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/EncodingStats.java": [
                157,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/MinMax.java": [
                56,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/ParquetProperties.java": [
                589,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/UnknownColumnException.java": [
                40,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/UnknownColumnTypeException.java": [
                41,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/ValuesType.java": [
                26,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/impl/ColumnReadStoreImpl.java": [
                104,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/impl/ColumnReaderBase.java": [
                790,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/impl/ColumnReaderImpl.java": [
                58,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/impl/ColumnWriteStoreBase.java": [
                273,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/impl/ColumnWriteStoreV1.java": [
                52,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/impl/ColumnWriteStoreV2.java": [
                46,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/impl/ColumnWriterBase.java": [
                408,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/impl/ColumnWriterV1.java": [
                68,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/impl/ColumnWriterV2.java": [
                94,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/impl/SynchronizingColumnReader.java": [
                111,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/page/DataPage.java": [
                72,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/page/DataPageV1.java": [
                127,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/page/DataPageV2.java": [
                207,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/page/DictionaryPage.java": [
                83,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/page/DictionaryPageReadStore.java": [
                36,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/page/Page.java": [
                62,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/page/PageReadStore.java": [
                64,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/page/PageReader.java": [
                40,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/page/PageWriteStore.java": [
                35,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/page/PageWriter.java": [
                102,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/statistics/BinaryStatistics.java": [
                188,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/statistics/BooleanStatistics.java": [
                147,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/statistics/DoubleStatistics.java": [
                147,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/statistics/FloatStatistics.java": [
                148,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/statistics/IntStatistics.java": [
                147,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/statistics/LongStatistics.java": [
                147,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/statistics/Statistics.java": [
                539,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/statistics/StatisticsClassException.java": [
                44,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/values/RequiresFallback.java": [
                51,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/values/RequiresPreviousReader.java": [
                23,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/values/ValuesReader.java": [
                205,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/values/ValuesWriter.java": [
                136,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/values/bitpacking/BitPackingValuesReader.java": [
                84,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/values/bitpacking/BitPackingValuesWriter.java": [
                130,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/values/bitpacking/ByteBitPackingValuesReader.java": [
                99,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/values/bitpacking/ByteBitPackingValuesWriter.java": [
                86,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/values/bitpacking/DevNullValuesWriter.java": [
                89,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/values/bloomfilter/AdaptiveBlockSplitBloomFilter.java": [
                305,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/values/bloomfilter/BlockSplitBloomFilter.java": [
                424,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/values/bloomfilter/BloomFilter.java": [
                203,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/values/bloomfilter/BloomFilterWriteStore.java": [
                35,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/values/bloomfilter/BloomFilterWriter.java": [
                31,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/values/bloomfilter/HashFunction.java": [
                41,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/values/bloomfilter/XxHash.java": [
                40,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/values/bytestreamsplit/ByteStreamSplitValuesReader.java": [
                111,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/values/bytestreamsplit/ByteStreamSplitValuesReaderForDouble.java": [
                37,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/values/bytestreamsplit/ByteStreamSplitValuesReaderForFloat.java": [
                37,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/values/bytestreamsplit/ByteStreamSplitValuesWriter.java": [
                142,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/values/delta/DeltaBinaryPackingConfig.java": [
                55,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/values/delta/DeltaBinaryPackingValuesReader.java": [
                171,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/values/delta/DeltaBinaryPackingValuesWriter.java": [
                136,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/values/delta/DeltaBinaryPackingValuesWriterForInteger.java": [
                196,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/values/delta/DeltaBinaryPackingValuesWriterForLong.java": [
                198,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/values/deltalengthbytearray/DeltaLengthByteArrayValuesReader.java": [
                80,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/values/deltalengthbytearray/DeltaLengthByteArrayValuesWriter.java": [
                115,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/values/deltastrings/DeltaByteArrayReader.java": [
                96,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/values/deltastrings/DeltaByteArrayWriter.java": [
                100,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/values/dictionary/DictionaryValuesReader.java": [
                131,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/values/dictionary/DictionaryValuesWriter.java": [
                597,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/values/dictionary/IntList.java": [
                159,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/values/dictionary/PlainValuesDictionary.java": [
                313,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/values/factory/DefaultV1ValuesWriterFactory.java": [
                122,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/values/factory/DefaultV2ValuesWriterFactory.java": [
                126,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/values/factory/DefaultValuesWriterFactory.java": [
                87,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/values/factory/ValuesWriterFactory.java": [
                52,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/values/fallback/FallbackValuesWriter.java": [
                204,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/values/plain/BinaryPlainValuesReader.java": [
                63,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/values/plain/BooleanPlainValuesReader.java": [
                73,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/values/plain/BooleanPlainValuesWriter.java": [
                81,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/values/plain/FixedLenByteArrayPlainValuesReader.java": [
                72,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/values/plain/FixedLenByteArrayPlainValuesWriter.java": [
                106,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/values/plain/PlainValuesReader.java": [
                139,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/values/plain/PlainValuesWriter.java": [
                148,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/values/rle/RunLengthBitPackingHybridDecoder.java": [
                107,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/values/rle/RunLengthBitPackingHybridEncoder.java": [
                293,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/values/rle/RunLengthBitPackingHybridValuesReader.java": [
                68,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/values/rle/RunLengthBitPackingHybridValuesWriter.java": [
                95,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/values/rle/ZeroIntegerValuesReader.java": [
                50,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/example/DummyRecordConverter.java": [
                114,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/example/Paper.java": [
                164,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/example/data/Group.java": [
                147,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/example/data/GroupFactory.java": [
                25,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/example/data/GroupValueSource.java": [
                89,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/example/data/GroupWriter.java": [
                62,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/example/data/simple/BinaryValue.java": [
                52,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/example/data/simple/BooleanValue.java": [
                44,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/example/data/simple/DoubleValue.java": [
                45,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/example/data/simple/FloatValue.java": [
                45,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/example/data/simple/Int96Value.java": [
                46,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/example/data/simple/IntegerValue.java": [
                46,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/example/data/simple/LongValue.java": [
                45,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/example/data/simple/NanoTime.java": [
                80,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/example/data/simple/Primitive.java": [
                60,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/example/data/simple/SimpleGroup.java": [
                236,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/example/data/simple/SimpleGroupFactory.java": [
                38,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/example/data/simple/convert/GroupRecordConverter.java": [
                57,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/example/data/simple/convert/SimpleGroupConverter.java": [
                67,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/example/data/simple/convert/SimplePrimitiveConverter.java": [
                88,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/filter/AndRecordFilter.java": [
                65,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/filter/ColumnPredicates.java": [
                191,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/filter/ColumnRecordFilter.java": [
                76,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/filter/NotRecordFilter.java": [
                60,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/filter/OrRecordFilter.java": [
                62,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/filter/PagedRecordFilter.java": [
                65,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/filter/RecordFilter.java": [
                33,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/filter/UnboundRecordFilter.java": [
                37,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/filter2/compat/FilterCompat.java": [
                181,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/filter2/predicate/FilterApi.java": [
                328,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/filter2/predicate/FilterPredicate.java": [
                84,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/filter2/predicate/LogicalInverseRewriter.java": [
                126,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/filter2/predicate/LogicalInverter.java": [
                120,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/filter2/predicate/Operators.java": [
                587,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/filter2/predicate/PrimitiveToBoxedClass.java": [
                50,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/filter2/predicate/SchemaCompatibilityValidator.java": [
                204,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/filter2/predicate/Statistics.java": [
                93,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/filter2/predicate/UserDefinedPredicate.java": [
                131,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/filter2/predicate/ValidTypeMap.java": [
                128,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/filter2/recordlevel/FilteringGroupConverter.java": [
                112,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/filter2/recordlevel/FilteringPrimitiveConverter.java": [
                109,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/filter2/recordlevel/FilteringRecordMaterializer.java": [
                116,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/filter2/recordlevel/IncrementallyUpdatedFilterPredicate.java": [
                166,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/filter2/recordlevel/IncrementallyUpdatedFilterPredicateBuilderBase.java": [
                116,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/filter2/recordlevel/IncrementallyUpdatedFilterPredicateEvaluator.java": [
                62,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/filter2/recordlevel/IncrementallyUpdatedFilterPredicateResetter.java": [
                59,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/internal/column/columnindex/BinaryColumnIndexBuilder.java": [
                140,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/internal/column/columnindex/BinaryTruncator.java": [
                221,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/internal/column/columnindex/BooleanColumnIndexBuilder.java": [
                133,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/internal/column/columnindex/BoundaryOrder.java": [
                384,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/internal/column/columnindex/ColumnIndex.java": [
                60,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/internal/column/columnindex/ColumnIndexBuilder.java": [
                686,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/internal/column/columnindex/DoubleColumnIndexBuilder.java": [
                155,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/internal/column/columnindex/FloatColumnIndexBuilder.java": [
                155,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/internal/column/columnindex/IndexIterator.java": [
                89,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/internal/column/columnindex/IntColumnIndexBuilder.java": [
                136,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/internal/column/columnindex/LongColumnIndexBuilder.java": [
                136,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/internal/column/columnindex/OffsetIndex.java": [
                73,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/internal/column/columnindex/OffsetIndexBuilder.java": [
                193,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/internal/filter2/columnindex/ColumnIndexFilter.java": [
                217,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/internal/filter2/columnindex/ColumnIndexStore.java": [
                55,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/internal/filter2/columnindex/RowRanges.java": [
                318,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/io/BaseRecordReader.java": [
                149,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/io/ColumnIO.java": [
                138,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/io/ColumnIOFactory.java": [
                174,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/io/CompilationException.java": [
                44,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/io/EmptyRecordReader.java": [
                48,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/io/FilteredRecordReader.java": [
                97,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/io/GroupColumnIO.java": [
                121,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/io/InvalidFileOffsetException.java": [
                29,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/io/InvalidRecordException.java": [
                45,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/io/MessageColumnIO.java": [
                534,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/io/ParquetDecodingException.java": [
                44,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/io/ParquetEncodingException.java": [
                44,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/io/PrimitiveColumnIO.java": [
                108,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/io/RecordConsumerLoggingWrapper.java": [
                187,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/io/RecordReader.java": [
                43,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/io/RecordReaderImplementation.java": [
                474,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/io/ValidatingRecordConsumer.java": [
                247,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/io/api/Binary.java": [
                737,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/io/api/Converter.java": [
                37,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/io/api/GroupConverter.java": [
                55,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/io/api/PrimitiveConverter.java": [
                108,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/io/api/RecordConsumer.java": [
                134,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/io/api/RecordMaterializer.java": [
                73,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/schema/ColumnOrder.java": [
                97,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/schema/ConversionPatterns.java": [
                133,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/schema/DecimalMetadata.java": [
                62,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/schema/GroupType.java": [
                421,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/schema/IncompatibleSchemaModificationException.java": [
                46,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/schema/InvalidSchemaException.java": [
                31,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/schema/LogicalTypeAnnotation.java": [
                1064,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/schema/MessageType.java": [
                145,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/schema/MessageTypeParser.java": [
                243,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/schema/OriginalType.java": [
                48,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/schema/PrimitiveComparator.java": [
                279,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/schema/PrimitiveStringifier.java": [
                451,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/schema/PrimitiveType.java": [
                797,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/schema/Type.java": [
                366,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/schema/TypeConverter.java": [
                53,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/schema/TypeUtil.java": [
                45,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/schema/TypeVisitor.java": [
                43,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/schema/Types.java": [
                1542,
                0
            ],
            "parquet-column/src/main/resources/META-INF/LICENSE": null,
            "parquet-column/src/test/java/org/apache/parquet/CorruptStatisticsTest.java": [
                92,
                0
            ],
            "parquet-column/src/test/java/org/apache/parquet/FixedBinaryTestUtils.java": [
                96,
                0
            ],
            "parquet-column/src/test/java/org/apache/parquet/ResourceIntensiveTestRule.java": [
                58,
                0
            ],
            "parquet-column/src/test/java/org/apache/parquet/column/TestColumnDescriptor.java": [
                52,
                0
            ],
            "parquet-column/src/test/java/org/apache/parquet/column/TestEncodingStats.java": [
                202,
                0
            ],
            "parquet-column/src/test/java/org/apache/parquet/column/impl/TestColumnReaderImpl.java": [
                131,
                0
            ],
            "parquet-column/src/test/java/org/apache/parquet/column/impl/TestCorruptDeltaByteArrays.java": [
                269,
                0
            ],
            "parquet-column/src/test/java/org/apache/parquet/column/mem/TestMemColumn.java": [
                246,
                0
            ],
            "parquet-column/src/test/java/org/apache/parquet/column/mem/TestMemPageStore.java": [
                61,
                0
            ],
            "parquet-column/src/test/java/org/apache/parquet/column/page/mem/MemPageReader.java": [
                67,
                0
            ],
            "parquet-column/src/test/java/org/apache/parquet/column/page/mem/MemPageStore.java": [
                78,
                0
            ],
            "parquet-column/src/test/java/org/apache/parquet/column/page/mem/MemPageWriter.java": [
                117,
                0
            ],
            "parquet-column/src/test/java/org/apache/parquet/column/statistics/TestStatistics.java": [
                789,
                0
            ],
            "parquet-column/src/test/java/org/apache/parquet/column/values/TestValuesReaderImpl.java": [
                148,
                0
            ],
            "parquet-column/src/test/java/org/apache/parquet/column/values/Utils.java": [
                76,
                0
            ],
            "parquet-column/src/test/java/org/apache/parquet/column/values/bitpacking/BitPackingPerfTest.java": [
                103,
                0
            ],
            "parquet-column/src/test/java/org/apache/parquet/column/values/bitpacking/TestBitPackingColumn.java": [
                232,
                0
            ],
            "parquet-column/src/test/java/org/apache/parquet/column/values/bloomfilter/TestBlockSplitBloomFilter.java": [
                325,
                0
            ],
            "parquet-column/src/test/java/org/apache/parquet/column/values/bytestreamsplit/ByteStreamSplitValuesEndToEndTest.java": [
                111,
                0
            ],
            "parquet-column/src/test/java/org/apache/parquet/column/values/bytestreamsplit/ByteStreamSplitValuesReaderTest.java": [
                193,
                0
            ],
            "parquet-column/src/test/java/org/apache/parquet/column/values/bytestreamsplit/ByteStreamSplitValuesWriterTest.java": [
                189,
                0
            ],
            "parquet-column/src/test/java/org/apache/parquet/column/values/delta/DeltaBinaryPackingValuesWriterForIntegerTest.java": [
                294,
                0
            ],
            "parquet-column/src/test/java/org/apache/parquet/column/values/delta/DeltaBinaryPackingValuesWriterForLongTest.java": [
                291,
                0
            ],
            "parquet-column/src/test/java/org/apache/parquet/column/values/delta/benchmark/BenchMarkTest.java": [
                41,
                0
            ],
            "parquet-column/src/test/java/org/apache/parquet/column/values/delta/benchmark/BenchmarkIntegerOutputSize.java": [
                107,
                0
            ],
            "parquet-column/src/test/java/org/apache/parquet/column/values/delta/benchmark/BenchmarkReadingRandomIntegers.java": [
                102,
                0
            ],
            "parquet-column/src/test/java/org/apache/parquet/column/values/delta/benchmark/RandomWritingBenchmarkTest.java": [
                76,
                0
            ],
            "parquet-column/src/test/java/org/apache/parquet/column/values/delta/benchmark/SmallRangeWritingBenchmarkTest.java": [
                49,
                0
            ],
            "parquet-column/src/test/java/org/apache/parquet/column/values/deltalengthbytearray/TestDeltaLengthByteArray.java": [
                103,
                0
            ],
            "parquet-column/src/test/java/org/apache/parquet/column/values/deltalengthbytearray/benchmark/BenchmarkDeltaLengthByteArray.java": [
                73,
                0
            ],
            "parquet-column/src/test/java/org/apache/parquet/column/values/deltastrings/TestDeltaByteArray.java": [
                130,
                0
            ],
            "parquet-column/src/test/java/org/apache/parquet/column/values/deltastrings/benchmark/BenchmarkDeltaByteArray.java": [
                103,
                0
            ],
            "parquet-column/src/test/java/org/apache/parquet/column/values/dictionary/IntListTest.java": [
                84,
                0
            ],
            "parquet-column/src/test/java/org/apache/parquet/column/values/dictionary/TestDictionary.java": [
                661,
                0
            ],
            "parquet-column/src/test/java/org/apache/parquet/column/values/factory/DefaultValuesWriterFactoryTest.java": [
                546,
                0
            ],
            "parquet-column/src/test/java/org/apache/parquet/column/values/rle/RunLengthBitPackingHybridIntegrationTest.java": [
                86,
                0
            ],
            "parquet-column/src/test/java/org/apache/parquet/column/values/rle/TestRunLengthBitPackingHybridEncoder.java": [
                329,
                0
            ],
            "parquet-column/src/test/java/org/apache/parquet/filter2/predicate/DummyUdp.java": [
                37,
                0
            ],
            "parquet-column/src/test/java/org/apache/parquet/filter2/predicate/TestFilterApiMethods.java": [
                172,
                0
            ],
            "parquet-column/src/test/java/org/apache/parquet/filter2/predicate/TestLogicalInverseRewriter.java": [
                103,
                0
            ],
            "parquet-column/src/test/java/org/apache/parquet/filter2/predicate/TestLogicalInverter.java": [
                94,
                0
            ],
            "parquet-column/src/test/java/org/apache/parquet/filter2/predicate/TestSchemaCompatibilityValidator.java": [
                142,
                0
            ],
            "parquet-column/src/test/java/org/apache/parquet/filter2/predicate/TestValidTypeMap.java": [
                98,
                0
            ],
            "parquet-column/src/test/java/org/apache/parquet/filter2/recordlevel/TestIncrementallyUpdatedFilterPredicateEvaluator.java": [
                209,
                0
            ],
            "parquet-column/src/test/java/org/apache/parquet/filter2/recordlevel/TestIncrementallyUpdatedFilterPredicateResetter.java": [
                69,
                0
            ],
            "parquet-column/src/test/java/org/apache/parquet/filter2/recordlevel/TestValueInspector.java": [
                97,
                0
            ],
            "parquet-column/src/test/java/org/apache/parquet/internal/column/columnindex/TestBinaryTruncator.java": [
                285,
                0
            ],
            "parquet-column/src/test/java/org/apache/parquet/internal/column/columnindex/TestBoundaryOrder.java": [
                543,
                0
            ],
            "parquet-column/src/test/java/org/apache/parquet/internal/column/columnindex/TestColumnIndexBuilder.java": [
                1728,
                0
            ],
            "parquet-column/src/test/java/org/apache/parquet/internal/column/columnindex/TestIndexIterator.java": [
                63,
                0
            ],
            "parquet-column/src/test/java/org/apache/parquet/internal/column/columnindex/TestOffsetIndexBuilder.java": [
                111,
                0
            ],
            "parquet-column/src/test/java/org/apache/parquet/internal/filter2/columnindex/TestColumnIndexFilter.java": [
                555,
                0
            ],
            "parquet-column/src/test/java/org/apache/parquet/internal/filter2/columnindex/TestRowRanges.java": [
                155,
                0
            ],
            "parquet-column/src/test/java/org/apache/parquet/io/ConverterConsumer.java": [
                125,
                0
            ],
            "parquet-column/src/test/java/org/apache/parquet/io/ExpectationValidatingConverter.java": [
                169,
                0
            ],
            "parquet-column/src/test/java/org/apache/parquet/io/ExpectationValidatingRecordConsumer.java": [
                112,
                0
            ],
            "parquet-column/src/test/java/org/apache/parquet/io/PerfTest.java": [
                128,
                0
            ],
            "parquet-column/src/test/java/org/apache/parquet/io/TestColumnIO.java": [
                709,
                0
            ],
            "parquet-column/src/test/java/org/apache/parquet/io/TestFiltered.java": [
                278,
                0
            ],
            "parquet-column/src/test/java/org/apache/parquet/io/api/TestBinary.java": [
                271,
                0
            ],
            "parquet-column/src/test/java/org/apache/parquet/parser/TestParquetParser.java": [
                374,
                0
            ],
            "parquet-column/src/test/java/org/apache/parquet/schema/TestMessageType.java": [
                247,
                0
            ],
            "parquet-column/src/test/java/org/apache/parquet/schema/TestPrimitiveComparator.java": [
                330,
                0
            ],
            "parquet-column/src/test/java/org/apache/parquet/schema/TestPrimitiveStringifier.java": [
                391,
                0
            ],
            "parquet-column/src/test/java/org/apache/parquet/schema/TestRepetitionType.java": [
                36,
                0
            ],
            "parquet-column/src/test/java/org/apache/parquet/schema/TestTypeBuilders.java": [
                1372,
                0
            ],
            "parquet-column/src/test/java/org/apache/parquet/schema/TestTypeBuildersWithLogicalTypes.java": [
                422,
                0
            ],
            "parquet-column/src/test/java/org/apache/parquet/schema/TestTypeUtil.java": [
                80,
                0
            ],
            "parquet-common/REVIEWERS.md": null,
            "parquet-common/pom.xml": null,
            "parquet-common/src/main/java/org/apache/parquet/Closeables.java": [
                60,
                0
            ],
            "parquet-common/src/main/java/org/apache/parquet/Exceptions.java": [
                39,
                0
            ],
            "parquet-common/src/main/java/org/apache/parquet/Files.java": [
                54,
                0
            ],
            "parquet-common/src/main/java/org/apache/parquet/IOExceptionUtils.java": [
                45,
                0
            ],
            "parquet-common/src/main/java/org/apache/parquet/Ints.java": [
                44,
                0
            ],
            "parquet-common/src/main/java/org/apache/parquet/Log.java": [
                146,
                0
            ],
            "parquet-common/src/main/java/org/apache/parquet/OutputStreamCloseException.java": [
                46,
                0
            ],
            "parquet-common/src/main/java/org/apache/parquet/ParquetRuntimeException.java": [
                42,
                0
            ],
            "parquet-common/src/main/java/org/apache/parquet/Preconditions.java": [
                251,
                0
            ],
            "parquet-common/src/main/java/org/apache/parquet/SemanticVersion.java": [
                293,
                0
            ],
            "parquet-common/src/main/java/org/apache/parquet/ShouldNeverHappenException.java": [
                40,
                0
            ],
            "parquet-common/src/main/java/org/apache/parquet/Strings.java": [
                132,
                0
            ],
            "parquet-common/src/main/java/org/apache/parquet/VersionParser.java": [
                129,
                0
            ],
            "parquet-common/src/main/java/org/apache/parquet/bytes/ByteBufferAllocator.java": [
                40,
                0
            ],
            "parquet-common/src/main/java/org/apache/parquet/bytes/ByteBufferInputStream.java": [
                160,
                0
            ],
            "parquet-common/src/main/java/org/apache/parquet/bytes/BytesInput.java": [
                545,
                0
            ],
            "parquet-common/src/main/java/org/apache/parquet/bytes/BytesUtils.java": [
                335,
                0
            ],
            "parquet-common/src/main/java/org/apache/parquet/bytes/CapacityByteArrayOutputStream.java": [
                352,
                0
            ],
            "parquet-common/src/main/java/org/apache/parquet/bytes/ConcatenatingByteArrayCollector.java": [
                63,
                0
            ],
            "parquet-common/src/main/java/org/apache/parquet/bytes/DirectByteBufferAllocator.java": [
                43,
                0
            ],
            "parquet-common/src/main/java/org/apache/parquet/bytes/HeapByteBufferAllocator.java": [
                44,
                0
            ],
            "parquet-common/src/main/java/org/apache/parquet/bytes/LittleEndianDataInputStream.java": [
                421,
                0
            ],
            "parquet-common/src/main/java/org/apache/parquet/bytes/LittleEndianDataOutputStream.java": [
                218,
                0
            ],
            "parquet-common/src/main/java/org/apache/parquet/bytes/MultiBufferInputStream.java": [
                382,
                0
            ],
            "parquet-common/src/main/java/org/apache/parquet/bytes/SingleBufferInputStream.java": [
                177,
                0
            ],
            "parquet-common/src/main/java/org/apache/parquet/compression/CompressionCodecFactory.java": [
                47,
                0
            ],
            "parquet-common/src/main/java/org/apache/parquet/glob/GlobExpander.java": [
                129,
                0
            ],
            "parquet-common/src/main/java/org/apache/parquet/glob/GlobNode.java": [
                157,
                0
            ],
            "parquet-common/src/main/java/org/apache/parquet/glob/GlobParser.java": [
                224,
                0
            ],
            "parquet-common/src/main/java/org/apache/parquet/glob/WildcardPath.java": [
                121,
                0
            ],
            "parquet-common/src/main/java/org/apache/parquet/hadoop/codec/CompressionCodecNotSupportedException.java": [
                38,
                0
            ],
            "parquet-common/src/main/java/org/apache/parquet/hadoop/metadata/Canonicalizer.java": [
                61,
                0
            ],
            "parquet-common/src/main/java/org/apache/parquet/hadoop/metadata/ColumnPath.java": [
                88,
                0
            ],
            "parquet-common/src/main/java/org/apache/parquet/hadoop/metadata/CompressionCodecName.java": [
                99,
                0
            ],
            "parquet-common/src/main/java/org/apache/parquet/io/DelegatingPositionOutputStream.java": [
                63,
                0
            ],
            "parquet-common/src/main/java/org/apache/parquet/io/DelegatingSeekableInputStream.java": [
                171,
                0
            ],
            "parquet-common/src/main/java/org/apache/parquet/io/InputFile.java": [
                44,
                0
            ],
            "parquet-common/src/main/java/org/apache/parquet/io/LocalInputFile.java": [
                102,
                0
            ],
            "parquet-common/src/main/java/org/apache/parquet/io/LocalOutputFile.java": [
                107,
                0
            ],
            "parquet-common/src/main/java/org/apache/parquet/io/OutputFile.java": [
                62,
                0
            ],
            "parquet-common/src/main/java/org/apache/parquet/io/PositionOutputStream.java": [
                39,
                0
            ],
            "parquet-common/src/main/java/org/apache/parquet/io/SeekableInputStream.java": [
                108,
                0
            ],
            "parquet-common/src/main/java/org/apache/parquet/util/DynConstructors.java": [
                263,
                0
            ],
            "parquet-common/src/main/java/org/apache/parquet/util/DynMethods.java": [
                506,
                0
            ],
            "parquet-common/src/test/java/org/apache/parquet/SemanticVersionTest.java": [
                114,
                0
            ],
            "parquet-common/src/test/java/org/apache/parquet/TestPreconditions.java": [
                246,
                0
            ],
            "parquet-common/src/test/java/org/apache/parquet/TestUtils.java": [
                70,
                0
            ],
            "parquet-common/src/test/java/org/apache/parquet/VersionTest.java": [
                100,
                0
            ],
            "parquet-common/src/test/java/org/apache/parquet/bytes/TestByteBufferInputStreams.java": [
                589,
                0
            ],
            "parquet-common/src/test/java/org/apache/parquet/bytes/TestBytesUtil.java": [
                49,
                0
            ],
            "parquet-common/src/test/java/org/apache/parquet/bytes/TestDeprecatedBufferInputStream.java": [
                152,
                0
            ],
            "parquet-common/src/test/java/org/apache/parquet/bytes/TestMultiBufferInputStream.java": [
                141,
                0
            ],
            "parquet-common/src/test/java/org/apache/parquet/bytes/TestSingleBufferInputStream.java": [
                130,
                0
            ],
            "parquet-common/src/test/java/org/apache/parquet/glob/TestGlob.java": [
                144,
                0
            ],
            "parquet-common/src/test/java/org/apache/parquet/glob/TestWildcardPath.java": [
                125,
                0
            ],
            "parquet-common/src/test/java/org/apache/parquet/io/MockInputStream.java": [
                56,
                0
            ],
            "parquet-common/src/test/java/org/apache/parquet/io/TestDelegatingSeekableInputStream.java": [
                844,
                0
            ],
            "parquet-common/src/test/java/org/apache/parquet/io/TestLocalInputOutput.java": [
                92,
                0
            ],
            "parquet-common/src/test/java/org/apache/parquet/util/Concatenator.java": [
                82,
                0
            ],
            "parquet-common/src/test/java/org/apache/parquet/util/TestDynConstructors.java": [
                165,
                0
            ],
            "parquet-common/src/test/java/org/apache/parquet/util/TestDynMethods.java": [
                315,
                0
            ],
            "parquet-encoding/REVIEWERS.md": null,
            "parquet-encoding/pom.xml": null,
            "parquet-encoding/src/main/java/org/apache/parquet/column/values/bitpacking/BitPacking.java": [
                717,
                0
            ],
            "parquet-encoding/src/main/java/org/apache/parquet/column/values/bitpacking/ByteBasedBitPackingEncoder.java": [
                142,
                0
            ],
            "parquet-encoding/src/main/java/org/apache/parquet/column/values/bitpacking/BytePacker.java": [
                141,
                0
            ],
            "parquet-encoding/src/main/java/org/apache/parquet/column/values/bitpacking/BytePackerFactory.java": [
                25,
                0
            ],
            "parquet-encoding/src/main/java/org/apache/parquet/column/values/bitpacking/BytePackerForLong.java": [
                109,
                0
            ],
            "parquet-encoding/src/main/java/org/apache/parquet/column/values/bitpacking/BytePackerForLongFactory.java": [
                25,
                0
            ],
            "parquet-encoding/src/main/java/org/apache/parquet/column/values/bitpacking/IntPacker.java": [
                63,
                0
            ],
            "parquet-encoding/src/main/java/org/apache/parquet/column/values/bitpacking/IntPackerFactory.java": [
                25,
                0
            ],
            "parquet-encoding/src/main/java/org/apache/parquet/column/values/bitpacking/Packer.java": [
                137,
                0
            ],
            "parquet-encoding/src/main/resources/META-INF/LICENSE": null,
            "parquet-encoding/src/test/java/org/apache/parquet/bytes/TestBytesInput.java": [
                42,
                0
            ],
            "parquet-encoding/src/test/java/org/apache/parquet/bytes/TestCapacityByteArrayOutputStream.java": [
                242,
                0
            ],
            "parquet-encoding/src/test/java/org/apache/parquet/column/values/bitpacking/TestBitPacking.java": [
                233,
                0
            ],
            "parquet-encoding/src/test/java/org/apache/parquet/column/values/bitpacking/TestByteBasedBitPackingEncoder.java": [
                46,
                0
            ],
            "parquet-encoding/src/test/java/org/apache/parquet/column/values/bitpacking/TestByteBitPacking.java": [
                198,
                0
            ],
            "parquet-encoding/src/test/java/org/apache/parquet/column/values/bitpacking/TestLemireBitPacking.java": [
                125,
                0
            ],
            "parquet-format-structures/pom.xml": null,
            "parquet-format-structures/src/main/java/org/apache/parquet/format/BlockCipher.java": [
                76,
                0
            ],
            "parquet-format-structures/src/main/java/org/apache/parquet/format/CliUtils.java": [
                55,
                0
            ],
            "parquet-format-structures/src/main/java/org/apache/parquet/format/InterningProtocol.java": [
                236,
                0
            ],
            "parquet-format-structures/src/main/java/org/apache/parquet/format/InvalidParquetMetadataException.java": [
                30,
                0
            ],
            "parquet-format-structures/src/main/java/org/apache/parquet/format/LogicalTypes.java": [
                55,
                0
            ],
            "parquet-format-structures/src/main/java/org/apache/parquet/format/MetadataValidator.java": [
                44,
                0
            ],
            "parquet-format-structures/src/main/java/org/apache/parquet/format/Util.java": [
                389,
                0
            ],
            "parquet-format-structures/src/main/java/org/apache/parquet/format/event/Consumers.java": [
                191,
                0
            ],
            "parquet-format-structures/src/main/java/org/apache/parquet/format/event/EventBasedThriftReader.java": [
                126,
                0
            ],
            "parquet-format-structures/src/main/java/org/apache/parquet/format/event/FieldConsumer.java": [
                39,
                0
            ],
            "parquet-format-structures/src/main/java/org/apache/parquet/format/event/TypedConsumer.java": [
                205,
                0
            ],
            "parquet-format-structures/src/test/java/org/apache/parquet/format/TestUtil.java": [
                101,
                0
            ],
            "parquet-generator/REVIEWERS.md": null,
            "parquet-generator/pom.xml": null,
            "parquet-generator/src/main/java/org/apache/parquet/encoding/Generator.java": [
                34,
                0
            ],
            "parquet-generator/src/main/java/org/apache/parquet/encoding/bitpacking/ByteBasedBitPackingGenerator.java": [
                319,
                0
            ],
            "parquet-generator/src/main/java/org/apache/parquet/encoding/bitpacking/IntBasedBitPackingGenerator.java": [
                208,
                0
            ],
            "parquet-generator/src/main/java/org/apache/parquet/filter2/Generator.java": [
                28,
                0
            ],
            "parquet-generator/src/main/java/org/apache/parquet/filter2/IncrementallyUpdatedFilterPredicateGenerator.java": [
                335,
                0
            ],
            "parquet-generator/src/main/java/org/apache/parquet/version/Generator.java": [
                28,
                0
            ],
            "parquet-generator/src/main/java/org/apache/parquet/version/VersionGenerator.java": [
                87,
                0
            ],
            "parquet-generator/src/main/resources/META-INF/LICENSE": null,
            "parquet-generator/src/main/resources/parquet-version.properties": null,
            "parquet-hadoop-bundle/README": null,
            "parquet-hadoop-bundle/pom.xml": null,
            "parquet-hadoop-bundle/src/main/resources/META-INF/LICENSE": null,
            "parquet-hadoop-bundle/src/main/resources/org/apache/parquet/bundle": null,
            "parquet-hadoop/README.md": null,
            "parquet-hadoop/REVIEWERS.md": null,
            "parquet-hadoop/pom.xml": null,
            "parquet-hadoop/src/main/java/org/apache/parquet/HadoopReadOptions.java": [
                143,
                0
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/ParquetReadOptions.java": [
                345,
                0
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/crypto/AADPrefixVerifier.java": [
                32,
                0
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/crypto/AesCipher.java": [
                164,
                0
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/crypto/AesCtrDecryptor.java": [
                170,
                0
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/crypto/AesCtrEncryptor.java": [
                104,
                0
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/crypto/AesGcmDecryptor.java": [
                151,
                0
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/crypto/AesGcmEncryptor.java": [
                91,
                0
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/crypto/AesMode.java": [
                35,
                0
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/crypto/ColumnDecryptionProperties.java": [
                104,
                0
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/crypto/ColumnEncryptionProperties.java": [
                195,
                0
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/crypto/DecryptionKeyRetriever.java": [
                39,
                0
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/crypto/DecryptionPropertiesFactory.java": [
                88,
                0
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/crypto/EncryptionPropertiesFactory.java": [
                93,
                0
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/crypto/FileDecryptionProperties.java": [
                254,
                0
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/crypto/FileEncryptionProperties.java": [
                278,
                0
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/crypto/InternalColumnDecryptionSetup.java": [
                74,
                0
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/crypto/InternalColumnEncryptionSetup.java": [
                82,
                0
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/crypto/InternalFileDecryptor.java": [
                312,
                0
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/crypto/InternalFileEncryptor.java": [
                200,
                0
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/crypto/KeyAccessDeniedException.java": [
                39,
                0
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/crypto/ModuleCipherFactory.java": [
                73,
                0
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/crypto/ParquetCipher.java": [
                42,
                0
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/crypto/ParquetCryptoRuntimeException.java": [
                42,
                0
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/crypto/TagVerificationException.java": [
                39,
                0
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/crypto/keytools/FileKeyMaterialStore.java": [
                72,
                0
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/crypto/keytools/FileKeyUnwrapper.java": [
                178,
                0
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/crypto/keytools/FileKeyWrapper.java": [
                177,
                0
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/crypto/keytools/HadoopFSKeyMaterialStore.java": [
                136,
                0
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/crypto/keytools/KeyMaterial.java": [
                210,
                0
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/crypto/keytools/KeyMetadata.java": [
                130,
                0
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/crypto/keytools/KeyToolkit.java": [
                394,
                0
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/crypto/keytools/KmsClient.java": [
                72,
                0
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/crypto/keytools/LocalWrapKmsClient.java": [
                181,
                0
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/crypto/keytools/PropertiesDrivenCryptoFactory.java": [
                258,
                0
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/crypto/keytools/TwoLevelCacheWithExpiration.java": [
                105,
                0
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/filter2/bloomfilterlevel/BloomFilterImpl.java": [
                187,
                0
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/filter2/compat/RowGroupFilter.java": [
                131,
                0
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/filter2/dictionarylevel/DictionaryFilter.java": [
                570,
                0
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/filter2/statisticslevel/StatisticsFilter.java": [
                485,
                0
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/format/converter/ParquetMetadataConverter.java": [
                2080,
                0
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/BadConfigurationException.java": [
                44,
                0
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/BloomFilterReader.java": [
                70,
                0
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/CodecFactory.java": [
                289,
                0
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ColumnChunkPageReadStore.java": [
                364,
                0
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ColumnChunkPageWriteStore.java": [
                462,
                0
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ColumnConfigParser.java": [
                72,
                0
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ColumnIndexFilterUtils.java": [
                162,
                0
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ColumnIndexStoreImpl.java": [
                155,
                0
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ColumnIndexValidator.java": [
                613,
                0
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/DictionaryPageReader.java": [
                115,
                0
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/DirectCodecFactory.java": [
                528,
                0
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/DirectZstd.java": [
                144,
                0
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/Footer.java": [
                53,
                0
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/InternalParquetRecordReader.java": [
                321,
                0
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/InternalParquetRecordWriter.java": [
                209,
                0
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/LruCache.java": [
                195,
                0
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/MemoryManager.java": [
                199,
                0
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/Offsets.java": [
                94,
                0
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ParquetEmptyBlockException.java": [
                41,
                0
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ParquetFileReader.java": [
                1869,
                0
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ParquetFileWriter.java": [
                1731,
                0
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ParquetInputFormat.java": [
                837,
                0
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ParquetInputSplit.java": [
                295,
                0
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ParquetMemoryManagerRuntimeException.java": [
                38,
                0
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ParquetOutputCommitter.java": [
                112,
                0
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ParquetOutputFormat.java": [
                570,
                0
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ParquetReader.java": [
                379,
                0
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ParquetRecordReader.java": [
                233,
                0
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ParquetRecordWriter.java": [
                184,
                0
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ParquetWriter.java": [
                744,
                0
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/PrintFooter.java": [
                265,
                0
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/UnmaterializableRecordCounter.java": [
                103,
                0
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/api/DelegatingReadSupport.java": [
                60,
                0
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/api/DelegatingWriteSupport.java": [
                69,
                0
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/api/InitContext.java": [
                99,
                0
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/api/ReadSupport.java": [
                145,
                0
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/api/WriteSupport.java": [
                140,
                0
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/api/package-info.java": [
                27,
                0
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/codec/CleanUtil.java": [
                111,
                0
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/codec/CodecConfig.java": [
                167,
                0
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/codec/Lz4RawCodec.java": [
                112,
                0
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/codec/Lz4RawCompressor.java": [
                44,
                0
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/codec/Lz4RawDecompressor.java": [
                46,
                0
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/codec/NonBlockedCompressor.java": [
                192,
                0
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/codec/NonBlockedCompressorStream.java": [
                50,
                0
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/codec/NonBlockedDecompressor.java": [
                180,
                0
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/codec/NonBlockedDecompressorStream.java": [
                57,
                0
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/codec/SnappyCodec.java": [
                105,
                0
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/codec/SnappyCompressor.java": [
                38,
                0
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/codec/SnappyDecompressor.java": [
                38,
                0
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/codec/SnappyUtil.java": [
                33,
                0
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/codec/ZstandardCodec.java": [
                130,
                0
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/codec/ZstdCompressorStream.java": [
                70,
                0
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/codec/ZstdDecompressorStream.java": [
                62,
                0
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/example/ExampleInputFormat.java": [
                35,
                0
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/example/ExampleOutputFormat.java": [
                58,
                0
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/example/ExampleParquetWriter.java": [
                118,
                0
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/example/GroupReadSupport.java": [
                49,
                0
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/example/GroupWriteSupport.java": [
                88,
                0
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/mapred/Container.java": [
                37,
                0
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/mapred/DeprecatedParquetInputFormat.java": [
                209,
                0
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/mapred/DeprecatedParquetOutputFormat.java": [
                119,
                0
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/mapred/MapredParquetOutputCommitter.java": [
                42,
                0
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/metadata/BlockMetaData.java": [
                153,
                0
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/metadata/ColumnChunkMetaData.java": [
                683,
                0
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/metadata/ColumnChunkProperties.java": [
                118,
                0
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/metadata/ConcatenatingKeyValueMetadataMergeStrategy.java": [
                61,
                0
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/metadata/EncodingList.java": [
                81,
                0
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/metadata/FileMetaData.java": [
                108,
                0
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/metadata/GlobalMetaData.java": [
                110,
                0
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/metadata/KeyValueMetadataMergeStrategy.java": [
                42,
                0
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/metadata/ParquetMetadata.java": [
                134,
                0
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/metadata/StrictKeyValueMetadataMergeStrategy.java": [
                42,
                0
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/package-info.java": [
                33,
                0
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/rewrite/MaskMode.java": [
                38,
                0
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/rewrite/ParquetRewriter.java": [
                819,
                0
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/rewrite/RewriteOptions.java": [
                262,
                0
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/util/ColumnEncryptor.java": [
                90,
                0
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/util/ColumnMasker.java": [
                98,
                0
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/util/ColumnPruner.java": [
                42,
                0
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/util/CompressionConverter.java": [
                81,
                0
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/util/ConfigurationUtil.java": [
                44,
                0
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/util/ContextUtil.java": [
                315,
                0
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/util/H1SeekableInputStream.java": [
                59,
                0
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/util/H2SeekableInputStream.java": [
                99,
                0
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/util/HadoopCodecs.java": [
                39,
                0
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/util/HadoopInputFile.java": [
                76,
                0
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/util/HadoopOutputFile.java": [
                105,
                0
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/util/HadoopPositionOutputStream.java": [
                66,
                0
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/util/HadoopStreams.java": [
                148,
                0
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/util/HiddenFileFilter.java": [
                39,
                0
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/util/SerializationUtil.java": [
                93,
                0
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/util/counters/BenchmarkCounter.java": [
                112,
                0
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/util/counters/CounterLoader.java": [
                27,
                0
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/util/counters/ICounter.java": [
                28,
                0
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/util/counters/mapred/MapRedCounterAdapter.java": [
                43,
                0
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/util/counters/mapred/MapRedCounterLoader.java": [
                51,
                0
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/util/counters/mapreduce/MapReduceCounterAdapter.java": [
                44,
                0
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/util/counters/mapreduce/MapReduceCounterLoader.java": [
                47,
                0
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/internal/hadoop/metadata/IndexReference.java": [
                41,
                0
            ],
            "parquet-hadoop/src/main/resources/META-INF/LICENSE": null,
            "parquet-hadoop/src/test/java/org/apache/parquet/DirectWriterTest.java": [
                102,
                0
            ],
            "parquet-hadoop/src/test/java/org/apache/parquet/crypto/DecryptionKeyRetrieverMock.java": [
                41,
                0
            ],
            "parquet-hadoop/src/test/java/org/apache/parquet/crypto/DecryptionPropertiesFactoryTest.java": [
                43,
                0
            ],
            "parquet-hadoop/src/test/java/org/apache/parquet/crypto/EncryptionPropertiesFactoryTest.java": [
                45,
                0
            ],
            "parquet-hadoop/src/test/java/org/apache/parquet/crypto/SampleDecryptionPropertiesFactory.java": [
                57,
                0
            ],
            "parquet-hadoop/src/test/java/org/apache/parquet/crypto/SampleEncryptionPropertiesFactory.java": [
                58,
                0
            ],
            "parquet-hadoop/src/test/java/org/apache/parquet/crypto/SingleRow.java": [
                139,
                0
            ],
            "parquet-hadoop/src/test/java/org/apache/parquet/crypto/TestPropertiesDrivenEncryption.java": [
                705,
                0
            ],
            "parquet-hadoop/src/test/java/org/apache/parquet/crypto/keytools/mocks/InMemoryKMS.java": [
                116,
                0
            ],
            "parquet-hadoop/src/test/java/org/apache/parquet/crypto/keytools/mocks/LocalWrapInMemoryKMS.java": [
                79,
                0
            ],
            "parquet-hadoop/src/test/java/org/apache/parquet/crypto/keytools/samples/VaultClient.java": [
                184,
                0
            ],
            "parquet-hadoop/src/test/java/org/apache/parquet/crypto/propertiesfactory/SchemaControlEncryptionTest.java": [
                250,
                0
            ],
            "parquet-hadoop/src/test/java/org/apache/parquet/crypto/propertiesfactory/SchemaCryptoPropertiesFactory.java": [
                137,
                0
            ],
            "parquet-hadoop/src/test/java/org/apache/parquet/encodings/FileEncodingsIT.java": [
                564,
                0
            ],
            "parquet-hadoop/src/test/java/org/apache/parquet/filter2/TestFiltersWithMissingColumns.java": [
                275,
                0
            ],
            "parquet-hadoop/src/test/java/org/apache/parquet/filter2/compat/TestRowGroupFilter.java": [
                128,
                0
            ],
            "parquet-hadoop/src/test/java/org/apache/parquet/filter2/dictionarylevel/DictionaryFilterTest.java": [
                839,
                0
            ],
            "parquet-hadoop/src/test/java/org/apache/parquet/filter2/recordlevel/PhoneBookWriter.java": [
                373,
                0
            ],
            "parquet-hadoop/src/test/java/org/apache/parquet/filter2/recordlevel/TestRecordLevelFilters.java": [
                310,
                0
            ],
            "parquet-hadoop/src/test/java/org/apache/parquet/filter2/statisticslevel/TestStatisticsFilter.java": [
                561,
                0
            ],
            "parquet-hadoop/src/test/java/org/apache/parquet/format/converter/TestParquetMetadataConverter.java": [
                1389,
                0
            ],
            "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/DeprecatedInputFormatTest.java": [
                346,
                0
            ],
            "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/DeprecatedOutputFormatTest.java": [
                108,
                0
            ],
            "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/ITTestEncryptionOptions.java": [
                50,
                0
            ],
            "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/TestAdaptiveBlockSplitBloomFiltering.java": [
                78,
                0
            ],
            "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/TestBloomFiltering.java": [
                421,
                0
            ],
            "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/TestColumnChunkPageWriteStore.java": [
                288,
                0
            ],
            "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/TestColumnIndexFiltering.java": [
                617,
                0
            ],
            "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/TestDataPageV1Checksums.java": [
                563,
                0
            ],
            "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/TestDirectCodecFactory.java": [
                178,
                0
            ],
            "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/TestEncryptionOptions.java": [
                752,
                0
            ],
            "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/TestInputFormat.java": [
                555,
                0
            ],
            "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/TestInputFormatColumnProjection.java": [
                180,
                0
            ],
            "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/TestInputOutputFormatWithPadding.java": [
                214,
                0
            ],
            "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/TestLargeColumnChunk.java": [
                145,
                0
            ],
            "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/TestLruCache.java": [
                162,
                0
            ],
            "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/TestMemoryManager.java": [
                189,
                0
            ],
            "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/TestMergeMetadataFiles.java": [
                221,
                0
            ],
            "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/TestMultipleWriteRead.java": [
                250,
                0
            ],
            "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/TestParquetFileWriter.java": [
                1218,
                0
            ],
            "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/TestParquetOutputFormatJobSummaryLevel.java": [
                69,
                0
            ],
            "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/TestParquetReader.java": [
                198,
                0
            ],
            "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/TestParquetReaderEmptyBlock.java": [
                170,
                0
            ],
            "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/TestParquetReaderRandomAccess.java": [
                387,
                0
            ],
            "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/TestParquetWriter.java": [
                431,
                0
            ],
            "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/TestParquetWriterAppendBlocks.java": [
                361,
                0
            ],
            "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/TestParquetWriterNewPage.java": [
                136,
                0
            ],
            "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/TestParquetWriterTruncation.java": [
                125,
                0
            ],
            "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/TestReadWriteEncodingStats.java": [
                122,
                0
            ],
            "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/TestSnappyCodec.java": [
                140,
                0
            ],
            "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/TestStoreBloomFilter.java": [
                132,
                0
            ],
            "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/TestUtils.java": [
                85,
                0
            ],
            "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/TestZstandardCodec.java": [
                173,
                0
            ],
            "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/codec/CodecConfigTest.java": [
                77,
                0
            ],
            "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/codec/TestCompressionCodec.java": [
                177,
                0
            ],
            "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/codec/TestInteropReadLz4RawCodec.java": [
                129,
                0
            ],
            "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/example/GroupReadSupportTest.java": [
                65,
                0
            ],
            "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/example/TestInputOutputFormat.java": [
                364,
                0
            ],
            "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/metadata/TestColumnChunkMetaData.java": [
                83,
                0
            ],
            "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/rewrite/ParquetRewriterTest.java": [
                772,
                0
            ],
            "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/util/ColumnEncryptorTest.java": [
                315,
                0
            ],
            "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/util/ColumnMaskerTest.java": [
                223,
                0
            ],
            "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/util/ColumnPrunerTest.java": [
                246,
                0
            ],
            "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/util/CompressionConverterTest.java": [
                312,
                0
            ],
            "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/util/EncDecProperties.java": [
                94,
                0
            ],
            "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/util/EncryptionTestFile.java": [
                38,
                0
            ],
            "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/util/MockHadoopInputStream.java": [
                87,
                0
            ],
            "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/util/TestFileBuilder.java": [
                198,
                0
            ],
            "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/util/TestHadoop2ByteBufferReads.java": [
                446,
                0
            ],
            "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/util/TestSerializationUtil.java": [
                71,
                0
            ],
            "parquet-hadoop/src/test/java/org/apache/parquet/statistics/DataGenerationContext.java": [
                85,
                0
            ],
            "parquet-hadoop/src/test/java/org/apache/parquet/statistics/RandomValues.java": [
                383,
                0
            ],
            "parquet-hadoop/src/test/java/org/apache/parquet/statistics/TestColumnIndexes.java": [
                304,
                0
            ],
            "parquet-hadoop/src/test/java/org/apache/parquet/statistics/TestStatistics.java": [
                459,
                0
            ],
            "parquet-hadoop/src/test/resources/log4j.properties": null,
            "parquet-hadoop/src/test/resources/test-append_1.parquet": null,
            "parquet-hadoop/src/test/resources/test-append_2.parquet": null,
            "parquet-hadoop/src/test/resources/test-empty-row-group_1.parquet": null,
            "parquet-hadoop/src/test/resources/test-empty-row-group_2.parquet": null,
            "parquet-hadoop/src/test/resources/test-empty-row-group_3.parquet": null,
            "parquet-hadoop/src/test/resources/test-file-with-no-column-indexes-1.parquet": null,
            "parquet-jackson/README.md": null,
            "parquet-jackson/pom.xml": null,
            "parquet-jackson/src/main/resources/META-INF/LICENSE": null,
            "parquet-pig-bundle/pom.xml": null,
            "parquet-pig-bundle/src/main/resources/META-INF/LICENSE": null,
            "parquet-pig-bundle/src/main/resources/org/apache/parquet/bundle": null,
            "parquet-pig/REVIEWERS.md": null,
            "parquet-pig/pom.xml": null,
            "parquet-pig/src/main/java/org/apache/parquet/pig/ParquetLoader.java": [
                575,
                0
            ],
            "parquet-pig/src/main/java/org/apache/parquet/pig/ParquetStorer.java": [
                152,
                0
            ],
            "parquet-pig/src/main/java/org/apache/parquet/pig/PigMetaData.java": [
                91,
                0
            ],
            "parquet-pig/src/main/java/org/apache/parquet/pig/PigSchemaConverter.java": [
                551,
                0
            ],
            "parquet-pig/src/main/java/org/apache/parquet/pig/SchemaConversionException.java": [
                44,
                0
            ],
            "parquet-pig/src/main/java/org/apache/parquet/pig/TupleConversionException.java": [
                42,
                0
            ],
            "parquet-pig/src/main/java/org/apache/parquet/pig/TupleReadSupport.java": [
                191,
                0
            ],
            "parquet-pig/src/main/java/org/apache/parquet/pig/TupleWriteSupport.java": [
                209,
                0
            ],
            "parquet-pig/src/main/java/org/apache/parquet/pig/convert/DecimalUtils.java": [
                65,
                0
            ],
            "parquet-pig/src/main/java/org/apache/parquet/pig/convert/MapConverter.java": [
                190,
                0
            ],
            "parquet-pig/src/main/java/org/apache/parquet/pig/convert/ParentValueContainer.java": [
                32,
                0
            ],
            "parquet-pig/src/main/java/org/apache/parquet/pig/convert/TupleConverter.java": [
                592,
                0
            ],
            "parquet-pig/src/main/java/org/apache/parquet/pig/convert/TupleRecordMaterializer.java": [
                50,
                0
            ],
            "parquet-pig/src/main/java/org/apache/parquet/pig/summary/BagSummaryData.java": [
                72,
                0
            ],
            "parquet-pig/src/main/java/org/apache/parquet/pig/summary/EnumStat.java": [
                115,
                0
            ],
            "parquet-pig/src/main/java/org/apache/parquet/pig/summary/FieldSummaryData.java": [
                178,
                0
            ],
            "parquet-pig/src/main/java/org/apache/parquet/pig/summary/MapSummaryData.java": [
                85,
                0
            ],
            "parquet-pig/src/main/java/org/apache/parquet/pig/summary/NumberSummaryData.java": [
                47,
                0
            ],
            "parquet-pig/src/main/java/org/apache/parquet/pig/summary/StringSummaryData.java": [
                82,
                0
            ],
            "parquet-pig/src/main/java/org/apache/parquet/pig/summary/Summary.java": [
                224,
                0
            ],
            "parquet-pig/src/main/java/org/apache/parquet/pig/summary/SummaryData.java": [
                135,
                0
            ],
            "parquet-pig/src/main/java/org/apache/parquet/pig/summary/TupleSummaryData.java": [
                98,
                0
            ],
            "parquet-pig/src/main/java/org/apache/parquet/pig/summary/ValueStat.java": [
                64,
                0
            ],
            "parquet-pig/src/test/java/org/apache/parquet/pig/PerfTest.java": [
                104,
                0
            ],
            "parquet-pig/src/test/java/org/apache/parquet/pig/PerfTest2.java": [
                185,
                0
            ],
            "parquet-pig/src/test/java/org/apache/parquet/pig/PerfTestReadAllCols.java": [
                47,
                0
            ],
            "parquet-pig/src/test/java/org/apache/parquet/pig/TestDecimalUtils.java": [
                79,
                0
            ],
            "parquet-pig/src/test/java/org/apache/parquet/pig/TestParquetLoader.java": [
                367,
                0
            ],
            "parquet-pig/src/test/java/org/apache/parquet/pig/TestParquetStorer.java": [
                264,
                0
            ],
            "parquet-pig/src/test/java/org/apache/parquet/pig/TestPigSchemaConverter.java": [
                291,
                0
            ],
            "parquet-pig/src/test/java/org/apache/parquet/pig/TestTupleRecordConsumer.java": [
                210,
                0
            ],
            "parquet-pig/src/test/java/org/apache/parquet/pig/TupleConsumerPerfTest.java": [
                206,
                0
            ],
            "parquet-pig/src/test/java/org/apache/parquet/pig/summary/TestSummary.java": [
                158,
                0
            ],
            "parquet-pig/src/test/resources/log4j.properties": null,
            "parquet-plugins/parquet-encoding-vector/pom.xml": null,
            "parquet-plugins/parquet-encoding-vector/src/main/java/org/apache/parquet/column/values/bitpacking/ByteBitPacking512VectorLE.java": [
                3010,
                0
            ],
            "parquet-plugins/parquet-encoding-vector/src/main/java/org/apache/parquet/column/values/bitpacking/ParquetReadRouter.java": [
                133,
                0
            ],
            "parquet-plugins/parquet-encoding-vector/src/main/java/org/apache/parquet/column/values/bitpacking/VectorSupport.java": [
                27,
                0
            ],
            "parquet-plugins/parquet-encoding-vector/src/test/java/org/apache/parquet/column/values/bitpacking/TestByteBitPacking512VectorLE.java": [
                169,
                0
            ],
            "parquet-plugins/parquet-encoding-vector/src/test/java/org/apache/parquet/column/values/bitpacking/TestParquetReadRouter.java": [
                59,
                0
            ],
            "parquet-plugins/parquet-plugins-benchmarks/pom.xml": null,
            "parquet-plugins/parquet-plugins-benchmarks/src/main/java/org/apache/parquet/plugins/benchmarks/ByteBitPackingVectorBenchmarks.java": [
                92,
                0
            ],
            "parquet-plugins/parquet-plugins-benchmarks/src/main/resources/log4j.properties": null,
            "parquet-protobuf/README.md": null,
            "parquet-protobuf/REVIEWERS.md": null,
            "parquet-protobuf/pom.xml": null,
            "parquet-protobuf/src/main/java/org/apache/parquet/proto/ProtoConstants.java": [
                46,
                0
            ],
            "parquet-protobuf/src/main/java/org/apache/parquet/proto/ProtoMessageConverter.java": [
                599,
                0
            ],
            "parquet-protobuf/src/main/java/org/apache/parquet/proto/ProtoParquetInputFormat.java": [
                38,
                0
            ],
            "parquet-protobuf/src/main/java/org/apache/parquet/proto/ProtoParquetOutputFormat.java": [
                52,
                0
            ],
            "parquet-protobuf/src/main/java/org/apache/parquet/proto/ProtoParquetReader.java": [
                101,
                0
            ],
            "parquet-protobuf/src/main/java/org/apache/parquet/proto/ProtoParquetWriter.java": [
                127,
                0
            ],
            "parquet-protobuf/src/main/java/org/apache/parquet/proto/ProtoReadSupport.java": [
                97,
                0
            ],
            "parquet-protobuf/src/main/java/org/apache/parquet/proto/ProtoRecordConverter.java": [
                100,
                0
            ],
            "parquet-protobuf/src/main/java/org/apache/parquet/proto/ProtoRecordMaterializer.java": [
                47,
                0
            ],
            "parquet-protobuf/src/main/java/org/apache/parquet/proto/ProtoSchemaConverter.java": [
                297,
                0
            ],
            "parquet-protobuf/src/main/java/org/apache/parquet/proto/ProtoWriteSupport.java": [
                586,
                0
            ],
            "parquet-protobuf/src/main/resources/META-INF/NOTICE": null,
            "parquet-protobuf/src/test/java/org/apache/parquet/proto/ProtoInputOutputFormatTest.java": [
                618,
                0
            ],
            "parquet-protobuf/src/test/java/org/apache/parquet/proto/ProtoRecordConverterTest.java": [
                363,
                0
            ],
            "parquet-protobuf/src/test/java/org/apache/parquet/proto/ProtoSchemaConverterTest.java": [
                539,
                0
            ],
            "parquet-protobuf/src/test/java/org/apache/parquet/proto/ProtoSchemaEvolutionTest.java": [
                133,
                0
            ],
            "parquet-protobuf/src/test/java/org/apache/parquet/proto/ProtoWriteSupportTest.java": [
                1204,
                0
            ],
            "parquet-protobuf/src/test/java/org/apache/parquet/proto/TestUtils.java": [
                232,
                0
            ],
            "parquet-protobuf/src/test/java/org/apache/parquet/proto/utils/ReadUsingMR.java": [
                94,
                0
            ],
            "parquet-protobuf/src/test/java/org/apache/parquet/proto/utils/WriteUsingMR.java": [
                121,
                0
            ],
            "parquet-protobuf/src/test/resources/BinaryTree.par": null,
            "parquet-protobuf/src/test/resources/Struct.par": null,
            "parquet-protobuf/src/test/resources/TestProto3.proto": null,
            "parquet-protobuf/src/test/resources/TestProto3SchemaV1.proto": null,
            "parquet-protobuf/src/test/resources/TestProto3SchemaV2.proto": null,
            "parquet-protobuf/src/test/resources/TestProto3SchemaV3.proto": null,
            "parquet-protobuf/src/test/resources/TestProtobuf.proto": null,
            "parquet-protobuf/src/test/resources/Trees.proto": null,
            "parquet-protobuf/src/test/resources/Value.par": null,
            "parquet-protobuf/src/test/resources/WideTree.par": null,
            "parquet-protobuf/src/test/resources/log4j.properties": null,
            "parquet-scala/pom.xml": null,
            "parquet-scala/src/main/scala/org/apache/parquet/filter2/dsl/Dsl.scala": null,
            "parquet-scala/src/test/scala/org/apache/parquet/filter2/dsl/DslTest.scala": null,
            "parquet-thrift/README.md": null,
            "parquet-thrift/REVIEWERS.md": null,
            "parquet-thrift/pom.xml": null,
            "parquet-thrift/src/main/java/org/apache/parquet/hadoop/thrift/AbstractThriftWriteSupport.java": [
                129,
                0
            ],
            "parquet-thrift/src/main/java/org/apache/parquet/hadoop/thrift/ParquetThriftBytesOutputFormat.java": [
                96,
                0
            ],
            "parquet-thrift/src/main/java/org/apache/parquet/hadoop/thrift/ParquetThriftInputFormat.java": [
                66,
                0
            ],
            "parquet-thrift/src/main/java/org/apache/parquet/hadoop/thrift/ParquetThriftOutputFormat.java": [
                43,
                0
            ],
            "parquet-thrift/src/main/java/org/apache/parquet/hadoop/thrift/TBaseWriteSupport.java": [
                70,
                0
            ],
            "parquet-thrift/src/main/java/org/apache/parquet/hadoop/thrift/ThriftBytesWriteSupport.java": [
                196,
                0
            ],
            "parquet-thrift/src/main/java/org/apache/parquet/hadoop/thrift/ThriftReadSupport.java": [
                289,
                0
            ],
            "parquet-thrift/src/main/java/org/apache/parquet/hadoop/thrift/ThriftToParquetFileWriter.java": [
                125,
                0
            ],
            "parquet-thrift/src/main/java/org/apache/parquet/hadoop/thrift/ThriftWriteSupport.java": [
                80,
                0
            ],
            "parquet-thrift/src/main/java/org/apache/parquet/thrift/BufferedProtocolReadToWrite.java": [
                738,
                0
            ],
            "parquet-thrift/src/main/java/org/apache/parquet/thrift/ConvertedField.java": [
                169,
                0
            ],
            "parquet-thrift/src/main/java/org/apache/parquet/thrift/DecodingSchemaMismatchException.java": [
                30,
                0
            ],
            "parquet-thrift/src/main/java/org/apache/parquet/thrift/FieldIgnoredHandler.java": [
                45,
                0
            ],
            "parquet-thrift/src/main/java/org/apache/parquet/thrift/KeepOnlyFirstPrimitiveFilter.java": [
                44,
                0
            ],
            "parquet-thrift/src/main/java/org/apache/parquet/thrift/ParquetProtocol.java": [
                282,
                0
            ],
            "parquet-thrift/src/main/java/org/apache/parquet/thrift/ParquetReadProtocol.java": [
                164,
                0
            ],
            "parquet-thrift/src/main/java/org/apache/parquet/thrift/ParquetWriteProtocol.java": [
                778,
                0
            ],
            "parquet-thrift/src/main/java/org/apache/parquet/thrift/ProtocolPipe.java": [
                29,
                0
            ],
            "parquet-thrift/src/main/java/org/apache/parquet/thrift/ProtocolReadToWrite.java": [
                142,
                0
            ],
            "parquet-thrift/src/main/java/org/apache/parquet/thrift/SkippableException.java": [
                47,
                0
            ],
            "parquet-thrift/src/main/java/org/apache/parquet/thrift/TBaseRecordConverter.java": [
                61,
                0
            ],
            "parquet-thrift/src/main/java/org/apache/parquet/thrift/ThriftMetaData.java": [
                147,
                0
            ],
            "parquet-thrift/src/main/java/org/apache/parquet/thrift/ThriftParquetReader.java": [
                139,
                0
            ],
            "parquet-thrift/src/main/java/org/apache/parquet/thrift/ThriftParquetWriter.java": [
                52,
                0
            ],
            "parquet-thrift/src/main/java/org/apache/parquet/thrift/ThriftReader.java": [
                28,
                0
            ],
            "parquet-thrift/src/main/java/org/apache/parquet/thrift/ThriftRecordConverter.java": [
                954,
                0
            ],
            "parquet-thrift/src/main/java/org/apache/parquet/thrift/ThriftSchemaConvertVisitor.java": [
                409,
                0
            ],
            "parquet-thrift/src/main/java/org/apache/parquet/thrift/ThriftSchemaConverter.java": [
                226,
                0
            ],
            "parquet-thrift/src/main/java/org/apache/parquet/thrift/pig/ParquetThriftStorer.java": [
                90,
                0
            ],
            "parquet-thrift/src/main/java/org/apache/parquet/thrift/pig/TupleToThriftWriteSupport.java": [
                79,
                0
            ],
            "parquet-thrift/src/main/java/org/apache/parquet/thrift/projection/FieldProjectionFilter.java": [
                62,
                0
            ],
            "parquet-thrift/src/main/java/org/apache/parquet/thrift/projection/FieldsPath.java": [
                87,
                0
            ],
            "parquet-thrift/src/main/java/org/apache/parquet/thrift/projection/StrictFieldProjectionFilter.java": [
                187,
                0
            ],
            "parquet-thrift/src/main/java/org/apache/parquet/thrift/projection/ThriftProjectionException.java": [
                45,
                0
            ],
            "parquet-thrift/src/main/java/org/apache/parquet/thrift/projection/amend/DefaultEventsVisitor.java": [
                228,
                0
            ],
            "parquet-thrift/src/main/java/org/apache/parquet/thrift/projection/amend/DefaultProtocolEventsGenerator.java": [
                68,
                0
            ],
            "parquet-thrift/src/main/java/org/apache/parquet/thrift/projection/amend/ProtocolEventsAmender.java": [
                171,
                0
            ],
            "parquet-thrift/src/main/java/org/apache/parquet/thrift/projection/amend/ReadFieldBeginProtocol.java": [
                44,
                0
            ],
            "parquet-thrift/src/main/java/org/apache/parquet/thrift/projection/deprecated/DeprecatedFieldProjectionFilter.java": [
                106,
                0
            ],
            "parquet-thrift/src/main/java/org/apache/parquet/thrift/projection/deprecated/PathGlobPattern.java": [
                173,
                0
            ],
            "parquet-thrift/src/main/java/org/apache/parquet/thrift/struct/CompatibilityChecker.java": [
                265,
                0
            ],
            "parquet-thrift/src/main/java/org/apache/parquet/thrift/struct/CompatibilityRunner.java": [
                104,
                0
            ],
            "parquet-thrift/src/main/java/org/apache/parquet/thrift/struct/JSON.java": [
                50,
                0
            ],
            "parquet-thrift/src/main/java/org/apache/parquet/thrift/struct/ThriftField.java": [
                121,
                0
            ],
            "parquet-thrift/src/main/java/org/apache/parquet/thrift/struct/ThriftType.java": [
                698,
                0
            ],
            "parquet-thrift/src/main/java/org/apache/parquet/thrift/struct/ThriftTypeID.java": [
                108,
                0
            ],
            "parquet-thrift/src/test/java/org/apache/parquet/hadoop/thrift/TestArrayCompatibility.java": [
                779,
                0
            ],
            "parquet-thrift/src/test/java/org/apache/parquet/hadoop/thrift/TestBinary.java": [
                86,
                0
            ],
            "parquet-thrift/src/test/java/org/apache/parquet/hadoop/thrift/TestCorruptThriftRecords.java": [
                213,
                0
            ],
            "parquet-thrift/src/test/java/org/apache/parquet/hadoop/thrift/TestInputOutputFormat.java": [
                258,
                0
            ],
            "parquet-thrift/src/test/java/org/apache/parquet/hadoop/thrift/TestParquetToThriftReadWriteAndProjection.java": [
                385,
                0
            ],
            "parquet-thrift/src/test/java/org/apache/parquet/hadoop/thrift/TestThriftToParquetFileWriter.java": [
                360,
                0
            ],
            "parquet-thrift/src/test/java/org/apache/parquet/thrift/TestParquetReadProtocol.java": [
                173,
                0
            ],
            "parquet-thrift/src/test/java/org/apache/parquet/thrift/TestParquetWriteProtocol.java": [
                719,
                0
            ],
            "parquet-thrift/src/test/java/org/apache/parquet/thrift/TestProtocolReadToWrite.java": [
                384,
                0
            ],
            "parquet-thrift/src/test/java/org/apache/parquet/thrift/TestThriftMetaData.java": [
                56,
                0
            ],
            "parquet-thrift/src/test/java/org/apache/parquet/thrift/TestThriftParquetReaderWriter.java": [
                83,
                0
            ],
            "parquet-thrift/src/test/java/org/apache/parquet/thrift/TestThriftRecordConverter.java": [
                101,
                0
            ],
            "parquet-thrift/src/test/java/org/apache/parquet/thrift/TestThriftSchemaConvertVisitor.java": [
                178,
                0
            ],
            "parquet-thrift/src/test/java/org/apache/parquet/thrift/TestThriftSchemaConverter.java": [
                353,
                0
            ],
            "parquet-thrift/src/test/java/org/apache/parquet/thrift/TestThriftSchemaConverterProjectUnion.java": [
                480,
                0
            ],
            "parquet-thrift/src/test/java/org/apache/parquet/thrift/TestThriftToPigCompatibility.java": [
                171,
                0
            ],
            "parquet-thrift/src/test/java/org/apache/parquet/thrift/pig/TestParquetThriftStorer.java": [
                82,
                0
            ],
            "parquet-thrift/src/test/java/org/apache/parquet/thrift/projection/TestFieldsPath.java": [
                162,
                0
            ],
            "parquet-thrift/src/test/java/org/apache/parquet/thrift/projection/TestStrictFieldProjectionFilter.java": [
                119,
                0
            ],
            "parquet-thrift/src/test/java/org/apache/parquet/thrift/projection/deprecated/PathGlobPatternTest.java": [
                59,
                0
            ],
            "parquet-thrift/src/test/java/org/apache/parquet/thrift/struct/CompatibilityCheckerTest.java": [
                132,
                0
            ],
            "parquet-thrift/src/test/java/org/apache/parquet/thrift/struct/TestThriftType.java": [
                70,
                0
            ],
            "parquet-thrift/src/test/resources/org/apache/parquet/hadoop/thrift/AddressBook.json": null,
            "parquet-thrift/src/test/resources/org/apache/parquet/thrift/StructWithUnionV1NoStructOrUnionMeta.json": null,
            "parquet-thrift/src/test/thrift/array_compat.thrift": null,
            "parquet-thrift/src/test/thrift/binary.thrift": null,
            "parquet-thrift/src/test/thrift/compat.thrift": null,
            "parquet-thrift/src/test/thrift/test.thrift": null,
            "pom.xml": null,
            "src/license.txt": null,
            "src/main/java/parquet/proto/ProtoParquetInputFormat.java": [
                0,
                35
            ],
            "src/main/java/parquet/proto/ProtoParquetOutputFormat.java": [
                0,
                37
            ],
            "src/main/java/parquet/proto/ProtoParquetReader.java": [
                0,
                40
            ],
            "src/main/java/parquet/proto/ProtoParquetWriter.java": [
                0,
                78
            ],
            "src/main/java/parquet/proto/ProtoReadSupport.java": [
                0,
                70
            ],
            "src/main/java/parquet/proto/ProtoRecordMaterializer.java": [
                0,
                41
            ],
            "src/main/java/parquet/proto/ProtoSchemaConverter.java": [
                0,
                131
            ],
            "src/main/java/parquet/proto/ProtoWriteSupport.java": [
                0,
                185
            ],
            "src/main/java/parquet/proto/ProtobufferRecordConverter.java": [
                0,
                68
            ],
            "src/main/java/parquet/proto/converters/ParentValueContainer.java": [
                0,
                10
            ],
            "src/main/java/parquet/proto/converters/ProtoArrayConverter.java": [
                0,
                28
            ],
            "src/main/java/parquet/proto/converters/ProtoBinaryConverter.java": [
                0,
                18
            ],
            "src/main/java/parquet/proto/converters/ProtoBooleanConverter.java": [
                0,
                18
            ],
            "src/main/java/parquet/proto/converters/ProtoDoubleConverter.java": [
                0,
                17
            ],
            "src/main/java/parquet/proto/converters/ProtoEnumConverter.java": [
                0,
                48
            ],
            "src/main/java/parquet/proto/converters/ProtoFloatConverter.java": [
                0,
                17
            ],
            "src/main/java/parquet/proto/converters/ProtoIntConverter.java": [
                0,
                17
            ],
            "src/main/java/parquet/proto/converters/ProtoLongConverter.java": [
                0,
                17
            ],
            "src/main/java/parquet/proto/converters/ProtoMessageConverter.java": [
                0,
                170
            ],
            "src/main/java/parquet/proto/converters/ProtobufStringConverter.java": [
                0,
                20
            ],
            "src/main/java/parquet/proto/package-info.java": [
                0,
                89
            ],
            "src/main/java/parquet/proto/todo.txt": null,
            "src/test/java/parquet/proto/BugHuntingTest.java": [
                0,
                54
            ],
            "src/test/java/parquet/proto/ProtoTest.java": [
                0,
                154
            ],
            "src/test/java/parquet/proto/TestSandbox.java": [
                0,
                43
            ],
            "src/test/java/parquet/proto/TestUtils.java": [
                0,
                159
            ],
            "src/test/resources/TestProtobuf.proto": null
        }
    },
    "dfa27b41bf80000fccb881467c8e992491ffd89d": {
        "datetime": "2013-10-23T21:51:50+02:00",
        "summary": "Merge branch 'master' of https://github.com/lukasnalezenec/parquet-protobuf",
        "message": "Merge branch 'master' of https://github.com/lukasnalezenec/parquet-protobuf\n",
        "diff": {
            ".gitignore": null,
            "README.md": null
        }
    },
    "dd536a421b53f78550ed0c33a7927b813d391677": {
        "datetime": "2013-10-23T21:56:02+02:00",
        "summary": "Delete todo.txt",
        "message": "Delete todo.txt",
        "diff": {
            "src/main/java/parquet/proto/todo.txt": null
        }
    },
    "ab4cb69e09b109f82e92de8ed21925d75751eef0": {
        "datetime": "2013-10-23T16:43:29-07:00",
        "summary": "Make the ParquetLoader.inputFormatCache HashMap a WeakHashMap in order to free memory for long running processes that do not leverage caching",
        "message": "Make the ParquetLoader.inputFormatCache HashMap a WeakHashMap in order to free memory for long running processes that do not leverage caching\n",
        "diff": {
            "parquet-pig/src/main/java/parquet/pig/ParquetLoader.java": [
                2,
                2
            ]
        }
    },
    "5f29f4374ee0b4925b7fdc36945a9a104389e964": {
        "datetime": "2013-10-23T20:30:49-07:00",
        "summary": "use a new string in order to enforce weak reference on the key",
        "message": "use a new string in order to enforce weak reference on the key\n",
        "diff": {
            "parquet-pig/src/main/java/parquet/pig/ParquetLoader.java": [
                1,
                3
            ]
        }
    },
    "93780e026d08c7541ca7af703aebc9d26e52e68f": {
        "datetime": "2013-10-23T20:33:18-07:00",
        "summary": "use a new string in order to enforce weak reference on the key",
        "message": "use a new string in order to enforce weak reference on the key\n",
        "diff": {
            "parquet-pig/src/main/java/parquet/pig/ParquetLoader.java": [
                2,
                2
            ]
        }
    },
    "cf1f44268d802922b0a1b26d6cdcf5edf8e45f0e": {
        "datetime": "2013-10-23T20:34:52-07:00",
        "summary": "use a new string in order to enforce weak reference on the key",
        "message": "use a new string in order to enforce weak reference on the key\n",
        "diff": {
            "parquet-pig/src/main/java/parquet/pig/ParquetLoader.java": [
                2,
                2
            ]
        }
    },
    "21efc9beb1e6dd0c9177b88f15934884478add9e": {
        "datetime": "2013-10-24T12:14:46+02:00",
        "summary": "use cascading 2.2.0",
        "message": "use cascading 2.2.0\n",
        "diff": {
            "parquet-cascading/pom.xml": null
        }
    },
    "8edc1029818ab9b5e3b712eae3546e54eda6a1a6": {
        "datetime": "2013-10-24T08:36:19-07:00",
        "summary": "throw ParquetEncodingException",
        "message": "throw ParquetEncodingException\n",
        "diff": {
            "parquet-thrift/src/main/java/parquet/thrift/ParquetWriteProtocol.java": [
                2,
                2
            ]
        }
    },
    "a148e1608fd18467101496fdcf05e353492dde0b": {
        "datetime": "2013-10-24T09:00:03-07:00",
        "summary": "Merge pull request #205 from fs111/master",
        "message": "Merge pull request #205 from fs111/master\n\nuse cascading 2.2.0",
        "diff": {
            "parquet-cascading/pom.xml": null
        }
    },
    "be83477f361d90d5b78d10affe13f173b85192cc": {
        "datetime": "2013-10-24T09:04:57-07:00",
        "summary": "Merge pull request #203 from Parquet/check_null_for_enum_write_protocol",
        "message": "Merge pull request #203 from Parquet/check_null_for_enum_write_protocol\n\nadd null check for EnumWriteProtocol",
        "diff": {
            "parquet-thrift/src/main/java/parquet/thrift/ParquetWriteProtocol.java": [
                2,
                7
            ]
        }
    },
    "3b63d13250862534a1ae6532750e3a343987ce36": {
        "datetime": "2013-10-24T09:42:42-07:00",
        "summary": "fix comment",
        "message": "fix comment\n",
        "diff": {
            "parquet-pig/src/main/java/parquet/pig/ParquetLoader.java": [
                2,
                2
            ]
        }
    },
    "c5ce1fa1ee49419f0e809596a272ed369d93cfc7": {
        "datetime": "2013-10-24T09:45:15-07:00",
        "summary": "fix comment, remove size",
        "message": "fix comment, remove size\n",
        "diff": {
            "parquet-pig/src/main/java/parquet/pig/ParquetLoader.java": [
                1,
                1
            ]
        }
    },
    "a34df077d0607ad80b2a3977321d7c2a3fdf3fa8": {
        "datetime": "2013-10-24T09:55:02-07:00",
        "summary": "Merge pull request #204 from aaghevli/ParquetLoader.inputFormatCache",
        "message": "Merge pull request #204 from aaghevli/ParquetLoader.inputFormatCache\n\nParquetLoader.inputFormatCache as WeakHashMap",
        "diff": {
            "parquet-pig/src/main/java/parquet/pig/ParquetLoader.java": [
                3,
                5
            ]
        }
    },
    "464945308c70beb14373ac5987cd38d0c9478cfc": {
        "datetime": "2013-10-25T16:53:17-07:00",
        "summary": "Merge branch 'master' into plumb_original_type",
        "message": "Merge branch 'master' into plumb_original_type\n",
        "diff": {
            "parquet-cascading/pom.xml": null,
            "parquet-pig/src/main/java/parquet/pig/ParquetLoader.java": [
                3,
                5
            ],
            "parquet-thrift/src/main/java/parquet/thrift/ParquetWriteProtocol.java": [
                2,
                7
            ]
        }
    },
    "e337bd2f9c54b58245e3e050372a32c555b2417f": {
        "datetime": "2013-10-27T21:24:46+01:00",
        "summary": "Protobuf conversion over Java types",
        "message": "Protobuf conversion over Java types\n",
        "diff": {
            "src/main/java/parquet/proto/ProtoSchemaConverter.java": [
                11,
                12
            ]
        }
    },
    "a6aa8f766154bceab65aa97bc8092aa4d30420ee": {
        "datetime": "2013-10-28T11:38:57-07:00",
        "summary": "[maven-release-plugin] prepare release parquet-1.2.5",
        "message": "[maven-release-plugin] prepare release parquet-1.2.5\n",
        "diff": {
            "parquet-avro/pom.xml": null,
            "parquet-cascading/pom.xml": null,
            "parquet-column/pom.xml": null,
            "parquet-common/pom.xml": null,
            "parquet-encoding/pom.xml": null,
            "parquet-generator/pom.xml": null,
            "parquet-hadoop/pom.xml": null,
            "parquet-hive/pom.xml": null,
            "parquet-pig-bundle/pom.xml": null,
            "parquet-pig/pom.xml": null,
            "parquet-scrooge/pom.xml": null,
            "parquet-test-hadoop2/pom.xml": null,
            "parquet-thrift/pom.xml": null,
            "pom.xml": null
        }
    },
    "9c5bdb695eb0c03b0a4f7fb07a0d45aa97a08d12": {
        "datetime": "2013-10-28T11:39:01-07:00",
        "summary": "[maven-release-plugin] prepare for next development iteration",
        "message": "[maven-release-plugin] prepare for next development iteration\n",
        "diff": {
            "parquet-avro/pom.xml": null,
            "parquet-cascading/pom.xml": null,
            "parquet-column/pom.xml": null,
            "parquet-common/pom.xml": null,
            "parquet-encoding/pom.xml": null,
            "parquet-generator/pom.xml": null,
            "parquet-hadoop/pom.xml": null,
            "parquet-hive/pom.xml": null,
            "parquet-pig-bundle/pom.xml": null,
            "parquet-pig/pom.xml": null,
            "parquet-scrooge/pom.xml": null,
            "parquet-test-hadoop2/pom.xml": null,
            "parquet-thrift/pom.xml": null,
            "pom.xml": null
        }
    },
    "170797fa974add3e7dd9cc204b4f46b099817eb6": {
        "datetime": "2013-10-29T09:07:09-07:00",
        "summary": "Create PoweredBy",
        "message": "Create PoweredBy",
        "diff": {
            "PoweredBy": null
        }
    },
    "9a91418bdead533d0201207e12288294481da7e7": {
        "datetime": "2013-10-29T09:08:00-07:00",
        "summary": "Create PoweredBy.md",
        "message": "Create PoweredBy.md",
        "diff": {
            "PoweredBy.md": null
        }
    },
    "05c0f060641829827ffa3554e7d9b6bff867e2ee": {
        "datetime": "2013-10-29T09:11:36-07:00",
        "summary": "Delete PoweredBy",
        "message": "Delete PoweredBy",
        "diff": {
            "PoweredBy": null
        }
    },
    "6f1e8126c2a375b05a361677a4f549bb8a606b51": {
        "datetime": "2013-10-29T09:24:00-07:00",
        "summary": "Update PoweredBy.md",
        "message": "Update PoweredBy.md",
        "diff": {
            "PoweredBy.md": null
        }
    },
    "75a610229d905f74b4f844c9875b9e4bb6a956da": {
        "datetime": "2013-10-29T09:24:24-07:00",
        "summary": "Update PoweredBy.md",
        "message": "Update PoweredBy.md",
        "diff": {
            "PoweredBy.md": null
        }
    },
    "12a1cd7697fdef011503936d81a7904516a8151e": {
        "datetime": "2013-10-29T09:27:42-07:00",
        "summary": "Update PoweredBy.md",
        "message": "Update PoweredBy.md",
        "diff": {
            "PoweredBy.md": null
        }
    },
    "70a433b59282340471482bdc6602fa92f1c684ce": {
        "datetime": "2013-10-29T09:27:56-07:00",
        "summary": "Update PoweredBy.md",
        "message": "Update PoweredBy.md",
        "diff": {
            "PoweredBy.md": null
        }
    },
    "81a1af0c47219598a6ebf4c86a2e0d43d028706d": {
        "datetime": "2013-10-29T13:18:36-07:00",
        "summary": "improve fallback for IntDictionaryWriter",
        "message": "improve fallback for IntDictionaryWriter\n",
        "diff": {
            "parquet-column/src/main/java/parquet/column/values/dictionary/DictionaryValuesWriter.java": [
                3,
                9
            ],
            "parquet-column/src/test/java/parquet/column/values/dictionary/TestDictionary.java": [
                0,
                34
            ]
        }
    },
    "1a4bb6a372cbd702e0e48fb44fc82c33570e86ed": {
        "datetime": "2013-10-29T13:39:53-07:00",
        "summary": "Merge pull request #206 from Parquet/PoweredBy",
        "message": "Merge pull request #206 from Parquet/PoweredBy\n\nCreate a \"Powered by\" page",
        "diff": {
            "PoweredBy.md": null
        }
    },
    "11f30faffbc095068d23e8173fb3387e99b1a341": {
        "datetime": "2013-10-29T13:58:52-07:00",
        "summary": "fix bug, add rawDataByteSize for dictionaryValuesWriter to decide if fall back to Plain encoding or not",
        "message": "fix bug, add rawDataByteSize for dictionaryValuesWriter to decide if fall back to Plain encoding or not\n",
        "diff": {
            "parquet-column/src/main/java/parquet/column/values/dictionary/DictionaryValuesWriter.java": [
                1,
                18
            ]
        }
    },
    "be6a4aeed809a0a78cbf0c156ace3ed8c1a12af9": {
        "datetime": "2013-10-29T14:56:51-07:00",
        "summary": "fix bug: reverse dictionary lookup for fallbacking to plain encoding",
        "message": "fix bug: reverse dictionary lookup for fallbacking to plain encoding\n",
        "diff": {
            "parquet-column/src/main/java/parquet/column/values/dictionary/DictionaryValuesWriter.java": [
                2,
                14
            ]
        }
    },
    "4d55b59776ff9be7a97c8bff605204f9c625747a": {
        "datetime": "2013-10-29T15:11:05-07:00",
        "summary": "improve fallback for float",
        "message": "improve fallback for float\n",
        "diff": {
            "parquet-column/src/main/java/parquet/column/values/dictionary/DictionaryValuesWriter.java": [
                4,
                18
            ],
            "parquet-column/src/test/java/parquet/column/values/dictionary/TestDictionary.java": [
                0,
                28
            ]
        }
    },
    "1afdf14faa875b268aca616e323957040a9695f8": {
        "datetime": "2013-10-30T16:06:25-07:00",
        "summary": "minor fix, the length used in RLEValuesReader",
        "message": "minor fix, the length used in RLEValuesReader\n",
        "diff": {
            "parquet-column/src/main/java/parquet/column/values/rle/RunLengthBitPackingHybridValuesReader.java": [
                1,
                1
            ]
        }
    },
    "d942b454af8bf930394744311a523a76802cb7c5": {
        "datetime": "2013-10-30T16:07:36-07:00",
        "summary": "format",
        "message": "format\n",
        "diff": {
            "parquet-column/src/main/java/parquet/column/values/rle/RunLengthBitPackingHybridValuesReader.java": [
                1,
                1
            ]
        }
    },
    "55a451c7478ba836e63e19c8bc3284a4a7187adf": {
        "datetime": "2013-10-31T11:03:58+01:00",
        "summary": "Merge branch 'master' of https://github.com/lukasnalezenec/parquet-protobuf",
        "message": "Merge branch 'master' of https://github.com/lukasnalezenec/parquet-protobuf\n",
        "diff": {
            "src/main/java/parquet/proto/todo.txt": null
        }
    },
    "3c99aa31c350d4b87e31c5d1dfd740f6938b5b47": {
        "datetime": "2013-10-31T09:50:38-07:00",
        "summary": "improve fallback for double",
        "message": "improve fallback for double\n",
        "diff": {
            "parquet-column/src/main/java/parquet/column/values/dictionary/DictionaryValuesWriter.java": [
                4,
                18
            ],
            "parquet-column/src/test/java/parquet/column/values/dictionary/TestDictionary.java": [
                8,
                27
            ]
        }
    },
    "b84e2726bed4ec02a896e5142c363a9426c3295e": {
        "datetime": "2013-10-31T10:39:53-07:00",
        "summary": "Merge pull request #207 from Parquet/fix_offset",
        "message": "Merge pull request #207 from Parquet/fix_offset\n\nFix offset",
        "diff": {
            "parquet-column/src/main/java/parquet/column/values/rle/RunLengthBitPackingHybridValuesReader.java": [
                1,
                1
            ]
        }
    },
    "245d43ea7eb45f11d0c3822eb3704eccf429dc04": {
        "datetime": "2013-10-31T11:43:09-07:00",
        "summary": "use primitve array for int, float , double, get rid of auto boxing,unboxing",
        "message": "use primitve array for int, float , double, get rid of auto boxing,unboxing\n",
        "diff": {
            "parquet-column/src/main/java/parquet/column/values/dictionary/DictionaryValuesWriter.java": [
                21,
                22
            ]
        }
    },
    "c9b768f4d2a942dd29cecfd3871549794d337b25": {
        "datetime": "2013-10-31T12:05:22-07:00",
        "summary": "improve long fallback",
        "message": "improve long fallback\n",
        "diff": {
            "parquet-column/src/main/java/parquet/column/values/dictionary/DictionaryValuesWriter.java": [
                4,
                18
            ],
            "parquet-column/src/test/java/parquet/column/values/dictionary/TestDictionary.java": [
                0,
                25
            ]
        }
    },
    "bee675509d8fc7f927d410b4815e95f457ee1fa2": {
        "datetime": "2013-10-31T13:49:39-07:00",
        "summary": "improve binary fallback",
        "message": "improve binary fallback\n",
        "diff": {
            "parquet-column/src/main/java/parquet/column/values/dictionary/DictionaryValuesWriter.java": [
                4,
                17
            ],
            "parquet-column/src/test/java/parquet/column/values/dictionary/TestDictionary.java": [
                0,
                27
            ]
        }
    },
    "d33aa40c7e9e9f577bfe05f0a15eb9687ad22cba": {
        "datetime": "2013-10-31T14:13:23-07:00",
        "summary": "bug fix: separate fallBackDictionaryEncodedData to a method, will always be called when fallbacking to plainEncoding",
        "message": "bug fix: separate fallBackDictionaryEncodedData to a method, will always be called when fallbacking to plainEncoding\n",
        "diff": {
            "parquet-column/src/main/java/parquet/column/values/dictionary/DictionaryValuesWriter.java": [
                10,
                29
            ]
        }
    },
    "1278cde66ac37c94e2e0c602282ff6d0d13a4700": {
        "datetime": "2013-10-31T14:16:09-07:00",
        "summary": "remove unused import",
        "message": "remove unused import\n",
        "diff": {
            "parquet-column/src/main/java/parquet/column/values/dictionary/DictionaryValuesWriter.java": [
                3,
                0
            ]
        }
    },
    "65ca5ed89db94a8217e8300b3222abd2918f1848": {
        "datetime": "2013-11-01T16:28:27+01:00",
        "summary": "Copyrights in converters",
        "message": "Copyrights in converters\n",
        "diff": {
            "src/main/java/parquet/proto/converters/ParentValueContainer.java": [
                0,
                16
            ],
            "src/main/java/parquet/proto/converters/ProtoArrayConverter.java": [
                0,
                16
            ],
            "src/main/java/parquet/proto/converters/ProtoBinaryConverter.java": [
                0,
                16
            ],
            "src/main/java/parquet/proto/converters/ProtoBooleanConverter.java": [
                0,
                16
            ],
            "src/main/java/parquet/proto/converters/ProtoDoubleConverter.java": [
                0,
                16
            ],
            "src/main/java/parquet/proto/converters/ProtoEnumConverter.java": [
                0,
                16
            ],
            "src/main/java/parquet/proto/converters/ProtoFloatConverter.java": [
                0,
                16
            ],
            "src/main/java/parquet/proto/converters/ProtoIntConverter.java": [
                0,
                16
            ],
            "src/main/java/parquet/proto/converters/ProtoLongConverter.java": [
                0,
                16
            ],
            "src/main/java/parquet/proto/converters/ProtoMessageConverter.java": [
                0,
                16
            ],
            "src/main/java/parquet/proto/converters/ProtobufStringConverter.java": [
                0,
                16
            ]
        }
    },
    "492da11c61dfc6d58a8b093affa2b8b6e7054df1": {
        "datetime": "2013-11-01T13:49:09-07:00",
        "summary": "remove hash lookup and unused comments",
        "message": "remove hash lookup and unused comments\n",
        "diff": {
            "parquet-column/src/main/java/parquet/column/values/dictionary/DictionaryValuesWriter.java": [
                35,
                30
            ]
        }
    },
    "edfd7d96f939f5602d9338575d6fa5ad243b8b2e": {
        "datetime": "2013-11-01T14:04:57-07:00",
        "summary": "return raw data size as bufferSize in dictionaryValuesWriter",
        "message": "return raw data size as bufferSize in dictionaryValuesWriter\n",
        "diff": {
            "parquet-column/src/main/java/parquet/column/values/dictionary/DictionaryValuesWriter.java": [
                3,
                4
            ]
        }
    },
    "66900aada51693bd977cb54cb96e7078001231d1": {
        "datetime": "2013-11-01T14:07:27-07:00",
        "summary": "more comment",
        "message": "more comment\n",
        "diff": {
            "parquet-column/src/main/java/parquet/column/values/dictionary/DictionaryValuesWriter.java": [
                0,
                1
            ]
        }
    },
    "7427a895ef33a8b8703e8c7af9a17ffb15fe2bb2": {
        "datetime": "2013-11-01T15:10:17-07:00",
        "summary": "revert fixing page cutting, fix bug, raw data size should be long",
        "message": "revert fixing page cutting, fix bug, raw data size should be long\n",
        "diff": {
            "parquet-column/src/main/java/parquet/column/values/dictionary/DictionaryValuesWriter.java": [
                5,
                4
            ]
        }
    },
    "198f5540fdbca63bbd73943a30be79dd9761af4a": {
        "datetime": "2013-11-01T15:32:44-07:00",
        "summary": "revert revert.. use rawDataByteSize as buffered size in DictionaryValuesWriter",
        "message": "revert revert.. use rawDataByteSize as buffered size in DictionaryValuesWriter\n",
        "diff": {
            "parquet-column/src/main/java/parquet/column/values/dictionary/DictionaryValuesWriter.java": [
                3,
                4
            ]
        }
    },
    "a7de264ff2fa559ca5d5e6b8a33e3a5d2590952f": {
        "datetime": "2013-11-03T00:53:40+01:00",
        "summary": "Specification of written protobuffer class in output format",
        "message": "Specification of written protobuffer class in output format\n",
        "diff": {
            "src/main/java/parquet/proto/ProtoParquetOutputFormat.java": [
                3,
                20
            ],
            "src/main/java/parquet/proto/ProtoWriteSupport.java": [
                2,
                13
            ]
        }
    },
    "2e78704e82f62822f1183131340cbd59c7b7831f": {
        "datetime": "2013-11-03T16:36:59+01:00",
        "summary": "Code cleanup",
        "message": "Code cleanup\n",
        "diff": {
            "src/main/java/parquet/proto/ProtoWriteSupport.java": [
                15,
                4
            ]
        }
    },
    "090a2a41e5e7ef8c409fbfc8f872707d3e1907c4": {
        "datetime": "2013-11-03T16:51:10+01:00",
        "summary": "Code Cleanup",
        "message": "Code Cleanup\n",
        "diff": {
            "src/main/java/parquet/proto/ProtoSchemaConverter.java": [
                12,
                2
            ]
        }
    },
    "1bec97fa188a450a52289a4836b71edfa607e017": {
        "datetime": "2013-11-03T17:06:03+01:00",
        "summary": "Projections in read support",
        "message": "Projections in read support\n",
        "diff": {
            "src/main/java/parquet/proto/ProtoReadSupport.java": [
                9,
                4
            ]
        }
    },
    "40ae3fbe969a484318ecaf33960ae26c68677c45": {
        "datetime": "2013-11-03T21:59:02+01:00",
        "summary": "artifact version changed to 1.2.5, unused dependencies removed.",
        "message": "artifact version changed to 1.2.5, unused dependencies removed.\n",
        "diff": {
            "pom.xml": null
        }
    },
    "0d47734c372a5322e17feea56bf426226b6bebb5": {
        "datetime": "2013-11-04T14:49:49+01:00",
        "summary": "Add test on DeprecatedParquetInputFormat.getSplit()",
        "message": "Add test on DeprecatedParquetInputFormat.getSplit()\n",
        "diff": {
            "parquet-hive/src/main/java/parquet/hive/DeprecatedParquetInputFormat.java": [
                11,
                9
            ],
            "parquet-hive/src/test/java/parquet/hive/TestDeprecatedParquetInputFormat.java": [
                4,
                89
            ],
            "parquet-hive/src/test/java/parquet/hive/UtilitiesTestMethods.java": [
                1,
                33
            ]
        }
    },
    "f479aeee14eb7373b8e1daf9e94e1b6a56530736": {
        "datetime": "2013-11-04T11:17:15-08:00",
        "summary": "Merge pull request #208 from Parquet/improve_dic_fall_back",
        "message": "Merge pull request #208 from Parquet/improve_dic_fall_back\n\nImprove dic fall back",
        "diff": {
            "parquet-column/src/main/java/parquet/column/values/dictionary/DictionaryValuesWriter.java": [
                19,
                123
            ],
            "parquet-column/src/test/java/parquet/column/values/dictionary/TestDictionary.java": [
                0,
                133
            ]
        }
    },
    "7c2785f95170ca95a786bf33b8427a44b53aeb27": {
        "datetime": "2013-11-05T13:33:58-08:00",
        "summary": "Merge pull request #202 from Parquet/hive_requested_schema",
        "message": "Merge pull request #202 from Parquet/hive_requested_schema\n\nFix requested schema when recreating splits in hive",
        "diff": {
            "parquet-hive/src/main/java/parquet/hive/DeprecatedParquetInputFormat.java": [
                12,
                10
            ],
            "parquet-hive/src/test/java/parquet/hive/TestDeprecatedParquetInputFormat.java": [
                4,
                89
            ],
            "parquet-hive/src/test/java/parquet/hive/UtilitiesTestMethods.java": [
                1,
                33
            ]
        }
    },
    "6e9004190ee16ff5e338fd6dbddc1dd56ca2911f": {
        "datetime": "2013-11-05T19:04:32-08:00",
        "summary": "Merge branch 'master' into plumb_original_type",
        "message": "Merge branch 'master' into plumb_original_type\n",
        "diff": {
            "PoweredBy.md": null,
            "parquet-avro/pom.xml": null,
            "parquet-cascading/pom.xml": null,
            "parquet-column/pom.xml": null,
            "parquet-column/src/main/java/parquet/column/values/dictionary/DictionaryValuesWriter.java": [
                19,
                123
            ],
            "parquet-column/src/main/java/parquet/column/values/rle/RunLengthBitPackingHybridValuesReader.java": [
                1,
                1
            ],
            "parquet-column/src/test/java/parquet/column/values/dictionary/TestDictionary.java": [
                0,
                133
            ],
            "parquet-common/pom.xml": null,
            "parquet-encoding/pom.xml": null,
            "parquet-generator/pom.xml": null,
            "parquet-hadoop/pom.xml": null,
            "parquet-hive/pom.xml": null,
            "parquet-hive/src/main/java/parquet/hive/DeprecatedParquetInputFormat.java": [
                12,
                10
            ],
            "parquet-hive/src/test/java/parquet/hive/TestDeprecatedParquetInputFormat.java": [
                4,
                89
            ],
            "parquet-hive/src/test/java/parquet/hive/UtilitiesTestMethods.java": [
                1,
                33
            ],
            "parquet-pig-bundle/pom.xml": null,
            "parquet-pig/pom.xml": null,
            "parquet-scrooge/pom.xml": null,
            "parquet-test-hadoop2/pom.xml": null,
            "parquet-thrift/pom.xml": null,
            "pom.xml": null
        }
    },
    "59bd08b9a98483dec17ca10f9dd3d9eaae1ce774": {
        "datetime": "2013-11-06T14:19:34-05:00",
        "summary": "One of the constructors in ParquetWriter ignores",
        "message": "One of the constructors in ParquetWriter ignores\nthe enable dictionary and validating flags.\n",
        "diff": {
            "parquet-hadoop/src/main/java/parquet/hadoop/ParquetWriter.java": [
                1,
                1
            ]
        }
    },
    "484915554e374b1322bc5e5cdf47442077133d55": {
        "datetime": "2013-11-06T14:56:31-08:00",
        "summary": "Merge pull request #210 from wesleypeck/fixwriter",
        "message": "Merge pull request #210 from wesleypeck/fixwriter\n\nParquetWriter ignores enable dictionary and validating flags.",
        "diff": {
            "parquet-hadoop/src/main/java/parquet/hadoop/ParquetWriter.java": [
                1,
                1
            ]
        }
    },
    "402e96dfb58077cdf3e6bf2e496bdca6bad11743": {
        "datetime": "2013-11-09T22:43:56+01:00",
        "summary": "Wrong merge",
        "message": "Wrong merge\n",
        "diff": {
            "src/main/java/parquet/proto/ProtoWriteSupport.java": [
                0,
                1
            ]
        }
    },
    "4daff70016010a5baa881c7353304713e5e4bbaa": {
        "datetime": "2013-11-11T17:51:01-08:00",
        "summary": "group parquet-format version in one property",
        "message": "group parquet-format version in one property\n",
        "diff": {
            "parquet-avro/pom.xml": null,
            "parquet-hadoop/pom.xml": null,
            "parquet-pig/pom.xml": null,
            "pom.xml": null
        }
    },
    "8af5a22fd64699fe6c7063870a82704c81dd8bff": {
        "datetime": "2013-11-13T17:32:55-08:00",
        "summary": "Fix Binary.equals().",
        "message": "Fix Binary.equals().\n",
        "diff": {
            "parquet-column/src/main/java/parquet/io/api/Binary.java": [
                1,
                2
            ]
        }
    },
    "0b3400add17a2920ca96b757cd45d361c5022cf0": {
        "datetime": "2013-11-13T18:01:53-08:00",
        "summary": "Merge pull request #215 from Parquet/binary_equals",
        "message": "Merge pull request #215 from Parquet/binary_equals\n\nFix Binary.equals().",
        "diff": {
            "parquet-column/src/main/java/parquet/io/api/Binary.java": [
                1,
                2
            ]
        }
    },
    "31aaa530b55a458fc0227717f93c40a4a1b6d878": {
        "datetime": "2013-11-14T12:46:02-08:00",
        "summary": "Merge pull request #213 from aniket486/parquet_format_pom_refactor",
        "message": "Merge pull request #213 from aniket486/parquet_format_pom_refactor\n\ngroup parquet-format version in one property",
        "diff": {
            "parquet-avro/pom.xml": null,
            "parquet-hadoop/pom.xml": null,
            "parquet-pig/pom.xml": null,
            "pom.xml": null
        }
    },
    "f4d6e17d027eeadc379ffab9498e1f392b82f514": {
        "datetime": "2013-11-15T13:35:04-08:00",
        "summary": "Merge branch 'master' into plumb_original_type",
        "message": "Merge branch 'master' into plumb_original_type\n",
        "diff": {
            "parquet-avro/pom.xml": null,
            "parquet-column/src/main/java/parquet/io/api/Binary.java": [
                1,
                2
            ],
            "parquet-hadoop/pom.xml": null,
            "parquet-hadoop/src/main/java/parquet/hadoop/ParquetWriter.java": [
                1,
                1
            ],
            "parquet-pig/pom.xml": null,
            "pom.xml": null
        }
    },
    "0334948eadddfac9891277d673117e6b4bec0d7e": {
        "datetime": "2013-11-19T10:26:37-06:00",
        "summary": "parquet-hive should ship and uber jar",
        "message": "parquet-hive should ship and uber jar\n\n* Creates parquet-hive-bundle which is an uber jar of dependencies required for Hive.\n* Removes runtime dependency on commons-lang\n* Marks Hadoop and Hive dependencies as optional so they don't have to be excluded by dependees\n",
        "diff": {
            "parquet-hive-bundle/pom.xml": null,
            "parquet-hive-bundle/src/main/resources/parquet/bundle": null,
            "parquet-hive/pom.xml": null,
            "parquet-hive/src/main/java/parquet/hive/convert/HiveSchemaConverter.java": [
                6,
                5
            ],
            "parquet-hive/src/main/java/parquet/hive/serde/ArrayWritableObjectInspector.java": [
                2,
                1
            ],
            "parquet-hive/src/main/java/parquet/hive/write/DataWritableWriter.java": [
                2,
                1
            ]
        }
    },
    "bbfa4ac952cdf4656a8f957a9db7b916ac709779": {
        "datetime": "2013-11-19T15:55:26-06:00",
        "summary": "Address comments on pull request",
        "message": "Address comments on pull request\n",
        "diff": {
            "parquet-hive/pom.xml": null,
            "pom.xml": null
        }
    },
    "700c223954d9d9508812a985b39f8542845635e9": {
        "datetime": "2013-11-19T14:10:03-08:00",
        "summary": "Merge pull request #220 from brockn/master",
        "message": "Merge pull request #220 from brockn/master\n\nIssue #219 - parquet-hive should ship and uber jar",
        "diff": {
            "parquet-hive-bundle/pom.xml": null,
            "parquet-hive-bundle/src/main/resources/parquet/bundle": null,
            "parquet-hive/pom.xml": null,
            "parquet-hive/src/main/java/parquet/hive/convert/HiveSchemaConverter.java": [
                6,
                5
            ],
            "parquet-hive/src/main/java/parquet/hive/serde/ArrayWritableObjectInspector.java": [
                2,
                1
            ],
            "parquet-hive/src/main/java/parquet/hive/write/DataWritableWriter.java": [
                2,
                1
            ],
            "pom.xml": null
        }
    },
    "1028fb9dc35cbde49e6735020d5065163cccc522": {
        "datetime": "2013-11-19T14:24:46-08:00",
        "summary": "make pig, hadoop and log4j jars provided",
        "message": "make pig, hadoop and log4j jars provided\n",
        "diff": {
            "parquet-avro/pom.xml": null,
            "parquet-cascading/pom.xml": null,
            "parquet-hadoop/pom.xml": null,
            "parquet-pig-bundle/pom.xml": null,
            "parquet-pig/pom.xml": null,
            "parquet-scrooge/pom.xml": null,
            "parquet-thrift/pom.xml": null,
            "pom.xml": null
        }
    },
    "e54735a988f331dced9317dbccdd317c72e16f66": {
        "datetime": "2013-11-19T14:25:26-08:00",
        "summary": "Merge branch 'master' into cleanup_dependencies",
        "message": "Merge branch 'master' into cleanup_dependencies\n",
        "diff": {
            "parquet-hive-bundle/pom.xml": null,
            "parquet-hive-bundle/src/main/resources/parquet/bundle": null,
            "parquet-hive/pom.xml": null,
            "parquet-hive/src/main/java/parquet/hive/convert/HiveSchemaConverter.java": [
                6,
                5
            ],
            "parquet-hive/src/main/java/parquet/hive/serde/ArrayWritableObjectInspector.java": [
                2,
                1
            ],
            "parquet-hive/src/main/java/parquet/hive/write/DataWritableWriter.java": [
                2,
                1
            ],
            "pom.xml": null
        }
    },
    "61af0b959d02829918f5cfcd47dbc894a6b4e1fd": {
        "datetime": "2013-11-19T14:49:11-08:00",
        "summary": "Merge pull request #221 from Parquet/cleanup_dependencies",
        "message": "Merge pull request #221 from Parquet/cleanup_dependencies\n\nmake pig, hadoop and log4j jars provided",
        "diff": {
            "parquet-avro/pom.xml": null,
            "parquet-cascading/pom.xml": null,
            "parquet-hadoop/pom.xml": null,
            "parquet-pig-bundle/pom.xml": null,
            "parquet-pig/pom.xml": null,
            "parquet-scrooge/pom.xml": null,
            "parquet-thrift/pom.xml": null,
            "pom.xml": null
        }
    },
    "014f583366d1aa4fe6860b6c444db755b07ff4a6": {
        "datetime": "2013-11-19T16:36:53-08:00",
        "summary": "[maven-release-plugin] prepare release parquet-1.2.6",
        "message": "[maven-release-plugin] prepare release parquet-1.2.6\n",
        "diff": {
            "parquet-avro/pom.xml": null,
            "parquet-cascading/pom.xml": null,
            "parquet-column/pom.xml": null,
            "parquet-common/pom.xml": null,
            "parquet-encoding/pom.xml": null,
            "parquet-generator/pom.xml": null,
            "parquet-hadoop/pom.xml": null,
            "parquet-hive-bundle/pom.xml": null,
            "parquet-hive/pom.xml": null,
            "parquet-pig-bundle/pom.xml": null,
            "parquet-pig/pom.xml": null,
            "parquet-scrooge/pom.xml": null,
            "parquet-test-hadoop2/pom.xml": null,
            "parquet-thrift/pom.xml": null,
            "pom.xml": null
        }
    },
    "94240182fd59639f815af42f95cfe87adc305242": {
        "datetime": "2013-11-19T16:37:11-08:00",
        "summary": "[maven-release-plugin] prepare for next development iteration",
        "message": "[maven-release-plugin] prepare for next development iteration\n",
        "diff": {
            "parquet-avro/pom.xml": null,
            "parquet-cascading/pom.xml": null,
            "parquet-column/pom.xml": null,
            "parquet-common/pom.xml": null,
            "parquet-encoding/pom.xml": null,
            "parquet-generator/pom.xml": null,
            "parquet-hadoop/pom.xml": null,
            "parquet-hive-bundle/pom.xml": null,
            "parquet-hive/pom.xml": null,
            "parquet-pig-bundle/pom.xml": null,
            "parquet-pig/pom.xml": null,
            "parquet-scrooge/pom.xml": null,
            "parquet-test-hadoop2/pom.xml": null,
            "parquet-thrift/pom.xml": null,
            "pom.xml": null
        }
    },
    "de81ee89049c264c244a377e7cdb614abf2b00ef": {
        "datetime": "2013-11-20T11:52:32-08:00",
        "summary": "changelog for 1.2.5 and 1.2.6",
        "message": "changelog for 1.2.5 and 1.2.6\n",
        "diff": {
            "CHANGES.md": null
        }
    },
    "6b5d2d1399c62c5d58436befd72a09491e29904b": {
        "datetime": "2013-11-20T13:30:36-08:00",
        "summary": "fix bug: set raw data size to 0 after reset",
        "message": "fix bug: set raw data size to 0 after reset\n",
        "diff": {
            "parquet-column/src/main/java/parquet/column/values/dictionary/DictionaryValuesWriter.java": [
                0,
                1
            ],
            "parquet-column/src/test/java/parquet/column/values/dictionary/TestDictionary.java": [
                0,
                22
            ]
        }
    },
    "8e1110b1433199d6fd638d04b013ec806c52f729": {
        "datetime": "2013-11-20T14:17:59-08:00",
        "summary": "Merge pull request #222 from Parquet/fix_dic_fallback_page_cutting",
        "message": "Merge pull request #222 from Parquet/fix_dic_fallback_page_cutting\n\nfix bug: set raw data size to 0 after reset",
        "diff": {
            "parquet-column/src/main/java/parquet/column/values/dictionary/DictionaryValuesWriter.java": [
                0,
                1
            ],
            "parquet-column/src/test/java/parquet/column/values/dictionary/TestDictionary.java": [
                0,
                22
            ]
        }
    },
    "f4ad9dfc394f1336e68444944e41772d6d435744": {
        "datetime": "2013-11-20T14:50:10-08:00",
        "summary": "refactor encoded values changes and test that resetDictionary works",
        "message": "refactor encoded values changes and test that resetDictionary works\n",
        "diff": {
            "parquet-column/src/main/java/parquet/column/values/dictionary/DictionaryValuesWriter.java": [
                6,
                4
            ],
            "parquet-column/src/test/java/parquet/column/values/dictionary/TestDictionary.java": [
                52,
                70
            ]
        }
    },
    "e0c5ac84285e4aaa6f684f45249bb7f0245480ac": {
        "datetime": "2013-11-20T15:09:30-08:00",
        "summary": "Merge pull request #223 from Parquet/dictionary_reset",
        "message": "Merge pull request #223 from Parquet/dictionary_reset\n\nrefactor encoded values changes and test that resetDictionary works",
        "diff": {
            "parquet-column/src/main/java/parquet/column/values/dictionary/DictionaryValuesWriter.java": [
                6,
                4
            ],
            "parquet-column/src/test/java/parquet/column/values/dictionary/TestDictionary.java": [
                52,
                70
            ]
        }
    },
    "ab7959d9ac4a61c13220f53484bdce9ad6c3c67f": {
        "datetime": "2013-11-20T15:49:00-08:00",
        "summary": "[maven-release-plugin] prepare release parquet-1.2.7",
        "message": "[maven-release-plugin] prepare release parquet-1.2.7\n",
        "diff": {
            "parquet-avro/pom.xml": null,
            "parquet-cascading/pom.xml": null,
            "parquet-column/pom.xml": null,
            "parquet-common/pom.xml": null,
            "parquet-encoding/pom.xml": null,
            "parquet-generator/pom.xml": null,
            "parquet-hadoop/pom.xml": null,
            "parquet-hive-bundle/pom.xml": null,
            "parquet-hive/pom.xml": null,
            "parquet-pig-bundle/pom.xml": null,
            "parquet-pig/pom.xml": null,
            "parquet-scrooge/pom.xml": null,
            "parquet-test-hadoop2/pom.xml": null,
            "parquet-thrift/pom.xml": null,
            "pom.xml": null
        }
    },
    "f58747157f3b5e8b4dc8b527fabba8fa676bc826": {
        "datetime": "2013-11-20T15:49:04-08:00",
        "summary": "[maven-release-plugin] prepare for next development iteration",
        "message": "[maven-release-plugin] prepare for next development iteration\n",
        "diff": {
            "parquet-avro/pom.xml": null,
            "parquet-cascading/pom.xml": null,
            "parquet-column/pom.xml": null,
            "parquet-common/pom.xml": null,
            "parquet-encoding/pom.xml": null,
            "parquet-generator/pom.xml": null,
            "parquet-hadoop/pom.xml": null,
            "parquet-hive-bundle/pom.xml": null,
            "parquet-hive/pom.xml": null,
            "parquet-pig-bundle/pom.xml": null,
            "parquet-pig/pom.xml": null,
            "parquet-scrooge/pom.xml": null,
            "parquet-test-hadoop2/pom.xml": null,
            "parquet-thrift/pom.xml": null,
            "pom.xml": null
        }
    },
    "493bb9fd70a008e7c083509d93a419c99fd7bc26": {
        "datetime": "2013-11-22T02:31:12-08:00",
        "summary": "Changing read and write methods in ParquetInputSplit so that they can deal with large schemas (avoiding use of writeUTF and readUTF which are limited to 65536 characters).",
        "message": "Changing read and write methods in ParquetInputSplit so that they can deal with large schemas (avoiding use of writeUTF and readUTF which are limited to 65536 characters).\n",
        "diff": {
            "parquet-hadoop/src/main/java/parquet/hadoop/ParquetInputSplit.java": [
                4,
                5
            ]
        }
    },
    "d2ccc72cb739ada1ce3d5ae9af7032952908352c": {
        "datetime": "2013-11-26T13:30:13-06:00",
        "summary": "Breaks parquet-hive up into several submodules, creating infrastructure to handle",
        "message": "Breaks parquet-hive up into several submodules, creating infrastructure to handle\nvarious versions of Hive going forward.\n\n* parquet-hive-storage-handler - this is almost all the previous code\n* parquet-hive-binding - contains the various binding modules for specific hive versions\n* parquet-hive-binding-interface - the interface the storage handler compiles to\n* parquet-hive-binding-factory - factory which can depend on interface, 0.10, and 0.12\n* parquet-hive-0.10-binding - binding layer for 0.10 (and 0.11)\n* parquet-hive-0.12-binding - binding layer for 0.12 (and 0.13)\n",
        "diff": {
            "parquet-hive-bundle/pom.xml": null,
            "parquet-hive/parquet-hive-binding/parquet-hive-0.10-binding/pom.xml": null,
            "parquet-hive/parquet-hive-binding/parquet-hive-0.12-binding/pom.xml": null,
            "parquet-hive/parquet-hive-binding/parquet-hive-0.12-binding/src/main/java/parquet/hive/internal/Hive012Binding.java": [
                0,
                135
            ],
            "parquet-hive/parquet-hive-binding/parquet-hive-binding-bundle/pom.xml": null,
            "parquet-hive/parquet-hive-binding/parquet-hive-binding-bundle/src/assemble/uberjar.xml": null,
            "parquet-hive/parquet-hive-binding/parquet-hive-binding-factory/pom.xml": null,
            "parquet-hive/parquet-hive-binding/parquet-hive-binding-factory/src/main/java/parquet/hive/HiveBindingFactory.java": [
                0,
                104
            ],
            "parquet-hive/parquet-hive-binding/parquet-hive-binding-factory/src/test/java/parquet/hive/TestHiveBindingFactory.java": [
                0,
                106
            ],
            "parquet-hive/parquet-hive-binding/parquet-hive-binding-interface/pom.xml": null,
            "parquet-hive/parquet-hive-binding/parquet-hive-binding-interface/src/main/java/parquet/hive/HiveBinding.java": [
                0,
                48
            ],
            "parquet-hive/parquet-hive-binding/parquet-hive-binding-interface/src/main/java/parquet/hive/internal/AbstractHiveBinding.java": [
                0,
                31
            ],
            "parquet-hive/parquet-hive-binding/pom.xml": null,
            "parquet-hive/parquet-hive-storage-handler/pom.xml": null,
            "parquet-hive/pom.xml": null,
            "parquet-hive/src/main/java/parquet/hive/DeprecatedParquetInputFormat.java": [
                12,
                21
            ],
            "parquet-hive/src/main/java/parquet/hive/DeprecatedParquetOutputFormat.java": [
                0,
                0
            ],
            "parquet-hive/src/main/java/parquet/hive/ManageJobConfig.java": [
                62,
                12
            ],
            "parquet-hive/src/main/java/parquet/hive/convert/ArrayWritableGroupConverter.java": [
                0,
                0
            ],
            "parquet-hive/src/main/java/parquet/hive/convert/DataWritableGroupConverter.java": [
                0,
                0
            ],
            "parquet-hive/src/main/java/parquet/hive/convert/DataWritableRecordConverter.java": [
                0,
                0
            ],
            "parquet-hive/src/main/java/parquet/hive/convert/ETypeConverter.java": [
                0,
                0
            ],
            "parquet-hive/src/main/java/parquet/hive/convert/HiveGroupConverter.java": [
                0,
                0
            ],
            "parquet-hive/src/main/java/parquet/hive/convert/HiveSchemaConverter.java": [
                0,
                0
            ],
            "parquet-hive/src/main/java/parquet/hive/read/DataWritableReadSupport.java": [
                3,
                2
            ],
            "parquet-hive/src/main/java/parquet/hive/serde/AbstractParquetMapInspector.java": [
                0,
                0
            ],
            "parquet-hive/src/main/java/parquet/hive/serde/ArrayWritableObjectInspector.java": [
                0,
                0
            ],
            "parquet-hive/src/main/java/parquet/hive/serde/DeepParquetHiveMapInspector.java": [
                0,
                0
            ],
            "parquet-hive/src/main/java/parquet/hive/serde/ParquetHiveArrayInspector.java": [
                0,
                0
            ],
            "parquet-hive/src/main/java/parquet/hive/serde/ParquetHiveSerDe.java": [
                0,
                0
            ],
            "parquet-hive/src/main/java/parquet/hive/serde/StandardParquetHiveMapInspector.java": [
                0,
                0
            ],
            "parquet-hive/src/main/java/parquet/hive/serde/primitive/ParquetByteInspector.java": [
                0,
                0
            ],
            "parquet-hive/src/main/java/parquet/hive/serde/primitive/ParquetPrimitiveInspectorFactory.java": [
                0,
                0
            ],
            "parquet-hive/src/main/java/parquet/hive/serde/primitive/ParquetShortInspector.java": [
                0,
                0
            ],
            "parquet-hive/src/main/java/parquet/hive/serde/primitive/ParquetStringInspector.java": [
                0,
                0
            ],
            "parquet-hive/src/main/java/parquet/hive/writable/BigDecimalWritable.java": [
                0,
                0
            ],
            "parquet-hive/src/main/java/parquet/hive/writable/BinaryWritable.java": [
                0,
                0
            ],
            "parquet-hive/src/main/java/parquet/hive/write/DataWritableWriteSupport.java": [
                0,
                0
            ],
            "parquet-hive/src/main/java/parquet/hive/write/DataWritableWriter.java": [
                0,
                0
            ],
            "parquet-hive/src/test/java/parquet/hive/TestDeprecatedParquetInputFormat.java": [
                0,
                0
            ],
            "parquet-hive/src/test/java/parquet/hive/TestDeprecatedParquetOuputFormat.java": [
                0,
                0
            ],
            "parquet-hive/src/test/java/parquet/hive/TestHiveSchemaConverter.java": [
                0,
                0
            ],
            "parquet-hive/src/test/java/parquet/hive/TestParquetSerDe.java": [
                0,
                0
            ],
            "parquet-hive/src/test/java/parquet/hive/UtilitiesTestMethods.java": [
                0,
                0
            ]
        }
    },
    "f18bc49046d51e1700d419e401ad49093322771d": {
        "datetime": "2013-11-26T15:10:15-08:00",
        "summary": "enable globing files for parquetTupleScheme, refactor unit tests and remove binary test fixture",
        "message": "enable globing files for parquetTupleScheme, refactor unit tests and remove binary test fixture\n",
        "diff": {
            "parquet-cascading/src/main/java/parquet/cascading/ParquetTupleScheme.java": [
                1,
                5
            ],
            "parquet-cascading/src/test/java/parquet/cascading/TestParquetTupleScheme.java": [
                54,
                138
            ],
            "parquet-cascading/src/test/resources/part-m-00000.gz.parquet": null,
            "parquet-hadoop/src/main/java/parquet/hadoop/mapred/DeprecatedParquetInputFormat.java": [
                2,
                6
            ]
        }
    },
    "d7c8467f4614483f3d2aa5f872f9a603c3725ad3": {
        "datetime": "2013-11-26T18:26:48-08:00",
        "summary": "Merge pull request #224 from dave2718/master",
        "message": "Merge pull request #224 from dave2718/master\n\nChanging read and write methods in ParquetInputSplit so that they can de...",
        "diff": {
            "parquet-hadoop/src/main/java/parquet/hadoop/ParquetInputSplit.java": [
                4,
                5
            ]
        }
    },
    "d7994dca3ce076aacddec8dd9d4a25c4999699ad": {
        "datetime": "2013-11-26T18:31:14-08:00",
        "summary": "add changelog tool",
        "message": "add changelog tool\n",
        "diff": {
            "changelog.sh": null
        }
    },
    "60c651262e87540bd06f884b25c66ede491c34b7": {
        "datetime": "2013-11-27T11:00:22-06:00",
        "summary": "Updates Hive 0.12 compatability patch by adressing all comments",
        "message": "Updates Hive 0.12 compatability patch by adressing all comments\nfrom Julien's review plus a few additional cleanups, specifically:\n\n* If hive is version 0.12 or newer return 0.12 binding\n* Adds javadoc and inheritDoc statements where appropiate\n* Add's link to Hive*Binding implementations describing where code came from\n* Renames Deprecated{Input,Output}Format to Mapred{Input,Output}Format\n* Creates shell classes Deprecated{Input,Output}Format inheriting from Mapred{Input,Output}Format\n* Moves TestMapred{Input,Output}Format to the JUnit 4 API\n* Replaces Apache licenses in files touched with the version capped at a shorter line length\n* Add's debug log statements to the binding layers to log items of interest\n",
        "diff": {
            "parquet-hive/parquet-hive-binding/parquet-hive-0.10-binding/pom.xml": null,
            "parquet-hive/parquet-hive-binding/parquet-hive-0.10-binding/src/main/java/parquet/hive/internal/Hive010Binding.java": [
                13,
                26
            ],
            "parquet-hive/parquet-hive-binding/parquet-hive-0.12-binding/pom.xml": null,
            "parquet-hive/parquet-hive-binding/parquet-hive-0.12-binding/src/main/java/parquet/hive/internal/Hive012Binding.java": [
                13,
                27
            ],
            "parquet-hive/parquet-hive-binding/parquet-hive-binding-bundle/pom.xml": null,
            "parquet-hive/parquet-hive-binding/parquet-hive-binding-factory/pom.xml": null,
            "parquet-hive/parquet-hive-binding/parquet-hive-binding-factory/src/main/java/parquet/hive/HiveBindingFactory.java": [
                16,
                32
            ],
            "parquet-hive/parquet-hive-binding/parquet-hive-binding-factory/src/test/java/parquet/hive/TestHiveBindingFactory.java": [
                4,
                7
            ],
            "parquet-hive/parquet-hive-binding/parquet-hive-binding-interface/src/main/java/parquet/hive/HiveBinding.java": [
                4,
                8
            ],
            "parquet-hive/parquet-hive-binding/parquet-hive-binding-interface/src/main/java/parquet/hive/internal/AbstractHiveBinding.java": [
                2,
                7
            ],
            "parquet-hive/parquet-hive-storage-handler/src/main/java/parquet/hive/DeprecatedParquetInputFormat.java": [
                354,
                16
            ],
            "parquet-hive/parquet-hive-storage-handler/src/main/java/parquet/hive/DeprecatedParquetOutputFormat.java": [
                143,
                16
            ],
            "parquet-hive/parquet-hive-storage-handler/src/main/java/parquet/hive/MapredParquetInputFormat.java": [
                0,
                379
            ],
            "parquet-hive/parquet-hive-storage-handler/src/main/java/parquet/hive/MapredParquetOutputFormat.java": [
                0,
                167
            ],
            "parquet-hive/parquet-hive-storage-handler/src/main/java/parquet/hive/read/DataWritableReadSupport.java": [
                1,
                1
            ],
            "parquet-hive/parquet-hive-storage-handler/src/test/java/parquet/hive/TestDeprecatedParquetInputFormat.java": [
                25,
                35
            ],
            "parquet-hive/parquet-hive-storage-handler/src/test/java/parquet/hive/TestDeprecatedParquetOuputFormat.java": [
                25,
                27
            ]
        }
    },
    "4d13df5a42a3212914e2da6c9e479607aeff5ddc": {
        "datetime": "2013-11-27T10:23:28-08:00",
        "summary": "encapuslate getFooter into a separate method",
        "message": "encapuslate getFooter into a separate method\n",
        "diff": {
            "parquet-cascading/src/main/java/parquet/cascading/ParquetTupleScheme.java": [
                5,
                9
            ]
        }
    },
    "c31a6be5e50a303ab8d12f810a1f3a44c3326272": {
        "datetime": "2013-11-27T11:35:45-08:00",
        "summary": "Merge pull request #228 from Parquet/glob_files_for_parquet_tuple_scheme",
        "message": "Merge pull request #228 from Parquet/glob_files_for_parquet_tuple_scheme\n\nenable globing files for parquetTupleScheme, refactor unit tests and rem...",
        "diff": {
            "parquet-cascading/src/main/java/parquet/cascading/ParquetTupleScheme.java": [
                2,
                10
            ],
            "parquet-cascading/src/test/java/parquet/cascading/TestParquetTupleScheme.java": [
                54,
                138
            ],
            "parquet-cascading/src/test/resources/part-m-00000.gz.parquet": null,
            "parquet-hadoop/src/main/java/parquet/hadoop/mapred/DeprecatedParquetInputFormat.java": [
                2,
                6
            ]
        }
    },
    "c2499daebfb3aeb0342ebc032451cde65531ccf3": {
        "datetime": "2013-11-27T11:43:48-08:00",
        "summary": "[maven-release-plugin] prepare release parquet-1.2.8",
        "message": "[maven-release-plugin] prepare release parquet-1.2.8\n",
        "diff": {
            "parquet-avro/pom.xml": null,
            "parquet-cascading/pom.xml": null,
            "parquet-column/pom.xml": null,
            "parquet-common/pom.xml": null,
            "parquet-encoding/pom.xml": null,
            "parquet-generator/pom.xml": null,
            "parquet-hadoop/pom.xml": null,
            "parquet-hive-bundle/pom.xml": null,
            "parquet-hive/pom.xml": null,
            "parquet-pig-bundle/pom.xml": null,
            "parquet-pig/pom.xml": null,
            "parquet-scrooge/pom.xml": null,
            "parquet-test-hadoop2/pom.xml": null,
            "parquet-thrift/pom.xml": null,
            "pom.xml": null
        }
    },
    "e1d335b4fdf5f9562a2f9348e6565de6fbaa5da6": {
        "datetime": "2013-11-27T11:43:53-08:00",
        "summary": "[maven-release-plugin] prepare for next development iteration",
        "message": "[maven-release-plugin] prepare for next development iteration\n",
        "diff": {
            "parquet-avro/pom.xml": null,
            "parquet-cascading/pom.xml": null,
            "parquet-column/pom.xml": null,
            "parquet-common/pom.xml": null,
            "parquet-encoding/pom.xml": null,
            "parquet-generator/pom.xml": null,
            "parquet-hadoop/pom.xml": null,
            "parquet-hive-bundle/pom.xml": null,
            "parquet-hive/pom.xml": null,
            "parquet-pig-bundle/pom.xml": null,
            "parquet-pig/pom.xml": null,
            "parquet-scrooge/pom.xml": null,
            "parquet-test-hadoop2/pom.xml": null,
            "parquet-thrift/pom.xml": null,
            "pom.xml": null
        }
    },
    "842500e713232761d93fa27ec42430cce7ce616e": {
        "datetime": "2013-11-27T12:10:11-08:00",
        "summary": "[maven-release-plugin] prepare release parquet-1.2.8",
        "message": "[maven-release-plugin] prepare release parquet-1.2.8\n",
        "diff": {
            "parquet-avro/pom.xml": null,
            "parquet-cascading/pom.xml": null,
            "parquet-column/pom.xml": null,
            "parquet-common/pom.xml": null,
            "parquet-encoding/pom.xml": null,
            "parquet-generator/pom.xml": null,
            "parquet-hadoop/pom.xml": null,
            "parquet-hive-bundle/pom.xml": null,
            "parquet-hive/pom.xml": null,
            "parquet-pig-bundle/pom.xml": null,
            "parquet-pig/pom.xml": null,
            "parquet-scrooge/pom.xml": null,
            "parquet-test-hadoop2/pom.xml": null,
            "parquet-thrift/pom.xml": null,
            "pom.xml": null
        }
    },
    "6cb038c7b8ffef2538ebe43a757a3c603b61c92f": {
        "datetime": "2013-11-27T12:10:16-08:00",
        "summary": "[maven-release-plugin] prepare for next development iteration",
        "message": "[maven-release-plugin] prepare for next development iteration\n",
        "diff": {
            "parquet-avro/pom.xml": null,
            "parquet-cascading/pom.xml": null,
            "parquet-column/pom.xml": null,
            "parquet-common/pom.xml": null,
            "parquet-encoding/pom.xml": null,
            "parquet-generator/pom.xml": null,
            "parquet-hadoop/pom.xml": null,
            "parquet-hive-bundle/pom.xml": null,
            "parquet-hive/pom.xml": null,
            "parquet-pig-bundle/pom.xml": null,
            "parquet-pig/pom.xml": null,
            "parquet-scrooge/pom.xml": null,
            "parquet-test-hadoop2/pom.xml": null,
            "parquet-thrift/pom.xml": null,
            "pom.xml": null
        }
    },
    "3b4ae5eb775d386473aefe2c31538422d682dd86": {
        "datetime": "2013-12-02T22:23:06-08:00",
        "summary": "Merge branch 'master' of https://github.com/Parquet/parquet-mr",
        "message": "Merge branch 'master' of https://github.com/Parquet/parquet-mr\n",
        "diff": {}
    },
    "b297c73c1082728ad9626d17ce0f7abe6abaa36b": {
        "datetime": "2013-12-03T11:54:55-08:00",
        "summary": "optimize chunk scan; fix compressed size",
        "message": "optimize chunk scan; fix compressed size\n",
        "diff": {
            "parquet-hadoop/src/main/java/parquet/hadoop/ParquetFileReader.java": [
                5,
                38
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/ParquetFileWriter.java": [
                2,
                3
            ]
        }
    },
    "476b8ea875c653fee292b8fa4291cf2834102442": {
        "datetime": "2013-12-03T12:16:17-08:00",
        "summary": "Merge branch 'master' into plumb_original_type",
        "message": "Merge branch 'master' into plumb_original_type\n",
        "diff": {
            "CHANGES.md": null,
            "parquet-avro/pom.xml": null,
            "parquet-cascading/pom.xml": null,
            "parquet-cascading/src/main/java/parquet/cascading/ParquetTupleScheme.java": [
                2,
                10
            ],
            "parquet-cascading/src/test/java/parquet/cascading/TestParquetTupleScheme.java": [
                54,
                138
            ],
            "parquet-cascading/src/test/resources/part-m-00000.gz.parquet": null,
            "parquet-column/pom.xml": null,
            "parquet-column/src/main/java/parquet/column/values/dictionary/DictionaryValuesWriter.java": [
                6,
                5
            ],
            "parquet-column/src/test/java/parquet/column/values/dictionary/TestDictionary.java": [
                47,
                87
            ],
            "parquet-common/pom.xml": null,
            "parquet-encoding/pom.xml": null,
            "parquet-generator/pom.xml": null,
            "parquet-hadoop/pom.xml": null,
            "parquet-hadoop/src/main/java/parquet/hadoop/ParquetInputSplit.java": [
                4,
                5
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/mapred/DeprecatedParquetInputFormat.java": [
                2,
                6
            ],
            "parquet-hive-bundle/pom.xml": null,
            "parquet-hive-bundle/src/main/resources/parquet/bundle": null,
            "parquet-hive/pom.xml": null,
            "parquet-hive/src/main/java/parquet/hive/convert/HiveSchemaConverter.java": [
                6,
                5
            ],
            "parquet-hive/src/main/java/parquet/hive/serde/ArrayWritableObjectInspector.java": [
                2,
                1
            ],
            "parquet-hive/src/main/java/parquet/hive/write/DataWritableWriter.java": [
                2,
                1
            ],
            "parquet-pig-bundle/pom.xml": null,
            "parquet-pig/pom.xml": null,
            "parquet-scrooge/pom.xml": null,
            "parquet-test-hadoop2/pom.xml": null,
            "parquet-thrift/pom.xml": null,
            "pom.xml": null
        }
    },
    "e1ce0632157706beed11f3ecf12590cd33bc711a": {
        "datetime": "2013-12-03T14:35:54-08:00",
        "summary": "check if pig is loaded when writing pig metadata",
        "message": "check if pig is loaded when writing pig metadata\n",
        "diff": {
            "parquet-thrift/src/main/java/parquet/hadoop/thrift/ThriftWriteSupport.java": [
                1,
                16
            ]
        }
    },
    "7dfd436245c4ff9ced2bf9ab07cb0fe4289734a0": {
        "datetime": "2013-12-03T16:28:56-08:00",
        "summary": "format",
        "message": "format\n",
        "diff": {
            "parquet-thrift/src/main/java/parquet/hadoop/thrift/ThriftWriteSupport.java": [
                1,
                1
            ]
        }
    },
    "7fa1b6a0450e6129f080d2120f20592ee9a923a1": {
        "datetime": "2013-12-03T20:42:41-08:00",
        "summary": "make cascading a provided dependency",
        "message": "make cascading a provided dependency\n",
        "diff": {
            "parquet-cascading/pom.xml": null
        }
    },
    "3b829a21759d3a2e47f95a2cb880e4abfc4ba6fe": {
        "datetime": "2013-12-03T22:50:46-08:00",
        "summary": "refactor get codec logic to remove duplication in DeprecatedParquetOutputFormat",
        "message": "refactor get codec logic to remove duplication in DeprecatedParquetOutputFormat\n",
        "diff": {
            "parquet-hadoop/src/main/java/parquet/hadoop/ParquetOutputFormat.java": [
                32,
                61
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/mapred/DeprecatedParquetOutputFormat.java": [
                15,
                23
            ]
        }
    },
    "70f29c7f51e2f086c4e4b30ba436f77c99734f27": {
        "datetime": "2013-12-04T11:12:17-08:00",
        "summary": "add cascading dependency to scrooge, and add cascading.version propertie in project pom",
        "message": "add cascading dependency to scrooge, and add cascading.version propertie in project pom\n",
        "diff": {
            "parquet-cascading/pom.xml": null,
            "parquet-scrooge/pom.xml": null,
            "pom.xml": null
        }
    },
    "6fa653b0ab784d7c04647c684f308b3febfbfb9d": {
        "datetime": "2013-12-04T12:28:14-08:00",
        "summary": "Merge pull request #236 from Parquet/make_cascading_a_provided_dependency",
        "message": "Merge pull request #236 from Parquet/make_cascading_a_provided_dependency\n\nMake cascading a provided dependency",
        "diff": {
            "parquet-cascading/pom.xml": null,
            "parquet-scrooge/pom.xml": null,
            "pom.xml": null
        }
    },
    "8b0d05c592f00aef470aef93b59675664fb25a44": {
        "datetime": "2013-12-04T12:29:29-08:00",
        "summary": "Merge pull request #229 from Parquet/changelog_tool",
        "message": "Merge pull request #229 from Parquet/changelog_tool\n\nadd changelog tool",
        "diff": {
            "changelog.sh": null
        }
    },
    "407a52d538c31f65e3ba313c1d7be4fb5f9831b8": {
        "datetime": "2013-12-04T15:00:34-08:00",
        "summary": "fix missing codec",
        "message": "fix missing codec\n",
        "diff": {
            "parquet-hadoop/pom.xml": null,
            "parquet-hadoop/src/main/java/parquet/hadoop/CodecFactory.java": [
                1,
                1
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/ParquetOutputFormat.java": [
                63,
                1
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/codec/CompressionCodecNotSupportedException.java": [
                0,
                14
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/codec/HadoopCodecConfig.java": [
                0,
                92
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/codec/MapReduceCodecConfig.java": [
                0,
                48
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/codec/MapredCodecConfig.java": [
                0,
                46
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/mapred/DeprecatedParquetOutputFormat.java": [
                26,
                2
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/metadata/CompressionCodecName.java": [
                3,
                16
            ],
            "parquet-hadoop/src/test/java/parquet/hadoop/codec/MapReduceCodecConfigTest.java": [
                0,
                46
            ]
        }
    },
    "7641febd3373d5703596dfafaaf8e304a716856c": {
        "datetime": "2013-12-04T16:09:52-08:00",
        "summary": "Merge pull request #227 from brockn/master",
        "message": "Merge pull request #227 from brockn/master\n\nBreaks parquet-hive up into several submodules, creating infrastructure ...",
        "diff": {
            "parquet-hive-bundle/pom.xml": null,
            "parquet-hive/parquet-hive-binding/parquet-hive-0.10-binding/pom.xml": null,
            "parquet-hive/parquet-hive-binding/parquet-hive-0.12-binding/pom.xml": null,
            "parquet-hive/parquet-hive-binding/parquet-hive-0.12-binding/src/main/java/parquet/hive/internal/Hive012Binding.java": [
                0,
                149
            ],
            "parquet-hive/parquet-hive-binding/parquet-hive-binding-bundle/pom.xml": null,
            "parquet-hive/parquet-hive-binding/parquet-hive-binding-bundle/src/assemble/uberjar.xml": null,
            "parquet-hive/parquet-hive-binding/parquet-hive-binding-factory/pom.xml": null,
            "parquet-hive/parquet-hive-binding/parquet-hive-binding-factory/src/main/java/parquet/hive/HiveBindingFactory.java": [
                0,
                120
            ],
            "parquet-hive/parquet-hive-binding/parquet-hive-binding-factory/src/test/java/parquet/hive/TestHiveBindingFactory.java": [
                0,
                109
            ],
            "parquet-hive/parquet-hive-binding/parquet-hive-binding-interface/pom.xml": null,
            "parquet-hive/parquet-hive-binding/parquet-hive-binding-interface/src/main/java/parquet/hive/HiveBinding.java": [
                0,
                52
            ],
            "parquet-hive/parquet-hive-binding/parquet-hive-binding-interface/src/main/java/parquet/hive/internal/AbstractHiveBinding.java": [
                0,
                36
            ],
            "parquet-hive/parquet-hive-binding/pom.xml": null,
            "parquet-hive/parquet-hive-storage-handler/pom.xml": null,
            "parquet-hive/parquet-hive-storage-handler/src/main/java/parquet/hive/DeprecatedParquetInputFormat.java": [
                0,
                35
            ],
            "parquet-hive/parquet-hive-storage-handler/src/main/java/parquet/hive/DeprecatedParquetOutputFormat.java": [
                0,
                35
            ],
            "parquet-hive/pom.xml": null,
            "parquet-hive/src/main/java/parquet/hive/DeprecatedParquetInputFormat.java": [
                25,
                40
            ],
            "parquet-hive/src/main/java/parquet/hive/DeprecatedParquetOutputFormat.java": [
                8,
                13
            ],
            "parquet-hive/src/main/java/parquet/hive/ManageJobConfig.java": [
                68,
                31
            ],
            "parquet-hive/src/main/java/parquet/hive/convert/ArrayWritableGroupConverter.java": [
                0,
                0
            ],
            "parquet-hive/src/main/java/parquet/hive/convert/DataWritableGroupConverter.java": [
                0,
                0
            ],
            "parquet-hive/src/main/java/parquet/hive/convert/DataWritableRecordConverter.java": [
                0,
                0
            ],
            "parquet-hive/src/main/java/parquet/hive/convert/ETypeConverter.java": [
                0,
                0
            ],
            "parquet-hive/src/main/java/parquet/hive/convert/HiveGroupConverter.java": [
                0,
                0
            ],
            "parquet-hive/src/main/java/parquet/hive/convert/HiveSchemaConverter.java": [
                0,
                0
            ],
            "parquet-hive/src/main/java/parquet/hive/read/DataWritableReadSupport.java": [
                3,
                2
            ],
            "parquet-hive/src/main/java/parquet/hive/serde/AbstractParquetMapInspector.java": [
                0,
                0
            ],
            "parquet-hive/src/main/java/parquet/hive/serde/ArrayWritableObjectInspector.java": [
                0,
                0
            ],
            "parquet-hive/src/main/java/parquet/hive/serde/DeepParquetHiveMapInspector.java": [
                0,
                0
            ],
            "parquet-hive/src/main/java/parquet/hive/serde/ParquetHiveArrayInspector.java": [
                0,
                0
            ],
            "parquet-hive/src/main/java/parquet/hive/serde/ParquetHiveSerDe.java": [
                0,
                0
            ],
            "parquet-hive/src/main/java/parquet/hive/serde/StandardParquetHiveMapInspector.java": [
                0,
                0
            ],
            "parquet-hive/src/main/java/parquet/hive/serde/primitive/ParquetByteInspector.java": [
                0,
                0
            ],
            "parquet-hive/src/main/java/parquet/hive/serde/primitive/ParquetPrimitiveInspectorFactory.java": [
                0,
                0
            ],
            "parquet-hive/src/main/java/parquet/hive/serde/primitive/ParquetShortInspector.java": [
                0,
                0
            ],
            "parquet-hive/src/main/java/parquet/hive/serde/primitive/ParquetStringInspector.java": [
                0,
                0
            ],
            "parquet-hive/src/main/java/parquet/hive/writable/BigDecimalWritable.java": [
                0,
                0
            ],
            "parquet-hive/src/main/java/parquet/hive/writable/BinaryWritable.java": [
                0,
                0
            ],
            "parquet-hive/src/main/java/parquet/hive/write/DataWritableWriteSupport.java": [
                0,
                0
            ],
            "parquet-hive/src/main/java/parquet/hive/write/DataWritableWriter.java": [
                0,
                0
            ],
            "parquet-hive/src/test/java/parquet/hive/TestDeprecatedParquetInputFormat.java": [
                25,
                35
            ],
            "parquet-hive/src/test/java/parquet/hive/TestDeprecatedParquetOuputFormat.java": [
                25,
                27
            ],
            "parquet-hive/src/test/java/parquet/hive/TestHiveSchemaConverter.java": [
                0,
                0
            ],
            "parquet-hive/src/test/java/parquet/hive/TestParquetSerDe.java": [
                0,
                0
            ],
            "parquet-hive/src/test/java/parquet/hive/UtilitiesTestMethods.java": [
                0,
                0
            ]
        }
    },
    "716a030d9cd05b47dd0e78dadb5311ab0594adf6": {
        "datetime": "2013-12-04T16:42:54-08:00",
        "summary": "remove lzo test and lzo dependency",
        "message": "remove lzo test and lzo dependency\n",
        "diff": {
            "parquet-hadoop/pom.xml": null,
            "parquet-hadoop/src/main/java/parquet/hadoop/codec/HadoopCodecConfig.java": [
                19,
                17
            ],
            "parquet-hadoop/src/test/java/parquet/hadoop/codec/MapReduceCodecConfigTest.java": [
                10,
                23
            ]
        }
    },
    "0b61cd9df927e2657712739ba3dd1b7e602f0b25": {
        "datetime": "2013-12-04T17:13:33-08:00",
        "summary": "Merge branch 'not_write_pig_meta_data_only_when_pig_is_not_avaliable' into handle_codec_not_found",
        "message": "Merge branch 'not_write_pig_meta_data_only_when_pig_is_not_avaliable' into handle_codec_not_found\n",
        "diff": {
            "parquet-thrift/src/main/java/parquet/hadoop/thrift/ThriftWriteSupport.java": [
                1,
                16
            ]
        }
    },
    "5a04096a4a09f8ad26ff01be05d20836643f54b9": {
        "datetime": "2013-12-04T22:11:03-08:00",
        "summary": "license header",
        "message": "license header\n",
        "diff": {
            "parquet-hadoop/src/main/java/parquet/hadoop/codec/CompressionCodecNotSupportedException.java": [
                0,
                15
            ],
            "parquet-hadoop/src/test/java/parquet/hadoop/codec/HadoopCodecConfigTest.java": [
                0,
                15
            ]
        }
    },
    "491481e96db9eae8a139466cd6a2a2b6b2fdffe3": {
        "datetime": "2013-12-05T10:53:14-08:00",
        "summary": "Merge pull request #235 from Parquet/not_write_pig_meta_data_only_when_pig_is_not_avaliable",
        "message": "Merge pull request #235 from Parquet/not_write_pig_meta_data_only_when_pig_is_not_avaliable\n\nNot write pig meta data only when pig is not avaliable",
        "diff": {
            "parquet-thrift/src/main/java/parquet/hadoop/thrift/ThriftWriteSupport.java": [
                1,
                16
            ]
        }
    },
    "d920ce2127426c62dbf4ccaa7cd08375dfc39ff7": {
        "datetime": "2013-12-05T11:36:44-08:00",
        "summary": "fix plugin versions",
        "message": "fix plugin versions\n",
        "diff": {
            "pom.xml": null
        }
    },
    "f7b2cd78fc1b8f0c22edf1d5537fe37dc6c28d50": {
        "datetime": "2013-12-05T11:36:53-08:00",
        "summary": "make CodecConfig a factory",
        "message": "make CodecConfig a factory\n",
        "diff": {
            "parquet-hadoop/src/main/java/parquet/hadoop/ParquetOutputFormat.java": [
                2,
                10
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/codec/CompressionCodecNotSupportedException.java": [
                0,
                4
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/codec/HadoopCodecConfig.java": [
                12,
                89
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/codec/MapReduceCodecConfig.java": [
                48,
                0
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/codec/MapredCodecConfig.java": [
                46,
                0
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/mapred/DeprecatedParquetOutputFormat.java": [
                2,
                2
            ],
            "parquet-hadoop/src/test/java/parquet/hadoop/codec/HadoopCodecConfigTest.java": [
                5,
                5
            ]
        }
    },
    "2e3a37018bf9b92224975fab5e2708d6c2c5328b": {
        "datetime": "2013-12-05T11:51:16-08:00",
        "summary": "restore getCompression methods in ParquetOutputFormat for compatibility",
        "message": "restore getCompression methods in ParquetOutputFormat for compatibility\n",
        "diff": {
            "parquet-hadoop/src/main/java/parquet/hadoop/ParquetOutputFormat.java": [
                0,
                8
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/codec/CodecConfig.java": [
                2,
                1
            ]
        }
    },
    "dbf495cb352474b4904ba795138c0f58be45b27f": {
        "datetime": "2013-12-05T11:56:47-08:00",
        "summary": "fix plugin name",
        "message": "fix plugin name\n",
        "diff": {
            "pom.xml": null
        }
    },
    "0b49e8ad5c4d9ac807043e6ba205ca1419c77fb7": {
        "datetime": "2013-12-05T12:19:00-08:00",
        "summary": "update mvn shade plugin instead",
        "message": "update mvn shade plugin instead\n",
        "diff": {
            "pom.xml": null
        }
    },
    "0810736201b3c29044f44b48aa1192288a22f372": {
        "datetime": "2013-12-05T12:34:12-08:00",
        "summary": "fix pom version caused by bad merge",
        "message": "fix pom version caused by bad merge\n",
        "diff": {
            "parquet-hive/parquet-hive-binding/parquet-hive-0.10-binding/pom.xml": null,
            "parquet-hive/parquet-hive-binding/parquet-hive-0.12-binding/pom.xml": null,
            "parquet-hive/parquet-hive-binding/parquet-hive-binding-bundle/pom.xml": null,
            "parquet-hive/parquet-hive-binding/parquet-hive-binding-factory/pom.xml": null,
            "parquet-hive/parquet-hive-binding/parquet-hive-binding-interface/pom.xml": null,
            "parquet-hive/parquet-hive-binding/pom.xml": null,
            "parquet-hive/parquet-hive-storage-handler/pom.xml": null
        }
    },
    "73e3d08ba098febea60840b62c6eeb5b79d96a04": {
        "datetime": "2013-12-05T12:49:07-08:00",
        "summary": "Merge pull request #77 from Parquet/fix_plugin_versions",
        "message": "Merge pull request #77 from Parquet/fix_plugin_versions\n\nfix plugin versions",
        "diff": {
            "pom.xml": null
        }
    },
    "3db0d58db01b1e6b44eb48d6ad38384812f3d09f": {
        "datetime": "2013-12-05T16:02:31-08:00",
        "summary": "Merge pull request #238 from Parquet/fix_version",
        "message": "Merge pull request #238 from Parquet/fix_version\n\nfix pom version caused by bad merge",
        "diff": {
            "parquet-hive/parquet-hive-binding/parquet-hive-0.10-binding/pom.xml": null,
            "parquet-hive/parquet-hive-binding/parquet-hive-0.12-binding/pom.xml": null,
            "parquet-hive/parquet-hive-binding/parquet-hive-binding-bundle/pom.xml": null,
            "parquet-hive/parquet-hive-binding/parquet-hive-binding-factory/pom.xml": null,
            "parquet-hive/parquet-hive-binding/parquet-hive-binding-interface/pom.xml": null,
            "parquet-hive/parquet-hive-binding/pom.xml": null,
            "parquet-hive/parquet-hive-storage-handler/pom.xml": null
        }
    },
    "8958626f6453e828b3fb27a14159f0ef810d6e56": {
        "datetime": "2013-12-05T16:04:25-08:00",
        "summary": "Merge branch 'master' into handle_codec_not_found",
        "message": "Merge branch 'master' into handle_codec_not_found\n",
        "diff": {
            "changelog.sh": null,
            "parquet-cascading/pom.xml": null,
            "parquet-hive-bundle/pom.xml": null,
            "parquet-hive/parquet-hive-binding/parquet-hive-0.10-binding/pom.xml": null,
            "parquet-hive/parquet-hive-binding/parquet-hive-0.12-binding/pom.xml": null,
            "parquet-hive/parquet-hive-binding/parquet-hive-0.12-binding/src/main/java/parquet/hive/internal/Hive012Binding.java": [
                0,
                149
            ],
            "parquet-hive/parquet-hive-binding/parquet-hive-binding-bundle/pom.xml": null,
            "parquet-hive/parquet-hive-binding/parquet-hive-binding-bundle/src/assemble/uberjar.xml": null,
            "parquet-hive/parquet-hive-binding/parquet-hive-binding-factory/pom.xml": null,
            "parquet-hive/parquet-hive-binding/parquet-hive-binding-factory/src/main/java/parquet/hive/HiveBindingFactory.java": [
                0,
                120
            ],
            "parquet-hive/parquet-hive-binding/parquet-hive-binding-factory/src/test/java/parquet/hive/TestHiveBindingFactory.java": [
                0,
                109
            ],
            "parquet-hive/parquet-hive-binding/parquet-hive-binding-interface/pom.xml": null,
            "parquet-hive/parquet-hive-binding/parquet-hive-binding-interface/src/main/java/parquet/hive/HiveBinding.java": [
                0,
                52
            ],
            "parquet-hive/parquet-hive-binding/parquet-hive-binding-interface/src/main/java/parquet/hive/internal/AbstractHiveBinding.java": [
                0,
                36
            ],
            "parquet-hive/parquet-hive-binding/pom.xml": null,
            "parquet-hive/parquet-hive-storage-handler/pom.xml": null,
            "parquet-hive/parquet-hive-storage-handler/src/main/java/parquet/hive/DeprecatedParquetInputFormat.java": [
                0,
                35
            ],
            "parquet-hive/parquet-hive-storage-handler/src/main/java/parquet/hive/DeprecatedParquetOutputFormat.java": [
                0,
                35
            ],
            "parquet-hive/pom.xml": null,
            "parquet-hive/src/main/java/parquet/hive/DeprecatedParquetInputFormat.java": [
                25,
                40
            ],
            "parquet-hive/src/main/java/parquet/hive/DeprecatedParquetOutputFormat.java": [
                8,
                13
            ],
            "parquet-hive/src/main/java/parquet/hive/ManageJobConfig.java": [
                68,
                31
            ],
            "parquet-hive/src/main/java/parquet/hive/convert/ArrayWritableGroupConverter.java": [
                0,
                0
            ],
            "parquet-hive/src/main/java/parquet/hive/convert/DataWritableGroupConverter.java": [
                0,
                0
            ],
            "parquet-hive/src/main/java/parquet/hive/convert/DataWritableRecordConverter.java": [
                0,
                0
            ],
            "parquet-hive/src/main/java/parquet/hive/convert/ETypeConverter.java": [
                0,
                0
            ],
            "parquet-hive/src/main/java/parquet/hive/convert/HiveGroupConverter.java": [
                0,
                0
            ],
            "parquet-hive/src/main/java/parquet/hive/convert/HiveSchemaConverter.java": [
                0,
                0
            ],
            "parquet-hive/src/main/java/parquet/hive/read/DataWritableReadSupport.java": [
                3,
                2
            ],
            "parquet-hive/src/main/java/parquet/hive/serde/AbstractParquetMapInspector.java": [
                0,
                0
            ],
            "parquet-hive/src/main/java/parquet/hive/serde/ArrayWritableObjectInspector.java": [
                0,
                0
            ],
            "parquet-hive/src/main/java/parquet/hive/serde/DeepParquetHiveMapInspector.java": [
                0,
                0
            ],
            "parquet-hive/src/main/java/parquet/hive/serde/ParquetHiveArrayInspector.java": [
                0,
                0
            ],
            "parquet-hive/src/main/java/parquet/hive/serde/ParquetHiveSerDe.java": [
                0,
                0
            ],
            "parquet-hive/src/main/java/parquet/hive/serde/StandardParquetHiveMapInspector.java": [
                0,
                0
            ],
            "parquet-hive/src/main/java/parquet/hive/serde/primitive/ParquetByteInspector.java": [
                0,
                0
            ],
            "parquet-hive/src/main/java/parquet/hive/serde/primitive/ParquetPrimitiveInspectorFactory.java": [
                0,
                0
            ],
            "parquet-hive/src/main/java/parquet/hive/serde/primitive/ParquetShortInspector.java": [
                0,
                0
            ],
            "parquet-hive/src/main/java/parquet/hive/serde/primitive/ParquetStringInspector.java": [
                0,
                0
            ],
            "parquet-hive/src/main/java/parquet/hive/writable/BigDecimalWritable.java": [
                0,
                0
            ],
            "parquet-hive/src/main/java/parquet/hive/writable/BinaryWritable.java": [
                0,
                0
            ],
            "parquet-hive/src/main/java/parquet/hive/write/DataWritableWriteSupport.java": [
                0,
                0
            ],
            "parquet-hive/src/main/java/parquet/hive/write/DataWritableWriter.java": [
                0,
                0
            ],
            "parquet-hive/src/test/java/parquet/hive/TestDeprecatedParquetInputFormat.java": [
                25,
                35
            ],
            "parquet-hive/src/test/java/parquet/hive/TestDeprecatedParquetOuputFormat.java": [
                25,
                27
            ],
            "parquet-hive/src/test/java/parquet/hive/TestHiveSchemaConverter.java": [
                0,
                0
            ],
            "parquet-hive/src/test/java/parquet/hive/TestParquetSerDe.java": [
                0,
                0
            ],
            "parquet-hive/src/test/java/parquet/hive/UtilitiesTestMethods.java": [
                0,
                0
            ],
            "parquet-scrooge/pom.xml": null,
            "pom.xml": null
        }
    },
    "e8796802ad20acc562e77a08a7114f6eb57e9396": {
        "datetime": "2013-12-05T16:36:19-08:00",
        "summary": "Merge pull request #237 from Parquet/handle_codec_not_found",
        "message": "Merge pull request #237 from Parquet/handle_codec_not_found\n\nHandle codec not found",
        "diff": {
            "parquet-hadoop/src/main/java/parquet/hadoop/CodecFactory.java": [
                1,
                1
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/ParquetOutputFormat.java": [
                23,
                6
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/codec/CodecConfig.java": [
                0,
                166
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/codec/CompressionCodecNotSupportedException.java": [
                0,
                33
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/mapred/DeprecatedParquetOutputFormat.java": [
                21,
                5
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/metadata/CompressionCodecName.java": [
                3,
                16
            ],
            "parquet-hadoop/src/test/java/parquet/hadoop/codec/CodecConfigTest.java": [
                0,
                74
            ]
        }
    },
    "92a47b2d9eb76ca3ee0756a934e807b8aa72b49a": {
        "datetime": "2013-12-06T16:18:03+01:00",
        "summary": "Fix hive map and array inspectors with null containers",
        "message": "Fix hive map and array inspectors with null containers\n\n- This can happen if the data was not generated by Hive\n- Also add unit tests on these\n",
        "diff": {
            "parquet-hive/parquet-hive-storage-handler/src/main/java/parquet/hive/serde/AbstractParquetMapInspector.java": [
                1,
                11
            ],
            "parquet-hive/parquet-hive-storage-handler/src/main/java/parquet/hive/serde/DeepParquetHiveMapInspector.java": [
                0,
                5
            ],
            "parquet-hive/parquet-hive-storage-handler/src/main/java/parquet/hive/serde/ParquetHiveArrayInspector.java": [
                3,
                21
            ],
            "parquet-hive/parquet-hive-storage-handler/src/main/java/parquet/hive/serde/StandardParquetHiveMapInspector.java": [
                0,
                5
            ],
            "parquet-hive/parquet-hive-storage-handler/src/test/java/parquet/hive/serde/TestAbstractParquetMapInspector.java": [
                0,
                102
            ],
            "parquet-hive/parquet-hive-storage-handler/src/test/java/parquet/hive/serde/TestDeepParquetHiveMapInspector.java": [
                0,
                94
            ],
            "parquet-hive/parquet-hive-storage-handler/src/test/java/parquet/hive/serde/TestParquetHiveArrayInspector.java": [
                0,
                84
            ],
            "parquet-hive/parquet-hive-storage-handler/src/test/java/parquet/hive/serde/TestStandardParquetHiveMapInspector.java": [
                0,
                92
            ]
        }
    },
    "a39ad4cdf231adaf7ce18c10bce406eea529fc16": {
        "datetime": "2013-12-06T11:38:07-08:00",
        "summary": "fix loader cache",
        "message": "fix loader cache\n",
        "diff": {
            "parquet-pig/src/main/java/parquet/pig/ParquetLoader.java": [
                10,
                10
            ]
        }
    },
    "ca01d15d79f8c6197e38c24fa6543f591f6efdc7": {
        "datetime": "2013-12-06T12:45:55-08:00",
        "summary": "make the cache use a SoftReference",
        "message": "make the cache use a SoftReference\n",
        "diff": {
            "parquet-pig/src/main/java/parquet/pig/ParquetLoader.java": [
                3,
                5
            ]
        }
    },
    "090d5429b346df529993cd4b9bdef051632da764": {
        "datetime": "2013-12-06T13:01:05-08:00",
        "summary": "Update CHANGES.md",
        "message": "Update CHANGES.md",
        "diff": {
            "CHANGES.md": null
        }
    },
    "aca1d8b895fb6f47e1e97e1f0133148ccbe4ab17": {
        "datetime": "2013-12-06T13:06:05-08:00",
        "summary": "Merge pull request #234 from Parquet/optimize_chunk_scan",
        "message": "Merge pull request #234 from Parquet/optimize_chunk_scan\n\noptimize chunk scan; fix compressed size",
        "diff": {
            "parquet-hadoop/src/main/java/parquet/hadoop/ParquetFileReader.java": [
                5,
                38
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/ParquetFileWriter.java": [
                2,
                3
            ]
        }
    },
    "c95cb214f7821a9beb2a065e7c237ea3da67ac4a": {
        "datetime": "2013-12-06T13:07:03-08:00",
        "summary": "Merge pull request #239 from Parquet/hive_fix_null_maps",
        "message": "Merge pull request #239 from Parquet/hive_fix_null_maps\n\nFix hive map and array inspectors with null containers",
        "diff": {
            "parquet-hive/parquet-hive-storage-handler/src/main/java/parquet/hive/serde/AbstractParquetMapInspector.java": [
                1,
                11
            ],
            "parquet-hive/parquet-hive-storage-handler/src/main/java/parquet/hive/serde/DeepParquetHiveMapInspector.java": [
                0,
                5
            ],
            "parquet-hive/parquet-hive-storage-handler/src/main/java/parquet/hive/serde/ParquetHiveArrayInspector.java": [
                3,
                21
            ],
            "parquet-hive/parquet-hive-storage-handler/src/main/java/parquet/hive/serde/StandardParquetHiveMapInspector.java": [
                0,
                5
            ],
            "parquet-hive/parquet-hive-storage-handler/src/test/java/parquet/hive/serde/TestAbstractParquetMapInspector.java": [
                0,
                102
            ],
            "parquet-hive/parquet-hive-storage-handler/src/test/java/parquet/hive/serde/TestDeepParquetHiveMapInspector.java": [
                0,
                94
            ],
            "parquet-hive/parquet-hive-storage-handler/src/test/java/parquet/hive/serde/TestParquetHiveArrayInspector.java": [
                0,
                84
            ],
            "parquet-hive/parquet-hive-storage-handler/src/test/java/parquet/hive/serde/TestStandardParquetHiveMapInspector.java": [
                0,
                92
            ]
        }
    },
    "760367b9fe669ca1a7e75c850a1f455ab1bbbc2c": {
        "datetime": "2013-12-08T16:24:35-06:00",
        "summary": "Update reference to 0.10 in Hive012Binding javadoc and remove some trailing",
        "message": "Update reference to 0.10 in Hive012Binding javadoc and remove some trailing\nwhitespace I noticed when while updating the javadoc.\n",
        "diff": {
            "parquet-hive/parquet-hive-binding/parquet-hive-0.10-binding/src/main/java/parquet/hive/internal/Hive010Binding.java": [
                1,
                1
            ],
            "parquet-hive/parquet-hive-binding/parquet-hive-0.12-binding/src/main/java/parquet/hive/internal/Hive012Binding.java": [
                3,
                3
            ]
        }
    },
    "54308f7fa8ecbfd12de053a4bfb3c2619bff9f9a": {
        "datetime": "2013-12-08T15:54:20-08:00",
        "summary": "Merge pull request #241 from brockn/master",
        "message": "Merge pull request #241 from brockn/master\n\nUpdate reference to 0.10 in Hive012Binding javadoc",
        "diff": {
            "parquet-hive/parquet-hive-binding/parquet-hive-0.10-binding/src/main/java/parquet/hive/internal/Hive010Binding.java": [
                1,
                1
            ],
            "parquet-hive/parquet-hive-binding/parquet-hive-0.12-binding/src/main/java/parquet/hive/internal/Hive012Binding.java": [
                3,
                3
            ]
        }
    },
    "c73754b5dba84452affa8bce9a65a9598d2a20cb": {
        "datetime": "2013-12-09T12:15:58+01:00",
        "summary": "use latest stable release of cascading: 2.5.1",
        "message": "use latest stable release of cascading: 2.5.1\n",
        "diff": {
            "pom.xml": null
        }
    },
    "3f75f0e171be461eda66b2260e45c54df768ce5f": {
        "datetime": "2013-12-09T11:00:49-08:00",
        "summary": "Merge pull request #233 from fs111/master",
        "message": "Merge pull request #233 from fs111/master\n\nuse latest stable release of cascading: 2.5.1",
        "diff": {
            "pom.xml": null
        }
    },
    "bb9d898021d53d879c3b5d6e4d5af3a030f10d0d": {
        "datetime": "2013-12-09T11:29:12-08:00",
        "summary": "Merge pull request #240 from Parquet/fix_loader_cache",
        "message": "Merge pull request #240 from Parquet/fix_loader_cache\n\nfix loader cache",
        "diff": {
            "parquet-pig/src/main/java/parquet/pig/ParquetLoader.java": [
                10,
                12
            ]
        }
    },
    "22282a979ecbaad21d54887954d011d269b05493": {
        "datetime": "2013-12-09T14:21:37-08:00",
        "summary": "upgrade elephant-bird version to 4.3",
        "message": "upgrade elephant-bird version to 4.3\n",
        "diff": {
            "parquet-thrift/pom.xml": null
        }
    },
    "600e7c989fec70f04d619aea16de355c3d3d0e64": {
        "datetime": "2013-12-09T14:22:37-08:00",
        "summary": "Merge pull request #242 from Parquet/upgrade_eb_to_4_3",
        "message": "Merge pull request #242 from Parquet/upgrade_eb_to_4_3\n\nupgrade elephant-bird version to 4.3",
        "diff": {
            "parquet-thrift/pom.xml": null
        }
    },
    "7436d8f44914a8a87e2528990cdc3e7afb070da0": {
        "datetime": "2013-12-09T15:31:45-08:00",
        "summary": "add source to parquet-hive-binding",
        "message": "add source to parquet-hive-binding\n",
        "diff": {
            "parquet-hive/parquet-hive-binding/parquet-hive-binding-bundle/src/main/resources/parquet/bundle": null
        }
    },
    "eb4966f0b0c82683d91ae07a29ecba98e8153313": {
        "datetime": "2013-12-09T15:40:48-08:00",
        "summary": "[maven-release-plugin] prepare release parquet-1.2.9",
        "message": "[maven-release-plugin] prepare release parquet-1.2.9\n",
        "diff": {
            "parquet-avro/pom.xml": null,
            "parquet-cascading/pom.xml": null,
            "parquet-column/pom.xml": null,
            "parquet-common/pom.xml": null,
            "parquet-encoding/pom.xml": null,
            "parquet-generator/pom.xml": null,
            "parquet-hadoop/pom.xml": null,
            "parquet-hive-bundle/pom.xml": null,
            "parquet-hive/parquet-hive-binding/parquet-hive-0.10-binding/pom.xml": null,
            "parquet-hive/parquet-hive-binding/parquet-hive-0.12-binding/pom.xml": null,
            "parquet-hive/parquet-hive-binding/parquet-hive-binding-bundle/pom.xml": null,
            "parquet-hive/parquet-hive-binding/parquet-hive-binding-factory/pom.xml": null,
            "parquet-hive/parquet-hive-binding/parquet-hive-binding-interface/pom.xml": null,
            "parquet-hive/parquet-hive-binding/pom.xml": null,
            "parquet-hive/parquet-hive-storage-handler/pom.xml": null,
            "parquet-hive/pom.xml": null,
            "parquet-pig-bundle/pom.xml": null,
            "parquet-pig/pom.xml": null,
            "parquet-scrooge/pom.xml": null,
            "parquet-test-hadoop2/pom.xml": null,
            "parquet-thrift/pom.xml": null,
            "pom.xml": null
        }
    },
    "a6f140cf076f787afc50c081f2da9cfc0e2f538e": {
        "datetime": "2013-12-09T15:40:52-08:00",
        "summary": "[maven-release-plugin] prepare for next development iteration",
        "message": "[maven-release-plugin] prepare for next development iteration\n",
        "diff": {
            "parquet-avro/pom.xml": null,
            "parquet-cascading/pom.xml": null,
            "parquet-column/pom.xml": null,
            "parquet-common/pom.xml": null,
            "parquet-encoding/pom.xml": null,
            "parquet-generator/pom.xml": null,
            "parquet-hadoop/pom.xml": null,
            "parquet-hive-bundle/pom.xml": null,
            "parquet-hive/parquet-hive-binding/parquet-hive-0.10-binding/pom.xml": null,
            "parquet-hive/parquet-hive-binding/parquet-hive-0.12-binding/pom.xml": null,
            "parquet-hive/parquet-hive-binding/parquet-hive-binding-bundle/pom.xml": null,
            "parquet-hive/parquet-hive-binding/parquet-hive-binding-factory/pom.xml": null,
            "parquet-hive/parquet-hive-binding/parquet-hive-binding-interface/pom.xml": null,
            "parquet-hive/parquet-hive-binding/pom.xml": null,
            "parquet-hive/parquet-hive-storage-handler/pom.xml": null,
            "parquet-hive/pom.xml": null,
            "parquet-pig-bundle/pom.xml": null,
            "parquet-pig/pom.xml": null,
            "parquet-scrooge/pom.xml": null,
            "parquet-test-hadoop2/pom.xml": null,
            "parquet-thrift/pom.xml": null,
            "pom.xml": null
        }
    },
    "e5ed117a3ead25dca2cd17275d675baae9b7f5a3": {
        "datetime": "2013-12-09T16:01:57-08:00",
        "summary": "Update CHANGES.md",
        "message": "Update CHANGES.md",
        "diff": {
            "CHANGES.md": null
        }
    },
    "8e23c246a641f6cd5a5e89a23317111c8178cf60": {
        "datetime": "2013-12-09T16:41:01-08:00",
        "summary": "add parquet cascading integration documentation",
        "message": "add parquet cascading integration documentation\n",
        "diff": {
            "parquet_cascading.md": null
        }
    },
    "9df136c5b134b0012a34d741506519924b463e3d": {
        "datetime": "2013-12-10T11:28:44-08:00",
        "summary": "fix typo",
        "message": "fix typo\n",
        "diff": {
            "parquet_cascading.md": null
        }
    },
    "99798b5915cc45b3db7cd274f22ee0a3405bb54d": {
        "datetime": "2013-12-10T12:21:41-08:00",
        "summary": "fix grammar",
        "message": "fix grammar\n",
        "diff": {
            "parquet_cascading.md": null
        }
    },
    "955cd7eb3a83b78640a36ea441d1001e01fe5b22": {
        "datetime": "2013-12-11T10:53:26-08:00",
        "summary": "plural for records",
        "message": "plural for records\n",
        "diff": {
            "parquet_cascading.md": null
        }
    },
    "847df8f37ba983dd2cb26683023f2f8c324bfa80": {
        "datetime": "2013-12-11T14:01:23-08:00",
        "summary": "fix changelog",
        "message": "fix changelog\n",
        "diff": {
            "CHANGES.md": null,
            "changelog.sh": null
        }
    },
    "59601d78ff6546225e3b2c1a590c410e8a87ab55": {
        "datetime": "2013-12-11T14:24:06-08:00",
        "summary": "Update CHANGES.md",
        "message": "Update CHANGES.md",
        "diff": {
            "CHANGES.md": null
        }
    },
    "a3474811fbed4ee4b87ee03d296a6077f8eca64a": {
        "datetime": "2013-12-11T14:26:09-08:00",
        "summary": "improve changelog",
        "message": "improve changelog\n",
        "diff": {
            "changelog.sh": null
        }
    },
    "17146c31cefd81b5b13eaede7b36296e580546b8": {
        "datetime": "2013-12-11T16:43:00-08:00",
        "summary": "Merge branch 'master' into plumb_original_type",
        "message": "Merge branch 'master' into plumb_original_type\n",
        "diff": {
            "CHANGES.md": null,
            "changelog.sh": null,
            "parquet-avro/pom.xml": null,
            "parquet-cascading/pom.xml": null,
            "parquet-column/pom.xml": null,
            "parquet-common/pom.xml": null,
            "parquet-encoding/pom.xml": null,
            "parquet-generator/pom.xml": null,
            "parquet-hadoop/pom.xml": null,
            "parquet-hadoop/src/main/java/parquet/hadoop/CodecFactory.java": [
                1,
                1
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/ParquetFileReader.java": [
                5,
                38
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/ParquetFileWriter.java": [
                2,
                3
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/ParquetOutputFormat.java": [
                23,
                6
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/codec/CodecConfig.java": [
                0,
                166
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/codec/CompressionCodecNotSupportedException.java": [
                0,
                33
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/mapred/DeprecatedParquetOutputFormat.java": [
                21,
                5
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/metadata/CompressionCodecName.java": [
                3,
                16
            ],
            "parquet-hadoop/src/test/java/parquet/hadoop/codec/CodecConfigTest.java": [
                0,
                74
            ],
            "parquet-hive-bundle/pom.xml": null,
            "parquet-hive/parquet-hive-binding/parquet-hive-0.10-binding/pom.xml": null,
            "parquet-hive/parquet-hive-binding/parquet-hive-0.12-binding/pom.xml": null,
            "parquet-hive/parquet-hive-binding/parquet-hive-0.12-binding/src/main/java/parquet/hive/internal/Hive012Binding.java": [
                0,
                149
            ],
            "parquet-hive/parquet-hive-binding/parquet-hive-binding-bundle/pom.xml": null,
            "parquet-hive/parquet-hive-binding/parquet-hive-binding-bundle/src/assemble/uberjar.xml": null,
            "parquet-hive/parquet-hive-binding/parquet-hive-binding-bundle/src/main/resources/parquet/bundle": null,
            "parquet-hive/parquet-hive-binding/parquet-hive-binding-factory/pom.xml": null,
            "parquet-hive/parquet-hive-binding/parquet-hive-binding-factory/src/main/java/parquet/hive/HiveBindingFactory.java": [
                0,
                120
            ],
            "parquet-hive/parquet-hive-binding/parquet-hive-binding-factory/src/test/java/parquet/hive/TestHiveBindingFactory.java": [
                0,
                109
            ],
            "parquet-hive/parquet-hive-binding/parquet-hive-binding-interface/pom.xml": null,
            "parquet-hive/parquet-hive-binding/parquet-hive-binding-interface/src/main/java/parquet/hive/HiveBinding.java": [
                0,
                52
            ],
            "parquet-hive/parquet-hive-binding/parquet-hive-binding-interface/src/main/java/parquet/hive/internal/AbstractHiveBinding.java": [
                0,
                36
            ],
            "parquet-hive/parquet-hive-binding/pom.xml": null,
            "parquet-hive/parquet-hive-storage-handler/pom.xml": null,
            "parquet-hive/parquet-hive-storage-handler/src/main/java/parquet/hive/DeprecatedParquetInputFormat.java": [
                0,
                35
            ],
            "parquet-hive/parquet-hive-storage-handler/src/main/java/parquet/hive/DeprecatedParquetOutputFormat.java": [
                0,
                35
            ],
            "parquet-hive/parquet-hive-storage-handler/src/test/java/parquet/hive/serde/TestAbstractParquetMapInspector.java": [
                0,
                102
            ],
            "parquet-hive/parquet-hive-storage-handler/src/test/java/parquet/hive/serde/TestDeepParquetHiveMapInspector.java": [
                0,
                94
            ],
            "parquet-hive/parquet-hive-storage-handler/src/test/java/parquet/hive/serde/TestParquetHiveArrayInspector.java": [
                0,
                84
            ],
            "parquet-hive/parquet-hive-storage-handler/src/test/java/parquet/hive/serde/TestStandardParquetHiveMapInspector.java": [
                0,
                92
            ],
            "parquet-hive/pom.xml": null,
            "parquet-hive/src/main/java/parquet/hive/DeprecatedParquetInputFormat.java": [
                25,
                40
            ],
            "parquet-hive/src/main/java/parquet/hive/DeprecatedParquetOutputFormat.java": [
                8,
                13
            ],
            "parquet-hive/src/main/java/parquet/hive/ManageJobConfig.java": [
                68,
                31
            ],
            "parquet-hive/src/main/java/parquet/hive/convert/ArrayWritableGroupConverter.java": [
                0,
                0
            ],
            "parquet-hive/src/main/java/parquet/hive/convert/DataWritableGroupConverter.java": [
                0,
                0
            ],
            "parquet-hive/src/main/java/parquet/hive/convert/DataWritableRecordConverter.java": [
                0,
                0
            ],
            "parquet-hive/src/main/java/parquet/hive/convert/ETypeConverter.java": [
                0,
                0
            ],
            "parquet-hive/src/main/java/parquet/hive/convert/HiveGroupConverter.java": [
                0,
                0
            ],
            "parquet-hive/src/main/java/parquet/hive/convert/HiveSchemaConverter.java": [
                0,
                0
            ],
            "parquet-hive/src/main/java/parquet/hive/read/DataWritableReadSupport.java": [
                3,
                2
            ],
            "parquet-hive/src/main/java/parquet/hive/serde/AbstractParquetMapInspector.java": [
                1,
                11
            ],
            "parquet-hive/src/main/java/parquet/hive/serde/ArrayWritableObjectInspector.java": [
                0,
                0
            ],
            "parquet-hive/src/main/java/parquet/hive/serde/DeepParquetHiveMapInspector.java": [
                0,
                5
            ],
            "parquet-hive/src/main/java/parquet/hive/serde/ParquetHiveArrayInspector.java": [
                3,
                21
            ],
            "parquet-hive/src/main/java/parquet/hive/serde/ParquetHiveSerDe.java": [
                0,
                0
            ],
            "parquet-hive/src/main/java/parquet/hive/serde/StandardParquetHiveMapInspector.java": [
                0,
                5
            ],
            "parquet-hive/src/main/java/parquet/hive/serde/primitive/ParquetByteInspector.java": [
                0,
                0
            ],
            "parquet-hive/src/main/java/parquet/hive/serde/primitive/ParquetPrimitiveInspectorFactory.java": [
                0,
                0
            ],
            "parquet-hive/src/main/java/parquet/hive/serde/primitive/ParquetShortInspector.java": [
                0,
                0
            ],
            "parquet-hive/src/main/java/parquet/hive/serde/primitive/ParquetStringInspector.java": [
                0,
                0
            ],
            "parquet-hive/src/main/java/parquet/hive/writable/BigDecimalWritable.java": [
                0,
                0
            ],
            "parquet-hive/src/main/java/parquet/hive/writable/BinaryWritable.java": [
                0,
                0
            ],
            "parquet-hive/src/main/java/parquet/hive/write/DataWritableWriteSupport.java": [
                0,
                0
            ],
            "parquet-hive/src/main/java/parquet/hive/write/DataWritableWriter.java": [
                0,
                0
            ],
            "parquet-hive/src/test/java/parquet/hive/TestDeprecatedParquetInputFormat.java": [
                25,
                35
            ],
            "parquet-hive/src/test/java/parquet/hive/TestDeprecatedParquetOuputFormat.java": [
                25,
                27
            ],
            "parquet-hive/src/test/java/parquet/hive/TestHiveSchemaConverter.java": [
                0,
                0
            ],
            "parquet-hive/src/test/java/parquet/hive/TestParquetSerDe.java": [
                0,
                0
            ],
            "parquet-hive/src/test/java/parquet/hive/UtilitiesTestMethods.java": [
                0,
                0
            ],
            "parquet-pig-bundle/pom.xml": null,
            "parquet-pig/pom.xml": null,
            "parquet-pig/src/main/java/parquet/pig/ParquetLoader.java": [
                10,
                12
            ],
            "parquet-scrooge/pom.xml": null,
            "parquet-test-hadoop2/pom.xml": null,
            "parquet-thrift/pom.xml": null,
            "parquet-thrift/src/main/java/parquet/hadoop/thrift/ThriftWriteSupport.java": [
                1,
                16
            ],
            "pom.xml": null
        }
    },
    "e2d819c2ae6ab5573606e32f325c0743c6ec0c2f": {
        "datetime": "2013-12-12T16:59:33+01:00",
        "summary": "Loading correct pbClass to ProtoSchemaConverter",
        "message": "Loading correct pbClass to ProtoSchemaConverter\n",
        "diff": {
            "src/main/java/parquet/proto/ProtoWriteSupport.java": [
                3,
                6
            ]
        }
    },
    "08a204ddb8cfda6b41309af911c5a4511fd426df": {
        "datetime": "2013-12-12T17:00:34+01:00",
        "summary": "Depricated init override removed",
        "message": "Depricated init override removed\n",
        "diff": {
            "src/main/java/parquet/proto/ProtoReadSupport.java": [
                4,
                5
            ]
        }
    },
    "83f06463cd68732d282c16bffc0a32e21555d066": {
        "datetime": "2013-12-12T17:05:34+01:00",
        "summary": "pom.xml version 1.2.10-SNAPSHOT",
        "message": "pom.xml version 1.2.10-SNAPSHOT\n",
        "diff": {
            "pom.xml": null
        }
    },
    "051725362f48c5b6490a15ae5241967a81b523f9": {
        "datetime": "2013-12-12T17:09:03+01:00",
        "summary": "TestUtils refactoring",
        "message": "TestUtils refactoring\n",
        "diff": {
            "src/test/java/parquet/proto/ProtoTest.java": [
                1,
                1
            ],
            "src/test/java/parquet/proto/TestUtils.java": [
                4,
                10
            ]
        }
    },
    "c590038425156af6a99f5424d8ccecd4526f071f": {
        "datetime": "2013-12-12T17:13:16+01:00",
        "summary": "Obsolete test removed",
        "message": "Obsolete test removed\n",
        "diff": {
            "src/test/java/parquet/proto/BugHuntingTest.java": [
                54,
                0
            ],
            "src/test/java/parquet/proto/ProtoTest.java": [
                154,
                0
            ],
            "src/test/java/parquet/proto/TestSandbox.java": [
                43,
                0
            ],
            "src/test/resources/TestProtobuf.proto": null
        }
    },
    "aa442465c481d4b599ce11cbe520ccbebd6e0671": {
        "datetime": "2013-12-13T16:44:07-08:00",
        "summary": "[maven-release-plugin] prepare release parquet-format-2.0.0",
        "message": "[maven-release-plugin] prepare release parquet-format-2.0.0\n",
        "diff": {
            "pom.xml": null
        }
    },
    "891cc3ae0809dabad4c4ca32eef5a4431f0cf53e": {
        "datetime": "2013-12-13T16:44:14-08:00",
        "summary": "[maven-release-plugin] prepare for next development iteration",
        "message": "[maven-release-plugin] prepare for next development iteration\n",
        "diff": {
            "pom.xml": null
        }
    },
    "5bb9e8d9a5aa6dbb459e2d7243cfda40f095bb9e": {
        "datetime": "2013-12-13T18:00:43-08:00",
        "summary": "integrate parquet format 2.0",
        "message": "integrate parquet format 2.0\n",
        "diff": {
            "parquet-column/src/main/java/parquet/column/Encoding.java": [
                9,
                25
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/metadata/EncodingList.java": [
                1,
                0
            ],
            "pom.xml": null
        }
    },
    "314ac2b98a8119ee028417f8045ae3c50e488a95": {
        "datetime": "2013-12-14T09:52:35-08:00",
        "summary": "Merge pull request #245 from Parquet/integrate_parquet_format_2",
        "message": "Merge pull request #245 from Parquet/integrate_parquet_format_2\n\nintegrate parquet format 2.0",
        "diff": {
            "parquet-column/src/main/java/parquet/column/Encoding.java": [
                9,
                25
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/metadata/EncodingList.java": [
                1,
                0
            ],
            "pom.xml": null
        }
    },
    "652b0fe0521c5b57c3a61cecf9889d7eac054981": {
        "datetime": "2013-12-14T15:48:56-08:00",
        "summary": "Merge branch 'master' into plumb_original_type",
        "message": "Merge branch 'master' into plumb_original_type\n",
        "diff": {
            "parquet-column/src/main/java/parquet/column/Encoding.java": [
                9,
                25
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/metadata/EncodingList.java": [
                1,
                0
            ],
            "pom.xml": null
        }
    },
    "e36b2f0b4c724cdc610eb3b6879b795fe301f24c": {
        "datetime": "2013-12-15T12:30:22-08:00",
        "summary": "implement error handler",
        "message": "implement error handler\n",
        "diff": {
            "parquet-thrift/src/main/java/parquet/thrift/BufferedProtocolReadToWrite.java": [
                2,
                69
            ],
            "parquet-thrift/src/test/java/parquet/thrift/TestProtocolReadToWrite.java": [
                0,
                65
            ]
        }
    },
    "8269a6f5bd54a80328d77b2c42443c709b373953": {
        "datetime": "2013-12-15T12:31:06-08:00",
        "summary": "handle extra field in data",
        "message": "handle extra field in data\n",
        "diff": {
            "parquet-thrift/src/main/java/parquet/thrift/BufferedProtocolReadToWrite.java": [
                75,
                291
            ],
            "parquet-thrift/src/main/java/parquet/thrift/ProtocolReadToWrite.java": [
                1,
                1
            ],
            "parquet-thrift/src/test/java/parquet/thrift/TestProtocolReadToWrite.java": [
                29,
                33
            ],
            "parquet-thrift/src/test/thrift/compat.thrift": null
        }
    },
    "3d4513f0073de5026e75643a725f9a22bf2f677f": {
        "datetime": "2013-12-15T13:17:14-08:00",
        "summary": "add checkEnum",
        "message": "add checkEnum\n",
        "diff": {
            "parquet-thrift/src/main/java/parquet/thrift/BufferedProtocolReadToWrite.java": [
                17,
                43
            ],
            "parquet-thrift/src/main/java/parquet/thrift/DecodingSchemaMismatchException.java": [
                0,
                12
            ],
            "parquet-thrift/src/test/java/parquet/thrift/TestProtocolReadToWrite.java": [
                0,
                9
            ]
        }
    },
    "564f370e84e3ac920a5f5d2bb160293d64609e73": {
        "datetime": "2013-12-15T13:27:04-08:00",
        "summary": "add tests, fix bug",
        "message": "add tests, fix bug\n",
        "diff": {
            "parquet-thrift/src/main/java/parquet/thrift/BufferedProtocolReadToWrite.java": [
                5,
                2
            ],
            "parquet-thrift/src/test/java/parquet/thrift/TestProtocolReadToWrite.java": [
                50,
                94
            ],
            "parquet-thrift/src/test/thrift/compat.thrift": null
        }
    },
    "da4b7fd73b9c6179b2b521dfce40c96490cf4ec4": {
        "datetime": "2013-12-15T13:32:54-08:00",
        "summary": "refactor",
        "message": "refactor\n",
        "diff": {
            "parquet-thrift/src/main/java/parquet/thrift/BufferedProtocolReadToWrite.java": [
                77,
                105
            ]
        }
    },
    "bdf5d6b57203e2c7b494bd34babcdf8849963185": {
        "datetime": "2013-12-15T18:23:48-08:00",
        "summary": "Merge pull request #187 from davidzchen/plumb_original_type",
        "message": "Merge pull request #187 from davidzchen/plumb_original_type\n\nPlumb OriginalType",
        "diff": {
            "parquet-hadoop/src/main/java/parquet/format/converter/ParquetMetadataConverter.java": [
                5,
                56
            ]
        }
    },
    "f5eb89d45ccbe373534e249d711155d98a0a49de": {
        "datetime": "2013-12-15T18:24:21-08:00",
        "summary": "Merge pull request #244 from Parquet/feature/error_handler",
        "message": "Merge pull request #244 from Parquet/feature/error_handler\n\nFeature/error handler",
        "diff": {
            "parquet-thrift/src/main/java/parquet/thrift/BufferedProtocolReadToWrite.java": [
                115,
                449
            ],
            "parquet-thrift/src/main/java/parquet/thrift/DecodingSchemaMismatchException.java": [
                0,
                12
            ],
            "parquet-thrift/src/main/java/parquet/thrift/ProtocolReadToWrite.java": [
                1,
                1
            ],
            "parquet-thrift/src/test/java/parquet/thrift/TestProtocolReadToWrite.java": [
                7,
                129
            ],
            "parquet-thrift/src/test/thrift/compat.thrift": null
        }
    },
    "e29c2dfa1b92c4daacf242f7003ca5e0bd583aad": {
        "datetime": "2013-12-16T10:50:00-08:00",
        "summary": "fix when field index is greater than zero",
        "message": "fix when field index is greater than zero\n",
        "diff": {
            "parquet-thrift/src/main/java/parquet/thrift/BufferedProtocolReadToWrite.java": [
                2,
                3
            ],
            "parquet-thrift/src/main/java/parquet/thrift/struct/CompatibilityChecker.java": [
                4,
                2
            ],
            "parquet-thrift/src/main/java/parquet/thrift/struct/ThriftType.java": [
                1,
                5
            ],
            "parquet-thrift/src/test/java/parquet/thrift/TestProtocolReadToWrite.java": [
                0,
                32
            ],
            "parquet-thrift/src/test/thrift/test.thrift": null
        }
    },
    "e94b392ede6bb50a158a8df161da88b54f92ff61": {
        "datetime": "2013-12-16T10:53:08-08:00",
        "summary": "format",
        "message": "format\n",
        "diff": {
            "parquet-thrift/src/main/java/parquet/thrift/BufferedProtocolReadToWrite.java": [
                1,
                0
            ]
        }
    },
    "cd00dc8944f768753522ca10930919ba1d8b7161": {
        "datetime": "2013-12-16T11:13:43-08:00",
        "summary": "Merge pull request #247 from Parquet/fix/detect_extra_field_when_index_is_not_start_from_zero",
        "message": "Merge pull request #247 from Parquet/fix/detect_extra_field_when_index_is_not_start_from_zero\n\nfix bug: when field index is greater than zero",
        "diff": {
            "parquet-thrift/src/main/java/parquet/thrift/BufferedProtocolReadToWrite.java": [
                2,
                2
            ],
            "parquet-thrift/src/main/java/parquet/thrift/struct/CompatibilityChecker.java": [
                4,
                2
            ],
            "parquet-thrift/src/main/java/parquet/thrift/struct/ThriftType.java": [
                1,
                5
            ],
            "parquet-thrift/src/test/java/parquet/thrift/TestProtocolReadToWrite.java": [
                0,
                32
            ],
            "parquet-thrift/src/test/thrift/test.thrift": null
        }
    },
    "aad047a8d8a133dbd5ac4970887481b61c4e173e": {
        "datetime": "2013-12-16T11:32:16-08:00",
        "summary": "[maven-release-plugin] prepare release parquet-1.2.10",
        "message": "[maven-release-plugin] prepare release parquet-1.2.10\n",
        "diff": {
            "parquet-avro/pom.xml": null,
            "parquet-cascading/pom.xml": null,
            "parquet-column/pom.xml": null,
            "parquet-common/pom.xml": null,
            "parquet-encoding/pom.xml": null,
            "parquet-generator/pom.xml": null,
            "parquet-hadoop/pom.xml": null,
            "parquet-hive-bundle/pom.xml": null,
            "parquet-hive/parquet-hive-binding/parquet-hive-0.10-binding/pom.xml": null,
            "parquet-hive/parquet-hive-binding/parquet-hive-0.12-binding/pom.xml": null,
            "parquet-hive/parquet-hive-binding/parquet-hive-binding-bundle/pom.xml": null,
            "parquet-hive/parquet-hive-binding/parquet-hive-binding-factory/pom.xml": null,
            "parquet-hive/parquet-hive-binding/parquet-hive-binding-interface/pom.xml": null,
            "parquet-hive/parquet-hive-binding/pom.xml": null,
            "parquet-hive/parquet-hive-storage-handler/pom.xml": null,
            "parquet-hive/pom.xml": null,
            "parquet-pig-bundle/pom.xml": null,
            "parquet-pig/pom.xml": null,
            "parquet-scrooge/pom.xml": null,
            "parquet-test-hadoop2/pom.xml": null,
            "parquet-thrift/pom.xml": null,
            "pom.xml": null
        }
    },
    "5f13c8c20f82eda9229e1b245b9d43f415c14be5": {
        "datetime": "2013-12-16T11:32:20-08:00",
        "summary": "[maven-release-plugin] prepare for next development iteration",
        "message": "[maven-release-plugin] prepare for next development iteration\n",
        "diff": {
            "parquet-avro/pom.xml": null,
            "parquet-cascading/pom.xml": null,
            "parquet-column/pom.xml": null,
            "parquet-common/pom.xml": null,
            "parquet-encoding/pom.xml": null,
            "parquet-generator/pom.xml": null,
            "parquet-hadoop/pom.xml": null,
            "parquet-hive-bundle/pom.xml": null,
            "parquet-hive/parquet-hive-binding/parquet-hive-0.10-binding/pom.xml": null,
            "parquet-hive/parquet-hive-binding/parquet-hive-0.12-binding/pom.xml": null,
            "parquet-hive/parquet-hive-binding/parquet-hive-binding-bundle/pom.xml": null,
            "parquet-hive/parquet-hive-binding/parquet-hive-binding-factory/pom.xml": null,
            "parquet-hive/parquet-hive-binding/parquet-hive-binding-interface/pom.xml": null,
            "parquet-hive/parquet-hive-binding/pom.xml": null,
            "parquet-hive/parquet-hive-storage-handler/pom.xml": null,
            "parquet-hive/pom.xml": null,
            "parquet-pig-bundle/pom.xml": null,
            "parquet-pig/pom.xml": null,
            "parquet-scrooge/pom.xml": null,
            "parquet-test-hadoop2/pom.xml": null,
            "parquet-thrift/pom.xml": null,
            "pom.xml": null
        }
    },
    "0743b60507fe0933dc2d6cfdfb4f769ec3875e60": {
        "datetime": "2013-12-16T11:44:38-08:00",
        "summary": "Update CHANGES.md",
        "message": "Update CHANGES.md",
        "diff": {
            "CHANGES.md": null
        }
    },
    "0a01dae77c560e3309766ddf1a0cae4600d4cc39": {
        "datetime": "2013-12-17T12:18:24+00:00",
        "summary": "Use ContextUtil in tests to avoid dependency on parts of new MR API",
        "message": "Use ContextUtil in tests to avoid dependency on parts of new MR API\nthat are incompatible between MR1 and MR2.\n",
        "diff": {
            "parquet-cascading/src/test/java/parquet/cascading/TestParquetTBaseScheme.java": [
                1,
                2
            ],
            "parquet-cascading/src/test/java/parquet/cascading/TestParquetTupleScheme.java": [
                1,
                2
            ],
            "parquet-hadoop/src/test/java/parquet/hadoop/codec/CodecConfigTest.java": [
                2,
                3
            ],
            "parquet-hive/parquet-hive-storage-handler/src/main/java/parquet/hive/MapredParquetOutputFormat.java": [
                1,
                1
            ],
            "parquet-pig/src/test/java/parquet/pig/PerfTest2.java": [
                4,
                4
            ],
            "parquet-scrooge/src/test/java/parquet/scrooge/ParquetScroogeSchemeTest.java": [
                3,
                3
            ],
            "parquet-thrift/src/test/java/parquet/hadoop/thrift/TestParquetToThriftReadProjection.java": [
                3,
                3
            ],
            "parquet-thrift/src/test/java/parquet/hadoop/thrift/TestThriftToParquetFileWriter.java": [
                2,
                2
            ]
        }
    },
    "0df24f071e70b19aad5e9c45f16a14b379313f5d": {
        "datetime": "2013-12-17T12:19:10+00:00",
        "summary": "Rename ParquetInputFormat#addInputPathRecursively to avoid",
        "message": "Rename ParquetInputFormat#addInputPathRecursively to avoid\nclash with non-static Hadoop 2 method of same name on FileInputFormat.\n",
        "diff": {
            "parquet-hadoop/src/main/java/parquet/hadoop/ParquetInputFormat.java": [
                3,
                3
            ]
        }
    },
    "ea9fd2049243400cd8b75943b3fda56a95295367": {
        "datetime": "2013-12-17T12:19:55+00:00",
        "summary": "Fix syntax error in test that Pig 0.12 complains about.",
        "message": "Fix syntax error in test that Pig 0.12 complains about.\n",
        "diff": {
            "parquet-pig/src/test/java/parquet/pig/TestPigSchemaConverter.java": [
                1,
                1
            ]
        }
    },
    "e83778a2588dfb14e1b225ad5c5cae817291a655": {
        "datetime": "2013-12-17T13:23:10-08:00",
        "summary": "make summary files read in parallel; improve memory footprint of metadata",
        "message": "make summary files read in parallel; improve memory footprint of metadata\n",
        "diff": {
            "parquet-hadoop/src/main/java/parquet/hadoop/ParquetFileReader.java": [
                41,
                65
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/metadata/BlockMetaData.java": [
                1,
                2
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/metadata/ColumnChunkMetaData.java": [
                15,
                15
            ]
        }
    },
    "f21fb3158a92837ea33187335d0c1029f0890cbe": {
        "datetime": "2013-12-17T13:37:01-08:00",
        "summary": "Merge pull request #248 from tomwhite/hadoop-2-compatibility-fixes",
        "message": "Merge pull request #248 from tomwhite/hadoop-2-compatibility-fixes\n\nMore Hadoop 2 compatibility fixes",
        "diff": {
            "parquet-cascading/src/test/java/parquet/cascading/TestParquetTBaseScheme.java": [
                1,
                2
            ],
            "parquet-cascading/src/test/java/parquet/cascading/TestParquetTupleScheme.java": [
                1,
                2
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/ParquetInputFormat.java": [
                3,
                3
            ],
            "parquet-hadoop/src/test/java/parquet/hadoop/codec/CodecConfigTest.java": [
                2,
                3
            ],
            "parquet-hive/parquet-hive-storage-handler/src/main/java/parquet/hive/MapredParquetOutputFormat.java": [
                1,
                1
            ],
            "parquet-pig/src/test/java/parquet/pig/PerfTest2.java": [
                4,
                4
            ],
            "parquet-pig/src/test/java/parquet/pig/TestPigSchemaConverter.java": [
                1,
                1
            ],
            "parquet-scrooge/src/test/java/parquet/scrooge/ParquetScroogeSchemeTest.java": [
                3,
                3
            ],
            "parquet-thrift/src/test/java/parquet/hadoop/thrift/TestParquetToThriftReadProjection.java": [
                3,
                3
            ],
            "parquet-thrift/src/test/java/parquet/hadoop/thrift/TestThriftToParquetFileWriter.java": [
                2,
                2
            ]
        }
    },
    "884a5e5f93aeae33ed35d5c7ff556962ee0d9be1": {
        "datetime": "2013-12-17T15:30:38-08:00",
        "summary": "Merge pull request #243 from Parquet/parquet_cascading_doc",
        "message": "Merge pull request #243 from Parquet/parquet_cascading_doc\n\nadd parquet cascading integration documentation",
        "diff": {
            "parquet_cascading.md": null
        }
    },
    "a34507d54550a794e55cee68d39b483793954561": {
        "datetime": "2013-12-17T15:59:40-08:00",
        "summary": "pretty_print_json_for_compatibility_checker",
        "message": "pretty_print_json_for_compatibility_checker\n",
        "diff": {
            "parquet-thrift/src/main/java/parquet/thrift/struct/CompatibilityRunner.java": [
                1,
                1
            ]
        }
    },
    "18012a0db7e6fac06a36670fc1c2b4050d903e07": {
        "datetime": "2013-12-17T16:03:21-08:00",
        "summary": "Merge pull request #250 from Parquet/pretty_print_json_for_compatibility_checker",
        "message": "Merge pull request #250 from Parquet/pretty_print_json_for_compatibility_checker\n\npretty_print_json_for_compatibility_checker",
        "diff": {
            "parquet-thrift/src/main/java/parquet/thrift/struct/CompatibilityRunner.java": [
                1,
                1
            ]
        }
    },
    "da066e78b8e1dc4e25746f9c12a8445bf28f76b4": {
        "datetime": "2013-12-17T16:15:08-08:00",
        "summary": "[maven-release-plugin] prepare release parquet-1.2.11",
        "message": "[maven-release-plugin] prepare release parquet-1.2.11\n",
        "diff": {
            "parquet-avro/pom.xml": null,
            "parquet-cascading/pom.xml": null,
            "parquet-column/pom.xml": null,
            "parquet-common/pom.xml": null,
            "parquet-encoding/pom.xml": null,
            "parquet-generator/pom.xml": null,
            "parquet-hadoop/pom.xml": null,
            "parquet-hive-bundle/pom.xml": null,
            "parquet-hive/parquet-hive-binding/parquet-hive-0.10-binding/pom.xml": null,
            "parquet-hive/parquet-hive-binding/parquet-hive-0.12-binding/pom.xml": null,
            "parquet-hive/parquet-hive-binding/parquet-hive-binding-bundle/pom.xml": null,
            "parquet-hive/parquet-hive-binding/parquet-hive-binding-factory/pom.xml": null,
            "parquet-hive/parquet-hive-binding/parquet-hive-binding-interface/pom.xml": null,
            "parquet-hive/parquet-hive-binding/pom.xml": null,
            "parquet-hive/parquet-hive-storage-handler/pom.xml": null,
            "parquet-hive/pom.xml": null,
            "parquet-pig-bundle/pom.xml": null,
            "parquet-pig/pom.xml": null,
            "parquet-scrooge/pom.xml": null,
            "parquet-test-hadoop2/pom.xml": null,
            "parquet-thrift/pom.xml": null,
            "pom.xml": null
        }
    },
    "313c300578fd79be6ec60c92ea0c9963dd52c127": {
        "datetime": "2013-12-17T16:15:12-08:00",
        "summary": "[maven-release-plugin] prepare for next development iteration",
        "message": "[maven-release-plugin] prepare for next development iteration\n",
        "diff": {
            "parquet-avro/pom.xml": null,
            "parquet-cascading/pom.xml": null,
            "parquet-column/pom.xml": null,
            "parquet-common/pom.xml": null,
            "parquet-encoding/pom.xml": null,
            "parquet-generator/pom.xml": null,
            "parquet-hadoop/pom.xml": null,
            "parquet-hive-bundle/pom.xml": null,
            "parquet-hive/parquet-hive-binding/parquet-hive-0.10-binding/pom.xml": null,
            "parquet-hive/parquet-hive-binding/parquet-hive-0.12-binding/pom.xml": null,
            "parquet-hive/parquet-hive-binding/parquet-hive-binding-bundle/pom.xml": null,
            "parquet-hive/parquet-hive-binding/parquet-hive-binding-factory/pom.xml": null,
            "parquet-hive/parquet-hive-binding/parquet-hive-binding-interface/pom.xml": null,
            "parquet-hive/parquet-hive-binding/pom.xml": null,
            "parquet-hive/parquet-hive-storage-handler/pom.xml": null,
            "parquet-hive/pom.xml": null,
            "parquet-pig-bundle/pom.xml": null,
            "parquet-pig/pom.xml": null,
            "parquet-scrooge/pom.xml": null,
            "parquet-test-hadoop2/pom.xml": null,
            "parquet-thrift/pom.xml": null,
            "pom.xml": null
        }
    },
    "392a801878836e50d992353910dceb802393a6f5": {
        "datetime": "2013-12-18T14:37:48-08:00",
        "summary": "refactor",
        "message": "refactor\n",
        "diff": {
            "parquet-thrift/src/main/java/parquet/hadoop/thrift/ParquetThriftBytesOutputFormat.java": [
                2,
                4
            ],
            "parquet-thrift/src/main/java/parquet/hadoop/thrift/ThriftBytesWriteSupport.java": [
                2,
                9
            ],
            "parquet-thrift/src/main/java/parquet/hadoop/thrift/ThriftToParquetFileWriter.java": [
                3,
                25
            ],
            "parquet-thrift/src/main/java/parquet/thrift/BufferedProtocolReadToWrite.java": [
                42,
                7
            ],
            "parquet-thrift/src/main/java/parquet/thrift/ReadWriteErrorHandler.java": [
                0,
                39
            ],
            "parquet-thrift/src/test/java/parquet/thrift/TestProtocolReadToWrite.java": [
                83,
                64
            ]
        }
    },
    "0888bdeacf422a6def35239abd69f0ad8b580abc": {
        "datetime": "2013-12-18T15:38:55-08:00",
        "summary": "adress comments",
        "message": "adress comments\n",
        "diff": {
            "parquet-hadoop/src/main/java/parquet/hadoop/ParquetFileReader.java": [
                0,
                1
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/metadata/ColumnChunkMetaData.java": [
                15,
                47
            ]
        }
    },
    "67a7a9d242a4831e8e79a1606c0f7304a802ed6e": {
        "datetime": "2013-12-18T17:01:17-08:00",
        "summary": "Add writer version flag to parquet and make initial changes for supported parquet 2.0 encodings",
        "message": "Add writer version flag to parquet and make initial changes for supported parquet 2.0 encodings\n",
        "diff": {
            "parquet-column/src/main/java/parquet/column/ParquetProperties.java": [
                0,
                119
            ],
            "parquet-column/src/main/java/parquet/column/impl/ColumnWriteStoreImpl.java": [
                2,
                4
            ],
            "parquet-column/src/main/java/parquet/column/impl/ColumnWriterImpl.java": [
                53,
                8
            ],
            "parquet-column/src/test/java/parquet/column/mem/TestMemColumn.java": [
                1,
                3
            ],
            "parquet-column/src/test/java/parquet/io/PerfTest.java": [
                1,
                2
            ],
            "parquet-column/src/test/java/parquet/io/TestColumnIO.java": [
                1,
                3
            ],
            "parquet-column/src/test/java/parquet/io/TestFiltered.java": [
                1,
                2
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/InternalParquetRecordWriter.java": [
                2,
                5
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/ParquetOutputFormat.java": [
                6,
                19
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/ParquetRecordWriter.java": [
                2,
                3
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/ParquetWriter.java": [
                2,
                31
            ],
            "parquet-hive/parquet-hive-storage-handler/src/test/java/parquet/hive/TestMapredParquetInputFormat.java": [
                1,
                2
            ],
            "parquet-pig/src/test/java/parquet/pig/GenerateIntTestFile.java": [
                1,
                2
            ],
            "parquet-pig/src/test/java/parquet/pig/GenerateTPCH.java": [
                1,
                2
            ],
            "parquet-pig/src/test/java/parquet/pig/TupleConsumerPerfTest.java": [
                1,
                2
            ],
            "parquet-thrift/src/test/java/parquet/thrift/TestParquetReadProtocol.java": [
                1,
                2
            ]
        }
    },
    "d185966b8a3ef3cb096e57a8e10c6860b9eabac2": {
        "datetime": "2013-12-18T17:29:59-08:00",
        "summary": "pom version fix",
        "message": "pom version fix\n",
        "diff": {
            "parquet-avro/pom.xml": null,
            "parquet-cascading/pom.xml": null,
            "parquet-column/pom.xml": null,
            "parquet-common/pom.xml": null,
            "parquet-encoding/pom.xml": null,
            "parquet-generator/pom.xml": null,
            "parquet-hadoop/pom.xml": null,
            "parquet-hive-bundle/pom.xml": null,
            "parquet-hive/parquet-hive-binding/parquet-hive-0.10-binding/pom.xml": null,
            "parquet-hive/parquet-hive-binding/parquet-hive-0.12-binding/pom.xml": null,
            "parquet-hive/parquet-hive-binding/parquet-hive-binding-bundle/pom.xml": null,
            "parquet-hive/parquet-hive-binding/parquet-hive-binding-factory/pom.xml": null,
            "parquet-hive/parquet-hive-binding/parquet-hive-binding-interface/pom.xml": null,
            "parquet-hive/parquet-hive-binding/pom.xml": null,
            "parquet-hive/parquet-hive-storage-handler/pom.xml": null,
            "parquet-hive/pom.xml": null,
            "parquet-pig-bundle/pom.xml": null,
            "parquet-pig/pom.xml": null,
            "parquet-scrooge/pom.xml": null,
            "parquet-test-hadoop2/pom.xml": null,
            "parquet-thrift/pom.xml": null,
            "pom.xml": null
        }
    },
    "cf9a3677ac749ed0789be77eb7de70f80b203a2d": {
        "datetime": "2013-12-18T17:31:00-08:00",
        "summary": "Merge pull request #252 from Parquet/refactor_error_handler",
        "message": "Merge pull request #252 from Parquet/refactor_error_handler\n\nrefactor error handler for BufferedProtocolReadToWrite to be non-static",
        "diff": {
            "parquet-thrift/src/main/java/parquet/hadoop/thrift/ParquetThriftBytesOutputFormat.java": [
                2,
                4
            ],
            "parquet-thrift/src/main/java/parquet/hadoop/thrift/ThriftBytesWriteSupport.java": [
                2,
                9
            ],
            "parquet-thrift/src/main/java/parquet/hadoop/thrift/ThriftToParquetFileWriter.java": [
                3,
                25
            ],
            "parquet-thrift/src/main/java/parquet/thrift/BufferedProtocolReadToWrite.java": [
                42,
                7
            ],
            "parquet-thrift/src/main/java/parquet/thrift/ReadWriteErrorHandler.java": [
                0,
                39
            ],
            "parquet-thrift/src/test/java/parquet/thrift/TestProtocolReadToWrite.java": [
                83,
                64
            ]
        }
    },
    "f2e7baae6817aae3440edef23f6379d7270f998f": {
        "datetime": "2013-12-19T11:02:40-06:00",
        "summary": "Resolves issue #251 by doing additional checks if Hive returns \"Unknown\" as a version.",
        "message": "Resolves issue #251 by doing additional checks if Hive returns \"Unknown\" as a version.\n",
        "diff": {
            "parquet-hive/parquet-hive-binding/parquet-hive-binding-factory/src/main/java/parquet/hive/HiveBindingFactory.java": [
                0,
                27
            ],
            "parquet-hive/parquet-hive-binding/parquet-hive-binding-factory/src/test/java/parquet/hive/TestHiveBindingFactory.java": [
                4,
                16
            ]
        }
    },
    "956ad0770b644153317d45c276ec1615c509da5b": {
        "datetime": "2013-12-19T10:58:19-08:00",
        "summary": "Merge pull request #256 from brockn/master",
        "message": "Merge pull request #256 from brockn/master\n\nResolves issue #251 by doing additional checks if Hive returns \"Unknown\" as a version",
        "diff": {
            "parquet-hive/parquet-hive-binding/parquet-hive-binding-factory/src/main/java/parquet/hive/HiveBindingFactory.java": [
                0,
                27
            ],
            "parquet-hive/parquet-hive-binding/parquet-hive-binding-factory/src/test/java/parquet/hive/TestHiveBindingFactory.java": [
                4,
                16
            ]
        }
    },
    "4a18684068266d8f8130e7f1ecf098fc039a672e": {
        "datetime": "2013-12-19T12:15:35-08:00",
        "summary": "changes for code review comments - enum as params, shortname for writerversion",
        "message": "changes for code review comments - enum as params, shortname for writerversion\n",
        "diff": {
            "parquet-column/src/main/java/parquet/column/ParquetProperties.java": [
                9,
                25
            ],
            "parquet-column/src/main/java/parquet/column/impl/ColumnWriteStoreImpl.java": [
                2,
                3
            ],
            "parquet-column/src/main/java/parquet/column/impl/ColumnWriterImpl.java": [
                1,
                2
            ],
            "parquet-column/src/test/java/parquet/column/mem/TestMemColumn.java": [
                1,
                1
            ],
            "parquet-column/src/test/java/parquet/io/PerfTest.java": [
                1,
                1
            ],
            "parquet-column/src/test/java/parquet/io/TestColumnIO.java": [
                1,
                1
            ],
            "parquet-column/src/test/java/parquet/io/TestFiltered.java": [
                1,
                1
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/InternalParquetRecordWriter.java": [
                2,
                3
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/ParquetOutputFormat.java": [
                5,
                3
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/ParquetRecordWriter.java": [
                1,
                3
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/ParquetWriter.java": [
                2,
                2
            ],
            "parquet-hive/parquet-hive-storage-handler/src/test/java/parquet/hive/TestMapredParquetInputFormat.java": [
                1,
                1
            ],
            "parquet-pig/src/test/java/parquet/pig/GenerateIntTestFile.java": [
                1,
                1
            ],
            "parquet-pig/src/test/java/parquet/pig/GenerateTPCH.java": [
                1,
                1
            ],
            "parquet-pig/src/test/java/parquet/pig/TupleConsumerPerfTest.java": [
                1,
                1
            ],
            "parquet-thrift/src/test/java/parquet/thrift/TestParquetReadProtocol.java": [
                1,
                1
            ]
        }
    },
    "f61331e122101a34e5d02fcec0b95d46e3be664a": {
        "datetime": "2013-12-19T14:40:36-06:00",
        "summary": "In HIVE-5783 we will need a bundle jar to depend on that does not include",
        "message": "In HIVE-5783 we will need a bundle jar to depend on that does not include\nthe Hive Serde since Hive trunk will contain the Hive Serde.\n\nThis change introduces such a bundle which would be generally useful\nfor anyone writing Parquet within Hadoop.\n",
        "diff": {
            "parquet-hadoop-bundle/README": null,
            "parquet-hadoop-bundle/pom.xml": null,
            "parquet-hadoop-bundle/src/main/resources/parquet/bundle": null,
            "pom.xml": null
        }
    },
    "a68c8fc97685eab6e1c916f47badedd70a1c0670": {
        "datetime": "2013-12-19T13:33:43-08:00",
        "summary": "Merge pull request #254 from Parquet/parquet_2.0_writer",
        "message": "Merge pull request #254 from Parquet/parquet_2.0_writer\n\nAdd writer version flag to parquet and make initial changes for supported parquet 2.0 encodings",
        "diff": {
            "parquet-column/src/main/java/parquet/column/ParquetProperties.java": [
                0,
                135
            ],
            "parquet-column/src/main/java/parquet/column/impl/ColumnWriteStoreImpl.java": [
                2,
                5
            ],
            "parquet-column/src/main/java/parquet/column/impl/ColumnWriterImpl.java": [
                53,
                9
            ],
            "parquet-column/src/test/java/parquet/column/mem/TestMemColumn.java": [
                1,
                3
            ],
            "parquet-column/src/test/java/parquet/io/PerfTest.java": [
                1,
                2
            ],
            "parquet-column/src/test/java/parquet/io/TestColumnIO.java": [
                1,
                3
            ],
            "parquet-column/src/test/java/parquet/io/TestFiltered.java": [
                1,
                2
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/InternalParquetRecordWriter.java": [
                2,
                6
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/ParquetOutputFormat.java": [
                6,
                17
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/ParquetRecordWriter.java": [
                2,
                5
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/ParquetWriter.java": [
                2,
                31
            ],
            "parquet-hive/parquet-hive-storage-handler/src/test/java/parquet/hive/TestMapredParquetInputFormat.java": [
                1,
                2
            ],
            "parquet-pig/src/test/java/parquet/pig/GenerateIntTestFile.java": [
                1,
                2
            ],
            "parquet-pig/src/test/java/parquet/pig/GenerateTPCH.java": [
                1,
                2
            ],
            "parquet-pig/src/test/java/parquet/pig/TupleConsumerPerfTest.java": [
                1,
                2
            ],
            "parquet-thrift/src/test/java/parquet/thrift/TestParquetReadProtocol.java": [
                1,
                2
            ]
        }
    },
    "c81778533dd1c963f0cf7b8e704afd7c6259907e": {
        "datetime": "2013-12-19T14:31:15-08:00",
        "summary": "delta int bin pack",
        "message": "delta int bin pack\n",
        "diff": {
            "parquet-column/pom.xml": null,
            "parquet-column/src/main/java/parquet/column/Encoding.java": [
                1,
                11
            ],
            "parquet-column/src/main/java/parquet/column/values/delta/DeltaBinaryPackingConfig.java": [
                0,
                54
            ],
            "parquet-column/src/main/java/parquet/column/values/delta/DeltaBinaryPackingValuesReader.java": [
                0,
                167
            ],
            "parquet-column/src/main/java/parquet/column/values/delta/DeltaBinaryPackingValuesWriter.java": [
                0,
                267
            ],
            "parquet-column/src/test/java/parquet/column/values/delta/DeltaBinaryPackingValuesWriterTest.java": [
                0,
                338
            ],
            "parquet-column/src/test/java/parquet/column/values/delta/benchmark/BenchMarkTest.java": [
                0,
                26
            ],
            "parquet-column/src/test/java/parquet/column/values/delta/benchmark/BenchmarkIntegerOutputSize.java": [
                0,
                105
            ],
            "parquet-column/src/test/java/parquet/column/values/delta/benchmark/BenchmarkReadingRandomIntegers.java": [
                0,
                94
            ],
            "parquet-column/src/test/java/parquet/column/values/delta/benchmark/RandomWritingBenchmarkTest.java": [
                0,
                55
            ],
            "parquet-column/src/test/java/parquet/column/values/delta/benchmark/SmallRangeWritingBenchmarkTest.java": [
                0,
                32
            ],
            "parquet-common/src/main/java/parquet/bytes/BytesUtils.java": [
                0,
                16
            ],
            "parquet-encoding/src/main/java/parquet/bytes/BytesInput.java": [
                0,
                37
            ],
            "pom.xml": null
        }
    },
    "d617084a4552621c887b078447de3ab725e47f63": {
        "datetime": "2013-12-19T14:50:43-08:00",
        "summary": "formatting and license header",
        "message": "formatting and license header\n",
        "diff": {
            "parquet-column/src/main/java/parquet/column/values/delta/DeltaBinaryPackingValuesReader.java": [
                3,
                0
            ],
            "parquet-column/src/main/java/parquet/column/values/delta/DeltaBinaryPackingValuesWriter.java": [
                1,
                0
            ],
            "parquet-column/src/test/java/parquet/column/values/delta/DeltaBinaryPackingValuesWriterTest.java": [
                77,
                1
            ],
            "parquet-column/src/test/java/parquet/column/values/delta/benchmark/BenchMarkTest.java": [
                1,
                15
            ],
            "parquet-column/src/test/java/parquet/column/values/delta/benchmark/BenchmarkIntegerOutputSize.java": [
                5,
                0
            ],
            "parquet-column/src/test/java/parquet/column/values/delta/benchmark/BenchmarkReadingRandomIntegers.java": [
                1,
                0
            ],
            "parquet-column/src/test/java/parquet/column/values/delta/benchmark/RandomWritingBenchmarkTest.java": [
                2,
                15
            ],
            "parquet-column/src/test/java/parquet/column/values/delta/benchmark/SmallRangeWritingBenchmarkTest.java": [
                1,
                15
            ]
        }
    },
    "290385c888b05797e5663acbd8f1ce10bc6fb8a6": {
        "datetime": "2013-12-19T14:55:40-08:00",
        "summary": "format",
        "message": "format\n",
        "diff": {
            "parquet-column/src/test/java/parquet/column/values/delta/benchmark/BenchmarkIntegerOutputSize.java": [
                1,
                0
            ],
            "parquet-column/src/test/java/parquet/column/values/delta/benchmark/RandomWritingBenchmarkTest.java": [
                1,
                0
            ],
            "parquet-column/src/test/java/parquet/column/values/delta/benchmark/SmallRangeWritingBenchmarkTest.java": [
                1,
                0
            ]
        }
    },
    "74269e42bca92c8fd531d81b5f3eecf386883ff3": {
        "datetime": "2013-12-19T15:01:11-08:00",
        "summary": "Merge pull request #253 from Parquet/delta_int",
        "message": "Merge pull request #253 from Parquet/delta_int\n\nDelta Binary Packing for Int",
        "diff": {
            "parquet-column/pom.xml": null,
            "parquet-column/src/main/java/parquet/column/Encoding.java": [
                1,
                11
            ],
            "parquet-column/src/main/java/parquet/column/values/delta/DeltaBinaryPackingConfig.java": [
                0,
                54
            ],
            "parquet-column/src/main/java/parquet/column/values/delta/DeltaBinaryPackingValuesReader.java": [
                0,
                164
            ],
            "parquet-column/src/main/java/parquet/column/values/delta/DeltaBinaryPackingValuesWriter.java": [
                0,
                266
            ],
            "parquet-column/src/test/java/parquet/column/values/delta/DeltaBinaryPackingValuesWriterTest.java": [
                0,
                262
            ],
            "parquet-column/src/test/java/parquet/column/values/delta/benchmark/BenchMarkTest.java": [
                0,
                40
            ],
            "parquet-column/src/test/java/parquet/column/values/delta/benchmark/BenchmarkIntegerOutputSize.java": [
                0,
                99
            ],
            "parquet-column/src/test/java/parquet/column/values/delta/benchmark/BenchmarkReadingRandomIntegers.java": [
                0,
                93
            ],
            "parquet-column/src/test/java/parquet/column/values/delta/benchmark/RandomWritingBenchmarkTest.java": [
                0,
                67
            ],
            "parquet-column/src/test/java/parquet/column/values/delta/benchmark/SmallRangeWritingBenchmarkTest.java": [
                0,
                45
            ],
            "parquet-common/src/main/java/parquet/bytes/BytesUtils.java": [
                0,
                16
            ],
            "parquet-encoding/src/main/java/parquet/bytes/BytesInput.java": [
                0,
                37
            ],
            "pom.xml": null
        }
    },
    "978e396663297338a186bac466f5ee7319943c6e": {
        "datetime": "2013-12-20T12:28:27+01:00",
        "summary": "ProtoSchemaConverterUnitTest",
        "message": "ProtoSchemaConverterUnitTest\n",
        "diff": {
            "src/main/java/parquet/proto/ProtoSchemaConverter.java": [
                4,
                18
            ],
            "src/test/java/parquet/proto/ProtoSchemaConverterTest.java": [
                0,
                101
            ],
            "src/test/resources/TestProtobuf.proto": null
        }
    },
    "ffcc0b851f7e8b31f7ce7253e4bb369f133d8f91": {
        "datetime": "2013-12-20T07:09:59-08:00",
        "summary": "Merge pull request #257 from brockn/master",
        "message": "Merge pull request #257 from brockn/master\n\nCreate parquet-hadoop-bundle which will eventually replace parquet-hive-bundle",
        "diff": {
            "parquet-hadoop-bundle/README": null,
            "parquet-hadoop-bundle/pom.xml": null,
            "parquet-hadoop-bundle/src/main/resources/parquet/bundle": null,
            "pom.xml": null
        }
    },
    "273728238acad7800a074b11ad3ef0beb3a4af4d": {
        "datetime": "2013-12-20T11:04:43-08:00",
        "summary": "optimize consecutive row groups scans",
        "message": "optimize consecutive row groups scans\n",
        "diff": {
            "parquet-hadoop/src/main/java/parquet/hadoop/ParquetFileReader.java": [
                90,
                244
            ]
        }
    },
    "a4aef0d55338b1f0b6487e40e7de87170e6a8e26": {
        "datetime": "2013-12-20T11:24:52-08:00",
        "summary": "Initial commit",
        "message": "Initial commit\n",
        "diff": {
            "parquet-jackson/pom.xml": null,
            "pom.xml": null
        }
    },
    "861016bc72b36074ac35c7c8b9f5eea7df87f2ad": {
        "datetime": "2013-12-20T21:55:51+01:00",
        "summary": "Removing hadoop-core dependency conflict",
        "message": "Removing hadoop-core dependency conflict\n",
        "diff": {
            "pom.xml": null
        }
    },
    "dba65be43fd824266f947570ac310775187cef83": {
        "datetime": "2013-12-20T21:59:42+01:00",
        "summary": "tests for Input and Output Formats",
        "message": "tests for Input and Output Formats\n",
        "diff": {
            "src/main/java/parquet/proto/ProtobufferRecordConverter.java": [
                4,
                8
            ],
            "src/test/java/parquet/proto/ProtoInputOutputFormatTest.java": [
                0,
                173
            ],
            "src/test/resources/TestProtobuf.proto": null
        }
    },
    "16b2f7362bfcf64eb23a28933098d32ce19cddaf": {
        "datetime": "2013-12-20T22:10:12+01:00",
        "summary": "ProtoSchemaConverter Code Style",
        "message": "ProtoSchemaConverter Code Style\n",
        "diff": {
            "src/test/java/parquet/proto/ProtoSchemaConverterTest.java": [
                47,
                45
            ]
        }
    },
    "13942364d47d493fe10c66c17644d8284a84cbc7": {
        "datetime": "2013-12-20T22:41:52+01:00",
        "summary": "CodeStyle",
        "message": "CodeStyle\n",
        "diff": {
            "src/main/java/parquet/proto/ProtoParquetOutputFormat.java": [
                2,
                2
            ],
            "src/main/java/parquet/proto/ProtoWriteSupport.java": [
                2,
                2
            ],
            "src/main/java/parquet/proto/ProtobufferRecordConverter.java": [
                1,
                1
            ],
            "src/test/java/parquet/proto/ProtoInputOutputFormatTest.java": [
                13,
                13
            ],
            "src/test/java/parquet/proto/ProtoSchemaConverterTest.java": [
                44,
                43
            ],
            "src/test/java/parquet/proto/TestUtils.java": [
                8,
                15
            ]
        }
    },
    "c1b616132a7625ffb0b7b3230e0738b06b49a1a3": {
        "datetime": "2013-12-20T14:31:27-08:00",
        "summary": "add delta length byte arrays and delta byte arrays encodings",
        "message": "add delta length byte arrays and delta byte arrays encodings\n",
        "diff": {
            "parquet-column/src/main/java/parquet/column/Encoding.java": [
                2,
                28
            ],
            "parquet-column/src/main/java/parquet/column/impl/ColumnReaderImpl.java": [
                3,
                5
            ],
            "parquet-column/src/main/java/parquet/column/values/ValuesReader.java": [
                2,
                11
            ],
            "parquet-column/src/main/java/parquet/column/values/bitpacking/BitPackingValuesReader.java": [
                4,
                9
            ],
            "parquet-column/src/main/java/parquet/column/values/bitpacking/ByteBitPackingValuesReader.java": [
                4,
                9
            ],
            "parquet-column/src/main/java/parquet/column/values/boundedint/BoundedIntValuesReader.java": [
                2,
                8
            ],
            "parquet-column/src/main/java/parquet/column/values/boundedint/ZeroIntegerValuesReader.java": [
                2,
                9
            ],
            "parquet-column/src/main/java/parquet/column/values/delta/DeltaBinaryPackingValuesReader.java": [
                2,
                5
            ],
            "parquet-column/src/main/java/parquet/column/values/deltalengthbytearray/DeltaLengthByteArrayValuesReader.java": [
                0,
                67
            ],
            "parquet-column/src/main/java/parquet/column/values/deltalengthbytearray/DeltaLengthByteArrayValuesWriter.java": [
                0,
                103
            ],
            "parquet-column/src/main/java/parquet/column/values/deltastrings/DeltaByteArrayReader.java": [
                0,
                75
            ],
            "parquet-column/src/main/java/parquet/column/values/deltastrings/DeltaByteArrayWriter.java": [
                0,
                89
            ],
            "parquet-column/src/main/java/parquet/column/values/dictionary/DictionaryValuesReader.java": [
                2,
                1
            ],
            "parquet-column/src/main/java/parquet/column/values/plain/BinaryPlainValuesReader.java": [
                2,
                1
            ],
            "parquet-column/src/main/java/parquet/column/values/plain/BooleanPlainValuesReader.java": [
                2,
                7
            ],
            "parquet-column/src/main/java/parquet/column/values/plain/FixedLenByteArrayPlainValuesReader.java": [
                3,
                1
            ],
            "parquet-column/src/main/java/parquet/column/values/plain/PlainValuesReader.java": [
                11,
                8
            ],
            "parquet-column/src/main/java/parquet/column/values/plain/PlainValuesWriter.java": [
                1,
                0
            ],
            "parquet-column/src/main/java/parquet/column/values/rle/RunLengthBitPackingHybridValuesReader.java": [
                13,
                13
            ],
            "parquet-column/src/main/java/parquet/column/values/rle/RunLengthBitPackingHybridValuesWriter.java": [
                0,
                5
            ],
            "parquet-column/src/test/java/parquet/column/values/RandomStr.java": [
                0,
                53
            ],
            "parquet-column/src/test/java/parquet/column/values/Utils.java": [
                0,
                87
            ],
            "parquet-column/src/test/java/parquet/column/values/boundedint/TestBoundedColumns.java": [
                1,
                2
            ],
            "parquet-column/src/test/java/parquet/column/values/deltalengthbytearray/TestDeltaLengthByteArray.java": [
                0,
                72
            ],
            "parquet-column/src/test/java/parquet/column/values/deltalengthbytearray/benchmark/BenchmarkDeltaLengthByteArray.java": [
                0,
                68
            ],
            "parquet-column/src/test/java/parquet/column/values/deltastrings/TestDeltaByteArray.java": [
                0,
                82
            ],
            "parquet-column/src/test/java/parquet/column/values/deltastrings/benchmark/BenchmarkDeltaByteArray.java": [
                0,
                98
            ]
        }
    },
    "5051acc8d2ba103a7b544383f275c18ad913df7f": {
        "datetime": "2013-12-20T14:33:23-08:00",
        "summary": "fix minor typo in Encoding reader",
        "message": "fix minor typo in Encoding reader\n",
        "diff": {
            "parquet-column/src/main/java/parquet/column/Encoding.java": [
                1,
                2
            ]
        }
    },
    "017d08860a816203d7c4cd92600bb99792327631": {
        "datetime": "2013-12-20T14:41:15-08:00",
        "summary": "minor javadoc changes",
        "message": "minor javadoc changes\n",
        "diff": {
            "parquet-column/src/main/java/parquet/column/values/ValuesReader.java": [
                2,
                2
            ]
        }
    },
    "82b889c0af816ba7be2d59f84d2fac6918304037": {
        "datetime": "2013-12-20T14:55:37-08:00",
        "summary": "Merge pull request #1 from Parquet/master",
        "message": "Merge pull request #1 from Parquet/master\n\nupdate",
        "diff": {
            "CHANGES.md": null,
            "PoweredBy.md": null,
            "README.md": null,
            "changelog.sh": null,
            "parquet-avro/pom.xml": null,
            "parquet-cascading/pom.xml": null,
            "parquet-cascading/src/main/java/parquet/cascading/ParquetTupleScheme.java": [
                2,
                10
            ],
            "parquet-cascading/src/test/java/parquet/cascading/TestParquetTBaseScheme.java": [
                1,
                2
            ],
            "parquet-cascading/src/test/java/parquet/cascading/TestParquetTupleScheme.java": [
                54,
                139
            ],
            "parquet-cascading/src/test/resources/part-m-00000.gz.parquet": null,
            "parquet-column/pom.xml": null,
            "parquet-column/src/main/java/parquet/column/Encoding.java": [
                9,
                35
            ],
            "parquet-column/src/main/java/parquet/column/ParquetProperties.java": [
                0,
                135
            ],
            "parquet-column/src/main/java/parquet/column/impl/ColumnWriteStoreImpl.java": [
                2,
                7
            ],
            "parquet-column/src/main/java/parquet/column/impl/ColumnWriterImpl.java": [
                62,
                16
            ],
            "parquet-column/src/main/java/parquet/column/values/delta/DeltaBinaryPackingConfig.java": [
                0,
                54
            ],
            "parquet-column/src/main/java/parquet/column/values/delta/DeltaBinaryPackingValuesReader.java": [
                0,
                164
            ],
            "parquet-column/src/main/java/parquet/column/values/delta/DeltaBinaryPackingValuesWriter.java": [
                0,
                266
            ],
            "parquet-column/src/main/java/parquet/column/values/dictionary/DictionaryValuesReader.java": [
                2,
                2
            ],
            "parquet-column/src/main/java/parquet/column/values/dictionary/DictionaryValuesWriter.java": [
                66,
                181
            ],
            "parquet-column/src/main/java/parquet/column/values/rle/RunLengthBitPackingHybridDecoder.java": [
                13,
                8
            ],
            "parquet-column/src/main/java/parquet/column/values/rle/RunLengthBitPackingHybridValuesReader.java": [
                2,
                2
            ],
            "parquet-column/src/main/java/parquet/filter/ColumnPredicates.java": [
                0,
                90
            ],
            "parquet-column/src/main/java/parquet/io/api/Binary.java": [
                1,
                22
            ],
            "parquet-column/src/test/java/parquet/column/mem/TestMemColumn.java": [
                4,
                10
            ],
            "parquet-column/src/test/java/parquet/column/values/delta/DeltaBinaryPackingValuesWriterTest.java": [
                0,
                262
            ],
            "parquet-column/src/test/java/parquet/column/values/delta/benchmark/BenchMarkTest.java": [
                0,
                40
            ],
            "parquet-column/src/test/java/parquet/column/values/delta/benchmark/BenchmarkIntegerOutputSize.java": [
                0,
                99
            ],
            "parquet-column/src/test/java/parquet/column/values/delta/benchmark/BenchmarkReadingRandomIntegers.java": [
                0,
                93
            ],
            "parquet-column/src/test/java/parquet/column/values/delta/benchmark/RandomWritingBenchmarkTest.java": [
                0,
                67
            ],
            "parquet-column/src/test/java/parquet/column/values/delta/benchmark/SmallRangeWritingBenchmarkTest.java": [
                0,
                45
            ],
            "parquet-column/src/test/java/parquet/column/values/dictionary/TestDictionary.java": [
                319,
                287
            ],
            "parquet-column/src/test/java/parquet/column/values/rle/RunLengthBitPackingHybridIntegrationTest.java": [
                2,
                3
            ],
            "parquet-column/src/test/java/parquet/column/values/rle/TestRunLengthBitPackingHybridEncoder.java": [
                1,
                1
            ],
            "parquet-column/src/test/java/parquet/io/PerfTest.java": [
                1,
                2
            ],
            "parquet-column/src/test/java/parquet/io/TestColumnIO.java": [
                11,
                16
            ],
            "parquet-column/src/test/java/parquet/io/TestFiltered.java": [
                21,
                92
            ],
            "parquet-common/pom.xml": null,
            "parquet-common/src/main/java/parquet/bytes/BytesUtils.java": [
                0,
                16
            ],
            "parquet-encoding/pom.xml": null,
            "parquet-encoding/src/main/java/parquet/bytes/BytesInput.java": [
                0,
                37
            ],
            "parquet-generator/pom.xml": null,
            "parquet-hadoop-bundle/README": null,
            "parquet-hadoop-bundle/pom.xml": null,
            "parquet-hadoop-bundle/src/main/resources/parquet/bundle": null,
            "parquet-hadoop/pom.xml": null,
            "parquet-hadoop/src/main/java/parquet/format/converter/ParquetMetadataConverter.java": [
                5,
                56
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/CodecFactory.java": [
                1,
                1
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/InternalParquetRecordWriter.java": [
                16,
                26
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/ParquetFileReader.java": [
                5,
                38
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/ParquetFileWriter.java": [
                2,
                3
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/ParquetInputFormat.java": [
                3,
                3
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/ParquetInputSplit.java": [
                4,
                5
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/ParquetOutputFormat.java": [
                38,
                51
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/ParquetRecordWriter.java": [
                2,
                18
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/ParquetWriter.java": [
                5,
                69
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/codec/CodecConfig.java": [
                0,
                166
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/codec/CompressionCodecNotSupportedException.java": [
                0,
                33
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/mapred/DeprecatedParquetInputFormat.java": [
                2,
                6
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/mapred/DeprecatedParquetOutputFormat.java": [
                21,
                5
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/metadata/CompressionCodecName.java": [
                3,
                16
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/metadata/EncodingList.java": [
                1,
                0
            ],
            "parquet-hadoop/src/test/java/parquet/hadoop/codec/CodecConfigTest.java": [
                0,
                75
            ],
            "parquet-hive-bundle/pom.xml": null,
            "parquet-hive-bundle/src/main/resources/parquet/bundle": null,
            "parquet-hive/parquet-hive-binding/parquet-hive-0.10-binding/pom.xml": null,
            "parquet-hive/parquet-hive-binding/parquet-hive-0.12-binding/pom.xml": null,
            "parquet-hive/parquet-hive-binding/parquet-hive-0.12-binding/src/main/java/parquet/hive/internal/Hive012Binding.java": [
                0,
                149
            ],
            "parquet-hive/parquet-hive-binding/parquet-hive-binding-bundle/pom.xml": null,
            "parquet-hive/parquet-hive-binding/parquet-hive-binding-bundle/src/assemble/uberjar.xml": null,
            "parquet-hive/parquet-hive-binding/parquet-hive-binding-bundle/src/main/resources/parquet/bundle": null,
            "parquet-hive/parquet-hive-binding/parquet-hive-binding-factory/pom.xml": null,
            "parquet-hive/parquet-hive-binding/parquet-hive-binding-factory/src/main/java/parquet/hive/HiveBindingFactory.java": [
                0,
                147
            ],
            "parquet-hive/parquet-hive-binding/parquet-hive-binding-factory/src/test/java/parquet/hive/TestHiveBindingFactory.java": [
                0,
                121
            ],
            "parquet-hive/parquet-hive-binding/parquet-hive-binding-interface/pom.xml": null,
            "parquet-hive/parquet-hive-binding/parquet-hive-binding-interface/src/main/java/parquet/hive/HiveBinding.java": [
                0,
                52
            ],
            "parquet-hive/parquet-hive-binding/parquet-hive-binding-interface/src/main/java/parquet/hive/internal/AbstractHiveBinding.java": [
                0,
                36
            ],
            "parquet-hive/parquet-hive-binding/pom.xml": null,
            "parquet-hive/parquet-hive-storage-handler/pom.xml": null,
            "parquet-hive/parquet-hive-storage-handler/src/main/java/parquet/hive/DeprecatedParquetInputFormat.java": [
                0,
                35
            ],
            "parquet-hive/parquet-hive-storage-handler/src/main/java/parquet/hive/DeprecatedParquetOutputFormat.java": [
                0,
                35
            ],
            "parquet-hive/parquet-hive-storage-handler/src/main/java/parquet/hive/convert/ETypeConverter.java": [
                0,
                165
            ],
            "parquet-hive/parquet-hive-storage-handler/src/main/java/parquet/hive/serde/AbstractParquetMapInspector.java": [
                0,
                163
            ],
            "parquet-hive/parquet-hive-storage-handler/src/main/java/parquet/hive/serde/ArrayWritableObjectInspector.java": [
                0,
                224
            ],
            "parquet-hive/parquet-hive-storage-handler/src/main/java/parquet/hive/serde/DeepParquetHiveMapInspector.java": [
                0,
                82
            ],
            "parquet-hive/parquet-hive-storage-handler/src/main/java/parquet/hive/serde/ParquetHiveArrayInspector.java": [
                0,
                185
            ],
            "parquet-hive/parquet-hive-storage-handler/src/main/java/parquet/hive/serde/StandardParquetHiveMapInspector.java": [
                0,
                65
            ],
            "parquet-hive/parquet-hive-storage-handler/src/main/java/parquet/hive/serde/primitive/ParquetByteInspector.java": [
                0,
                59
            ],
            "parquet-hive/parquet-hive-storage-handler/src/main/java/parquet/hive/serde/primitive/ParquetPrimitiveInspectorFactory.java": [
                0,
                32
            ],
            "parquet-hive/parquet-hive-storage-handler/src/main/java/parquet/hive/serde/primitive/ParquetShortInspector.java": [
                0,
                59
            ],
            "parquet-hive/parquet-hive-storage-handler/src/main/java/parquet/hive/serde/primitive/ParquetStringInspector.java": [
                0,
                100
            ],
            "parquet-hive/parquet-hive-storage-handler/src/main/java/parquet/hive/writable/BinaryWritable.java": [
                0,
                98
            ],
            "parquet-hive/parquet-hive-storage-handler/src/test/java/parquet/hive/serde/TestAbstractParquetMapInspector.java": [
                0,
                102
            ],
            "parquet-hive/parquet-hive-storage-handler/src/test/java/parquet/hive/serde/TestDeepParquetHiveMapInspector.java": [
                0,
                94
            ],
            "parquet-hive/parquet-hive-storage-handler/src/test/java/parquet/hive/serde/TestParquetHiveArrayInspector.java": [
                0,
                84
            ],
            "parquet-hive/parquet-hive-storage-handler/src/test/java/parquet/hive/serde/TestStandardParquetHiveMapInspector.java": [
                0,
                92
            ],
            "parquet-hive/pom.xml": null,
            "parquet-hive/src/main/java/parquet/hive/DeprecatedParquetInputFormat.java": [
                32,
                45
            ],
            "parquet-hive/src/main/java/parquet/hive/DeprecatedParquetOutputFormat.java": [
                9,
                14
            ],
            "parquet-hive/src/main/java/parquet/hive/ManageJobConfig.java": [
                68,
                31
            ],
            "parquet-hive/src/main/java/parquet/hive/convert/ArrayWritableGroupConverter.java": [
                0,
                0
            ],
            "parquet-hive/src/main/java/parquet/hive/convert/DataWritableGroupConverter.java": [
                3,
                1
            ],
            "parquet-hive/src/main/java/parquet/hive/convert/DataWritableRecordConverter.java": [
                0,
                0
            ],
            "parquet-hive/src/main/java/parquet/hive/convert/ETypeConverter.java": [
                283,
                0
            ],
            "parquet-hive/src/main/java/parquet/hive/convert/HiveGroupConverter.java": [
                0,
                0
            ],
            "parquet-hive/src/main/java/parquet/hive/convert/HiveSchemaConverter.java": [
                6,
                5
            ],
            "parquet-hive/src/main/java/parquet/hive/read/DataWritableReadSupport.java": [
                29,
                34
            ],
            "parquet-hive/src/main/java/parquet/hive/serde/ArrayWritableObjectInspector.java": [
                313,
                0
            ],
            "parquet-hive/src/main/java/parquet/hive/serde/ParquetHiveArrayInspector.java": [
                144,
                0
            ],
            "parquet-hive/src/main/java/parquet/hive/serde/ParquetHiveMapInspector.java": [
                102,
                0
            ],
            "parquet-hive/src/main/java/parquet/hive/serde/ParquetHiveSerDe.java": [
                1,
                2
            ],
            "parquet-hive/src/main/java/parquet/hive/writable/BigDecimalWritable.java": [
                0,
                0
            ],
            "parquet-hive/src/main/java/parquet/hive/writable/BinaryWritable.java": [
                46,
                0
            ],
            "parquet-hive/src/main/java/parquet/hive/write/DataWritableWriteSupport.java": [
                0,
                0
            ],
            "parquet-hive/src/main/java/parquet/hive/write/DataWritableWriter.java": [
                3,
                2
            ],
            "parquet-hive/src/test/java/parquet/hive/TestDeprecatedParquetInputFormat.java": [
                21,
                117
            ],
            "parquet-hive/src/test/java/parquet/hive/TestDeprecatedParquetOuputFormat.java": [
                25,
                27
            ],
            "parquet-hive/src/test/java/parquet/hive/TestHiveSchemaConverter.java": [
                0,
                0
            ],
            "parquet-hive/src/test/java/parquet/hive/TestParquetSerDe.java": [
                3,
                4
            ],
            "parquet-hive/src/test/java/parquet/hive/UtilitiesTestMethods.java": [
                11,
                43
            ],
            "parquet-pig-bundle/pom.xml": null,
            "parquet-pig/pom.xml": null,
            "parquet-pig/src/main/java/parquet/pig/ParquetLoader.java": [
                10,
                14
            ],
            "parquet-pig/src/main/java/parquet/pig/ParquetStorer.java": [
                3,
                1
            ],
            "parquet-pig/src/main/java/parquet/pig/TupleWriteSupport.java": [
                2,
                20
            ],
            "parquet-pig/src/test/java/parquet/pig/GenerateIntTestFile.java": [
                1,
                2
            ],
            "parquet-pig/src/test/java/parquet/pig/GenerateTPCH.java": [
                1,
                2
            ],
            "parquet-pig/src/test/java/parquet/pig/PerfTest2.java": [
                4,
                4
            ],
            "parquet-pig/src/test/java/parquet/pig/TestPigSchemaConverter.java": [
                1,
                1
            ],
            "parquet-pig/src/test/java/parquet/pig/TestTupleRecordConsumer.java": [
                11,
                9
            ],
            "parquet-pig/src/test/java/parquet/pig/TupleConsumerPerfTest.java": [
                2,
                3
            ],
            "parquet-scrooge/pom.xml": null,
            "parquet-scrooge/src/test/java/parquet/scrooge/ParquetScroogeSchemeTest.java": [
                3,
                3
            ],
            "parquet-test-hadoop2/pom.xml": null,
            "parquet-thrift/pom.xml": null,
            "parquet-thrift/src/main/java/parquet/hadoop/thrift/ParquetThriftBytesOutputFormat.java": [
                2,
                4
            ],
            "parquet-thrift/src/main/java/parquet/hadoop/thrift/ThriftBytesWriteSupport.java": [
                2,
                9
            ],
            "parquet-thrift/src/main/java/parquet/hadoop/thrift/ThriftToParquetFileWriter.java": [
                3,
                25
            ],
            "parquet-thrift/src/main/java/parquet/hadoop/thrift/ThriftWriteSupport.java": [
                1,
                16
            ],
            "parquet-thrift/src/main/java/parquet/thrift/BufferedProtocolReadToWrite.java": [
                116,
                415
            ],
            "parquet-thrift/src/main/java/parquet/thrift/DecodingSchemaMismatchException.java": [
                0,
                12
            ],
            "parquet-thrift/src/main/java/parquet/thrift/ParquetWriteProtocol.java": [
                2,
                7
            ],
            "parquet-thrift/src/main/java/parquet/thrift/ProtocolReadToWrite.java": [
                1,
                1
            ],
            "parquet-thrift/src/main/java/parquet/thrift/ReadWriteErrorHandler.java": [
                0,
                39
            ],
            "parquet-thrift/src/main/java/parquet/thrift/struct/CompatibilityChecker.java": [
                0,
                218
            ],
            "parquet-thrift/src/main/java/parquet/thrift/struct/CompatibilityRunner.java": [
                0,
                96
            ],
            "parquet-thrift/src/main/java/parquet/thrift/struct/ThriftType.java": [
                1,
                5
            ],
            "parquet-thrift/src/test/java/parquet/hadoop/thrift/TestParquetToThriftReadProjection.java": [
                3,
                3
            ],
            "parquet-thrift/src/test/java/parquet/hadoop/thrift/TestThriftToParquetFileWriter.java": [
                2,
                2
            ],
            "parquet-thrift/src/test/java/parquet/thrift/TestParquetReadProtocol.java": [
                1,
                2
            ],
            "parquet-thrift/src/test/java/parquet/thrift/TestParquetWriteProtocol.java": [
                1,
                1
            ],
            "parquet-thrift/src/test/java/parquet/thrift/TestProtocolReadToWrite.java": [
                34,
                169
            ],
            "parquet-thrift/src/test/java/parquet/thrift/struct/CompatibilityCheckerTest.java": [
                0,
                117
            ],
            "parquet-thrift/src/test/thrift/compat.thrift": null,
            "parquet-thrift/src/test/thrift/test.thrift": null,
            "parquet_cascading.md": null,
            "pom.xml": null
        }
    },
    "1f75813a03305c30da1d2f9326affc92e541443a": {
        "datetime": "2013-12-21T00:05:07+01:00",
        "summary": "junit test for enum schema conversion",
        "message": "junit test for enum schema conversion\n",
        "diff": {
            "src/main/java/parquet/proto/converters/ProtoEnumConverter.java": [
                1,
                6
            ],
            "src/test/java/parquet/proto/ProtoSchemaConverterTest.java": [
                1,
                2
            ],
            "src/test/resources/TestProtobuf.proto": null
        }
    },
    "51ca71a63e332e8976649f0631664de808529a25": {
        "datetime": "2013-12-21T00:12:22+01:00",
        "summary": "remove old package info",
        "message": "remove old package info\n",
        "diff": {
            "src/main/java/parquet/proto/package-info.java": [
                89,
                0
            ]
        }
    },
    "52ffcfe6eea65f54b4d06ee5a6680497f4905b2a": {
        "datetime": "2013-12-21T00:14:36+01:00",
        "summary": "remove commented code",
        "message": "remove commented code\n",
        "diff": {
            "src/main/java/parquet/proto/converters/ProtoMessageConverter.java": [
                2,
                1
            ]
        }
    },
    "f2e607efe4683f5a111dafe602951206b6ce4726": {
        "datetime": "2013-12-20T15:37:55-08:00",
        "summary": "add unit test",
        "message": "add unit test\n",
        "diff": {
            "parquet-hadoop/src/test/java/parquet/hadoop/metadata/TestColumnChunkMetaData.java": [
                0,
                64
            ]
        }
    },
    "7def49cdd57d670a87abdf264aef5a461de9610a": {
        "datetime": "2013-12-20T15:53:54-08:00",
        "summary": "Adds parquet-jackson module to jackson-dependent modules",
        "message": "Adds parquet-jackson module to jackson-dependent modules\n",
        "diff": {
            "parquet-hadoop/pom.xml": null,
            "parquet-jackson/pom.xml": null,
            "parquet-pig/pom.xml": null,
            "parquet-scrooge/pom.xml": null,
            "parquet-thrift/pom.xml": null,
            "pom.xml": null
        }
    },
    "3013b9f1ec57db26d9b09ee1981e3881fd65641f": {
        "datetime": "2013-12-20T15:59:13-08:00",
        "summary": "Merge pull request #249 from Parquet/metadata_opt",
        "message": "Merge pull request #249 from Parquet/metadata_opt\n\nmake summary files read in parallel; improve memory footprint of metadata; avoid unnecessary seek",
        "diff": {
            "parquet-hadoop/src/main/java/parquet/hadoop/ParquetFileReader.java": [
                41,
                66
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/metadata/BlockMetaData.java": [
                1,
                2
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/metadata/ColumnChunkMetaData.java": [
                15,
                47
            ],
            "parquet-hadoop/src/test/java/parquet/hadoop/metadata/TestColumnChunkMetaData.java": [
                0,
                64
            ]
        }
    },
    "124f2ed8314083d0c2c642e9efdf1a08cba6f9c1": {
        "datetime": "2013-12-20T16:00:37-08:00",
        "summary": "Merge branch 'master' into optimize_scan",
        "message": "Merge branch 'master' into optimize_scan\n",
        "diff": {
            "parquet-cascading/src/test/java/parquet/cascading/TestParquetTBaseScheme.java": [
                1,
                2
            ],
            "parquet-cascading/src/test/java/parquet/cascading/TestParquetTupleScheme.java": [
                1,
                2
            ],
            "parquet-column/pom.xml": null,
            "parquet-column/src/main/java/parquet/column/Encoding.java": [
                1,
                11
            ],
            "parquet-column/src/main/java/parquet/column/ParquetProperties.java": [
                0,
                135
            ],
            "parquet-column/src/main/java/parquet/column/impl/ColumnWriteStoreImpl.java": [
                2,
                5
            ],
            "parquet-column/src/main/java/parquet/column/impl/ColumnWriterImpl.java": [
                53,
                9
            ],
            "parquet-column/src/main/java/parquet/column/values/delta/DeltaBinaryPackingConfig.java": [
                0,
                54
            ],
            "parquet-column/src/main/java/parquet/column/values/delta/DeltaBinaryPackingValuesReader.java": [
                0,
                164
            ],
            "parquet-column/src/main/java/parquet/column/values/delta/DeltaBinaryPackingValuesWriter.java": [
                0,
                266
            ],
            "parquet-column/src/test/java/parquet/column/mem/TestMemColumn.java": [
                1,
                3
            ],
            "parquet-column/src/test/java/parquet/column/values/delta/DeltaBinaryPackingValuesWriterTest.java": [
                0,
                262
            ],
            "parquet-column/src/test/java/parquet/column/values/delta/benchmark/BenchMarkTest.java": [
                0,
                40
            ],
            "parquet-column/src/test/java/parquet/column/values/delta/benchmark/BenchmarkIntegerOutputSize.java": [
                0,
                99
            ],
            "parquet-column/src/test/java/parquet/column/values/delta/benchmark/BenchmarkReadingRandomIntegers.java": [
                0,
                93
            ],
            "parquet-column/src/test/java/parquet/column/values/delta/benchmark/RandomWritingBenchmarkTest.java": [
                0,
                67
            ],
            "parquet-column/src/test/java/parquet/column/values/delta/benchmark/SmallRangeWritingBenchmarkTest.java": [
                0,
                45
            ],
            "parquet-column/src/test/java/parquet/io/PerfTest.java": [
                1,
                2
            ],
            "parquet-column/src/test/java/parquet/io/TestColumnIO.java": [
                1,
                3
            ],
            "parquet-column/src/test/java/parquet/io/TestFiltered.java": [
                1,
                2
            ],
            "parquet-common/src/main/java/parquet/bytes/BytesUtils.java": [
                0,
                16
            ],
            "parquet-encoding/src/main/java/parquet/bytes/BytesInput.java": [
                0,
                37
            ],
            "parquet-hadoop-bundle/README": null,
            "parquet-hadoop-bundle/pom.xml": null,
            "parquet-hadoop-bundle/src/main/resources/parquet/bundle": null,
            "parquet-hadoop/src/main/java/parquet/hadoop/InternalParquetRecordWriter.java": [
                2,
                6
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/ParquetInputFormat.java": [
                3,
                3
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/ParquetOutputFormat.java": [
                6,
                17
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/ParquetRecordWriter.java": [
                2,
                5
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/ParquetWriter.java": [
                2,
                31
            ],
            "parquet-hadoop/src/test/java/parquet/hadoop/codec/CodecConfigTest.java": [
                2,
                3
            ],
            "parquet-hadoop/src/test/java/parquet/hadoop/metadata/TestColumnChunkMetaData.java": [
                0,
                64
            ],
            "parquet-hive/parquet-hive-binding/parquet-hive-binding-factory/src/main/java/parquet/hive/HiveBindingFactory.java": [
                0,
                27
            ],
            "parquet-hive/parquet-hive-binding/parquet-hive-binding-factory/src/test/java/parquet/hive/TestHiveBindingFactory.java": [
                4,
                16
            ],
            "parquet-hive/parquet-hive-storage-handler/src/main/java/parquet/hive/MapredParquetOutputFormat.java": [
                1,
                1
            ],
            "parquet-hive/parquet-hive-storage-handler/src/test/java/parquet/hive/TestMapredParquetInputFormat.java": [
                1,
                2
            ],
            "parquet-pig/src/test/java/parquet/pig/GenerateIntTestFile.java": [
                1,
                2
            ],
            "parquet-pig/src/test/java/parquet/pig/GenerateTPCH.java": [
                1,
                2
            ],
            "parquet-pig/src/test/java/parquet/pig/PerfTest2.java": [
                4,
                4
            ],
            "parquet-pig/src/test/java/parquet/pig/TestPigSchemaConverter.java": [
                1,
                1
            ],
            "parquet-pig/src/test/java/parquet/pig/TupleConsumerPerfTest.java": [
                1,
                2
            ],
            "parquet-scrooge/src/test/java/parquet/scrooge/ParquetScroogeSchemeTest.java": [
                3,
                3
            ],
            "parquet-thrift/src/main/java/parquet/hadoop/thrift/ParquetThriftBytesOutputFormat.java": [
                2,
                4
            ],
            "parquet-thrift/src/main/java/parquet/hadoop/thrift/ThriftBytesWriteSupport.java": [
                2,
                9
            ],
            "parquet-thrift/src/main/java/parquet/hadoop/thrift/ThriftToParquetFileWriter.java": [
                3,
                25
            ],
            "parquet-thrift/src/main/java/parquet/thrift/BufferedProtocolReadToWrite.java": [
                42,
                7
            ],
            "parquet-thrift/src/main/java/parquet/thrift/ReadWriteErrorHandler.java": [
                0,
                39
            ],
            "parquet-thrift/src/main/java/parquet/thrift/struct/CompatibilityRunner.java": [
                1,
                1
            ],
            "parquet-thrift/src/test/java/parquet/hadoop/thrift/TestParquetToThriftReadProjection.java": [
                3,
                3
            ],
            "parquet-thrift/src/test/java/parquet/hadoop/thrift/TestThriftToParquetFileWriter.java": [
                2,
                2
            ],
            "parquet-thrift/src/test/java/parquet/thrift/TestParquetReadProtocol.java": [
                1,
                2
            ],
            "parquet-thrift/src/test/java/parquet/thrift/TestProtocolReadToWrite.java": [
                83,
                64
            ],
            "parquet_cascading.md": null,
            "pom.xml": null
        }
    },
    "3c91e46cb37600a78532233e888c7f27a42d9fea": {
        "datetime": "2013-12-20T16:05:34-08:00",
        "summary": "refactor dictionary page handling",
        "message": "refactor dictionary page handling\n",
        "diff": {
            "parquet-hadoop/src/main/java/parquet/hadoop/ParquetFileReader.java": [
                7,
                7
            ]
        }
    },
    "dc7addc32651005e67e7d50b70247ec1127e3304": {
        "datetime": "2013-12-20T16:18:58-08:00",
        "summary": "update with correct junit imports",
        "message": "update with correct junit imports\n",
        "diff": {
            "parquet-column/src/test/java/parquet/column/values/delta/DeltaBinaryPackingValuesWriterTest.java": [
                3,
                1
            ],
            "parquet-column/src/test/java/parquet/column/values/deltalengthbytearray/TestDeltaLengthByteArray.java": [
                2,
                1
            ],
            "parquet-column/src/test/java/parquet/column/values/deltastrings/TestDeltaByteArray.java": [
                2,
                1
            ],
            "parquet-hadoop/src/test/java/parquet/hadoop/codec/CodecConfigTest.java": [
                2,
                1
            ],
            "parquet-pig/src/main/java/parquet/pig/ParquetLoader.java": [
                1,
                0
            ],
            "parquet-pig/src/main/java/parquet/pig/TupleReadSupport.java": [
                4,
                0
            ],
            "parquet-pig/src/test/java/parquet/pig/TestParquetLoader.java": [
                1,
                5
            ],
            "parquet-pig/src/test/java/parquet/pig/TestPigSchemaConverter.java": [
                4,
                0
            ]
        }
    },
    "30adb12691698730c23247d4218f75ab2e0687ac": {
        "datetime": "2013-12-20T16:21:04-08:00",
        "summary": "Adds small comment",
        "message": "Adds small comment\n",
        "diff": {
            "pom.xml": null
        }
    },
    "9af41250a6852df1a0705c23b3655f0e504f3b6f": {
        "datetime": "2013-12-20T16:26:44-08:00",
        "summary": "turn on parquet 2.0 flags",
        "message": "turn on parquet 2.0 flags\n",
        "diff": {
            "parquet-column/src/main/java/parquet/column/ParquetProperties.java": [
                6,
                4
            ],
            "parquet-column/src/test/java/parquet/column/values/delta/DeltaBinaryPackingValuesWriterTest.java": [
                6,
                5
            ]
        }
    },
    "e91cda90fabda87d82a14708422933e2f9b44ab7": {
        "datetime": "2013-12-20T16:42:52-08:00",
        "summary": "Merge pull request #259 from Parquet/delta_strings",
        "message": "Merge pull request #259 from Parquet/delta_strings\n\nadd delta length byte arrays and delta byte arrays encodings",
        "diff": {
            "parquet-column/src/main/java/parquet/column/Encoding.java": [
                2,
                29
            ],
            "parquet-column/src/main/java/parquet/column/ParquetProperties.java": [
                6,
                4
            ],
            "parquet-column/src/main/java/parquet/column/impl/ColumnReaderImpl.java": [
                3,
                5
            ],
            "parquet-column/src/main/java/parquet/column/values/ValuesReader.java": [
                2,
                11
            ],
            "parquet-column/src/main/java/parquet/column/values/bitpacking/BitPackingValuesReader.java": [
                4,
                9
            ],
            "parquet-column/src/main/java/parquet/column/values/bitpacking/ByteBitPackingValuesReader.java": [
                4,
                9
            ],
            "parquet-column/src/main/java/parquet/column/values/boundedint/BoundedIntValuesReader.java": [
                2,
                8
            ],
            "parquet-column/src/main/java/parquet/column/values/boundedint/ZeroIntegerValuesReader.java": [
                2,
                9
            ],
            "parquet-column/src/main/java/parquet/column/values/delta/DeltaBinaryPackingValuesReader.java": [
                2,
                5
            ],
            "parquet-column/src/main/java/parquet/column/values/deltalengthbytearray/DeltaLengthByteArrayValuesReader.java": [
                0,
                67
            ],
            "parquet-column/src/main/java/parquet/column/values/deltalengthbytearray/DeltaLengthByteArrayValuesWriter.java": [
                0,
                103
            ],
            "parquet-column/src/main/java/parquet/column/values/deltastrings/DeltaByteArrayReader.java": [
                0,
                75
            ],
            "parquet-column/src/main/java/parquet/column/values/deltastrings/DeltaByteArrayWriter.java": [
                0,
                89
            ],
            "parquet-column/src/main/java/parquet/column/values/dictionary/DictionaryValuesReader.java": [
                2,
                1
            ],
            "parquet-column/src/main/java/parquet/column/values/plain/BinaryPlainValuesReader.java": [
                2,
                1
            ],
            "parquet-column/src/main/java/parquet/column/values/plain/BooleanPlainValuesReader.java": [
                2,
                7
            ],
            "parquet-column/src/main/java/parquet/column/values/plain/FixedLenByteArrayPlainValuesReader.java": [
                3,
                1
            ],
            "parquet-column/src/main/java/parquet/column/values/plain/PlainValuesReader.java": [
                11,
                8
            ],
            "parquet-column/src/main/java/parquet/column/values/plain/PlainValuesWriter.java": [
                1,
                0
            ],
            "parquet-column/src/main/java/parquet/column/values/rle/RunLengthBitPackingHybridValuesReader.java": [
                13,
                13
            ],
            "parquet-column/src/main/java/parquet/column/values/rle/RunLengthBitPackingHybridValuesWriter.java": [
                0,
                5
            ],
            "parquet-column/src/test/java/parquet/column/values/RandomStr.java": [
                0,
                53
            ],
            "parquet-column/src/test/java/parquet/column/values/Utils.java": [
                0,
                87
            ],
            "parquet-column/src/test/java/parquet/column/values/boundedint/TestBoundedColumns.java": [
                1,
                2
            ],
            "parquet-column/src/test/java/parquet/column/values/delta/DeltaBinaryPackingValuesWriterTest.java": [
                9,
                6
            ],
            "parquet-column/src/test/java/parquet/column/values/deltalengthbytearray/TestDeltaLengthByteArray.java": [
                0,
                71
            ],
            "parquet-column/src/test/java/parquet/column/values/deltalengthbytearray/benchmark/BenchmarkDeltaLengthByteArray.java": [
                0,
                68
            ],
            "parquet-column/src/test/java/parquet/column/values/deltastrings/TestDeltaByteArray.java": [
                0,
                81
            ],
            "parquet-column/src/test/java/parquet/column/values/deltastrings/benchmark/BenchmarkDeltaByteArray.java": [
                0,
                98
            ],
            "parquet-hadoop/src/test/java/parquet/hadoop/codec/CodecConfigTest.java": [
                2,
                1
            ],
            "parquet-pig/src/main/java/parquet/pig/ParquetLoader.java": [
                1,
                0
            ],
            "parquet-pig/src/main/java/parquet/pig/TupleReadSupport.java": [
                4,
                0
            ],
            "parquet-pig/src/test/java/parquet/pig/TestParquetLoader.java": [
                1,
                5
            ],
            "parquet-pig/src/test/java/parquet/pig/TestPigSchemaConverter.java": [
                4,
                0
            ]
        }
    },
    "2b80e47b6346d4f34dacd0d6314ab6bea80fe6d7": {
        "datetime": "2013-12-20T16:55:54-08:00",
        "summary": "Merge branch 'master' into add-parquet-jackson-module",
        "message": "Merge branch 'master' into add-parquet-jackson-module\n",
        "diff": {
            "parquet-cascading/src/test/java/parquet/cascading/TestParquetTBaseScheme.java": [
                1,
                2
            ],
            "parquet-cascading/src/test/java/parquet/cascading/TestParquetTupleScheme.java": [
                1,
                2
            ],
            "parquet-column/pom.xml": null,
            "parquet-column/src/main/java/parquet/column/Encoding.java": [
                3,
                40
            ],
            "parquet-column/src/main/java/parquet/column/ParquetProperties.java": [
                0,
                133
            ],
            "parquet-column/src/main/java/parquet/column/impl/ColumnReaderImpl.java": [
                3,
                5
            ],
            "parquet-column/src/main/java/parquet/column/impl/ColumnWriteStoreImpl.java": [
                2,
                5
            ],
            "parquet-column/src/main/java/parquet/column/impl/ColumnWriterImpl.java": [
                53,
                9
            ],
            "parquet-column/src/main/java/parquet/column/values/ValuesReader.java": [
                2,
                11
            ],
            "parquet-column/src/main/java/parquet/column/values/bitpacking/BitPackingValuesReader.java": [
                4,
                9
            ],
            "parquet-column/src/main/java/parquet/column/values/bitpacking/ByteBitPackingValuesReader.java": [
                4,
                9
            ],
            "parquet-column/src/main/java/parquet/column/values/boundedint/BoundedIntValuesReader.java": [
                2,
                8
            ],
            "parquet-column/src/main/java/parquet/column/values/boundedint/ZeroIntegerValuesReader.java": [
                2,
                9
            ],
            "parquet-column/src/main/java/parquet/column/values/delta/DeltaBinaryPackingConfig.java": [
                0,
                54
            ],
            "parquet-column/src/main/java/parquet/column/values/delta/DeltaBinaryPackingValuesReader.java": [
                0,
                167
            ],
            "parquet-column/src/main/java/parquet/column/values/delta/DeltaBinaryPackingValuesWriter.java": [
                0,
                266
            ],
            "parquet-column/src/main/java/parquet/column/values/deltalengthbytearray/DeltaLengthByteArrayValuesReader.java": [
                0,
                67
            ],
            "parquet-column/src/main/java/parquet/column/values/deltalengthbytearray/DeltaLengthByteArrayValuesWriter.java": [
                0,
                103
            ],
            "parquet-column/src/main/java/parquet/column/values/deltastrings/DeltaByteArrayReader.java": [
                0,
                75
            ],
            "parquet-column/src/main/java/parquet/column/values/deltastrings/DeltaByteArrayWriter.java": [
                0,
                89
            ],
            "parquet-column/src/main/java/parquet/column/values/dictionary/DictionaryValuesReader.java": [
                2,
                1
            ],
            "parquet-column/src/main/java/parquet/column/values/plain/BinaryPlainValuesReader.java": [
                2,
                1
            ],
            "parquet-column/src/main/java/parquet/column/values/plain/BooleanPlainValuesReader.java": [
                2,
                7
            ],
            "parquet-column/src/main/java/parquet/column/values/plain/FixedLenByteArrayPlainValuesReader.java": [
                3,
                1
            ],
            "parquet-column/src/main/java/parquet/column/values/plain/PlainValuesReader.java": [
                11,
                8
            ],
            "parquet-column/src/main/java/parquet/column/values/plain/PlainValuesWriter.java": [
                1,
                0
            ],
            "parquet-column/src/main/java/parquet/column/values/rle/RunLengthBitPackingHybridValuesReader.java": [
                13,
                13
            ],
            "parquet-column/src/main/java/parquet/column/values/rle/RunLengthBitPackingHybridValuesWriter.java": [
                0,
                5
            ],
            "parquet-column/src/test/java/parquet/column/mem/TestMemColumn.java": [
                1,
                3
            ],
            "parquet-column/src/test/java/parquet/column/values/RandomStr.java": [
                0,
                53
            ],
            "parquet-column/src/test/java/parquet/column/values/Utils.java": [
                0,
                87
            ],
            "parquet-column/src/test/java/parquet/column/values/boundedint/TestBoundedColumns.java": [
                1,
                2
            ],
            "parquet-column/src/test/java/parquet/column/values/delta/DeltaBinaryPackingValuesWriterTest.java": [
                0,
                259
            ],
            "parquet-column/src/test/java/parquet/column/values/delta/benchmark/BenchMarkTest.java": [
                0,
                40
            ],
            "parquet-column/src/test/java/parquet/column/values/delta/benchmark/BenchmarkIntegerOutputSize.java": [
                0,
                99
            ],
            "parquet-column/src/test/java/parquet/column/values/delta/benchmark/BenchmarkReadingRandomIntegers.java": [
                0,
                93
            ],
            "parquet-column/src/test/java/parquet/column/values/delta/benchmark/RandomWritingBenchmarkTest.java": [
                0,
                67
            ],
            "parquet-column/src/test/java/parquet/column/values/delta/benchmark/SmallRangeWritingBenchmarkTest.java": [
                0,
                45
            ],
            "parquet-column/src/test/java/parquet/column/values/deltalengthbytearray/TestDeltaLengthByteArray.java": [
                0,
                71
            ],
            "parquet-column/src/test/java/parquet/column/values/deltalengthbytearray/benchmark/BenchmarkDeltaLengthByteArray.java": [
                0,
                68
            ],
            "parquet-column/src/test/java/parquet/column/values/deltastrings/TestDeltaByteArray.java": [
                0,
                81
            ],
            "parquet-column/src/test/java/parquet/column/values/deltastrings/benchmark/BenchmarkDeltaByteArray.java": [
                0,
                98
            ],
            "parquet-column/src/test/java/parquet/io/PerfTest.java": [
                1,
                2
            ],
            "parquet-column/src/test/java/parquet/io/TestColumnIO.java": [
                1,
                3
            ],
            "parquet-column/src/test/java/parquet/io/TestFiltered.java": [
                1,
                2
            ],
            "parquet-common/src/main/java/parquet/bytes/BytesUtils.java": [
                0,
                16
            ],
            "parquet-encoding/src/main/java/parquet/bytes/BytesInput.java": [
                0,
                37
            ],
            "parquet-hadoop-bundle/README": null,
            "parquet-hadoop-bundle/pom.xml": null,
            "parquet-hadoop-bundle/src/main/resources/parquet/bundle": null,
            "parquet-hadoop/src/main/java/parquet/hadoop/InternalParquetRecordWriter.java": [
                2,
                6
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/ParquetFileReader.java": [
                41,
                66
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/ParquetInputFormat.java": [
                3,
                3
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/ParquetOutputFormat.java": [
                6,
                17
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/ParquetRecordWriter.java": [
                2,
                5
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/ParquetWriter.java": [
                2,
                31
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/metadata/BlockMetaData.java": [
                1,
                2
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/metadata/ColumnChunkMetaData.java": [
                15,
                47
            ],
            "parquet-hadoop/src/test/java/parquet/hadoop/codec/CodecConfigTest.java": [
                4,
                4
            ],
            "parquet-hadoop/src/test/java/parquet/hadoop/metadata/TestColumnChunkMetaData.java": [
                0,
                64
            ],
            "parquet-hive/parquet-hive-binding/parquet-hive-binding-factory/src/main/java/parquet/hive/HiveBindingFactory.java": [
                0,
                27
            ],
            "parquet-hive/parquet-hive-binding/parquet-hive-binding-factory/src/test/java/parquet/hive/TestHiveBindingFactory.java": [
                4,
                16
            ],
            "parquet-hive/parquet-hive-storage-handler/src/main/java/parquet/hive/MapredParquetOutputFormat.java": [
                1,
                1
            ],
            "parquet-hive/parquet-hive-storage-handler/src/test/java/parquet/hive/TestMapredParquetInputFormat.java": [
                1,
                2
            ],
            "parquet-pig/src/main/java/parquet/pig/ParquetLoader.java": [
                1,
                0
            ],
            "parquet-pig/src/main/java/parquet/pig/TupleReadSupport.java": [
                4,
                0
            ],
            "parquet-pig/src/test/java/parquet/pig/GenerateIntTestFile.java": [
                1,
                2
            ],
            "parquet-pig/src/test/java/parquet/pig/GenerateTPCH.java": [
                1,
                2
            ],
            "parquet-pig/src/test/java/parquet/pig/PerfTest2.java": [
                4,
                4
            ],
            "parquet-pig/src/test/java/parquet/pig/TestParquetLoader.java": [
                1,
                5
            ],
            "parquet-pig/src/test/java/parquet/pig/TestPigSchemaConverter.java": [
                5,
                1
            ],
            "parquet-pig/src/test/java/parquet/pig/TupleConsumerPerfTest.java": [
                1,
                2
            ],
            "parquet-scrooge/src/test/java/parquet/scrooge/ParquetScroogeSchemeTest.java": [
                3,
                3
            ],
            "parquet-thrift/src/main/java/parquet/hadoop/thrift/ParquetThriftBytesOutputFormat.java": [
                2,
                4
            ],
            "parquet-thrift/src/main/java/parquet/hadoop/thrift/ThriftBytesWriteSupport.java": [
                2,
                9
            ],
            "parquet-thrift/src/main/java/parquet/hadoop/thrift/ThriftToParquetFileWriter.java": [
                3,
                25
            ],
            "parquet-thrift/src/main/java/parquet/thrift/BufferedProtocolReadToWrite.java": [
                42,
                7
            ],
            "parquet-thrift/src/main/java/parquet/thrift/ReadWriteErrorHandler.java": [
                0,
                39
            ],
            "parquet-thrift/src/main/java/parquet/thrift/struct/CompatibilityRunner.java": [
                1,
                1
            ],
            "parquet-thrift/src/test/java/parquet/hadoop/thrift/TestParquetToThriftReadProjection.java": [
                3,
                3
            ],
            "parquet-thrift/src/test/java/parquet/hadoop/thrift/TestThriftToParquetFileWriter.java": [
                2,
                2
            ],
            "parquet-thrift/src/test/java/parquet/thrift/TestParquetReadProtocol.java": [
                1,
                2
            ],
            "parquet-thrift/src/test/java/parquet/thrift/TestProtocolReadToWrite.java": [
                83,
                64
            ],
            "parquet_cascading.md": null,
            "pom.xml": null
        }
    },
    "cc8375c1c708dfbcfbd02207129bbd9a8b5756a4": {
        "datetime": "2013-12-20T16:58:27-08:00",
        "summary": "Merge pull request #258 from Parquet/optimize_scan",
        "message": "Merge pull request #258 from Parquet/optimize_scan\n\nOptimize scan",
        "diff": {
            "parquet-hadoop/src/main/java/parquet/hadoop/ParquetFileReader.java": [
                90,
                244
            ]
        }
    },
    "1e69167860dc5bd80e4a3939e64a3a364acd6b91": {
        "datetime": "2013-12-20T17:00:43-08:00",
        "summary": "Renames jackson.shade.prefix property into shade.prefix",
        "message": "Renames jackson.shade.prefix property into shade.prefix\n",
        "diff": {
            "parquet-jackson/pom.xml": null,
            "pom.xml": null
        }
    },
    "8926033d70d6b87b06398a8f7b705997901b8f8d": {
        "datetime": "2013-12-20T17:01:05-08:00",
        "summary": "Replaces org.codehaus.jackson groupId with corresponding maven property",
        "message": "Replaces org.codehaus.jackson groupId with corresponding maven property\n",
        "diff": {
            "parquet-hadoop/pom.xml": null,
            "parquet-pig/pom.xml": null,
            "parquet-scrooge/pom.xml": null,
            "parquet-thrift/pom.xml": null
        }
    },
    "1ef3e9fdca48af35e868a2b88a5619f1e57f0240": {
        "datetime": "2013-12-20T17:33:25-08:00",
        "summary": "Adds README with some explanations",
        "message": "Adds README with some explanations\n",
        "diff": {
            "parquet-jackson/README.md": null
        }
    },
    "ee6d882274e81a433b0a7d0f45e571cde46107ea": {
        "datetime": "2013-12-23T09:48:54-08:00",
        "summary": "Renames jackson.shade.prefix property to shade.prefix (part2)",
        "message": "Renames jackson.shade.prefix property to shade.prefix (part2)\n",
        "diff": {
            "pom.xml": null
        }
    },
    "87864cbd1f0ce52d4e357c02ca522f5309061caa": {
        "datetime": "2013-12-23T10:57:56-08:00",
        "summary": "[maven-release-plugin] prepare release parquet-1.3.0",
        "message": "[maven-release-plugin] prepare release parquet-1.3.0\n",
        "diff": {
            "parquet-avro/pom.xml": null,
            "parquet-cascading/pom.xml": null,
            "parquet-column/pom.xml": null,
            "parquet-common/pom.xml": null,
            "parquet-encoding/pom.xml": null,
            "parquet-generator/pom.xml": null,
            "parquet-hadoop-bundle/pom.xml": null,
            "parquet-hadoop/pom.xml": null,
            "parquet-hive-bundle/pom.xml": null,
            "parquet-hive/parquet-hive-binding/parquet-hive-0.10-binding/pom.xml": null,
            "parquet-hive/parquet-hive-binding/parquet-hive-0.12-binding/pom.xml": null,
            "parquet-hive/parquet-hive-binding/parquet-hive-binding-bundle/pom.xml": null,
            "parquet-hive/parquet-hive-binding/parquet-hive-binding-factory/pom.xml": null,
            "parquet-hive/parquet-hive-binding/parquet-hive-binding-interface/pom.xml": null,
            "parquet-hive/parquet-hive-binding/pom.xml": null,
            "parquet-hive/parquet-hive-storage-handler/pom.xml": null,
            "parquet-hive/pom.xml": null,
            "parquet-pig-bundle/pom.xml": null,
            "parquet-pig/pom.xml": null,
            "parquet-scrooge/pom.xml": null,
            "parquet-test-hadoop2/pom.xml": null,
            "parquet-thrift/pom.xml": null,
            "pom.xml": null
        }
    },
    "a609147c8ab1544400c79a103ef44e6907b7470b": {
        "datetime": "2013-12-23T10:58:00-08:00",
        "summary": "[maven-release-plugin] prepare for next development iteration",
        "message": "[maven-release-plugin] prepare for next development iteration\n",
        "diff": {
            "parquet-avro/pom.xml": null,
            "parquet-cascading/pom.xml": null,
            "parquet-column/pom.xml": null,
            "parquet-common/pom.xml": null,
            "parquet-encoding/pom.xml": null,
            "parquet-generator/pom.xml": null,
            "parquet-hadoop-bundle/pom.xml": null,
            "parquet-hadoop/pom.xml": null,
            "parquet-hive-bundle/pom.xml": null,
            "parquet-hive/parquet-hive-binding/parquet-hive-0.10-binding/pom.xml": null,
            "parquet-hive/parquet-hive-binding/parquet-hive-0.12-binding/pom.xml": null,
            "parquet-hive/parquet-hive-binding/parquet-hive-binding-bundle/pom.xml": null,
            "parquet-hive/parquet-hive-binding/parquet-hive-binding-factory/pom.xml": null,
            "parquet-hive/parquet-hive-binding/parquet-hive-binding-interface/pom.xml": null,
            "parquet-hive/parquet-hive-binding/pom.xml": null,
            "parquet-hive/parquet-hive-storage-handler/pom.xml": null,
            "parquet-hive/pom.xml": null,
            "parquet-pig-bundle/pom.xml": null,
            "parquet-pig/pom.xml": null,
            "parquet-scrooge/pom.xml": null,
            "parquet-test-hadoop2/pom.xml": null,
            "parquet-thrift/pom.xml": null,
            "pom.xml": null
        }
    },
    "f7a90232cab0da9121c327ad0b43c2d39811fb53": {
        "datetime": "2013-12-26T14:15:12+01:00",
        "summary": "correct byte[] storage",
        "message": "correct byte[] storage\n",
        "diff": {
            "src/main/java/parquet/proto/ProtoWriteSupport.java": [
                6,
                10
            ],
            "src/main/java/parquet/proto/converters/ProtoBinaryConverter.java": [
                2,
                4
            ]
        }
    },
    "5997bf5ce0f588c7ea8ad0e6786d7dc3105908b5": {
        "datetime": "2013-12-26T16:18:22+01:00",
        "summary": "#projection test",
        "message": "#projection test\n",
        "diff": {
            "src/main/java/parquet/proto/ProtoParquetInputFormat.java": [
                5,
                4
            ],
            "src/test/java/parquet/proto/ProtoInputOutputFormatTest.java": [
                100,
                29
            ],
            "src/test/java/parquet/proto/utils/ReadUsingMR.java": [
                0,
                74
            ],
            "src/test/java/parquet/proto/utils/WriteUsingMR.java": [
                0,
                104
            ]
        }
    },
    "96f230019ae8e91f0eacf1490481a73161b4d8a2": {
        "datetime": "2013-12-26T16:22:11+01:00",
        "summary": "#projection test - fix - cannot use inner class as mapper",
        "message": "#projection test - fix - cannot use inner class as mapper\n",
        "diff": {
            "src/test/java/parquet/proto/utils/ReadUsingMR.java": [
                25,
                30
            ],
            "src/test/java/parquet/proto/utils/WriteUsingMR.java": [
                31,
                40
            ]
        }
    },
    "985002ee33ffe6c199ff6471b3df89394bb22f14": {
        "datetime": "2013-12-26T21:00:30+01:00",
        "summary": "Code cleanup",
        "message": "Code cleanup\n",
        "diff": {
            "src/main/java/parquet/proto/converters/ProtoEnumConverter.java": [
                3,
                3
            ],
            "src/main/java/parquet/proto/converters/ProtoMessageConverter.java": [
                6,
                4
            ],
            "src/main/java/parquet/proto/converters/ProtobufStringConverter.java": [
                2,
                3
            ],
            "src/test/java/parquet/proto/utils/ReadUsingMR.java": [
                2,
                1
            ]
        }
    },
    "b273684b5a4efdd49a5bc3e0e5aa70ad3abbb155": {
        "datetime": "2013-12-26T21:00:45+01:00",
        "summary": "ConverterTest",
        "message": "ConverterTest\n",
        "diff": {
            "src/test/java/parquet/proto/ProtoSchemaConverterTest.java": [
                1,
                1
            ],
            "src/test/java/parquet/proto/ProtobufferRecordConverterTest.java": [
                0,
                134
            ],
            "src/test/java/parquet/proto/TestUtils.java": [
                3,
                5
            ],
            "src/test/resources/TestProtobuf.proto": null
        }
    },
    "99b7e52a58d55d894dc244c93e5a4c4d183e411e": {
        "datetime": "2013-12-26T21:08:35+01:00",
        "summary": "new root directory",
        "message": "new root directory\n",
        "diff": {
            ".idea/ant.xml": null,
            ".idea/libraries/Maven__commons_beanutils_commons_beanutils_1_7_0.xml": null,
            ".idea/libraries/Maven__commons_beanutils_commons_beanutils_core_1_8_0.xml": null,
            ".idea/libraries/Maven__commons_collections_commons_collections_3_2_1.xml": null,
            ".idea/libraries/Maven__commons_configuration_commons_configuration_1_6.xml": null,
            ".idea/libraries/Maven__commons_digester_commons_digester_1_8.xml": null,
            ".idea/libraries/Maven__commons_io_commons_io_2_1.xml": null,
            ".idea/libraries/Maven__org_apache_commons_commons_math_2_1.xml": null,
            ".idea/libraries/Maven__org_apache_hadoop_hadoop_core_1_1_0.xml": null,
            ".idea/libraries/Maven__org_codehaus_jackson_jackson_core_asl_1_0_1.xml": null,
            ".idea/libraries/Maven__org_codehaus_jackson_jackson_mapper_asl_1_0_1.xml": null,
            "README.md": null,
            "pom.xml": null,
            "src/main/java/parquet/proto/ProtoParquetInputFormat.java": [
                0,
                0
            ],
            "src/main/java/parquet/proto/ProtoParquetOutputFormat.java": [
                0,
                0
            ],
            "src/main/java/parquet/proto/ProtoParquetReader.java": [
                0,
                0
            ],
            "src/main/java/parquet/proto/ProtoParquetWriter.java": [
                0,
                0
            ],
            "src/main/java/parquet/proto/ProtoReadSupport.java": [
                0,
                0
            ],
            "src/main/java/parquet/proto/ProtoRecordMaterializer.java": [
                0,
                0
            ],
            "src/main/java/parquet/proto/ProtoSchemaConverter.java": [
                0,
                0
            ],
            "src/main/java/parquet/proto/ProtoWriteSupport.java": [
                0,
                0
            ],
            "src/main/java/parquet/proto/ProtobufferRecordConverter.java": [
                0,
                0
            ],
            "src/main/java/parquet/proto/converters/ParentValueContainer.java": [
                0,
                0
            ],
            "src/main/java/parquet/proto/converters/ProtoArrayConverter.java": [
                0,
                0
            ],
            "src/main/java/parquet/proto/converters/ProtoBinaryConverter.java": [
                0,
                0
            ],
            "src/main/java/parquet/proto/converters/ProtoBooleanConverter.java": [
                0,
                0
            ],
            "src/main/java/parquet/proto/converters/ProtoDoubleConverter.java": [
                0,
                0
            ],
            "src/main/java/parquet/proto/converters/ProtoEnumConverter.java": [
                0,
                0
            ],
            "src/main/java/parquet/proto/converters/ProtoFloatConverter.java": [
                0,
                0
            ],
            "src/main/java/parquet/proto/converters/ProtoIntConverter.java": [
                0,
                0
            ],
            "src/main/java/parquet/proto/converters/ProtoLongConverter.java": [
                0,
                0
            ],
            "src/main/java/parquet/proto/converters/ProtoMessageConverter.java": [
                0,
                0
            ],
            "src/main/java/parquet/proto/converters/ProtobufStringConverter.java": [
                0,
                0
            ],
            "src/test/java/parquet/proto/ProtoInputOutputFormatTest.java": [
                0,
                0
            ],
            "src/test/java/parquet/proto/ProtoSchemaConverterTest.java": [
                0,
                0
            ],
            "src/test/java/parquet/proto/ProtobufferRecordConverterTest.java": [
                0,
                0
            ],
            "src/test/java/parquet/proto/TestUtils.java": [
                0,
                0
            ],
            "src/test/java/parquet/proto/utils/ReadUsingMR.java": [
                0,
                0
            ],
            "src/test/java/parquet/proto/utils/WriteUsingMR.java": [
                0,
                0
            ],
            "src/test/resources/TestProtobuf.proto": null
        }
    },
    "94b2ec0b93c826b39a881f5e0653719ae78889ce": {
        "datetime": "2013-12-26T21:13:48+01:00",
        "summary": "delete .idea directory",
        "message": "delete .idea directory\n",
        "diff": {
            ".idea/ant.xml": null,
            ".idea/libraries/Maven__commons_beanutils_commons_beanutils_1_7_0.xml": null,
            ".idea/libraries/Maven__commons_beanutils_commons_beanutils_core_1_8_0.xml": null,
            ".idea/libraries/Maven__commons_collections_commons_collections_3_2_1.xml": null,
            ".idea/libraries/Maven__commons_configuration_commons_configuration_1_6.xml": null,
            ".idea/libraries/Maven__commons_digester_commons_digester_1_8.xml": null,
            ".idea/libraries/Maven__commons_io_commons_io_2_1.xml": null,
            ".idea/libraries/Maven__org_apache_commons_commons_math_2_1.xml": null,
            ".idea/libraries/Maven__org_apache_hadoop_hadoop_core_1_1_0.xml": null,
            ".idea/libraries/Maven__org_codehaus_jackson_jackson_core_asl_1_0_1.xml": null,
            ".idea/libraries/Maven__org_codehaus_jackson_jackson_mapper_asl_1_0_1.xml": null
        }
    },
    "a717bbf2fc28f26e84f8374f6ffce4d30d8c618c": {
        "datetime": "2013-12-26T22:13:52+01:00",
        "summary": "merge",
        "message": "merge\n",
        "diff": {
            ".gitignore": null,
            "parquet-protobuf/README.md": null,
            "parquet-protobuf/pom.xml": null,
            "parquet-protobuf/src/main/java/parquet/proto/ProtoParquetInputFormat.java": [
                0,
                34
            ],
            "parquet-protobuf/src/main/java/parquet/proto/ProtoParquetOutputFormat.java": [
                0,
                54
            ],
            "parquet-protobuf/src/main/java/parquet/proto/ProtoParquetReader.java": [
                0,
                40
            ],
            "parquet-protobuf/src/main/java/parquet/proto/ProtoParquetWriter.java": [
                0,
                78
            ],
            "parquet-protobuf/src/main/java/parquet/proto/ProtoReadSupport.java": [
                0,
                66
            ],
            "parquet-protobuf/src/main/java/parquet/proto/ProtoRecordMaterializer.java": [
                0,
                41
            ],
            "parquet-protobuf/src/main/java/parquet/proto/ProtoSchemaConverter.java": [
                0,
                136
            ],
            "parquet-protobuf/src/main/java/parquet/proto/ProtoWriteSupport.java": [
                0,
                193
            ],
            "parquet-protobuf/src/main/java/parquet/proto/ProtobufferRecordConverter.java": [
                0,
                72
            ],
            "parquet-protobuf/src/main/java/parquet/proto/converters/ParentValueContainer.java": [
                0,
                26
            ],
            "parquet-protobuf/src/main/java/parquet/proto/converters/ProtoArrayConverter.java": [
                0,
                44
            ],
            "parquet-protobuf/src/main/java/parquet/proto/converters/ProtoBinaryConverter.java": [
                0,
                36
            ],
            "parquet-protobuf/src/main/java/parquet/proto/converters/ProtoBooleanConverter.java": [
                0,
                34
            ],
            "parquet-protobuf/src/main/java/parquet/proto/converters/ProtoDoubleConverter.java": [
                0,
                33
            ],
            "parquet-protobuf/src/main/java/parquet/proto/converters/ProtoEnumConverter.java": [
                0,
                69
            ],
            "parquet-protobuf/src/main/java/parquet/proto/converters/ProtoFloatConverter.java": [
                0,
                33
            ],
            "parquet-protobuf/src/main/java/parquet/proto/converters/ProtoIntConverter.java": [
                0,
                33
            ],
            "parquet-protobuf/src/main/java/parquet/proto/converters/ProtoLongConverter.java": [
                0,
                33
            ],
            "parquet-protobuf/src/main/java/parquet/proto/converters/ProtoMessageConverter.java": [
                0,
                183
            ],
            "parquet-protobuf/src/main/java/parquet/proto/converters/ProtobufStringConverter.java": [
                0,
                37
            ],
            "parquet-protobuf/src/test/java/parquet/proto/ProtoInputOutputFormatTest.java": [
                0,
                102
            ],
            "parquet-protobuf/src/test/java/parquet/proto/ProtoSchemaConverterTest.java": [
                0,
                99
            ],
            "parquet-protobuf/src/test/java/parquet/proto/ProtobufferRecordConverterTest.java": [
                0,
                134
            ],
            "parquet-protobuf/src/test/java/parquet/proto/TestUtils.java": [
                0,
                174
            ],
            "parquet-protobuf/src/test/java/parquet/proto/utils/ReadUsingMR.java": [
                0,
                78
            ],
            "parquet-protobuf/src/test/java/parquet/proto/utils/WriteUsingMR.java": [
                0,
                113
            ],
            "parquet-protobuf/src/test/resources/TestProtobuf.proto": null
        }
    },
    "d708c7dafa6ac39ee5d3d8a5d8091ae380ada2e6": {
        "datetime": "2013-12-26T22:39:27+01:00",
        "summary": "parquet-protobuf added to root pom.xml",
        "message": "parquet-protobuf added to root pom.xml\n",
        "diff": {
            "pom.xml": null
        }
    },
    "919db0ba56e7bce8d22c9a5a69d2b29e674a24ec": {
        "datetime": "2013-12-26T23:40:46+01:00",
        "summary": "Consistent naming protoXYZ",
        "message": "Consistent naming protoXYZ\n",
        "diff": {
            "parquet-protobuf/README.md": null,
            "parquet-protobuf/src/main/java/parquet/proto/ProtoParquetOutputFormat.java": [
                3,
                3
            ],
            "parquet-protobuf/src/main/java/parquet/proto/ProtoParquetReader.java": [
                2,
                2
            ],
            "parquet-protobuf/src/main/java/parquet/proto/ProtoParquetWriter.java": [
                2,
                2
            ],
            "parquet-protobuf/src/main/java/parquet/proto/ProtoReadSupport.java": [
                1,
                1
            ],
            "parquet-protobuf/src/main/java/parquet/proto/ProtoRecordMaterializer.java": [
                3,
                3
            ],
            "parquet-protobuf/src/main/java/parquet/proto/ProtoSchemaConverter.java": [
                4,
                4
            ],
            "parquet-protobuf/src/main/java/parquet/proto/ProtoWriteSupport.java": [
                3,
                3
            ],
            "parquet-protobuf/src/main/java/parquet/proto/ProtobufferRecordConverter.java": [
                3,
                3
            ],
            "parquet-protobuf/src/main/java/parquet/proto/converters/ProtoEnumConverter.java": [
                1,
                1
            ],
            "parquet-protobuf/src/test/java/parquet/proto/ProtoInputOutputFormatTest.java": [
                2,
                2
            ],
            "parquet-protobuf/src/test/java/parquet/proto/ProtoSchemaConverterTest.java": [
                2,
                2
            ],
            "parquet-protobuf/src/test/java/parquet/proto/ProtobufferRecordConverterTest.java": [
                4,
                3
            ],
            "parquet-protobuf/src/test/java/parquet/proto/TestUtils.java": [
                2,
                2
            ],
            "parquet-protobuf/src/test/java/parquet/proto/utils/WriteUsingMR.java": [
                10,
                4
            ],
            "parquet-protobuf/src/test/resources/TestProtobuf.proto": null
        }
    },
    "c8188f32b8761f0bb6ceb564333e166f5a91a321": {
        "datetime": "2013-12-27T00:01:11+01:00",
        "summary": "pom - latest version",
        "message": "pom - latest version\n",
        "diff": {
            "parquet-protobuf/pom.xml": null
        }
    },
    "1f4a9db0b7216e5d7d5444aa86ae56ecdfda1b71": {
        "datetime": "2013-12-27T00:01:29+01:00",
        "summary": "Code cleanup",
        "message": "Code cleanup\n",
        "diff": {
            "parquet-protobuf/src/main/java/parquet/proto/ProtoReadSupport.java": [
                3,
                14
            ],
            "parquet-protobuf/src/main/java/parquet/proto/ProtoSchemaConverter.java": [
                2,
                2
            ],
            "parquet-protobuf/src/main/java/parquet/proto/converters/ProtoMessageConverter.java": [
                3,
                4
            ],
            "parquet-protobuf/src/main/java/parquet/proto/converters/ProtobufStringConverter.java": [
                2,
                2
            ],
            "parquet-protobuf/src/test/java/parquet/proto/ProtoInputOutputFormatTest.java": [
                0,
                4
            ]
        }
    },
    "c7c39c3f5a12d3b823813bd6307d2e0e2ed98fce": {
        "datetime": "2013-12-27T00:50:48+01:00",
        "summary": "Repeated Messages test",
        "message": "Repeated Messages test\n",
        "diff": {
            "parquet-protobuf/src/main/java/parquet/proto/converters/ProtoMessageConverter.java": [
                2,
                1
            ],
            "parquet-protobuf/src/test/java/parquet/proto/ProtoRecordConverterTest.java": [
                0,
                27
            ],
            "parquet-protobuf/src/test/resources/TestProtobuf.proto": null
        }
    },
    "47cd5723c39fd87c4aac676bebf67a6d6c931e43": {
        "datetime": "2013-12-27T00:51:42+01:00",
        "summary": "Method ProtoParquetInputFormat.setRequestedProjection signature",
        "message": "Method ProtoParquetInputFormat.setRequestedProjection signature\n",
        "diff": {
            "parquet-protobuf/src/main/java/parquet/proto/ProtoParquetInputFormat.java": [
                3,
                4
            ],
            "parquet-protobuf/src/main/java/parquet/proto/ProtoRecordConverter.java": [
                2,
                8
            ],
            "parquet-protobuf/src/test/java/parquet/proto/ProtoInputOutputFormatTest.java": [
                4,
                1
            ],
            "parquet-protobuf/src/test/java/parquet/proto/utils/ReadUsingMR.java": [
                5,
                11
            ],
            "parquet-protobuf/src/test/java/parquet/proto/utils/WriteUsingMR.java": [
                4,
                4
            ]
        }
    },
    "565638f859d07256bc9f22218a54c04ae48f162f": {
        "datetime": "2013-12-26T16:17:12-08:00",
        "summary": "refactor",
        "message": "refactor\n",
        "diff": {
            "parquet-scrooge/src/main/java/parquet/scrooge/EnumConverter.java": [
                44,
                0
            ],
            "parquet-scrooge/src/main/java/parquet/scrooge/ScroogeEnumDesc.java": [
                34,
                0
            ],
            "parquet-scrooge/src/main/java/parquet/scrooge/ScroogeSchemaConverter.java": [
                96,
                193
            ],
            "parquet-scrooge/src/test/java/parquet/scrooge/ParquetScroogeSchemeTest.java": [
                2,
                3
            ],
            "parquet-scrooge/src/test/java/parquet/scrooge/ScroogeSchemaConverterTest.java": [
                179,
                22
            ],
            "parquet-scrooge/src/test/thrift/test.thrift": null
        }
    },
    "1d1dd2fa7832a51133c8003451334c1f4068cfe8": {
        "datetime": "2013-12-26T19:26:14-08:00",
        "summary": "1. refactor: maket ThriftSchemaConverter pluggable, can use",
        "message": "1. refactor: maket ThriftSchemaConverter pluggable, can use\nThriftStructConverter or ScroogeStructConvert to convert class to\nThriftType\n2. support scrooge read projection pushdown\n3. add scroogeReadSupport\n",
        "diff": {
            "parquet-scrooge/src/main/java/parquet/scrooge/ParquetScroogeScheme.java": [
                1,
                1
            ],
            "parquet-scrooge/src/main/java/parquet/scrooge/ScroogeReadSupport.java": [
                0,
                42
            ],
            "parquet-scrooge/src/main/java/parquet/scrooge/ScroogeSchemaConverter.java": [
                14,
                39
            ],
            "parquet-scrooge/src/test/java/parquet/scrooge/ParquetScroogeSchemeTest.java": [
                12,
                37
            ],
            "parquet-scrooge/src/test/java/parquet/scrooge/ScroogeSchemaConverterTest.java": [
                22,
                25
            ],
            "parquet-thrift/src/main/java/parquet/hadoop/thrift/ThriftReadSupport.java": [
                7,
                6
            ],
            "parquet-thrift/src/main/java/parquet/thrift/ThriftSchemaConverter.java": [
                73,
                83
            ],
            "parquet-thrift/src/test/java/parquet/thrift/TestThriftSchemaConverter.java": [
                4,
                2
            ]
        }
    },
    "ebc87de72be2249ce749b6893021b9c48f6a93c8": {
        "datetime": "2013-12-26T19:38:01-08:00",
        "summary": "format",
        "message": "format\n",
        "diff": {
            "parquet-scrooge/src/main/java/parquet/scrooge/ScroogeRecordConverter.java": [
                1,
                1
            ],
            "parquet-scrooge/src/main/java/parquet/scrooge/ScroogeStructConverter.java": [
                2,
                2
            ],
            "parquet-scrooge/src/test/java/parquet/scrooge/ParquetScroogeSchemeTest.java": [
                1,
                0
            ]
        }
    },
    "0fb0173132b27a3077d0faefc0a70888f5b49baf": {
        "datetime": "2013-12-26T19:45:40-08:00",
        "summary": "merge master",
        "message": "merge master\n",
        "diff": {
            "CHANGES.md": null,
            "PoweredBy.md": null,
            "README.md": null,
            "changelog.sh": null,
            "parquet-avro/pom.xml": null,
            "parquet-avro/src/main/java/parquet/avro/AvroIndexedRecordConverter.java": [
                3,
                30
            ],
            "parquet-avro/src/main/java/parquet/avro/AvroParquetReader.java": [
                1,
                13
            ],
            "parquet-avro/src/main/java/parquet/avro/AvroSchemaConverter.java": [
                5,
                14
            ],
            "parquet-avro/src/main/java/parquet/avro/AvroWriteSupport.java": [
                34,
                42
            ],
            "parquet-avro/src/test/java/parquet/avro/TestAvroSchemaConverter.java": [
                8,
                19
            ],
            "parquet-avro/src/test/java/parquet/avro/TestReadWrite.java": [
                9,
                105
            ],
            "parquet-avro/src/test/java/parquet/avro/TestSpecificInputOutputFormat.java": [
                10,
                12
            ],
            "parquet-avro/src/test/java/parquet/avro/TestSpecificReadWrite.java": [
                31,
                75
            ],
            "parquet-avro/src/test/resources/all-minus-fixed.avsc": null,
            "parquet-avro/src/test/resources/all.avsc": null,
            "parquet-avro/src/test/resources/array.avsc": null,
            "parquet-avro/src/test/resources/car.avdl": null,
            "parquet-avro/src/test/resources/map.avsc": null,
            "parquet-cascading/pom.xml": null,
            "parquet-cascading/src/main/java/parquet/cascading/ParquetTBaseScheme.java": [
                19,
                24
            ],
            "parquet-cascading/src/main/java/parquet/cascading/ParquetTupleScheme.java": [
                2,
                10
            ],
            "parquet-cascading/src/main/java/parquet/cascading/ParquetValueScheme.java": [
                0,
                16
            ],
            "parquet-cascading/src/test/java/parquet/cascading/TestParquetTBaseScheme.java": [
                46,
                136
            ],
            "parquet-cascading/src/test/java/parquet/cascading/TestParquetTupleScheme.java": [
                54,
                139
            ],
            "parquet-cascading/src/test/resources/names.txt": null,
            "parquet-cascading/src/test/resources/part-m-00000.gz.parquet": null,
            "parquet-cascading/src/test/thrift/test.thrift": null,
            "parquet-column/pom.xml": null,
            "parquet-column/src/main/java/parquet/column/ColumnDescriptor.java": [
                2,
                24
            ],
            "parquet-column/src/main/java/parquet/column/ColumnWriter.java": [
                0,
                1
            ],
            "parquet-column/src/main/java/parquet/column/Encoding.java": [
                9,
                65
            ],
            "parquet-column/src/main/java/parquet/column/ParquetProperties.java": [
                0,
                133
            ],
            "parquet-column/src/main/java/parquet/column/impl/ColumnReaderImpl.java": [
                6,
                24
            ],
            "parquet-column/src/main/java/parquet/column/impl/ColumnWriteStoreImpl.java": [
                2,
                7
            ],
            "parquet-column/src/main/java/parquet/column/impl/ColumnWriterImpl.java": [
                60,
                17
            ],
            "parquet-column/src/main/java/parquet/column/values/ValuesReader.java": [
                2,
                12
            ],
            "parquet-column/src/main/java/parquet/column/values/bitpacking/BitPackingValuesReader.java": [
                4,
                9
            ],
            "parquet-column/src/main/java/parquet/column/values/bitpacking/ByteBitPackingValuesReader.java": [
                4,
                9
            ],
            "parquet-column/src/main/java/parquet/column/values/boundedint/BoundedIntValuesReader.java": [
                2,
                8
            ],
            "parquet-column/src/main/java/parquet/column/values/boundedint/ZeroIntegerValuesReader.java": [
                2,
                9
            ],
            "parquet-column/src/main/java/parquet/column/values/delta/DeltaBinaryPackingConfig.java": [
                0,
                54
            ],
            "parquet-column/src/main/java/parquet/column/values/delta/DeltaBinaryPackingValuesReader.java": [
                0,
                167
            ],
            "parquet-column/src/main/java/parquet/column/values/delta/DeltaBinaryPackingValuesWriter.java": [
                0,
                266
            ],
            "parquet-column/src/main/java/parquet/column/values/deltalengthbytearray/DeltaLengthByteArrayValuesReader.java": [
                0,
                67
            ],
            "parquet-column/src/main/java/parquet/column/values/deltalengthbytearray/DeltaLengthByteArrayValuesWriter.java": [
                0,
                103
            ],
            "parquet-column/src/main/java/parquet/column/values/deltastrings/DeltaByteArrayReader.java": [
                0,
                75
            ],
            "parquet-column/src/main/java/parquet/column/values/deltastrings/DeltaByteArrayWriter.java": [
                0,
                89
            ],
            "parquet-column/src/main/java/parquet/column/values/dictionary/DictionaryValuesReader.java": [
                4,
                3
            ],
            "parquet-column/src/main/java/parquet/column/values/dictionary/DictionaryValuesWriter.java": [
                66,
                181
            ],
            "parquet-column/src/main/java/parquet/column/values/plain/BinaryPlainValuesReader.java": [
                2,
                1
            ],
            "parquet-column/src/main/java/parquet/column/values/plain/BooleanPlainValuesReader.java": [
                2,
                7
            ],
            "parquet-column/src/main/java/parquet/column/values/plain/FixedLenByteArrayPlainValuesReader.java": [
                0,
                65
            ],
            "parquet-column/src/main/java/parquet/column/values/plain/FixedLenByteArrayPlainValuesWriter.java": [
                0,
                95
            ],
            "parquet-column/src/main/java/parquet/column/values/plain/PlainValuesReader.java": [
                11,
                8
            ],
            "parquet-column/src/main/java/parquet/column/values/plain/PlainValuesWriter.java": [
                1,
                0
            ],
            "parquet-column/src/main/java/parquet/column/values/rle/RunLengthBitPackingHybridDecoder.java": [
                13,
                8
            ],
            "parquet-column/src/main/java/parquet/column/values/rle/RunLengthBitPackingHybridValuesReader.java": [
                15,
                15
            ],
            "parquet-column/src/main/java/parquet/column/values/rle/RunLengthBitPackingHybridValuesWriter.java": [
                0,
                5
            ],
            "parquet-column/src/main/java/parquet/example/data/simple/convert/SimplePrimitiveConverter.java": [
                5,
                4
            ],
            "parquet-column/src/main/java/parquet/filter/ColumnPredicates.java": [
                0,
                90
            ],
            "parquet-column/src/main/java/parquet/filter/NotRecordFilter.java": [
                0,
                55
            ],
            "parquet-column/src/main/java/parquet/filter/OrRecordFilter.java": [
                0,
                59
            ],
            "parquet-column/src/main/java/parquet/io/PrimitiveColumnIO.java": [
                1,
                8
            ],
            "parquet-column/src/main/java/parquet/io/api/Binary.java": [
                1,
                22
            ],
            "parquet-column/src/main/java/parquet/schema/MessageType.java": [
                3,
                10
            ],
            "parquet-column/src/main/java/parquet/schema/MessageTypeParser.java": [
                1,
                18
            ],
            "parquet-column/src/main/java/parquet/schema/PrimitiveType.java": [
                17,
                51
            ],
            "parquet-column/src/test/java/parquet/column/mem/TestMemColumn.java": [
                4,
                10
            ],
            "parquet-column/src/test/java/parquet/column/values/RandomStr.java": [
                0,
                53
            ],
            "parquet-column/src/test/java/parquet/column/values/Utils.java": [
                0,
                87
            ],
            "parquet-column/src/test/java/parquet/column/values/boundedint/TestBoundedColumns.java": [
                1,
                2
            ],
            "parquet-column/src/test/java/parquet/column/values/delta/DeltaBinaryPackingValuesWriterTest.java": [
                0,
                259
            ],
            "parquet-column/src/test/java/parquet/column/values/delta/benchmark/BenchMarkTest.java": [
                0,
                40
            ],
            "parquet-column/src/test/java/parquet/column/values/delta/benchmark/BenchmarkIntegerOutputSize.java": [
                0,
                99
            ],
            "parquet-column/src/test/java/parquet/column/values/delta/benchmark/BenchmarkReadingRandomIntegers.java": [
                0,
                93
            ],
            "parquet-column/src/test/java/parquet/column/values/delta/benchmark/RandomWritingBenchmarkTest.java": [
                0,
                67
            ],
            "parquet-column/src/test/java/parquet/column/values/delta/benchmark/SmallRangeWritingBenchmarkTest.java": [
                0,
                45
            ],
            "parquet-column/src/test/java/parquet/column/values/deltalengthbytearray/TestDeltaLengthByteArray.java": [
                0,
                71
            ],
            "parquet-column/src/test/java/parquet/column/values/deltalengthbytearray/benchmark/BenchmarkDeltaLengthByteArray.java": [
                0,
                68
            ],
            "parquet-column/src/test/java/parquet/column/values/deltastrings/TestDeltaByteArray.java": [
                0,
                81
            ],
            "parquet-column/src/test/java/parquet/column/values/deltastrings/benchmark/BenchmarkDeltaByteArray.java": [
                0,
                98
            ],
            "parquet-column/src/test/java/parquet/column/values/dictionary/TestDictionary.java": [
                319,
                287
            ],
            "parquet-column/src/test/java/parquet/column/values/rle/RunLengthBitPackingHybridIntegrationTest.java": [
                2,
                3
            ],
            "parquet-column/src/test/java/parquet/column/values/rle/TestRunLengthBitPackingHybridEncoder.java": [
                1,
                1
            ],
            "parquet-column/src/test/java/parquet/io/ExpectationValidatingRecordConsumer.java": [
                0,
                1
            ],
            "parquet-column/src/test/java/parquet/io/PerfTest.java": [
                1,
                2
            ],
            "parquet-column/src/test/java/parquet/io/TestColumnIO.java": [
                23,
                27
            ],
            "parquet-column/src/test/java/parquet/io/TestFiltered.java": [
                16,
                125
            ],
            "parquet-common/pom.xml": null,
            "parquet-common/src/main/java/parquet/bytes/BytesUtils.java": [
                0,
                16
            ],
            "parquet-encoding/pom.xml": null,
            "parquet-encoding/src/main/java/parquet/bytes/BytesInput.java": [
                0,
                37
            ],
            "parquet-generator/pom.xml": null,
            "parquet-hadoop-bundle/README": null,
            "parquet-hadoop-bundle/pom.xml": null,
            "parquet-hadoop-bundle/src/main/resources/parquet/bundle": null,
            "parquet-hadoop/pom.xml": null,
            "parquet-hadoop/src/main/java/parquet/format/converter/ParquetMetadataConverter.java": [
                15,
                72
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/CodecFactory.java": [
                1,
                1
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/InternalParquetRecordWriter.java": [
                16,
                26
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/ParquetFileReader.java": [
                106,
                318
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/ParquetFileWriter.java": [
                2,
                3
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/ParquetInputFormat.java": [
                3,
                3
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/ParquetInputSplit.java": [
                4,
                5
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/ParquetOutputFormat.java": [
                61,
                125
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/ParquetReader.java": [
                1,
                22
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/ParquetRecordWriter.java": [
                2,
                18
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/ParquetWriter.java": [
                5,
                69
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/codec/CodecConfig.java": [
                0,
                166
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/codec/CompressionCodecNotSupportedException.java": [
                0,
                33
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/mapred/DeprecatedParquetInputFormat.java": [
                2,
                6
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/mapred/DeprecatedParquetOutputFormat.java": [
                0,
                114
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/metadata/BlockMetaData.java": [
                1,
                2
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/metadata/ColumnChunkMetaData.java": [
                15,
                47
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/metadata/CompressionCodecName.java": [
                3,
                16
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/metadata/EncodingList.java": [
                1,
                0
            ],
            "parquet-hadoop/src/test/java/parquet/hadoop/DeprecatedInputFormatTest.java": [
                1,
                1
            ],
            "parquet-hadoop/src/test/java/parquet/hadoop/DeprecatedOutputFormatTest.java": [
                0,
                106
            ],
            "parquet-hadoop/src/test/java/parquet/hadoop/codec/CodecConfigTest.java": [
                0,
                74
            ],
            "parquet-hadoop/src/test/java/parquet/hadoop/metadata/TestColumnChunkMetaData.java": [
                0,
                64
            ],
            "parquet-hive-bundle/pom.xml": null,
            "parquet-hive-bundle/src/main/resources/parquet/bundle": null,
            "parquet-hive/parquet-hive-binding/parquet-hive-0.10-binding/pom.xml": null,
            "parquet-hive/parquet-hive-binding/parquet-hive-0.12-binding/pom.xml": null,
            "parquet-hive/parquet-hive-binding/parquet-hive-0.12-binding/src/main/java/parquet/hive/internal/Hive012Binding.java": [
                0,
                149
            ],
            "parquet-hive/parquet-hive-binding/parquet-hive-binding-bundle/pom.xml": null,
            "parquet-hive/parquet-hive-binding/parquet-hive-binding-bundle/src/assemble/uberjar.xml": null,
            "parquet-hive/parquet-hive-binding/parquet-hive-binding-bundle/src/main/resources/parquet/bundle": null,
            "parquet-hive/parquet-hive-binding/parquet-hive-binding-factory/pom.xml": null,
            "parquet-hive/parquet-hive-binding/parquet-hive-binding-factory/src/main/java/parquet/hive/HiveBindingFactory.java": [
                0,
                147
            ],
            "parquet-hive/parquet-hive-binding/parquet-hive-binding-factory/src/test/java/parquet/hive/TestHiveBindingFactory.java": [
                0,
                121
            ],
            "parquet-hive/parquet-hive-binding/parquet-hive-binding-interface/pom.xml": null,
            "parquet-hive/parquet-hive-binding/parquet-hive-binding-interface/src/main/java/parquet/hive/HiveBinding.java": [
                0,
                52
            ],
            "parquet-hive/parquet-hive-binding/parquet-hive-binding-interface/src/main/java/parquet/hive/internal/AbstractHiveBinding.java": [
                0,
                36
            ],
            "parquet-hive/parquet-hive-binding/pom.xml": null,
            "parquet-hive/parquet-hive-storage-handler/pom.xml": null,
            "parquet-hive/parquet-hive-storage-handler/src/main/java/parquet/hive/DeprecatedParquetInputFormat.java": [
                0,
                35
            ],
            "parquet-hive/parquet-hive-storage-handler/src/main/java/parquet/hive/DeprecatedParquetOutputFormat.java": [
                0,
                35
            ],
            "parquet-hive/parquet-hive-storage-handler/src/main/java/parquet/hive/convert/ETypeConverter.java": [
                0,
                165
            ],
            "parquet-hive/parquet-hive-storage-handler/src/main/java/parquet/hive/serde/AbstractParquetMapInspector.java": [
                0,
                163
            ],
            "parquet-hive/parquet-hive-storage-handler/src/main/java/parquet/hive/serde/ArrayWritableObjectInspector.java": [
                0,
                224
            ],
            "parquet-hive/parquet-hive-storage-handler/src/main/java/parquet/hive/serde/DeepParquetHiveMapInspector.java": [
                0,
                82
            ],
            "parquet-hive/parquet-hive-storage-handler/src/main/java/parquet/hive/serde/ParquetHiveArrayInspector.java": [
                0,
                185
            ],
            "parquet-hive/parquet-hive-storage-handler/src/main/java/parquet/hive/serde/StandardParquetHiveMapInspector.java": [
                0,
                65
            ],
            "parquet-hive/parquet-hive-storage-handler/src/main/java/parquet/hive/serde/primitive/ParquetByteInspector.java": [
                0,
                59
            ],
            "parquet-hive/parquet-hive-storage-handler/src/main/java/parquet/hive/serde/primitive/ParquetPrimitiveInspectorFactory.java": [
                0,
                32
            ],
            "parquet-hive/parquet-hive-storage-handler/src/main/java/parquet/hive/serde/primitive/ParquetShortInspector.java": [
                0,
                59
            ],
            "parquet-hive/parquet-hive-storage-handler/src/main/java/parquet/hive/serde/primitive/ParquetStringInspector.java": [
                0,
                100
            ],
            "parquet-hive/parquet-hive-storage-handler/src/main/java/parquet/hive/writable/BinaryWritable.java": [
                0,
                98
            ],
            "parquet-hive/parquet-hive-storage-handler/src/test/java/parquet/hive/serde/TestAbstractParquetMapInspector.java": [
                0,
                102
            ],
            "parquet-hive/parquet-hive-storage-handler/src/test/java/parquet/hive/serde/TestDeepParquetHiveMapInspector.java": [
                0,
                94
            ],
            "parquet-hive/parquet-hive-storage-handler/src/test/java/parquet/hive/serde/TestParquetHiveArrayInspector.java": [
                0,
                84
            ],
            "parquet-hive/parquet-hive-storage-handler/src/test/java/parquet/hive/serde/TestStandardParquetHiveMapInspector.java": [
                0,
                92
            ],
            "parquet-hive/pom.xml": null,
            "parquet-hive/src/main/java/parquet/hive/DeprecatedParquetInputFormat.java": [
                32,
                45
            ],
            "parquet-hive/src/main/java/parquet/hive/DeprecatedParquetOutputFormat.java": [
                9,
                14
            ],
            "parquet-hive/src/main/java/parquet/hive/ManageJobConfig.java": [
                68,
                31
            ],
            "parquet-hive/src/main/java/parquet/hive/convert/ArrayWritableGroupConverter.java": [
                0,
                0
            ],
            "parquet-hive/src/main/java/parquet/hive/convert/DataWritableGroupConverter.java": [
                3,
                1
            ],
            "parquet-hive/src/main/java/parquet/hive/convert/DataWritableRecordConverter.java": [
                0,
                0
            ],
            "parquet-hive/src/main/java/parquet/hive/convert/ETypeConverter.java": [
                283,
                0
            ],
            "parquet-hive/src/main/java/parquet/hive/convert/HiveGroupConverter.java": [
                0,
                0
            ],
            "parquet-hive/src/main/java/parquet/hive/convert/HiveSchemaConverter.java": [
                6,
                5
            ],
            "parquet-hive/src/main/java/parquet/hive/read/DataWritableReadSupport.java": [
                29,
                34
            ],
            "parquet-hive/src/main/java/parquet/hive/serde/ArrayWritableObjectInspector.java": [
                313,
                0
            ],
            "parquet-hive/src/main/java/parquet/hive/serde/ParquetHiveArrayInspector.java": [
                144,
                0
            ],
            "parquet-hive/src/main/java/parquet/hive/serde/ParquetHiveMapInspector.java": [
                102,
                0
            ],
            "parquet-hive/src/main/java/parquet/hive/serde/ParquetHiveSerDe.java": [
                1,
                2
            ],
            "parquet-hive/src/main/java/parquet/hive/writable/BigDecimalWritable.java": [
                0,
                0
            ],
            "parquet-hive/src/main/java/parquet/hive/writable/BinaryWritable.java": [
                46,
                0
            ],
            "parquet-hive/src/main/java/parquet/hive/write/DataWritableWriteSupport.java": [
                0,
                0
            ],
            "parquet-hive/src/main/java/parquet/hive/write/DataWritableWriter.java": [
                3,
                2
            ],
            "parquet-hive/src/test/java/parquet/hive/TestDeprecatedParquetInputFormat.java": [
                21,
                117
            ],
            "parquet-hive/src/test/java/parquet/hive/TestDeprecatedParquetOuputFormat.java": [
                25,
                27
            ],
            "parquet-hive/src/test/java/parquet/hive/TestHiveSchemaConverter.java": [
                3,
                2
            ],
            "parquet-hive/src/test/java/parquet/hive/TestParquetSerDe.java": [
                3,
                4
            ],
            "parquet-hive/src/test/java/parquet/hive/UtilitiesTestMethods.java": [
                11,
                43
            ],
            "parquet-pig-bundle/pom.xml": null,
            "parquet-pig-bundle/src/main/resources/parquet/bundle": null,
            "parquet-pig/pom.xml": null,
            "parquet-pig/src/main/java/parquet/pig/ParquetLoader.java": [
                10,
                13
            ],
            "parquet-pig/src/main/java/parquet/pig/ParquetStorer.java": [
                3,
                1
            ],
            "parquet-pig/src/main/java/parquet/pig/PigSchemaConverter.java": [
                90,
                109
            ],
            "parquet-pig/src/main/java/parquet/pig/TupleReadSupport.java": [
                4,
                0
            ],
            "parquet-pig/src/main/java/parquet/pig/TupleWriteSupport.java": [
                2,
                20
            ],
            "parquet-pig/src/test/java/parquet/pig/GenerateIntTestFile.java": [
                1,
                2
            ],
            "parquet-pig/src/test/java/parquet/pig/GenerateTPCH.java": [
                1,
                2
            ],
            "parquet-pig/src/test/java/parquet/pig/PerfTest2.java": [
                4,
                4
            ],
            "parquet-pig/src/test/java/parquet/pig/TestParquetLoader.java": [
                2,
                9
            ],
            "parquet-pig/src/test/java/parquet/pig/TestPigSchemaConverter.java": [
                5,
                28
            ],
            "parquet-pig/src/test/java/parquet/pig/TestTupleRecordConsumer.java": [
                11,
                9
            ],
            "parquet-pig/src/test/java/parquet/pig/TupleConsumerPerfTest.java": [
                2,
                3
            ],
            "parquet-scrooge/pom.xml": null,
            "parquet-scrooge/src/test/java/parquet/scrooge/ParquetScroogeSchemeTest.java": [
                2,
                1
            ],
            "parquet-test-hadoop2/pom.xml": null,
            "parquet-thrift/pom.xml": null,
            "parquet-thrift/src/main/java/parquet/hadoop/thrift/ParquetThriftBytesOutputFormat.java": [
                2,
                4
            ],
            "parquet-thrift/src/main/java/parquet/hadoop/thrift/ThriftBytesWriteSupport.java": [
                2,
                9
            ],
            "parquet-thrift/src/main/java/parquet/hadoop/thrift/ThriftToParquetFileWriter.java": [
                3,
                25
            ],
            "parquet-thrift/src/main/java/parquet/hadoop/thrift/ThriftWriteSupport.java": [
                1,
                16
            ],
            "parquet-thrift/src/main/java/parquet/thrift/BufferedProtocolReadToWrite.java": [
                116,
                415
            ],
            "parquet-thrift/src/main/java/parquet/thrift/DecodingSchemaMismatchException.java": [
                0,
                12
            ],
            "parquet-thrift/src/main/java/parquet/thrift/ParquetWriteProtocol.java": [
                2,
                7
            ],
            "parquet-thrift/src/main/java/parquet/thrift/ProtocolReadToWrite.java": [
                1,
                1
            ],
            "parquet-thrift/src/main/java/parquet/thrift/ReadWriteErrorHandler.java": [
                0,
                39
            ],
            "parquet-thrift/src/main/java/parquet/thrift/ThriftParquetReader.java": [
                0,
                21
            ],
            "parquet-thrift/src/main/java/parquet/thrift/struct/CompatibilityChecker.java": [
                0,
                218
            ],
            "parquet-thrift/src/main/java/parquet/thrift/struct/CompatibilityRunner.java": [
                0,
                96
            ],
            "parquet-thrift/src/main/java/parquet/thrift/struct/ThriftType.java": [
                1,
                5
            ],
            "parquet-thrift/src/test/java/parquet/hadoop/thrift/TestParquetToThriftReadProjection.java": [
                8,
                8
            ],
            "parquet-thrift/src/test/java/parquet/hadoop/thrift/TestThriftToParquetFileWriter.java": [
                2,
                2
            ],
            "parquet-thrift/src/test/java/parquet/thrift/TestParquetReadProtocol.java": [
                1,
                2
            ],
            "parquet-thrift/src/test/java/parquet/thrift/TestParquetWriteProtocol.java": [
                1,
                1
            ],
            "parquet-thrift/src/test/java/parquet/thrift/TestProtocolReadToWrite.java": [
                34,
                169
            ],
            "parquet-thrift/src/test/java/parquet/thrift/struct/CompatibilityCheckerTest.java": [
                0,
                117
            ],
            "parquet-thrift/src/test/thrift/compat.thrift": null,
            "parquet-thrift/src/test/thrift/test.thrift": null,
            "parquet_cascading.md": null,
            "pom.xml": null
        }
    },
    "b9e272aecbcbfb500245720eec41566fd918a18a": {
        "datetime": "2013-12-26T19:59:30-08:00",
        "summary": "fix test",
        "message": "fix test\n",
        "diff": {
            "parquet-scrooge/src/test/java/parquet/scrooge/ParquetScroogeSchemeTest.java": [
                0,
                1
            ]
        }
    },
    "36c3b66f327c823ee3a68fafb3744bc23321dea4": {
        "datetime": "2013-12-26T20:13:32-08:00",
        "summary": "format",
        "message": "format\n",
        "diff": {
            "parquet-thrift/src/main/java/parquet/thrift/ThriftMetaData.java": [
                9,
                0
            ],
            "parquet-thrift/src/main/java/parquet/thrift/ThriftSchemaConverter.java": [
                1,
                1
            ],
            "parquet-thrift/src/main/java/parquet/thrift/struct/ThriftType.java": [
                2,
                0
            ]
        }
    },
    "7c0d29037f59ec37c1f652df9cc4fc1bef76ea82": {
        "datetime": "2013-12-27T22:41:15+01:00",
        "summary": "Code cleanup",
        "message": "Code cleanup\n",
        "diff": {
            "parquet-protobuf/src/main/java/parquet/proto/ProtoWriteSupport.java": [
                10,
                3
            ],
            "parquet-protobuf/src/test/java/parquet/proto/ProtoInputOutputFormatTest.java": [
                4,
                4
            ],
            "parquet-protobuf/src/test/java/parquet/proto/TestUtils.java": [
                1,
                1
            ],
            "parquet-protobuf/src/test/java/parquet/proto/utils/WriteUsingMR.java": [
                3,
                6
            ]
        }
    },
    "63b710dad7aa9e87cab013d701b100aa0178ec38": {
        "datetime": "2013-12-29T19:09:34+01:00",
        "summary": "Code cleanup - Enum comparsions",
        "message": "Code cleanup - Enum comparsions\n",
        "diff": {
            "parquet-protobuf/src/main/java/parquet/proto/ProtoSchemaConverter.java": [
                28,
                22
            ],
            "parquet-protobuf/src/main/java/parquet/proto/ProtoWriteSupport.java": [
                20,
                22
            ],
            "parquet-protobuf/src/main/java/parquet/proto/converters/ProtoMessageConverter.java": [
                10,
                12
            ]
        }
    },
    "8ed45d07603a354f4e05a454a841995f5d558eb1": {
        "datetime": "2013-12-29T19:14:58+01:00",
        "summary": "Unnecessary unboxing",
        "message": "Unnecessary unboxing\n",
        "diff": {
            "parquet-protobuf/src/main/java/parquet/proto/ProtoWriteSupport.java": [
                4,
                4
            ]
        }
    },
    "31e4b068e66b77cdd6c31983f7b019a5ad4a2306": {
        "datetime": "2014-01-01T10:51:06+01:00",
        "summary": "Url to main parquet repo",
        "message": "Url to main parquet repo\n",
        "diff": {
            "parquet-protobuf/pom.xml": null
        }
    },
    "e4e9fc271d201eaf0a26894c4567ec489d32e0c4": {
        "datetime": "2014-01-02T15:21:27-08:00",
        "summary": "Update CHANGES.md",
        "message": "Update CHANGES.md",
        "diff": {
            "CHANGES.md": null
        }
    },
    "0261cd6a7525fa37229d6c4f8df1d6409332646d": {
        "datetime": "2014-01-02T17:19:57-08:00",
        "summary": "upgrade parquet-mr to elephant-bird 4.4",
        "message": "upgrade parquet-mr to elephant-bird 4.4\n",
        "diff": {
            "parquet-thrift/pom.xml": null,
            "parquet-thrift/src/test/java/parquet/thrift/TestParquetReadProtocol.java": [
                1,
                3
            ],
            "parquet-thrift/src/test/java/parquet/thrift/TestParquetWriteProtocol.java": [
                33,
                49
            ],
            "parquet-thrift/src/test/java/parquet/thrift/TestThriftToPigCompatibility.java": [
                1,
                3
            ]
        }
    },
    "622a4000f69dcc87947e1566835fc51b3be46aaf": {
        "datetime": "2014-01-02T17:39:05-08:00",
        "summary": "handler only handle ignored field, exception during will be thrown as SkippableException",
        "message": "handler only handle ignored field, exception during will be thrown as SkippableException\n",
        "diff": {
            "parquet-thrift/src/main/java/parquet/hadoop/thrift/ParquetThriftBytesOutputFormat.java": [
                2,
                2
            ],
            "parquet-thrift/src/main/java/parquet/hadoop/thrift/ThriftBytesWriteSupport.java": [
                3,
                3
            ],
            "parquet-thrift/src/main/java/parquet/hadoop/thrift/ThriftToParquetFileWriter.java": [
                3,
                3
            ],
            "parquet-thrift/src/main/java/parquet/thrift/BufferedProtocolReadToWrite.java": [
                29,
                12
            ],
            "parquet-thrift/src/main/java/parquet/thrift/ReadWriteErrorHandler.java": [
                17,
                6
            ],
            "parquet-thrift/src/test/java/parquet/thrift/TestProtocolReadToWrite.java": [
                49,
                21
            ]
        }
    },
    "2e43df55e0d8dd60b05349b26c84958e5ee55841": {
        "datetime": "2014-01-02T23:00:22-08:00",
        "summary": "fixes #265: add semver validation checks to non-bundle builds",
        "message": "fixes #265: add semver validation checks to non-bundle builds\n",
        "diff": {
            "parquet-avro/pom.xml": null,
            "parquet-cascading/pom.xml": null,
            "parquet-column/pom.xml": null,
            "parquet-common/pom.xml": null,
            "parquet-encoding/pom.xml": null,
            "parquet-generator/pom.xml": null,
            "parquet-hadoop/pom.xml": null,
            "parquet-pig/pom.xml": null,
            "parquet-scrooge/pom.xml": null,
            "parquet-test-hadoop2/pom.xml": null,
            "parquet-thrift/pom.xml": null
        }
    },
    "7dac815773821154f76b38adc0e6ca75fcbdc4fa": {
        "datetime": "2014-01-03T10:22:45-08:00",
        "summary": "Merge pull request #266 from aniket486/upgrade_eb_4.4",
        "message": "Merge pull request #266 from aniket486/upgrade_eb_4.4\n\nupgrade parquet-mr to elephant-bird 4.4",
        "diff": {
            "parquet-thrift/pom.xml": null,
            "parquet-thrift/src/test/java/parquet/thrift/TestParquetReadProtocol.java": [
                1,
                3
            ],
            "parquet-thrift/src/test/java/parquet/thrift/TestParquetWriteProtocol.java": [
                33,
                49
            ],
            "parquet-thrift/src/test/java/parquet/thrift/TestThriftToPigCompatibility.java": [
                1,
                3
            ]
        }
    },
    "79cc35df33325166d24b68be6f13e19d24370c91": {
        "datetime": "2014-01-03T10:36:46-08:00",
        "summary": "Merge pull request #267 from Parquet/handler_only_handle_ignored_fields",
        "message": "Merge pull request #267 from Parquet/handler_only_handle_ignored_fields\n\nhandler only handle ignored field, exception during will be thrown as Sk...",
        "diff": {
            "parquet-thrift/src/main/java/parquet/hadoop/thrift/ParquetThriftBytesOutputFormat.java": [
                2,
                2
            ],
            "parquet-thrift/src/main/java/parquet/hadoop/thrift/ThriftBytesWriteSupport.java": [
                3,
                3
            ],
            "parquet-thrift/src/main/java/parquet/hadoop/thrift/ThriftToParquetFileWriter.java": [
                3,
                3
            ],
            "parquet-thrift/src/main/java/parquet/thrift/BufferedProtocolReadToWrite.java": [
                29,
                12
            ],
            "parquet-thrift/src/main/java/parquet/thrift/ReadWriteErrorHandler.java": [
                17,
                6
            ],
            "parquet-thrift/src/test/java/parquet/thrift/TestProtocolReadToWrite.java": [
                49,
                21
            ]
        }
    },
    "5f57e46305f329e3355d934424f380284fdc1d8d": {
        "datetime": "2014-01-03T12:31:26-08:00",
        "summary": "bump maven-enforcer to 1.3.1 and remove some xml cruft",
        "message": "bump maven-enforcer to 1.3.1 and remove some xml cruft\n",
        "diff": {
            "parquet-avro/pom.xml": null,
            "parquet-cascading/pom.xml": null,
            "parquet-column/pom.xml": null,
            "parquet-common/pom.xml": null,
            "parquet-encoding/pom.xml": null,
            "parquet-generator/pom.xml": null,
            "parquet-hadoop/pom.xml": null,
            "parquet-pig/pom.xml": null,
            "parquet-scrooge/pom.xml": null,
            "parquet-test-hadoop2/pom.xml": null,
            "parquet-thrift/pom.xml": null
        }
    },
    "9199f3e6ab5ab88d4c0f02f6a5201b9382097a06": {
        "datetime": "2014-01-03T13:21:05-08:00",
        "summary": "[maven-release-plugin] prepare release parquet-1.3.1",
        "message": "[maven-release-plugin] prepare release parquet-1.3.1\n",
        "diff": {
            "parquet-avro/pom.xml": null,
            "parquet-cascading/pom.xml": null,
            "parquet-column/pom.xml": null,
            "parquet-common/pom.xml": null,
            "parquet-encoding/pom.xml": null,
            "parquet-generator/pom.xml": null,
            "parquet-hadoop-bundle/pom.xml": null,
            "parquet-hadoop/pom.xml": null,
            "parquet-hive-bundle/pom.xml": null,
            "parquet-hive/parquet-hive-binding/parquet-hive-0.10-binding/pom.xml": null,
            "parquet-hive/parquet-hive-binding/parquet-hive-0.12-binding/pom.xml": null,
            "parquet-hive/parquet-hive-binding/parquet-hive-binding-bundle/pom.xml": null,
            "parquet-hive/parquet-hive-binding/parquet-hive-binding-factory/pom.xml": null,
            "parquet-hive/parquet-hive-binding/parquet-hive-binding-interface/pom.xml": null,
            "parquet-hive/parquet-hive-binding/pom.xml": null,
            "parquet-hive/parquet-hive-storage-handler/pom.xml": null,
            "parquet-hive/pom.xml": null,
            "parquet-pig-bundle/pom.xml": null,
            "parquet-pig/pom.xml": null,
            "parquet-scrooge/pom.xml": null,
            "parquet-test-hadoop2/pom.xml": null,
            "parquet-thrift/pom.xml": null,
            "pom.xml": null
        }
    },
    "a906f0fe02aa849dc854890df4b60b57e44d7dd4": {
        "datetime": "2014-01-03T13:21:09-08:00",
        "summary": "[maven-release-plugin] prepare for next development iteration",
        "message": "[maven-release-plugin] prepare for next development iteration\n",
        "diff": {
            "parquet-avro/pom.xml": null,
            "parquet-cascading/pom.xml": null,
            "parquet-column/pom.xml": null,
            "parquet-common/pom.xml": null,
            "parquet-encoding/pom.xml": null,
            "parquet-generator/pom.xml": null,
            "parquet-hadoop-bundle/pom.xml": null,
            "parquet-hadoop/pom.xml": null,
            "parquet-hive-bundle/pom.xml": null,
            "parquet-hive/parquet-hive-binding/parquet-hive-0.10-binding/pom.xml": null,
            "parquet-hive/parquet-hive-binding/parquet-hive-0.12-binding/pom.xml": null,
            "parquet-hive/parquet-hive-binding/parquet-hive-binding-bundle/pom.xml": null,
            "parquet-hive/parquet-hive-binding/parquet-hive-binding-factory/pom.xml": null,
            "parquet-hive/parquet-hive-binding/parquet-hive-binding-interface/pom.xml": null,
            "parquet-hive/parquet-hive-binding/pom.xml": null,
            "parquet-hive/parquet-hive-storage-handler/pom.xml": null,
            "parquet-hive/pom.xml": null,
            "parquet-pig-bundle/pom.xml": null,
            "parquet-pig/pom.xml": null,
            "parquet-scrooge/pom.xml": null,
            "parquet-test-hadoop2/pom.xml": null,
            "parquet-thrift/pom.xml": null,
            "pom.xml": null
        }
    },
    "954f39b8234ddeaa64f495724f6cc4926a786096": {
        "datetime": "2014-01-03T22:37:06+01:00",
        "summary": "new ElephantBird (4.3) + correct dependencies.",
        "message": "new ElephantBird (4.3) + correct dependencies.\n",
        "diff": {
            "parquet-protobuf/pom.xml": null
        }
    },
    "b752260ccd27b8decd6080dc54cce0d255e0140b": {
        "datetime": "2014-01-03T23:22:41+01:00",
        "summary": "ElephantBird 4.4 + hadoop client dependency",
        "message": "ElephantBird 4.4 + hadoop client dependency\n",
        "diff": {
            "parquet-protobuf/pom.xml": null
        }
    },
    "063edb4feb4c74b4d8b3e48256becfa2a5320c44": {
        "datetime": "2014-01-03T15:33:04-08:00",
        "summary": "Merge pull request #260 from laurentgo/add-parquet-jackson-module",
        "message": "Merge pull request #260 from laurentgo/add-parquet-jackson-module\n\nShade jackson only once for all parquet modules",
        "diff": {
            "parquet-hadoop/pom.xml": null,
            "parquet-jackson/README.md": null,
            "parquet-jackson/pom.xml": null,
            "parquet-pig/pom.xml": null,
            "parquet-scrooge/pom.xml": null,
            "parquet-thrift/pom.xml": null,
            "pom.xml": null
        }
    },
    "55ebcac5b738a302ba888405371542a8794ea7ab": {
        "datetime": "2014-01-03T16:22:54-08:00",
        "summary": "Bumps parquet-jackson parent version",
        "message": "Bumps parquet-jackson parent version\n",
        "diff": {
            "parquet-jackson/pom.xml": null
        }
    },
    "283293fa830858e33999880e27892b1754e6120a": {
        "datetime": "2014-01-03T16:42:56-08:00",
        "summary": "Merge pull request #269 from laurentgo/fix-parquet-jackson-parent-version",
        "message": "Merge pull request #269 from laurentgo/fix-parquet-jackson-parent-version\n\nBumps parquet-jackson parent version",
        "diff": {
            "parquet-jackson/pom.xml": null
        }
    },
    "da9642074fe1eefcaababfc79cee6cb73065d2a1": {
        "datetime": "2014-01-03T17:09:35-08:00",
        "summary": "Merge branch 'master' of github.com:Parquet/parquet-mr into add_semver_checks",
        "message": "Merge branch 'master' of github.com:Parquet/parquet-mr into add_semver_checks\n",
        "diff": {
            "parquet-avro/pom.xml": null,
            "parquet-cascading/pom.xml": null,
            "parquet-column/pom.xml": null,
            "parquet-common/pom.xml": null,
            "parquet-encoding/pom.xml": null,
            "parquet-generator/pom.xml": null,
            "parquet-hadoop-bundle/pom.xml": null,
            "parquet-hadoop/pom.xml": null,
            "parquet-hive-bundle/pom.xml": null,
            "parquet-hive/parquet-hive-binding/parquet-hive-0.10-binding/pom.xml": null,
            "parquet-hive/parquet-hive-binding/parquet-hive-0.12-binding/pom.xml": null,
            "parquet-hive/parquet-hive-binding/parquet-hive-binding-bundle/pom.xml": null,
            "parquet-hive/parquet-hive-binding/parquet-hive-binding-factory/pom.xml": null,
            "parquet-hive/parquet-hive-binding/parquet-hive-binding-interface/pom.xml": null,
            "parquet-hive/parquet-hive-binding/pom.xml": null,
            "parquet-hive/parquet-hive-storage-handler/pom.xml": null,
            "parquet-hive/pom.xml": null,
            "parquet-jackson/README.md": null,
            "parquet-jackson/pom.xml": null,
            "parquet-pig-bundle/pom.xml": null,
            "parquet-pig/pom.xml": null,
            "parquet-scrooge/pom.xml": null,
            "parquet-test-hadoop2/pom.xml": null,
            "parquet-thrift/pom.xml": null,
            "parquet-thrift/src/main/java/parquet/hadoop/thrift/ParquetThriftBytesOutputFormat.java": [
                2,
                2
            ],
            "parquet-thrift/src/main/java/parquet/hadoop/thrift/ThriftBytesWriteSupport.java": [
                3,
                3
            ],
            "parquet-thrift/src/main/java/parquet/hadoop/thrift/ThriftToParquetFileWriter.java": [
                3,
                3
            ],
            "parquet-thrift/src/main/java/parquet/thrift/BufferedProtocolReadToWrite.java": [
                29,
                12
            ],
            "parquet-thrift/src/main/java/parquet/thrift/ReadWriteErrorHandler.java": [
                17,
                6
            ],
            "parquet-thrift/src/test/java/parquet/thrift/TestParquetReadProtocol.java": [
                1,
                3
            ],
            "parquet-thrift/src/test/java/parquet/thrift/TestParquetWriteProtocol.java": [
                33,
                49
            ],
            "parquet-thrift/src/test/java/parquet/thrift/TestProtocolReadToWrite.java": [
                49,
                21
            ],
            "parquet-thrift/src/test/java/parquet/thrift/TestThriftToPigCompatibility.java": [
                1,
                3
            ],
            "pom.xml": null
        }
    },
    "4dae164fe36075b8470a1cd9d7ac365982a48e29": {
        "datetime": "2014-01-05T16:31:34+01:00",
        "summary": "unused method in TestUtils",
        "message": "unused method in TestUtils\n",
        "diff": {
            "parquet-protobuf/src/test/java/parquet/proto/ProtoRecordConverterTest.java": [
                0,
                2
            ],
            "parquet-protobuf/src/test/java/parquet/proto/TestUtils.java": [
                5,
                1
            ]
        }
    },
    "bc610e51fdb6517dccaa08b864bb69e55af6b6ef": {
        "datetime": "2014-01-05T16:35:46+01:00",
        "summary": "pom version 1.3.2-SNAPSHOT",
        "message": "pom version 1.3.2-SNAPSHOT\n",
        "diff": {
            "parquet-protobuf/pom.xml": null
        }
    },
    "880da33d81a6f600064d26b53a17ed23f370469e": {
        "datetime": "2014-01-05T15:40:50-08:00",
        "summary": "ignore jackson packaging changes w.r.t semver",
        "message": "ignore jackson packaging changes w.r.t semver\n",
        "diff": {
            "parquet-avro/pom.xml": null,
            "parquet-hadoop/pom.xml": null,
            "parquet-pig/pom.xml": null,
            "parquet-thrift/pom.xml": null
        }
    },
    "3830a1545ad1ef824db0d721c4da71a7a3c60c88": {
        "datetime": "2014-01-05T15:41:20-08:00",
        "summary": "add maven central as a repo to work around Travis build issues with semver",
        "message": "add maven central as a repo to work around Travis build issues with semver\n",
        "diff": {
            "pom.xml": null
        }
    },
    "c1e86d80f372f1a1f33064a063661d114c3a5230": {
        "datetime": "2014-01-05T16:20:46-08:00",
        "summary": "remove snapshots=false from maven central xml",
        "message": "remove snapshots=false from maven central xml\n",
        "diff": {
            "pom.xml": null
        }
    },
    "81ab42663de1c0976fea942374227808443662ed": {
        "datetime": "2014-01-06T18:31:52+01:00",
        "summary": "Make package java.parquet.proto.converters (mostly) package protected",
        "message": "Make package java.parquet.proto.converters (mostly) package protected\n",
        "diff": {
            "parquet-protobuf/src/main/java/parquet/proto/ProtoRecordConverter.java": [
                3,
                3
            ],
            "parquet-protobuf/src/main/java/parquet/proto/ProtoRecordMaterializer.java": [
                0,
                1
            ],
            "parquet-protobuf/src/main/java/parquet/proto/converters/ParentValueContainer.java": [
                1,
                1
            ],
            "parquet-protobuf/src/main/java/parquet/proto/converters/ProtoArrayConverter.java": [
                1,
                1
            ],
            "parquet-protobuf/src/main/java/parquet/proto/converters/ProtoBinaryConverter.java": [
                1,
                1
            ],
            "parquet-protobuf/src/main/java/parquet/proto/converters/ProtoBooleanConverter.java": [
                1,
                1
            ],
            "parquet-protobuf/src/main/java/parquet/proto/converters/ProtoDoubleConverter.java": [
                1,
                1
            ],
            "parquet-protobuf/src/main/java/parquet/proto/converters/ProtoEnumConverter.java": [
                1,
                1
            ],
            "parquet-protobuf/src/main/java/parquet/proto/converters/ProtoFloatConverter.java": [
                1,
                1
            ],
            "parquet-protobuf/src/main/java/parquet/proto/converters/ProtoIntConverter.java": [
                1,
                1
            ],
            "parquet-protobuf/src/main/java/parquet/proto/converters/ProtoLongConverter.java": [
                1,
                1
            ],
            "parquet-protobuf/src/main/java/parquet/proto/converters/ProtoMessageConverter.java": [
                1,
                1
            ],
            "parquet-protobuf/src/main/java/parquet/proto/converters/ProtoStringConverter.java": [
                1,
                1
            ],
            "parquet-protobuf/src/test/java/parquet/proto/ProtoRecordConverterTest.java": [
                1,
                1
            ]
        }
    },
    "2207cb95ba17bfabdd9e03ef035aa1349f162fd6": {
        "datetime": "2014-01-06T20:38:19+01:00",
        "summary": "switches on enums",
        "message": "switches on enums\n",
        "diff": {
            "parquet-protobuf/src/main/java/parquet/proto/ProtoSchemaConverter.java": [
                20,
                15
            ],
            "parquet-protobuf/src/main/java/parquet/proto/ProtoWriteSupport.java": [
                28,
                37
            ]
        }
    },
    "09914752a40cc7f950695b66395d1fe783a97224": {
        "datetime": "2014-01-06T20:41:14+01:00",
        "summary": "Code style - small fixes",
        "message": "Code style - small fixes\n",
        "diff": {
            "parquet-protobuf/src/main/java/parquet/proto/ProtoParquetReader.java": [
                3,
                2
            ],
            "parquet-protobuf/src/main/java/parquet/proto/ProtoParquetWriter.java": [
                5,
                5
            ],
            "parquet-protobuf/src/main/java/parquet/proto/converters/ProtoBooleanConverter.java": [
                1,
                1
            ]
        }
    },
    "f232e7793f85d1cd4c2121c8d14df73a217e4df3": {
        "datetime": "2014-01-06T15:09:24-08:00",
        "summary": "Make ParquetInputSplit extend FileSplit",
        "message": "Make ParquetInputSplit extend FileSplit\n",
        "diff": {
            "parquet-hadoop/src/main/java/parquet/hadoop/ParquetInputSplit.java": [
                62,
                14
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/mapred/DeprecatedParquetInputFormat.java": [
                10,
                0
            ],
            "pom.xml": null
        }
    },
    "5c6876accde093e56efb244345f1b77e3bce7144": {
        "datetime": "2014-01-06T15:27:52-08:00",
        "summary": "Revert \"Make ParquetInputSplit extend FileSplit\"",
        "message": "Revert \"Make ParquetInputSplit extend FileSplit\"\n\nThis reverts commit f232e7793f85d1cd4c2121c8d14df73a217e4df3.\n",
        "diff": {
            "parquet-hadoop/src/main/java/parquet/hadoop/ParquetInputSplit.java": [
                14,
                62
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/mapred/DeprecatedParquetInputFormat.java": [
                0,
                10
            ],
            "pom.xml": null
        }
    },
    "af880ec55c070b9239f073b36e6b95e888b4a684": {
        "datetime": "2014-01-06T15:42:58-08:00",
        "summary": "Make ParquetInputSplit extend FileSplit",
        "message": "Make ParquetInputSplit extend FileSplit\n",
        "diff": {
            "parquet-hadoop/src/main/java/parquet/hadoop/ParquetInputSplit.java": [
                62,
                14
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/mapred/DeprecatedParquetInputFormat.java": [
                10,
                0
            ]
        }
    },
    "6664165962e47903e3facb289e617d0b323a0acf": {
        "datetime": "2014-01-06T17:07:15-08:00",
        "summary": "fix MapredParquetInputFormat exception issue caused by ParquetInputSplit extending FileSplit",
        "message": "fix MapredParquetInputFormat exception issue caused by ParquetInputSplit extending FileSplit\n",
        "diff": {
            "parquet-hive/parquet-hive-storage-handler/src/main/java/parquet/hive/MapredParquetInputFormat.java": [
                10,
                0
            ]
        }
    },
    "c1298b7a75e438ddfe9138876ab6be1580830785": {
        "datetime": "2014-01-07T16:59:50-08:00",
        "summary": "Force <previousVersion>",
        "message": "Force <previousVersion>\n\nSigned-off-by: Chris Aniszczyk <zx@twitter.com>\n",
        "diff": {
            "parquet-avro/pom.xml": null,
            "parquet-cascading/pom.xml": null,
            "parquet-column/pom.xml": null,
            "parquet-common/pom.xml": null,
            "parquet-encoding/pom.xml": null,
            "parquet-generator/pom.xml": null,
            "parquet-hadoop/pom.xml": null,
            "parquet-pig/pom.xml": null,
            "parquet-scrooge/pom.xml": null,
            "parquet-test-hadoop2/pom.xml": null,
            "parquet-thrift/pom.xml": null,
            "pom.xml": null
        }
    },
    "8c8cbde707f5d5708c55303e56db4b7fb8c911e3": {
        "datetime": "2014-01-07T21:12:25-08:00",
        "summary": "Merge pull request #268 from Parquet/add_semver_checks",
        "message": "Merge pull request #268 from Parquet/add_semver_checks\n\nfixes #265: add semver validation checks to non-bundle builds",
        "diff": {
            "parquet-avro/pom.xml": null,
            "parquet-cascading/pom.xml": null,
            "parquet-column/pom.xml": null,
            "parquet-common/pom.xml": null,
            "parquet-encoding/pom.xml": null,
            "parquet-generator/pom.xml": null,
            "parquet-hadoop/pom.xml": null,
            "parquet-pig/pom.xml": null,
            "parquet-scrooge/pom.xml": null,
            "parquet-test-hadoop2/pom.xml": null,
            "parquet-thrift/pom.xml": null,
            "pom.xml": null
        }
    },
    "46b1ad00a8169943d9d8b4096cdd21260a55b73a": {
        "datetime": "2014-01-07T21:45:44-08:00",
        "summary": "fix bug: when enum index being written is the last index defined in the Enum, a DecodingSchemaMismatchException is thrown. maintain enum loopup table in EnumType",
        "message": "fix bug: when enum index being written is the last index defined in the Enum, a DecodingSchemaMismatchException is thrown. maintain enum loopup table in EnumType\n",
        "diff": {
            "parquet-thrift/src/main/java/parquet/thrift/BufferedProtocolReadToWrite.java": [
                2,
                3
            ],
            "parquet-thrift/src/main/java/parquet/thrift/ParquetWriteProtocol.java": [
                7,
                5
            ],
            "parquet-thrift/src/main/java/parquet/thrift/ThriftRecordConverter.java": [
                1,
                1
            ],
            "parquet-thrift/src/main/java/parquet/thrift/struct/ThriftType.java": [
                3,
                25
            ],
            "parquet-thrift/src/test/java/parquet/thrift/TestProtocolReadToWrite.java": [
                2,
                4
            ]
        }
    },
    "40f9b24c036733e2d02afcb1b8c78c3feb28a5f9": {
        "datetime": "2014-01-07T22:06:18-08:00",
        "summary": "name fix",
        "message": "name fix\n",
        "diff": {
            "parquet-thrift/src/main/java/parquet/thrift/BufferedProtocolReadToWrite.java": [
                2,
                2
            ]
        }
    },
    "ff6219464d65dcf6376c0155b5c8d89e03f2bfd4": {
        "datetime": "2014-01-07T23:31:02-08:00",
        "summary": "Merge pull request #271 from Parquet/fix_bug_enum_last_value_exception",
        "message": "Merge pull request #271 from Parquet/fix_bug_enum_last_value_exception\n\nfix bug: last enum index throws DecodingSchemaMismatchException",
        "diff": {
            "parquet-thrift/src/main/java/parquet/thrift/BufferedProtocolReadToWrite.java": [
                2,
                3
            ],
            "parquet-thrift/src/main/java/parquet/thrift/ParquetWriteProtocol.java": [
                7,
                5
            ],
            "parquet-thrift/src/main/java/parquet/thrift/ThriftRecordConverter.java": [
                1,
                1
            ],
            "parquet-thrift/src/main/java/parquet/thrift/struct/ThriftType.java": [
                3,
                25
            ],
            "parquet-thrift/src/test/java/parquet/thrift/TestProtocolReadToWrite.java": [
                2,
                4
            ]
        }
    },
    "b2184b8468268cc2d99211693b827fd78fd1bfae": {
        "datetime": "2014-01-07T23:49:47-08:00",
        "summary": "add 1.3.1",
        "message": "add 1.3.1",
        "diff": {
            "CHANGES.md": null
        }
    },
    "8fb0b022b52325b5c033ecdad3c1553dbd50f10b": {
        "datetime": "2014-01-07T23:50:05-08:00",
        "summary": "Update CHANGES.md",
        "message": "Update CHANGES.md",
        "diff": {
            "CHANGES.md": null
        }
    },
    "0dfb067a348d8e13d216857613fe1c52c7a4de6b": {
        "datetime": "2014-01-08T10:17:45-08:00",
        "summary": "[maven-release-plugin] prepare release parquet-1.3.2",
        "message": "[maven-release-plugin] prepare release parquet-1.3.2\n",
        "diff": {
            "parquet-avro/pom.xml": null,
            "parquet-cascading/pom.xml": null,
            "parquet-column/pom.xml": null,
            "parquet-common/pom.xml": null,
            "parquet-encoding/pom.xml": null,
            "parquet-generator/pom.xml": null,
            "parquet-hadoop-bundle/pom.xml": null,
            "parquet-hadoop/pom.xml": null,
            "parquet-hive-bundle/pom.xml": null,
            "parquet-hive/parquet-hive-binding/parquet-hive-0.10-binding/pom.xml": null,
            "parquet-hive/parquet-hive-binding/parquet-hive-0.12-binding/pom.xml": null,
            "parquet-hive/parquet-hive-binding/parquet-hive-binding-bundle/pom.xml": null,
            "parquet-hive/parquet-hive-binding/parquet-hive-binding-factory/pom.xml": null,
            "parquet-hive/parquet-hive-binding/parquet-hive-binding-interface/pom.xml": null,
            "parquet-hive/parquet-hive-binding/pom.xml": null,
            "parquet-hive/parquet-hive-storage-handler/pom.xml": null,
            "parquet-hive/pom.xml": null,
            "parquet-jackson/pom.xml": null,
            "parquet-pig-bundle/pom.xml": null,
            "parquet-pig/pom.xml": null,
            "parquet-scrooge/pom.xml": null,
            "parquet-test-hadoop2/pom.xml": null,
            "parquet-thrift/pom.xml": null,
            "pom.xml": null
        }
    },
    "f012db02f1e3b0f683ad6ae88bc2e50b5fe994be": {
        "datetime": "2014-01-08T10:17:49-08:00",
        "summary": "[maven-release-plugin] prepare for next development iteration",
        "message": "[maven-release-plugin] prepare for next development iteration\n",
        "diff": {
            "parquet-avro/pom.xml": null,
            "parquet-cascading/pom.xml": null,
            "parquet-column/pom.xml": null,
            "parquet-common/pom.xml": null,
            "parquet-encoding/pom.xml": null,
            "parquet-generator/pom.xml": null,
            "parquet-hadoop-bundle/pom.xml": null,
            "parquet-hadoop/pom.xml": null,
            "parquet-hive-bundle/pom.xml": null,
            "parquet-hive/parquet-hive-binding/parquet-hive-0.10-binding/pom.xml": null,
            "parquet-hive/parquet-hive-binding/parquet-hive-0.12-binding/pom.xml": null,
            "parquet-hive/parquet-hive-binding/parquet-hive-binding-bundle/pom.xml": null,
            "parquet-hive/parquet-hive-binding/parquet-hive-binding-factory/pom.xml": null,
            "parquet-hive/parquet-hive-binding/parquet-hive-binding-interface/pom.xml": null,
            "parquet-hive/parquet-hive-binding/pom.xml": null,
            "parquet-hive/parquet-hive-storage-handler/pom.xml": null,
            "parquet-hive/pom.xml": null,
            "parquet-jackson/pom.xml": null,
            "parquet-pig-bundle/pom.xml": null,
            "parquet-pig/pom.xml": null,
            "parquet-scrooge/pom.xml": null,
            "parquet-test-hadoop2/pom.xml": null,
            "parquet-thrift/pom.xml": null,
            "pom.xml": null
        }
    },
    "9bdaff93041368a5c03c1bf71d1c093242cd5d67": {
        "datetime": "2014-01-08T11:13:40-08:00",
        "summary": "Add code of conduct to Readme.md",
        "message": "Add code of conduct to Readme.md",
        "diff": {
            "README.md": null
        }
    },
    "ac8968ec23bc59937f56394648a2797fcbf486e4": {
        "datetime": "2014-01-08T12:36:31-08:00",
        "summary": "prettify a few lines",
        "message": "prettify a few lines\n",
        "diff": {
            "parquet-hadoop/src/main/java/parquet/hadoop/ParquetInputSplit.java": [
                1,
                3
            ]
        }
    },
    "471a693e39850eaa30931b765a6c99d21d656c90": {
        "datetime": "2014-01-08T14:46:22-08:00",
        "summary": "1.3.2",
        "message": "1.3.2",
        "diff": {
            "CHANGES.md": null
        }
    },
    "d40381aff0c1eb7c88190f83ae57f32bde877645": {
        "datetime": "2014-01-08T23:22:36-08:00",
        "summary": "Upgrade maven-shade-plugin to 2.1 to compile with mvn 3.1.1",
        "message": "Upgrade maven-shade-plugin to 2.1 to compile with mvn 3.1.1\n",
        "diff": {
            "pom.xml": null
        }
    },
    "4b517aec78cbe542939a9c0f03f9723cdc641217": {
        "datetime": "2014-01-09T10:45:24-08:00",
        "summary": "Merge pull request #80 from gerashegalov/master",
        "message": "Merge pull request #80 from gerashegalov/master\n\nUpgrade maven-shade-plugin to 2.1 to compile with mvn 3.1.1",
        "diff": {}
    },
    "81f33a66055ee9ba23ccc6d9422f0c27304e12ad": {
        "datetime": "2014-01-11T21:20:13-08:00",
        "summary": "Merge remote branch 'upstream/master'",
        "message": "Merge remote branch 'upstream/master'\n",
        "diff": {
            "CHANGES.md": null,
            "README.md": null,
            "parquet-avro/pom.xml": null,
            "parquet-cascading/pom.xml": null,
            "parquet-column/pom.xml": null,
            "parquet-common/pom.xml": null,
            "parquet-encoding/pom.xml": null,
            "parquet-generator/pom.xml": null,
            "parquet-hadoop-bundle/pom.xml": null,
            "parquet-hadoop/pom.xml": null,
            "parquet-hive-bundle/pom.xml": null,
            "parquet-hive/parquet-hive-binding/parquet-hive-0.10-binding/pom.xml": null,
            "parquet-hive/parquet-hive-binding/parquet-hive-0.12-binding/pom.xml": null,
            "parquet-hive/parquet-hive-binding/parquet-hive-binding-bundle/pom.xml": null,
            "parquet-hive/parquet-hive-binding/parquet-hive-binding-factory/pom.xml": null,
            "parquet-hive/parquet-hive-binding/parquet-hive-binding-interface/pom.xml": null,
            "parquet-hive/parquet-hive-binding/pom.xml": null,
            "parquet-hive/parquet-hive-storage-handler/pom.xml": null,
            "parquet-hive/pom.xml": null,
            "parquet-jackson/README.md": null,
            "parquet-jackson/pom.xml": null,
            "parquet-pig-bundle/pom.xml": null,
            "parquet-pig/pom.xml": null,
            "parquet-scrooge/pom.xml": null,
            "parquet-test-hadoop2/pom.xml": null,
            "parquet-thrift/pom.xml": null,
            "parquet-thrift/src/main/java/parquet/hadoop/thrift/ParquetThriftBytesOutputFormat.java": [
                2,
                2
            ],
            "parquet-thrift/src/main/java/parquet/hadoop/thrift/ThriftBytesWriteSupport.java": [
                3,
                3
            ],
            "parquet-thrift/src/main/java/parquet/hadoop/thrift/ThriftToParquetFileWriter.java": [
                3,
                3
            ],
            "parquet-thrift/src/main/java/parquet/thrift/BufferedProtocolReadToWrite.java": [
                31,
                15
            ],
            "parquet-thrift/src/main/java/parquet/thrift/ParquetWriteProtocol.java": [
                7,
                5
            ],
            "parquet-thrift/src/main/java/parquet/thrift/ReadWriteErrorHandler.java": [
                17,
                6
            ],
            "parquet-thrift/src/main/java/parquet/thrift/ThriftRecordConverter.java": [
                1,
                1
            ],
            "parquet-thrift/src/main/java/parquet/thrift/struct/ThriftType.java": [
                3,
                25
            ],
            "parquet-thrift/src/test/java/parquet/thrift/TestParquetReadProtocol.java": [
                1,
                3
            ],
            "parquet-thrift/src/test/java/parquet/thrift/TestParquetWriteProtocol.java": [
                33,
                49
            ],
            "parquet-thrift/src/test/java/parquet/thrift/TestProtocolReadToWrite.java": [
                51,
                25
            ],
            "parquet-thrift/src/test/java/parquet/thrift/TestThriftToPigCompatibility.java": [
                1,
                3
            ],
            "pom.xml": null
        }
    },
    "c00409aeca05566cf884f35249c4d0e922f44370": {
        "datetime": "2014-01-11T21:30:22-08:00",
        "summary": "exclude ParquetInputSplit from semver check which seems to have an issue with inherited method check",
        "message": "exclude ParquetInputSplit from semver check which seems to have an issue with inherited method check\n",
        "diff": {
            "parquet-hadoop/pom.xml": null
        }
    },
    "21faa3d82f4f4c10713b07544a0650b896f67ef8": {
        "datetime": "2014-01-13T23:20:56-08:00",
        "summary": "Merge pull request #270 from ledbit/master",
        "message": "Merge pull request #270 from ledbit/master\n\nMake ParquetInputSplit extend FileSplit",
        "diff": {
            "parquet-hadoop/pom.xml": null,
            "parquet-hadoop/src/main/java/parquet/hadoop/ParquetInputSplit.java": [
                62,
                16
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/mapred/DeprecatedParquetInputFormat.java": [
                10,
                0
            ],
            "parquet-hive/parquet-hive-storage-handler/src/main/java/parquet/hive/MapredParquetInputFormat.java": [
                10,
                0
            ]
        }
    },
    "a8be812545907cd7dc2c51832c1c02a9767aa2be": {
        "datetime": "2014-01-15T18:30:56+01:00",
        "summary": "Readme.md - mark Protobuf support as in dev",
        "message": "Readme.md - mark Protobuf support as in dev\n",
        "diff": {
            "README.md": null
        }
    },
    "a2691a742379c023acb2e7a3d6ae7bd08f92a8be": {
        "datetime": "2014-01-16T10:43:40+01:00",
        "summary": "Exception message",
        "message": "Exception message\n",
        "diff": {
            "parquet-column/src/main/java/parquet/io/api/Converter.java": [
                2,
                2
            ]
        }
    },
    "6763f71bdb48cc3f955825ed5e2090ca10688d54": {
        "datetime": "2014-01-16T18:50:24+01:00",
        "summary": "storage of repeated fields without extra level",
        "message": "storage of repeated fields without extra level\n",
        "diff": {
            "parquet-protobuf/src/main/java/parquet/proto/ProtoSchemaConverter.java": [
                10,
                1
            ],
            "parquet-protobuf/src/main/java/parquet/proto/ProtoWriteSupport.java": [
                41,
                96
            ],
            "parquet-protobuf/src/main/java/parquet/proto/converters/ProtoArrayConverter.java": [
                44,
                0
            ],
            "parquet-protobuf/src/main/java/parquet/proto/converters/ProtoMessageConverter.java": [
                28,
                6
            ],
            "parquet-protobuf/src/test/java/parquet/proto/ProtoSchemaConverterTest.java": [
                7,
                3
            ],
            "parquet-protobuf/src/test/java/parquet/proto/converters/ProtoRecordConverterTest.java": [
                0,
                19
            ]
        }
    },
    "bbacdf0aa67dd74351e04310b0b383021c2aa2c3": {
        "datetime": "2014-01-16T18:52:07+01:00",
        "summary": "storage of repeated fields without extra level - missing protobuffer",
        "message": "storage of repeated fields without extra level - missing protobuffer\n",
        "diff": {
            "parquet-protobuf/src/test/resources/TestProtobuf.proto": null
        }
    },
    "b25de9814b5d20afe380a0fe1e59d3329102e1d0": {
        "datetime": "2014-01-17T20:44:30-08:00",
        "summary": "style: junit.framework to org.junit",
        "message": "style: junit.framework to org.junit\n",
        "diff": {
            "parquet-hive/parquet-hive-storage-handler/src/test/java/parquet/hive/TestParquetSerDe.java": [
                1,
                1
            ],
            "parquet-hive/parquet-hive-storage-handler/src/test/java/parquet/hive/serde/TestAbstractParquetMapInspector.java": [
                1,
                1
            ],
            "parquet-hive/parquet-hive-storage-handler/src/test/java/parquet/hive/serde/TestDeepParquetHiveMapInspector.java": [
                1,
                1
            ],
            "parquet-hive/parquet-hive-storage-handler/src/test/java/parquet/hive/serde/TestParquetHiveArrayInspector.java": [
                1,
                1
            ],
            "parquet-hive/parquet-hive-storage-handler/src/test/java/parquet/hive/serde/TestStandardParquetHiveMapInspector.java": [
                1,
                1
            ],
            "parquet-thrift/src/test/java/parquet/hadoop/thrift/TestInputOutputFormat.java": [
                1,
                1
            ],
            "parquet-thrift/src/test/java/parquet/thrift/TestThriftParquetReaderWriter.java": [
                1,
                1
            ],
            "parquet-thrift/src/test/java/parquet/thrift/struct/CompatibilityCheckerTest.java": [
                1,
                1
            ]
        }
    },
    "da17462e59a01b01017b0a90a2e850e2743ce663": {
        "datetime": "2014-01-19T00:04:38+01:00",
        "summary": "Matching parquet and pbfields by index",
        "message": "Matching parquet and pbfields by index\n",
        "diff": {
            "parquet-protobuf/src/main/java/parquet/proto/ProtoWriteSupport.java": [
                25,
                36
            ]
        }
    },
    "3c0ab7a908e7e503660781c94f463c8f3f314ec3": {
        "datetime": "2014-01-19T00:29:39+01:00",
        "summary": "List cannot be empty",
        "message": "List cannot be empty\n",
        "diff": {
            "parquet-protobuf/src/main/java/parquet/proto/ProtoWriteSupport.java": [
                9,
                5
            ]
        }
    },
    "942cfe26cceb69cc420e5019f854213c654ec844": {
        "datetime": "2014-01-19T00:31:15+01:00",
        "summary": "Dictionary enum conversion",
        "message": "Dictionary enum conversion\n",
        "diff": {
            "parquet-protobuf/src/main/java/parquet/proto/converters/ProtoEnumConverter.java": [
                6,
                39
            ]
        }
    },
    "d00eb4e682599300d9b1f5a1e22594da6700cf80": {
        "datetime": "2014-01-23T14:46:31-08:00",
        "summary": "Merge branch 'master' of github.com:Parquet/parquet-mr into junit_framework_to_org",
        "message": "Merge branch 'master' of github.com:Parquet/parquet-mr into junit_framework_to_org\n",
        "diff": {
            "CHANGES.md": null,
            "parquet-hadoop/pom.xml": null,
            "parquet-hadoop/src/main/java/parquet/hadoop/ParquetInputSplit.java": [
                62,
                16
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/mapred/DeprecatedParquetInputFormat.java": [
                10,
                0
            ],
            "parquet-hive/parquet-hive-storage-handler/src/main/java/parquet/hive/MapredParquetInputFormat.java": [
                10,
                0
            ]
        }
    },
    "e4329cde9f32e8f3cea88d82420d0ab920348d02": {
        "datetime": "2014-01-23T15:51:17-08:00",
        "summary": "move from junit3 to junit4",
        "message": "move from junit3 to junit4\n",
        "diff": {
            "parquet-hive/parquet-hive-storage-handler/src/test/java/parquet/hive/TestParquetSerDe.java": [
                2,
                6
            ],
            "parquet-hive/parquet-hive-storage-handler/src/test/java/parquet/hive/serde/TestAbstractParquetMapInspector.java": [
                5,
                6
            ],
            "parquet-hive/parquet-hive-storage-handler/src/test/java/parquet/hive/serde/TestDeepParquetHiveMapInspector.java": [
                3,
                5
            ],
            "parquet-hive/parquet-hive-storage-handler/src/test/java/parquet/hive/serde/TestParquetHiveArrayInspector.java": [
                4,
                5
            ],
            "parquet-hive/parquet-hive-storage-handler/src/test/java/parquet/hive/serde/TestStandardParquetHiveMapInspector.java": [
                4,
                6
            ]
        }
    },
    "6edfa7e6ee517536dbde935c0c6cfc68e7155b44": {
        "datetime": "2014-01-25T00:32:42+01:00",
        "summary": "ProtoWriteSupport unit tests",
        "message": "ProtoWriteSupport unit tests\n",
        "diff": {
            "parquet-protobuf/src/test/java/parquet/proto/ProtoWriteSupportTest.java": [
                0,
                143
            ],
            "parquet-protobuf/src/test/resources/TestProtobuf.proto": null
        }
    },
    "8cc4cecd580438643c3423bf147c476c8ad606e0": {
        "datetime": "2014-01-25T18:08:48+01:00",
        "summary": "New ProtoWriteSupport",
        "message": "New ProtoWriteSupport\n",
        "diff": {
            "parquet-protobuf/pom.xml": null,
            "parquet-protobuf/src/main/java/parquet/proto/ProtoWriteSupport.java": [
                159,
                236
            ],
            "parquet-protobuf/src/main/java/parquet/proto/converters/ProtoMessageConverter.java": [
                4,
                2
            ],
            "parquet-protobuf/src/test/java/parquet/proto/ProtoWriteSupportTest.java": [
                11,
                33
            ]
        }
    },
    "496e3fd019ad524b165242ee6fc914d9cdcbf174": {
        "datetime": "2014-01-26T14:11:35+01:00",
        "summary": "Scalar Converters are part of Message converter",
        "message": "Scalar Converters are part of Message converter\n",
        "diff": {
            "parquet-protobuf/src/main/java/parquet/proto/ProtoMessageConverter.java": [
                0,
                361
            ],
            "parquet-protobuf/src/main/java/parquet/proto/converters/ParentValueContainer.java": [
                26,
                0
            ],
            "parquet-protobuf/src/main/java/parquet/proto/converters/ProtoBinaryConverter.java": [
                36,
                0
            ],
            "parquet-protobuf/src/main/java/parquet/proto/converters/ProtoBooleanConverter.java": [
                34,
                0
            ],
            "parquet-protobuf/src/main/java/parquet/proto/converters/ProtoDoubleConverter.java": [
                33,
                0
            ],
            "parquet-protobuf/src/main/java/parquet/proto/converters/ProtoEnumConverter.java": [
                102,
                0
            ],
            "parquet-protobuf/src/main/java/parquet/proto/converters/ProtoFloatConverter.java": [
                33,
                0
            ],
            "parquet-protobuf/src/main/java/parquet/proto/converters/ProtoIntConverter.java": [
                33,
                0
            ],
            "parquet-protobuf/src/main/java/parquet/proto/converters/ProtoLongConverter.java": [
                33,
                0
            ],
            "parquet-protobuf/src/main/java/parquet/proto/converters/ProtoMessageConverter.java": [
                161,
                0
            ],
            "parquet-protobuf/src/main/java/parquet/proto/converters/ProtoRecordConverter.java": [
                3,
                6
            ],
            "parquet-protobuf/src/main/java/parquet/proto/converters/ProtoStringConverter.java": [
                37,
                0
            ],
            "parquet-protobuf/src/test/java/parquet/proto/converters/ProtoRecordConverterTest.java": [
                1,
                42
            ]
        }
    },
    "5b1b79c7cca8df23c0bb387e19a14e4c55645998": {
        "datetime": "2014-01-26T14:14:00+01:00",
        "summary": "javadoc",
        "message": "javadoc\n",
        "diff": {
            "parquet-protobuf/src/main/java/parquet/proto/ProtoMessageConverter.java": [
                0,
                2
            ],
            "parquet-protobuf/src/main/java/parquet/proto/ProtoRecordConverter.java": [
                2,
                2
            ]
        }
    },
    "02f7707e13755b6ab9e4c5a5bd8cf98152488631": {
        "datetime": "2014-01-26T14:36:57+01:00",
        "summary": "ProtoMessageConverter case",
        "message": "ProtoMessageConverter case\n",
        "diff": {
            "parquet-protobuf/src/main/java/parquet/proto/ProtoMessageConverter.java": [
                29,
                12
            ]
        }
    },
    "2d9cf95dfa0cbc2c969ff4c61f6cdae16cac87d6": {
        "datetime": "2014-01-27T18:24:37-08:00",
        "summary": "make setup calls static in tests",
        "message": "make setup calls static in tests\n",
        "diff": {
            "parquet-hive/parquet-hive-storage-handler/src/test/java/parquet/hive/serde/TestAbstractParquetMapInspector.java": [
                3,
                3
            ],
            "parquet-hive/parquet-hive-storage-handler/src/test/java/parquet/hive/serde/TestDeepParquetHiveMapInspector.java": [
                2,
                2
            ],
            "parquet-hive/parquet-hive-storage-handler/src/test/java/parquet/hive/serde/TestParquetHiveArrayInspector.java": [
                2,
                2
            ],
            "parquet-hive/parquet-hive-storage-handler/src/test/java/parquet/hive/serde/TestStandardParquetHiveMapInspector.java": [
                2,
                2
            ]
        }
    },
    "b929d196fc3190d705096362e76cd9878fbf35cf": {
        "datetime": "2014-01-28T14:26:34-08:00",
        "summary": "Merge pull request #280 from aniket486/junit_framework_to_org",
        "message": "Merge pull request #280 from aniket486/junit_framework_to_org\n\nstyle: junit.framework to org.junit",
        "diff": {
            "parquet-hive/parquet-hive-storage-handler/src/test/java/parquet/hive/TestParquetSerDe.java": [
                2,
                6
            ],
            "parquet-hive/parquet-hive-storage-handler/src/test/java/parquet/hive/serde/TestAbstractParquetMapInspector.java": [
                8,
                9
            ],
            "parquet-hive/parquet-hive-storage-handler/src/test/java/parquet/hive/serde/TestDeepParquetHiveMapInspector.java": [
                5,
                7
            ],
            "parquet-hive/parquet-hive-storage-handler/src/test/java/parquet/hive/serde/TestParquetHiveArrayInspector.java": [
                6,
                7
            ],
            "parquet-hive/parquet-hive-storage-handler/src/test/java/parquet/hive/serde/TestStandardParquetHiveMapInspector.java": [
                6,
                8
            ],
            "parquet-thrift/src/test/java/parquet/hadoop/thrift/TestInputOutputFormat.java": [
                1,
                1
            ],
            "parquet-thrift/src/test/java/parquet/thrift/TestThriftParquetReaderWriter.java": [
                1,
                1
            ],
            "parquet-thrift/src/test/java/parquet/thrift/struct/CompatibilityCheckerTest.java": [
                1,
                1
            ]
        }
    },
    "c8b7ba82e630f1813a8a1d29c9dd8585767d39bc": {
        "datetime": "2014-01-29T10:36:57+01:00",
        "summary": "Merge remote branch 'upstream/master' into protobuf",
        "message": "Merge remote branch 'upstream/master' into protobuf\n",
        "diff": {
            "CHANGES.md": null,
            "README.md": null,
            "parquet-avro/pom.xml": null,
            "parquet-cascading/pom.xml": null,
            "parquet-column/pom.xml": null,
            "parquet-column/src/main/java/parquet/column/Encoding.java": [
                2,
                29
            ],
            "parquet-column/src/main/java/parquet/column/ParquetProperties.java": [
                6,
                4
            ],
            "parquet-column/src/main/java/parquet/column/impl/ColumnReaderImpl.java": [
                3,
                5
            ],
            "parquet-column/src/main/java/parquet/column/values/ValuesReader.java": [
                2,
                11
            ],
            "parquet-column/src/main/java/parquet/column/values/bitpacking/BitPackingValuesReader.java": [
                4,
                9
            ],
            "parquet-column/src/main/java/parquet/column/values/bitpacking/ByteBitPackingValuesReader.java": [
                4,
                9
            ],
            "parquet-column/src/main/java/parquet/column/values/boundedint/BoundedIntValuesReader.java": [
                2,
                8
            ],
            "parquet-column/src/main/java/parquet/column/values/boundedint/ZeroIntegerValuesReader.java": [
                2,
                9
            ],
            "parquet-column/src/main/java/parquet/column/values/delta/DeltaBinaryPackingValuesReader.java": [
                2,
                5
            ],
            "parquet-column/src/main/java/parquet/column/values/deltalengthbytearray/DeltaLengthByteArrayValuesReader.java": [
                0,
                67
            ],
            "parquet-column/src/main/java/parquet/column/values/deltalengthbytearray/DeltaLengthByteArrayValuesWriter.java": [
                0,
                103
            ],
            "parquet-column/src/main/java/parquet/column/values/deltastrings/DeltaByteArrayReader.java": [
                0,
                75
            ],
            "parquet-column/src/main/java/parquet/column/values/deltastrings/DeltaByteArrayWriter.java": [
                0,
                89
            ],
            "parquet-column/src/main/java/parquet/column/values/dictionary/DictionaryValuesReader.java": [
                2,
                1
            ],
            "parquet-column/src/main/java/parquet/column/values/plain/BinaryPlainValuesReader.java": [
                2,
                1
            ],
            "parquet-column/src/main/java/parquet/column/values/plain/BooleanPlainValuesReader.java": [
                2,
                7
            ],
            "parquet-column/src/main/java/parquet/column/values/plain/FixedLenByteArrayPlainValuesReader.java": [
                3,
                1
            ],
            "parquet-column/src/main/java/parquet/column/values/plain/PlainValuesReader.java": [
                11,
                8
            ],
            "parquet-column/src/main/java/parquet/column/values/plain/PlainValuesWriter.java": [
                1,
                0
            ],
            "parquet-column/src/main/java/parquet/column/values/rle/RunLengthBitPackingHybridValuesReader.java": [
                13,
                13
            ],
            "parquet-column/src/main/java/parquet/column/values/rle/RunLengthBitPackingHybridValuesWriter.java": [
                0,
                5
            ],
            "parquet-column/src/test/java/parquet/column/values/RandomStr.java": [
                0,
                53
            ],
            "parquet-column/src/test/java/parquet/column/values/Utils.java": [
                0,
                87
            ],
            "parquet-column/src/test/java/parquet/column/values/boundedint/TestBoundedColumns.java": [
                1,
                2
            ],
            "parquet-column/src/test/java/parquet/column/values/delta/DeltaBinaryPackingValuesWriterTest.java": [
                9,
                6
            ],
            "parquet-column/src/test/java/parquet/column/values/deltalengthbytearray/TestDeltaLengthByteArray.java": [
                0,
                71
            ],
            "parquet-column/src/test/java/parquet/column/values/deltalengthbytearray/benchmark/BenchmarkDeltaLengthByteArray.java": [
                0,
                68
            ],
            "parquet-column/src/test/java/parquet/column/values/deltastrings/TestDeltaByteArray.java": [
                0,
                81
            ],
            "parquet-column/src/test/java/parquet/column/values/deltastrings/benchmark/BenchmarkDeltaByteArray.java": [
                0,
                98
            ],
            "parquet-common/pom.xml": null,
            "parquet-encoding/pom.xml": null,
            "parquet-generator/pom.xml": null,
            "parquet-hadoop-bundle/pom.xml": null,
            "parquet-hadoop/pom.xml": null,
            "parquet-hadoop/src/main/java/parquet/hadoop/ParquetFileReader.java": [
                128,
                307
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/ParquetInputSplit.java": [
                62,
                16
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/mapred/DeprecatedParquetInputFormat.java": [
                10,
                0
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/metadata/BlockMetaData.java": [
                1,
                2
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/metadata/ColumnChunkMetaData.java": [
                15,
                47
            ],
            "parquet-hadoop/src/test/java/parquet/hadoop/codec/CodecConfigTest.java": [
                2,
                1
            ],
            "parquet-hadoop/src/test/java/parquet/hadoop/metadata/TestColumnChunkMetaData.java": [
                0,
                64
            ],
            "parquet-hive-bundle/pom.xml": null,
            "parquet-hive/parquet-hive-binding/parquet-hive-0.10-binding/pom.xml": null,
            "parquet-hive/parquet-hive-binding/parquet-hive-0.12-binding/pom.xml": null,
            "parquet-hive/parquet-hive-binding/parquet-hive-binding-bundle/pom.xml": null,
            "parquet-hive/parquet-hive-binding/parquet-hive-binding-factory/pom.xml": null,
            "parquet-hive/parquet-hive-binding/parquet-hive-binding-interface/pom.xml": null,
            "parquet-hive/parquet-hive-binding/pom.xml": null,
            "parquet-hive/parquet-hive-storage-handler/pom.xml": null,
            "parquet-hive/parquet-hive-storage-handler/src/main/java/parquet/hive/MapredParquetInputFormat.java": [
                10,
                0
            ],
            "parquet-hive/parquet-hive-storage-handler/src/test/java/parquet/hive/TestParquetSerDe.java": [
                2,
                6
            ],
            "parquet-hive/parquet-hive-storage-handler/src/test/java/parquet/hive/serde/TestAbstractParquetMapInspector.java": [
                8,
                9
            ],
            "parquet-hive/parquet-hive-storage-handler/src/test/java/parquet/hive/serde/TestDeepParquetHiveMapInspector.java": [
                5,
                7
            ],
            "parquet-hive/parquet-hive-storage-handler/src/test/java/parquet/hive/serde/TestParquetHiveArrayInspector.java": [
                6,
                7
            ],
            "parquet-hive/parquet-hive-storage-handler/src/test/java/parquet/hive/serde/TestStandardParquetHiveMapInspector.java": [
                6,
                8
            ],
            "parquet-hive/pom.xml": null,
            "parquet-jackson/README.md": null,
            "parquet-jackson/pom.xml": null,
            "parquet-pig-bundle/pom.xml": null,
            "parquet-pig/pom.xml": null,
            "parquet-pig/src/main/java/parquet/pig/ParquetLoader.java": [
                1,
                0
            ],
            "parquet-pig/src/main/java/parquet/pig/TupleReadSupport.java": [
                4,
                0
            ],
            "parquet-pig/src/test/java/parquet/pig/TestParquetLoader.java": [
                1,
                5
            ],
            "parquet-pig/src/test/java/parquet/pig/TestPigSchemaConverter.java": [
                4,
                0
            ],
            "parquet-scrooge/pom.xml": null,
            "parquet-test-hadoop2/pom.xml": null,
            "parquet-thrift/pom.xml": null,
            "parquet-thrift/src/main/java/parquet/hadoop/thrift/ParquetThriftBytesOutputFormat.java": [
                2,
                2
            ],
            "parquet-thrift/src/main/java/parquet/hadoop/thrift/ThriftBytesWriteSupport.java": [
                3,
                3
            ],
            "parquet-thrift/src/main/java/parquet/hadoop/thrift/ThriftToParquetFileWriter.java": [
                3,
                3
            ],
            "parquet-thrift/src/main/java/parquet/thrift/BufferedProtocolReadToWrite.java": [
                31,
                15
            ],
            "parquet-thrift/src/main/java/parquet/thrift/ParquetWriteProtocol.java": [
                7,
                5
            ],
            "parquet-thrift/src/main/java/parquet/thrift/ReadWriteErrorHandler.java": [
                17,
                6
            ],
            "parquet-thrift/src/main/java/parquet/thrift/ThriftRecordConverter.java": [
                1,
                1
            ],
            "parquet-thrift/src/main/java/parquet/thrift/struct/ThriftType.java": [
                3,
                25
            ],
            "parquet-thrift/src/test/java/parquet/hadoop/thrift/TestInputOutputFormat.java": [
                1,
                1
            ],
            "parquet-thrift/src/test/java/parquet/thrift/TestParquetReadProtocol.java": [
                1,
                3
            ],
            "parquet-thrift/src/test/java/parquet/thrift/TestParquetWriteProtocol.java": [
                33,
                49
            ],
            "parquet-thrift/src/test/java/parquet/thrift/TestProtocolReadToWrite.java": [
                51,
                25
            ],
            "parquet-thrift/src/test/java/parquet/thrift/TestThriftParquetReaderWriter.java": [
                1,
                1
            ],
            "parquet-thrift/src/test/java/parquet/thrift/TestThriftToPigCompatibility.java": [
                1,
                3
            ],
            "parquet-thrift/src/test/java/parquet/thrift/struct/CompatibilityCheckerTest.java": [
                1,
                1
            ],
            "pom.xml": null
        }
    },
    "5ffaba99e7b10e55df9b49e3401396660e3262a7": {
        "datetime": "2014-01-29T13:36:01+01:00",
        "summary": "Maven shade plugin removed",
        "message": "Maven shade plugin removed\n",
        "diff": {
            "parquet-protobuf/pom.xml": null
        }
    },
    "b1a67742ec0c79f4f7143d94bbc1a848fe2b741b": {
        "datetime": "2014-01-29T13:40:59+01:00",
        "summary": "version 1.3.3-SNAPSHOT + shade plugin",
        "message": "version 1.3.3-SNAPSHOT + shade plugin\n",
        "diff": {
            "parquet-protobuf/pom.xml": null
        }
    },
    "024d5abf6a2c96f13c733d04501fcdaed66aa860": {
        "datetime": "2014-01-29T14:17:09+01:00",
        "summary": "build fix - deleted package",
        "message": "build fix - deleted package\n",
        "diff": {
            "parquet-protobuf/src/main/java/parquet/proto/ProtoRecordMaterializer.java": [
                1,
                0
            ]
        }
    },
    "8ecb0b22d80cae8f962b0de573fd276bbcac3385": {
        "datetime": "2014-01-30T09:49:17-08:00",
        "summary": "first use current thread's classloader to load a class, if current thread does not have a classloader, use the class's current classloader to load a class.",
        "message": "first use current thread's classloader to load a class, if current thread does not have a classloader, use the class's current classloader to load a class.\nThis will make sure a class not packaged in parquet but on classpath loaded properly. Otherwise, for example, if you set your own ReadSupport class to the\nConfiguration object and expect it to be loaded by ParquetInputFormat, it will fail and throw ClassNotFoundException.\n",
        "diff": {
            "parquet-hadoop/src/main/java/parquet/hadoop/util/ConfigurationUtil.java": [
                1,
                5
            ]
        }
    },
    "a1b7a315726ebf3038ef4160aede0fe8e91024f6": {
        "datetime": "2014-01-30T18:46:04-08:00",
        "summary": "use utility method from Configuration class to load class to avoid ClassNotFoundException",
        "message": "use utility method from Configuration class to load class to avoid ClassNotFoundException\n",
        "diff": {
            "parquet-hadoop/src/main/java/parquet/hadoop/util/ConfigurationUtil.java": [
                5,
                2
            ]
        }
    },
    "83bb4b89b433df79049411a7642b615821c03654": {
        "datetime": "2014-02-02T22:08:09-08:00",
        "summary": "Added ParquetWriter() that takes an instance of Hadoop's Configuration.",
        "message": "Added ParquetWriter() that takes an instance of Hadoop's Configuration.\n",
        "diff": {
            "parquet-hadoop/src/main/java/parquet/hadoop/ParquetWriter.java": [
                4,
                38
            ]
        }
    },
    "0185b491c9e0264a591611259a4233e068390f0c": {
        "datetime": "2014-02-04T16:22:49+00:00",
        "summary": "Minor changes following Julien's review",
        "message": "Minor changes following Julien's review\n",
        "diff": {
            "parquet-avro/src/main/java/parquet/avro/AvroReadSupport.java": [
                1,
                3
            ]
        }
    },
    "ab54b702f1039d827a1a0a04299368338e2554ac": {
        "datetime": "2014-02-04T16:22:49+00:00",
        "summary": "Add tests for reading Parquet files using the default",
        "message": "Add tests for reading Parquet files using the default\nAvro schema.\n",
        "diff": {
            "parquet-avro/src/main/java/parquet/avro/AvroReadSupport.java": [
                3,
                11
            ],
            "parquet-avro/src/main/java/parquet/avro/AvroSchemaConverter.java": [
                2,
                1
            ],
            "parquet-avro/src/test/java/parquet/avro/TestAvroSchemaConverter.java": [
                29,
                35
            ],
            "parquet-avro/src/test/java/parquet/avro/TestReadWrite.java": [
                3,
                208
            ],
            "parquet-avro/src/test/resources/allFromParquet.avsc": null
        }
    },
    "e29d26bebca603e00c8f437ef46befd9ef0d7a02": {
        "datetime": "2014-02-04T16:22:49+00:00",
        "summary": "Use a default Avro read schema when none specified in Parquet-Avro.",
        "message": "Use a default Avro read schema when none specified in Parquet-Avro.\n",
        "diff": {
            "parquet-avro/src/main/java/parquet/avro/AvroSchemaConverter.java": [
                1,
                121
            ],
            "parquet-avro/src/main/java/parquet/avro/package-info.java": [
                0,
                79
            ],
            "parquet-avro/src/test/java/parquet/avro/TestAvroSchemaConverter.java": [
                41,
                112
            ],
            "parquet-avro/src/test/resources/allFromParquet.avsc": null
        }
    },
    "01bba92984f12d111042cb54332d906d3d8add4c": {
        "datetime": "2014-02-04T16:22:49+00:00",
        "summary": "Support promotion of int, long and float to wider types.",
        "message": "Support promotion of int, long and float to wider types.\n\nThis is specified in http://avro.apache.org/docs/current/spec.html#Schema+Resolution\n",
        "diff": {
            "parquet-avro/src/main/java/parquet/avro/AvroIndexedRecordConverter.java": [
                0,
                30
            ],
            "parquet-avro/src/test/resources/car.avdl": null
        }
    },
    "be43f8847748bf810142f1c9df500b085e87b21c": {
        "datetime": "2014-02-04T16:22:49+00:00",
        "summary": "Make setting requested projection and avro schema more independent, so that",
        "message": "Make setting requested projection and avro schema more independent, so that\nyou only need to set the Avro schema if it is different to the\nwriter's schema.\n",
        "diff": {
            "parquet-avro/src/main/java/parquet/avro/AvroIndexedRecordConverter.java": [
                2,
                0
            ],
            "parquet-avro/src/main/java/parquet/avro/AvroParquetInputFormat.java": [
                3,
                33
            ],
            "parquet-avro/src/main/java/parquet/avro/AvroParquetOutputFormat.java": [
                0,
                9
            ],
            "parquet-avro/src/main/java/parquet/avro/AvroReadSupport.java": [
                22,
                26
            ],
            "parquet-avro/src/main/java/parquet/avro/AvroWriteSupport.java": [
                3,
                8
            ],
            "parquet-avro/src/test/java/parquet/avro/TestSpecificInputOutputFormat.java": [
                7,
                4
            ],
            "parquet-avro/src/test/java/parquet/avro/TestSpecificReadWrite.java": [
                5,
                17
            ],
            "parquet-avro/src/test/resources/car.avdl": null
        }
    },
    "f2f8e42e95f4d1851f5bcc6dc82e03a159f8abd1": {
        "datetime": "2014-02-04T16:22:49+00:00",
        "summary": "Fix to read a new avro schema...",
        "message": "Fix to read a new avro schema...\n",
        "diff": {
            "parquet-avro/src/main/java/parquet/avro/AvroIndexedRecordConverter.java": [
                3,
                4
            ],
            "parquet-avro/src/main/java/parquet/avro/AvroParquetInputFormat.java": [
                0,
                4
            ],
            "parquet-avro/src/main/java/parquet/avro/AvroReadSupport.java": [
                2,
                20
            ],
            "parquet-avro/src/test/java/parquet/avro/TestSpecificInputOutputFormat.java": [
                41,
                126
            ],
            "parquet-avro/src/test/java/parquet/avro/TestSpecificReadWrite.java": [
                15,
                13
            ],
            "parquet-avro/src/test/resources/car.avdl": null
        }
    },
    "aadaae5be5d207f73b54b89e11d73ea06fa45171": {
        "datetime": "2014-02-04T16:28:18+00:00",
        "summary": "Revert change making field final that failed compatibility test.",
        "message": "Revert change making field final that failed compatibility test.\n",
        "diff": {
            "parquet-avro/src/main/java/parquet/avro/AvroReadSupport.java": [
                1,
                1
            ]
        }
    },
    "644bf006a2fb19cde2cebdf3e4f47a7eee42a118": {
        "datetime": "2014-02-04T11:36:57-08:00",
        "summary": "Merge pull request #282 from tomwhite/avro-default-read-schema",
        "message": "Merge pull request #282 from tomwhite/avro-default-read-schema\n\nAvro default read schema",
        "diff": {
            "parquet-avro/src/main/java/parquet/avro/AvroIndexedRecordConverter.java": [
                3,
                32
            ],
            "parquet-avro/src/main/java/parquet/avro/AvroParquetInputFormat.java": [
                1,
                35
            ],
            "parquet-avro/src/main/java/parquet/avro/AvroParquetOutputFormat.java": [
                0,
                9
            ],
            "parquet-avro/src/main/java/parquet/avro/AvroReadSupport.java": [
                7,
                39
            ],
            "parquet-avro/src/main/java/parquet/avro/AvroSchemaConverter.java": [
                1,
                120
            ],
            "parquet-avro/src/main/java/parquet/avro/AvroWriteSupport.java": [
                3,
                8
            ],
            "parquet-avro/src/main/java/parquet/avro/package-info.java": [
                0,
                79
            ],
            "parquet-avro/src/test/java/parquet/avro/TestAvroSchemaConverter.java": [
                41,
                118
            ],
            "parquet-avro/src/test/java/parquet/avro/TestReadWrite.java": [
                3,
                208
            ],
            "parquet-avro/src/test/java/parquet/avro/TestSpecificInputOutputFormat.java": [
                41,
                123
            ],
            "parquet-avro/src/test/java/parquet/avro/TestSpecificReadWrite.java": [
                17,
                27
            ],
            "parquet-avro/src/test/resources/allFromParquet.avsc": null,
            "parquet-avro/src/test/resources/car.avdl": null
        }
    },
    "3d7d9ad11bedb4772aca271b73bc952f2542c6bc": {
        "datetime": "2014-02-04T11:38:17-08:00",
        "summary": "Merge pull request #292 from esammer/master",
        "message": "Merge pull request #292 from esammer/master\n\nAdded ParquetWriter() that takes an instance of Hadoop's Configuration.",
        "diff": {
            "parquet-hadoop/src/main/java/parquet/hadoop/ParquetWriter.java": [
                4,
                38
            ]
        }
    },
    "137b1e292eacbccb06c9723e9b86d2259045b860": {
        "datetime": "2014-02-04T12:09:20-08:00",
        "summary": "Merge pull request #289 from allanyan/master",
        "message": "Merge pull request #289 from allanyan/master\n\nfirst use current thread's classloader to load a class, if current threa...",
        "diff": {
            "parquet-hadoop/src/main/java/parquet/hadoop/util/ConfigurationUtil.java": [
                1,
                2
            ]
        }
    },
    "68b531441eb4fc19d00d2a18ff61bef140fd25ee": {
        "datetime": "2014-02-06T14:29:15-08:00",
        "summary": "better error messages, create ParquetScroogeInputFormat class",
        "message": "better error messages, create ParquetScroogeInputFormat class\n",
        "diff": {
            "parquet-scrooge/src/main/java/parquet/scrooge/ParquetScroogeInputFormat.java": [
                0,
                28
            ],
            "parquet-scrooge/src/main/java/parquet/scrooge/ScroogeStructConverter.java": [
                12,
                11
            ],
            "parquet-scrooge/src/test/java/parquet/scrooge/ParquetScroogeSchemeTest.java": [
                5,
                0
            ],
            "parquet-scrooge/src/test/java/parquet/scrooge/ScroogeStructConverterTest.java": [
                1,
                1
            ],
            "parquet-thrift/src/main/java/parquet/hadoop/thrift/ParquetThriftInputFormat.java": [
                1,
                9
            ]
        }
    },
    "045343dd5153c879cb35e55da28232e4cd436a8a": {
        "datetime": "2014-02-07T23:43:41+01:00",
        "summary": "Merge remote-tracking branch 'upstream/master' into protobuf",
        "message": "Merge remote-tracking branch 'upstream/master' into protobuf\n",
        "diff": {
            "parquet-avro/src/main/java/parquet/avro/AvroIndexedRecordConverter.java": [
                3,
                32
            ],
            "parquet-avro/src/main/java/parquet/avro/AvroParquetInputFormat.java": [
                1,
                35
            ],
            "parquet-avro/src/main/java/parquet/avro/AvroParquetOutputFormat.java": [
                0,
                9
            ],
            "parquet-avro/src/main/java/parquet/avro/AvroReadSupport.java": [
                7,
                39
            ],
            "parquet-avro/src/main/java/parquet/avro/AvroSchemaConverter.java": [
                1,
                120
            ],
            "parquet-avro/src/main/java/parquet/avro/AvroWriteSupport.java": [
                3,
                8
            ],
            "parquet-avro/src/main/java/parquet/avro/package-info.java": [
                0,
                79
            ],
            "parquet-avro/src/test/java/parquet/avro/TestAvroSchemaConverter.java": [
                41,
                118
            ],
            "parquet-avro/src/test/java/parquet/avro/TestReadWrite.java": [
                3,
                208
            ],
            "parquet-avro/src/test/java/parquet/avro/TestSpecificInputOutputFormat.java": [
                41,
                123
            ],
            "parquet-avro/src/test/java/parquet/avro/TestSpecificReadWrite.java": [
                17,
                27
            ],
            "parquet-avro/src/test/resources/allFromParquet.avsc": null,
            "parquet-avro/src/test/resources/car.avdl": null,
            "parquet-hadoop/src/main/java/parquet/hadoop/ParquetWriter.java": [
                4,
                38
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/util/ConfigurationUtil.java": [
                1,
                2
            ]
        }
    },
    "38241cc7e85e943d404f186fe684bf2ceb855de6": {
        "datetime": "2014-02-10T09:16:57-06:00",
        "summary": "Ports HIVE-5783 to the parquet-hive module so that patches",
        "message": "Ports HIVE-5783 to the parquet-hive module so that patches\ncan be ported between the two code bases with ease. Note\nthat the code base in Hive itself should be considered the\ngolden copy and any changes made there and then ported\nto the parquet-hive module.\n",
        "diff": {
            "parquet-hive/parquet-hive-binding/parquet-hive-binding-factory/src/main/java/parquet/hive/HiveBindingFactory.java": [
                0,
                7
            ],
            "parquet-hive/parquet-hive-binding/parquet-hive-binding-factory/src/test/java/parquet/hive/TestHiveBindingFactory.java": [
                3,
                3
            ],
            "parquet-hive/parquet-hive-storage-handler/src/main/java/org/apache/hadoop/hive/ql/io/IOConstants.java": [
                0,
                28
            ],
            "parquet-hive/parquet-hive-storage-handler/src/main/java/org/apache/hadoop/hive/ql/io/parquet/MapredParquetInputFormat.java": [
                0,
                56
            ],
            "parquet-hive/parquet-hive-storage-handler/src/main/java/org/apache/hadoop/hive/ql/io/parquet/MapredParquetOutputFormat.java": [
                0,
                125
            ],
            "parquet-hive/parquet-hive-storage-handler/src/main/java/org/apache/hadoop/hive/ql/io/parquet/read/ParquetRecordReaderWrapper.java": [
                0,
                238
            ],
            "parquet-hive/parquet-hive-storage-handler/src/main/java/org/apache/hadoop/hive/ql/io/parquet/serde/ParquetHiveSerDe.java": [
                0,
                274
            ],
            "parquet-hive/parquet-hive-storage-handler/src/main/java/org/apache/hadoop/hive/ql/io/parquet/write/ParquetRecordWriterWrapper.java": [
                0,
                93
            ],
            "parquet-hive/parquet-hive-storage-handler/src/main/java/parquet/hive/DeprecatedParquetInputFormat.java": [
                3,
                5
            ],
            "parquet-hive/parquet-hive-storage-handler/src/main/java/parquet/hive/DeprecatedParquetOutputFormat.java": [
                1,
                2
            ],
            "parquet-hive/parquet-hive-storage-handler/src/main/java/parquet/hive/MapredParquetInputFormat.java": [
                342,
                9
            ],
            "parquet-hive/parquet-hive-storage-handler/src/main/java/parquet/hive/MapredParquetOutputFormat.java": [
                141,
                9
            ],
            "parquet-hive/parquet-hive-storage-handler/src/main/java/parquet/hive/convert/ArrayWritableGroupConverter.java": [
                26,
                13
            ],
            "parquet-hive/parquet-hive-storage-handler/src/main/java/parquet/hive/convert/DataWritableGroupConverter.java": [
                22,
                24
            ],
            "parquet-hive/parquet-hive-storage-handler/src/main/java/parquet/hive/convert/DataWritableRecordConverter.java": [
                9,
                9
            ],
            "parquet-hive/parquet-hive-storage-handler/src/main/java/parquet/hive/convert/ETypeConverter.java": [
                18,
                13
            ],
            "parquet-hive/parquet-hive-storage-handler/src/main/java/parquet/hive/convert/HiveGroupConverter.java": [
                8,
                7
            ],
            "parquet-hive/parquet-hive-storage-handler/src/main/java/parquet/hive/convert/HiveSchemaConverter.java": [
                35,
                26
            ],
            "parquet-hive/parquet-hive-storage-handler/src/main/java/parquet/hive/read/DataWritableReadSupport.java": [
                23,
                34
            ],
            "parquet-hive/parquet-hive-storage-handler/src/main/java/parquet/hive/serde/AbstractParquetMapInspector.java": [
                14,
                14
            ],
            "parquet-hive/parquet-hive-storage-handler/src/main/java/parquet/hive/serde/ArrayWritableObjectInspector.java": [
                13,
                11
            ],
            "parquet-hive/parquet-hive-storage-handler/src/main/java/parquet/hive/serde/DeepParquetHiveMapInspector.java": [
                9,
                9
            ],
            "parquet-hive/parquet-hive-storage-handler/src/main/java/parquet/hive/serde/ParquetHiveArrayInspector.java": [
                9,
                9
            ],
            "parquet-hive/parquet-hive-storage-handler/src/main/java/parquet/hive/serde/ParquetHiveSerDe.java": [
                272,
                6
            ],
            "parquet-hive/parquet-hive-storage-handler/src/main/java/parquet/hive/serde/StandardParquetHiveMapInspector.java": [
                16,
                11
            ],
            "parquet-hive/parquet-hive-storage-handler/src/main/java/parquet/hive/serde/primitive/ParquetByteInspector.java": [
                6,
                3
            ],
            "parquet-hive/parquet-hive-storage-handler/src/main/java/parquet/hive/serde/primitive/ParquetPrimitiveInspectorFactory.java": [
                6,
                3
            ],
            "parquet-hive/parquet-hive-storage-handler/src/main/java/parquet/hive/serde/primitive/ParquetShortInspector.java": [
                6,
                3
            ],
            "parquet-hive/parquet-hive-storage-handler/src/main/java/parquet/hive/serde/primitive/ParquetStringInspector.java": [
                7,
                5
            ],
            "parquet-hive/parquet-hive-storage-handler/src/main/java/parquet/hive/writable/BigDecimalWritable.java": [
                15,
                6
            ],
            "parquet-hive/parquet-hive-storage-handler/src/main/java/parquet/hive/writable/BinaryWritable.java": [
                9,
                4
            ],
            "parquet-hive/parquet-hive-storage-handler/src/main/java/parquet/hive/write/DataWritableWriteSupport.java": [
                12,
                12
            ],
            "parquet-hive/parquet-hive-storage-handler/src/main/java/parquet/hive/write/DataWritableWriter.java": [
                19,
                12
            ],
            "parquet-hive/parquet-hive-storage-handler/src/test/java/org/apache/hadoop/hive/ql/io/parquet/TestMapredParquetInputFormat.java": [
                0,
                37
            ],
            "parquet-hive/parquet-hive-storage-handler/src/test/java/org/apache/hadoop/hive/ql/io/parquet/TestMapredParquetOutputFormat.java": [
                0,
                90
            ],
            "parquet-hive/parquet-hive-storage-handler/src/test/java/parquet/hive/TestHiveSchemaConverter.java": [
                12,
                2
            ],
            "parquet-hive/parquet-hive-storage-handler/src/test/java/parquet/hive/TestMapredParquetInputFormat.java": [
                388,
                0
            ],
            "parquet-hive/parquet-hive-storage-handler/src/test/java/parquet/hive/TestMapredParquetOuputFormat.java": [
                235,
                0
            ],
            "parquet-hive/parquet-hive-storage-handler/src/test/java/parquet/hive/TestParquetSerDe.java": [
                24,
                41
            ],
            "parquet-hive/parquet-hive-storage-handler/src/test/java/parquet/hive/UtilitiesTestMethods.java": [
                245,
                0
            ],
            "parquet-hive/parquet-hive-storage-handler/src/test/java/parquet/hive/serde/TestAbstractParquetMapInspector.java": [
                18,
                13
            ],
            "parquet-hive/parquet-hive-storage-handler/src/test/java/parquet/hive/serde/TestDeepParquetHiveMapInspector.java": [
                17,
                11
            ],
            "parquet-hive/parquet-hive-storage-handler/src/test/java/parquet/hive/serde/TestParquetHiveArrayInspector.java": [
                16,
                11
            ],
            "parquet-hive/parquet-hive-storage-handler/src/test/java/parquet/hive/serde/TestStandardParquetHiveMapInspector.java": [
                17,
                11
            ]
        }
    },
    "083c51317f4cde839c2a948e6fa5c2b62221be31": {
        "datetime": "2014-02-10T11:14:31-06:00",
        "summary": "Convert ParquetHiveSerDe back to SerDe interface to support Hive 0.10",
        "message": "Convert ParquetHiveSerDe back to SerDe interface to support Hive 0.10\n",
        "diff": {
            "parquet-hive/parquet-hive-storage-handler/src/main/java/org/apache/hadoop/hive/ql/io/parquet/serde/ParquetHiveSerDe.java": [
                2,
                2
            ]
        }
    },
    "3f37ca2a19783dee35c41c3a66e56cee194c9138": {
        "datetime": "2014-02-10T13:55:02-08:00",
        "summary": "exclude thrift source from jar",
        "message": "exclude thrift source from jar\n",
        "diff": {
            "pom.xml": null
        }
    },
    "c54e6d5f9092eb5d5beb98aa41c515949be58a2e": {
        "datetime": "2014-02-10T14:06:26-08:00",
        "summary": "Merge pull request #82 from Parquet/exclude_thrift_source_from_jar",
        "message": "Merge pull request #82 from Parquet/exclude_thrift_source_from_jar\n\nexclude thrift source from jar",
        "diff": {
            "pom.xml": null
        }
    },
    "1be4d6c9ac35c133d5e257839c65aa83155a4455": {
        "datetime": "2014-02-10T22:49:46-08:00",
        "summary": "bugfix: reorder fields in thrift struct caused writting nulls. fixed it by keeping track of which fields are being written in each level, and only write nulls when current level is finished in MessageColumnIO",
        "message": "bugfix: reorder fields in thrift struct caused writting nulls. fixed it by keeping track of which fields are being written in each level, and only write nulls when current level is finished in MessageColumnIO\n",
        "diff": {
            "parquet-column/src/main/java/parquet/io/MessageColumnIO.java": [
                21,
                59
            ],
            "parquet-column/src/test/java/parquet/io/TestColumnIO.java": [
                4,
                7
            ],
            "parquet-thrift/src/test/java/parquet/hadoop/thrift/TestParquetToThriftReadProjection.java": [
                8,
                15
            ],
            "parquet-thrift/src/test/thrift/test.thrift": null
        }
    },
    "02f50f7ea0b417a8b963b8b2b081b16190ffc9ef": {
        "datetime": "2014-02-10T22:52:28-08:00",
        "summary": "rename var",
        "message": "rename var\n",
        "diff": {
            "parquet-column/src/main/java/parquet/io/MessageColumnIO.java": [
                3,
                3
            ]
        }
    },
    "94d703c7cad93228ddee626622841953eae665b1": {
        "datetime": "2014-02-11T17:37:48+00:00",
        "summary": "Fill in default values for new fields in the read schema that",
        "message": "Fill in default values for new fields in the read schema that\nwere not in the write schema.\n\nSome of the implementation was inspired by\nhttps://issues.apache.org/jira/browse/AVRO-1228.\n",
        "diff": {
            "parquet-avro/src/main/java/parquet/avro/AvroIndexedRecordConverter.java": [
                1,
                23
            ],
            "parquet-avro/src/test/java/parquet/avro/TestSpecificReadWrite.java": [
                0,
                1
            ],
            "parquet-avro/src/test/resources/car.avdl": null
        }
    },
    "0d111b1defc6cc5100470dd1162b6eece86fdbd8": {
        "datetime": "2014-02-11T13:19:34-08:00",
        "summary": "remove fieldCount from marker",
        "message": "remove fieldCount from marker\n",
        "diff": {
            "parquet-column/src/main/java/parquet/io/MessageColumnIO.java": [
                9,
                3
            ]
        }
    },
    "5dccd0cdf5d1384bcc46b738c27cf4c7f42a2d6c": {
        "datetime": "2014-02-11T13:24:16-08:00",
        "summary": "format",
        "message": "format\n",
        "diff": {
            "parquet-column/src/test/java/parquet/io/TestColumnIO.java": [
                2,
                0
            ],
            "parquet-thrift/src/test/java/parquet/hadoop/thrift/TestParquetToThriftReadWriteAndProjection.java": [
                1,
                0
            ]
        }
    },
    "6496bcc8e1ed9150614fdca9ad8ec46294336ed2": {
        "datetime": "2014-02-11T13:42:42-08:00",
        "summary": "Merge pull request #298 from Parquet/bugfix_reorder_thrift_fields_causing_writting_nulls",
        "message": "Merge pull request #298 from Parquet/bugfix_reorder_thrift_fields_causing_writting_nulls\n\nBugfix reorder thrift fields causing writting nulls",
        "diff": {
            "parquet-column/src/main/java/parquet/io/MessageColumnIO.java": [
                21,
                53
            ],
            "parquet-column/src/test/java/parquet/io/TestColumnIO.java": [
                4,
                5
            ],
            "parquet-thrift/src/test/java/parquet/hadoop/thrift/TestParquetToThriftReadProjection.java": [
                8,
                14
            ],
            "parquet-thrift/src/test/thrift/test.thrift": null
        }
    },
    "76bbf4a88645abc657ba6e4c2dc636712f03b944": {
        "datetime": "2014-02-12T11:00:17+01:00",
        "summary": "[CASCADING] Provide the sink implementation",
        "message": "[CASCADING] Provide the sink implementation\nin order to write some parquet files with ParquetTupleScheme\n",
        "diff": {
            "parquet-cascading/src/main/java/parquet/cascading/ParquetTupleScheme.java": [
                12,
                31
            ],
            "parquet-cascading/src/main/java/parquet/cascading/TupleWriteSupport.java": [
                0,
                103
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/ParquetOutputFormat.java": [
                0,
                5
            ]
        }
    },
    "cc59a4077dc880bb5de5555954906bda64369678": {
        "datetime": "2014-02-12T12:07:04+00:00",
        "summary": "Don't deep copy immutable primitive types.",
        "message": "Don't deep copy immutable primitive types.\n",
        "diff": {
            "parquet-avro/src/main/java/parquet/avro/AvroIndexedRecordConverter.java": [
                1,
                15
            ]
        }
    },
    "de7ae6be9d550bc7d387bdfc986111387923eb32": {
        "datetime": "2014-02-12T12:48:55+00:00",
        "summary": "Add explicit blank namespaces to account for change in AVRO-1295 in Avro 1.7.5.",
        "message": "Add explicit blank namespaces to account for change in AVRO-1295 in Avro 1.7.5.\n",
        "diff": {
            "parquet-avro/src/test/resources/all.avsc": null,
            "parquet-avro/src/test/resources/allFromParquet.avsc": null
        }
    },
    "808de5d963b4186d69b2ae39c00ed5f5bb08b2cc": {
        "datetime": "2014-02-12T12:48:55+00:00",
        "summary": "Support field renaming for Avro read schemas, by means of",
        "message": "Support field renaming for Avro read schemas, by means of\nfield aliases.\n\nAvro 1.7.6 is required since it fixes https://issues.apache.org/jira/browse/AVRO-1433\nBut note that this is only to allow the test to run correctly.\n",
        "diff": {
            "parquet-avro/pom.xml": null,
            "parquet-avro/src/main/java/parquet/avro/AvroIndexedRecordConverter.java": [
                5,
                15
            ],
            "parquet-avro/src/test/java/parquet/avro/TestSpecificReadWrite.java": [
                1,
                1
            ],
            "parquet-avro/src/test/resources/car.avdl": null
        }
    },
    "3151b2f76eaf0c43f1b321ab7480d5c4a3288622": {
        "datetime": "2014-02-13T15:09:43-08:00",
        "summary": "Merge pull request #299 from tomwhite/avro-fill-in-default-values",
        "message": "Merge pull request #299 from tomwhite/avro-fill-in-default-values\n\nFill in default values for new fields in the Avro read schema",
        "diff": {
            "parquet-avro/src/main/java/parquet/avro/AvroIndexedRecordConverter.java": [
                1,
                37
            ],
            "parquet-avro/src/test/java/parquet/avro/TestSpecificReadWrite.java": [
                0,
                1
            ],
            "parquet-avro/src/test/resources/car.avdl": null
        }
    },
    "29fe0e0e42b24a8155084375acc1d99fa484830e": {
        "datetime": "2014-02-14T09:44:37+00:00",
        "summary": "Merge pull request #303 from tomwhite/avro-read-schema-aliases",
        "message": "Merge pull request #303 from tomwhite/avro-read-schema-aliases\n\nAvro read schema aliases",
        "diff": {
            "parquet-avro/pom.xml": null,
            "parquet-avro/src/main/java/parquet/avro/AvroIndexedRecordConverter.java": [
                5,
                15
            ],
            "parquet-avro/src/test/java/parquet/avro/TestSpecificReadWrite.java": [
                1,
                1
            ],
            "parquet-avro/src/test/resources/all.avsc": null,
            "parquet-avro/src/test/resources/allFromParquet.avsc": null,
            "parquet-avro/src/test/resources/car.avdl": null
        }
    },
    "cad7f56b655599fe663b1bd7632c3afc3e40d5f2": {
        "datetime": "2014-02-14T15:58:24-08:00",
        "summary": "Update poms to use thrift.exectuable property.",
        "message": "Update poms to use thrift.exectuable property.\n\nUses -Dthrift.executable=<path> to set the thrift install directory, which\nallows running against 0.7.0 when another version is the shell default.\n",
        "diff": {
            "parquet-cascading/pom.xml": null,
            "parquet-scrooge/pom.xml": null,
            "parquet-thrift/pom.xml": null,
            "pom.xml": null
        }
    },
    "c48e8c1324562937cdca552657afb4e090f119f2": {
        "datetime": "2014-02-18T13:21:03-06:00",
        "summary": "HIVE-6456 - Implement Parquet schema evolution",
        "message": "HIVE-6456 - Implement Parquet schema evolution\n",
        "diff": {
            "parquet-hive/parquet-hive-storage-handler/src/main/java/org/apache/hadoop/hive/ql/io/parquet/read/DataWritableReadSupport.java": [
                0,
                3
            ]
        }
    },
    "81028366038e22cff7a3f62e8eab6d00758f978e": {
        "datetime": "2014-02-18T13:31:18-06:00",
        "summary": "Merge the parquet-tools project into parquet-mr.",
        "message": "Merge the parquet-tools project into parquet-mr.\n",
        "diff": {
            "parquet-tools/NOTICE": null,
            "parquet-tools/README.md": null,
            "parquet-tools/pom.xml": null,
            "parquet-tools/src/main/assembly/assembly.xml": null,
            "parquet-tools/src/main/java/parquet/tools/Main.java": [
                0,
                229
            ],
            "parquet-tools/src/main/java/parquet/tools/command/ArgsOnlyCommand.java": [
                0,
                53
            ],
            "parquet-tools/src/main/java/parquet/tools/command/CatCommand.java": [
                0,
                67
            ],
            "parquet-tools/src/main/java/parquet/tools/command/Command.java": [
                0,
                27
            ],
            "parquet-tools/src/main/java/parquet/tools/command/DumpCommand.java": [
                0,
                320
            ],
            "parquet-tools/src/main/java/parquet/tools/command/HeadCommand.java": [
                0,
                92
            ],
            "parquet-tools/src/main/java/parquet/tools/command/Registry.java": [
                0,
                57
            ],
            "parquet-tools/src/main/java/parquet/tools/command/ShowMetaCommand.java": [
                0,
                67
            ],
            "parquet-tools/src/main/java/parquet/tools/command/ShowSchemaCommand.java": [
                0,
                83
            ],
            "parquet-tools/src/main/java/parquet/tools/read/SimpleReadSupport.java": [
                0,
                38
            ],
            "parquet-tools/src/main/java/parquet/tools/read/SimpleRecord.java": [
                0,
                117
            ],
            "parquet-tools/src/main/java/parquet/tools/read/SimpleRecordConverter.java": [
                0,
                165
            ],
            "parquet-tools/src/main/java/parquet/tools/read/SimpleRecordMaterializer.java": [
                0,
                39
            ],
            "parquet-tools/src/main/java/parquet/tools/util/MetadataUtils.java": [
                0,
                225
            ],
            "parquet-tools/src/main/java/parquet/tools/util/PrettyPrintWriter.java": [
                0,
                1032
            ],
            "parquet-tools/src/main/scripts/parquet-cat": null,
            "parquet-tools/src/main/scripts/parquet-dump": null,
            "parquet-tools/src/main/scripts/parquet-head": null,
            "parquet-tools/src/main/scripts/parquet-meta": null,
            "parquet-tools/src/main/scripts/parquet-schema": null,
            "parquet-tools/src/main/scripts/parquet-tools": null,
            "pom.xml": null
        }
    },
    "7593e65aa1c7d5ab3beeba7a39b751ec8604511f": {
        "datetime": "2014-02-18T13:31:18-06:00",
        "summary": "Add explicit blank namespaces to account for change in AVRO-1295 in Avro 1.7.5.",
        "message": "Add explicit blank namespaces to account for change in AVRO-1295 in Avro 1.7.5.\n",
        "diff": {
            "parquet-avro/src/test/resources/all.avsc": null,
            "parquet-avro/src/test/resources/allFromParquet.avsc": null
        }
    },
    "555837ad2df87cf19d269919e6dbb809c3b060bb": {
        "datetime": "2014-02-18T13:31:18-06:00",
        "summary": "Support field renaming for Avro read schemas, by means of",
        "message": "Support field renaming for Avro read schemas, by means of\nfield aliases.\n\nAvro 1.7.6 is required since it fixes https://issues.apache.org/jira/browse/AVRO-1433\nBut note that this is only to allow the test to run correctly.\n",
        "diff": {
            "parquet-avro/pom.xml": null,
            "parquet-avro/src/main/java/parquet/avro/AvroIndexedRecordConverter.java": [
                5,
                15
            ],
            "parquet-avro/src/test/java/parquet/avro/TestSpecificReadWrite.java": [
                1,
                1
            ],
            "parquet-avro/src/test/resources/car.avdl": null
        }
    },
    "8cc8bdc05260d0f5f60b3435da7d0f0edef6a786": {
        "datetime": "2014-02-18T13:35:04-06:00",
        "summary": "Merge the parquet-tools project into parquet-mr.",
        "message": "Merge the parquet-tools project into parquet-mr.\n",
        "diff": {
            "parquet-tools/NOTICE": null,
            "parquet-tools/README.md": null,
            "parquet-tools/pom.xml": null,
            "parquet-tools/src/main/assembly/assembly.xml": null,
            "parquet-tools/src/main/java/parquet/tools/Main.java": [
                0,
                229
            ],
            "parquet-tools/src/main/java/parquet/tools/command/ArgsOnlyCommand.java": [
                0,
                53
            ],
            "parquet-tools/src/main/java/parquet/tools/command/CatCommand.java": [
                0,
                67
            ],
            "parquet-tools/src/main/java/parquet/tools/command/Command.java": [
                0,
                27
            ],
            "parquet-tools/src/main/java/parquet/tools/command/DumpCommand.java": [
                0,
                320
            ],
            "parquet-tools/src/main/java/parquet/tools/command/HeadCommand.java": [
                0,
                92
            ],
            "parquet-tools/src/main/java/parquet/tools/command/Registry.java": [
                0,
                57
            ],
            "parquet-tools/src/main/java/parquet/tools/command/ShowMetaCommand.java": [
                0,
                67
            ],
            "parquet-tools/src/main/java/parquet/tools/command/ShowSchemaCommand.java": [
                0,
                83
            ],
            "parquet-tools/src/main/java/parquet/tools/read/SimpleReadSupport.java": [
                0,
                38
            ],
            "parquet-tools/src/main/java/parquet/tools/read/SimpleRecord.java": [
                0,
                117
            ],
            "parquet-tools/src/main/java/parquet/tools/read/SimpleRecordConverter.java": [
                0,
                165
            ],
            "parquet-tools/src/main/java/parquet/tools/read/SimpleRecordMaterializer.java": [
                0,
                39
            ],
            "parquet-tools/src/main/java/parquet/tools/util/MetadataUtils.java": [
                0,
                225
            ],
            "parquet-tools/src/main/java/parquet/tools/util/PrettyPrintWriter.java": [
                0,
                1032
            ],
            "parquet-tools/src/main/scripts/parquet-cat": null,
            "parquet-tools/src/main/scripts/parquet-dump": null,
            "parquet-tools/src/main/scripts/parquet-head": null,
            "parquet-tools/src/main/scripts/parquet-meta": null,
            "parquet-tools/src/main/scripts/parquet-schema": null,
            "parquet-tools/src/main/scripts/parquet-tools": null,
            "pom.xml": null
        }
    },
    "588f868a26b792e49954b9957e1083f8b43be293": {
        "datetime": "2014-02-18T13:37:15-06:00",
        "summary": "Merge branch 'merge_parquet_tools' of github.com:wesleypeck/parquet-mr into merge_parquet_tools",
        "message": "Merge branch 'merge_parquet_tools' of github.com:wesleypeck/parquet-mr into merge_parquet_tools\n",
        "diff": {}
    },
    "712e6d796c41a44a751dcf441f0db4dae87eb693": {
        "datetime": "2014-02-18T13:54:01-06:00",
        "summary": "fix compile error in previous commit",
        "message": "fix compile error in previous commit\n",
        "diff": {
            "parquet-hive/parquet-hive-storage-handler/src/main/java/org/apache/hadoop/hive/ql/io/parquet/read/DataWritableReadSupport.java": [
                0,
                3
            ]
        }
    },
    "7b0778c490e6782a83663bd5b1ec9d8a7dd7c2ae": {
        "datetime": "2014-02-20T11:59:03-08:00",
        "summary": "Merge pull request #297 from brockn/master",
        "message": "Merge pull request #297 from brockn/master\n\nPorts HIVE-5783 to the parquet-hive module",
        "diff": {
            "parquet-hive/parquet-hive-binding/parquet-hive-binding-factory/src/main/java/parquet/hive/HiveBindingFactory.java": [
                0,
                7
            ],
            "parquet-hive/parquet-hive-binding/parquet-hive-binding-factory/src/test/java/parquet/hive/TestHiveBindingFactory.java": [
                3,
                3
            ],
            "parquet-hive/parquet-hive-storage-handler/src/main/java/org/apache/hadoop/hive/ql/io/IOConstants.java": [
                0,
                28
            ],
            "parquet-hive/parquet-hive-storage-handler/src/main/java/org/apache/hadoop/hive/ql/io/parquet/MapredParquetInputFormat.java": [
                0,
                56
            ],
            "parquet-hive/parquet-hive-storage-handler/src/main/java/org/apache/hadoop/hive/ql/io/parquet/MapredParquetOutputFormat.java": [
                0,
                125
            ],
            "parquet-hive/parquet-hive-storage-handler/src/main/java/org/apache/hadoop/hive/ql/io/parquet/read/ParquetRecordReaderWrapper.java": [
                0,
                238
            ],
            "parquet-hive/parquet-hive-storage-handler/src/main/java/org/apache/hadoop/hive/ql/io/parquet/serde/ParquetHiveSerDe.java": [
                0,
                274
            ],
            "parquet-hive/parquet-hive-storage-handler/src/main/java/org/apache/hadoop/hive/ql/io/parquet/write/ParquetRecordWriterWrapper.java": [
                0,
                93
            ],
            "parquet-hive/parquet-hive-storage-handler/src/main/java/parquet/hive/DeprecatedParquetInputFormat.java": [
                3,
                5
            ],
            "parquet-hive/parquet-hive-storage-handler/src/main/java/parquet/hive/DeprecatedParquetOutputFormat.java": [
                1,
                2
            ],
            "parquet-hive/parquet-hive-storage-handler/src/main/java/parquet/hive/MapredParquetInputFormat.java": [
                342,
                9
            ],
            "parquet-hive/parquet-hive-storage-handler/src/main/java/parquet/hive/MapredParquetOutputFormat.java": [
                141,
                9
            ],
            "parquet-hive/parquet-hive-storage-handler/src/main/java/parquet/hive/convert/ArrayWritableGroupConverter.java": [
                26,
                13
            ],
            "parquet-hive/parquet-hive-storage-handler/src/main/java/parquet/hive/convert/DataWritableGroupConverter.java": [
                22,
                24
            ],
            "parquet-hive/parquet-hive-storage-handler/src/main/java/parquet/hive/convert/DataWritableRecordConverter.java": [
                9,
                9
            ],
            "parquet-hive/parquet-hive-storage-handler/src/main/java/parquet/hive/convert/ETypeConverter.java": [
                18,
                13
            ],
            "parquet-hive/parquet-hive-storage-handler/src/main/java/parquet/hive/convert/HiveGroupConverter.java": [
                8,
                7
            ],
            "parquet-hive/parquet-hive-storage-handler/src/main/java/parquet/hive/convert/HiveSchemaConverter.java": [
                35,
                26
            ],
            "parquet-hive/parquet-hive-storage-handler/src/main/java/parquet/hive/read/DataWritableReadSupport.java": [
                19,
                36
            ],
            "parquet-hive/parquet-hive-storage-handler/src/main/java/parquet/hive/serde/AbstractParquetMapInspector.java": [
                14,
                14
            ],
            "parquet-hive/parquet-hive-storage-handler/src/main/java/parquet/hive/serde/ArrayWritableObjectInspector.java": [
                13,
                11
            ],
            "parquet-hive/parquet-hive-storage-handler/src/main/java/parquet/hive/serde/DeepParquetHiveMapInspector.java": [
                9,
                9
            ],
            "parquet-hive/parquet-hive-storage-handler/src/main/java/parquet/hive/serde/ParquetHiveArrayInspector.java": [
                9,
                9
            ],
            "parquet-hive/parquet-hive-storage-handler/src/main/java/parquet/hive/serde/ParquetHiveSerDe.java": [
                272,
                6
            ],
            "parquet-hive/parquet-hive-storage-handler/src/main/java/parquet/hive/serde/StandardParquetHiveMapInspector.java": [
                16,
                11
            ],
            "parquet-hive/parquet-hive-storage-handler/src/main/java/parquet/hive/serde/primitive/ParquetByteInspector.java": [
                6,
                3
            ],
            "parquet-hive/parquet-hive-storage-handler/src/main/java/parquet/hive/serde/primitive/ParquetPrimitiveInspectorFactory.java": [
                6,
                3
            ],
            "parquet-hive/parquet-hive-storage-handler/src/main/java/parquet/hive/serde/primitive/ParquetShortInspector.java": [
                6,
                3
            ],
            "parquet-hive/parquet-hive-storage-handler/src/main/java/parquet/hive/serde/primitive/ParquetStringInspector.java": [
                7,
                5
            ],
            "parquet-hive/parquet-hive-storage-handler/src/main/java/parquet/hive/writable/BigDecimalWritable.java": [
                15,
                6
            ],
            "parquet-hive/parquet-hive-storage-handler/src/main/java/parquet/hive/writable/BinaryWritable.java": [
                9,
                4
            ],
            "parquet-hive/parquet-hive-storage-handler/src/main/java/parquet/hive/write/DataWritableWriteSupport.java": [
                12,
                12
            ],
            "parquet-hive/parquet-hive-storage-handler/src/main/java/parquet/hive/write/DataWritableWriter.java": [
                19,
                12
            ],
            "parquet-hive/parquet-hive-storage-handler/src/test/java/org/apache/hadoop/hive/ql/io/parquet/TestMapredParquetInputFormat.java": [
                0,
                37
            ],
            "parquet-hive/parquet-hive-storage-handler/src/test/java/org/apache/hadoop/hive/ql/io/parquet/TestMapredParquetOutputFormat.java": [
                0,
                90
            ],
            "parquet-hive/parquet-hive-storage-handler/src/test/java/parquet/hive/TestHiveSchemaConverter.java": [
                12,
                2
            ],
            "parquet-hive/parquet-hive-storage-handler/src/test/java/parquet/hive/TestMapredParquetInputFormat.java": [
                388,
                0
            ],
            "parquet-hive/parquet-hive-storage-handler/src/test/java/parquet/hive/TestMapredParquetOuputFormat.java": [
                235,
                0
            ],
            "parquet-hive/parquet-hive-storage-handler/src/test/java/parquet/hive/TestParquetSerDe.java": [
                24,
                41
            ],
            "parquet-hive/parquet-hive-storage-handler/src/test/java/parquet/hive/UtilitiesTestMethods.java": [
                245,
                0
            ],
            "parquet-hive/parquet-hive-storage-handler/src/test/java/parquet/hive/serde/TestAbstractParquetMapInspector.java": [
                18,
                13
            ],
            "parquet-hive/parquet-hive-storage-handler/src/test/java/parquet/hive/serde/TestDeepParquetHiveMapInspector.java": [
                17,
                11
            ],
            "parquet-hive/parquet-hive-storage-handler/src/test/java/parquet/hive/serde/TestParquetHiveArrayInspector.java": [
                16,
                11
            ],
            "parquet-hive/parquet-hive-storage-handler/src/test/java/parquet/hive/serde/TestStandardParquetHiveMapInspector.java": [
                17,
                11
            ]
        }
    },
    "e237fc4938ef2c5a499c723c8e738df0a01319f0": {
        "datetime": "2014-02-20T15:59:39-08:00",
        "summary": "Don't shade Jackson since Avro exposes Jackson classes in its public API for representing default values for fields.",
        "message": "Don't shade Jackson since Avro exposes Jackson classes in its public API for representing default values for fields.\n",
        "diff": {
            "parquet-avro/pom.xml": null
        }
    },
    "ed08077daa9c780a8dfea360a638bcab50269bbc": {
        "datetime": "2014-02-20T15:59:39-08:00",
        "summary": "Don't fail if no default value specified for a new value in the",
        "message": "Don't fail if no default value specified for a new value in the\nread schema.\n",
        "diff": {
            "parquet-avro/src/main/java/parquet/avro/AvroIndexedRecordConverter.java": [
                0,
                3
            ],
            "parquet-avro/src/test/resources/car.avdl": null
        }
    },
    "c7e892cbd3c8fa5f03dadda55c9d529517c8c74c": {
        "datetime": "2014-02-21T10:48:51-08:00",
        "summary": "merge master",
        "message": "merge master\n",
        "diff": {
            "CHANGES.md": null,
            "README.md": null,
            "parquet-avro/pom.xml": null,
            "parquet-avro/src/main/java/parquet/avro/AvroIndexedRecordConverter.java": [
                9,
                84
            ],
            "parquet-avro/src/main/java/parquet/avro/AvroParquetInputFormat.java": [
                1,
                35
            ],
            "parquet-avro/src/main/java/parquet/avro/AvroParquetOutputFormat.java": [
                0,
                9
            ],
            "parquet-avro/src/main/java/parquet/avro/AvroReadSupport.java": [
                7,
                39
            ],
            "parquet-avro/src/main/java/parquet/avro/AvroSchemaConverter.java": [
                1,
                120
            ],
            "parquet-avro/src/main/java/parquet/avro/AvroWriteSupport.java": [
                3,
                8
            ],
            "parquet-avro/src/main/java/parquet/avro/package-info.java": [
                0,
                79
            ],
            "parquet-avro/src/test/java/parquet/avro/TestAvroSchemaConverter.java": [
                41,
                118
            ],
            "parquet-avro/src/test/java/parquet/avro/TestReadWrite.java": [
                3,
                208
            ],
            "parquet-avro/src/test/java/parquet/avro/TestSpecificInputOutputFormat.java": [
                41,
                123
            ],
            "parquet-avro/src/test/java/parquet/avro/TestSpecificReadWrite.java": [
                17,
                28
            ],
            "parquet-avro/src/test/resources/all.avsc": null,
            "parquet-avro/src/test/resources/allFromParquet.avsc": null,
            "parquet-avro/src/test/resources/car.avdl": null,
            "parquet-cascading/pom.xml": null,
            "parquet-column/pom.xml": null,
            "parquet-column/src/main/java/parquet/io/MessageColumnIO.java": [
                21,
                53
            ],
            "parquet-column/src/test/java/parquet/io/TestColumnIO.java": [
                4,
                5
            ],
            "parquet-common/pom.xml": null,
            "parquet-encoding/pom.xml": null,
            "parquet-generator/pom.xml": null,
            "parquet-hadoop-bundle/pom.xml": null,
            "parquet-hadoop/pom.xml": null,
            "parquet-hadoop/src/main/java/parquet/hadoop/ParquetInputSplit.java": [
                62,
                16
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/ParquetWriter.java": [
                4,
                38
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/mapred/DeprecatedParquetInputFormat.java": [
                10,
                0
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/util/ConfigurationUtil.java": [
                1,
                2
            ],
            "parquet-hive-bundle/pom.xml": null,
            "parquet-hive/parquet-hive-binding/parquet-hive-0.10-binding/pom.xml": null,
            "parquet-hive/parquet-hive-binding/parquet-hive-0.12-binding/pom.xml": null,
            "parquet-hive/parquet-hive-binding/parquet-hive-binding-bundle/pom.xml": null,
            "parquet-hive/parquet-hive-binding/parquet-hive-binding-factory/pom.xml": null,
            "parquet-hive/parquet-hive-binding/parquet-hive-binding-factory/src/main/java/parquet/hive/HiveBindingFactory.java": [
                0,
                7
            ],
            "parquet-hive/parquet-hive-binding/parquet-hive-binding-factory/src/test/java/parquet/hive/TestHiveBindingFactory.java": [
                3,
                3
            ],
            "parquet-hive/parquet-hive-binding/parquet-hive-binding-interface/pom.xml": null,
            "parquet-hive/parquet-hive-binding/pom.xml": null,
            "parquet-hive/parquet-hive-storage-handler/pom.xml": null,
            "parquet-hive/parquet-hive-storage-handler/src/main/java/org/apache/hadoop/hive/ql/io/IOConstants.java": [
                0,
                28
            ],
            "parquet-hive/parquet-hive-storage-handler/src/main/java/org/apache/hadoop/hive/ql/io/parquet/MapredParquetInputFormat.java": [
                0,
                56
            ],
            "parquet-hive/parquet-hive-storage-handler/src/main/java/org/apache/hadoop/hive/ql/io/parquet/MapredParquetOutputFormat.java": [
                0,
                125
            ],
            "parquet-hive/parquet-hive-storage-handler/src/main/java/org/apache/hadoop/hive/ql/io/parquet/read/ParquetRecordReaderWrapper.java": [
                0,
                238
            ],
            "parquet-hive/parquet-hive-storage-handler/src/main/java/org/apache/hadoop/hive/ql/io/parquet/serde/ParquetHiveSerDe.java": [
                0,
                274
            ],
            "parquet-hive/parquet-hive-storage-handler/src/main/java/org/apache/hadoop/hive/ql/io/parquet/write/ParquetRecordWriterWrapper.java": [
                0,
                93
            ],
            "parquet-hive/parquet-hive-storage-handler/src/main/java/parquet/hive/DeprecatedParquetInputFormat.java": [
                3,
                5
            ],
            "parquet-hive/parquet-hive-storage-handler/src/main/java/parquet/hive/DeprecatedParquetOutputFormat.java": [
                1,
                2
            ],
            "parquet-hive/parquet-hive-storage-handler/src/main/java/parquet/hive/MapredParquetInputFormat.java": [
                352,
                9
            ],
            "parquet-hive/parquet-hive-storage-handler/src/main/java/parquet/hive/MapredParquetOutputFormat.java": [
                141,
                9
            ],
            "parquet-hive/parquet-hive-storage-handler/src/main/java/parquet/hive/convert/ArrayWritableGroupConverter.java": [
                26,
                13
            ],
            "parquet-hive/parquet-hive-storage-handler/src/main/java/parquet/hive/convert/DataWritableGroupConverter.java": [
                22,
                24
            ],
            "parquet-hive/parquet-hive-storage-handler/src/main/java/parquet/hive/convert/DataWritableRecordConverter.java": [
                9,
                9
            ],
            "parquet-hive/parquet-hive-storage-handler/src/main/java/parquet/hive/convert/ETypeConverter.java": [
                18,
                13
            ],
            "parquet-hive/parquet-hive-storage-handler/src/main/java/parquet/hive/convert/HiveGroupConverter.java": [
                8,
                7
            ],
            "parquet-hive/parquet-hive-storage-handler/src/main/java/parquet/hive/convert/HiveSchemaConverter.java": [
                35,
                26
            ],
            "parquet-hive/parquet-hive-storage-handler/src/main/java/parquet/hive/read/DataWritableReadSupport.java": [
                19,
                36
            ],
            "parquet-hive/parquet-hive-storage-handler/src/main/java/parquet/hive/serde/AbstractParquetMapInspector.java": [
                14,
                14
            ],
            "parquet-hive/parquet-hive-storage-handler/src/main/java/parquet/hive/serde/ArrayWritableObjectInspector.java": [
                13,
                11
            ],
            "parquet-hive/parquet-hive-storage-handler/src/main/java/parquet/hive/serde/DeepParquetHiveMapInspector.java": [
                9,
                9
            ],
            "parquet-hive/parquet-hive-storage-handler/src/main/java/parquet/hive/serde/ParquetHiveArrayInspector.java": [
                9,
                9
            ],
            "parquet-hive/parquet-hive-storage-handler/src/main/java/parquet/hive/serde/ParquetHiveSerDe.java": [
                272,
                6
            ],
            "parquet-hive/parquet-hive-storage-handler/src/main/java/parquet/hive/serde/StandardParquetHiveMapInspector.java": [
                16,
                11
            ],
            "parquet-hive/parquet-hive-storage-handler/src/main/java/parquet/hive/serde/primitive/ParquetByteInspector.java": [
                6,
                3
            ],
            "parquet-hive/parquet-hive-storage-handler/src/main/java/parquet/hive/serde/primitive/ParquetPrimitiveInspectorFactory.java": [
                6,
                3
            ],
            "parquet-hive/parquet-hive-storage-handler/src/main/java/parquet/hive/serde/primitive/ParquetShortInspector.java": [
                6,
                3
            ],
            "parquet-hive/parquet-hive-storage-handler/src/main/java/parquet/hive/serde/primitive/ParquetStringInspector.java": [
                7,
                5
            ],
            "parquet-hive/parquet-hive-storage-handler/src/main/java/parquet/hive/writable/BigDecimalWritable.java": [
                15,
                6
            ],
            "parquet-hive/parquet-hive-storage-handler/src/main/java/parquet/hive/writable/BinaryWritable.java": [
                9,
                4
            ],
            "parquet-hive/parquet-hive-storage-handler/src/main/java/parquet/hive/write/DataWritableWriteSupport.java": [
                12,
                12
            ],
            "parquet-hive/parquet-hive-storage-handler/src/main/java/parquet/hive/write/DataWritableWriter.java": [
                19,
                12
            ],
            "parquet-hive/parquet-hive-storage-handler/src/test/java/org/apache/hadoop/hive/ql/io/parquet/TestMapredParquetInputFormat.java": [
                0,
                37
            ],
            "parquet-hive/parquet-hive-storage-handler/src/test/java/org/apache/hadoop/hive/ql/io/parquet/TestMapredParquetOutputFormat.java": [
                0,
                90
            ],
            "parquet-hive/parquet-hive-storage-handler/src/test/java/parquet/hive/TestHiveSchemaConverter.java": [
                12,
                2
            ],
            "parquet-hive/parquet-hive-storage-handler/src/test/java/parquet/hive/TestMapredParquetInputFormat.java": [
                388,
                0
            ],
            "parquet-hive/parquet-hive-storage-handler/src/test/java/parquet/hive/TestMapredParquetOuputFormat.java": [
                235,
                0
            ],
            "parquet-hive/parquet-hive-storage-handler/src/test/java/parquet/hive/TestParquetSerDe.java": [
                18,
                39
            ],
            "parquet-hive/parquet-hive-storage-handler/src/test/java/parquet/hive/UtilitiesTestMethods.java": [
                245,
                0
            ],
            "parquet-hive/parquet-hive-storage-handler/src/test/java/parquet/hive/serde/TestAbstractParquetMapInspector.java": [
                9,
                5
            ],
            "parquet-hive/parquet-hive-storage-handler/src/test/java/parquet/hive/serde/TestDeepParquetHiveMapInspector.java": [
                10,
                6
            ],
            "parquet-hive/parquet-hive-storage-handler/src/test/java/parquet/hive/serde/TestParquetHiveArrayInspector.java": [
                9,
                5
            ],
            "parquet-hive/parquet-hive-storage-handler/src/test/java/parquet/hive/serde/TestStandardParquetHiveMapInspector.java": [
                9,
                5
            ],
            "parquet-hive/pom.xml": null,
            "parquet-jackson/README.md": null,
            "parquet-jackson/pom.xml": null,
            "parquet-pig-bundle/pom.xml": null,
            "parquet-pig/pom.xml": null,
            "parquet-scrooge/pom.xml": null,
            "parquet-test-hadoop2/pom.xml": null,
            "parquet-thrift/pom.xml": null,
            "parquet-thrift/src/main/java/parquet/hadoop/thrift/ParquetThriftBytesOutputFormat.java": [
                2,
                2
            ],
            "parquet-thrift/src/main/java/parquet/hadoop/thrift/ThriftBytesWriteSupport.java": [
                3,
                3
            ],
            "parquet-thrift/src/main/java/parquet/hadoop/thrift/ThriftToParquetFileWriter.java": [
                3,
                3
            ],
            "parquet-thrift/src/main/java/parquet/thrift/BufferedProtocolReadToWrite.java": [
                31,
                15
            ],
            "parquet-thrift/src/main/java/parquet/thrift/ParquetWriteProtocol.java": [
                7,
                5
            ],
            "parquet-thrift/src/main/java/parquet/thrift/ReadWriteErrorHandler.java": [
                17,
                6
            ],
            "parquet-thrift/src/main/java/parquet/thrift/ThriftRecordConverter.java": [
                1,
                1
            ],
            "parquet-thrift/src/main/java/parquet/thrift/struct/ThriftType.java": [
                3,
                25
            ],
            "parquet-thrift/src/test/java/parquet/hadoop/thrift/TestInputOutputFormat.java": [
                1,
                1
            ],
            "parquet-thrift/src/test/java/parquet/hadoop/thrift/TestParquetToThriftReadProjection.java": [
                8,
                14
            ],
            "parquet-thrift/src/test/java/parquet/thrift/TestParquetReadProtocol.java": [
                1,
                3
            ],
            "parquet-thrift/src/test/java/parquet/thrift/TestParquetWriteProtocol.java": [
                33,
                49
            ],
            "parquet-thrift/src/test/java/parquet/thrift/TestProtocolReadToWrite.java": [
                51,
                25
            ],
            "parquet-thrift/src/test/java/parquet/thrift/TestThriftParquetReaderWriter.java": [
                1,
                1
            ],
            "parquet-thrift/src/test/java/parquet/thrift/TestThriftToPigCompatibility.java": [
                1,
                3
            ],
            "parquet-thrift/src/test/java/parquet/thrift/struct/CompatibilityCheckerTest.java": [
                1,
                1
            ],
            "parquet-thrift/src/test/thrift/test.thrift": null,
            "pom.xml": null
        }
    },
    "b07b16013482fe8af9333727814f9e6ff1d3ca7a": {
        "datetime": "2014-02-21T11:43:16-08:00",
        "summary": "Merge pull request #262 from Parquet/scrooge_schema_converter",
        "message": "Merge pull request #262 from Parquet/scrooge_schema_converter\n\nReadSupport for Scrooge including Scrooge schema converter and projection pushdown in Scrooge",
        "diff": {
            "parquet-scrooge/pom.xml": null,
            "parquet-scrooge/src/main/java/parquet/scrooge/ParquetScroogeInputFormat.java": [
                0,
                28
            ],
            "parquet-scrooge/src/main/java/parquet/scrooge/ParquetScroogeScheme.java": [
                1,
                1
            ],
            "parquet-scrooge/src/main/java/parquet/scrooge/ScroogeReadSupport.java": [
                0,
                42
            ],
            "parquet-scrooge/src/main/java/parquet/scrooge/ScroogeStructConverter.java": [
                0,
                294
            ],
            "parquet-scrooge/src/test/java/parquet/scrooge/ParquetScroogeSchemeTest.java": [
                15,
                35
            ],
            "parquet-scrooge/src/test/java/parquet/scrooge/ScroogeStructConverterTest.java": [
                0,
                105
            ],
            "parquet-scrooge/src/test/thrift/test.thrift": null,
            "parquet-thrift/src/main/java/parquet/hadoop/thrift/ParquetThriftInputFormat.java": [
                1,
                9
            ],
            "parquet-thrift/src/main/java/parquet/hadoop/thrift/ThriftReadSupport.java": [
                7,
                7
            ],
            "parquet-thrift/src/main/java/parquet/thrift/ThriftMetaData.java": [
                9,
                10
            ],
            "parquet-thrift/src/main/java/parquet/thrift/ThriftSchemaConverter.java": [
                73,
                83
            ],
            "parquet-thrift/src/main/java/parquet/thrift/struct/ThriftField.java": [
                0,
                23
            ],
            "parquet-thrift/src/main/java/parquet/thrift/struct/ThriftType.java": [
                0,
                134
            ],
            "parquet-thrift/src/test/java/parquet/thrift/TestThriftSchemaConverter.java": [
                22,
                3
            ]
        }
    },
    "70eada470f069ea27c5e2d47d1004fec56f7dcca": {
        "datetime": "2014-02-22T01:28:16+01:00",
        "summary": "NULL tuples cause NPE when writing",
        "message": "NULL tuples cause NPE when writing\n",
        "diff": {
            "parquet-cascading/src/main/java/parquet/cascading/TupleWriteSupport.java": [
                0,
                4
            ]
        }
    },
    "000659a2d80ca4584e0e39fae4164009944d3549": {
        "datetime": "2014-02-24T15:41:59+01:00",
        "summary": "Merge pull request #1 from jalkjaer/cascading_sink",
        "message": "Merge pull request #1 from jalkjaer/cascading_sink\n\nNULL tuples causes NPE when writing",
        "diff": {
            "parquet-cascading/src/main/java/parquet/cascading/TupleWriteSupport.java": [
                0,
                4
            ]
        }
    },
    "509e26883b30a2d505c64b28633be2e628cd1f56": {
        "datetime": "2014-02-24T15:46:28+01:00",
        "summary": "Better writing of a loop",
        "message": "Better writing of a loop\n",
        "diff": {
            "parquet-cascading/src/main/java/parquet/cascading/TupleWriteSupport.java": [
                9,
                5
            ]
        }
    },
    "2403257ff4c412465e4bfc4af5f0e745b5d96565": {
        "datetime": "2014-02-27T08:16:18-08:00",
        "summary": "Use toStringUsingUTF8 to fix tests.",
        "message": "Use toStringUsingUTF8 to fix tests.\n\nBinary values will not necessarily decode with UTF8, but the\nExpectationValidatingRecordConsumer can decode because its inputs are\ncontrolled for testing.\n",
        "diff": {
            "parquet-column/src/test/java/parquet/io/ExpectationValidatingRecordConsumer.java": [
                1,
                1
            ]
        }
    },
    "3fc099fd7b315a2daecf2f832071f8b91006ecf8": {
        "datetime": "2014-02-27T08:16:18-08:00",
        "summary": "Factoring out common Binary impl in dictionary writer.",
        "message": "Factoring out common Binary impl in dictionary writer.\n",
        "diff": {
            "parquet-column/src/main/java/parquet/column/values/dictionary/DictionaryValuesWriter.java": [
                42,
                32
            ]
        }
    },
    "d7c7395b44144d05ff4dcb464bdcc4e90056c3c6": {
        "datetime": "2014-02-27T08:16:18-08:00",
        "summary": "Merge Fixed dictionary with Binary dictionary.",
        "message": "Merge Fixed dictionary with Binary dictionary.\n",
        "diff": {
            "parquet-column/src/main/java/parquet/column/Encoding.java": [
                2,
                1
            ],
            "parquet-column/src/main/java/parquet/column/values/dictionary/PlainValuesDictionary.java": [
                59,
                45
            ]
        }
    },
    "6b2eef9d99600f4fc48a9ba40e15fea3e5e748ad": {
        "datetime": "2014-02-27T08:16:18-08:00",
        "summary": "Delegate fixed and int96 types to convertBINARY.",
        "message": "Delegate fixed and int96 types to convertBINARY.\n",
        "diff": {
            "parquet-column/src/main/java/parquet/column/impl/ColumnReaderImpl.java": [
                34,
                2
            ]
        }
    },
    "56387e33db7df5f50b5754b756d1551af2735fe3": {
        "datetime": "2014-02-27T08:16:18-08:00",
        "summary": "Remove int96 references from RecordConsumer and Converters.",
        "message": "Remove int96 references from RecordConsumer and Converters.\n\nThis commit removes int96-specific code from the RecordConsumer and\nthe Converters. Implementations are responsible for checking the Type of\ncolumns.\n\nBecause Binary is used for int96 values, it is no longer assumed that\na Binary is printable as a UTF8 string in methods like Binary#toString.\n",
        "diff": {
            "parquet-column/src/main/java/parquet/example/data/simple/Int96Value.java": [
                1,
                1
            ],
            "parquet-column/src/main/java/parquet/example/data/simple/convert/SimplePrimitiveConverter.java": [
                9,
                0
            ],
            "parquet-column/src/main/java/parquet/io/MessageColumnIO.java": [
                10,
                0
            ],
            "parquet-column/src/main/java/parquet/io/RecordConsumerLoggingWrapper.java": [
                10,
                1
            ],
            "parquet-column/src/main/java/parquet/io/ValidatingRecordConsumer.java": [
                10,
                28
            ],
            "parquet-column/src/main/java/parquet/io/api/Binary.java": [
                1,
                1
            ],
            "parquet-column/src/main/java/parquet/io/api/PrimitiveConverter.java": [
                7,
                0
            ],
            "parquet-column/src/main/java/parquet/io/api/RecordConsumer.java": [
                5,
                0
            ],
            "parquet-column/src/main/java/parquet/schema/PrimitiveType.java": [
                2,
                2
            ],
            "parquet-column/src/test/java/parquet/io/ConverterConsumer.java": [
                5,
                0
            ],
            "parquet-column/src/test/java/parquet/io/ExpectationValidatingConverter.java": [
                5,
                0
            ],
            "parquet-column/src/test/java/parquet/io/ExpectationValidatingRecordConsumer.java": [
                6,
                1
            ]
        }
    },
    "34b90d7b86c600804038048e905f0f3587aba687": {
        "datetime": "2014-02-27T08:16:18-08:00",
        "summary": "Removing Int96 class, using Binary instead.",
        "message": "Removing Int96 class, using Binary instead.\n\nThis removes all references to the Int96 class and uses Binary instead.\nInt96 calls are still used at the RecordConsumer and Converter level,\nspecifically used by PrimitiveType.PrimitiveTypeName.INT96.\n",
        "diff": {
            "parquet-column/src/main/java/parquet/column/ColumnReader.java": [
                6,
                0
            ],
            "parquet-column/src/main/java/parquet/column/ColumnWriter.java": [
                9,
                0
            ],
            "parquet-column/src/main/java/parquet/column/Dictionary.java": [
                5,
                0
            ],
            "parquet-column/src/main/java/parquet/column/Encoding.java": [
                4,
                3
            ],
            "parquet-column/src/main/java/parquet/column/ParquetProperties.java": [
                3,
                3
            ],
            "parquet-column/src/main/java/parquet/column/impl/ColumnReaderImpl.java": [
                25,
                4
            ],
            "parquet-column/src/main/java/parquet/column/impl/ColumnWriterImpl.java": [
                10,
                0
            ],
            "parquet-column/src/main/java/parquet/column/values/ValuesReader.java": [
                8,
                0
            ],
            "parquet-column/src/main/java/parquet/column/values/ValuesWriter.java": [
                8,
                0
            ],
            "parquet-column/src/main/java/parquet/column/values/dictionary/DictionaryValuesReader.java": [
                10,
                0
            ],
            "parquet-column/src/main/java/parquet/column/values/dictionary/DictionaryValuesWriter.java": [
                21,
                21
            ],
            "parquet-column/src/main/java/parquet/column/values/dictionary/PlainValuesDictionary.java": [
                22,
                23
            ],
            "parquet-column/src/main/java/parquet/column/values/plain/FixedLenByteArrayPlainValuesReader.java": [
                14,
                2
            ],
            "parquet-column/src/main/java/parquet/column/values/plain/Int96PlainValuesReader.java": [
                14,
                0
            ],
            "parquet-column/src/main/java/parquet/column/values/plain/PlainValuesWriter.java": [
                14,
                0
            ],
            "parquet-column/src/main/java/parquet/example/DummyRecordConverter.java": [
                5,
                0
            ],
            "parquet-column/src/main/java/parquet/example/data/Group.java": [
                12,
                0
            ],
            "parquet-column/src/main/java/parquet/example/data/GroupValueSource.java": [
                2,
                5
            ],
            "parquet-column/src/main/java/parquet/example/data/simple/Primitive.java": [
                2,
                1
            ],
            "parquet-column/src/main/java/parquet/example/data/simple/SimpleGroup.java": [
                9,
                12
            ],
            "parquet-column/src/main/java/parquet/example/data/simple/convert/Int96Value.java": [
                6,
                5
            ],
            "parquet-column/src/main/java/parquet/example/data/simple/convert/SimplePrimitiveConverter.java": [
                4,
                3
            ],
            "parquet-column/src/main/java/parquet/io/MessageColumnIO.java": [
                3,
                2
            ],
            "parquet-column/src/main/java/parquet/io/RecordConsumerLoggingWrapper.java": [
                3,
                3
            ],
            "parquet-column/src/main/java/parquet/io/ValidatingRecordConsumer.java": [
                2,
                2
            ],
            "parquet-column/src/main/java/parquet/io/api/Int96.java": [
                26,
                0
            ],
            "parquet-column/src/main/java/parquet/io/api/PrimitiveConverter.java": [
                1,
                1
            ],
            "parquet-column/src/main/java/parquet/io/api/RecordConsumer.java": [
                1,
                1
            ],
            "parquet-column/src/main/java/parquet/schema/PrimitiveType.java": [
                10,
                9
            ],
            "parquet-column/src/test/java/parquet/io/ConverterConsumer.java": [
                2,
                1
            ],
            "parquet-column/src/test/java/parquet/io/ExpectationValidatingConverter.java": [
                3,
                2
            ],
            "parquet-column/src/test/java/parquet/io/ExpectationValidatingRecordConsumer.java": [
                3,
                3
            ],
            "parquet-column/src/test/java/parquet/io/TestColumnIO.java": [
                10,
                2
            ]
        }
    },
    "77a355af4b7828daeffcdf312108ad9f1fa738d7": {
        "datetime": "2014-02-27T08:16:18-08:00",
        "summary": "Extending example and group classes for int96.",
        "message": "Extending example and group classes for int96.\n\nThis commit gets TestColumnIO#testOneOfEach passing with an int96\ncolumn.\n",
        "diff": {
            "parquet-column/src/main/java/parquet/example/DummyRecordConverter.java": [
                0,
                5
            ],
            "parquet-column/src/main/java/parquet/example/data/Group.java": [
                0,
                12
            ],
            "parquet-column/src/main/java/parquet/example/data/GroupValueSource.java": [
                0,
                3
            ],
            "parquet-column/src/main/java/parquet/example/data/simple/Primitive.java": [
                0,
                5
            ],
            "parquet-column/src/main/java/parquet/example/data/simple/SimpleGroup.java": [
                0,
                12
            ],
            "parquet-column/src/main/java/parquet/example/data/simple/convert/Int96Value.java": [
                0,
                29
            ],
            "parquet-column/src/main/java/parquet/example/data/simple/convert/SimplePrimitiveConverter.java": [
                1,
                11
            ],
            "parquet-column/src/main/java/parquet/io/api/Int96.java": [
                0,
                2
            ],
            "parquet-column/src/test/java/parquet/io/TestColumnIO.java": [
                1,
                5
            ]
        }
    },
    "7043a64617eb25608498f502feb6c76c58b15242": {
        "datetime": "2014-02-27T08:16:18-08:00",
        "summary": "Initial int96 implementation.",
        "message": "Initial int96 implementation.\n\nThis primarily adds int96 calls throughout the read and write paths.\nInt96 is mostly a place-holder class that wraps a ByteBuffer.\n\nThis adds int96 support to the PLAIN and PLAIN_DICTIONARY encodings.\n\nExisting tests are passing.\n",
        "diff": {
            "parquet-column/src/main/java/parquet/column/ColumnReader.java": [
                0,
                6
            ],
            "parquet-column/src/main/java/parquet/column/ColumnWriter.java": [
                0,
                9
            ],
            "parquet-column/src/main/java/parquet/column/Dictionary.java": [
                0,
                5
            ],
            "parquet-column/src/main/java/parquet/column/Encoding.java": [
                0,
                7
            ],
            "parquet-column/src/main/java/parquet/column/ParquetProperties.java": [
                0,
                7
            ],
            "parquet-column/src/main/java/parquet/column/impl/ColumnReaderImpl.java": [
                2,
                39
            ],
            "parquet-column/src/main/java/parquet/column/impl/ColumnWriterImpl.java": [
                0,
                10
            ],
            "parquet-column/src/main/java/parquet/column/values/ValuesReader.java": [
                0,
                8
            ],
            "parquet-column/src/main/java/parquet/column/values/ValuesWriter.java": [
                0,
                8
            ],
            "parquet-column/src/main/java/parquet/column/values/dictionary/DictionaryValuesReader.java": [
                0,
                10
            ],
            "parquet-column/src/main/java/parquet/column/values/dictionary/DictionaryValuesWriter.java": [
                0,
                79
            ],
            "parquet-column/src/main/java/parquet/column/values/dictionary/PlainValuesDictionary.java": [
                0,
                48
            ],
            "parquet-column/src/main/java/parquet/column/values/plain/FixedLenByteArrayPlainValuesReader.java": [
                0,
                11
            ],
            "parquet-column/src/main/java/parquet/column/values/plain/Int96PlainValuesReader.java": [
                0,
                14
            ],
            "parquet-column/src/main/java/parquet/column/values/plain/PlainValuesWriter.java": [
                0,
                14
            ],
            "parquet-column/src/main/java/parquet/io/MessageColumnIO.java": [
                0,
                11
            ],
            "parquet-column/src/main/java/parquet/io/RecordConsumerLoggingWrapper.java": [
                0,
                10
            ],
            "parquet-column/src/main/java/parquet/io/ValidatingRecordConsumer.java": [
                0,
                9
            ],
            "parquet-column/src/main/java/parquet/io/api/Binary.java": [
                0,
                2
            ],
            "parquet-column/src/main/java/parquet/io/api/Int96.java": [
                0,
                24
            ],
            "parquet-column/src/main/java/parquet/io/api/PrimitiveConverter.java": [
                0,
                7
            ],
            "parquet-column/src/main/java/parquet/io/api/RecordConsumer.java": [
                0,
                5
            ],
            "parquet-column/src/main/java/parquet/schema/PrimitiveType.java": [
                9,
                10
            ],
            "parquet-column/src/test/java/parquet/io/ConverterConsumer.java": [
                0,
                6
            ],
            "parquet-column/src/test/java/parquet/io/ExpectationValidatingConverter.java": [
                0,
                6
            ],
            "parquet-column/src/test/java/parquet/io/ExpectationValidatingRecordConsumer.java": [
                0,
                6
            ],
            "parquet-column/src/test/java/parquet/io/TestColumnIO.java": [
                0,
                6
            ]
        }
    },
    "af2380fbcf5d440315d0a5335975197586ebf929": {
        "datetime": "2014-02-27T08:16:19-08:00",
        "summary": "Add NanoTime to example.",
        "message": "Add NanoTime to example.\n\nThis adds NanoTime to the example objects, stored as an int96, for\ntesting.\n",
        "diff": {
            "parquet-column/src/main/java/parquet/example/data/Group.java": [
                0,
                12
            ],
            "parquet-column/src/main/java/parquet/example/data/simple/NanoTime.java": [
                0,
                57
            ],
            "parquet-column/src/main/java/parquet/example/data/simple/SimpleGroup.java": [
                0,
                9
            ],
            "parquet-column/src/test/java/parquet/io/TestColumnIO.java": [
                2,
                2
            ]
        }
    },
    "a5d2de14fda5215cece2b25ab2dd1e73396ec25e": {
        "datetime": "2014-02-27T08:26:06-08:00",
        "summary": "Add avro constructors with Configuration for #295.",
        "message": "Add avro constructors with Configuration for #295.\n\nTo avoid doubling the number of constructors in ParquetWriter, this\ncreates more defaults that subclasses can use. The new AvroParquetWriter\nconstructors call the most specific constructor directly and use the\ndefault constants from ParquetWriter to match the default behavior of\nits constructors.\n\nAlso fixed a few doc mistakes.\n",
        "diff": {
            "parquet-avro/src/main/java/parquet/avro/AvroParquetWriter.java": [
                5,
                31
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/ParquetWriter.java": [
                3,
                12
            ]
        }
    },
    "603c0dc927c2b1aa46dba6675b24a375cfb3fc1c": {
        "datetime": "2014-02-27T08:28:56-08:00",
        "summary": "Fix avro schema conv for arrays of optional type for #312.",
        "message": "Fix avro schema conv for arrays of optional type for #312.\n",
        "diff": {
            "parquet-avro/src/main/java/parquet/avro/AvroSchemaConverter.java": [
                2,
                4
            ],
            "parquet-avro/src/test/java/parquet/avro/TestAvroSchemaConverter.java": [
                3,
                32
            ]
        }
    },
    "5e74bbed3698e94a2b7d3e3353880bdf5f5d3205": {
        "datetime": "2014-02-27T08:34:28-08:00",
        "summary": "Add Configuration constructor in thrift writer for #295.",
        "message": "Add Configuration constructor in thrift writer for #295.\n",
        "diff": {
            "parquet-thrift/src/main/java/parquet/thrift/ThriftParquetWriter.java": [
                0,
                7
            ]
        }
    },
    "8cc3e29cc28896cfd47c90abec97f1aa866832c1": {
        "datetime": "2014-02-27T21:57:08+00:00",
        "summary": "Merge pull request #313 from rdblue/295-add-conf",
        "message": "Merge pull request #313 from rdblue/295-add-conf\n\nAdd hadoop Configuration to Avro and Thrift writers (#295).",
        "diff": {
            "parquet-avro/src/main/java/parquet/avro/AvroParquetWriter.java": [
                5,
                31
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/ParquetWriter.java": [
                3,
                12
            ],
            "parquet-thrift/src/main/java/parquet/thrift/ThriftParquetWriter.java": [
                0,
                7
            ]
        }
    },
    "132f75d8d4a43772d7ae99a809345542a8c2fb83": {
        "datetime": "2014-02-27T22:11:37+00:00",
        "summary": "Merge pull request #293 from rdblue/int96-support",
        "message": "Merge pull request #293 from rdblue/int96-support\n\nInt96 support",
        "diff": {
            "parquet-column/src/main/java/parquet/column/Encoding.java": [
                0,
                5
            ],
            "parquet-column/src/main/java/parquet/column/ParquetProperties.java": [
                0,
                7
            ],
            "parquet-column/src/main/java/parquet/column/impl/ColumnReaderImpl.java": [
                19,
                3
            ],
            "parquet-column/src/main/java/parquet/column/values/dictionary/DictionaryValuesWriter.java": [
                5,
                74
            ],
            "parquet-column/src/main/java/parquet/column/values/dictionary/PlainValuesDictionary.java": [
                10,
                45
            ],
            "parquet-column/src/main/java/parquet/column/values/plain/FixedLenByteArrayPlainValuesReader.java": [
                3,
                2
            ],
            "parquet-column/src/main/java/parquet/example/DummyRecordConverter.java": [
                0,
                0
            ],
            "parquet-column/src/main/java/parquet/example/data/Group.java": [
                0,
                12
            ],
            "parquet-column/src/main/java/parquet/example/data/GroupValueSource.java": [
                0,
                6
            ],
            "parquet-column/src/main/java/parquet/example/data/simple/Int96Value.java": [
                0,
                28
            ],
            "parquet-column/src/main/java/parquet/example/data/simple/NanoTime.java": [
                0,
                57
            ],
            "parquet-column/src/main/java/parquet/example/data/simple/Primitive.java": [
                0,
                4
            ],
            "parquet-column/src/main/java/parquet/example/data/simple/SimpleGroup.java": [
                1,
                25
            ],
            "parquet-column/src/main/java/parquet/example/data/simple/convert/SimplePrimitiveConverter.java": [
                2,
                2
            ],
            "parquet-column/src/main/java/parquet/io/RecordConsumerLoggingWrapper.java": [
                1,
                2
            ],
            "parquet-column/src/main/java/parquet/io/ValidatingRecordConsumer.java": [
                1,
                28
            ],
            "parquet-column/src/main/java/parquet/io/api/Binary.java": [
                1,
                3
            ],
            "parquet-column/src/main/java/parquet/schema/PrimitiveType.java": [
                9,
                9
            ],
            "parquet-column/src/test/java/parquet/io/ExpectationValidatingRecordConsumer.java": [
                0,
                1
            ],
            "parquet-column/src/test/java/parquet/io/TestColumnIO.java": [
                2,
                4
            ]
        }
    },
    "d35657890c351e2945711e712f9a784cf8a9fbd6": {
        "datetime": "2014-02-28T13:25:16-08:00",
        "summary": "Merge pull request #264 from lukasnalezenec/protobuf",
        "message": "Merge pull request #264 from lukasnalezenec/protobuf\n\nNative Protocol Buffer support",
        "diff": {
            ".gitignore": null,
            "README.md": null,
            "parquet-column/src/main/java/parquet/io/api/Converter.java": [
                2,
                2
            ],
            "parquet-protobuf/README.md": null,
            "parquet-protobuf/pom.xml": null,
            "parquet-protobuf/src/main/java/parquet/proto/ProtoMessageConverter.java": [
                0,
                346
            ],
            "parquet-protobuf/src/main/java/parquet/proto/ProtoParquetInputFormat.java": [
                0,
                35
            ],
            "parquet-protobuf/src/main/java/parquet/proto/ProtoParquetOutputFormat.java": [
                0,
                54
            ],
            "parquet-protobuf/src/main/java/parquet/proto/ProtoParquetReader.java": [
                0,
                39
            ],
            "parquet-protobuf/src/main/java/parquet/proto/ProtoParquetWriter.java": [
                0,
                78
            ],
            "parquet-protobuf/src/main/java/parquet/proto/ProtoReadSupport.java": [
                0,
                77
            ],
            "parquet-protobuf/src/main/java/parquet/proto/ProtoRecordConverter.java": [
                0,
                81
            ],
            "parquet-protobuf/src/main/java/parquet/proto/ProtoRecordMaterializer.java": [
                0,
                41
            ],
            "parquet-protobuf/src/main/java/parquet/proto/ProtoSchemaConverter.java": [
                0,
                116
            ],
            "parquet-protobuf/src/main/java/parquet/proto/ProtoWriteSupport.java": [
                0,
                336
            ],
            "parquet-protobuf/src/test/java/parquet/proto/ProtoInputOutputFormatTest.java": [
                0,
                103
            ],
            "parquet-protobuf/src/test/java/parquet/proto/ProtoRecordConverterTest.java": [
                0,
                222
            ],
            "parquet-protobuf/src/test/java/parquet/proto/ProtoSchemaConverterTest.java": [
                0,
                95
            ],
            "parquet-protobuf/src/test/java/parquet/proto/ProtoWriteSupportTest.java": [
                0,
                165
            ],
            "parquet-protobuf/src/test/java/parquet/proto/TestUtils.java": [
                0,
                170
            ],
            "parquet-protobuf/src/test/java/parquet/proto/utils/ReadUsingMR.java": [
                0,
                84
            ],
            "parquet-protobuf/src/test/java/parquet/proto/utils/WriteUsingMR.java": [
                0,
                110
            ],
            "parquet-protobuf/src/test/resources/TestProtobuf.proto": null,
            "pom.xml": null
        }
    },
    "6063921a37a77d9cd29eab64be3f91146ac52a15": {
        "datetime": "2014-02-28T13:33:47-08:00",
        "summary": "Merge pull request #285 from mickaellcr/cascading_sink",
        "message": "Merge pull request #285 from mickaellcr/cascading_sink\n\n[CASCADING] Provide the sink implementation for ParquetTupleScheme",
        "diff": {
            "parquet-cascading/src/main/java/parquet/cascading/ParquetTupleScheme.java": [
                12,
                31
            ],
            "parquet-cascading/src/main/java/parquet/cascading/TupleWriteSupport.java": [
                0,
                103
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/ParquetOutputFormat.java": [
                0,
                5
            ]
        }
    },
    "f93c9cff515f1d676e104470a54b8d5713a2d2a5": {
        "datetime": "2014-02-28T13:34:44-08:00",
        "summary": "Update cascading doc with Scrooge projection down.",
        "message": "Update cascading doc with Scrooge projection down.",
        "diff": {
            "parquet_cascading.md": null
        }
    },
    "e3923592020fb27332b9c3f68f399cbd900bf0b2": {
        "datetime": "2014-02-28T13:48:22-08:00",
        "summary": "Merge pull request #316 from rdblue/thrift-prefix",
        "message": "Merge pull request #316 from rdblue/thrift-prefix\n\nUpdate poms to use thrift.exectuable property.",
        "diff": {
            "parquet-cascading/pom.xml": null,
            "parquet-scrooge/pom.xml": null,
            "parquet-thrift/pom.xml": null,
            "pom.xml": null
        }
    },
    "2d5563b5296f60a053ea2fb84fee33db5c67fc76": {
        "datetime": "2014-02-28T13:54:21-08:00",
        "summary": "Merge pull request #311 from tomwhite/avro-null-default-values-bug",
        "message": "Merge pull request #311 from tomwhite/avro-null-default-values-bug\n\nAvro null default values bug",
        "diff": {
            "parquet-avro/pom.xml": null,
            "parquet-avro/src/main/java/parquet/avro/AvroIndexedRecordConverter.java": [
                0,
                3
            ],
            "parquet-avro/src/test/resources/car.avdl": null
        }
    },
    "b722e7bd77ead0676c253bd9bdbd30cd263864f1": {
        "datetime": "2014-02-28T13:57:26-08:00",
        "summary": "Merge pull request #314 from rdblue/312-fix-avro-array-of-optional",
        "message": "Merge pull request #314 from rdblue/312-fix-avro-array-of-optional\n\nFix avro schema conv for arrays of optional type for #312.",
        "diff": {
            "parquet-avro/src/main/java/parquet/avro/AvroSchemaConverter.java": [
                2,
                4
            ],
            "parquet-avro/src/test/java/parquet/avro/TestAvroSchemaConverter.java": [
                3,
                32
            ]
        }
    },
    "3cfea0a6b817a43cb9ac4fbcfb3fdb9d66b1ab30": {
        "datetime": "2014-03-05T17:09:13-08:00",
        "summary": "Merge pull request #310 from wesleypeck/merge_parquet_tools",
        "message": "Merge pull request #310 from wesleypeck/merge_parquet_tools\n\nMerge parquet tools",
        "diff": {
            "parquet-tools/NOTICE": null,
            "parquet-tools/README.md": null,
            "parquet-tools/pom.xml": null,
            "parquet-tools/src/main/assembly/assembly.xml": null,
            "parquet-tools/src/main/java/parquet/tools/Main.java": [
                0,
                229
            ],
            "parquet-tools/src/main/java/parquet/tools/command/ArgsOnlyCommand.java": [
                0,
                53
            ],
            "parquet-tools/src/main/java/parquet/tools/command/CatCommand.java": [
                0,
                67
            ],
            "parquet-tools/src/main/java/parquet/tools/command/Command.java": [
                0,
                27
            ],
            "parquet-tools/src/main/java/parquet/tools/command/DumpCommand.java": [
                0,
                320
            ],
            "parquet-tools/src/main/java/parquet/tools/command/HeadCommand.java": [
                0,
                92
            ],
            "parquet-tools/src/main/java/parquet/tools/command/Registry.java": [
                0,
                57
            ],
            "parquet-tools/src/main/java/parquet/tools/command/ShowMetaCommand.java": [
                0,
                67
            ],
            "parquet-tools/src/main/java/parquet/tools/command/ShowSchemaCommand.java": [
                0,
                83
            ],
            "parquet-tools/src/main/java/parquet/tools/read/SimpleReadSupport.java": [
                0,
                38
            ],
            "parquet-tools/src/main/java/parquet/tools/read/SimpleRecord.java": [
                0,
                117
            ],
            "parquet-tools/src/main/java/parquet/tools/read/SimpleRecordConverter.java": [
                0,
                165
            ],
            "parquet-tools/src/main/java/parquet/tools/read/SimpleRecordMaterializer.java": [
                0,
                39
            ],
            "parquet-tools/src/main/java/parquet/tools/util/MetadataUtils.java": [
                0,
                225
            ],
            "parquet-tools/src/main/java/parquet/tools/util/PrettyPrintWriter.java": [
                0,
                1032
            ],
            "parquet-tools/src/main/scripts/parquet-cat": null,
            "parquet-tools/src/main/scripts/parquet-dump": null,
            "parquet-tools/src/main/scripts/parquet-head": null,
            "parquet-tools/src/main/scripts/parquet-meta": null,
            "parquet-tools/src/main/scripts/parquet-schema": null,
            "parquet-tools/src/main/scripts/parquet-tools": null,
            "pom.xml": null
        }
    },
    "deb5e5d0aef6f082b650a3d539f118cba22a80fd": {
        "datetime": "2014-03-06T17:07:04-08:00",
        "summary": "oauth based authentication; fix grep change",
        "message": "oauth based authentication; fix grep change\n",
        "diff": {
            "changelog.sh": null
        }
    },
    "459b29b2734c81a4b21bbf11175a582423613e4b": {
        "datetime": "2014-03-06T17:35:41-08:00",
        "summary": "Merge pull request #319 from Parquet/fix_changelog",
        "message": "Merge pull request #319 from Parquet/fix_changelog\n\noauth based authentication; fix grep change",
        "diff": {
            "changelog.sh": null
        }
    },
    "a08d2570f55bf2161b7c2981ce76bfb59c0ed22e": {
        "datetime": "2014-03-07T10:26:57-08:00",
        "summary": "Spelling fix",
        "message": "Spelling fix\n",
        "diff": {
            "parquet-protobuf/src/test/resources/TestProtobuf.proto": null
        }
    },
    "eb77222fd964301909ab9cef7b522c38601d37d8": {
        "datetime": "2014-03-07T10:43:51-08:00",
        "summary": "Merge pull request #320 from posix4e/master",
        "message": "Merge pull request #320 from posix4e/master\n\nSpelling fix",
        "diff": {
            "parquet-protobuf/src/test/resources/TestProtobuf.proto": null
        }
    },
    "9899e5ba66d3c9d0a8611b9dc914ed79ca7d70f0": {
        "datetime": "2014-03-20T10:41:40-07:00",
        "summary": "fix filesystem resolution",
        "message": "fix filesystem resolution\n",
        "diff": {
            "parquet-hadoop/src/main/java/parquet/hadoop/ParquetReader.java": [
                1,
                1
            ]
        }
    },
    "0b5116a6d694b99e7b460ac32fd02810162f49f9": {
        "datetime": "2014-03-20T11:22:50-07:00",
        "summary": "Merge pull request #329 from Parquet/fix_file_system_resolution",
        "message": "Merge pull request #329 from Parquet/fix_file_system_resolution\n\nfix filesystem resolution",
        "diff": {
            "parquet-hadoop/src/main/java/parquet/hadoop/ParquetReader.java": [
                1,
                1
            ]
        }
    },
    "1920abc2b5c2c4007e44b2c452870e24f7a0e17a": {
        "datetime": "2014-03-23T19:43:48-07:00",
        "summary": "compress schemas in input splits",
        "message": "compress schemas in input splits\n",
        "diff": {
            "parquet-column/pom.xml": null,
            "parquet-encoding/pom.xml": null,
            "parquet-hadoop/pom.xml": null,
            "parquet-hadoop/src/main/java/parquet/hadoop/ParquetInputSplit.java": [
                8,
                57
            ],
            "parquet-hadoop/src/test/java/parquet/hadoop/TestParquetInputSplit.java": [
                0,
                45
            ]
        }
    },
    "d0e548feae5d16d8901385d158929a363b4da780": {
        "datetime": "2014-03-23T20:08:11-07:00",
        "summary": "a bit of jar size optimization",
        "message": "a bit of jar size optimization\n",
        "diff": {
            "parquet-hadoop/pom.xml": null
        }
    },
    "4246d18a5fd8d87b29740a56ec3616f14320f07c": {
        "datetime": "2014-03-23T22:39:11-07:00",
        "summary": "close gzip stream in finally",
        "message": "close gzip stream in finally\n",
        "diff": {
            "parquet-hadoop/src/main/java/parquet/hadoop/ParquetInputSplit.java": [
                4,
                11
            ]
        }
    },
    "9fdafc0e255e086d849b0738117d1e01f47208fd": {
        "datetime": "2014-03-24T11:35:45-07:00",
        "summary": "Merge pull request #333 from Parquet/compress_schemas_in_split",
        "message": "Merge pull request #333 from Parquet/compress_schemas_in_split\n\nCompress schemas in split",
        "diff": {
            "parquet-column/pom.xml": null,
            "parquet-encoding/pom.xml": null,
            "parquet-hadoop/pom.xml": null,
            "parquet-hadoop/src/main/java/parquet/hadoop/ParquetInputSplit.java": [
                8,
                64
            ],
            "parquet-hadoop/src/test/java/parquet/hadoop/TestParquetInputSplit.java": [
                0,
                45
            ]
        }
    },
    "737a5d5d8447ef410819f71c8ed112c3af694a3c": {
        "datetime": "2014-03-24T19:23:53-07:00",
        "summary": "issue #290, hive map conversion to parquet schema",
        "message": "issue #290, hive map conversion to parquet schema\n",
        "diff": {
            "parquet-column/src/main/java/parquet/schema/GroupType.java": [
                0,
                1
            ],
            "parquet-hive/parquet-hive-storage-handler/src/main/java/org/apache/hadoop/hive/ql/io/parquet/convert/HiveSchemaConverter.java": [
                2,
                2
            ]
        }
    },
    "3d4311fd2d4ab7a2ae3ee326a974bbdc6c62b538": {
        "datetime": "2014-03-25T11:27:08-07:00",
        "summary": "remove originalType check for typeEquals of GroupType and add tests for HiveSchemaConverter",
        "message": "remove originalType check for typeEquals of GroupType and add tests for HiveSchemaConverter\n",
        "diff": {
            "parquet-column/src/main/java/parquet/schema/GroupType.java": [
                1,
                0
            ],
            "parquet-hive/parquet-hive-storage-handler/src/main/java/org/apache/hadoop/hive/ql/io/parquet/convert/HiveSchemaConverter.java": [
                2,
                2
            ],
            "parquet-hive/parquet-hive-storage-handler/src/test/java/org/apache/hadoop/hive/ql/io/parquet/TestHiveSchemaConverter.java": [
                0,
                24
            ]
        }
    },
    "ba9411990eaed723b3208216496afb3b59a5289e": {
        "datetime": "2014-03-26T21:30:22+01:00",
        "summary": "protobuf dependency version changed from 2.4.1 to 2.5.0",
        "message": "protobuf dependency version changed from 2.4.1 to 2.5.0\n",
        "diff": {
            "parquet-protobuf/pom.xml": null
        }
    },
    "ee00e61b156001e157538ebd2bf93edfd293d2d6": {
        "datetime": "2014-03-26T21:33:39+01:00",
        "summary": "protobuf dependency version changed from 2.4.1 to 2.5.0 - commit fix",
        "message": "protobuf dependency version changed from 2.4.1 to 2.5.0 - commit fix\n",
        "diff": {
            "parquet-protobuf/pom.xml": null
        }
    },
    "05dea98103d8115a50302be4bda7c957c0dd9d9e": {
        "datetime": "2014-03-26T17:25:50-07:00",
        "summary": " issue #324, move ParquetStringInspector to org.apache.hadoop.hive.serde2.objectinspector.primitive package",
        "message": " issue #324, move ParquetStringInspector to org.apache.hadoop.hive.serde2.objectinspector.primitive package\n",
        "diff": {
            "parquet-hive/parquet-hive-storage-handler/src/main/java/org/apache/hadoop/hive/ql/io/parquet/serde/ArrayWritableObjectInspector.java": [
                1,
                8
            ],
            "parquet-hive/parquet-hive-storage-handler/src/main/java/org/apache/hadoop/hive/ql/io/parquet/serde/primitive/ParquetPrimitiveInspectorFactory.java": [
                0,
                1
            ],
            "parquet-hive/parquet-hive-storage-handler/src/main/java/org/apache/hadoop/hive/ql/io/parquet/serde/primitive/ParquetStringInspector.java": [
                5,
                6
            ]
        }
    },
    "621cf4e92be3dd3f2dd1a92a8dd12f244a7d7be3": {
        "datetime": "2014-03-27T16:42:15-07:00",
        "summary": "Added statistics to Parquet pages and rowGroups",
        "message": "Added statistics to Parquet pages and rowGroups\n",
        "diff": {
            "parquet-column/src/main/java/parquet/column/ColumnWriter.java": [
                0,
                6
            ],
            "parquet-column/src/main/java/parquet/column/UnknownColumnTypeException.java": [
                0,
                40
            ],
            "parquet-column/src/main/java/parquet/column/impl/ColumnWriteStoreImpl.java": [
                0,
                5
            ],
            "parquet-column/src/main/java/parquet/column/impl/ColumnWriterImpl.java": [
                12,
                46
            ],
            "parquet-column/src/main/java/parquet/column/page/Page.java": [
                2,
                13
            ],
            "parquet-column/src/main/java/parquet/column/page/PageWriter.java": [
                1,
                3
            ],
            "parquet-column/src/main/java/parquet/column/statistics/BinaryStatistics.java": [
                0,
                95
            ],
            "parquet-column/src/main/java/parquet/column/statistics/BooleanStatistics.java": [
                0,
                93
            ],
            "parquet-column/src/main/java/parquet/column/statistics/DoubleStatistics.java": [
                0,
                93
            ],
            "parquet-column/src/main/java/parquet/column/statistics/FloatStatistics.java": [
                0,
                94
            ],
            "parquet-column/src/main/java/parquet/column/statistics/IntStatistics.java": [
                0,
                93
            ],
            "parquet-column/src/main/java/parquet/column/statistics/LongStatistics.java": [
                0,
                92
            ],
            "parquet-column/src/main/java/parquet/column/statistics/Statistics.java": [
                0,
                77
            ],
            "parquet-column/src/main/java/parquet/column/statistics/StatisticsClassException.java": [
                0,
                31
            ],
            "parquet-column/src/main/java/parquet/column/statistics/StatsHelper.java": [
                0,
                30
            ],
            "parquet-column/src/test/java/parquet/column/mem/TestMemPageStore.java": [
                4,
                6
            ],
            "parquet-column/src/test/java/parquet/column/page/mem/MemPageWriter.java": [
                4,
                4
            ],
            "parquet-column/src/test/java/parquet/column/statistics/TestStatistics.java": [
                0,
                447
            ],
            "parquet-column/src/test/java/parquet/io/TestColumnIO.java": [
                0,
                127
            ],
            "parquet-common/src/main/java/parquet/bytes/BytesUtils.java": [
                0,
                50
            ],
            "parquet-hadoop/src/main/java/parquet/format/converter/ParquetMetadataConverter.java": [
                2,
                34
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/ColumnChunkPageReadStore.java": [
                0,
                1
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/ColumnChunkPageWriteStore.java": [
                2,
                14
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/ParquetFileReader.java": [
                0,
                1
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/ParquetFileWriter.java": [
                2,
                21
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/ParquetInputSplit.java": [
                5,
                5
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/metadata/ColumnChunkMetaData.java": [
                4,
                44
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/metadata/ColumnChunkProperties.java": [
                4,
                8
            ],
            "parquet-hadoop/src/test/java/parquet/hadoop/TestInputFormat.java": [
                3,
                7
            ],
            "parquet-hadoop/src/test/java/parquet/hadoop/TestParquetFileWriter.java": [
                15,
                116
            ],
            "parquet-hadoop/src/test/java/parquet/hadoop/metadata/TestColumnChunkMetaData.java": [
                3,
                4
            ]
        }
    },
    "860e123b8b8df55eaa81c0e4192373bdd7fd2497": {
        "datetime": "2014-03-29T11:52:40-07:00",
        "summary": "remove originalType check for typeEquals of GroupType and add tests for HiveSchemaConverter",
        "message": "remove originalType check for typeEquals of GroupType and add tests for HiveSchemaConverter\n",
        "diff": {
            "parquet-column/src/main/java/parquet/schema/GroupType.java": [
                1,
                0
            ],
            "parquet-hive/parquet-hive-storage-handler/src/main/java/org/apache/hadoop/hive/ql/io/parquet/convert/HiveSchemaConverter.java": [
                2,
                2
            ],
            "parquet-hive/parquet-hive-storage-handler/src/test/java/org/apache/hadoop/hive/ql/io/parquet/TestHiveSchemaConverter.java": [
                0,
                24
            ]
        }
    },
    "5ba0ff1ebf8a46a9589cc7476559da1266525cec": {
        "datetime": "2014-03-29T11:57:25-07:00",
        "summary": "Merge branch 'master' of github.com:tongjiechen/parquet-mr",
        "message": "Merge branch 'master' of github.com:tongjiechen/parquet-mr\n\nremove unnecessary tab and spaces\n",
        "diff": {
            "parquet-hive/parquet-hive-storage-handler/src/test/java/org/apache/hadoop/hive/ql/io/parquet/TestHiveSchemaConverter.java": [
                1,
                1
            ]
        }
    },
    "7b5e2ecf2cbc54ed9e53445ba52e2fc6efd3745e": {
        "datetime": "2014-04-01T13:07:21-07:00",
        "summary": "Addresses some initial comments. Javadocs, removed StatsHelper",
        "message": "Addresses some initial comments. Javadocs, removed StatsHelper\n",
        "diff": {
            "parquet-column/src/main/java/parquet/column/UnknownColumnTypeException.java": [
                1,
                1
            ],
            "parquet-column/src/main/java/parquet/column/impl/ColumnWriterImpl.java": [
                2,
                2
            ],
            "parquet-column/src/main/java/parquet/column/statistics/Statistics.java": [
                6,
                106
            ],
            "parquet-column/src/main/java/parquet/column/statistics/StatsHelper.java": [
                30,
                0
            ],
            "parquet-hadoop/src/main/java/parquet/format/converter/ParquetMetadataConverter.java": [
                2,
                1
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/ColumnChunkPageWriteStore.java": [
                2,
                1
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/ParquetFileWriter.java": [
                2,
                1
            ]
        }
    },
    "73d66174032ebba5274a7faa172542b4d70b093a": {
        "datetime": "2014-04-01T13:37:44-07:00",
        "summary": "[maven-release-plugin] prepare release parquet-1.4.0",
        "message": "[maven-release-plugin] prepare release parquet-1.4.0\n",
        "diff": {
            "parquet-avro/pom.xml": null,
            "parquet-cascading/pom.xml": null,
            "parquet-column/pom.xml": null,
            "parquet-common/pom.xml": null,
            "parquet-encoding/pom.xml": null,
            "parquet-generator/pom.xml": null,
            "parquet-hadoop-bundle/pom.xml": null,
            "parquet-hadoop/pom.xml": null,
            "parquet-hive-bundle/pom.xml": null,
            "parquet-hive/parquet-hive-binding/parquet-hive-0.10-binding/pom.xml": null,
            "parquet-hive/parquet-hive-binding/parquet-hive-0.12-binding/pom.xml": null,
            "parquet-hive/parquet-hive-binding/parquet-hive-binding-bundle/pom.xml": null,
            "parquet-hive/parquet-hive-binding/parquet-hive-binding-factory/pom.xml": null,
            "parquet-hive/parquet-hive-binding/parquet-hive-binding-interface/pom.xml": null,
            "parquet-hive/parquet-hive-binding/pom.xml": null,
            "parquet-hive/parquet-hive-storage-handler/pom.xml": null,
            "parquet-hive/pom.xml": null,
            "parquet-jackson/pom.xml": null,
            "parquet-pig-bundle/pom.xml": null,
            "parquet-pig/pom.xml": null,
            "parquet-protobuf/pom.xml": null,
            "parquet-scrooge/pom.xml": null,
            "parquet-test-hadoop2/pom.xml": null,
            "parquet-thrift/pom.xml": null,
            "parquet-tools/pom.xml": null,
            "pom.xml": null
        }
    },
    "db13f1942dcc7b5add45f5e5917ec1e792046ad0": {
        "datetime": "2014-04-01T13:37:49-07:00",
        "summary": "[maven-release-plugin] prepare for next development iteration",
        "message": "[maven-release-plugin] prepare for next development iteration\n",
        "diff": {
            "parquet-avro/pom.xml": null,
            "parquet-cascading/pom.xml": null,
            "parquet-column/pom.xml": null,
            "parquet-common/pom.xml": null,
            "parquet-encoding/pom.xml": null,
            "parquet-generator/pom.xml": null,
            "parquet-hadoop-bundle/pom.xml": null,
            "parquet-hadoop/pom.xml": null,
            "parquet-hive-bundle/pom.xml": null,
            "parquet-hive/parquet-hive-binding/parquet-hive-0.10-binding/pom.xml": null,
            "parquet-hive/parquet-hive-binding/parquet-hive-0.12-binding/pom.xml": null,
            "parquet-hive/parquet-hive-binding/parquet-hive-binding-bundle/pom.xml": null,
            "parquet-hive/parquet-hive-binding/parquet-hive-binding-factory/pom.xml": null,
            "parquet-hive/parquet-hive-binding/parquet-hive-binding-interface/pom.xml": null,
            "parquet-hive/parquet-hive-binding/pom.xml": null,
            "parquet-hive/parquet-hive-storage-handler/pom.xml": null,
            "parquet-hive/pom.xml": null,
            "parquet-jackson/pom.xml": null,
            "parquet-pig-bundle/pom.xml": null,
            "parquet-pig/pom.xml": null,
            "parquet-protobuf/pom.xml": null,
            "parquet-scrooge/pom.xml": null,
            "parquet-test-hadoop2/pom.xml": null,
            "parquet-thrift/pom.xml": null,
            "parquet-tools/pom.xml": null,
            "pom.xml": null
        }
    },
    "670c94065a21d639f5b5dc41690fb9352ffbe06f": {
        "datetime": "2014-04-01T13:47:49-07:00",
        "summary": "Merge branch 'master' of github.com:egonina/parquet-mr into stats",
        "message": "Merge branch 'master' of github.com:egonina/parquet-mr into stats\n\nConflicts:\n\tparquet-hadoop/src/main/java/parquet/hadoop/ParquetInputSplit.java\n",
        "diff": {
            "parquet-avro/pom.xml": null,
            "parquet-cascading/pom.xml": null,
            "parquet-column/pom.xml": null,
            "parquet-common/pom.xml": null,
            "parquet-encoding/pom.xml": null,
            "parquet-generator/pom.xml": null,
            "parquet-hadoop-bundle/pom.xml": null,
            "parquet-hadoop/pom.xml": null,
            "parquet-hadoop/src/main/java/parquet/hadoop/ParquetInputSplit.java": [
                4,
                62
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/ParquetReader.java": [
                1,
                1
            ],
            "parquet-hadoop/src/test/java/parquet/hadoop/TestParquetInputSplit.java": [
                0,
                45
            ],
            "parquet-hive-bundle/pom.xml": null,
            "parquet-hive/parquet-hive-binding/parquet-hive-0.10-binding/pom.xml": null,
            "parquet-hive/parquet-hive-binding/parquet-hive-0.12-binding/pom.xml": null,
            "parquet-hive/parquet-hive-binding/parquet-hive-binding-bundle/pom.xml": null,
            "parquet-hive/parquet-hive-binding/parquet-hive-binding-factory/pom.xml": null,
            "parquet-hive/parquet-hive-binding/parquet-hive-binding-interface/pom.xml": null,
            "parquet-hive/parquet-hive-binding/pom.xml": null,
            "parquet-hive/parquet-hive-storage-handler/pom.xml": null,
            "parquet-hive/pom.xml": null,
            "parquet-jackson/pom.xml": null,
            "parquet-pig-bundle/pom.xml": null,
            "parquet-pig/pom.xml": null,
            "parquet-protobuf/pom.xml": null,
            "parquet-scrooge/pom.xml": null,
            "parquet-test-hadoop2/pom.xml": null,
            "parquet-thrift/pom.xml": null,
            "parquet-tools/pom.xml": null,
            "pom.xml": null
        }
    },
    "594c47ea97bde54cccdd60cae2389509bfd85d2a": {
        "datetime": "2014-04-01T13:56:17-07:00",
        "summary": "Added licence to new files",
        "message": "Added licence to new files\n",
        "diff": {
            "parquet-column/src/main/java/parquet/column/UnknownColumnTypeException.java": [
                1,
                1
            ],
            "parquet-column/src/main/java/parquet/column/statistics/BinaryStatistics.java": [
                0,
                15
            ],
            "parquet-column/src/main/java/parquet/column/statistics/BooleanStatistics.java": [
                0,
                15
            ],
            "parquet-column/src/main/java/parquet/column/statistics/DoubleStatistics.java": [
                0,
                15
            ],
            "parquet-column/src/main/java/parquet/column/statistics/FloatStatistics.java": [
                0,
                15
            ],
            "parquet-column/src/main/java/parquet/column/statistics/IntStatistics.java": [
                0,
                15
            ],
            "parquet-column/src/main/java/parquet/column/statistics/LongStatistics.java": [
                0,
                15
            ],
            "parquet-column/src/main/java/parquet/column/statistics/Statistics.java": [
                0,
                15
            ],
            "parquet-column/src/main/java/parquet/column/statistics/StatisticsClassException.java": [
                1,
                1
            ],
            "parquet-column/src/test/java/parquet/column/statistics/TestStatistics.java": [
                0,
                15
            ]
        }
    },
    "616f7783fb7fc527c4bbf559071e2b068ea916a9": {
        "datetime": "2014-04-01T14:06:45-07:00",
        "summary": "Update CHANGES.md",
        "message": "Update CHANGES.md",
        "diff": {
            "CHANGES.md": null
        }
    },
    "44f31c53c5116932401d5b759e9be07ff5bdb9e4": {
        "datetime": "2014-04-01T14:31:59-07:00",
        "summary": "Update CHANGES.md",
        "message": "Update CHANGES.md",
        "diff": {
            "CHANGES.md": null
        }
    },
    "125529bbb0a8e49d6b78d60472121eb20d53a9f8": {
        "datetime": "2014-04-01T15:47:30-07:00",
        "summary": " issue #324, move ParquetStringInspector to org.apache.hadoop.hive.serde2.objectinspector.primitive package",
        "message": " issue #324, move ParquetStringInspector to org.apache.hadoop.hive.serde2.objectinspector.primitive package\n",
        "diff": {
            "parquet-hive/parquet-hive-storage-handler/src/main/java/org/apache/hadoop/hive/ql/io/parquet/serde/ArrayWritableObjectInspector.java": [
                0,
                7
            ],
            "parquet-hive/parquet-hive-storage-handler/src/main/java/org/apache/hadoop/hive/ql/io/parquet/serde/primitive/ParquetPrimitiveInspectorFactory.java": [
                0,
                1
            ],
            "parquet-hive/parquet-hive-storage-handler/src/main/java/org/apache/hadoop/hive/ql/io/parquet/serde/primitive/ParquetStringInspector.java": [
                7,
                4
            ]
        }
    },
    "e8d9763c40ba5b8b01cc2160f3b806b31a5c9e5b": {
        "datetime": "2014-04-01T17:12:25-07:00",
        "summary": "Merge branch 'master' of https://github.com/Parquet/parquet-mr into issue324",
        "message": "Merge branch 'master' of https://github.com/Parquet/parquet-mr into issue324\n",
        "diff": {
            "CHANGES.md": null,
            "parquet-avro/pom.xml": null,
            "parquet-cascading/pom.xml": null,
            "parquet-column/pom.xml": null,
            "parquet-common/pom.xml": null,
            "parquet-encoding/pom.xml": null,
            "parquet-generator/pom.xml": null,
            "parquet-hadoop-bundle/pom.xml": null,
            "parquet-hadoop/pom.xml": null,
            "parquet-hive-bundle/pom.xml": null,
            "parquet-hive/parquet-hive-binding/parquet-hive-0.10-binding/pom.xml": null,
            "parquet-hive/parquet-hive-binding/parquet-hive-0.12-binding/pom.xml": null,
            "parquet-hive/parquet-hive-binding/parquet-hive-binding-bundle/pom.xml": null,
            "parquet-hive/parquet-hive-binding/parquet-hive-binding-factory/pom.xml": null,
            "parquet-hive/parquet-hive-binding/parquet-hive-binding-interface/pom.xml": null,
            "parquet-hive/parquet-hive-binding/pom.xml": null,
            "parquet-hive/parquet-hive-storage-handler/pom.xml": null,
            "parquet-hive/pom.xml": null,
            "parquet-jackson/pom.xml": null,
            "parquet-pig-bundle/pom.xml": null,
            "parquet-pig/pom.xml": null,
            "parquet-protobuf/pom.xml": null,
            "parquet-scrooge/pom.xml": null,
            "parquet-test-hadoop2/pom.xml": null,
            "parquet-thrift/pom.xml": null,
            "parquet-tools/pom.xml": null,
            "pom.xml": null
        }
    },
    "9f43945682e73992bb3958ec8d478873b20b5b0e": {
        "datetime": "2014-04-01T17:16:09-07:00",
        "summary": "Refactored the *Statistics classes to reuse more code. Added Binary compareTo methods",
        "message": "Refactored the *Statistics classes to reuse more code. Added Binary compareTo methods\n",
        "diff": {
            "parquet-column/src/main/java/parquet/column/statistics/BinaryStatistics.java": [
                39,
                14
            ],
            "parquet-column/src/main/java/parquet/column/statistics/BooleanStatistics.java": [
                37,
                14
            ],
            "parquet-column/src/main/java/parquet/column/statistics/DoubleStatistics.java": [
                37,
                14
            ],
            "parquet-column/src/main/java/parquet/column/statistics/FloatStatistics.java": [
                38,
                14
            ],
            "parquet-column/src/main/java/parquet/column/statistics/IntStatistics.java": [
                37,
                14
            ],
            "parquet-column/src/main/java/parquet/column/statistics/LongStatistics.java": [
                37,
                15
            ],
            "parquet-column/src/main/java/parquet/column/statistics/Statistics.java": [
                4,
                25
            ],
            "parquet-column/src/main/java/parquet/io/api/Binary.java": [
                0,
                63
            ]
        }
    },
    "7345536789597b798332bc49d0e2e8b3836ae7c0": {
        "datetime": "2014-04-01T17:30:31-07:00",
        "summary": "Merge branch 'issue324' of github.com:tongjiechen/parquet-mr into issue324",
        "message": "Merge branch 'issue324' of github.com:tongjiechen/parquet-mr into issue324\n\nConflicts:\n\tparquet-hive/parquet-hive-storage-handler/src/main/java/org/apache/hadoop/hive/serde2/objectinspector/primitive/ParquetStringInspector.java\n",
        "diff": {
            "parquet-hive/parquet-hive-storage-handler/src/main/java/org/apache/hadoop/hive/ql/io/parquet/serde/ArrayWritableObjectInspector.java": [
                1,
                8
            ]
        }
    },
    "07c54722a2ebf6edb45a1765c8fc6a5d7bc02795": {
        "datetime": "2014-04-01T17:59:42-07:00",
        "summary": "Merge branch 'issue324' of github.com:tongjiechen/parquet-mr into issue324",
        "message": "Merge branch 'issue324' of github.com:tongjiechen/parquet-mr into issue324\n\nremove additional tab\n",
        "diff": {
            "parquet-hive/parquet-hive-storage-handler/src/main/java/org/apache/hadoop/hive/ql/io/parquet/serde/ArrayWritableObjectInspector.java": [
                1,
                8
            ]
        }
    },
    "82ec5842372645535e1602df8c51ec05d683d5bd": {
        "datetime": "2014-04-01T18:00:41-07:00",
        "summary": "issue #324 remove additional tab",
        "message": "issue #324 remove additional tab\n",
        "diff": {
            "parquet-hive/parquet-hive-storage-handler/src/main/java/org/apache/hadoop/hive/ql/io/parquet/serde/ArrayWritableObjectInspector.java": [
                1,
                1
            ]
        }
    },
    "47ff4ab39a22094968b2868b2f0138c5ccbeec08": {
        "datetime": "2014-04-01T18:03:32-07:00",
        "summary": "Merge branch 'issue324' of github.com:tongjiechen/parquet-mr into issue324",
        "message": "Merge branch 'issue324' of github.com:tongjiechen/parquet-mr into issue324\n",
        "diff": {}
    },
    "156b186bac66598c1eb6f81c2507fe4f116575d8": {
        "datetime": "2014-04-01T18:28:56-07:00",
        "summary": "remove duplicate code",
        "message": "remove duplicate code\n",
        "diff": {
            "parquet-hive/parquet-hive-storage-handler/src/main/java/org/apache/hadoop/hive/ql/io/parquet/serde/ArrayWritableObjectInspector.java": [
                7,
                0
            ]
        }
    },
    "c54cad5e4a54dbbae417bc1561c623b1267f2079": {
        "datetime": "2014-04-01T18:51:00-07:00",
        "summary": "compress kv pairs in ParquetInputSplits",
        "message": "compress kv pairs in ParquetInputSplits\n",
        "diff": {
            "parquet-hadoop/src/main/java/parquet/hadoop/ParquetInputSplit.java": [
                4,
                4
            ]
        }
    },
    "5207422b349f30ec26958be86dc7390b46d63990": {
        "datetime": "2014-04-01T19:53:05-07:00",
        "summary": "Merge pull request #342 from Parquet/compress_kv_pairs_in_split",
        "message": "Merge pull request #342 from Parquet/compress_kv_pairs_in_split\n\ncompress kv pairs in ParquetInputSplits",
        "diff": {
            "parquet-hadoop/src/main/java/parquet/hadoop/ParquetInputSplit.java": [
                4,
                4
            ]
        }
    },
    "253eb6a182b1abe746aa792eae9ddf9389d99b61": {
        "datetime": "2014-04-02T11:04:45-07:00",
        "summary": "select * from parquet hive table containing map columns runs into exception. Issue #341.",
        "message": "select * from parquet hive table containing map columns runs into exception. Issue #341.\n",
        "diff": {
            "parquet-hive/parquet-hive-storage-handler/src/main/java/org/apache/hadoop/hive/ql/io/parquet/serde/AbstractParquetMapInspector.java": [
                13,
                25
            ]
        }
    },
    "e1b480032bd1b37a9cd7c144ea28c64899806dd1": {
        "datetime": "2014-04-02T15:31:52-04:00",
        "summary": "set cascading version to 2.5.3",
        "message": "set cascading version to 2.5.3\n",
        "diff": {
            "pom.xml": null
        }
    },
    "6aeaa526abe22e4c49fe39bc1c3a88448230855e": {
        "datetime": "2014-04-02T18:06:01-07:00",
        "summary": "Merge pull request #345 from epishkin/cascading_2.5.3",
        "message": "Merge pull request #345 from epishkin/cascading_2.5.3\n\nset cascading version to 2.5.3",
        "diff": {
            "pom.xml": null
        }
    },
    "f9a867689a18e33cb95fbd21b10fcd5b648739be": {
        "datetime": "2014-04-02T22:10:46-07:00",
        "summary": "stop using strings and b64 for compressed input splits",
        "message": "stop using strings and b64 for compressed input splits\n",
        "diff": {
            "parquet-hadoop/pom.xml": null,
            "parquet-hadoop/src/main/java/parquet/hadoop/ParquetInputSplit.java": [
                18,
                29
            ],
            "parquet-hadoop/src/test/java/parquet/hadoop/TestParquetInputSplit.java": [
                2,
                2
            ]
        }
    },
    "ce2301e2c663a2944d9ca1ea6349d55074bf70f9": {
        "datetime": "2014-04-03T09:20:16-07:00",
        "summary": "Merge pull request #346 from Parquet/compress_kv_pairs_in_split",
        "message": "Merge pull request #346 from Parquet/compress_kv_pairs_in_split\n\nstop using strings and b64 for compressed input splits",
        "diff": {
            "parquet-hadoop/pom.xml": null,
            "parquet-hadoop/src/main/java/parquet/hadoop/ParquetInputSplit.java": [
                18,
                29
            ],
            "parquet-hadoop/src/test/java/parquet/hadoop/TestParquetInputSplit.java": [
                2,
                2
            ]
        }
    },
    "5b8af1f8097e7729c41cd86562b6706cefe2c56d": {
        "datetime": "2014-04-03T11:14:47-07:00",
        "summary": "set reading length in ThriftBytesWriteSupport to avoid potential OOM caused by corrupted data",
        "message": "set reading length in ThriftBytesWriteSupport to avoid potential OOM caused by corrupted data\n",
        "diff": {
            "parquet-thrift/src/main/java/parquet/hadoop/thrift/ThriftBytesWriteSupport.java": [
                2,
                12
            ]
        }
    },
    "f5edd0a74598f951310e9014ae552f89c60a5853": {
        "datetime": "2014-04-03T13:39:34-07:00",
        "summary": "Merge pull request #347 from Parquet/check_read_length_avoid_oom",
        "message": "Merge pull request #347 from Parquet/check_read_length_avoid_oom\n\nset reading length in ThriftBytesWriteSupport to avoid potential OOM caused by trying to allocate big byte arrays caused by corrupted thrift data.",
        "diff": {
            "parquet-thrift/src/main/java/parquet/hadoop/thrift/ThriftBytesWriteSupport.java": [
                2,
                12
            ]
        }
    },
    "3f5de7612fdcfa5a8d6e0c81477cf297d6006316": {
        "datetime": "2014-04-04T14:42:14-07:00",
        "summary": "Merge pull request #344 from szehon/master",
        "message": "Merge pull request #344 from szehon/master\n\nselect * from parquet hive table containing map columns runs into exception. Issue #341.",
        "diff": {
            "parquet-hive/parquet-hive-storage-handler/src/main/java/org/apache/hadoop/hive/ql/io/parquet/serde/AbstractParquetMapInspector.java": [
                13,
                25
            ]
        }
    },
    "30810ff61f5bd033b0bf90bbccd574c331b62d2f": {
        "datetime": "2014-04-04T16:26:37-07:00",
        "summary": "fix header bug",
        "message": "fix header bug\n",
        "diff": {
            "parquet-hadoop/src/main/java/parquet/hadoop/ParquetFileReader.java": [
                2,
                19
            ]
        }
    },
    "05327c1cacd598106b8d8228927a5a8884faaec9": {
        "datetime": "2014-04-04T16:45:02-07:00",
        "summary": "Added hashCode() method for Statistics class",
        "message": "Added hashCode() method for Statistics class\n",
        "diff": {
            "parquet-column/src/main/java/parquet/column/statistics/Statistics.java": [
                0,
                8
            ]
        }
    },
    "16d38e2d32f1d09bd10a8455bdcf11905f8cdd72": {
        "datetime": "2014-04-07T12:29:25-07:00",
        "summary": "Fix bug #350, fixed length argument out of order.",
        "message": "Fix bug #350, fixed length argument out of order.\n",
        "diff": {
            "parquet-column/src/main/java/parquet/column/ParquetProperties.java": [
                1,
                1
            ]
        }
    },
    "27f71a18579ebac6db2b0e9ac758d64288b6dbff": {
        "datetime": "2014-04-07T16:39:05-07:00",
        "summary": "[maven-release-plugin] prepare release parquet-1.4.1",
        "message": "[maven-release-plugin] prepare release parquet-1.4.1\n",
        "diff": {
            "parquet-avro/pom.xml": null,
            "parquet-cascading/pom.xml": null,
            "parquet-column/pom.xml": null,
            "parquet-common/pom.xml": null,
            "parquet-encoding/pom.xml": null,
            "parquet-generator/pom.xml": null,
            "parquet-hadoop-bundle/pom.xml": null,
            "parquet-hadoop/pom.xml": null,
            "parquet-hive-bundle/pom.xml": null,
            "parquet-hive/parquet-hive-binding/parquet-hive-0.10-binding/pom.xml": null,
            "parquet-hive/parquet-hive-binding/parquet-hive-0.12-binding/pom.xml": null,
            "parquet-hive/parquet-hive-binding/parquet-hive-binding-bundle/pom.xml": null,
            "parquet-hive/parquet-hive-binding/parquet-hive-binding-factory/pom.xml": null,
            "parquet-hive/parquet-hive-binding/parquet-hive-binding-interface/pom.xml": null,
            "parquet-hive/parquet-hive-binding/pom.xml": null,
            "parquet-hive/parquet-hive-storage-handler/pom.xml": null,
            "parquet-hive/pom.xml": null,
            "parquet-jackson/pom.xml": null,
            "parquet-pig-bundle/pom.xml": null,
            "parquet-pig/pom.xml": null,
            "parquet-protobuf/pom.xml": null,
            "parquet-scrooge/pom.xml": null,
            "parquet-test-hadoop2/pom.xml": null,
            "parquet-thrift/pom.xml": null,
            "parquet-tools/pom.xml": null,
            "pom.xml": null
        }
    },
    "bad0012aa4e0a6d695793644045e655bbd5b4034": {
        "datetime": "2014-04-07T16:39:09-07:00",
        "summary": "[maven-release-plugin] prepare for next development iteration",
        "message": "[maven-release-plugin] prepare for next development iteration\n",
        "diff": {
            "parquet-avro/pom.xml": null,
            "parquet-cascading/pom.xml": null,
            "parquet-column/pom.xml": null,
            "parquet-common/pom.xml": null,
            "parquet-encoding/pom.xml": null,
            "parquet-generator/pom.xml": null,
            "parquet-hadoop-bundle/pom.xml": null,
            "parquet-hadoop/pom.xml": null,
            "parquet-hive-bundle/pom.xml": null,
            "parquet-hive/parquet-hive-binding/parquet-hive-0.10-binding/pom.xml": null,
            "parquet-hive/parquet-hive-binding/parquet-hive-0.12-binding/pom.xml": null,
            "parquet-hive/parquet-hive-binding/parquet-hive-binding-bundle/pom.xml": null,
            "parquet-hive/parquet-hive-binding/parquet-hive-binding-factory/pom.xml": null,
            "parquet-hive/parquet-hive-binding/parquet-hive-binding-interface/pom.xml": null,
            "parquet-hive/parquet-hive-binding/pom.xml": null,
            "parquet-hive/parquet-hive-storage-handler/pom.xml": null,
            "parquet-hive/pom.xml": null,
            "parquet-jackson/pom.xml": null,
            "parquet-pig-bundle/pom.xml": null,
            "parquet-pig/pom.xml": null,
            "parquet-protobuf/pom.xml": null,
            "parquet-scrooge/pom.xml": null,
            "parquet-test-hadoop2/pom.xml": null,
            "parquet-thrift/pom.xml": null,
            "parquet-tools/pom.xml": null,
            "pom.xml": null
        }
    },
    "93359c0f2cac705cc7b2fbf3c057d74142025b37": {
        "datetime": "2014-04-08T12:41:22-07:00",
        "summary": "Added length check for comparing two byte arrays",
        "message": "Added length check for comparing two byte arrays\n",
        "diff": {
            "parquet-column/src/main/java/parquet/io/api/Binary.java": [
                1,
                1
            ]
        }
    },
    "f98de7588149bba0d731f38232b4a8fdde14b94a": {
        "datetime": "2014-04-08T14:31:06-07:00",
        "summary": "adding comments",
        "message": "adding comments\n",
        "diff": {
            "parquet-hadoop/src/main/java/parquet/hadoop/ParquetFileReader.java": [
                2,
                8
            ]
        }
    },
    "41df19051825d724626e91425c8e690c04a39998": {
        "datetime": "2014-04-08T15:10:17-07:00",
        "summary": "Merge pull request #349 from Parquet/null_header",
        "message": "Merge pull request #349 from Parquet/null_header\n\nfix header bug #334",
        "diff": {
            "parquet-hadoop/src/main/java/parquet/hadoop/ParquetFileReader.java": [
                2,
                25
            ]
        }
    },
    "b8149e92dd283d98132319d506248c3204718302": {
        "datetime": "2014-04-08T18:36:26-07:00",
        "summary": "ParquetThriftStorer",
        "message": "ParquetThriftStorer\n",
        "diff": {
            "parquet-thrift/src/main/java/parquet/thrift/pig/ParquetThriftStorer.java": [
                0,
                77
            ],
            "parquet-thrift/src/main/java/parquet/thrift/pig/TupleToThriftWriteSupport.java": [
                0,
                75
            ],
            "parquet-thrift/src/test/java/parquet/thrift/pig/TestParquetThriftStorer.java": [
                0,
                65
            ]
        }
    },
    "a13ae411677847137c93aec573abe6b0601079ff": {
        "datetime": "2014-04-08T18:57:39-07:00",
        "summary": "cleanup",
        "message": "cleanup\n",
        "diff": {
            "parquet-thrift/src/main/java/parquet/thrift/pig/ParquetThriftStorer.java": [
                2,
                0
            ],
            "parquet-thrift/src/main/java/parquet/thrift/pig/TupleToThriftWriteSupport.java": [
                9,
                8
            ]
        }
    },
    "0943978a7e37f960db6ee280096cac8a2e7ee38b": {
        "datetime": "2014-04-09T13:54:53-07:00",
        "summary": "headers",
        "message": "headers\n",
        "diff": {
            "parquet-thrift/src/main/java/parquet/thrift/pig/ParquetThriftStorer.java": [
                0,
                15
            ],
            "parquet-thrift/src/test/java/parquet/thrift/pig/TestParquetThriftStorer.java": [
                0,
                15
            ]
        }
    },
    "67c1e11364455dfa8b48dcc013398657d080376e": {
        "datetime": "2014-04-09T18:35:55-07:00",
        "summary": "use own test fixtures",
        "message": "use own test fixtures\n",
        "diff": {
            "parquet-thrift/src/test/java/parquet/thrift/pig/TestParquetThriftStorer.java": [
                6,
                5
            ]
        }
    },
    "6417baede9f9e9b4cb711d7120ee31499a19b5ea": {
        "datetime": "2014-04-10T17:35:23-07:00",
        "summary": "1. upgrade scrooge dep to 3.12.1  2. fix bug when an enum field is optional, scroogeSchemaConverter would fail",
        "message": "1. upgrade scrooge dep to 3.12.1  2. fix bug when an enum field is optional, scroogeSchemaConverter would fail\n",
        "diff": {
            "parquet-scrooge/pom.xml": null,
            "parquet-scrooge/src/main/java/parquet/scrooge/ScroogeStructConverter.java": [
                2,
                8
            ],
            "parquet-scrooge/src/test/java/parquet/scrooge/ScroogeStructConverterTest.java": [
                1,
                0
            ],
            "parquet-scrooge/src/test/thrift/test.thrift": null
        }
    },
    "ddca03c2754bd67b3aa9f37a5d404814ed79b4bd": {
        "datetime": "2014-04-14T16:01:18-07:00",
        "summary": "cleanup log messages in tests",
        "message": "cleanup log messages in tests\n",
        "diff": {
            "parquet-encoding/src/test/java/parquet/column/values/bitpacking/TestBitPacking.java": [
                3,
                5
            ],
            "parquet-encoding/src/test/java/parquet/column/values/bitpacking/TestByteBitPacking.java": [
                18,
                20
            ],
            "parquet-encoding/src/test/java/parquet/column/values/bitpacking/TestLemireBitPacking.java": [
                5,
                7
            ]
        }
    },
    "de0bfe3a7b9cddf4e949e6ebfd97d9c16bd143fc": {
        "datetime": "2014-04-14T16:34:41-07:00",
        "summary": "cleanup log messages in tests",
        "message": "cleanup log messages in tests\n",
        "diff": {
            "parquet-encoding/src/test/java/parquet/column/values/bitpacking/TestLemireBitPacking.java": [
                7,
                7
            ]
        }
    },
    "9ef1be6697ed432e5de5d5d7aa2f5810e134350a": {
        "datetime": "2014-04-14T18:29:27-07:00",
        "summary": "cleanup log messages in tests",
        "message": "cleanup log messages in tests\n",
        "diff": {
            "parquet-column/src/test/java/parquet/column/values/bitpacking/TestBitPackingColumn.java": [
                4,
                6
            ]
        }
    },
    "f5c3151d057708a7377430b6c51621071656d10e": {
        "datetime": "2014-04-15T12:17:27+01:00",
        "summary": "Expose values in SimpleRecord",
        "message": "Expose values in SimpleRecord\n\nThis allows for quick'n dirty integration with clojure/pigpen in local mode, without the hassle of reimplementing file reading.",
        "diff": {
            "parquet-tools/src/main/java/parquet/tools/read/SimpleRecord.java": [
                0,
                4
            ]
        }
    },
    "f8877f1648b607a288af159c810b32049a49e086": {
        "datetime": "2014-04-15T13:56:18-07:00",
        "summary": "cleanup log messages for default codec",
        "message": "cleanup log messages for default codec\n",
        "diff": {
            "parquet-hadoop/src/main/java/parquet/hadoop/metadata/CompressionCodecName.java": [
                0,
                3
            ]
        }
    },
    "110fe216e493ebe52eea32275a7fc0896552ab3c": {
        "datetime": "2014-04-15T14:40:55-07:00",
        "summary": "fix test runtime dep missing from pig",
        "message": "fix test runtime dep missing from pig\n",
        "diff": {
            "parquet-hadoop/src/test/java/parquet/hadoop/codec/CodecConfigTest.java": [
                2,
                2
            ],
            "parquet-thrift/pom.xml": null
        }
    },
    "d093f497007e140c9ee0350b88d5b93b00ab9382": {
        "datetime": "2014-04-15T15:41:40-07:00",
        "summary": "reverse codec changes",
        "message": "reverse codec changes\n",
        "diff": {
            "parquet-hadoop/src/main/java/parquet/hadoop/metadata/CompressionCodecName.java": [
                3,
                0
            ],
            "parquet-hadoop/src/test/java/parquet/hadoop/codec/CodecConfigTest.java": [
                2,
                2
            ]
        }
    },
    "3fad81609562f2819639f4fdb02d6d6481a7165b": {
        "datetime": "2014-04-15T19:00:26-04:00",
        "summary": "Fix output bug during parquet-dump command",
        "message": "Fix output bug during parquet-dump command\n\nIt was outputting the current definition level as both the repetition &\ndefinition level for the current value.\n",
        "diff": {
            "parquet-tools/src/main/java/parquet/tools/command/DumpCommand.java": [
                1,
                1
            ]
        }
    },
    "79a4ac84c969d1dbe14644d6d01f705883a36b6d": {
        "datetime": "2014-04-16T09:37:01-07:00",
        "summary": "Merge pull request #352 from Parquet/ParquetThriftStorer",
        "message": "Merge pull request #352 from Parquet/ParquetThriftStorer\n\nParquet thrift storer",
        "diff": {
            "parquet-column/src/test/java/parquet/column/values/bitpacking/TestBitPackingColumn.java": [
                4,
                6
            ],
            "parquet-encoding/src/test/java/parquet/column/values/bitpacking/TestBitPacking.java": [
                3,
                5
            ],
            "parquet-encoding/src/test/java/parquet/column/values/bitpacking/TestByteBitPacking.java": [
                18,
                20
            ],
            "parquet-encoding/src/test/java/parquet/column/values/bitpacking/TestLemireBitPacking.java": [
                12,
                14
            ],
            "parquet-thrift/pom.xml": null,
            "parquet-thrift/src/main/java/parquet/thrift/pig/ParquetThriftStorer.java": [
                0,
                90
            ],
            "parquet-thrift/src/main/java/parquet/thrift/pig/TupleToThriftWriteSupport.java": [
                0,
                74
            ],
            "parquet-thrift/src/test/java/parquet/thrift/pig/TestParquetThriftStorer.java": [
                0,
                79
            ]
        }
    },
    "5d06526d49451135bd5c3befc06a64624431de02": {
        "datetime": "2014-04-16T12:53:13-07:00",
        "summary": "generate splits by min max size, and align to HDFS block when possible",
        "message": "generate splits by min max size, and align to HDFS block when possible\n",
        "diff": {
            "parquet-hadoop/src/main/java/parquet/hadoop/ParquetInputFormat.java": [
                72,
                150
            ],
            "parquet-hadoop/src/test/java/parquet/hadoop/TestInputFormat.java": [
                33,
                127
            ]
        }
    },
    "796b7dd3d6fa9ec70e36d9502c0f79bbd94550fb": {
        "datetime": "2014-04-17T10:40:05-07:00",
        "summary": "do not call schema converter to generate projected schema when the projectionFilterStrubg or projectionSchemaStr is specified",
        "message": "do not call schema converter to generate projected schema when the projectionFilterStrubg or projectionSchemaStr is specified\n",
        "diff": {
            "parquet-thrift/src/main/java/parquet/hadoop/thrift/ThriftReadSupport.java": [
                4,
                5
            ]
        }
    },
    "3321b67329a895171d47e321279901d0dc346aad": {
        "datetime": "2014-04-17T11:12:21-07:00",
        "summary": "fix enum to be upper case",
        "message": "fix enum to be upper case\n",
        "diff": {
            "parquet-scrooge/src/main/java/parquet/scrooge/ScroogeStructConverter.java": [
                1,
                1
            ]
        }
    },
    "f4a0900ba9fecfa81b2fb15eb1b562b0beff6371": {
        "datetime": "2014-04-17T11:21:46-07:00",
        "summary": "remove unused code",
        "message": "remove unused code\n",
        "diff": {
            "parquet-thrift/src/main/java/parquet/hadoop/thrift/ThriftReadSupport.java": [
                1,
                0
            ]
        }
    },
    "b55eea04135d41a67b8c5d321f993ccf35a17c99": {
        "datetime": "2014-04-17T15:28:58-07:00",
        "summary": "make ParquetFileWriter throw IOException in invalid state case",
        "message": "make ParquetFileWriter throw IOException in invalid state case\n",
        "diff": {
            "parquet-hadoop/src/main/java/parquet/hadoop/ParquetFileWriter.java": [
                7,
                11
            ]
        }
    },
    "eeae127a20759116200070ac154748ad3709d2ab": {
        "datetime": "2014-04-17T16:02:06-07:00",
        "summary": "Merge pull request #367 from Parquet/ioexception",
        "message": "Merge pull request #367 from Parquet/ioexception\n\nmake ParquetFileWriter throw IOException in invalid state case",
        "diff": {
            "parquet-hadoop/src/main/java/parquet/hadoop/ParquetFileWriter.java": [
                7,
                11
            ]
        }
    },
    "6b7bc5411deb24a50025577b4384f8626cd273e5": {
        "datetime": "2014-04-17T16:22:11-07:00",
        "summary": "Merge pull request #366 from Parquet/avoid_convert_thrift_scrooge_class_when_projection_is_not_specified",
        "message": "Merge pull request #366 from Parquet/avoid_convert_thrift_scrooge_class_when_projection_is_not_specified\n\ndo not call schema converter to generate projected schema when projection is not set",
        "diff": {
            "parquet-thrift/src/main/java/parquet/hadoop/thrift/ThriftReadSupport.java": [
                5,
                5
            ]
        }
    },
    "0a96b2c66c1367a88d750357c6d6527b2efbbb08": {
        "datetime": "2014-04-17T17:25:37-07:00",
        "summary": "local variable of hdfsBlock",
        "message": "local variable of hdfsBlock\n",
        "diff": {
            "parquet-hadoop/src/main/java/parquet/hadoop/ParquetInputFormat.java": [
                1,
                2
            ]
        }
    },
    "dd8c32a41670e831a09558bf3f2697f54fb5fcfa": {
        "datetime": "2014-04-17T17:26:10-07:00",
        "summary": "fix missing space",
        "message": "fix missing space\n",
        "diff": {
            "parquet-hadoop/src/main/java/parquet/hadoop/ParquetInputFormat.java": [
                1,
                1
            ]
        }
    },
    "23958b8fde926368176dd8ade908938e17f713c0": {
        "datetime": "2014-04-17T17:38:07-07:00",
        "summary": "check maxSplit size must be greater or equal to minSplitSize",
        "message": "check maxSplit size must be greater or equal to minSplitSize\n",
        "diff": {
            "parquet-hadoop/src/main/java/parquet/hadoop/ParquetInputFormat.java": [
                1,
                7
            ]
        }
    },
    "83493c59396479659d3d260d53498faf2d7518ac": {
        "datetime": "2014-04-17T18:00:07-07:00",
        "summary": "maxSplitSize should always be positive",
        "message": "maxSplitSize should always be positive\n",
        "diff": {
            "parquet-hadoop/src/main/java/parquet/hadoop/ParquetInputFormat.java": [
                2,
                2
            ],
            "parquet-hadoop/src/test/java/parquet/hadoop/TestInputFormat.java": [
                0,
                24
            ]
        }
    },
    "2056bfab8080ff013905268fbccbde835b9ae63e": {
        "datetime": "2014-04-17T18:06:27-07:00",
        "summary": "separate out getParquetInputSplit method in the SplitInfo class, reduce LOC in the generateSplit method",
        "message": "separate out getParquetInputSplit method in the SplitInfo class, reduce LOC in the generateSplit method\n",
        "diff": {
            "parquet-hadoop/src/main/java/parquet/hadoop/ParquetInputFormat.java": [
                23,
                29
            ]
        }
    },
    "fca4cc9fcb3dbfd622e11861e0b7a8f2a3ac26d1": {
        "datetime": "2014-04-17T18:08:07-07:00",
        "summary": "move parseMessageType out of the loop",
        "message": "move parseMessageType out of the loop\n",
        "diff": {
            "parquet-hadoop/src/main/java/parquet/hadoop/ParquetInputFormat.java": [
                1,
                2
            ]
        }
    },
    "7845cc76fb72aef6908ae16a89df92e60b171f66": {
        "datetime": "2014-04-17T18:15:23-07:00",
        "summary": "1. remove unused readSupportClass parameter from generateSplit method; 2. double check split min max to be postive in the getSplits method; 3. explicit import java.util.xx in test",
        "message": "1. remove unused readSupportClass parameter from generateSplit method; 2. double check split min max to be postive in the getSplits method; 3. explicit import java.util.xx in test\n",
        "diff": {
            "parquet-hadoop/src/main/java/parquet/hadoop/ParquetInputFormat.java": [
                3,
                3
            ],
            "parquet-hadoop/src/test/java/parquet/hadoop/TestInputFormat.java": [
                3,
                6
            ]
        }
    },
    "9814332cc3fed776eab8ebd03bbbc241ec562c15": {
        "datetime": "2014-04-17T18:58:50-07:00",
        "summary": "add more tests so the hdfsSize is not multiple of rowGroup size",
        "message": "add more tests so the hdfsSize is not multiple of rowGroup size\n",
        "diff": {
            "parquet-hadoop/src/test/java/parquet/hadoop/TestInputFormat.java": [
                12,
                95
            ]
        }
    },
    "ac816d91e2c30f7bceacb8601ae13a0ab0107277": {
        "datetime": "2014-04-18T09:49:20-07:00",
        "summary": "min split size default to 0",
        "message": "min split size default to 0\n",
        "diff": {
            "parquet-hadoop/src/main/java/parquet/hadoop/ParquetInputFormat.java": [
                1,
                1
            ]
        }
    },
    "83e34bec54298265c50e366fae364c02a9e2dfe3": {
        "datetime": "2014-04-18T09:53:48-07:00",
        "summary": "add non-negative check in generateSplits method",
        "message": "add non-negative check in generateSplits method\n",
        "diff": {
            "parquet-hadoop/src/main/java/parquet/hadoop/ParquetInputFormat.java": [
                2,
                2
            ]
        }
    },
    "a85b7fddbbdd381378a7075741be74c19c681ed0": {
        "datetime": "2014-04-18T10:40:09-07:00",
        "summary": "better message",
        "message": "better message\n",
        "diff": {
            "parquet-hadoop/src/test/java/parquet/hadoop/TestInputFormat.java": [
                1,
                1
            ]
        }
    },
    "4c870b0f2ff514d31f5933f29973ddbc56ccaa58": {
        "datetime": "2014-04-18T12:06:45-07:00",
        "summary": "Merge pull request #362 from nealsid/master",
        "message": "Merge pull request #362 from nealsid/master\n\nFix output bug during parquet-dump command",
        "diff": {
            "parquet-tools/src/main/java/parquet/tools/command/DumpCommand.java": [
                1,
                1
            ]
        }
    },
    "8e348e60b822d86a7e0862902c315beb56388725": {
        "datetime": "2014-04-18T13:51:34-07:00",
        "summary": "create a getStartingPos in ColumnChunkMetaData",
        "message": "create a getStartingPos in ColumnChunkMetaData\n",
        "diff": {
            "parquet-hadoop/src/main/java/parquet/hadoop/ParquetFileReader.java": [
                13,
                2
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/ParquetInputFormat.java": [
                8,
                5
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/metadata/ColumnChunkMetaData.java": [
                5,
                18
            ],
            "parquet-hadoop/src/test/java/parquet/hadoop/TestInputFormat.java": [
                2,
                2
            ]
        }
    },
    "00d631c15d147e7e7a07d65fe50999c878a921a8": {
        "datetime": "2014-04-18T14:08:37-07:00",
        "summary": "make SplitInfo contain the hdfsBlock",
        "message": "make SplitInfo contain the hdfsBlock\n",
        "diff": {
            "parquet-hadoop/src/main/java/parquet/hadoop/ParquetInputFormat.java": [
                21,
                16
            ]
        }
    },
    "9705f4905a5077ec7208a0fa3e230668157fe471": {
        "datetime": "2014-04-18T14:16:47-07:00",
        "summary": "1. check row groups are sorted; 2. add getStartingPos for BlockMetadata, which returns the startingPos for the first Column",
        "message": "1. check row groups are sorted; 2. add getStartingPos for BlockMetadata, which returns the startingPos for the first Column\n",
        "diff": {
            "parquet-hadoop/src/main/java/parquet/hadoop/ParquetInputFormat.java": [
                1,
                11
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/metadata/BlockMetaData.java": [
                0,
                7
            ]
        }
    },
    "70707e4bd2f5b41a08d4b5a306d5876473532e01": {
        "datetime": "2014-04-18T14:20:48-07:00",
        "summary": "use getStartingPos for BlockMetadata, which returns the startingPos for the first Column",
        "message": "use getStartingPos for BlockMetadata, which returns the startingPos for the first Column\n",
        "diff": {
            "parquet-hadoop/src/main/java/parquet/hadoop/ParquetInputFormat.java": [
                7,
                2
            ]
        }
    },
    "05c3e2706a356ea878177faf93ed108a348bc7ae": {
        "datetime": "2014-04-21T12:57:05+01:00",
        "summary": "ensure SimpleRecord#getValues() is unmodifiable",
        "message": "ensure SimpleRecord#getValues() is unmodifiable\n\nThis avoids modification from the outside",
        "diff": {
            "parquet-tools/src/main/java/parquet/tools/read/SimpleRecord.java": [
                1,
                2
            ]
        }
    },
    "9f672d69432e6339fc69c6848b384bd6bb744051": {
        "datetime": "2014-04-21T13:10:10-07:00",
        "summary": "use mid point of a row group to decide to create a split or not",
        "message": "use mid point of a row group to decide to create a split or not\n",
        "diff": {
            "parquet-hadoop/src/main/java/parquet/hadoop/ParquetInputFormat.java": [
                15,
                34
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/metadata/BlockMetaData.java": [
                0,
                10
            ],
            "parquet-hadoop/src/test/java/parquet/hadoop/TestInputFormat.java": [
                29,
                39
            ]
        }
    },
    "bba221d789909dcce126b9875c9859b4359ce911": {
        "datetime": "2014-04-21T13:26:09-07:00",
        "summary": "format",
        "message": "format\n",
        "diff": {
            "parquet-hadoop/src/main/java/parquet/hadoop/ParquetInputFormat.java": [
                4,
                0
            ]
        }
    },
    "72dbbdc4d14e9fb7479cdb8921394fea30b27745": {
        "datetime": "2014-04-21T13:41:17-07:00",
        "summary": "Merge pull request #353 from Parquet/bugfix_failed_convert_to_scrooge_struct_when_enum_is_optional",
        "message": "Merge pull request #353 from Parquet/bugfix_failed_convert_to_scrooge_struct_when_enum_is_optional\n\nFix bug: optional enum field causing ScroogeSchemaConverter to fail",
        "diff": {
            "parquet-scrooge/pom.xml": null,
            "parquet-scrooge/src/main/java/parquet/scrooge/ScroogeStructConverter.java": [
                2,
                8
            ],
            "parquet-scrooge/src/test/java/parquet/scrooge/ScroogeStructConverterTest.java": [
                1,
                0
            ],
            "parquet-scrooge/src/test/thrift/test.thrift": null
        }
    },
    "ac2b15ebb0d4d5140587e11a0e7a71f898293668": {
        "datetime": "2014-04-21T13:52:18-07:00",
        "summary": "change name to checkBelongingToANewHDFSBlock",
        "message": "change name to checkBelongingToANewHDFSBlock\n",
        "diff": {
            "parquet-hadoop/src/main/java/parquet/hadoop/ParquetInputFormat.java": [
                5,
                5
            ]
        }
    },
    "93d11c5316e494cb42d646e58d9f7ac98e942266": {
        "datetime": "2014-04-21T14:48:21-07:00",
        "summary": "Merge pull request #365 from Parquet/generate_splits_by_min_max_size",
        "message": "Merge pull request #365 from Parquet/generate_splits_by_min_max_size\n\ngenerate splits by min max size, and align to HDFS block when possible",
        "diff": {
            "parquet-hadoop/src/main/java/parquet/hadoop/ParquetFileReader.java": [
                13,
                2
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/ParquetInputFormat.java": [
                80,
                184
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/metadata/BlockMetaData.java": [
                0,
                17
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/metadata/ColumnChunkMetaData.java": [
                5,
                18
            ],
            "parquet-hadoop/src/test/java/parquet/hadoop/TestInputFormat.java": [
                36,
                250
            ]
        }
    },
    "8aeea149f7c78090cf3a63ff9f21188553ee8b94": {
        "datetime": "2014-04-21T15:39:28-07:00",
        "summary": "Merge pull request #335 from tongjiechen/master",
        "message": "Merge pull request #335 from tongjiechen/master\n\nissue #290, hive map conversion to parquet schema",
        "diff": {
            "parquet-hive/parquet-hive-storage-handler/src/main/java/org/apache/hadoop/hive/ql/io/parquet/convert/HiveSchemaConverter.java": [
                2,
                2
            ],
            "parquet-hive/parquet-hive-storage-handler/src/test/java/org/apache/hadoop/hive/ql/io/parquet/TestHiveSchemaConverter.java": [
                0,
                24
            ]
        }
    },
    "c0b96220312ab371f05ad721c4dcf6bde3fefa1f": {
        "datetime": "2014-04-21T15:49:14-07:00",
        "summary": "Merge pull request #359 from mping/patch-1",
        "message": "Merge pull request #359 from mping/patch-1\n\nExpose values in SimpleRecord",
        "diff": {
            "parquet-tools/src/main/java/parquet/tools/read/SimpleRecord.java": [
                0,
                5
            ]
        }
    },
    "c9445a3d01743704ebbd2e548a84db477478a830": {
        "datetime": "2014-04-23T09:25:35-07:00",
        "summary": "[maven-release-plugin] prepare release parquet-1.4.2",
        "message": "[maven-release-plugin] prepare release parquet-1.4.2\n",
        "diff": {
            "parquet-avro/pom.xml": null,
            "parquet-cascading/pom.xml": null,
            "parquet-column/pom.xml": null,
            "parquet-common/pom.xml": null,
            "parquet-encoding/pom.xml": null,
            "parquet-generator/pom.xml": null,
            "parquet-hadoop-bundle/pom.xml": null,
            "parquet-hadoop/pom.xml": null,
            "parquet-hive-bundle/pom.xml": null,
            "parquet-hive/parquet-hive-binding/parquet-hive-0.10-binding/pom.xml": null,
            "parquet-hive/parquet-hive-binding/parquet-hive-0.12-binding/pom.xml": null,
            "parquet-hive/parquet-hive-binding/parquet-hive-binding-bundle/pom.xml": null,
            "parquet-hive/parquet-hive-binding/parquet-hive-binding-factory/pom.xml": null,
            "parquet-hive/parquet-hive-binding/parquet-hive-binding-interface/pom.xml": null,
            "parquet-hive/parquet-hive-binding/pom.xml": null,
            "parquet-hive/parquet-hive-storage-handler/pom.xml": null,
            "parquet-hive/pom.xml": null,
            "parquet-jackson/pom.xml": null,
            "parquet-pig-bundle/pom.xml": null,
            "parquet-pig/pom.xml": null,
            "parquet-protobuf/pom.xml": null,
            "parquet-scrooge/pom.xml": null,
            "parquet-test-hadoop2/pom.xml": null,
            "parquet-thrift/pom.xml": null,
            "parquet-tools/pom.xml": null,
            "pom.xml": null
        }
    },
    "10a0af6be18173b3a862db279da05d9ffdc8f67e": {
        "datetime": "2014-04-23T09:25:39-07:00",
        "summary": "[maven-release-plugin] prepare for next development iteration",
        "message": "[maven-release-plugin] prepare for next development iteration\n",
        "diff": {
            "parquet-avro/pom.xml": null,
            "parquet-cascading/pom.xml": null,
            "parquet-column/pom.xml": null,
            "parquet-common/pom.xml": null,
            "parquet-encoding/pom.xml": null,
            "parquet-generator/pom.xml": null,
            "parquet-hadoop-bundle/pom.xml": null,
            "parquet-hadoop/pom.xml": null,
            "parquet-hive-bundle/pom.xml": null,
            "parquet-hive/parquet-hive-binding/parquet-hive-0.10-binding/pom.xml": null,
            "parquet-hive/parquet-hive-binding/parquet-hive-0.12-binding/pom.xml": null,
            "parquet-hive/parquet-hive-binding/parquet-hive-binding-bundle/pom.xml": null,
            "parquet-hive/parquet-hive-binding/parquet-hive-binding-factory/pom.xml": null,
            "parquet-hive/parquet-hive-binding/parquet-hive-binding-interface/pom.xml": null,
            "parquet-hive/parquet-hive-binding/pom.xml": null,
            "parquet-hive/parquet-hive-storage-handler/pom.xml": null,
            "parquet-hive/pom.xml": null,
            "parquet-jackson/pom.xml": null,
            "parquet-pig-bundle/pom.xml": null,
            "parquet-pig/pom.xml": null,
            "parquet-protobuf/pom.xml": null,
            "parquet-scrooge/pom.xml": null,
            "parquet-test-hadoop2/pom.xml": null,
            "parquet-thrift/pom.xml": null,
            "parquet-tools/pom.xml": null,
            "pom.xml": null
        }
    },
    "76d05fa79ad7c866800abbff07bc4aa0425c44dc": {
        "datetime": "2014-04-23T09:50:28-07:00",
        "summary": "Update CHANGES.md",
        "message": "Update CHANGES.md",
        "diff": {
            "CHANGES.md": null
        }
    },
    "7640224b3fee25e3c347f1ffdabdf5392212256b": {
        "datetime": "2014-04-23T16:02:12-07:00",
        "summary": "Adding back the Page() and writePage() methods for backward-compatibility",
        "message": "Adding back the Page() and writePage() methods for backward-compatibility\nThe methods now pass an empty Stats object downstream\n",
        "diff": {
            "parquet-column/src/main/java/parquet/column/page/Page.java": [
                0,
                22
            ],
            "parquet-column/src/main/java/parquet/column/page/PageWriter.java": [
                0,
                12
            ],
            "parquet-column/src/test/java/parquet/column/page/mem/MemPageWriter.java": [
                1,
                14
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/ColumnChunkPageWriteStore.java": [
                0,
                31
            ]
        }
    },
    "3e90b41aa06a04af2873fc6fcf68530e4a4976e9": {
        "datetime": "2014-04-23T16:39:31-07:00",
        "summary": "Merge branch 'master' of https://github.com/Parquet/parquet-mr into stats",
        "message": "Merge branch 'master' of https://github.com/Parquet/parquet-mr into stats\n\nConflicts:\n\tparquet-hadoop/src/main/java/parquet/hadoop/metadata/ColumnChunkMetaData.java\n\tparquet-hadoop/src/test/java/parquet/hadoop/TestInputFormat.java\n",
        "diff": {
            "CHANGES.md": null,
            "parquet-avro/pom.xml": null,
            "parquet-cascading/pom.xml": null,
            "parquet-column/pom.xml": null,
            "parquet-column/src/test/java/parquet/column/values/bitpacking/TestBitPackingColumn.java": [
                4,
                6
            ],
            "parquet-common/pom.xml": null,
            "parquet-encoding/pom.xml": null,
            "parquet-encoding/src/test/java/parquet/column/values/bitpacking/TestBitPacking.java": [
                3,
                5
            ],
            "parquet-encoding/src/test/java/parquet/column/values/bitpacking/TestByteBitPacking.java": [
                18,
                20
            ],
            "parquet-encoding/src/test/java/parquet/column/values/bitpacking/TestLemireBitPacking.java": [
                12,
                14
            ],
            "parquet-generator/pom.xml": null,
            "parquet-hadoop-bundle/pom.xml": null,
            "parquet-hadoop/pom.xml": null,
            "parquet-hadoop/src/main/java/parquet/hadoop/ParquetFileReader.java": [
                15,
                27
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/ParquetFileWriter.java": [
                7,
                11
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/ParquetInputFormat.java": [
                80,
                184
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/ParquetInputSplit.java": [
                18,
                29
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/metadata/BlockMetaData.java": [
                0,
                17
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/metadata/ColumnChunkMetaData.java": [
                5,
                18
            ],
            "parquet-hadoop/src/test/java/parquet/hadoop/TestInputFormat.java": [
                34,
                249
            ],
            "parquet-hadoop/src/test/java/parquet/hadoop/TestParquetInputSplit.java": [
                2,
                2
            ],
            "parquet-hive-bundle/pom.xml": null,
            "parquet-hive/parquet-hive-binding/parquet-hive-0.10-binding/pom.xml": null,
            "parquet-hive/parquet-hive-binding/parquet-hive-0.12-binding/pom.xml": null,
            "parquet-hive/parquet-hive-binding/parquet-hive-binding-bundle/pom.xml": null,
            "parquet-hive/parquet-hive-binding/parquet-hive-binding-factory/pom.xml": null,
            "parquet-hive/parquet-hive-binding/parquet-hive-binding-interface/pom.xml": null,
            "parquet-hive/parquet-hive-binding/pom.xml": null,
            "parquet-hive/parquet-hive-storage-handler/pom.xml": null,
            "parquet-hive/parquet-hive-storage-handler/src/main/java/org/apache/hadoop/hive/ql/io/parquet/convert/HiveSchemaConverter.java": [
                2,
                2
            ],
            "parquet-hive/parquet-hive-storage-handler/src/main/java/org/apache/hadoop/hive/ql/io/parquet/serde/AbstractParquetMapInspector.java": [
                13,
                25
            ],
            "parquet-hive/parquet-hive-storage-handler/src/test/java/org/apache/hadoop/hive/ql/io/parquet/TestHiveSchemaConverter.java": [
                0,
                24
            ],
            "parquet-hive/pom.xml": null,
            "parquet-jackson/pom.xml": null,
            "parquet-pig-bundle/pom.xml": null,
            "parquet-pig/pom.xml": null,
            "parquet-protobuf/pom.xml": null,
            "parquet-scrooge/pom.xml": null,
            "parquet-scrooge/src/main/java/parquet/scrooge/ScroogeStructConverter.java": [
                2,
                8
            ],
            "parquet-scrooge/src/test/java/parquet/scrooge/ScroogeStructConverterTest.java": [
                1,
                0
            ],
            "parquet-scrooge/src/test/thrift/test.thrift": null,
            "parquet-test-hadoop2/pom.xml": null,
            "parquet-thrift/pom.xml": null,
            "parquet-thrift/src/main/java/parquet/hadoop/thrift/ThriftBytesWriteSupport.java": [
                2,
                12
            ],
            "parquet-thrift/src/main/java/parquet/hadoop/thrift/ThriftReadSupport.java": [
                5,
                5
            ],
            "parquet-thrift/src/main/java/parquet/thrift/pig/ParquetThriftStorer.java": [
                0,
                90
            ],
            "parquet-thrift/src/main/java/parquet/thrift/pig/TupleToThriftWriteSupport.java": [
                0,
                74
            ],
            "parquet-thrift/src/test/java/parquet/thrift/pig/TestParquetThriftStorer.java": [
                0,
                79
            ],
            "parquet-tools/pom.xml": null,
            "parquet-tools/src/main/java/parquet/tools/command/DumpCommand.java": [
                1,
                1
            ],
            "parquet-tools/src/main/java/parquet/tools/read/SimpleRecord.java": [
                0,
                5
            ],
            "pom.xml": null
        }
    },
    "78491a40c3413064bec0b66702c3499dcffc43a0": {
        "datetime": "2014-04-23T17:22:26-07:00",
        "summary": "adding 1.4.1 as previous version",
        "message": "adding 1.4.1 as previous version\n",
        "diff": {
            "pom.xml": null
        }
    },
    "f6a2218a50d948061915223d971bf05e02d60ae8": {
        "datetime": "2014-04-25T17:20:55-07:00",
        "summary": "configure semver to enforce semantic versioning",
        "message": "configure semver to enforce semantic versioning\n",
        "diff": {
            "parquet-avro/pom.xml": null,
            "parquet-cascading/pom.xml": null,
            "parquet-column/pom.xml": null,
            "parquet-common/pom.xml": null,
            "parquet-encoding/pom.xml": null,
            "parquet-generator/pom.xml": null,
            "parquet-hadoop/pom.xml": null,
            "parquet-pig/pom.xml": null,
            "parquet-scrooge/pom.xml": null,
            "parquet-test-hadoop2/pom.xml": null,
            "parquet-thrift/pom.xml": null,
            "parquet-tools/pom.xml": null,
            "pom.xml": null
        }
    },
    "9a38aecccf96ceee20779d838aa395262270ea36": {
        "datetime": "2014-04-29T15:54:54-07:00",
        "summary": "fix metadata concurency problem",
        "message": "fix metadata concurency problem\n",
        "diff": {
            "parquet-hadoop/src/main/java/parquet/hadoop/metadata/Canonicalizer.java": [
                0,
                59
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/metadata/ColumnChunkProperties.java": [
                10,
                2
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/metadata/ColumnPath.java": [
                13,
                10
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/metadata/EncodingList.java": [
                10,
                2
            ]
        }
    },
    "6aed5288fd4a1398063a5a219b2ae4a9f71b02cf": {
        "datetime": "2014-04-29T16:48:12-07:00",
        "summary": "Merge pull request #381 from Parquet/fix_concurency_problem",
        "message": "Merge pull request #381 from Parquet/fix_concurency_problem\n\nfix metadata concurency problem",
        "diff": {
            "parquet-hadoop/src/main/java/parquet/hadoop/metadata/Canonicalizer.java": [
                0,
                59
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/metadata/ColumnChunkProperties.java": [
                10,
                2
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/metadata/ColumnPath.java": [
                13,
                10
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/metadata/EncodingList.java": [
                10,
                2
            ]
        }
    },
    "3f25ad97f209e7653e9f816508252f850abd635f": {
        "datetime": "2014-04-29T20:24:07-07:00",
        "summary": "[maven-release-plugin] prepare release parquet-1.4.3",
        "message": "[maven-release-plugin] prepare release parquet-1.4.3\n",
        "diff": {
            "parquet-avro/pom.xml": null,
            "parquet-cascading/pom.xml": null,
            "parquet-column/pom.xml": null,
            "parquet-common/pom.xml": null,
            "parquet-encoding/pom.xml": null,
            "parquet-generator/pom.xml": null,
            "parquet-hadoop-bundle/pom.xml": null,
            "parquet-hadoop/pom.xml": null,
            "parquet-hive-bundle/pom.xml": null,
            "parquet-hive/parquet-hive-binding/parquet-hive-0.10-binding/pom.xml": null,
            "parquet-hive/parquet-hive-binding/parquet-hive-0.12-binding/pom.xml": null,
            "parquet-hive/parquet-hive-binding/parquet-hive-binding-bundle/pom.xml": null,
            "parquet-hive/parquet-hive-binding/parquet-hive-binding-factory/pom.xml": null,
            "parquet-hive/parquet-hive-binding/parquet-hive-binding-interface/pom.xml": null,
            "parquet-hive/parquet-hive-binding/pom.xml": null,
            "parquet-hive/parquet-hive-storage-handler/pom.xml": null,
            "parquet-hive/pom.xml": null,
            "parquet-jackson/pom.xml": null,
            "parquet-pig-bundle/pom.xml": null,
            "parquet-pig/pom.xml": null,
            "parquet-protobuf/pom.xml": null,
            "parquet-scrooge/pom.xml": null,
            "parquet-test-hadoop2/pom.xml": null,
            "parquet-thrift/pom.xml": null,
            "parquet-tools/pom.xml": null,
            "pom.xml": null
        }
    },
    "00e794a1109635166621885ce9318759a5c8fd8f": {
        "datetime": "2014-04-29T20:24:12-07:00",
        "summary": "[maven-release-plugin] prepare for next development iteration",
        "message": "[maven-release-plugin] prepare for next development iteration\n",
        "diff": {
            "parquet-avro/pom.xml": null,
            "parquet-cascading/pom.xml": null,
            "parquet-column/pom.xml": null,
            "parquet-common/pom.xml": null,
            "parquet-encoding/pom.xml": null,
            "parquet-generator/pom.xml": null,
            "parquet-hadoop-bundle/pom.xml": null,
            "parquet-hadoop/pom.xml": null,
            "parquet-hive-bundle/pom.xml": null,
            "parquet-hive/parquet-hive-binding/parquet-hive-0.10-binding/pom.xml": null,
            "parquet-hive/parquet-hive-binding/parquet-hive-0.12-binding/pom.xml": null,
            "parquet-hive/parquet-hive-binding/parquet-hive-binding-bundle/pom.xml": null,
            "parquet-hive/parquet-hive-binding/parquet-hive-binding-factory/pom.xml": null,
            "parquet-hive/parquet-hive-binding/parquet-hive-binding-interface/pom.xml": null,
            "parquet-hive/parquet-hive-binding/pom.xml": null,
            "parquet-hive/parquet-hive-storage-handler/pom.xml": null,
            "parquet-hive/pom.xml": null,
            "parquet-jackson/pom.xml": null,
            "parquet-pig-bundle/pom.xml": null,
            "parquet-pig/pom.xml": null,
            "parquet-protobuf/pom.xml": null,
            "parquet-scrooge/pom.xml": null,
            "parquet-test-hadoop2/pom.xml": null,
            "parquet-thrift/pom.xml": null,
            "parquet-tools/pom.xml": null,
            "pom.xml": null
        }
    },
    "0e334ca38b9f76b5b5df6a56510400b7b151f5af": {
        "datetime": "2014-05-02T16:46:27-07:00",
        "summary": "Use parameterized to test with and without dictionary.",
        "message": "Use parameterized to test with and without dictionary.\n",
        "diff": {
            "parquet-column/src/test/java/parquet/io/TestColumnIO.java": [
                1,
                20
            ]
        }
    },
    "5d1a66a9b8777c701a6fa376b941f12531e96e8f": {
        "datetime": "2014-05-04T22:05:59+02:00",
        "summary": "protobuf 2.5 instalation script for Travis",
        "message": "protobuf 2.5 instalation script for Travis\n",
        "diff": {
            ".travis.yml": null
        }
    },
    "636457c03dccbfd66570dd9d6653c901dbb51ef9": {
        "datetime": "2014-05-04T22:25:28+02:00",
        "summary": "protobuf 2.5 instalation script for Travis - build fix",
        "message": "protobuf 2.5 instalation script for Travis - build fix\n",
        "diff": {
            ".travis.yml": null
        }
    },
    "af74b795119af777961cc9604457def59c8c804b": {
        "datetime": "2014-05-04T22:42:16+02:00",
        "summary": "protobuf 2.5 instalation script for Travis - pushd/popd",
        "message": "protobuf 2.5 instalation script for Travis - pushd/popd\n",
        "diff": {
            ".travis.yml": null
        }
    },
    "51065930beca75f029323f4f658662a55e09f837": {
        "datetime": "2014-05-04T23:00:48+02:00",
        "summary": "protobuf 2.5 instalation script for Travis - fix",
        "message": "protobuf 2.5 instalation script for Travis - fix\n",
        "diff": {
            ".travis.yml": null
        }
    },
    "cb3e51466b5c9d6146e1b8cae8a4f7082cbd0821": {
        "datetime": "2014-05-05T15:11:48+02:00",
        "summary": "protobuf 2.5 instalation script for Travis - remove make check",
        "message": "protobuf 2.5 instalation script for Travis - remove make check\n",
        "diff": {
            ".travis.yml": null
        }
    },
    "346b387ae779e2eda2d4ef9b3bff361fac2d753d": {
        "datetime": "2014-05-05T16:09:59-07:00",
        "summary": "Merge pull request #337 from tongjiechen/issue324",
        "message": "Merge pull request #337 from tongjiechen/issue324\n\n issue #324, move ParquetStringInspector to org.apache.hadoop.hive.serde...",
        "diff": {
            "parquet-hive/parquet-hive-storage-handler/src/main/java/org/apache/hadoop/hive/ql/io/parquet/serde/ArrayWritableObjectInspector.java": [
                0,
                7
            ],
            "parquet-hive/parquet-hive-storage-handler/src/main/java/org/apache/hadoop/hive/ql/io/parquet/serde/primitive/ParquetPrimitiveInspectorFactory.java": [
                0,
                1
            ],
            "parquet-hive/parquet-hive-storage-handler/src/main/java/org/apache/hadoop/hive/ql/io/parquet/serde/primitive/ParquetStringInspector.java": [
                7,
                4
            ]
        }
    },
    "70a00125132600c9071fa6627a033262046e0278": {
        "datetime": "2014-05-06T14:58:12-07:00",
        "summary": "[maven-release-plugin] prepare release parquet-format-2.1.0",
        "message": "[maven-release-plugin] prepare release parquet-format-2.1.0\n",
        "diff": {
            "pom.xml": null
        }
    },
    "31df4fa3afbf209f0e0928eb16838697d4905c7a": {
        "datetime": "2014-05-06T14:58:15-07:00",
        "summary": "[maven-release-plugin] prepare for next development iteration",
        "message": "[maven-release-plugin] prepare for next development iteration\n",
        "diff": {
            "pom.xml": null
        }
    },
    "57b0131513366863198f320caa9d9f053a9a78a7": {
        "datetime": "2014-05-07T15:57:17-07:00",
        "summary": "Merge pull request #336 from lukasnalezenec/protobuf",
        "message": "Merge pull request #336 from lukasnalezenec/protobuf\n\nprotobuf dependency version changed from 2.4.1 to 2.5.0",
        "diff": {
            ".travis.yml": null,
            "parquet-protobuf/pom.xml": null
        }
    },
    "50701e7d2af0aab49b77518c2fb4c4b8c931f855": {
        "datetime": "2014-05-07T16:09:15-07:00",
        "summary": "Merge branch 'master' into tweak_semver",
        "message": "Merge branch 'master' into tweak_semver\n",
        "diff": {
            ".travis.yml": null,
            "parquet-avro/pom.xml": null,
            "parquet-cascading/pom.xml": null,
            "parquet-column/pom.xml": null,
            "parquet-common/pom.xml": null,
            "parquet-encoding/pom.xml": null,
            "parquet-generator/pom.xml": null,
            "parquet-hadoop-bundle/pom.xml": null,
            "parquet-hadoop/pom.xml": null,
            "parquet-hadoop/src/main/java/parquet/hadoop/metadata/Canonicalizer.java": [
                0,
                59
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/metadata/ColumnChunkProperties.java": [
                10,
                2
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/metadata/ColumnPath.java": [
                13,
                10
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/metadata/EncodingList.java": [
                10,
                2
            ],
            "parquet-hive-bundle/pom.xml": null,
            "parquet-hive/parquet-hive-binding/parquet-hive-0.10-binding/pom.xml": null,
            "parquet-hive/parquet-hive-binding/parquet-hive-0.12-binding/pom.xml": null,
            "parquet-hive/parquet-hive-binding/parquet-hive-binding-bundle/pom.xml": null,
            "parquet-hive/parquet-hive-binding/parquet-hive-binding-factory/pom.xml": null,
            "parquet-hive/parquet-hive-binding/parquet-hive-binding-interface/pom.xml": null,
            "parquet-hive/parquet-hive-binding/pom.xml": null,
            "parquet-hive/parquet-hive-storage-handler/pom.xml": null,
            "parquet-hive/parquet-hive-storage-handler/src/main/java/org/apache/hadoop/hive/ql/io/parquet/serde/ArrayWritableObjectInspector.java": [
                0,
                7
            ],
            "parquet-hive/parquet-hive-storage-handler/src/main/java/org/apache/hadoop/hive/ql/io/parquet/serde/primitive/ParquetPrimitiveInspectorFactory.java": [
                0,
                1
            ],
            "parquet-hive/parquet-hive-storage-handler/src/main/java/org/apache/hadoop/hive/ql/io/parquet/serde/primitive/ParquetStringInspector.java": [
                7,
                4
            ],
            "parquet-hive/pom.xml": null,
            "parquet-jackson/pom.xml": null,
            "parquet-pig-bundle/pom.xml": null,
            "parquet-pig/pom.xml": null,
            "parquet-protobuf/pom.xml": null,
            "parquet-scrooge/pom.xml": null,
            "parquet-test-hadoop2/pom.xml": null,
            "parquet-thrift/pom.xml": null,
            "parquet-tools/pom.xml": null,
            "pom.xml": null
        }
    },
    "163bf6bd3436ee8d558524b09d7cc9e4df8a0275": {
        "datetime": "2014-05-07T19:43:22-07:00",
        "summary": "Add support for DECIMAL type annotation.",
        "message": "Add support for DECIMAL type annotation.\n\nChanges:\n* Add Types builder API to consolidate type building, consistency checks\n* Update schema parser to support precision and scale on DECIMAL:\n  required binary aDecimal (DECIMAL(9,2));\n* Update writeToStringBuilder methods to add precision and scale\n* Add DECIMAL conversion in ParquetMetadataConverter\n* Add precision, scale conversion in ParquetMetadataConverter\n* Add OriginalTypeMeta to hold type annotation metadata (e.g., scale)\n* Add more testing to ensure compatibility\n",
        "diff": {
            "parquet-column/src/main/java/parquet/schema/GroupType.java": [
                4,
                19
            ],
            "parquet-column/src/main/java/parquet/schema/MessageTypeParser.java": [
                26,
                47
            ],
            "parquet-column/src/main/java/parquet/schema/OriginalType.java": [
                1,
                2
            ],
            "parquet-column/src/main/java/parquet/schema/OriginalTypeMeta.java": [
                0,
                39
            ],
            "parquet-column/src/main/java/parquet/schema/PrimitiveType.java": [
                13,
                35
            ],
            "parquet-column/src/main/java/parquet/schema/Type.java": [
                2,
                21
            ],
            "parquet-column/src/main/java/parquet/schema/Types.java": [
                0,
                282
            ],
            "parquet-column/src/test/java/parquet/parser/TestParquetParser.java": [
                6,
                133
            ],
            "parquet-column/src/test/java/parquet/schema/TestTypeBuilders.java": [
                0,
                151
            ],
            "parquet-common/src/main/java/parquet/Preconditions.java": [
                0,
                6
            ],
            "parquet-hadoop/src/main/java/parquet/format/converter/ParquetMetadataConverter.java": [
                34,
                41
            ],
            "parquet-hadoop/src/test/java/parquet/format/converter/TestParquetMetadataConverter.java": [
                0,
                35
            ],
            "pom.xml": null
        }
    },
    "0189ff1757a3b3f0c9c268ed68cee6387d3e5187": {
        "datetime": "2014-05-07T19:43:23-07:00",
        "summary": "Fix more code review finds.",
        "message": "Fix more code review finds.\n",
        "diff": {
            "parquet-column/src/main/java/parquet/schema/PrimitiveType.java": [
                2,
                3
            ],
            "parquet-column/src/main/java/parquet/schema/Types.java": [
                0,
                14
            ],
            "parquet-hadoop/src/main/java/parquet/format/converter/ParquetMetadataConverter.java": [
                3,
                3
            ]
        }
    },
    "c825e89c84fa78222baae7a35c4843b2ef199869": {
        "datetime": "2014-05-07T19:43:23-07:00",
        "summary": "Remove unchecked casts from Types.Builder.",
        "message": "Remove unchecked casts from Types.Builder.\n\nThis simplifies the logic so that either a return object is supplied\nwhen a Builder is constructed, or the expected type is supplied so that\nthe code can check the return type is valid.\n",
        "diff": {
            "parquet-column/src/main/java/parquet/schema/Types.java": [
                20,
                39
            ]
        }
    },
    "acaac8bb700debdec66d0a633a60be503b7a20b4": {
        "datetime": "2014-05-07T19:43:23-07:00",
        "summary": "Implement code review changes.",
        "message": "Implement code review changes.\n",
        "diff": {
            "parquet-column/src/main/java/parquet/schema/GroupType.java": [
                19,
                4
            ],
            "parquet-column/src/main/java/parquet/schema/MessageTypeParser.java": [
                20,
                41
            ],
            "parquet-column/src/main/java/parquet/schema/OriginalTypeMeta.java": [
                3,
                3
            ],
            "parquet-column/src/main/java/parquet/schema/PrimitiveType.java": [
                4,
                18
            ],
            "parquet-column/src/main/java/parquet/schema/Type.java": [
                21,
                2
            ],
            "parquet-column/src/main/java/parquet/schema/Types.java": [
                58,
                68
            ],
            "parquet-column/src/test/java/parquet/schema/TestTypeBuilders.java": [
                17,
                20
            ],
            "parquet-common/src/main/java/parquet/Preconditions.java": [
                0,
                5
            ],
            "parquet-hadoop/src/main/java/parquet/format/converter/ParquetMetadataConverter.java": [
                12,
                10
            ]
        }
    },
    "86501c2352413feb8a4128362d862c89e6cbb1f7": {
        "datetime": "2014-05-07T19:43:23-07:00",
        "summary": "Add INT32 and INT64 as supported types for DECIMAL.",
        "message": "Add INT32 and INT64 as supported types for DECIMAL.\n",
        "diff": {
            "parquet-column/src/main/java/parquet/schema/Types.java": [
                5,
                18
            ],
            "parquet-column/src/test/java/parquet/schema/TestTypeBuilders.java": [
                44,
                140
            ]
        }
    },
    "9ef22e630907eeb85600ab3ef53257fb575a0f8e": {
        "datetime": "2014-05-07T19:43:23-07:00",
        "summary": "Fix maximum precision calculation, account for sign bit.",
        "message": "Fix maximum precision calculation, account for sign bit.\n",
        "diff": {
            "parquet-column/src/main/java/parquet/schema/Types.java": [
                3,
                3
            ],
            "parquet-column/src/test/java/parquet/schema/TestTypeBuilders.java": [
                2,
                2
            ]
        }
    },
    "5c807055aa1959737c2b2a1d2256e5769c9a7f25": {
        "datetime": "2014-05-07T19:43:23-07:00",
        "summary": "Update documentation and formatting.",
        "message": "Update documentation and formatting.\n",
        "diff": {
            "parquet-column/src/main/java/parquet/schema/Types.java": [
                19,
                23
            ]
        }
    },
    "73d7558bdaf966a9fbfae7fc1c8f0ba727a98de9": {
        "datetime": "2014-05-07T19:43:23-07:00",
        "summary": "Simplify Types API by moving repetition.",
        "message": "Simplify Types API by moving repetition.\n",
        "diff": {
            "parquet-column/src/main/java/parquet/schema/MessageTypeParser.java": [
                5,
                2
            ],
            "parquet-column/src/main/java/parquet/schema/PrimitiveType.java": [
                2,
                2
            ],
            "parquet-column/src/main/java/parquet/schema/Types.java": [
                9,
                13
            ],
            "parquet-column/src/test/java/parquet/schema/TestTypeBuilders.java": [
                27,
                5
            ],
            "parquet-hadoop/src/main/java/parquet/format/converter/ParquetMetadataConverter.java": [
                4,
                4
            ]
        }
    },
    "299e0ca760ccc0608ba7b0ebd3461f4ec5e606f8": {
        "datetime": "2014-05-07T19:43:23-07:00",
        "summary": "Add Types builder API documentation.",
        "message": "Add Types builder API documentation.\n\nAlso add check that scale <= precision and test.\n",
        "diff": {
            "parquet-column/src/main/java/parquet/schema/Types.java": [
                4,
                260
            ],
            "parquet-column/src/test/java/parquet/schema/TestTypeBuilders.java": [
                0,
                25
            ]
        }
    },
    "63ffdce40355d8c75dae6a6888ca315889737f1c": {
        "datetime": "2014-05-07T19:43:23-07:00",
        "summary": "Add test for decimal with unsupported primitive types.",
        "message": "Add test for decimal with unsupported primitive types.\n",
        "diff": {
            "parquet-column/src/test/java/parquet/schema/TestTypeBuilders.java": [
                0,
                18
            ]
        }
    },
    "3af02db83a4b18f814a400bfe8569c31de4932b7": {
        "datetime": "2014-05-07T19:43:23-07:00",
        "summary": "Add more tests for type builders.",
        "message": "Add more tests for type builders.\n",
        "diff": {
            "parquet-column/src/test/java/parquet/schema/TestTypeBuilders.java": [
                0,
                199
            ]
        }
    },
    "a1d7260a4ace24a8d6f514149271ad998019eb5e": {
        "datetime": "2014-05-07T19:43:23-07:00",
        "summary": "Fix primitive type equality for fixed with different lengths.",
        "message": "Fix primitive type equality for fixed with different lengths.\n",
        "diff": {
            "parquet-column/src/main/java/parquet/schema/PrimitiveType.java": [
                0,
                4
            ],
            "parquet-column/src/test/java/parquet/schema/TestTypeBuilders.java": [
                0,
                8
            ]
        }
    },
    "db31a49a94ada2484690ac81909e2baabfff09d9": {
        "datetime": "2014-05-07T23:18:57-07:00",
        "summary": "upgrade semver and add exclude for shaded stuff",
        "message": "upgrade semver and add exclude for shaded stuff\n",
        "diff": {
            "pom.xml": null
        }
    },
    "638c0446c7debe135a4d9a088a46ffb1ba607f52": {
        "datetime": "2014-05-07T23:41:27-07:00",
        "summary": "update version",
        "message": "update version\n",
        "diff": {
            "parquet-avro/pom.xml": null,
            "parquet-cascading/pom.xml": null,
            "parquet-column/pom.xml": null,
            "parquet-common/pom.xml": null,
            "parquet-encoding/pom.xml": null,
            "parquet-generator/pom.xml": null,
            "parquet-hadoop-bundle/pom.xml": null,
            "parquet-hadoop/pom.xml": null,
            "parquet-hive-bundle/pom.xml": null,
            "parquet-hive/parquet-hive-binding/parquet-hive-0.10-binding/pom.xml": null,
            "parquet-hive/parquet-hive-binding/parquet-hive-0.12-binding/pom.xml": null,
            "parquet-hive/parquet-hive-binding/parquet-hive-binding-bundle/pom.xml": null,
            "parquet-hive/parquet-hive-binding/parquet-hive-binding-factory/pom.xml": null,
            "parquet-hive/parquet-hive-binding/parquet-hive-binding-interface/pom.xml": null,
            "parquet-hive/parquet-hive-binding/pom.xml": null,
            "parquet-hive/parquet-hive-storage-handler/pom.xml": null,
            "parquet-hive/pom.xml": null,
            "parquet-jackson/pom.xml": null,
            "parquet-pig-bundle/pom.xml": null,
            "parquet-pig/pom.xml": null,
            "parquet-protobuf/pom.xml": null,
            "parquet-scrooge/pom.xml": null,
            "parquet-test-hadoop2/pom.xml": null,
            "parquet-thrift/pom.xml": null,
            "parquet-tools/pom.xml": null,
            "pom.xml": null
        }
    },
    "9f75dd1f59236f22e199bd5561f511dc5e45d66a": {
        "datetime": "2014-05-08T16:57:28+01:00",
        "summary": "Merge pull request #355 from rdblue/decimal",
        "message": "Merge pull request #355 from rdblue/decimal\n\nAdd support for DECIMAL type annotation.",
        "diff": {
            "parquet-column/src/main/java/parquet/schema/DecimalMetadata.java": [
                0,
                39
            ],
            "parquet-column/src/main/java/parquet/schema/MessageTypeParser.java": [
                31,
                70
            ],
            "parquet-column/src/main/java/parquet/schema/OriginalType.java": [
                1,
                2
            ],
            "parquet-column/src/main/java/parquet/schema/PrimitiveType.java": [
                6,
                47
            ],
            "parquet-column/src/main/java/parquet/schema/Types.java": [
                0,
                602
            ],
            "parquet-column/src/test/java/parquet/parser/TestParquetParser.java": [
                6,
                133
            ],
            "parquet-column/src/test/java/parquet/schema/TestTypeBuilders.java": [
                0,
                478
            ],
            "parquet-common/src/main/java/parquet/Preconditions.java": [
                0,
                11
            ],
            "parquet-hadoop/src/main/java/parquet/format/converter/ParquetMetadataConverter.java": [
                34,
                39
            ],
            "parquet-hadoop/src/test/java/parquet/format/converter/TestParquetMetadataConverter.java": [
                0,
                35
            ],
            "pom.xml": null
        }
    },
    "0c740e0178f079591c951485f72cd094c3dcd583": {
        "datetime": "2014-05-08T12:39:29-07:00",
        "summary": "remove exclude for Split",
        "message": "remove exclude for Split\n",
        "diff": {
            "pom.xml": null
        }
    },
    "bcd2ec5db4d479cd66c561ea696d8d7510afebc4": {
        "datetime": "2014-05-08T13:41:22-07:00",
        "summary": "remove unnecessary version number in parquet-scrooge",
        "message": "remove unnecessary version number in parquet-scrooge\n",
        "diff": {
            "parquet-scrooge/pom.xml": null
        }
    },
    "d08313cbae60faecdca09d7eeb286f999bfbb42d": {
        "datetime": "2014-05-08T14:10:02-07:00",
        "summary": "add release 1.4.3 to changelog",
        "message": "add release 1.4.3 to changelog\n",
        "diff": {
            "CHANGES.md": null
        }
    },
    "7d335d8bfd121068adb391dcfe3e98201d372967": {
        "datetime": "2014-05-08T14:16:27-07:00",
        "summary": "Merge pull request #378 from Parquet/tweak_semver",
        "message": "Merge pull request #378 from Parquet/tweak_semver\n\nconfigure semver to enforce semantic versioning",
        "diff": {
            "parquet-avro/pom.xml": null,
            "parquet-cascading/pom.xml": null,
            "parquet-column/pom.xml": null,
            "parquet-common/pom.xml": null,
            "parquet-encoding/pom.xml": null,
            "parquet-generator/pom.xml": null,
            "parquet-hadoop-bundle/pom.xml": null,
            "parquet-hadoop/pom.xml": null,
            "parquet-hive-bundle/pom.xml": null,
            "parquet-hive/parquet-hive-binding/parquet-hive-0.10-binding/pom.xml": null,
            "parquet-hive/parquet-hive-binding/parquet-hive-0.12-binding/pom.xml": null,
            "parquet-hive/parquet-hive-binding/parquet-hive-binding-bundle/pom.xml": null,
            "parquet-hive/parquet-hive-binding/parquet-hive-binding-factory/pom.xml": null,
            "parquet-hive/parquet-hive-binding/parquet-hive-binding-interface/pom.xml": null,
            "parquet-hive/parquet-hive-binding/pom.xml": null,
            "parquet-hive/parquet-hive-storage-handler/pom.xml": null,
            "parquet-hive/pom.xml": null,
            "parquet-jackson/pom.xml": null,
            "parquet-pig-bundle/pom.xml": null,
            "parquet-pig/pom.xml": null,
            "parquet-protobuf/pom.xml": null,
            "parquet-scrooge/pom.xml": null,
            "parquet-test-hadoop2/pom.xml": null,
            "parquet-thrift/pom.xml": null,
            "parquet-tools/pom.xml": null,
            "pom.xml": null
        }
    },
    "96b94e1b7e61c8c9b17c9c08ce059a9d4015052e": {
        "datetime": "2014-05-08T14:17:16-07:00",
        "summary": "Merge pull request #351 from rdblue/350-fix-int96-dictionary",
        "message": "Merge pull request #351 from rdblue/350-fix-int96-dictionary\n\nFix bug #350, fixed length argument out of order.",
        "diff": {
            "parquet-column/src/main/java/parquet/column/ParquetProperties.java": [
                1,
                1
            ],
            "parquet-column/src/test/java/parquet/io/TestColumnIO.java": [
                1,
                20
            ]
        }
    },
    "ff830a95aef80460dbca996036fef736b38ab1d0": {
        "datetime": "2014-05-09T10:23:40-07:00",
        "summary": "previous version to 1.4.2",
        "message": "previous version to 1.4.2\n",
        "diff": {
            "pom.xml": null
        }
    },
    "2678e39483965083c3604e10b9dd143a2c89dd7b": {
        "datetime": "2014-05-09T10:26:21-07:00",
        "summary": "Merge branch 'master' of https://github.com/Parquet/parquet-mr into stats",
        "message": "Merge branch 'master' of https://github.com/Parquet/parquet-mr into stats\n\nConflicts:\n\tparquet-hadoop/src/main/java/parquet/hadoop/metadata/ColumnChunkProperties.java\n\tpom.xml\n",
        "diff": {
            ".travis.yml": null,
            "CHANGES.md": null,
            "parquet-avro/pom.xml": null,
            "parquet-cascading/pom.xml": null,
            "parquet-column/pom.xml": null,
            "parquet-column/src/main/java/parquet/column/ParquetProperties.java": [
                1,
                1
            ],
            "parquet-column/src/main/java/parquet/schema/DecimalMetadata.java": [
                0,
                39
            ],
            "parquet-column/src/main/java/parquet/schema/MessageTypeParser.java": [
                31,
                70
            ],
            "parquet-column/src/main/java/parquet/schema/OriginalType.java": [
                1,
                2
            ],
            "parquet-column/src/main/java/parquet/schema/PrimitiveType.java": [
                6,
                47
            ],
            "parquet-column/src/main/java/parquet/schema/Types.java": [
                0,
                602
            ],
            "parquet-column/src/test/java/parquet/io/TestColumnIO.java": [
                1,
                20
            ],
            "parquet-column/src/test/java/parquet/parser/TestParquetParser.java": [
                6,
                133
            ],
            "parquet-column/src/test/java/parquet/schema/TestTypeBuilders.java": [
                0,
                478
            ],
            "parquet-common/pom.xml": null,
            "parquet-common/src/main/java/parquet/Preconditions.java": [
                0,
                11
            ],
            "parquet-encoding/pom.xml": null,
            "parquet-generator/pom.xml": null,
            "parquet-hadoop-bundle/pom.xml": null,
            "parquet-hadoop/pom.xml": null,
            "parquet-hadoop/src/main/java/parquet/format/converter/ParquetMetadataConverter.java": [
                34,
                39
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/metadata/Canonicalizer.java": [
                0,
                59
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/metadata/ColumnChunkProperties.java": [
                14,
                3
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/metadata/ColumnPath.java": [
                13,
                10
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/metadata/EncodingList.java": [
                10,
                2
            ],
            "parquet-hadoop/src/test/java/parquet/format/converter/TestParquetMetadataConverter.java": [
                0,
                35
            ],
            "parquet-hive-bundle/pom.xml": null,
            "parquet-hive/parquet-hive-binding/parquet-hive-0.10-binding/pom.xml": null,
            "parquet-hive/parquet-hive-binding/parquet-hive-0.12-binding/pom.xml": null,
            "parquet-hive/parquet-hive-binding/parquet-hive-binding-bundle/pom.xml": null,
            "parquet-hive/parquet-hive-binding/parquet-hive-binding-factory/pom.xml": null,
            "parquet-hive/parquet-hive-binding/parquet-hive-binding-interface/pom.xml": null,
            "parquet-hive/parquet-hive-binding/pom.xml": null,
            "parquet-hive/parquet-hive-storage-handler/pom.xml": null,
            "parquet-hive/parquet-hive-storage-handler/src/main/java/org/apache/hadoop/hive/ql/io/parquet/serde/ArrayWritableObjectInspector.java": [
                0,
                7
            ],
            "parquet-hive/parquet-hive-storage-handler/src/main/java/org/apache/hadoop/hive/ql/io/parquet/serde/primitive/ParquetPrimitiveInspectorFactory.java": [
                0,
                1
            ],
            "parquet-hive/parquet-hive-storage-handler/src/main/java/org/apache/hadoop/hive/ql/io/parquet/serde/primitive/ParquetStringInspector.java": [
                7,
                4
            ],
            "parquet-hive/pom.xml": null,
            "parquet-jackson/pom.xml": null,
            "parquet-pig-bundle/pom.xml": null,
            "parquet-pig/pom.xml": null,
            "parquet-protobuf/pom.xml": null,
            "parquet-scrooge/pom.xml": null,
            "parquet-test-hadoop2/pom.xml": null,
            "parquet-thrift/pom.xml": null,
            "parquet-tools/pom.xml": null,
            "pom.xml": null
        }
    },
    "c98d8af5c26a5622b2b830fc3410e8f8ae1f83e7": {
        "datetime": "2014-05-09T14:01:19-07:00",
        "summary": "adding back the parquet-hadoop methods that don't have statistics parameters, for backward comp",
        "message": "adding back the parquet-hadoop methods that don't have statistics parameters, for backward comp\n",
        "diff": {
            "parquet-hadoop/src/main/java/parquet/format/converter/ParquetMetadataConverter.java": [
                0,
                18
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/ParquetFileWriter.java": [
                0,
                38
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/metadata/ColumnChunkMetaData.java": [
                0,
                39
            ]
        }
    },
    "041146e6b0eb0dca699cf66991a19d3991bfe3e6": {
        "datetime": "2014-05-12T10:55:19+10:00",
        "summary": "Fixed hadoop WriteSupportClass loading",
        "message": "Fixed hadoop WriteSupportClass loading\n",
        "diff": {
            "parquet-hadoop/src/main/java/parquet/hadoop/ParquetOutputFormat.java": [
                9,
                3
            ]
        }
    },
    "882740f032fb57b48a5bc775da609532084c7fe4": {
        "datetime": "2014-05-12T16:11:22+02:00",
        "summary": "return NullCounter when read via Cascading, but not within a cluster side job",
        "message": "return NullCounter when read via Cascading, but not within a cluster side job\n",
        "diff": {
            "parquet-hadoop/src/main/java/parquet/hadoop/util/counters/mapred/MapRedCounterLoader.java": [
                4,
                7
            ]
        }
    },
    "05b4e7c6be490255f89f4beaddd5cbfa84560e38": {
        "datetime": "2014-05-12T14:54:57-07:00",
        "summary": "Merge pull request #338 from egonina/stats",
        "message": "Merge pull request #338 from egonina/stats\n\nAdded statistics to Parquet pages and rowGroups",
        "diff": {
            "parquet-column/src/main/java/parquet/column/ColumnWriter.java": [
                0,
                6
            ],
            "parquet-column/src/main/java/parquet/column/UnknownColumnTypeException.java": [
                0,
                40
            ],
            "parquet-column/src/main/java/parquet/column/impl/ColumnWriteStoreImpl.java": [
                0,
                5
            ],
            "parquet-column/src/main/java/parquet/column/impl/ColumnWriterImpl.java": [
                12,
                46
            ],
            "parquet-column/src/main/java/parquet/column/page/Page.java": [
                1,
                34
            ],
            "parquet-column/src/main/java/parquet/column/page/PageWriter.java": [
                0,
                14
            ],
            "parquet-column/src/main/java/parquet/column/statistics/BinaryStatistics.java": [
                0,
                85
            ],
            "parquet-column/src/main/java/parquet/column/statistics/BooleanStatistics.java": [
                0,
                85
            ],
            "parquet-column/src/main/java/parquet/column/statistics/DoubleStatistics.java": [
                0,
                85
            ],
            "parquet-column/src/main/java/parquet/column/statistics/FloatStatistics.java": [
                0,
                85
            ],
            "parquet-column/src/main/java/parquet/column/statistics/IntStatistics.java": [
                0,
                85
            ],
            "parquet-column/src/main/java/parquet/column/statistics/LongStatistics.java": [
                0,
                85
            ],
            "parquet-column/src/main/java/parquet/column/statistics/Statistics.java": [
                0,
                221
            ],
            "parquet-column/src/main/java/parquet/column/statistics/StatisticsClassException.java": [
                0,
                31
            ],
            "parquet-column/src/main/java/parquet/io/api/Binary.java": [
                0,
                63
            ],
            "parquet-column/src/test/java/parquet/column/mem/TestMemPageStore.java": [
                4,
                6
            ],
            "parquet-column/src/test/java/parquet/column/page/mem/MemPageWriter.java": [
                1,
                14
            ],
            "parquet-column/src/test/java/parquet/column/statistics/TestStatistics.java": [
                0,
                462
            ],
            "parquet-column/src/test/java/parquet/io/TestColumnIO.java": [
                0,
                127
            ],
            "parquet-common/src/main/java/parquet/bytes/BytesUtils.java": [
                0,
                50
            ],
            "parquet-hadoop/src/main/java/parquet/format/converter/ParquetMetadataConverter.java": [
                2,
                51
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/ColumnChunkPageReadStore.java": [
                0,
                1
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/ColumnChunkPageWriteStore.java": [
                2,
                44
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/ParquetFileReader.java": [
                0,
                1
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/ParquetFileWriter.java": [
                2,
                58
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/ParquetInputSplit.java": [
                1,
                3
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/metadata/ColumnChunkMetaData.java": [
                4,
                83
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/metadata/ColumnChunkProperties.java": [
                3,
                4
            ],
            "parquet-hadoop/src/test/java/parquet/hadoop/TestInputFormat.java": [
                3,
                8
            ],
            "parquet-hadoop/src/test/java/parquet/hadoop/TestParquetFileWriter.java": [
                15,
                116
            ],
            "parquet-hadoop/src/test/java/parquet/hadoop/metadata/TestColumnChunkMetaData.java": [
                3,
                4
            ]
        }
    },
    "cc28822843f97a6c791dfc2cb1c860c2e731d22a": {
        "datetime": "2014-05-13T11:57:34-07:00",
        "summary": "Added padding for columns not found in file schema",
        "message": "Added padding for columns not found in file schema\n",
        "diff": {
            "parquet-pig/src/main/java/parquet/pig/convert/TupleConverter.java": [
                13,
                16
            ]
        }
    },
    "70bb0ea0009f25f7ff432c177f94aa40dbd0ebe4": {
        "datetime": "2014-05-16T17:24:01-07:00",
        "summary": "fixes for converting from bytes, toString() methods, writing stats to Footer, unit testing for MAX/MIN_VALUE",
        "message": "fixes for converting from bytes, toString() methods, writing stats to Footer, unit testing for MAX/MIN_VALUE\n",
        "diff": {
            "parquet-column/src/main/java/parquet/column/statistics/BinaryStatistics.java": [
                0,
                8
            ],
            "parquet-column/src/main/java/parquet/column/statistics/BooleanStatistics.java": [
                0,
                8
            ],
            "parquet-column/src/main/java/parquet/column/statistics/DoubleStatistics.java": [
                0,
                8
            ],
            "parquet-column/src/main/java/parquet/column/statistics/FloatStatistics.java": [
                0,
                8
            ],
            "parquet-column/src/main/java/parquet/column/statistics/IntStatistics.java": [
                0,
                8
            ],
            "parquet-column/src/main/java/parquet/column/statistics/LongStatistics.java": [
                2,
                10
            ],
            "parquet-column/src/main/java/parquet/column/statistics/Statistics.java": [
                0,
                6
            ],
            "parquet-column/src/test/java/parquet/column/statistics/TestStatistics.java": [
                5,
                109
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/PrintFooter.java": [
                8,
                13
            ]
        }
    },
    "4d42afbaa5f1e67250bf00806c1e3e84088d101b": {
        "datetime": "2014-05-19T09:23:10-07:00",
        "summary": "Merge pull request #392 from egonina/stats",
        "message": "Merge pull request #392 from egonina/stats\n\nValue stats fixes",
        "diff": {
            "parquet-column/src/main/java/parquet/column/statistics/BinaryStatistics.java": [
                0,
                8
            ],
            "parquet-column/src/main/java/parquet/column/statistics/BooleanStatistics.java": [
                0,
                8
            ],
            "parquet-column/src/main/java/parquet/column/statistics/DoubleStatistics.java": [
                0,
                8
            ],
            "parquet-column/src/main/java/parquet/column/statistics/FloatStatistics.java": [
                0,
                8
            ],
            "parquet-column/src/main/java/parquet/column/statistics/IntStatistics.java": [
                0,
                8
            ],
            "parquet-column/src/main/java/parquet/column/statistics/LongStatistics.java": [
                2,
                10
            ],
            "parquet-column/src/main/java/parquet/column/statistics/Statistics.java": [
                0,
                6
            ],
            "parquet-column/src/test/java/parquet/column/statistics/TestStatistics.java": [
                5,
                109
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/PrintFooter.java": [
                8,
                13
            ]
        }
    },
    "10dc714bdbb9f7209538d412dc1fcf2219cc9afb": {
        "datetime": "2014-05-19T09:53:02-07:00",
        "summary": "Added test for null padding",
        "message": "Added test for null padding\n",
        "diff": {
            "parquet-pig/src/test/java/parquet/pig/TestParquetLoader.java": [
                0,
                45
            ]
        }
    },
    "d5a8f9fa4a34bfc6dfa7369cb7b786634914698c": {
        "datetime": "2014-05-19T10:27:54-07:00",
        "summary": "Merge pull request #389 from dcw-netflix/pad-schema",
        "message": "Merge pull request #389 from dcw-netflix/pad-schema\n\nAdded padding for requested columns not found in file schema",
        "diff": {
            "parquet-pig/src/main/java/parquet/pig/convert/TupleConverter.java": [
                13,
                16
            ],
            "parquet-pig/src/test/java/parquet/pig/TestParquetLoader.java": [
                0,
                45
            ]
        }
    },
    "24076a4a44ab08534e4528ff4b08e8eec60ddcb7": {
        "datetime": "2014-05-20T16:15:27-07:00",
        "summary": "Fixed issue with column pruning when using requested schema",
        "message": "Fixed issue with column pruning when using requested schema\n",
        "diff": {
            "parquet-pig/src/main/java/parquet/pig/ParquetLoader.java": [
                2,
                2
            ],
            "parquet-pig/src/test/java/parquet/pig/TestParquetLoader.java": [
                0,
                34
            ]
        }
    },
    "fb7dba1ad4bef40ffe6dbe59f6f9ace9ecd1c131": {
        "datetime": "2014-05-20T17:18:29-07:00",
        "summary": "Updated test and remove shortcut return statement in loader",
        "message": "Updated test and remove shortcut return statement in loader\n",
        "diff": {
            "parquet-pig/src/main/java/parquet/pig/ParquetLoader.java": [
                1,
                0
            ],
            "parquet-pig/src/test/java/parquet/pig/TestParquetLoader.java": [
                6,
                7
            ]
        }
    },
    "b70509ddc393a51332977bd9c67c4de0073173c7": {
        "datetime": "2014-05-20T17:45:48-07:00",
        "summary": "Merge pull request #397 from dcw-netflix/requested-schema-pruning",
        "message": "Merge pull request #397 from dcw-netflix/requested-schema-pruning\n\nFixed issue with column pruning when using requested schema",
        "diff": {
            "parquet-pig/src/main/java/parquet/pig/ParquetLoader.java": [
                3,
                2
            ],
            "parquet-pig/src/test/java/parquet/pig/TestParquetLoader.java": [
                4,
                39
            ]
        }
    },
    "8091a1b511aa66ff3775644a757bd30a8c869faf": {
        "datetime": "2014-05-20T23:31:33-07:00",
        "summary": "fix null stats",
        "message": "fix null stats\n",
        "diff": {
            "parquet-column/src/main/java/parquet/column/impl/ColumnWriterImpl.java": [
                1,
                6
            ]
        }
    },
    "7e4346b2120d13a958aa93df26dfc265a8756b2b": {
        "datetime": "2014-05-21T14:04:09-07:00",
        "summary": "merging with fix_null_stats branch",
        "message": "merging with fix_null_stats branch\n",
        "diff": {
            "parquet-column/src/main/java/parquet/column/impl/ColumnWriterImpl.java": [
                2,
                5
            ],
            "parquet-column/src/test/java/parquet/io/TestColumnIO.java": [
                9,
                12
            ],
            "parquet-hadoop/src/main/java/parquet/format/converter/ParquetMetadataConverter.java": [
                2,
                2
            ],
            "parquet-hadoop/src/test/java/parquet/hadoop/TestParquetFileWriter.java": [
                0,
                30
            ],
            "parquet-thrift/src/test/java/parquet/hadoop/thrift/TestThriftToParquetFileWriter.java": [
                9,
                26
            ]
        }
    },
    "e4991ffe47aec9ed991b269d3cbe6fa9c9665627": {
        "datetime": "2014-05-21T15:49:28-07:00",
        "summary": "Merge branch 'master' of https://github.com/Parquet/parquet-mr into stats",
        "message": "Merge branch 'master' of https://github.com/Parquet/parquet-mr into stats\n",
        "diff": {
            "parquet-pig/src/main/java/parquet/pig/ParquetLoader.java": [
                3,
                2
            ],
            "parquet-pig/src/main/java/parquet/pig/convert/TupleConverter.java": [
                13,
                16
            ],
            "parquet-pig/src/test/java/parquet/pig/TestParquetLoader.java": [
                0,
                80
            ]
        }
    },
    "4fee0a7cb53e37d6866f5dc52c51b09ccea330a9": {
        "datetime": "2014-05-21T16:03:15-07:00",
        "summary": "Bug fix - resetting stats after writing page. Fixed unit test to test reading footer",
        "message": "Bug fix - resetting stats after writing page. Fixed unit test to test reading footer\n",
        "diff": {
            "parquet-column/src/main/java/parquet/column/ColumnWriter.java": [
                6,
                0
            ],
            "parquet-column/src/main/java/parquet/column/impl/ColumnWriterImpl.java": [
                5,
                0
            ],
            "parquet-column/src/test/java/parquet/io/TestColumnIO.java": [
                128,
                0
            ],
            "parquet-thrift/src/test/java/parquet/hadoop/thrift/TestThriftToParquetFileWriter.java": [
                18,
                61
            ]
        }
    },
    "54f9b1044d23c53a153743441b44bfbd631ff0e6": {
        "datetime": "2014-05-21T16:47:40-07:00",
        "summary": "Cleaning up + testing small & large values",
        "message": "Cleaning up + testing small & large values\n",
        "diff": {
            "parquet-hadoop/src/test/java/parquet/hadoop/TestParquetFileWriter.java": [
                11,
                0
            ],
            "parquet-thrift/src/test/java/parquet/hadoop/thrift/TestThriftToParquetFileWriter.java": [
                23,
                65
            ]
        }
    },
    "fd8d18f26af9ad7813dda71352b5dcb0080306eb": {
        "datetime": "2014-05-21T17:43:35-07:00",
        "summary": "Merge pull request #399 from egonina/stats",
        "message": "Merge pull request #399 from egonina/stats\n\nFixed resetting stats after writePage bug, unit testing of readFooter",
        "diff": {
            "parquet-column/src/main/java/parquet/column/ColumnWriter.java": [
                6,
                0
            ],
            "parquet-column/src/main/java/parquet/column/impl/ColumnWriterImpl.java": [
                6,
                9
            ],
            "parquet-column/src/test/java/parquet/io/TestColumnIO.java": [
                125,
                0
            ],
            "parquet-hadoop/src/main/java/parquet/format/converter/ParquetMetadataConverter.java": [
                2,
                2
            ],
            "parquet-hadoop/src/test/java/parquet/hadoop/TestParquetFileWriter.java": [
                0,
                19
            ],
            "parquet-thrift/src/test/java/parquet/hadoop/thrift/TestThriftToParquetFileWriter.java": [
                8,
                110
            ]
        }
    },
    "79977453b8cd65e6244f16316fac3a510aa87aa8": {
        "datetime": "2014-05-21T17:56:53-07:00",
        "summary": "[maven-release-plugin] prepare release parquet-1.5.0",
        "message": "[maven-release-plugin] prepare release parquet-1.5.0\n",
        "diff": {
            "parquet-avro/pom.xml": null,
            "parquet-cascading/pom.xml": null,
            "parquet-column/pom.xml": null,
            "parquet-common/pom.xml": null,
            "parquet-encoding/pom.xml": null,
            "parquet-generator/pom.xml": null,
            "parquet-hadoop-bundle/pom.xml": null,
            "parquet-hadoop/pom.xml": null,
            "parquet-hive-bundle/pom.xml": null,
            "parquet-hive/parquet-hive-binding/parquet-hive-0.10-binding/pom.xml": null,
            "parquet-hive/parquet-hive-binding/parquet-hive-0.12-binding/pom.xml": null,
            "parquet-hive/parquet-hive-binding/parquet-hive-binding-bundle/pom.xml": null,
            "parquet-hive/parquet-hive-binding/parquet-hive-binding-factory/pom.xml": null,
            "parquet-hive/parquet-hive-binding/parquet-hive-binding-interface/pom.xml": null,
            "parquet-hive/parquet-hive-binding/pom.xml": null,
            "parquet-hive/parquet-hive-storage-handler/pom.xml": null,
            "parquet-hive/pom.xml": null,
            "parquet-jackson/pom.xml": null,
            "parquet-pig-bundle/pom.xml": null,
            "parquet-pig/pom.xml": null,
            "parquet-protobuf/pom.xml": null,
            "parquet-scrooge/pom.xml": null,
            "parquet-test-hadoop2/pom.xml": null,
            "parquet-thrift/pom.xml": null,
            "parquet-tools/pom.xml": null,
            "pom.xml": null
        }
    },
    "b2f0fae0511e1d471ff223912f1b231101b31a19": {
        "datetime": "2014-05-21T17:56:58-07:00",
        "summary": "[maven-release-plugin] prepare for next development iteration",
        "message": "[maven-release-plugin] prepare for next development iteration\n",
        "diff": {
            "parquet-avro/pom.xml": null,
            "parquet-cascading/pom.xml": null,
            "parquet-column/pom.xml": null,
            "parquet-common/pom.xml": null,
            "parquet-encoding/pom.xml": null,
            "parquet-generator/pom.xml": null,
            "parquet-hadoop-bundle/pom.xml": null,
            "parquet-hadoop/pom.xml": null,
            "parquet-hive-bundle/pom.xml": null,
            "parquet-hive/parquet-hive-binding/parquet-hive-0.10-binding/pom.xml": null,
            "parquet-hive/parquet-hive-binding/parquet-hive-0.12-binding/pom.xml": null,
            "parquet-hive/parquet-hive-binding/parquet-hive-binding-bundle/pom.xml": null,
            "parquet-hive/parquet-hive-binding/parquet-hive-binding-factory/pom.xml": null,
            "parquet-hive/parquet-hive-binding/parquet-hive-binding-interface/pom.xml": null,
            "parquet-hive/parquet-hive-binding/pom.xml": null,
            "parquet-hive/parquet-hive-storage-handler/pom.xml": null,
            "parquet-hive/pom.xml": null,
            "parquet-jackson/pom.xml": null,
            "parquet-pig-bundle/pom.xml": null,
            "parquet-pig/pom.xml": null,
            "parquet-protobuf/pom.xml": null,
            "parquet-scrooge/pom.xml": null,
            "parquet-test-hadoop2/pom.xml": null,
            "parquet-thrift/pom.xml": null,
            "parquet-tools/pom.xml": null,
            "pom.xml": null
        }
    },
    "01d5157a0031c3da393abe766c42fd1f2f2989f4": {
        "datetime": "2014-05-22T10:28:08-07:00",
        "summary": "Update CHANGES.md",
        "message": "Update CHANGES.md",
        "diff": {
            "CHANGES.md": null
        }
    },
    "a05afe2682ce33e401e9fdf87a4c8b147f6daa3a": {
        "datetime": "2014-05-22T17:55:28-07:00",
        "summary": "Merge pull request #387 from ambiata/fix-writeclass",
        "message": "Merge pull request #387 from ambiata/fix-writeclass\n\nFixed hadoop WriteSupportClass loading",
        "diff": {
            "parquet-hadoop/src/main/java/parquet/hadoop/ParquetOutputFormat.java": [
                9,
                3
            ]
        }
    },
    "ee0b98ceaec86f94ca6ef2f9292510b92c5a073c": {
        "datetime": "2014-05-27T14:30:47-07:00",
        "summary": "Merge pull request #388 from fs111/master",
        "message": "Merge pull request #388 from fs111/master\n\nreturn NullCounter when read via Cascading, but not within a cluster side job",
        "diff": {
            "parquet-hadoop/src/main/java/parquet/hadoop/util/counters/mapred/MapRedCounterLoader.java": [
                4,
                7
            ]
        }
    },
    "dd98249ab204669425e6e0e9b1425c8ed58ee0bb": {
        "datetime": "2014-05-27T15:13:36-07:00",
        "summary": "Merge branch 'master' into field_id",
        "message": "Merge branch 'master' into field_id\n\nConflicts:\n\tsrc/thrift/parquet.thrift\n",
        "diff": {
            "pom.xml": null
        }
    },
    "402749f0aea57e7dc2ef37cdbb424079f8f761ad": {
        "datetime": "2014-05-27T15:33:28-07:00",
        "summary": "Merge pull request #85 from Parquet/field_id",
        "message": "Merge pull request #85 from Parquet/field_id\n\nadd field_id in SchemaElement",
        "diff": {}
    },
    "b767ac4e3964f0b8aac50b3cec3b11e9068b101f": {
        "datetime": "2014-06-02T11:30:47-07:00",
        "summary": "Update README.md",
        "message": "Update README.md",
        "diff": {
            "README.md": null
        }
    },
    "859b6b4b9485186fdfd3dd0cd0439d2a48b56aa5": {
        "datetime": "2014-06-20T18:37:19-07:00",
        "summary": "PARQUET-3: tool to merge pull requests based on Spark",
        "message": "PARQUET-3: tool to merge pull requests based on Spark\n\ngiven a pull request id on github.com/apache/incubator-parquet-mr this script will merge it\nrequires 2 remotes: apache-github and apache to point to the corresponding repos.\ntested here (pretending my fork is the apache remote):\nhttps://github.com/julienledem/incubator-parquet-mr/commit/485658a5b7654198ab1fcc77e2b850ee12999491\n\noriginal tool:\nhttps://github.com/apache/spark/blob/master/dev/merge_spark_pr.py\n\nAuthor: Julien Le Dem <julien@twitter.com>\nAuthor: julien <julien@twitter.com>\n\nCloses #5 from julienledem/merge_pr_tool and squashes the following commits:\n\nf719846 [Julien Le Dem] rephrase 'apache credentials'\nfaab516 [Julien Le Dem] Create README.md\nab3b8fa [julien] tool to merge pull requests based on Spark\n",
        "diff": {
            "dev/README.md": null,
            "dev/merge_parquet_pr.py": [
                0,
                336
            ]
        }
    },
    "9ad5485c3310a8c51510ea50e24834b6cf98c45c": {
        "datetime": "2014-06-24T10:19:27-07:00",
        "summary": "PARQUET-2: Adding Type Persuasion for Primitive Types",
        "message": "PARQUET-2: Adding Type Persuasion for Primitive Types\n\nOriginal from the old repo: https://github.com/Parquet/parquet-mr/pull/410\nJIRA: https://issues.apache.org/jira/browse/PARQUET-2\n\nThese changes allow primitive types to be requested as different types than what is stored in the file format using a flag to turn off strict type checking (default is on). Types are cast to the requested type where possible and will suffer precision loss for casting where necessary (e.g. requesting a double as an int).\n\nNo performance penalty is imposed for using the type defined in the file type.  A flag exists to\n\nA 6x6 test case is provided to test conversion between the primitive types.\n\nAuthor: Daniel Weeks <dweeks@netflix.com>\n\nCloses #3 from dcw-netflix/type-persuasion and squashes the following commits:\n\n97f4e9a [Daniel Weeks] Added documentation as suggested by code review\n1c3c0c7 [Daniel Weeks] Fixed test with strict checking off\nf3cb495 [Daniel Weeks] Added type persuasion for primitive types with a flag to control strict type checking for conflicting schemas, which is strict by default.\n",
        "diff": {
            "parquet-column/src/main/java/parquet/io/ColumnIOFactory.java": [
                2,
                19
            ],
            "parquet-column/src/main/java/parquet/schema/GroupType.java": [
                1,
                16
            ],
            "parquet-column/src/main/java/parquet/schema/MessageType.java": [
                1,
                5
            ],
            "parquet-column/src/main/java/parquet/schema/PrimitiveType.java": [
                2,
                7
            ],
            "parquet-column/src/main/java/parquet/schema/Type.java": [
                0,
                7
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/InternalParquetRecordReader.java": [
                2,
                4
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/ParquetFileWriter.java": [
                4,
                28
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/ParquetInputFormat.java": [
                1,
                6
            ],
            "parquet-pig/src/main/java/parquet/pig/convert/TupleConverter.java": [
                3,
                150
            ],
            "parquet-pig/src/test/java/parquet/pig/TestParquetLoader.java": [
                7,
                63
            ]
        }
    },
    "4ad7303dc25c998fbb23dacb5bcf950f89ef6a6f": {
        "datetime": "2014-07-10T16:08:48-07:00",
        "summary": "Minor fix",
        "message": "Minor fix\n\nSpell and comment issue.\n\nAuthor: WangTao <barneystinson@aliyun.com>\n\nCloses #10 from WangTaoTheTonic/minorFix and squashes the following commits:\n\n0727a8f [WangTao] Minor fix\n",
        "diff": {
            "parquet-column/src/main/java/parquet/schema/GroupType.java": [
                2,
                2
            ],
            "parquet-column/src/main/java/parquet/schema/Type.java": [
                4,
                4
            ]
        }
    },
    "9c2fab441bb9f615e8d4c275016a54e9d2f03462": {
        "datetime": "2014-07-11T12:42:28-07:00",
        "summary": "PARQUET-6: Create documentation on how to contribute.",
        "message": "PARQUET-6: Create documentation on how to contribute.\n\nAuthor: Julien Le Dem <julien@twitter.com>\n\nCloses #8 from julienledem/master and squashes the following commits:\n\naa0d751 [Julien Le Dem] correct mailling-list\n285b39c [Julien Le Dem] Update CONTRIBUTING.md\nbca9bc4 [Julien Le Dem] Create CONTRIBUTING.md\n",
        "diff": {
            "CONTRIBUTING.md": null
        }
    },
    "2d8ebdbe00786823658bcdd2817e6b5afee15b25": {
        "datetime": "2014-07-16T14:50:29+01:00",
        "summary": "PARQUET-9: Filtering records across multiple blocks",
        "message": "PARQUET-9: Filtering records across multiple blocks\n\nUpdate of the minimal fix discussed in https://github.com/apache/incubator-parquet-mr/pull/1, with the recursive call changed to to a loop.\n\nAuthor: Tom White <tom@cloudera.com>\nAuthor: Steven Willis <swillis@compete.com>\n\nCloses #9 from tomwhite/filtering-records-across-multiple-blocks and squashes the following commits:\n\nafb08a4 [Tom White] Minimal fix\n9e723ee [Steven Willis] Test for filtering records across multiple blocks\n",
        "diff": {
            "parquet-avro/src/test/java/parquet/avro/TestSpecificReadWrite.java": [
                1,
                51
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/InternalParquetRecordReader.java": [
                2,
                12
            ]
        }
    },
    "5dffe3521588016cf3519792953b0879054c3bfd": {
        "datetime": "2014-07-18T16:02:09-07:00",
        "summary": "PARQUET-4: Use LRU caching for footers in ParquetInputFormat.",
        "message": "PARQUET-4: Use LRU caching for footers in ParquetInputFormat.\n\nReopening https://github.com/Parquet/parquet-mr/pull/403 against the new Apache repository.\n\nAuthor: Matthieu Martin <ma.tt.b.ma.rt.in+parquet@gmail.com>\n\nCloses #2 from matt-martin/master and squashes the following commits:\n\n99bb5a3 [Matthieu Martin] Minor javadoc and whitespace changes. Also added the FileStatusWrapper class to ParquetInputFormat to make sure that the debugging log statements print out meaningful paths.\n250a398 [Matthieu Martin] Be less aggressive about checking whether the underlying file has been appended to/overwritten/deleted in order to minimize the number of namenode interactions.\nd946445 [Matthieu Martin] Add javadocs to parquet.hadoop.LruCache.  Rename cache \"entries\" as cache \"values\" to avoid confusion with java.util.Map.Entry (which contains key value pairs whereas our old \"entries\" really only refer to the values).\na363622 [Matthieu Martin] Use LRU caching for footers in ParquetInputFormat.\n",
        "diff": {
            "parquet-hadoop/pom.xml": null,
            "parquet-hadoop/src/main/java/parquet/hadoop/LruCache.java": [
                0,
                181
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/ParquetInputFormat.java": [
                8,
                137
            ],
            "parquet-hadoop/src/test/java/parquet/hadoop/TestInputFormat.java": [
                3,
                49
            ],
            "parquet-hadoop/src/test/java/parquet/hadoop/TestLruCache.java": [
                0,
                144
            ]
        }
    },
    "f6c02e2c95a5c031ea3735737515e7e76b173ab2": {
        "datetime": "2014-07-18T16:04:21-07:00",
        "summary": "PARQUET-21: Fix reference to 'github-apache' in dev docs",
        "message": "PARQUET-21: Fix reference to 'github-apache' in dev docs\n\nAuthor: Tom White <tom@cloudera.com>\n\nCloses #20 from tomwhite/git-remote-name-fix and squashes the following commits:\n\nc7f8a18 [Tom White] Change 'github-apache' to 'apache-github' in docs to match script.\n",
        "diff": {
            "dev/README.md": null
        }
    },
    "fb0104896815d55183f61c24b78c277dbae3987e": {
        "datetime": "2014-07-18T16:19:25-07:00",
        "summary": "PARQUET-18: Fix all-null value pages with dict encoding.",
        "message": "PARQUET-18: Fix all-null value pages with dict encoding.\n\nTestDictionary#testZeroValues demonstrates the problem, where a page of\nall null values is decoded using the DicitonaryValuesReader. Because\nthere are no non-null values, the page values section is 0 byte, but the\nDictionaryValuesReader assumes there is at least one encoded value and\nattempts to read a bit width. The test passes a byte array to\ninitFromPage with the offset equal to the array's length.\n\nThe fix is to detect that there are no input bytes to read. To avoid\nadding validity checks to the read path, this sets the internal decoder\nto one that will throw an exception if any reads are attempted.\n\nAuthor: Ryan Blue <rblue@cloudera.com>\n\nCloses #18 from rdblue/PARQUET-18-fix-nulls-with-dictionary and squashes the following commits:\n\n0711766 [Ryan Blue] PARQUET-18: Fix all-null value pages with dict encoding.\n",
        "diff": {
            "parquet-column/src/main/java/parquet/column/values/dictionary/DictionaryValuesReader.java": [
                5,
                14
            ],
            "parquet-column/src/test/java/parquet/column/values/dictionary/TestDictionary.java": [
                0,
                14
            ]
        }
    },
    "f284238631cb1026b4977f6f0b7ef342260d35c5": {
        "datetime": "2014-07-18T18:35:12-07:00",
        "summary": "PARQUET-22: Backport of HIVE-6938 adding rename support for parquet",
        "message": "PARQUET-22: Backport of HIVE-6938 adding rename support for parquet\n\nThis patch was included in hive after the moving the Serde to hive (included in hive 0.14+).  Backport is required for use with previous versions.\n\nAuthor: Daniel Weeks <dweeks@netflix.com>\n\nCloses #13 from dcw-netflix/backport-hive-6938-rename and squashes the following commits:\n\n453367b [Daniel Weeks] Backport of HIVE-6938 adding rename support for parquet\n",
        "diff": {
            "parquet-hive/parquet-hive-storage-handler/src/main/java/org/apache/hadoop/hive/ql/io/parquet/read/DataWritableReadSupport.java": [
                3,
                28
            ]
        }
    },
    "4a07b3f545aaf60f0b1d6bba91ee22d214dfaff8": {
        "datetime": "2014-07-23T14:29:35+01:00",
        "summary": "PARQUET-25. Pushdown predicates only work with hardcoded arguments.",
        "message": "PARQUET-25. Pushdown predicates only work with hardcoded arguments.\n\nPull request for Sandy Ryza's fix for PARQUET-25.\n\nAuthor: Sandy Ryza <sandy.ryza@cloudera.com>\n\nCloses #22 from tomwhite/PARQUET-25-unbound-record-filter-configurable and squashes the following commits:\n\na9d3fdc [Sandy Ryza] PARQUET-25. Pushdown predicates only work with hardcoded arguments.\n",
        "diff": {
            "parquet-hadoop/src/main/java/parquet/hadoop/ParquetInputFormat.java": [
                3,
                9
            ]
        }
    },
    "17864dfc0711d52d5af330469a1c2bd76128d46e": {
        "datetime": "2014-07-28T18:07:07-07:00",
        "summary": "Column index access support",
        "message": "Column index access support\n\nThis patch adds the ability to use column index based access to parquet files in pig, which allows for rename capability similar to other file formats.  This is achieved by using the parametrized loader with an alternate schema.\n\nExample:\n# File Schema: {c1:int, c2:float, c3:chararray}\np = LOAD '/data/parquet/' USING parquet.pig.ParquetLoader('n1:int, n2:float, n3:chararray', 'true');\n\nIn this example, the names from the requested schema will be translated to the column positions from the file and will produce tuples based on the index position.\n\nTwo test cases are included that exercise index based access for both full file reads and column projected reads.\n\nNote:  This patch also disables the enforcer plugin on the pig project per discussion at the parquet meetup.  The justification for this is that the enforcer is too strict for internal classes and results in dead code because duplicating methods is required to add parameters where there is only one usage of the constructor/method.  The interface for the pig loader is imposed by LoadFunc and StoreFunc by the pig project and the implementations internals should not be used directly.\n\nAuthor: Daniel Weeks <dweeks@netflix.com>\n\nCloses #12 from dcw-netflix/column-index-access and squashes the following commits:\n\n1b5c5cf [Daniel Weeks] Refactored based on rewview comments\n12b53c1 [Daniel Weeks] Fixed some formatting and the missing filter method sig\ne5553f1 [Daniel Weeks] Adding back default constructor to satisfy other project requirements\n69d21e0 [Daniel Weeks] Merge branch 'master' into column-index-access\nf725c6f [Daniel Weeks] Removed enforcer for pig support\nd182dc6 [Daniel Weeks] Introduces column index access\n1c3c0c7 [Daniel Weeks] Fixed test with strict checking off\nf3cb495 [Daniel Weeks] Added type persuasion for primitive types with a flag to control strict type checking for conflicting schemas, which is strict by default.\n",
        "diff": {
            "parquet-pig/pom.xml": null,
            "parquet-pig/src/main/java/parquet/pig/ParquetLoader.java": [
                1,
                54
            ],
            "parquet-pig/src/main/java/parquet/pig/PigSchemaConverter.java": [
                21,
                107
            ],
            "parquet-pig/src/main/java/parquet/pig/TupleReadSupport.java": [
                9,
                34
            ],
            "parquet-pig/src/main/java/parquet/pig/TupleWriteSupport.java": [
                1,
                1
            ],
            "parquet-pig/src/main/java/parquet/pig/convert/MapConverter.java": [
                5,
                5
            ],
            "parquet-pig/src/main/java/parquet/pig/convert/TupleConverter.java": [
                12,
                25
            ],
            "parquet-pig/src/main/java/parquet/pig/convert/TupleRecordMaterializer.java": [
                1,
                5
            ],
            "parquet-pig/src/test/java/parquet/pig/TestParquetLoader.java": [
                0,
                74
            ],
            "parquet-pig/src/test/java/parquet/pig/TestPigSchemaConverter.java": [
                1,
                1
            ]
        }
    },
    "fc2c29df71c8455346a00b43dd1c4f118c335d2c": {
        "datetime": "2014-07-29T10:15:42-07:00",
        "summary": "PARQUET-19: Fix NPE when an empty file is included in a Hive query that uses CombineHiveInputFormat",
        "message": "PARQUET-19: Fix NPE when an empty file is included in a Hive query that uses CombineHiveInputFormat\n\nMake sure the valueObj instance variable is always initialized.  This change is neeeded when running a Hive query that uses the CombineHiveInputFormat and the first file in the combined split is empty.  This can lead to a NullPointerException because the valueObj is null when the CombineHiveInputFormat calls the createValue method.\n\nAuthor: Matthieu Martin <ma.tt.b.ma.rt.in+parquet@gmail.com>\n\nCloses #19 from matt-martin/fix_for_empty_files_NPE_with_CombineHiveInputFormat and squashes the following commits:\n\n6c3a7f5 [Matthieu Martin] Make sure the valueObj instance variable is always initialized.  This change is neeeded when running a Hive query that uses the CombineHiveInputFormat and the first file in the combined split is empty.  This can lead to a NullPointerException because the valueObj is null when the CombineHiveInputFormat calls the createValue method.\n",
        "diff": {
            "parquet-hive/parquet-hive-storage-handler/src/main/java/org/apache/hadoop/hive/ql/io/parquet/read/ParquetRecordReaderWrapper.java": [
                3,
                3
            ]
        }
    },
    "ad32bf0fd111ab473ad1080cde11de39e3c5a67f": {
        "datetime": "2014-07-29T14:38:59-07:00",
        "summary": "Add a unified and optionally more constrained API for expressing filters on columns",
        "message": "Add a unified and optionally more constrained API for expressing filters on columns\n\nThis is a re-opened version of:\nhttps://github.com/Parquet/parquet-mr/pull/412\n\nThe idea behind this pull request is to add a way to express filters on columns using DSL that allows parquet visibility into what is being filtered and how. This visibility will allow us to make optimizations at read time, the biggest one being filtering entire row groups or pages of records without even reading them based on the statistics / metadata that is stored along with each row group or page.\n\nIncluded in this api are interfaces for user defined predicates, which must operate at the value level by may opt in to operating at the row group / page level as well. This should make this new API a superset of the `parquet.filter` package. This new api will need to be reconciled with the column filters currently in the `parquet.filter` package, but I wanted to get feedback on this first.\n\nA limitation in both this api and the old one is that you can't do cross-column filters, eg: columX > columnY.\n\nAuthor: Alex Levenson <alexlevenson@twitter.com>\n\nCloses #4 from isnotinvain/alexlevenson/filter-api and squashes the following commits:\n\nc1ab7e3 [Alex Levenson] Address feedback\nc1bd610 [Alex Levenson] cleanup dotString in ColumnPath\n418bfc1 [Alex Levenson] Update version, add temporary hacks for semantic enforcer\n6643bd3 [Alex Levenson] Fix some more non backward incompatible changes\n39f977f [Alex Levenson] Put a bunch of backwards compatible stuff back in, add @Deprecated\n13a02c6 [Alex Levenson] Fix compile errors, add back in overloaded getRecordReader\nf82edb7 [Alex Levenson] Merge branch 'master' into alexlevenson/filter-api\n9bd014f [Alex Levenson] clean up TODOs and reference jiras\n4cc7e87 [Alex Levenson] Add some comments\n30e3d61 [Alex Levenson] Create a common interface for both kinds of filters\nac153a6 [Alex Levenson] Create a Statistics class for use in UDPs\nfbbf601 [Alex Levenson] refactor IncrementallyUpdatedFilterPredicateGenerator to only generate the parts that require generation\n5df47cd [Alex Levenson] Static imports of checkNotNull\nc1d1823 [Alex Levenson] address some of the minor feedback items\n67a3ba0 [Alex Levenson] update binary's toString\n3d7372b [Alex Levenson] minor fixes\nfed9531 [Alex Levenson] Add skipCurrentRecord method to clear events in thrift converter\n2e632d5 [Alex Levenson] Make Binary Serializable\n09c024f [Alex Levenson] update comments\n3169849 [Alex Levenson] fix compilation error\n0185030 [Alex Levenson] Add integration test for value level filters\n4fde18c [Alex Levenson] move to right package\nae36b37 [Alex Levenson] Handle merge issues\naf69486 [Alex Levenson] Merge branch 'master' into alexlevenson/filter-api\n0665271 [Alex Levenson] Add tests for value inspector\nc5e3b07 [Alex Levenson] Add tests for resetter and evaluator\n29f677a [Alex Levenson] Fix scala DSL\n8897a28 [Alex Levenson] Fix some tests\nb448bee [Alex Levenson] Fix mistake in MessageColumnIO\nc8133f8 [Alex Levenson] Fix some tests\n4cf686d [Alex Levenson] more null checks\n69e683b [Alex Levenson] check all the nulls\n220a682 [Alex Levenson] more cleanup\naad5af3 [Alex Levenson] rm generated src file from git\n5075243 [Alex Levenson] more minor cleanup\n9966713 [Alex Levenson] Hook generation into maven build\n8282725 [Alex Levenson] minor cleanup\nfea3ea9 [Alex Levenson] minor cleanup\n9e35406 [Alex Levenson] move statistics filter\nc52750c [Alex Levenson] finish moving things around\n97a6bfd [Alex Levenson] Move things around pt2\n843b9fe [Alex Levenson] Move some files around pt 1\n5eedcc0 [Alex Levenson] turn off dictionary support for AtomicConverter\n541319e [Alex Levenson] various cleanup and fixes\n08e9638 [Alex Levenson] rm ColumnPathUtil\nbfe6795 [Alex Levenson] Add type bounds to FilterApi\n6c831ab [Alex Levenson] don't double log exception in SerializationUtil\na7a58d1 [Alex Levenson] use ColumnPath instead of String\n8f11a6b [Alex Levenson] Move ColumnPath and Canonicalizer to parquet-common\n9164359 [Alex Levenson] stash\nabc2be2 [Alex Levenson] Add null handling to record filters -- this impl is still broken though\n90ba8f7 [Alex Levenson] Update Serialization Util\n0a261f1 [Alex Levenson] Add compression in SerializationUtil\nf1278be [Alex Levenson] Add comment, fix tests\ncbd1a85 [Alex Levenson] Replace some specialization with generic views\ne496cbf [Alex Levenson] Fix short circuiting in StatisticsFilter\ndb6b32d [Alex Levenson] Address some comments, fix constructor in ParquetReader\nfd6f44d [Alex Levenson] Fix semver backward compat\n2fdd304 [Alex Levenson] Some more cleanup\nd34fb89 [Alex Levenson] Cleanup some TODOs\n544499c [Alex Levenson] stash\n7b32016 [Alex Levenson] Merge branch 'master' into alexlevenson/filter-api\n0e31251 [Alex Levenson] First pass at values filter, needs reworking\n470e409 [Alex Levenson] fix java6/7 bug, minor cleanup\nee7b221 [Alex Levenson] more InputFormat tests\n5ef849e [Alex Levenson] Add guards for not specifying both kinds of filter\n0186b1f [Alex Levenson] Add logging to ParquetInputFormat and tests for configuration\na622648 [Alex Levenson] cleanup imports\n9b1ea88 [Alex Levenson] Add tests for statistics filter\nd517373 [Alex Levenson] tests for filter validator\nb25fc44 [Alex Levenson] small cleanup of filter validator\n32067a1 [Alex Levenson] add test for collapse logical nots\n1efc198 [Alex Levenson] Add tests for invert filter predicate\n046b106 [Alex Levenson] some more fixes\nd3c4d7a [Alex Levenson] fix some more types, add in test for SerializationUtil\ncc51274 [Alex Levenson] fix generics in FilterPredicateInverter\nea08349 [Alex Levenson] First pass at rowgroup filter, needs testing\n156d91b [Alex Levenson] Add runtime type checker\n4dfb4f2 [Alex Levenson] Add serialization util\n8f80b20 [Alex Levenson] update comment\n7c25121 [Alex Levenson] Add class to Column struct\n58f1190 [Alex Levenson] Remove filterByUniqueValues\n7f20de6 [Alex Levenson] rename user predicates\naf14b42 [Alex Levenson] Update dsl\n04409c5 [Alex Levenson] Add generic types into Visitor\nba42884 [Alex Levenson] rm getClassName\n65f8af9 [Alex Levenson] Add in support for user defined predicates on columns\n6926337 [Alex Levenson] Add explicit tokens for notEq, ltEq, gtEq\n667ec9f [Alex Levenson] remove test for collapsing double negation\ndb2f71a [Alex Levenson] rename FilterPredicatesTest\na0a0533 [Alex Levenson] Address first round of comments\nb2bca94 [Alex Levenson] Add scala DSL and tests\nbedda87 [Alex Levenson] Add tests for FilterPredicate building\n238cbbe [Alex Levenson] Add scala dsl\n39f7b24 [Alex Levenson] add scala mvn boilerplate\n2ec71a7 [Alex Levenson] Add predicate API\n",
        "diff": {
            "parquet-avro/pom.xml": null,
            "parquet-avro/src/main/java/parquet/avro/AvroParquetReader.java": [
                11,
                28
            ],
            "parquet-cascading/pom.xml": null,
            "parquet-column/pom.xml": null,
            "parquet-column/src/main/java/parquet/column/statistics/BinaryStatistics.java": [
                1,
                11
            ],
            "parquet-column/src/main/java/parquet/column/statistics/BooleanStatistics.java": [
                1,
                11
            ],
            "parquet-column/src/main/java/parquet/column/statistics/DoubleStatistics.java": [
                1,
                11
            ],
            "parquet-column/src/main/java/parquet/column/statistics/FloatStatistics.java": [
                1,
                11
            ],
            "parquet-column/src/main/java/parquet/column/statistics/IntStatistics.java": [
                1,
                11
            ],
            "parquet-column/src/main/java/parquet/column/statistics/LongStatistics.java": [
                1,
                11
            ],
            "parquet-column/src/main/java/parquet/column/statistics/Statistics.java": [
                1,
                4
            ],
            "parquet-column/src/main/java/parquet/filter2/compat/FilterCompat.java": [
                0,
                140
            ],
            "parquet-column/src/main/java/parquet/filter2/predicate/FilterApi.java": [
                0,
                177
            ],
            "parquet-column/src/main/java/parquet/filter2/predicate/FilterPredicate.java": [
                0,
                54
            ],
            "parquet-column/src/main/java/parquet/filter2/predicate/LogicalInverseRewriter.java": [
                0,
                95
            ],
            "parquet-column/src/main/java/parquet/filter2/predicate/LogicalInverter.java": [
                0,
                90
            ],
            "parquet-column/src/main/java/parquet/filter2/predicate/Operators.java": [
                0,
                455
            ],
            "parquet-column/src/main/java/parquet/filter2/predicate/SchemaCompatibilityValidator.java": [
                0,
                172
            ],
            "parquet-column/src/main/java/parquet/filter2/predicate/Statistics.java": [
                0,
                24
            ],
            "parquet-column/src/main/java/parquet/filter2/predicate/UserDefinedPredicate.java": [
                0,
                90
            ],
            "parquet-column/src/main/java/parquet/filter2/predicate/ValidTypeMap.java": [
                0,
                160
            ],
            "parquet-column/src/main/java/parquet/filter2/recordlevel/FilteringGroupConverter.java": [
                0,
                97
            ],
            "parquet-column/src/main/java/parquet/filter2/recordlevel/FilteringPrimitiveConverter.java": [
                0,
                91
            ],
            "parquet-column/src/main/java/parquet/filter2/recordlevel/FilteringRecordMaterializer.java": [
                0,
                97
            ],
            "parquet-column/src/main/java/parquet/filter2/recordlevel/IncrementallyUpdatedFilterPredicate.java": [
                0,
                139
            ],
            "parquet-column/src/main/java/parquet/filter2/recordlevel/IncrementallyUpdatedFilterPredicateBuilderBase.java": [
                0,
                79
            ],
            "parquet-column/src/main/java/parquet/filter2/recordlevel/IncrementallyUpdatedFilterPredicateEvaluator.java": [
                0,
                45
            ],
            "parquet-column/src/main/java/parquet/filter2/recordlevel/IncrementallyUpdatedFilterPredicateResetter.java": [
                0,
                42
            ],
            "parquet-column/src/main/java/parquet/io/FilteredRecordReader.java": [
                0,
                6
            ],
            "parquet-column/src/main/java/parquet/io/MessageColumnIO.java": [
                22,
                76
            ],
            "parquet-column/src/main/java/parquet/io/RecordReader.java": [
                1,
                8
            ],
            "parquet-column/src/main/java/parquet/io/RecordReaderImplementation.java": [
                1,
                13
            ],
            "parquet-column/src/main/java/parquet/io/api/Binary.java": [
                227,
                287
            ],
            "parquet-column/src/main/java/parquet/io/api/RecordMaterializer.java": [
                0,
                5
            ],
            "parquet-column/src/test/java/parquet/filter2/predicate/DummyUdp.java": [
                0,
                19
            ],
            "parquet-column/src/test/java/parquet/filter2/predicate/TestFilterApiMethods.java": [
                0,
                103
            ],
            "parquet-column/src/test/java/parquet/filter2/predicate/TestLogicalInverseRewriter.java": [
                0,
                85
            ],
            "parquet-column/src/test/java/parquet/filter2/predicate/TestLogicalInverter.java": [
                0,
                76
            ],
            "parquet-column/src/test/java/parquet/filter2/predicate/TestSchemaCompatibilityValidator.java": [
                0,
                124
            ],
            "parquet-column/src/test/java/parquet/filter2/predicate/TestValidTypeMap.java": [
                0,
                93
            ],
            "parquet-column/src/test/java/parquet/filter2/recordlevel/TestIncrementallyUpdatedFilterPredicateEvaluator.java": [
                0,
                191
            ],
            "parquet-column/src/test/java/parquet/filter2/recordlevel/TestIncrementallyUpdatedFilterPredicateResetter.java": [
                0,
                51
            ],
            "parquet-column/src/test/java/parquet/filter2/recordlevel/TestValueInspector.java": [
                0,
                79
            ],
            "parquet-column/src/test/java/parquet/io/TestFiltered.java": [
                31,
                31
            ],
            "parquet-common/pom.xml": null,
            "parquet-common/src/main/java/parquet/Closeables.java": [
                0,
                37
            ],
            "parquet-encoding/pom.xml": null,
            "parquet-generator/pom.xml": null,
            "parquet-generator/src/main/java/parquet/encoding/Generator.java": [
                1,
                1
            ],
            "parquet-generator/src/main/java/parquet/filter2/Generator.java": [
                0,
                10
            ],
            "parquet-generator/src/main/java/parquet/filter2/IncrementallyUpdatedFilterPredicateGenerator.java": [
                0,
                251
            ],
            "parquet-hadoop-bundle/pom.xml": null,
            "parquet-hadoop/pom.xml": null,
            "parquet-hadoop/src/main/java/parquet/filter2/compat/RowGroupFilter.java": [
                0,
                63
            ],
            "parquet-hadoop/src/main/java/parquet/filter2/statisticslevel/StatisticsFilter.java": [
                0,
                244
            ],
            "parquet-hadoop/src/main/java/parquet/format/converter/ParquetMetadataConverter.java": [
                6,
                6
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/InternalParquetRecordReader.java": [
                19,
                42
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/ParquetFileReader.java": [
                6,
                6
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/ParquetFileWriter.java": [
                4,
                4
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/ParquetInputFormat.java": [
                19,
                99
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/ParquetInputSplit.java": [
                1,
                1
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/ParquetReader.java": [
                22,
                74
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/ParquetRecordReader.java": [
                5,
                19
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/ParquetWriter.java": [
                0,
                13
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/mapred/DeprecatedParquetInputFormat.java": [
                8,
                5
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/metadata/Canonicalizer.java": [
                1,
                1
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/metadata/ColumnChunkMetaData.java": [
                1,
                2
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/metadata/ColumnChunkProperties.java": [
                0,
                2
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/metadata/ColumnPath.java": [
                2,
                25
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/metadata/EncodingList.java": [
                0,
                1
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/util/SerializationUtil.java": [
                0,
                93
            ],
            "parquet-hadoop/src/test/java/parquet/filter2/compat/TestRowGroupFilter.java": [
                0,
                84
            ],
            "parquet-hadoop/src/test/java/parquet/filter2/recordlevel/PhoneBookWriter.java": [
                0,
                251
            ],
            "parquet-hadoop/src/test/java/parquet/filter2/recordlevel/TestRecordLevelFilters.java": [
                0,
                205
            ],
            "parquet-hadoop/src/test/java/parquet/filter2/statisticslevel/TestStatisticsFilter.java": [
                0,
                307
            ],
            "parquet-hadoop/src/test/java/parquet/hadoop/TestInputFormat.java": [
                10,
                100
            ],
            "parquet-hadoop/src/test/java/parquet/hadoop/metadata/TestColumnChunkMetaData.java": [
                4,
                5
            ],
            "parquet-hadoop/src/test/java/parquet/hadoop/util/TestSerializationUtil.java": [
                0,
                53
            ],
            "parquet-hive-bundle/pom.xml": null,
            "parquet-hive/parquet-hive-binding/parquet-hive-0.10-binding/pom.xml": null,
            "parquet-hive/parquet-hive-binding/parquet-hive-0.12-binding/pom.xml": null,
            "parquet-hive/parquet-hive-binding/parquet-hive-binding-bundle/pom.xml": null,
            "parquet-hive/parquet-hive-binding/parquet-hive-binding-factory/pom.xml": null,
            "parquet-hive/parquet-hive-binding/parquet-hive-binding-interface/pom.xml": null,
            "parquet-hive/parquet-hive-binding/pom.xml": null,
            "parquet-hive/parquet-hive-storage-handler/pom.xml": null,
            "parquet-hive/pom.xml": null,
            "parquet-jackson/pom.xml": null,
            "parquet-pig-bundle/pom.xml": null,
            "parquet-pig/pom.xml": null,
            "parquet-protobuf/pom.xml": null,
            "parquet-protobuf/src/main/java/parquet/proto/ProtoParquetReader.java": [
                4,
                19
            ],
            "parquet-scala/pom.xml": null,
            "parquet-scala/src/main/scala/parquet/filter2/dsl/Dsl.scala": null,
            "parquet-scala/src/test/scala/parquet/filter2/dsl/DslTest.scala": null,
            "parquet-scrooge/pom.xml": null,
            "parquet-test-hadoop2/pom.xml": null,
            "parquet-thrift/pom.xml": null,
            "parquet-thrift/src/main/java/parquet/thrift/ThriftParquetReader.java": [
                1,
                63
            ],
            "parquet-thrift/src/main/java/parquet/thrift/ThriftRecordConverter.java": [
                0,
                5
            ],
            "parquet-tools/pom.xml": null,
            "parquet-tools/src/main/java/parquet/tools/command/DumpCommand.java": [
                1,
                0
            ],
            "pom.xml": null
        }
    },
    "b0e26ee6f20a00a0d0769408575744c51a016018": {
        "datetime": "2014-07-30T13:49:00-07:00",
        "summary": "Only call put() when needed in SchemaCompatibilityValidator#validateColumn()",
        "message": "Only call put() when needed in SchemaCompatibilityValidator#validateColumn()\n\nThis is some minor cleanup suggested by @tsdeng\n\nAuthor: Alex Levenson <alexlevenson@twitter.com>\n\nCloses #24 from isnotinvain/alexlevenson/columnTypesEncountered and squashes the following commits:\n\n7f05d90 [Alex Levenson] Only call put() when needed in SchemaCompatibilityValidator#validateColumn()\n",
        "diff": {
            "parquet-column/src/main/java/parquet/filter2/predicate/SchemaCompatibilityValidator.java": [
                1,
                4
            ]
        }
    },
    "21d871b54940ad8e552fac54808fe0b31872ade8": {
        "datetime": "2014-07-30T14:19:00-07:00",
        "summary": "PARQUET-56: Added an accessor for the Long column type.",
        "message": "PARQUET-56: Added an accessor for the Long column type.\n\nI noticed there was a missing accessor for the Long column type in the example Group.\n\nAuthor: James Scott <jim.scott@urbanairship.com>\n\nCloses #25 from scottjab/getLong and squashes the following commits:\n\nf96bb83 [James Scott] Added support for getting Longs in the sample group object.\n",
        "diff": {
            "parquet-column/src/main/java/parquet/example/data/GroupValueSource.java": [
                0,
                6
            ],
            "parquet-column/src/main/java/parquet/example/data/simple/SimpleGroup.java": [
                0,
                5
            ]
        }
    },
    "0793e49b85d34135fee9f55030997d95f62af97b": {
        "datetime": "2014-07-31T14:57:54-07:00",
        "summary": "PARQUET-57 - Update dev README to clarify two points",
        "message": "PARQUET-57 - Update dev README to clarify two points\n\nAuthor: Brock Noland <brock@apache.org>\n\nCloses #26 from brockn/PARQUET-57 and squashes the following commits:\n\nffb2a9a [Brock Noland] Prompt for jira user/pass if not set\n0135cdd [Brock Noland] Fix spelling\n171d714 [Brock Noland] PARQUET-57 - Update dev README to clarify two points\n",
        "diff": {
            "dev/README.md": null,
            "dev/merge_parquet_pr.py": [
                2,
                8
            ]
        }
    },
    "0148455170be07f89bd6b9230960a6cd510c7ca6": {
        "datetime": "2014-08-01T16:38:03-07:00",
        "summary": "PARQUET-13: The `-d` option for `parquet-schema` shouldn't have optional argument",
        "message": "PARQUET-13: The `-d` option for `parquet-schema` shouldn't have optional argument\n\nAuthor: Cheng Lian <lian.cs.zju@gmail.com>\n\nCloses #11 from liancheng/fix-cli-arg and squashes the following commits:\n\n85a5453 [Cheng Lian] Reverted the dummy change\n47ce817 [Cheng Lian] Dummy change to trigger Travis\n1c0a244 [Cheng Lian] The `-d` option for `parquet-schema` shouldn't have optional argument\n",
        "diff": {
            "parquet-tools/src/main/java/parquet/tools/command/ShowSchemaCommand.java": [
                1,
                0
            ]
        }
    },
    "3a396d3a4000bd2575e5314cdea0ba1e2367804c": {
        "datetime": "2014-08-04T19:04:18-07:00",
        "summary": "PARQUET-59: Fix parquet-scrooge test on hadoop-2.",
        "message": "PARQUET-59: Fix parquet-scrooge test on hadoop-2.\n\nAuthor: Ryan Blue <rblue@cloudera.com>\n\nCloses #27 from rdblue/PARQUET-59-fix-scrooge-test-on-hadoop-2 and squashes the following commits:\n\nac34369 [Ryan Blue] PARQUET-59: Fix parquet-scrooge test on hadoop-2.\n",
        "diff": {
            "parquet-scrooge/src/test/java/parquet/scrooge/ParquetScroogeSchemeTest.java": [
                2,
                2
            ]
        }
    },
    "b86b01b1e4f20b41a10dc77d7d5326890fc27867": {
        "datetime": "2014-08-12T18:03:52-07:00",
        "summary": "[maven-release-plugin] prepare release parquet-1.6.0rc1",
        "message": "[maven-release-plugin] prepare release parquet-1.6.0rc1\n",
        "diff": {
            "parquet-avro/pom.xml": null,
            "parquet-cascading/pom.xml": null,
            "parquet-column/pom.xml": null,
            "parquet-common/pom.xml": null,
            "parquet-encoding/pom.xml": null,
            "parquet-generator/pom.xml": null,
            "parquet-hadoop-bundle/pom.xml": null,
            "parquet-hadoop/pom.xml": null,
            "parquet-hive-bundle/pom.xml": null,
            "parquet-hive/parquet-hive-binding/parquet-hive-0.10-binding/pom.xml": null,
            "parquet-hive/parquet-hive-binding/parquet-hive-0.12-binding/pom.xml": null,
            "parquet-hive/parquet-hive-binding/parquet-hive-binding-bundle/pom.xml": null,
            "parquet-hive/parquet-hive-binding/parquet-hive-binding-factory/pom.xml": null,
            "parquet-hive/parquet-hive-binding/parquet-hive-binding-interface/pom.xml": null,
            "parquet-hive/parquet-hive-binding/pom.xml": null,
            "parquet-hive/parquet-hive-storage-handler/pom.xml": null,
            "parquet-hive/pom.xml": null,
            "parquet-jackson/pom.xml": null,
            "parquet-pig-bundle/pom.xml": null,
            "parquet-pig/pom.xml": null,
            "parquet-protobuf/pom.xml": null,
            "parquet-scala/pom.xml": null,
            "parquet-scrooge/pom.xml": null,
            "parquet-test-hadoop2/pom.xml": null,
            "parquet-thrift/pom.xml": null,
            "parquet-tools/pom.xml": null,
            "pom.xml": null
        }
    },
    "08a3c6a7dd41f02bb0c876829c01392e6f2d09a2": {
        "datetime": "2014-08-12T18:03:56-07:00",
        "summary": "[maven-release-plugin] prepare for next development iteration",
        "message": "[maven-release-plugin] prepare for next development iteration\n",
        "diff": {
            "parquet-avro/pom.xml": null,
            "parquet-cascading/pom.xml": null,
            "parquet-column/pom.xml": null,
            "parquet-common/pom.xml": null,
            "parquet-encoding/pom.xml": null,
            "parquet-generator/pom.xml": null,
            "parquet-hadoop-bundle/pom.xml": null,
            "parquet-hadoop/pom.xml": null,
            "parquet-hive-bundle/pom.xml": null,
            "parquet-hive/parquet-hive-binding/parquet-hive-0.10-binding/pom.xml": null,
            "parquet-hive/parquet-hive-binding/parquet-hive-0.12-binding/pom.xml": null,
            "parquet-hive/parquet-hive-binding/parquet-hive-binding-bundle/pom.xml": null,
            "parquet-hive/parquet-hive-binding/parquet-hive-binding-factory/pom.xml": null,
            "parquet-hive/parquet-hive-binding/parquet-hive-binding-interface/pom.xml": null,
            "parquet-hive/parquet-hive-binding/pom.xml": null,
            "parquet-hive/parquet-hive-storage-handler/pom.xml": null,
            "parquet-hive/pom.xml": null,
            "parquet-jackson/pom.xml": null,
            "parquet-pig-bundle/pom.xml": null,
            "parquet-pig/pom.xml": null,
            "parquet-protobuf/pom.xml": null,
            "parquet-scala/pom.xml": null,
            "parquet-scrooge/pom.xml": null,
            "parquet-test-hadoop2/pom.xml": null,
            "parquet-thrift/pom.xml": null,
            "parquet-tools/pom.xml": null,
            "pom.xml": null
        }
    },
    "0d497c4547934485f2aa9e2e9ead46f26fab7bd2": {
        "datetime": "2014-08-18T10:38:11-07:00",
        "summary": "PARQUET-73: Add support for FilterPredicates to cascading schemes",
        "message": "PARQUET-73: Add support for FilterPredicates to cascading schemes\n\nAuthor: Alex Levenson <alexlevenson@twitter.com>\n\nCloses #34 from isnotinvain/alexlevenson/filter-cascading-scheme and squashes the following commits:\n\ncd69a8e [Alex Levenson] Add support for FilterPredicates to cascading schemes\n",
        "diff": {
            "parquet-cascading/src/main/java/parquet/cascading/ParquetTBaseScheme.java": [
                2,
                14
            ],
            "parquet-cascading/src/main/java/parquet/cascading/ParquetTupleScheme.java": [
                24,
                45
            ],
            "parquet-cascading/src/main/java/parquet/cascading/ParquetValueScheme.java": [
                4,
                23
            ],
            "parquet-scala/src/main/scala/parquet/filter2/dsl/Dsl.scala": null,
            "parquet-scrooge/src/main/java/parquet/scrooge/ParquetScroogeScheme.java": [
                5,
                11
            ]
        }
    },
    "7af955a0ac0182deca139e4a15352ce702691dd4": {
        "datetime": "2014-08-20T13:47:04-07:00",
        "summary": "PARQUET-50: Re-Enable the semver enforcer",
        "message": "PARQUET-50: Re-Enable the semver enforcer\n\nAuthor: Alex Levenson <alexlevenson@twitter.com>\n\nCloses #37 from isnotinvain/alexlevenson/fix-backwards-compat-check and squashes the following commits:\n\nc91335c [Alex Levenson] Bump version to 1.6.1 to make semver enforcer happy\nc09c8c1 [Alex Levenson] PARQUET-50: Re-Enable the semver enforcer\n",
        "diff": {
            "parquet-avro/pom.xml": null,
            "parquet-cascading/pom.xml": null,
            "parquet-column/pom.xml": null,
            "parquet-common/pom.xml": null,
            "parquet-encoding/pom.xml": null,
            "parquet-generator/pom.xml": null,
            "parquet-hadoop-bundle/pom.xml": null,
            "parquet-hadoop/pom.xml": null,
            "parquet-hive-bundle/pom.xml": null,
            "parquet-hive/parquet-hive-binding/parquet-hive-0.10-binding/pom.xml": null,
            "parquet-hive/parquet-hive-binding/parquet-hive-0.12-binding/pom.xml": null,
            "parquet-hive/parquet-hive-binding/parquet-hive-binding-bundle/pom.xml": null,
            "parquet-hive/parquet-hive-binding/parquet-hive-binding-factory/pom.xml": null,
            "parquet-hive/parquet-hive-binding/parquet-hive-binding-interface/pom.xml": null,
            "parquet-hive/parquet-hive-binding/pom.xml": null,
            "parquet-hive/parquet-hive-storage-handler/pom.xml": null,
            "parquet-hive/pom.xml": null,
            "parquet-jackson/pom.xml": null,
            "parquet-pig-bundle/pom.xml": null,
            "parquet-pig/pom.xml": null,
            "parquet-protobuf/pom.xml": null,
            "parquet-scala/pom.xml": null,
            "parquet-scrooge/pom.xml": null,
            "parquet-test-hadoop2/pom.xml": null,
            "parquet-thrift/pom.xml": null,
            "parquet-tools/pom.xml": null,
            "pom.xml": null
        }
    },
    "7b415faaed09eba1103ea30577ef1a32fba7048c": {
        "datetime": "2014-08-20T13:52:42-07:00",
        "summary": "Parquet-70: Fixed storing pig schema to udfcontext for non projection case and moved...",
        "message": "Parquet-70: Fixed storing pig schema to udfcontext for non projection case and moved...\n\n... column index access setting to udfcontext so as not to affect other loaders.\n\nI found an problem that affects both the Column name access and column index access due to the way the pig schema is stored by the loader.\n\n##Column Name Access:\nThe ParquetLoader was only storing the pig schema in the UDFContext when push projection is applied.  In the full load case, the schema was not stored which triggered a full reload of the schema during task execution.  You can see in initSchema references the UDFContext for the schema, but that is only set in push projection.  However, the schema needs to be set in both the job context (so the TupleReadSupport can access the schema) and the UDFContext (so the task side loader can access it), which is why it is set in both locations.  This also meant the requested schema was never set to the task side either, which could cause other problems as well.\n\n##Column Index Access:\nFor index based access, the problem was that the column index access setting and the requested schema were not stored in the udfcontext and sent to the task side (unless pushProjection was called).  The schema was stored in the job context, but this would be overwritten if another loader was executed first.  Also, the property to use column index access was only being set at the job context level, so subsequent loaders would use column index access even if they didn't request it.\n\nThis fix now ensures that both the schema and column index access are set in the udfcontext and loaded in the initSchema method.\n\nJIRA: https://issues.apache.org/jira/browse/PARQUET-70\n\n-Dan\n\nAuthor: Daniel Weeks <dweeks@netflix.com>\n\nCloses #36 from dcw-netflix/pig-schema-context and squashes the following commits:\n\nf896a25 [Daniel Weeks] Moved property loading into setInput\n8f3dc28 [Daniel Weeks] Changed to set job conf settings in both front and backend\nd758de0 [Daniel Weeks] Updated to use isFrontend() for setting context properties\nb7ef96a [Daniel Weeks] Fixed storing pig schema to udfcontext for non projection case and moved column index access setting to udfcontext so as not to affect other loaders.\n",
        "diff": {
            "parquet-pig/src/main/java/parquet/pig/ParquetLoader.java": [
                12,
                23
            ]
        }
    },
    "45e581028ab60949b0303d4a0cfe4eee077bcce8": {
        "datetime": "2014-08-20T14:01:03-07:00",
        "summary": "PARQUET-69: Committer doc",
        "message": "PARQUET-69: Committer doc\n\nIn order to improve turnaround time on reviewing pull requests here are a few guidelines and informations.\n\nAuthor: Julien Le Dem <julien@twitter.com>\n\nCloses #23 from julienledem/committer_doc and squashes the following commits:\n\nd4b2e19 [Julien Le Dem] Update REVIEWERS.md\nf7d8a5e [Julien Le Dem] Update COMMITTERS.md\nb627d50 [Julien Le Dem] Create REVIEWERS.md\n0027a98 [Julien Le Dem] Create REVIEWERS.md\n6fd49d0 [Julien Le Dem] Create REVIEWERS.md\nc6c26e6 [Julien Le Dem] Create REVIEWERS.md\ncbbec60 [Julien Le Dem] Create REVIEWERS.md\n56b7d3d [Julien Le Dem] Create REVIEWERS.md\na93ddcb [Julien Le Dem] Create REVIEWERS.md\n98f1e52 [Julien Le Dem] Create REVIEWERS.md\n5d960f4 [Julien Le Dem] Update COMMITTERS.md\n7be5f36 [Julien Le Dem] Create REVIEWERS.md\n24ef829 [Julien Le Dem] Create REVIEWERS.md\n799a067 [Julien Le Dem] Create REVIEWERS.md\n8ef1250 [Julien Le Dem] Create REVIEWERS.md\nb85f454 [Julien Le Dem] Create REVIEWERS.md\n38d1afa [Julien Le Dem] Update COMMITTERS.md\n425224d [Julien Le Dem] Update COMMITTERS.md\n46249ed [Julien Le Dem] Update COMMITTERS.md\n7879de2 [Julien Le Dem] Create COMMITTERS.md\n",
        "diff": {
            "dev/COMMITTERS.md": null,
            "parquet-avro/REVIEWERS.md": null,
            "parquet-cascading/REVIEWERS.md": null,
            "parquet-column/REVIEWERS.md": null,
            "parquet-common/REVIEWERS.md": null,
            "parquet-encoding/REVIEWERS.md": null,
            "parquet-generator/REVIEWERS.md": null,
            "parquet-hadoop/REVIEWERS.md": null,
            "parquet-hive/REVIEWERS.md": null,
            "parquet-pig/REVIEWERS.md": null,
            "parquet-protobuf/REVIEWERS.md": null,
            "parquet-scrooge/REVIEWERS.md": null,
            "parquet-thrift/REVIEWERS.md": null,
            "parquet-tools/REVIEWERS.md": null
        }
    },
    "54bb983271adcbcc1519ab9e2288871d69093708": {
        "datetime": "2014-08-20T14:02:01-07:00",
        "summary": "PARQUET-62: Fix binary dictionary write bug.",
        "message": "PARQUET-62: Fix binary dictionary write bug.\n\nThe binary dictionary writers keep track of written values in memory to\ndeduplicate and write dictionary pages periodically. If the written\nvalues are changed by the caller, then this corrupts the dictionary\nwithout an error message. This adds a defensive copy to fix the problem.\n\nAuthor: Ryan Blue <rblue@cloudera.com>\n\nCloses #29 from rdblue/PARQUET-62-fix-dictionary-bug and squashes the following commits:\n\n42b6920 [Ryan Blue] PARQUET-62: Fix binary dictionary write bug.\n",
        "diff": {
            "parquet-column/src/main/java/parquet/column/values/dictionary/DictionaryValuesWriter.java": [
                2,
                8
            ],
            "parquet-column/src/test/java/parquet/column/values/dictionary/TestDictionary.java": [
                1,
                30
            ]
        }
    },
    "792b1490db122e953c9120279ddc86407ffae3c0": {
        "datetime": "2014-08-20T14:09:28-07:00",
        "summary": "PARQUET-67: mechanism to add extra metadata in the footer",
        "message": "PARQUET-67: mechanism to add extra metadata in the footer\n\nthis expands on the idea proposed by @wesleypeck in https://github.com/Parquet/parquet-mr/pull/185\n\nAuthor: julien <julien@twitter.com>\n\nCloses #32 from julienledem/extensible_metadata and squashes the following commits:\n\n72e0a50 [julien] mechanism to add extra metadata in the footer\n",
        "diff": {
            "parquet-hadoop/src/main/java/parquet/hadoop/InternalParquetRecordWriter.java": [
                1,
                6
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/ParquetOutputFormat.java": [
                4,
                5
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/api/DelegatingReadSupport.java": [
                0,
                44
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/api/DelegatingWriteSupport.java": [
                0,
                48
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/api/WriteSupport.java": [
                8,
                45
            ],
            "parquet-hadoop/src/test/java/parquet/hadoop/example/TestInputOutputFormat.java": [
                15,
                61
            ]
        }
    },
    "84ebe4c82405895706552ccf1becf6647886663f": {
        "datetime": "2014-08-20T14:09:38-07:00",
        "summary": "PARQUET-66: Upcast blockSize to long to prevent integer overflow.",
        "message": "PARQUET-66: Upcast blockSize to long to prevent integer overflow.\n\nAuthor: Eric Snyder <snyderep@gmail.com>\n\nCloses #33 from snyderep/master and squashes the following commits:\n\nc99802e [Eric Snyder] PARQUET-66: Upcast blockSize to long to prevent integer overflow.\n",
        "diff": {
            "parquet-hadoop/src/main/java/parquet/hadoop/InternalParquetRecordWriter.java": [
                1,
                1
            ]
        }
    },
    "02abe096f293608906d0f06708bfece92156b49a": {
        "datetime": "2014-08-22T15:34:48-07:00",
        "summary": "PARQUET-11: Reduce memory pressure when reading footers",
        "message": "PARQUET-11: Reduce memory pressure when reading footers\n\nbased on https://github.com/apache/incubator-parquet-format/pull/2\n\nAuthor: julien <julien@twitter.com>\nAuthor: Dmitriy Ryaboy <dvryaboy@gmail.com>\n\nCloses #7 from julienledem/reduce_metadata_memory and squashes the following commits:\n\n96ff408 [julien] Merge branch 'master' into reduce_metadata_memory\n1c382cc [julien] implement delegate instead\n7664919 [Dmitriy Ryaboy] intern parquet metadata strings when reading them\n",
        "diff": {
            "src/main/java/parquet/format/InterningProtocol.java": [
                0,
                215
            ],
            "src/main/java/parquet/format/Util.java": [
                4,
                9
            ]
        }
    },
    "8474f6d8142c7d509fa1a459956c6284c0cb3ff2": {
        "datetime": "2014-08-28T10:35:19-07:00",
        "summary": "PARQUET-80: upgrade semver plugin version to 0.9.27",
        "message": "PARQUET-80: upgrade semver plugin version to 0.9.27\n\nTo include the fix in:\nhttps://github.com/jeluard/semantic-versioning/pull/39\n\nAuthor: julien <julien@twitter.com>\n\nCloses #46 from julienledem/upgrade_semver_plugin and squashes the following commits:\n\n30e7247 [julien] upgrade semver plugin version to 0.9.27\n",
        "diff": {
            "pom.xml": null
        }
    },
    "d3cd97a8ad7f1c1df48bf42080d993b861158786": {
        "datetime": "2014-08-28T11:30:50-07:00",
        "summary": "PARQUET-75: Fixed string decode performance issue",
        "message": "PARQUET-75: Fixed string decode performance issue\n\nSwitch to using 'UTF8.decode' as opposed to 'new String'\n\nhttps://issues.apache.org/jira/browse/PARQUET-75\n\nAuthor: Daniel Weeks <dweeks@netflix.com>\n\nCloses #40 from dcw-netflix/string-decode and squashes the following commits:\n\n2cf53e7 [Daniel Weeks] Fixed string decode performance issue\n",
        "diff": {
            "parquet-column/src/main/java/parquet/io/api/Binary.java": [
                2,
                2
            ]
        }
    },
    "7a105068e60b7dd6e9f28dd0ccdb9b696a9bc941": {
        "datetime": "2014-08-28T13:50:00-07:00",
        "summary": "PARQUET-8: bump scrooge-maven-plugin version",
        "message": "PARQUET-8: bump scrooge-maven-plugin version\n\nThis makes eclipse:eclipse target work.\n\nAuthor: dvryaboy <dvryaboy@gmail.com>\nAuthor: Dmitriy Ryaboy <dmitriy@twitter.com>\n\nCloses #41 from dvryaboy/PARQUET-8 and squashes the following commits:\n\nf089bac [dvryaboy] trivial change to retrigger travis build.\nd06a98e [Dmitriy Ryaboy] bump scrooge-maven-plugin version\n",
        "diff": {
            "NOTICE": null,
            "parquet-scrooge/pom.xml": null
        }
    },
    "97964f357e9e6e6eb37fbb83acebf434cd2d7d45": {
        "datetime": "2014-08-29T17:33:19-07:00",
        "summary": "PARQUET-79: add a streaming Thrift API, to enable processing the metadata as we read it and skipping unnecessary fields.",
        "message": "PARQUET-79: add a streaming Thrift API, to enable processing the metadata as we read it and skipping unnecessary fields.\n\nThis pull request provides an API to read thrift in a streaming fashion.\nThis enables ignoring fields that are not needed without loading them into memory.\nIt also aloow treating the data as it comes instead of when it's fully loaded in memory.\n\nAuthor: julien <julien@twitter.com>\n\nCloses #8 from julienledem/streaming_metadata and squashes the following commits:\n\n621769a [julien] cleanup refactoring\na58913d [julien] rename add to consume\ne5c78fc [julien] #simplify\ncb386ce [julien] RIP TypedConsumerProvider, @tsdeng did not like you\n8dd801e [julien] Merge branch 'master' into streaming_metadata\n958726f [julien] javadoc; fix apis\n9be786a [julien] added simple readMetaData method\nbee937a [julien] refactor, cleanup\n6368bdc [julien] streaming thrift reader\n71c85de [julien] first stab\n",
        "diff": {
            "pom.xml": null,
            "src/main/java/parquet/format/Util.java": [
                0,
                142
            ],
            "src/main/java/parquet/format/event/Consumers.java": [
                0,
                181
            ],
            "src/main/java/parquet/format/event/EventBasedThriftReader.java": [
                0,
                111
            ],
            "src/main/java/parquet/format/event/FieldConsumer.java": [
                0,
                25
            ],
            "src/main/java/parquet/format/event/TypedConsumer.java": [
                0,
                186
            ],
            "src/test/java/parquet/format/TestUtil.java": [
                0,
                65
            ]
        }
    },
    "78de104a807504a3597d8c00f0771b42c1a8b810": {
        "datetime": "2014-09-02T17:09:31-07:00",
        "summary": "PARQUET-72: Prepare for Apache release",
        "message": "PARQUET-72: Prepare for Apache release\n\nAdd license headers and other documentation required by the ASF.\n\nThis doesn't update the maven release configuration.\n\nAuthor: Ryan Blue <rblue@cloudera.com>\n\nCloses #6 from rdblue/PARQUET-72-prepare-apache-release and squashes the following commits:\n\ne48a607 [Ryan Blue] Adding NOTICE, DISCLAIMER, and KEYS.\n3d2ca06 [Ryan Blue] Add license headers and enable apache-rat-plugin.\n",
        "diff": {
            "pom.xml": null,
            "src/main/java/parquet/format/InterningProtocol.java": [
                0,
                19
            ],
            "src/main/java/parquet/format/Util.java": [
                0,
                19
            ]
        }
    },
    "f6608e6d64e1fdb2bff7b3957dc06c7aad58b5f0": {
        "datetime": "2014-09-03T09:00:15-07:00",
        "summary": "PARQUET-85: add license headers",
        "message": "PARQUET-85: add license headers\n\nAuthor: julien <julien@twitter.com>\n\nCloses #10 from julienledem/fix_headers and squashes the following commits:\n\ne6922a0 [julien] add license headers\n",
        "diff": {
            "src/main/java/parquet/format/event/Consumers.java": [
                0,
                18
            ],
            "src/main/java/parquet/format/event/EventBasedThriftReader.java": [
                0,
                18
            ],
            "src/main/java/parquet/format/event/FieldConsumer.java": [
                0,
                18
            ],
            "src/main/java/parquet/format/event/TypedConsumer.java": [
                0,
                18
            ],
            "src/test/java/parquet/format/TestUtil.java": [
                0,
                18
            ]
        }
    },
    "f8bc8d1ceb76fc43535ef1fac35ba604d315abf8": {
        "datetime": "2014-09-03T13:42:13-07:00",
        "summary": "PARQUET-72: Update POM to use ASF parent.",
        "message": "PARQUET-72: Update POM to use ASF parent.\n\nAdds the org.apache:apache POM as the parent, which sets up the standard\nApache release configuration, including repositories,\ndistributionManagement, and a release profile. The existing Sonatype\nrelease info is still present and the maven-release-plugin is configured\nto use the Sonatype settings. To move to Apache, remove the\nmaven-release-pluging configuration and the Sonatype profile,\ndistributionManagement, and repositories.\n\nRemoves settings that are supplied by the parent, like encoding\nproperties and plugin versions. Overrides parent settings for compiler\nsource and target versions. Updates scm links.\n\nAdds info for mailing lists and issue tracker.\n\nAuthor: Ryan Blue <rblue@cloudera.com>\n\nCloses #11 from rdblue/PARQUET-72-update-maven-for-release and squashes the following commits:\n\nb8b8048 [Ryan Blue] PARQUET-72: Update POM to use ASF parent.\n",
        "diff": {
            "pom.xml": null
        }
    },
    "149ef7a4d229a5c7b51af98ed14e836bb75ad722": {
        "datetime": "2014-09-03T13:44:32-07:00",
        "summary": "[maven-release-plugin] prepare release parquet-format-2.2.0-rc1",
        "message": "[maven-release-plugin] prepare release parquet-format-2.2.0-rc1\n",
        "diff": {
            "pom.xml": null
        }
    },
    "f2d88f210d21f7363173c1e555a19ccc9561659f": {
        "datetime": "2014-09-03T13:47:29-07:00",
        "summary": "[maven-release-plugin] prepare for next development iteration",
        "message": "[maven-release-plugin] prepare for next development iteration\n",
        "diff": {
            "pom.xml": null
        }
    },
    "f8b06df7a56f92f4bc7dd564ad7ec026e3b4f3da": {
        "datetime": "2014-09-03T15:37:00-07:00",
        "summary": "do ProtocolEvents fixing only when there is required fields missing in the requested schema",
        "message": "do ProtocolEvents fixing only when there is required fields missing in the requested schema\n\nhttps://issues.apache.org/jira/browse/PARQUET-61\nThis PR is trying to redo the https://github.com/apache/incubator-parquet-mr/pull/7\n\nIn this PR, it fixes the protocol event in a more precise condition:\nOnly when the requested schema missing some required fields that are present in the full schema\n\nSo even if there a projection, as long as the projection is not getting rid of the required field, the protocol events amender will not be called.\n\nCould you take a look at this ? @dvryaboy @yan-qi\n\nAuthor: Tianshuo Deng <tdeng@twitter.com>\n\nCloses #28 from tsdeng/fix_protocol_when_required_field_missing and squashes the following commits:\n\nba778b9 [Tianshuo Deng] add continue for readability\nd5639df [Tianshuo Deng] fix unused import\n090e894 [Tianshuo Deng] format\n13a609d [Tianshuo Deng] comment format\nef1fe58 [Tianshuo Deng] little refactor, remove the hasMissingRequiredFieldFromProjection method\n7c2c158 [Tianshuo Deng] format\n83a5655 [Tianshuo Deng] do ProtocolEvents fixing only when there is required fields missing in the requested schema\n",
        "diff": {
            "parquet-thrift/src/main/java/parquet/thrift/ThriftRecordConverter.java": [
                2,
                35
            ]
        }
    },
    "647b8a70f9b7c94cabf9a7ec7bce2e7cbbb4c05b": {
        "datetime": "2014-09-04T11:28:03-07:00",
        "summary": "PARQUET-63: Enable dictionary encoding for FIXED.",
        "message": "PARQUET-63: Enable dictionary encoding for FIXED.\n\nThis uses the existing dictionary support introduced for int96. Encoding\nand ParquetProperties have been updated to use the dictionary supporting\nclasses, when requested for write or present during read. This also\nfixes a bug in the fixed dictionary values writer, where the length was\nhard-coded for int96, 12 bytes.\n\nAuthor: Ryan Blue <rblue@cloudera.com>\n\nCloses #30 from rdblue/PARQUET-63-add-fixed-dictionary-support and squashes the following commits:\n\nbc34a34 [Ryan Blue] PARQUET-63: Enable dictionary encoding for FIXED.\n",
        "diff": {
            "parquet-column/src/main/java/parquet/column/Encoding.java": [
                0,
                3
            ],
            "parquet-column/src/main/java/parquet/column/ParquetProperties.java": [
                1,
                5
            ],
            "parquet-column/src/main/java/parquet/column/values/dictionary/DictionaryValuesWriter.java": [
                1,
                1
            ],
            "parquet-column/src/main/java/parquet/example/data/simple/SimpleGroup.java": [
                0,
                1
            ],
            "parquet-column/src/main/java/parquet/io/ValidatingRecordConsumer.java": [
                17,
                22
            ],
            "parquet-column/src/test/java/parquet/io/TestColumnIO.java": [
                1,
                3
            ]
        }
    },
    "5dafd127f3de7c516ce9c1b7329087a01ab2fc57": {
        "datetime": "2014-09-05T11:32:46-07:00",
        "summary": "PARQUET-84: Avoid reading rowgroup metadata in memory on the client side.",
        "message": "PARQUET-84: Avoid reading rowgroup metadata in memory on the client side.\n\nThis will improve reading big datasets with a large schema (thousands of columns)\nInstead rowgroup metadata can be read in the tasks where each tasks reads only the metadata of the file it's reading\n\nAuthor: julien <julien@twitter.com>\n\nCloses #45 from julienledem/skip_reading_row_groups and squashes the following commits:\n\nccdd08c [julien] fix parquet-hive\n24a2050 [julien] Merge branch 'master' into skip_reading_row_groups\n3d7e35a [julien] adress review feedback\n5b6bd1b [julien] more tests\n323d254 [julien] sdd unit tests\nf599259 [julien] review feedback\nfb11f02 [julien] fix backward compatibility check\n2c20b46 [julien] cleanup readFooters methods\n3da37d8 [julien] fix read summary\nab95a45 [julien] cleanup\n4d16df3 [julien] implement task side metadata\n9bb8059 [julien] first stab at integrating skipping row groups\n",
        "diff": {
            "parquet-hadoop/src/main/java/parquet/format/converter/ParquetMetadataConverter.java": [
                33,
                152
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/ParquetFileReader.java": [
                46,
                173
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/ParquetFileWriter.java": [
                12,
                19
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/ParquetInputFormat.java": [
                246,
                392
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/ParquetInputSplit.java": [
                219,
                143
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/ParquetOutputCommitter.java": [
                1,
                0
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/ParquetOutputFormat.java": [
                1,
                0
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/ParquetReader.java": [
                3,
                3
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/ParquetRecordReader.java": [
                8,
                62
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/PrintFooter.java": [
                1,
                2
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/mapred/DeprecatedParquetInputFormat.java": [
                18,
                12
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/mapred/DeprecatedParquetOutputFormat.java": [
                10,
                7
            ],
            "parquet-hadoop/src/test/java/parquet/format/converter/TestParquetMetadataConverter.java": [
                1,
                127
            ],
            "parquet-hadoop/src/test/java/parquet/hadoop/DeprecatedInputFormatTest.java": [
                1,
                1
            ],
            "parquet-hadoop/src/test/java/parquet/hadoop/TestInputFormat.java": [
                26,
                211
            ],
            "parquet-hadoop/src/test/java/parquet/hadoop/TestParquetFileWriter.java": [
                6,
                8
            ],
            "parquet-hadoop/src/test/java/parquet/hadoop/TestParquetInputSplit.java": [
                45,
                0
            ],
            "parquet-hadoop/src/test/java/parquet/hadoop/example/TestInputOutputFormat.java": [
                5,
                19
            ],
            "parquet-hive/parquet-hive-storage-handler/src/main/java/org/apache/hadoop/hive/ql/io/parquet/read/ParquetRecordReaderWrapper.java": [
                32,
                19
            ],
            "parquet-pig/src/main/java/parquet/pig/ParquetLoader.java": [
                19,
                19
            ],
            "parquet-pig/src/main/java/parquet/pig/TupleReadSupport.java": [
                7,
                7
            ],
            "pom.xml": null
        }
    },
    "5f39948b2414ea2582892f6447566d7fe4909b4f": {
        "datetime": "2014-09-08T14:12:11-07:00",
        "summary": "update scala 2.10",
        "message": "update scala 2.10\n\nTry to upgrade to scala 2.10\n\nAuthor: Tianshuo Deng <tdeng@twitter.com>\n\nCloses #35 from tsdeng/update_scala_2_10 and squashes the following commits:\n\n1b7e55f [Tianshuo Deng] fix comment\nbed9de3 [Tianshuo Deng] remove twitter artifactory\n2bce643 [Tianshuo Deng] publish fix\n06b374e [Tianshuo Deng] define scala.binary.version\nfcf6965 [Tianshuo Deng] Merge branch 'master' into update_scala_2_10\ne91d9f7 [Tianshuo Deng] update version\n5d18b88 [Tianshuo Deng] version\n83df898 [Tianshuo Deng] update scala 2.10\n",
        "diff": {
            "parquet-scala/pom.xml": null,
            "parquet-scrooge/pom.xml": null,
            "parquet-scrooge/src/main/java/parquet/scrooge/ScroogeStructConverter.java": [
                1,
                2
            ],
            "pom.xml": null
        }
    },
    "24119cc8e41fa07f6ec0a1a33428419f5c99a829": {
        "datetime": "2014-09-09T15:45:20-07:00",
        "summary": "upgrade scalatest_version to depend on scala 2.10.4",
        "message": "upgrade scalatest_version to depend on scala 2.10.4\n\nAuthor: julien <julien@twitter.com>\n\nCloses #52 from julienledem/scalatest_version and squashes the following commits:\n\n945fa75 [julien] upgrade scalatest_version to depend on scala 2.10.4\n",
        "diff": {
            "parquet-scala/pom.xml": null
        }
    },
    "f637c4458a3b1dc4ecaa35957adf13ecfbe7d12d": {
        "datetime": "2014-09-10T10:37:51-07:00",
        "summary": "PARQUET-87: Add API for projection pushdown on the cascading scheme level",
        "message": "PARQUET-87: Add API for projection pushdown on the cascading scheme level\n\nJIRA: https://issues.apache.org/jira/browse/PARQUET-87\nPreviously, the projection pushdown configuration is global, and not bind to a specific tap.\nAfter adding this API, projection pushdown can be done more \"naturally\", which may benefit scalding. The code that uses this API would look like:\n\n```\nScheme sourceScheme = new ParquetScroogeScheme(new Config().withProjection(projectionFilter));\n Tap source = new Hfs(sourceScheme, PARQUET_PATH);\n```\n\nAuthor: Tianshuo Deng <tdeng@twitter.com>\n\nCloses #51 from tsdeng/projection_from_scheme and squashes the following commits:\n\n2c72757 [Tianshuo Deng] make config class final\n813dc1a [Tianshuo Deng] erge branch 'master' into projection_from_scheme\nb587b79 [Tianshuo Deng] make constructor of Config private, fix format\n3aa7dd2 [Tianshuo Deng] remove builder\n9348266 [Tianshuo Deng] use builder()\n7c91869 [Tianshuo Deng] make fields of Config private, create builder method for Config\n5fdc881 [Tianshuo Deng] builder for setting projection pushdown and predicate pushdown\na47f271 [Tianshuo Deng] immutable\n3d514b1 [Tianshuo Deng] done\n",
        "diff": {
            "parquet-cascading/src/main/java/parquet/cascading/ParquetTBaseScheme.java": [
                13,
                10
            ],
            "parquet-cascading/src/main/java/parquet/cascading/ParquetValueScheme.java": [
                5,
                73
            ],
            "parquet-scrooge/src/main/java/parquet/scrooge/ParquetScroogeScheme.java": [
                5,
                7
            ],
            "parquet-scrooge/src/test/java/parquet/scrooge/ParquetScroogeSchemeTest.java": [
                40,
                83
            ],
            "parquet-thrift/src/main/java/parquet/hadoop/thrift/ThriftReadSupport.java": [
                0,
                4
            ]
        }
    },
    "fbe458f8407210b20aaa2d60de9359ff88bc05c4": {
        "datetime": "2014-09-10T12:45:05-07:00",
        "summary": "PARQUET-88: fix pre-version enforcement",
        "message": "PARQUET-88: fix pre-version enforcement\n\nupdate semver dependency to use https://github.com/jeluard/semantic-versioning/pull/40\n\nAuthor: julien <julien@twitter.com>\n\nCloses #53 from julienledem/fix_semver and squashes the following commits:\n\n70248be [julien] fix pre-version enforcement https://github.com/jeluard/semantic-versioning/pull/40\n",
        "diff": {
            "pom.xml": null
        }
    },
    "8d878afb497810ceb34a0b8a4788914d9debf74b": {
        "datetime": "2014-09-10T16:13:20-07:00",
        "summary": "PARQUET-24: enforce JIRA prefix",
        "message": "PARQUET-24: enforce JIRA prefix\n\nAuthor: julien <julien@twitter.com>\n\nCloses #54 from julienledem/PARQUET-24 and squashes the following commits:\n\nd444f2f [julien] add option to not close JIRA\n00d4b13 [julien] fix close jira\n7cf9bb3 [julien] enforce JIRA prefix\n",
        "diff": {
            "dev/merge_parquet_pr.py": [
                6,
                20
            ]
        }
    },
    "316b5682e52cacc1d4eb7641da3066fd7a691aed": {
        "datetime": "2014-09-10T16:44:54-07:00",
        "summary": "[maven-release-plugin] prepare release parquet-1.6.0rc2",
        "message": "[maven-release-plugin] prepare release parquet-1.6.0rc2\n",
        "diff": {
            "parquet-avro/pom.xml": null,
            "parquet-cascading/pom.xml": null,
            "parquet-column/pom.xml": null,
            "parquet-common/pom.xml": null,
            "parquet-encoding/pom.xml": null,
            "parquet-generator/pom.xml": null,
            "parquet-hadoop-bundle/pom.xml": null,
            "parquet-hadoop/pom.xml": null,
            "parquet-hive-bundle/pom.xml": null,
            "parquet-hive/parquet-hive-binding/parquet-hive-0.10-binding/pom.xml": null,
            "parquet-hive/parquet-hive-binding/parquet-hive-0.12-binding/pom.xml": null,
            "parquet-hive/parquet-hive-binding/parquet-hive-binding-bundle/pom.xml": null,
            "parquet-hive/parquet-hive-binding/parquet-hive-binding-factory/pom.xml": null,
            "parquet-hive/parquet-hive-binding/parquet-hive-binding-interface/pom.xml": null,
            "parquet-hive/parquet-hive-binding/pom.xml": null,
            "parquet-hive/parquet-hive-storage-handler/pom.xml": null,
            "parquet-hive/pom.xml": null,
            "parquet-jackson/pom.xml": null,
            "parquet-pig-bundle/pom.xml": null,
            "parquet-pig/pom.xml": null,
            "parquet-protobuf/pom.xml": null,
            "parquet-scala/pom.xml": null,
            "parquet-scrooge/pom.xml": null,
            "parquet-test-hadoop2/pom.xml": null,
            "parquet-thrift/pom.xml": null,
            "parquet-tools/pom.xml": null,
            "pom.xml": null
        }
    },
    "501e8feac3fb60e794979e8445cf2ceebce94b04": {
        "datetime": "2014-09-10T16:44:58-07:00",
        "summary": "[maven-release-plugin] prepare for next development iteration",
        "message": "[maven-release-plugin] prepare for next development iteration\n",
        "diff": {
            "parquet-avro/pom.xml": null,
            "parquet-cascading/pom.xml": null,
            "parquet-column/pom.xml": null,
            "parquet-common/pom.xml": null,
            "parquet-encoding/pom.xml": null,
            "parquet-generator/pom.xml": null,
            "parquet-hadoop-bundle/pom.xml": null,
            "parquet-hadoop/pom.xml": null,
            "parquet-hive-bundle/pom.xml": null,
            "parquet-hive/parquet-hive-binding/parquet-hive-0.10-binding/pom.xml": null,
            "parquet-hive/parquet-hive-binding/parquet-hive-0.12-binding/pom.xml": null,
            "parquet-hive/parquet-hive-binding/parquet-hive-binding-bundle/pom.xml": null,
            "parquet-hive/parquet-hive-binding/parquet-hive-binding-factory/pom.xml": null,
            "parquet-hive/parquet-hive-binding/parquet-hive-binding-interface/pom.xml": null,
            "parquet-hive/parquet-hive-binding/pom.xml": null,
            "parquet-hive/parquet-hive-storage-handler/pom.xml": null,
            "parquet-hive/pom.xml": null,
            "parquet-jackson/pom.xml": null,
            "parquet-pig-bundle/pom.xml": null,
            "parquet-pig/pom.xml": null,
            "parquet-protobuf/pom.xml": null,
            "parquet-scala/pom.xml": null,
            "parquet-scrooge/pom.xml": null,
            "parquet-test-hadoop2/pom.xml": null,
            "parquet-thrift/pom.xml": null,
            "parquet-tools/pom.xml": null,
            "pom.xml": null
        }
    },
    "29633178d85af1fe2ba591d576585c16f4fa4fa6": {
        "datetime": "2014-09-16T14:15:15-07:00",
        "summary": "PARQUET-72: Fix NOTICE",
        "message": "PARQUET-72: Fix NOTICE\n\nAuthor: Ryan Blue <rblue@cloudera.com>\n\nCloses #13 from rdblue/PARQUET-72-fix-notice and squashes the following commits:\n\n92d25c2 [Ryan Blue] PARQUET-72: Remove unnecessary entries in NOTICE.\n",
        "diff": {
            "pom.xml": null
        }
    },
    "9cdcf3bbdf8f772d3fadf388b2db048598c155e9": {
        "datetime": "2014-09-22T11:11:08-07:00",
        "summary": "PARQUET-94: Fix bug in ParquetScroogeScheme constructor, minor cleanup",
        "message": "PARQUET-94: Fix bug in ParquetScroogeScheme constructor, minor cleanup\n\nI noticed that ParquetScroogeScheme's constructor ignores the provided klass argument.\nI also added in missing type parameters for the Config object where they were missing.\n\nAuthor: Alex Levenson <alexlevenson@twitter.com>\n\nCloses #61 from isnotinvain/alexlevenson/parquet-scrooge-cleanup and squashes the following commits:\n\n2b16007 [Alex Levenson] Fix bug in ParquetScroogeScheme constructor, minor cleanup\n",
        "diff": {
            "parquet-cascading/src/main/java/parquet/cascading/ParquetTBaseScheme.java": [
                8,
                5
            ],
            "parquet-cascading/src/main/java/parquet/cascading/ParquetValueScheme.java": [
                12,
                11
            ],
            "parquet-scrooge/src/main/java/parquet/scrooge/ParquetScroogeScheme.java": [
                7,
                3
            ]
        }
    },
    "3dc223cc85022e11dc6cd954784e715e3a49fe5c": {
        "datetime": "2014-09-22T11:21:20-07:00",
        "summary": "PARQUET-92: Pig parallel control",
        "message": "PARQUET-92: Pig parallel control\n\nThe parallelism for reading footers was fixed at '5', which isn't optimal for using pig with S3.  Just adding a property to adjust the parallelism.\n\nJIRA: https://issues.apache.org/jira/browse/PARQUET-92\n\nAuthor: Daniel Weeks <dweeks@netflix.com>\n\nCloses #57 from dcw-netflix/pig-parallel-control and squashes the following commits:\n\ne49087c [Daniel Weeks] Update ParquetFileReader.java\nec4f8ca [Daniel Weeks] Added configurable control of parallelism\nd37a6de [Daniel Weeks] Resetting pom to main\n0c1572e [Daniel Weeks] Merge remote-tracking branch 'upstream/master'\n98c6607 [Daniel Weeks] Merge remote-tracking branch 'upstream/master'\n96ba602 [Daniel Weeks] Disabled projects that don't compile\n",
        "diff": {
            "parquet-hadoop/src/main/java/parquet/hadoop/ParquetFileReader.java": [
                2,
                5
            ]
        }
    },
    "0eb96379518db4f84f7a95b651c6dc9a639cc9ac": {
        "datetime": "2014-09-22T15:07:04-07:00",
        "summary": "PARQUET-89: Add hadoop-2 test profile for Travis CI.",
        "message": "PARQUET-89: Add hadoop-2 test profile for Travis CI.\n\nThis also fixes problems that prevented hadoop-2 from passing:\n* Dynamically resolve counter methods in parquet-hadoop\n* Parameterize pig version with hadoop-2 support\n* Update pig test for hadoop-2 change (no nulls allowed)\n* Update parquet-hive to depend on hadoop-client\n\nThe travis config will now run each test profile in a different run.\n\nAuthor: Ryan Blue <rblue@cloudera.com>\n\nCloses #55 from rdblue/PARQUET-89-add-test-profiles and squashes the following commits:\n\n006c6d8 [Ryan Blue] PARQUET-89: Add hadoop-2 test profile for travis CI.\n",
        "diff": {
            ".travis.yml": null,
            "parquet-hadoop/src/test/java/parquet/hadoop/example/TestInputOutputFormat.java": [
                7,
                22
            ],
            "parquet-hive/parquet-hive-binding/parquet-hive-0.10-binding/pom.xml": null,
            "parquet-hive/parquet-hive-binding/parquet-hive-0.12-binding/pom.xml": null,
            "parquet-hive/parquet-hive-binding/parquet-hive-binding-factory/pom.xml": null,
            "parquet-hive/parquet-hive-binding/parquet-hive-binding-interface/pom.xml": null,
            "parquet-hive/parquet-hive-storage-handler/pom.xml": null,
            "parquet-pig/pom.xml": null,
            "parquet-pig/src/test/java/parquet/pig/summary/TestSummary.java": [
                9,
                4
            ],
            "parquet-test-hadoop2/pom.xml": null,
            "parquet-test-hadoop2/src/test/java/parquet/hadoop2/TestInputOutputFormat.java": [
                139,
                0
            ],
            "parquet-thrift/pom.xml": null,
            "pom.xml": null
        }
    },
    "59c58d0b829aa156f038cc900b803508f8849765": {
        "datetime": "2014-09-23T12:14:17-07:00",
        "summary": "PARQUET-82: Check page size is valid when writing.",
        "message": "PARQUET-82: Check page size is valid when writing.\n\nAuthor: Ryan Blue <rblue@cloudera.com>\n\nCloses #48 from rdblue/PARQUET-82-check-page-size and squashes the following commits:\n\n9f31402 [Ryan Blue] PARQUET-82: Check page size is valid when writing.\n",
        "diff": {
            "parquet-hadoop/src/main/java/parquet/hadoop/ColumnChunkPageWriteStore.java": [
                0,
                20
            ]
        }
    },
    "0c4f13a846b458e31cfcaafd8e83f0f4c1d04237": {
        "datetime": "2014-09-25T10:12:58-07:00",
        "summary": "PARQUET-101: fix meta data lookup when not using task.side.metadata",
        "message": "PARQUET-101: fix meta data lookup when not using task.side.metadata\n\nAuthor: julien <julien@twitter.com>\n\nCloses #64 from julienledem/PARQUET-101 and squashes the following commits:\n\n54ffbc9 [julien] fix meta data lookup when not using task.side.metadata\n",
        "diff": {
            "parquet-hadoop/src/main/java/parquet/hadoop/ParquetRecordReader.java": [
                7,
                13
            ]
        }
    },
    "3a082e8e390898646c094d20f4ec1eeba45b79ac": {
        "datetime": "2014-09-25T11:25:53-07:00",
        "summary": "PARQUET-90: integrate field ids in schema",
        "message": "PARQUET-90: integrate field ids in schema\n\nThis integrates support for field is that was introduced in Parquet format.\nThrift and Protobufs ids will now be saved in the Parquet schema.\n\nAuthor: julien <julien@twitter.com>\n\nCloses #56 from julienledem/field_ids and squashes the following commits:\n\n62c2809 [julien] remove withOriginalType; use Typles builder more\n8ff0034 [julien] review feedback\n084c8be [julien] binary compat\n85d785c [julien] add proto id in schema; fix schema parsing for ids\nd4be488 [julien] integrate field ids in schema\n",
        "diff": {
            "parquet-column/src/main/java/parquet/schema/GroupType.java": [
                26,
                68
            ],
            "parquet-column/src/main/java/parquet/schema/MessageType.java": [
                6,
                4
            ],
            "parquet-column/src/main/java/parquet/schema/MessageTypeParser.java": [
                6,
                15
            ],
            "parquet-column/src/main/java/parquet/schema/PrimitiveType.java": [
                39,
                62
            ],
            "parquet-column/src/main/java/parquet/schema/Type.java": [
                11,
                95
            ],
            "parquet-column/src/main/java/parquet/schema/Types.java": [
                4,
                27
            ],
            "parquet-column/src/test/java/parquet/parser/TestParquetParser.java": [
                83,
                117
            ],
            "parquet-column/src/test/java/parquet/schema/TestMessageType.java": [
                1,
                13
            ],
            "parquet-column/src/test/java/parquet/schema/TestTypeBuilders.java": [
                8,
                8
            ],
            "parquet-hadoop/src/main/java/parquet/format/converter/ParquetMetadataConverter.java": [
                0,
                3
            ],
            "parquet-pig/src/main/java/parquet/pig/PigSchemaConverter.java": [
                37,
                29
            ],
            "parquet-protobuf/src/main/java/parquet/proto/ProtoSchemaConverter.java": [
                60,
                48
            ],
            "parquet-protobuf/src/test/java/parquet/proto/ProtoSchemaConverterTest.java": [
                29,
                29
            ],
            "parquet-thrift/src/main/java/parquet/thrift/ThriftSchemaConvertVisitor.java": [
                41,
                55
            ],
            "parquet-thrift/src/main/java/parquet/thrift/projection/FieldsPath.java": [
                3,
                2
            ],
            "parquet-thrift/src/test/java/parquet/thrift/TestThriftSchemaConverter.java": [
                55,
                58
            ]
        }
    },
    "bf20abbf4825fa5892d8e15c066e768671a39289": {
        "datetime": "2014-09-25T16:45:56-07:00",
        "summary": "PARQUET-96: fill out some missing methods on parquet.example classes",
        "message": "PARQUET-96: fill out some missing methods on parquet.example classes\n\nI'm slightly embarrassed to say that we use these, and we'd really like to stop needing a fork, so here we are.\n\nAuthor: Colin Marc <colinmarc@gmail.com>\n\nCloses #59 from colinmarc/missing-group-methods and squashes the following commits:\n\naf8ea08 [Colin Marc] fill out some missing methods on parquet.example classes\n",
        "diff": {
            "parquet-column/src/main/java/parquet/example/data/Group.java": [
                0,
                6
            ],
            "parquet-column/src/main/java/parquet/example/data/GroupValueSource.java": [
                0,
                12
            ],
            "parquet-column/src/main/java/parquet/example/data/simple/SimpleGroup.java": [
                1,
                16
            ]
        }
    },
    "0b17cbee9541998df66d33c8a99b675ced80d9aa": {
        "datetime": "2014-09-29T12:00:03-07:00",
        "summary": "PARQUET-104: Fix writing empty row group at the end of the file",
        "message": "PARQUET-104: Fix writing empty row group at the end of the file\n\nAt then end of a parquet file, it may writes an empty rowgroup.\nThis happens when: numberOfRecords mod sizeOfRowGroup = 0\n\nAuthor: Tianshuo Deng <tdeng@twitter.com>\n\nCloses #66 from tsdeng/fix_empty_row_group and squashes the following commits:\n\n10b93fb [Tianshuo Deng] rename\ne3a5896 [Tianshuo Deng] format\n91fa0d4 [Tianshuo Deng] fix empty row group\n",
        "diff": {
            "parquet-hadoop/src/main/java/parquet/hadoop/InternalParquetRecordWriter.java": [
                30,
                34
            ]
        }
    },
    "da9129927bce90feb6d2860745263f4d74d0dfa8": {
        "datetime": "2014-10-01T13:44:45-07:00",
        "summary": "PARQUET-64: Add new OriginalTypes in parquet-format 2.2.0.",
        "message": "PARQUET-64: Add new OriginalTypes in parquet-format 2.2.0.\n\nThis implements the restrictions for those types documented in the parquet-format logical types spec.\n\nThis requires a release of parquet-format 2.2.0 with the new types. I'll rebase and update the dependency when it is released.\n\nAuthor: Ryan Blue <rblue@cloudera.com>\n\nCloses #31 from rdblue/PARQUET-64-add-new-types and squashes the following commits:\n\n10feab9 [Ryan Blue] PARQUET-64: Add new OriginalTypes in parquet-format 2.2.0.\n",
        "diff": {
            "parquet-column/src/main/java/parquet/schema/OriginalType.java": [
                1,
                15
            ],
            "parquet-column/src/main/java/parquet/schema/Types.java": [
                1,
                26
            ],
            "parquet-column/src/test/java/parquet/parser/TestParquetParser.java": [
                5,
                77
            ],
            "parquet-column/src/test/java/parquet/schema/TestTypeBuilders.java": [
                48,
                171
            ],
            "parquet-hadoop/src/main/java/parquet/format/converter/ParquetMetadataConverter.java": [
                0,
                57
            ],
            "parquet-hadoop/src/test/java/parquet/format/converter/TestParquetMetadataConverter.java": [
                0,
                6
            ]
        }
    },
    "be1222ef4a3260ddcf516d73c6ceecd144a134cb": {
        "datetime": "2014-10-01T14:14:24-07:00",
        "summary": "PARQUET-107: Add option to disable summary metadata.",
        "message": "PARQUET-107: Add option to disable summary metadata.\n\nThis adds an option to the commitJob phase of the MR OutputCommitter,\nparquet.enable.summary-metadata (default true), that can be used to\ndisable the summary metadata files generated from the footers of all of\nthe files produced. This enables more control over when those summary\nfiles are produced and makes it possible to rename MR outputs and then\ngenerate the summaries.\n\nAuthor: Ryan Blue <rblue@cloudera.com>\n\nCloses #68 from rdblue/PARQUET-107-add-summary-metadata-option and squashes the following commits:\n\n261e5e4 [Ryan Blue] PARQUET-107: Add option to disable summary metadata.\n",
        "diff": {
            "parquet-hadoop/src/main/java/parquet/hadoop/ParquetOutputCommitter.java": [
                12,
                14
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/ParquetOutputFormat.java": [
                0,
                5
            ]
        }
    },
    "3633dee0c36e84ed728871a923bbcbc34425fa96": {
        "datetime": "2014-10-01T15:40:52-07:00",
        "summary": "PARQUET-109: Update NOTICE, add binary LICENSE.",
        "message": "PARQUET-109: Update NOTICE, add binary LICENSE.\n\nThis makes a minor change to NOTICE to match the maven-generated project\nname (Apache Parquet => Apache Parquet Format (Incubating)). There\nshould be no more additions to NOTICE needed. The Thrift NOTICE has no\nadditions beyond the standard Apache boilerplate and SLF4J has no NOTICE\nfile. **Please double-check this**\n\nThis also adds a LICENSE file in the resources that is included in the\nbinary distribution. This LICENSE represents the contents of the binary\ndistribution and includes the QOS.ch BSD license for SLF4J. There are no\nother licenses required. Although the LICENSE.txt in the thrift binary\nthat is shaded includes other licenses, the files that they apply to are\nnot included in either source or binary form because the shaded jar\ncontains only the Thrift Java library. **Please double-check this**\n\nThis also removes the Thrift NOTICE.txt and LICENSE.txt files from the\nbinary distribution. The parquet-format NOTICE and LICENSE files\nrepresent the contents of the jar.\n\nAuthor: Ryan Blue <rblue@cloudera.com>\n\nCloses #15 from rdblue/PARQUET-109-licensing-fixes and squashes the following commits:\n\n3b34771 [Ryan Blue] PARQUET-109: Update NOTICE, add binary LICENSE.\n",
        "diff": {
            "pom.xml": null
        }
    },
    "31fb4dfef212791f86f052ce8a3adeabaf830cf2": {
        "datetime": "2014-10-21T09:54:20-07:00",
        "summary": "PARQUET-105: use mvn shade plugin to create uber jar, support meta on a folder",
        "message": "PARQUET-105: use mvn shade plugin to create uber jar, support meta on a folder\n\n1. Make hadoop dependency from parquet-tools so it is provided. It can be used against different version of hadoop\n2. Use maven shade plugin to create a all in one jar, which can be used both locally or in hadoop\n3. Make parquet-meta command support both folder(read summary file) and a single file\n\nAuthor: Tianshuo Deng <tdeng@twitter.com>\n\nCloses #69 from tsdeng/bundle_parquet_tools and squashes the following commits:\n\nd8dcd3e [Tianshuo Deng] print file offset, file path, and cancel autoCrop\na2d1399 [Tianshuo Deng] support local mode\n5009a85 [Tianshuo Deng] fix README\n0756f81 [Tianshuo Deng] remove semver check for parquet_tools\n78c7f4b [Tianshuo Deng] use mvn shade plugin to create uber jar, support meta on a folder\n",
        "diff": {
            "parquet-tools/README.md": null,
            "parquet-tools/pom.xml": null,
            "parquet-tools/src/main/java/parquet/tools/Main.java": [
                15,
                14
            ],
            "parquet-tools/src/main/java/parquet/tools/command/ShowMetaCommand.java": [
                7,
                13
            ],
            "parquet-tools/src/main/java/parquet/tools/command/ShowSchemaCommand.java": [
                2,
                0
            ],
            "parquet-tools/src/main/java/parquet/tools/util/MetadataUtils.java": [
                1,
                2
            ]
        }
    },
    "ccfca8f714055cd9fbd00cf7e847b880132cae69": {
        "datetime": "2014-10-29T11:10:16-07:00",
        "summary": "PARQUET-106: Relax InputSplit Protections",
        "message": "PARQUET-106: Relax InputSplit Protections\n\nhttps://issues.apache.org/jira/browse/PARQUET-106\n\nAuthor: Daniel Weeks <dweeks@netflix.com>\n\nCloses #67 from dcw-netflix/input-split2 and squashes the following commits:\n\n2f2c0c7 [Daniel Weeks] Update ParquetInputSplit.java\n12bd3c1 [Daniel Weeks] Update ParquetInputSplit.java\n6c662ee [Daniel Weeks] Update ParquetInputSplit.java\n5f9f02e [Daniel Weeks] Update ParquetInputSplit.java\nd19e1ac [Daniel Weeks] Merge branch 'master' into input-split2\nc4172bb [Daniel Weeks] Merge remote-tracking branch 'upstream/master'\n01a5e8f [Daniel Weeks] Relaxed protections on input split class\nd37a6de [Daniel Weeks] Resetting pom to main\n0c1572e [Daniel Weeks] Merge remote-tracking branch 'upstream/master'\n98c6607 [Daniel Weeks] Merge remote-tracking branch 'upstream/master'\n96ba602 [Daniel Weeks] Disabled projects that don't compile\n",
        "diff": {
            "parquet-hadoop/src/main/java/parquet/hadoop/ParquetInputSplit.java": [
                6,
                6
            ]
        }
    },
    "a29815abf4f0e51b332a8af1b83ad344104c14d9": {
        "datetime": "2014-11-03T14:00:33+00:00",
        "summary": "PARQUET-123: Enable dictionary support in AvroIndexedRecordConverter",
        "message": "PARQUET-123: Enable dictionary support in AvroIndexedRecordConverter\n\nIf consumers are loading Parquet records into an immutable structure\nlike an Apache Spark RDD, being able to configure string reuse in\nAvroIndexedRecordConverter can drastically reduce the overall memory\nfootprint of strings.\n\nNOTE: This isn't meant to be a merge-able PR (yet). I want to use\nthis PR as a way to discuss: (1) if this is a reasonable approach\nand (2) to learn if PrimitiveConverter needs to be thread-safe as\nI'm currently using a ConcurrentHashMap. If there's agreement\nthat this would be worthwhile, I'll create a JIRA and write some\nunit tests.\n\nAuthor: Matt Massie <massie@cs.berkeley.edu>\n\nCloses #76 from massie/immutable-strings and squashes the following commits:\n\n88ce5bf [Matt Massie] PARQUET-123: Enable dictionary support in AvroIndexedRecordConverter\n",
        "diff": {
            "parquet-avro/src/main/java/parquet/avro/AvroIndexedRecordConverter.java": [
                2,
                24
            ],
            "parquet-avro/src/test/java/parquet/avro/TestSpecificInputOutputFormat.java": [
                2,
                9
            ]
        }
    },
    "f1da5e927ed18aeec1610bec67f88facd6a470e1": {
        "datetime": "2014-11-03T14:11:03+00:00",
        "summary": "PARQUET-121: Allow Parquet to build with Java 8",
        "message": "PARQUET-121: Allow Parquet to build with Java 8\n\nThere are test failures running with Java 8 due to http://openjdk.java.net/jeps/180 which changed retrieval order for HashMap.\n\nHere's how I tested this:\n\n```bash\nuse-java8\nmvn clean install -DskipTests -Dmaven.javadoc.skip=true\nmvn test\nmvn test -P hadoop-2\n```\n\nI also compiled the main code with Java 7 (target=1.6 bytecode), and compiled the tests with Java 8, and ran them with Java 8. The idea here is to simulate users who want to run Parquet with JRE 8.\n```bash\nuse-java7\nmvn clean install -DskipTests -Dmaven.javadoc.skip=true\nuse-java8\nfind . -name test-classes | grep target/test-classes | grep -v 'parquet-scrooge' | xargs rm -rf\nmvn test -DtargetJavaVersion=1.8 -Dmaven.main.skip=true -Dscala.maven.test.skip=true\n```\nA couple of notes about this:\n* The targetJavaVersion property is used since other Hadoop projects use the same name.\n* I couldn\u2019t get parquet-scrooge to compile with target=1.8, which is why I introduced scala.maven.test.skip (and updated scala-maven-plugin to the latest version which supports the property). Compiling with target=1.8 should be fixed in another JIRA as it looks pretty involved.\n\nAuthor: Tom White <tom@cloudera.com>\n\nCloses #77 from tomwhite/PARQUET-121-java8 and squashes the following commits:\n\n8717e13 [Tom White] Fix tests to run under Java 8.\n35ea670 [Tom White] PARQUET-121. Allow Parquet to build with Java 8.\n",
        "diff": {
            "parquet-pig/src/main/java/parquet/pig/convert/MapConverter.java": [
                1,
                2
            ],
            "parquet-pig/src/test/java/parquet/pig/TestParquetStorer.java": [
                4,
                16
            ],
            "parquet-pig/src/test/java/parquet/pig/TestPigSchemaConverter.java": [
                2,
                5
            ],
            "parquet-scrooge/pom.xml": null,
            "parquet-thrift/src/test/java/parquet/thrift/TestParquetWriteProtocol.java": [
                1,
                38
            ],
            "pom.xml": null
        }
    },
    "92e6d716069686583b852a6dcf12af986d6dc694": {
        "datetime": "2014-11-07T11:02:27-08:00",
        "summary": "PARQUET-122: make task side metadata true by default",
        "message": "PARQUET-122: make task side metadata true by default\n\nAuthor: julien <julien@twitter.com>\n\nCloses #78 from julienledem/task_side_metadata_default_true and squashes the following commits:\n\n32451a7 [julien] make task side metadata true by default\n",
        "diff": {
            "parquet-hadoop/src/main/java/parquet/hadoop/ParquetInputFormat.java": [
                2,
                13
            ]
        }
    },
    "251a495d2a72de7e892ade7f64980f51f2fcc0dd": {
        "datetime": "2014-11-17T16:53:08-08:00",
        "summary": "PARQUET-135: Input location is not getting set for the getStatistics in ParquetLoader when using two different loaders within a Pig script.",
        "message": "PARQUET-135: Input location is not getting set for the getStatistics in ParquetLoader when using two different loaders within a Pig script.\n\nAuthor: elif dede <edede@twitter.com>\n\nCloses #86 from elifdd/parquetLoader_error_PARQUET-135 and squashes the following commits:\n\nb0150ee [elif dede] fixed white space\nbdb381a [elif dede] PARQUET-135: Call setInput from getStatistics in ParquetLoader to fix ReduceEstimator errors in pig jobs\n",
        "diff": {
            "parquet-hadoop/src/test/java/parquet/format/converter/TestParquetMetadataConverter.java": [
                1,
                1
            ],
            "parquet-pig/src/main/java/parquet/pig/ParquetLoader.java": [
                2,
                3
            ]
        }
    },
    "d105819a0e72765ff5ba4efa5622d727360ee2b8": {
        "datetime": "2014-11-18T20:20:04-08:00",
        "summary": "PARQUET-132: Add type parameter to AvroParquetInputFormat.",
        "message": "PARQUET-132: Add type parameter to AvroParquetInputFormat.\n\nAuthor: Ryan Blue <blue@apache.org>\n\nCloses #84 from rdblue/PARQUET-132-parameterize-avro-inputformat and squashes the following commits:\n\n63114b0 [Ryan Blue] PARQUET-132: Add type parameter to AvroParquetInputFormat.\n",
        "diff": {
            "parquet-avro/src/main/java/parquet/avro/AvroParquetInputFormat.java": [
                1,
                1
            ]
        }
    },
    "3aa6f11785a2f1b3b09df328a02a2c28dfa0bb57": {
        "datetime": "2014-11-20T09:19:25-08:00",
        "summary": "PARQUET-114: Sample NanoTime class serializes and deserializes Timestamp incorrectly",
        "message": "PARQUET-114: Sample NanoTime class serializes and deserializes Timestamp incorrectly\n\nI ran the Parquet Column tests and they passed.\n\nFYI @rdblue\n\nAuthor: Brock Noland <brock@apache.org>\n\nCloses #71 from brockn/master and squashes the following commits:\n\n69ba484 [Brock Noland] PARQUET-114 - Sample NanoTime class serializes and deserializes Timestamp incorrectly\n",
        "diff": {
            "parquet-column/src/main/java/parquet/example/data/simple/NanoTime.java": [
                2,
                7
            ]
        }
    },
    "ad06e61143d6ad3d883907e75100014b9554c357": {
        "datetime": "2014-11-25T10:48:54-08:00",
        "summary": "PARQUET-52: refactor fallback mechanism",
        "message": "PARQUET-52: refactor fallback mechanism\n\nSee: https://issues.apache.org/jira/browse/PARQUET-52\nContext:\nIn the ValuesWriter API there is a mechanism to return the Encoding actually used which allows to fallback to a different encoding.\nFor example the dictionary encoding may fail if there are too many distinct values and the dictionary grows too big. In such cases the DictionaryValuesWriter was falling back to the Plain encoding.\nThis can happen as well if the space savings are not satisfying when writing the first page and we prefer to fallback to a more light weight encoding.\nWith Parquet 2.0 we are adding new encodings and the fall back is not necessarily Plain anymore.\nThis Pull Request decouple the fallback mechanism from Dictionary and Plain encodings and allows to reuse the fallback logic with other encodings.\nOne could imagine more than one level of fallback in the future by chaining the FallBackValuesWriter.\n\nAuthor: julien <julien@twitter.com>\n\nCloses #74 from julienledem/fallback and squashes the following commits:\n\nb74a4ca [julien] Merge branch 'master' into fallback\nd9abd62 [julien] better naming\naa90caf [julien] exclude values encoding from SemVer\n10f295e [julien] better test setup\nc516bd9 [julien] improve test\n780c4c3 [julien] license header\nf16311a [julien] javadoc\naeb8084 [julien] add more test; fix dic decoding\n0793399 [julien] Merge branch 'master' into fallback\n2638ec9 [julien] fix dictionary encoding labelling\n2fd9372 [julien] consistent naming\ncf7a734 [julien] rewrite ParquetProperties to enable proper fallback\nbf1474a [julien] refactor fallback mechanism\n",
        "diff": {
            "parquet-column/src/main/java/parquet/column/Encoding.java": [
                46,
                67
            ],
            "parquet-column/src/main/java/parquet/column/ParquetProperties.java": [
                68,
                122
            ],
            "parquet-column/src/main/java/parquet/column/values/RequiresFallback.java": [
                0,
                51
            ],
            "parquet-column/src/main/java/parquet/column/values/dictionary/DictionaryValuesWriter.java": [
                211,
                133
            ],
            "parquet-column/src/main/java/parquet/column/values/dictionary/PlainValuesDictionary.java": [
                1,
                3
            ],
            "parquet-column/src/main/java/parquet/column/values/fallback/FallbackValuesWriter.java": [
                0,
                187
            ],
            "parquet-column/src/test/java/parquet/column/values/dictionary/TestDictionary.java": [
                51,
                74
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/example/GroupWriteSupport.java": [
                1,
                5
            ],
            "parquet-hadoop/src/test/java/parquet/hadoop/TestParquetFileWriter.java": [
                2,
                2
            ],
            "parquet-hadoop/src/test/java/parquet/hadoop/TestParquetWriter.java": [
                0,
                111
            ],
            "parquet-hadoop/src/test/java/parquet/hadoop/TestUtils.java": [
                0,
                22
            ],
            "pom.xml": null
        }
    },
    "b5f6a3bd86bfe0f186b07eb69480564d5fc854dc": {
        "datetime": "2014-12-02T16:19:14+00:00",
        "summary": "PARQUET-140: Allow clients to control the GenericData instance used to read Avro records",
        "message": "PARQUET-140: Allow clients to control the GenericData instance used to read Avro records\n\nAuthor: Josh Wills <jwills@cloudera.com>\n\nCloses #90 from jwills/master and squashes the following commits:\n\n044cf54 [Josh Wills] PARQUET-140: Allow clients to control the GenericData object that is used to read Avro records\n",
        "diff": {
            "parquet-avro/src/main/java/parquet/avro/AvroDataSupplier.java": [
                0,
                28
            ],
            "parquet-avro/src/main/java/parquet/avro/AvroIndexedRecordConverter.java": [
                24,
                42
            ],
            "parquet-avro/src/main/java/parquet/avro/AvroParquetInputFormat.java": [
                0,
                11
            ],
            "parquet-avro/src/main/java/parquet/avro/AvroReadSupport.java": [
                1,
                13
            ],
            "parquet-avro/src/main/java/parquet/avro/AvroRecordMaterializer.java": [
                2,
                4
            ],
            "parquet-avro/src/main/java/parquet/avro/SpecificDataSupplier.java": [
                0,
                26
            ]
        }
    },
    "ccc29e4dde24584118211f27c71bb01bacc39326": {
        "datetime": "2014-12-04T13:16:11-08:00",
        "summary": "PARQUET-117: implement the new page format for Parquet 2.0",
        "message": "PARQUET-117: implement the new page format for Parquet 2.0\n\nThe new page format was defined some time ago:\nhttps://github.com/Parquet/parquet-format/pull/64\nhttps://github.com/Parquet/parquet-format/issues/44\nThe goals are the following:\n - cut pages on record boundaries to facilitate skipping pages in predicate poush down\n - read rl and dl independently of data\n - optionally not compress data\n\nAuthor: julien <julien@twitter.com>\n\nCloses #75 from julienledem/new_page_format and squashes the following commits:\n\nfbbc23a [julien] make mvn install display output only if it fails\n4189383 [julien] save output lines as travis cuts after 10000\n44d3684 [julien] fix parquet-tools for new page format\n0fb8c15 [julien] Merge branch 'master' into new_page_format\n5880cbb [julien] Merge branch 'master' into new_page_format\n6ee7303 [julien] make parquet.column package not semver compliant\n42f6c9f [julien] add tests and fix bugs\n266302b [julien] fix write path\n4e76369 [julien] read path\n050a487 [julien] fix compilation\ne0e9d00 [julien] better ColumnWriterStore definition\necf04ce [julien] remove unnecessary change\n2bc4d01 [julien] first stab at write path for the new page format\n",
        "diff": {
            ".travis.yml": null,
            "parquet-column/src/main/java/parquet/column/ColumnWriteStore.java": [
                0,
                22
            ],
            "parquet-column/src/main/java/parquet/column/ColumnWriter.java": [
                12,
                0
            ],
            "parquet-column/src/main/java/parquet/column/ParquetProperties.java": [
                0,
                25
            ],
            "parquet-column/src/main/java/parquet/column/impl/ColumnReaderImpl.java": [
                22,
                121
            ],
            "parquet-column/src/main/java/parquet/column/impl/ColumnWriteStoreImpl.java": [
                26,
                33
            ],
            "parquet-column/src/main/java/parquet/column/impl/ColumnWriteStoreV2.java": [
                0,
                163
            ],
            "parquet-column/src/main/java/parquet/column/impl/ColumnWriterImpl.java": [
                9,
                3
            ],
            "parquet-column/src/main/java/parquet/column/impl/ColumnWriterV2.java": [
                0,
                295
            ],
            "parquet-column/src/main/java/parquet/column/page/DataPage.java": [
                0,
                50
            ],
            "parquet-column/src/main/java/parquet/column/page/DataPageV1.java": [
                0,
                80
            ],
            "parquet-column/src/main/java/parquet/column/page/DataPageV2.java": [
                0,
                138
            ],
            "parquet-column/src/main/java/parquet/column/page/DictionaryPage.java": [
                9,
                5
            ],
            "parquet-column/src/main/java/parquet/column/page/Page.java": [
                124,
                10
            ],
            "parquet-column/src/main/java/parquet/column/page/PageReader.java": [
                1,
                1
            ],
            "parquet-column/src/main/java/parquet/column/page/PageWriter.java": [
                14,
                26
            ],
            "parquet-column/src/main/java/parquet/column/values/ValuesWriter.java": [
                2,
                1
            ],
            "parquet-column/src/main/java/parquet/column/values/rle/RunLengthBitPackingHybridDecoder.java": [
                4,
                3
            ],
            "parquet-column/src/main/java/parquet/column/values/rle/RunLengthBitPackingHybridValuesWriter.java": [
                8,
                2
            ],
            "parquet-column/src/main/java/parquet/io/MessageColumnIO.java": [
                0,
                3
            ],
            "parquet-column/src/test/java/parquet/column/impl/TestColumnReaderImpl.java": [
                0,
                105
            ],
            "parquet-column/src/test/java/parquet/column/mem/TestMemColumn.java": [
                14,
                13
            ],
            "parquet-column/src/test/java/parquet/column/mem/TestMemPageStore.java": [
                2,
                2
            ],
            "parquet-column/src/test/java/parquet/column/page/mem/MemPageReader.java": [
                5,
                5
            ],
            "parquet-column/src/test/java/parquet/column/page/mem/MemPageStore.java": [
                2,
                2
            ],
            "parquet-column/src/test/java/parquet/column/page/mem/MemPageWriter.java": [
                18,
                23
            ],
            "parquet-column/src/test/java/parquet/io/PerfTest.java": [
                3,
                3
            ],
            "parquet-column/src/test/java/parquet/io/TestColumnIO.java": [
                77,
                93
            ],
            "parquet-column/src/test/java/parquet/io/TestFiltered.java": [
                2,
                2
            ],
            "parquet-hadoop/src/main/java/parquet/format/converter/ParquetMetadataConverter.java": [
                9,
                44
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/ColumnChunkPageReadStore.java": [
                19,
                53
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/ColumnChunkPageWriteStore.java": [
                54,
                47
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/InternalParquetRecordWriter.java": [
                12,
                16
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/ParquetFileReader.java": [
                23,
                51
            ],
            "parquet-hadoop/src/test/java/parquet/hadoop/TestColumnChunkPageWriteStore.java": [
                0,
                107
            ],
            "parquet-hadoop/src/test/java/parquet/hadoop/TestParquetFileWriter.java": [
                3,
                4
            ],
            "parquet-hadoop/src/test/java/parquet/hadoop/TestParquetWriterNewPage.java": [
                0,
                117
            ],
            "parquet-pig/src/test/java/parquet/pig/GenerateIntTestFile.java": [
                142,
                0
            ],
            "parquet-pig/src/test/java/parquet/pig/GenerateTPCH.java": [
                112,
                0
            ],
            "parquet-pig/src/test/java/parquet/pig/TupleConsumerPerfTest.java": [
                4,
                4
            ],
            "parquet-thrift/src/test/java/parquet/thrift/TestParquetReadProtocol.java": [
                2,
                2
            ],
            "parquet-tools/src/main/java/parquet/tools/command/DumpCommand.java": [
                9,
                25
            ],
            "pom.xml": null
        }
    },
    "b7a82a918f0a595a96047f7eef2672fd95d5626c": {
        "datetime": "2014-12-11T14:01:27-08:00",
        "summary": "PARQUET-145 InternalParquetRecordReader.close() should not throw an exception if initialization has failed",
        "message": "PARQUET-145 InternalParquetRecordReader.close() should not throw an exception if initialization has failed\n\nPARQUET-145 InternalParquetRecordReader.close() should not throw an exception if initialization has failed\n\nAuthor: Wolfgang Hoschek <whoschek@cloudera.com>\n\nCloses #93 from whoschek/PARQUET-145-3 and squashes the following commits:\n\n52a6acb [Wolfgang Hoschek] PARQUET-145 InternalParquetRecordReader.close() should not throw an exception if initialization has failed\n",
        "diff": {
            "parquet-hadoop/src/main/java/parquet/hadoop/InternalParquetRecordReader.java": [
                1,
                3
            ]
        }
    },
    "8e2ea92ee6ed83f74619681fd1158dd081c4dd4e": {
        "datetime": "2014-12-16T09:56:02-08:00",
        "summary": "PARQUET-150 Update merge script issue id matching.",
        "message": "PARQUET-150 Update merge script issue id matching.\n\nThis matches a word boundary after the issue id rather than a colon.\n\nAuthor: Ryan Blue <blue@apache.org>\n\nThis patch had conflicts when merged, resolved by\nCommitter: Ryan Blue <blue@apache.org>\n\nCloses #94 from rdblue/PARQUET-150-update-merge-script and squashes the following commits:\n\ncc39713 [Ryan Blue] PARQUET-150: Update merge script issue id matching.\n",
        "diff": {
            "dev/merge_parquet_pr.py": [
                1,
                1
            ]
        }
    },
    "0fcfe617859603a31fac471255cf5bef7190714b": {
        "datetime": "2014-12-18T15:33:56-08:00",
        "summary": "PARQUET-23: Refactor parquet-format to org.apache names.",
        "message": "PARQUET-23: Refactor parquet-format to org.apache names.\n\nThis updates parquet-format to use org.apache names. Still need to:\n* Validate that parquet-mr works as expected when relying on these changes\n\nAuthor: Ryan Blue <blue@apache.org>\n\nCloses #18 from rdblue/PARQUET-23-rename-to-org-apache and squashes the following commits:\n\nddcd50e [Ryan Blue] PARQUET-23: Update changelog for org.apache parquet-format 2.2.0.\n5c339d4 [Ryan Blue] PARQUET-23: Update POM to use Apache maven release config.\nac982ca [Ryan Blue] PARQUET-23: Refactor parquet-format to org.apache names.\n",
        "diff": {
            "pom.xml": null,
            "src/main/java/parquet/format/InterningProtocol.java": [
                1,
                1
            ],
            "src/main/java/parquet/format/Util.java": [
                18,
                18
            ],
            "src/main/java/parquet/format/event/Consumers.java": [
                5,
                5
            ],
            "src/main/java/parquet/format/event/EventBasedThriftReader.java": [
                4,
                4
            ],
            "src/main/java/parquet/format/event/FieldConsumer.java": [
                1,
                1
            ],
            "src/main/java/parquet/format/event/TypedConsumer.java": [
                1,
                1
            ],
            "src/test/java/parquet/format/TestUtil.java": [
                4,
                4
            ]
        }
    },
    "23db4eb88aa018da25563586bab322e7c1867ad5": {
        "datetime": "2014-12-29T09:17:34-06:00",
        "summary": "PARQUET-108: Parquet Memory Management in Java",
        "message": "PARQUET-108: Parquet Memory Management in Java\n\nPARQUET-108: Parquet Memory Management in Java.\nWhen Parquet tries to write very large \"row groups\", it may causes tasks to run out of memory during dynamic partitions when a reducer may have many Parquet files open at a given time.\n\nThis patch implements a memory manager to control the total memory size used by writers and balance their memory usage, which ensures that we don't run out of memory due to writing too many row groups within a single JVM.\n\nAuthor: dongche1 <dong1.chen@intel.com>\n\nCloses #80 from dongche/master and squashes the following commits:\n\ne511f85 [dongche1] Merge remote branch 'upstream/master'\n60a96b5 [dongche1] Merge remote branch 'upstream/master'\n2d17212 [dongche1] improve MemoryManger instantiation, change access level\n6e9333e [dongche1] change blocksize type from int to long\ne07b16e [dongche1] Refine updateAllocation(), addWriter(). Remove redundant getMemoryPoolRatio\n9a0a831 [dongche1] log the inconsistent ratio config instead of thowing an exception\n3a35d22 [dongche1] Move the creation of MemoryManager. Throw exception instead of logging it\naeda7bc [dongche1] PARQUET-108: Parquet Memory Management in Java\" ;\nc883bba [dongche1] PARQUET-108: Parquet Memory Management in Java\n7b45b2c [dongche1] PARQUET-108: Parquet Memory Management in Java\n6d766aa [dongche1] PARQUET-108: Parquet Memory Management in Java --- address some comments\n3abfe2b [dongche1] parquet 108\n",
        "diff": {
            "parquet-hadoop/src/main/java/parquet/hadoop/InternalParquetRecordWriter.java": [
                7,
                21
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/MemoryManager.java": [
                0,
                137
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/ParquetInputSplit.java": [
                5,
                18
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/ParquetOutputFormat.java": [
                2,
                28
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/ParquetRecordWriter.java": [
                3,
                42
            ],
            "parquet-hadoop/src/test/java/parquet/hadoop/TestInputFormat.java": [
                0,
                38
            ],
            "parquet-hadoop/src/test/java/parquet/hadoop/TestMemoryManager.java": [
                0,
                103
            ]
        }
    },
    "52f3240d90f2397cd1850ab11674ba08a0ecb2a0": {
        "datetime": "2015-01-12T16:01:06-08:00",
        "summary": "PARQUET-141: upgrade to scrooge 3.17.0, remove reflection based field info inspection...",
        "message": "PARQUET-141: upgrade to scrooge 3.17.0, remove reflection based field info inspection...\n\nupgrade to scrooge 3.17.0, remove reflection based field info inspection, support enum and requirement type correctly\n\nThis PR is essential for scrooge write support https://github.com/apache/incubator-parquet-mr/pull/58\n\nAuthor: Tianshuo Deng <tdeng@twitter.com>\n\nCloses #88 from tsdeng/scrooge_schema_converter_upgrade and squashes the following commits:\n\n77cc12a [Tianshuo Deng] delete empty line, retrigger jenkins\n80d61ad [Tianshuo Deng] format\n26e1fe1 [Tianshuo Deng] fix exception handling\n706497d [Tianshuo Deng] support union\n1b51f0f [Tianshuo Deng] upgrade to scrooge 3.17.0, remove reflection based field info inspection, support enum and requirement type correctly\n",
        "diff": {
            "parquet-scrooge/pom.xml": null,
            "parquet-scrooge/src/main/java/parquet/scrooge/ScroogeSchemaConversionException.java": [
                0,
                18
            ],
            "parquet-scrooge/src/main/java/parquet/scrooge/ScroogeStructConverter.java": [
                84,
                107
            ],
            "parquet-scrooge/src/test/java/parquet/scrooge/ScroogeStructConverterTest.java": [
                1,
                10
            ],
            "parquet-scrooge/src/test/thrift/test.thrift": null,
            "pom.xml": null
        }
    },
    "d70fdbc40195077057a1edb14ccd16a26435d007": {
        "datetime": "2015-01-23T16:20:10-08:00",
        "summary": "PARQUET-168: Fixes parquet-tools command line option description",
        "message": "PARQUET-168: Fixes parquet-tools command line option description\n\n<!-- Reviewable:start -->\n[<img src=\"https://reviewable.io/review_button.png\" height=40 alt=\"Review on Reviewable\"/>](https://reviewable.io/reviews/apache/incubator-parquet-mr/106)\n<!-- Reviewable:end -->\n\nAuthor: Cheng Lian <lian@databricks.com>\n\nCloses #106 from liancheng/PARQUET-168 and squashes the following commits:\n\n4524f2d [Cheng Lian] Fixes command line option description\n",
        "diff": {
            "parquet-tools/src/main/java/parquet/tools/Main.java": [
                2,
                2
            ]
        }
    },
    "4bf9be34a87b51d07e0b0c9e74831bbcdbce0f74": {
        "datetime": "2015-01-26T18:21:11-08:00",
        "summary": "PARQUET-136: NPE thrown in StatisticsFilter when all values in a string/binary column trunk are null",
        "message": "PARQUET-136: NPE thrown in StatisticsFilter when all values in a string/binary column trunk are null\n\nIn case of all nulls in a binary column, statistics object read from file metadata is empty, and should return true for all nulls check for the column. Even if column has no values, it can be ignored.\n\nThe other way is to fix this behaviour in the writer, but is that what we want ?\n\nAuthor: Yash Datta <Yash.Datta@guavus.com>\nAuthor: Alex Levenson <alexlevenson@twitter.com>\nAuthor: Yash Datta <saucam@gmail.com>\n\nCloses #99 from saucam/npe and squashes the following commits:\n\n5138e44 [Yash Datta] PARQUET-136: Remove unreachable block\nb17cd38 [Yash Datta] Revert \"PARQUET-161: Trigger tests\"\n82209e6 [Yash Datta] PARQUET-161: Trigger tests\naab2f81 [Yash Datta] PARQUET-161: Review comments for the test case\n2217ee2 [Yash Datta] PARQUET-161: Add a test case for checking the correct statistics info is recorded in case of all nulls in a column\nc2f8d6f [Yash Datta] PARQUET-161: Fix the write path to write statistics object in case of only nulls in the column\n97bb517 [Yash Datta] Revert \"revert TestStatisticsFilter.java\"\na06f0d0 [Yash Datta] Merge pull request #1 from isnotinvain/alexlevenson/PARQUET-161-136\nb1001eb [Alex Levenson] Fix statistics isEmpty, handle more edge cases in statistics filter\n0c88be0 [Alex Levenson] revert TestStatisticsFilter.java\n1ac9192 [Yash Datta] PARQUET-136: Its better to not filter chunks for which empty statistics object is returned. Empty statistics can be read in case of 1. pre-statistics files, 2. files written from current writer that has a bug, as it does not write the statistics if column has all nulls\ne5e924e [Yash Datta] Revert \"PARQUET-136: In case of all nulls in a binary column, statistics object read from file metadata is empty, and should return true for all nulls check for the column\"\n8cc5106 [Yash Datta] Revert \"PARQUET-136: fix hasNulls to cater to the case where all values are nulls\"\nc7c126f [Yash Datta] PARQUET-136: fix hasNulls to cater to the case where all values are nulls\n974a22b [Yash Datta] PARQUET-136: In case of all nulls in a binary column, statistics object read from file metadata is empty, and should return true for all nulls check for the column\n",
        "diff": {
            "parquet-column/src/main/java/parquet/column/statistics/BinaryStatistics.java": [
                4,
                6
            ],
            "parquet-column/src/main/java/parquet/column/statistics/BooleanStatistics.java": [
                4,
                6
            ],
            "parquet-column/src/main/java/parquet/column/statistics/DoubleStatistics.java": [
                3,
                5
            ],
            "parquet-column/src/main/java/parquet/column/statistics/FloatStatistics.java": [
                3,
                5
            ],
            "parquet-column/src/main/java/parquet/column/statistics/IntStatistics.java": [
                3,
                5
            ],
            "parquet-column/src/main/java/parquet/column/statistics/LongStatistics.java": [
                3,
                5
            ],
            "parquet-column/src/main/java/parquet/column/statistics/Statistics.java": [
                5,
                19
            ],
            "parquet-hadoop/src/main/java/parquet/filter2/statisticslevel/StatisticsFilter.java": [
                12,
                51
            ],
            "parquet-hadoop/src/main/java/parquet/format/converter/ParquetMetadataConverter.java": [
                3,
                7
            ],
            "parquet-hadoop/src/test/java/parquet/filter2/statisticslevel/TestStatisticsFilter.java": [
                4,
                4
            ],
            "parquet-hadoop/src/test/java/parquet/hadoop/TestParquetFileWriter.java": [
                0,
                36
            ]
        }
    },
    "0751f97bf6677c3d55aa71542d572dc8fcb9e79a": {
        "datetime": "2015-01-28T16:07:48-08:00",
        "summary": "PARQUET-174: Replaces AssertionError constructor introduced in Java7",
        "message": "PARQUET-174: Replaces AssertionError constructor introduced in Java7\n\nAssertionError(String, Throwable) was introduced in Java7. Replacing it with AssertionError(String) + initCause(Throwable)\n\nAuthor: Laurent Goujon <laurentgo@users.noreply.github.com>\n\nCloses #101 from laurentgo/fix-java7ism and squashes the following commits:\n\nc00fb7c [Laurent Goujon] Replaces AssertionError constructor introduced in Java7\n",
        "diff": {
            "parquet-hadoop/src/test/java/parquet/format/converter/TestParquetMetadataConverter.java": [
                1,
                1
            ]
        }
    },
    "d7dd228d01518f82cf1e81b6ad1f2d393ee063c5": {
        "datetime": "2015-01-29T17:18:07-08:00",
        "summary": "PARQUET-133: Upgrade snappy-java to 1.1.1.6",
        "message": "PARQUET-133: Upgrade snappy-java to 1.1.1.6\n\nUpgrade snappy-java to 1.1.1.6 (the latest vesrion), since 1.0.5 is no longer maintained in https://github.com/xerial/snappy-java, and 1.1.1.6 supports broader platforms including PowerPC, IBM-AIX 6.4, SunOS, etc. And also it has a better native coding loading mechanism (allowing to use snappy-java from multiple class loaders)\n\nAuthor: Taro L. Saito <leo@xerial.org>\n\nCloses #85 from xerial/PARQUET-133 and squashes the following commits:\n\n01d7b78 [Taro L. Saito] PARQUET-133: Upgrade snappy-java to 1.1.1.6\n",
        "diff": {
            "parquet-hadoop/pom.xml": null
        }
    },
    "e505e1fea57e0ab9f1d5edab92546d778a5f41e0": {
        "datetime": "2015-01-29T17:29:06-08:00",
        "summary": "PARQUET-124: normalize path checking to prevent mismatch between URI and ...",
        "message": "PARQUET-124: normalize path checking to prevent mismatch between URI and ...\n\n...path\n\nAuthor: Chris Albright <calbright@cj.com>\n\nCloses #79 from chrisalbright/master and squashes the following commits:\n\nb1b0086 [Chris Albright] Merge remote-tracking branch 'upstream/master'\n9669427 [Chris Albright] PARQUET-124: Adding test (Thanks Ryan Blue) that proves mergeFooters was failing\n8e342ed [Chris Albright] PARQUET-124: normalize path checking to prevent mismatch between URI and path\n",
        "diff": {
            "parquet-hadoop/src/main/java/parquet/hadoop/ParquetFileWriter.java": [
                9,
                9
            ],
            "parquet-hadoop/src/test/java/parquet/hadoop/TestParquetFileWriter.java": [
                24,
                56
            ]
        }
    },
    "b4380f20059dc9e4ccfe2b709587e8069ac0fa34": {
        "datetime": "2015-01-29T17:31:04-08:00",
        "summary": "PARQUET-142: add path filter in ParquetReader",
        "message": "PARQUET-142: add path filter in ParquetReader\n\nCurrently parquet-tools command fails when input is a directory with _SUCCESS file from mapreduce. Filtering those out like ParquetFileReader does fixes the problem.\n\n```\nparquet-cat /tmp/parquet_write_test\nCould not read footer: java.lang.RuntimeException: file:/tmp/parquet_write_test/_SUCCESS is not a Parquet file (too small)\n\n$ tree /tmp/parquet_write_test\n/tmp/parquet_write_test\n\u251c\u2500\u2500 part-m-00000.parquet\n\u2514\u2500\u2500 _SUCCESS\n```\n\nAuthor: Neville Li <neville@spotify.com>\n\nCloses #89 from nevillelyh/gh/path-filter and squashes the following commits:\n\n7377a20 [Neville Li] PARQUET-142: add path filter in ParquetReader\n",
        "diff": {
            "parquet-hadoop/src/main/java/parquet/hadoop/ParquetReader.java": [
                1,
                7
            ]
        }
    },
    "32a9c6d42a3a48314d3f9fe2956bfc8bf49ac5d5": {
        "datetime": "2015-01-29T17:32:54-08:00",
        "summary": "PARQUET-157: Divide by zero fix",
        "message": "PARQUET-157: Divide by zero fix\n\nThere is a divide by zero error in logging code inside the InternalParquetRecordReader. I've been running with this fixed for a while but everytime I revert I hit the problem again. I can't believe anyone else hasn't had this problem. I submitted a Jira ticket a few weeks ago but didn't hear anything on the list so here's the fix.\n\nThis also avoids compiling log statements in some cases where it's unnecessary inside the checkRead method of InternalParquetRecordReader.\n\nAlso added a .gitignore entry to clean up a build artifact.\n\nAuthor: Jim Carroll <jim@dontcallme.com>\n\nCloses #102 from jimfcarroll/divide-by-zero-fix and squashes the following commits:\n\n423200c [Jim Carroll] Filter out parquet-scrooge build artifact from git.\n22337f3 [Jim Carroll] PARQUET-157: Fix a divide by zero error when Parquet runs quickly. Also avoid compiling log statements in some cases where it's unnecessary.\n",
        "diff": {
            ".gitignore": null,
            "parquet-hadoop/src/main/java/parquet/hadoop/InternalParquetRecordReader.java": [
                8,
                11
            ]
        }
    },
    "a635f214af8f4e4e24bbd36934e58b1decf628cc": {
        "datetime": "2015-01-30T09:03:50-08:00",
        "summary": "Update Travis CI link in README.md.",
        "message": "Update Travis CI link in README.md.\n",
        "diff": {
            "README.md": null
        }
    },
    "3df3372a1ee7b6ea74af89f53a614895b8078609": {
        "datetime": "2015-02-02T16:43:01-08:00",
        "summary": "PARQUET-111: Updates for apache release",
        "message": "PARQUET-111: Updates for apache release\n\nUpdates for first Apache release of parquet-mr.\n\nAuthor: Ryan Blue <blue@apache.org>\n\nCloses #109 from rdblue/PARQUET-111-update-for-apache-release and squashes the following commits:\n\nbf19849 [Ryan Blue] PARQUET-111: Add ARRIS copyright header to parquet-tools.\nf1a5c28 [Ryan Blue] PARQUET-111: Update headers in parquet-protobuf.\nee4ea88 [Ryan Blue] PARQUET-111: Remove leaked LICENSE and NOTICE files.\n5bf178b [Ryan Blue] PARQUET-111: Update module names, urls, and binary LICENSE files.\n6736320 [Ryan Blue] PARQUET-111: Add RAT exclusion for auto-generated POM files.\n7db4553 [Ryan Blue] PARQUET-111: Add attribution for Spark dev script to LICENSE.\n45e29f2 [Ryan Blue] PARQUET-111: Update LICENSE and NOTICE.\n516c058 [Ryan Blue] PARQUET-111: Update license headers to pass RAT check.\nda688e3 [Ryan Blue] PARQUET-111: Update NOTICE with Apache boilerplate.\n234715d [Ryan Blue] PARQUET-111: Add DISCLAIMER and KEYS.\nf1d3601 [Ryan Blue] PARQUET-111: Update to use Apache parent POM.\n",
        "diff": {
            "CHANGES.md": null,
            "CONTRIBUTING.md": null,
            "DISCLAIMER": null,
            "KEYS": null,
            "LICENSE": null,
            "NOTICE": null,
            "PoweredBy.md": null,
            "README.md": null,
            "changelog.sh": null,
            "dev/COMMITTERS.md": null,
            "dev/README.md": null,
            "parquet-avro/REVIEWERS.md": null,
            "parquet-avro/pom.xml": null,
            "parquet-avro/src/main/java/parquet/avro/AvroDataSupplier.java": [
                14,
                17
            ],
            "parquet-avro/src/main/java/parquet/avro/AvroIndexedRecordConverter.java": [
                14,
                17
            ],
            "parquet-avro/src/main/java/parquet/avro/AvroParquetInputFormat.java": [
                14,
                17
            ],
            "parquet-avro/src/main/java/parquet/avro/AvroParquetOutputFormat.java": [
                14,
                17
            ],
            "parquet-avro/src/main/java/parquet/avro/AvroParquetReader.java": [
                14,
                17
            ],
            "parquet-avro/src/main/java/parquet/avro/AvroParquetWriter.java": [
                14,
                17
            ],
            "parquet-avro/src/main/java/parquet/avro/AvroReadSupport.java": [
                14,
                17
            ],
            "parquet-avro/src/main/java/parquet/avro/AvroRecordMaterializer.java": [
                14,
                17
            ],
            "parquet-avro/src/main/java/parquet/avro/AvroSchemaConverter.java": [
                14,
                17
            ],
            "parquet-avro/src/main/java/parquet/avro/AvroWriteSupport.java": [
                14,
                17
            ],
            "parquet-avro/src/main/java/parquet/avro/SpecificDataSupplier.java": [
                14,
                17
            ],
            "parquet-avro/src/main/java/parquet/avro/package-info.java": [
                14,
                17
            ],
            "parquet-avro/src/test/java/parquet/avro/TestAvroSchemaConverter.java": [
                14,
                17
            ],
            "parquet-avro/src/test/java/parquet/avro/TestInputOutputFormat.java": [
                14,
                17
            ],
            "parquet-avro/src/test/java/parquet/avro/TestReadWrite.java": [
                14,
                17
            ],
            "parquet-avro/src/test/java/parquet/avro/TestSpecificInputOutputFormat.java": [
                14,
                17
            ],
            "parquet-avro/src/test/java/parquet/avro/TestSpecificReadWrite.java": [
                14,
                17
            ],
            "parquet-avro/src/test/resources/car.avdl": null,
            "parquet-cascading/REVIEWERS.md": null,
            "parquet-cascading/pom.xml": null,
            "parquet-cascading/src/main/java/parquet/cascading/ParquetTBaseScheme.java": [
                14,
                17
            ],
            "parquet-cascading/src/main/java/parquet/cascading/ParquetTupleScheme.java": [
                14,
                17
            ],
            "parquet-cascading/src/main/java/parquet/cascading/ParquetValueScheme.java": [
                14,
                17
            ],
            "parquet-cascading/src/main/java/parquet/cascading/SchemaIntersection.java": [
                14,
                17
            ],
            "parquet-cascading/src/main/java/parquet/cascading/TupleReadSupport.java": [
                14,
                17
            ],
            "parquet-cascading/src/main/java/parquet/cascading/TupleWriteSupport.java": [
                14,
                17
            ],
            "parquet-cascading/src/main/java/parquet/cascading/convert/TupleConverter.java": [
                14,
                17
            ],
            "parquet-cascading/src/main/java/parquet/cascading/convert/TupleRecordMaterializer.java": [
                14,
                17
            ],
            "parquet-cascading/src/test/java/parquet/cascading/TestParquetTBaseScheme.java": [
                14,
                17
            ],
            "parquet-cascading/src/test/java/parquet/cascading/TestParquetTupleScheme.java": [
                14,
                17
            ],
            "parquet-cascading/src/test/thrift/test.thrift": null,
            "parquet-column/REVIEWERS.md": null,
            "parquet-column/pom.xml": null,
            "parquet-column/src/main/java/parquet/column/ColumnDescriptor.java": [
                14,
                17
            ],
            "parquet-column/src/main/java/parquet/column/ColumnReadStore.java": [
                14,
                17
            ],
            "parquet-column/src/main/java/parquet/column/ColumnReader.java": [
                14,
                17
            ],
            "parquet-column/src/main/java/parquet/column/ColumnWriteStore.java": [
                14,
                17
            ],
            "parquet-column/src/main/java/parquet/column/ColumnWriter.java": [
                14,
                17
            ],
            "parquet-column/src/main/java/parquet/column/Dictionary.java": [
                14,
                17
            ],
            "parquet-column/src/main/java/parquet/column/Encoding.java": [
                14,
                17
            ],
            "parquet-column/src/main/java/parquet/column/ParquetProperties.java": [
                0,
                18
            ],
            "parquet-column/src/main/java/parquet/column/UnknownColumnException.java": [
                14,
                17
            ],
            "parquet-column/src/main/java/parquet/column/UnknownColumnTypeException.java": [
                14,
                17
            ],
            "parquet-column/src/main/java/parquet/column/ValuesType.java": [
                14,
                17
            ],
            "parquet-column/src/main/java/parquet/column/impl/ColumnReadStoreImpl.java": [
                14,
                17
            ],
            "parquet-column/src/main/java/parquet/column/impl/ColumnReaderImpl.java": [
                14,
                17
            ],
            "parquet-column/src/main/java/parquet/column/impl/ColumnWriteStoreV1.java": [
                14,
                17
            ],
            "parquet-column/src/main/java/parquet/column/impl/ColumnWriteStoreV2.java": [
                14,
                17
            ],
            "parquet-column/src/main/java/parquet/column/impl/ColumnWriterV1.java": [
                14,
                17
            ],
            "parquet-column/src/main/java/parquet/column/impl/ColumnWriterV2.java": [
                14,
                17
            ],
            "parquet-column/src/main/java/parquet/column/page/DataPage.java": [
                14,
                17
            ],
            "parquet-column/src/main/java/parquet/column/page/DataPageV1.java": [
                0,
                18
            ],
            "parquet-column/src/main/java/parquet/column/page/DataPageV2.java": [
                0,
                18
            ],
            "parquet-column/src/main/java/parquet/column/page/DictionaryPage.java": [
                14,
                17
            ],
            "parquet-column/src/main/java/parquet/column/page/Page.java": [
                0,
                18
            ],
            "parquet-column/src/main/java/parquet/column/page/PageReadStore.java": [
                14,
                17
            ],
            "parquet-column/src/main/java/parquet/column/page/PageReader.java": [
                14,
                17
            ],
            "parquet-column/src/main/java/parquet/column/page/PageWriteStore.java": [
                14,
                17
            ],
            "parquet-column/src/main/java/parquet/column/page/PageWriter.java": [
                14,
                17
            ],
            "parquet-column/src/main/java/parquet/column/statistics/BinaryStatistics.java": [
                14,
                17
            ],
            "parquet-column/src/main/java/parquet/column/statistics/BooleanStatistics.java": [
                14,
                17
            ],
            "parquet-column/src/main/java/parquet/column/statistics/DoubleStatistics.java": [
                14,
                17
            ],
            "parquet-column/src/main/java/parquet/column/statistics/FloatStatistics.java": [
                14,
                17
            ],
            "parquet-column/src/main/java/parquet/column/statistics/IntStatistics.java": [
                14,
                17
            ],
            "parquet-column/src/main/java/parquet/column/statistics/LongStatistics.java": [
                14,
                17
            ],
            "parquet-column/src/main/java/parquet/column/statistics/Statistics.java": [
                14,
                17
            ],
            "parquet-column/src/main/java/parquet/column/statistics/StatisticsClassException.java": [
                14,
                17
            ],
            "parquet-column/src/main/java/parquet/column/values/RequiresFallback.java": [
                14,
                17
            ],
            "parquet-column/src/main/java/parquet/column/values/ValuesReader.java": [
                14,
                17
            ],
            "parquet-column/src/main/java/parquet/column/values/ValuesWriter.java": [
                14,
                17
            ],
            "parquet-column/src/main/java/parquet/column/values/bitpacking/BitPackingValuesReader.java": [
                14,
                17
            ],
            "parquet-column/src/main/java/parquet/column/values/bitpacking/BitPackingValuesWriter.java": [
                14,
                17
            ],
            "parquet-column/src/main/java/parquet/column/values/bitpacking/ByteBitPackingValuesReader.java": [
                14,
                17
            ],
            "parquet-column/src/main/java/parquet/column/values/bitpacking/ByteBitPackingValuesWriter.java": [
                14,
                17
            ],
            "parquet-column/src/main/java/parquet/column/values/boundedint/BitReader.java": [
                14,
                17
            ],
            "parquet-column/src/main/java/parquet/column/values/boundedint/BitWriter.java": [
                14,
                17
            ],
            "parquet-column/src/main/java/parquet/column/values/boundedint/BoundedIntValuesFactory.java": [
                14,
                17
            ],
            "parquet-column/src/main/java/parquet/column/values/boundedint/BoundedIntValuesReader.java": [
                14,
                17
            ],
            "parquet-column/src/main/java/parquet/column/values/boundedint/BoundedIntValuesWriter.java": [
                14,
                17
            ],
            "parquet-column/src/main/java/parquet/column/values/boundedint/DevNullValuesWriter.java": [
                14,
                17
            ],
            "parquet-column/src/main/java/parquet/column/values/boundedint/ZeroIntegerValuesReader.java": [
                14,
                17
            ],
            "parquet-column/src/main/java/parquet/column/values/delta/DeltaBinaryPackingConfig.java": [
                14,
                17
            ],
            "parquet-column/src/main/java/parquet/column/values/delta/DeltaBinaryPackingValuesReader.java": [
                14,
                17
            ],
            "parquet-column/src/main/java/parquet/column/values/delta/DeltaBinaryPackingValuesWriter.java": [
                14,
                17
            ],
            "parquet-column/src/main/java/parquet/column/values/deltalengthbytearray/DeltaLengthByteArrayValuesReader.java": [
                14,
                17
            ],
            "parquet-column/src/main/java/parquet/column/values/deltalengthbytearray/DeltaLengthByteArrayValuesWriter.java": [
                14,
                17
            ],
            "parquet-column/src/main/java/parquet/column/values/deltastrings/DeltaByteArrayReader.java": [
                14,
                17
            ],
            "parquet-column/src/main/java/parquet/column/values/deltastrings/DeltaByteArrayWriter.java": [
                14,
                17
            ],
            "parquet-column/src/main/java/parquet/column/values/dictionary/DictionaryValuesReader.java": [
                14,
                17
            ],
            "parquet-column/src/main/java/parquet/column/values/dictionary/DictionaryValuesWriter.java": [
                14,
                17
            ],
            "parquet-column/src/main/java/parquet/column/values/dictionary/IntList.java": [
                14,
                17
            ],
            "parquet-column/src/main/java/parquet/column/values/dictionary/PlainValuesDictionary.java": [
                14,
                17
            ],
            "parquet-column/src/main/java/parquet/column/values/fallback/FallbackValuesWriter.java": [
                14,
                17
            ],
            "parquet-column/src/main/java/parquet/column/values/plain/BinaryPlainValuesReader.java": [
                14,
                17
            ],
            "parquet-column/src/main/java/parquet/column/values/plain/BooleanPlainValuesReader.java": [
                14,
                17
            ],
            "parquet-column/src/main/java/parquet/column/values/plain/BooleanPlainValuesWriter.java": [
                14,
                17
            ],
            "parquet-column/src/main/java/parquet/column/values/plain/FixedLenByteArrayPlainValuesReader.java": [
                14,
                17
            ],
            "parquet-column/src/main/java/parquet/column/values/plain/FixedLenByteArrayPlainValuesWriter.java": [
                14,
                17
            ],
            "parquet-column/src/main/java/parquet/column/values/plain/PlainValuesReader.java": [
                14,
                17
            ],
            "parquet-column/src/main/java/parquet/column/values/plain/PlainValuesWriter.java": [
                14,
                17
            ],
            "parquet-column/src/main/java/parquet/column/values/rle/RunLengthBitPackingHybridDecoder.java": [
                14,
                17
            ],
            "parquet-column/src/main/java/parquet/column/values/rle/RunLengthBitPackingHybridEncoder.java": [
                14,
                17
            ],
            "parquet-column/src/main/java/parquet/column/values/rle/RunLengthBitPackingHybridValuesReader.java": [
                14,
                17
            ],
            "parquet-column/src/main/java/parquet/column/values/rle/RunLengthBitPackingHybridValuesWriter.java": [
                14,
                17
            ],
            "parquet-column/src/main/java/parquet/example/DummyRecordConverter.java": [
                14,
                17
            ],
            "parquet-column/src/main/java/parquet/example/Paper.java": [
                14,
                17
            ],
            "parquet-column/src/main/java/parquet/example/data/Group.java": [
                14,
                17
            ],
            "parquet-column/src/main/java/parquet/example/data/GroupFactory.java": [
                14,
                17
            ],
            "parquet-column/src/main/java/parquet/example/data/GroupValueSource.java": [
                14,
                17
            ],
            "parquet-column/src/main/java/parquet/example/data/GroupWriter.java": [
                14,
                17
            ],
            "parquet-column/src/main/java/parquet/example/data/simple/BinaryValue.java": [
                14,
                17
            ],
            "parquet-column/src/main/java/parquet/example/data/simple/BooleanValue.java": [
                14,
                17
            ],
            "parquet-column/src/main/java/parquet/example/data/simple/DoubleValue.java": [
                14,
                17
            ],
            "parquet-column/src/main/java/parquet/example/data/simple/FloatValue.java": [
                14,
                17
            ],
            "parquet-column/src/main/java/parquet/example/data/simple/Int96Value.java": [
                0,
                18
            ],
            "parquet-column/src/main/java/parquet/example/data/simple/IntegerValue.java": [
                14,
                17
            ],
            "parquet-column/src/main/java/parquet/example/data/simple/LongValue.java": [
                14,
                17
            ],
            "parquet-column/src/main/java/parquet/example/data/simple/NanoTime.java": [
                0,
                18
            ],
            "parquet-column/src/main/java/parquet/example/data/simple/Primitive.java": [
                14,
                17
            ],
            "parquet-column/src/main/java/parquet/example/data/simple/SimpleGroup.java": [
                14,
                17
            ],
            "parquet-column/src/main/java/parquet/example/data/simple/SimpleGroupFactory.java": [
                14,
                17
            ],
            "parquet-column/src/main/java/parquet/example/data/simple/convert/GroupRecordConverter.java": [
                14,
                17
            ],
            "parquet-column/src/main/java/parquet/example/data/simple/convert/SimpleGroupConverter.java": [
                14,
                17
            ],
            "parquet-column/src/main/java/parquet/example/data/simple/convert/SimplePrimitiveConverter.java": [
                14,
                17
            ],
            "parquet-column/src/main/java/parquet/filter/AndRecordFilter.java": [
                14,
                17
            ],
            "parquet-column/src/main/java/parquet/filter/ColumnPredicates.java": [
                14,
                17
            ],
            "parquet-column/src/main/java/parquet/filter/ColumnRecordFilter.java": [
                14,
                17
            ],
            "parquet-column/src/main/java/parquet/filter/NotRecordFilter.java": [
                14,
                17
            ],
            "parquet-column/src/main/java/parquet/filter/OrRecordFilter.java": [
                14,
                17
            ],
            "parquet-column/src/main/java/parquet/filter/PagedRecordFilter.java": [
                14,
                17
            ],
            "parquet-column/src/main/java/parquet/filter/RecordFilter.java": [
                14,
                17
            ],
            "parquet-column/src/main/java/parquet/filter/UnboundRecordFilter.java": [
                14,
                17
            ],
            "parquet-column/src/main/java/parquet/filter2/compat/FilterCompat.java": [
                0,
                18
            ],
            "parquet-column/src/main/java/parquet/filter2/predicate/FilterApi.java": [
                0,
                18
            ],
            "parquet-column/src/main/java/parquet/filter2/predicate/FilterPredicate.java": [
                0,
                18
            ],
            "parquet-column/src/main/java/parquet/filter2/predicate/LogicalInverseRewriter.java": [
                0,
                18
            ],
            "parquet-column/src/main/java/parquet/filter2/predicate/LogicalInverter.java": [
                0,
                18
            ],
            "parquet-column/src/main/java/parquet/filter2/predicate/Operators.java": [
                0,
                18
            ],
            "parquet-column/src/main/java/parquet/filter2/predicate/SchemaCompatibilityValidator.java": [
                0,
                18
            ],
            "parquet-column/src/main/java/parquet/filter2/predicate/Statistics.java": [
                0,
                18
            ],
            "parquet-column/src/main/java/parquet/filter2/predicate/UserDefinedPredicate.java": [
                0,
                18
            ],
            "parquet-column/src/main/java/parquet/filter2/predicate/ValidTypeMap.java": [
                0,
                18
            ],
            "parquet-column/src/main/java/parquet/filter2/recordlevel/FilteringGroupConverter.java": [
                0,
                18
            ],
            "parquet-column/src/main/java/parquet/filter2/recordlevel/FilteringPrimitiveConverter.java": [
                0,
                18
            ],
            "parquet-column/src/main/java/parquet/filter2/recordlevel/FilteringRecordMaterializer.java": [
                0,
                18
            ],
            "parquet-column/src/main/java/parquet/filter2/recordlevel/IncrementallyUpdatedFilterPredicate.java": [
                0,
                18
            ],
            "parquet-column/src/main/java/parquet/filter2/recordlevel/IncrementallyUpdatedFilterPredicateBuilderBase.java": [
                0,
                18
            ],
            "parquet-column/src/main/java/parquet/filter2/recordlevel/IncrementallyUpdatedFilterPredicateEvaluator.java": [
                0,
                18
            ],
            "parquet-column/src/main/java/parquet/filter2/recordlevel/IncrementallyUpdatedFilterPredicateResetter.java": [
                0,
                18
            ],
            "parquet-column/src/main/java/parquet/io/BaseRecordReader.java": [
                14,
                17
            ],
            "parquet-column/src/main/java/parquet/io/ColumnIO.java": [
                14,
                17
            ],
            "parquet-column/src/main/java/parquet/io/ColumnIOFactory.java": [
                14,
                17
            ],
            "parquet-column/src/main/java/parquet/io/CompilationException.java": [
                14,
                17
            ],
            "parquet-column/src/main/java/parquet/io/EmptyRecordReader.java": [
                14,
                17
            ],
            "parquet-column/src/main/java/parquet/io/FilteredRecordReader.java": [
                14,
                17
            ],
            "parquet-column/src/main/java/parquet/io/GroupColumnIO.java": [
                14,
                17
            ],
            "parquet-column/src/main/java/parquet/io/InvalidRecordException.java": [
                14,
                17
            ],
            "parquet-column/src/main/java/parquet/io/MessageColumnIO.java": [
                14,
                17
            ],
            "parquet-column/src/main/java/parquet/io/ParquetDecodingException.java": [
                14,
                17
            ],
            "parquet-column/src/main/java/parquet/io/ParquetEncodingException.java": [
                14,
                17
            ],
            "parquet-column/src/main/java/parquet/io/PrimitiveColumnIO.java": [
                14,
                17
            ],
            "parquet-column/src/main/java/parquet/io/RecordConsumerLoggingWrapper.java": [
                14,
                17
            ],
            "parquet-column/src/main/java/parquet/io/RecordReader.java": [
                14,
                17
            ],
            "parquet-column/src/main/java/parquet/io/RecordReaderImplementation.java": [
                14,
                17
            ],
            "parquet-column/src/main/java/parquet/io/ValidatingRecordConsumer.java": [
                14,
                17
            ],
            "parquet-column/src/main/java/parquet/io/api/Binary.java": [
                14,
                17
            ],
            "parquet-column/src/main/java/parquet/io/api/Converter.java": [
                14,
                17
            ],
            "parquet-column/src/main/java/parquet/io/api/GroupConverter.java": [
                14,
                17
            ],
            "parquet-column/src/main/java/parquet/io/api/PrimitiveConverter.java": [
                14,
                17
            ],
            "parquet-column/src/main/java/parquet/io/api/RecordConsumer.java": [
                14,
                17
            ],
            "parquet-column/src/main/java/parquet/io/api/RecordMaterializer.java": [
                14,
                17
            ],
            "parquet-column/src/main/java/parquet/schema/ConversionPatterns.java": [
                14,
                17
            ],
            "parquet-column/src/main/java/parquet/schema/DecimalMetadata.java": [
                0,
                18
            ],
            "parquet-column/src/main/java/parquet/schema/GroupType.java": [
                14,
                17
            ],
            "parquet-column/src/main/java/parquet/schema/IncompatibleSchemaModificationException.java": [
                14,
                17
            ],
            "parquet-column/src/main/java/parquet/schema/MessageType.java": [
                14,
                17
            ],
            "parquet-column/src/main/java/parquet/schema/MessageTypeParser.java": [
                14,
                17
            ],
            "parquet-column/src/main/java/parquet/schema/OriginalType.java": [
                14,
                17
            ],
            "parquet-column/src/main/java/parquet/schema/PrimitiveType.java": [
                14,
                17
            ],
            "parquet-column/src/main/java/parquet/schema/Type.java": [
                14,
                17
            ],
            "parquet-column/src/main/java/parquet/schema/TypeConverter.java": [
                14,
                17
            ],
            "parquet-column/src/main/java/parquet/schema/TypeVisitor.java": [
                14,
                17
            ],
            "parquet-column/src/main/java/parquet/schema/Types.java": [
                0,
                18
            ],
            "parquet-column/src/main/resources/META-INF/LICENSE": null,
            "parquet-column/src/test/java/parquet/column/impl/TestColumnReaderImpl.java": [
                0,
                18
            ],
            "parquet-column/src/test/java/parquet/column/mem/TestMemColumn.java": [
                14,
                17
            ],
            "parquet-column/src/test/java/parquet/column/mem/TestMemPageStore.java": [
                14,
                17
            ],
            "parquet-column/src/test/java/parquet/column/page/mem/MemPageReader.java": [
                14,
                17
            ],
            "parquet-column/src/test/java/parquet/column/page/mem/MemPageStore.java": [
                14,
                17
            ],
            "parquet-column/src/test/java/parquet/column/page/mem/MemPageWriter.java": [
                14,
                17
            ],
            "parquet-column/src/test/java/parquet/column/statistics/TestStatistics.java": [
                14,
                17
            ],
            "parquet-column/src/test/java/parquet/column/values/RandomStr.java": [
                14,
                17
            ],
            "parquet-column/src/test/java/parquet/column/values/Utils.java": [
                14,
                17
            ],
            "parquet-column/src/test/java/parquet/column/values/bitpacking/BitPackingPerfTest.java": [
                14,
                17
            ],
            "parquet-column/src/test/java/parquet/column/values/bitpacking/TestBitPackingColumn.java": [
                14,
                17
            ],
            "parquet-column/src/test/java/parquet/column/values/boundedint/TestBoundedColumns.java": [
                14,
                17
            ],
            "parquet-column/src/test/java/parquet/column/values/delta/DeltaBinaryPackingValuesWriterTest.java": [
                14,
                17
            ],
            "parquet-column/src/test/java/parquet/column/values/delta/benchmark/BenchMarkTest.java": [
                14,
                17
            ],
            "parquet-column/src/test/java/parquet/column/values/delta/benchmark/BenchmarkIntegerOutputSize.java": [
                14,
                17
            ],
            "parquet-column/src/test/java/parquet/column/values/delta/benchmark/BenchmarkReadingRandomIntegers.java": [
                14,
                17
            ],
            "parquet-column/src/test/java/parquet/column/values/delta/benchmark/RandomWritingBenchmarkTest.java": [
                14,
                17
            ],
            "parquet-column/src/test/java/parquet/column/values/delta/benchmark/SmallRangeWritingBenchmarkTest.java": [
                14,
                17
            ],
            "parquet-column/src/test/java/parquet/column/values/deltalengthbytearray/TestDeltaLengthByteArray.java": [
                14,
                17
            ],
            "parquet-column/src/test/java/parquet/column/values/deltalengthbytearray/benchmark/BenchmarkDeltaLengthByteArray.java": [
                14,
                17
            ],
            "parquet-column/src/test/java/parquet/column/values/deltastrings/TestDeltaByteArray.java": [
                14,
                17
            ],
            "parquet-column/src/test/java/parquet/column/values/deltastrings/benchmark/BenchmarkDeltaByteArray.java": [
                14,
                17
            ],
            "parquet-column/src/test/java/parquet/column/values/dictionary/TestDictionary.java": [
                14,
                17
            ],
            "parquet-column/src/test/java/parquet/column/values/rle/RunLengthBitPackingHybridIntegrationTest.java": [
                14,
                17
            ],
            "parquet-column/src/test/java/parquet/column/values/rle/TestRunLengthBitPackingHybridEncoder.java": [
                14,
                17
            ],
            "parquet-column/src/test/java/parquet/filter2/predicate/DummyUdp.java": [
                0,
                18
            ],
            "parquet-column/src/test/java/parquet/filter2/predicate/TestFilterApiMethods.java": [
                0,
                18
            ],
            "parquet-column/src/test/java/parquet/filter2/predicate/TestLogicalInverseRewriter.java": [
                0,
                18
            ],
            "parquet-column/src/test/java/parquet/filter2/predicate/TestLogicalInverter.java": [
                0,
                18
            ],
            "parquet-column/src/test/java/parquet/filter2/predicate/TestSchemaCompatibilityValidator.java": [
                0,
                18
            ],
            "parquet-column/src/test/java/parquet/filter2/predicate/TestValidTypeMap.java": [
                0,
                18
            ],
            "parquet-column/src/test/java/parquet/filter2/recordlevel/TestIncrementallyUpdatedFilterPredicateEvaluator.java": [
                0,
                18
            ],
            "parquet-column/src/test/java/parquet/filter2/recordlevel/TestIncrementallyUpdatedFilterPredicateResetter.java": [
                0,
                18
            ],
            "parquet-column/src/test/java/parquet/filter2/recordlevel/TestValueInspector.java": [
                0,
                18
            ],
            "parquet-column/src/test/java/parquet/io/ConverterConsumer.java": [
                14,
                17
            ],
            "parquet-column/src/test/java/parquet/io/ExpectationValidatingConverter.java": [
                14,
                17
            ],
            "parquet-column/src/test/java/parquet/io/ExpectationValidatingRecordConsumer.java": [
                14,
                17
            ],
            "parquet-column/src/test/java/parquet/io/PerfTest.java": [
                14,
                17
            ],
            "parquet-column/src/test/java/parquet/io/TestColumnIO.java": [
                14,
                17
            ],
            "parquet-column/src/test/java/parquet/io/TestFiltered.java": [
                14,
                17
            ],
            "parquet-column/src/test/java/parquet/parser/TestParquetParser.java": [
                14,
                17
            ],
            "parquet-column/src/test/java/parquet/schema/TestMessageType.java": [
                14,
                17
            ],
            "parquet-column/src/test/java/parquet/schema/TestTypeBuilders.java": [
                0,
                18
            ],
            "parquet-common/REVIEWERS.md": null,
            "parquet-common/pom.xml": null,
            "parquet-common/src/main/java/parquet/Closeables.java": [
                0,
                18
            ],
            "parquet-common/src/main/java/parquet/Ints.java": [
                14,
                17
            ],
            "parquet-common/src/main/java/parquet/Log.java": [
                14,
                17
            ],
            "parquet-common/src/main/java/parquet/ParquetRuntimeException.java": [
                14,
                17
            ],
            "parquet-common/src/main/java/parquet/Preconditions.java": [
                14,
                17
            ],
            "parquet-common/src/main/java/parquet/Version.java": [
                14,
                17
            ],
            "parquet-common/src/main/java/parquet/bytes/BytesUtils.java": [
                14,
                17
            ],
            "parquet-common/src/main/java/parquet/common/internal/Canonicalizer.java": [
                14,
                17
            ],
            "parquet-common/src/main/java/parquet/common/schema/ColumnPath.java": [
                14,
                17
            ],
            "parquet-common/src/test/java/parquet/TestLog.java": [
                14,
                17
            ],
            "parquet-common/src/test/java/parquet/bytes/TestBytesUtil.java": [
                14,
                17
            ],
            "parquet-encoding/REVIEWERS.md": null,
            "parquet-encoding/pom.xml": null,
            "parquet-encoding/src/main/java/parquet/bytes/BytesInput.java": [
                14,
                17
            ],
            "parquet-encoding/src/main/java/parquet/bytes/CapacityByteArrayOutputStream.java": [
                14,
                17
            ],
            "parquet-encoding/src/main/java/parquet/bytes/LittleEndianDataInputStream.java": [
                14,
                17
            ],
            "parquet-encoding/src/main/java/parquet/bytes/LittleEndianDataOutputStream.java": [
                14,
                17
            ],
            "parquet-encoding/src/main/java/parquet/column/values/bitpacking/BitPacking.java": [
                14,
                17
            ],
            "parquet-encoding/src/main/java/parquet/column/values/bitpacking/ByteBasedBitPackingEncoder.java": [
                14,
                17
            ],
            "parquet-encoding/src/main/java/parquet/column/values/bitpacking/BytePacker.java": [
                14,
                17
            ],
            "parquet-encoding/src/main/java/parquet/column/values/bitpacking/BytePackerFactory.java": [
                14,
                17
            ],
            "parquet-encoding/src/main/java/parquet/column/values/bitpacking/IntPacker.java": [
                14,
                17
            ],
            "parquet-encoding/src/main/java/parquet/column/values/bitpacking/IntPackerFactory.java": [
                14,
                17
            ],
            "parquet-encoding/src/main/java/parquet/column/values/bitpacking/Packer.java": [
                14,
                17
            ],
            "parquet-encoding/src/main/resources/META-INF/LICENSE": null,
            "parquet-encoding/src/test/java/parquet/bytes/TestCapacityByteArrayOutputStream.java": [
                14,
                17
            ],
            "parquet-encoding/src/test/java/parquet/column/values/bitpacking/TestBitPacking.java": [
                14,
                17
            ],
            "parquet-encoding/src/test/java/parquet/column/values/bitpacking/TestByteBasedBitPackingEncoder.java": [
                14,
                17
            ],
            "parquet-encoding/src/test/java/parquet/column/values/bitpacking/TestByteBitPacking.java": [
                14,
                17
            ],
            "parquet-encoding/src/test/java/parquet/column/values/bitpacking/TestLemireBitPacking.java": [
                14,
                17
            ],
            "parquet-generator/REVIEWERS.md": null,
            "parquet-generator/pom.xml": null,
            "parquet-generator/src/main/java/parquet/encoding/Generator.java": [
                14,
                17
            ],
            "parquet-generator/src/main/java/parquet/encoding/bitpacking/ByteBasedBitPackingGenerator.java": [
                14,
                17
            ],
            "parquet-generator/src/main/java/parquet/encoding/bitpacking/IntBasedBitPackingGenerator.java": [
                14,
                17
            ],
            "parquet-generator/src/main/java/parquet/filter2/Generator.java": [
                0,
                18
            ],
            "parquet-generator/src/main/java/parquet/filter2/IncrementallyUpdatedFilterPredicateGenerator.java": [
                0,
                18
            ],
            "parquet-generator/src/main/resources/META-INF/LICENSE": null,
            "parquet-hadoop-bundle/pom.xml": null,
            "parquet-hadoop-bundle/src/main/resources/META-INF/LICENSE": null,
            "parquet-hadoop-bundle/src/main/resources/parquet/bundle": null,
            "parquet-hadoop/REVIEWERS.md": null,
            "parquet-hadoop/pom.xml": null,
            "parquet-hadoop/src/main/java/parquet/filter2/compat/RowGroupFilter.java": [
                0,
                18
            ],
            "parquet-hadoop/src/main/java/parquet/filter2/statisticslevel/StatisticsFilter.java": [
                0,
                18
            ],
            "parquet-hadoop/src/main/java/parquet/format/converter/ParquetMetadataConverter.java": [
                14,
                17
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/BadConfigurationException.java": [
                14,
                17
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/CodecFactory.java": [
                14,
                17
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/ColumnChunkPageReadStore.java": [
                14,
                17
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/ColumnChunkPageWriteStore.java": [
                14,
                17
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/Footer.java": [
                14,
                17
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/InternalParquetRecordReader.java": [
                14,
                17
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/InternalParquetRecordWriter.java": [
                14,
                17
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/LruCache.java": [
                0,
                18
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/MemoryManager.java": [
                14,
                17
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/ParquetFileReader.java": [
                14,
                17
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/ParquetFileWriter.java": [
                14,
                17
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/ParquetInputFormat.java": [
                14,
                17
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/ParquetInputSplit.java": [
                14,
                17
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/ParquetOutputCommitter.java": [
                14,
                17
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/ParquetOutputFormat.java": [
                14,
                17
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/ParquetReader.java": [
                14,
                17
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/ParquetRecordReader.java": [
                11,
                14
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/ParquetRecordWriter.java": [
                14,
                17
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/ParquetWriter.java": [
                14,
                17
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/PrintFooter.java": [
                14,
                17
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/api/DelegatingReadSupport.java": [
                0,
                18
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/api/DelegatingWriteSupport.java": [
                0,
                18
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/api/InitContext.java": [
                14,
                17
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/api/ReadSupport.java": [
                14,
                17
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/api/WriteSupport.java": [
                14,
                17
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/api/package-info.java": [
                12,
                16
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/codec/CodecConfig.java": [
                14,
                17
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/codec/CompressionCodecNotSupportedException.java": [
                14,
                17
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/codec/NonBlockedCompressorStream.java": [
                14,
                17
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/codec/NonBlockedDecompressorStream.java": [
                14,
                17
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/codec/SnappyCodec.java": [
                14,
                17
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/codec/SnappyCompressor.java": [
                14,
                17
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/codec/SnappyDecompressor.java": [
                14,
                17
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/codec/SnappyUtil.java": [
                14,
                17
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/example/ExampleInputFormat.java": [
                14,
                17
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/example/ExampleOutputFormat.java": [
                14,
                17
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/example/GroupReadSupport.java": [
                14,
                17
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/example/GroupWriteSupport.java": [
                14,
                17
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/mapred/Container.java": [
                14,
                17
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/mapred/DeprecatedParquetInputFormat.java": [
                14,
                17
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/mapred/DeprecatedParquetOutputFormat.java": [
                14,
                17
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/metadata/BlockMetaData.java": [
                14,
                17
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/metadata/ColumnChunkMetaData.java": [
                14,
                17
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/metadata/ColumnChunkProperties.java": [
                14,
                17
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/metadata/CompressionCodecName.java": [
                14,
                17
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/metadata/EncodingList.java": [
                14,
                17
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/metadata/FileMetaData.java": [
                14,
                17
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/metadata/GlobalMetaData.java": [
                14,
                17
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/metadata/ParquetMetadata.java": [
                14,
                17
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/package-info.java": [
                12,
                16
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/util/ConfigurationUtil.java": [
                14,
                17
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/util/ContextUtil.java": [
                14,
                17
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/util/SerializationUtil.java": [
                0,
                18
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/util/counters/BenchmarkCounter.java": [
                14,
                17
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/util/counters/CounterLoader.java": [
                14,
                17
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/util/counters/ICounter.java": [
                14,
                17
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/util/counters/mapred/MapRedCounterAdapter.java": [
                14,
                17
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/util/counters/mapred/MapRedCounterLoader.java": [
                14,
                17
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/util/counters/mapreduce/MapReduceCounterAdapter.java": [
                14,
                17
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/util/counters/mapreduce/MapReduceCounterLoader.java": [
                14,
                17
            ],
            "parquet-hadoop/src/test/java/parquet/filter2/compat/TestRowGroupFilter.java": [
                0,
                18
            ],
            "parquet-hadoop/src/test/java/parquet/filter2/recordlevel/PhoneBookWriter.java": [
                0,
                18
            ],
            "parquet-hadoop/src/test/java/parquet/filter2/recordlevel/TestRecordLevelFilters.java": [
                0,
                18
            ],
            "parquet-hadoop/src/test/java/parquet/filter2/statisticslevel/TestStatisticsFilter.java": [
                0,
                18
            ],
            "parquet-hadoop/src/test/java/parquet/format/converter/TestParquetMetadataConverter.java": [
                14,
                17
            ],
            "parquet-hadoop/src/test/java/parquet/hadoop/DeprecatedInputFormatTest.java": [
                14,
                17
            ],
            "parquet-hadoop/src/test/java/parquet/hadoop/DeprecatedOutputFormatTest.java": [
                14,
                17
            ],
            "parquet-hadoop/src/test/java/parquet/hadoop/TestColumnChunkPageWriteStore.java": [
                0,
                18
            ],
            "parquet-hadoop/src/test/java/parquet/hadoop/TestInputFormat.java": [
                14,
                17
            ],
            "parquet-hadoop/src/test/java/parquet/hadoop/TestLruCache.java": [
                0,
                18
            ],
            "parquet-hadoop/src/test/java/parquet/hadoop/TestMemoryManager.java": [
                14,
                17
            ],
            "parquet-hadoop/src/test/java/parquet/hadoop/TestParquetFileWriter.java": [
                14,
                17
            ],
            "parquet-hadoop/src/test/java/parquet/hadoop/TestParquetWriter.java": [
                0,
                18
            ],
            "parquet-hadoop/src/test/java/parquet/hadoop/TestParquetWriterNewPage.java": [
                0,
                18
            ],
            "parquet-hadoop/src/test/java/parquet/hadoop/TestSnappyCodec.java": [
                14,
                17
            ],
            "parquet-hadoop/src/test/java/parquet/hadoop/TestUtils.java": [
                0,
                18
            ],
            "parquet-hadoop/src/test/java/parquet/hadoop/codec/CodecConfigTest.java": [
                14,
                17
            ],
            "parquet-hadoop/src/test/java/parquet/hadoop/example/GroupReadSupportTest.java": [
                14,
                17
            ],
            "parquet-hadoop/src/test/java/parquet/hadoop/example/TestInputOutputFormat.java": [
                14,
                17
            ],
            "parquet-hadoop/src/test/java/parquet/hadoop/metadata/TestColumnChunkMetaData.java": [
                0,
                18
            ],
            "parquet-hadoop/src/test/java/parquet/hadoop/util/TestSerializationUtil.java": [
                0,
                18
            ],
            "parquet-hive-bundle/pom.xml": null,
            "parquet-hive-bundle/src/main/resources/META-INF/LICENSE": null,
            "parquet-hive-bundle/src/main/resources/parquet/bundle": null,
            "parquet-hive/REVIEWERS.md": null,
            "parquet-hive/parquet-hive-binding/parquet-hive-0.10-binding/pom.xml": null,
            "parquet-hive/parquet-hive-binding/parquet-hive-0.10-binding/src/main/java/parquet/hive/internal/Hive010Binding.java": [
                0,
                18
            ],
            "parquet-hive/parquet-hive-binding/parquet-hive-0.12-binding/pom.xml": null,
            "parquet-hive/parquet-hive-binding/parquet-hive-0.12-binding/src/main/java/parquet/hive/internal/Hive012Binding.java": [
                0,
                18
            ],
            "parquet-hive/parquet-hive-binding/parquet-hive-binding-bundle/pom.xml": null,
            "parquet-hive/parquet-hive-binding/parquet-hive-binding-bundle/src/assemble/uberjar.xml": null,
            "parquet-hive/parquet-hive-binding/parquet-hive-binding-bundle/src/main/resources/parquet/bundle": null,
            "parquet-hive/parquet-hive-binding/parquet-hive-binding-factory/pom.xml": null,
            "parquet-hive/parquet-hive-binding/parquet-hive-binding-factory/src/main/java/parquet/hive/HiveBindingFactory.java": [
                12,
                17
            ],
            "parquet-hive/parquet-hive-binding/parquet-hive-binding-factory/src/test/java/parquet/hive/TestHiveBindingFactory.java": [
                0,
                18
            ],
            "parquet-hive/parquet-hive-binding/parquet-hive-binding-interface/pom.xml": null,
            "parquet-hive/parquet-hive-binding/parquet-hive-binding-interface/src/main/java/parquet/hive/HiveBinding.java": [
                12,
                17
            ],
            "parquet-hive/parquet-hive-binding/parquet-hive-binding-interface/src/main/java/parquet/hive/internal/AbstractHiveBinding.java": [
                0,
                18
            ],
            "parquet-hive/parquet-hive-binding/pom.xml": null,
            "parquet-hive/parquet-hive-storage-handler/pom.xml": null,
            "parquet-hive/parquet-hive-storage-handler/src/main/java/org/apache/hadoop/hive/ql/io/IOConstants.java": [
                9,
                10
            ],
            "parquet-hive/parquet-hive-storage-handler/src/main/java/org/apache/hadoop/hive/ql/io/parquet/MapredParquetInputFormat.java": [
                12,
                17
            ],
            "parquet-hive/parquet-hive-storage-handler/src/main/java/org/apache/hadoop/hive/ql/io/parquet/MapredParquetOutputFormat.java": [
                12,
                17
            ],
            "parquet-hive/parquet-hive-storage-handler/src/main/java/org/apache/hadoop/hive/ql/io/parquet/convert/ArrayWritableGroupConverter.java": [
                12,
                17
            ],
            "parquet-hive/parquet-hive-storage-handler/src/main/java/org/apache/hadoop/hive/ql/io/parquet/convert/DataWritableGroupConverter.java": [
                12,
                17
            ],
            "parquet-hive/parquet-hive-storage-handler/src/main/java/org/apache/hadoop/hive/ql/io/parquet/convert/DataWritableRecordConverter.java": [
                12,
                17
            ],
            "parquet-hive/parquet-hive-storage-handler/src/main/java/org/apache/hadoop/hive/ql/io/parquet/convert/ETypeConverter.java": [
                12,
                17
            ],
            "parquet-hive/parquet-hive-storage-handler/src/main/java/org/apache/hadoop/hive/ql/io/parquet/convert/HiveGroupConverter.java": [
                12,
                17
            ],
            "parquet-hive/parquet-hive-storage-handler/src/main/java/org/apache/hadoop/hive/ql/io/parquet/convert/HiveSchemaConverter.java": [
                12,
                17
            ],
            "parquet-hive/parquet-hive-storage-handler/src/main/java/org/apache/hadoop/hive/ql/io/parquet/read/DataWritableReadSupport.java": [
                12,
                17
            ],
            "parquet-hive/parquet-hive-storage-handler/src/main/java/org/apache/hadoop/hive/ql/io/parquet/read/ParquetRecordReaderWrapper.java": [
                12,
                17
            ],
            "parquet-hive/parquet-hive-storage-handler/src/main/java/org/apache/hadoop/hive/ql/io/parquet/serde/AbstractParquetMapInspector.java": [
                12,
                17
            ],
            "parquet-hive/parquet-hive-storage-handler/src/main/java/org/apache/hadoop/hive/ql/io/parquet/serde/ArrayWritableObjectInspector.java": [
                12,
                17
            ],
            "parquet-hive/parquet-hive-storage-handler/src/main/java/org/apache/hadoop/hive/ql/io/parquet/serde/DeepParquetHiveMapInspector.java": [
                12,
                17
            ],
            "parquet-hive/parquet-hive-storage-handler/src/main/java/org/apache/hadoop/hive/ql/io/parquet/serde/ParquetHiveArrayInspector.java": [
                12,
                17
            ],
            "parquet-hive/parquet-hive-storage-handler/src/main/java/org/apache/hadoop/hive/ql/io/parquet/serde/ParquetHiveSerDe.java": [
                12,
                17
            ],
            "parquet-hive/parquet-hive-storage-handler/src/main/java/org/apache/hadoop/hive/ql/io/parquet/serde/StandardParquetHiveMapInspector.java": [
                12,
                17
            ],
            "parquet-hive/parquet-hive-storage-handler/src/main/java/org/apache/hadoop/hive/ql/io/parquet/serde/primitive/ParquetByteInspector.java": [
                12,
                17
            ],
            "parquet-hive/parquet-hive-storage-handler/src/main/java/org/apache/hadoop/hive/ql/io/parquet/serde/primitive/ParquetPrimitiveInspectorFactory.java": [
                12,
                17
            ],
            "parquet-hive/parquet-hive-storage-handler/src/main/java/org/apache/hadoop/hive/ql/io/parquet/serde/primitive/ParquetShortInspector.java": [
                12,
                17
            ],
            "parquet-hive/parquet-hive-storage-handler/src/main/java/org/apache/hadoop/hive/ql/io/parquet/writable/BigDecimalWritable.java": [
                12,
                17
            ],
            "parquet-hive/parquet-hive-storage-handler/src/main/java/org/apache/hadoop/hive/ql/io/parquet/writable/BinaryWritable.java": [
                12,
                17
            ],
            "parquet-hive/parquet-hive-storage-handler/src/main/java/org/apache/hadoop/hive/ql/io/parquet/write/DataWritableWriteSupport.java": [
                12,
                17
            ],
            "parquet-hive/parquet-hive-storage-handler/src/main/java/org/apache/hadoop/hive/ql/io/parquet/write/DataWritableWriter.java": [
                12,
                17
            ],
            "parquet-hive/parquet-hive-storage-handler/src/main/java/org/apache/hadoop/hive/ql/io/parquet/write/ParquetRecordWriterWrapper.java": [
                12,
                17
            ],
            "parquet-hive/parquet-hive-storage-handler/src/main/java/org/apache/hadoop/hive/serde2/objectinspector/primitive/ParquetStringInspector.java": [
                12,
                17
            ],
            "parquet-hive/parquet-hive-storage-handler/src/main/java/parquet/hive/DeprecatedParquetInputFormat.java": [
                12,
                17
            ],
            "parquet-hive/parquet-hive-storage-handler/src/main/java/parquet/hive/DeprecatedParquetOutputFormat.java": [
                12,
                17
            ],
            "parquet-hive/parquet-hive-storage-handler/src/main/java/parquet/hive/MapredParquetInputFormat.java": [
                12,
                17
            ],
            "parquet-hive/parquet-hive-storage-handler/src/main/java/parquet/hive/MapredParquetOutputFormat.java": [
                12,
                17
            ],
            "parquet-hive/parquet-hive-storage-handler/src/main/java/parquet/hive/serde/ParquetHiveSerDe.java": [
                12,
                17
            ],
            "parquet-hive/parquet-hive-storage-handler/src/test/java/org/apache/hadoop/hive/ql/io/parquet/TestHiveSchemaConverter.java": [
                12,
                17
            ],
            "parquet-hive/parquet-hive-storage-handler/src/test/java/org/apache/hadoop/hive/ql/io/parquet/TestMapredParquetInputFormat.java": [
                12,
                17
            ],
            "parquet-hive/parquet-hive-storage-handler/src/test/java/org/apache/hadoop/hive/ql/io/parquet/TestMapredParquetOutputFormat.java": [
                12,
                17
            ],
            "parquet-hive/parquet-hive-storage-handler/src/test/java/org/apache/hadoop/hive/ql/io/parquet/TestParquetSerDe.java": [
                12,
                17
            ],
            "parquet-hive/parquet-hive-storage-handler/src/test/java/org/apache/hadoop/hive/ql/io/parquet/serde/TestAbstractParquetMapInspector.java": [
                12,
                17
            ],
            "parquet-hive/parquet-hive-storage-handler/src/test/java/org/apache/hadoop/hive/ql/io/parquet/serde/TestDeepParquetHiveMapInspector.java": [
                12,
                17
            ],
            "parquet-hive/parquet-hive-storage-handler/src/test/java/org/apache/hadoop/hive/ql/io/parquet/serde/TestParquetHiveArrayInspector.java": [
                12,
                17
            ],
            "parquet-hive/parquet-hive-storage-handler/src/test/java/org/apache/hadoop/hive/ql/io/parquet/serde/TestStandardParquetHiveMapInspector.java": [
                12,
                17
            ],
            "parquet-hive/pom.xml": null,
            "parquet-jackson/README.md": null,
            "parquet-jackson/pom.xml": null,
            "parquet-jackson/src/main/resources/META-INF/LICENSE": null,
            "parquet-pig-bundle/pom.xml": null,
            "parquet-pig-bundle/src/main/resources/META-INF/LICENSE": null,
            "parquet-pig-bundle/src/main/resources/parquet/bundle": null,
            "parquet-pig/REVIEWERS.md": null,
            "parquet-pig/pom.xml": null,
            "parquet-pig/src/main/java/parquet/pig/ParquetLoader.java": [
                14,
                17
            ],
            "parquet-pig/src/main/java/parquet/pig/ParquetStorer.java": [
                14,
                17
            ],
            "parquet-pig/src/main/java/parquet/pig/PigMetaData.java": [
                14,
                17
            ],
            "parquet-pig/src/main/java/parquet/pig/PigSchemaConverter.java": [
                14,
                17
            ],
            "parquet-pig/src/main/java/parquet/pig/SchemaConversionException.java": [
                14,
                17
            ],
            "parquet-pig/src/main/java/parquet/pig/TupleConversionException.java": [
                14,
                17
            ],
            "parquet-pig/src/main/java/parquet/pig/TupleReadSupport.java": [
                14,
                17
            ],
            "parquet-pig/src/main/java/parquet/pig/TupleWriteSupport.java": [
                14,
                17
            ],
            "parquet-pig/src/main/java/parquet/pig/convert/MapConverter.java": [
                14,
                17
            ],
            "parquet-pig/src/main/java/parquet/pig/convert/ParentValueContainer.java": [
                14,
                17
            ],
            "parquet-pig/src/main/java/parquet/pig/convert/TupleConverter.java": [
                14,
                17
            ],
            "parquet-pig/src/main/java/parquet/pig/convert/TupleRecordMaterializer.java": [
                14,
                17
            ],
            "parquet-pig/src/main/java/parquet/pig/summary/BagSummaryData.java": [
                14,
                17
            ],
            "parquet-pig/src/main/java/parquet/pig/summary/EnumStat.java": [
                14,
                17
            ],
            "parquet-pig/src/main/java/parquet/pig/summary/FieldSummaryData.java": [
                14,
                17
            ],
            "parquet-pig/src/main/java/parquet/pig/summary/MapSummaryData.java": [
                14,
                17
            ],
            "parquet-pig/src/main/java/parquet/pig/summary/NumberSummaryData.java": [
                14,
                17
            ],
            "parquet-pig/src/main/java/parquet/pig/summary/StringSummaryData.java": [
                14,
                17
            ],
            "parquet-pig/src/main/java/parquet/pig/summary/Summary.java": [
                14,
                17
            ],
            "parquet-pig/src/main/java/parquet/pig/summary/SummaryData.java": [
                14,
                17
            ],
            "parquet-pig/src/main/java/parquet/pig/summary/TupleSummaryData.java": [
                14,
                17
            ],
            "parquet-pig/src/main/java/parquet/pig/summary/ValueStat.java": [
                14,
                17
            ],
            "parquet-pig/src/test/java/parquet/pig/PerfTest.java": [
                14,
                17
            ],
            "parquet-pig/src/test/java/parquet/pig/PerfTest2.java": [
                14,
                17
            ],
            "parquet-pig/src/test/java/parquet/pig/PerfTestReadAllCols.java": [
                14,
                17
            ],
            "parquet-pig/src/test/java/parquet/pig/TestParquetLoader.java": [
                14,
                17
            ],
            "parquet-pig/src/test/java/parquet/pig/TestParquetStorer.java": [
                14,
                17
            ],
            "parquet-pig/src/test/java/parquet/pig/TestPigSchemaConverter.java": [
                14,
                17
            ],
            "parquet-pig/src/test/java/parquet/pig/TestTupleRecordConsumer.java": [
                14,
                17
            ],
            "parquet-pig/src/test/java/parquet/pig/TupleConsumerPerfTest.java": [
                14,
                17
            ],
            "parquet-pig/src/test/java/parquet/pig/summary/TestSummary.java": [
                14,
                17
            ],
            "parquet-protobuf/README.md": null,
            "parquet-protobuf/REVIEWERS.md": null,
            "parquet-protobuf/pom.xml": null,
            "parquet-protobuf/src/main/java/parquet/proto/ProtoMessageConverter.java": [
                15,
                17
            ],
            "parquet-protobuf/src/main/java/parquet/proto/ProtoParquetInputFormat.java": [
                14,
                17
            ],
            "parquet-protobuf/src/main/java/parquet/proto/ProtoParquetOutputFormat.java": [
                14,
                17
            ],
            "parquet-protobuf/src/main/java/parquet/proto/ProtoParquetReader.java": [
                14,
                17
            ],
            "parquet-protobuf/src/main/java/parquet/proto/ProtoParquetWriter.java": [
                14,
                17
            ],
            "parquet-protobuf/src/main/java/parquet/proto/ProtoReadSupport.java": [
                14,
                17
            ],
            "parquet-protobuf/src/main/java/parquet/proto/ProtoRecordConverter.java": [
                14,
                17
            ],
            "parquet-protobuf/src/main/java/parquet/proto/ProtoRecordMaterializer.java": [
                14,
                17
            ],
            "parquet-protobuf/src/main/java/parquet/proto/ProtoSchemaConverter.java": [
                14,
                17
            ],
            "parquet-protobuf/src/main/java/parquet/proto/ProtoWriteSupport.java": [
                14,
                17
            ],
            "parquet-protobuf/src/main/resources/META-INF/NOTICE": null,
            "parquet-protobuf/src/test/java/parquet/proto/ProtoInputOutputFormatTest.java": [
                14,
                17
            ],
            "parquet-protobuf/src/test/java/parquet/proto/ProtoRecordConverterTest.java": [
                15,
                17
            ],
            "parquet-protobuf/src/test/java/parquet/proto/ProtoSchemaConverterTest.java": [
                15,
                17
            ],
            "parquet-protobuf/src/test/java/parquet/proto/ProtoWriteSupportTest.java": [
                14,
                17
            ],
            "parquet-protobuf/src/test/java/parquet/proto/TestUtils.java": [
                0,
                18
            ],
            "parquet-protobuf/src/test/java/parquet/proto/utils/ReadUsingMR.java": [
                14,
                17
            ],
            "parquet-protobuf/src/test/java/parquet/proto/utils/WriteUsingMR.java": [
                14,
                17
            ],
            "parquet-protobuf/src/test/resources/TestProtobuf.proto": null,
            "parquet-scala/pom.xml": null,
            "parquet-scala/src/main/scala/parquet/filter2/dsl/Dsl.scala": null,
            "parquet-scala/src/test/scala/parquet/filter2/dsl/DslTest.scala": null,
            "parquet-scrooge/REVIEWERS.md": null,
            "parquet-scrooge/pom.xml": null,
            "parquet-scrooge/src/main/java/parquet/scrooge/ParquetScroogeInputFormat.java": [
                15,
                18
            ],
            "parquet-scrooge/src/main/java/parquet/scrooge/ParquetScroogeScheme.java": [
                15,
                17
            ],
            "parquet-scrooge/src/main/java/parquet/scrooge/ScroogeReadSupport.java": [
                14,
                17
            ],
            "parquet-scrooge/src/main/java/parquet/scrooge/ScroogeRecordConverter.java": [
                14,
                17
            ],
            "parquet-scrooge/src/main/java/parquet/scrooge/ScroogeSchemaConversionException.java": [
                0,
                18
            ],
            "parquet-scrooge/src/main/java/parquet/scrooge/ScroogeStructConverter.java": [
                14,
                17
            ],
            "parquet-scrooge/src/test/java/parquet/scrooge/ParquetScroogeSchemeTest.java": [
                14,
                17
            ],
            "parquet-scrooge/src/test/java/parquet/scrooge/ScroogeStructConverterTest.java": [
                14,
                17
            ],
            "parquet-scrooge/src/test/thrift/test.thrift": null,
            "parquet-thrift/REVIEWERS.md": null,
            "parquet-thrift/pom.xml": null,
            "parquet-thrift/src/main/java/parquet/hadoop/thrift/ParquetThriftBytesOutputFormat.java": [
                14,
                17
            ],
            "parquet-thrift/src/main/java/parquet/hadoop/thrift/ParquetThriftInputFormat.java": [
                14,
                17
            ],
            "parquet-thrift/src/main/java/parquet/hadoop/thrift/ParquetThriftOutputFormat.java": [
                14,
                17
            ],
            "parquet-thrift/src/main/java/parquet/hadoop/thrift/ThriftBytesWriteSupport.java": [
                14,
                17
            ],
            "parquet-thrift/src/main/java/parquet/hadoop/thrift/ThriftReadSupport.java": [
                14,
                17
            ],
            "parquet-thrift/src/main/java/parquet/hadoop/thrift/ThriftToParquetFileWriter.java": [
                14,
                17
            ],
            "parquet-thrift/src/main/java/parquet/hadoop/thrift/ThriftWriteSupport.java": [
                14,
                17
            ],
            "parquet-thrift/src/main/java/parquet/thrift/BufferedProtocolReadToWrite.java": [
                14,
                17
            ],
            "parquet-thrift/src/main/java/parquet/thrift/DecodingSchemaMismatchException.java": [
                0,
                18
            ],
            "parquet-thrift/src/main/java/parquet/thrift/FieldIgnoredHandler.java": [
                0,
                18
            ],
            "parquet-thrift/src/main/java/parquet/thrift/ParquetProtocol.java": [
                14,
                17
            ],
            "parquet-thrift/src/main/java/parquet/thrift/ParquetReadProtocol.java": [
                14,
                17
            ],
            "parquet-thrift/src/main/java/parquet/thrift/ParquetWriteProtocol.java": [
                14,
                17
            ],
            "parquet-thrift/src/main/java/parquet/thrift/ProtocolPipe.java": [
                14,
                17
            ],
            "parquet-thrift/src/main/java/parquet/thrift/ProtocolReadToWrite.java": [
                14,
                17
            ],
            "parquet-thrift/src/main/java/parquet/thrift/SkippableException.java": [
                0,
                18
            ],
            "parquet-thrift/src/main/java/parquet/thrift/TBaseRecordConverter.java": [
                14,
                17
            ],
            "parquet-thrift/src/main/java/parquet/thrift/ThriftMetaData.java": [
                14,
                17
            ],
            "parquet-thrift/src/main/java/parquet/thrift/ThriftParquetReader.java": [
                14,
                17
            ],
            "parquet-thrift/src/main/java/parquet/thrift/ThriftParquetWriter.java": [
                14,
                17
            ],
            "parquet-thrift/src/main/java/parquet/thrift/ThriftReader.java": [
                14,
                17
            ],
            "parquet-thrift/src/main/java/parquet/thrift/ThriftRecordConverter.java": [
                14,
                17
            ],
            "parquet-thrift/src/main/java/parquet/thrift/ThriftSchemaConvertVisitor.java": [
                15,
                17
            ],
            "parquet-thrift/src/main/java/parquet/thrift/ThriftSchemaConverter.java": [
                14,
                17
            ],
            "parquet-thrift/src/main/java/parquet/thrift/pig/ParquetThriftStorer.java": [
                14,
                17
            ],
            "parquet-thrift/src/main/java/parquet/thrift/pig/TupleToThriftWriteSupport.java": [
                14,
                17
            ],
            "parquet-thrift/src/main/java/parquet/thrift/projection/FieldProjectionFilter.java": [
                15,
                17
            ],
            "parquet-thrift/src/main/java/parquet/thrift/projection/FieldsPath.java": [
                14,
                17
            ],
            "parquet-thrift/src/main/java/parquet/thrift/projection/PathGlobPattern.java": [
                0,
                18
            ],
            "parquet-thrift/src/main/java/parquet/thrift/projection/ThriftProjectionException.java": [
                15,
                17
            ],
            "parquet-thrift/src/main/java/parquet/thrift/projection/amend/DefaultEventsVisitor.java": [
                14,
                17
            ],
            "parquet-thrift/src/main/java/parquet/thrift/projection/amend/DefaultProtocolEventsGenerator.java": [
                14,
                17
            ],
            "parquet-thrift/src/main/java/parquet/thrift/projection/amend/ProtocolEventsAmender.java": [
                14,
                17
            ],
            "parquet-thrift/src/main/java/parquet/thrift/projection/amend/ReadFieldBeginProtocol.java": [
                14,
                17
            ],
            "parquet-thrift/src/main/java/parquet/thrift/struct/CompatibilityChecker.java": [
                14,
                17
            ],
            "parquet-thrift/src/main/java/parquet/thrift/struct/CompatibilityRunner.java": [
                14,
                17
            ],
            "parquet-thrift/src/main/java/parquet/thrift/struct/JSON.java": [
                14,
                17
            ],
            "parquet-thrift/src/main/java/parquet/thrift/struct/ThriftField.java": [
                14,
                17
            ],
            "parquet-thrift/src/main/java/parquet/thrift/struct/ThriftType.java": [
                14,
                17
            ],
            "parquet-thrift/src/main/java/parquet/thrift/struct/ThriftTypeID.java": [
                14,
                17
            ],
            "parquet-thrift/src/test/java/parquet/hadoop/thrift/TestInputOutputFormat.java": [
                14,
                17
            ],
            "parquet-thrift/src/test/java/parquet/hadoop/thrift/TestParquetToThriftReadWriteAndProjection.java": [
                14,
                17
            ],
            "parquet-thrift/src/test/java/parquet/hadoop/thrift/TestThriftToParquetFileWriter.java": [
                14,
                17
            ],
            "parquet-thrift/src/test/java/parquet/thrift/TestParquetReadProtocol.java": [
                14,
                17
            ],
            "parquet-thrift/src/test/java/parquet/thrift/TestParquetWriteProtocol.java": [
                14,
                17
            ],
            "parquet-thrift/src/test/java/parquet/thrift/TestProtocolReadToWrite.java": [
                14,
                17
            ],
            "parquet-thrift/src/test/java/parquet/thrift/TestThriftParquetReaderWriter.java": [
                14,
                17
            ],
            "parquet-thrift/src/test/java/parquet/thrift/TestThriftSchemaConverter.java": [
                14,
                17
            ],
            "parquet-thrift/src/test/java/parquet/thrift/TestThriftToPigCompatibility.java": [
                14,
                17
            ],
            "parquet-thrift/src/test/java/parquet/thrift/pig/TestParquetThriftStorer.java": [
                14,
                17
            ],
            "parquet-thrift/src/test/java/parquet/thrift/projection/PathGlobPatternTest.java": [
                15,
                17
            ],
            "parquet-thrift/src/test/java/parquet/thrift/struct/CompatibilityCheckerTest.java": [
                14,
                17
            ],
            "parquet-thrift/src/test/thrift/compat.thrift": null,
            "parquet-thrift/src/test/thrift/test.thrift": null,
            "parquet-tools/README.md": null,
            "parquet-tools/REVIEWERS.md": null,
            "parquet-tools/pom.xml": null,
            "parquet-tools/src/main/resources/META-INF/LICENSE": null,
            "parquet-tools/src/main/resources/META-INF/NOTICE": null,
            "parquet-tools/src/main/scripts/parquet-cat": null,
            "parquet-tools/src/main/scripts/parquet-dump": null,
            "parquet-tools/src/main/scripts/parquet-head": null,
            "parquet-tools/src/main/scripts/parquet-meta": null,
            "parquet-tools/src/main/scripts/parquet-schema": null,
            "parquet-tools/src/main/scripts/parquet-tools": null,
            "parquet_cascading.md": null,
            "pom.xml": null
        }
    },
    "80417356f04c5ee1cd6f636e9b043db3f2de24f2": {
        "datetime": "2015-02-03T12:53:37-08:00",
        "summary": "PARQUET-173: Fixes `StatisticsFilter` for `And` filter predicate",
        "message": "PARQUET-173: Fixes `StatisticsFilter` for `And` filter predicate\n\n<!-- Reviewable:start -->\n[<img src=\"https://reviewable.io/review_button.png\" height=40 alt=\"Review on Reviewable\"/>](https://reviewable.io/reviews/apache/incubator-parquet-mr/108)\n<!-- Reviewable:end -->\n\nAuthor: Cheng Lian <lian@databricks.com>\n\nCloses #108 from liancheng/PARQUET-173 and squashes the following commits:\n\nd188f0b [Cheng Lian] Fixes test case\nbe2c8a1 [Cheng Lian] Fixes `StatisticsFilter` for `And` filter predicate\n",
        "diff": {
            "parquet-hadoop/src/main/java/parquet/filter2/statisticslevel/StatisticsFilter.java": [
                1,
                5
            ],
            "parquet-hadoop/src/test/java/parquet/filter2/statisticslevel/TestStatisticsFilter.java": [
                2,
                2
            ]
        }
    },
    "668d031d7213d5e76cf39770ffce7f030c9bf056": {
        "datetime": "2015-02-05T11:37:06-08:00",
        "summary": "PARQUET-181: Scrooge Write Support (take two)",
        "message": "PARQUET-181: Scrooge Write Support (take two)\n\nThis is similar to https://github.com/apache/incubator-parquet-mr/pull/43, but instead of making `ThriftWriteSupport` abstract, it keeps it around (but deprecated) and adds `AbstractThriftWriteSupport`. This is a little less elegant, but it seems to appease the semver overlords.\n\nAuthor: Colin Marc <colinmarc@gmail.com>\n\nCloses #58 from colinmarc/scrooge-write-support-2 and squashes the following commits:\n\ne2a0abd [Colin Marc] add write support to ParquetScroogeScheme\n19cf1a8 [Colin Marc] Add ScroogeWriteSupport and ParquetScroogeOutputFormat.\n",
        "diff": {
            "parquet-cascading/src/main/java/parquet/cascading/ParquetTBaseScheme.java": [
                3,
                3
            ],
            "parquet-scrooge/src/main/java/parquet/scrooge/ParquetScroogeOutputFormat.java": [
                0,
                39
            ],
            "parquet-scrooge/src/main/java/parquet/scrooge/ParquetScroogeScheme.java": [
                15,
                7
            ],
            "parquet-scrooge/src/main/java/parquet/scrooge/ScroogeWriteSupport.java": [
                0,
                65
            ],
            "parquet-scrooge/src/test/java/parquet/scrooge/ParquetScroogeSchemeTest.java": [
                0,
                78
            ],
            "parquet-scrooge/src/test/resources/names.txt": null,
            "parquet-thrift/src/main/java/parquet/hadoop/thrift/AbstractThriftWriteSupport.java": [
                0,
                126
            ],
            "parquet-thrift/src/main/java/parquet/hadoop/thrift/ParquetThriftBytesOutputFormat.java": [
                2,
                2
            ],
            "parquet-thrift/src/main/java/parquet/hadoop/thrift/TBaseWriteSupport.java": [
                0,
                63
            ],
            "parquet-thrift/src/main/java/parquet/hadoop/thrift/ThriftBytesWriteSupport.java": [
                5,
                5
            ],
            "parquet-thrift/src/main/java/parquet/hadoop/thrift/ThriftWriteSupport.java": [
                68,
                14
            ],
            "parquet-thrift/src/main/java/parquet/thrift/ThriftMetaData.java": [
                3,
                0
            ],
            "parquet-thrift/src/main/java/parquet/thrift/ThriftParquetWriter.java": [
                4,
                4
            ]
        }
    },
    "05adc21b15dbe30d9bded0cde56f482f1c932d6f": {
        "datetime": "2015-02-05T14:36:28-08:00",
        "summary": "PARQUET-177: Added lower bound to memory manager resize",
        "message": "PARQUET-177: Added lower bound to memory manager resize\n\nPARQUET-177\n\nAuthor: Daniel Weeks <dweeks@netflix.com>\n\nCloses #115 from danielcweeks/memory-manager-limit and squashes the following commits:\n\nb2e4708 [Daniel Weeks] Updated to base memory allocation off estimated chunk size\n09d7aa3 [Daniel Weeks] Updated property name and default value\n8f6cff1 [Daniel Weeks] Added low bound to memory manager resize\n",
        "diff": {
            "parquet-hadoop/src/main/java/parquet/hadoop/InternalParquetRecordWriter.java": [
                0,
                4
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/MemoryManager.java": [
                1,
                15
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/ParquetOutputFormat.java": [
                1,
                4
            ]
        }
    },
    "ce65dfb394623c34dd7919aba5c0687f1bcf39f2": {
        "datetime": "2015-02-05T15:06:12-08:00",
        "summary": "PARQUET-139: Avoid reading footers when using task-side metadata",
        "message": "PARQUET-139: Avoid reading footers when using task-side metadata\n\nThis updates the InternalParquetRecordReader to initialize the ReadContext in each task rather than once for an entire job. There are two reasons for this change:\n\n1. For correctness, the requested projection schema must be validated against each file schema, not once using the merged schema.\n2. To avoid reading file footers on the client side, which is a performance bottleneck.\n\nBecause the read context is reinitialized in every task, it is no longer necessary to pass the its contents to each task in ParquetInputSplit. The fields and accessors have been removed.\n\nThis also adds a new InputFormat, ParquetFileInputFormat that uses FileSplits instead of ParquetSplits. It goes through the normal ParquetRecordReader and creates a ParquetSplit on the task side. This is to avoid accidental behavior changes in ParquetInputFormat.\n\nAuthor: Ryan Blue <blue@apache.org>\n\nCloses #91 from rdblue/PARQUET-139-input-format-task-side and squashes the following commits:\n\ncb30660 [Ryan Blue] PARQUET-139: Fix deprecated reader bug from review fixes.\n09cde8d [Ryan Blue] PARQUET-139: Implement changes from reviews.\n3eec553 [Ryan Blue] PARQUET-139: Merge new InputFormat into ParquetInputFormat.\n8971b80 [Ryan Blue] PARQUET-139: Add ParquetFileInputFormat that uses FileSplit.\n87dfe86 [Ryan Blue] PARQUET-139: Expose read support helper methods.\n057c7dc [Ryan Blue] PARQUET-139: Update reader to initialize read context in tasks.\n",
        "diff": {
            "parquet-avro/src/main/java/parquet/avro/AvroReadSupport.java": [
                1,
                3
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/InternalParquetRecordReader.java": [
                6,
                24
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/ParquetInputFormat.java": [
                127,
                61
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/ParquetInputSplit.java": [
                71,
                30
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/ParquetReader.java": [
                15,
                7
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/ParquetRecordReader.java": [
                10,
                18
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/mapred/DeprecatedParquetInputFormat.java": [
                8,
                24
            ],
            "parquet-hadoop/src/test/java/parquet/hadoop/TestInputFormat.java": [
                163,
                0
            ],
            "parquet-hive/parquet-hive-storage-handler/src/main/java/org/apache/hadoop/hive/ql/io/parquet/read/ParquetRecordReaderWrapper.java": [
                3,
                1
            ]
        }
    },
    "ec9612fe4eb0b6a7cd8edb0a548d3e799900245b": {
        "datetime": "2015-02-06T14:12:02-08:00",
        "summary": "PARQUET-111: Update LICENSE and pom.",
        "message": "PARQUET-111: Update LICENSE and pom.\n\nThis updates the LICENSE and shading configuration in the pom for\nproblem found while working on PARQUET-111 in parquet-mr.\n\nAuthor: Ryan Blue <blue@apache.org>\n\nCloses #19 from rdblue/PARQUET-111-fixes-from-mr and squashes the following commits:\n\ned98c6a [Ryan Blue] PARQUET-111: Update LICENSE and pom.\n",
        "diff": {
            "pom.xml": null
        }
    },
    "fc5f1f88c0c859193c86dbb8e8c83f2996af15ba": {
        "datetime": "2015-02-06T14:34:34-08:00",
        "summary": "[maven-release-plugin] prepare release parquet-format-2.2.0",
        "message": "[maven-release-plugin] prepare release parquet-format-2.2.0\n",
        "diff": {
            "pom.xml": null
        }
    },
    "6827f850730288b8d1789e46d85b558eee033cb1": {
        "datetime": "2015-02-06T14:37:43-08:00",
        "summary": "Revert \"[maven-release-plugin] prepare release parquet-format-2.2.0\"",
        "message": "Revert \"[maven-release-plugin] prepare release parquet-format-2.2.0\"\n\nThis reverts commit fd55aaa98982ad0d8f75cbfed90a3b9374595ba5.\n",
        "diff": {
            "pom.xml": null
        }
    },
    "bf8c7fd3887b8bc4aac0cac9a1d7a9955b9ac67f": {
        "datetime": "2015-02-06T14:38:39-08:00",
        "summary": "[maven-release-plugin] prepare release apache-parquet-format-2.2.0",
        "message": "[maven-release-plugin] prepare release apache-parquet-format-2.2.0\n",
        "diff": {
            "pom.xml": null
        }
    },
    "e9f2b904bffd09069d798cc47b8dbcb60696a4ad": {
        "datetime": "2015-02-06T14:38:53-08:00",
        "summary": "[maven-release-plugin] prepare for next development iteration",
        "message": "[maven-release-plugin] prepare for next development iteration\n",
        "diff": {
            "pom.xml": null
        }
    },
    "89f9a7a2359d1bbd993a1f757008d4f7a904f288": {
        "datetime": "2015-02-06T16:34:01-08:00",
        "summary": "[maven-release-plugin] prepare release apache-parquet-format-2.3.0",
        "message": "[maven-release-plugin] prepare release apache-parquet-format-2.3.0\n",
        "diff": {
            "pom.xml": null
        }
    },
    "2c23ff7eec03a40922147cb503b1316364e36de2": {
        "datetime": "2015-02-06T16:34:16-08:00",
        "summary": "[maven-release-plugin] prepare for next development iteration",
        "message": "[maven-release-plugin] prepare for next development iteration\n",
        "diff": {
            "pom.xml": null
        }
    },
    "807915b4cacede6a8de49630469b673b7c248a6f": {
        "datetime": "2015-02-09T17:51:46-08:00",
        "summary": "PARQUET-116: Pass a filter object to user defined predicate in filter2 api",
        "message": "PARQUET-116: Pass a filter object to user defined predicate in filter2 api\n\nCurrently for creating a user defined predicate using the new filter api, no value can be passed to create a dynamic filter at runtime. This reduces the usefulness of the user defined predicate, and meaningful predicates cannot be created. We can add a generic Object value that is passed through the api, which can internally be used in the keep function of the user defined predicate for creating many different types of filters.\nFor example, in spark sql, we can pass in a list of filter values for a where IN clause query and filter the row values based on that list.\n\nAuthor: Yash Datta <Yash.Datta@guavus.com>\nAuthor: Alex Levenson <alexlevenson@twitter.com>\nAuthor: Yash Datta <saucam@gmail.com>\n\nCloses #73 from saucam/master and squashes the following commits:\n\n7231a3b [Yash Datta] Merge pull request #3 from isnotinvain/alexlevenson/fix-binary-compat\ndcc276b [Alex Levenson] Ignore binary incompatibility in private filter2 class\n7bfa5ad [Yash Datta] Merge pull request #2 from isnotinvain/alexlevenson/simplify-udp-state\n0187376 [Alex Levenson] Resolve merge conflicts\n25aa716 [Alex Levenson] Simplify user defined predicates with state\n51952f8 [Yash Datta] PARQUET-116: Fix whitespace\nd7b7159 [Yash Datta] PARQUET-116: Make UserDefined abstract, add two subclasses, one accepting udp class, other accepting serializable udp instance\n40d394a [Yash Datta] PARQUET-116: Fix whitespace\n9a63611 [Yash Datta] PARQUET-116: Fix whitespace\n7caa4dc [Yash Datta] PARQUET-116: Add ConfiguredUserDefined that takes a serialiazble udp directly\n0eaabf4 [Yash Datta] PARQUET-116: Move the config object from keep method to a configure method in udp predicate\nf51a431 [Yash Datta] PARQUET-116: Adding type safety for the filter object to be passed to user defined predicate\nd5a2b9e [Yash Datta] PARQUET-116: Enforce that the filter object to be passed must be Serializable\ndfd0478 [Yash Datta] PARQUET-116: Add a test case for passing a filter object to user defined predicate\n4ab46ec [Yash Datta] PARQUET-116: Pass a filter object to user defined predicate in filter2 api\n",
        "diff": {
            "parquet-column/src/main/java/parquet/filter2/predicate/FilterApi.java": [
                1,
                18
            ],
            "parquet-column/src/main/java/parquet/filter2/predicate/Operators.java": [
                14,
                67
            ],
            "parquet-column/src/main/java/parquet/filter2/predicate/UserDefinedPredicate.java": [
                0,
                0
            ],
            "parquet-column/src/test/java/parquet/filter2/predicate/TestFilterApiMethods.java": [
                4,
                55
            ],
            "parquet-hadoop/src/test/java/parquet/filter2/recordlevel/TestRecordLevelFilters.java": [
                0,
                54
            ],
            "parquet-scala/src/main/scala/parquet/filter2/dsl/Dsl.scala": null,
            "parquet-scala/src/test/scala/parquet/filter2/dsl/DslTest.scala": null,
            "pom.xml": null
        }
    },
    "f48bca0510703b0673709b10a806a9d54894a999": {
        "datetime": "2015-02-09T23:07:35-08:00",
        "summary": "PARQUET-164: Add warning when scaling row group sizes.",
        "message": "PARQUET-164: Add warning when scaling row group sizes.\n\nAuthor: Ryan Blue <blue@apache.org>\n\nCloses #119 from rdblue/PARQUET-164-add-memory-manager-warning and squashes the following commits:\n\n241144f [Ryan Blue] PARQUET-164: Add warning when scaling row group sizes.\n",
        "diff": {
            "parquet-hadoop/src/main/java/parquet/hadoop/MemoryManager.java": [
                0,
                4
            ]
        }
    },
    "2726dc5de491520c321887f8ff3e7d37277b30a7": {
        "datetime": "2015-02-11T14:57:42-08:00",
        "summary": "PARQUET-185: Update release scripts and POM.",
        "message": "PARQUET-185: Update release scripts and POM.\n\n* Disable source zip generation in POM\n* Update scripts to use -incubating version\n\nAuthor: Ryan Blue <blue@apache.org>\n\nCloses #21 from rdblue/PARQUET-185-update-for-release and squashes the following commits:\n\n056f966 [Ryan Blue] PARQUET-185: Update release scripts and POM.\n",
        "diff": {
            "pom.xml": null
        }
    },
    "db35a4ce4de4edf9a8bf356fc2061cd1b7c166f2": {
        "datetime": "2015-02-11T14:59:06-08:00",
        "summary": "[maven-release-plugin] prepare release apache-parquet-format-2.3.0-incubating",
        "message": "[maven-release-plugin] prepare release apache-parquet-format-2.3.0-incubating\n",
        "diff": {
            "pom.xml": null
        }
    },
    "23fd7368311fecf30d9be1dea8eac93237d2c053": {
        "datetime": "2015-02-11T14:59:20-08:00",
        "summary": "[maven-release-plugin] prepare for next development iteration",
        "message": "[maven-release-plugin] prepare for next development iteration\n",
        "diff": {
            "pom.xml": null
        }
    },
    "4f87e0f483ed76a885c228c6ab75249f25041081": {
        "datetime": "2015-02-26T13:40:02-08:00",
        "summary": "PARQUET-190: fix an inconsistent Javadoc comment of ReadSupport.prepareForRead",
        "message": "PARQUET-190: fix an inconsistent Javadoc comment of ReadSupport.prepareForRead\n\nReadSupport.prepareForRead does not return RecordConsumer but RecordMaterializer\n\nAuthor: choplin <choplin.choplin@gmail.com>\n\nCloses #125 from choplin/fix-javadoc-comment and squashes the following commits:\n\nc3574f3 [choplin] fix an inconsistent Javadoc comment of ReadSupport.prepareForRead\n",
        "diff": {
            "parquet-hadoop/src/main/java/parquet/hadoop/api/ReadSupport.java": [
                2,
                2
            ]
        }
    },
    "f1b54876ab8893a5d9c0e3d7c1a9c884e683dc8a": {
        "datetime": "2015-03-04T12:11:50-08:00",
        "summary": "PARQUET-191: Fix map Type to Avro Schema conversion.",
        "message": "PARQUET-191: Fix map Type to Avro Schema conversion.\n\nAuthor: Ryan Blue <blue@apache.org>\n\nCloses #126 from rdblue/PARQUET-191-fix-map-value-conversion and squashes the following commits:\n\n33f6bbc [Ryan Blue] PARQUET-191: Fix map Type to Avro Schema conversion.\n",
        "diff": {
            "parquet-avro/src/main/java/parquet/avro/AvroIndexedRecordConverter.java": [
                2,
                2
            ],
            "parquet-avro/src/main/java/parquet/avro/AvroSchemaConverter.java": [
                6,
                13
            ],
            "parquet-avro/src/test/java/parquet/avro/TestAvroSchemaConverter.java": [
                4,
                27
            ]
        }
    },
    "c82f703768eb8a122546de23e412a037aa1770b2": {
        "datetime": "2015-03-04T12:26:52-08:00",
        "summary": "PARQUET-192: Fix map null encoding",
        "message": "PARQUET-192: Fix map null encoding\n\nThis depends on PARQUET-191 for the correct schema representation.\n\nAuthor: Ryan Blue <blue@apache.org>\n\nCloses #127 from rdblue/PARQUET-192-fix-map-null-encoding and squashes the following commits:\n\nfffde82 [Ryan Blue] PARQUET-192: Fix parquet-avro maps with null values.\n",
        "diff": {
            "parquet-avro/src/main/java/parquet/avro/AvroWriteSupport.java": [
                17,
                19
            ],
            "parquet-avro/src/test/java/parquet/avro/TestReadWrite.java": [
                0,
                57
            ],
            "parquet-avro/src/test/resources/map_with_nulls.avsc": null
        }
    },
    "36a02dc549f32433d7329444455dbb1be2e67f20": {
        "datetime": "2015-03-04T12:35:40-08:00",
        "summary": "PARQUET-188: Change column ordering to match the field order.",
        "message": "PARQUET-188: Change column ordering to match the field order.\n\nThis was the behavior before the V2 pages were added.\n\nAuthor: Ryan Blue <blue@apache.org>\n\nCloses #129 from rdblue/PARQUET-188-fix-column-metadata-order and squashes the following commits:\n\n3c9fa5d [Ryan Blue] PARQUET-188: Change column ordering to match the field order.\n",
        "diff": {
            "parquet-hadoop/src/main/java/parquet/hadoop/ColumnChunkPageWriteStore.java": [
                1,
                5
            ],
            "parquet-hadoop/src/test/java/parquet/hadoop/TestColumnChunkPageWriteStore.java": [
                7,
                67
            ]
        }
    },
    "fa8957d7939b59e8d391fa17000b34e865de015d": {
        "datetime": "2015-03-04T12:49:50-08:00",
        "summary": "PARQUET-187: Replace JavaConversions.asJavaList with JavaConversions.seqAsJavaList",
        "message": "PARQUET-187: Replace JavaConversions.asJavaList with JavaConversions.seqAsJavaList\n\nThe former was removed in 2.11, but the latter exists in 2.9, 2.10 and 2.11. With this change, I can build on 2.11 without any issue.\n\nAuthor: Colin Marc <colinmarc@gmail.com>\n\nCloses #121 from colinmarc/build-211 and squashes the following commits:\n\n8a29319 [Colin Marc] Replace JavaConversions.asJavaList with JavaConversions.seqAsJavaList.\n",
        "diff": {
            "parquet-scrooge/src/main/java/parquet/scrooge/ScroogeStructConverter.java": [
                1,
                1
            ]
        }
    },
    "d084ad29e0a2f456407f655c99999e070bf529f9": {
        "datetime": "2015-03-04T17:26:44-08:00",
        "summary": "PARQUET-160: avoid wasting 64K per empty buffer.",
        "message": "PARQUET-160: avoid wasting 64K per empty buffer.\n\nThis buffer initializes itself to a default size when instantiated.\nThis leads to a lot of unused small buffers when there are a lot of empty columns.\n\nAuthor: Alex Levenson <alexlevenson@twitter.com>\nAuthor: julien <julien@twitter.com>\nAuthor: Julien Le Dem <julien@twitter.com>\n\nCloses #98 from julienledem/avoid_wasting_64K_per_empty_buffer and squashes the following commits:\n\nb0200dd [julien] add license\na1b278e [julien] Merge branch 'master' into avoid_wasting_64K_per_empty_buffer\n5304ee1 [julien] remove unused constant\n81e399f [julien] Merge branch 'avoid_wasting_64K_per_empty_buffer' of github.com:julienledem/incubator-parquet-mr into avoid_wasting_64K_per_empty_buffer\nccf677d [julien] Merge branch 'master' into avoid_wasting_64K_per_empty_buffer\n37148d6 [Julien Le Dem] Merge pull request #2 from isnotinvain/PR-98\nb9abab0 [Alex Levenson] Address Julien's comment\n965af7f [Alex Levenson] one more typo\n9939d8d [Alex Levenson] fix typos in comments\n61c0100 [Alex Levenson] Make initial slab size heuristic into a helper method, apply in DictionaryValuesWriter as well\na257ee4 [Alex Levenson] Improve IndexOutOfBoundsException message\n64d6c7f [Alex Levenson] update comments\n8b54667 [Alex Levenson] Don't use CapacityByteArrayOutputStream for writing page chunks\n6a20e8b [Alex Levenson] Remove initialSlabSize decision from InternalParquetRecordReader, use a simpler heuristic in the column writers instead\n3a0f8e4 [Alex Levenson] Use simpler settings for column chunk writer\nb2736a1 [Alex Levenson] Some cleanup in CapacityByteArrayOutputStream\n1df4a71 [julien] refactor CapacityByteArray to be aware of page size\n95c8fb6 [julien] avoid wasting 64K per empty buffer.\n",
        "diff": {
            "parquet-column/src/main/java/parquet/column/ParquetProperties.java": [
                25,
                26
            ],
            "parquet-column/src/main/java/parquet/column/impl/ColumnWriteStoreV1.java": [
                4,
                2
            ],
            "parquet-column/src/main/java/parquet/column/impl/ColumnWriteStoreV2.java": [
                2,
                2
            ],
            "parquet-column/src/main/java/parquet/column/impl/ColumnWriterV1.java": [
                4,
                11
            ],
            "parquet-column/src/main/java/parquet/column/impl/ColumnWriterV2.java": [
                5,
                12
            ],
            "parquet-column/src/main/java/parquet/column/values/bitpacking/BitPackingValuesWriter.java": [
                2,
                3
            ],
            "parquet-column/src/main/java/parquet/column/values/boundedint/BitWriter.java": [
                2,
                2
            ],
            "parquet-column/src/main/java/parquet/column/values/boundedint/BoundedIntValuesFactory.java": [
                2,
                2
            ],
            "parquet-column/src/main/java/parquet/column/values/boundedint/BoundedIntValuesWriter.java": [
                2,
                2
            ],
            "parquet-column/src/main/java/parquet/column/values/delta/DeltaBinaryPackingValuesWriter.java": [
                7,
                7
            ],
            "parquet-column/src/main/java/parquet/column/values/deltalengthbytearray/DeltaLengthByteArrayValuesWriter.java": [
                5,
                5
            ],
            "parquet-column/src/main/java/parquet/column/values/deltastrings/DeltaByteArrayWriter.java": [
                4,
                4
            ],
            "parquet-column/src/main/java/parquet/column/values/dictionary/DictionaryValuesWriter.java": [
                8,
                14
            ],
            "parquet-column/src/main/java/parquet/column/values/plain/FixedLenByteArrayPlainValuesWriter.java": [
                7,
                7
            ],
            "parquet-column/src/main/java/parquet/column/values/plain/PlainValuesWriter.java": [
                2,
                2
            ],
            "parquet-column/src/main/java/parquet/column/values/rle/RunLengthBitPackingHybridEncoder.java": [
                2,
                2
            ],
            "parquet-column/src/main/java/parquet/column/values/rle/RunLengthBitPackingHybridValuesWriter.java": [
                2,
                2
            ],
            "parquet-column/src/test/java/parquet/column/impl/TestColumnReaderImpl.java": [
                2,
                2
            ],
            "parquet-column/src/test/java/parquet/column/mem/TestMemColumn.java": [
                1,
                1
            ],
            "parquet-column/src/test/java/parquet/column/values/bitpacking/TestBitPackingColumn.java": [
                1,
                1
            ],
            "parquet-column/src/test/java/parquet/column/values/boundedint/TestBoundedColumns.java": [
                2,
                2
            ],
            "parquet-column/src/test/java/parquet/column/values/delta/DeltaBinaryPackingValuesWriterTest.java": [
                2,
                2
            ],
            "parquet-column/src/test/java/parquet/column/values/delta/benchmark/BenchmarkIntegerOutputSize.java": [
                2,
                2
            ],
            "parquet-column/src/test/java/parquet/column/values/delta/benchmark/BenchmarkReadingRandomIntegers.java": [
                2,
                2
            ],
            "parquet-column/src/test/java/parquet/column/values/delta/benchmark/RandomWritingBenchmarkTest.java": [
                3,
                3
            ],
            "parquet-column/src/test/java/parquet/column/values/delta/benchmark/SmallRangeWritingBenchmarkTest.java": [
                1,
                1
            ],
            "parquet-column/src/test/java/parquet/column/values/deltalengthbytearray/TestDeltaLengthByteArray.java": [
                4,
                4
            ],
            "parquet-column/src/test/java/parquet/column/values/deltalengthbytearray/benchmark/BenchmarkDeltaLengthByteArray.java": [
                8,
                8
            ],
            "parquet-column/src/test/java/parquet/column/values/deltastrings/TestDeltaByteArray.java": [
                6,
                6
            ],
            "parquet-column/src/test/java/parquet/column/values/deltastrings/benchmark/BenchmarkDeltaByteArray.java": [
                14,
                14
            ],
            "parquet-column/src/test/java/parquet/column/values/dictionary/TestDictionary.java": [
                1,
                1
            ],
            "parquet-column/src/test/java/parquet/column/values/rle/RunLengthBitPackingHybridIntegrationTest.java": [
                1,
                1
            ],
            "parquet-column/src/test/java/parquet/column/values/rle/TestRunLengthBitPackingHybridEncoder.java": [
                11,
                11
            ],
            "parquet-column/src/test/java/parquet/io/PerfTest.java": [
                1,
                1
            ],
            "parquet-column/src/test/java/parquet/io/TestColumnIO.java": [
                1,
                1
            ],
            "parquet-column/src/test/java/parquet/io/TestFiltered.java": [
                1,
                1
            ],
            "parquet-encoding/src/main/java/parquet/bytes/CapacityByteArrayOutputStream.java": [
                120,
                148
            ],
            "parquet-encoding/src/main/java/parquet/bytes/ConcatenatingByteArrayCollector.java": [
                0,
                63
            ],
            "parquet-encoding/src/test/java/parquet/bytes/TestCapacityByteArrayOutputStream.java": [
                11,
                15
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/ColumnChunkPageWriteStore.java": [
                20,
                34
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/InternalParquetRecordWriter.java": [
                14,
                2
            ],
            "parquet-hadoop/src/test/java/parquet/hadoop/TestColumnChunkPageWriteStore.java": [
                9,
                4
            ],
            "parquet-pig/src/test/java/parquet/pig/TupleConsumerPerfTest.java": [
                1,
                1
            ],
            "parquet-thrift/src/test/java/parquet/thrift/TestParquetReadProtocol.java": [
                1,
                1
            ]
        }
    },
    "ea81e9aac328b2a89226417e58d4d8366891a9f4": {
        "datetime": "2015-03-04T17:56:52-08:00",
        "summary": "PARQUET-186: Fix Precondition performance problem in SnappyUtil.",
        "message": "PARQUET-186: Fix Precondition performance problem in SnappyUtil.\n\nThis fixes the problem by adding string formatting to the preconditions. This avoids any string formatting unless the precondition throws an Exception. We should check for string operations in other tight loops as well.\n\nAuthor: Ryan Blue <blue@apache.org>\n\nCloses #133 from rdblue/PARQUET-186-precondition-format-string and squashes the following commits:\n\nbe0b8fe [Ryan Blue] PARQUET-186: Fix Precondition performance bug in SnappyUtil.\n67f9bf2 [Ryan Blue] PARQUET-186: Add format string and args to Preconditions.\n",
        "diff": {
            "parquet-common/src/main/java/parquet/Preconditions.java": [
                10,
                69
            ],
            "parquet-common/src/test/java/parquet/TestPreconditions.java": [
                0,
                58
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/codec/SnappyUtil.java": [
                2,
                2
            ]
        }
    },
    "998d6507ecabf025188d9f3e8c8367f810895a17": {
        "datetime": "2015-03-04T18:24:21-08:00",
        "summary": "PARQUET-134 patch - Support file write mode",
        "message": "PARQUET-134 patch - Support file write mode\n\nJulien,\n   I changed the integer constants to enum as you requested.  Please review the patch.\n\nThanks.\n\nAuthor: Mariappan Asokan <masokan@gmail.com>\n\nCloses #111 from masokan/master and squashes the following commits:\n\n7a8aa6f [Mariappan Asokan] PARQUET-134 patch - Support file write mode\n",
        "diff": {
            "parquet-hadoop/src/main/java/parquet/hadoop/ParquetFileWriter.java": [
                5,
                24
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/ParquetWriter.java": [
                1,
                34
            ],
            "parquet-hadoop/src/test/java/parquet/hadoop/TestParquetFileWriter.java": [
                0,
                33
            ]
        }
    },
    "258349426eecfbe5c135f91809bae80e60c6db6a": {
        "datetime": "2015-03-05T15:22:03-08:00",
        "summary": "PARQUET-162: ParquetThrift should throw when unrecognized columns are passed to the column projection API",
        "message": "PARQUET-162: ParquetThrift should throw when unrecognized columns are passed to the column projection API\n\nParquetThrift should throw when unrecognized columns are passed to the column projection API\n\nAuthor: Tianshuo Deng <tdeng@twitter.com>\n\nCloses #123 from tsdeng/throw_when_projection_filter_matches_nothing and squashes the following commits:\n\n12c08da [Tianshuo Deng] make PathGlobPatternStatus static\n4360b36 [Tianshuo Deng] fix tests\na74f621 [Tianshuo Deng] clean up test\n3c581f3 [Tianshuo Deng] refactor unit test\n6a86de7 [Tianshuo Deng] format\nbdc625d [Tianshuo Deng] throw when projection filter matches nothing\n",
        "diff": {
            "parquet-thrift/src/main/java/parquet/thrift/ThriftSchemaConvertVisitor.java": [
                0,
                4
            ],
            "parquet-thrift/src/main/java/parquet/thrift/ThriftSchemaConverter.java": [
                1,
                11
            ],
            "parquet-thrift/src/main/java/parquet/thrift/projection/FieldProjectionFilter.java": [
                10,
                36
            ],
            "parquet-thrift/src/main/java/parquet/thrift/projection/PathGlobPattern.java": [
                0,
                5
            ],
            "parquet-thrift/src/test/java/parquet/hadoop/thrift/TestParquetToThriftReadWriteAndProjection.java": [
                57,
                62
            ],
            "parquet-thrift/src/test/java/parquet/thrift/TestThriftSchemaConverter.java": [
                3,
                22
            ]
        }
    },
    "5851e6da7a05b5d53a01803ccabc0f685fc36d52": {
        "datetime": "2015-03-05T15:56:58-08:00",
        "summary": "PARQUET-197 : fix parquet-cascading not writing parquet metadata file",
        "message": "PARQUET-197 : fix parquet-cascading not writing parquet metadata file\n\nRepro: run a scalding job that writes parquet files to a folder. no _metadata and _common_metadata file is created\nImpact: potential performance problem if parquet metadata is read from client side, which is the case for sparkSQL\ncasue: the metatdata writing logic is in the mapreduce API but not the mapred API of parquet.\n\nAuthor: Tianshuo Deng <tdeng@twitter.com>\n\nCloses #131 from tsdeng/fix_mapred_output_committer and squashes the following commits:\n\n6e8d8eb [Tianshuo Deng] rename to MapredParquetOutputCommiter, add setAsOutputFormat method to set the outputCommiter\nec758db [Tianshuo Deng] license\n448b649 [Tianshuo Deng] fix parquet-cascading not writing parquet metadata file\n",
        "diff": {
            "parquet-cascading/src/main/java/parquet/cascading/ParquetTBaseScheme.java": [
                1,
                1
            ],
            "parquet-cascading/src/main/java/parquet/cascading/ParquetTupleScheme.java": [
                1,
                1
            ],
            "parquet-cascading/src/test/java/parquet/cascading/TestParquetTBaseScheme.java": [
                0,
                3
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/ParquetOutputCommitter.java": [
                0,
                4
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/mapred/DeprecatedParquetOutputFormat.java": [
                0,
                5
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/mapred/MapredParquetOutputCommitter.java": [
                0,
                42
            ],
            "parquet-scrooge/src/main/java/parquet/scrooge/ParquetScroogeScheme.java": [
                4,
                1
            ]
        }
    },
    "2d1eaefb0f9ec2d81ea7a89defbaa506c0ed55f5": {
        "datetime": "2015-03-05T18:26:31-08:00",
        "summary": "PARQUET-202 Typo in the connection info in the pom prevents publishing an RC",
        "message": "PARQUET-202 Typo in the connection info in the pom prevents publishing an RC\n\nAuthor: Alex Levenson <alexlevenson@twitter.com>\n\nCloses #134 from isnotinvain/alexlevenson/developerconnection and squashes the following commits:\n\n8734e11 [Alex Levenson] Fix developer connection url\n",
        "diff": {
            "pom.xml": null
        }
    },
    "b2623f12a6c1946b12e5ea55d483e0acd351edb6": {
        "datetime": "2015-03-05T18:37:32-08:00",
        "summary": "[maven-release-plugin] prepare release parquet-1.6.0rc5",
        "message": "[maven-release-plugin] prepare release parquet-1.6.0rc5\n",
        "diff": {
            "parquet-avro/pom.xml": null,
            "parquet-cascading/pom.xml": null,
            "parquet-column/pom.xml": null,
            "parquet-common/pom.xml": null,
            "parquet-encoding/pom.xml": null,
            "parquet-generator/pom.xml": null,
            "parquet-hadoop-bundle/pom.xml": null,
            "parquet-hadoop/pom.xml": null,
            "parquet-hive-bundle/pom.xml": null,
            "parquet-hive/parquet-hive-binding/parquet-hive-0.10-binding/pom.xml": null,
            "parquet-hive/parquet-hive-binding/parquet-hive-0.12-binding/pom.xml": null,
            "parquet-hive/parquet-hive-binding/parquet-hive-binding-bundle/pom.xml": null,
            "parquet-hive/parquet-hive-binding/parquet-hive-binding-factory/pom.xml": null,
            "parquet-hive/parquet-hive-binding/parquet-hive-binding-interface/pom.xml": null,
            "parquet-hive/parquet-hive-binding/pom.xml": null,
            "parquet-hive/parquet-hive-storage-handler/pom.xml": null,
            "parquet-hive/pom.xml": null,
            "parquet-jackson/pom.xml": null,
            "parquet-pig-bundle/pom.xml": null,
            "parquet-pig/pom.xml": null,
            "parquet-protobuf/pom.xml": null,
            "parquet-scala/pom.xml": null,
            "parquet-scrooge/pom.xml": null,
            "parquet-thrift/pom.xml": null,
            "parquet-tools/pom.xml": null,
            "pom.xml": null
        }
    },
    "a7155a8d7a980b4b1122961a05e8c42a0f26540e": {
        "datetime": "2015-03-05T18:41:26-08:00",
        "summary": "[maven-release-plugin] prepare for next development iteration",
        "message": "[maven-release-plugin] prepare for next development iteration\n",
        "diff": {
            "parquet-avro/pom.xml": null,
            "parquet-cascading/pom.xml": null,
            "parquet-column/pom.xml": null,
            "parquet-common/pom.xml": null,
            "parquet-encoding/pom.xml": null,
            "parquet-generator/pom.xml": null,
            "parquet-hadoop-bundle/pom.xml": null,
            "parquet-hadoop/pom.xml": null,
            "parquet-hive-bundle/pom.xml": null,
            "parquet-hive/parquet-hive-binding/parquet-hive-0.10-binding/pom.xml": null,
            "parquet-hive/parquet-hive-binding/parquet-hive-0.12-binding/pom.xml": null,
            "parquet-hive/parquet-hive-binding/parquet-hive-binding-bundle/pom.xml": null,
            "parquet-hive/parquet-hive-binding/parquet-hive-binding-factory/pom.xml": null,
            "parquet-hive/parquet-hive-binding/parquet-hive-binding-interface/pom.xml": null,
            "parquet-hive/parquet-hive-binding/pom.xml": null,
            "parquet-hive/parquet-hive-storage-handler/pom.xml": null,
            "parquet-hive/pom.xml": null,
            "parquet-jackson/pom.xml": null,
            "parquet-pig-bundle/pom.xml": null,
            "parquet-pig/pom.xml": null,
            "parquet-protobuf/pom.xml": null,
            "parquet-scala/pom.xml": null,
            "parquet-scrooge/pom.xml": null,
            "parquet-thrift/pom.xml": null,
            "parquet-tools/pom.xml": null,
            "pom.xml": null
        }
    },
    "12ee6b442bbf6557c06ecd7c1f7ae2fceeae55d6": {
        "datetime": "2015-03-06T16:38:49-08:00",
        "summary": "PARQUET-208: Revert PARQUET-197",
        "message": "PARQUET-208: Revert PARQUET-197\n\nRevert \"PARQUET-197 : fix parquet-cascading not writing parquet metadata...\n\nAuthor: Tianshuo Deng <tdeng@twitter.com>\n\nCloses #139 from tsdeng/revert_parquet_197 and squashes the following commits:\n\na74b5c8 [Tianshuo Deng] Revert \"PARQUET-197 : fix parquet-cascading not writing parquet metadata file\"\n",
        "diff": {
            "parquet-cascading/src/main/java/parquet/cascading/ParquetTBaseScheme.java": [
                1,
                1
            ],
            "parquet-cascading/src/main/java/parquet/cascading/ParquetTupleScheme.java": [
                1,
                1
            ],
            "parquet-cascading/src/test/java/parquet/cascading/TestParquetTBaseScheme.java": [
                3,
                0
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/ParquetOutputCommitter.java": [
                4,
                0
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/mapred/DeprecatedParquetOutputFormat.java": [
                5,
                0
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/mapred/MapredParquetOutputCommitter.java": [
                42,
                0
            ],
            "parquet-scrooge/src/main/java/parquet/scrooge/ParquetScroogeScheme.java": [
                1,
                4
            ]
        }
    },
    "3fc28541f001ce6e4a7afa91fec8d21bfeaa17db": {
        "datetime": "2015-03-06T17:06:34-08:00",
        "summary": "PARQUET-193: Implement nested types compatibility rules in Avro",
        "message": "PARQUET-193: Implement nested types compatibility rules in Avro\n\nThis depends on PARQUET-191 and PARQUET-192.\n\nThis replaces #83.\n\nAuthor: Ryan Blue <blue@apache.org>\n\nCloses #128 from rdblue/PARQUET-193-implement-compatilibity-avro and squashes the following commits:\n\nbd0491e [Ryan Blue] PARQUET-193: Implement nested types rules in Avro.\n",
        "diff": {
            "parquet-avro/src/main/java/parquet/avro/AvroIndexedRecordConverter.java": [
                18,
                119
            ],
            "parquet-avro/src/main/java/parquet/avro/AvroReadSupport.java": [
                7,
                11
            ],
            "parquet-avro/src/main/java/parquet/avro/AvroSchemaConverter.java": [
                5,
                53
            ],
            "parquet-avro/src/main/java/parquet/avro/AvroWriteSupport.java": [
                9,
                10
            ],
            "parquet-avro/src/test/java/parquet/avro/AvroTestUtil.java": [
                0,
                69
            ],
            "parquet-avro/src/test/java/parquet/avro/TestArrayCompatibility.java": [
                0,
                999
            ]
        }
    },
    "ba4314241536554c6d886cd7a8f752d1f5ac7079": {
        "datetime": "2015-03-06T19:45:21-08:00",
        "summary": "[maven-release-plugin] prepare release parquet-1.6.0rc6",
        "message": "[maven-release-plugin] prepare release parquet-1.6.0rc6\n",
        "diff": {
            "parquet-avro/pom.xml": null,
            "parquet-cascading/pom.xml": null,
            "parquet-column/pom.xml": null,
            "parquet-common/pom.xml": null,
            "parquet-encoding/pom.xml": null,
            "parquet-generator/pom.xml": null,
            "parquet-hadoop-bundle/pom.xml": null,
            "parquet-hadoop/pom.xml": null,
            "parquet-hive-bundle/pom.xml": null,
            "parquet-hive/parquet-hive-binding/parquet-hive-0.10-binding/pom.xml": null,
            "parquet-hive/parquet-hive-binding/parquet-hive-0.12-binding/pom.xml": null,
            "parquet-hive/parquet-hive-binding/parquet-hive-binding-bundle/pom.xml": null,
            "parquet-hive/parquet-hive-binding/parquet-hive-binding-factory/pom.xml": null,
            "parquet-hive/parquet-hive-binding/parquet-hive-binding-interface/pom.xml": null,
            "parquet-hive/parquet-hive-binding/pom.xml": null,
            "parquet-hive/parquet-hive-storage-handler/pom.xml": null,
            "parquet-hive/pom.xml": null,
            "parquet-jackson/pom.xml": null,
            "parquet-pig-bundle/pom.xml": null,
            "parquet-pig/pom.xml": null,
            "parquet-protobuf/pom.xml": null,
            "parquet-scala/pom.xml": null,
            "parquet-scrooge/pom.xml": null,
            "parquet-thrift/pom.xml": null,
            "parquet-tools/pom.xml": null,
            "pom.xml": null
        }
    },
    "cd89c8885d4c1004c615a3a9d60028635409a9d0": {
        "datetime": "2015-03-06T19:45:27-08:00",
        "summary": "[maven-release-plugin] prepare for next development iteration",
        "message": "[maven-release-plugin] prepare for next development iteration\n",
        "diff": {
            "parquet-avro/pom.xml": null,
            "parquet-cascading/pom.xml": null,
            "parquet-column/pom.xml": null,
            "parquet-common/pom.xml": null,
            "parquet-encoding/pom.xml": null,
            "parquet-generator/pom.xml": null,
            "parquet-hadoop-bundle/pom.xml": null,
            "parquet-hadoop/pom.xml": null,
            "parquet-hive-bundle/pom.xml": null,
            "parquet-hive/parquet-hive-binding/parquet-hive-0.10-binding/pom.xml": null,
            "parquet-hive/parquet-hive-binding/parquet-hive-0.12-binding/pom.xml": null,
            "parquet-hive/parquet-hive-binding/parquet-hive-binding-bundle/pom.xml": null,
            "parquet-hive/parquet-hive-binding/parquet-hive-binding-factory/pom.xml": null,
            "parquet-hive/parquet-hive-binding/parquet-hive-binding-interface/pom.xml": null,
            "parquet-hive/parquet-hive-binding/pom.xml": null,
            "parquet-hive/parquet-hive-storage-handler/pom.xml": null,
            "parquet-hive/pom.xml": null,
            "parquet-jackson/pom.xml": null,
            "parquet-pig-bundle/pom.xml": null,
            "parquet-pig/pom.xml": null,
            "parquet-protobuf/pom.xml": null,
            "parquet-scala/pom.xml": null,
            "parquet-scrooge/pom.xml": null,
            "parquet-thrift/pom.xml": null,
            "parquet-tools/pom.xml": null,
            "pom.xml": null
        }
    },
    "a0c77b6a442e2c4a355a4b145898bed976f23bb4": {
        "datetime": "2015-03-09T12:59:45-07:00",
        "summary": "PARQUET-111: Update headers in parquet-tools, remove NOTICE.",
        "message": "PARQUET-111: Update headers in parquet-tools, remove NOTICE.\n\nThis commit update the copyright headers in parquet-tools from ARRIS to the standard Apache license header. This needs ARRIS or @wesleypeck to \"provide written permission for the ASF to make such removal or relocation of the notices\". Please +1 this commit, or submit a PR with similar changes. Thanks!\n\nAuthor: Ryan Blue <blue@apache.org>\n\nCloses #114 from rdblue/PARQUET-111-parquet-tools-changes and squashes the following commits:\n\n87eb75f [Ryan Blue] PARQUET-111: Update headers in parquet-tools, remove NOTICE.\n",
        "diff": {
            "parquet-tools/NOTICE": null,
            "parquet-tools/README.md": null,
            "parquet-tools/pom.xml": null,
            "parquet-tools/src/main/assembly/assembly.xml": null,
            "parquet-tools/src/main/java/parquet/tools/Main.java": [
                14,
                17
            ],
            "parquet-tools/src/main/java/parquet/tools/command/ArgsOnlyCommand.java": [
                14,
                17
            ],
            "parquet-tools/src/main/java/parquet/tools/command/CatCommand.java": [
                14,
                17
            ],
            "parquet-tools/src/main/java/parquet/tools/command/Command.java": [
                14,
                17
            ],
            "parquet-tools/src/main/java/parquet/tools/command/DumpCommand.java": [
                14,
                17
            ],
            "parquet-tools/src/main/java/parquet/tools/command/HeadCommand.java": [
                14,
                17
            ],
            "parquet-tools/src/main/java/parquet/tools/command/Registry.java": [
                14,
                17
            ],
            "parquet-tools/src/main/java/parquet/tools/command/ShowMetaCommand.java": [
                14,
                17
            ],
            "parquet-tools/src/main/java/parquet/tools/command/ShowSchemaCommand.java": [
                14,
                17
            ],
            "parquet-tools/src/main/java/parquet/tools/read/SimpleReadSupport.java": [
                14,
                17
            ],
            "parquet-tools/src/main/java/parquet/tools/read/SimpleRecord.java": [
                14,
                17
            ],
            "parquet-tools/src/main/java/parquet/tools/read/SimpleRecordConverter.java": [
                14,
                17
            ],
            "parquet-tools/src/main/java/parquet/tools/read/SimpleRecordMaterializer.java": [
                14,
                17
            ],
            "parquet-tools/src/main/java/parquet/tools/util/MetadataUtils.java": [
                14,
                17
            ],
            "parquet-tools/src/main/java/parquet/tools/util/PrettyPrintWriter.java": [
                14,
                17
            ],
            "parquet-tools/src/main/scripts/parquet-cat": null,
            "parquet-tools/src/main/scripts/parquet-dump": null,
            "parquet-tools/src/main/scripts/parquet-head": null,
            "parquet-tools/src/main/scripts/parquet-meta": null,
            "parquet-tools/src/main/scripts/parquet-schema": null,
            "parquet-tools/src/main/scripts/parquet-tools": null
        }
    },
    "5acc6a5502bffaa66be7e859849856de0ea27acb": {
        "datetime": "2015-03-10T14:04:59+01:00",
        "summary": "PARQUET-97: make ProtoParquetReader#builder static",
        "message": "PARQUET-97: make ProtoParquetReader#builder static\n\nAuthor: Viktor Szathma\u0301ry <phraktle@gmail.com>\n\nCloses #63 from phraktle/fix_ppr_factory and squashes the following commits:\n\n8b67439 [Viktor Szathma\u0301ry] make ProtoParquetReader#builder static\n9c8fcd5 [Viktor Szathma\u0301ry] make ProtoParquetReader#builder static\n",
        "diff": {
            "parquet-protobuf/src/main/java/parquet/proto/ProtoParquetReader.java": [
                1,
                1
            ]
        }
    },
    "031a762d105bceda2049204ba54b8f8737f359b4": {
        "datetime": "2015-03-11T15:11:16-07:00",
        "summary": "PARQUET-172: Add parquet-thrift binary tests.",
        "message": "PARQUET-172: Add parquet-thrift binary tests.\n\nThese tests validate that there is no encoding problem with parquet-thrift or parquet-scrooge. See https://github.com/laurencer/parquet-mr-bug\n\nAuthor: Ryan Blue <blue@apache.org>\n\nCloses #145 from rdblue/PARQUET-172-add-thrift-binary-test and squashes the following commits:\n\n6856414 [Ryan Blue] PARQUET-172: Add parquet-thrift binary tests.\n",
        "diff": {
            "parquet-scrooge/src/test/java/parquet/scrooge/ScroogeBinaryTest.java": [
                0,
                100
            ],
            "parquet-scrooge/src/test/java/parquet/scrooge/ScroogeStructConverterTest.java": [
                0,
                7
            ],
            "parquet-scrooge/src/test/thrift/test.thrift": null,
            "parquet-thrift/src/test/java/parquet/hadoop/thrift/TestBinary.java": [
                0,
                66
            ],
            "parquet-thrift/src/test/thrift/binary.thrift": null
        }
    },
    "b58789c5badc4f9680ec5724568af05a84670e22": {
        "datetime": "2015-03-11T15:21:45-07:00",
        "summary": "PARQUET-180: Update use of TBinaryProtocol#setReadLength.",
        "message": "PARQUET-180: Update use of TBinaryProtocol#setReadLength.\n\nThis is no longer supported in thrift 0.9.2 and was only used\ndefensively. The reason to remove it now is to avoid linker errors when\nthe wrong version of thrift is found in the classpath.\n\nAuthor: Ryan Blue <blue@apache.org>\n\nCloses #118 from rdblue/PARQUET-180 and squashes the following commits:\n\n5100424 [Ryan Blue] PARQUET-180: Dynamic use of TBinaryProtocol#setReadLength.\n",
        "diff": {
            "parquet-thrift/src/main/java/parquet/hadoop/thrift/ThriftBytesWriteSupport.java": [
                1,
                12
            ]
        }
    },
    "77826fda8751bd5c0acbca5d0c3887e9a6b10f65": {
        "datetime": "2015-03-12T14:25:13-07:00",
        "summary": "PARQUET-215 Discard records with unrecognized union members in the thrift write path",
        "message": "PARQUET-215 Discard records with unrecognized union members in the thrift write path\n\nFixes Parquet-215, adds a test case for it, and fixes some tests that were quietly not doing anything previously to actually exercise the code they were intended to exercise. (they were tests that catch exceptions and make assertions about them, but never enforced that the exception was actually thrown, and in one case, it never was).\n\nAuthor: Alex Levenson <alexlevenson@twitter.com>\n\nCloses #146 from isnotinvain/alexlevenson/unrecognized-union and squashes the following commits:\n\n7bec4a6 [Alex Levenson] Add license header\nb0d8e6c [Alex Levenson] Merge branch 'master' into alexlevenson/unrecognized-union\ne152bc8 [Alex Levenson] Update comment\n97232b7 [Alex Levenson] Address comments\nc542199 [Alex Levenson] Go back to using boolean for isUnion\n2e18dbd [Alex Levenson] Remove exclusion\n0a60c46 [Alex Levenson] Support isUnion being unknown\nb0dfdf9 [Alex Levenson] Fix tests\n68940d7 [Alex Levenson] Discard records with unrecognized union members in the thrift write path\n",
        "diff": {
            "parquet-scrooge/src/main/java/parquet/scrooge/ScroogeStructConverter.java": [
                1,
                6
            ],
            "parquet-thrift/src/main/java/parquet/thrift/BufferedProtocolReadToWrite.java": [
                5,
                24
            ],
            "parquet-thrift/src/main/java/parquet/thrift/ThriftSchemaConverter.java": [
                1,
                8
            ],
            "parquet-thrift/src/main/java/parquet/thrift/struct/ThriftType.java": [
                1,
                27
            ],
            "parquet-thrift/src/test/java/parquet/thrift/TestProtocolReadToWrite.java": [
                3,
                42
            ],
            "parquet-thrift/src/test/java/parquet/thrift/struct/TestThriftType.java": [
                0,
                67
            ],
            "parquet-thrift/src/test/thrift/compat.thrift": null
        }
    },
    "9ee3a16179cb65f5fe4170257ab7cde558f1dbeb": {
        "datetime": "2015-03-13T12:54:58-07:00",
        "summary": "PARQUET-217 Use simpler heuristic in MemoryManager",
        "message": "PARQUET-217 Use simpler heuristic in MemoryManager\n\nWe found that the heuristic of throwing when:\n```\nminMemoryAllocation > 0 && newSize/maxColCount < minMemoryAllocation\n```\nin MemoryManager is not really valid when you have many (3k +) columns, due to the division by the number of columns.\nThis check throws immediately when writing a single file with a 3GB heap and > 3K columns.\n\nThis PR introduces a simpler heuristic, which is a min scale, and we throw when the MemoryManager's scale gets too small. By default I chose 25%, but I'm happy to change that to something else.\n\nFor backwards compatibility I've left the original check in, but it's not executed by default anymore, to get this behavior the min chunk size will have to be set in the hadoop configuration. I'm also open to removing it entirely if we don't think we need it anymore.\n\nWhat do you think?\n@danielcweeks @rdblue @dongche @julienledem\n\nAuthor: Alex Levenson <alexlevenson@twitter.com>\n\nCloses #143 from isnotinvain/alexlevenson/mem-manager-heuristic and squashes the following commits:\n\nacda66f [Alex Levenson] Add units to exception\n10237c6 [Alex Levenson] Decouple DEFAULT_MIN_MEMORY_ALLOCATION from DEFAULT_PAGE_SIZE\n29c9881 [Alex Levenson] Use an absolute minimum on rowgroup size, only apply when scale < 1\n8877125 [Alex Levenson] Merge branch 'master' into alexlevenson/mem-manager-heuristic\ne5117a0 [Alex Levenson] Merge branch 'master' into alexlevenson/mem-manager-heuristic\n6ee5f46 [Alex Levenson] Use simpler heuristic in MemoryManager\n",
        "diff": {
            "parquet-hadoop/src/main/java/parquet/hadoop/MemoryManager.java": [
                5,
                5
            ]
        }
    },
    "2e3c05359a0e21be44d307104eea3134afcef5f0": {
        "datetime": "2015-03-13T13:36:49-07:00",
        "summary": "PARQUET-197 : Gen parquet metadata from cascading",
        "message": "PARQUET-197 : Gen parquet metadata from cascading\n\nretry of PARQUET-197\n\nfixed support for hadoop2 API\n\nAuthor: Tianshuo Deng <tdeng@twitter.com>\n\nCloses #141 from tsdeng/gen_parquet_meta and squashes the following commits:\n\nd1211a0 [Tianshuo Deng] fix hadoop2 API\n8686ce4 [Tianshuo Deng] gem parquet metadata\n",
        "diff": {
            "parquet-cascading/src/main/java/parquet/cascading/ParquetTBaseScheme.java": [
                1,
                1
            ],
            "parquet-cascading/src/main/java/parquet/cascading/ParquetTupleScheme.java": [
                1,
                1
            ],
            "parquet-cascading/src/test/java/parquet/cascading/TestParquetTBaseScheme.java": [
                5,
                14
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/ParquetOutputCommitter.java": [
                0,
                4
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/mapred/DeprecatedParquetOutputFormat.java": [
                0,
                5
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/mapred/MapredParquetOutputCommitter.java": [
                0,
                45
            ],
            "parquet-scrooge/src/main/java/parquet/scrooge/ParquetScroogeScheme.java": [
                4,
                1
            ]
        }
    },
    "ec6f200b4943cfcbc8be5a8e53fdebf07a8e16f7": {
        "datetime": "2015-03-13T14:35:02-07:00",
        "summary": "[maven-release-plugin] prepare release parquet-1.6.0rc7",
        "message": "[maven-release-plugin] prepare release parquet-1.6.0rc7\n",
        "diff": {
            "parquet-avro/pom.xml": null,
            "parquet-cascading/pom.xml": null,
            "parquet-column/pom.xml": null,
            "parquet-common/pom.xml": null,
            "parquet-encoding/pom.xml": null,
            "parquet-generator/pom.xml": null,
            "parquet-hadoop-bundle/pom.xml": null,
            "parquet-hadoop/pom.xml": null,
            "parquet-hive-bundle/pom.xml": null,
            "parquet-hive/parquet-hive-binding/parquet-hive-0.10-binding/pom.xml": null,
            "parquet-hive/parquet-hive-binding/parquet-hive-0.12-binding/pom.xml": null,
            "parquet-hive/parquet-hive-binding/parquet-hive-binding-bundle/pom.xml": null,
            "parquet-hive/parquet-hive-binding/parquet-hive-binding-factory/pom.xml": null,
            "parquet-hive/parquet-hive-binding/parquet-hive-binding-interface/pom.xml": null,
            "parquet-hive/parquet-hive-binding/pom.xml": null,
            "parquet-hive/parquet-hive-storage-handler/pom.xml": null,
            "parquet-hive/pom.xml": null,
            "parquet-jackson/pom.xml": null,
            "parquet-pig-bundle/pom.xml": null,
            "parquet-pig/pom.xml": null,
            "parquet-protobuf/pom.xml": null,
            "parquet-scala/pom.xml": null,
            "parquet-scrooge/pom.xml": null,
            "parquet-thrift/pom.xml": null,
            "parquet-tools/pom.xml": null,
            "pom.xml": null
        }
    },
    "cb7f6a8cb956b2503f04a5308f6a461672df1301": {
        "datetime": "2015-03-13T14:35:06-07:00",
        "summary": "[maven-release-plugin] prepare for next development iteration",
        "message": "[maven-release-plugin] prepare for next development iteration\n",
        "diff": {
            "parquet-avro/pom.xml": null,
            "parquet-cascading/pom.xml": null,
            "parquet-column/pom.xml": null,
            "parquet-common/pom.xml": null,
            "parquet-encoding/pom.xml": null,
            "parquet-generator/pom.xml": null,
            "parquet-hadoop-bundle/pom.xml": null,
            "parquet-hadoop/pom.xml": null,
            "parquet-hive-bundle/pom.xml": null,
            "parquet-hive/parquet-hive-binding/parquet-hive-0.10-binding/pom.xml": null,
            "parquet-hive/parquet-hive-binding/parquet-hive-0.12-binding/pom.xml": null,
            "parquet-hive/parquet-hive-binding/parquet-hive-binding-bundle/pom.xml": null,
            "parquet-hive/parquet-hive-binding/parquet-hive-binding-factory/pom.xml": null,
            "parquet-hive/parquet-hive-binding/parquet-hive-binding-interface/pom.xml": null,
            "parquet-hive/parquet-hive-binding/pom.xml": null,
            "parquet-hive/parquet-hive-storage-handler/pom.xml": null,
            "parquet-hive/pom.xml": null,
            "parquet-jackson/pom.xml": null,
            "parquet-pig-bundle/pom.xml": null,
            "parquet-pig/pom.xml": null,
            "parquet-protobuf/pom.xml": null,
            "parquet-scala/pom.xml": null,
            "parquet-scrooge/pom.xml": null,
            "parquet-thrift/pom.xml": null,
            "parquet-tools/pom.xml": null,
            "pom.xml": null
        }
    },
    "fd3085ed31d920e8ca6bba391e75d1423ed8b607": {
        "datetime": "2015-03-24T16:06:26-07:00",
        "summary": "PARQUET-204: add parquet-schema directory support",
        "message": "PARQUET-204: add parquet-schema directory support\n\nAuthor: Neville Li <neville@spotify.com>\n\nCloses #136 from nevillelyh/neville/PARQUET-204 and squashes the following commits:\n\n633829b [Neville Li] PARQUET-204: add parquet-schema directory support\n7aa8581 [Neville Li] PARQUET-203: consolidate PathFilter for hidden files\n",
        "diff": {
            "parquet-hadoop/src/main/java/parquet/hadoop/ParquetFileReader.java": [
                7,
                2
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/ParquetInputFormat.java": [
                8,
                2
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/ParquetReader.java": [
                7,
                2
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/PrintFooter.java": [
                7,
                2
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/util/HiddenFileFilter.java": [
                0,
                33
            ],
            "parquet-hadoop/src/test/java/parquet/hadoop/TestParquetFileWriter.java": [
                7,
                2
            ],
            "parquet-tools/src/main/java/parquet/tools/command/ShowSchemaCommand.java": [
                1,
                18
            ]
        }
    },
    "b8f5d89e0f4347ce54cf680bd7dffc9bc02f876a": {
        "datetime": "2015-03-24T16:24:03-07:00",
        "summary": "PARQUET-189: Support building parquet with thrift 0.9.0",
        "message": "PARQUET-189: Support building parquet with thrift 0.9.0\n\n6cbed83f [Ferdinand Xu] PARQUET-189: Support building parquet with thrift 0.9.0\n",
        "diff": {
            "parquet-thrift/pom.xml": null,
            "pom.xml": null
        }
    },
    "4fea3ea6997c8135bc18a2bff31dc0a54e7bd82d": {
        "datetime": "2015-03-31T11:23:42-07:00",
        "summary": "PARQUET-165: Add a new parquet-benchmark module",
        "message": "PARQUET-165: Add a new parquet-benchmark module\n\nPARQUET-165\n\nThis PR is an initial version of a new ``parquet-benchmark`` module that we can build upon. The module already contains some simple benchmarks for read/writes, we can discuss how we can make those more representative.\n\nWhen run, various statistics will be printed for all the benchmarks in this module. For example, for the read benchmarks the output will look like:\n\n```\n# Run complete. Total time: 00:03:16\n\nBenchmark                                                             Mode  Samples  Score   Error  Units\np.b.ReadBenchmarks.read1MRowsBS256MPS4MUncompressed                  thrpt        1  0.248 \u00b1   NaN  ops/s\np.b.ReadBenchmarks.read1MRowsBS256MPS8MUncompressed                  thrpt        1  0.331 \u00b1   NaN  ops/s\np.b.ReadBenchmarks.read1MRowsBS512MPS4MUncompressed                  thrpt        1  0.309 \u00b1   NaN  ops/s\np.b.ReadBenchmarks.read1MRowsBS512MPS8MUncompressed                  thrpt        1  0.303 \u00b1   NaN  ops/s\np.b.ReadBenchmarks.read1MRowsDefaultBlockAndPageSizeGZIP             thrpt        1  0.264 \u00b1   NaN  ops/s\np.b.ReadBenchmarks.read1MRowsDefaultBlockAndPageSizeSNAPPY           thrpt        1  0.499 \u00b1   NaN  ops/s\np.b.ReadBenchmarks.read1MRowsDefaultBlockAndPageSizeUncompressed     thrpt        1  0.360 \u00b1   NaN  ops/s\np.b.ReadBenchmarks.read1MRowsBS256MPS4MUncompressed                   avgt        1  3.623 \u00b1   NaN   s/op\np.b.ReadBenchmarks.read1MRowsBS256MPS8MUncompressed                   avgt        1  3.162 \u00b1   NaN   s/op\np.b.ReadBenchmarks.read1MRowsBS512MPS4MUncompressed                   avgt        1  3.231 \u00b1   NaN   s/op\np.b.ReadBenchmarks.read1MRowsBS512MPS8MUncompressed                   avgt        1  2.583 \u00b1   NaN   s/op\np.b.ReadBenchmarks.read1MRowsDefaultBlockAndPageSizeGZIP              avgt        1  3.713 \u00b1   NaN   s/op\np.b.ReadBenchmarks.read1MRowsDefaultBlockAndPageSizeSNAPPY            avgt        1  2.055 \u00b1   NaN   s/op\np.b.ReadBenchmarks.read1MRowsDefaultBlockAndPageSizeUncompressed      avgt        1  2.904 \u00b1   NaN   s/op\np.b.ReadBenchmarks.read1MRowsBS256MPS4MUncompressed                 sample        1  2.772 \u00b1   NaN   s/op\np.b.ReadBenchmarks.read1MRowsBS256MPS8MUncompressed                 sample        1  2.538 \u00b1   NaN   s/op\np.b.ReadBenchmarks.read1MRowsBS512MPS4MUncompressed                 sample        1  2.496 \u00b1   NaN   s/op\np.b.ReadBenchmarks.read1MRowsBS512MPS8MUncompressed                 sample        1  2.416 \u00b1   NaN   s/op\np.b.ReadBenchmarks.read1MRowsDefaultBlockAndPageSizeGZIP            sample        1  3.712 \u00b1   NaN   s/op\np.b.ReadBenchmarks.read1MRowsDefaultBlockAndPageSizeSNAPPY          sample        1  1.772 \u00b1   NaN   s/op\np.b.ReadBenchmarks.read1MRowsDefaultBlockAndPageSizeUncompressed    sample        1  2.819 \u00b1   NaN   s/op\np.b.ReadBenchmarks.read1MRowsBS256MPS4MUncompressed                     ss        1  2.416 \u00b1   NaN      s\np.b.ReadBenchmarks.read1MRowsBS256MPS8MUncompressed                     ss        1  2.564 \u00b1   NaN      s\np.b.ReadBenchmarks.read1MRowsBS512MPS4MUncompressed                     ss        1  2.547 \u00b1   NaN      s\np.b.ReadBenchmarks.read1MRowsBS512MPS8MUncompressed                     ss        1  3.094 \u00b1   NaN      s\np.b.ReadBenchmarks.read1MRowsDefaultBlockAndPageSizeGZIP                ss        1  3.689 \u00b1   NaN      s\np.b.ReadBenchmarks.read1MRowsDefaultBlockAndPageSizeSNAPPY              ss        1  1.983 \u00b1   NaN      s\np.b.ReadBenchmarks.read1MRowsDefaultBlockAndPageSizeUncompressed        ss        1  2.928 \u00b1   NaN      s\n\n```\n\nAuthor: Nezih Yigitbasi <nyigitbasi@netflix.com>\n\nCloses #104 from nezihyigitbasi/benchmark-module and squashes the following commits:\n\n90c72f5 [Nezih Yigitbasi] Add a new parquet-benchmark module\n",
        "diff": {
            "parquet-benchmarks/README.md": null,
            "parquet-benchmarks/pom.xml": null,
            "parquet-benchmarks/run.sh": null,
            "parquet-benchmarks/src/main/java/parquet/benchmarks/BenchmarkConstants.java": [
                0,
                42
            ],
            "parquet-benchmarks/src/main/java/parquet/benchmarks/BenchmarkFiles.java": [
                0,
                40
            ],
            "parquet-benchmarks/src/main/java/parquet/benchmarks/BenchmarkUtils.java": [
                0,
                46
            ],
            "parquet-benchmarks/src/main/java/parquet/benchmarks/DataGenerator.java": [
                0,
                144
            ],
            "parquet-benchmarks/src/main/java/parquet/benchmarks/ReadBenchmarks.java": [
                0,
                106
            ],
            "parquet-benchmarks/src/main/java/parquet/benchmarks/WriteBenchmarks.java": [
                0,
                159
            ],
            "pom.xml": null
        }
    },
    "9a92f39783c01ba36d32d6e9cb2631ac589b9ac8": {
        "datetime": "2015-03-31T11:59:03-07:00",
        "summary": "PARQUET-165: Update parquet version in the benchmark module",
        "message": "PARQUET-165: Update parquet version in the benchmark module\n\nAuthor: Nezih Yigitbasi <nyigitbasi@netflix.com>\n\nCloses #155 from nezihyigitbasi/parquet-benchmarks-fix and squashes the following commits:\n\n3f43427 [Nezih Yigitbasi] Update parquet version\n",
        "diff": {
            "parquet-benchmarks/pom.xml": null
        }
    },
    "0ab0013522df1dc03a68bce6e7539bbfd0ea67d9": {
        "datetime": "2015-03-31T16:34:47-07:00",
        "summary": "PARQUET-210: add JSON support for parquet-cat",
        "message": "PARQUET-210: add JSON support for parquet-cat\n\nJSON output with this patch:\n```\n{\"int_field\":99,\"long_field\":1099,\"float_field\":2099.5,\"double_field\":5099.5,\"boolean_field\":true,\"string_field\":\"str99\",\"nested\":{\"numbers\":[100,101,102,103,104],\"name\":\"name99\",\"dict\":{\"a\":100,\"b\":200,\"c\":300}}}\n```\n\nCurrent output format:\n```\nint_field = 99\nlong_field = 1099\nfloat_field = 2099.5\ndouble_field = 5099.5\nboolean_field = true\nstring_field = str99\nnested:\n.numbers:\n..array = 100\n..array = 101\n..array = 102\n..array = 103\n..array = 104\n.name = name99\n.dict:\n..map:\n...key = a\n...value = 100\n..map:\n...key = b\n...value = 200\n..map:\n...key = c\n...value = 300\n```\n\nAuthor: Neville Li <neville@spotify.com>\n\nCloses #140 from nevillelyh/neville/PARQUET-210 and squashes the following commits:\n\n45fd629 [Neville Li] PARQUET-210: add JSON support for parquet-cat\n",
        "diff": {
            "parquet-tools/src/main/java/parquet/tools/command/CatCommand.java": [
                1,
                22
            ],
            "parquet-tools/src/main/java/parquet/tools/read/SimpleListRecord.java": [
                0,
                30
            ],
            "parquet-tools/src/main/java/parquet/tools/read/SimpleListRecordConverter.java": [
                0,
                34
            ],
            "parquet-tools/src/main/java/parquet/tools/read/SimpleMapRecord.java": [
                0,
                43
            ],
            "parquet-tools/src/main/java/parquet/tools/read/SimpleMapRecordConverter.java": [
                0,
                34
            ],
            "parquet-tools/src/main/java/parquet/tools/read/SimpleRecord.java": [
                6,
                30
            ],
            "parquet-tools/src/main/java/parquet/tools/read/SimpleRecordConverter.java": [
                20,
                11
            ]
        }
    },
    "4ed0bdf1c73fd82d3080d15085675de96d5be0aa": {
        "datetime": "2015-03-31T16:49:30-07:00",
        "summary": "PARQUET-214: Fix Avro string regression.",
        "message": "PARQUET-214: Fix Avro string regression.\n\nAt some point, parquet-avro converted string fields to binary without\nthe UTF8 annotation. The change in PARQUET-139 to filter the file's\nschema using the requested projection causes a regression because the\nannotation is not present in some file schemas, but is present in the\nprojection schema converted from Avro.\n\nThis reverts the projection change to avoid a regression in a release.\nFixing the projection as in PARQUET-139 will need to be done as a\nfollow-up.\n\nAuthor: Ryan Blue <blue@apache.org>\n\nCloses #142 from rdblue/PARQUET-214-fix-avro-regression and squashes the following commits:\n\n71e0207 [Ryan Blue] PARQUET-214: Add support for old avro.schema property.\n95148f9 [Ryan Blue] PARQUET-214: Revert Schema projection change from PARQUET-139.\n",
        "diff": {
            "parquet-avro/src/main/java/parquet/avro/AvroReadSupport.java": [
                3,
                6
            ],
            "parquet-avro/src/test/java/parquet/avro/TestBackwardCompatibility.java": [
                0,
                51
            ],
            "parquet-avro/src/test/resources/strings-2.parquet": null
        }
    },
    "27ba68133faf92d92b395829a6b6dff97e53e2c6": {
        "datetime": "2015-04-03T15:41:50-07:00",
        "summary": "PARQUET-230: Add build instructions to README.",
        "message": "PARQUET-230: Add build instructions to README.\n\nAuthor: Ryan Blue <blue@apache.org>\n\nCloses #156 from rdblue/PARQUET-230-add-build-instructions-to-readme and squashes the following commits:\n\n896604a [Ryan Blue] PARQUET-230: Add build instructions to README.\n",
        "diff": {
            "README.md": null
        }
    },
    "bfb314505469afcd5ea7b5bd15121acd50425318": {
        "datetime": "2015-04-06T14:39:53-07:00",
        "summary": "PARQUET-220: Remove unnecessary warnings initializing ParquetRecordReader",
        "message": "PARQUET-220: Remove unnecessary warnings initializing ParquetRecordReader\n\nRefactored to replace TaskInputOutputContext with TaskAttemptContext.\n\nParquetRecordReader used to check that the passed context is instance of\nTaskInputOutputContext however the functionality it uses doesn't rely on this\nfact.\n\nThis closes #152 when committed. It fixes the review feedback on that issue to include it in 1.6.0.\n\nAuthor: Konstantin Shaposhnikov <Konstantin.Shaposhnikov@sc.com>\n\nCloses #162 from rdblue/PARQUET-152-remove-counter-warning and squashes the following commits:\n\n0a7780f [Konstantin Shaposhnikov] PARQUET-220: do not log unnecessary warnings on initializing ParquetRecordReader\n",
        "diff": {
            "parquet-hadoop/src/main/java/parquet/hadoop/ParquetRecordReader.java": [
                9,
                1
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/util/ContextUtil.java": [
                2,
                1
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/util/counters/BenchmarkCounter.java": [
                1,
                14
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/util/counters/mapreduce/MapReduceCounterLoader.java": [
                1,
                14
            ],
            "pom.xml": null
        }
    },
    "ff7a4863152a4d3873ea038af73024e9999426ac": {
        "datetime": "2015-04-06T15:49:39-07:00",
        "summary": "Revert \"PARQUET-220: Remove unnecessary warnings initializing ParquetRecordReader\"",
        "message": "Revert \"PARQUET-220: Remove unnecessary warnings initializing ParquetRecordReader\"\n\nThis reverts commit bfb314505469afcd5ea7b5bd15121acd50425318.\n",
        "diff": {
            "parquet-hadoop/src/main/java/parquet/hadoop/ParquetRecordReader.java": [
                1,
                9
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/util/ContextUtil.java": [
                1,
                2
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/util/counters/BenchmarkCounter.java": [
                14,
                1
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/util/counters/mapreduce/MapReduceCounterLoader.java": [
                14,
                1
            ],
            "pom.xml": null
        }
    },
    "4950ad86a16e63fa26d51cd709e39666008c5fbc": {
        "datetime": "2015-04-07T09:43:55-07:00",
        "summary": "PARQUET-242: Fix AvroReadSupport.setAvroDataSupplier.",
        "message": "PARQUET-242: Fix AvroReadSupport.setAvroDataSupplier.\n\nThis should use the supplier class's name, rather than its toString\nrepresentation or else loading the class doesn't work.\n\nAuthor: Ryan Blue <blue@apache.org>\n\nCloses #161 from rdblue/PARQUET-242-fix-avro-data-supplier and squashes the following commits:\n\nff5b7f8 [Ryan Blue] PARQUET-242: Add Avro data supplier test.\n87a488b [Ryan Blue] PARQUET-242: Fix AvroReadSupport.setAvroDataSupplier.\n",
        "diff": {
            "parquet-avro/src/main/java/parquet/avro/AvroReadSupport.java": [
                1,
                1
            ],
            "parquet-avro/src/test/java/parquet/avro/TestAvroDataSupplier.java": [
                0,
                43
            ]
        }
    },
    "f272a6e96f0fe80b0c2b4643836006d840d5aa8a": {
        "datetime": "2015-04-07T13:12:55-07:00",
        "summary": "PARQUET-234: Add ParquetInputSplit methods for compatibility.",
        "message": "PARQUET-234: Add ParquetInputSplit methods for compatibility.\n\nAuthor: Ryan Blue <blue@apache.org>\n\nCloses #159 from rdblue/PARQUET-234 and squashes the following commits:\n\nb09d34d [Ryan Blue] PARQUET-234: Add ParquetInputSplit methods for compatibility.\n",
        "diff": {
            "parquet-hadoop/src/main/java/parquet/hadoop/ParquetInputSplit.java": [
                0,
                50
            ]
        }
    },
    "920192a542ab9e9dd2fbf090e1efd3c4ec99977d": {
        "datetime": "2015-04-07T13:14:13-07:00",
        "summary": "PARQUET-235: Fix parquet.metadata compatibility.",
        "message": "PARQUET-235: Fix parquet.metadata compatibility.\n\nColumnPath and Canonicalizer were moved from parquet-hadoop to\nparquet-common in parquet.common.{internal,schema}, which broke\ncompatibility and would require bumping the major version. This moves\nthe classes back into parquet.hadoop.metadata and adds temporary\nexclusions for the move between modules. There are no breaking changes\nto the classes themselves, verified by copying them into parquet-hadoop\nand building.\n\nThis also changes the previous version back to 1.5.0 rather than an RC\n(which carries no compatibility guarantees, though this is compatible\nwith both version). It also adds an exclusions for a false positive in\nBinary.\n\nAuthor: Ryan Blue <blue@apache.org>\n\nCloses #166 from rdblue/PARQUET-235-fix-parquet-metadata and squashes the following commits:\n\nf56a57e [Ryan Blue] PARQUET-235: Fix parquet.metadata compatibility.\n",
        "diff": {
            "parquet-column/src/main/java/parquet/filter2/predicate/FilterApi.java": [
                1,
                1
            ],
            "parquet-column/src/main/java/parquet/filter2/predicate/Operators.java": [
                1,
                1
            ],
            "parquet-column/src/main/java/parquet/filter2/predicate/SchemaCompatibilityValidator.java": [
                1,
                1
            ],
            "parquet-column/src/main/java/parquet/filter2/predicate/ValidTypeMap.java": [
                1,
                1
            ],
            "parquet-column/src/main/java/parquet/filter2/recordlevel/FilteringGroupConverter.java": [
                1,
                1
            ],
            "parquet-column/src/main/java/parquet/filter2/recordlevel/FilteringRecordMaterializer.java": [
                1,
                1
            ],
            "parquet-column/src/main/java/parquet/filter2/recordlevel/IncrementallyUpdatedFilterPredicateBuilderBase.java": [
                1,
                1
            ],
            "parquet-column/src/test/java/parquet/filter2/predicate/TestFilterApiMethods.java": [
                1,
                1
            ],
            "parquet-column/src/test/java/parquet/filter2/predicate/TestValidTypeMap.java": [
                1,
                1
            ],
            "parquet-common/src/main/java/parquet/common/internal/Canonicalizer.java": [
                1,
                1
            ],
            "parquet-common/src/main/java/parquet/common/schema/ColumnPath.java": [
                3,
                1
            ],
            "parquet-generator/src/main/java/parquet/filter2/IncrementallyUpdatedFilterPredicateGenerator.java": [
                1,
                1
            ],
            "parquet-hadoop/src/main/java/parquet/filter2/statisticslevel/StatisticsFilter.java": [
                1,
                1
            ],
            "parquet-hadoop/src/main/java/parquet/format/converter/ParquetMetadataConverter.java": [
                1,
                1
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/ParquetFileReader.java": [
                1,
                1
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/ParquetFileWriter.java": [
                1,
                1
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/metadata/ColumnChunkMetaData.java": [
                1,
                0
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/metadata/ColumnChunkProperties.java": [
                2,
                0
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/metadata/EncodingList.java": [
                1,
                0
            ],
            "parquet-hadoop/src/test/java/parquet/filter2/statisticslevel/TestStatisticsFilter.java": [
                1,
                1
            ],
            "parquet-hadoop/src/test/java/parquet/hadoop/TestInputFormat.java": [
                1,
                1
            ],
            "parquet-hadoop/src/test/java/parquet/hadoop/metadata/TestColumnChunkMetaData.java": [
                1,
                0
            ],
            "pom.xml": null
        }
    },
    "b61362933f7a564d2ae0b7d6b9723f79f4948769": {
        "datetime": "2015-04-07T13:43:06-07:00",
        "summary": "PARQUET-239: Make AvroParquetReader#builder static.",
        "message": "PARQUET-239: Make AvroParquetReader#builder static.\n\nFixes new API method added since 1.5.0.\n\nAuthor: Ryan Blue <blue@apache.org>\n\nCloses #158 from rdblue/PARQUET-239-fix-avro-builder and squashes the following commits:\n\nc8c64d7 [Ryan Blue] PARQUET-239: Make AvroParquetReader#builder static.\n",
        "diff": {
            "parquet-avro/src/main/java/parquet/avro/AvroParquetReader.java": [
                1,
                1
            ]
        }
    },
    "828ff75c002ed63f1fe186c51f616fc913d369d3": {
        "datetime": "2015-04-07T14:20:43-07:00",
        "summary": "PARQUET-211: 1.6.0 release changes",
        "message": "PARQUET-211: 1.6.0 release changes\n\nAuthor: Ryan Blue <blue@apache.org>\n\nCloses #168 from rdblue/PARQUET-211-release-changes and squashes the following commits:\n\nd00aed7 [Ryan Blue] PARQUET-211: Add script for source release artifacts.\nd809d02 [Ryan Blue] PARQUET-211: Add release notes from JIRA 1.6.0.\n",
        "diff": {
            "CHANGES.md": null,
            "dev/source-release.sh": null
        }
    },
    "4f660778f89d4164c72676f6b15bbc74c0d09373": {
        "datetime": "2015-04-07T16:51:08-07:00",
        "summary": "PARQUET-211: Set version to 1.6.0 for release.",
        "message": "PARQUET-211: Set version to 1.6.0 for release.\n",
        "diff": {
            "parquet-avro/pom.xml": null,
            "parquet-benchmarks/pom.xml": null,
            "parquet-cascading/pom.xml": null,
            "parquet-column/pom.xml": null,
            "parquet-common/pom.xml": null,
            "parquet-encoding/pom.xml": null,
            "parquet-generator/pom.xml": null,
            "parquet-hadoop-bundle/pom.xml": null,
            "parquet-hadoop/pom.xml": null,
            "parquet-hive-bundle/pom.xml": null,
            "parquet-hive/parquet-hive-binding/parquet-hive-0.10-binding/pom.xml": null,
            "parquet-hive/parquet-hive-binding/parquet-hive-0.12-binding/pom.xml": null,
            "parquet-hive/parquet-hive-binding/parquet-hive-binding-bundle/pom.xml": null,
            "parquet-hive/parquet-hive-binding/parquet-hive-binding-factory/pom.xml": null,
            "parquet-hive/parquet-hive-binding/parquet-hive-binding-interface/pom.xml": null,
            "parquet-hive/parquet-hive-binding/pom.xml": null,
            "parquet-hive/parquet-hive-storage-handler/pom.xml": null,
            "parquet-hive/pom.xml": null,
            "parquet-jackson/pom.xml": null,
            "parquet-pig-bundle/pom.xml": null,
            "parquet-pig/pom.xml": null,
            "parquet-protobuf/pom.xml": null,
            "parquet-scala/pom.xml": null,
            "parquet-scrooge/pom.xml": null,
            "parquet-thrift/pom.xml": null,
            "parquet-tools/pom.xml": null,
            "pom.xml": null
        }
    },
    "e1019172573297dfa1efef4a5b4cdca748308e6c": {
        "datetime": "2015-04-16T10:45:00-07:00",
        "summary": "PARQUET-211: Set version for 1.7.0-incubating development.",
        "message": "PARQUET-211: Set version for 1.7.0-incubating development.\n\nAuthor: Ryan Blue <blue@apache.org>\n\nCloses #176 from rdblue/PARQUET-211-set-dev-version and squashes the following commits:\n\n90e8fbd [Ryan Blue] PARQUET-211: Set version for 1.7.0-incubating development.\n",
        "diff": {
            "parquet-avro/pom.xml": null,
            "parquet-benchmarks/pom.xml": null,
            "parquet-cascading/pom.xml": null,
            "parquet-column/pom.xml": null,
            "parquet-common/pom.xml": null,
            "parquet-encoding/pom.xml": null,
            "parquet-generator/pom.xml": null,
            "parquet-hadoop-bundle/pom.xml": null,
            "parquet-hadoop/pom.xml": null,
            "parquet-hive-bundle/pom.xml": null,
            "parquet-hive/parquet-hive-binding/parquet-hive-0.10-binding/pom.xml": null,
            "parquet-hive/parquet-hive-binding/parquet-hive-0.12-binding/pom.xml": null,
            "parquet-hive/parquet-hive-binding/parquet-hive-binding-bundle/pom.xml": null,
            "parquet-hive/parquet-hive-binding/parquet-hive-binding-factory/pom.xml": null,
            "parquet-hive/parquet-hive-binding/parquet-hive-binding-interface/pom.xml": null,
            "parquet-hive/parquet-hive-binding/pom.xml": null,
            "parquet-hive/parquet-hive-storage-handler/pom.xml": null,
            "parquet-hive/pom.xml": null,
            "parquet-jackson/pom.xml": null,
            "parquet-pig-bundle/pom.xml": null,
            "parquet-pig/pom.xml": null,
            "parquet-protobuf/pom.xml": null,
            "parquet-scala/pom.xml": null,
            "parquet-scrooge/pom.xml": null,
            "parquet-thrift/pom.xml": null,
            "parquet-tools/pom.xml": null,
            "pom.xml": null
        }
    },
    "f28aa71041181867a720134e26b64b03cbccb6ec": {
        "datetime": "2015-04-27T10:34:38-07:00",
        "summary": "PARQUET-252 : Support nests container types for scrooge support",
        "message": "PARQUET-252 : Support nests container types for scrooge support\n\nparquet should support nested container type for scrooge, like list<list> or list<map>\n\nAuthor: Tianshuo Deng <tdeng@twitter.com>\n\nCloses #175 from tsdeng/support_nests_container_types_for_scrooge_support and squashes the following commits:\n\nbae3e68 [Tianshuo Deng] move set list and map inner elem name conversion to private static methods\n48b4342 [Tianshuo Deng] catch ClassCastException\nfc25bd0 [Tianshuo Deng] remove hack/fix for nested name\n429c61c [Tianshuo Deng] fix exception handling, use explicit imports\nf54e648 [Tianshuo Deng] comments\n815ee29 [Tianshuo Deng] support nested scrooge type\n",
        "diff": {
            "parquet-scrooge/src/main/java/parquet/scrooge/ScroogeStructConverter.java": [
                139,
                179
            ],
            "parquet-scrooge/src/test/java/parquet/scrooge/ScroogeStructConverterTest.java": [
                51,
                106
            ],
            "parquet-scrooge/src/test/thrift/test.thrift": null
        }
    },
    "720b988fd8d7a50fbe922e6c73a3681b1c566331": {
        "datetime": "2015-04-27T15:37:21-07:00",
        "summary": "Revert \"PARQUET-252 : Support nests container types for scrooge support\"",
        "message": "Revert \"PARQUET-252 : Support nests container types for scrooge support\"\n\nThis reverts commit f28aa71041181867a720134e26b64b03cbccb6ec.\n",
        "diff": {
            "parquet-scrooge/src/main/java/parquet/scrooge/ScroogeStructConverter.java": [
                179,
                139
            ],
            "parquet-scrooge/src/test/java/parquet/scrooge/ScroogeStructConverterTest.java": [
                106,
                51
            ],
            "parquet-scrooge/src/test/thrift/test.thrift": null
        }
    },
    "b10870e4ee7d4168a7a1530494e0a8acd8e6cb3f": {
        "datetime": "2015-04-27T16:11:42-07:00",
        "summary": "PARQUET-23: Rename to org.apache.parquet.",
        "message": "PARQUET-23: Rename to org.apache.parquet.\n\nThis includes all of the code updates by module (so that we can use github for the review). I think this is currently all of the changes needed.\n\nAuthor: Ryan Blue <blue@apache.org>\n\nCloses #179 from rdblue/PARQUET-23-rename-to-org-apache and squashes the following commits:\n\n5018c94 [Ryan Blue] PARQUET-23: Change artifacts to org.apache.parquet group id.\n487b044 [Ryan Blue] PARQUET-23: POM fixes for move to org.apache.parquet.\nfe76459 [Ryan Blue] PARQUET-23: Move parquet-tools to org.apache.parquet.\n431bc6e [Ryan Blue] PARQUET-23: Move parquet-hive to org.apache.parquet.\n382db6f [Ryan Blue] PARQUET-23: Move parquet-scrooge to org.apache.parquet.\nf76b052 [Ryan Blue] PARQUET-23: Move parquet-scala to org.apache.parquet.\nc557515 [Ryan Blue] PARQUET-23: Move parquet-protobuf to org.apache.parquet.\n2a82366 [Ryan Blue] PARQUET-23: Move parquet-cascading to org.apache.parquet.\nf33db35 [Ryan Blue] PARQUET-23: Move parquet-thrift to org.apache.parquet.\n02399d2 [Ryan Blue] PARQUET-23: Move parquet-pig to org.apache.parquet.\ne0bb9ad [Ryan Blue] PARQUET-23: Move parquet-benchmarks to org.apache.parquet.\n55fb0c4 [Ryan Blue] PARQUET-23: Move parquet-avro to org.apache.parquet.\n8b7318f [Ryan Blue] PARQUET-23: Move parquet-hadoop to org.apache.parquet.\n666b3d7 [Ryan Blue] PARQUET-23: Move parquet-column to org.apache.parquet.\n3aaf772 [Ryan Blue] PARQUET-23: Move parquet-encoding to org.apache.parquet.\n9f6df3e [Ryan Blue] PARQUET-23: Move parquet-generator to org.apache.parquet.\ne34edab [Ryan Blue] PARQUET-23: Move parquet-common to org.apache.parquet.\n3ae3f7e [Ryan Blue] PARQUET-23: Use org.apache.parquet:parquet-format.\n",
        "diff": {
            "parquet-avro/pom.xml": null,
            "parquet-avro/src/main/java/org/apache/parquet/avro/AvroDataSupplier.java": [
                0,
                31
            ],
            "parquet-avro/src/main/java/org/apache/parquet/avro/AvroIndexedRecordConverter.java": [
                0,
                700
            ],
            "parquet-avro/src/main/java/org/apache/parquet/avro/AvroParquetInputFormat.java": [
                0,
                84
            ],
            "parquet-avro/src/main/java/org/apache/parquet/avro/AvroParquetOutputFormat.java": [
                0,
                50
            ],
            "parquet-avro/src/main/java/org/apache/parquet/avro/AvroParquetReader.java": [
                0,
                70
            ],
            "parquet-avro/src/main/java/org/apache/parquet/avro/AvroParquetWriter.java": [
                0,
                106
            ],
            "parquet-avro/src/main/java/org/apache/parquet/avro/AvroReadSupport.java": [
                0,
                113
            ],
            "parquet-avro/src/main/java/org/apache/parquet/avro/AvroRecordMaterializer.java": [
                0,
                46
            ],
            "parquet-avro/src/main/java/org/apache/parquet/avro/AvroSchemaConverter.java": [
                0,
                355
            ],
            "parquet-avro/src/main/java/org/apache/parquet/avro/AvroWriteSupport.java": [
                0,
                234
            ],
            "parquet-avro/src/main/java/org/apache/parquet/avro/SpecificDataSupplier.java": [
                0,
                29
            ],
            "parquet-avro/src/main/java/org/apache/parquet/avro/package-info.java": [
                0,
                171
            ],
            "parquet-avro/src/main/java/parquet/avro/AvroDataSupplier.java": [
                31,
                0
            ],
            "parquet-avro/src/main/java/parquet/avro/AvroIndexedRecordConverter.java": [
                700,
                0
            ],
            "parquet-avro/src/main/java/parquet/avro/AvroParquetInputFormat.java": [
                84,
                0
            ],
            "parquet-avro/src/main/java/parquet/avro/AvroParquetOutputFormat.java": [
                50,
                0
            ],
            "parquet-avro/src/main/java/parquet/avro/AvroParquetReader.java": [
                70,
                0
            ],
            "parquet-avro/src/main/java/parquet/avro/AvroParquetWriter.java": [
                106,
                0
            ],
            "parquet-avro/src/main/java/parquet/avro/AvroReadSupport.java": [
                113,
                0
            ],
            "parquet-avro/src/main/java/parquet/avro/AvroRecordMaterializer.java": [
                46,
                0
            ],
            "parquet-avro/src/main/java/parquet/avro/AvroSchemaConverter.java": [
                355,
                0
            ],
            "parquet-avro/src/main/java/parquet/avro/AvroWriteSupport.java": [
                234,
                0
            ],
            "parquet-avro/src/main/java/parquet/avro/SpecificDataSupplier.java": [
                29,
                0
            ],
            "parquet-avro/src/main/java/parquet/avro/package-info.java": [
                171,
                0
            ],
            "parquet-avro/src/test/java/org/apache/parquet/avro/AvroTestUtil.java": [
                0,
                69
            ],
            "parquet-avro/src/test/java/org/apache/parquet/avro/TestArrayCompatibility.java": [
                0,
                999
            ],
            "parquet-avro/src/test/java/org/apache/parquet/avro/TestAvroDataSupplier.java": [
                0,
                43
            ],
            "parquet-avro/src/test/java/org/apache/parquet/avro/TestAvroSchemaConverter.java": [
                0,
                256
            ],
            "parquet-avro/src/test/java/org/apache/parquet/avro/TestBackwardCompatibility.java": [
                0,
                51
            ],
            "parquet-avro/src/test/java/org/apache/parquet/avro/TestInputOutputFormat.java": [
                0,
                144
            ],
            "parquet-avro/src/test/java/org/apache/parquet/avro/TestReadWrite.java": [
                0,
                460
            ],
            "parquet-avro/src/test/java/org/apache/parquet/avro/TestSpecificInputOutputFormat.java": [
                0,
                286
            ],
            "parquet-avro/src/test/java/org/apache/parquet/avro/TestSpecificReadWrite.java": [
                0,
                288
            ],
            "parquet-avro/src/test/java/parquet/avro/AvroTestUtil.java": [
                69,
                0
            ],
            "parquet-avro/src/test/java/parquet/avro/TestArrayCompatibility.java": [
                999,
                0
            ],
            "parquet-avro/src/test/java/parquet/avro/TestAvroDataSupplier.java": [
                43,
                0
            ],
            "parquet-avro/src/test/java/parquet/avro/TestAvroSchemaConverter.java": [
                256,
                0
            ],
            "parquet-avro/src/test/java/parquet/avro/TestBackwardCompatibility.java": [
                51,
                0
            ],
            "parquet-avro/src/test/java/parquet/avro/TestInputOutputFormat.java": [
                144,
                0
            ],
            "parquet-avro/src/test/java/parquet/avro/TestReadWrite.java": [
                460,
                0
            ],
            "parquet-avro/src/test/java/parquet/avro/TestSpecificInputOutputFormat.java": [
                286,
                0
            ],
            "parquet-avro/src/test/java/parquet/avro/TestSpecificReadWrite.java": [
                288,
                0
            ],
            "parquet-avro/src/test/resources/all.avsc": null,
            "parquet-avro/src/test/resources/allFromParquet.avsc": null,
            "parquet-avro/src/test/resources/car.avdl": null,
            "parquet-benchmarks/pom.xml": null,
            "parquet-benchmarks/src/main/java/org/apache/parquet/benchmarks/BenchmarkConstants.java": [
                0,
                42
            ],
            "parquet-benchmarks/src/main/java/org/apache/parquet/benchmarks/BenchmarkFiles.java": [
                0,
                40
            ],
            "parquet-benchmarks/src/main/java/org/apache/parquet/benchmarks/BenchmarkUtils.java": [
                0,
                46
            ],
            "parquet-benchmarks/src/main/java/org/apache/parquet/benchmarks/DataGenerator.java": [
                0,
                144
            ],
            "parquet-benchmarks/src/main/java/org/apache/parquet/benchmarks/ReadBenchmarks.java": [
                0,
                106
            ],
            "parquet-benchmarks/src/main/java/org/apache/parquet/benchmarks/WriteBenchmarks.java": [
                0,
                159
            ],
            "parquet-benchmarks/src/main/java/parquet/benchmarks/BenchmarkConstants.java": [
                42,
                0
            ],
            "parquet-benchmarks/src/main/java/parquet/benchmarks/BenchmarkFiles.java": [
                40,
                0
            ],
            "parquet-benchmarks/src/main/java/parquet/benchmarks/BenchmarkUtils.java": [
                46,
                0
            ],
            "parquet-benchmarks/src/main/java/parquet/benchmarks/DataGenerator.java": [
                144,
                0
            ],
            "parquet-benchmarks/src/main/java/parquet/benchmarks/ReadBenchmarks.java": [
                106,
                0
            ],
            "parquet-benchmarks/src/main/java/parquet/benchmarks/WriteBenchmarks.java": [
                159,
                0
            ],
            "parquet-cascading/pom.xml": null,
            "parquet-cascading/src/main/java/org/apache/parquet/cascading/ParquetTBaseScheme.java": [
                0,
                80
            ],
            "parquet-cascading/src/main/java/org/apache/parquet/cascading/ParquetTupleScheme.java": [
                0,
                191
            ],
            "parquet-cascading/src/main/java/org/apache/parquet/cascading/ParquetValueScheme.java": [
                0,
                162
            ],
            "parquet-cascading/src/main/java/org/apache/parquet/cascading/SchemaIntersection.java": [
                0,
                63
            ],
            "parquet-cascading/src/main/java/org/apache/parquet/cascading/TupleReadSupport.java": [
                0,
                80
            ],
            "parquet-cascading/src/main/java/org/apache/parquet/cascading/TupleWriteSupport.java": [
                0,
                106
            ],
            "parquet-cascading/src/main/java/org/apache/parquet/cascading/convert/TupleConverter.java": [
                0,
                115
            ],
            "parquet-cascading/src/main/java/org/apache/parquet/cascading/convert/TupleRecordMaterializer.java": [
                0,
                46
            ],
            "parquet-cascading/src/main/java/parquet/cascading/ParquetTBaseScheme.java": [
                80,
                0
            ],
            "parquet-cascading/src/main/java/parquet/cascading/ParquetTupleScheme.java": [
                191,
                0
            ],
            "parquet-cascading/src/main/java/parquet/cascading/ParquetValueScheme.java": [
                162,
                0
            ],
            "parquet-cascading/src/main/java/parquet/cascading/SchemaIntersection.java": [
                63,
                0
            ],
            "parquet-cascading/src/main/java/parquet/cascading/TupleReadSupport.java": [
                80,
                0
            ],
            "parquet-cascading/src/main/java/parquet/cascading/TupleWriteSupport.java": [
                106,
                0
            ],
            "parquet-cascading/src/main/java/parquet/cascading/convert/TupleConverter.java": [
                115,
                0
            ],
            "parquet-cascading/src/main/java/parquet/cascading/convert/TupleRecordMaterializer.java": [
                46,
                0
            ],
            "parquet-cascading/src/test/java/org/apache/parquet/cascading/TestParquetTBaseScheme.java": [
                0,
                186
            ],
            "parquet-cascading/src/test/java/org/apache/parquet/cascading/TestParquetTupleScheme.java": [
                0,
                182
            ],
            "parquet-cascading/src/test/java/parquet/cascading/TestParquetTBaseScheme.java": [
                186,
                0
            ],
            "parquet-cascading/src/test/java/parquet/cascading/TestParquetTupleScheme.java": [
                182,
                0
            ],
            "parquet-cascading/src/test/thrift/test.thrift": null,
            "parquet-column/pom.xml": null,
            "parquet-column/src/main/java/org/apache/parquet/column/ColumnDescriptor.java": [
                0,
                129
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/ColumnReadStore.java": [
                0,
                34
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/ColumnReader.java": [
                0,
                115
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/ColumnWriteStore.java": [
                0,
                61
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/ColumnWriter.java": [
                0,
                87
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/Dictionary.java": [
                0,
                66
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/Encoding.java": [
                0,
                291
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/ParquetProperties.java": [
                0,
                242
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/UnknownColumnException.java": [
                0,
                42
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/UnknownColumnTypeException.java": [
                0,
                43
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/ValuesType.java": [
                0,
                29
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/impl/ColumnReadStoreImpl.java": [
                0,
                82
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/impl/ColumnReaderImpl.java": [
                0,
                661
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/impl/ColumnWriteStoreV1.java": [
                0,
                135
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/impl/ColumnWriteStoreV2.java": [
                0,
                166
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/impl/ColumnWriterV1.java": [
                0,
                278
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/impl/ColumnWriterV2.java": [
                0,
                304
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/page/DataPage.java": [
                0,
                53
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/page/DataPageV1.java": [
                0,
                98
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/page/DataPageV2.java": [
                0,
                156
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/page/DictionaryPage.java": [
                0,
                88
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/page/Page.java": [
                0,
                49
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/page/PageReadStore.java": [
                0,
                46
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/page/PageReader.java": [
                0,
                43
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/page/PageWriteStore.java": [
                0,
                38
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/page/PageWriter.java": [
                0,
                89
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/statistics/BinaryStatistics.java": [
                0,
                108
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/statistics/BooleanStatistics.java": [
                0,
                108
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/statistics/DoubleStatistics.java": [
                0,
                108
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/statistics/FloatStatistics.java": [
                0,
                108
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/statistics/IntStatistics.java": [
                0,
                108
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/statistics/LongStatistics.java": [
                0,
                108
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/statistics/Statistics.java": [
                0,
                247
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/statistics/StatisticsClassException.java": [
                0,
                34
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/values/RequiresFallback.java": [
                0,
                54
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/values/ValuesReader.java": [
                0,
                126
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/values/ValuesWriter.java": [
                0,
                128
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/values/bitpacking/BitPackingValuesReader.java": [
                0,
                91
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/values/bitpacking/BitPackingValuesWriter.java": [
                0,
                125
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/values/bitpacking/ByteBitPackingValuesReader.java": [
                0,
                83
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/values/bitpacking/ByteBitPackingValuesWriter.java": [
                0,
                86
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/values/boundedint/BitReader.java": [
                0,
                123
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/values/boundedint/BitWriter.java": [
                0,
                159
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/values/boundedint/BoundedIntValuesFactory.java": [
                0,
                32
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/values/boundedint/BoundedIntValuesReader.java": [
                0,
                93
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/values/boundedint/BoundedIntValuesWriter.java": [
                0,
                159
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/values/boundedint/DevNullValuesWriter.java": [
                0,
                89
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/values/boundedint/ZeroIntegerValuesReader.java": [
                0,
                52
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/values/delta/DeltaBinaryPackingConfig.java": [
                0,
                57
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/values/delta/DeltaBinaryPackingValuesReader.java": [
                0,
                170
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/values/delta/DeltaBinaryPackingValuesWriter.java": [
                0,
                269
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/values/deltalengthbytearray/DeltaLengthByteArrayValuesReader.java": [
                0,
                70
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/values/deltalengthbytearray/DeltaLengthByteArrayValuesWriter.java": [
                0,
                106
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/values/deltastrings/DeltaByteArrayReader.java": [
                0,
                78
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/values/deltastrings/DeltaByteArrayWriter.java": [
                0,
                92
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/values/dictionary/DictionaryValuesReader.java": [
                0,
                135
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/values/dictionary/DictionaryValuesWriter.java": [
                0,
                625
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/values/dictionary/IntList.java": [
                0,
                123
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/values/dictionary/PlainValuesDictionary.java": [
                0,
                310
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/values/fallback/FallbackValuesWriter.java": [
                0,
                190
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/values/plain/BinaryPlainValuesReader.java": [
                0,
                70
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/values/plain/BooleanPlainValuesReader.java": [
                0,
                75
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/values/plain/BooleanPlainValuesWriter.java": [
                0,
                78
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/values/plain/FixedLenByteArrayPlainValuesReader.java": [
                0,
                67
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/values/plain/FixedLenByteArrayPlainValuesWriter.java": [
                0,
                98
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/values/plain/PlainValuesReader.java": [
                0,
                135
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/values/plain/PlainValuesWriter.java": [
                0,
                143
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/values/rle/RunLengthBitPackingHybridDecoder.java": [
                0,
                109
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/values/rle/RunLengthBitPackingHybridEncoder.java": [
                0,
                291
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/values/rle/RunLengthBitPackingHybridValuesReader.java": [
                0,
                77
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/values/rle/RunLengthBitPackingHybridValuesWriter.java": [
                0,
                88
            ],
            "parquet-column/src/main/java/org/apache/parquet/example/DummyRecordConverter.java": [
                0,
                114
            ],
            "parquet-column/src/main/java/org/apache/parquet/example/Paper.java": [
                0,
                167
            ],
            "parquet-column/src/main/java/org/apache/parquet/example/data/Group.java": [
                0,
                143
            ],
            "parquet-column/src/main/java/org/apache/parquet/example/data/GroupFactory.java": [
                0,
                25
            ],
            "parquet-column/src/main/java/org/apache/parquet/example/data/GroupValueSource.java": [
                0,
                89
            ],
            "parquet-column/src/main/java/org/apache/parquet/example/data/GroupWriter.java": [
                0,
                62
            ],
            "parquet-column/src/main/java/org/apache/parquet/example/data/simple/BinaryValue.java": [
                0,
                52
            ],
            "parquet-column/src/main/java/org/apache/parquet/example/data/simple/BooleanValue.java": [
                0,
                44
            ],
            "parquet-column/src/main/java/org/apache/parquet/example/data/simple/DoubleValue.java": [
                0,
                45
            ],
            "parquet-column/src/main/java/org/apache/parquet/example/data/simple/FloatValue.java": [
                0,
                45
            ],
            "parquet-column/src/main/java/org/apache/parquet/example/data/simple/Int96Value.java": [
                0,
                46
            ],
            "parquet-column/src/main/java/org/apache/parquet/example/data/simple/IntegerValue.java": [
                0,
                46
            ],
            "parquet-column/src/main/java/org/apache/parquet/example/data/simple/LongValue.java": [
                0,
                45
            ],
            "parquet-column/src/main/java/org/apache/parquet/example/data/simple/NanoTime.java": [
                0,
                80
            ],
            "parquet-column/src/main/java/org/apache/parquet/example/data/simple/Primitive.java": [
                0,
                60
            ],
            "parquet-column/src/main/java/org/apache/parquet/example/data/simple/SimpleGroup.java": [
                0,
                232
            ],
            "parquet-column/src/main/java/org/apache/parquet/example/data/simple/SimpleGroupFactory.java": [
                0,
                38
            ],
            "parquet-column/src/main/java/org/apache/parquet/example/data/simple/convert/GroupRecordConverter.java": [
                0,
                57
            ],
            "parquet-column/src/main/java/org/apache/parquet/example/data/simple/convert/SimpleGroupConverter.java": [
                0,
                67
            ],
            "parquet-column/src/main/java/org/apache/parquet/example/data/simple/convert/SimplePrimitiveConverter.java": [
                0,
                88
            ],
            "parquet-column/src/main/java/org/apache/parquet/filter/AndRecordFilter.java": [
                0,
                64
            ],
            "parquet-column/src/main/java/org/apache/parquet/filter/ColumnPredicates.java": [
                0,
                190
            ],
            "parquet-column/src/main/java/org/apache/parquet/filter/ColumnRecordFilter.java": [
                0,
                75
            ],
            "parquet-column/src/main/java/org/apache/parquet/filter/NotRecordFilter.java": [
                0,
                58
            ],
            "parquet-column/src/main/java/org/apache/parquet/filter/OrRecordFilter.java": [
                0,
                62
            ],
            "parquet-column/src/main/java/org/apache/parquet/filter/PagedRecordFilter.java": [
                0,
                64
            ],
            "parquet-column/src/main/java/org/apache/parquet/filter/RecordFilter.java": [
                0,
                34
            ],
            "parquet-column/src/main/java/org/apache/parquet/filter/UnboundRecordFilter.java": [
                0,
                36
            ],
            "parquet-column/src/main/java/org/apache/parquet/filter2/compat/FilterCompat.java": [
                0,
                158
            ],
            "parquet-column/src/main/java/org/apache/parquet/filter2/predicate/FilterApi.java": [
                0,
                212
            ],
            "parquet-column/src/main/java/org/apache/parquet/filter2/predicate/FilterPredicate.java": [
                0,
                72
            ],
            "parquet-column/src/main/java/org/apache/parquet/filter2/predicate/LogicalInverseRewriter.java": [
                0,
                113
            ],
            "parquet-column/src/main/java/org/apache/parquet/filter2/predicate/LogicalInverter.java": [
                0,
                108
            ],
            "parquet-column/src/main/java/org/apache/parquet/filter2/predicate/Operators.java": [
                0,
                526
            ],
            "parquet-column/src/main/java/org/apache/parquet/filter2/predicate/SchemaCompatibilityValidator.java": [
                0,
                193
            ],
            "parquet-column/src/main/java/org/apache/parquet/filter2/predicate/Statistics.java": [
                0,
                42
            ],
            "parquet-column/src/main/java/org/apache/parquet/filter2/predicate/UserDefinedPredicate.java": [
                0,
                108
            ],
            "parquet-column/src/main/java/org/apache/parquet/filter2/predicate/ValidTypeMap.java": [
                0,
                178
            ],
            "parquet-column/src/main/java/org/apache/parquet/filter2/recordlevel/FilteringGroupConverter.java": [
                0,
                115
            ],
            "parquet-column/src/main/java/org/apache/parquet/filter2/recordlevel/FilteringPrimitiveConverter.java": [
                0,
                109
            ],
            "parquet-column/src/main/java/org/apache/parquet/filter2/recordlevel/FilteringRecordMaterializer.java": [
                0,
                115
            ],
            "parquet-column/src/main/java/org/apache/parquet/filter2/recordlevel/IncrementallyUpdatedFilterPredicate.java": [
                0,
                157
            ],
            "parquet-column/src/main/java/org/apache/parquet/filter2/recordlevel/IncrementallyUpdatedFilterPredicateBuilderBase.java": [
                0,
                97
            ],
            "parquet-column/src/main/java/org/apache/parquet/filter2/recordlevel/IncrementallyUpdatedFilterPredicateEvaluator.java": [
                0,
                63
            ],
            "parquet-column/src/main/java/org/apache/parquet/filter2/recordlevel/IncrementallyUpdatedFilterPredicateResetter.java": [
                0,
                60
            ],
            "parquet-column/src/main/java/org/apache/parquet/io/BaseRecordReader.java": [
                0,
                144
            ],
            "parquet-column/src/main/java/org/apache/parquet/io/ColumnIO.java": [
                0,
                138
            ],
            "parquet-column/src/main/java/org/apache/parquet/io/ColumnIOFactory.java": [
                0,
                161
            ],
            "parquet-column/src/main/java/org/apache/parquet/io/CompilationException.java": [
                0,
                47
            ],
            "parquet-column/src/main/java/org/apache/parquet/io/EmptyRecordReader.java": [
                0,
                50
            ],
            "parquet-column/src/main/java/org/apache/parquet/io/FilteredRecordReader.java": [
                0,
                99
            ],
            "parquet-column/src/main/java/org/apache/parquet/io/GroupColumnIO.java": [
                0,
                122
            ],
            "parquet-column/src/main/java/org/apache/parquet/io/InvalidRecordException.java": [
                0,
                48
            ],
            "parquet-column/src/main/java/org/apache/parquet/io/MessageColumnIO.java": [
                0,
                396
            ],
            "parquet-column/src/main/java/org/apache/parquet/io/ParquetDecodingException.java": [
                0,
                47
            ],
            "parquet-column/src/main/java/org/apache/parquet/io/ParquetEncodingException.java": [
                0,
                47
            ],
            "parquet-column/src/main/java/org/apache/parquet/io/PrimitiveColumnIO.java": [
                0,
                113
            ],
            "parquet-column/src/main/java/org/apache/parquet/io/RecordConsumerLoggingWrapper.java": [
                0,
                178
            ],
            "parquet-column/src/main/java/org/apache/parquet/io/RecordReader.java": [
                0,
                43
            ],
            "parquet-column/src/main/java/org/apache/parquet/io/RecordReaderImplementation.java": [
                0,
                473
            ],
            "parquet-column/src/main/java/org/apache/parquet/io/ValidatingRecordConsumer.java": [
                0,
                230
            ],
            "parquet-column/src/main/java/org/apache/parquet/io/api/Binary.java": [
                0,
                413
            ],
            "parquet-column/src/main/java/org/apache/parquet/io/api/Converter.java": [
                0,
                40
            ],
            "parquet-column/src/main/java/org/apache/parquet/io/api/GroupConverter.java": [
                0,
                58
            ],
            "parquet-column/src/main/java/org/apache/parquet/io/api/PrimitiveConverter.java": [
                0,
                111
            ],
            "parquet-column/src/main/java/org/apache/parquet/io/api/RecordConsumer.java": [
                0,
                128
            ],
            "parquet-column/src/main/java/org/apache/parquet/io/api/RecordMaterializer.java": [
                0,
                48
            ],
            "parquet-column/src/main/java/org/apache/parquet/schema/ConversionPatterns.java": [
                0,
                104
            ],
            "parquet-column/src/main/java/org/apache/parquet/schema/DecimalMetadata.java": [
                0,
                57
            ],
            "parquet-column/src/main/java/org/apache/parquet/schema/GroupType.java": [
                0,
                391
            ],
            "parquet-column/src/main/java/org/apache/parquet/schema/IncompatibleSchemaModificationException.java": [
                0,
                49
            ],
            "parquet-column/src/main/java/org/apache/parquet/schema/MessageType.java": [
                0,
                148
            ],
            "parquet-column/src/main/java/org/apache/parquet/schema/MessageTypeParser.java": [
                0,
                216
            ],
            "parquet-column/src/main/java/org/apache/parquet/schema/OriginalType.java": [
                0,
                42
            ],
            "parquet-column/src/main/java/org/apache/parquet/schema/PrimitiveType.java": [
                0,
                530
            ],
            "parquet-column/src/main/java/org/apache/parquet/schema/Type.java": [
                0,
                317
            ],
            "parquet-column/src/main/java/org/apache/parquet/schema/TypeConverter.java": [
                0,
                55
            ],
            "parquet-column/src/main/java/org/apache/parquet/schema/TypeVisitor.java": [
                0,
                46
            ],
            "parquet-column/src/main/java/org/apache/parquet/schema/Types.java": [
                0,
                668
            ],
            "parquet-column/src/main/java/parquet/column/ColumnDescriptor.java": [
                129,
                0
            ],
            "parquet-column/src/main/java/parquet/column/ColumnReadStore.java": [
                34,
                0
            ],
            "parquet-column/src/main/java/parquet/column/ColumnReader.java": [
                115,
                0
            ],
            "parquet-column/src/main/java/parquet/column/ColumnWriteStore.java": [
                61,
                0
            ],
            "parquet-column/src/main/java/parquet/column/ColumnWriter.java": [
                87,
                0
            ],
            "parquet-column/src/main/java/parquet/column/Dictionary.java": [
                66,
                0
            ],
            "parquet-column/src/main/java/parquet/column/Encoding.java": [
                291,
                0
            ],
            "parquet-column/src/main/java/parquet/column/ParquetProperties.java": [
                242,
                0
            ],
            "parquet-column/src/main/java/parquet/column/UnknownColumnException.java": [
                42,
                0
            ],
            "parquet-column/src/main/java/parquet/column/UnknownColumnTypeException.java": [
                43,
                0
            ],
            "parquet-column/src/main/java/parquet/column/ValuesType.java": [
                29,
                0
            ],
            "parquet-column/src/main/java/parquet/column/impl/ColumnReadStoreImpl.java": [
                82,
                0
            ],
            "parquet-column/src/main/java/parquet/column/impl/ColumnReaderImpl.java": [
                661,
                0
            ],
            "parquet-column/src/main/java/parquet/column/impl/ColumnWriteStoreV1.java": [
                135,
                0
            ],
            "parquet-column/src/main/java/parquet/column/impl/ColumnWriteStoreV2.java": [
                166,
                0
            ],
            "parquet-column/src/main/java/parquet/column/impl/ColumnWriterV1.java": [
                279,
                0
            ],
            "parquet-column/src/main/java/parquet/column/impl/ColumnWriterV2.java": [
                305,
                0
            ],
            "parquet-column/src/main/java/parquet/column/page/DataPage.java": [
                53,
                0
            ],
            "parquet-column/src/main/java/parquet/column/page/DataPageV1.java": [
                98,
                0
            ],
            "parquet-column/src/main/java/parquet/column/page/DataPageV2.java": [
                156,
                0
            ],
            "parquet-column/src/main/java/parquet/column/page/DictionaryPage.java": [
                88,
                0
            ],
            "parquet-column/src/main/java/parquet/column/page/Page.java": [
                49,
                0
            ],
            "parquet-column/src/main/java/parquet/column/page/PageReadStore.java": [
                46,
                0
            ],
            "parquet-column/src/main/java/parquet/column/page/PageReader.java": [
                43,
                0
            ],
            "parquet-column/src/main/java/parquet/column/page/PageWriteStore.java": [
                38,
                0
            ],
            "parquet-column/src/main/java/parquet/column/page/PageWriter.java": [
                89,
                0
            ],
            "parquet-column/src/main/java/parquet/column/statistics/BinaryStatistics.java": [
                108,
                0
            ],
            "parquet-column/src/main/java/parquet/column/statistics/BooleanStatistics.java": [
                108,
                0
            ],
            "parquet-column/src/main/java/parquet/column/statistics/DoubleStatistics.java": [
                108,
                0
            ],
            "parquet-column/src/main/java/parquet/column/statistics/FloatStatistics.java": [
                108,
                0
            ],
            "parquet-column/src/main/java/parquet/column/statistics/IntStatistics.java": [
                108,
                0
            ],
            "parquet-column/src/main/java/parquet/column/statistics/LongStatistics.java": [
                108,
                0
            ],
            "parquet-column/src/main/java/parquet/column/statistics/Statistics.java": [
                247,
                0
            ],
            "parquet-column/src/main/java/parquet/column/statistics/StatisticsClassException.java": [
                34,
                0
            ],
            "parquet-column/src/main/java/parquet/column/values/RequiresFallback.java": [
                54,
                0
            ],
            "parquet-column/src/main/java/parquet/column/values/ValuesReader.java": [
                126,
                0
            ],
            "parquet-column/src/main/java/parquet/column/values/ValuesWriter.java": [
                128,
                0
            ],
            "parquet-column/src/main/java/parquet/column/values/bitpacking/BitPackingValuesReader.java": [
                91,
                0
            ],
            "parquet-column/src/main/java/parquet/column/values/bitpacking/BitPackingValuesWriter.java": [
                125,
                0
            ],
            "parquet-column/src/main/java/parquet/column/values/bitpacking/ByteBitPackingValuesReader.java": [
                83,
                0
            ],
            "parquet-column/src/main/java/parquet/column/values/bitpacking/ByteBitPackingValuesWriter.java": [
                86,
                0
            ],
            "parquet-column/src/main/java/parquet/column/values/boundedint/BitReader.java": [
                123,
                0
            ],
            "parquet-column/src/main/java/parquet/column/values/boundedint/BitWriter.java": [
                159,
                0
            ],
            "parquet-column/src/main/java/parquet/column/values/boundedint/BoundedIntValuesFactory.java": [
                32,
                0
            ],
            "parquet-column/src/main/java/parquet/column/values/boundedint/BoundedIntValuesReader.java": [
                93,
                0
            ],
            "parquet-column/src/main/java/parquet/column/values/boundedint/BoundedIntValuesWriter.java": [
                159,
                0
            ],
            "parquet-column/src/main/java/parquet/column/values/boundedint/DevNullValuesWriter.java": [
                89,
                0
            ],
            "parquet-column/src/main/java/parquet/column/values/boundedint/ZeroIntegerValuesReader.java": [
                52,
                0
            ],
            "parquet-column/src/main/java/parquet/column/values/delta/DeltaBinaryPackingConfig.java": [
                57,
                0
            ],
            "parquet-column/src/main/java/parquet/column/values/delta/DeltaBinaryPackingValuesReader.java": [
                170,
                0
            ],
            "parquet-column/src/main/java/parquet/column/values/delta/DeltaBinaryPackingValuesWriter.java": [
                269,
                0
            ],
            "parquet-column/src/main/java/parquet/column/values/deltalengthbytearray/DeltaLengthByteArrayValuesReader.java": [
                70,
                0
            ],
            "parquet-column/src/main/java/parquet/column/values/deltalengthbytearray/DeltaLengthByteArrayValuesWriter.java": [
                106,
                0
            ],
            "parquet-column/src/main/java/parquet/column/values/deltastrings/DeltaByteArrayReader.java": [
                78,
                0
            ],
            "parquet-column/src/main/java/parquet/column/values/deltastrings/DeltaByteArrayWriter.java": [
                92,
                0
            ],
            "parquet-column/src/main/java/parquet/column/values/dictionary/DictionaryValuesReader.java": [
                135,
                0
            ],
            "parquet-column/src/main/java/parquet/column/values/dictionary/DictionaryValuesWriter.java": [
                625,
                0
            ],
            "parquet-column/src/main/java/parquet/column/values/dictionary/IntList.java": [
                123,
                0
            ],
            "parquet-column/src/main/java/parquet/column/values/dictionary/PlainValuesDictionary.java": [
                310,
                0
            ],
            "parquet-column/src/main/java/parquet/column/values/fallback/FallbackValuesWriter.java": [
                190,
                0
            ],
            "parquet-column/src/main/java/parquet/column/values/plain/BinaryPlainValuesReader.java": [
                70,
                0
            ],
            "parquet-column/src/main/java/parquet/column/values/plain/BooleanPlainValuesReader.java": [
                75,
                0
            ],
            "parquet-column/src/main/java/parquet/column/values/plain/BooleanPlainValuesWriter.java": [
                78,
                0
            ],
            "parquet-column/src/main/java/parquet/column/values/plain/FixedLenByteArrayPlainValuesReader.java": [
                67,
                0
            ],
            "parquet-column/src/main/java/parquet/column/values/plain/FixedLenByteArrayPlainValuesWriter.java": [
                98,
                0
            ],
            "parquet-column/src/main/java/parquet/column/values/plain/PlainValuesReader.java": [
                135,
                0
            ],
            "parquet-column/src/main/java/parquet/column/values/plain/PlainValuesWriter.java": [
                143,
                0
            ],
            "parquet-column/src/main/java/parquet/column/values/rle/RunLengthBitPackingHybridDecoder.java": [
                109,
                0
            ],
            "parquet-column/src/main/java/parquet/column/values/rle/RunLengthBitPackingHybridEncoder.java": [
                291,
                0
            ],
            "parquet-column/src/main/java/parquet/column/values/rle/RunLengthBitPackingHybridValuesReader.java": [
                77,
                0
            ],
            "parquet-column/src/main/java/parquet/column/values/rle/RunLengthBitPackingHybridValuesWriter.java": [
                88,
                0
            ],
            "parquet-column/src/main/java/parquet/example/DummyRecordConverter.java": [
                114,
                0
            ],
            "parquet-column/src/main/java/parquet/example/Paper.java": [
                167,
                0
            ],
            "parquet-column/src/main/java/parquet/example/data/Group.java": [
                143,
                0
            ],
            "parquet-column/src/main/java/parquet/example/data/GroupFactory.java": [
                25,
                0
            ],
            "parquet-column/src/main/java/parquet/example/data/GroupValueSource.java": [
                89,
                0
            ],
            "parquet-column/src/main/java/parquet/example/data/GroupWriter.java": [
                62,
                0
            ],
            "parquet-column/src/main/java/parquet/example/data/simple/BinaryValue.java": [
                52,
                0
            ],
            "parquet-column/src/main/java/parquet/example/data/simple/BooleanValue.java": [
                44,
                0
            ],
            "parquet-column/src/main/java/parquet/example/data/simple/DoubleValue.java": [
                45,
                0
            ],
            "parquet-column/src/main/java/parquet/example/data/simple/FloatValue.java": [
                45,
                0
            ],
            "parquet-column/src/main/java/parquet/example/data/simple/Int96Value.java": [
                46,
                0
            ],
            "parquet-column/src/main/java/parquet/example/data/simple/IntegerValue.java": [
                46,
                0
            ],
            "parquet-column/src/main/java/parquet/example/data/simple/LongValue.java": [
                45,
                0
            ],
            "parquet-column/src/main/java/parquet/example/data/simple/NanoTime.java": [
                80,
                0
            ],
            "parquet-column/src/main/java/parquet/example/data/simple/Primitive.java": [
                60,
                0
            ],
            "parquet-column/src/main/java/parquet/example/data/simple/SimpleGroup.java": [
                232,
                0
            ],
            "parquet-column/src/main/java/parquet/example/data/simple/SimpleGroupFactory.java": [
                38,
                0
            ],
            "parquet-column/src/main/java/parquet/example/data/simple/convert/GroupRecordConverter.java": [
                57,
                0
            ],
            "parquet-column/src/main/java/parquet/example/data/simple/convert/SimpleGroupConverter.java": [
                67,
                0
            ],
            "parquet-column/src/main/java/parquet/example/data/simple/convert/SimplePrimitiveConverter.java": [
                88,
                0
            ],
            "parquet-column/src/main/java/parquet/filter/AndRecordFilter.java": [
                64,
                0
            ],
            "parquet-column/src/main/java/parquet/filter/ColumnPredicates.java": [
                190,
                0
            ],
            "parquet-column/src/main/java/parquet/filter/ColumnRecordFilter.java": [
                75,
                0
            ],
            "parquet-column/src/main/java/parquet/filter/NotRecordFilter.java": [
                58,
                0
            ],
            "parquet-column/src/main/java/parquet/filter/OrRecordFilter.java": [
                62,
                0
            ],
            "parquet-column/src/main/java/parquet/filter/PagedRecordFilter.java": [
                64,
                0
            ],
            "parquet-column/src/main/java/parquet/filter/RecordFilter.java": [
                34,
                0
            ],
            "parquet-column/src/main/java/parquet/filter/UnboundRecordFilter.java": [
                36,
                0
            ],
            "parquet-column/src/main/java/parquet/filter2/compat/FilterCompat.java": [
                158,
                0
            ],
            "parquet-column/src/main/java/parquet/filter2/predicate/FilterApi.java": [
                212,
                0
            ],
            "parquet-column/src/main/java/parquet/filter2/predicate/FilterPredicate.java": [
                72,
                0
            ],
            "parquet-column/src/main/java/parquet/filter2/predicate/LogicalInverseRewriter.java": [
                113,
                0
            ],
            "parquet-column/src/main/java/parquet/filter2/predicate/LogicalInverter.java": [
                108,
                0
            ],
            "parquet-column/src/main/java/parquet/filter2/predicate/Operators.java": [
                526,
                0
            ],
            "parquet-column/src/main/java/parquet/filter2/predicate/SchemaCompatibilityValidator.java": [
                193,
                0
            ],
            "parquet-column/src/main/java/parquet/filter2/predicate/Statistics.java": [
                42,
                0
            ],
            "parquet-column/src/main/java/parquet/filter2/predicate/UserDefinedPredicate.java": [
                108,
                0
            ],
            "parquet-column/src/main/java/parquet/filter2/predicate/ValidTypeMap.java": [
                178,
                0
            ],
            "parquet-column/src/main/java/parquet/filter2/recordlevel/FilteringGroupConverter.java": [
                115,
                0
            ],
            "parquet-column/src/main/java/parquet/filter2/recordlevel/FilteringPrimitiveConverter.java": [
                109,
                0
            ],
            "parquet-column/src/main/java/parquet/filter2/recordlevel/FilteringRecordMaterializer.java": [
                115,
                0
            ],
            "parquet-column/src/main/java/parquet/filter2/recordlevel/IncrementallyUpdatedFilterPredicate.java": [
                157,
                0
            ],
            "parquet-column/src/main/java/parquet/filter2/recordlevel/IncrementallyUpdatedFilterPredicateBuilderBase.java": [
                97,
                0
            ],
            "parquet-column/src/main/java/parquet/filter2/recordlevel/IncrementallyUpdatedFilterPredicateEvaluator.java": [
                63,
                0
            ],
            "parquet-column/src/main/java/parquet/filter2/recordlevel/IncrementallyUpdatedFilterPredicateResetter.java": [
                60,
                0
            ],
            "parquet-column/src/main/java/parquet/io/BaseRecordReader.java": [
                144,
                0
            ],
            "parquet-column/src/main/java/parquet/io/ColumnIO.java": [
                138,
                0
            ],
            "parquet-column/src/main/java/parquet/io/ColumnIOFactory.java": [
                163,
                0
            ],
            "parquet-column/src/main/java/parquet/io/CompilationException.java": [
                47,
                0
            ],
            "parquet-column/src/main/java/parquet/io/EmptyRecordReader.java": [
                50,
                0
            ],
            "parquet-column/src/main/java/parquet/io/FilteredRecordReader.java": [
                99,
                0
            ],
            "parquet-column/src/main/java/parquet/io/GroupColumnIO.java": [
                122,
                0
            ],
            "parquet-column/src/main/java/parquet/io/InvalidRecordException.java": [
                48,
                0
            ],
            "parquet-column/src/main/java/parquet/io/MessageColumnIO.java": [
                396,
                0
            ],
            "parquet-column/src/main/java/parquet/io/ParquetDecodingException.java": [
                47,
                0
            ],
            "parquet-column/src/main/java/parquet/io/ParquetEncodingException.java": [
                47,
                0
            ],
            "parquet-column/src/main/java/parquet/io/PrimitiveColumnIO.java": [
                113,
                0
            ],
            "parquet-column/src/main/java/parquet/io/RecordConsumerLoggingWrapper.java": [
                178,
                0
            ],
            "parquet-column/src/main/java/parquet/io/RecordReader.java": [
                43,
                0
            ],
            "parquet-column/src/main/java/parquet/io/RecordReaderImplementation.java": [
                473,
                0
            ],
            "parquet-column/src/main/java/parquet/io/ValidatingRecordConsumer.java": [
                230,
                0
            ],
            "parquet-column/src/main/java/parquet/io/api/Binary.java": [
                414,
                0
            ],
            "parquet-column/src/main/java/parquet/io/api/Converter.java": [
                40,
                0
            ],
            "parquet-column/src/main/java/parquet/io/api/GroupConverter.java": [
                58,
                0
            ],
            "parquet-column/src/main/java/parquet/io/api/PrimitiveConverter.java": [
                111,
                0
            ],
            "parquet-column/src/main/java/parquet/io/api/RecordConsumer.java": [
                128,
                0
            ],
            "parquet-column/src/main/java/parquet/io/api/RecordMaterializer.java": [
                48,
                0
            ],
            "parquet-column/src/main/java/parquet/schema/ConversionPatterns.java": [
                104,
                0
            ],
            "parquet-column/src/main/java/parquet/schema/DecimalMetadata.java": [
                57,
                0
            ],
            "parquet-column/src/main/java/parquet/schema/GroupType.java": [
                391,
                0
            ],
            "parquet-column/src/main/java/parquet/schema/IncompatibleSchemaModificationException.java": [
                49,
                0
            ],
            "parquet-column/src/main/java/parquet/schema/MessageType.java": [
                148,
                0
            ],
            "parquet-column/src/main/java/parquet/schema/MessageTypeParser.java": [
                216,
                0
            ],
            "parquet-column/src/main/java/parquet/schema/OriginalType.java": [
                42,
                0
            ],
            "parquet-column/src/main/java/parquet/schema/PrimitiveType.java": [
                530,
                0
            ],
            "parquet-column/src/main/java/parquet/schema/Type.java": [
                317,
                0
            ],
            "parquet-column/src/main/java/parquet/schema/TypeConverter.java": [
                55,
                0
            ],
            "parquet-column/src/main/java/parquet/schema/TypeVisitor.java": [
                46,
                0
            ],
            "parquet-column/src/main/java/parquet/schema/Types.java": [
                668,
                0
            ],
            "parquet-column/src/test/java/org/apache/parquet/column/impl/TestColumnReaderImpl.java": [
                0,
                123
            ],
            "parquet-column/src/test/java/org/apache/parquet/column/mem/TestMemColumn.java": [
                0,
                164
            ],
            "parquet-column/src/test/java/org/apache/parquet/column/mem/TestMemPageStore.java": [
                0,
                61
            ],
            "parquet-column/src/test/java/org/apache/parquet/column/page/mem/MemPageReader.java": [
                0,
                69
            ],
            "parquet-column/src/test/java/org/apache/parquet/column/page/mem/MemPageStore.java": [
                0,
                77
            ],
            "parquet-column/src/test/java/org/apache/parquet/column/page/mem/MemPageWriter.java": [
                0,
                113
            ],
            "parquet-column/src/test/java/org/apache/parquet/column/statistics/TestStatistics.java": [
                0,
                569
            ],
            "parquet-column/src/test/java/org/apache/parquet/column/values/RandomStr.java": [
                0,
                56
            ],
            "parquet-column/src/test/java/org/apache/parquet/column/values/Utils.java": [
                0,
                90
            ],
            "parquet-column/src/test/java/org/apache/parquet/column/values/bitpacking/BitPackingPerfTest.java": [
                0,
                103
            ],
            "parquet-column/src/test/java/org/apache/parquet/column/values/bitpacking/TestBitPackingColumn.java": [
                0,
                208
            ],
            "parquet-column/src/test/java/org/apache/parquet/column/values/boundedint/TestBoundedColumns.java": [
                0,
                172
            ],
            "parquet-column/src/test/java/org/apache/parquet/column/values/delta/DeltaBinaryPackingValuesWriterTest.java": [
                0,
                262
            ],
            "parquet-column/src/test/java/org/apache/parquet/column/values/delta/benchmark/BenchMarkTest.java": [
                0,
                43
            ],
            "parquet-column/src/test/java/org/apache/parquet/column/values/delta/benchmark/BenchmarkIntegerOutputSize.java": [
                0,
                102
            ],
            "parquet-column/src/test/java/org/apache/parquet/column/values/delta/benchmark/BenchmarkReadingRandomIntegers.java": [
                0,
                96
            ],
            "parquet-column/src/test/java/org/apache/parquet/column/values/delta/benchmark/RandomWritingBenchmarkTest.java": [
                0,
                70
            ],
            "parquet-column/src/test/java/org/apache/parquet/column/values/delta/benchmark/SmallRangeWritingBenchmarkTest.java": [
                0,
                48
            ],
            "parquet-column/src/test/java/org/apache/parquet/column/values/deltalengthbytearray/TestDeltaLengthByteArray.java": [
                0,
                74
            ],
            "parquet-column/src/test/java/org/apache/parquet/column/values/deltalengthbytearray/benchmark/BenchmarkDeltaLengthByteArray.java": [
                0,
                71
            ],
            "parquet-column/src/test/java/org/apache/parquet/column/values/deltastrings/TestDeltaByteArray.java": [
                0,
                84
            ],
            "parquet-column/src/test/java/org/apache/parquet/column/values/deltastrings/benchmark/BenchmarkDeltaByteArray.java": [
                0,
                101
            ],
            "parquet-column/src/test/java/org/apache/parquet/column/values/dictionary/TestDictionary.java": [
                0,
                531
            ],
            "parquet-column/src/test/java/org/apache/parquet/column/values/rle/RunLengthBitPackingHybridIntegrationTest.java": [
                0,
                99
            ],
            "parquet-column/src/test/java/org/apache/parquet/column/values/rle/TestRunLengthBitPackingHybridEncoder.java": [
                0,
                322
            ],
            "parquet-column/src/test/java/org/apache/parquet/filter2/predicate/DummyUdp.java": [
                0,
                37
            ],
            "parquet-column/src/test/java/org/apache/parquet/filter2/predicate/TestFilterApiMethods.java": [
                0,
                172
            ],
            "parquet-column/src/test/java/org/apache/parquet/filter2/predicate/TestLogicalInverseRewriter.java": [
                0,
                103
            ],
            "parquet-column/src/test/java/org/apache/parquet/filter2/predicate/TestLogicalInverter.java": [
                0,
                94
            ],
            "parquet-column/src/test/java/org/apache/parquet/filter2/predicate/TestSchemaCompatibilityValidator.java": [
                0,
                142
            ],
            "parquet-column/src/test/java/org/apache/parquet/filter2/predicate/TestValidTypeMap.java": [
                0,
                111
            ],
            "parquet-column/src/test/java/org/apache/parquet/filter2/recordlevel/TestIncrementallyUpdatedFilterPredicateEvaluator.java": [
                0,
                209
            ],
            "parquet-column/src/test/java/org/apache/parquet/filter2/recordlevel/TestIncrementallyUpdatedFilterPredicateResetter.java": [
                0,
                69
            ],
            "parquet-column/src/test/java/org/apache/parquet/filter2/recordlevel/TestValueInspector.java": [
                0,
                97
            ],
            "parquet-column/src/test/java/org/apache/parquet/io/ConverterConsumer.java": [
                0,
                117
            ],
            "parquet-column/src/test/java/org/apache/parquet/io/ExpectationValidatingConverter.java": [
                0,
                169
            ],
            "parquet-column/src/test/java/org/apache/parquet/io/ExpectationValidatingRecordConsumer.java": [
                0,
                104
            ],
            "parquet-column/src/test/java/org/apache/parquet/io/PerfTest.java": [
                0,
                132
            ],
            "parquet-column/src/test/java/org/apache/parquet/io/TestColumnIO.java": [
                0,
                674
            ],
            "parquet-column/src/test/java/org/apache/parquet/io/TestFiltered.java": [
                0,
                270
            ],
            "parquet-column/src/test/java/org/apache/parquet/parser/TestParquetParser.java": [
                0,
                313
            ],
            "parquet-column/src/test/java/org/apache/parquet/schema/TestMessageType.java": [
                0,
                148
            ],
            "parquet-column/src/test/java/org/apache/parquet/schema/TestTypeBuilders.java": [
                0,
                619
            ],
            "parquet-column/src/test/java/parquet/column/impl/TestColumnReaderImpl.java": [
                123,
                0
            ],
            "parquet-column/src/test/java/parquet/column/mem/TestMemColumn.java": [
                164,
                0
            ],
            "parquet-column/src/test/java/parquet/column/mem/TestMemPageStore.java": [
                61,
                0
            ],
            "parquet-column/src/test/java/parquet/column/page/mem/MemPageReader.java": [
                69,
                0
            ],
            "parquet-column/src/test/java/parquet/column/page/mem/MemPageStore.java": [
                77,
                0
            ],
            "parquet-column/src/test/java/parquet/column/page/mem/MemPageWriter.java": [
                114,
                0
            ],
            "parquet-column/src/test/java/parquet/column/statistics/TestStatistics.java": [
                569,
                0
            ],
            "parquet-column/src/test/java/parquet/column/values/RandomStr.java": [
                56,
                0
            ],
            "parquet-column/src/test/java/parquet/column/values/Utils.java": [
                90,
                0
            ],
            "parquet-column/src/test/java/parquet/column/values/bitpacking/BitPackingPerfTest.java": [
                103,
                0
            ],
            "parquet-column/src/test/java/parquet/column/values/bitpacking/TestBitPackingColumn.java": [
                208,
                0
            ],
            "parquet-column/src/test/java/parquet/column/values/boundedint/TestBoundedColumns.java": [
                175,
                0
            ],
            "parquet-column/src/test/java/parquet/column/values/delta/DeltaBinaryPackingValuesWriterTest.java": [
                262,
                0
            ],
            "parquet-column/src/test/java/parquet/column/values/delta/benchmark/BenchMarkTest.java": [
                43,
                0
            ],
            "parquet-column/src/test/java/parquet/column/values/delta/benchmark/BenchmarkIntegerOutputSize.java": [
                102,
                0
            ],
            "parquet-column/src/test/java/parquet/column/values/delta/benchmark/BenchmarkReadingRandomIntegers.java": [
                96,
                0
            ],
            "parquet-column/src/test/java/parquet/column/values/delta/benchmark/RandomWritingBenchmarkTest.java": [
                70,
                0
            ],
            "parquet-column/src/test/java/parquet/column/values/delta/benchmark/SmallRangeWritingBenchmarkTest.java": [
                48,
                0
            ],
            "parquet-column/src/test/java/parquet/column/values/deltalengthbytearray/TestDeltaLengthByteArray.java": [
                74,
                0
            ],
            "parquet-column/src/test/java/parquet/column/values/deltalengthbytearray/benchmark/BenchmarkDeltaLengthByteArray.java": [
                71,
                0
            ],
            "parquet-column/src/test/java/parquet/column/values/deltastrings/TestDeltaByteArray.java": [
                84,
                0
            ],
            "parquet-column/src/test/java/parquet/column/values/deltastrings/benchmark/BenchmarkDeltaByteArray.java": [
                101,
                0
            ],
            "parquet-column/src/test/java/parquet/column/values/dictionary/TestDictionary.java": [
                531,
                0
            ],
            "parquet-column/src/test/java/parquet/column/values/rle/RunLengthBitPackingHybridIntegrationTest.java": [
                100,
                0
            ],
            "parquet-column/src/test/java/parquet/column/values/rle/TestRunLengthBitPackingHybridEncoder.java": [
                322,
                0
            ],
            "parquet-column/src/test/java/parquet/filter2/predicate/DummyUdp.java": [
                37,
                0
            ],
            "parquet-column/src/test/java/parquet/filter2/predicate/TestFilterApiMethods.java": [
                172,
                0
            ],
            "parquet-column/src/test/java/parquet/filter2/predicate/TestLogicalInverseRewriter.java": [
                103,
                0
            ],
            "parquet-column/src/test/java/parquet/filter2/predicate/TestLogicalInverter.java": [
                94,
                0
            ],
            "parquet-column/src/test/java/parquet/filter2/predicate/TestSchemaCompatibilityValidator.java": [
                142,
                0
            ],
            "parquet-column/src/test/java/parquet/filter2/predicate/TestValidTypeMap.java": [
                111,
                0
            ],
            "parquet-column/src/test/java/parquet/filter2/recordlevel/TestIncrementallyUpdatedFilterPredicateEvaluator.java": [
                209,
                0
            ],
            "parquet-column/src/test/java/parquet/filter2/recordlevel/TestIncrementallyUpdatedFilterPredicateResetter.java": [
                69,
                0
            ],
            "parquet-column/src/test/java/parquet/filter2/recordlevel/TestValueInspector.java": [
                97,
                0
            ],
            "parquet-column/src/test/java/parquet/io/ConverterConsumer.java": [
                117,
                0
            ],
            "parquet-column/src/test/java/parquet/io/ExpectationValidatingConverter.java": [
                169,
                0
            ],
            "parquet-column/src/test/java/parquet/io/ExpectationValidatingRecordConsumer.java": [
                105,
                0
            ],
            "parquet-column/src/test/java/parquet/io/PerfTest.java": [
                132,
                0
            ],
            "parquet-column/src/test/java/parquet/io/TestColumnIO.java": [
                674,
                0
            ],
            "parquet-column/src/test/java/parquet/io/TestFiltered.java": [
                270,
                0
            ],
            "parquet-column/src/test/java/parquet/parser/TestParquetParser.java": [
                313,
                0
            ],
            "parquet-column/src/test/java/parquet/schema/TestMessageType.java": [
                148,
                0
            ],
            "parquet-column/src/test/java/parquet/schema/TestTypeBuilders.java": [
                619,
                0
            ],
            "parquet-common/pom.xml": null,
            "parquet-common/src/main/java/org/apache/parquet/Closeables.java": [
                0,
                55
            ],
            "parquet-common/src/main/java/org/apache/parquet/Ints.java": [
                0,
                44
            ],
            "parquet-common/src/main/java/org/apache/parquet/Log.java": [
                0,
                206
            ],
            "parquet-common/src/main/java/org/apache/parquet/ParquetRuntimeException.java": [
                0,
                46
            ],
            "parquet-common/src/main/java/org/apache/parquet/Preconditions.java": [
                0,
                123
            ],
            "parquet-common/src/main/java/org/apache/parquet/Version.java": [
                0,
                103
            ],
            "parquet-common/src/main/java/org/apache/parquet/bytes/BytesUtils.java": [
                0,
                269
            ],
            "parquet-common/src/main/java/org/apache/parquet/hadoop/metadata/Canonicalizer.java": [
                0,
                62
            ],
            "parquet-common/src/main/java/org/apache/parquet/hadoop/metadata/ColumnPath.java": [
                0,
                97
            ],
            "parquet-common/src/main/java/parquet/Closeables.java": [
                55,
                0
            ],
            "parquet-common/src/main/java/parquet/Ints.java": [
                44,
                0
            ],
            "parquet-common/src/main/java/parquet/Log.java": [
                206,
                0
            ],
            "parquet-common/src/main/java/parquet/ParquetRuntimeException.java": [
                46,
                0
            ],
            "parquet-common/src/main/java/parquet/Preconditions.java": [
                123,
                0
            ],
            "parquet-common/src/main/java/parquet/Version.java": [
                103,
                0
            ],
            "parquet-common/src/main/java/parquet/bytes/BytesUtils.java": [
                269,
                0
            ],
            "parquet-common/src/main/java/parquet/hadoop/metadata/Canonicalizer.java": [
                62,
                0
            ],
            "parquet-common/src/main/java/parquet/hadoop/metadata/ColumnPath.java": [
                97,
                0
            ],
            "parquet-common/src/test/java/org/apache/parquet/TestLog.java": [
                0,
                31
            ],
            "parquet-common/src/test/java/org/apache/parquet/TestPreconditions.java": [
                0,
                58
            ],
            "parquet-common/src/test/java/org/apache/parquet/bytes/TestBytesUtil.java": [
                0,
                49
            ],
            "parquet-common/src/test/java/parquet/TestLog.java": [
                31,
                0
            ],
            "parquet-common/src/test/java/parquet/TestPreconditions.java": [
                58,
                0
            ],
            "parquet-common/src/test/java/parquet/bytes/TestBytesUtil.java": [
                49,
                0
            ],
            "parquet-encoding/pom.xml": null,
            "parquet-encoding/src/main/java/org/apache/parquet/bytes/BytesInput.java": [
                0,
                365
            ],
            "parquet-encoding/src/main/java/org/apache/parquet/bytes/CapacityByteArrayOutputStream.java": [
                0,
                276
            ],
            "parquet-encoding/src/main/java/org/apache/parquet/bytes/ConcatenatingByteArrayCollector.java": [
                0,
                63
            ],
            "parquet-encoding/src/main/java/org/apache/parquet/bytes/LittleEndianDataInputStream.java": [
                0,
                424
            ],
            "parquet-encoding/src/main/java/org/apache/parquet/bytes/LittleEndianDataOutputStream.java": [
                0,
                213
            ],
            "parquet-encoding/src/main/java/org/apache/parquet/column/values/bitpacking/BitPacking.java": [
                0,
                725
            ],
            "parquet-encoding/src/main/java/org/apache/parquet/column/values/bitpacking/ByteBasedBitPackingEncoder.java": [
                0,
                130
            ],
            "parquet-encoding/src/main/java/org/apache/parquet/column/values/bitpacking/BytePacker.java": [
                0,
                86
            ],
            "parquet-encoding/src/main/java/org/apache/parquet/column/values/bitpacking/BytePackerFactory.java": [
                0,
                25
            ],
            "parquet-encoding/src/main/java/org/apache/parquet/column/values/bitpacking/IntPacker.java": [
                0,
                66
            ],
            "parquet-encoding/src/main/java/org/apache/parquet/column/values/bitpacking/IntPackerFactory.java": [
                0,
                25
            ],
            "parquet-encoding/src/main/java/org/apache/parquet/column/values/bitpacking/Packer.java": [
                0,
                99
            ],
            "parquet-encoding/src/main/java/parquet/bytes/BytesInput.java": [
                365,
                0
            ],
            "parquet-encoding/src/main/java/parquet/bytes/CapacityByteArrayOutputStream.java": [
                276,
                0
            ],
            "parquet-encoding/src/main/java/parquet/bytes/ConcatenatingByteArrayCollector.java": [
                63,
                0
            ],
            "parquet-encoding/src/main/java/parquet/bytes/LittleEndianDataInputStream.java": [
                424,
                0
            ],
            "parquet-encoding/src/main/java/parquet/bytes/LittleEndianDataOutputStream.java": [
                213,
                0
            ],
            "parquet-encoding/src/main/java/parquet/column/values/bitpacking/BitPacking.java": [
                725,
                0
            ],
            "parquet-encoding/src/main/java/parquet/column/values/bitpacking/ByteBasedBitPackingEncoder.java": [
                130,
                0
            ],
            "parquet-encoding/src/main/java/parquet/column/values/bitpacking/BytePacker.java": [
                86,
                0
            ],
            "parquet-encoding/src/main/java/parquet/column/values/bitpacking/BytePackerFactory.java": [
                25,
                0
            ],
            "parquet-encoding/src/main/java/parquet/column/values/bitpacking/IntPacker.java": [
                66,
                0
            ],
            "parquet-encoding/src/main/java/parquet/column/values/bitpacking/IntPackerFactory.java": [
                25,
                0
            ],
            "parquet-encoding/src/main/java/parquet/column/values/bitpacking/Packer.java": [
                99,
                0
            ],
            "parquet-encoding/src/test/java/org/apache/parquet/bytes/TestCapacityByteArrayOutputStream.java": [
                0,
                242
            ],
            "parquet-encoding/src/test/java/org/apache/parquet/column/values/bitpacking/TestBitPacking.java": [
                0,
                218
            ],
            "parquet-encoding/src/test/java/org/apache/parquet/column/values/bitpacking/TestByteBasedBitPackingEncoder.java": [
                0,
                40
            ],
            "parquet-encoding/src/test/java/org/apache/parquet/column/values/bitpacking/TestByteBitPacking.java": [
                0,
                150
            ],
            "parquet-encoding/src/test/java/org/apache/parquet/column/values/bitpacking/TestLemireBitPacking.java": [
                0,
                123
            ],
            "parquet-encoding/src/test/java/parquet/bytes/TestCapacityByteArrayOutputStream.java": [
                242,
                0
            ],
            "parquet-encoding/src/test/java/parquet/column/values/bitpacking/TestBitPacking.java": [
                218,
                0
            ],
            "parquet-encoding/src/test/java/parquet/column/values/bitpacking/TestByteBasedBitPackingEncoder.java": [
                40,
                0
            ],
            "parquet-encoding/src/test/java/parquet/column/values/bitpacking/TestByteBitPacking.java": [
                151,
                0
            ],
            "parquet-encoding/src/test/java/parquet/column/values/bitpacking/TestLemireBitPacking.java": [
                123,
                0
            ],
            "parquet-generator/pom.xml": null,
            "parquet-generator/src/main/java/org/apache/parquet/encoding/Generator.java": [
                0,
                37
            ],
            "parquet-generator/src/main/java/org/apache/parquet/encoding/bitpacking/ByteBasedBitPackingGenerator.java": [
                0,
                259
            ],
            "parquet-generator/src/main/java/org/apache/parquet/encoding/bitpacking/IntBasedBitPackingGenerator.java": [
                0,
                211
            ],
            "parquet-generator/src/main/java/org/apache/parquet/filter2/Generator.java": [
                0,
                28
            ],
            "parquet-generator/src/main/java/org/apache/parquet/filter2/IncrementallyUpdatedFilterPredicateGenerator.java": [
                0,
                269
            ],
            "parquet-generator/src/main/java/parquet/encoding/Generator.java": [
                37,
                0
            ],
            "parquet-generator/src/main/java/parquet/encoding/bitpacking/ByteBasedBitPackingGenerator.java": [
                259,
                0
            ],
            "parquet-generator/src/main/java/parquet/encoding/bitpacking/IntBasedBitPackingGenerator.java": [
                211,
                0
            ],
            "parquet-generator/src/main/java/parquet/filter2/Generator.java": [
                28,
                0
            ],
            "parquet-generator/src/main/java/parquet/filter2/IncrementallyUpdatedFilterPredicateGenerator.java": [
                269,
                0
            ],
            "parquet-hadoop-bundle/pom.xml": null,
            "parquet-hadoop-bundle/src/main/resources/parquet/bundle": null,
            "parquet-hadoop/pom.xml": null,
            "parquet-hadoop/src/main/java/org/apache/parquet/filter2/compat/RowGroupFilter.java": [
                0,
                81
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/filter2/statisticslevel/StatisticsFilter.java": [
                0,
                305
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/format/converter/ParquetMetadataConverter.java": [
                0,
                735
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/BadConfigurationException.java": [
                0,
                47
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/CodecFactory.java": [
                0,
                195
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ColumnChunkPageReadStore.java": [
                0,
                170
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ColumnChunkPageWriteStore.java": [
                0,
                242
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/Footer.java": [
                0,
                57
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/InternalParquetRecordReader.java": [
                0,
                244
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/InternalParquetRecordWriter.java": [
                0,
                175
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/LruCache.java": [
                0,
                199
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/MemoryManager.java": [
                0,
                158
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ParquetFileReader.java": [
                0,
                782
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ParquetFileWriter.java": [
                0,
                553
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ParquetInputFormat.java": [
                0,
                778
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ParquetInputSplit.java": [
                0,
                294
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ParquetOutputCommitter.java": [
                0,
                72
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ParquetOutputFormat.java": [
                0,
                353
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ParquetReader.java": [
                0,
                195
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ParquetRecordReader.java": [
                0,
                217
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ParquetRecordWriter.java": [
                0,
                126
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ParquetWriter.java": [
                0,
                272
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/PrintFooter.java": [
                0,
                271
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/api/DelegatingReadSupport.java": [
                0,
                62
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/api/DelegatingWriteSupport.java": [
                0,
                66
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/api/InitContext.java": [
                0,
                102
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/api/ReadSupport.java": [
                0,
                150
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/api/WriteSupport.java": [
                0,
                131
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/api/package-info.java": [
                0,
                27
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/codec/CodecConfig.java": [
                0,
                169
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/codec/CompressionCodecNotSupportedException.java": [
                0,
                36
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/codec/NonBlockedCompressorStream.java": [
                0,
                50
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/codec/NonBlockedDecompressorStream.java": [
                0,
                57
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/codec/SnappyCodec.java": [
                0,
                105
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/codec/SnappyCompressor.java": [
                0,
                161
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/codec/SnappyDecompressor.java": [
                0,
                150
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/codec/SnappyUtil.java": [
                0,
                33
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/example/ExampleInputFormat.java": [
                0,
                38
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/example/ExampleOutputFormat.java": [
                0,
                62
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/example/GroupReadSupport.java": [
                0,
                49
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/example/GroupWriteSupport.java": [
                0,
                67
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/mapred/Container.java": [
                0,
                37
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/mapred/DeprecatedParquetInputFormat.java": [
                0,
                208
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/mapred/DeprecatedParquetOutputFormat.java": [
                0,
                119
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/mapred/MapredParquetOutputCommitter.java": [
                0,
                45
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/metadata/BlockMetaData.java": [
                0,
                123
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/metadata/ColumnChunkMetaData.java": [
                0,
                389
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/metadata/ColumnChunkProperties.java": [
                0,
                89
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/metadata/CompressionCodecName.java": [
                0,
                93
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/metadata/EncodingList.java": [
                0,
                81
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/metadata/FileMetaData.java": [
                0,
                83
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/metadata/GlobalMetaData.java": [
                0,
                106
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/metadata/ParquetMetadata.java": [
                0,
                132
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/package-info.java": [
                0,
                35
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/util/ConfigurationUtil.java": [
                0,
                44
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/util/ContextUtil.java": [
                0,
                275
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/util/HiddenFileFilter.java": [
                0,
                33
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/util/SerializationUtil.java": [
                0,
                111
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/util/counters/BenchmarkCounter.java": [
                0,
                114
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/util/counters/CounterLoader.java": [
                0,
                28
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/util/counters/ICounter.java": [
                0,
                29
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/util/counters/mapred/MapRedCounterAdapter.java": [
                0,
                44
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/util/counters/mapred/MapRedCounterLoader.java": [
                0,
                52
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/util/counters/mapreduce/MapReduceCounterAdapter.java": [
                0,
                45
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/util/counters/mapreduce/MapReduceCounterLoader.java": [
                0,
                47
            ],
            "parquet-hadoop/src/main/java/parquet/filter2/compat/RowGroupFilter.java": [
                81,
                0
            ],
            "parquet-hadoop/src/main/java/parquet/filter2/statisticslevel/StatisticsFilter.java": [
                305,
                0
            ],
            "parquet-hadoop/src/main/java/parquet/format/converter/ParquetMetadataConverter.java": [
                735,
                0
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/BadConfigurationException.java": [
                47,
                0
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/CodecFactory.java": [
                195,
                0
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/ColumnChunkPageReadStore.java": [
                170,
                0
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/ColumnChunkPageWriteStore.java": [
                242,
                0
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/Footer.java": [
                57,
                0
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/InternalParquetRecordReader.java": [
                244,
                0
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/InternalParquetRecordWriter.java": [
                175,
                0
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/LruCache.java": [
                199,
                0
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/MemoryManager.java": [
                158,
                0
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/ParquetFileReader.java": [
                782,
                0
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/ParquetFileWriter.java": [
                553,
                0
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/ParquetInputFormat.java": [
                778,
                0
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/ParquetInputSplit.java": [
                294,
                0
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/ParquetOutputCommitter.java": [
                72,
                0
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/ParquetOutputFormat.java": [
                353,
                0
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/ParquetReader.java": [
                195,
                0
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/ParquetRecordReader.java": [
                217,
                0
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/ParquetRecordWriter.java": [
                126,
                0
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/ParquetWriter.java": [
                272,
                0
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/PrintFooter.java": [
                271,
                0
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/api/DelegatingReadSupport.java": [
                62,
                0
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/api/DelegatingWriteSupport.java": [
                66,
                0
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/api/InitContext.java": [
                102,
                0
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/api/ReadSupport.java": [
                150,
                0
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/api/WriteSupport.java": [
                131,
                0
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/api/package-info.java": [
                27,
                0
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/codec/CodecConfig.java": [
                169,
                0
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/codec/CompressionCodecNotSupportedException.java": [
                36,
                0
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/codec/NonBlockedCompressorStream.java": [
                50,
                0
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/codec/NonBlockedDecompressorStream.java": [
                57,
                0
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/codec/SnappyCodec.java": [
                105,
                0
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/codec/SnappyCompressor.java": [
                161,
                0
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/codec/SnappyDecompressor.java": [
                150,
                0
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/codec/SnappyUtil.java": [
                33,
                0
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/example/ExampleInputFormat.java": [
                38,
                0
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/example/ExampleOutputFormat.java": [
                62,
                0
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/example/GroupReadSupport.java": [
                49,
                0
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/example/GroupWriteSupport.java": [
                67,
                0
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/mapred/Container.java": [
                37,
                0
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/mapred/DeprecatedParquetInputFormat.java": [
                208,
                0
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/mapred/DeprecatedParquetOutputFormat.java": [
                119,
                0
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/mapred/MapredParquetOutputCommitter.java": [
                45,
                0
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/metadata/BlockMetaData.java": [
                123,
                0
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/metadata/ColumnChunkMetaData.java": [
                389,
                0
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/metadata/ColumnChunkProperties.java": [
                89,
                0
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/metadata/CompressionCodecName.java": [
                93,
                0
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/metadata/EncodingList.java": [
                81,
                0
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/metadata/FileMetaData.java": [
                83,
                0
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/metadata/GlobalMetaData.java": [
                106,
                0
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/metadata/ParquetMetadata.java": [
                132,
                0
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/package-info.java": [
                35,
                0
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/util/ConfigurationUtil.java": [
                44,
                0
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/util/ContextUtil.java": [
                275,
                0
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/util/HiddenFileFilter.java": [
                33,
                0
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/util/SerializationUtil.java": [
                111,
                0
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/util/counters/BenchmarkCounter.java": [
                114,
                0
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/util/counters/CounterLoader.java": [
                28,
                0
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/util/counters/ICounter.java": [
                29,
                0
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/util/counters/mapred/MapRedCounterAdapter.java": [
                44,
                0
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/util/counters/mapred/MapRedCounterLoader.java": [
                52,
                0
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/util/counters/mapreduce/MapReduceCounterAdapter.java": [
                45,
                0
            ],
            "parquet-hadoop/src/main/java/parquet/hadoop/util/counters/mapreduce/MapReduceCounterLoader.java": [
                47,
                0
            ],
            "parquet-hadoop/src/test/java/org/apache/parquet/filter2/compat/TestRowGroupFilter.java": [
                0,
                102
            ],
            "parquet-hadoop/src/test/java/org/apache/parquet/filter2/recordlevel/PhoneBookWriter.java": [
                0,
                269
            ],
            "parquet-hadoop/src/test/java/org/apache/parquet/filter2/recordlevel/TestRecordLevelFilters.java": [
                0,
                276
            ],
            "parquet-hadoop/src/test/java/org/apache/parquet/filter2/statisticslevel/TestStatisticsFilter.java": [
                0,
                325
            ],
            "parquet-hadoop/src/test/java/org/apache/parquet/format/converter/TestParquetMetadataConverter.java": [
                0,
                255
            ],
            "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/DeprecatedInputFormatTest.java": [
                0,
                182
            ],
            "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/DeprecatedOutputFormatTest.java": [
                0,
                109
            ],
            "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/TestColumnChunkPageWriteStore.java": [
                0,
                180
            ],
            "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/TestInputFormat.java": [
                0,
                498
            ],
            "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/TestLruCache.java": [
                0,
                162
            ],
            "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/TestMemoryManager.java": [
                0,
                106
            ],
            "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/TestParquetFileWriter.java": [
                0,
                499
            ],
            "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/TestParquetWriter.java": [
                0,
                129
            ],
            "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/TestParquetWriterNewPage.java": [
                0,
                135
            ],
            "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/TestSnappyCodec.java": [
                0,
                140
            ],
            "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/TestUtils.java": [
                0,
                40
            ],
            "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/codec/CodecConfigTest.java": [
                0,
                77
            ],
            "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/example/GroupReadSupportTest.java": [
                0,
                65
            ],
            "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/example/TestInputOutputFormat.java": [
                0,
                291
            ],
            "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/metadata/TestColumnChunkMetaData.java": [
                0,
                83
            ],
            "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/util/TestSerializationUtil.java": [
                0,
                71
            ],
            "parquet-hadoop/src/test/java/parquet/filter2/compat/TestRowGroupFilter.java": [
                102,
                0
            ],
            "parquet-hadoop/src/test/java/parquet/filter2/recordlevel/PhoneBookWriter.java": [
                269,
                0
            ],
            "parquet-hadoop/src/test/java/parquet/filter2/recordlevel/TestRecordLevelFilters.java": [
                277,
                0
            ],
            "parquet-hadoop/src/test/java/parquet/filter2/statisticslevel/TestStatisticsFilter.java": [
                325,
                0
            ],
            "parquet-hadoop/src/test/java/parquet/format/converter/TestParquetMetadataConverter.java": [
                255,
                0
            ],
            "parquet-hadoop/src/test/java/parquet/hadoop/DeprecatedInputFormatTest.java": [
                182,
                0
            ],
            "parquet-hadoop/src/test/java/parquet/hadoop/DeprecatedOutputFormatTest.java": [
                109,
                0
            ],
            "parquet-hadoop/src/test/java/parquet/hadoop/TestColumnChunkPageWriteStore.java": [
                180,
                0
            ],
            "parquet-hadoop/src/test/java/parquet/hadoop/TestInputFormat.java": [
                498,
                0
            ],
            "parquet-hadoop/src/test/java/parquet/hadoop/TestLruCache.java": [
                162,
                0
            ],
            "parquet-hadoop/src/test/java/parquet/hadoop/TestMemoryManager.java": [
                106,
                0
            ],
            "parquet-hadoop/src/test/java/parquet/hadoop/TestParquetFileWriter.java": [
                499,
                0
            ],
            "parquet-hadoop/src/test/java/parquet/hadoop/TestParquetWriter.java": [
                129,
                0
            ],
            "parquet-hadoop/src/test/java/parquet/hadoop/TestParquetWriterNewPage.java": [
                135,
                0
            ],
            "parquet-hadoop/src/test/java/parquet/hadoop/TestSnappyCodec.java": [
                140,
                0
            ],
            "parquet-hadoop/src/test/java/parquet/hadoop/TestUtils.java": [
                40,
                0
            ],
            "parquet-hadoop/src/test/java/parquet/hadoop/codec/CodecConfigTest.java": [
                77,
                0
            ],
            "parquet-hadoop/src/test/java/parquet/hadoop/example/GroupReadSupportTest.java": [
                65,
                0
            ],
            "parquet-hadoop/src/test/java/parquet/hadoop/example/TestInputOutputFormat.java": [
                291,
                0
            ],
            "parquet-hadoop/src/test/java/parquet/hadoop/metadata/TestColumnChunkMetaData.java": [
                83,
                0
            ],
            "parquet-hadoop/src/test/java/parquet/hadoop/util/TestSerializationUtil.java": [
                71,
                0
            ],
            "parquet-hive-bundle/pom.xml": null,
            "parquet-hive-bundle/src/main/resources/parquet/bundle": null,
            "parquet-hive/parquet-hive-binding/parquet-hive-0.10-binding/pom.xml": null,
            "parquet-hive/parquet-hive-binding/parquet-hive-0.10-binding/src/main/java/org/apache/parquet/hive/internal/Hive010Binding.java": [
                0,
                166
            ],
            "parquet-hive/parquet-hive-binding/parquet-hive-0.10-binding/src/main/java/parquet/hive/internal/Hive010Binding.java": [
                166,
                0
            ],
            "parquet-hive/parquet-hive-binding/parquet-hive-0.12-binding/pom.xml": null,
            "parquet-hive/parquet-hive-binding/parquet-hive-0.12-binding/src/main/java/org/apache/parquet/hive/internal/Hive012Binding.java": [
                0,
                167
            ],
            "parquet-hive/parquet-hive-binding/parquet-hive-0.12-binding/src/main/java/parquet/hive/internal/Hive012Binding.java": [
                167,
                0
            ],
            "parquet-hive/parquet-hive-binding/parquet-hive-binding-bundle/pom.xml": null,
            "parquet-hive/parquet-hive-binding/parquet-hive-binding-bundle/src/main/resources/parquet/bundle": null,
            "parquet-hive/parquet-hive-binding/parquet-hive-binding-factory/pom.xml": null,
            "parquet-hive/parquet-hive-binding/parquet-hive-binding-factory/src/main/java/org/apache/parquet/hive/HiveBindingFactory.java": [
                0,
                159
            ],
            "parquet-hive/parquet-hive-binding/parquet-hive-binding-factory/src/main/java/parquet/hive/HiveBindingFactory.java": [
                159,
                0
            ],
            "parquet-hive/parquet-hive-binding/parquet-hive-binding-factory/src/test/java/org/apache/parquet/hive/TestHiveBindingFactory.java": [
                0,
                139
            ],
            "parquet-hive/parquet-hive-binding/parquet-hive-binding-factory/src/test/java/parquet/hive/TestHiveBindingFactory.java": [
                139,
                0
            ],
            "parquet-hive/parquet-hive-binding/parquet-hive-binding-interface/pom.xml": null,
            "parquet-hive/parquet-hive-binding/parquet-hive-binding-interface/src/main/java/org/apache/parquet/hive/HiveBinding.java": [
                0,
                57
            ],
            "parquet-hive/parquet-hive-binding/parquet-hive-binding-interface/src/main/java/org/apache/parquet/hive/internal/AbstractHiveBinding.java": [
                0,
                54
            ],
            "parquet-hive/parquet-hive-binding/parquet-hive-binding-interface/src/main/java/parquet/hive/HiveBinding.java": [
                57,
                0
            ],
            "parquet-hive/parquet-hive-binding/parquet-hive-binding-interface/src/main/java/parquet/hive/internal/AbstractHiveBinding.java": [
                54,
                0
            ],
            "parquet-hive/parquet-hive-binding/pom.xml": null,
            "parquet-hive/parquet-hive-storage-handler/pom.xml": null,
            "parquet-hive/parquet-hive-storage-handler/src/main/java/org/apache/hadoop/hive/ql/io/parquet/MapredParquetInputFormat.java": [
                1,
                1
            ],
            "parquet-hive/parquet-hive-storage-handler/src/main/java/org/apache/hadoop/hive/ql/io/parquet/MapredParquetOutputFormat.java": [
                1,
                1
            ],
            "parquet-hive/parquet-hive-storage-handler/src/main/java/org/apache/hadoop/hive/ql/io/parquet/convert/ArrayWritableGroupConverter.java": [
                3,
                3
            ],
            "parquet-hive/parquet-hive-storage-handler/src/main/java/org/apache/hadoop/hive/ql/io/parquet/convert/DataWritableGroupConverter.java": [
                3,
                3
            ],
            "parquet-hive/parquet-hive-storage-handler/src/main/java/org/apache/hadoop/hive/ql/io/parquet/convert/DataWritableRecordConverter.java": [
                3,
                3
            ],
            "parquet-hive/parquet-hive-storage-handler/src/main/java/org/apache/hadoop/hive/ql/io/parquet/convert/ETypeConverter.java": [
                4,
                4
            ],
            "parquet-hive/parquet-hive-storage-handler/src/main/java/org/apache/hadoop/hive/ql/io/parquet/convert/HiveGroupConverter.java": [
                4,
                4
            ],
            "parquet-hive/parquet-hive-storage-handler/src/main/java/org/apache/hadoop/hive/ql/io/parquet/convert/HiveSchemaConverter.java": [
                8,
                8
            ],
            "parquet-hive/parquet-hive-storage-handler/src/main/java/org/apache/hadoop/hive/ql/io/parquet/read/DataWritableReadSupport.java": [
                11,
                11
            ],
            "parquet-hive/parquet-hive-storage-handler/src/main/java/org/apache/hadoop/hive/ql/io/parquet/read/ParquetRecordReaderWrapper.java": [
                11,
                11
            ],
            "parquet-hive/parquet-hive-storage-handler/src/main/java/org/apache/hadoop/hive/ql/io/parquet/serde/ParquetHiveSerDe.java": [
                1,
                1
            ],
            "parquet-hive/parquet-hive-storage-handler/src/main/java/org/apache/hadoop/hive/ql/io/parquet/writable/BinaryWritable.java": [
                1,
                1
            ],
            "parquet-hive/parquet-hive-storage-handler/src/main/java/org/apache/hadoop/hive/ql/io/parquet/write/DataWritableWriteSupport.java": [
                4,
                4
            ],
            "parquet-hive/parquet-hive-storage-handler/src/main/java/org/apache/hadoop/hive/ql/io/parquet/write/DataWritableWriter.java": [
                4,
                4
            ],
            "parquet-hive/parquet-hive-storage-handler/src/main/java/org/apache/hadoop/hive/ql/io/parquet/write/ParquetRecordWriterWrapper.java": [
                2,
                2
            ],
            "parquet-hive/parquet-hive-storage-handler/src/main/java/org/apache/hadoop/hive/serde2/objectinspector/primitive/ParquetStringInspector.java": [
                1,
                1
            ],
            "parquet-hive/parquet-hive-storage-handler/src/main/java/org/apache/parquet/hive/DeprecatedParquetInputFormat.java": [
                0,
                42
            ],
            "parquet-hive/parquet-hive-storage-handler/src/main/java/org/apache/parquet/hive/DeprecatedParquetOutputFormat.java": [
                0,
                41
            ],
            "parquet-hive/parquet-hive-storage-handler/src/main/java/org/apache/parquet/hive/MapredParquetInputFormat.java": [
                0,
                41
            ],
            "parquet-hive/parquet-hive-storage-handler/src/main/java/org/apache/parquet/hive/MapredParquetOutputFormat.java": [
                0,
                40
            ],
            "parquet-hive/parquet-hive-storage-handler/src/main/java/org/apache/parquet/hive/serde/ParquetHiveSerDe.java": [
                0,
                30
            ],
            "parquet-hive/parquet-hive-storage-handler/src/main/java/parquet/hive/DeprecatedParquetInputFormat.java": [
                42,
                0
            ],
            "parquet-hive/parquet-hive-storage-handler/src/main/java/parquet/hive/DeprecatedParquetOutputFormat.java": [
                41,
                0
            ],
            "parquet-hive/parquet-hive-storage-handler/src/main/java/parquet/hive/MapredParquetInputFormat.java": [
                41,
                0
            ],
            "parquet-hive/parquet-hive-storage-handler/src/main/java/parquet/hive/MapredParquetOutputFormat.java": [
                40,
                0
            ],
            "parquet-hive/parquet-hive-storage-handler/src/main/java/parquet/hive/serde/ParquetHiveSerDe.java": [
                30,
                0
            ],
            "parquet-hive/parquet-hive-storage-handler/src/test/java/org/apache/hadoop/hive/ql/io/parquet/TestHiveSchemaConverter.java": [
                6,
                6
            ],
            "parquet-hive/parquet-hive-storage-handler/src/test/java/org/apache/hadoop/hive/ql/io/parquet/TestMapredParquetInputFormat.java": [
                1,
                1
            ],
            "parquet-hive/parquet-hive-storage-handler/src/test/java/org/apache/hadoop/hive/ql/io/parquet/TestMapredParquetOutputFormat.java": [
                1,
                1
            ],
            "parquet-hive/parquet-hive-storage-handler/src/test/java/org/apache/hadoop/hive/ql/io/parquet/TestParquetSerDe.java": [
                1,
                1
            ],
            "parquet-hive/pom.xml": null,
            "parquet-jackson/pom.xml": null,
            "parquet-pig-bundle/pom.xml": null,
            "parquet-pig-bundle/src/main/resources/parquet/bundle": null,
            "parquet-pig/pom.xml": null,
            "parquet-pig/src/main/java/org/apache/parquet/pig/ParquetLoader.java": [
                0,
                383
            ],
            "parquet-pig/src/main/java/org/apache/parquet/pig/ParquetStorer.java": [
                0,
                155
            ],
            "parquet-pig/src/main/java/org/apache/parquet/pig/PigMetaData.java": [
                0,
                94
            ],
            "parquet-pig/src/main/java/org/apache/parquet/pig/PigSchemaConverter.java": [
                0,
                514
            ],
            "parquet-pig/src/main/java/org/apache/parquet/pig/SchemaConversionException.java": [
                0,
                47
            ],
            "parquet-pig/src/main/java/org/apache/parquet/pig/TupleConversionException.java": [
                0,
                42
            ],
            "parquet-pig/src/main/java/org/apache/parquet/pig/TupleReadSupport.java": [
                0,
                193
            ],
            "parquet-pig/src/main/java/org/apache/parquet/pig/TupleWriteSupport.java": [
                0,
                206
            ],
            "parquet-pig/src/main/java/org/apache/parquet/pig/convert/MapConverter.java": [
                0,
                201
            ],
            "parquet-pig/src/main/java/org/apache/parquet/pig/convert/ParentValueContainer.java": [
                0,
                35
            ],
            "parquet-pig/src/main/java/org/apache/parquet/pig/convert/TupleConverter.java": [
                0,
                594
            ],
            "parquet-pig/src/main/java/org/apache/parquet/pig/convert/TupleRecordMaterializer.java": [
                0,
                50
            ],
            "parquet-pig/src/main/java/org/apache/parquet/pig/summary/BagSummaryData.java": [
                0,
                80
            ],
            "parquet-pig/src/main/java/org/apache/parquet/pig/summary/EnumStat.java": [
                0,
                115
            ],
            "parquet-pig/src/main/java/org/apache/parquet/pig/summary/FieldSummaryData.java": [
                0,
                184
            ],
            "parquet-pig/src/main/java/org/apache/parquet/pig/summary/MapSummaryData.java": [
                0,
                92
            ],
            "parquet-pig/src/main/java/org/apache/parquet/pig/summary/NumberSummaryData.java": [
                0,
                50
            ],
            "parquet-pig/src/main/java/org/apache/parquet/pig/summary/StringSummaryData.java": [
                0,
                85
            ],
            "parquet-pig/src/main/java/org/apache/parquet/pig/summary/Summary.java": [
                0,
                283
            ],
            "parquet-pig/src/main/java/org/apache/parquet/pig/summary/SummaryData.java": [
                0,
                159
            ],
            "parquet-pig/src/main/java/org/apache/parquet/pig/summary/TupleSummaryData.java": [
                0,
                106
            ],
            "parquet-pig/src/main/java/org/apache/parquet/pig/summary/ValueStat.java": [
                0,
                64
            ],
            "parquet-pig/src/main/java/parquet/pig/ParquetLoader.java": [
                383,
                0
            ],
            "parquet-pig/src/main/java/parquet/pig/ParquetStorer.java": [
                155,
                0
            ],
            "parquet-pig/src/main/java/parquet/pig/PigMetaData.java": [
                94,
                0
            ],
            "parquet-pig/src/main/java/parquet/pig/PigSchemaConverter.java": [
                514,
                0
            ],
            "parquet-pig/src/main/java/parquet/pig/SchemaConversionException.java": [
                47,
                0
            ],
            "parquet-pig/src/main/java/parquet/pig/TupleConversionException.java": [
                42,
                0
            ],
            "parquet-pig/src/main/java/parquet/pig/TupleReadSupport.java": [
                193,
                0
            ],
            "parquet-pig/src/main/java/parquet/pig/TupleWriteSupport.java": [
                206,
                0
            ],
            "parquet-pig/src/main/java/parquet/pig/convert/MapConverter.java": [
                201,
                0
            ],
            "parquet-pig/src/main/java/parquet/pig/convert/ParentValueContainer.java": [
                35,
                0
            ],
            "parquet-pig/src/main/java/parquet/pig/convert/TupleConverter.java": [
                594,
                0
            ],
            "parquet-pig/src/main/java/parquet/pig/convert/TupleRecordMaterializer.java": [
                50,
                0
            ],
            "parquet-pig/src/main/java/parquet/pig/summary/BagSummaryData.java": [
                80,
                0
            ],
            "parquet-pig/src/main/java/parquet/pig/summary/EnumStat.java": [
                115,
                0
            ],
            "parquet-pig/src/main/java/parquet/pig/summary/FieldSummaryData.java": [
                184,
                0
            ],
            "parquet-pig/src/main/java/parquet/pig/summary/MapSummaryData.java": [
                92,
                0
            ],
            "parquet-pig/src/main/java/parquet/pig/summary/NumberSummaryData.java": [
                50,
                0
            ],
            "parquet-pig/src/main/java/parquet/pig/summary/StringSummaryData.java": [
                85,
                0
            ],
            "parquet-pig/src/main/java/parquet/pig/summary/Summary.java": [
                283,
                0
            ],
            "parquet-pig/src/main/java/parquet/pig/summary/SummaryData.java": [
                159,
                0
            ],
            "parquet-pig/src/main/java/parquet/pig/summary/TupleSummaryData.java": [
                106,
                0
            ],
            "parquet-pig/src/main/java/parquet/pig/summary/ValueStat.java": [
                64,
                0
            ],
            "parquet-pig/src/test/java/org/apache/parquet/pig/PerfTest.java": [
                0,
                108
            ],
            "parquet-pig/src/test/java/org/apache/parquet/pig/PerfTest2.java": [
                0,
                185
            ],
            "parquet-pig/src/test/java/org/apache/parquet/pig/PerfTestReadAllCols.java": [
                0,
                51
            ],
            "parquet-pig/src/test/java/org/apache/parquet/pig/TestParquetLoader.java": [
                0,
                334
            ],
            "parquet-pig/src/test/java/org/apache/parquet/pig/TestParquetStorer.java": [
                0,
                264
            ],
            "parquet-pig/src/test/java/org/apache/parquet/pig/TestPigSchemaConverter.java": [
                0,
                228
            ],
            "parquet-pig/src/test/java/org/apache/parquet/pig/TestTupleRecordConsumer.java": [
                0,
                209
            ],
            "parquet-pig/src/test/java/org/apache/parquet/pig/TupleConsumerPerfTest.java": [
                0,
                209
            ],
            "parquet-pig/src/test/java/org/apache/parquet/pig/summary/TestSummary.java": [
                0,
                160
            ],
            "parquet-pig/src/test/java/parquet/pig/PerfTest.java": [
                111,
                0
            ],
            "parquet-pig/src/test/java/parquet/pig/PerfTest2.java": [
                187,
                0
            ],
            "parquet-pig/src/test/java/parquet/pig/PerfTestReadAllCols.java": [
                51,
                0
            ],
            "parquet-pig/src/test/java/parquet/pig/TestParquetLoader.java": [
                334,
                0
            ],
            "parquet-pig/src/test/java/parquet/pig/TestParquetStorer.java": [
                267,
                0
            ],
            "parquet-pig/src/test/java/parquet/pig/TestPigSchemaConverter.java": [
                231,
                0
            ],
            "parquet-pig/src/test/java/parquet/pig/TestTupleRecordConsumer.java": [
                209,
                0
            ],
            "parquet-pig/src/test/java/parquet/pig/TupleConsumerPerfTest.java": [
                209,
                0
            ],
            "parquet-pig/src/test/java/parquet/pig/summary/TestSummary.java": [
                160,
                0
            ],
            "parquet-protobuf/pom.xml": null,
            "parquet-protobuf/src/main/java/org/apache/parquet/proto/ProtoMessageConverter.java": [
                0,
                348
            ],
            "parquet-protobuf/src/main/java/org/apache/parquet/proto/ProtoParquetInputFormat.java": [
                0,
                38
            ],
            "parquet-protobuf/src/main/java/org/apache/parquet/proto/ProtoParquetOutputFormat.java": [
                0,
                57
            ],
            "parquet-protobuf/src/main/java/org/apache/parquet/proto/ProtoParquetReader.java": [
                0,
                57
            ],
            "parquet-protobuf/src/main/java/org/apache/parquet/proto/ProtoParquetWriter.java": [
                0,
                81
            ],
            "parquet-protobuf/src/main/java/org/apache/parquet/proto/ProtoReadSupport.java": [
                0,
                80
            ],
            "parquet-protobuf/src/main/java/org/apache/parquet/proto/ProtoRecordConverter.java": [
                0,
                84
            ],
            "parquet-protobuf/src/main/java/org/apache/parquet/proto/ProtoRecordMaterializer.java": [
                0,
                44
            ],
            "parquet-protobuf/src/main/java/org/apache/parquet/proto/ProtoSchemaConverter.java": [
                0,
                107
            ],
            "parquet-protobuf/src/main/java/org/apache/parquet/proto/ProtoWriteSupport.java": [
                0,
                339
            ],
            "parquet-protobuf/src/main/java/parquet/proto/ProtoMessageConverter.java": [
                348,
                0
            ],
            "parquet-protobuf/src/main/java/parquet/proto/ProtoParquetInputFormat.java": [
                38,
                0
            ],
            "parquet-protobuf/src/main/java/parquet/proto/ProtoParquetOutputFormat.java": [
                57,
                0
            ],
            "parquet-protobuf/src/main/java/parquet/proto/ProtoParquetReader.java": [
                57,
                0
            ],
            "parquet-protobuf/src/main/java/parquet/proto/ProtoParquetWriter.java": [
                81,
                0
            ],
            "parquet-protobuf/src/main/java/parquet/proto/ProtoReadSupport.java": [
                80,
                0
            ],
            "parquet-protobuf/src/main/java/parquet/proto/ProtoRecordConverter.java": [
                84,
                0
            ],
            "parquet-protobuf/src/main/java/parquet/proto/ProtoRecordMaterializer.java": [
                44,
                0
            ],
            "parquet-protobuf/src/main/java/parquet/proto/ProtoSchemaConverter.java": [
                107,
                0
            ],
            "parquet-protobuf/src/main/java/parquet/proto/ProtoWriteSupport.java": [
                339,
                0
            ],
            "parquet-protobuf/src/test/java/org/apache/parquet/proto/ProtoInputOutputFormatTest.java": [
                0,
                106
            ],
            "parquet-protobuf/src/test/java/org/apache/parquet/proto/ProtoRecordConverterTest.java": [
                0,
                224
            ],
            "parquet-protobuf/src/test/java/org/apache/parquet/proto/ProtoSchemaConverterTest.java": [
                0,
                97
            ],
            "parquet-protobuf/src/test/java/org/apache/parquet/proto/ProtoWriteSupportTest.java": [
                0,
                168
            ],
            "parquet-protobuf/src/test/java/org/apache/parquet/proto/TestUtils.java": [
                0,
                188
            ],
            "parquet-protobuf/src/test/java/org/apache/parquet/proto/utils/ReadUsingMR.java": [
                0,
                87
            ],
            "parquet-protobuf/src/test/java/org/apache/parquet/proto/utils/WriteUsingMR.java": [
                0,
                113
            ],
            "parquet-protobuf/src/test/java/parquet/proto/ProtoInputOutputFormatTest.java": [
                106,
                0
            ],
            "parquet-protobuf/src/test/java/parquet/proto/ProtoRecordConverterTest.java": [
                224,
                0
            ],
            "parquet-protobuf/src/test/java/parquet/proto/ProtoSchemaConverterTest.java": [
                97,
                0
            ],
            "parquet-protobuf/src/test/java/parquet/proto/ProtoWriteSupportTest.java": [
                168,
                0
            ],
            "parquet-protobuf/src/test/java/parquet/proto/TestUtils.java": [
                188,
                0
            ],
            "parquet-protobuf/src/test/java/parquet/proto/utils/ReadUsingMR.java": [
                87,
                0
            ],
            "parquet-protobuf/src/test/java/parquet/proto/utils/WriteUsingMR.java": [
                113,
                0
            ],
            "parquet-protobuf/src/test/resources/TestProtobuf.proto": null,
            "parquet-scala/pom.xml": null,
            "parquet-scala/src/main/scala/org/apache/parquet/filter2/dsl/Dsl.scala": null,
            "parquet-scala/src/main/scala/parquet/filter2/dsl/Dsl.scala": null,
            "parquet-scala/src/test/scala/org/apache/parquet/filter2/dsl/DslTest.scala": null,
            "parquet-scala/src/test/scala/parquet/filter2/dsl/DslTest.scala": null,
            "parquet-scrooge/pom.xml": null,
            "parquet-scrooge/src/main/java/org/apache/parquet/scrooge/ParquetScroogeInputFormat.java": [
                0,
                31
            ],
            "parquet-scrooge/src/main/java/org/apache/parquet/scrooge/ParquetScroogeOutputFormat.java": [
                0,
                39
            ],
            "parquet-scrooge/src/main/java/org/apache/parquet/scrooge/ParquetScroogeScheme.java": [
                0,
                69
            ],
            "parquet-scrooge/src/main/java/org/apache/parquet/scrooge/ScroogeReadSupport.java": [
                0,
                45
            ],
            "parquet-scrooge/src/main/java/org/apache/parquet/scrooge/ScroogeRecordConverter.java": [
                0,
                57
            ],
            "parquet-scrooge/src/main/java/org/apache/parquet/scrooge/ScroogeSchemaConversionException.java": [
                0,
                36
            ],
            "parquet-scrooge/src/main/java/org/apache/parquet/scrooge/ScroogeStructConverter.java": [
                0,
                332
            ],
            "parquet-scrooge/src/main/java/org/apache/parquet/scrooge/ScroogeWriteSupport.java": [
                0,
                65
            ],
            "parquet-scrooge/src/main/java/parquet/scrooge/ParquetScroogeInputFormat.java": [
                31,
                0
            ],
            "parquet-scrooge/src/main/java/parquet/scrooge/ParquetScroogeOutputFormat.java": [
                39,
                0
            ],
            "parquet-scrooge/src/main/java/parquet/scrooge/ParquetScroogeScheme.java": [
                69,
                0
            ],
            "parquet-scrooge/src/main/java/parquet/scrooge/ScroogeReadSupport.java": [
                45,
                0
            ],
            "parquet-scrooge/src/main/java/parquet/scrooge/ScroogeRecordConverter.java": [
                57,
                0
            ],
            "parquet-scrooge/src/main/java/parquet/scrooge/ScroogeSchemaConversionException.java": [
                36,
                0
            ],
            "parquet-scrooge/src/main/java/parquet/scrooge/ScroogeStructConverter.java": [
                332,
                0
            ],
            "parquet-scrooge/src/main/java/parquet/scrooge/ScroogeWriteSupport.java": [
                65,
                0
            ],
            "parquet-scrooge/src/test/java/org/apache/parquet/scrooge/ParquetScroogeSchemeTest.java": [
                0,
                237
            ],
            "parquet-scrooge/src/test/java/org/apache/parquet/scrooge/ScroogeBinaryTest.java": [
                0,
                100
            ],
            "parquet-scrooge/src/test/java/org/apache/parquet/scrooge/ScroogeStructConverterTest.java": [
                0,
                123
            ],
            "parquet-scrooge/src/test/java/parquet/scrooge/ParquetScroogeSchemeTest.java": [
                237,
                0
            ],
            "parquet-scrooge/src/test/java/parquet/scrooge/ScroogeBinaryTest.java": [
                100,
                0
            ],
            "parquet-scrooge/src/test/java/parquet/scrooge/ScroogeStructConverterTest.java": [
                123,
                0
            ],
            "parquet-scrooge/src/test/thrift/test.thrift": null,
            "parquet-thrift/pom.xml": null,
            "parquet-thrift/src/main/java/org/apache/parquet/hadoop/thrift/AbstractThriftWriteSupport.java": [
                0,
                125
            ],
            "parquet-thrift/src/main/java/org/apache/parquet/hadoop/thrift/ParquetThriftBytesOutputFormat.java": [
                0,
                73
            ],
            "parquet-thrift/src/main/java/org/apache/parquet/hadoop/thrift/ParquetThriftInputFormat.java": [
                0,
                64
            ],
            "parquet-thrift/src/main/java/org/apache/parquet/hadoop/thrift/ParquetThriftOutputFormat.java": [
                0,
                46
            ],
            "parquet-thrift/src/main/java/org/apache/parquet/hadoop/thrift/TBaseWriteSupport.java": [
                0,
                62
            ],
            "parquet-thrift/src/main/java/org/apache/parquet/hadoop/thrift/ThriftBytesWriteSupport.java": [
                0,
                162
            ],
            "parquet-thrift/src/main/java/org/apache/parquet/hadoop/thrift/ThriftReadSupport.java": [
                0,
                180
            ],
            "parquet-thrift/src/main/java/org/apache/parquet/hadoop/thrift/ThriftToParquetFileWriter.java": [
                0,
                125
            ],
            "parquet-thrift/src/main/java/org/apache/parquet/hadoop/thrift/ThriftWriteSupport.java": [
                0,
                75
            ],
            "parquet-thrift/src/main/java/org/apache/parquet/thrift/BufferedProtocolReadToWrite.java": [
                0,
                680
            ],
            "parquet-thrift/src/main/java/org/apache/parquet/thrift/DecodingSchemaMismatchException.java": [
                0,
                30
            ],
            "parquet-thrift/src/main/java/org/apache/parquet/thrift/FieldIgnoredHandler.java": [
                0,
                46
            ],
            "parquet-thrift/src/main/java/org/apache/parquet/thrift/ParquetProtocol.java": [
                0,
                280
            ],
            "parquet-thrift/src/main/java/org/apache/parquet/thrift/ParquetReadProtocol.java": [
                0,
                161
            ],
            "parquet-thrift/src/main/java/org/apache/parquet/thrift/ParquetWriteProtocol.java": [
                0,
                690
            ],
            "parquet-thrift/src/main/java/org/apache/parquet/thrift/ProtocolPipe.java": [
                0,
                32
            ],
            "parquet-thrift/src/main/java/org/apache/parquet/thrift/ProtocolReadToWrite.java": [
                0,
                145
            ],
            "parquet-thrift/src/main/java/org/apache/parquet/thrift/SkippableException.java": [
                0,
                50
            ],
            "parquet-thrift/src/main/java/org/apache/parquet/thrift/TBaseRecordConverter.java": [
                0,
                48
            ],
            "parquet-thrift/src/main/java/org/apache/parquet/thrift/ThriftMetaData.java": [
                0,
                134
            ],
            "parquet-thrift/src/main/java/org/apache/parquet/thrift/ThriftParquetReader.java": [
                0,
                138
            ],
            "parquet-thrift/src/main/java/org/apache/parquet/thrift/ThriftParquetWriter.java": [
                0,
                54
            ],
            "parquet-thrift/src/main/java/org/apache/parquet/thrift/ThriftReader.java": [
                0,
                28
            ],
            "parquet-thrift/src/main/java/org/apache/parquet/thrift/ThriftRecordConverter.java": [
                0,
                883
            ],
            "parquet-thrift/src/main/java/org/apache/parquet/thrift/ThriftSchemaConvertVisitor.java": [
                0,
                276
            ],
            "parquet-thrift/src/main/java/org/apache/parquet/thrift/ThriftSchemaConverter.java": [
                0,
                165
            ],
            "parquet-thrift/src/main/java/org/apache/parquet/thrift/pig/ParquetThriftStorer.java": [
                0,
                93
            ],
            "parquet-thrift/src/main/java/org/apache/parquet/thrift/pig/TupleToThriftWriteSupport.java": [
                0,
                77
            ],
            "parquet-thrift/src/main/java/org/apache/parquet/thrift/projection/FieldProjectionFilter.java": [
                0,
                93
            ],
            "parquet-thrift/src/main/java/org/apache/parquet/thrift/projection/FieldsPath.java": [
                0,
                84
            ],
            "parquet-thrift/src/main/java/org/apache/parquet/thrift/projection/PathGlobPattern.java": [
                0,
                184
            ],
            "parquet-thrift/src/main/java/org/apache/parquet/thrift/projection/ThriftProjectionException.java": [
                0,
                48
            ],
            "parquet-thrift/src/main/java/org/apache/parquet/thrift/projection/amend/DefaultEventsVisitor.java": [
                0,
                215
            ],
            "parquet-thrift/src/main/java/org/apache/parquet/thrift/projection/amend/DefaultProtocolEventsGenerator.java": [
                0,
                68
            ],
            "parquet-thrift/src/main/java/org/apache/parquet/thrift/projection/amend/ProtocolEventsAmender.java": [
                0,
                173
            ],
            "parquet-thrift/src/main/java/org/apache/parquet/thrift/projection/amend/ReadFieldBeginProtocol.java": [
                0,
                44
            ],
            "parquet-thrift/src/main/java/org/apache/parquet/thrift/struct/CompatibilityChecker.java": [
                0,
                221
            ],
            "parquet-thrift/src/main/java/org/apache/parquet/thrift/struct/CompatibilityRunner.java": [
                0,
                99
            ],
            "parquet-thrift/src/main/java/org/apache/parquet/thrift/struct/JSON.java": [
                0,
                51
            ],
            "parquet-thrift/src/main/java/org/apache/parquet/thrift/struct/ThriftField.java": [
                0,
                121
            ],
            "parquet-thrift/src/main/java/org/apache/parquet/thrift/struct/ThriftType.java": [
                0,
                578
            ],
            "parquet-thrift/src/main/java/org/apache/parquet/thrift/struct/ThriftTypeID.java": [
                0,
                111
            ],
            "parquet-thrift/src/main/java/parquet/hadoop/thrift/AbstractThriftWriteSupport.java": [
                126,
                0
            ],
            "parquet-thrift/src/main/java/parquet/hadoop/thrift/ParquetThriftBytesOutputFormat.java": [
                73,
                0
            ],
            "parquet-thrift/src/main/java/parquet/hadoop/thrift/ParquetThriftInputFormat.java": [
                64,
                0
            ],
            "parquet-thrift/src/main/java/parquet/hadoop/thrift/ParquetThriftOutputFormat.java": [
                46,
                0
            ],
            "parquet-thrift/src/main/java/parquet/hadoop/thrift/TBaseWriteSupport.java": [
                63,
                0
            ],
            "parquet-thrift/src/main/java/parquet/hadoop/thrift/ThriftBytesWriteSupport.java": [
                162,
                0
            ],
            "parquet-thrift/src/main/java/parquet/hadoop/thrift/ThriftReadSupport.java": [
                180,
                0
            ],
            "parquet-thrift/src/main/java/parquet/hadoop/thrift/ThriftToParquetFileWriter.java": [
                125,
                0
            ],
            "parquet-thrift/src/main/java/parquet/hadoop/thrift/ThriftWriteSupport.java": [
                78,
                0
            ],
            "parquet-thrift/src/main/java/parquet/thrift/BufferedProtocolReadToWrite.java": [
                680,
                0
            ],
            "parquet-thrift/src/main/java/parquet/thrift/DecodingSchemaMismatchException.java": [
                30,
                0
            ],
            "parquet-thrift/src/main/java/parquet/thrift/FieldIgnoredHandler.java": [
                46,
                0
            ],
            "parquet-thrift/src/main/java/parquet/thrift/ParquetProtocol.java": [
                280,
                0
            ],
            "parquet-thrift/src/main/java/parquet/thrift/ParquetReadProtocol.java": [
                161,
                0
            ],
            "parquet-thrift/src/main/java/parquet/thrift/ParquetWriteProtocol.java": [
                692,
                0
            ],
            "parquet-thrift/src/main/java/parquet/thrift/ProtocolPipe.java": [
                32,
                0
            ],
            "parquet-thrift/src/main/java/parquet/thrift/ProtocolReadToWrite.java": [
                145,
                0
            ],
            "parquet-thrift/src/main/java/parquet/thrift/SkippableException.java": [
                50,
                0
            ],
            "parquet-thrift/src/main/java/parquet/thrift/TBaseRecordConverter.java": [
                48,
                0
            ],
            "parquet-thrift/src/main/java/parquet/thrift/ThriftMetaData.java": [
                136,
                0
            ],
            "parquet-thrift/src/main/java/parquet/thrift/ThriftParquetReader.java": [
                138,
                0
            ],
            "parquet-thrift/src/main/java/parquet/thrift/ThriftParquetWriter.java": [
                54,
                0
            ],
            "parquet-thrift/src/main/java/parquet/thrift/ThriftReader.java": [
                28,
                0
            ],
            "parquet-thrift/src/main/java/parquet/thrift/ThriftRecordConverter.java": [
                883,
                0
            ],
            "parquet-thrift/src/main/java/parquet/thrift/ThriftSchemaConvertVisitor.java": [
                276,
                0
            ],
            "parquet-thrift/src/main/java/parquet/thrift/ThriftSchemaConverter.java": [
                165,
                0
            ],
            "parquet-thrift/src/main/java/parquet/thrift/pig/ParquetThriftStorer.java": [
                93,
                0
            ],
            "parquet-thrift/src/main/java/parquet/thrift/pig/TupleToThriftWriteSupport.java": [
                77,
                0
            ],
            "parquet-thrift/src/main/java/parquet/thrift/projection/FieldProjectionFilter.java": [
                93,
                0
            ],
            "parquet-thrift/src/main/java/parquet/thrift/projection/FieldsPath.java": [
                84,
                0
            ],
            "parquet-thrift/src/main/java/parquet/thrift/projection/PathGlobPattern.java": [
                184,
                0
            ],
            "parquet-thrift/src/main/java/parquet/thrift/projection/ThriftProjectionException.java": [
                48,
                0
            ],
            "parquet-thrift/src/main/java/parquet/thrift/projection/amend/DefaultEventsVisitor.java": [
                215,
                0
            ],
            "parquet-thrift/src/main/java/parquet/thrift/projection/amend/DefaultProtocolEventsGenerator.java": [
                68,
                0
            ],
            "parquet-thrift/src/main/java/parquet/thrift/projection/amend/ProtocolEventsAmender.java": [
                173,
                0
            ],
            "parquet-thrift/src/main/java/parquet/thrift/projection/amend/ReadFieldBeginProtocol.java": [
                44,
                0
            ],
            "parquet-thrift/src/main/java/parquet/thrift/struct/CompatibilityChecker.java": [
                221,
                0
            ],
            "parquet-thrift/src/main/java/parquet/thrift/struct/CompatibilityRunner.java": [
                99,
                0
            ],
            "parquet-thrift/src/main/java/parquet/thrift/struct/JSON.java": [
                51,
                0
            ],
            "parquet-thrift/src/main/java/parquet/thrift/struct/ThriftField.java": [
                121,
                0
            ],
            "parquet-thrift/src/main/java/parquet/thrift/struct/ThriftType.java": [
                578,
                0
            ],
            "parquet-thrift/src/main/java/parquet/thrift/struct/ThriftTypeID.java": [
                111,
                0
            ],
            "parquet-thrift/src/test/java/org/apache/parquet/hadoop/thrift/TestBinary.java": [
                0,
                66
            ],
            "parquet-thrift/src/test/java/org/apache/parquet/hadoop/thrift/TestInputOutputFormat.java": [
                0,
                257
            ],
            "parquet-thrift/src/test/java/org/apache/parquet/hadoop/thrift/TestParquetToThriftReadWriteAndProjection.java": [
                0,
                244
            ],
            "parquet-thrift/src/test/java/org/apache/parquet/hadoop/thrift/TestThriftToParquetFileWriter.java": [
                0,
                294
            ],
            "parquet-thrift/src/test/java/org/apache/parquet/thrift/TestParquetReadProtocol.java": [
                0,
                167
            ],
            "parquet-thrift/src/test/java/org/apache/parquet/thrift/TestParquetWriteProtocol.java": [
                0,
                550
            ],
            "parquet-thrift/src/test/java/org/apache/parquet/thrift/TestProtocolReadToWrite.java": [
                0,
                286
            ],
            "parquet-thrift/src/test/java/org/apache/parquet/thrift/TestThriftParquetReaderWriter.java": [
                0,
                73
            ],
            "parquet-thrift/src/test/java/org/apache/parquet/thrift/TestThriftSchemaConverter.java": [
                0,
                250
            ],
            "parquet-thrift/src/test/java/org/apache/parquet/thrift/TestThriftToPigCompatibility.java": [
                0,
                171
            ],
            "parquet-thrift/src/test/java/org/apache/parquet/thrift/pig/TestParquetThriftStorer.java": [
                0,
                82
            ],
            "parquet-thrift/src/test/java/org/apache/parquet/thrift/projection/PathGlobPatternTest.java": [
                0,
                59
            ],
            "parquet-thrift/src/test/java/org/apache/parquet/thrift/struct/CompatibilityCheckerTest.java": [
                0,
                120
            ],
            "parquet-thrift/src/test/java/org/apache/parquet/thrift/struct/TestThriftType.java": [
                0,
                67
            ],
            "parquet-thrift/src/test/java/parquet/hadoop/thrift/TestBinary.java": [
                66,
                0
            ],
            "parquet-thrift/src/test/java/parquet/hadoop/thrift/TestInputOutputFormat.java": [
                257,
                0
            ],
            "parquet-thrift/src/test/java/parquet/hadoop/thrift/TestParquetToThriftReadWriteAndProjection.java": [
                244,
                0
            ],
            "parquet-thrift/src/test/java/parquet/hadoop/thrift/TestThriftToParquetFileWriter.java": [
                294,
                0
            ],
            "parquet-thrift/src/test/java/parquet/thrift/TestParquetReadProtocol.java": [
                167,
                0
            ],
            "parquet-thrift/src/test/java/parquet/thrift/TestParquetWriteProtocol.java": [
                550,
                0
            ],
            "parquet-thrift/src/test/java/parquet/thrift/TestProtocolReadToWrite.java": [
                286,
                0
            ],
            "parquet-thrift/src/test/java/parquet/thrift/TestThriftParquetReaderWriter.java": [
                73,
                0
            ],
            "parquet-thrift/src/test/java/parquet/thrift/TestThriftSchemaConverter.java": [
                250,
                0
            ],
            "parquet-thrift/src/test/java/parquet/thrift/TestThriftToPigCompatibility.java": [
                171,
                0
            ],
            "parquet-thrift/src/test/java/parquet/thrift/pig/TestParquetThriftStorer.java": [
                82,
                0
            ],
            "parquet-thrift/src/test/java/parquet/thrift/projection/PathGlobPatternTest.java": [
                59,
                0
            ],
            "parquet-thrift/src/test/java/parquet/thrift/struct/CompatibilityCheckerTest.java": [
                120,
                0
            ],
            "parquet-thrift/src/test/java/parquet/thrift/struct/TestThriftType.java": [
                67,
                0
            ],
            "parquet-thrift/src/test/resources/parquet/hadoop/thrift/AddressBook.json": null,
            "parquet-thrift/src/test/thrift/binary.thrift": null,
            "parquet-thrift/src/test/thrift/compat.thrift": null,
            "parquet-thrift/src/test/thrift/test.thrift": null,
            "parquet-tools/pom.xml": null,
            "parquet-tools/src/main/java/org/apache/parquet/tools/Main.java": [
                0,
                231
            ],
            "parquet-tools/src/main/java/org/apache/parquet/tools/command/ArgsOnlyCommand.java": [
                0,
                56
            ],
            "parquet-tools/src/main/java/org/apache/parquet/tools/command/CatCommand.java": [
                0,
                91
            ],
            "parquet-tools/src/main/java/org/apache/parquet/tools/command/Command.java": [
                0,
                30
            ],
            "parquet-tools/src/main/java/org/apache/parquet/tools/command/DumpCommand.java": [
                0,
                338
            ],
            "parquet-tools/src/main/java/org/apache/parquet/tools/command/HeadCommand.java": [
                0,
                95
            ],
            "parquet-tools/src/main/java/org/apache/parquet/tools/command/Registry.java": [
                0,
                60
            ],
            "parquet-tools/src/main/java/org/apache/parquet/tools/command/ShowMetaCommand.java": [
                0,
                76
            ],
            "parquet-tools/src/main/java/org/apache/parquet/tools/command/ShowSchemaCommand.java": [
                0,
                100
            ],
            "parquet-tools/src/main/java/org/apache/parquet/tools/read/SimpleListRecord.java": [
                0,
                30
            ],
            "parquet-tools/src/main/java/org/apache/parquet/tools/read/SimpleListRecordConverter.java": [
                0,
                34
            ],
            "parquet-tools/src/main/java/org/apache/parquet/tools/read/SimpleMapRecord.java": [
                0,
                43
            ],
            "parquet-tools/src/main/java/org/apache/parquet/tools/read/SimpleMapRecordConverter.java": [
                0,
                34
            ],
            "parquet-tools/src/main/java/org/apache/parquet/tools/read/SimpleReadSupport.java": [
                0,
                41
            ],
            "parquet-tools/src/main/java/org/apache/parquet/tools/read/SimpleRecord.java": [
                0,
                149
            ],
            "parquet-tools/src/main/java/org/apache/parquet/tools/read/SimpleRecordConverter.java": [
                0,
                159
            ],
            "parquet-tools/src/main/java/org/apache/parquet/tools/read/SimpleRecordMaterializer.java": [
                0,
                42
            ],
            "parquet-tools/src/main/java/org/apache/parquet/tools/util/MetadataUtils.java": [
                0,
                229
            ],
            "parquet-tools/src/main/java/org/apache/parquet/tools/util/PrettyPrintWriter.java": [
                0,
                1035
            ],
            "parquet-tools/src/main/java/parquet/tools/Main.java": [
                231,
                0
            ],
            "parquet-tools/src/main/java/parquet/tools/command/ArgsOnlyCommand.java": [
                56,
                0
            ],
            "parquet-tools/src/main/java/parquet/tools/command/CatCommand.java": [
                91,
                0
            ],
            "parquet-tools/src/main/java/parquet/tools/command/Command.java": [
                30,
                0
            ],
            "parquet-tools/src/main/java/parquet/tools/command/DumpCommand.java": [
                338,
                0
            ],
            "parquet-tools/src/main/java/parquet/tools/command/HeadCommand.java": [
                95,
                0
            ],
            "parquet-tools/src/main/java/parquet/tools/command/Registry.java": [
                60,
                0
            ],
            "parquet-tools/src/main/java/parquet/tools/command/ShowMetaCommand.java": [
                76,
                0
            ],
            "parquet-tools/src/main/java/parquet/tools/command/ShowSchemaCommand.java": [
                100,
                0
            ],
            "parquet-tools/src/main/java/parquet/tools/read/SimpleListRecord.java": [
                30,
                0
            ],
            "parquet-tools/src/main/java/parquet/tools/read/SimpleListRecordConverter.java": [
                34,
                0
            ],
            "parquet-tools/src/main/java/parquet/tools/read/SimpleMapRecord.java": [
                43,
                0
            ],
            "parquet-tools/src/main/java/parquet/tools/read/SimpleMapRecordConverter.java": [
                34,
                0
            ],
            "parquet-tools/src/main/java/parquet/tools/read/SimpleReadSupport.java": [
                41,
                0
            ],
            "parquet-tools/src/main/java/parquet/tools/read/SimpleRecord.java": [
                149,
                0
            ],
            "parquet-tools/src/main/java/parquet/tools/read/SimpleRecordConverter.java": [
                159,
                0
            ],
            "parquet-tools/src/main/java/parquet/tools/read/SimpleRecordMaterializer.java": [
                42,
                0
            ],
            "parquet-tools/src/main/java/parquet/tools/util/MetadataUtils.java": [
                229,
                0
            ],
            "parquet-tools/src/main/java/parquet/tools/util/PrettyPrintWriter.java": [
                1035,
                0
            ],
            "parquet-tools/src/main/scripts/parquet-tools": null,
            "pom.xml": null
        }
    },
    "7c42398332bf1522b7fcc952110471c86cd7ec28": {
        "datetime": "2015-04-27T17:59:44-07:00",
        "summary": "PARQUET-211: Update version for 1.8.0 development.",
        "message": "PARQUET-211: Update version for 1.8.0 development.\n\nAuthor: Ryan Blue <blue@apache.org>\n\nCloses #182 from rdblue/PARQUET-211-update-to-1.8.0 and squashes the following commits:\n\n139e682 [Ryan Blue] PARQUET-211: Update version for 1.8.0 development.\n",
        "diff": {
            "dev/merge_parquet_pr.py": [
                2,
                0
            ],
            "parquet-avro/pom.xml": null,
            "parquet-benchmarks/pom.xml": null,
            "parquet-cascading/pom.xml": null,
            "parquet-column/pom.xml": null,
            "parquet-common/pom.xml": null,
            "parquet-encoding/pom.xml": null,
            "parquet-generator/pom.xml": null,
            "parquet-hadoop-bundle/pom.xml": null,
            "parquet-hadoop/pom.xml": null,
            "parquet-hive-bundle/pom.xml": null,
            "parquet-hive/parquet-hive-binding/parquet-hive-0.10-binding/pom.xml": null,
            "parquet-hive/parquet-hive-binding/parquet-hive-0.12-binding/pom.xml": null,
            "parquet-hive/parquet-hive-binding/parquet-hive-binding-bundle/pom.xml": null,
            "parquet-hive/parquet-hive-binding/parquet-hive-binding-factory/pom.xml": null,
            "parquet-hive/parquet-hive-binding/parquet-hive-binding-interface/pom.xml": null,
            "parquet-hive/parquet-hive-binding/pom.xml": null,
            "parquet-hive/parquet-hive-storage-handler/pom.xml": null,
            "parquet-hive/pom.xml": null,
            "parquet-jackson/pom.xml": null,
            "parquet-pig-bundle/pom.xml": null,
            "parquet-pig/pom.xml": null,
            "parquet-protobuf/pom.xml": null,
            "parquet-scala/pom.xml": null,
            "parquet-scrooge/pom.xml": null,
            "parquet-thrift/pom.xml": null,
            "parquet-tools/pom.xml": null,
            "pom.xml": null
        }
    },
    "4f7c704d47e11f8faf015169c6e158b1f4e0326d": {
        "datetime": "2015-04-28T14:39:20-07:00",
        "summary": "PARQUET-245: Only run tests in Travis CI if build succeeds.",
        "message": "PARQUET-245: Only run tests in Travis CI if build succeeds.\n\nAuthor: Ryan Blue <blue@apache.org>\n\nCloses #167 from rdblue/PARQUET-245-fix-travis-ci and squashes the following commits:\n\nccdb0b1 [Ryan Blue] PARQUET-245: Add retry to Travis CI to fix maven downloads.\nf1bb713 [Ryan Blue] PARQUET-245: Only run tests in Travis CI if build succeeds.\n",
        "diff": {
            ".travis.yml": null
        }
    },
    "9d744f7136f23da9a5f9324432b300b5a68e3b39": {
        "datetime": "2015-04-29T17:47:03-07:00",
        "summary": "PARQUET-268: Downgrade scrooge-maven-plugin.",
        "message": "PARQUET-268: Downgrade scrooge-maven-plugin.\n\nThe 3.17.0 version no longer works because a transitive dependency has\nbeen purged. 3.18.0 is the natural upgrade, but fails with a\nconfiguration problem. The latest documentation on updates is for moving\nto 3.17.0, so the easiest solution that works is to downgrade to 3.16.0.\nThe build is working.\n\nAuthor: Ryan Blue <blue@apache.org>\n\nCloses #187 from rdblue/PARQUET-268-fix-scrooge-plugin-version and squashes the following commits:\n\n2b90634 [Ryan Blue] PARQUET-268: Downgrade scrooge-maven-plugin.\n",
        "diff": {
            "parquet-scrooge/pom.xml": null,
            "parquet-scrooge/src/test/java/org/apache/parquet/scrooge/ScroogeStructConverterTest.java": [
                0,
                3
            ]
        }
    },
    "1be38782d00a061476b9fc6fa2475699008db2f6": {
        "datetime": "2015-04-29T17:53:10-07:00",
        "summary": "PARQUET-270: Adds a legend for meta output to readme.md",
        "message": "PARQUET-270: Adds a legend for meta output to readme.md\n\nAuthor: Brett Stime <brett.stime@nativex.com>\n\nCloses #178 from w3iBStime/patch-2 and squashes the following commits:\n\nc6c6898 [Brett Stime] Makes meta legend more descriptive\n6d32bc3 [Brett Stime] Update README.md\nb1e38aa [Brett Stime] Adds a legend for meta output to readme.md\n",
        "diff": {
            "parquet-tools/README.md": null
        }
    },
    "b287d35fe6c3814f38db44e31cf52d978e659960": {
        "datetime": "2015-04-29T17:56:39-07:00",
        "summary": "PARQUET-271: Fixes parquet-tools java examples",
        "message": "PARQUET-271: Fixes parquet-tools java examples\n\nUses a dash (hyphen) in front of the -jar argument per\nhttp://docs.oracle.com/javase/7/docs/technotes/tools/solaris/java.html\nand\nhttp://docs.oracle.com/javase/7/docs/technotes/tools/windows/java.html\n\nAuthor: Brett Stime <brett.stime@nativex.com>\n\nCloses #177 from w3iBStime/patch-1 and squashes the following commits:\n\n2a44063 [Brett Stime] Fixes parquet-tools java examples\n",
        "diff": {
            "parquet-tools/README.md": null
        }
    },
    "9993450ad1f023e0e2b59291361d0b3b9f0e1c8d": {
        "datetime": "2015-04-29T23:18:47-07:00",
        "summary": "PARQUET-227 Enforce that unions have only 1 set value, tolerate bad records in read path",
        "message": "PARQUET-227 Enforce that unions have only 1 set value, tolerate bad records in read path\n\nSee https://issues.apache.org/jira/browse/PARQUET-227\n\nAuthor: Alex Levenson <alexlevenson@twitter.com>\n\nCloses #153 from isnotinvain/alexlevenson/double-union and squashes the following commits:\n\nef4d36f [Alex Levenson] fix package names\ne201deb [Alex Levenson] Merge branch 'master' into alexlevenson/double-union\n01694fa [Alex Levenson] Forgot a break in a switch statement\n2f31321 [Alex Levenson] Merge branch 'master' into alexlevenson/double-union\n9292274 [Alex Levenson] Add in ShouldNeverHappenException which I forgot to check in\n8d61515 [Alex Levenson] Address first round of comments\n4d71bcb [Alex Levenson] Merge branch 'master' into alexlevenson/double-union\n8f9334c [Alex Levenson] Some cleanup and fixes\n8153bc9 [Alex Levenson] Enforce that unions have only 1 set value, tolerate bad records in read path\n",
        "diff": {
            "parquet-column/src/main/java/org/apache/parquet/io/api/RecordMaterializer.java": [
                0,
                27
            ],
            "parquet-common/src/main/java/org/apache/parquet/ShouldNeverHappenException.java": [
                0,
                40
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/InternalParquetRecordReader.java": [
                2,
                14
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/UnmaterializableRecordCounter.java": [
                0,
                87
            ],
            "parquet-scrooge/src/test/java/org/apache/parquet/scrooge/TestCorruptScroogeRecords.java": [
                0,
                69
            ],
            "parquet-scrooge/src/test/thrift/test.thrift": null,
            "parquet-thrift/src/main/java/org/apache/parquet/hadoop/thrift/ThriftReadSupport.java": [
                0,
                15
            ],
            "parquet-thrift/src/main/java/org/apache/parquet/thrift/BufferedProtocolReadToWrite.java": [
                28,
                85
            ],
            "parquet-thrift/src/main/java/org/apache/parquet/thrift/ParquetProtocol.java": [
                2,
                2
            ],
            "parquet-thrift/src/main/java/org/apache/parquet/thrift/ParquetReadProtocol.java": [
                0,
                4
            ],
            "parquet-thrift/src/main/java/org/apache/parquet/thrift/ThriftRecordConverter.java": [
                2,
                3
            ],
            "parquet-thrift/src/test/java/org/apache/parquet/hadoop/thrift/TestCorruptThriftRecords.java": [
                0,
                213
            ],
            "parquet-thrift/src/test/java/org/apache/parquet/hadoop/thrift/TestInputOutputFormat.java": [
                1,
                1
            ],
            "parquet-thrift/src/test/java/org/apache/parquet/thrift/TestProtocolReadToWrite.java": [
                0,
                60
            ],
            "parquet-thrift/src/test/thrift/compat.thrift": null
        }
    },
    "98f54c158acb12a26fa6f335b1665accd2aed347": {
        "datetime": "2015-04-30T12:33:56+02:00",
        "summary": "PARQUET-175 reading custom protobuf class",
        "message": "PARQUET-175 reading custom protobuf class\n\n Changes to be committed:\n\tmodified:   parquet-protobuf/src/main/java/org/apache/parquet/proto/ProtoReadSupport.java\n\tmodified:   parquet-protobuf/src/test/java/org/apache/parquet/proto/ProtoInputOutputFormatTest.java\n\tmodified:   parquet-protobuf/src/test/resources/TestProtobuf.proto\n\nAuthor: Nalezenec, Lukas <lukas.nalezenec@gmail.com>\n\nCloses #183 from lukasnalezenec/master and squashes the following commits:\n\n796cd39 [Nalezenec, Lukas] PARQUET-175 Allow setting of a custom protobuf class when reading parquet file using parquet-protobuf.\n",
        "diff": {
            "parquet-protobuf/src/main/java/org/apache/parquet/proto/ProtoReadSupport.java": [
                4,
                20
            ],
            "parquet-protobuf/src/test/java/org/apache/parquet/proto/ProtoInputOutputFormatTest.java": [
                8,
                33
            ],
            "parquet-protobuf/src/test/resources/TestProtobuf.proto": null
        }
    },
    "22c6d087012fd55bc65e578a27f2edb66f4d3808": {
        "datetime": "2015-04-30T16:59:20-07:00",
        "summary": "PARQUET-269: Restore scrooge-maven-plugin to version 3.17.0",
        "message": "PARQUET-269: Restore scrooge-maven-plugin to version 3.17.0\n\nScrooge has re-published scrooge-maven-plugin 3.17.0, so we should be able to use it again.\nLets see if travis is able to pick up the changes.\n\nAuthor: Alex Levenson <alexlevenson@twitter.com>\n\nCloses #188 from isnotinvain/alexlevenson/restore-scrooge-plugin and squashes the following commits:\n\nfbec238 [Alex Levenson] Revert \"make a whitespace change to trigger tests\"\n5ea3d26 [Alex Levenson] make a whitespace change to trigger tests\nbfe181f [Alex Levenson] Restore scrooge-maven-plugin to version 3.17.0\n",
        "diff": {
            "parquet-scrooge/pom.xml": null,
            "parquet-scrooge/src/test/java/org/apache/parquet/scrooge/ScroogeStructConverterTest.java": [
                3,
                0
            ]
        }
    },
    "7fc7998398373a14b4cdc0ce18abdeb221b1ccf9": {
        "datetime": "2015-04-30T17:45:11-07:00",
        "summary": "PARQUET-229 Add a strict thrift projection API with backwards compat support",
        "message": "PARQUET-229 Add a strict thrift projection API with backwards compat support\n\nCurrently, the thrift projection API accepts strings in a very general glob format that supports not only wildcards like `*` and `?` and expansions (`{x,y,z}`) but also character classes `[abc]`, and negation.\nBecause of this flexibility, it's hard to give users good error reporting, for example letting them know that when they requested columns `foo.bar.{a,b,c}` there is actually no such column `foo.bar.c`.\n\nThis PR introduces a new syntax that supports a more restrictive form of glob syntax and enforces that all **expansions** of a glob match a column, not just that all globs match a column. The new syntax is very simple and only has four special characters: `{`,`}`,`,`, and `*`\n\nIt supports glob expansion, for example:\n`home.{phone,address}` or `org.apache{-incubator,}.foo`\n\nAnd the wildcard `*` which is treated the same way as java regex treats `(.*)`, for example:\n`home.*` or `org.apache*.foo`\n\nIn the new syntax glob paths mean \"keep all the child fields of the field matched by this glob\", just like variable access would work in a programming language. For example: `x.y.z` means keep field `z` and all of its children (if any). So it's not necessary to do `x.y.z.*`. However, `x.y.z` would not keep field `x.y.zoo`. If that was desired, then `x.y.z*` could be used instead.\n\nSetting `\"parquet.thrift.column.filter\"` will result in the same behavior that it does currently in master, though a deprecation warning will be logged. The classes that implement the current behavior have been marked as deprecated, and using this will log a warning.\n\nSetting `\"parquet.thrift.column.projection.globs\"` will instead use this new syntax, and entry points in the various Builder's in the codebase is added as well.\n\nThis PR does a little bit of cleanup as well, moving some shared methods to a `Strings` class and simplifying some of the class hierarchy in `ThriftSchemaConverterVisitor`. There are a few `// TODO Why?` added as well that I wanted to ask about.\n\nAuthor: Alex Levenson <alexlevenson@twitter.com>\n\nCloses #150 from isnotinvain/alexlevenson/strict-projection and squashes the following commits:\n\n6c58e1c [Alex Levenson] clean up docs\n1aab666 [Alex Levenson] Merge branch 'master' into alexlevenson/strict-projection\n92b6ba6 [Alex Levenson] Merge branch 'master' into alexlevenson/strict-projection\nceaf6cd [Alex Levenson] update packages\na28dc19 [Alex Levenson] Merge branch 'master' into alexlevenson/strict-projection\nebc4761 [Alex Levenson] Remove unneeded TODO\nc2e12c5 [Alex Levenson] Update docs\neecf5f3 [Alex Levenson] Merge branch 'master' into alexlevenson/strict-projection\n671f0b5 [Alex Levenson] Merge branch 'master' into alexlevenson/strict-projection\n298cad8 [Alex Levenson] Add warning\n8b7e4bb [Alex Levenson] Add more comments to StrictFieldProjectionFilter\n8f65ed2 [Alex Levenson] Add tests for strict projection filter\nc81d9e1 [Alex Levenson] Docs and cleanup for FieldProjectionFilter\n71139a7 [Alex Levenson] Add tests for FieldsPath\n7d17068 [Alex Levenson] Tests for WildcardPath\n8a3d2af [Alex Levenson] Add some tests\nf3fd931 [Alex Levenson] More docs\n0b190c3 [Alex Levenson] Add more comments\n6e67df5 [Alex Levenson] Add a strict thrift projection API with backwards support for the current API\n",
        "diff": {
            "parquet-cascading/src/main/java/org/apache/parquet/cascading/ParquetValueScheme.java": [
                10,
                32
            ],
            "parquet-common/src/main/java/org/apache/parquet/Strings.java": [
                0,
                110
            ],
            "parquet-common/src/main/java/org/apache/parquet/glob/GlobExpander.java": [
                0,
                114
            ],
            "parquet-common/src/main/java/org/apache/parquet/glob/GlobNode.java": [
                0,
                157
            ],
            "parquet-common/src/main/java/org/apache/parquet/glob/GlobParser.java": [
                0,
                224
            ],
            "parquet-common/src/main/java/org/apache/parquet/glob/WildcardPath.java": [
                0,
                122
            ],
            "parquet-common/src/main/java/org/apache/parquet/hadoop/metadata/ColumnPath.java": [
                9,
                3
            ],
            "parquet-common/src/test/java/org/apache/parquet/glob/TestGlob.java": [
                0,
                144
            ],
            "parquet-common/src/test/java/org/apache/parquet/glob/TestWildcardPath.java": [
                0,
                125
            ],
            "parquet-thrift/src/main/java/org/apache/parquet/hadoop/thrift/ThriftReadSupport.java": [
                16,
                62
            ],
            "parquet-thrift/src/main/java/org/apache/parquet/thrift/ThriftSchemaConvertVisitor.java": [
                24,
                14
            ],
            "parquet-thrift/src/main/java/org/apache/parquet/thrift/ThriftSchemaConverter.java": [
                43,
                26
            ],
            "parquet-thrift/src/main/java/org/apache/parquet/thrift/projection/FieldProjectionFilter.java": [
                63,
                31
            ],
            "parquet-thrift/src/main/java/org/apache/parquet/thrift/projection/FieldsPath.java": [
                30,
                33
            ],
            "parquet-thrift/src/main/java/org/apache/parquet/thrift/projection/PathGlobPattern.java": [
                2,
                5
            ],
            "parquet-thrift/src/main/java/org/apache/parquet/thrift/projection/StrictFieldProjectionFilter.java": [
                0,
                182
            ],
            "parquet-thrift/src/main/java/org/apache/parquet/thrift/projection/deprecated/DeprecatedFieldProjectionFilter.java": [
                0,
                107
            ],
            "parquet-thrift/src/test/java/org/apache/parquet/hadoop/thrift/TestParquetToThriftReadWriteAndProjection.java": [
                1,
                1
            ],
            "parquet-thrift/src/test/java/org/apache/parquet/thrift/TestThriftSchemaConverter.java": [
                51,
                50
            ],
            "parquet-thrift/src/test/java/org/apache/parquet/thrift/projection/PathGlobPatternTest.java": [
                1,
                1
            ],
            "parquet-thrift/src/test/java/org/apache/parquet/thrift/projection/TestFieldsPath.java": [
                0,
                166
            ],
            "parquet-thrift/src/test/java/org/apache/parquet/thrift/projection/TestStrictFieldProjectionFilter.java": [
                0,
                119
            ],
            "parquet_cascading.md": null,
            "pom.xml": null
        }
    },
    "890b387d713d04c22406db6d5a5fc9b51bec2df5": {
        "datetime": "2015-05-04T12:08:41-07:00",
        "summary": "PARQUET-252 : support nested container type for parquet-scrooge",
        "message": "PARQUET-252 : support nested container type for parquet-scrooge\n\nresubmit\n\nAuthor: Tianshuo Deng <tdeng@twitter.com>\n\nCloses #185 from tsdeng/scrooge_nested_container and squashes the following commits:\n\nb29465f [Tianshuo Deng] retrigger jenkins\n4542c1a [Tianshuo Deng] support nested container type for parquet-scrooge\n",
        "diff": {
            "changelog.sh": null,
            "parquet-scrooge/src/main/java/org/apache/parquet/scrooge/ScroogeStructConverter.java": [
                139,
                179
            ],
            "parquet-scrooge/src/test/java/org/apache/parquet/scrooge/ScroogeStructConverterTest.java": [
                51,
                107
            ],
            "parquet-scrooge/src/test/thrift/test.thrift": null
        }
    },
    "b8aae90d333094da4afd65ad5f5eb13854811f28": {
        "datetime": "2015-05-06T16:34:24-07:00",
        "summary": "PARQUET-272: Updates docs description to match data model",
        "message": "PARQUET-272: Updates docs description to match data model\n\nAuthor: Ben Pence <bpence@twitter.com>\n\nCloses #190 from benpence/doc_fixes and squashes the following commits:\n\n0d5da56 [Ben Pence] Updates docs description to match data model\n",
        "diff": {
            "parquet_cascading.md": null
        }
    },
    "9500c773ed121c963cdfc57fb239410a81458147": {
        "datetime": "2015-05-07T14:17:46-07:00",
        "summary": "PARQUET-276: Updates CONTRIBUTING file with new repo info",
        "message": "PARQUET-276: Updates CONTRIBUTING file with new repo info\n\nAuthor: Ben Pence <bpence@twitter.com>\n\nCloses #193 from benpence/contributing and squashes the following commits:\n\nec9c672 [Ben Pence] Updates CONTRIBUTING file with new repo info\n",
        "diff": {
            "CONTRIBUTING.md": null
        }
    },
    "c7d56cffbb4668d0955ef00196e08f42f2efe363": {
        "datetime": "2015-05-12T11:15:40-07:00",
        "summary": "PARQUET-273 : remove usage of ReflectiveOperationException to support JAVA6",
        "message": "PARQUET-273 : remove usage of ReflectiveOperationException to support JAVA6\n\nas commented here: https://github.com/apache/parquet-mr/commit/52f3240d90f2397cd1850ab11674ba08a0ecb2a0#commitcomment-11065301\n\nAuthor: Tianshuo Deng <tdeng@twitter.com>\n\nCloses #191 from tsdeng/remove_usage_of_reflective_operation_exception and squashes the following commits:\n\nadbe37a [Tianshuo Deng] remove usage of ReflectiveOperationException to support JAVA6\n",
        "diff": {
            "parquet-scrooge/src/main/java/org/apache/parquet/scrooge/ScroogeStructConverter.java": [
                5,
                21
            ]
        }
    },
    "e5d9c6c7982b16840eb9ea95f8e087a2abfd1027": {
        "datetime": "2015-05-14T15:39:39-07:00",
        "summary": "PARQUET-265: Update POM files for Parquet TLP.",
        "message": "PARQUET-265: Update POM files for Parquet TLP.\n\nAuthor: Ryan Blue <blue@apache.org>\n\nCloses #186 from rdblue/PARQUET-265-update-build-for-graduation and squashes the following commits:\n\n7bd2931 [Ryan Blue] PARQUET-265: Update POM files for Parquet TLP.\n",
        "diff": {
            "dev/source-release.sh": null,
            "parquet-avro/pom.xml": null,
            "parquet-benchmarks/pom.xml": null,
            "parquet-cascading/pom.xml": null,
            "parquet-column/pom.xml": null,
            "parquet-common/pom.xml": null,
            "parquet-encoding/pom.xml": null,
            "parquet-generator/pom.xml": null,
            "parquet-hadoop-bundle/pom.xml": null,
            "parquet-hadoop/pom.xml": null,
            "parquet-hive-bundle/pom.xml": null,
            "parquet-hive/parquet-hive-binding/parquet-hive-0.10-binding/pom.xml": null,
            "parquet-hive/parquet-hive-binding/parquet-hive-0.12-binding/pom.xml": null,
            "parquet-hive/parquet-hive-binding/parquet-hive-binding-bundle/pom.xml": null,
            "parquet-hive/parquet-hive-binding/parquet-hive-binding-factory/pom.xml": null,
            "parquet-hive/parquet-hive-binding/parquet-hive-binding-interface/pom.xml": null,
            "parquet-hive/parquet-hive-binding/pom.xml": null,
            "parquet-hive/parquet-hive-storage-handler/pom.xml": null,
            "parquet-hive/pom.xml": null,
            "parquet-jackson/pom.xml": null,
            "parquet-pig-bundle/pom.xml": null,
            "parquet-pig/pom.xml": null,
            "parquet-protobuf/pom.xml": null,
            "parquet-scala/pom.xml": null,
            "parquet-scrooge/pom.xml": null,
            "parquet-thrift/pom.xml": null,
            "parquet-tools/pom.xml": null,
            "pom.xml": null
        }
    },
    "7680fae14c9f544d0585a7b150004a1e48fff53a": {
        "datetime": "2015-05-15T12:40:27-07:00",
        "summary": "PARQUET-254: Fixes exception message",
        "message": "PARQUET-254: Fixes exception message\n\n<!-- Reviewable:start -->\n[<img src=\"https://reviewable.io/review_button.png\" height=40 alt=\"Review on Reviewable\"/>](https://reviewable.io/reviews/apache/incubator-parquet-mr/174)\n<!-- Reviewable:end -->\n\nAuthor: Cheng Lian <lian@databricks.com>\n\nCloses #174 from liancheng/fix-exception-message and squashes the following commits:\n\ndb816c2 [Cheng Lian] Fixes exception message\n",
        "diff": {
            "parquet-avro/src/main/java/org/apache/parquet/avro/AvroSchemaConverter.java": [
                1,
                1
            ]
        }
    },
    "136c5ffe80e558a87cde01baebf823b06e3cbe75": {
        "datetime": "2015-05-15T12:41:15-07:00",
        "summary": "PARQUET-253: Fixes Javadoc of AvroSchemaConverter",
        "message": "PARQUET-253: Fixes Javadoc of AvroSchemaConverter\n\nGot confused by the original Javadoc at first and didn't realize `AvroSchemaConverter` is also capable to convert a Parquet schema to an Avro schema.\n\n<!-- Reviewable:start -->\n[<img src=\"https://reviewable.io/review_button.png\" height=40 alt=\"Review on Reviewable\"/>](https://reviewable.io/reviews/apache/incubator-parquet-mr/173)\n<!-- Reviewable:end -->\n\nAuthor: Cheng Lian <lian@databricks.com>\n\nCloses #173 from liancheng/avro-schema-converter-comment-fix and squashes the following commits:\n\n47b11ce [Cheng Lian] Fixes Javadoc of AvroSchemaConverter\n",
        "diff": {
            "parquet-avro/src/main/java/org/apache/parquet/avro/AvroSchemaConverter.java": [
                9,
                9
            ]
        }
    },
    "1dbcdf2e36043706957ed514f0f6e47452f3f841": {
        "datetime": "2015-05-15T12:47:54-07:00",
        "summary": "PARQUET-274: Updates URLs to link against the apache user instead of Parquet on github",
        "message": "PARQUET-274: Updates URLs to link against the apache user instead of Parquet on github\n\nAuthor: Ben Pence <bpence@twitter.com>\nAuthor: Ben Pence <github@benpence.com>\n\nThis patch had conflicts when merged, resolved by\nCommitter: Ryan Blue <blue@apache.org>\n\nCloses #192 from benpence/docs_url and squashes the following commits:\n\nc3cedf2 [Ben Pence] Reverts modification of wiki link in README\n80a0455 [Ben Pence] Updates project home link\n1588609 [Ben Pence] Fixes docs blob links to point to new path\n53e1ffe [Ben Pence] Reverts all pull request links to old repo's issues\n3bea34b [Ben Pence] Updates URLs to use the apache user instead of Parquet\n",
        "diff": {
            "README.md": null,
            "parquet-tools/README.md": null,
            "parquet_cascading.md": null
        }
    },
    "60edcf9df1bbe271b1414b04e914641937395d8a": {
        "datetime": "2015-05-15T13:07:14-07:00",
        "summary": "PARQUET-278 : enforce non empty group on MessageType level",
        "message": "PARQUET-278 : enforce non empty group on MessageType level\n\nAs columnar format, parquet currently does not support empty struct/group without leaves. We should throw when constructing an empty GroupType to give a clear message.\n\nAuthor: Tianshuo Deng <tdeng@twitter.com>\n\nCloses #195 from tsdeng/message_type_enforce_non_empty_group and squashes the following commits:\n\na286c58 [Tianshuo Deng] revert change to merge_parquet_pr\na09f6ba [Tianshuo Deng] fix test\nac63567 [Tianshuo Deng] fix tests\naa2633c [Tianshuo Deng] enforce non empty group on MessageType level\n",
        "diff": {
            "parquet-column/src/main/java/org/apache/parquet/schema/GroupType.java": [
                0,
                3
            ],
            "parquet-column/src/main/java/org/apache/parquet/schema/IncompatibleSchemaModificationException.java": [
                3,
                3
            ],
            "parquet-column/src/main/java/org/apache/parquet/schema/InvalidSchemaException.java": [
                0,
                31
            ],
            "parquet-column/src/test/java/org/apache/parquet/schema/TestMessageType.java": [
                0,
                14
            ],
            "parquet-pig/src/test/java/org/apache/parquet/pig/TestPigSchemaConverter.java": [
                1,
                6
            ],
            "parquet-thrift/src/main/java/org/apache/parquet/thrift/ThriftSchemaConverter.java": [
                1,
                1
            ]
        }
    },
    "a458e1a2f3cd1ccd692f1530b64d3143c9beda51": {
        "datetime": "2015-05-18T10:08:32-07:00",
        "summary": "PARQUET-243: Add Avro reflect support",
        "message": "PARQUET-243: Add Avro reflect support\n\nAuthor: Ryan Blue <blue@apache.org>\n\nCloses #165 from rdblue/PARQUET-243-add-avro-reflect and squashes the following commits:\n\na1a17b4 [Ryan Blue] PARQUET-243: Update for Tom's review comments.\n16584d1 [Ryan Blue] PARQUET-243: Fix AvroWriteSupport bug.\nfa4a9ec [Ryan Blue] PARQUET-243: Add reflect tests.\n4c50cd1 [Ryan Blue] PARQUET-243: Update write support for reflected objects.\nb50c482 [Ryan Blue] PARQUET-243: Update tests to run with new converters.\n0b7a333 [Ryan Blue] PARQUET-243: Use common AvroConverters where possible.\n2f6825d [Ryan Blue] PARQUET-243: Add reflect converters that behave more like Avro.\n98f10df [Ryan Blue] PARQUET-243: Add Avro compatible record materializer.\n",
        "diff": {
            "parquet-avro/pom.xml": null,
            "parquet-avro/src/main/java/org/apache/parquet/avro/AvroCompatRecordMaterializer.java": [
                0,
                46
            ],
            "parquet-avro/src/main/java/org/apache/parquet/avro/AvroConverters.java": [
                0,
                253
            ],
            "parquet-avro/src/main/java/org/apache/parquet/avro/AvroIndexedRecordConverter.java": [
                192,
                37
            ],
            "parquet-avro/src/main/java/org/apache/parquet/avro/AvroParquetOutputFormat.java": [
                2,
                15
            ],
            "parquet-avro/src/main/java/org/apache/parquet/avro/AvroParquetReader.java": [
                3,
                2
            ],
            "parquet-avro/src/main/java/org/apache/parquet/avro/AvroParquetWriter.java": [
                12,
                129
            ],
            "parquet-avro/src/main/java/org/apache/parquet/avro/AvroReadSupport.java": [
                15,
                39
            ],
            "parquet-avro/src/main/java/org/apache/parquet/avro/AvroRecordConverter.java": [
                0,
                827
            ],
            "parquet-avro/src/main/java/org/apache/parquet/avro/AvroRecordMaterializer.java": [
                4,
                3
            ],
            "parquet-avro/src/main/java/org/apache/parquet/avro/AvroWriteSupport.java": [
                21,
                215
            ],
            "parquet-avro/src/main/java/org/apache/parquet/avro/GenericDataSupplier.java": [
                0,
                28
            ],
            "parquet-avro/src/main/java/org/apache/parquet/avro/ParentValueContainer.java": [
                0,
                63
            ],
            "parquet-avro/src/main/java/org/apache/parquet/avro/ReflectDataSupplier.java": [
                0,
                29
            ],
            "parquet-avro/src/test/java/org/apache/parquet/avro/TestBackwardCompatibility.java": [
                1,
                17
            ],
            "parquet-avro/src/test/java/org/apache/parquet/avro/TestReadWrite.java": [
                11,
                30
            ],
            "parquet-avro/src/test/java/org/apache/parquet/avro/TestReflectInputOutputFormat.java": [
                0,
                495
            ],
            "parquet-avro/src/test/java/org/apache/parquet/avro/TestReflectReadWrite.java": [
                0,
                215
            ],
            "parquet-avro/src/test/java/org/apache/parquet/avro/TestSpecificReadWrite.java": [
                13,
                32
            ],
            "parquet-column/pom.xml": null,
            "pom.xml": null
        }
    },
    "181affd5c937755f54ff31ef056a6ec091e95f51": {
        "datetime": "2015-05-19T11:26:07-07:00",
        "summary": "PARQUET-164: Add a counter and increment when parquet memory manager kicks in",
        "message": "PARQUET-164: Add a counter and increment when parquet memory manager kicks in\n\nAdd a counter for writers, and increment it when memory manager scaling down row group size.\n\nHive could use this counter to warn users.\n\nAuthor: dongche1 <dong1.chen@intel.com>\nAuthor: dongche <dong1.chen@intel.com>\nAuthor: root <root@bdpe15.sh.intel.com>\n\nCloses #120 from dongche/PARQUET-164 and squashes the following commits:\n\n9bcb1ba [dongche] Remove stats, and change returned callbacks map unmodifiable\n3cbbeb9 [dongche] Merge remote branch 'upstream1/master' into PARQUET-164\nbdef233 [dongche] Merge remote branch 'upstream1/master' into PARQUET-164\n780be6d [root] revert change about callable and address comments\n11f9163 [dongche1] Merge remote branch 'upstream/master' into PARQUET-164\n55549a5 [dongche1] Use callable and strict registerScallCallBack method.\n74054aa [dongche1] Use Runnable as a generic callback\n8782a02 [dongche1] Add a callback mechanism instead of shims. And rebase trunk\nb138b7f [dongche1] Merge remote branch 'upstream/master' into PARQUET-164\n93a4678 [dongche1] PARQUET-164: Add a counter and increment when parquet memory manager kicks in\n",
        "diff": {
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/MemoryManager.java": [
                1,
                41
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ParquetOutputFormat.java": [
                1,
                1
            ],
            "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/TestMemoryManager.java": [
                1,
                27
            ]
        }
    },
    "ded56ffd598e41e32817f6c1b091595fe7122e8b": {
        "datetime": "2015-05-19T19:36:04-07:00",
        "summary": "PARQUET-287: Keep a least 1 column from union members when projecting thrift unions",
        "message": "PARQUET-287: Keep a least 1 column from union members when projecting thrift unions\n\nCurrently, the projection API allows you to select only some \"kinds\" of a union, or to drop a required union entirely. This becomes an issue when assembling these records, as they will be appear to be unions of an unknown type (how do you coerce an empty struct into a union?). The way this case is handled for primitives is by supplying a default value (like 0, or null). However, with a union, you have to choose what \"kind\" of the union it will act as, and in the interest of not being misleading, this PR reads one column to figure out what the correct \"kind\" is.\n\nIn the future, the better solution is to filter these records out -- a projection is really a request for a filter in this case. But for now, this should get us correctness without involving the filter API.\n\nI think this PR needs some more tests before merging, but I wanted to get it out and get some feedback now.\n\nI also refactored how ThriftSchemaVisitor works to not be stateful, by explicitly passing state through the recursion -- this makes it much easier to reason about.\n\n*edit* This PR also includes a fix for PARQUET-275 because I encountered it during testing.\n\n*edit 2* This PR also includes a fix for PARQUET-283\n\nAuthor: Alex Levenson <alexlevenson@twitter.com>\n\nCloses #189 from isnotinvain/alexlevenson/project-union and squashes the following commits:\n\nc710702 [Alex Levenson] Avoid instantiating (unused) empty group type\nc43a44c [Alex Levenson] Merge branch 'master' into alexlevenson/project-union\nd62ee8c [Alex Levenson] Merge branch 'master' into alexlevenson/project-union\ndf51f41 [Alex Levenson] Fix tests\n4d3f825 [Alex Levenson] Address review comments\n6dd95f5 [Alex Levenson] Update tests to reflect changes\nd7cee7e [Alex Levenson] Add tests for nested maps\n9c34b20 [Alex Levenson] Keep a sentinel column in map values\n53e5580 [Alex Levenson] Remove debug println\nc525a65 [Alex Levenson] update docs to reflect set projection rules\naefb637 [Alex Levenson] Do not allow partial projection of keys or set elements\n8b4e791 [Alex Levenson] Add tests for maps of unions\n35de282 [Alex Levenson] Add test for list<union>\n098630f [Alex Levenson] Merge branch 'master' into alexlevenson/project-union\n77cc9e9 [Alex Levenson] Add license header\n63b80fd [Alex Levenson] more clean up\n6341747 [Alex Levenson] Clean up ConvertedField\ndcd3ea9 [Alex Levenson] Merge branch 'master' into alexlevenson/project-union\n9ce4781 [Alex Levenson] Some cleanup and comments\n6964837 [Alex Levenson] Keep one sentinel column in projected unions that cannot be dropped entirely\n37a9bef [Alex Levenson] Clean up visitor pattern for thrift types\n",
        "diff": {
            "parquet-thrift/src/main/java/org/apache/parquet/thrift/ConvertedField.java": [
                0,
                167
            ],
            "parquet-thrift/src/main/java/org/apache/parquet/thrift/KeepOnlyFirstPrimitiveFilter.java": [
                0,
                44
            ],
            "parquet-thrift/src/main/java/org/apache/parquet/thrift/ThriftSchemaConvertVisitor.java": [
                190,
                287
            ],
            "parquet-thrift/src/main/java/org/apache/parquet/thrift/ThriftSchemaConverter.java": [
                7,
                4
            ],
            "parquet-thrift/src/main/java/org/apache/parquet/thrift/projection/FieldProjectionFilter.java": [
                1,
                2
            ],
            "parquet-thrift/src/main/java/org/apache/parquet/thrift/projection/FieldsPath.java": [
                8,
                10
            ],
            "parquet-thrift/src/main/java/org/apache/parquet/thrift/projection/amend/DefaultEventsVisitor.java": [
                16,
                29
            ],
            "parquet-thrift/src/main/java/org/apache/parquet/thrift/projection/amend/DefaultProtocolEventsGenerator.java": [
                1,
                1
            ],
            "parquet-thrift/src/main/java/org/apache/parquet/thrift/struct/CompatibilityChecker.java": [
                29,
                42
            ],
            "parquet-thrift/src/main/java/org/apache/parquet/thrift/struct/ThriftType.java": [
                82,
                39
            ],
            "parquet-thrift/src/test/java/org/apache/parquet/hadoop/thrift/TestParquetToThriftReadWriteAndProjection.java": [
                0,
                140
            ],
            "parquet-thrift/src/test/java/org/apache/parquet/thrift/TestThriftSchemaConverter.java": [
                14,
                81
            ],
            "parquet-thrift/src/test/java/org/apache/parquet/thrift/TestThriftSchemaConverterProjectUnion.java": [
                0,
                480
            ],
            "parquet-thrift/src/test/java/org/apache/parquet/thrift/projection/TestFieldsPath.java": [
                42,
                38
            ],
            "parquet-thrift/src/test/thrift/compat.thrift": null,
            "parquet_cascading.md": null
        }
    },
    "8769d0f2cc4b7555dc025b7c0e49a81346a1e2dd": {
        "datetime": "2015-05-21T16:18:03-07:00",
        "summary": "PARQUET-262: Restore semver checks.",
        "message": "PARQUET-262: Restore semver checks.\n\nBecause 1.6.0 to 1.7.0 was a breaking rename, semver was turned off\nuntil the 1.7.0 artifacts were released. Now that they are available,\nthe check needs to be restored.\n\nThere were already 2 breaking changes that are fixed by this commit:\n* A field in AvroReadSupport was made final\n* An accessor method in ThriftSchemaConvertVisitor was removed\n\nAuthor: Ryan Blue <blue@apache.org>\n\nCloses #200 from rdblue/PARQUET-262-restore-semver and squashes the following commits:\n\n09aeaf4 [Ryan Blue] PARQUET-262: Restore semver checks.\n",
        "diff": {
            "parquet-avro/src/main/java/org/apache/parquet/avro/AvroReadSupport.java": [
                1,
                2
            ],
            "parquet-thrift/src/main/java/org/apache/parquet/thrift/ThriftSchemaConvertVisitor.java": [
                0,
                8
            ],
            "pom.xml": null
        }
    },
    "dd92a9db6b288def8159f30336f6793239882c9d": {
        "datetime": "2015-05-26T14:31:51-07:00",
        "summary": "PARQUET-223: Add builders for MAP and LIST types",
        "message": "PARQUET-223: Add builders for MAP and LIST types\n\nAs of now, Parquet does not provide builders for Maps and Lists. This leaves margin for user errors. Having Map and List builders will make it easier for users to build these types.\n\nAuthor: asingh <asingh@cloudera.com>\n\nCloses #148 from SinghAsDev/map and squashes the following commits:\n\ncc7da06 [asingh] Pull changes made by Ryan\n825b5b8 [asingh] Remove non-functional changes\nbec675b [asingh] Remove required and optional version of methods that take pre-built Type\n6dcaa78 [asingh] Address review comments and some clean up\n544d1e4 [asingh] Add key(Type) and value(Type) variants to MapBuilder\nf2a1697 [asingh] Add listKey support\n68c06f5 [asingh] Add support for null value in MapBuilder\nf31f2b0 [asingh] Add more tests to cover list and map value types in map builder\nf035439 [asingh] Add Map and List value types to map\n1afa2c7 [asingh] Address review comments\n484495b [asingh] PARQUET-223: Add builders for MAP and LIST types\n",
        "diff": {
            "parquet-column/src/main/java/org/apache/parquet/schema/Types.java": [
                89,
                789
            ],
            "parquet-column/src/test/java/org/apache/parquet/schema/TestTypeBuilders.java": [
                0,
                769
            ]
        }
    },
    "213e952df6677b44690dccfb8b2cf4d790a2551d": {
        "datetime": "2015-05-26T16:40:25-07:00",
        "summary": "[maven-release-plugin] prepare release parquet-1.8.0rc1",
        "message": "[maven-release-plugin] prepare release parquet-1.8.0rc1\n",
        "diff": {
            "parquet-avro/pom.xml": null,
            "parquet-benchmarks/pom.xml": null,
            "parquet-cascading/pom.xml": null,
            "parquet-column/pom.xml": null,
            "parquet-common/pom.xml": null,
            "parquet-encoding/pom.xml": null,
            "parquet-generator/pom.xml": null,
            "parquet-hadoop-bundle/pom.xml": null,
            "parquet-hadoop/pom.xml": null,
            "parquet-hive-bundle/pom.xml": null,
            "parquet-hive/parquet-hive-binding/parquet-hive-0.10-binding/pom.xml": null,
            "parquet-hive/parquet-hive-binding/parquet-hive-0.12-binding/pom.xml": null,
            "parquet-hive/parquet-hive-binding/parquet-hive-binding-bundle/pom.xml": null,
            "parquet-hive/parquet-hive-binding/parquet-hive-binding-factory/pom.xml": null,
            "parquet-hive/parquet-hive-binding/parquet-hive-binding-interface/pom.xml": null,
            "parquet-hive/parquet-hive-binding/pom.xml": null,
            "parquet-hive/parquet-hive-storage-handler/pom.xml": null,
            "parquet-hive/pom.xml": null,
            "parquet-jackson/pom.xml": null,
            "parquet-pig-bundle/pom.xml": null,
            "parquet-pig/pom.xml": null,
            "parquet-protobuf/pom.xml": null,
            "parquet-scala/pom.xml": null,
            "parquet-scrooge/pom.xml": null,
            "parquet-thrift/pom.xml": null,
            "parquet-tools/pom.xml": null,
            "pom.xml": null
        }
    },
    "33a2202603e27132fdfff21c902cf07b0ff12073": {
        "datetime": "2015-05-26T16:40:40-07:00",
        "summary": "[maven-release-plugin] prepare for next development iteration",
        "message": "[maven-release-plugin] prepare for next development iteration\n",
        "diff": {
            "parquet-avro/pom.xml": null,
            "parquet-benchmarks/pom.xml": null,
            "parquet-cascading/pom.xml": null,
            "parquet-column/pom.xml": null,
            "parquet-common/pom.xml": null,
            "parquet-encoding/pom.xml": null,
            "parquet-generator/pom.xml": null,
            "parquet-hadoop-bundle/pom.xml": null,
            "parquet-hadoop/pom.xml": null,
            "parquet-hive-bundle/pom.xml": null,
            "parquet-hive/parquet-hive-binding/parquet-hive-0.10-binding/pom.xml": null,
            "parquet-hive/parquet-hive-binding/parquet-hive-0.12-binding/pom.xml": null,
            "parquet-hive/parquet-hive-binding/parquet-hive-binding-bundle/pom.xml": null,
            "parquet-hive/parquet-hive-binding/parquet-hive-binding-factory/pom.xml": null,
            "parquet-hive/parquet-hive-binding/parquet-hive-binding-interface/pom.xml": null,
            "parquet-hive/parquet-hive-binding/pom.xml": null,
            "parquet-hive/parquet-hive-storage-handler/pom.xml": null,
            "parquet-hive/pom.xml": null,
            "parquet-jackson/pom.xml": null,
            "parquet-pig-bundle/pom.xml": null,
            "parquet-pig/pom.xml": null,
            "parquet-protobuf/pom.xml": null,
            "parquet-scala/pom.xml": null,
            "parquet-scrooge/pom.xml": null,
            "parquet-thrift/pom.xml": null,
            "parquet-tools/pom.xml": null,
            "pom.xml": null
        }
    },
    "4b5cda5a2c6ca613db5129d50ffffce2604ad9eb": {
        "datetime": "2015-06-01T14:21:53-07:00",
        "summary": "PARQUET-151: Skip writing _metadata file in case of no footers since schema cannot be determined.",
        "message": "PARQUET-151: Skip writing _metadata file in case of no footers since schema cannot be determined.\n\nThis fixes npe seen during mergeFooters in such a case.\n For this scenario onus of writing any summary files lies with the caller (It might have some global schema available) So for example spark does it when persisting empty RDD.\n\nAuthor: Yash Datta <Yash.Datta@guavus.com>\n\nCloses #205 from saucam/footer_bug and squashes the following commits:\n\nb2b3ddf [Yash Datta] PARQUET-151: Skip writing _metadata file in case of no footers since schema cannot be determined. This fixes npe seen during mergeFooters in such a case.              For this scenario onus of writing any summary files lies with the caller (It might have some global schema available)\n",
        "diff": {
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ParquetOutputCommitter.java": [
                0,
                5
            ]
        }
    },
    "d6f082b9be5d507ff60c6bc83a179cc44015ab97": {
        "datetime": "2015-06-01T17:46:29-07:00",
        "summary": "PARQUET-285: Implement 3-level lists in Avro",
        "message": "PARQUET-285: Implement 3-level lists in Avro\n\nThis includes the write-side the changes from #83 that implement the 3-level list structure for parquet-avro. The old commit was https://github.com/rdblue/parquet-mr/commit/3589a7367c829b9eabc36b2e2e1cab31685415eb.\n\nAuthor: Ryan Blue <blue@apache.org>\n\nCloses #198 from rdblue/PARQUET-285-avro-nested-lists and squashes the following commits:\n\n3498571 [Ryan Blue] PARQUET-285: Fix review issues.\n67ed2f4 [Ryan Blue] PARQUET-285: Add tests for new list write behavior.\n6ec9120 [Ryan Blue] PARQUET-285: Implement nested type rules for Avro.\n109111f [Ryan Blue] PARQUET-285: Add a better conversion pattern for lists.\n",
        "diff": {
            "parquet-avro/src/main/java/org/apache/parquet/avro/AvroIndexedRecordConverter.java": [
                1,
                2
            ],
            "parquet-avro/src/main/java/org/apache/parquet/avro/AvroParquetWriter.java": [
                2,
                10
            ],
            "parquet-avro/src/main/java/org/apache/parquet/avro/AvroRecordConverter.java": [
                1,
                1
            ],
            "parquet-avro/src/main/java/org/apache/parquet/avro/AvroSchemaConverter.java": [
                3,
                14
            ],
            "parquet-avro/src/main/java/org/apache/parquet/avro/AvroWriteSupport.java": [
                168,
                285
            ],
            "parquet-avro/src/test/java/org/apache/parquet/avro/TestAvroSchemaConverter.java": [
                25,
                169
            ],
            "parquet-avro/src/test/java/org/apache/parquet/avro/TestReadWrite.java": [
                16,
                69
            ],
            "parquet-avro/src/test/java/org/apache/parquet/avro/TestReadWriteOldBehavior.java": [
                0,
                588
            ],
            "parquet-avro/src/test/resources/all.avsc": null,
            "parquet-avro/src/test/resources/allFromParquet.avsc": null,
            "parquet-avro/src/test/resources/allFromParquetOldBehavior.avsc": null,
            "parquet-column/src/main/java/org/apache/parquet/schema/ConversionPatterns.java": [
                0,
                28
            ]
        }
    },
    "918609f2cc4e4de95445ce4fdd7dc952b9625017": {
        "datetime": "2015-06-04T10:45:50-07:00",
        "summary": "PARQUET-286: Update String support to match upstream Avro.",
        "message": "PARQUET-286: Update String support to match upstream Avro.\n\nThis adds getStringableClass, which determines what String\nrepresentation upstream Avro would use. Specific and reflect will use an\nalternative String class if java-class is set that is instantiated using\na constructor that takes a String. Otherwise, reflect will always use\nString and both specific and generic will use Utf8 or String depending\non whether avro.java.string is set to \"string\".\n\nThe new string representations required two new converters: one for Utf8\nand one for stringable classes (those with constructors that take a\nsingle String). The converters have also been refactored so that all\nbinary converters now implement dictionary support.\n\nAuthor: Ryan Blue <blue@apache.org>\n\nCloses #201 from rdblue/PARQUET-286-avro-utf8-support and squashes the following commits:\n\nbeb5a44 [Ryan Blue] PARQUET-286: Add tests, support for stringable map keys.\n0e9240f [Ryan Blue] PARQUET-286: Update string support to match upstream Avro.\n",
        "diff": {
            "parquet-avro/pom.xml": null,
            "parquet-avro/src/main/java/org/apache/parquet/avro/AvroConverters.java": [
                158,
                218
            ],
            "parquet-avro/src/main/java/org/apache/parquet/avro/AvroRecordConverter.java": [
                18,
                94
            ],
            "parquet-avro/src/test/avro/stringBehavior.avsc": null,
            "parquet-avro/src/test/java/org/apache/parquet/avro/TestBackwardCompatibility.java": [
                1,
                2
            ],
            "parquet-avro/src/test/java/org/apache/parquet/avro/TestReadWrite.java": [
                10,
                17
            ],
            "parquet-avro/src/test/java/org/apache/parquet/avro/TestReadWriteOldBehavior.java": [
                12,
                18
            ],
            "parquet-avro/src/test/java/org/apache/parquet/avro/TestReflectReadWrite.java": [
                10,
                11
            ],
            "parquet-avro/src/test/java/org/apache/parquet/avro/TestStringBehavior.java": [
                0,
                363
            ]
        }
    },
    "2e62764c0c386632e87ee8d12d0505848df1015e": {
        "datetime": "2015-06-05T10:32:54-07:00",
        "summary": "PARQUET-266: Add support for lists of primitives to Pig schema converter",
        "message": "PARQUET-266: Add support for lists of primitives to Pig schema converter\n\nAuthor: Christian Rolf <christian.rolf@adello.com>\n\nCloses #209 from ccrolf/PigPrimitivesList and squashes the following commits:\n\n5a69273 [Christian Rolf] Add support for lists of primitives to Pig schema converter\n",
        "diff": {
            "parquet-pig/src/main/java/org/apache/parquet/pig/PigSchemaConverter.java": [
                2,
                7
            ],
            "parquet-pig/src/test/java/org/apache/parquet/pig/TestPigSchemaConverter.java": [
                0,
                33
            ]
        }
    },
    "75f07158a6ac5684f9fde79532d738eb4d2a7599": {
        "datetime": "2015-06-16T09:47:19-07:00",
        "summary": "PARQUET-265: Update POM for Parquet TLP.",
        "message": "PARQUET-265: Update POM for Parquet TLP.\n",
        "diff": {
            "pom.xml": null
        }
    },
    "3052d4ebf75495d33867ff2327bebdb4f41c61a6": {
        "datetime": "2015-06-16T09:49:32-07:00",
        "summary": "PARQUET-178: Remove SLF4J META-INF from binary artifacts.",
        "message": "PARQUET-178: Remove SLF4J META-INF from binary artifacts.\n\nAuthor: Ryan Blue <blue@apache.org>\n\nCloses #24 from rdblue/PARQUET-178-remove-slf4j-meta-inf and squashes the following commits:\n\n379fa0e [Ryan Blue] PARQUET-178: Remove SLF4J META-INF from binary artifacts.\n",
        "diff": {
            "pom.xml": null
        }
    },
    "4590f14e97beb6d10ffb7b5dd312c632af155ed3": {
        "datetime": "2015-06-17T09:17:23-07:00",
        "summary": "PARQUET-246: fix incomplete state reset in DeltaByteArrayWriter.reset()",
        "message": "PARQUET-246: fix incomplete state reset in DeltaByteArrayWriter.reset()\n\n...thod\n\nAuthor: Alex Levenson <alexlevenson@twitter.com>\nAuthor: Konstantin Shaposhnikov <Konstantin.Shaposhnikov@sc.com>\nAuthor: kostya-sh <kostya-sh@users.noreply.github.com>\n\nCloses #171 from kostya-sh/PARQUET-246 and squashes the following commits:\n\n75950c5 [kostya-sh] Merge pull request #1 from isnotinvain/PR-171\na718309 [Konstantin Shaposhnikov] Merge remote-tracking branch 'refs/remotes/origin/master' into PARQUET-246\n0367588 [Alex Levenson] Add regression test for PR-171\n94e8fda [Alex Levenson] Merge branch 'master' into PR-171\n0a9ac9f [Konstantin Shaposhnikov] [PARQUET-246] bugfix: reset all DeltaByteArrayWriter state in reset() method\n",
        "diff": {
            "parquet-column/src/main/java/org/apache/parquet/column/values/deltastrings/DeltaByteArrayWriter.java": [
                0,
                1
            ],
            "parquet-column/src/test/java/org/apache/parquet/column/values/deltastrings/TestDeltaByteArray.java": [
                15,
                24
            ]
        }
    },
    "faf542134df2bec8f0334c819d44464f1aab6696": {
        "datetime": "2015-06-17T16:11:03-07:00",
        "summary": "PARQUET-263: Release changes from parquet-1.7.0 branch",
        "message": "PARQUET-263: Release changes from parquet-1.7.0 branch\n\nThese are the additional changes needed to build the 1.7.0 RC. No functional changes to the library, just configuration in the POM, release scripts, and the addition to the changelog.\n\nAuthor: Ryan Blue <blue@apache.org>\n\nCloses #196 from rdblue/PARQUET-263-release-changes-from-1.7.0 and squashes the following commits:\n\nc02f565 [Ryan Blue] PARQUET-263: Update release scripts for TLP, add maven.\nc0554ff [Ryan Blue] PARQUET-263: Update pom to use Apache maven release config.\ndc4945b [Ryan Blue] PARQUET-263: Update changelog.\n",
        "diff": {
            "CHANGES.md": null,
            "dev/prepare-release.sh": null,
            "dev/source-release.sh": null,
            "pom.xml": null
        }
    },
    "5f48f19ec460a05e4eddc841e5eb436f0a8dc97e": {
        "datetime": "2015-06-17T16:24:27-07:00",
        "summary": "PARQUET-309: remove unnecessary compile dependency on parquet-generator",
        "message": "PARQUET-309: remove unnecessary compile dependency on parquet-generator\n\nparquet-generator is build-time dependency only and shouldn't be listed in\npom.xml dependencies section.\n\nAuthor: Konstantin Shaposhnikov <Konstantin.Shaposhnikov@sc.com>\n\nCloses #214 from kostya-sh/PARQUET-309 and squashes the following commits:\n\n9d224c1 [Konstantin Shaposhnikov] PARQUET-309: remove unnecessary compile dependency on parquet-generator\n",
        "diff": {
            "parquet-column/pom.xml": null,
            "parquet-encoding/pom.xml": null
        }
    },
    "1c160685840dc2082d94839a41b800821d934f5d": {
        "datetime": "2015-06-18T11:35:28-07:00",
        "summary": "PARQUET-264: Remove remaining references to parquet being an incubator project",
        "message": "PARQUET-264: Remove remaining references to parquet being an incubator project\n\nDo we need a new DISCLAIMER file, or can we just rm it?\n\nAuthor: Alex Levenson <alexlevenson@twitter.com>\n\nCloses #216 from isnotinvain/alexlevenson/rm-incubator-refs and squashes the following commits:\n\nb300a04 [Alex Levenson] Update pick me up link\n9bc3ba5 [Alex Levenson] fix one more travis link\n6debacd [Alex Levenson] Consolidate contributing + readme files, address feedback from Ryan\n9e1fff3 [Alex Levenson] Remove remaining references to parquet being an incubator project\n",
        "diff": {
            "CONTRIBUTING.md": null,
            "DISCLAIMER": null,
            "README.md": null,
            "dev/README.md": null
        }
    },
    "ad443210312d2420efef6d03a0296d71e71feb22": {
        "datetime": "2015-06-18T16:58:45-07:00",
        "summary": "PARQUET-297: generate Version class using parquet-generator",
        "message": "PARQUET-297: generate Version class using parquet-generator\n\nAuthor: Konstantin Shaposhnikov <Konstantin.Shaposhnikov@sc.com>\nAuthor: Konstantin Shaposhnikov <k.shaposhnikov@gmail.com>\n\nCloses #213 from kostya-sh/PARQUET-297_2 and squashes the following commits:\n\nddb469a [Konstantin Shaposhnikov] add comment about paddedByteCountFromBits coming from ByteUtils\n6b47b04 [Konstantin Shaposhnikov] Change VersionGenerator to generate main() method\n10d0b38 [Konstantin Shaposhnikov] PARQUET-297: generate Version class using parquet-generator\n11d29bc [Konstantin Shaposhnikov] parquet-generator: remove dependency on parquet-common\n",
        "diff": {
            "parquet-common/pom.xml": null,
            "parquet-common/src/main/java/org/apache/parquet/Version.java": [
                103,
                0
            ],
            "parquet-generator/pom.xml": null,
            "parquet-generator/src/main/java/org/apache/parquet/encoding/bitpacking/ByteBasedBitPackingGenerator.java": [
                3,
                6
            ],
            "parquet-generator/src/main/java/org/apache/parquet/version/Generator.java": [
                0,
                28
            ],
            "parquet-generator/src/main/java/org/apache/parquet/version/VersionGenerator.java": [
                0,
                83
            ],
            "parquet-generator/src/main/resources/parquet-version.properties": null
        }
    },
    "079bcd0339f30343c01c5fd3d5521be4b822d30f": {
        "datetime": "2015-06-18T17:50:28-07:00",
        "summary": "PARQUET-297: Tests for PR 213 (Version generator)",
        "message": "PARQUET-297: Tests for PR 213 (Version generator)\n\nAdds tests for #213\n\nHow's this look @rdblue @kostya-sh ?\n\nAuthor: Alex Levenson <alexlevenson@twitter.com>\n\nCloses #218 from isnotinvain/tests-for-pr-213 and squashes the following commits:\n\n8ee996b [Alex Levenson] Fix group indexes off by 1\nb239a2a [Alex Levenson] Add license header :p\n38fc78d [Alex Levenson] Add test for Version generator\n",
        "diff": {
            "parquet-common/pom.xml": null,
            "parquet-common/src/test/java/org/apache/parquet/VersionTest.java": [
                0,
                62
            ],
            "pom.xml": null
        }
    },
    "29283b775291bf03cd9a7e1aaa496faaa5757578": {
        "datetime": "2015-06-22T12:37:37-07:00",
        "summary": "PARQUET-314: Fix broken equals implementations",
        "message": "PARQUET-314: Fix broken equals implementations\n\nAuthor: Nezih Yigitbasi <nyigitbasi@netflix.com>\n\nCloses #223 from nezihyigitbasi/parquet-fixes and squashes the following commits:\n\n5279e60 [Nezih Yigitbasi] Override Object.equals properly\n",
        "diff": {
            "parquet-column/src/main/java/org/apache/parquet/column/ColumnDescriptor.java": [
                2,
                7
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/statistics/Statistics.java": [
                4,
                11
            ]
        }
    },
    "89321a2dee438328e75a11954e972175c78f0a2a": {
        "datetime": "2015-06-22T14:28:42-07:00",
        "summary": "PARQUET-311: Fix NPE when debug logging metadata",
        "message": "PARQUET-311: Fix NPE when debug logging metadata\n\nFixes the issue reported at https://issues.apache.org/jira/browse/PARQUET-311\n\nAuthor: Nezih Yigitbasi <nyigitbasi@netflix.com>\n\nCloses #221 from nezihyigitbasi/debug-log-fix and squashes the following commits:\n\n59129ed [Nezih Yigitbasi] PARQUET-311: Fix NPE when debug logging metadata\n",
        "diff": {
            "parquet-column/src/main/java/org/apache/parquet/column/statistics/BinaryStatistics.java": [
                2,
                2
            ],
            "parquet-hadoop/src/test/java/org/apache/parquet/format/converter/TestParquetMetadataConverter.java": [
                0,
                31
            ]
        }
    },
    "412ab9669810921d04f9feabfbeafa906d4de506": {
        "datetime": "2015-06-22T17:11:27-07:00",
        "summary": "PARQUET-306: Add row group alignment",
        "message": "PARQUET-306: Add row group alignment\n\nThis adds `AlignmentStrategy` to the `ParquetFileWriter` that can alter the position of row groups and recommend a target size for the next row group. There are two strategies: `NoAlignment` and `PaddingAlignment`. Padding alignment is used for HDFS and no alignment is used for all other file systems. When HDFS-3689 is available, we can add a strategy to use that.\n\nThe amount of padding is controlled by a threshold between 0 and 1 that controls the fraction of the row group size that can be padded. This is interpreted as the maximum amount of padding that is acceptable, in terms of the row group size. For example, setting this to 5% will write padding when the bytes left in a HDFS block are less than 5% of the row group size. This defaults to 0%, which prevents padding from being added and matches the current behavior. The threshold is controlled by a new OutputFormat configuration property, `parquet.writer.padding-thresh`.\n\nAuthor: Ryan Blue <blue@apache.org>\n\nCloses #211 from rdblue/PARQUET-306-row-group-alignment and squashes the following commits:\n\n0137ddf [Ryan Blue] PARQUET-306: Add MR test with padding.\n6ce3f08 [Ryan Blue] PARQUET-306: Add parquet.writer.max-padding setting.\nf1dc659 [Ryan Blue] PARQUET-306: Base next row group size on bytes remaining.\nc6a3e97 [Ryan Blue] PARQUET-306: Add AlignmentStrategy to ParquetFileWriter.\n",
        "diff": {
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/InternalParquetRecordWriter.java": [
                8,
                12
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ParquetFileWriter.java": [
                18,
                168
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ParquetOutputFormat.java": [
                1,
                25
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ParquetWriter.java": [
                1,
                5
            ],
            "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/TestInputOutputFormatWithPadding.java": [
                0,
                216
            ],
            "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/TestParquetFileWriter.java": [
                51,
                268
            ]
        }
    },
    "46448e934250705b6ebd6f21caa09698d611dbfd": {
        "datetime": "2015-06-24T13:58:04-07:00",
        "summary": "PARQUET-201: Fix ValidTypeMap being overly strict with respect to OriginalTypes",
        "message": "PARQUET-201: Fix ValidTypeMap being overly strict with respect to OriginalTypes\n\nAuthor: Alex Levenson <alexlevenson@twitter.com>\n\nCloses #219 from isnotinvain/alexlevenson/PARQUET-201 and squashes the following commits:\n\n1cd8b58 [Alex Levenson] Merge branch 'master' into alexlevenson/PARQUET-201\n1d83e13 [Alex Levenson] Fix ValidTypeMap being overly strict with respect to OriginalTypes\n",
        "diff": {
            "parquet-column/src/main/java/org/apache/parquet/filter2/predicate/PrimitiveToBoxedClass.java": [
                0,
                50
            ],
            "parquet-column/src/main/java/org/apache/parquet/filter2/predicate/SchemaCompatibilityValidator.java": [
                11,
                2
            ],
            "parquet-column/src/main/java/org/apache/parquet/filter2/predicate/ValidTypeMap.java": [
                73,
                23
            ],
            "parquet-column/src/test/java/org/apache/parquet/filter2/predicate/TestSchemaCompatibilityValidator.java": [
                1,
                1
            ],
            "parquet-column/src/test/java/org/apache/parquet/filter2/predicate/TestValidTypeMap.java": [
                23,
                11
            ]
        }
    },
    "5c2ba72f9b4897d4441eff34ff0591e74a1d94bb": {
        "datetime": "2015-06-24T16:02:30-07:00",
        "summary": "PARQUET-284: Clean up ParquetMetadataConverter",
        "message": "PARQUET-284: Clean up ParquetMetadataConverter\n\nmakes all method static, removes unused thread-unsafe cache, etc.\n\nTurns out the \"cache\" was only read from *after* rebuilding what needed to be cached... so no performance gain there (and no loss by getting rid of it)\n\nHowever, I don't know if this will fix the issue mentioned in PARQUET-284, I don't think concurrent access to a HashMap will cause deadlock, it would just cause undefined behavior in reads or maybe ConcurrentModificationException\n\nUPDATE: I'm wrong, it can cause an infinite loop so this should fix the issue https://gist.github.com/rednaxelafx/1081908\n\nUPDATE2: Put the cache back in, made it static + thread safe\n\nAuthor: Alex Levenson <alexlevenson@twitter.com>\n\nCloses #220 from isnotinvain/alexlevenson/PARQUET-284 and squashes the following commits:\n\n4797b48 [Alex Levenson] Fix merge conflict issue\n8ff5775 [Alex Levenson] Merge branch 'master' into alexlevenson/PARQUET-284\nccd4776 [Alex Levenson] add encoding cache back in\n9ea5a5f [Alex Levenson] Clean up ParquetMetadataConverter: make all method static, remove unused thread-unsafe cache\n",
        "diff": {
            "parquet-hadoop/src/main/java/org/apache/parquet/format/converter/ParquetMetadataConverter.java": [
                61,
                67
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ColumnChunkPageWriteStore.java": [
                4,
                2
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ParquetFileReader.java": [
                9,
                7
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ParquetFileWriter.java": [
                6,
                4
            ],
            "parquet-hadoop/src/test/java/org/apache/parquet/format/converter/TestParquetMetadataConverter.java": [
                17,
                50
            ]
        }
    },
    "cb04562742688f8a444a52c90b2183c4be528be6": {
        "datetime": "2015-06-25T09:40:21-07:00",
        "summary": "PARQUET-248: Add ParquetWriter.Builder.",
        "message": "PARQUET-248: Add ParquetWriter.Builder.\n\nThis refactors the builder recently added to parquet-avro so that it can\nbe used by all object models. The Builder class is abstract and\nimplementations should extend it.\n\nThis changes the API slightly from AvroParquetWriter, renaming\nwithBlockSize to withRowGroupSize. The Avro builder has not been\nreleased so this isn't a breaking change.\n\nAuthor: Ryan Blue <blue@apache.org>\n\nCloses #199 from rdblue/PARQUET-248-add-parquet-writer-builder and squashes the following commits:\n\na1a25ee [Ryan Blue] PARQUET-248: Add write mode and max padding to writer builder.\n622af4c [Ryan Blue] PARQUET-248: Add ParquetWriter.Builder.\n",
        "diff": {
            "parquet-avro/src/main/java/org/apache/parquet/avro/AvroParquetWriter.java": [
                65,
                10
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ParquetWriter.java": [
                28,
                239
            ]
        }
    },
    "1f3e72fa069536ae20f37b29575288ff65e66803": {
        "datetime": "2015-06-25T21:48:00-07:00",
        "summary": "PARQUET-317: Fix writeMetadataFile crash when a relative root path is used",
        "message": "PARQUET-317: Fix writeMetadataFile crash when a relative root path is used\n\nThis commit ensures the fully-qualified path is used prior to calling mergeFooters(..).\n\nAuthor: Steven She <steven@canopylabs.com>\n\nCloses #228 from stevencanopy/relative-metadata-path and squashes the following commits:\n\n988772b [Steven She] use outputPath.getFileSystem(...) to get the FS for the path\n1cea508 [Steven She] PARQUET-317: Fix writeMetadataFile crash when a relative root path is used\n",
        "diff": {
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ParquetFileWriter.java": [
                1,
                1
            ],
            "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/TestParquetFileWriter.java": [
                0,
                27
            ]
        }
    },
    "e6ee42e9bca274b59c42f134f4c71d14ab6ed8a6": {
        "datetime": "2015-06-30T11:00:37-07:00",
        "summary": "PARQUET-316: Fix the benchmark module",
        "message": "PARQUET-316: Fix the benchmark module\n\n`run.sh` is now broken with the packages renamed to `org.apache...` and also somehow the `hadoop-2` profile creates a jar file that doesn't include `/META-INF/BenchmarkList` -- a file that jmh needs:\n\n```\nException in thread \"main\" java.lang.RuntimeException: ERROR: Unable to find the resource: /META-INF/BenchmarkList\n    at org.openjdk.jmh.runner.AbstractResourceReader.getReaders(AbstractResourceReader.java:96)\n    at org.openjdk.jmh.runner.BenchmarkList.find(BenchmarkList.java:104)\n    at org.openjdk.jmh.runner.Runner.internalRun(Runner.java:228)\n    at org.openjdk.jmh.runner.Runner.run(Runner.java:178)\n    at org.openjdk.jmh.Main.main(Main.java:66)\n```\n\nAuthor: Nezih Yigitbasi <nyigitbasi@netflix.com>\n\nCloses #226 from nezihyigitbasi/316 and squashes the following commits:\n\nf9192d5 [Nezih Yigitbasi] PARQUET-316: Fix the benchmark module build instructions and its run script\n",
        "diff": {
            "parquet-benchmarks/README.md": null,
            "parquet-benchmarks/run.sh": null
        }
    },
    "e3b95020f777eb5e0651977f654c1662e3ea1f29": {
        "datetime": "2015-06-30T18:34:48-07:00",
        "summary": "PARQUET-251: Binary column statistics error when reuse byte[] among rows",
        "message": "PARQUET-251: Binary column statistics error when reuse byte[] among rows\n\nAuthor: asingh <asingh@cloudera.com>\nAuthor: Alex Levenson <alexlevenson@twitter.com>\nAuthor: Ashish Singh <asingh@cloudera.com>\n\nCloses #197 from SinghAsDev/PARQUET-251 and squashes the following commits:\n\n68e0eae [asingh] Remove deprecated constructors from private classes\n67e4e5f [asingh] Add removed public methods in Binary and deprecate them\n0e71728 [asingh] Add comment for BinaryStatistics.setMinMaxFromBytes\nfbe873f [Ashish Singh] Merge pull request #4 from isnotinvain/PR-197-3\n9826ee6 [Alex Levenson] Some minor cleanup\n7570035 [asingh] Remove test for stats getting ingnored for version 160 when type is int64\naf43d28 [Alex Levenson] Address PR feedback\n89ab4ee [Alex Levenson] put the headers in the right location\n2838cc9 [Alex Levenson] Split out version checks to separate files, add some tests\n5af9142 [Alex Levenson] Generalize tests, make Binary.fromString reused=false\ne00d9b7 [asingh] Rename isReused => isBackingBytesReused\nd2ad939 [asingh] Rebase over latest trunk\n857141a [asingh] Remove redundant junit dependency\n32b88ed [asingh] Remove semver from hadoop-common\n7a0e99e [asingh] Revert to fromConstantByteArray for ByteString\nc820ec9 [asingh] Add unit tests for Binary and to check if stats are ignored for version 160\n9bbd1e5 [asingh] Improve version parsing\n84a1d8b [asingh] Remove ignoring stats on write side and ignore it on read side\n903f8e3 [asingh] Address some review comments. * Ignore stats for writer's version < 1.8.0 * Refactor shoudlIgnoreStatistics method a bit * Assume implementations other than parquet-mr were writing binary   statistics correctly * Add toParquetStatistics method's original method signature to maintain   backwards compatibility and mark it as deprecated\n64c2617 [asingh] Revert changes for ignoring stats at RowGroupFilter level\ne861b18 [asingh] Ignore max min stats while reading\n3a8cb8d [asingh] Fix typo\n8e12618 [asingh] Fix usage of fromConstant versions of Binary constructors\n860adf7 [asingh] Rename unmodified to constant and isReused instead of isUnmodifiable\n0d127a7 [asingh] Add unmodfied and Reused versions for creating a Binary. Add copy() to Binary.\nb4e2950 [asingh] Skip filtering based on stats when file was written with version older than 1.6.1\n6fcee8c [asingh] Add getBytesUnsafe() to Binary that returns backing byte[] if possible, else returns result of getBytes()\n30b07dd [asingh] PARQUET-251: Binary column statistics error when reuse byte[] among rows\n",
        "diff": {
            "parquet-avro/src/main/java/org/apache/parquet/avro/AvroWriteSupport.java": [
                4,
                4
            ],
            "parquet-avro/src/test/java/org/apache/parquet/avro/TestReadWrite.java": [
                2,
                3
            ],
            "parquet-avro/src/test/java/org/apache/parquet/avro/TestReadWriteOldListBehavior.java": [
                2,
                2
            ],
            "parquet-benchmarks/src/main/java/org/apache/parquet/benchmarks/DataGenerator.java": [
                1,
                1
            ],
            "parquet-column/src/main/java/org/apache/parquet/CorruptStatistics.java": [
                0,
                104
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/statistics/BinaryStatistics.java": [
                6,
                12
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/values/deltalengthbytearray/DeltaLengthByteArrayValuesReader.java": [
                1,
                1
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/values/deltalengthbytearray/DeltaLengthByteArrayValuesWriter.java": [
                1,
                1
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/values/deltastrings/DeltaByteArrayReader.java": [
                4,
                4
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/values/deltastrings/DeltaByteArrayWriter.java": [
                1,
                1
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/values/dictionary/DictionaryValuesWriter.java": [
                7,
                2
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/values/dictionary/PlainValuesDictionary.java": [
                2,
                2
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/values/plain/BinaryPlainValuesReader.java": [
                1,
                1
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/values/plain/FixedLenByteArrayPlainValuesReader.java": [
                1,
                1
            ],
            "parquet-column/src/main/java/org/apache/parquet/example/data/simple/NanoTime.java": [
                1,
                1
            ],
            "parquet-column/src/main/java/org/apache/parquet/io/RecordConsumerLoggingWrapper.java": [
                1,
                1
            ],
            "parquet-column/src/main/java/org/apache/parquet/io/api/Binary.java": [
                23,
                146
            ],
            "parquet-column/src/main/java/org/apache/parquet/schema/PrimitiveType.java": [
                1,
                1
            ],
            "parquet-column/src/test/java/org/apache/parquet/CorruptStatisticsTest.java": [
                0,
                78
            ],
            "parquet-column/src/test/java/org/apache/parquet/column/statistics/TestStatistics.java": [
                0,
                18
            ],
            "parquet-column/src/test/java/org/apache/parquet/column/values/dictionary/TestDictionary.java": [
                3,
                5
            ],
            "parquet-column/src/test/java/org/apache/parquet/io/api/TestBinary.java": [
                0,
                215
            ],
            "parquet-common/src/main/java/org/apache/parquet/SemanticVersion.java": [
                0,
                133
            ],
            "parquet-common/src/main/java/org/apache/parquet/VersionParser.java": [
                0,
                105
            ],
            "parquet-common/src/test/java/org/apache/parquet/SemanticVersionTest.java": [
                0,
                53
            ],
            "parquet-common/src/test/java/org/apache/parquet/VersionTest.java": [
                9,
                35
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/format/converter/ParquetMetadataConverter.java": [
                9,
                32
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/InternalParquetRecordReader.java": [
                2,
                4
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ParquetFileReader.java": [
                8,
                31
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ParquetReader.java": [
                1,
                1
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ParquetRecordReader.java": [
                2,
                1
            ],
            "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/TestColumnChunkPageWriteStore.java": [
                1,
                2
            ],
            "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/TestParquetFileWriter.java": [
                8,
                19
            ],
            "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/TestParquetWriter.java": [
                3,
                3
            ],
            "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/TestParquetWriterNewPage.java": [
                2,
                3
            ],
            "parquet-hive/parquet-hive-storage-handler/src/main/java/org/apache/hadoop/hive/ql/io/parquet/writable/BinaryWritable.java": [
                1,
                1
            ],
            "parquet-hive/parquet-hive-storage-handler/src/main/java/org/apache/hadoop/hive/serde2/objectinspector/primitive/ParquetStringInspector.java": [
                1,
                2
            ],
            "parquet-pig/src/main/java/org/apache/parquet/pig/TupleWriteSupport.java": [
                1,
                1
            ],
            "parquet-protobuf/src/main/java/org/apache/parquet/proto/ProtoWriteSupport.java": [
                1,
                1
            ],
            "parquet-protobuf/src/test/java/org/apache/parquet/proto/ProtoWriteSupportTest.java": [
                6,
                6
            ],
            "parquet-thrift/src/main/java/org/apache/parquet/thrift/ParquetWriteProtocol.java": [
                1,
                2
            ],
            "parquet-tools/src/main/java/org/apache/parquet/tools/command/DumpCommand.java": [
                4,
                6
            ]
        }
    },
    "9fde65345e677256975bcecdc027649f31450a57": {
        "datetime": "2015-07-01T16:33:39-07:00",
        "summary": "PARQUET-320: Fix semver problems for parquet-hadoop.",
        "message": "PARQUET-320: Fix semver problems for parquet-hadoop.\n\nRe-enables semver checks for Parquet packages by removing the parquet/** exclusion that was matching unexpected classes. This also fixes all of the semver problems that have been committed since the check started excluding all Parquet classes.\n\nAuthor: Ryan Blue <blue@apache.org>\n\nCloses #230 from rdblue/PARQUET-320-fix-semver-issues and squashes the following commits:\n\na0e730d [Ryan Blue] PARQUET-320: Fix Thrift incompatibilities from ded56ffd.\nba71f3f [Ryan Blue] PARQUET-320: Fix semver problems for parquet-hadoop.\n",
        "diff": {
            "parquet-hadoop/src/main/java/org/apache/parquet/format/converter/ParquetMetadataConverter.java": [
                26,
                25
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ColumnChunkPageWriteStore.java": [
                2,
                4
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ParquetFileReader.java": [
                7,
                9
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ParquetFileWriter.java": [
                4,
                6
            ],
            "parquet-hadoop/src/test/java/org/apache/parquet/format/converter/TestParquetMetadataConverter.java": [
                14,
                19
            ],
            "parquet-thrift/src/main/java/org/apache/parquet/thrift/ThriftSchemaConvertVisitor.java": [
                1,
                1
            ],
            "parquet-thrift/src/main/java/org/apache/parquet/thrift/projection/amend/DefaultEventsVisitor.java": [
                1,
                1
            ],
            "parquet-thrift/src/main/java/org/apache/parquet/thrift/struct/CompatibilityChecker.java": [
                30,
                18
            ],
            "parquet-thrift/src/main/java/org/apache/parquet/thrift/struct/ThriftType.java": [
                27,
                168
            ],
            "parquet-thrift/src/test/java/org/apache/parquet/thrift/projection/TestFieldsPath.java": [
                1,
                1
            ],
            "pom.xml": null
        }
    },
    "c7720ca4c232d317cfc800a04eda4a1d5a44a944": {
        "datetime": "2015-07-01T16:46:23-07:00",
        "summary": "PARQUET-325: Always use row group size when padding is 0.",
        "message": "PARQUET-325: Always use row group size when padding is 0.\n\nFor block file systems, if the size left in the block is greater than\nthe max padding, a row group will be targeted at the remaining size.\nHowever, when using 0 to turn padding off, the remaining bytes will\nalways be greater than padding and row groups can be targeted at very\ntiny spaces. When padding is off, the next row group's size should\nalways be the default size.\n\nAuthor: Ryan Blue <blue@apache.org>\n\nCloses #234 from rdblue/PARQUET-325-padding-0-fix and squashes the following commits:\n\nf4b3c2b [Ryan Blue] PARQUET-325: Always use row group size when padding is 0.\n",
        "diff": {
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ParquetFileWriter.java": [
                0,
                4
            ]
        }
    },
    "a747456bfe077da467ff036172968a37f3b1e893": {
        "datetime": "2015-07-01T16:53:34-07:00",
        "summary": "PARQUET-308: Add ParquetWriter#getDataSize accessor.",
        "message": "PARQUET-308: Add ParquetWriter#getDataSize accessor.\n\nThis returns the current file position plus the amount of data buffered\nin the current row group as an estimate of final data size.\n\nAuthor: Ryan Blue <blue@apache.org>\n\nCloses #212 from rdblue/PARQUET-308-add-data-size-accessor and squashes the following commits:\n\n1c0d798 [Ryan Blue] PARQUET-308: Add ParquetWriter#getDataSize accessor.\n",
        "diff": {
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/InternalParquetRecordWriter.java": [
                0,
                9
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ParquetWriter.java": [
                0,
                7
            ]
        }
    },
    "2f2c8b1cc6e6e731f7bc52b0988ea8316f475004": {
        "datetime": "2015-07-01T17:18:41-07:00",
        "summary": "PARQUET-289: Allow ParquetReader.Builder subclasses.",
        "message": "PARQUET-289: Allow ParquetReader.Builder subclasses.\n\nThis adds a protected constructor for subclasses, a getReadSupport\nmethod for subclasses to override, and exposes the configuration for\nsubclasses to modify inside of getReadSupport.\n\nAuthor: Ryan Blue <blue@apache.org>\n\nCloses #203 from rdblue/PARQUET-289-extend-reader-builder and squashes the following commits:\n\n692f159 [Ryan Blue] PARQUET-289: Allow ParquetReader.Builder subclasses.\n",
        "diff": {
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ParquetReader.java": [
                2,
                17
            ]
        }
    },
    "c334a1bca8338c92e76f0f1cf2ef4884e3eb5dbd": {
        "datetime": "2015-07-01T17:30:29-07:00",
        "summary": "PARQUET-290: Add data model to Avro reader builder",
        "message": "PARQUET-290: Add data model to Avro reader builder\n\nThis PR currently includes #203, which will be removed when it is merged.\n\nAuthor: Ryan Blue <blue@apache.org>\n\nCloses #204 from rdblue/PARQUET-290-data-model-builder and squashes the following commits:\n\nd257a2c [Ryan Blue] PARQUET-290: Add Avro data model to reader builder.\n",
        "diff": {
            "parquet-avro/src/main/java/org/apache/parquet/avro/AvroParquetReader.java": [
                1,
                47
            ],
            "parquet-avro/src/main/java/org/apache/parquet/avro/AvroReadSupport.java": [
                1,
                13
            ],
            "parquet-avro/src/main/java/org/apache/parquet/avro/SpecificDataSupplier.java": [
                1,
                1
            ],
            "pom.xml": null
        }
    },
    "013b445ede8d9e7aad4915859d0c869b9b712f8d": {
        "datetime": "2015-07-03T10:51:34-07:00",
        "summary": "PARQUET-152: Add validation on Encoding.DELTA_BYTE_ARRAY to allow FIX\u2026",
        "message": "PARQUET-152: Add validation on Encoding.DELTA_BYTE_ARRAY to allow FIX\u2026\n\nPARQUET-152: Add validation on Encoding.DELTA_BYTE_ARRAY to allow FIXED_LEN_BYTE_ARRAY types.\n\n  * FIXED_LEN_BYTE_ARRAY types are binary values that may use DELTA_BYTE_ARRAY encoding,\n    so they should be allowed to be decoded using the same DELTA_BYTE_ARRAY encoding.\n\n@rdblue @nezihyigitbasi  Could you review this fix?\n\nI executed a test by writing a file that fall backs to DELTA_BYTE_ARRAY encoding, then read the file, and compare the read values with the written values, and it worked fine.\n\nAuthor: Sergio Pena <sergio.pena@cloudera.com>\n\nCloses #225 from spena/parquet-152 and squashes the following commits:\n\n93fa03e [Sergio Pena] PARQUET-152: Add validation on Encoding.DELTA_BYTE_ARRAY to allow FIXED_LEN_BYTE_ARRAY types.\n",
        "diff": {
            "parquet-column/src/main/java/org/apache/parquet/column/Encoding.java": [
                2,
                3
            ]
        }
    },
    "f4e754e66e3661274df624bc328991cd88dd03d6": {
        "datetime": "2015-07-03T10:53:22-07:00",
        "summary": "PARQUET-324: row count incorrect if data file has more than 2^31 rows",
        "message": "PARQUET-324: row count incorrect if data file has more than 2^31 rows\n\nNeed to change numRows counter from int to long to account for input files with more than 2^31 rows.\n\nAuthor: Thomas Friedrich <tfriedr@us.ibm.com>\n\nCloses #233 from tfriedr/parquet-324 and squashes the following commits:\n\n0120205 [Thomas Friedrich] change numRows from int to long\n",
        "diff": {
            "parquet-hadoop/src/main/java/org/apache/parquet/format/converter/ParquetMetadataConverter.java": [
                1,
                1
            ]
        }
    },
    "043fcde300267e183972056a007bcf406e5c484a": {
        "datetime": "2015-07-09T10:19:51-07:00",
        "summary": "PARQUET-246: File recovery and work-arounds",
        "message": "PARQUET-246: File recovery and work-arounds\n\nThis is another way to recover data written with the delta byte array problem in PARQUET-246. This builds on @isnotinvain's strategy for solving the problem by adding a method to the encoding to detect it. This version is more similar to the fix for PARQUET-251 and includes a CorruptDeltaByteArrays helper class that uses the writer version. Most of the file changes are to get the file writer version to Encoding and the ColumnReaderImpl.\n\nThis also repairs the problem by using a new interface, RequiresPreviousReader, to pass the previous ValuesReader, which is slightly cleaner because the reader doesn't need to expose getter and setter methods.\n\nThe problem affects pages written to different row groups, so it was necessary to detect the problem in parquet-hadoop and fail jobs that cannot reconstruct data. The work-around to recover is to set \"parquet.split.files\" to false so that files are read sequentially. This could be set automatically in isSplittable, but this would require reading all file footers before submitting jobs, which was recently fixed. I think it is a fair compromise to detect the error case and recommend a solution.\n\nThis also includes tests for the problem to verify the fix.\n\nReplaces old pull requests: closes #217 closes #235\n\nAuthor: Ryan Blue <blue@apache.org>\n\nCloses #235 from rdblue/PARQUET-246-recover-files and squashes the following commits:\n\n067d5ca [Ryan Blue] PARQUET-246: Refactor after review comments.\n3236a3b [Ryan Blue] PARQUET-246: Fix ParquetInputFormat for delta byte[] corruption.\n3107362 [Ryan Blue] PARQUET-246: Add tests for delta byte array fix.\na10b157 [Ryan Blue] PARQUET-246: Fix reading for corrupt delta byte arrays.\n5c9497c [Ryan Blue] PARQUET-246: Parse semantic version with full version.\n",
        "diff": {
            "parquet-column/src/main/java/org/apache/parquet/CorruptDeltaByteArrays.java": [
                0,
                99
            ],
            "parquet-column/src/main/java/org/apache/parquet/CorruptStatistics.java": [
                2,
                2
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/impl/ColumnReadStoreImpl.java": [
                3,
                19
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/impl/ColumnReaderImpl.java": [
                4,
                38
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/values/RequiresPreviousReader.java": [
                0,
                23
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/values/deltastrings/DeltaByteArrayReader.java": [
                2,
                23
            ],
            "parquet-column/src/main/java/org/apache/parquet/io/ColumnIOFactory.java": [
                11,
                27
            ],
            "parquet-column/src/main/java/org/apache/parquet/io/MessageColumnIO.java": [
                5,
                6
            ],
            "parquet-column/src/test/java/org/apache/parquet/column/impl/TestColumnReaderImpl.java": [
                4,
                6
            ],
            "parquet-column/src/test/java/org/apache/parquet/column/impl/TestCorruptDeltaByteArrays.java": [
                0,
                259
            ],
            "parquet-column/src/test/java/org/apache/parquet/column/mem/TestMemColumn.java": [
                1,
                2
            ],
            "parquet-common/src/main/java/org/apache/parquet/SemanticVersion.java": [
                3,
                26
            ],
            "parquet-common/src/main/java/org/apache/parquet/VersionParser.java": [
                6,
                33
            ],
            "parquet-common/src/test/java/org/apache/parquet/SemanticVersionTest.java": [
                3,
                7
            ],
            "parquet-common/src/test/java/org/apache/parquet/VersionTest.java": [
                7,
                2
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/InternalParquetRecordReader.java": [
                1,
                2
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ParquetInputFormat.java": [
                0,
                10
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ParquetRecordReader.java": [
                1,
                26
            ],
            "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/TestParquetFileWriter.java": [
                0,
                11
            ],
            "parquet-tools/src/main/java/org/apache/parquet/tools/command/DumpCommand.java": [
                1,
                3
            ],
            "pom.xml": null
        }
    },
    "4c7d7523088373be3c7ff203ea895d5a6d84083e": {
        "datetime": "2015-07-11T16:26:51-07:00",
        "summary": "PARQUET-329: Restore ThriftReadSupport#THRIFT_COLUMN_FILTER_KEY",
        "message": "PARQUET-329: Restore ThriftReadSupport#THRIFT_COLUMN_FILTER_KEY\n\nThriftReadSupport#THRIFT_COLUMN_FILTER_KEY was removed (incompatible change)\n\nAuthor: asingh <asingh@cloudera.com>\n\nCloses #239 from SinghAsDev/PARQUET-329 and squashes the following commits:\n\n1e44a70 [asingh] Remove o.a.p.hadoop.thrift from semver excludes\n4a1e572 [asingh] PARQUET-329: Restore ThriftReadSupport#THRIFT_COLUMN_FILTER_KEY\n",
        "diff": {
            "parquet-thrift/src/main/java/org/apache/parquet/hadoop/thrift/ThriftReadSupport.java": [
                7,
                7
            ],
            "parquet-thrift/src/main/java/org/apache/parquet/thrift/projection/deprecated/DeprecatedFieldProjectionFilter.java": [
                1,
                1
            ],
            "parquet-thrift/src/main/java/org/apache/parquet/thrift/projection/deprecated/PathGlobPattern.java": [
                1,
                1
            ],
            "parquet-thrift/src/test/java/org/apache/parquet/hadoop/thrift/TestParquetToThriftReadWriteAndProjection.java": [
                1,
                1
            ],
            "pom.xml": null
        }
    },
    "8f898dad262a835d6366bf108b61272139601793": {
        "datetime": "2015-07-11T16:51:28-07:00",
        "summary": "PARQUET-292: Update CHANGES.md for 1.8.0.",
        "message": "PARQUET-292: Update CHANGES.md for 1.8.0.\n\nAlso, cleaning up PRs: closes #206, closes #47, closes #72, closes #87,\ncloses #96, closes #100, closes #107, and closes #112.\n",
        "diff": {
            "CHANGES.md": null
        }
    },
    "0fda28af84b9746396014ad6a415b90592a98b3b": {
        "datetime": "2015-07-11T17:11:06-07:00",
        "summary": "[maven-release-plugin] prepare release apache-parquet-1.8.0",
        "message": "[maven-release-plugin] prepare release apache-parquet-1.8.0\n",
        "diff": {
            "parquet-avro/pom.xml": null,
            "parquet-benchmarks/pom.xml": null,
            "parquet-cascading/pom.xml": null,
            "parquet-column/pom.xml": null,
            "parquet-common/pom.xml": null,
            "parquet-encoding/pom.xml": null,
            "parquet-generator/pom.xml": null,
            "parquet-hadoop-bundle/pom.xml": null,
            "parquet-hadoop/pom.xml": null,
            "parquet-hive-bundle/pom.xml": null,
            "parquet-hive/parquet-hive-binding/parquet-hive-0.10-binding/pom.xml": null,
            "parquet-hive/parquet-hive-binding/parquet-hive-0.12-binding/pom.xml": null,
            "parquet-hive/parquet-hive-binding/parquet-hive-binding-bundle/pom.xml": null,
            "parquet-hive/parquet-hive-binding/parquet-hive-binding-factory/pom.xml": null,
            "parquet-hive/parquet-hive-binding/parquet-hive-binding-interface/pom.xml": null,
            "parquet-hive/parquet-hive-binding/pom.xml": null,
            "parquet-hive/parquet-hive-storage-handler/pom.xml": null,
            "parquet-hive/pom.xml": null,
            "parquet-jackson/pom.xml": null,
            "parquet-pig-bundle/pom.xml": null,
            "parquet-pig/pom.xml": null,
            "parquet-protobuf/pom.xml": null,
            "parquet-scala/pom.xml": null,
            "parquet-scrooge/pom.xml": null,
            "parquet-thrift/pom.xml": null,
            "parquet-tools/pom.xml": null,
            "pom.xml": null
        }
    },
    "abfe3559f2469537be0c955dbb2518da5795bbbb": {
        "datetime": "2015-07-11T17:11:23-07:00",
        "summary": "[maven-release-plugin] prepare for next development iteration",
        "message": "[maven-release-plugin] prepare for next development iteration\n",
        "diff": {
            "parquet-avro/pom.xml": null,
            "parquet-benchmarks/pom.xml": null,
            "parquet-cascading/pom.xml": null,
            "parquet-column/pom.xml": null,
            "parquet-common/pom.xml": null,
            "parquet-encoding/pom.xml": null,
            "parquet-generator/pom.xml": null,
            "parquet-hadoop-bundle/pom.xml": null,
            "parquet-hadoop/pom.xml": null,
            "parquet-hive-bundle/pom.xml": null,
            "parquet-hive/parquet-hive-binding/parquet-hive-0.10-binding/pom.xml": null,
            "parquet-hive/parquet-hive-binding/parquet-hive-0.12-binding/pom.xml": null,
            "parquet-hive/parquet-hive-binding/parquet-hive-binding-bundle/pom.xml": null,
            "parquet-hive/parquet-hive-binding/parquet-hive-binding-factory/pom.xml": null,
            "parquet-hive/parquet-hive-binding/parquet-hive-binding-interface/pom.xml": null,
            "parquet-hive/parquet-hive-binding/pom.xml": null,
            "parquet-hive/parquet-hive-storage-handler/pom.xml": null,
            "parquet-hive/pom.xml": null,
            "parquet-jackson/pom.xml": null,
            "parquet-pig-bundle/pom.xml": null,
            "parquet-pig/pom.xml": null,
            "parquet-protobuf/pom.xml": null,
            "parquet-scala/pom.xml": null,
            "parquet-scrooge/pom.xml": null,
            "parquet-thrift/pom.xml": null,
            "parquet-tools/pom.xml": null,
            "pom.xml": null
        }
    },
    "fcd568282b2a150f9f42953f12268dc88d09da89": {
        "datetime": "2015-07-13T10:36:18-07:00",
        "summary": "PARQUET-279 : Check empty struct in compatibility checker",
        "message": "PARQUET-279 : Check empty struct in compatibility checker\n\nAdd the empty struct check in the CompatibilityChecker util.\nParquet currently does not support empty struct/group without leaves\n\nAuthor: Tianshuo Deng <tdeng@twitter.com>\n\nCloses #194 from tsdeng/check_empty_struct and squashes the following commits:\n\n35d77a1 [Tianshuo Deng] fix rebase\nd781cf3 [Tianshuo Deng] simplify constructor\ncd2fa8e [Tianshuo Deng] add State\ne75a6ac [Tianshuo Deng] use immutable FieldsPath\n2bff920 [Tianshuo Deng] fix test\n69b4b9c [Tianshuo Deng] minor fixes\n2db8c4b [Tianshuo Deng] remove unused println\n5107ce2 [Tianshuo Deng] fix comments\n265e228 [Tianshuo Deng] wip\n",
        "diff": {
            "parquet-common/src/main/java/org/apache/parquet/Strings.java": [
                1,
                13
            ],
            "parquet-thrift/src/main/java/org/apache/parquet/thrift/ThriftSchemaConverter.java": [
                2,
                2
            ],
            "parquet-thrift/src/main/java/org/apache/parquet/thrift/struct/CompatibilityChecker.java": [
                56,
                103
            ],
            "parquet-thrift/src/main/java/org/apache/parquet/thrift/struct/CompatibilityRunner.java": [
                0,
                7
            ],
            "parquet-thrift/src/test/java/org/apache/parquet/thrift/struct/CompatibilityCheckerTest.java": [
                2,
                14
            ],
            "parquet-thrift/src/test/thrift/compat.thrift": null
        }
    },
    "be9f3cb2a8095c89b5a11c33a498532f3c6413a3": {
        "datetime": "2015-07-14T09:56:20-07:00",
        "summary": "PARQUET-331: Surface subprocess stderr in merge script",
        "message": "PARQUET-331: Surface subprocess stderr in merge script\n\nThis makes it a little easier to understand why the merge script failed\n\nAuthor: Alex Levenson <alexlevenson@twitter.com>\n\nCloses #240 from isnotinvain/alexlevenson/merge-script-error-handling and squashes the following commits:\n\n7c38c01 [Alex Levenson] Surface subprocess stderr in merge script\n",
        "diff": {
            "dev/merge_parquet_pr.py": [
                5,
                13
            ]
        }
    },
    "8a2c6186628da556504dfde803ad660f5280d640": {
        "datetime": "2015-07-16T16:39:48-07:00",
        "summary": "PARQUET-338: Fix pull request example in README",
        "message": "PARQUET-338: Fix pull request example in README\n\nThe example PR has the wrong format, it uses [PARQUET-123] instead of PARQUET-123:\n\nAuthor: Alex Levenson <alex@isnotinvain.com>\n\nCloses #244 from isnotinvain/patch-2 and squashes the following commits:\n\n41aaad2 [Alex Levenson] Fix pull request example in README\n",
        "diff": {
            "README.md": null
        }
    },
    "f79c9365d0ee89cb407b90cc084eece8fcf9a8a2": {
        "datetime": "2015-07-16T16:41:04-07:00",
        "summary": "PARQUET-337 handle binary fields in set/map/list in parquet-scrooge",
        "message": "PARQUET-337 handle binary fields in set/map/list in parquet-scrooge\n\nhttps://issues.apache.org/jira/browse/PARQUET-337\n\nAuthor: Jake Donham <jdonham@twitter.com>\n\nCloses #243 from jaked/PARQUET-337 and squashes the following commits:\n\n8129fe5 [Jake Donham] parquet-scrooge: handle binary fields in set/map/list\n",
        "diff": {
            "parquet-scrooge/src/main/java/org/apache/parquet/scrooge/ScroogeStructConverter.java": [
                3,
                6
            ],
            "parquet-scrooge/src/test/java/org/apache/parquet/scrooge/ScroogeStructConverterTest.java": [
                3,
                9
            ],
            "parquet-scrooge/src/test/thrift/test.thrift": null
        }
    },
    "8714dd031647be34d0d27f461894e7b194f25cd7": {
        "datetime": "2015-07-16T16:42:38-07:00",
        "summary": "PARQUET-336: Fix ArrayIndexOutOfBounds in checkDeltaByteArrayProblem",
        "message": "PARQUET-336: Fix ArrayIndexOutOfBounds in checkDeltaByteArrayProblem\n\nAuthor: Alex Levenson <alexlevenson@twitter.com>\nAuthor: Alex Levenson <alex@isnotinvain.com>\n\nCloses #242 from isnotinvain/patch-1 and squashes the following commits:\n\nce1f81e [Alex Levenson] Add tests\n4688930 [Alex Levenson] Fix ArrayIndexOutOfBounds in checkDeltaByteArrayProblem\n",
        "diff": {
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ParquetRecordReader.java": [
                1,
                3
            ],
            "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/example/TestInputOutputFormat.java": [
                2,
                69
            ]
        }
    },
    "8da9456357dea61c1dba5a19483920fe91ae2b09": {
        "datetime": "2015-07-16T17:18:07-07:00",
        "summary": "PARQUET-339: Add Alex Levenson to KEYS file",
        "message": "PARQUET-339: Add Alex Levenson to KEYS file\n\nAuthor: Alex Levenson <alexlevenson@twitter.com>\n\nCloses #245 from isnotinvain/alexlevenson/add-keys and squashes the following commits:\n\ne3dae4d [Alex Levenson] Add Alex Levenson to KEYS file\n",
        "diff": {
            "KEYS": null
        }
    },
    "07cefb82189e9d2236036fadec19a9436652c090": {
        "datetime": "2015-07-17T12:57:08-07:00",
        "summary": "Update CHANGES for 1.8.1 release",
        "message": "Update CHANGES for 1.8.1 release\n",
        "diff": {
            "CHANGES.md": null
        }
    },
    "4aba4dae7bb0d4edbcf7923ae1339f28fd3f7fcf": {
        "datetime": "2015-07-17T13:31:55-07:00",
        "summary": "[maven-release-plugin] prepare release apache-parquet-1.8.1",
        "message": "[maven-release-plugin] prepare release apache-parquet-1.8.1\n",
        "diff": {
            "parquet-avro/pom.xml": null,
            "parquet-benchmarks/pom.xml": null,
            "parquet-cascading/pom.xml": null,
            "parquet-column/pom.xml": null,
            "parquet-common/pom.xml": null,
            "parquet-encoding/pom.xml": null,
            "parquet-generator/pom.xml": null,
            "parquet-hadoop-bundle/pom.xml": null,
            "parquet-hadoop/pom.xml": null,
            "parquet-hive-bundle/pom.xml": null,
            "parquet-hive/parquet-hive-binding/parquet-hive-0.10-binding/pom.xml": null,
            "parquet-hive/parquet-hive-binding/parquet-hive-0.12-binding/pom.xml": null,
            "parquet-hive/parquet-hive-binding/parquet-hive-binding-bundle/pom.xml": null,
            "parquet-hive/parquet-hive-binding/parquet-hive-binding-factory/pom.xml": null,
            "parquet-hive/parquet-hive-binding/parquet-hive-binding-interface/pom.xml": null,
            "parquet-hive/parquet-hive-binding/pom.xml": null,
            "parquet-hive/parquet-hive-storage-handler/pom.xml": null,
            "parquet-hive/pom.xml": null,
            "parquet-jackson/pom.xml": null,
            "parquet-pig-bundle/pom.xml": null,
            "parquet-pig/pom.xml": null,
            "parquet-protobuf/pom.xml": null,
            "parquet-scala/pom.xml": null,
            "parquet-scrooge/pom.xml": null,
            "parquet-thrift/pom.xml": null,
            "parquet-tools/pom.xml": null,
            "pom.xml": null
        }
    },
    "1dd5cec0871b20e85892f4e8d2757af41d0ba250": {
        "datetime": "2015-07-17T13:32:11-07:00",
        "summary": "[maven-release-plugin] prepare for next development iteration",
        "message": "[maven-release-plugin] prepare for next development iteration\n",
        "diff": {
            "parquet-avro/pom.xml": null,
            "parquet-benchmarks/pom.xml": null,
            "parquet-cascading/pom.xml": null,
            "parquet-column/pom.xml": null,
            "parquet-common/pom.xml": null,
            "parquet-encoding/pom.xml": null,
            "parquet-generator/pom.xml": null,
            "parquet-hadoop-bundle/pom.xml": null,
            "parquet-hadoop/pom.xml": null,
            "parquet-hive-bundle/pom.xml": null,
            "parquet-hive/parquet-hive-binding/parquet-hive-0.10-binding/pom.xml": null,
            "parquet-hive/parquet-hive-binding/parquet-hive-0.12-binding/pom.xml": null,
            "parquet-hive/parquet-hive-binding/parquet-hive-binding-bundle/pom.xml": null,
            "parquet-hive/parquet-hive-binding/parquet-hive-binding-factory/pom.xml": null,
            "parquet-hive/parquet-hive-binding/parquet-hive-binding-interface/pom.xml": null,
            "parquet-hive/parquet-hive-binding/pom.xml": null,
            "parquet-hive/parquet-hive-storage-handler/pom.xml": null,
            "parquet-hive/pom.xml": null,
            "parquet-jackson/pom.xml": null,
            "parquet-pig-bundle/pom.xml": null,
            "parquet-pig/pom.xml": null,
            "parquet-protobuf/pom.xml": null,
            "parquet-scala/pom.xml": null,
            "parquet-scrooge/pom.xml": null,
            "parquet-thrift/pom.xml": null,
            "parquet-tools/pom.xml": null,
            "pom.xml": null
        }
    },
    "83406b73e70a251eec5daae34f1bd8d554cdddec": {
        "datetime": "2015-07-20T09:59:29-07:00",
        "summary": "PARQUET-340: MemoryManager: max memory can be truncated",
        "message": "PARQUET-340: MemoryManager: max memory can be truncated\n\nUsing float will cause the max heap limit to be limited to 2147483647\ndue to math.round(float) if used with a large heap. This should be a double\nprecision to prevent rounding to an int32 before storing into a long.\n\nAuthor: Chris Bannister <c.bannister@gmail.com>\n\nCloses #246 from Zariel/default-mem-truncated and squashes the following commits:\n\nbf375f6 [Chris Bannister] MemoryManager: ensure max memory is not truncated\n",
        "diff": {
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/MemoryManager.java": [
                1,
                1
            ],
            "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/TestMemoryManager.java": [
                1,
                1
            ]
        }
    },
    "454fc3655509f1f4f47ce44acaff7c1566ede108": {
        "datetime": "2015-07-28T14:55:14-07:00",
        "summary": "PARQUET-342: Updates to be Java 6 compatible",
        "message": "PARQUET-342: Updates to be Java 6 compatible\n\nAuthor: Nezih Yigitbasi <nyigitbasi@netflix.com>\n\nCloses #248 from nezihyigitbasi/java6-fixes and squashes the following commits:\n\n2ab2598 [Nezih Yigitbasi] Updates to be Java 6 compatible\n",
        "diff": {
            "parquet-common/src/main/java/org/apache/parquet/Files.java": [
                0,
                51
            ],
            "parquet-common/src/main/java/org/apache/parquet/SemanticVersion.java": [
                4,
                12
            ],
            "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/TestInputOutputFormatWithPadding.java": [
                6,
                5
            ],
            "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/example/TestInputOutputFormat.java": [
                4,
                5
            ]
        }
    },
    "b86f68e39dc7b6a7c2bff1e4fea3bb7c28d103f0": {
        "datetime": "2015-07-31T16:57:19-07:00",
        "summary": "PARQUET-346: Minor fixes for PARQUET-350, PARQUET-348, PARQUET-346, PARQUET-345",
        "message": "PARQUET-346: Minor fixes for PARQUET-350, PARQUET-348, PARQUET-346, PARQUET-345\n\nPARQUET-346:\nThriftSchemaConverter throws for unknown struct or union type\nThis is triggered when passing a StructType that comes from old file metadata\n\nPARQUET-350:\nThriftRecordConverter throws NPE for unrecognized enum values\nThis is just some better error reporting.\n\nPARQUET-348:\nshouldIgnoreStatistics too noisy\nThis is just a case of way over logging something, to the point that it make the logs unreadable\n\nPARQUET-345\nThriftMetaData toString() should not try to load class reflectively\nThis is a case where the error reporting itself crashes, which results in the real error message getting lost\n\nAuthor: Alex Levenson <alexlevenson@twitter.com>\n\nCloses #252 from isnotinvain/alexlevenson/various-fixes and squashes the following commits:\n\n9b5cb0e [Alex Levenson] Add comments, cleanup some minor use of ThriftSchemaConverter\n376343e [Alex Levenson] Fix test\nd9d5dad [Alex Levenson] add license headers\ne26dc0c [Alex Levenson] Add tests\n8d9dde0 [Alex Levenson] Fixes for PARQUET-350, PARQUET-348, PARQUET-346, PARQUET-345\n",
        "diff": {
            "parquet-column/src/main/java/org/apache/parquet/CorruptStatistics.java": [
                9,
                21
            ],
            "parquet-scrooge/src/test/java/org/apache/parquet/scrooge/ScroogeStructConverterTest.java": [
                3,
                2
            ],
            "parquet-thrift/src/main/java/org/apache/parquet/hadoop/thrift/AbstractThriftWriteSupport.java": [
                2,
                1
            ],
            "parquet-thrift/src/main/java/org/apache/parquet/hadoop/thrift/TBaseWriteSupport.java": [
                2,
                1
            ],
            "parquet-thrift/src/main/java/org/apache/parquet/hadoop/thrift/ThriftBytesWriteSupport.java": [
                3,
                2
            ],
            "parquet-thrift/src/main/java/org/apache/parquet/thrift/ThriftMetaData.java": [
                2,
                1
            ],
            "parquet-thrift/src/main/java/org/apache/parquet/thrift/ThriftRecordConverter.java": [
                19,
                30
            ],
            "parquet-thrift/src/main/java/org/apache/parquet/thrift/ThriftSchemaConvertVisitor.java": [
                8,
                15
            ],
            "parquet-thrift/src/main/java/org/apache/parquet/thrift/ThriftSchemaConverter.java": [
                1,
                15
            ],
            "parquet-thrift/src/main/java/org/apache/parquet/thrift/struct/CompatibilityRunner.java": [
                1,
                1
            ],
            "parquet-thrift/src/test/java/org/apache/parquet/thrift/TestProtocolReadToWrite.java": [
                7,
                7
            ],
            "parquet-thrift/src/test/java/org/apache/parquet/thrift/TestThriftMetaData.java": [
                0,
                55
            ],
            "parquet-thrift/src/test/java/org/apache/parquet/thrift/TestThriftRecordConverter.java": [
                0,
                101
            ],
            "parquet-thrift/src/test/java/org/apache/parquet/thrift/TestThriftToPigCompatibility.java": [
                1,
                1
            ],
            "parquet-thrift/src/test/java/org/apache/parquet/thrift/struct/CompatibilityCheckerTest.java": [
                1,
                1
            ],
            "parquet-thrift/src/test/resources/org/apache/parquet/thrift/StructWithUnionV1NoStructOrUnionMeta.json": null
        }
    },
    "2f956f46580e5b4752173e885d37a20fe31a78d8": {
        "datetime": "2015-08-05T16:29:00-07:00",
        "summary": "PARQUET-341 improve write performance for wide schema sparse data",
        "message": "PARQUET-341 improve write performance for wide schema sparse data\n\nIn write path, when there are tons of sparse data, most of time is spent on writing nulls.\nCurrently writing nulls has the same code path as writing values, which is reclusive traverse all the leaves when a group is null.\nDue to the fact that when a group is null all the leaves beneath it should be written with null value with the same repetition level and definition level, we can eliminate the recursion call to get the leaves\n\nThis PR caches the leaves for each group node. So when a group node is null, their leaves can be flushed with null values directly.\n\nWe tested it with a really wide schema on one of our production data. It improves the performance by ~20%\n\nAuthor: Tianshuo Deng <tdeng@twitter.com>\n\nCloses #247 from tsdeng/flush_null_directly and squashes the following commits:\n\n253f2e3 [Tianshuo Deng] address comments\n8676cd7 [Tianshuo Deng] flush null directly to leaves\n",
        "diff": {
            "parquet-column/src/main/java/org/apache/parquet/io/MessageColumnIO.java": [
                5,
                34
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/InternalParquetRecordReader.java": [
                1,
                2
            ]
        }
    },
    "3f36b7b50bdda3eeca632ad5440bb82b8e34cb40": {
        "datetime": "2015-08-20T13:52:56-07:00",
        "summary": "PARQUET-362 - Fix parquet buffered writer being oversensitive to union schema changes",
        "message": "PARQUET-362 - Fix parquet buffered writer being oversensitive to union schema changes\n\nParquet does prevent records with unknown union fields to be written as it would\ncreate a TProtocol violation. But it also prevents records with unions having one their field\nitself having an unknown field (which is acceptable if it is a struct).\n\nAuthor: Laurent Goujon <lgoujon@twitter.com>\n\nCloses #262 from laurentgo/fix-parquet-union-write-bug and squashes the following commits:\n\nd15ee74 [Laurent Goujon] Fix parquet buffered writer being oversentive to union changes\n",
        "diff": {
            "parquet-thrift/src/main/java/org/apache/parquet/thrift/BufferedProtocolReadToWrite.java": [
                5,
                4
            ],
            "parquet-thrift/src/test/java/org/apache/parquet/thrift/TestProtocolReadToWrite.java": [
                0,
                37
            ],
            "parquet-thrift/src/test/thrift/compat.thrift": null
        }
    },
    "01fbf81e34a36cedf505f20b1c52306afceedc3e": {
        "datetime": "2015-08-20T14:21:12-07:00",
        "summary": "PARQUET-343 Caching nulls on group node to improve write performance on wide schema sparse data",
        "message": "PARQUET-343 Caching nulls on group node to improve write performance on wide schema sparse data\n\nFor really wide schema with sparse data, If a group node is empty, it could have a huge number of leaves underneath it. Calling writeMull for each leaf every time when it's ancestor group node is null is in-effcient and is bad for data locality in the memory especially when the number of leaves is huge.\n\nInstead, null can be cached on the group node. Flushing is only triggered when a group node becomes non-null from null. This way, all the cached null values will be flushed to the leaf nodes in a tight loop and improves write performance.\n\nWe tested this approach combined with PARQUET-341 on a really large schema and gave us ~2X improvement on write performance\n\nAuthor: Tianshuo Deng <tdeng@twitter.com>\n\nCloses #249 from tsdeng/batch_null and squashes the following commits:\n\n0a61646 [Tianshuo Deng] use curly braces even for 1 line if statements\na8964c0 [Tianshuo Deng] optimize writeNullToLeaves\n5309612 [Tianshuo Deng] optimize cacheNullForGroup\necbdfca [Tianshuo Deng] add comments\ned692c0 [Tianshuo Deng] WIP\n0cae1b6 [Tianshuo Deng] remove unused class\n8e07db4 [Tianshuo Deng] refactor\ndead618 [Tianshuo Deng] reformat\nc3c0c70 [Tianshuo Deng] refactor\n636ab52 [Tianshuo Deng] remove unused method\n767b4fd [Tianshuo Deng] use parent definition level\n8f251a0 [Tianshuo Deng] use IntArrayList\nc549c84 [Tianshuo Deng] fix\n9583d04 [Tianshuo Deng] wIP\nd8cb878 [Tianshuo Deng] WIP\n35f1fa1 [Tianshuo Deng] cache columnWriter for each parent\n46fd464 [Tianshuo Deng] address comments\n8c83964 [Tianshuo Deng] flush null directly to leaves\n",
        "diff": {
            "parquet-column/src/main/java/org/apache/parquet/io/MessageColumnIO.java": [
                26,
                119
            ],
            "parquet-column/src/main/java/org/apache/parquet/io/ValidatingRecordConsumer.java": [
                0,
                4
            ],
            "parquet-column/src/main/java/org/apache/parquet/io/api/RecordConsumer.java": [
                0,
                7
            ],
            "parquet-column/src/test/java/org/apache/parquet/io/TestColumnIO.java": [
                5,
                16
            ],
            "parquet-column/src/test/java/org/apache/parquet/io/TestFiltered.java": [
                1,
                4
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/InternalParquetRecordReader.java": [
                2,
                1
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/InternalParquetRecordWriter.java": [
                1,
                5
            ],
            "parquet-thrift/src/test/java/org/apache/parquet/thrift/TestParquetReadProtocol.java": [
                0,
                1
            ]
        }
    },
    "2c90a9dad1c9a7cdab6af48c4bd7f7dcecf3fbb7": {
        "datetime": "2015-08-20T14:27:00-07:00",
        "summary": "PARQUET-356: Update LICENSE files for code from ElephantBird.",
        "message": "PARQUET-356: Update LICENSE files for code from ElephantBird.\n\nThis updates the root LICENSE and the parquet-hadoop binary LICENSE files for the inclusion of code from Twitter's ElephantBird project in 9993450.\n\nAuthor: Ryan Blue <blue@apache.org>\n\nCloses #256 from rdblue/PARQUET-356-add-elephantbird-license and squashes the following commits:\n\n503f393 [Ryan Blue] PARQUET-356: Update LICENSE files for code from ElephantBird.\n",
        "diff": {
            "LICENSE": null,
            "parquet-hadoop/src/main/resources/META-INF/LICENSE": null
        }
    },
    "04f524d5ad91b1cdda66dfde4089f2f83f4528aa": {
        "datetime": "2015-08-20T15:23:22-07:00",
        "summary": "PARQUET-361: Add semver prerelease logic.",
        "message": "PARQUET-361: Add semver prerelease logic.\n\nThis also adds more versions where PARQUET-251 is fixed.\n\nAuthor: Ryan Blue <blue@apache.org>\n\nCloses #261 from rdblue/PARQUET-361-add-semver-prerelease and squashes the following commits:\n\nc01142d [Ryan Blue] PARQUET-361: Add semver prerelease logic.\n",
        "diff": {
            "parquet-column/src/main/java/org/apache/parquet/CorruptStatistics.java": [
                1,
                5
            ],
            "parquet-column/src/test/java/org/apache/parquet/CorruptStatisticsTest.java": [
                0,
                14
            ],
            "parquet-common/src/main/java/org/apache/parquet/SemanticVersion.java": [
                13,
                142
            ],
            "parquet-common/src/test/java/org/apache/parquet/SemanticVersionTest.java": [
                2,
                59
            ]
        }
    },
    "9962a0fd02fe2ef06765271605b06729af8b2e59": {
        "datetime": "2015-09-11T10:31:38-07:00",
        "summary": "PARQUET-335: Remove Avro check for MAP_KEY_VALUE.",
        "message": "PARQUET-335: Remove Avro check for MAP_KEY_VALUE.\n\nThis is not required by the map type spec. This does not affect data\nwritten by the Avro object model because this bug is in the conversion\nfrom a Parquet schema to an Avro schema. Files written with parquet-avro\ndo not convert the underlying schema because they use the Avro schema.\n\nAuthor: Ryan Blue <blue@apache.org>\n\nCloses #241 from rdblue/PARQUET-335-remove-key-value-check and squashes the following commits:\n\n1fd9541 [Ryan Blue] PARQUET-335: Test that MAP_KEY_VALUE is not required.\n247cc76 [Ryan Blue] PARQUET-335: Remove Avro check for MAP_KEY_VALUE.\n",
        "diff": {
            "parquet-avro/src/main/java/org/apache/parquet/avro/AvroSchemaConverter.java": [
                1,
                0
            ],
            "parquet-avro/src/test/java/org/apache/parquet/avro/TestAvroSchemaConverter.java": [
                0,
                20
            ]
        }
    },
    "f203d809d7b94501a2e5409c667ba86206480f90": {
        "datetime": "2015-09-11T15:14:00-07:00",
        "summary": "PARQUET-363: Allow empty schema groups.",
        "message": "PARQUET-363: Allow empty schema groups.\n\nThis removes the check added in PARQUET-278 that rejects schema groups\nthat have no fields. Selecting 0 columns from a file is allowed and used\nby Hive and SparkSQL to implement queries like `select count(1) ...`\n\nAuthor: Ryan Blue <blue@apache.org>\n\nCloses #263 from rdblue/PARQUET-363-allow-empty-groups and squashes the following commits:\n\nab370f1 [Ryan Blue] PARQUET-363: Update Type builder tests to allow empty groups.\n926932b [Ryan Blue] PARQUET-363: Add write-side schema validation.\n365f30d [Ryan Blue] PARQUET-363: Allow empty schema groups.\n",
        "diff": {
            "parquet-column/src/main/java/org/apache/parquet/schema/GroupType.java": [
                3,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/schema/TypeUtil.java": [
                0,
                45
            ],
            "parquet-column/src/main/java/org/apache/parquet/schema/Types.java": [
                2,
                0
            ],
            "parquet-column/src/test/java/org/apache/parquet/schema/TestMessageType.java": [
                13,
                0
            ],
            "parquet-column/src/test/java/org/apache/parquet/schema/TestTypeBuilders.java": [
                30,
                10
            ],
            "parquet-column/src/test/java/org/apache/parquet/schema/TestTypeUtil.java": [
                0,
                89
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ParquetFileWriter.java": [
                0,
                2
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/example/ExampleParquetWriter.java": [
                0,
                93
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/example/GroupWriteSupport.java": [
                2,
                12
            ],
            "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/TestParquetWriter.java": [
                0,
                37
            ],
            "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/TestUtils.java": [
                0,
                19
            ]
        }
    },
    "d24ecb32ff58d13c178991f0c8618980ff123080": {
        "datetime": "2015-09-14T16:39:25-07:00",
        "summary": "PARQUET-376: Tolerate square brackets in PR titles",
        "message": "PARQUET-376: Tolerate square brackets in PR titles\n\nThis allows for PRs like:\n\n`[PARQUET-XXXX] description`\n\nto be parsed, as we often get this format and we usually have to ask the submitter to change the title for us.\n\nAuthor: Alex Levenson <alexlevenson@twitter.com>\n\nCloses #271 from isnotinvain/alexlevenson/tolerate-brackets-pr-merge and squashes the following commits:\n\nedf086d [Alex Levenson] Remove brackets from commit message\n3ba963d [Alex Levenson] Tolerate square brackets in PR titles\n",
        "diff": {
            "dev/merge_parquet_pr.py": [
                2,
                11
            ]
        }
    },
    "415761dc0d7c86bc455608f6b12184ae7ff296ce": {
        "datetime": "2015-09-14T16:40:52-07:00",
        "summary": "Revert \"PARQUET-376: Tolerate square brackets in PR titles\"",
        "message": "Revert \"PARQUET-376: Tolerate square brackets in PR titles\"\n\nThis reverts commit d24ecb32ff58d13c178991f0c8618980ff123080.\n",
        "diff": {
            "dev/merge_parquet_pr.py": [
                11,
                2
            ]
        }
    },
    "66e39fc7d5a6fb29a5ff04b23132468dc6adbde6": {
        "datetime": "2015-09-14T16:56:52-07:00",
        "summary": "PARQUET-375: Update current release version in README.md",
        "message": "PARQUET-375: Update current release version in README.md\n\nCurrent README.md was still pointing to release 1.7.0\n\nAuthor: Luciano Resende <lresende@apache.org>\n\nCloses #260 from lresende/update-release-version and squashes the following commits:\n\nf7a6964 [Luciano Resende] Update current release version in README.md\n",
        "diff": {
            "README.md": null
        }
    },
    "0637e2fbcd401f47bb062d5c2d1cceddabf372b7": {
        "datetime": "2015-09-17T11:46:41-07:00",
        "summary": "PARQUET-360: Handle all map key types with cat tool's json dump",
        "message": "PARQUET-360: Handle all map key types with cat tool's json dump\n\nWhen dumping a parquet map with `parquet-cat --json` it throws a class cast exception as it doesn't properly handle all map key types.\n\n```\njava.lang.ClassCastException: [B cannot be cast to java.lang.String\n\tat org.apache.parquet.tools.read.SimpleMapRecord.toJsonObject(SimpleMapRecord.java:34)\n\tat org.apache.parquet.tools.read.SimpleRecord.toJsonValue(SimpleRecord.java:119)\n\tat org.apache.parquet.tools.read.SimpleRecord.toJsonObject(SimpleRecord.java:112)\n\tat org.apache.parquet.tools.read.SimpleRecord.prettyPrintJson(SimpleRecord.java:106)\n\tat org.apache.parquet.tools.command.CatCommand.execute(CatCommand.java:76)\n\tat org.apache.parquet.tools.Main.main(Main.java:222)\n[B cannot be cast to java.lang.String\n```\n\nAuthor: Nezih Yigitbasi <nyigitbasi@netflix.com>\n\nCloses #259 from nezihyigitbasi/parquet-cat-json and squashes the following commits:\n\nd047502 [Nezih Yigitbasi] Add unit test\ne4cd545 [Nezih Yigitbasi] Get rid of deprecated methods\nbdc8fdf [Nezih Yigitbasi] Handle all map key types with cat tool's json dump\n",
        "diff": {
            "parquet-tools/src/main/java/org/apache/parquet/tools/command/CatCommand.java": [
                1,
                1
            ],
            "parquet-tools/src/main/java/org/apache/parquet/tools/command/DumpCommand.java": [
                1,
                4
            ],
            "parquet-tools/src/main/java/org/apache/parquet/tools/command/HeadCommand.java": [
                1,
                1
            ],
            "parquet-tools/src/main/java/org/apache/parquet/tools/command/ShowSchemaCommand.java": [
                1,
                3
            ],
            "parquet-tools/src/main/java/org/apache/parquet/tools/read/SimpleMapRecord.java": [
                4,
                47
            ],
            "parquet-tools/src/test/java/org/apache/parquet/tools/read/TestSimpleMapRecord.java": [
                0,
                56
            ]
        }
    },
    "c3819688c48480ec75a9563c71f18ea755e34620": {
        "datetime": "2015-09-18T15:08:49-07:00",
        "summary": "PARQUET-355: Add Statistics Test for Parquet Columns",
        "message": "PARQUET-355: Add Statistics Test for Parquet Columns\n\nIn response to PARQUET-251 created an integration test that generates random values and compares the statistics against the values read from a parquet file.\n\nThere are two tools classes `DataGenerationContext` and `RandomValueGenerators` which are located in the same package as the unit test. I'm sure there is a better place to put these, but I leave that to your discretion.\n\nThanks\nReuben\n\nAuthor: Reuben Kuhnert <sircodesalot@gmail.com>\nAuthor: Ryan Blue <blue@apache.org>\n\nCloses #255 from sircodesalotOfTheRound/stats-validation and squashes the following commits:\n\n680e96a [Reuben Kuhnert] Merge pull request #1 from rdblue/PARQUET-355-stats-validation-tests\n9f0033f [Ryan Blue] PARQUET-355: Use ColumnReaderImpl.\n7d0b4fe [Reuben Kuhnert] PARQUET-355: Add Statistics Validation Test\n",
        "diff": {
            "parquet-column/src/main/java/org/apache/parquet/column/impl/ColumnReaderImpl.java": [
                3,
                3
            ],
            "parquet-hadoop/src/test/java/org/apache/parquet/statistics/RandomValues.java": [
                0,
                271
            ],
            "parquet-hadoop/src/test/java/org/apache/parquet/statistics/TestStatistics.java": [
                0,
                449
            ]
        }
    },
    "b1ea059a66c7d6d6bb4cb53d2005a9b7bb599ada": {
        "datetime": "2015-10-13T15:54:03-07:00",
        "summary": "PARQUET-381: Add feature to merge metadata (summary) files, and control which files are generated",
        "message": "PARQUET-381: Add feature to merge metadata (summary) files, and control which files are generated\n\n1) Add helper to merge 2 summary files, useful for merging 2 directories of data into 1\n2) Add more control over whether _common_metadata, _metadata, or both is written\n\nAuthor: Alex Levenson <alexlevenson@twitter.com>\n\nCloses #277 from isnotinvain/alexlevenson/merge-summary-files and squashes the following commits:\n\n86232f5 [Alex Levenson] Address comments\n96b9495 [Alex Levenson] Fix null extraMetaData\n099c913 [Alex Levenson] Make deprecated method delegate to new method\n7a98957 [Alex Levenson] Merge branch 'master' into alexlevenson/merge-summary-files\nddaf4ff [Alex Levenson] Introduce job summary levels for controlling which metadata files are generated\n87a2ebc [Alex Levenson] Update comments\n9d2b8da [Alex Levenson] Add helper method for merging metadata files\n",
        "diff": {
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ParquetFileReader.java": [
                2,
                11
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ParquetFileWriter.java": [
                5,
                60
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ParquetOutputCommitter.java": [
                16,
                50
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ParquetOutputFormat.java": [
                1,
                50
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/example/ExampleParquetWriter.java": [
                1,
                10
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/example/GroupWriteSupport.java": [
                2,
                10
            ],
            "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/TestMergeMetadataFiles.java": [
                0,
                215
            ],
            "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/TestParquetFileWriter.java": [
                2,
                3
            ],
            "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/TestParquetOutputFormatJobSummaryLevel.java": [
                0,
                69
            ]
        }
    },
    "5294c64b342818e021800b38413f36f426e35b3c": {
        "datetime": "2015-10-19T15:51:07-07:00",
        "summary": "PARQUET-373: Fix flaky MemoryManager tests.",
        "message": "PARQUET-373: Fix flaky MemoryManager tests.\n\nAuthor: Ryan Blue <blue@apache.org>\n\nCloses #269 from rdblue/PARQUET-373-fix-flaky-mem-manager-tests and squashes the following commits:\n\n1b55889 [Ryan Blue] PARQUET-373: Fix flaky MemoryManager tests.\n",
        "diff": {
            "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/TestMemoryManager.java": [
                54,
                115
            ]
        }
    },
    "d5eb86348347aacb152665ece8ab6c4e1a03b2f1": {
        "datetime": "2015-10-27T15:08:17-07:00",
        "summary": "PARQUET-369: Add shaded SLF4J NOP binding.",
        "message": "PARQUET-369: Add shaded SLF4J NOP binding.\n\nThis silences the complaint that no logger implementation could be\nfound. No logger implementation was possible because the class that\nSLF4J was trying to load had been relocated. The only options are to\nrelocate an implementation along with SLF4J or not shade SLF4J. This\nadds the NOP logger to silence the warning.\n\nAuthor: Ryan Blue <blue@apache.org>\n\nCloses #32 from rdblue/PARQUET-369-fix-slf4j-binding and squashes the following commits:\n\nf993a91 [Ryan Blue] PARQUET-369: Add shaded SLF4J NOP binding.\n",
        "diff": {
            "pom.xml": null
        }
    },
    "5a45ae3b1deb5117cb9e9a13141eeab1e9ad3d71": {
        "datetime": "2015-10-29T15:42:43-07:00",
        "summary": "PARQUET-241: Fix ParquetInputFormat.getFooters() order",
        "message": "PARQUET-241: Fix ParquetInputFormat.getFooters() order\n\nParquetInputFormat.getFooters() should return in the same order as what listStatus() returns\n\nAuthor: Mingyu Kim <mkim@palantir.com>\n\nCloses #164 from mingyukim/parquet-241 and squashes the following commits:\n\n86fe900 [Mingyu Kim] Address PR comments\nb0181e2 [Mingyu Kim] PARQUET-241: ParquetInputFormat.getFooters() should return in the same order as what listStatus() returns\n",
        "diff": {
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ParquetInputFormat.java": [
                18,
                31
            ],
            "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/TestInputFormat.java": [
                1,
                64
            ]
        }
    },
    "6b605a4ea05b66e1a6bf843353abcb4834a4ced8": {
        "datetime": "2015-11-04T09:13:09-08:00",
        "summary": "PARQUET-77: ByteBuffer use in read and write paths",
        "message": "PARQUET-77: ByteBuffer use in read and write paths\n\nThis work is based on the GSOC project from the summer of 2014. We have expanded on it to fix bugs and change the write path to use ByteBuffers as well. This PR replaces the earlier PRs #6, #49 and #50\n\nAuthor: Jason Altekruse <altekrusejason@gmail.com>\nAuthor: sunyu <stormdsy@gmail.com>\nAuthor: adeneche <adeneche@gmail.com>\nAuthor: Jacques Nadeau <jacques@apache.org>\nAuthor: Parth Chandra <pchandra@maprtech.com>\nAuthor: stormdsy@gmail.com <stormdsy@gmail.com>\nAuthor: Jason Altekruse <altekrusejason@open-math.com>\nAuthor: dsy <stormdsy@gmail.com>\nAuthor: Steven Phillips <sphillips@maprtech.com>\nAuthor: Gera Shegalov <gera@twitter.com>\nAuthor: Ryan Blue <blue@apache.org>\n\nCloses #267 from jaltekruse/1.6.0rc3-drill-r0.3-merge and squashes the following commits:\n\n56316d0 [Jason Altekruse] An exception out of the read method doesn't necessarily mean something is very wrong, so it shouldn't get wrapped in a ShouldNeverHappenException. This invocationTargetException will wrap any kind of exception coming out of the method, including an IOException.\n58340d8 [Jason Altekruse] Fix CompatibilityUtil, primary issue was a small error in the package name for the class that was being used to detect if the Hadoop 2.x API was available.\n96e19a8 [Jason Altekruse] Properly set the byte buffer position when reading out of a filesystem that does not implement the byte buffer based read method in the Hadoop 2.x API.\n269daef [Jason Altekruse] Make CodecFactory public\nbd7aa97 [Jason Altekruse] Remove unused imports, one of which has been moved to package private and is no longer accessible in this class.\na44fdba [Jason Altekruse] Fix logging and restrict access to classes inside of CodecFactory.\n723701c [Jason Altekruse] Adding isDirect interface to ByteBufferAllocator to add a restriction on the allocators used by a DirectCodecFactory.\n10b5ba3 [Jason Altekruse] Remove unneeded TODO\n57491a2 [Jason Altekruse] Delete older version of test file, all of these tests look to be covered in the newer version.\nd6501b1 [Jason Altekruse] Thought I had fixed this double deallocation earlier, guess the change got lost somewhere.\na8d2dc1 [Jason Altekruse] Address review comments.\n40714a4 [Jason Altekruse] Move pageSize to the constructor of codecfactory rather than the method for getting a compressor.\ndf7fd9c [Jason Altekruse] Limit access to classes and methods used for reflection based access to Hadoop 2.0 compression APIs.\n192c717 [Jason Altekruse] Fix error message\n1a47767 [Jason Altekruse] Address review comments\n5869156 [Jason Altekruse] Move fallback classes from HeapCodecFactory to the DirectCodecFactory\n3945674 [Jason Altekruse] Switch to using the DirectCodecFactory everywhere, one test is failing form the command line that is passing in intellij.\ne7f7f7f [Jason Altekruse] WIP - removing unneeded generics form CodecFactories\n659230f [Jason Altekruse] Remove second version of the class ByteBufferBytesInput that was nested in DirectCodecFactory. Replace with the one that was declared in the BytesInput class.\nc305984 [Jason Altekruse] Adding back code generation for method to take a byte array as well as the new implementation that takes a Bytebuffer.\nb8f54c2 [Jason Altekruse] Add a unit test for ByteBufferBackedBinary.\nae58486 [Jason Altekruse] Changing argument lists that previously included both an allocator and a ParquetProperties object.\nb4266fb [Jason Altekruse] Add license header to new class\nf8e5988 [Jason Altekruse] Added javadocs, removed unused code in DirectCodecFactory\nd332ca7 [Jason Altekruse] Add test for UnsignedVarIntBytesInput\nb7a6457 [Jason Altekruse] fix license leader\n8ff878a [Jason Altekruse] Addressing review comments\n862eb13 [Jason Altekruse] Fix usage of old constructor in Thrift module that caused a compilation failure. I had been skipping this module entirely during my work as the tests will fail to compile without a binary version of thrift 0.7, which seems hard to come by or compile yourself on Mac OS X.\n0496350 [Jason Altekruse] Add unit test for direct codec factory.\nda1b52a [Jason Altekruse] Moving classes into parquet from Drill.\n2f1a6c7 [Jason Altekruse] Consolidate a little more code\n8f66e43 [Jason Altekruse] Create utility methods to transform checked exceptions to unchecked when using reflection.\nf217e6a [Jason Altekruse] Restore old interfaces\nd5536b6 [Jason Altekruse] Restore original name of CapacityByteArrayOutputStream to keep compatibility with 1.7\n4c3195e [Jason Altekruse] Turn back on SemVer\n2e95915 [Jason Altekruse] Addressing minor review comments, comments out code, star import, formatting\na793be8 [Jason Altekruse] Add closeQuietly method to convert checked  IOExceptions from classless into runtime exceptions. Remove a bunch of unused imports from when there were previously try catch blocks that did this wrapping themselves (many actually were refactored to remove any need for special exception handling in an earlier commit, only one is actually using the new method).\nfdb689c [Jason Altekruse] Remove unnecessary copy writing a Binary to an OutputStream if it is backed by a byte array.\nd4819b4 [Jason Altekruse] remove methods now unneccesary as same implementation has been moved to the base class.\nad58bbe [Jason Altekruse] Addressing small review comments, unused imports, doc cleanup, etc.\n9fb65dd [Jason Altekruse] Rename method to get a dictionary page to clarify that the dictionary will be closed and not available for further insertion.\ne79684e [Jason Altekruse] Review comments - fixing use of ParquetProperties and removing unused interfaces on PageWriter\nb1040a8 [Jason Altekruse] Remove code used to debug a test that was failing after the initial merge.\n9dccb94 [Jason Altekruse] Add new method to turn BytesInput into an InputStream.\nf0e31ec [Jason Altekruse] revert small formatting and renaming changes, TODO make sure these result in a net diff of no changes (or only intended functional changes)\n0098b1c [Jason Altekruse] Remove unused method\n8c6e4a9 [Jason Altekruse] Addressing review comments, moving code out of generated class into abstract base class.\n29cc747 [Jason Altekruse] Factor out common code\n6959db7 [Jason Altekruse] addressing review comments, avoiding unnecessary copies when creating ByteBuffers\nfec4242 [Jason Altekruse] Address review comments - factoring out code in tests\n104a1d1 [Jason Altekruse] Remove test requiring a hard-coded binary file. This was actually a bad file being produced by Drill because we were not flushing the RecordConsumer.\n86317b0 [Jason Altekruse] Address review comments, make field in immutable ParquetProperties object final, make an interface now expecting a ByteBuffer deprecated for the version that takes a byte[].\n1971fc5 [Jason Altekruse] Fixes made while debugging drill unit tests\nebae775 [Jason Altekruse] Fix issue reading page data into an off-heap ByteBuffer\n705b864 [Jason Altekruse] Rename CapacityByteArrayOutputStream to CapacityByteBufferOutputStream to reflect new implementation internals. Add close method to CapacityByteBufferOutputStream and a few other classes.\n35d8386 [Jason Altekruse] Move call to getBytes() on dictionaryPages to remove the need to cache a list of dictionaryEncoders to be closed later.\nd40706b [Jason Altekruse] Get rid of unnecessary calls to Bytebuffer.wrap(byte[]), as an interface that takes a byte array is still available.\nfddd4af [Jason Altekruse] WIP - removing copies from the ByteBufferBasedBinary equals, compareTo, hashCode methods. Current tests are passing, but I should add some new ones.\n829af6f [Jason Altekruse] WIP - getting rid of unnecessary copies in Binary.java\n23ad48e [Jason Altekruse] WIP - addressing review comments\n7e252f3 [Jason Altekruse] WIP - addressing review comments\n1f4f504 [Jason Altekruse] WIP - addressing review comments\nab54c4e [Jason Altekruse] Moving classes out of the old packages.\n45cadee [Jason Altekruse] Cleaning up code in Binary after merge.\n864b011 [Jason Altekruse] Simplifying how buffer allocators are passed when creating ValuesWriters.\n2b8328b [Jason Altekruse] I all of the tests are now passing after the merge.\n1bfa3a0 [Jason Altekruse] Merge branch 'master' into 1.6.0rc3-drill-r0.3-merge\n9bbc269 [Jacques Nadeau] Update to 1.6.0rc3-drill-r0.3\n9f22bd7 [Jacques Nadeau] Make CodecFactory pluggable\n4a9dd28 [Jacques Nadeau] update pom version\n173aa25 [Jacques Nadeau] Set max preferred slab size to 16mb\nc98ec2a [adeneche] bumped version to 1.6.0rc3-drill-r0.1\n51cf2f1 [Ryan Blue] cherry pick pull#188\ne1df3b9 [adeneche] disabled enforcer and changed version to -drill\n6943536 [adeneche] fixing bug related to testDictionaryError_419\n48cceef [Steven Phillips] Fix allocation in DictionaryValuesWriter\n98b99ea [Parth Chandra] Revert readFooter to not use ZeroCopy path.\na6389db [Steven Phillips] Make constructor for PrimitiveType that takes decimalMetadata public.\ne488924 [adeneche] after merge code cleanup\n35b10af [Parth Chandra] Use ByteBuffers in the Write path. Allow callers to pass in an allocator to allocate the ByteBuffer.\n2187697 [Jacques Nadeau] Update Binary to make a copy of data for initial statistics.\n8143174 [adeneche] update pig.version to build with Hadoop 2 jars\n2c2b183 [Parth Chandra] Remove Zero Copy read path while reading footers\n7bc2a4d [Parth Chandra] Make a copy of Min and Max values for BinaryStatistics so that direct memory can be released before stats are written.\n5bc8774 [Parth Chandra] Update Snappy Codec to implement DirectDecompressionCodec interface Add compatibility function to read directly into a byte buffer\n0d22908 [adeneche] merging with master\n8be638a [sunyu] Address tsdeng's comments\n861e541 [dsy] enable enforcer check.\n912cbaf [sunyu] fix a bug in equals in ByteBuffer Binary with offset and length\n016e89c [sunyu] remove some unncessary codes. add compatible method initFromPage in ValueReaders. add toByteBuffer method in ByteBufferInputStream. add V21FileAPI class to encapsulate v21 APIs and make it a singlton. add ByteBuffer based equal and compareto method in Binary.\n26dc879 [dsy] disable enforcer to pass build.\na7bcfbb [sunyu] Make BytePacker consume ByteBuffer directly.\n01c2ae5 [sunyu] Implement FSDISTransport in Compatible layer. Fix bugs in Binary.\n47b177d [sunyu] Move CompatibilityUtil to parquet.hadoop.util. Use reflect to call new API to keep compatible.\n970fc8b [stormdsy@gmail.com] Add a Hadoop compatible layer to abstract away the zero copy API and old API.\n4f399aa [stormdsy@gmail.com] Add original readIntLittleEndian function to keep compatible with previous verision.\n7ac1df5 [stormdsy@gmail.com] Using Writable Channel to replace write to OutputStream one by one.\n36aba13 [sunyu] Read from ByteBuffer instead of ByteArray to avoid unnecessary array copy through read path.\n53500d4 [sunyu] Add ByteBufferInputStream and modify Chunk to consume ByteBuffer instead of byte array.\ndf1ad93 [stormdsy@gmail.com] Reading chunk using zero-copy API\n2d32f49 [Gera Shegalov] Reading file metadata using zero-copy API\n686d598 [Gera Shegalov] Use ByteBuf-based api to read magic.\n",
        "diff": {
            "parquet-column/src/main/java/org/apache/parquet/column/ColumnWriteStore.java": [
                0,
                6
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/ColumnWriter.java": [
                0,
                11
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/ParquetProperties.java": [
                18,
                35
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/impl/ColumnReaderImpl.java": [
                5,
                6
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/impl/ColumnWriteStoreV1.java": [
                2,
                12
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/impl/ColumnWriteStoreV2.java": [
                0,
                11
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/impl/ColumnWriterV1.java": [
                5,
                17
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/impl/ColumnWriterV2.java": [
                4,
                23
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/page/PageWriter.java": [
                1,
                1
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/values/ValuesReader.java": [
                3,
                16
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/values/ValuesWriter.java": [
                1,
                12
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/values/bitpacking/BitPackingValuesReader.java": [
                6,
                7
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/values/bitpacking/BitPackingValuesWriter.java": [
                2,
                8
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/values/bitpacking/ByteBitPackingValuesReader.java": [
                4,
                10
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/values/bitpacking/ByteBitPackingValuesWriter.java": [
                0,
                1
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/values/boundedint/BitReader.java": [
                3,
                4
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/values/boundedint/BitWriter.java": [
                2,
                10
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/values/boundedint/BoundedIntValuesFactory.java": [
                2,
                3
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/values/boundedint/BoundedIntValuesReader.java": [
                2,
                3
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/values/boundedint/BoundedIntValuesWriter.java": [
                2,
                8
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/values/boundedint/ZeroIntegerValuesReader.java": [
                1,
                2
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/values/delta/DeltaBinaryPackingValuesReader.java": [
                7,
                8
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/values/delta/DeltaBinaryPackingValuesWriter.java": [
                4,
                13
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/values/deltalengthbytearray/DeltaLengthByteArrayValuesReader.java": [
                5,
                6
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/values/deltalengthbytearray/DeltaLengthByteArrayValuesWriter.java": [
                3,
                11
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/values/deltastrings/DeltaByteArrayReader.java": [
                2,
                3
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/values/deltastrings/DeltaByteArrayWriter.java": [
                3,
                11
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/values/dictionary/DictionaryValuesReader.java": [
                6,
                7
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/values/dictionary/DictionaryValuesWriter.java": [
                35,
                53
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/values/dictionary/PlainValuesDictionary.java": [
                12,
                14
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/values/fallback/FallbackValuesWriter.java": [
                3,
                9
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/values/plain/BinaryPlainValuesReader.java": [
                5,
                5
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/values/plain/BooleanPlainValuesReader.java": [
                2,
                3
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/values/plain/BooleanPlainValuesWriter.java": [
                0,
                6
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/values/plain/FixedLenByteArrayPlainValuesReader.java": [
                4,
                5
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/values/plain/FixedLenByteArrayPlainValuesWriter.java": [
                2,
                11
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/values/plain/PlainValuesReader.java": [
                5,
                10
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/values/plain/PlainValuesWriter.java": [
                2,
                9
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/values/rle/RunLengthBitPackingHybridDecoder.java": [
                3,
                5
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/values/rle/RunLengthBitPackingHybridEncoder.java": [
                2,
                8
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/values/rle/RunLengthBitPackingHybridValuesReader.java": [
                3,
                4
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/values/rle/RunLengthBitPackingHybridValuesWriter.java": [
                2,
                8
            ],
            "parquet-column/src/main/java/org/apache/parquet/io/api/Binary.java": [
                39,
                175
            ],
            "parquet-column/src/main/java/org/apache/parquet/schema/PrimitiveType.java": [
                4,
                3
            ],
            "parquet-column/src/test/java/org/apache/parquet/column/impl/TestColumnReaderImpl.java": [
                0,
                1
            ],
            "parquet-column/src/test/java/org/apache/parquet/column/impl/TestCorruptDeltaByteArrays.java": [
                26,
                33
            ],
            "parquet-column/src/test/java/org/apache/parquet/column/mem/TestMemColumn.java": [
                1,
                2
            ],
            "parquet-column/src/test/java/org/apache/parquet/column/page/mem/MemPageWriter.java": [
                1,
                0
            ],
            "parquet-column/src/test/java/org/apache/parquet/column/values/Utils.java": [
                2,
                3
            ],
            "parquet-column/src/test/java/org/apache/parquet/column/values/bitpacking/BitPackingPerfTest.java": [
                1,
                2
            ],
            "parquet-column/src/test/java/org/apache/parquet/column/values/bitpacking/TestBitPackingColumn.java": [
                2,
                4
            ],
            "parquet-column/src/test/java/org/apache/parquet/column/values/boundedint/TestBoundedColumns.java": [
                4,
                7
            ],
            "parquet-column/src/test/java/org/apache/parquet/column/values/delta/DeltaBinaryPackingValuesWriterTest.java": [
                5,
                7
            ],
            "parquet-column/src/test/java/org/apache/parquet/column/values/delta/benchmark/BenchmarkIntegerOutputSize.java": [
                2,
                3
            ],
            "parquet-column/src/test/java/org/apache/parquet/column/values/delta/benchmark/BenchmarkReadingRandomIntegers.java": [
                3,
                5
            ],
            "parquet-column/src/test/java/org/apache/parquet/column/values/delta/benchmark/RandomWritingBenchmarkTest.java": [
                3,
                4
            ],
            "parquet-column/src/test/java/org/apache/parquet/column/values/delta/benchmark/SmallRangeWritingBenchmarkTest.java": [
                1,
                2
            ],
            "parquet-column/src/test/java/org/apache/parquet/column/values/deltalengthbytearray/TestDeltaLengthByteArray.java": [
                4,
                9
            ],
            "parquet-column/src/test/java/org/apache/parquet/column/values/deltalengthbytearray/benchmark/BenchmarkDeltaLengthByteArray.java": [
                2,
                3
            ],
            "parquet-column/src/test/java/org/apache/parquet/column/values/deltastrings/TestDeltaByteArray.java": [
                4,
                5
            ],
            "parquet-column/src/test/java/org/apache/parquet/column/values/deltastrings/benchmark/BenchmarkDeltaByteArray.java": [
                4,
                5
            ],
            "parquet-column/src/test/java/org/apache/parquet/column/values/dictionary/TestDictionary.java": [
                24,
                26
            ],
            "parquet-column/src/test/java/org/apache/parquet/column/values/rle/RunLengthBitPackingHybridIntegrationTest.java": [
                4,
                6
            ],
            "parquet-column/src/test/java/org/apache/parquet/column/values/rle/TestRunLengthBitPackingHybridEncoder.java": [
                9,
                21
            ],
            "parquet-column/src/test/java/org/apache/parquet/io/PerfTest.java": [
                1,
                2
            ],
            "parquet-column/src/test/java/org/apache/parquet/io/TestColumnIO.java": [
                3,
                21
            ],
            "parquet-column/src/test/java/org/apache/parquet/io/TestFiltered.java": [
                1,
                2
            ],
            "parquet-column/src/test/java/org/apache/parquet/io/api/TestBinary.java": [
                0,
                25
            ],
            "parquet-common/src/main/java/org/apache/parquet/IOExceptionUtils.java": [
                0,
                43
            ],
            "parquet-common/src/main/java/org/apache/parquet/OutputStreamCloseException.java": [
                0,
                46
            ],
            "parquet-common/src/main/java/org/apache/parquet/ParquetRuntimeException.java": [
                1,
                3
            ],
            "parquet-common/src/main/java/org/apache/parquet/bytes/ByteBufferAllocator.java": [
                0,
                38
            ],
            "parquet-common/src/main/java/org/apache/parquet/bytes/ByteBufferInputStream.java": [
                0,
                82
            ],
            "parquet-common/src/main/java/org/apache/parquet/bytes/BytesUtils.java": [
                0,
                24
            ],
            "parquet-common/src/main/java/org/apache/parquet/bytes/DirectByteBufferAllocator.java": [
                0,
                43
            ],
            "parquet-common/src/main/java/org/apache/parquet/bytes/HeapByteBufferAllocator.java": [
                0,
                44
            ],
            "parquet-encoding/src/main/java/org/apache/parquet/bytes/BytesInput.java": [
                1,
                83
            ],
            "parquet-encoding/src/main/java/org/apache/parquet/bytes/CapacityByteArrayOutputStream.java": [
                28,
                87
            ],
            "parquet-encoding/src/main/java/org/apache/parquet/bytes/LittleEndianDataOutputStream.java": [
                0,
                7
            ],
            "parquet-encoding/src/main/java/org/apache/parquet/column/values/bitpacking/BytePacker.java": [
                2,
                19
            ],
            "parquet-encoding/src/test/java/org/apache/parquet/bytes/TestBytesInput.java": [
                0,
                42
            ],
            "parquet-encoding/src/test/java/org/apache/parquet/bytes/TestCapacityByteArrayOutputStream.java": [
                3,
                3
            ],
            "parquet-encoding/src/test/java/org/apache/parquet/column/values/bitpacking/TestByteBitPacking.java": [
                2,
                3
            ],
            "parquet-encoding/src/test/java/org/apache/parquet/column/values/bitpacking/TestLemireBitPacking.java": [
                1,
                2
            ],
            "parquet-generator/src/main/java/org/apache/parquet/encoding/bitpacking/ByteBasedBitPackingGenerator.java": [
                5,
                21
            ],
            "parquet-hadoop/pom.xml": null,
            "parquet-hadoop/src/main/java/org/apache/parquet/format/converter/ParquetMetadataConverter.java": [
                0,
                1
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/CodecFactory.java": [
                54,
                119
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ColumnChunkPageReadStore.java": [
                3,
                3
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ColumnChunkPageWriteStore.java": [
                14,
                20
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/DirectCodecFactory.java": [
                0,
                522
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/InternalParquetRecordWriter.java": [
                8,
                13
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ParquetFileReader.java": [
                30,
                51
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ParquetFileWriter.java": [
                1,
                2
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ParquetOutputFormat.java": [
                2,
                3
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ParquetRecordWriter.java": [
                6,
                8
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ParquetWriter.java": [
                3,
                5
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/codec/SnappyDecompressor.java": [
                1,
                2
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/util/CompatibilityUtil.java": [
                0,
                114
            ],
            "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/TestColumnChunkPageWriteStore.java": [
                3,
                6
            ],
            "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/TestDirectCodecFactory.java": [
                0,
                165
            ],
            "parquet-pig/src/test/java/org/apache/parquet/pig/TupleConsumerPerfTest.java": [
                1,
                2
            ],
            "parquet-thrift/src/test/java/org/apache/parquet/thrift/TestParquetReadProtocol.java": [
                1,
                3
            ],
            "pom.xml": null
        }
    },
    "440882c659967572311402c7fe534cf13d501cf4": {
        "datetime": "2015-11-17T15:09:50-08:00",
        "summary": "PARQUET-364: Fix compatibility for Avro lists of lists.",
        "message": "PARQUET-364: Fix compatibility for Avro lists of lists.\n\nThis fixes lists of lists that have been written with Avro's 2-level\nrepresentation. The conversion setup logic missed the case where the\ninner field is repeated and cannot be the element in a 3-level list.\n\nThis also fixes the schema conversion for cases where an unknown\nwriter used a 2-level list of lists.\n\nThis is based on @liancheng's #264 but fixes the problem in a slightly different way.\n\nAuthor: Ryan Blue <blue@apache.org>\n\nCloses #272 from rdblue/PARQUET-364-fix-avro-lists-of-lists and squashes the following commits:\n\n41a70e0 [Ryan Blue] PARQUET-364: Fix compatibility for Avro lists of lists.\n",
        "diff": {
            "parquet-avro/src/main/java/org/apache/parquet/avro/AvroIndexedRecordConverter.java": [
                33,
                3
            ],
            "parquet-avro/src/main/java/org/apache/parquet/avro/AvroRecordConverter.java": [
                3,
                5
            ],
            "parquet-avro/src/main/java/org/apache/parquet/avro/AvroSchemaConverter.java": [
                4,
                6
            ],
            "parquet-avro/src/test/java/org/apache/parquet/avro/TestArrayCompatibility.java": [
                6,
                142
            ],
            "parquet-avro/src/test/java/org/apache/parquet/avro/TestAvroSchemaConverter.java": [
                0,
                92
            ]
        }
    },
    "09129877daf6f3b4b9cdb32432084dcbeb2fdde0": {
        "datetime": "2015-11-17T15:56:09-08:00",
        "summary": "PARQUET-380: Fix build when using thrift 0.9.0.",
        "message": "PARQUET-380: Fix build when using thrift 0.9.0.\n\nThis adds the correct version of libthrift as a dependency for\nparquet-cascading and parquet-scrooge, which overrides the 0.7.0\ndependency that elephantbird uses.\n\nAuthor: Ryan Blue <blue@apache.org>\n\nCloses #276 from rdblue/PARQUET-380-fix-thrift-0.9.0 and squashes the following commits:\n\ncbf0d84 [Ryan Blue] PARQUET-380: Fix build when using thrift 0.9.0.\n",
        "diff": {
            "parquet-cascading/pom.xml": null,
            "parquet-scrooge/pom.xml": null,
            "pom.xml": null
        }
    },
    "efafa61992658eab64c893e9eef49f545d75673c": {
        "datetime": "2015-11-19T10:46:07-08:00",
        "summary": "PARQUET-378: Add thoroughly parquet test encodings",
        "message": "PARQUET-378: Add thoroughly parquet test encodings\n\nA new test case TestTypeEncodings is added that test v1 and v2 encodings for all\nsupported column types. This test case spans many pages and row groups, and reads\neach page individually from first-to-last and from last-to-first.\n\nAuthor: Sergio Pena <sergio.pena@cloudera.com>\n\nCloses #274 from spena/parquet-378 and squashes the following commits:\n\nb35c339 [Sergio Pena] PARQUET-378: Add thoroughly parquet test encodings\n",
        "diff": {
            "parquet-hadoop/src/test/java/org/apache/parquet/encodings/FileEncodingsIT.java": [
                0,
                490
            ],
            "parquet-hadoop/src/test/java/org/apache/parquet/statistics/RandomValues.java": [
                9,
                9
            ],
            "pom.xml": null
        }
    },
    "630830476a6270e317e84229996a6bf92bd903ca": {
        "datetime": "2015-11-30T16:26:37-08:00",
        "summary": "PARQUET-396: Extend ParquetReader.Builder<T>",
        "message": "PARQUET-396: Extend ParquetReader.Builder<T>\n\nIn AvroParquetReader.Builder extend ParquetReader.Builder<T>\n\nAuthor: Chris Bannister <c.bannister@gmail.com>\n\nCloses #294 from Zariel/PARQUET-396 and squashes the following commits:\n\n79c1d0e [Chris Bannister] PARQUET-396: Extend ParquetReader.Builder<T>\n",
        "diff": {
            "parquet-avro/src/main/java/org/apache/parquet/avro/AvroParquetReader.java": [
                1,
                1
            ]
        }
    },
    "f4918bb0b1ba95c2bfc8585f015a2e8de0a6f35d": {
        "datetime": "2015-12-03T09:56:45-06:00",
        "summary": "PARQUET-398: Updates dev/COMMITTERS.md",
        "message": "PARQUET-398: Updates dev/COMMITTERS.md\n\nUpdates `dev/COMMITTERS.md` to test committership.\n\nAuthor: Cheng Lian <lian@databricks.com>\n\nCloses #298 from liancheng/parquet-389.test-committership and squashes the following commits:\n\n0cad244 [Cheng Lian] Updates dev/COMMITTERS.md\n",
        "diff": {
            "dev/COMMITTERS.md": null
        }
    },
    "e32aa6fe0d5260c21b35c34075eb5b69afbca464": {
        "datetime": "2015-12-04T00:49:51+08:00",
        "summary": "PARQUET-398: Add 'spena' information to dev/COMMITTERS.md",
        "message": "PARQUET-398: Add 'spena' information to dev/COMMITTERS.md\n\nAdd 'spena' information to `dev/COMMITTERS.md` to test committership.\n\nAuthor: Sergio Pena <sergio.pena@cloudera.com>\n\nCloses #299 from spena/parquet-398.test-committership and squashes the following commits:\n\n1c9f1da [Sergio Pena] PARQUET-398: Add 'spena' information to dev/COMMITTERS.md\n",
        "diff": {
            "dev/COMMITTERS.md": null
        }
    },
    "14097c64d243794610788d3ebb2e81ba8fd867c0": {
        "datetime": "2015-12-04T11:47:38-08:00",
        "summary": "PARQUET-387: Improve NPE message when avro arrays contain null.",
        "message": "PARQUET-387: Improve NPE message when avro arrays contain null.\n\nPreviously, the NPE had no error message but the Avro support accepts\nschemas that have nullable array elements.\n\nAuthor: Ryan Blue <blue@apache.org>\n\nCloses #291 from rdblue/PARQUET-387-fix-npe-message and squashes the following commits:\n\n39d3c83 [Ryan Blue] PARQUET-387: Update test case to verify help message.\nd6b6bd8 [Ryan Blue] PARQUET-387: Improve NPE message when avro arrays contain null.\n",
        "diff": {
            "parquet-avro/src/main/java/org/apache/parquet/avro/AvroWriteSupport.java": [
                4,
                34
            ],
            "parquet-avro/src/test/java/org/apache/parquet/avro/TestReadWriteOldListBehavior.java": [
                1,
                3
            ]
        }
    },
    "f2615d9a611db401cdedc022112c87ad938b5680": {
        "datetime": "2015-12-08T10:02:31-08:00",
        "summary": "PARQUET-349: VersionParser does not handle versions missing 'build' section",
        "message": "PARQUET-349: VersionParser does not handle versions missing 'build' section\n\nThis change reworks the regular expression in VersionParser.java to allow for missing 'version' and 'build' sections.\n\nAuthor: Reuben Kuhnert <reuben.kuhnert@cloudera.com>\n\nCloses #283 from sircodesalotOfTheRound/fix-version-test and squashes the following commits:\n\n0f4a22f [Reuben Kuhnert] PARQUET-349: VersionParser does not handle versions missing 'build' section.\n",
        "diff": {
            "parquet-common/src/main/java/org/apache/parquet/VersionParser.java": [
                3,
                3
            ],
            "parquet-common/src/test/java/org/apache/parquet/VersionTest.java": [
                0,
                17
            ]
        }
    },
    "dcd1c33f0dba247b43418b922c1c3a2fc432dc11": {
        "datetime": "2015-12-08T10:15:30-08:00",
        "summary": "PARQUET-352: Add object model property to file footers.",
        "message": "PARQUET-352: Add object model property to file footers.\n\nWriteSupport now has a getName getter method that is added to the footer\nif it returns a non-null string as writer.model.name. This is intended\nto help identify files written by object models incorrectly.\n\nAuthor: Ryan Blue <blue@apache.org>\n\nCloses #289 from rdblue/PARQUET-352-add-object-model-property and squashes the following commits:\n\n23f8f67 [Ryan Blue] PARQUET-352: Add object model property to file footers.\n",
        "diff": {
            "parquet-avro/src/main/java/org/apache/parquet/avro/AvroWriteSupport.java": [
                0,
                5
            ],
            "parquet-cascading/src/main/java/org/apache/parquet/cascading/TupleWriteSupport.java": [
                0,
                5
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/InternalParquetRecordWriter.java": [
                0,
                4
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ParquetWriter.java": [
                0,
                2
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/api/DelegatingWriteSupport.java": [
                0,
                5
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/api/WriteSupport.java": [
                0,
                12
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/example/GroupWriteSupport.java": [
                0,
                5
            ],
            "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/TestParquetWriter.java": [
                0,
                3
            ],
            "parquet-pig/src/main/java/org/apache/parquet/pig/TupleWriteSupport.java": [
                0,
                5
            ],
            "parquet-protobuf/src/main/java/org/apache/parquet/proto/ProtoWriteSupport.java": [
                0,
                5
            ],
            "parquet-scrooge/src/main/java/org/apache/parquet/scrooge/ScroogeWriteSupport.java": [
                0,
                5
            ],
            "parquet-thrift/src/main/java/org/apache/parquet/hadoop/thrift/TBaseWriteSupport.java": [
                0,
                5
            ],
            "parquet-thrift/src/main/java/org/apache/parquet/hadoop/thrift/ThriftBytesWriteSupport.java": [
                0,
                5
            ],
            "parquet-thrift/src/main/java/org/apache/parquet/hadoop/thrift/ThriftWriteSupport.java": [
                0,
                5
            ],
            "parquet-thrift/src/main/java/org/apache/parquet/thrift/pig/TupleToThriftWriteSupport.java": [
                0,
                5
            ]
        }
    },
    "a24d624aaabc14a455d18450d9127f88d1b4f8be": {
        "datetime": "2015-12-08T10:39:47-08:00",
        "summary": "PARQUET-305: Update logging to SLF4J.",
        "message": "PARQUET-305: Update logging to SLF4J.\n\nThis removes the Log implementation based on java.util.logging and\nreplaces it with SLF4J. The compiler removal of debug log messages still\nworks because Log.DEBUG and similar final constants are unchanged.\n\nThis commit adds slf4j-simple as the test logger implementation.\nConfiguration for slf4j-simple is in the root pom. Two modules can't use\nslf4j-simple, parquet-pig and parquet-thrift, and use slf4j-log4j12\ninstead because pig depends on log4j and tests die without it.\n\nAuthor: Ryan Blue <blue@apache.org>\n\nCloses #290 from rdblue/PARQUET-305-update-logging and squashes the following commits:\n\n89257e8 [Ryan Blue] PARQUET-305: Remove deprecation annotations on Log.\n9f9b99a [Ryan Blue] PARQUET-305: Update logging to SLF4J.\n",
        "diff": {
            "parquet-avro/pom.xml": null,
            "parquet-benchmarks/pom.xml": null,
            "parquet-cascading/pom.xml": null,
            "parquet-column/pom.xml": null,
            "parquet-common/pom.xml": null,
            "parquet-common/src/main/java/org/apache/parquet/Log.java": [
                72,
                15
            ],
            "parquet-encoding/pom.xml": null,
            "parquet-hadoop/pom.xml": null,
            "parquet-pig/pom.xml": null,
            "parquet-protobuf/pom.xml": null,
            "parquet-scala/pom.xml": null,
            "parquet-scrooge/pom.xml": null,
            "parquet-thrift/pom.xml": null,
            "parquet-tools/pom.xml": null,
            "pom.xml": null
        }
    },
    "56326400fcb5df7bd9336f143f7a3b7d601e5f58": {
        "datetime": "2015-12-08T14:41:38-08:00",
        "summary": "PARQUET-99: Add page size check properties",
        "message": "PARQUET-99: Add page size check properties\n\nThis adds properties to set the min and max number of records that are passed between page checks, as well as a property that controls whether the next check will be based on records already seen or set to the minimum number of records between checks.\n\n* `parquet.page.size.row.check.min` - minimum number of records between page size checks\n* `parquet.page.size.row.check.max` - maximum number of records between page size checks\n* `parquet.page.size.check.estimate` - whether to estimate the number of records before the next check, or to always use the minimum number of records.\n\nThis also updates the internal API to use ParquetProperties to carry encoding settings (used in parquet-column) to reduce the number of parameters passed through internal APIs. It also adds a builder for ParquetProperties to avoid needing to reference defaults in other modules.\n\nThis closes #250\n\nAuthor: Daniel Weeks <dweeks@netflix.com>\nAuthor: Ryan Blue <blue@apache.org>\n\nCloses #297 from rdblue/parquet-properties-update and squashes the following commits:\n\nc93b73e [Ryan Blue] PARQUET-99: Use ParquetProperties to carry encoding config.\n18f8d3a [Daniel Weeks] Spacing\n2090719 [Daniel Weeks] Update sizeCheck to write page properly if estimating is turned off\n71336ee [Daniel Weeks] Fixed param name\n5d99072 [Daniel Weeks] Update page size checking for v2 writer\n3f7870c [Daniel Weeks] Rebase to resolve byte buffer conflicts\n68794f0 [Daniel Weeks] Merge branch 'master' into page_size_check\nb49f03c [Daniel Weeks] Fixed reset of nextSizeCheck\na057f46 [Daniel Weeks] Fixed inverted property logic\ne7cd54b [Daniel Weeks] Added property to toggle page size check estimation and initial row size checking\n",
        "diff": {
            "parquet-column/src/main/java/org/apache/parquet/column/ParquetProperties.java": [
                43,
                202
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/impl/ColumnWriteStoreV1.java": [
                13,
                6
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/impl/ColumnWriteStoreV2.java": [
                25,
                23
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/impl/ColumnWriterV1.java": [
                27,
                21
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/impl/ColumnWriterV2.java": [
                11,
                4
            ],
            "parquet-column/src/test/java/org/apache/parquet/column/impl/TestColumnReaderImpl.java": [
                3,
                8
            ],
            "parquet-column/src/test/java/org/apache/parquet/column/impl/TestCorruptDeltaByteArrays.java": [
                2,
                4
            ],
            "parquet-column/src/test/java/org/apache/parquet/column/mem/TestMemColumn.java": [
                3,
                6
            ],
            "parquet-column/src/test/java/org/apache/parquet/io/PerfTest.java": [
                3,
                7
            ],
            "parquet-column/src/test/java/org/apache/parquet/io/TestColumnIO.java": [
                3,
                7
            ],
            "parquet-column/src/test/java/org/apache/parquet/io/TestFiltered.java": [
                3,
                7
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/InternalParquetRecordWriter.java": [
                18,
                5
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ParquetOutputFormat.java": [
                21,
                50
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ParquetRecordWriter.java": [
                5,
                42
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ParquetWriter.java": [
                29,
                26
            ],
            "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/TestUtils.java": [
                1,
                6
            ],
            "parquet-pig/src/test/java/org/apache/parquet/pig/TupleConsumerPerfTest.java": [
                3,
                6
            ],
            "parquet-thrift/src/test/java/org/apache/parquet/thrift/TestParquetReadProtocol.java": [
                4,
                6
            ]
        }
    },
    "b45c4bdb496381b5f90df6872edca12e0a2e68ca": {
        "datetime": "2015-12-08T14:45:48-08:00",
        "summary": "PARQUET-382: Add methods to append encoded data to files.",
        "message": "PARQUET-382: Add methods to append encoded data to files.\n\nThis allows appending encoded data blocks to open ParquetFileWriters,\nwhich makes it possible to merge multiple Parquet files without\nre-encoding all of the records.\n\nThis works by finding the column chunk for each column in the file\nschema and then streaming the encoded data from one file to the other.\nNew starting offsets are tracked and the column chunk metadata in the\nfooter is updated with the new starting positions.\n\nAuthor: Ryan Blue <blue@apache.org>\n\nCloses #278 from rdblue/PARQUET-382-append-encoded-blocks and squashes the following commits:\n\ncb98552 [Ryan Blue] PARQUET-382: Add methods to append encoded data to files.\n",
        "diff": {
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ParquetFileReader.java": [
                0,
                9
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ParquetFileWriter.java": [
                11,
                149
            ],
            "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/TestParquetWriterAppendBlocks.java": [
                0,
                310
            ]
        }
    },
    "49169033546d893dae3db903a2fa6af712f125c0": {
        "datetime": "2015-12-11T13:17:04-08:00",
        "summary": "PARQUET-353: Release compression resources.",
        "message": "PARQUET-353: Release compression resources.\n\nThis updates the use of CodecFactory in the output format and writer\nclasses so that its lifecycle is tied to ParquetWriter and\nParquetRecordWriter. When those classes are closed, the resources held\nby the CodecFactory associated with the instance are released.\n\nThis is an alternative to and closes #282.\n\nAuthor: Ryan Blue <blue@apache.org>\n\nCloses #295 from rdblue/PARQUET-353-release-compressor-resources and squashes the following commits:\n\na00f4b7 [Ryan Blue] PARQUET-353: Release compression resources.\n",
        "diff": {
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ParquetOutputFormat.java": [
                7,
                4
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ParquetRecordWriter.java": [
                17,
                34
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ParquetWriter.java": [
                1,
                5
            ]
        }
    },
    "fa7588c4c0f8d403e4815fa72e3b8a3bc98d73ec": {
        "datetime": "2015-12-12T15:35:21-08:00",
        "summary": "PARQUET-334: UT test failure with Pig 0.15",
        "message": "PARQUET-334: UT test failure with Pig 0.15\n\nI made a few updates to the original patch PARQUET-334-1.patch proposed by Daniel. As the inputschema is maintained in EvalFunc, any reference to the private class variable inputSchema should be changed to getInputSchema(), and inputSchema can be removed because it will be null always.\n\nAuthor: Thomas Friedrich <tfriedr@us.ibm.com>\n\nCloses #292 from tfriedr/parquet-334 and squashes the following commits:\n\n012563e [Thomas Friedrich] PARQUET_334: UT test failure with Pig 0.15\n",
        "diff": {
            "parquet-pig/src/main/java/org/apache/parquet/pig/summary/Summary.java": [
                54,
                2
            ]
        }
    },
    "367fe13b46a0b4dda56b7f12273d6c9afb1da23f": {
        "datetime": "2015-12-16T11:41:46-08:00",
        "summary": "PARQUET-318: Remove unnecessary object mapper",
        "message": "PARQUET-318: Remove unnecessary object mapper\n\nAuthor: Nezih Yigitbasi <nyigitbasi@netflix.com>\n\nCloses #227 from nezihyigitbasi/318 and squashes the following commits:\n\nb8e4ca9 [Nezih Yigitbasi] Remove unnecessary object mapper\n",
        "diff": {
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/metadata/ParquetMetadata.java": [
                9,
                10
            ],
            "parquet-hadoop/src/test/java/org/apache/parquet/format/converter/TestParquetMetadataConverter.java": [
                1,
                11
            ]
        }
    },
    "fbb2c9e7230cc84c9458c9bf313d7cec7af310f3": {
        "datetime": "2015-12-17T15:42:14-08:00",
        "summary": "PARQUET-404: Replace git@github.com.apache for HTTPS URL on dev/README.md to avoid permission issues",
        "message": "PARQUET-404: Replace git@github.com.apache for HTTPS URL on dev/README.md to avoid permission issues\n\n\u2026lic key on committer github account is needed\n\n@julienledem @rdblue @liancheng Could you help me review this trivial patch for dev/README.md?\n\nAuthor: Sergio Pena <sergio.pena@cloudera.com>\n\nCloses #301 from spena/parquet-404 and squashes the following commits:\n\n97557f6 [Sergio Pena] PARQUET-404: Replace git@github.com.apache for HTTPS URL on dev/README.md to avoid permission issues\n",
        "diff": {
            "dev/README.md": null
        }
    },
    "368588b5c5c4140f39ea8b9a8ceb3d1af0708804": {
        "datetime": "2016-01-07T10:48:02-06:00",
        "summary": "PARQUET-413: Fix Java 8 test failure.",
        "message": "PARQUET-413: Fix Java 8 test failure.\n\nThe footer merge tests rely the order of unmergable values. This uses a\nLinkedHashSet to ensure the order doesn't change.\n\nAuthor: Ryan Blue <blue@apache.org>\n\nCloses #304 from rdblue/PARQUET-413-java-8-test-failure and squashes the following commits:\n\n57a83a8 [Ryan Blue] PARQUET-413: Fix Java 8 test failure.\n",
        "diff": {
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ParquetFileWriter.java": [
                1,
                2
            ]
        }
    },
    "37f72dc079c4cd69b2de16f3532b55f8108d3ac8": {
        "datetime": "2016-01-12T14:15:40-08:00",
        "summary": "PARQUET-212: Implement LIST read compatibility rules in Thrift",
        "message": "PARQUET-212: Implement LIST read compatibility rules in Thrift\n\nThis implements the read-side compatibility rules for 2-level and 3-level lists in Thrift.\n\nThrift doesn't allow null elements inside lists, but 3-level lists may have optional elements. This PR adds a property, parquet.thrift.ignore-null-elements, that allows thrift to read lists with optional elements by ignoring nulls. This is off by default, but is provided as an opt-in for compatibility with data written by Hive.\n\nThrift's schema conversion does not change because a Thrift class (or Scrooge etc.) must be set in a file's metadata or provided when constructing a reader.\n\nThis replaces and closes #144.\n\nAuthor: Ryan Blue <blue@apache.org>\n\nCloses #300 from rdblue/PARQUET-212-fix-thrift-3-level-lists and squashes the following commits:\n\nac7c405 [Ryan Blue] PARQUET-212: Add tests for list of list cases from PARQUET-364.\n356fdb7 [Ryan Blue] PARQUET-212: Rename isElementType => isListElementType.\n5d3b094 [Ryan Blue] PARQUET-212: Fix list handling with projection.\nb5f207f [Ryan Blue] PARQUET-212: Add Configuration to the ThriftRecordConverter ctor.\nb87eb65 [Ryan Blue] PARQUET-212: Add property to ignore nulls in lists.\n3d1e92f [Ryan Blue] PARQUET-212: Update thrift reads for LIST compatibility rules.\n0bf2b45 [Ryan Blue] PARQUET-212: Read non-thrift files if a Thrift class is supplied.\n4e148dc [Ryan Blue] PARQUET-212: Add DirectWriterTest base class.\n",
        "diff": {
            "parquet-avro/pom.xml": null,
            "parquet-avro/src/main/java/org/apache/parquet/avro/AvroRecordConverter.java": [
                5,
                8
            ],
            "parquet-avro/src/test/java/org/apache/parquet/avro/TestArrayCompatibility.java": [
                74,
                2
            ],
            "parquet-hadoop/src/test/java/org/apache/parquet/DirectWriterTest.java": [
                0,
                102
            ],
            "parquet-scrooge/src/main/java/org/apache/parquet/scrooge/ScroogeRecordConverter.java": [
                2,
                11
            ],
            "parquet-thrift/pom.xml": null,
            "parquet-thrift/src/main/java/org/apache/parquet/hadoop/thrift/ThriftReadSupport.java": [
                12,
                51
            ],
            "parquet-thrift/src/main/java/org/apache/parquet/thrift/TBaseRecordConverter.java": [
                1,
                11
            ],
            "parquet-thrift/src/main/java/org/apache/parquet/thrift/ThriftMetaData.java": [
                2,
                19
            ],
            "parquet-thrift/src/main/java/org/apache/parquet/thrift/ThriftRecordConverter.java": [
                18,
                105
            ],
            "parquet-thrift/src/main/java/org/apache/parquet/thrift/ThriftSchemaConverter.java": [
                0,
                38
            ],
            "parquet-thrift/src/test/java/org/apache/parquet/hadoop/thrift/TestArrayCompatibility.java": [
                0,
                779
            ],
            "parquet-thrift/src/test/thrift/array_compat.thrift": null
        }
    },
    "84b2b74179da8e279e2fafdafd031748c285e1b7": {
        "datetime": "2016-01-12T14:21:32-08:00",
        "summary": "PARQUET-421: Fix mismatch of javadoc names and method parameters in m...",
        "message": "PARQUET-421: Fix mismatch of javadoc names and method parameters in m...\n\n\u2026odule encoding, column, and hadoop\n\nCodes change now and then, but some corresponding doc comments are left out.\n\nThis PR fixes only the doc comments that should have been changed. It should be OK, since none codes are touched.\n\n@rdblue could you take a look please? Cheers.\n\nAuthor: proflin <proflin.me@gmail.com>\n\nCloses #307 from proflin/Minor--Fix-the-mismatch-of-the-parameters-and-their-doc-comments-in-module-encoding,-column,-and-hadoop and squashes the following commits:\n\n34c7b01 [proflin] Minor: Fix the mismatch of the parameters and their doc comments in module encoding, column, and hadoop\n",
        "diff": {
            "parquet-column/src/main/java/org/apache/parquet/column/page/DataPageV1.java": [
                2,
                2
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/values/ValuesWriter.java": [
                7,
                7
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/values/plain/BooleanPlainValuesReader.java": [
                2,
                2
            ],
            "parquet-column/src/main/java/org/apache/parquet/schema/TypeConverter.java": [
                1,
                1
            ],
            "parquet-encoding/src/main/java/org/apache/parquet/column/values/bitpacking/BitPacking.java": [
                1,
                1
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/example/ExampleOutputFormat.java": [
                3,
                3
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/metadata/ParquetMetadata.java": [
                1,
                0
            ]
        }
    },
    "30ee10d2740fe1f28595989c6b21f22b75a147fc": {
        "datetime": "2016-01-12T14:45:24-08:00",
        "summary": "PARQUET-422: Fix a potential bug in MessageTypeParser where we ignore\u2026",
        "message": "PARQUET-422: Fix a potential bug in MessageTypeParser where we ignore\u2026\n\n\u2026 and overwrite the initial value of a method parameter\n\nIn org.apache.parquet.schema.MessageTypeParser, for addGroupType() and addPrimitiveType(), the initial value of this parameter t is ignored, and t is overwritten here.\n\nThis often indicates a mistaken belief that the write to the parameter will be conveyed back to the caller.\n\nThis is a bug found by FindBugs\u2122.\n\nAuthor: proflin <proflin.me@gmail.com>\n\nCloses #308 from proflin/PARQUET-422 and squashes the following commits:\n\ndf1f908 [proflin] PARQUET-422: Fix a potential bug in MessageTypeParser where we ignore and overwrite the initial value of a method parameter\n",
        "diff": {
            "parquet-column/src/main/java/org/apache/parquet/schema/MessageTypeParser.java": [
                6,
                8
            ]
        }
    },
    "c38386d6b5622915a2d42d989c56d37f17c673d6": {
        "datetime": "2016-01-28T17:33:08-08:00",
        "summary": "PARQUET-393: Update to parquet-format 2.3.1.",
        "message": "PARQUET-393: Update to parquet-format 2.3.1.\n\nAuthor: Ryan Blue <blue@apache.org>\n\nCloses #303 from rdblue/PARQUET-393-update-parquet-format-version and squashes the following commits:\n\n0e4c798 [Ryan Blue] PARQUET-393: Add TIME_MICROS and TIMESTAMP_MICROS.\nca4a741 [Ryan Blue] PARQUET-393: Update to parquet-format 2.3.1.\n",
        "diff": {
            "parquet-column/src/main/java/org/apache/parquet/schema/OriginalType.java": [
                0,
                2
            ],
            "parquet-column/src/main/java/org/apache/parquet/schema/Types.java": [
                0,
                2
            ],
            "parquet-column/src/test/java/org/apache/parquet/schema/TestTypeBuilders.java": [
                2,
                2
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/format/converter/ParquetMetadataConverter.java": [
                1,
                8
            ],
            "pom.xml": null
        }
    },
    "af9fd052d1c208f191fbdf85873f965552465598": {
        "datetime": "2016-01-29T11:38:34-08:00",
        "summary": "PARQUET-432: Complete a todo for method ColumnDescriptor.compareTo()",
        "message": "PARQUET-432: Complete a todo for method ColumnDescriptor.compareTo()\n\nThe ticket proposes to consider the case *path.length < o.path.length* in, for method ColumnDescriptor.compareTo().\n\nAuthor: proflin <proflin.me@gmail.com>\n\nCloses #314 from proflin/PARQUET-432 and squashes the following commits:\n\n80ba94b [proflin] Addresses PR comments\n6ccd00f [proflin] Revert Updates\na4d2a4a [proflin] PARQUET-432: Complete a todo in method ColumnDescriptor.compareTo()\n694b76b [proflin] Updates\n",
        "diff": {
            "parquet-column/src/main/java/org/apache/parquet/column/ColumnDescriptor.java": [
                3,
                3
            ],
            "parquet-column/src/test/java/org/apache/parquet/column/TestColumnDescriptor.java": [
                0,
                52
            ]
        }
    },
    "57694790f8ca0e1a4f3ac76fbd25a6dd13041e03": {
        "datetime": "2016-01-31T19:21:48-08:00",
        "summary": "PARQUET-480: Update for Cascading 3.0",
        "message": "PARQUET-480: Update for Cascading 3.0\n\nThe code in parquet-cascading is adapted to the API as of Cascading 2.5.3\n\nSome incompatible changes were introduced in Cascading 3.0. This patch forks the parquet-cascading module to also provide a parquet-cascading3 module, which is about identical save for overloads which changed from requiring a Foo<JobConf> to requiring a Foo<? extends JobConf>\n\nAuthor: Cyrille Ch\u00e9p\u00e9lov (TP12) <cch@transparencyrights.com>\n\nCloses #284 from cchepelov/try_cascading3 and squashes the following commits:\n\ne7d1304 [Cyrille Ch\u00e9p\u00e9lov (TP12)] Adding a @Deprecated notice on parquet-cascading's remaining classes\n05a417d [Cyrille Ch\u00e9p\u00e9lov (TP12)] cascading2/3: share back TupleWriteSupport.java (accidentally unmerged)\n7fff2d4 [Cyrille Ch\u00e9p\u00e9lov (TP12)] cascading/cascading3: remove duplicates, push common files into parquet-cascading-common23\n338a416 [Cyrille Ch\u00e9p\u00e9lov (TP12)] Removing unwanted file (what?!) + .gitignoring this kind of files\nd9f0455 [Cyrille Ch\u00e9p\u00e9lov (TP12)] TupleEntry#get is now TupleEntry#getObject\na7f490a [Cyrille Ch\u00e9p\u00e9lov (TP12)] Revert \"Missing test conversion to Cascading 3.0\"\ncc8b870 [Cyrille Ch\u00e9p\u00e9lov (TP12)] Missing test conversion to Cascading 3.0\n2d73512 [Cyrille Ch\u00e9p\u00e9lov (TP12)] conflicting values can come in one order or the other. Accept both.\n33355d5 [Cyrille Ch\u00e9p\u00e9lov (TP12)] Fix version mismatch (duh!)\n7128639 [Cyrille Ch\u00e9p\u00e9lov (TP12)] non-C locale can break tests implementation (decimal formats)\n53aa2f9 [Cyrille Ch\u00e9p\u00e9lov (TP12)] Adding a parquet-cascading3 module (forking the parquet-cascading module and accounting for API changes)\n",
        "diff": {
            ".gitignore": null,
            "README.md": null,
            "parquet-cascading/pom.xml": null,
            "parquet-cascading/src/main/java/org/apache/parquet/cascading/ParquetTBaseScheme.java": [
                0,
                1
            ],
            "parquet-cascading/src/main/java/org/apache/parquet/cascading/ParquetTupleScheme.java": [
                0,
                1
            ],
            "parquet-cascading/src/main/java/org/apache/parquet/cascading/ParquetValueScheme.java": [
                0,
                1
            ],
            "parquet-cascading/src/main/java/org/apache/parquet/cascading/SchemaIntersection.java": [
                0,
                0
            ],
            "parquet-cascading/src/main/java/org/apache/parquet/cascading/TupleReadSupport.java": [
                0,
                0
            ],
            "parquet-cascading/src/main/java/org/apache/parquet/cascading/TupleWriteSupport.java": [
                0,
                0
            ],
            "parquet-cascading/src/main/java/org/apache/parquet/cascading/convert/TupleConverter.java": [
                0,
                0
            ],
            "parquet-cascading/src/main/java/org/apache/parquet/cascading/convert/TupleRecordMaterializer.java": [
                0,
                0
            ],
            "parquet-cascading/src/test/java/org/apache/parquet/cascading/TestParquetTBaseScheme.java": [
                1,
                2
            ],
            "parquet-cascading/src/test/java/org/apache/parquet/cascading/TestParquetTupleScheme.java": [
                0,
                0
            ],
            "parquet-cascading/src/test/resources/names.txt": null,
            "parquet-cascading/src/test/thrift/test.thrift": null,
            "parquet-cascading3/REVIEWERS.md": null,
            "parquet-cascading3/pom.xml": null,
            "parquet-cascading3/src/main/java/org/apache/parquet/cascading/ParquetTBaseScheme.java": [
                0,
                80
            ],
            "parquet-cascading3/src/main/java/org/apache/parquet/cascading/ParquetTupleScheme.java": [
                0,
                191
            ],
            "parquet-cascading3/src/main/java/org/apache/parquet/cascading/ParquetValueScheme.java": [
                0,
                184
            ],
            "parquet-cascading3/src/test/java/org/apache/parquet/cascading/TestParquetTBaseScheme.java": [
                0,
                186
            ],
            "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/TestMergeMetadataFiles.java": [
                2,
                8
            ],
            "parquet_cascading.md": null,
            "pom.xml": null
        }
    },
    "63d5ae78ac00d710c9bf631f8cb9ed6d07e6a2c9": {
        "datetime": "2016-02-01T10:09:20-08:00",
        "summary": "PARQUET-495: Fix mismatches in Types class comments",
        "message": "PARQUET-495: Fix mismatches in Types class comments\n\nTo produce\n> required group User {\n    required int64 id;\n    **optional** binary email (UTF8);\n }\n\nwe should do:\n>\nTypes.requiredGroup()\n      .required(INT64).named(\"id\")\n      .~~**required** (BINARY).as(UTF8).named(\"email\")~~\n      .**optional** (BINARY).as(UTF8).named(\"email\")\n      .named(\"User\")\n\n@rdblue @liancheng would you mind taking a look at it when you have time? Thanks!\n\nAuthor: Liwei Lin <proflin.me@gmail.com>\nAuthor: proflin <proflin.me@gmail.com>\n\nCloses #317 from proflin/PARQUET-495--Fix-mismatches-in-Types-class-comments and squashes the following commits:\n\nf26d57d [Liwei Lin] PARQUET-495: Fix mismatches in Types class comments\n839b458 [proflin] Merge remote-tracking branch 'refs/remotes/apache/master'\n",
        "diff": {
            "parquet-column/src/main/java/org/apache/parquet/schema/Types.java": [
                3,
                3
            ]
        }
    },
    "06a4689959e361729c405e78b8a5964228cb521f": {
        "datetime": "2016-02-03T11:49:08-08:00",
        "summary": "PARQUET-410: Fix hanging subprocess call in merge script.",
        "message": "PARQUET-410: Fix hanging subprocess call in merge script.\n\nThis removes the option that redirects stderr to stdout because it\ncauses git push to hang.\n\nAuthor: Ryan Blue <blue@apache.org>\n\nCloses #302 from rdblue/PARQUET-410-fix-subprocess-hang and squashes the following commits:\n\n340c316 [Ryan Blue] PARQUET-410: Fix hanging subprocess call in merge script.\n",
        "diff": {
            "dev/merge_parquet_pr.py": [
                2,
                2
            ]
        }
    },
    "0a711ebcec7d32b66ab3c90b2a1f48681201e557": {
        "datetime": "2016-02-03T12:45:27-08:00",
        "summary": "PARQUET-415: Fix ByteBuffer Binary serialization.",
        "message": "PARQUET-415: Fix ByteBuffer Binary serialization.\n\nThis also adds a test to validate that serialization works for all\nBinary objects that are already test cases.\n\nAuthor: Ryan Blue <blue@apache.org>\n\nCloses #305 from rdblue/PARQUET-415-fix-bytebuffer-binary-serialization and squashes the following commits:\n\n4e75d54 [Ryan Blue] PARQUET-415: Fix ByteBuffer Binary serialization.\n",
        "diff": {
            "parquet-column/src/main/java/org/apache/parquet/io/api/Binary.java": [
                3,
                5
            ],
            "parquet-column/src/test/java/org/apache/parquet/io/api/TestBinary.java": [
                0,
                21
            ]
        }
    },
    "a4acf53336a482f50335d33b4f650a70c9243b7b": {
        "datetime": "2016-02-06T11:41:21-08:00",
        "summary": "PARQUET-509: Fix args passed to string format calls",
        "message": "PARQUET-509: Fix args passed to string format calls\n\nThis PR fixes the args passed to the `String.format()` call.\n\nAuthor: Nezih Yigitbasi <nyigitbasi@netflix.com>\n\nCloses #320 from nezihyigitbasi/debug_args and squashes the following commits:\n\n43a6088 [Nezih Yigitbasi] Fix args passed to string format calls\n",
        "diff": {
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/DirectCodecFactory.java": [
                2,
                2
            ]
        }
    },
    "c26fa78817f30cc3eb91165b783e07fb80d80f59": {
        "datetime": "2016-02-06T11:57:19-08:00",
        "summary": "PARQUET-385 PARQUET-379: Fixes strict schema merging",
        "message": "PARQUET-385 PARQUET-379: Fixes strict schema merging\n\nThis PR fixes strict mode schema merging. To merge two `PrimitiveType` `t1` and `t2`, they must satisfy the following conditions:\n\n1. `t1` and `t2` have the same primitive type name\n1. `t1` and `t2` either\n   - don't have original type, or\n   - have the same original type\n1. If `t1` and `t2` are both `FIXED_LEN_BYTE_ARRAY`, they should have the same length\n\nAlso, merged schema now preserves original name if there's any.\n\nAuthor: Cheng Lian <lian@databricks.com>\n\nCloses #315 from liancheng/fix-strict-schema-merge and squashes the following commits:\n\na29138c [Cheng Lian] Addresses PR comment\n1ac804e [Cheng Lian] Fixes strict schema merging\n",
        "diff": {
            "parquet-column/src/main/java/org/apache/parquet/schema/PrimitiveType.java": [
                9,
                29
            ],
            "parquet-column/src/test/java/org/apache/parquet/schema/TestMessageType.java": [
                4,
                31
            ]
        }
    },
    "6c9ca4d4c0de4dff29b79f28ac5c51b4f6fed0da": {
        "datetime": "2016-02-15T16:35:33-08:00",
        "summary": "PARQUET-430: Change to use Locale parameterized version of String.toUpperCase()/toLowerCase",
        "message": "PARQUET-430: Change to use Locale parameterized version of String.toUpperCase()/toLowerCase\n\nA String is being converted to upper or lowercase, using the platform's default encoding. This may result in improper conversions when used with international characters.\n\nFor instance, \"TITLE\".toLowerCase() in a Turkish locale returns \"t\u0131tle\", where '\u0131' -- without a dot -- is the LATIN SMALL LETTER DOTLESS I character. To obtain correct results for locale insensitive strings, we'd better use toLowerCase(Locale.ENGLISH).\n\nFor more information on this, please see:\n- http://stackoverflow.com/questions/11063102/using-locales-with-javas-tolowercase-and-touppercase\n- http://lotusnotus.com/lotusnotus_en.nsf/dx/dotless-i-tolowercase-and-touppercase-functions-use-responsibly.htm\n- http://java.sys-con.com/node/46241\n\nThis PR changes our use of String.toUpperCase()/toLowerCase() to String.toUpperCase(Locale.*ENGLISH*)/toLowerCase(*Locale.ENGLISH*)\n\nAuthor: proflin <proflin.me@gmail.com>\n\nCloses #312 from proflin/PARQUET-430 and squashes the following commits:\n\ned55822 [proflin] PARQUET-430\n",
        "diff": {
            "parquet-column/src/main/java/org/apache/parquet/filter2/predicate/Operators.java": [
                4,
                5
            ],
            "parquet-column/src/main/java/org/apache/parquet/schema/GroupType.java": [
                1,
                2
            ],
            "parquet-column/src/main/java/org/apache/parquet/schema/MessageTypeParser.java": [
                2,
                3
            ],
            "parquet-column/src/main/java/org/apache/parquet/schema/PrimitiveType.java": [
                1,
                2
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/metadata/CompressionCodecName.java": [
                1,
                3
            ]
        }
    },
    "944291b748bcfec4e2f3c17623884db7a17b9f21": {
        "datetime": "2016-02-15T16:37:04-08:00",
        "summary": "PARQUET-431: Make ParquetOutputFormat.memoryManager volatile",
        "message": "PARQUET-431: Make ParquetOutputFormat.memoryManager volatile\n\nCurrently ParquetOutputFormat.getRecordWriter() contains an unsynchronized lazy initialization of the non-volatile static field *memoryManager*.\n\nBecause the compiler or processor may reorder instructions, threads are not guaranteed to see a completely initialized object, when ParquetOutputFormat.getRecordWriter() is called by multiple threads.\n\nThis PR makes *memoryManager* volatile to correct the problem.\n\nAuthor: Liwei Lin <proflin.me@gmail.com>\nAuthor: proflin <proflin.me@gmail.com>\n\nCloses #313 from proflin/PARQUET-431 and squashes the following commits:\n\n1aa4a44 [Liwei Lin] empty commit to trigger CI\n5e94fa3 [Liwei Lin] Remove the volatile modifier for memoryManager\nd54bb99 [Liwei Lin] Undo the Deprecated anotation\nfd1df4e [Liwei Lin] Adds synchronization around the creation of memoryManager as well as getMemoryManager()\n615aa5a [proflin] PARQUET-431\n",
        "diff": {
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ParquetOutputFormat.java": [
                5,
                7
            ]
        }
    },
    "c44f982e89b63a97190638cd12bd8bee2bafb883": {
        "datetime": "2016-02-21T18:36:50-08:00",
        "summary": "PARQUET-529: Avoid evoking job.toString() in ParquetLoader",
        "message": "PARQUET-529: Avoid evoking job.toString() in ParquetLoader\n\nWhen ran under hadoop2 environment and log level setting to `DEBUG`, ParquetLoader would evoke `job.toString()` in several methods, which might cause the whole application to stop due to :\n\n```\njava.lang.IllegalStateException: Job in state DEFINE instead of RUNNING\n\n\tat org.apache.hadoop.mapreduce.Job.ensureState(Job.java:283)\n\tat org.apache.hadoop.mapreduce.Job.toString(Job.java:452)\n\tat java.lang.String.valueOf(String.java:2847)\n\tat java.lang.StringBuilder.append(StringBuilder.java:128)\n\tat org.apache.parquet.pig.ParquetLoader.getSchema(ParquetLoader.java:260)\n\tat org.apache.parquet.pig.TestParquetLoader.testSchema(TestParquetLoader.java:54)\n    ...\n```\n\nThe reason is that in the hadoop 2.x branch, `org.apache.hadoop.mapreduce.Job.toString()` has added an `ensureState(JobState.RUNNING)` check; see [map-reduce: Job.java#452](http://grepcode.com/file/repo1.maven.org/maven2/org.apache.hadoop/hadoop-mapreduce-client-core/2.3.0/org/apache/hadoop/mapreduce/Job.java#452). In contrast, the hadoop 1.x branch does not contain such checks, so `ParquetLoader` works well.\n\nThis PR simply avoids evoking `job.toString()` in `ParquetLoader`.\n\nAuthor: proflin <proflin.me@gmail.com>\nAuthor: Liwei Lin <proflin.me@gmail.com>\n\nCloses #326 from proflin/PARQUET-529--Avoid-evoking-job.toString()-in-ParquetLoader and squashes the following commits:\n\nf464c7b [proflin] Add jobToString\n5d4c750 [proflin] PARQUET-529: Avoid evoking job.toString() in ParquetLoader.java\nbb4283a [Liwei Lin] Merge branch 'master' of https://github.com/proflin/parquet-mr\n839b458 [proflin] Merge remote-tracking branch 'refs/remotes/apache/master'\n",
        "diff": {
            "parquet-pig/src/main/java/org/apache/parquet/pig/ParquetLoader.java": [
                4,
                16
            ]
        }
    },
    "fb46b941f7763314d667c437c06b1675e61c3d38": {
        "datetime": "2016-02-26T10:28:07-08:00",
        "summary": "PARQUET-397: Implement Pig predicate pushdown",
        "message": "PARQUET-397: Implement Pig predicate pushdown\n\nThis is based on #296 from @danielcweeks and implements a few remaining review items.\n\nCloses #296.\n\nAuthor: Daniel Weeks <dweeks@netflix.com>\nAuthor: Ryan Blue <blue@apache.org>\n\nCloses #331 from rdblue/PARQUET-397-pig-predicate-pushdown and squashes the following commits:\n\nc7a9b02 [Ryan Blue] PARQUET-397: Address review comments.\n54e23a6 [Ryan Blue] PARQUET-397: Update Pig PPD to throw for bad expressions.\n388099b [Daniel Weeks] Cleaning up imports\n6b405b4 [Daniel Weeks] Merge remote-tracking branch 'rdblue/pig-predicate-pushdown' into pig-predicate-pushdown\nf1ef73e [Daniel Weeks] Fixed binary type and storing filter predicate\na39fdff [Ryan Blue] WIP: Handle a few error cases in Pig predicate pushdown.\n2666849 [Daniel Weeks] Fixed test to check the actual number of materialized rows from the reader\n7b019a6 [Daniel Weeks] update tests and logging\nf8ca447 [Daniel Weeks] Add predicate pushdown using filter2 api\n",
        "diff": {
            "parquet-pig/src/main/java/org/apache/parquet/pig/ParquetLoader.java": [
                1,
                185
            ],
            "parquet-pig/src/test/java/org/apache/parquet/pig/TestParquetLoader.java": [
                12,
                45
            ],
            "pom.xml": null
        }
    },
    "1f91c79de5e2d852c6e7d0cf7a4255087ef618ef": {
        "datetime": "2016-03-05T19:45:25+08:00",
        "summary": "PARQUET-528: Fix flush() for RecordConsumer and implementations",
        "message": "PARQUET-528: Fix flush() for RecordConsumer and implementations\n\n`flush()` was added in `RecordConsumer` and `MessageColumnIO` to help implementing nulls caching.\n\nHowever, other `RecordConsumer` implementations should also implements `flush()` properly. For instance, `RecordConsumerLoggingWrapper` and `ValidatingRecordConsumer` should call `delegate.flush()` in their `flush()` methods, otherwise data might be mistakenly truncated.\n\nThis PR:\n- makes `flush()` abstract in `RecordConsumer`\n- implements `flush()` properly for all `RecordConsumer` subclasses, specifically:\n - `RecordConsumerLoggingWrapper`\n - `ValidatingRecordConsumer`\n - `ConverterConsumer `\n - `ExpectationValidatingRecordConsumer `\n\nAuthor: proflin <proflin.me@gmail.com>\nAuthor: Liwei Lin <proflin.me@gmail.com>\n\nCloses #325 from proflin/PARQUET-528 and squashes the following commits:\n\n2c90740 [proflin] Minor style issue\n25444b9 [proflin] Still keep RecordConsumer.flush() non-abstract\n8776e3a [proflin] PARQUET-528: Fix flush() for RecordConsumer and implementations\nbb4283a [Liwei Lin] Merge branch 'master' of https://github.com/proflin/parquet-mr\n839b458 [proflin] Merge remote-tracking branch 'refs/remotes/apache/master'\n",
        "diff": {
            "parquet-column/src/main/java/org/apache/parquet/io/MessageColumnIO.java": [
                1,
                3
            ],
            "parquet-column/src/main/java/org/apache/parquet/io/RecordConsumerLoggingWrapper.java": [
                0,
                9
            ],
            "parquet-column/src/main/java/org/apache/parquet/io/ValidatingRecordConsumer.java": [
                0,
                4
            ],
            "parquet-column/src/main/java/org/apache/parquet/io/api/RecordConsumer.java": [
                0,
                1
            ],
            "parquet-column/src/test/java/org/apache/parquet/io/ConverterConsumer.java": [
                0,
                8
            ],
            "parquet-column/src/test/java/org/apache/parquet/io/ExpectationValidatingRecordConsumer.java": [
                0,
                8
            ]
        }
    },
    "4b1ff8f4b9dfa0ccb064ef286cf2953bfb2c492d": {
        "datetime": "2016-03-09T13:20:37-08:00",
        "summary": "PARQUET-384: Add dictionary filtering.",
        "message": "PARQUET-384: Add dictionary filtering.\n\nThis builds on #286 from @danielcweeks and cleans up some of the interfaces. It introduces `DictionaryPageReadStore` to expose dictionary pages to the filters and cleans up some internal calls by passing `ParquetFileReader`.\n\nWhen committed, this closes #286.\n\nAuthor: Ryan Blue <blue@apache.org>\nAuthor: Daniel Weeks <dweeks@netflix.com>\n\nCloses #330 from rdblue/PARQUET-384-add-dictionary-filtering and squashes the following commits:\n\nff89424 [Ryan Blue] PARQUET-384: Add a cache to DictionaryPageReader.\n1f6861c [Ryan Blue] PARQUET-384: Use ParquetFileReader to initialize readers.\n21ef4b6 [Daniel Weeks] PARQUET-384: Add dictionary row group filter.\n",
        "diff": {
            "parquet-column/src/main/java/org/apache/parquet/column/page/DictionaryPageReadStore.java": [
                0,
                36
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/filter2/compat/RowGroupFilter.java": [
                1,
                36
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/filter2/dictionarylevel/DictionaryFilter.java": [
                0,
                356
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/format/converter/ParquetMetadataConverter.java": [
                5,
                42
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ColumnChunkPageReadStore.java": [
                2,
                8
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/DictionaryPageReader.java": [
                0,
                110
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/InternalParquetRecordReader.java": [
                33,
                6
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ParquetFileReader.java": [
                54,
                276
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ParquetReader.java": [
                11,
                6
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ParquetRecordReader.java": [
                46,
                31
            ],
            "parquet-hadoop/src/test/java/org/apache/parquet/filter2/dictionarylevel/DictionaryFilterTest.java": [
                0,
                387
            ]
        }
    },
    "e9928c94ce1385ec72028336417f19f30ac38ac0": {
        "datetime": "2016-03-25T12:19:39-07:00",
        "summary": "PARQUET-571: Fix potential leak in ParquetFileReader.close()",
        "message": "PARQUET-571: Fix potential leak in ParquetFileReader.close()\n\nIf an exception occurs when closing the input stream `f`, the codecs\nwill not be released. This may cause native memory leaks for some codecs. \\cc @rdblue\n\nAuthor: Nezih Yigitbasi <nyigitbasi@netflix.com>\n\nCloses #338 from nezihyigitbasi/leak-fix and squashes the following commits:\n\nfcc5528 [Nezih Yigitbasi] Fix potential leak in close()\n",
        "diff": {
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ParquetFileReader.java": [
                5,
                8
            ]
        }
    },
    "d4021487539b0f7758ec644f2e0d83df95c66bba": {
        "datetime": "2016-04-16T17:23:59-07:00",
        "summary": "PARQUET-581: Fix two instances of the conflation of the min and max row",
        "message": "PARQUET-581: Fix two instances of the conflation of the min and max row\n\ncount for page size check in ParquetOutputFormat.java\n\nAuthor: Michael Allman <michael@videoamp.com>\n\nCloses #340 from mallman/fix_minmax_conflation and squashes the following commits:\n\n79331a5 [Michael Allman] PARQUET-581: Fix two instances of the conflation of the min and max row count for page size check in ParquetOutputFormat.java\n",
        "diff": {
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ParquetOutputFormat.java": [
                2,
                2
            ]
        }
    },
    "ac62c1c29f319a97a2552c39f32c8e6acd70c9e1": {
        "datetime": "2016-04-16T17:25:31-07:00",
        "summary": "PARQUET-580: Switch int[] initialization in IntList to be lazy",
        "message": "PARQUET-580: Switch int[] initialization in IntList to be lazy\n\nNoticed that for a dataset that we were trying to import that had a lot of columns (few thousand) that weren't being used, we ended up allocating a lot of unnecessary int arrays (each 64K in size). Heap footprint for all those int[]s turned out to be around 2GB or so (and results in some jobs OOMing). This seems unnecessary for columns that might not be used. The changes in this PR switch over to initialize the int[] only when it being used for the first time.\n\nAlso wondering if 64K is the right size to start off with. Wondering if a potential improvement is if we could allocate these int[]s in IntList in a way that slowly ramps up their size. So rather than create arrays of size 64K at a time (which is potentially wasteful if there are only a few hundred bytes), we could create say a 4K int[], then when it fills up an 8K[] and so on till we reach 64K (at which point the behavior is the same as the current implementation). If this sounds like a reasonable idea, I can update this PR to do that as well. Wasn't sure if there was some historical context around that..\n\nAuthor: Piyush Narang <pnarang@twitter.com>\n\nCloses #339 from piyushnarang/master and squashes the following commits:\n\n3ecc577 [Piyush Narang] Remove redundant IntList ctor\nf7dfd5f [Piyush Narang] Switch int[] initialization in IntList to be lazy\n",
        "diff": {
            "parquet-column/src/main/java/org/apache/parquet/column/values/dictionary/IntList.java": [
                9,
                12
            ]
        }
    },
    "dc08bb8ea6cdf01188f6699559e779e6cc296287": {
        "datetime": "2016-04-19T08:26:34-07:00",
        "summary": "PARQUET-584 show proper command usage when there's no arguments",
        "message": "PARQUET-584 show proper command usage when there's no arguments\n\nAuthor: Kaufman Ng <kaufman@cloudera.com>\nAuthor: Ryan Blue <blue@apache.org>\n\nCloses #336 from coughman/master and squashes the following commits:\n\ncd459f9 [Kaufman Ng] PARQUET-584: fixed formatting\n1d1e965 [Kaufman Ng] Merge branch 'master' of https://github.com/coughman/incubator-parquet-mr\n25b6d86 [Kaufman Ng] Merge branch 'master' of https://github.com/apache/parquet-mr\nbee66e5 [Ryan Blue] PARQUET-384: Add dictionary filtering.\n283f7c7 [Kaufman Ng] show proper command usage when there's no arguments\n",
        "diff": {
            "parquet-tools/src/main/java/org/apache/parquet/tools/Main.java": [
                3,
                4
            ]
        }
    },
    "82b8ecc3275d7c3578a6531ac3f1da3ffada9dcc": {
        "datetime": "2016-04-19T09:17:01-07:00",
        "summary": "PARQUET-484: Warn when Decimal is stored as INT64 while could be stored as INT32",
        "message": "PARQUET-484: Warn when Decimal is stored as INT64 while could be stored as INT32\n\nBelow is documented in [LogicalTypes.md](https://github.com/Parquet/parquet-format/blob/master/LogicalTypes.md#decimal):\n\n> int32: for 1 <= precision <= 9\n> int64: for 1 <= precision <= 18; precision < 10 will produce a warning\n\nThis PR implements the `precision < 10 will produce a warning` part.\n\n@rdblue @liancheng would mind taking a look at this when you have time? It's a fairly small addition; cheers.\n\nAuthor: Liwei Lin <proflin.me@gmail.com>\nAuthor: proflin <proflin.me@gmail.com>\n\nCloses #316 from lw-lin/P-484-2 and squashes the following commits:\n\n207e509 [Liwei Lin] Address comments\nb227484 [proflin] PARQUET-484: Warn when Decimal is stored as INT64 while could be stored as INT32\n",
        "diff": {
            "parquet-column/src/main/java/org/apache/parquet/schema/Types.java": [
                0,
                9
            ]
        }
    },
    "6b24a1d1b5e2792a7821ad172a45e38d2b04f9b8": {
        "datetime": "2016-04-20T08:41:22-07:00",
        "summary": "PARQUET-358: Add support for Avro's logical types API.",
        "message": "PARQUET-358: Add support for Avro's logical types API.\n\nThis adds support for Avro's logical types API to parquet-avro.\n\n* The logical types API was introduced in Avro 1.8.0, so this bumps the Avro dependency version to 1.8.0.\n* Types supported are: decimal, date, time-millis, time-micros, timestamp-millis, and timestamp-micros\n* Tests have been copied from Avro and ported to the parquet-avro API\n\nAuthor: Ryan Blue <blue@apache.org>\n\nCloses #318 from rdblue/PARQUET-358-add-avro-logical-types-api and squashes the following commits:\n\nbd81f9c [Ryan Blue] PARQUET-358: Fix review items.\n0a882ee [Ryan Blue] PARQUET-358: Add logical types circular reference test.\n5124618 [Ryan Blue] PARQUET-358: Add license documentation for code from Avro.\ndcb14be [Ryan Blue] PARQUET-358: Add support for Avro's logical types API.\n",
        "diff": {
            "LICENSE": null,
            "NOTICE": null,
            "parquet-avro/pom.xml": null,
            "parquet-avro/src/main/java/org/apache/parquet/avro/AvroIndexedRecordConverter.java": [
                1,
                17
            ],
            "parquet-avro/src/main/java/org/apache/parquet/avro/AvroReadSupport.java": [
                2,
                2
            ],
            "parquet-avro/src/main/java/org/apache/parquet/avro/AvroRecordConverter.java": [
                14,
                107
            ],
            "parquet-avro/src/main/java/org/apache/parquet/avro/AvroSchemaConverter.java": [
                43,
                106
            ],
            "parquet-avro/src/main/java/org/apache/parquet/avro/AvroWriteSupport.java": [
                43,
                124
            ],
            "parquet-avro/src/main/java/org/apache/parquet/avro/ParentValueContainer.java": [
                0,
                175
            ],
            "parquet-avro/src/main/resources/META-INF/LICENSE": null,
            "parquet-avro/src/main/resources/META-INF/NOTICE": null,
            "parquet-avro/src/test/java/org/apache/parquet/avro/AvroTestUtil.java": [
                0,
                53
            ],
            "parquet-avro/src/test/java/org/apache/parquet/avro/TestAvroSchemaConverter.java": [
                14,
                266
            ],
            "parquet-avro/src/test/java/org/apache/parquet/avro/TestCircularReferences.java": [
                0,
                383
            ],
            "parquet-avro/src/test/java/org/apache/parquet/avro/TestGenericLogicalTypes.java": [
                0,
                271
            ],
            "parquet-avro/src/test/java/org/apache/parquet/avro/TestReadWrite.java": [
                1,
                117
            ],
            "parquet-avro/src/test/java/org/apache/parquet/avro/TestReadWriteOldListBehavior.java": [
                1,
                0
            ],
            "parquet-avro/src/test/java/org/apache/parquet/avro/TestReflectLogicalTypes.java": [
                0,
                705
            ],
            "parquet-column/src/main/java/org/apache/parquet/io/api/Binary.java": [
                16,
                39
            ],
            "parquet-column/src/main/java/org/apache/parquet/schema/Types.java": [
                6,
                6
            ],
            "parquet-column/src/test/java/org/apache/parquet/io/api/TestBinary.java": [
                10,
                0
            ],
            "pom.xml": null
        }
    },
    "36ce032b612fc0a1156d28bca7327e06337c8815": {
        "datetime": "2016-04-20T20:47:49-07:00",
        "summary": "PARQUET-585: Slowly ramp up sizes of int[]s in IntList to keep sizes small when data sets are small",
        "message": "PARQUET-585: Slowly ramp up sizes of int[]s in IntList to keep sizes small when data sets are small\n\nOne of the follow up items from PR - https://github.com/apache/parquet-mr/pull/339 was to slowly ramp up the size of the int[] created in IntList to ensure we don't allocate 64K arrays right off the bat. This PR updates the code to start with a 4K array then keeps doubling till 64K (and stays at 64K after that).\n\nAuthor: Piyush Narang <pnarang@twitter.com>\n\nCloses #341 from piyushnarang/master and squashes the following commits:\n\n0bc6b84 [Piyush Narang] Fix review comments - add spaces, check slab size, fix slab init\nd1b4df1 [Piyush Narang] Make IntListTest values relative to constants in IntList\n9617015 [Piyush Narang] Update IntList slab creation to keep bumping up size gradually\nebf1c58 [Piyush Narang] Merge branch 'master' of https://github.com/apache/parquet-mr\n3ecc577 [Piyush Narang] Remove redundant IntList ctor\nf7dfd5f [Piyush Narang] Switch int[] initialization in IntList to be lazy\n",
        "diff": {
            "parquet-column/src/main/java/org/apache/parquet/column/values/dictionary/IntList.java": [
                12,
                52
            ],
            "parquet-column/src/test/java/org/apache/parquet/column/values/dictionary/IntListTest.java": [
                0,
                84
            ]
        }
    },
    "741944332d5bd90112b610a8b5f2eeefe51e08bc": {
        "datetime": "2016-04-20T20:58:40-07:00",
        "summary": "PARQUET-327. Show statistics in the dump output.",
        "message": "PARQUET-327. Show statistics in the dump output.\n\nCloses #237\n",
        "diff": {
            "parquet-tools/src/main/java/org/apache/parquet/tools/command/DumpCommand.java": [
                0,
                13
            ]
        }
    },
    "8bcfe6c55e2588c1047368b4edbf733d1c1d5381": {
        "datetime": "2016-04-21T11:37:51-07:00",
        "summary": "PARQUET-225: Add support for INT64 delta encoding.",
        "message": "PARQUET-225: Add support for INT64 delta encoding.\n\nAuthor: Vassil Lunchev <vassil@leanplum.com>\n\nCloses #154 from lunchev:int64 and squashes the following commits:\n\n84a40fe [Vassil Lunchev] INT64 support for Delta Encoding\n4389af4 [Vassil Lunchev] splitting delta INT32 and delta INT64\ne5e8fe2 [Vassil Lunchev] split delta encoding tests for INT32 and for INT64\neb4383a [Ryan Blue] PARQUET-225: Avoid multiple small copies in delta int/long encoding.\n",
        "diff": {
            "parquet-column/src/main/java/org/apache/parquet/column/Encoding.java": [
                2,
                3
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/ParquetProperties.java": [
                3,
                5
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/values/delta/DeltaBinaryPackingValuesReader.java": [
                9,
                17
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/values/delta/DeltaBinaryPackingValuesWriter.java": [
                147,
                11
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/values/delta/DeltaBinaryPackingValuesWriterForInteger.java": [
                0,
                199
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/values/delta/DeltaBinaryPackingValuesWriterForLong.java": [
                0,
                201
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/values/deltalengthbytearray/DeltaLengthByteArrayValuesWriter.java": [
                1,
                2
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/values/deltastrings/DeltaByteArrayWriter.java": [
                1,
                3
            ],
            "parquet-column/src/test/java/org/apache/parquet/column/values/delta/DeltaBinaryPackingValuesWriterForLongTest.java": [
                0,
                263
            ],
            "parquet-column/src/test/java/org/apache/parquet/column/values/delta/DeltaBinaryPackingValuesWriterTest.java": [
                8,
                10
            ],
            "parquet-column/src/test/java/org/apache/parquet/column/values/delta/benchmark/BenchmarkIntegerOutputSize.java": [
                4,
                8
            ],
            "parquet-column/src/test/java/org/apache/parquet/column/values/delta/benchmark/BenchmarkReadingRandomIntegers.java": [
                13,
                16
            ],
            "parquet-column/src/test/java/org/apache/parquet/column/values/delta/benchmark/RandomWritingBenchmarkTest.java": [
                10,
                15
            ],
            "parquet-common/src/main/java/org/apache/parquet/bytes/BytesUtils.java": [
                0,
                36
            ],
            "parquet-encoding/src/main/java/org/apache/parquet/bytes/BytesInput.java": [
                1,
                38
            ],
            "parquet-encoding/src/main/java/org/apache/parquet/column/values/bitpacking/BytePackerForLong.java": [
                0,
                112
            ],
            "parquet-encoding/src/main/java/org/apache/parquet/column/values/bitpacking/BytePackerForLongFactory.java": [
                0,
                25
            ],
            "parquet-encoding/src/main/java/org/apache/parquet/column/values/bitpacking/Packer.java": [
                2,
                22
            ],
            "parquet-encoding/src/test/java/org/apache/parquet/column/values/bitpacking/TestBitPacking.java": [
                0,
                14
            ],
            "parquet-encoding/src/test/java/org/apache/parquet/column/values/bitpacking/TestByteBitPacking.java": [
                1,
                47
            ],
            "parquet-generator/src/main/java/org/apache/parquet/encoding/bitpacking/ByteBasedBitPackingGenerator.java": [
                51,
                95
            ]
        }
    },
    "3dd2210e79a8eb84378c370b32652f9a53f87a93": {
        "datetime": "2016-04-22T17:39:52-07:00",
        "summary": "PARQUET-548: Add EncodingStats.",
        "message": "PARQUET-548: Add EncodingStats.\n\nThis adds `EncodingStats`, which tracks the number of pages for each encoding, separated into dictionary and data pages. It also adds convenience functions that are useful for dictionary filtering, like `hasDictionaryEncodedPages` and `hasNonDictionaryEncodedPages`.\n\n`EncodingStats` have a unit test in parquet-column and an integration test in parquet-hadoop that writes a file and verifies the stats are present and correct when it is read.\n\nThis includes commits from #330 because it updates the dictionary filter. I'll rebase and remove them once it is merged.\n\nAuthor: Ryan Blue <blue@apache.org>\n\nCloses #332 from rdblue/PARQUET-548-add-encoding-stats and squashes the following commits:\n\n5f148e6 [Ryan Blue] PARQUET-548: Fixes for review comments.\ndc332d3 [Ryan Blue] PARQUET-548: Add EncodingStats.\n",
        "diff": {
            "parquet-column/src/main/java/org/apache/parquet/column/EncodingStats.java": [
                0,
                162
            ],
            "parquet-column/src/test/java/org/apache/parquet/column/TestEncodingStats.java": [
                0,
                202
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/filter2/dictionarylevel/DictionaryFilter.java": [
                0,
                6
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/format/converter/ParquetMetadataConverter.java": [
                0,
                50
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ColumnChunkPageWriteStore.java": [
                9,
                16
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/DictionaryPageReader.java": [
                0,
                7
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ParquetFileWriter.java": [
                6,
                25
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/metadata/ColumnChunkMetaData.java": [
                30,
                41
            ],
            "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/TestReadWriteEncodingStats.java": [
                0,
                121
            ]
        }
    },
    "2f22533ef41533e2b839a6b41b262dca59e6dbf9": {
        "datetime": "2016-04-22T17:42:35-07:00",
        "summary": "PARQUET-569: Separate metadata filtering for ranges and offsets.",
        "message": "PARQUET-569: Separate metadata filtering for ranges and offsets.\n\nRange filtering should use the row group midpoint and offset filtering\nshould use the start offset.\n\nAuthor: Ryan Blue <blue@apache.org>\n\nCloses #337 from rdblue/PARQUET-569-fix-metadata-filter and squashes the following commits:\n\n6171af4 [Ryan Blue] PARQUET-569: Add tests for new offset metadata filter.\n3fe2d5e [Ryan Blue] PARQUET-569: Separate metadata filtering for ranges and offsets.\n",
        "diff": {
            "parquet-hadoop/src/main/java/org/apache/parquet/format/converter/ParquetMetadataConverter.java": [
                11,
                25
            ],
            "parquet-hadoop/src/test/java/org/apache/parquet/format/converter/TestParquetMetadataConverter.java": [
                2,
                29
            ]
        }
    },
    "39a3cd0f4210dbec1ae8ef39a87d34b76eac91a3": {
        "datetime": "2016-04-25T15:05:11-07:00",
        "summary": "PARQUET-560: Synchronize writes to the finishCalled variable",
        "message": "PARQUET-560: Synchronize writes to the finishCalled variable\n\nReads of the `finishCalled` variable are properly synchronized, but writes are not -- so there's some sort of inconsistent synch. going on here. This PR fixes that.\n\n/cc @rdblue can you please take a look?\n\nAuthor: Nezih Yigitbasi <nyigitbasi@netflix.com>\n\nCloses #334 from nezihyigitbasi/sc-synch-fix and squashes the following commits:\n\na85cf0c [Nezih Yigitbasi] Synchronize writes to the finishCalled variable\n",
        "diff": {
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/codec/SnappyCompressor.java": [
                1,
                1
            ],
            "pom.xml": null
        }
    },
    "c3f3830f771f26a537d2930b00b270451bbc5627": {
        "datetime": "2016-05-05T13:54:28-07:00",
        "summary": "PARQUET-372: Do not write stats larger than 4k.",
        "message": "PARQUET-372: Do not write stats larger than 4k.\n\nThis updates the stats conversion to check whether the min and max\nvalues for page stats are larger than 4k. If so, no statistics for a\npage are written.\n\nAuthor: Ryan Blue <blue@apache.org>\n\nCloses #275 from rdblue/PARQUET-372-fix-min-max-for-long-values and squashes the following commits:\n\n61e05d9 [Ryan Blue] PARQUET-372: Add comment to explain not truncating values.\nfbbc1c4 [Ryan Blue] PARQUET-372: Do not write stats larger than 4k.\n",
        "diff": {
            "parquet-column/src/main/java/org/apache/parquet/column/statistics/BinaryStatistics.java": [
                0,
                25
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/statistics/BooleanStatistics.java": [
                0,
                5
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/statistics/DoubleStatistics.java": [
                0,
                5
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/statistics/FloatStatistics.java": [
                0,
                5
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/statistics/IntStatistics.java": [
                0,
                5
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/statistics/LongStatistics.java": [
                0,
                5
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/statistics/Statistics.java": [
                0,
                8
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/format/converter/ParquetMetadataConverter.java": [
                1,
                7
            ],
            "parquet-hadoop/src/test/java/org/apache/parquet/format/converter/TestParquetMetadataConverter.java": [
                1,
                158
            ],
            "parquet-hadoop/src/test/java/org/apache/parquet/statistics/TestStatistics.java": [
                0,
                9
            ]
        }
    },
    "da69d4b764f4d13d38a4f7fe7462ef0c7d17c619": {
        "datetime": "2016-05-05T13:56:53-07:00",
        "summary": "PARQUET-367: \"parquet-cat -j\" doesn't show all records.",
        "message": "PARQUET-367: \"parquet-cat -j\" doesn't show all records.\n\nAdded JsonRecordFormatter which formats SimpleRecords into an structure that can be used with ObjectMapper to create a valid json structure. Unit test included.\n\nAuthor: Reuben Kuhnert <reuben.kuhnert@cloudera.com>\n\nCloses #281 from sircodesalotOfTheRound/fix-parquet-cat and squashes the following commits:\n\n67207ef [Reuben Kuhnert] PARQUET-367: \"parquet-cat -j\" doesn't show all records.\n",
        "diff": {
            "parquet-tools/src/main/java/org/apache/parquet/tools/command/CatCommand.java": [
                1,
                8
            ],
            "parquet-tools/src/main/java/org/apache/parquet/tools/json/JsonRecordFormatter.java": [
                0,
                132
            ],
            "parquet-tools/src/main/java/org/apache/parquet/tools/read/SimpleRecord.java": [
                0,
                1
            ],
            "parquet-tools/src/test/java/org/apache/parquet/tools/read/TestJsonRecordFormatter.java": [
                0,
                231
            ]
        }
    },
    "1f470253c46471033048383c027192e757480492": {
        "datetime": "2016-06-30T09:41:51-07:00",
        "summary": "PARQUET-544: Add closed flag to allow for closeable contract adherence",
        "message": "PARQUET-544: Add closed flag to allow for closeable contract adherence\n\nThe closeable interface states:\n> Closes this stream and releases any system resources associated with it. If the stream is already closed then invoking this method has no effect.\n\nAs InternalParquetRecordWriter implements this interface we should adhere to this contract.\n\nAuthor: Mark Reddy <mark.l.reddy@gmail.com>\n\nCloses #345 from markreddy/PARQUET-544-adhere-to-closeable-contract and squashes the following commits:\n\n135db9b [Mark Reddy] PARQUET-544: add closed flag to allow for adherence to closeable contract\n",
        "diff": {
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/InternalParquetRecordWriter.java": [
                8,
                13
            ]
        }
    },
    "9c40a7bb3c9aca51d17490960c988dfb7b5acebb": {
        "datetime": "2016-06-30T09:47:48-07:00",
        "summary": "PARQUET-645: Fix null handling in DictionaryFilter.",
        "message": "PARQUET-645: Fix null handling in DictionaryFilter.\n\nThis fixes how null is handled by `DictionaryFilter` for equals predicates. Null is never in the dictionary and is encoded by the definition level, so the `DictionaryFilter` would never find the value in the dictionary and would incorrectly filter row groups whenever the filter was `col == null`.\n\nAuthor: Ryan Blue <blue@apache.org>\n\nCloses #348 from rdblue/PARQUET-645-fix-null-dictionary-filter and squashes the following commits:\n\nae8dd41 [Ryan Blue] PARQUET-645: Fix null handling in DictionaryFilter.\n",
        "diff": {
            "parquet-hadoop/src/main/java/org/apache/parquet/filter2/dictionarylevel/DictionaryFilter.java": [
                0,
                12
            ],
            "parquet-hadoop/src/test/java/org/apache/parquet/filter2/dictionarylevel/DictionaryFilterTest.java": [
                0,
                6
            ]
        }
    },
    "7f8e952abc4d2fc4b96c97a51aa25fcf6ed8af02": {
        "datetime": "2016-06-30T09:50:59-07:00",
        "summary": "PARQUET-642: Improve performance of ByteBuffer based read / write paths",
        "message": "PARQUET-642: Improve performance of ByteBuffer based read / write paths\n\nWhile trying out the newest Parquet version, we noticed that the changes to start using ByteBuffers: https://github.com/apache/parquet-mr/commit/6b605a4ea05b66e1a6bf843353abcb4834a4ced8 and https://github.com/apache/parquet-mr/commit/6b24a1d1b5e2792a7821ad172a45e38d2b04f9b8 (mostly avro but a couple of ByteBuffer changes) caused our jobs to slow down a bit.\n\nRead overhead: 4-6% (in MB_Millis)\nWrite overhead: 6-10% (MB_Millis).\n\nSeems like this seems to be due to the encoding / decoding of Strings in the [Binary class](https://github.com/apache/parquet-mr/blob/master/parquet-column/src/main/java/org/apache/parquet/io/api/Binary.java):\n[toStringUsingUTF8()](https://github.com/apache/parquet-mr/blob/master/parquet-column/src/main/java/org/apache/parquet/io/api/Binary.java#L388) - for reads\n[encodeUTF8()](https://github.com/apache/parquet-mr/blob/master/parquet-column/src/main/java/org/apache/parquet/io/api/Binary.java#L236) - for writes\n\nWith these changes we see around 5% improvement in MB_Millis while running the job on our Hadoop cluster.\n\nAdded some microbenchmark details to the jira.\n\nNote that I've left the behavior the same for the avro write path - it still uses CharSequence and the Charset based encoders.\n\nAuthor: Piyush Narang <pnarang@twitter.com>\n\nCloses #347 from piyushnarang/bytebuffer-encoding-fix-pr and squashes the following commits:\n\n43c5bdd [Piyush Narang] Keep avro on char sequence\n2d50c8c [Piyush Narang] Update Binary approach\n9e58237 [Piyush Narang] Proof of concept fixes\n",
        "diff": {
            "parquet-avro/src/main/java/org/apache/parquet/avro/AvroWriteSupport.java": [
                1,
                1
            ],
            "parquet-column/src/main/java/org/apache/parquet/io/api/Binary.java": [
                22,
                53
            ]
        }
    },
    "bd0b5af025fab9cad8f94260138741c252f45fc8": {
        "datetime": "2016-06-30T09:54:08-07:00",
        "summary": "PARQUET-612: Add compression codec to FileEncodingsIT.",
        "message": "PARQUET-612: Add compression codec to FileEncodingsIT.\n\nAuthor: Ryan Blue <blue@apache.org>\n\nCloses #343 from rdblue/PARQUET-612-test-compression and squashes the following commits:\n\na5b7dbb [Ryan Blue] PARQUET-612: Add compression codec to FileEncodingsIT.\n",
        "diff": {
            ".travis.yml": null,
            "parquet-hadoop/src/test/java/org/apache/parquet/encodings/FileEncodingsIT.java": [
                20,
                94
            ]
        }
    },
    "e036d60d8a210d5ac28b2e5c51a45ceb82b58f09": {
        "datetime": "2016-07-13T14:50:08-07:00",
        "summary": "PARQUET-654: Add option to disable record-level filtering.",
        "message": "PARQUET-654: Add option to disable record-level filtering.\n\nThis can be used by frameworks that use codegen for filtering to avoid\nrunning filters within Parquet.\n\nAuthor: Ryan Blue <blue@apache.org>\n\nCloses #353 from rdblue/PARQUET-654-add-record-level-filter-option and squashes the following commits:\n\nb497e7f [Ryan Blue] PARQUET-654: Add option to disable record-level filtering.\n",
        "diff": {
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/InternalParquetRecordReader.java": [
                1,
                7
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ParquetFileReader.java": [
                2,
                8
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ParquetInputFormat.java": [
                0,
                18
            ]
        }
    },
    "02ce9b094c0229cdd5430d9931d7407e72e6f453": {
        "datetime": "2016-07-15T09:49:50-07:00",
        "summary": "PARQUET-663: Update README.md",
        "message": "PARQUET-663: Update README.md\n\nFix 404 links in documentation\n\nAuthor: Nihed MBAREK <nihedmm@gmail.com>\n\nCloses #350 from nihed/patch-1 and squashes the following commits:\n\n4ebe950 [Nihed MBAREK] Update README.md\n",
        "diff": {
            "README.md": null
        }
    },
    "42662f8750a2c33ee169f17f4b4e4586db98d869": {
        "datetime": "2016-07-15T09:53:33-07:00",
        "summary": "PARQUET-389: Support predicate push down on missing columns.",
        "message": "PARQUET-389: Support predicate push down on missing columns.\n\nPredicate push-down will complain when predicates reference columns that aren't in a file's schema. This makes it difficult to implement predicate push-down in engines where schemas evolve because each task needs to process the predicates and prune references to columns not in that task's file. This PR implements predicate evaluation for missing columns, where the values are all null. This allows engines to pass predicates as they are written.\n\nA future commit should rewrite the predicates to avoid the extra work currently done in record-level filtering, but that isn't included here because it is an optimization.\n\nAuthor: Ryan Blue <blue@apache.org>\n\nCloses #354 from rdblue/PARQUET-389-predicate-push-down-on-missing-columns and squashes the following commits:\n\nb4d809a [Ryan Blue] PARQUET-389: Support record-level filtering with missing columns.\n91b841c [Ryan Blue] PARQUET-389: Add missing column support to StatisticsFilter.\n275f950 [Ryan Blue] PARQUET-389: Add missing column support to DictionaryFilter.\n",
        "diff": {
            "parquet-column/src/main/java/org/apache/parquet/filter2/predicate/SchemaCompatibilityValidator.java": [
                3,
                6
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/filter2/dictionarylevel/DictionaryFilter.java": [
                25,
                57
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/filter2/statisticslevel/StatisticsFilter.java": [
                39,
                99
            ],
            "parquet-hadoop/src/test/java/org/apache/parquet/filter2/TestFiltersWithMissingColumns.java": [
                0,
                265
            ],
            "parquet-hadoop/src/test/java/org/apache/parquet/filter2/dictionarylevel/DictionaryFilterTest.java": [
                0,
                54
            ],
            "parquet-hadoop/src/test/java/org/apache/parquet/filter2/statisticslevel/TestStatisticsFilter.java": [
                11,
                28
            ]
        }
    },
    "a421d952efd85ec581131069a5b132934ee286d3": {
        "datetime": "2016-07-15T09:56:32-07:00",
        "summary": "PARQUET-540: Fix Cascading 3 build thrift and SLF4J.",
        "message": "PARQUET-540: Fix Cascading 3 build thrift and SLF4J.\n\nThis fixes:\n* parquet-cascading3 should have a libthrift dependency that uses thrift.version\n* parquet-cascading3 should have the standard SLF4J dependencies\n* Twitter's maven repo is no longer necessary because Parquet uses the Apache maven-thrift-plugin\n\nAuthor: Ryan Blue <blue@apache.org>\n\nCloses #328 from rdblue/PARQUET-540-fix-cascading3-build and squashes the following commits:\n\nb8e509b [Ryan Blue] PARQUET-540: Add a constant for maven-thrift-plugin version.\nc976e04 [Ryan Blue] PARQUET-540: Fix Cascading 3 build thrift and SLF4J.\n",
        "diff": {
            "parquet-cascading/pom.xml": null,
            "parquet-cascading3/pom.xml": null,
            "parquet-scrooge/pom.xml": null,
            "parquet-thrift/pom.xml": null,
            "pom.xml": null
        }
    },
    "626014eaf093fc2e3b53f5ad00c425bc209e1428": {
        "datetime": "2016-07-17T14:59:20-07:00",
        "summary": "PARQUET-651: Improve Avro's isElementType check.",
        "message": "PARQUET-651: Improve Avro's isElementType check.\n\nThe Avro implementation needs to check whether the read schema that is\npassed by the user (or automatically converted from the file schema)\nexpects an extra 1-field layer to be returned, which matches the\nprevious behavior of Avro when reading a 3-level list. Before this\ncommit, the check was done by testing the structure of the expected list\nelement type against the repeated group's schema. If they matched, then\nAvro assumed that the user expected an extra layer. However, for records\nthat happened to match (1-field records with a field named \"element\")\nthe check could be wrong and would cause exceptions later.\n\nThis commit updates the check to convert the file's element schema to\nAvro and compare the compatibility of that schema with what was passed\nby the user. This checks the entire tree from the element down and gets\nthe answer right based on the element and its children, not just the\nfield names on the element.\n\nAuthor: Ryan Blue <blue@apache.org>\n\nCloses #352 from rdblue/PARQUET-651-improve-is-element-type-check and squashes the following commits:\n\nad9c1ee [Ryan Blue] PARQUET-651: Undo accidental default setting change.\n1efa248 [Ryan Blue] PARQUET-651: Improve Avro's isElementType check.\n",
        "diff": {
            "parquet-avro/src/main/java/org/apache/parquet/avro/AvroRecordConverter.java": [
                6,
                17
            ],
            "parquet-avro/src/main/java/org/apache/parquet/avro/AvroSchemaConverter.java": [
                0,
                15
            ],
            "parquet-avro/src/test/java/org/apache/parquet/avro/TestArrayCompatibility.java": [
                1,
                147
            ]
        }
    },
    "6a62646bfcecec9c0806a216b17e1a4ccb4609aa": {
        "datetime": "2016-07-17T16:27:20-07:00",
        "summary": "PARQUET-543: Remove unused boundedint package.",
        "message": "PARQUET-543: Remove unused boundedint package.\n\nThis relocates the DevNullValuesWriter and ZeroIntegerValuesReader,\nwhich are used but are not related to the boundedint code.\n\nAuthor: Ryan Blue <blue@apache.org>\n\nCloses #329 from rdblue/PARQUET-543-remove-boundedint and squashes the following commits:\n\n0158c51 [Ryan Blue] PARQUET-543: Update new import in ParquetProperties.\n550a1a3 [Ryan Blue] PARQUET-543: Remove unused boundedint package.\n",
        "diff": {
            "parquet-column/src/main/java/org/apache/parquet/column/Encoding.java": [
                1,
                1
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/ParquetProperties.java": [
                1,
                1
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/values/boundedint/BitReader.java": [
                124,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/values/boundedint/BitWriter.java": [
                167,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/values/boundedint/BoundedIntValuesFactory.java": [
                33,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/values/boundedint/BoundedIntValuesReader.java": [
                94,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/values/boundedint/BoundedIntValuesWriter.java": [
                165,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/values/boundedint/DevNullValuesWriter.java": [
                1,
                1
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/values/boundedint/ZeroIntegerValuesReader.java": [
                1,
                1
            ],
            "parquet-column/src/test/java/org/apache/parquet/column/values/boundedint/TestBoundedColumns.java": [
                175,
                0
            ]
        }
    },
    "60b6d5aa3feeb31c03baa9f06e2de32172724d78": {
        "datetime": "2016-07-27T12:27:53-07:00",
        "summary": "PARQUET-667: Update committers lists to point to apache website",
        "message": "PARQUET-667: Update committers lists to point to apache website\n\nWe have two out of date lists of committers in .md files in the repo.\nThis PR changes them to point to the apache website which should stay up to date automatically.\n\nAuthor: Alex Levenson <alexlevenson@twitter.com>\n\nCloses #355 from isnotinvain/alexlevenson/committers-update and squashes the following commits:\n\n85945b9 [Alex Levenson] Update committers lists to point to apache website\n",
        "diff": {
            "README.md": null,
            "dev/COMMITTERS.md": null
        }
    },
    "5c85b8dda5f3047732a17b818256b9289274d071": {
        "datetime": "2016-08-01T14:38:07-07:00",
        "summary": "PARQUET-511: Integer overflow when counting values in column.",
        "message": "PARQUET-511: Integer overflow when counting values in column.\n\nThis commit fixes an issue when the number of entries in a column page is larger than the size of an integer. No exception is thrown directly, but the def level is set incorrectly, leading to a null value being returned during read.\n\nAuthor: Michal Gorecki <goreckim@amazon.com>\n\nCloses #321 from goreckm/int-overflow and squashes the following commits:\n\nd224815 [Michal Gorecki] enhancing exception message\n7334be2 [Michal Gorecki] PARQUET-511: Integer overflow when counting values in column.\n",
        "diff": {
            "parquet-column/src/main/java/org/apache/parquet/column/impl/ColumnReaderImpl.java": [
                3,
                3
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ColumnChunkPageReadStore.java": [
                1,
                1
            ]
        }
    },
    "ea402becca436dc1a8e47ac9385a3db475b49355": {
        "datetime": "2016-08-03T14:14:26-07:00",
        "summary": "PARQUET-668 - Provide option to disable auto crop feature in dump",
        "message": "PARQUET-668 - Provide option to disable auto crop feature in dump\n\nhttps://issues.apache.org/jira/browse/PARQUET-668\n\n1. Added option `--disable-crop`\n2. Updated `README.md` to reflect changes\n\nAuthor: djhworld <djharperuk@gmail.com>\n\nCloses #358 from djhworld/master and squashes the following commits:\n\n493c3d0 [djhworld] PARQUET-668: Removed usage instructions from README, replaced with --help flag\n696a5e6 [djhworld] PARQUET-668 -> Updated README.md to fix issue in usage string\n6cbf59b [djhworld] PARQUET-668 - Provide option to disable auto crop feature in DumpCommand output\n",
        "diff": {
            "parquet-tools/README.md": null,
            "parquet-tools/src/main/java/org/apache/parquet/tools/command/DumpCommand.java": [
                9,
                22
            ]
        }
    },
    "76a2ac814caa194c46be1cf7a3f5dc129546b1c1": {
        "datetime": "2016-08-03T14:22:27-07:00",
        "summary": "PARQUET-669: allow reading footers from provided file listing and streams",
        "message": "PARQUET-669: allow reading footers from provided file listing and streams\n\nThe use case is that I want to reuse existing listing of files and avoid doing it again when opening streams. This is in case where filesystem.open is expensive but you have other means of obtaining input stream for a file.\n\nAuthor: Robert Kruszewski <robertk@palantir.com>\n\nCloses #357 from robert3005/robertk/allow-reading-footers-from-streams and squashes the following commits:\n\n4d8a54c [Robert Kruszewski] allow reading footers from provided file listing and streams\n",
        "diff": {
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ParquetFileReader.java": [
                10,
                18
            ]
        }
    },
    "b301d12700acf5313de33785857f88f60bcb053a": {
        "datetime": "2016-08-05T16:22:27-07:00",
        "summary": "PARQUET-667: Add back + update committers table",
        "message": "PARQUET-667: Add back + update committers table\n\nAuthor: Alex Levenson <alexlevenson@twitter.com>\n\nCloses #360 from isnotinvain/alexlevenson/committers-update-2 and squashes the following commits:\n\n20782fa [Alex Levenson] Add back + update committers table\n",
        "diff": {
            "README.md": null,
            "dev/COMMITTERS.md": null
        }
    },
    "30aa91012cf6019bb9720609c1d03b5386a87ffb": {
        "datetime": "2016-08-11T13:30:43-07:00",
        "summary": "PARQUET-601: Add support to configure the encoding used by ValueWriters",
        "message": "PARQUET-601: Add support to configure the encoding used by ValueWriters\n\n### Context:\nParquet is currently structured to choose the appropriate value writer based on the type of the column as well as the Parquet version. As of now, the writer(s) (and hence encoding) for each data type is hard coded in the Parquet source code.\n\nThis PR adds support for being able to override the encodings per type via config. That allows users to experiment with various encoding strategies manually as well as enables them to override the hardcoded defaults if they don't suit their use case.\n\nWe can override encodings per data type (int32 / int64 / ...).\nSomething on the lines of:\n```\nparquet.writer.encoding-override.<type> = \"encoding1[,encoding2]\"\n```\n\nAs an example:\n```\n\"parquet.writer.encoding-override.int32\" = \"plain\"\n(Chooses Plain encoding and hence the PlainValuesWriter).\n```\n\nWhen a primary + fallback need to be specified, we can do the following:\n```\n\"parquet.writer.encoding-override.binary\" = \"rle_dictionary,delta_byte_array\"\n(Chooses RLE_DICTIONARY encoding as the initial encoding and DELTA_BYTE_ARRAY encoding as the fallback and hence creates a FallbackWriter(PlainBinaryDictionaryValuesWriter, DeltaByteArrayWriter).\n```\n\nIn such cases we can mandate that the first encoding listed must allow for Fallbacks by implementing [RequiresFallback](https://github.com/apache/parquet-mr/blob/master/parquet-column/src/main/java/org/apache/parquet/column/values/RequiresFallback.java#L31).\n\n### PR notes:\n\n- Restructured the ValuesWriter creation code. Pulled it out of ParquetProperties into a new class and refactored the flow based on type as it was getting hard to follow and I felt adding the overrides would make it harder. Added a bunch of unit tests to verify the ValuesWriter we create for combinations of type, parquet version and dictionary on / off.\n- Added unit tests to verify parsing of the encoding overrides + creation of ValuesWriters based on these overrides.\n- Manually tested some encoding overrides scenarios out on Hadoop (both parquet v1, v2).\n\nAuthor: Piyush Narang <pnarang@twitter.com>\n\nCloses #342 from piyushnarang/master and squashes the following commits:\n\n3ebab28 [Piyush Narang] Remove Configurable\n149bb98 [Piyush Narang] Switch to getValuesWriterFactory call to non-static\n0b78e04 [Piyush Narang] Address Ryan's feedback\n1da6ca3 [Piyush Narang] Merge branch 'master' into piyush/dynamic-encoding-overrides\nf021ed2 [Piyush Narang] Tweak comment in ValuesWriterFactory\ncb02ea0 [Piyush Narang] Fix review comments\nbf4bc6d [Piyush Narang] Add support for Config setting in ValuesWriter factory\n8a852a3 [Piyush Narang] Log values writer factory chosen\ne4b61a4 [Piyush Narang] Tweak factory instantiation a bit\nb46cccd [Piyush Narang] Add class based factory override\n6a5428f [Piyush Narang] Clean up some stuff in ValuesWriterFactory\n0f8cd09 [Piyush Narang] Refactor mockito version\n9ead61d [Piyush Narang] Add guava test dep\n5c636c7 [Piyush Narang] Add encoding-overrides config to ParquetOutputFormat config\nb9d6c13 [Piyush Narang] Refactor code in ValuesWriterFactory a bit\nff4c90d [Piyush Narang] Pull out value writer creation to ValuesWriterFactory and add unit tests\n",
        "diff": {
            "parquet-avro/pom.xml": null,
            "parquet-cascading/pom.xml": null,
            "parquet-cascading3/pom.xml": null,
            "parquet-column/pom.xml": null,
            "parquet-column/src/main/java/org/apache/parquet/column/ParquetProperties.java": [
                138,
                38
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/values/factory/DefaultV1ValuesWriterFactory.java": [
                0,
                111
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/values/factory/DefaultV2ValuesWriterFactory.java": [
                0,
                115
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/values/factory/DefaultValuesWriterFactory.java": [
                0,
                87
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/values/factory/ValuesWriterFactory.java": [
                0,
                47
            ],
            "parquet-column/src/test/java/org/apache/parquet/column/values/factory/DefaultValuesWriterFactoryTest.java": [
                0,
                350
            ],
            "parquet-hadoop/pom.xml": null,
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ParquetOutputFormat.java": [
                11,
                12
            ],
            "parquet-pig/pom.xml": null,
            "parquet-protobuf/pom.xml": null,
            "parquet-tools/pom.xml": null,
            "pom.xml": null
        }
    },
    "c8d78b21b3dde3bfb36fed7cb33bd4ec3f01b8da": {
        "datetime": "2016-08-15T14:59:03-07:00",
        "summary": "PARQUET-146: Move Parquet to Java 7",
        "message": "PARQUET-146: Move Parquet to Java 7\n\nThis has been pending for a while. With the other fix referenced in PARQUET-146, I think Parquet can now move to Java 7.\n\nAuthor: Nezih Yigitbasi <nyigitbasi@netflix.com>\n\nCloses #231 from nezihyigitbasi/parquet-java7 and squashes the following commits:\n\n0b7130a [Nezih Yigitbasi] Compile with Java 7\n",
        "diff": {
            "pom.xml": null
        }
    },
    "898f3d0f652f313473c67fef32e22d94d8294d4f": {
        "datetime": "2016-08-16T10:12:00-07:00",
        "summary": "PARQUET-400: Replace CompatibilityUtil with SeekableInputStream.",
        "message": "PARQUET-400: Replace CompatibilityUtil with SeekableInputStream.\n\nThis fixes PARQUET-400 by replacing `CompatibilityUtil` with `SeekableInputStream` that's implemented for hadoop-1 and hadoop-2. The benefit of this approach is that `SeekableInputStream` can be used for non-Hadoop file systems in the future.\n\nThis also changes the default Hadoop version to Hadoop-2. The library is still compatible with Hadoop 1.x, but this makes building Hadoop-2 classes, like `H2SeekableInputStream`, much easier and removes the need for multiple hadoop versions during compilation.\n\nAuthor: Ryan Blue <blue@apache.org>\n\nCloses #349 from rdblue/PARQUET-400-byte-buffers and squashes the following commits:\n\n1bcb8a8 [Ryan Blue] PARQUET-400: Fix review nits.\n823ca00 [Ryan Blue] PARQUET-400: Add tests for Hadoop 2 readFully.\n02d3709 [Ryan Blue] PARQUET-400: Remove unused property.\nb543013 [Ryan Blue] PARQUET-400: Fix logger for HadoopStreams.\n2cb6934 [Ryan Blue] PARQUET-400: Remove H2SeekableInputStream tests.\nabaa695 [Ryan Blue] PARQUET-400: Fix review items.\n5dc50a5 [Ryan Blue] PARQUET-400: Add tests for H1SeekableInputStream methods.\n730a9e2 [Ryan Blue] PARQUET-400: Move SeekableInputStream to io package.\n506a556 [Ryan Blue] PARQUET-400: Remove Hadoop dependencies from SeekableInputStream.\nc80580c [Ryan Blue] PARQUET-400: Handle UnsupportedOperationException from read(ByteBuffer).\nba08b3f [Ryan Blue] PARQUET-400: Replace CompatibilityUtil with SeekableInputStream.\n",
        "diff": {
            ".travis.yml": null,
            "parquet-common/src/main/java/org/apache/parquet/io/SeekableInputStream.java": [
                0,
                106
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ParquetFileReader.java": [
                14,
                17
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ParquetFileWriter.java": [
                2,
                15
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/util/CompatibilityUtil.java": [
                114,
                0
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/util/H1SeekableInputStream.java": [
                0,
                154
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/util/H2SeekableInputStream.java": [
                0,
                107
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/util/HadoopStreams.java": [
                0,
                100
            ],
            "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/util/MockInputStream.java": [
                0,
                87
            ],
            "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/util/TestHadoop1ByteBufferReads.java": [
                0,
                761
            ],
            "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/util/TestHadoop2ByteBufferReads.java": [
                0,
                405
            ],
            "pom.xml": null
        }
    },
    "255f10834a67cf13518316de0e2c8a345677ebbf": {
        "datetime": "2016-08-16T10:40:52-07:00",
        "summary": "PARQUET-460: merge multi parquet files to one file",
        "message": "PARQUET-460: merge multi parquet files to one file\n\nA merge command for parquet-tools based on https://issues.apache.org/jira/browse/PARQUET-382.\n\nAuthor: flykobe <flykobecy@gmail.com>\n\nCloses #327 from flykobe/merge_tool and squashes the following commits:\n\nb031c18 [flykobe] check input files\nda28832 [flykobe] merge multi parquet files to one file\n",
        "diff": {
            "parquet-tools/src/main/java/org/apache/parquet/tools/command/MergeCommand.java": [
                0,
                157
            ],
            "parquet-tools/src/main/java/org/apache/parquet/tools/command/Registry.java": [
                0,
                1
            ],
            "parquet-tools/src/main/scripts/parquet-merge": null
        }
    },
    "6dad1e3bd0e277f5b5e5e2a0720f474271c1648d": {
        "datetime": "2016-08-29T11:34:27-07:00",
        "summary": "PARQUET-696: fix travis build. Broken because google code shut down",
        "message": "PARQUET-696: fix travis build. Broken because google code shut down\n\nAuthor: Julien Le Dem <julien@dremio.com>\n\nCloses #364 from julienledem/fix_travis and squashes the following commits:\n\n3e80893 [Julien Le Dem] update README.md\n958e0ef [Julien Le Dem] fix travis build. Broken because google code shut down\n",
        "diff": {
            ".travis.yml": null,
            "README.md": null
        }
    },
    "044de16c14076019f87763b7b58c45664ee57c11": {
        "datetime": "2016-09-08T14:22:30-07:00",
        "summary": "PARQUET-623: Fix DeltaByteArrayReader#skip.",
        "message": "PARQUET-623: Fix DeltaByteArrayReader#skip.\n\nPreviously, this passed the skip to the underlying readers, but would\nnot update previous and would corrupt values or cause exceptions.\n\nAuthor: Ryan Blue <blue@apache.org>\n\nCloses #366 from rdblue/PARQUET-623-fix-delta-byte-array-skip and squashes the following commits:\n\nf85800c [Ryan Blue] PARQUET-623: Fix DeltaByteArrayReader#skip.\n",
        "diff": {
            "parquet-column/src/main/java/org/apache/parquet/column/values/deltastrings/DeltaByteArrayReader.java": [
                2,
                2
            ],
            "parquet-column/src/test/java/org/apache/parquet/column/values/deltastrings/TestDeltaByteArray.java": [
                0,
                18
            ]
        }
    },
    "e54ca615f213f5db6d34d9163c97eec98920d7a7": {
        "datetime": "2016-09-08T14:48:42-07:00",
        "summary": "PARQUET-660: Ignore extension fields in protobuf messages.",
        "message": "PARQUET-660: Ignore extension fields in protobuf messages.\n\nCurrently, converting protobuf messages with extension can result in an uninformative error or a data corruption. A more detailed explanation in the corresponding [jira](https://issues.apache.org/jira/browse/PARQUET-660).\n\nThis patch simply ignores extension fields in protobuf messages.\n\nIn the longer run, I'd like to add a proper support for Protobuf extensions. This might take a little longer though, so I've decided to improve the current situation with this patch.\n\nAuthor: Jakub Kukul <jakub.kukul@gmail.com>\n\nCloses #351 from jkukul/master and squashes the following commits:\n\n27580ab [Jakub Kukul] PARQUET-660: Throw Unsupported exception for messages with extensions.\ndb6e08b [Jakub Kukul] PARQUET-660: Refactor: Don't use additional variable for indexing fieldWriters.\ne910a8a [Jakub Kukul] PARQUET-660: Refactor: Add missing indentation.\n",
        "diff": {
            "parquet-protobuf/src/main/java/org/apache/parquet/proto/ProtoSchemaConverter.java": [
                15,
                15
            ],
            "parquet-protobuf/src/main/java/org/apache/parquet/proto/ProtoWriteSupport.java": [
                4,
                9
            ],
            "parquet-protobuf/src/test/java/org/apache/parquet/proto/ProtoWriteSupportTest.java": [
                0,
                15
            ],
            "parquet-protobuf/src/test/resources/TestProtobuf.proto": null
        }
    },
    "b59be86597cfcd805c24fa406af46071400e24c8": {
        "datetime": "2016-10-03T15:04:12-07:00",
        "summary": "PARQUET-674: Add InputFile abstraction for openable files.",
        "message": "PARQUET-674: Add InputFile abstraction for openable files.\n\nAuthor: Ryan Blue <blue@apache.org>\n\nCloses #368 from rdblue/PARQUET-674-add-data-source and squashes the following commits:\n\n8c689e9 [Ryan Blue] PARQUET-674: Implement review comments.\n4a7c327 [Ryan Blue] PARQUET-674: Add DataSource abstraction for openable files.\n",
        "diff": {
            "parquet-common/src/main/java/org/apache/parquet/io/InputFile.java": [
                0,
                43
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ParquetFileReader.java": [
                11,
                21
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/util/HadoopInputFile.java": [
                0,
                66
            ]
        }
    },
    "07a42d3ffd034e467e49b5c449d4f5f81c471cc5": {
        "datetime": "2016-10-05T13:20:41-07:00",
        "summary": "PARQUET-726: Increase max difference of testMemoryManagerUpperLimit to 10%",
        "message": "PARQUET-726: Increase max difference of testMemoryManagerUpperLimit to 10%\n\nAuthor: Niels Basjes <nbasjes@bol.com>\n\nCloses #370 from nielsbasjes/PARQUET-726 and squashes the following commits:\n\nf385ede [Niels Basjes] PARQUET-726: Increase max difference of testMemoryManagerUpperLimit to 10%\n",
        "diff": {
            "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/TestMemoryManager.java": [
                3,
                4
            ]
        }
    },
    "e6da0f682436e1387ad68e86edf7418c0f7cb368": {
        "datetime": "2016-10-05T13:21:40-07:00",
        "summary": "PARQUET-685 - Deprecated ParquetInputSplit constructor passes paramet\u2026",
        "message": "PARQUET-685 - Deprecated ParquetInputSplit constructor passes paramet\u2026\n\nThe problem was not discovered because the test was bugous. Updated both sides.\n\nAuthor: Gabor Szadovszky <gabor.szadovszky@cloudera.com>\n\nCloses #372 from gszadovszky/PARQUET-685 and squashes the following commits:\n\n9cbeee2 [Gabor Szadovszky] PARQUET-685 - Deprecated ParquetInputSplit constructor passes parameters in the wrong order.\n",
        "diff": {
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ParquetInputSplit.java": [
                2,
                1
            ],
            "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/TestInputFormat.java": [
                4,
                1
            ]
        }
    },
    "a0e6cc32c79ea725c72bc80335884635fe570ce1": {
        "datetime": "2016-10-07T14:28:40-07:00",
        "summary": "PARQUET-727: Ensure correct version of thrift is used",
        "message": "PARQUET-727: Ensure correct version of thrift is used\n\nThis will make the build fail if the wrong version of thrift is used before building the generated sources fails.\n\nAuthor: Niels Basjes <nbasjes@bol.com>\n\nCloses #371 from nielsbasjes/PARQUET-727 and squashes the following commits:\n\nf6e447b [Niels Basjes] PARQUET-727: Moved check to profile that is only active on non-Windows systems.\n732ef39 [Niels Basjes] PARQUET-727: Ensure correct version of thrift is used\n",
        "diff": {
            "parquet-thrift/pom.xml": null
        }
    },
    "06768d91b5fe9eb98f5872efcbe87c3ea447f61e": {
        "datetime": "2016-10-10T13:11:07-07:00",
        "summary": "PARQUET-740: Introduce editorconfig",
        "message": "PARQUET-740: Introduce editorconfig\n\nI examined some of the code and as far as I can tell this specification matches what has been done in this project so far. Please verify.\n\nAuthor: Niels Basjes <nbasjes@bol.com>\n\nCloses #373 from nielsbasjes/PARQUET-740 and squashes the following commits:\n\n2783fc6 [Niels Basjes] PARQUET-740: Introduce editorconfig\n",
        "diff": {
            ".editorconfig": null
        }
    },
    "de99127d77dabfc6c8134b3c58e0b9a0b74e5f37": {
        "datetime": "2016-10-12T09:35:51-07:00",
        "summary": "PARQUET-686: Do not return min/max for the wrong order.",
        "message": "PARQUET-686: Do not return min/max for the wrong order.\n\nMin and max are currently calculated using the default Java ordering\nthat uses signed comparison for all values. This is not correct for\nbinary types like strings and decimals or for unsigned numeric types.\nThis commit prevents statistics accumulated using the signed ordering\nfrom being returned by ParquetMetadataConverter when the type should use\nthe unsigned ordering.\n\nBecause many binary strings are not affected by using the wrong\nordering, this adds a property, parquet.strings.use-signed-order to\nallow overriding this change.\n\nAuthor: Ryan Blue <blue@apache.org>\n\nCloses #367 from rdblue/PARQUET-686-suppress-signed-stats and squashes the following commits:\n\nf9d459f [Ryan Blue] PARQUET-686: Add getConfiguration to HadoopInputFile.\n301bd3a [Ryan Blue] PARQUET-686: Address review comments.\nc099c35 [Ryan Blue] PARQUET-686: Do not return min/max for the wrong order.\n",
        "diff": {
            "parquet-hadoop/src/main/java/org/apache/parquet/format/converter/ParquetMetadataConverter.java": [
                2,
                137
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ParquetFileReader.java": [
                9,
                25
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/util/HadoopInputFile.java": [
                3,
                9
            ],
            "parquet-hadoop/src/test/java/org/apache/parquet/format/converter/TestParquetMetadataConverter.java": [
                2,
                51
            ],
            "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/TestParquetFileWriter.java": [
                4,
                4
            ],
            "parquet-thrift/src/test/java/org/apache/parquet/hadoop/thrift/TestThriftToParquetFileWriter.java": [
                0,
                2
            ]
        }
    },
    "59ec4f018963eb55e32fafc2b924826c39c09682": {
        "datetime": "2016-10-12T18:05:21-07:00",
        "summary": "PARQUET-743: Fix DictionaryFilter when compressed dictionaries are reused.",
        "message": "PARQUET-743: Fix DictionaryFilter when compressed dictionaries are reused.\n\nBytesInput is not supposed to be held and reused, but decompressed\ndictionary pages do this. Reusing the dictionary will cause a failure,\nso the cleanest option is to keep the bytes around once the underlying\nstream has been read.\n\nAuthor: Ryan Blue <blue@apache.org>\n\nCloses #376 from rdblue/PARQUET-743-fix-reused-dictionaries and squashes the following commits:\n\n28c0903 [Ryan Blue] PARQUET-743: Fix DictionaryFilter when dictionaries are reused.\n",
        "diff": {
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/DictionaryPageReader.java": [
                1,
                18
            ],
            "parquet-hadoop/src/test/java/org/apache/parquet/filter2/dictionarylevel/DictionaryFilterTest.java": [
                2,
                2
            ]
        }
    },
    "31d0d4d6d787246843dde4fb7d415565c8411945": {
        "datetime": "2016-10-13T08:28:04-07:00",
        "summary": "PARQUET-392: Update CHANGES.md for 1.9.0.",
        "message": "PARQUET-392: Update CHANGES.md for 1.9.0.\n",
        "diff": {
            "CHANGES.md": null
        }
    },
    "2a99abf784cb6e76160d49506ea87581a2256021": {
        "datetime": "2016-10-13T10:13:45-07:00",
        "summary": "[maven-release-plugin] prepare release apache-parquet-1.9.0",
        "message": "[maven-release-plugin] prepare release apache-parquet-1.9.0\n",
        "diff": {
            "parquet-avro/pom.xml": null,
            "parquet-benchmarks/pom.xml": null,
            "parquet-cascading/pom.xml": null,
            "parquet-cascading3/pom.xml": null,
            "parquet-column/pom.xml": null,
            "parquet-common/pom.xml": null,
            "parquet-encoding/pom.xml": null,
            "parquet-generator/pom.xml": null,
            "parquet-hadoop-bundle/pom.xml": null,
            "parquet-hadoop/pom.xml": null,
            "parquet-hive-bundle/pom.xml": null,
            "parquet-hive/parquet-hive-binding/parquet-hive-0.10-binding/pom.xml": null,
            "parquet-hive/parquet-hive-binding/parquet-hive-0.12-binding/pom.xml": null,
            "parquet-hive/parquet-hive-binding/parquet-hive-binding-bundle/pom.xml": null,
            "parquet-hive/parquet-hive-binding/parquet-hive-binding-factory/pom.xml": null,
            "parquet-hive/parquet-hive-binding/parquet-hive-binding-interface/pom.xml": null,
            "parquet-hive/parquet-hive-binding/pom.xml": null,
            "parquet-hive/parquet-hive-storage-handler/pom.xml": null,
            "parquet-hive/pom.xml": null,
            "parquet-jackson/pom.xml": null,
            "parquet-pig-bundle/pom.xml": null,
            "parquet-pig/pom.xml": null,
            "parquet-protobuf/pom.xml": null,
            "parquet-scala/pom.xml": null,
            "parquet-scrooge/pom.xml": null,
            "parquet-thrift/pom.xml": null,
            "parquet-tools/pom.xml": null,
            "pom.xml": null
        }
    },
    "27b9934c18a882917397efcd36ba0acb9bd1e3b5": {
        "datetime": "2016-10-13T10:14:03-07:00",
        "summary": "[maven-release-plugin] prepare for next development iteration",
        "message": "[maven-release-plugin] prepare for next development iteration\n",
        "diff": {
            "parquet-avro/pom.xml": null,
            "parquet-benchmarks/pom.xml": null,
            "parquet-cascading/pom.xml": null,
            "parquet-cascading3/pom.xml": null,
            "parquet-column/pom.xml": null,
            "parquet-common/pom.xml": null,
            "parquet-encoding/pom.xml": null,
            "parquet-generator/pom.xml": null,
            "parquet-hadoop-bundle/pom.xml": null,
            "parquet-hadoop/pom.xml": null,
            "parquet-hive-bundle/pom.xml": null,
            "parquet-hive/parquet-hive-binding/parquet-hive-0.10-binding/pom.xml": null,
            "parquet-hive/parquet-hive-binding/parquet-hive-0.12-binding/pom.xml": null,
            "parquet-hive/parquet-hive-binding/parquet-hive-binding-bundle/pom.xml": null,
            "parquet-hive/parquet-hive-binding/parquet-hive-binding-factory/pom.xml": null,
            "parquet-hive/parquet-hive-binding/parquet-hive-binding-interface/pom.xml": null,
            "parquet-hive/parquet-hive-binding/pom.xml": null,
            "parquet-hive/parquet-hive-storage-handler/pom.xml": null,
            "parquet-hive/pom.xml": null,
            "parquet-jackson/pom.xml": null,
            "parquet-pig-bundle/pom.xml": null,
            "parquet-pig/pom.xml": null,
            "parquet-protobuf/pom.xml": null,
            "parquet-scala/pom.xml": null,
            "parquet-scrooge/pom.xml": null,
            "parquet-thrift/pom.xml": null,
            "parquet-tools/pom.xml": null,
            "pom.xml": null
        }
    },
    "0116aa788e2b3b85859c1aa9b998d6ed32b16401": {
        "datetime": "2016-10-13T10:54:31-07:00",
        "summary": "PARQUET-392: Fix svn log message in source-release.sh.",
        "message": "PARQUET-392: Fix svn log message in source-release.sh.\n",
        "diff": {
            "dev/source-release.sh": null
        }
    },
    "1058b7d98f83c47d5f400c3c758f1cc898540988": {
        "datetime": "2016-10-13T10:55:42-07:00",
        "summary": "PARQUET-392: Fix staging instructions in prepare-release.sh.",
        "message": "PARQUET-392: Fix staging instructions in prepare-release.sh.\n",
        "diff": {
            "dev/prepare-release.sh": null
        }
    },
    "ece4b70cce24b89483236b4cff079c10597d680a": {
        "datetime": "2016-10-18T17:45:32-07:00",
        "summary": "PARQUET-751: Add setRequestedSchema to ParquetFileReader.",
        "message": "PARQUET-751: Add setRequestedSchema to ParquetFileReader.\n\nThis fixes a bug introduced by dictionary filters, which reused an\nexisting file reader to avoid opening multiple input streams. Before\nthat commit, a new file reader was opened and passed the projection\ncolumns from the read context. The fix is to set the requested schema on\nthe file reader instead of creating a new instance.\n\nThis also adds a test to ensure that column projection works to catch\nbugs like this in the future.\n\nAuthor: Ryan Blue <blue@apache.org>\n\nCloses #379 from rdblue/PARQUET-751-fix-column-projection and squashes the following commits:\n\n7ea0c16 [Ryan Blue] PARQUET-751: Fix column projection test.\n1da507e [Ryan Blue] PARQUET-751: Add setRequestedSchema to ParquetFileReader.\n",
        "diff": {
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/InternalParquetRecordReader.java": [
                0,
                1
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ParquetFileReader.java": [
                0,
                8
            ],
            "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/TestInputFormatColumnProjection.java": [
                0,
                180
            ]
        }
    },
    "38262e2c80015d0935dad20f8e18f2d6f9fbd03c": {
        "datetime": "2016-10-18T18:00:09-07:00",
        "summary": "[maven-release-plugin] prepare release apache-parquet-1.9.0",
        "message": "[maven-release-plugin] prepare release apache-parquet-1.9.0\n",
        "diff": {
            "parquet-avro/pom.xml": null,
            "parquet-benchmarks/pom.xml": null,
            "parquet-cascading/pom.xml": null,
            "parquet-cascading3/pom.xml": null,
            "parquet-column/pom.xml": null,
            "parquet-common/pom.xml": null,
            "parquet-encoding/pom.xml": null,
            "parquet-generator/pom.xml": null,
            "parquet-hadoop-bundle/pom.xml": null,
            "parquet-hadoop/pom.xml": null,
            "parquet-hive-bundle/pom.xml": null,
            "parquet-hive/parquet-hive-binding/parquet-hive-0.10-binding/pom.xml": null,
            "parquet-hive/parquet-hive-binding/parquet-hive-0.12-binding/pom.xml": null,
            "parquet-hive/parquet-hive-binding/parquet-hive-binding-bundle/pom.xml": null,
            "parquet-hive/parquet-hive-binding/parquet-hive-binding-factory/pom.xml": null,
            "parquet-hive/parquet-hive-binding/parquet-hive-binding-interface/pom.xml": null,
            "parquet-hive/parquet-hive-binding/pom.xml": null,
            "parquet-hive/parquet-hive-storage-handler/pom.xml": null,
            "parquet-hive/pom.xml": null,
            "parquet-jackson/pom.xml": null,
            "parquet-pig-bundle/pom.xml": null,
            "parquet-pig/pom.xml": null,
            "parquet-protobuf/pom.xml": null,
            "parquet-scala/pom.xml": null,
            "parquet-scrooge/pom.xml": null,
            "parquet-thrift/pom.xml": null,
            "parquet-tools/pom.xml": null,
            "pom.xml": null
        }
    },
    "aa416b5e2cb3cd28eae161d53b1a32f482533510": {
        "datetime": "2016-10-18T18:00:33-07:00",
        "summary": "[maven-release-plugin] prepare for next development iteration",
        "message": "[maven-release-plugin] prepare for next development iteration\n",
        "diff": {
            "parquet-avro/pom.xml": null,
            "parquet-benchmarks/pom.xml": null,
            "parquet-cascading/pom.xml": null,
            "parquet-cascading3/pom.xml": null,
            "parquet-column/pom.xml": null,
            "parquet-common/pom.xml": null,
            "parquet-encoding/pom.xml": null,
            "parquet-generator/pom.xml": null,
            "parquet-hadoop-bundle/pom.xml": null,
            "parquet-hadoop/pom.xml": null,
            "parquet-hive-bundle/pom.xml": null,
            "parquet-hive/parquet-hive-binding/parquet-hive-0.10-binding/pom.xml": null,
            "parquet-hive/parquet-hive-binding/parquet-hive-0.12-binding/pom.xml": null,
            "parquet-hive/parquet-hive-binding/parquet-hive-binding-bundle/pom.xml": null,
            "parquet-hive/parquet-hive-binding/parquet-hive-binding-factory/pom.xml": null,
            "parquet-hive/parquet-hive-binding/parquet-hive-binding-interface/pom.xml": null,
            "parquet-hive/parquet-hive-binding/pom.xml": null,
            "parquet-hive/parquet-hive-storage-handler/pom.xml": null,
            "parquet-hive/pom.xml": null,
            "parquet-jackson/pom.xml": null,
            "parquet-pig-bundle/pom.xml": null,
            "parquet-pig/pom.xml": null,
            "parquet-protobuf/pom.xml": null,
            "parquet-scala/pom.xml": null,
            "parquet-scrooge/pom.xml": null,
            "parquet-thrift/pom.xml": null,
            "parquet-tools/pom.xml": null,
            "pom.xml": null
        }
    },
    "df9d8e415436292ae33e1ca0b8da256640de9710": {
        "datetime": "2016-10-26T09:09:56-07:00",
        "summary": "PARQUET-423: Replace old Log class with SLF4J Logging",
        "message": "PARQUET-423: Replace old Log class with SLF4J Logging\n\nAnd make writing files less noisy\n\nAuthor: Niels Basjes <nbasjes@bol.com>\n\nCloses #369 from nielsbasjes/PARQUET-423-2 and squashes the following commits:\n\nb31e30f [Niels Basjes] Merge branch 'master' of github.com:apache/parquet-mr into PARQUET-423-2\n2d4db4b [Niels Basjes] Merge branch 'PARQUET-423-2' of github.com:nielsbasjes/parquet-mr into PARQUET-423-2\n49fcaa7 [Niels Basjes] PARQUET-423: Remove debug logging statements in high performance sections during build time\naaaf4a6 [Niels Basjes] Merge branch 'PARQUET-423-2' of github.com:nielsbasjes/parquet-mr into PARQUET-423-2\n745666e [Niels Basjes] Undo needless change\n94e0c7a [Niels Basjes] PARQUET-423: Further optimize logging performance\nb72f924 [Niels Basjes] PARQUET-423: Improved the performance\ncb7eb61 [Niels Basjes] PARQUET-423: Workaround AVRO errors\n7d161b3 [Niels Basjes] PARQUET-423: Restore the old (obsolete) Log class\n05d6a47 [Niels Basjes] PARQUET-423: Replace old Log class with SLF4J Logging\n692ebfb [Niels Basjes] Undo needless change\nf1ede3d [Niels Basjes] PARQUET-423: Further optimize logging performance\na0c6b59 [Niels Basjes] PARQUET-423: Improved the performance\n67bef9b [Niels Basjes] PARQUET-423: Workaround AVRO errors\n87cd64f [Niels Basjes] PARQUET-423: Restore the old (obsolete) Log class\n96d97d5 [Niels Basjes] PARQUET-423: Replace old Log class with SLF4J Logging\n",
        "diff": {
            "parquet-avro/src/test/java/org/apache/parquet/avro/TestInputOutputFormat.java": [
                4,
                5
            ],
            "parquet-avro/src/test/java/org/apache/parquet/avro/TestReflectInputOutputFormat.java": [
                4,
                5
            ],
            "parquet-avro/src/test/java/org/apache/parquet/avro/TestSpecificInputOutputFormat.java": [
                4,
                5
            ],
            "parquet-column/src/main/java/org/apache/parquet/CorruptDeltaByteArrays.java": [
                5,
                6
            ],
            "parquet-column/src/main/java/org/apache/parquet/CorruptStatistics.java": [
                1,
                3
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/impl/ColumnReaderImpl.java": [
                10,
                10
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/impl/ColumnWriterV1.java": [
                6,
                8
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/impl/ColumnWriterV2.java": [
                8,
                8
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/values/bitpacking/BitPackingValuesReader.java": [
                3,
                4
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/values/bitpacking/ByteBitPackingValuesReader.java": [
                3,
                4
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/values/deltalengthbytearray/DeltaLengthByteArrayValuesReader.java": [
                4,
                4
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/values/deltalengthbytearray/DeltaLengthByteArrayValuesWriter.java": [
                3,
                4
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/values/dictionary/DictionaryValuesReader.java": [
                6,
                5
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/values/dictionary/DictionaryValuesWriter.java": [
                5,
                6
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/values/plain/BinaryPlainValuesReader.java": [
                4,
                4
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/values/plain/BooleanPlainValuesReader.java": [
                4,
                4
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/values/plain/FixedLenByteArrayPlainValuesReader.java": [
                5,
                4
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/values/plain/FixedLenByteArrayPlainValuesWriter.java": [
                3,
                4
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/values/plain/PlainValuesReader.java": [
                5,
                4
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/values/plain/PlainValuesWriter.java": [
                3,
                4
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/values/rle/RunLengthBitPackingHybridDecoder.java": [
                6,
                6
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/values/rle/RunLengthBitPackingHybridEncoder.java": [
                7,
                5
            ],
            "parquet-column/src/main/java/org/apache/parquet/example/data/Group.java": [
                4,
                6
            ],
            "parquet-column/src/main/java/org/apache/parquet/filter2/compat/FilterCompat.java": [
                4,
                5
            ],
            "parquet-column/src/main/java/org/apache/parquet/io/BaseRecordReader.java": [
                14,
                14
            ],
            "parquet-column/src/main/java/org/apache/parquet/io/ColumnIO.java": [
                3,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/io/GroupColumnIO.java": [
                2,
                3
            ],
            "parquet-column/src/main/java/org/apache/parquet/io/MessageColumnIO.java": [
                28,
                32
            ],
            "parquet-column/src/main/java/org/apache/parquet/io/RecordConsumerLoggingWrapper.java": [
                23,
                26
            ],
            "parquet-column/src/main/java/org/apache/parquet/io/RecordReaderImplementation.java": [
                3,
                4
            ],
            "parquet-column/src/main/java/org/apache/parquet/io/ValidatingRecordConsumer.java": [
                5,
                5
            ],
            "parquet-column/src/main/java/org/apache/parquet/schema/MessageTypeParser.java": [
                2,
                3
            ],
            "parquet-column/src/test/java/org/apache/parquet/column/mem/TestMemColumn.java": [
                4,
                5
            ],
            "parquet-column/src/test/java/org/apache/parquet/column/page/mem/MemPageReader.java": [
                4,
                4
            ],
            "parquet-column/src/test/java/org/apache/parquet/column/page/mem/MemPageStore.java": [
                8,
                9
            ],
            "parquet-column/src/test/java/org/apache/parquet/column/page/mem/MemPageWriter.java": [
                17,
                16
            ],
            "parquet-column/src/test/java/org/apache/parquet/column/values/bitpacking/TestBitPackingColumn.java": [
                5,
                6
            ],
            "parquet-column/src/test/java/org/apache/parquet/io/PerfTest.java": [
                5,
                0
            ],
            "parquet-column/src/test/java/org/apache/parquet/io/TestColumnIO.java": [
                3,
                4
            ],
            "parquet-common/src/main/java/org/apache/parquet/Closeables.java": [
                1,
                4
            ],
            "parquet-common/src/main/java/org/apache/parquet/bytes/BytesUtils.java": [
                3,
                4
            ],
            "parquet-common/src/test/java/org/apache/parquet/TestLog.java": [
                31,
                0
            ],
            "parquet-encoding/src/main/java/org/apache/parquet/bytes/BytesInput.java": [
                12,
                14
            ],
            "parquet-encoding/src/main/java/org/apache/parquet/bytes/CapacityByteArrayOutputStream.java": [
                5,
                7
            ],
            "parquet-encoding/src/main/java/org/apache/parquet/column/values/bitpacking/ByteBasedBitPackingEncoder.java": [
                7,
                7
            ],
            "parquet-encoding/src/test/java/org/apache/parquet/column/values/bitpacking/TestBitPacking.java": [
                4,
                5
            ],
            "parquet-encoding/src/test/java/org/apache/parquet/column/values/bitpacking/TestByteBitPacking.java": [
                21,
                22
            ],
            "parquet-encoding/src/test/java/org/apache/parquet/column/values/bitpacking/TestLemireBitPacking.java": [
                8,
                9
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/filter2/dictionarylevel/DictionaryFilter.java": [
                3,
                4
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/format/converter/ParquetMetadataConverter.java": [
                4,
                5
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ColumnChunkPageReadStore.java": [
                2,
                3
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ColumnChunkPageWriteStore.java": [
                5,
                5
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/DirectCodecFactory.java": [
                5,
                6
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/InternalParquetRecordReader.java": [
                14,
                14
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/InternalParquetRecordWriter.java": [
                9,
                7
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/LruCache.java": [
                19,
                15
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/MemoryManager.java": [
                3,
                4
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ParquetFileReader.java": [
                24,
                12
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ParquetFileWriter.java": [
                22,
                19
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ParquetInputFormat.java": [
                16,
                14
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ParquetOutputCommitter.java": [
                2,
                3
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ParquetOutputFormat.java": [
                14,
                14
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ParquetRecordReader.java": [
                2,
                3
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/UnmaterializableRecordCounter.java": [
                2,
                3
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/codec/CodecConfig.java": [
                10,
                8
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/util/HadoopStreams.java": [
                2,
                4
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/util/SerializationUtil.java": [
                2,
                3
            ],
            "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/TestParquetFileWriter.java": [
                3,
                4
            ],
            "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/example/TestInputOutputFormat.java": [
                4,
                5
            ],
            "parquet-hadoop/src/test/resources/log4j.properties": null,
            "parquet-hive/parquet-hive-binding/parquet-hive-0.10-binding/src/main/java/org/apache/parquet/hive/internal/Hive010Binding.java": [
                2,
                3
            ],
            "parquet-hive/parquet-hive-binding/parquet-hive-0.12-binding/src/main/java/org/apache/parquet/hive/internal/Hive012Binding.java": [
                2,
                3
            ],
            "parquet-hive/parquet-hive-binding/parquet-hive-binding-factory/src/main/java/org/apache/parquet/hive/HiveBindingFactory.java": [
                8,
                7
            ],
            "parquet-hive/parquet-hive-storage-handler/src/main/java/org/apache/hadoop/hive/ql/io/parquet/MapredParquetOutputFormat.java": [
                4,
                4
            ],
            "parquet-hive/parquet-hive-storage-handler/src/main/java/org/apache/hadoop/hive/ql/io/parquet/read/ParquetRecordReaderWrapper.java": [
                3,
                3
            ],
            "parquet-hive/parquet-hive-storage-handler/src/main/java/org/apache/hadoop/hive/ql/io/parquet/write/ParquetRecordWriterWrapper.java": [
                5,
                5
            ],
            "parquet-pig/src/main/java/org/apache/parquet/pig/ParquetLoader.java": [
                16,
                16
            ],
            "parquet-pig/src/main/java/org/apache/parquet/pig/PigSchemaConverter.java": [
                9,
                9
            ],
            "parquet-pig/src/main/java/org/apache/parquet/pig/TupleReadSupport.java": [
                2,
                3
            ],
            "parquet-pig/src/test/java/org/apache/parquet/pig/PerfTest2.java": [
                2,
                6
            ],
            "parquet-pig/src/test/java/org/apache/parquet/pig/TestTupleRecordConsumer.java": [
                6,
                7
            ],
            "parquet-pig/src/test/java/org/apache/parquet/pig/TupleConsumerPerfTest.java": [
                1,
                0
            ],
            "parquet-protobuf/src/main/java/org/apache/parquet/proto/ProtoReadSupport.java": [
                5,
                6
            ],
            "parquet-protobuf/src/main/java/org/apache/parquet/proto/ProtoSchemaConverter.java": [
                2,
                3
            ],
            "parquet-protobuf/src/main/java/org/apache/parquet/proto/ProtoWriteSupport.java": [
                2,
                3
            ],
            "parquet-protobuf/src/test/java/org/apache/parquet/proto/utils/WriteUsingMR.java": [
                4,
                5
            ],
            "parquet-thrift/src/main/java/org/apache/parquet/hadoop/thrift/AbstractThriftWriteSupport.java": [
                2,
                3
            ],
            "parquet-thrift/src/main/java/org/apache/parquet/hadoop/thrift/ThriftReadSupport.java": [
                4,
                5
            ],
            "parquet-thrift/src/main/java/org/apache/parquet/thrift/ParquetReadProtocol.java": [
                24,
                23
            ],
            "parquet-thrift/src/main/java/org/apache/parquet/thrift/ParquetWriteProtocol.java": [
                24,
                24
            ],
            "parquet-thrift/src/main/java/org/apache/parquet/thrift/ThriftMetaData.java": [
                2,
                3
            ],
            "parquet-thrift/src/main/java/org/apache/parquet/thrift/ThriftRecordConverter.java": [
                2,
                3
            ],
            "parquet-thrift/src/main/java/org/apache/parquet/thrift/projection/StrictFieldProjectionFilter.java": [
                2,
                3
            ],
            "parquet-thrift/src/test/java/org/apache/parquet/hadoop/thrift/TestInputOutputFormat.java": [
                4,
                5
            ],
            "parquet-thrift/src/test/java/org/apache/parquet/hadoop/thrift/TestParquetToThriftReadWriteAndProjection.java": [
                3,
                4
            ],
            "parquet-thrift/src/test/java/org/apache/parquet/hadoop/thrift/TestThriftToParquetFileWriter.java": [
                4,
                4
            ],
            "parquet-thrift/src/test/java/org/apache/parquet/thrift/TestParquetReadProtocol.java": [
                3,
                4
            ],
            "parquet-thrift/src/test/java/org/apache/parquet/thrift/TestParquetWriteProtocol.java": [
                6,
                7
            ],
            "parquet-tools/src/main/java/org/apache/parquet/tools/command/MergeCommand.java": [
                2,
                0
            ],
            "pom.xml": null
        }
    },
    "e5cd652aeb3305ef2b82a7925cce3a132bf6f5ae": {
        "datetime": "2016-10-26T09:47:44-07:00",
        "summary": "PARQUET-753: Fixed GroupType.union() to handle original type",
        "message": "PARQUET-753: Fixed GroupType.union() to handle original type\n\nalso fixed GroupType.equals() to compare the original type and 2 unit tests that weren't setting the original type properly on the expected results\n\nAuthor: adeneche <adeneche@apache.org>\nAuthor: adeneche <adeneche@gmail.com>\n\nCloses #380 from adeneche/fix-grouptype-union and squashes the following commits:\n\nb04af7d [adeneche] reverted unnecessary formatting changes\n5461a57 [adeneche] Fixed unit tests in TestPigSchemaConverter that were failing because of my fix to GroupType.equals()\nec91315 [adeneche] fixed expected error message in TestMessageType#testMergeSchema\na1d7f63 [adeneche] Fixed GroupType.union() to handle original type\n",
        "diff": {
            "parquet-column/src/main/java/org/apache/parquet/schema/GroupType.java": [
                2,
                7
            ],
            "parquet-column/src/test/java/org/apache/parquet/parser/TestParquetParser.java": [
                3,
                3
            ],
            "parquet-column/src/test/java/org/apache/parquet/schema/TestMessageType.java": [
                1,
                28
            ],
            "parquet-pig/src/test/java/org/apache/parquet/pig/TestPigSchemaConverter.java": [
                27,
                27
            ]
        }
    },
    "0ed977ab4574b8fb8f7b978804582bd7ba7d7221": {
        "datetime": "2016-11-07T08:38:37-08:00",
        "summary": "PARQUET-768: Add Uwe L. Korn to KEYS",
        "message": "PARQUET-768: Add Uwe L. Korn to KEYS\n\nAuthor: Uwe L. Korn <uwelk@xhochy.com>\n\nCloses #383 from xhochy/PARQUET-768 and squashes the following commits:\n\ndf559d9 [Uwe L. Korn] PARQUET-768: Add Uwe L. Korn to KEYS\n",
        "diff": {
            "KEYS": null
        }
    },
    "cf991604d75d446d02baddc536c7c05b43cd8dea": {
        "datetime": "2016-11-09T08:58:59-08:00",
        "summary": "PARQUET-755: create parquet-arrow module with schema converter",
        "message": "PARQUET-755: create parquet-arrow module with schema converter\n\nAuthor: Julien Le Dem <julien@dremio.com>\n\nCloses #381 from julienledem/parquet_arrow and squashes the following commits:\n\n9792683 [Julien Le Dem] PARQUET-755: create parquet-arrow module with schema converter introduces SchemaMapping add repeated mapping\n",
        "diff": {
            "parquet-arrow/pom.xml": null,
            "parquet-arrow/src/main/java/org/apache/parquet/arrow/schema/List3Levels.java": [
                0,
                77
            ],
            "parquet-arrow/src/main/java/org/apache/parquet/arrow/schema/SchemaConverter.java": [
                0,
                642
            ],
            "parquet-arrow/src/main/java/org/apache/parquet/arrow/schema/SchemaMapping.java": [
                0,
                203
            ],
            "parquet-arrow/src/test/java/org/apache/parquet/arrow/schema/TestSchemaConverter.java": [
                0,
                343
            ],
            "parquet-column/src/main/java/org/apache/parquet/schema/Types.java": [
                4,
                5
            ],
            "pom.xml": null
        }
    },
    "4453aa3bffb632886d2c1406c6547e655dba2bb7": {
        "datetime": "2016-11-09T09:01:57-08:00",
        "summary": "PARQUET-765 - Upgrade Avro to 1.8.1",
        "message": "PARQUET-765 - Upgrade Avro to 1.8.1\n\nEscaping the field name `date` to make the test compatible to Avro 1.8.1 as _date_ is a keyword in avdl from 1.8.1.\n\nTested by setting the maven parameter `avro.version` to `1.8.1` and initiated a full build by `mvn clean install`.\n\nAuthor: Gabor Szadovszky <gabor.szadovszky@cloudera.com>\n\nCloses #382 from gszadovszky/PARQUET-765 and squashes the following commits:\n\n8e48332 [Gabor Szadovszky] PARQUET-765 - Upgrade Avro to 1.8.1\n8c8cf7d [Gabor Szadovszky] PARQUET-765 - Unit test failure with Avro 1.8.1\n",
        "diff": {
            "parquet-avro/src/test/resources/car.avdl": null,
            "pom.xml": null
        }
    },
    "09d28fe7995db1a4da2c651d362007d2082c663c": {
        "datetime": "2016-12-05T15:27:14-08:00",
        "summary": "PARQUET-783: Close the underlying stream when an H2SeekableInputStream is closed",
        "message": "PARQUET-783: Close the underlying stream when an H2SeekableInputStream is closed\n\nThis PR addresses https://issues.apache.org/jira/browse/PARQUET-783.\n\n`ParquetFileReader` opens a `SeekableInputStream` to read a footer. In the process, it opens a new `FSDataInputStream` and wraps it. However, `H2SeekableInputStream` does not override the `close` method. Therefore, when `ParquetFileReader` closes it, the underlying `FSDataInputStream` is not closed. As a result, these stale connections can exhaust a clusters' data nodes' connection resources and lead to mysterious HDFS read failures in HDFS clients, e.g.\n\n```\norg.apache.hadoop.hdfs.BlockMissingException: Could not obtain block: BP-905337612-172.16.70.103-1444328960665:blk_1720536852_646811517\n```\n\nAuthor: Michael Allman <michael@videoamp.com>\n\nCloses #388 from mallman/parquet-783-close_underlying_inputstream and squashes the following commits:\n\nf4b27c1 [Michael Allman] PARQUET-783 Close the underlying stream when an H2SeekableInputStream is closed\n",
        "diff": {
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/util/H2SeekableInputStream.java": [
                0,
                5
            ]
        }
    },
    "7987a544cce59537467621114b400f670c71d722": {
        "datetime": "2016-12-05T15:49:31-08:00",
        "summary": "PARQUET-786: 'java -jar', not 'java jar' closes #377, #374",
        "message": "PARQUET-786: 'java -jar', not 'java jar' closes #377, #374\n\nFix for PARQUET-786: parquet-tools/README.md should say to run parquet-tools locally with 'java -jar ...', not 'java jar ...'\n\nAuthor: Mark Nelson <mnelson@trueffect.com>\n\nCloses #386 from mcnels1/master and squashes the following commits:\n\nef215ec [Mark Nelson] 'java -jar', not 'java jar'\n",
        "diff": {
            "parquet-tools/README.md": null
        }
    },
    "4fd34e6517f2c400a06e3c1d43ec56df2ff5c392": {
        "datetime": "2016-12-05T17:01:38-08:00",
        "summary": "PARQUET-220: Unnecessary warning in ParquetRecordReader.initialize",
        "message": "PARQUET-220: Unnecessary warning in ParquetRecordReader.initialize\n\nRather than querying the COUNTER_METHOD up front, the counter method is resolved per object. This allows us to use the\n'getCounter' method on any TaskAttemptContext with the correct signature (ignoring versions where TaskAttemptContext does\nnot have an appropriate method/signature - preserving current behavior).\n\nAuthor: Reuben Kuhnert <reuben.kuhnert@cloudera.com>\n\nCloses #280 from sircodesalotOfTheRound/context-utils-parquet-220 and squashes the following commits:\n\nf118990 [Reuben Kuhnert] PARQUET-220: Unnecessary warning in ParquetRecordReader.initialize\n",
        "diff": {
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ParquetRecordReader.java": [
                4,
                6
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/util/ContextUtil.java": [
                12,
                45
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/util/counters/BenchmarkCounter.java": [
                2,
                2
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/util/counters/mapreduce/MapReduceCounterLoader.java": [
                2,
                3
            ],
            "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/example/TestInputOutputFormat.java": [
                0,
                1
            ],
            "pom.xml": null
        }
    },
    "98c27699cbcf65c3d9d655ecbcd67adcd8b45b05": {
        "datetime": "2016-12-07T11:07:03-08:00",
        "summary": "PARQUET-321: Default maximum block padding to 8MB.",
        "message": "PARQUET-321: Default maximum block padding to 8MB.\n\nrdblue's change applied to the newest code.\n\nOriginal pull request: https://github.com/apache/parquet-mr/pull/232/\n\nAuthor: Zoltan Ivanfi <zi@cloudera.com>\n\nCloses #391 from zicl/master and squashes the following commits:\n\nb1c5c1d [Zoltan Ivanfi] PARQUET-321: Default maximum block padding to 8MB.\n",
        "diff": {
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ParquetOutputFormat.java": [
                5,
                1
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ParquetWriter.java": [
                1,
                1
            ]
        }
    },
    "71cff7c5940b7101ff098601850d46b7a4698180": {
        "datetime": "2016-12-08T09:07:37-08:00",
        "summary": "PARQUET-791: Add missing column support for UserDefinedPredicate",
        "message": "PARQUET-791: Add missing column support for UserDefinedPredicate\n\nThis extends the fixing #354 to UserDefinedPredicate.\n\nAuthor: Liang-Chi Hsieh <viirya@gmail.com>\n\nCloses #389 from viirya/PARQUET-791 and squashes the following commits:\n\nd6be37d [Liang-Chi Hsieh] Address comment.\n7e929c3 [Liang-Chi Hsieh] PARQUET-791: Add missing column support for UserDefinedPredicate.\n",
        "diff": {
            "parquet-hadoop/src/main/java/org/apache/parquet/filter2/statisticslevel/StatisticsFilter.java": [
                5,
                18
            ],
            "parquet-hadoop/src/test/java/org/apache/parquet/filter2/statisticslevel/TestStatisticsFilter.java": [
                1,
                73
            ]
        }
    },
    "89e0607cf6470dda1a6a47b46abf37468df4e50f": {
        "datetime": "2016-12-20T14:35:57-08:00",
        "summary": "PARQUET-801: Allow UserDefinedPredicates in DictionaryFilter",
        "message": "PARQUET-801: Allow UserDefinedPredicates in DictionaryFilter\n\nAuthor: Patrick Woody <pwoody@palantir.com>\nAuthor: Patrick Woody <patrick.woody1@gmail.com>\n\nCloses #394 from pwoody/pw/dictionaryUdp and squashes the following commits:\n\nd8499a0 [Patrick Woody] short circuiting and style changes\n4cb9f0c [Patrick Woody] more missing imports\n1ec0d39 [Patrick Woody] fix missing import\n3ee4489 [Patrick Woody] PARQUET-801: Allow UserDefinedPredicates in DictionaryFilter\n",
        "diff": {
            "parquet-hadoop/src/main/java/org/apache/parquet/filter2/dictionarylevel/DictionaryFilter.java": [
                10,
                46
            ],
            "parquet-hadoop/src/test/java/org/apache/parquet/filter2/dictionarylevel/DictionaryFilterTest.java": [
                0,
                94
            ]
        }
    },
    "f68dbc3ea20230cb14ed3364539ad16e114bcdd9": {
        "datetime": "2017-01-26T15:32:28-08:00",
        "summary": "PARQUET-825: Static analyzer findings (NPEs, resource leaks)",
        "message": "PARQUET-825: Static analyzer findings (NPEs, resource leaks)\n\nSome trivial code fixes based on findings on static code analyzer tools (Sonar, Fortify)\n@piyushnarang: Sorry, renaming the branch caused the closing of the original PR...\n\nAuthor: Gabor Szadovszky <gabor.szadovszky@Budapests-MacBook-Pro-8.local>\nAuthor: Gabor Szadovszky <gabor.szadovszky@cloudera.com>\n\nCloses #399 from gszadovszky/PARQUET-825 and squashes the following commits:\n\n68a4764 [Gabor Szadovszky] PARQUET-825 - Static analyzer findings (NPEs, resource leaks)\na689c1c [Gabor Szadovszky] Code fixes related to null checks, exception handling and closing streams\n",
        "diff": {
            "parquet-column/src/main/java/org/apache/parquet/io/RecordReaderImplementation.java": [
                1,
                2
            ],
            "parquet-common/src/main/java/org/apache/parquet/glob/GlobNode.java": [
                3,
                3
            ],
            "parquet-generator/src/main/java/org/apache/parquet/encoding/bitpacking/ByteBasedBitPackingGenerator.java": [
                35,
                35
            ],
            "parquet-generator/src/main/java/org/apache/parquet/encoding/bitpacking/IntBasedBitPackingGenerator.java": [
                38,
                38
            ],
            "parquet-generator/src/main/java/org/apache/parquet/version/VersionGenerator.java": [
                1,
                5
            ],
            "parquet-tools/src/main/java/org/apache/parquet/tools/command/DumpCommand.java": [
                1,
                1
            ],
            "parquet-tools/src/main/java/org/apache/parquet/tools/command/Registry.java": [
                2,
                2
            ],
            "parquet-tools/src/main/java/org/apache/parquet/tools/util/PrettyPrintWriter.java": [
                2,
                2
            ]
        }
    },
    "6fb60857be1fed21bdacc4ce830bbf99103b6fdd": {
        "datetime": "2017-01-26T15:34:22-08:00",
        "summary": "PARQUET-822: Upgrade java dependencies",
        "message": "PARQUET-822: Upgrade java dependencies\n\n2 minor code/config modification related to the version upgrades:\n- TestMemoryManager.java: I guess, it was caused by the junit upgrade however, it is not clear why it was working before. The issue was that the second run of `createWriter(1).close(null)` failed with `IOException` about that the file already exists.\n- pom.xml (added exclusion for fastutil): The shaded dependency upgrade in `parquet-column`  caused failure of API version compatibility check.\n\n`mvn clean install` worked fine. Any idea about additional testing is welcomed.\n\nAuthor: Gabor Szadovszky <gabor.szadovszky@Budapests-MacBook-Pro-8.local>\n\nCloses #398 from gszadovszky/PARQUET-822 and squashes the following commits:\n\n25d0c7f [Gabor Szadovszky] Update hadoop-1 version; back to the old httpclient because of hadoop-1 test failure\n17a8137 [Gabor Szadovszky] PARQUET-822: Upgrade java dependencies\n",
        "diff": {
            "parquet-benchmarks/pom.xml": null,
            "parquet-column/pom.xml": null,
            "parquet-encoding/pom.xml": null,
            "parquet-hadoop/pom.xml": null,
            "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/TestMemoryManager.java": [
                1,
                1
            ],
            "parquet-hive/parquet-hive-storage-handler/pom.xml": null,
            "parquet-pig/pom.xml": null,
            "parquet-protobuf/pom.xml": null,
            "parquet-scala/pom.xml": null,
            "parquet-scrooge/pom.xml": null,
            "parquet-thrift/pom.xml": null,
            "parquet-tools/pom.xml": null,
            "pom.xml": null
        }
    },
    "3634821fa515365618209f0452443728e7290fca": {
        "datetime": "2017-01-26T15:37:57-08:00",
        "summary": "PARQUET-806: Parquet-tools silently suppresses error messages",
        "message": "PARQUET-806: Parquet-tools silently suppresses error messages\n\nThe \"error message\" that used to be\n\norg/apache/hadoop/conf/Configuration\n\nnow becomes:\n\nNoClassDefFoundError: org/apache/hadoop/conf/Configuration\n\nAuthor: Zoltan Ivanfi <zi@cloudera.com>\n\nCloses #396 from zivanfi/PARQUET-806 and squashes the following commits:\n\nb1fe699 [Zoltan Ivanfi] PARQUET-806: Parquet-tools silently suppresses error messages\n",
        "diff": {
            "parquet-tools/src/main/java/org/apache/parquet/tools/Main.java": [
                1,
                1
            ]
        }
    },
    "2fd62ee4d524c270764e9b91dca72e5cf1a005b7": {
        "datetime": "2017-01-26T15:39:31-08:00",
        "summary": "PARQUET-772: Fix locale-specific test failures.",
        "message": "PARQUET-772: Fix locale-specific test failures.\n\nThe statistics tests were failing in locales with a decimal mark other than \".\"\n\nAuthor: Zoltan Ivanfi <zi@cloudera.com>\n\nCloses #395 from zivanfi/PARQUET-772 and squashes the following commits:\n\nacec99c [Zoltan Ivanfi] PARQUET-772: Fix locale-specific test failures.\n",
        "diff": {
            "parquet-column/src/test/java/org/apache/parquet/column/statistics/TestStatistics.java": [
                2,
                2
            ]
        }
    },
    "70f28810a5547219e18ffc3465f519c454fee6e5": {
        "datetime": "2017-04-21T16:07:55-07:00",
        "summary": "PARQUET-665 Adds support for proto3",
        "message": "PARQUET-665 Adds support for proto3\n\nThis change bumps the protobuf version and adds\ntests to show compatibility with proto3. It does\nnot actually change anything else.\n\nTests are mostly identical to existing tests, and tests\nthat tested functionality not present in proto3 are not\npresent (such as groups and extensions). Proto3\noneof and map are represented in the tests.\n\nTested by running `mvn test --am --projects parquet-protobuf`\n\nAuthor: Mark Chua <mark@asana.com>\n\nCloses #407 from markchua/mkc/proto3 and squashes the following commits:\n\n40ef997 [Mark Chua] PARQUET-665 Adds support for proto3\n",
        "diff": {
            ".travis.yml": null,
            "parquet-protobuf/pom.xml": null,
            "parquet-protobuf/src/test/java/org/apache/parquet/proto/ProtoInputOutputFormatTest.java": [
                3,
                76
            ],
            "parquet-protobuf/src/test/java/org/apache/parquet/proto/ProtoRecordConverterTest.java": [
                36,
                156
            ],
            "parquet-protobuf/src/test/java/org/apache/parquet/proto/ProtoSchemaConverterTest.java": [
                3,
                60
            ],
            "parquet-protobuf/src/test/java/org/apache/parquet/proto/ProtoWriteSupportTest.java": [
                4,
                134
            ],
            "parquet-protobuf/src/test/resources/TestProto3.proto": null
        }
    },
    "a703ee75c40e0207f6831c4d48e1c7e62f160305": {
        "datetime": "2017-05-12T14:40:29-07:00",
        "summary": "PARQUET-969: Update parquet-tools to convert Decimal datatype to BigD\u2026",
        "message": "PARQUET-969: Update parquet-tools to convert Decimal datatype to BigD\u2026\n\nUpdate parquet-tools so that decimal datatypes in parquet files are converted to their actual number representation when cat'ing to stdout. Currently they are output in binary format.\n\nAuthor: dsfcode <fowler.dn@gmail.com>\n\nCloses #412 from dsfcode/master and squashes the following commits:\n\n7f05509 [dsfcode] PARQUET-969: Update parquet-tools to convert Decimal datatype to BigDecimal\n",
        "diff": {
            "parquet-tools/src/main/java/org/apache/parquet/tools/read/SimpleRecordConverter.java": [
                0,
                20
            ],
            "parquet-tools/src/test/java/org/apache/parquet/tools/read/TestSimplePrimitiveRecord.java": [
                0,
                58
            ]
        }
    },
    "fd7cfed070c2aab60521afb7dcc633a0b7abea80": {
        "datetime": "2017-05-12T15:02:27-07:00",
        "summary": "PARQUET-196: parquet-tools command for row count & size",
        "message": "PARQUET-196: parquet-tools command for row count & size\n\nThis is a rebase on already existing PR-\nhttps://github.com/apache/parquet-mr/pull/132\n\nAuthor: Swapnil Shinde <swapnilushinde@gmail.com>\n\nCloses #406 from swapnilushinde/master and squashes the following commits:\n\n59a8980 [Swapnil Shinde] Spacing to conform java style (if/for) is fixed\n5fd0279 [Swapnil Shinde] Parquet-196: parquet-tools command for row count & size\n",
        "diff": {
            "parquet-tools/src/main/java/org/apache/parquet/tools/command/Registry.java": [
                0,
                2
            ],
            "parquet-tools/src/main/java/org/apache/parquet/tools/command/RowCountCommand.java": [
                0,
                97
            ],
            "parquet-tools/src/main/java/org/apache/parquet/tools/command/SizeCommand.java": [
                0,
                140
            ],
            "parquet-tools/src/main/scripts/parquet-rowcount": null,
            "parquet-tools/src/main/scripts/parquet-size": null
        }
    },
    "1de41ef4baeee1c95e245837299f8be265294445": {
        "datetime": "2017-05-12T15:09:56-07:00",
        "summary": "PARQUET-852: Slowly ramp up sizes of byte[] in ByteBasedBitPackingEncoder",
        "message": "PARQUET-852: Slowly ramp up sizes of byte[] in ByteBasedBitPackingEncoder\n\nhttps://issues.apache.org/jira/browse/PARQUET-852\n\nAuthor: John Jenkins <jjenkins@kcg.com>\n\nCloses #401 from JohnPJenkins/PARQUET-852 and squashes the following commits:\n\n334acec [John Jenkins] PARQUET-852: Slowly ramp up sizes of byte[] in ByteBasedBitPackingEncoder\n",
        "diff": {
            "parquet-encoding/src/main/java/org/apache/parquet/column/values/bitpacking/ByteBasedBitPackingEncoder.java": [
                8,
                22
            ],
            "parquet-encoding/src/test/java/org/apache/parquet/column/values/bitpacking/TestByteBasedBitPackingEncoder.java": [
                6,
                12
            ]
        }
    },
    "9491d7a61681f7acc7103a6d1d45efe96f7981d2": {
        "datetime": "2017-05-16T17:19:06-07:00",
        "summary": "PARQUET-990 More detailed error messages in footer parsing",
        "message": "PARQUET-990 More detailed error messages in footer parsing\n\nInclude invalid values in exception messages when reading footer for two situations:\n\n- too-short files (include file length)\n- files with corrupted footer lengths (include calculated footer start index)\n\nAuthor: Andrew Ash <andrew@andrewash.com>\n\nCloses #408 from ash211/patch-1 and squashes the following commits:\n\n74f5836 [Andrew Ash] More detailed error messages in footer parsing\n",
        "diff": {
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ParquetFileReader.java": [
                2,
                2
            ]
        }
    },
    "9d58b6a83aa79dcad01c3bcc2ec0a7db74ba83b1": {
        "datetime": "2017-06-07T15:22:28-07:00",
        "summary": "Parquet-884: Add support for Decimal datatype to Parquet-Pig record reader",
        "message": "Parquet-884: Add support for Decimal datatype to Parquet-Pig record reader\n\nAdds conversion support to Pig for Decimal datatype. Based on the scala code in the spark project that provides a similar function for their sql library.\n\nAuthor: EllenKletscher <ellen.kletscher@capitalone.com>\n\nCloses #404 from EllenKletscher/master and squashes the following commits:\n\n7714738 [EllenKletscher] add comment for precision check\n50c75c8 [EllenKletscher] remove check for primitiveType null\n08d4dbb [EllenKletscher] PARQUET-884: Add missing AL header\n57c4d72 [EllenKletscher] PARQUET-884: Add missing AL header\nea61267 [EllenKletscher] PARQUET-884: add support for decimal type to pig reader\n",
        "diff": {
            "parquet-pig/src/main/java/org/apache/parquet/pig/PigSchemaConverter.java": [
                2,
                6
            ],
            "parquet-pig/src/main/java/org/apache/parquet/pig/convert/DecimalUtils.java": [
                0,
                65
            ],
            "parquet-pig/src/main/java/org/apache/parquet/pig/convert/TupleConverter.java": [
                0,
                27
            ],
            "parquet-pig/src/test/java/org/apache/parquet/pig/TestDecimalUtils.java": [
                0,
                79
            ]
        }
    },
    "2d3203b10cc8edf71a6e3e0822f0d742c9516aa3": {
        "datetime": "2017-06-09T11:34:21-07:00",
        "summary": "PARQUET-1005: Fix DumpCommand parsing to allow column projection",
        "message": "PARQUET-1005: Fix DumpCommand parsing to allow column projection\n\nDumpCommand option for -c is specified as hasArgs() for unlimited\nnumber of arguments following -c. The very description of the option\nshows the real intent of using hasArg() such that multiple columns\ncan be specified as '-c c1 -c c2 ...'. Otherwise, the input path\nis parsed as an argument for -c instead of the command itself.\n\nAuthor: Gera Shegalov <gera@twitter.com>\n\nCloses #413 from gerashegalov/dump_specific_columns_fix and squashes the following commits:\n\na6b2df3 [Gera Shegalov] Fix DumpCommand parsing to allow column projection\n",
        "diff": {
            "parquet-protobuf/pom.xml": null,
            "parquet-tools/src/main/java/org/apache/parquet/tools/Main.java": [
                4,
                3
            ],
            "parquet-tools/src/main/java/org/apache/parquet/tools/command/DumpCommand.java": [
                5,
                4
            ]
        }
    },
    "352b906996f392030bfd53b93e3cf4adb78d1a55": {
        "datetime": "2017-06-09T14:31:14-07:00",
        "summary": "PARQUET-1026: allow unsigned binary stats when min == max",
        "message": "PARQUET-1026: allow unsigned binary stats when min == max\n\nWhen min equals max this is a special case where unsigned stats would actually be the same as signed stats since there is only one value.\nThis is useful when the data is partitioned by that column and there's only one value in the file.\nDrill for example takes advantage of this.\n\nAuthor: Julien Le Dem <julien@apache.org>\n\nCloses #416 from julienledem/min_eq_max and squashes the following commits:\n\n1d71624 [Julien Le Dem] revert package import ordering change\n47d89fc [Julien Le Dem] allow unsigned binary stats when min == max\n",
        "diff": {
            "parquet-hadoop/src/main/java/org/apache/parquet/format/converter/ParquetMetadataConverter.java": [
                2,
                5
            ],
            "parquet-hadoop/src/test/java/org/apache/parquet/format/converter/TestParquetMetadataConverter.java": [
                1,
                21
            ],
            "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/TestParquetFileWriter.java": [
                5,
                6
            ]
        }
    },
    "df9f8d869fe47a116e9e78fb59ab55d84ffa13d1": {
        "datetime": "2017-06-09T15:22:31-07:00",
        "summary": "PARQUET-1024: allow for case insensitive parquet-xxx prefix in PR title",
        "message": "PARQUET-1024: allow for case insensitive parquet-xxx prefix in PR title\n\nAuthor: Julien Le Dem <julien@apache.org>\n\nCloses #415 from julienledem/improve_merge and squashes the following commits:\n\n0e34366 [Julien Le Dem] PARQUET-1024: allow for case insensitive parquet-xxx prefix in PR title\n",
        "diff": {
            "dev/merge_parquet_pr.py": [
                2,
                2
            ]
        }
    },
    "ddbeb4dd17d9c219b99b1e66d8be28efe37e3aa6": {
        "datetime": "2017-07-28T16:25:21-07:00",
        "summary": "PARQUET-777: Add Parquet CLI.",
        "message": "PARQUET-777: Add Parquet CLI.\n\nThis adds a new parquet-cli module with an improved command-line tool. The parquet-cli/README.md file has instructions for building and testing locally.\n\nAuthor: Ryan Blue <blue@apache.org>\nAuthor: Tom White <tom@cloudera.com>\n\nCloses #384 from rdblue/PARQUET-777-add-parquet-cli and squashes the following commits:\n\nde49eff [Ryan Blue] PARQUET-777: Move dynamic support classes, add tests.\naffdfb9 [Ryan Blue] PARQUET-777: Update for review feedback.\nf953fd4 [Ryan Blue] PARQUET-777: Update README.md with better instructions.\naed223d [Tom White] Replace source file headers with Apache header.\nd718363 [Ryan Blue] PARQUET-777: Add Parquet CLI.\n",
        "diff": {
            "NOTICE": null,
            "parquet-cli/README.md": null,
            "parquet-cli/pom.xml": null,
            "parquet-cli/src/main/java/org/apache/parquet/cli/BaseCommand.java": [
                0,
                397
            ],
            "parquet-cli/src/main/java/org/apache/parquet/cli/Command.java": [
                0,
                40
            ],
            "parquet-cli/src/main/java/org/apache/parquet/cli/HadoopFileSystemURLStreamHandler.java": [
                0,
                79
            ],
            "parquet-cli/src/main/java/org/apache/parquet/cli/Help.java": [
                0,
                147
            ],
            "parquet-cli/src/main/java/org/apache/parquet/cli/Main.java": [
                0,
                178
            ],
            "parquet-cli/src/main/java/org/apache/parquet/cli/Util.java": [
                0,
                335
            ],
            "parquet-cli/src/main/java/org/apache/parquet/cli/commands/CSVSchemaCommand.java": [
                0,
                131
            ],
            "parquet-cli/src/main/java/org/apache/parquet/cli/commands/CatCommand.java": [
                0,
                106
            ],
            "parquet-cli/src/main/java/org/apache/parquet/cli/commands/CheckParquet251Command.java": [
                0,
                351
            ],
            "parquet-cli/src/main/java/org/apache/parquet/cli/commands/ConvertCSVCommand.java": [
                0,
                204
            ],
            "parquet-cli/src/main/java/org/apache/parquet/cli/commands/ConvertCommand.java": [
                0,
                165
            ],
            "parquet-cli/src/main/java/org/apache/parquet/cli/commands/ParquetMetadataCommand.java": [
                0,
                180
            ],
            "parquet-cli/src/main/java/org/apache/parquet/cli/commands/SchemaCommand.java": [
                0,
                138
            ],
            "parquet-cli/src/main/java/org/apache/parquet/cli/commands/ShowDictionaryCommand.java": [
                0,
                131
            ],
            "parquet-cli/src/main/java/org/apache/parquet/cli/commands/ShowPagesCommand.java": [
                0,
                217
            ],
            "parquet-cli/src/main/java/org/apache/parquet/cli/commands/ToAvroCommand.java": [
                0,
                141
            ],
            "parquet-cli/src/main/java/org/apache/parquet/cli/csv/AvroCSV.java": [
                0,
                258
            ],
            "parquet-cli/src/main/java/org/apache/parquet/cli/csv/AvroCSVReader.java": [
                0,
                121
            ],
            "parquet-cli/src/main/java/org/apache/parquet/cli/csv/CSVProperties.java": [
                0,
                111
            ],
            "parquet-cli/src/main/java/org/apache/parquet/cli/csv/RecordBuilder.java": [
                0,
                200
            ],
            "parquet-cli/src/main/java/org/apache/parquet/cli/json/AvroJson.java": [
                0,
                636
            ],
            "parquet-cli/src/main/java/org/apache/parquet/cli/json/AvroJsonReader.java": [
                0,
                85
            ],
            "parquet-cli/src/main/java/org/apache/parquet/cli/util/Codecs.java": [
                0,
                50
            ],
            "parquet-cli/src/main/java/org/apache/parquet/cli/util/Expressions.java": [
                0,
                391
            ],
            "parquet-cli/src/main/java/org/apache/parquet/cli/util/Formats.java": [
                0,
                47
            ],
            "parquet-cli/src/main/java/org/apache/parquet/cli/util/GetClassLoader.java": [
                0,
                39
            ],
            "parquet-cli/src/main/java/org/apache/parquet/cli/util/RecordException.java": [
                0,
                53
            ],
            "parquet-cli/src/main/java/org/apache/parquet/cli/util/RuntimeIOException.java": [
                0,
                31
            ],
            "parquet-cli/src/main/java/org/apache/parquet/cli/util/Schemas.java": [
                0,
                498
            ],
            "parquet-cli/src/main/java/org/apache/parquet/cli/util/SeekableFSDataInputStream.java": [
                0,
                76
            ],
            "parquet-cli/src/main/resources/META-INF/LICENSE": null,
            "parquet-cli/src/main/resources/META-INF/NOTICE": null,
            "parquet-cli/src/main/resources/cli-logging.properties": null,
            "parquet-common/src/main/java/org/apache/parquet/Exceptions.java": [
                0,
                34
            ],
            "parquet-common/src/main/java/org/apache/parquet/util/DynConstructors.java": [
                0,
                273
            ],
            "parquet-common/src/main/java/org/apache/parquet/util/DynMethods.java": [
                0,
                520
            ],
            "parquet-common/src/test/java/org/apache/parquet/TestUtils.java": [
                0,
                70
            ],
            "parquet-common/src/test/java/org/apache/parquet/util/Concatenator.java": [
                0,
                82
            ],
            "parquet-common/src/test/java/org/apache/parquet/util/TestDynConstructors.java": [
                0,
                235
            ],
            "parquet-common/src/test/java/org/apache/parquet/util/TestDynMethods.java": [
                0,
                410
            ],
            "pom.xml": null
        }
    },
    "d55a572e5867832f6d5755fcd46101da51a38aa4": {
        "datetime": "2017-10-10T16:20:55-07:00",
        "summary": "PARQUET-1133 Add int96 support by returning bytearray, Skip originalType comparison for map types when originalType is null",
        "message": "PARQUET-1133 Add int96 support by returning bytearray, Skip originalType comparison for map types when originalType is null\n\n- PigSchemaConverter: Added a null check before comparing a mapKeyValueType's original type with the static constant\n- PigSchemaConverter: Changed the handling of int96 types - return bytearray instead of rejecting input\n- PigSchemaConverterTest: Added unit tests for int96 conversion and handling map entries without original type specified\n\nAuthor: Addisu Feyissa <addisu.feyissa@C1159.local>\n\nCloses #422 from adisu-feyissa/hotfix/remove_originalType_check_for_maps_and_add_int96_support and squashes the following commits:\n\ne6fa3444 [Addisu Feyissa] - PigSchemaConverter: Added a null check before comparing a mapKeyValueType's original type with the static constant - PigSchemaConverter: Changed the handling of int96 types - return bytearray instead of rejecting input - PigSchemaConverTest: Added unit tests for int96 conversion and handling map entries without original type specified\n",
        "diff": {
            "parquet-pig/src/main/java/org/apache/parquet/pig/PigSchemaConverter.java": [
                2,
                3
            ],
            "parquet-pig/src/test/java/org/apache/parquet/pig/TestPigSchemaConverter.java": [
                0,
                28
            ]
        }
    },
    "328c5deb015ee5bc0a24623bc29225f6ec1ae23d": {
        "datetime": "2017-11-07T14:37:39+01:00",
        "summary": "PARQUET-1115: Warn users when misusing parquet-tools merge",
        "message": "PARQUET-1115: Warn users when misusing parquet-tools merge\n\nAuthor: Nandor Kollar <nkollar@cloudera.com>\n\nCloses #433 from nandorKollar/PARQUET-1115 and squashes the following commits:\n\n5504a39 [Nandor Kollar] PARQUET-1115: Warn users when misusing parquet-tools merge\nf2ece26 [Nandor Kollar] PARQUET-1115: Warn users when misusing parquet-tools merge\n4f3ec99 [Nandor Kollar] PARQUET-1115: Warn users when misusing parquet-tools merge\nf97e620 [Nandor Kollar] PARQUET-1115: Prevent users from misusing parquet-tools merge\n",
        "diff": {
            "parquet-tools/src/main/java/org/apache/parquet/tools/Main.java": [
                0,
                1
            ],
            "parquet-tools/src/main/java/org/apache/parquet/tools/command/CatCommand.java": [
                0,
                5
            ],
            "parquet-tools/src/main/java/org/apache/parquet/tools/command/Command.java": [
                1,
                2
            ],
            "parquet-tools/src/main/java/org/apache/parquet/tools/command/DumpCommand.java": [
                1,
                6
            ],
            "parquet-tools/src/main/java/org/apache/parquet/tools/command/HeadCommand.java": [
                0,
                5
            ],
            "parquet-tools/src/main/java/org/apache/parquet/tools/command/MergeCommand.java": [
                0,
                26
            ],
            "parquet-tools/src/main/java/org/apache/parquet/tools/command/RowCountCommand.java": [
                0,
                5
            ],
            "parquet-tools/src/main/java/org/apache/parquet/tools/command/ShowMetaCommand.java": [
                3,
                5
            ],
            "parquet-tools/src/main/java/org/apache/parquet/tools/command/ShowSchemaCommand.java": [
                2,
                5
            ],
            "parquet-tools/src/main/java/org/apache/parquet/tools/command/SizeCommand.java": [
                0,
                5
            ],
            "parquet-tools/src/main/java/org/apache/parquet/tools/read/SimpleRecord.java": [
                2,
                5
            ],
            "parquet-tools/src/main/java/org/apache/parquet/tools/read/SimpleRecordConverter.java": [
                12,
                0
            ],
            "parquet-tools/src/main/java/org/apache/parquet/tools/util/MetadataUtils.java": [
                3,
                0
            ]
        }
    },
    "170cfa758547b4d9be50058ad93cf60ce0da5564": {
        "datetime": "2017-11-09T11:23:01+01:00",
        "summary": "PARQUET-1152: Parquet-thrift doesn't compile with Thrift 0.9.3",
        "message": "PARQUET-1152: Parquet-thrift doesn't compile with Thrift 0.9.3\n\nAuthor: Nandor Kollar <nkollar@cloudera.com>\n\nCloses #432 from nandorKollar/PARQUET-1152 and squashes the following commits:\n\nfd578ec [Zoltan Ivanfi] Undo unrelated whitespace changes.\n8bbcfad [Nandor Kollar] PARQUET-1152: Parquet-thrift doesn't compile with Thrift 0.9.3\n",
        "diff": {
            "parquet-thrift/src/main/java/org/apache/parquet/hadoop/thrift/ThriftBytesWriteSupport.java": [
                21,
                1
            ]
        }
    },
    "c532b0e637f28eb934f28f7f1d7c0889b1e5c811": {
        "datetime": "2017-11-09T17:16:53+01:00",
        "summary": "PARQUET-1153: Parquet-thrift doesn't compile with Thrift 0.10.0",
        "message": "PARQUET-1153: Parquet-thrift doesn't compile with Thrift 0.10.0\n\nAuthor: Nandor Kollar <nkollar@cloudera.com>\n\nCloses #434 from nandorKollar/PARQUET-1153 and squashes the following commits:\n\nb2da7c0 [Nandor Kollar] PARQUET-1153: Parquet-thrift doesn't compile with Thrift 0.10.0\n5e96e7f [Nandor Kollar] PARQUET-1153: Parquet-thrift doesn't compile with Thrift 0.10.0\nad237b0 [Nandor Kollar] PARQUET-1153: Parquet-thrift doesn't compile with Thrift 0.10.0\n0e4e0f9 [Nandor Kollar] PARQUET-1153: Parquet-thrift doesn't compile with Thrift 0.10.0\n29544b3 [Nandor Kollar] PARQUET-1153: Parquet-thrift doesn't compile with Thrift 0.10.0\n",
        "diff": {
            ".travis.yml": null,
            "parquet-cascading/pom.xml": null,
            "parquet-cascading3/pom.xml": null,
            "parquet-hive/parquet-hive-binding/parquet-hive-binding-interface/src/main/java/org/apache/parquet/hive/HiveBinding.java": [
                1,
                1
            ],
            "parquet-hive/parquet-hive-storage-handler/src/main/java/org/apache/hadoop/hive/ql/io/parquet/read/DataWritableReadSupport.java": [
                1,
                1
            ],
            "parquet-scrooge/pom.xml": null,
            "parquet-thrift/pom.xml": null,
            "pom.xml": null
        }
    },
    "ba7b8ba69984bd2c91c41eeab9a2f030661e5a49": {
        "datetime": "2017-11-10T11:15:22+01:00",
        "summary": "PARQUET-1149: Update Avro to 1.8.2",
        "message": "PARQUET-1149: Update Avro to 1.8.2\n\nAuthor: Fokko Driesprong <fokkodriesprong@godatadriven.com>\n\nCloses #431 from Fokko/PARQUET-1149 and squashes the following commits:\n\n3ef7c2e [Fokko Driesprong] [PARQUET-1149] Update Avro\n",
        "diff": {
            "pom.xml": null
        }
    },
    "132b2a8c553bdcfd445e88680beac6f225c50ac4": {
        "datetime": "2017-11-14T16:16:28-08:00",
        "summary": "PARQUET-1143: Update to Parquet format 2.4.0.",
        "message": "PARQUET-1143: Update to Parquet format 2.4.0.\n\nThis adds new compression codecs that are required by format 2.4.0.\n\nAuthor: Ryan Blue <blue@apache.org>\n\nCloses #430 from rdblue/PARQUET-1143-format-2.4.0-updates and squashes the following commits:\n\n0aca87812 [Ryan Blue] PARQUET-1143: Remove staging repository now that 2.4.0 is released.\n89b01cb64 [Ryan Blue] PARQUET-1143: Make brotli-codec an optional dependency.\na2f57ba5b [Ryan Blue] PARQUET-1143: Drop hadoop-1 tests from Travis CI.\nd0f81d7cd [Ryan Blue] PARQUET-1143: Use slf4j-simple and log4j in Thrift/Pig tests.\n326b8ac74 [Ryan Blue] PARQUET-1143: Update Travis to use the default ubuntu image.\n4ad46f94c [Ryan Blue] PARQUET-1143: Use slf4j-log4j12 in Pig tests.\n785e84dff [Ryan Blue] PARQUET-1143: Fix Travis CI.\nefa171fda [Ryan Blue] PARQUET-1143: Ban slf4j-log4j12 dependency.\nbf61e84ab [Ryan Blue] PARQUET-1143: Update to Parquet format 2.4.0.\n",
        "diff": {
            ".travis.yml": null,
            "parquet-avro/pom.xml": null,
            "parquet-benchmarks/pom.xml": null,
            "parquet-cascading/pom.xml": null,
            "parquet-cli/src/main/java/org/apache/parquet/cli/Util.java": [
                0,
                6
            ],
            "parquet-hadoop/pom.xml": null,
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/metadata/CompressionCodecName.java": [
                1,
                4
            ],
            "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/TestDirectCodecFactory.java": [
                2,
                12
            ],
            "parquet-pig/src/test/resources/log4j.properties": null,
            "parquet-protobuf/src/test/resources/log4j.properties": null,
            "parquet-scrooge/pom.xml": null,
            "parquet-thrift/pom.xml": null,
            "pom.xml": null
        }
    },
    "81f480149054399d28b0609482c978788d9f5895": {
        "datetime": "2017-11-29T16:00:19+01:00",
        "summary": "PARQUET-1156: Address dev/merge_parquet_pr.py problems.",
        "message": "PARQUET-1156: Address dev/merge_parquet_pr.py problems.\n\nAuthor: Zoltan Ivanfi <zi@cloudera.com>\n\nCloses #437 from zivanfi/PARQUET-1156 and squashes the following commits:\n\ncb4e8dc [Zoltan Ivanfi] PARQUET-1156: Address dev/merge_parquet_pr.py problems.\n",
        "diff": {
            "dev/merge_parquet_pr.py": [
                9,
                40
            ]
        }
    },
    "8bfd9b4d8f4fb0a2b522c9328f67eb642066306b": {
        "datetime": "2017-12-13T11:27:54-08:00",
        "summary": "PARQUET-1142: Add alternatives to Hadoop classes in the API",
        "message": "PARQUET-1142: Add alternatives to Hadoop classes in the API\n\nThis updates the read and write paths to avoid using Hadoop classes where possible.\n\n* Adds a generic compression interface, `CompressionCodecFactory`\n* Adds `OutputFile` and `PositionOutputStream`\n* Adds classes to help implementations wrap input and output streams: `DelegatingSeekableInputStream` and `DelegatingPositionOutputStream`\n* Adds `ParquetReadOptions` to avoid passing options with `Configuration`\n* Updates the read and write APIs to use new abstractions instead of Hadoop\n\nAuthor: Ryan Blue <blue@apache.org>\n\nCloses #429 from rdblue/PARQUET-1142-add-hadoop-alternatives and squashes the following commits:\n\n21500337b [Ryan Blue] PARQUET-1142: Fix NPE when not filtering with new read API.\n35eddd735 [Ryan Blue] PARQUET-1142: Fix problems from Gabor's review.\nda391b0d4 [Ryan Blue] PARQUET-1142: Fix binary incompatibilities.\n2e3d693ab [Ryan Blue] PARQUET-1142: Update the read and write paths to use new files and streams.\n8d57e089f [Ryan Blue] PARQUET-1142: Add OutputFile and PositionOutputStream.\n42908a95e [Ryan Blue] PARQUET-1142: Extract non-Hadoop API from CodecFactory.\n",
        "diff": {
            "parquet-common/pom.xml": null,
            "parquet-common/src/main/java/org/apache/parquet/compression/CompressionCodecFactory.java": [
                0,
                47
            ],
            "parquet-common/src/main/java/org/apache/parquet/hadoop/codec/CompressionCodecNotSupportedException.java": [
                0,
                38
            ],
            "parquet-common/src/main/java/org/apache/parquet/io/DelegatingPositionOutputStream.java": [
                0,
                63
            ],
            "parquet-common/src/main/java/org/apache/parquet/io/DelegatingSeekableInputStream.java": [
                0,
                171
            ],
            "parquet-common/src/main/java/org/apache/parquet/io/InputFile.java": [
                4,
                5
            ],
            "parquet-common/src/main/java/org/apache/parquet/io/OutputFile.java": [
                0,
                34
            ],
            "parquet-common/src/main/java/org/apache/parquet/io/PositionOutputStream.java": [
                0,
                39
            ],
            "parquet-common/src/test/java/org/apache/parquet/io/MockInputStream.java": [
                0,
                56
            ],
            "parquet-encoding/src/main/java/org/apache/parquet/bytes/BytesInput.java": [
                0,
                0
            ],
            "parquet-encoding/src/main/java/org/apache/parquet/bytes/CapacityByteArrayOutputStream.java": [
                0,
                0
            ],
            "parquet-encoding/src/main/java/org/apache/parquet/bytes/ConcatenatingByteArrayCollector.java": [
                0,
                0
            ],
            "parquet-encoding/src/main/java/org/apache/parquet/bytes/LittleEndianDataInputStream.java": [
                0,
                0
            ],
            "parquet-encoding/src/main/java/org/apache/parquet/bytes/LittleEndianDataOutputStream.java": [
                0,
                0
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/HadoopReadOptions.java": [
                0,
                98
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/ParquetReadOptions.java": [
                0,
                232
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/filter2/compat/RowGroupFilter.java": [
                0,
                4
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/format/converter/ParquetMetadataConverter.java": [
                2,
                20
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/CodecFactory.java": [
                7,
                19
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ColumnChunkPageReadStore.java": [
                2,
                4
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/DirectCodecFactory.java": [
                6,
                6
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/InternalParquetRecordReader.java": [
                3,
                31
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ParquetFileReader.java": [
                103,
                153
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ParquetFileWriter.java": [
                53,
                94
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ParquetInputFormat.java": [
                3,
                0
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ParquetOutputFormat.java": [
                2,
                3
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ParquetReader.java": [
                35,
                141
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ParquetRecordReader.java": [
                16,
                10
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ParquetWriter.java": [
                11,
                39
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/UnmaterializableRecordCounter.java": [
                0,
                15
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/codec/CompressionCodecNotSupportedException.java": [
                36,
                0
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/metadata/CompressionCodecName.java": [
                18,
                18
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/util/H1SeekableInputStream.java": [
                98,
                3
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/util/H2SeekableInputStream.java": [
                17,
                3
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/util/HadoopCodecs.java": [
                0,
                39
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/util/HadoopOutputFile.java": [
                0,
                100
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/util/HadoopPositionOutputStream.java": [
                0,
                66
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/util/HadoopStreams.java": [
                0,
                15
            ],
            "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/TestInputOutputFormatWithPadding.java": [
                2,
                4
            ],
            "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/TestParquetFileWriter.java": [
                0,
                1
            ],
            "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/util/MockInputStream.java": [
                2,
                2
            ],
            "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/util/TestHadoop1ByteBufferReads.java": [
                127,
                227
            ],
            "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/util/TestHadoop2ByteBufferReads.java": [
                15,
                15
            ],
            "parquet-tools/src/main/java/org/apache/parquet/tools/command/MergeCommand.java": [
                1,
                2
            ],
            "pom.xml": null
        }
    },
    "da3e8eb7e5a8cdc28ab0e36651bd7eceed35c2fe": {
        "datetime": "2018-01-04T17:50:39+01:00",
        "summary": "PARQUET-357: Parquet-thrift generates wrong schema for Thrift binary fields",
        "message": "PARQUET-357: Parquet-thrift generates wrong schema for Thrift binary fields\n\nAuthor: Nandor Kollar <nkollar@cloudera.com>\n\nCloses #439 from nandorKollar/PARQUET-357 and squashes the following commits:\n\n90cfcfb [Nandor Kollar] Address code review feedback\n4bf8089 [Nandor Kollar] PARQUET-357: Parquet-thrift generates wrong schema for Thrift binary fields\n",
        "diff": {
            "parquet-thrift/src/main/java/org/apache/parquet/thrift/ThriftSchemaConvertVisitor.java": [
                1,
                1
            ],
            "parquet-thrift/src/main/java/org/apache/parquet/thrift/ThriftSchemaConverter.java": [
                1,
                7
            ],
            "parquet-thrift/src/main/java/org/apache/parquet/thrift/struct/ThriftType.java": [
                0,
                10
            ],
            "parquet-thrift/src/test/java/org/apache/parquet/hadoop/thrift/TestBinary.java": [
                2,
                25
            ]
        }
    },
    "9191fbd202cd76d03fc23057c5a16cac547d90df": {
        "datetime": "2018-01-04T10:32:31-08:00",
        "summary": "PARQUET-1141: Fix field ID handling",
        "message": "PARQUET-1141: Fix field ID handling\n\nThere are two places where field IDs are dropped:\n* Map and list type builders were not passing IDs when building\n* ParquetMetadataConverter was not writing field IDs or reading the ID for root schemas\n\nAuthor: Ryan Blue <blue@apache.org>\n\nCloses #428 from rdblue/PARQUET-1141-fix-column-ids and squashes the following commits:\n\n475a90ed7 [Ryan Blue] PARQUET-1141: Fix tests by adding Type$ID#getId.\ne110c00a7 [Ryan Blue] PARQUET-1141: Fix IDs in ParquetMetadataConverter.\na63066a8c [Ryan Blue] PARQUET-1141: Fix IDs for lists and maps.\n",
        "diff": {
            "parquet-column/src/main/java/org/apache/parquet/schema/Type.java": [
                0,
                10
            ],
            "parquet-column/src/main/java/org/apache/parquet/schema/Types.java": [
                3,
                15
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/format/converter/ParquetMetadataConverter.java": [
                0,
                12
            ]
        }
    },
    "2adb657ae83c4ad8cef0c142ead7c9916e10915a": {
        "datetime": "2018-01-09T16:02:21+01:00",
        "summary": "PARQUET-1077: Use long key ids in KEYS file",
        "message": "PARQUET-1077: Use long key ids in KEYS file\n\nCreated like so:\n\ngpg --import < KEYS 2>&1 | grep key | sed -e 's/.*\"\\(.*\\)\".*/\\1/' | \\\nwhile read k; do gpg --list-sigs --keyid-format long $k; gpg --export \\\n--armor $k; done > newkeys\n\nAuthor: Lars Volker <lv@cloudera.com>\n\nCloses #421 from lekv/full_keys and squashes the following commits:\n\n7d8f6a1b [Lars Volker] PARQUET-1077: Use long key ids in KEYS file\n",
        "diff": {
            "KEYS": null
        }
    },
    "3783ca4476fec8186c867e4e57084e649c318c6b": {
        "datetime": "2018-01-10T14:54:01+01:00",
        "summary": "PARQUET-1185: TestBinary#testBinary unit test fails after PARQUET-1141",
        "message": "PARQUET-1185: TestBinary#testBinary unit test fails after PARQUET-1141\n\nAuthor: Nandor Kollar <nkollar@cloudera.com>\n\nCloses #444 from nandorKollar/PARQUET-1185 and squashes the following commits:\n\n533aeb4 [Nandor Kollar] PARQUET-1185: TestBinary#testBinary unit test fails after PARQUET-1141\ne75adef [Nandor Kollar] PARQUET-1185: TestBinary#testBinary unit test fails after PARQUET-1141\n5e919cb [Nandor Kollar] PARQUET-1185: TestBinary#testBinary unit test fails after PARQUET-1141\n",
        "diff": {
            "parquet-thrift/src/test/java/org/apache/parquet/hadoop/thrift/TestBinary.java": [
                2,
                2
            ]
        }
    },
    "4d996d1bac1bb1886cd9c473ba00e53e3c19cf3e": {
        "datetime": "2018-01-10T14:59:24+01:00",
        "summary": "PARQUET-386: Printing out the statistics of metadata in parquet-tools",
        "message": "PARQUET-386: Printing out the statistics of metadata in parquet-tools\n\nAuthor: Gabor Szadovszky <gabor.szadovszky@cloudera.com>\n\nCloses #442 from gszadovszky/PARQUET-386 and squashes the following commits:\n\ndb8c4b9 [Gabor Szadovszky] PARQUET-386: Printing out the statistics of metadata in parquet-tools\n",
        "diff": {
            "parquet-tools/src/main/java/org/apache/parquet/tools/util/MetadataUtils.java": [
                0,
                7
            ]
        }
    },
    "c6764c4a0848abf1d581e22df8b33e28ee9f2ced": {
        "datetime": "2018-01-12T16:29:48-08:00",
        "summary": "PARQUET-1025: Support new min-max statistics in parquet-mr",
        "message": "PARQUET-1025: Support new min-max statistics in parquet-mr\n\nAuthor: Gabor Szadovszky <gabor.szadovszky@cloudera.com>\n\nCloses #435 from gszadovszky/PARQUET-1025 and squashes the following commits:\n\n2a63fcf13 [Gabor Szadovszky] PARQUET-1025: Use constant instead of creating new TypeDefinedOrder instances\n820df6fb7 [Gabor Szadovszky] PARQUET-1025: Minor fixes at data generation for TestStatistics\ndc838f273 [Gabor Szadovszky] PARQUET-1025: Implement ColumnOrder; other updates for rdblue's findings\n524750be0 [Gabor Szadovszky] PARQUET-1025: Some updates for zi's findings\na2ae97ce5 [Gabor Szadovszky] PARQUET-1025: Unified formatting/comments/deprecation\nbc86e8a63 [Gabor Szadovszky] PARQUET-1025: Updates according to rdblue's comments\n70e56a759 [Gabor Szadovszky] PARQUET-1025: Add explicit list of types to not to read/write statistics\n95199e5e0 [Gabor Szadovszky] PARQUET-1025: Use lexicographical comparison for Binary.compareTo Also rename SIGNED_BINARY_COMPARATOR to a more descriptive name Also added comments for haxa representation of values at unsigned comparison testing\n2f28c2c0e [Gabor Szadovszky] PARQUET-1025: Finalize read/write stats updates\nc5536a0a3 [Gabor Szadovszky] PARQUET-1025: Some modifications according to zi's comments\n318e585d9 [Gabor Szadovszky] PARQUET-1025: Finalize reading/writing new stats; modify/implement unit tests accordingly\n688ef2efe [Gabor Szadovszky] PARQUET-1025: Updates according to zi's and rdblue's comments\n51bc1f827 [Gabor Szadovszky] PARQUET-1025: Add the proper comparators as required; revert Binary related changes\n20b937f46 [Gabor Szadovszky] PARQUET-1025: reading/writing new min-max statistics; use the comparators as needed\n52cd58f61 [Gabor Szadovszky] PARQUET-1025: Move comparators to Type\n3378b6d34 [Gabor Szadovszky] PARQUET-1025: Implement comparators and use them with statistics\ne1719bb3b [Gabor Szadovszky] PARQUET-1025: Refactor Binary to prepare from custom comparators\n",
        "diff": {
            "parquet-cli/src/main/java/org/apache/parquet/cli/Util.java": [
                46,
                4
            ],
            "parquet-cli/src/main/java/org/apache/parquet/cli/commands/CheckParquet251Command.java": [
                4,
                7
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/ColumnDescriptor.java": [
                8,
                32
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/impl/ColumnWriterV1.java": [
                1,
                1
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/impl/ColumnWriterV2.java": [
                1,
                1
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/statistics/BinaryStatistics.java": [
                11,
                38
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/statistics/BooleanStatistics.java": [
                12,
                41
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/statistics/DoubleStatistics.java": [
                12,
                46
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/statistics/FloatStatistics.java": [
                12,
                47
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/statistics/IntStatistics.java": [
                12,
                47
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/statistics/LongStatistics.java": [
                12,
                47
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/statistics/Statistics.java": [
                34,
                161
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/statistics/StatisticsClassException.java": [
                1,
                13
            ],
            "parquet-column/src/main/java/org/apache/parquet/filter2/predicate/Statistics.java": [
                0,
                36
            ],
            "parquet-column/src/main/java/org/apache/parquet/filter2/recordlevel/IncrementallyUpdatedFilterPredicateBuilderBase.java": [
                0,
                19
            ],
            "parquet-column/src/main/java/org/apache/parquet/io/MessageColumnIO.java": [
                1,
                1
            ],
            "parquet-column/src/main/java/org/apache/parquet/io/PrimitiveColumnIO.java": [
                4,
                3
            ],
            "parquet-column/src/main/java/org/apache/parquet/io/api/Binary.java": [
                108,
                12
            ],
            "parquet-column/src/main/java/org/apache/parquet/schema/ColumnOrder.java": [
                0,
                97
            ],
            "parquet-column/src/main/java/org/apache/parquet/schema/MessageType.java": [
                4,
                2
            ],
            "parquet-column/src/main/java/org/apache/parquet/schema/PrimitiveComparator.java": [
                0,
                290
            ],
            "parquet-column/src/main/java/org/apache/parquet/schema/PrimitiveType.java": [
                1,
                186
            ],
            "parquet-column/src/main/java/org/apache/parquet/schema/Types.java": [
                1,
                19
            ],
            "parquet-column/src/test/java/org/apache/parquet/column/statistics/TestStatistics.java": [
                0,
                28
            ],
            "parquet-column/src/test/java/org/apache/parquet/io/api/TestBinary.java": [
                0,
                20
            ],
            "parquet-column/src/test/java/org/apache/parquet/schema/TestMessageType.java": [
                0,
                45
            ],
            "parquet-column/src/test/java/org/apache/parquet/schema/TestPrimitiveComparator.java": [
                0,
                311
            ],
            "parquet-column/src/test/java/org/apache/parquet/schema/TestTypeBuilders.java": [
                0,
                47
            ],
            "parquet-generator/src/main/java/org/apache/parquet/filter2/IncrementallyUpdatedFilterPredicateGenerator.java": [
                21,
                22
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/filter2/dictionarylevel/DictionaryFilter.java": [
                5,
                10
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/filter2/statisticslevel/StatisticsFilter.java": [
                8,
                9
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/format/converter/ParquetMetadataConverter.java": [
                36,
                105
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ColumnChunkPageWriteStore.java": [
                5,
                15
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ParquetFileWriter.java": [
                8,
                14
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/metadata/ColumnChunkMetaData.java": [
                2,
                37
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/metadata/ColumnChunkProperties.java": [
                3,
                27
            ],
            "parquet-hadoop/src/test/java/org/apache/parquet/format/converter/TestParquetMetadataConverter.java": [
                53,
                328
            ],
            "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/TestParquetFileWriter.java": [
                4,
                4
            ],
            "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/TestUtils.java": [
                0,
                21
            ],
            "parquet-hadoop/src/test/java/org/apache/parquet/statistics/RandomValues.java": [
                13,
                84
            ],
            "parquet-hadoop/src/test/java/org/apache/parquet/statistics/TestStatistics.java": [
                65,
                131
            ],
            "parquet-thrift/src/test/java/org/apache/parquet/hadoop/thrift/TestThriftToParquetFileWriter.java": [
                12,
                11
            ]
        }
    },
    "b80b1844edf0074ecfc915b506eb60b4f0b8704d": {
        "datetime": "2018-01-18T14:39:32+01:00",
        "summary": "PARQUET-1197: Log rat failures",
        "message": "PARQUET-1197: Log rat failures\n\nAuthor: Gabor Szadovszky <gabor.szadovszky@cloudera.com>\n\nCloses #451 from gszadovszky/PARQUET-1197 and squashes the following commits:\n\n79d443f [Gabor Szadovszky] PARQUET-1197: Log rat failures\n",
        "diff": {
            "pom.xml": null
        }
    },
    "878ebcd0bc2592fa9d5dda01117c07bc3c40bb33": {
        "datetime": "2018-01-19T16:53:42+01:00",
        "summary": "PARQUET-1191: Type.hashCode() takes originalType into account but Type.equals() does not",
        "message": "PARQUET-1191: Type.hashCode() takes originalType into account but Type.equals() does not\n\nAuthor: Nandor Kollar <nkollar@cloudera.com>\n\nCloses #450 from nandorKollar/PARQUET-1191 and squashes the following commits:\n\nc7131df [Nandor Kollar] PARQUET-1191: Type.hashCode() takes originalType into account but Type.equals() does not\n",
        "diff": {
            "parquet-column/src/main/java/org/apache/parquet/schema/Type.java": [
                2,
                2
            ],
            "parquet-pig/src/test/java/org/apache/parquet/pig/TestPigSchemaConverter.java": [
                8,
                5
            ],
            "parquet-scrooge/src/main/java/org/apache/parquet/scrooge/ScroogeStructConverter.java": [
                1,
                7
            ],
            "parquet-thrift/src/main/java/org/apache/parquet/thrift/ThriftSchemaConverter.java": [
                0,
                2
            ],
            "parquet-thrift/src/test/java/org/apache/parquet/hadoop/thrift/TestBinary.java": [
                4,
                1
            ]
        }
    },
    "89aeec028b6f56be96b9c56c2fdbb931f80853ad": {
        "datetime": "2018-01-22T17:21:27+01:00",
        "summary": "PARQUET-1170: Logical-type-based toString for proper representeation in tools/logs",
        "message": "PARQUET-1170: Logical-type-based toString for proper representeation in tools/logs\n\nAuthor: Gabor Szadovszky <gabor.szadovszky@cloudera.com>\n\nCloses #448 from gszadovszky/PARQUET-1170 and squashes the following commits:\n\n8f1f8cc [Gabor Szadovszky] PARQUET-1170: Make interval test more readable\n90f73b5 [Gabor Szadovszky] PARQUET-1170: Fix endianess of interval\n612d70b [Gabor Szadovszky] PARQUET-1170: Add unit test for different locale\nd8c5204 [Gabor Szadovszky] PARQUET-1170: Implement toString based on logical type so values will be represented properly in tools/logs etc.\n",
        "diff": {
            "parquet-cli/src/main/java/org/apache/parquet/cli/Util.java": [
                37,
                3
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/statistics/BinaryStatistics.java": [
                3,
                2
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/statistics/BooleanStatistics.java": [
                0,
                5
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/statistics/DoubleStatistics.java": [
                2,
                2
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/statistics/FloatStatistics.java": [
                2,
                2
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/statistics/IntStatistics.java": [
                3,
                2
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/statistics/LongStatistics.java": [
                3,
                2
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/statistics/Statistics.java": [
                7,
                6
            ],
            "parquet-column/src/main/java/org/apache/parquet/schema/OriginalType.java": [
                19,
                41
            ],
            "parquet-column/src/main/java/org/apache/parquet/schema/PrimitiveStringifier.java": [
                0,
                360
            ],
            "parquet-column/src/main/java/org/apache/parquet/schema/PrimitiveType.java": [
                1,
                9
            ],
            "parquet-column/src/test/java/org/apache/parquet/column/statistics/TestStatistics.java": [
                11,
                35
            ],
            "parquet-column/src/test/java/org/apache/parquet/schema/TestPrimitiveStringifier.java": [
                0,
                298
            ],
            "parquet-tools/src/main/java/org/apache/parquet/tools/command/DumpCommand.java": [
                10,
                24
            ]
        }
    },
    "6e0cc729d06f70a674edb8272b855062b6bda7b3": {
        "datetime": "2018-01-25T16:16:35+01:00",
        "summary": "PARQUET-1065: Deprecate type-defined sort ordering for INT96 type.",
        "message": "PARQUET-1065: Deprecate type-defined sort ordering for INT96 type.\n\nAuthor: Zoltan Ivanfi <zi@cloudera.com>\n\nCloses #454 from zivanfi/PARQUET-1065 and squashes the following commits:\n\n8559f89 [Zoltan Ivanfi] PARQUET-1065: Deprecate type-defined sort ordering for INT96 type.\n",
        "diff": {
            "parquet-hadoop/src/main/java/org/apache/parquet/format/converter/ParquetMetadataConverter.java": [
                1,
                0
            ]
        }
    },
    "6a4bbe94ab482e56d35e6614cf5d05eceb449714": {
        "datetime": "2018-01-30T19:08:36+01:00",
        "summary": "PARQUET-1198: Bump java source and target to java8",
        "message": "PARQUET-1198: Bump java source and target to java8\n\nAuthor: Gabor Szadovszky <gabor.szadovszky@cloudera.com>\n\nCloses #452 from gszadovszky/PARQUET-1198 and squashes the following commits:\n\n5b7ee44 [Gabor Szadovszky] PARQUET-1198: Bump java source and target to java8\n",
        "diff": {
            "pom.xml": null
        }
    },
    "445cb9dc2f07553f8e1e5f7c1150f00fbb05c63f": {
        "datetime": "2018-02-15T09:07:29-08:00",
        "summary": "PARQUET-1215: Add getFooter to ParquetWriter.",
        "message": "PARQUET-1215: Add getFooter to ParquetWriter.\n\nThis adds getFooter to ParquetWriter, which will return the file footer that was written after the file is closed.\n\nAuthor: Ryan Blue <blue@apache.org>\n\nCloses #457 from rdblue/PARQUET-1215-add-footer-accessor-to-writers and squashes the following commits:\n\n79c5965a1 [Ryan Blue] PARQUET-1215: Add getFooter to ParquetWriter.\n",
        "diff": {
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/InternalParquetRecordWriter.java": [
                0,
                5
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ParquetFileWriter.java": [
                1,
                9
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ParquetWriter.java": [
                0,
                8
            ]
        }
    },
    "ad80bfe559e7380fedd7998daea5f27393ab643b": {
        "datetime": "2018-02-19T18:37:54+01:00",
        "summary": "PARQUET-1208: Occasional endless loop in unit test",
        "message": "PARQUET-1208: Occasional endless loop in unit test\n\nAuthor: Zoltan Ivanfi <zi@cloudera.com>\n\nCloses #455 from zivanfi/PARQUET-1208 and squashes the following commits:\n\n665ba37 [Zoltan Ivanfi] PARQUET-1208: Addressing Ryan's comments.\n2ff96a3 [Zoltan Ivanfi] PARQUET-1208: Occasional endless loop in unit test\n",
        "diff": {
            "parquet-hadoop/src/test/java/org/apache/parquet/format/converter/TestParquetMetadataConverter.java": [
                2,
                2
            ]
        }
    },
    "8bbc6cb95fd9b4b9e86c924ca1e40fd555ecac1d": {
        "datetime": "2018-02-21T09:40:07-08:00",
        "summary": "PARQUET-787: Limit read allocation size",
        "message": "PARQUET-787: Limit read allocation size\n\nWIP: This update the `ParquetFileReader` to use multiple buffers when reading a row group, instead of a single humongous allocation. As a consequence, many classes needed to be updated to accept a stream backed by multiple buffers, instead of using a single buffer directly. Assuming a single contiguous buffer would require too many copies.\n\nAuthor: Ryan Blue <blue@apache.org>\n\nCloses #390 from rdblue/PARQUET-787-limit-read-allocation-size and squashes the following commits:\n\n4abba3e7a [Ryan Blue] PARQUET-787: Update byte buffer input streams for review comments.\ne7c6c5dd2 [Ryan Blue] PARQUET-787: Fix problems from Zoltan's review.\nbe52b59fa [Ryan Blue] PARQUET-787: Update tests for both ByteBufferInputStreams.\nb0b614748 [Ryan Blue] PARQUET-787: Update encodings to use ByteBufferInputStream.\na4fa05ac5 [Ryan Blue] Refactor ByteBufferInputStream implementations.\n56b22a6a1 [Ryan Blue] Make allocation size configurable.\n103ed3d86 [Ryan Blue] Add tests for ByteBufferInputStream and fix bugs.\n614a2bbc8 [Ryan Blue] Limit allocation size to 8MB chunks for better garbage collection.\n",
        "diff": {
            "parquet-column/src/main/java/org/apache/parquet/column/impl/ColumnReaderImpl.java": [
                15,
                15
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/values/ValuesReader.java": [
                30,
                6
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/values/bitpacking/BitPackingValuesReader.java": [
                11,
                4
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/values/bitpacking/ByteBitPackingValuesReader.java": [
                24,
                24
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/values/delta/DeltaBinaryPackingValuesReader.java": [
                28,
                12
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/values/deltalengthbytearray/DeltaLengthByteArrayValuesReader.java": [
                12,
                18
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/values/deltastrings/DeltaByteArrayReader.java": [
                5,
                6
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/values/dictionary/DictionaryValuesReader.java": [
                4,
                5
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/values/dictionary/PlainValuesDictionary.java": [
                8,
                9
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/values/plain/BinaryPlainValuesReader.java": [
                17,
                14
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/values/plain/BooleanPlainValuesReader.java": [
                11,
                5
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/values/plain/FixedLenByteArrayPlainValuesReader.java": [
                13,
                16
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/values/plain/PlainValuesReader.java": [
                12,
                3
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/values/rle/RunLengthBitPackingHybridDecoder.java": [
                2,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/values/rle/RunLengthBitPackingHybridValuesReader.java": [
                15,
                4
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/values/rle/ZeroIntegerValuesReader.java": [
                9,
                2
            ],
            "parquet-column/src/test/java/org/apache/parquet/column/impl/TestCorruptDeltaByteArrays.java": [
                8,
                9
            ],
            "parquet-column/src/test/java/org/apache/parquet/column/values/Utils.java": [
                15,
                6
            ],
            "parquet-column/src/test/java/org/apache/parquet/column/values/bitpacking/BitPackingPerfTest.java": [
                1,
                2
            ],
            "parquet-column/src/test/java/org/apache/parquet/column/values/bitpacking/TestBitPackingColumn.java": [
                1,
                2
            ],
            "parquet-column/src/test/java/org/apache/parquet/column/values/delta/DeltaBinaryPackingValuesWriterForIntegerTest.java": [
                7,
                10
            ],
            "parquet-column/src/test/java/org/apache/parquet/column/values/delta/DeltaBinaryPackingValuesWriterForLongTest.java": [
                6,
                9
            ],
            "parquet-column/src/test/java/org/apache/parquet/column/values/delta/benchmark/BenchmarkReadingRandomIntegers.java": [
                1,
                2
            ],
            "parquet-column/src/test/java/org/apache/parquet/column/values/deltalengthbytearray/TestDeltaLengthByteArray.java": [
                3,
                3
            ],
            "parquet-column/src/test/java/org/apache/parquet/column/values/deltalengthbytearray/benchmark/BenchmarkDeltaLengthByteArray.java": [
                4,
                5
            ],
            "parquet-column/src/test/java/org/apache/parquet/column/values/deltastrings/TestDeltaByteArray.java": [
                5,
                5
            ],
            "parquet-column/src/test/java/org/apache/parquet/column/values/deltastrings/benchmark/BenchmarkDeltaByteArray.java": [
                8,
                9
            ],
            "parquet-column/src/test/java/org/apache/parquet/column/values/dictionary/TestDictionary.java": [
                17,
                19
            ],
            "parquet-column/src/test/java/org/apache/parquet/column/values/rle/RunLengthBitPackingHybridIntegrationTest.java": [
                1,
                1
            ],
            "parquet-column/src/test/java/org/apache/parquet/column/values/rle/TestRunLengthBitPackingHybridEncoder.java": [
                2,
                0
            ],
            "parquet-common/src/main/java/org/apache/parquet/bytes/ByteBufferInputStream.java": [
                50,
                40
            ],
            "parquet-common/src/main/java/org/apache/parquet/bytes/BytesInput.java": [
                34,
                66
            ],
            "parquet-common/src/main/java/org/apache/parquet/bytes/MultiBufferInputStream.java": [
                0,
                382
            ],
            "parquet-common/src/main/java/org/apache/parquet/bytes/SingleBufferInputStream.java": [
                0,
                177
            ],
            "parquet-common/src/test/java/org/apache/parquet/bytes/TestByteBufferInputStreams.java": [
                0,
                597
            ],
            "parquet-common/src/test/java/org/apache/parquet/bytes/TestMultiBufferInputStream.java": [
                0,
                141
            ],
            "parquet-common/src/test/java/org/apache/parquet/bytes/TestSingleBufferInputStream.java": [
                0,
                130
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/HadoopReadOptions.java": [
                2,
                7
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/ParquetReadOptions.java": [
                18,
                32
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/CodecFactory.java": [
                1,
                1
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/DirectCodecFactory.java": [
                1,
                3
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ParquetFileReader.java": [
                40,
                51
            ],
            "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/TestDirectCodecFactory.java": [
                3,
                3
            ]
        }
    },
    "b82d96218bfd37f6df95a2e8d7675d091ab61970": {
        "datetime": "2018-02-27T14:19:14+01:00",
        "summary": "PARQUET-1217: Incorrect handling of missing values in Statistics",
        "message": "PARQUET-1217: Incorrect handling of missing values in Statistics\n\nIn parquet-format every value in Statistics is optional while parquet-mr does not properly handle these scenarios:\n- null_count is set but min/max or min_value/max_value are not: filtering may fail with NPE or incorrect filtering occurs\n  fix: check if min/max is set before comparing to the related values\n- null_count is not set: filtering handles null_count as if it would be 0 -> incorrect filtering may occur\n  fix: introduce new method in Statistics object to check if num_nulls is set; check if num_nulls is set by the new method before using its value for filtering\n\nAuthor: Gabor Szadovszky <gabor.szadovszky@cloudera.com>\n\nCloses #458 from gszadovszky/PARQUET-1217 and squashes the following commits:\n\n9d14090 [Gabor Szadovszky] Updates according to rdblue's comments\n116d1d3 [Gabor Szadovszky] PARQUET-1217: Updates according to zi's comments\nc264b50 [Gabor Szadovszky] PARQUET-1217: fix handling of unset nullCount\n2ec2fb1 [Gabor Szadovszky] PARQUET-1217: Incorrect handling of missing values in Statistics\n",
        "diff": {
            "parquet-cli/src/main/java/org/apache/parquet/cli/commands/ParquetMetadataCommand.java": [
                2,
                2
            ],
            "parquet-cli/src/main/java/org/apache/parquet/cli/commands/ShowPagesCommand.java": [
                1,
                1
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/statistics/Statistics.java": [
                7,
                73
            ],
            "parquet-column/src/test/java/org/apache/parquet/column/statistics/TestStatistics.java": [
                0,
                1
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/filter2/statisticslevel/StatisticsFilter.java": [
                2,
                40
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/format/converter/ParquetMetadataConverter.java": [
                9,
                16
            ],
            "parquet-hadoop/src/test/java/org/apache/parquet/filter2/statisticslevel/TestStatisticsFilter.java": [
                4,
                60
            ],
            "parquet-hadoop/src/test/java/org/apache/parquet/format/converter/TestParquetMetadataConverter.java": [
                0,
                33
            ],
            "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/TestColumnChunkPageWriteStore.java": [
                1,
                3
            ],
            "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/TestParquetFileWriter.java": [
                24,
                24
            ]
        }
    },
    "3d2d4fd1588c8eb3f67f34d75b66967d0c7b06b6": {
        "datetime": "2018-03-09T16:14:11-08:00",
        "summary": "PARQUET-1135: upgrade thrift and protobuf dependencies",
        "message": "PARQUET-1135: upgrade thrift and protobuf dependencies\n\nAuthor: Julien Le Dem <julien.ledem@wework.com>\nAuthor: Julien Le Dem <julien@ledem.net>\n\nCloses #427 from julienledem/PARQUET_1135_thrift_PB and squashes the following commits:\n\nf23b32d9 [Julien Le Dem] remove double install\n78cbf734 [Julien Le Dem] remove running check on protobuf build\n4bc2b8f7 [Julien Le Dem] add timing; upgrade proto version\ne17ca956 [Julien Le Dem] without-nodejs\nd15e523d [Julien Le Dem] PARQUET-1135: upgrade thrift and protobuf dependencies\n",
        "diff": {
            ".travis.yml": null,
            "parquet-protobuf/pom.xml": null,
            "parquet-thrift/src/main/java/org/apache/parquet/hadoop/thrift/ThriftBytesWriteSupport.java": [
                2,
                30
            ],
            "pom.xml": null
        }
    },
    "0a86429939075984edce5e3b8195dfb7f9e3ab6b": {
        "datetime": "2018-03-19T14:43:12+01:00",
        "summary": "PARQUET-1246: Ignore float/double statistics in case of NaN",
        "message": "PARQUET-1246: Ignore float/double statistics in case of NaN\n\nBecause of the ambigous sorting order of float/double the following changes made at the reading path of the related statistics:\n- Ignoring statistics in case of it contains a NaN value.\n- Using -0.0 as min value and +0.0 as max value independently from which 0.0 value was saved in the statistics.\n\nAuthor: Gabor Szadovszky <gabor.szadovszky@cloudera.com>\n\nCloses #461 from gszadovszky/PARQUET-1246 and squashes the following commits:\n\n20e9332 [Gabor Szadovszky] PARQUET-1246: Changes according to zi's comments\n3447938 [Gabor Szadovszky] PARQUET-1246: Ignore float/double statistics in case of NaN\n",
        "diff": {
            "parquet-column/src/main/java/org/apache/parquet/column/statistics/Statistics.java": [
                4,
                77
            ],
            "parquet-column/src/test/java/org/apache/parquet/column/statistics/TestStatistics.java": [
                1,
                150
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/format/converter/ParquetMetadataConverter.java": [
                1,
                1
            ],
            "parquet-hadoop/src/test/java/org/apache/parquet/filter2/statisticslevel/TestStatisticsFilter.java": [
                2,
                2
            ],
            "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/TestColumnChunkPageWriteStore.java": [
                1,
                1
            ],
            "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/TestParquetFileWriter.java": [
                1,
                1
            ]
        }
    },
    "a7ca605e155a697795a8be90f083f8e9ca42bae3": {
        "datetime": "2018-03-29T17:39:57+02:00",
        "summary": "PARQUET-1258: Update scm developer connection to github (#462)",
        "message": "PARQUET-1258: Update scm developer connection to github (#462)\n\n",
        "diff": {
            "pom.xml": null
        }
    },
    "d54fad867da7f762ac4c0d947adffdc1f8f356f1": {
        "datetime": "2018-03-30T15:24:17-07:00",
        "summary": "PARQUET-1183: Add Avro builders using InputFile and OutputFile. (#460)",
        "message": "PARQUET-1183: Add Avro builders using InputFile and OutputFile. (#460)\n\n* PARQUET-1183: Add Avro builders using InputFile and OutputFile.\r\n* PARQUET-1183: Add deprecation warnings to Avro read builder.\r\n\r\nCloses #446",
        "diff": {
            "parquet-avro/src/main/java/org/apache/parquet/avro/AvroParquetReader.java": [
                0,
                14
            ],
            "parquet-avro/src/main/java/org/apache/parquet/avro/AvroParquetWriter.java": [
                0,
                9
            ]
        }
    },
    "12bbaf3550d56bc945b50f538b5f18af93bd316a": {
        "datetime": "2018-03-30T15:31:01-07:00",
        "summary": "PARQUET-1263: If file has a config, use it for ParquetReadOptions. (#464)",
        "message": "PARQUET-1263: If file has a config, use it for ParquetReadOptions. (#464)\n\n",
        "diff": {
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ParquetReader.java": [
                2,
                12
            ]
        }
    },
    "9261c28b2b61403cbd6ee335ada98c02b3b60332": {
        "datetime": "2018-03-30T15:33:43-07:00",
        "summary": "PARQUET-1189: Update CHANGES.md for 1.10.0 release.",
        "message": "PARQUET-1189: Update CHANGES.md for 1.10.0 release.\n",
        "diff": {
            "CHANGES.md": null
        }
    },
    "d61d221c9e752ce2cc0da65ede8b55653b3ae21f": {
        "datetime": "2018-03-30T17:51:23-07:00",
        "summary": "PARQUET-1264: Fix javadoc warnings for Java 8.",
        "message": "PARQUET-1264: Fix javadoc warnings for Java 8.\n",
        "diff": {
            "parquet-column/src/main/java/org/apache/parquet/CorruptStatistics.java": [
                0,
                4
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/page/DataPageV1.java": [
                1,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/page/DataPageV2.java": [
                6,
                6
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/page/PageWriter.java": [
                3,
                4
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/statistics/BinaryStatistics.java": [
                0,
                8
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/values/ValuesReader.java": [
                1,
                1
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/values/ValuesWriter.java": [
                1,
                1
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/values/bitpacking/BitPackingValuesWriter.java": [
                1,
                3
            ],
            "parquet-column/src/main/java/org/apache/parquet/filter/AndRecordFilter.java": [
                0,
                1
            ],
            "parquet-column/src/main/java/org/apache/parquet/filter/ColumnRecordFilter.java": [
                0,
                1
            ],
            "parquet-column/src/main/java/org/apache/parquet/filter/NotRecordFilter.java": [
                0,
                1
            ],
            "parquet-column/src/main/java/org/apache/parquet/filter/OrRecordFilter.java": [
                0,
                1
            ],
            "parquet-column/src/main/java/org/apache/parquet/filter/PagedRecordFilter.java": [
                0,
                1
            ],
            "parquet-column/src/main/java/org/apache/parquet/filter/RecordFilter.java": [
                0,
                1
            ],
            "parquet-column/src/main/java/org/apache/parquet/filter/UnboundRecordFilter.java": [
                0,
                3
            ],
            "parquet-column/src/main/java/org/apache/parquet/io/MessageColumnIO.java": [
                1,
                6
            ],
            "parquet-column/src/main/java/org/apache/parquet/io/RecordConsumerLoggingWrapper.java": [
                1,
                1
            ],
            "parquet-column/src/main/java/org/apache/parquet/io/RecordReader.java": [
                0,
                1
            ],
            "parquet-column/src/main/java/org/apache/parquet/io/api/Binary.java": [
                1,
                1
            ],
            "parquet-column/src/main/java/org/apache/parquet/io/api/RecordConsumer.java": [
                6,
                6
            ],
            "parquet-column/src/main/java/org/apache/parquet/schema/ConversionPatterns.java": [
                5,
                5
            ],
            "parquet-column/src/main/java/org/apache/parquet/schema/GroupType.java": [
                5,
                5
            ],
            "parquet-column/src/main/java/org/apache/parquet/schema/MessageType.java": [
                0,
                2
            ],
            "parquet-column/src/main/java/org/apache/parquet/schema/PrimitiveType.java": [
                1,
                4
            ],
            "parquet-column/src/main/java/org/apache/parquet/schema/Type.java": [
                3,
                6
            ],
            "parquet-column/src/main/java/org/apache/parquet/schema/Types.java": [
                2,
                5
            ],
            "parquet-common/src/main/java/org/apache/parquet/Exceptions.java": [
                0,
                5
            ],
            "parquet-common/src/main/java/org/apache/parquet/IOExceptionUtils.java": [
                1,
                1
            ],
            "parquet-common/src/main/java/org/apache/parquet/Log.java": [
                12,
                12
            ],
            "parquet-common/src/main/java/org/apache/parquet/Preconditions.java": [
                0,
                1
            ],
            "parquet-common/src/main/java/org/apache/parquet/Strings.java": [
                4,
                8
            ],
            "parquet-common/src/main/java/org/apache/parquet/bytes/ByteBufferAllocator.java": [
                0,
                2
            ],
            "parquet-common/src/main/java/org/apache/parquet/bytes/BytesInput.java": [
                13,
                15
            ],
            "parquet-common/src/main/java/org/apache/parquet/bytes/BytesUtils.java": [
                14,
                19
            ],
            "parquet-common/src/main/java/org/apache/parquet/bytes/CapacityByteArrayOutputStream.java": [
                2,
                11
            ],
            "parquet-common/src/main/java/org/apache/parquet/bytes/LittleEndianDataInputStream.java": [
                22,
                22
            ],
            "parquet-common/src/main/java/org/apache/parquet/glob/GlobExpander.java": [
                1,
                16
            ],
            "parquet-common/src/main/java/org/apache/parquet/hadoop/metadata/Canonicalizer.java": [
                1,
                1
            ],
            "parquet-common/src/main/java/org/apache/parquet/io/SeekableInputStream.java": [
                2,
                4
            ],
            "parquet-common/src/main/java/org/apache/parquet/util/DynMethods.java": [
                16,
                4
            ],
            "parquet-encoding/src/main/java/org/apache/parquet/column/values/bitpacking/BitPacking.java": [
                3,
                4
            ],
            "parquet-encoding/src/main/java/org/apache/parquet/column/values/bitpacking/ByteBasedBitPackingEncoder.java": [
                3,
                4
            ],
            "parquet-encoding/src/main/java/org/apache/parquet/column/values/bitpacking/BytePacker.java": [
                0,
                8
            ],
            "parquet-generator/src/main/java/org/apache/parquet/encoding/bitpacking/ByteBasedBitPackingGenerator.java": [
                1,
                1
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/codec/CodecConfig.java": [
                0,
                2
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/codec/SnappyDecompressor.java": [
                1,
                1
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/metadata/ColumnChunkMetaData.java": [
                1,
                13
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/metadata/ColumnChunkProperties.java": [
                0,
                5
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/metadata/ParquetMetadata.java": [
                3,
                2
            ]
        }
    },
    "150c578edb161bdb2e8c039f0914984f570ef8f0": {
        "datetime": "2018-03-30T17:53:49-07:00",
        "summary": "PARQUET-1264: Fix javadoc 8 problem in VersionGenerator.",
        "message": "PARQUET-1264: Fix javadoc 8 problem in VersionGenerator.\n",
        "diff": {
            "parquet-generator/src/main/java/org/apache/parquet/version/VersionGenerator.java": [
                1,
                1
            ]
        }
    },
    "0d55abd05b0e5027c18e60d1ac3b22998dd00951": {
        "datetime": "2018-04-05T12:42:15-07:00",
        "summary": "RQUET-1264: Fix javadoc warnings for Java 8.",
        "message": "RQUET-1264: Fix javadoc warnings for Java 8.\n",
        "diff": {
            "parquet-arrow/src/main/java/org/apache/parquet/arrow/schema/SchemaConverter.java": [
                7,
                7
            ],
            "parquet-arrow/src/main/java/org/apache/parquet/arrow/schema/SchemaMapping.java": [
                3,
                1
            ],
            "parquet-avro/src/main/java/org/apache/parquet/avro/AvroParquetInputFormat.java": [
                6,
                8
            ],
            "parquet-avro/src/main/java/org/apache/parquet/avro/AvroParquetOutputFormat.java": [
                2,
                2
            ],
            "parquet-avro/src/main/java/org/apache/parquet/avro/AvroParquetReader.java": [
                4,
                21
            ],
            "parquet-avro/src/main/java/org/apache/parquet/avro/AvroParquetWriter.java": [
                9,
                9
            ],
            "parquet-avro/src/main/java/org/apache/parquet/avro/AvroReadSupport.java": [
                0,
                6
            ],
            "parquet-avro/src/main/java/org/apache/parquet/avro/AvroWriteSupport.java": [
                1,
                5
            ],
            "parquet-avro/src/main/java/org/apache/parquet/avro/package-info.java": [
                0,
                3
            ],
            "parquet-cascading-common23/src/main/java/org/apache/parquet/cascading/TupleWriteSupport.java": [
                5,
                0
            ],
            "parquet-cascading/src/main/java/org/apache/parquet/cascading/ParquetTupleScheme.java": [
                2,
                0
            ],
            "parquet-cascading3/src/main/java/org/apache/parquet/cascading/ParquetTupleScheme.java": [
                2,
                0
            ],
            "parquet-cli/src/main/java/org/apache/parquet/cli/BaseCommand.java": [
                10,
                13
            ],
            "parquet-cli/src/main/java/org/apache/parquet/cli/Command.java": [
                1,
                1
            ],
            "parquet-cli/src/main/java/org/apache/parquet/cli/util/Expressions.java": [
                0,
                4
            ],
            "parquet-cli/src/main/java/org/apache/parquet/cli/util/RecordException.java": [
                0,
                2
            ],
            "parquet-cli/src/main/java/org/apache/parquet/cli/util/Schemas.java": [
                0,
                3
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/ColumnDescriptor.java": [
                5,
                3
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/ColumnReadStore.java": [
                2,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/ColumnReader.java": [
                5,
                4
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/ColumnWriteStore.java": [
                2,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/ColumnWriter.java": [
                23,
                20
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/Dictionary.java": [
                3,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/Encoding.java": [
                6,
                6
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/ParquetProperties.java": [
                3,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/UnknownColumnException.java": [
                2,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/UnknownColumnTypeException.java": [
                2,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/ValuesType.java": [
                3,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/impl/ColumnReadStoreImpl.java": [
                3,
                1
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/impl/ColumnReaderImpl.java": [
                6,
                2
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/impl/ColumnWriterV1.java": [
                3,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/impl/ColumnWriterV2.java": [
                3,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/page/DataPage.java": [
                3,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/page/DictionaryPage.java": [
                3,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/page/Page.java": [
                3,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/page/PageReadStore.java": [
                3,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/page/PageReader.java": [
                3,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/page/PageWriteStore.java": [
                3,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/page/PageWriter.java": [
                3,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/statistics/Statistics.java": [
                3,
                15
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/statistics/StatisticsClassException.java": [
                2,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/values/RequiresFallback.java": [
                4,
                1
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/values/ValuesReader.java": [
                2,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/values/ValuesWriter.java": [
                3,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/values/bitpacking/BitPackingValuesReader.java": [
                3,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/values/bitpacking/BitPackingValuesWriter.java": [
                3,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/values/delta/DeltaBinaryPackingConfig.java": [
                2,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/values/delta/DeltaBinaryPackingValuesReader.java": [
                2,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/values/delta/DeltaBinaryPackingValuesWriter.java": [
                4,
                1
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/values/delta/DeltaBinaryPackingValuesWriterForInteger.java": [
                5,
                2
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/values/delta/DeltaBinaryPackingValuesWriterForLong.java": [
                4,
                2
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/values/deltalengthbytearray/DeltaLengthByteArrayValuesReader.java": [
                3,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/values/deltalengthbytearray/DeltaLengthByteArrayValuesWriter.java": [
                1,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/values/deltastrings/DeltaByteArrayReader.java": [
                3,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/values/deltastrings/DeltaByteArrayWriter.java": [
                2,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/values/dictionary/DictionaryValuesReader.java": [
                3,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/values/dictionary/DictionaryValuesWriter.java": [
                42,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/values/dictionary/IntList.java": [
                7,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/values/dictionary/PlainValuesDictionary.java": [
                11,
                11
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/values/factory/ValuesWriterFactory.java": [
                1,
                6
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/values/plain/BooleanPlainValuesReader.java": [
                3,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/values/plain/BooleanPlainValuesWriter.java": [
                3,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/values/plain/FixedLenByteArrayPlainValuesReader.java": [
                2,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/values/plain/FixedLenByteArrayPlainValuesWriter.java": [
                2,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/values/plain/PlainValuesReader.java": [
                3,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/values/plain/PlainValuesWriter.java": [
                3,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/values/rle/RunLengthBitPackingHybridDecoder.java": [
                2,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/values/rle/RunLengthBitPackingHybridEncoder.java": [
                3,
                1
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/values/rle/RunLengthBitPackingHybridValuesReader.java": [
                2,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/values/rle/RunLengthBitPackingHybridValuesWriter.java": [
                3,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/example/DummyRecordConverter.java": [
                3,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/example/Paper.java": [
                3,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/filter/AndRecordFilter.java": [
                2,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/filter/NotRecordFilter.java": [
                2,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/filter/OrRecordFilter.java": [
                2,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/filter/RecordFilter.java": [
                2,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/filter/UnboundRecordFilter.java": [
                2,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/filter2/compat/FilterCompat.java": [
                4,
                14
            ],
            "parquet-column/src/main/java/org/apache/parquet/filter2/predicate/FilterApi.java": [
                9,
                72
            ],
            "parquet-column/src/main/java/org/apache/parquet/filter2/predicate/FilterPredicate.java": [
                0,
                4
            ],
            "parquet-column/src/main/java/org/apache/parquet/filter2/predicate/LogicalInverseRewriter.java": [
                1,
                1
            ],
            "parquet-column/src/main/java/org/apache/parquet/filter2/predicate/Statistics.java": [
                0,
                16
            ],
            "parquet-column/src/main/java/org/apache/parquet/filter2/predicate/UserDefinedPredicate.java": [
                14,
                19
            ],
            "parquet-column/src/main/java/org/apache/parquet/filter2/predicate/ValidTypeMap.java": [
                1,
                2
            ],
            "parquet-column/src/main/java/org/apache/parquet/filter2/recordlevel/IncrementallyUpdatedFilterPredicate.java": [
                0,
                9
            ],
            "parquet-column/src/main/java/org/apache/parquet/filter2/recordlevel/IncrementallyUpdatedFilterPredicateBuilderBase.java": [
                1,
                1
            ],
            "parquet-column/src/main/java/org/apache/parquet/io/ColumnIO.java": [
                3,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/io/ColumnIOFactory.java": [
                3,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/io/CompilationException.java": [
                3,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/io/EmptyRecordReader.java": [
                2,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/io/FilteredRecordReader.java": [
                2,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/io/GroupColumnIO.java": [
                4,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/io/InvalidRecordException.java": [
                3,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/io/MessageColumnIO.java": [
                3,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/io/ParquetDecodingException.java": [
                3,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/io/ParquetEncodingException.java": [
                3,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/io/PrimitiveColumnIO.java": [
                4,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/io/RecordConsumerLoggingWrapper.java": [
                3,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/io/RecordReader.java": [
                1,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/io/RecordReaderImplementation.java": [
                1,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/io/ValidatingRecordConsumer.java": [
                3,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/io/api/Converter.java": [
                3,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/io/api/GroupConverter.java": [
                3,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/io/api/PrimitiveConverter.java": [
                4,
                1
            ],
            "parquet-column/src/main/java/org/apache/parquet/io/api/RecordConsumer.java": [
                2,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/io/api/RecordMaterializer.java": [
                2,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/schema/GroupType.java": [
                3,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/schema/IncompatibleSchemaModificationException.java": [
                3,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/schema/MessageType.java": [
                3,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/schema/MessageTypeParser.java": [
                2,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/schema/PrimitiveType.java": [
                6,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/schema/Type.java": [
                5,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/schema/TypeConverter.java": [
                2,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/schema/TypeVisitor.java": [
                3,
                0
            ],
            "parquet-column/src/test/java/org/apache/parquet/column/values/RandomStr.java": [
                5,
                0
            ],
            "parquet-column/src/test/java/org/apache/parquet/column/values/Utils.java": [
                3,
                0
            ],
            "parquet-column/src/test/java/org/apache/parquet/column/values/bitpacking/BitPackingPerfTest.java": [
                2,
                0
            ],
            "parquet-column/src/test/java/org/apache/parquet/column/values/rle/RunLengthBitPackingHybridIntegrationTest.java": [
                3,
                0
            ],
            "parquet-column/src/test/java/org/apache/parquet/column/values/rle/TestRunLengthBitPackingHybridEncoder.java": [
                3,
                0
            ],
            "parquet-column/src/test/java/org/apache/parquet/io/PerfTest.java": [
                4,
                0
            ],
            "parquet-common/src/main/java/org/apache/parquet/Ints.java": [
                2,
                0
            ],
            "parquet-common/src/main/java/org/apache/parquet/Log.java": [
                3,
                0
            ],
            "parquet-common/src/main/java/org/apache/parquet/ParquetRuntimeException.java": [
                3,
                0
            ],
            "parquet-common/src/main/java/org/apache/parquet/Preconditions.java": [
                3,
                0
            ],
            "parquet-common/src/main/java/org/apache/parquet/bytes/BytesInput.java": [
                3,
                0
            ],
            "parquet-common/src/main/java/org/apache/parquet/bytes/BytesUtils.java": [
                3,
                0
            ],
            "parquet-common/src/main/java/org/apache/parquet/bytes/CapacityByteArrayOutputStream.java": [
                3,
                0
            ],
            "parquet-common/src/main/java/org/apache/parquet/bytes/LittleEndianDataInputStream.java": [
                3,
                0
            ],
            "parquet-common/src/main/java/org/apache/parquet/bytes/LittleEndianDataOutputStream.java": [
                3,
                0
            ],
            "parquet-common/src/main/java/org/apache/parquet/hadoop/metadata/Canonicalizer.java": [
                1,
                0
            ],
            "parquet-encoding/src/main/java/org/apache/parquet/column/values/bitpacking/BitPacking.java": [
                9,
                0
            ],
            "parquet-encoding/src/main/java/org/apache/parquet/column/values/bitpacking/ByteBasedBitPackingEncoder.java": [
                3,
                0
            ],
            "parquet-encoding/src/main/java/org/apache/parquet/column/values/bitpacking/BytePacker.java": [
                3,
                0
            ],
            "parquet-encoding/src/main/java/org/apache/parquet/column/values/bitpacking/BytePackerForLong.java": [
                3,
                0
            ],
            "parquet-encoding/src/main/java/org/apache/parquet/column/values/bitpacking/IntPacker.java": [
                3,
                0
            ],
            "parquet-encoding/src/main/java/org/apache/parquet/column/values/bitpacking/Packer.java": [
                3,
                0
            ],
            "parquet-generator/src/main/java/org/apache/parquet/encoding/Generator.java": [
                3,
                0
            ],
            "parquet-generator/src/main/java/org/apache/parquet/encoding/bitpacking/ByteBasedBitPackingGenerator.java": [
                4,
                1
            ],
            "parquet-generator/src/main/java/org/apache/parquet/encoding/bitpacking/IntBasedBitPackingGenerator.java": [
                4,
                1
            ],
            "parquet-generator/src/main/java/org/apache/parquet/filter2/IncrementallyUpdatedFilterPredicateGenerator.java": [
                1,
                1
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/filter2/compat/RowGroupFilter.java": [
                0,
                4
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/format/converter/ParquetMetadataConverter.java": [
                7,
                13
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/BadConfigurationException.java": [
                3,
                0
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/CodecFactory.java": [
                3,
                1
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/Footer.java": [
                4,
                0
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ParquetFileReader.java": [
                42,
                75
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ParquetFileWriter.java": [
                23,
                43
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ParquetInputFormat.java": [
                6,
                12
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ParquetInputSplit.java": [
                15,
                17
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ParquetOutputFormat.java": [
                2,
                4
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ParquetReader.java": [
                5,
                5
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ParquetRecordReader.java": [
                3,
                1
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ParquetRecordWriter.java": [
                2,
                5
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ParquetWriter.java": [
                12,
                16
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/PrintFooter.java": [
                2,
                0
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/api/DelegatingReadSupport.java": [
                3,
                1
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/api/DelegatingWriteSupport.java": [
                3,
                1
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/api/InitContext.java": [
                3,
                0
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/api/ReadSupport.java": [
                5,
                0
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/api/WriteSupport.java": [
                8,
                0
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/codec/CodecConfig.java": [
                2,
                0
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/example/ExampleInputFormat.java": [
                3,
                0
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/example/ExampleOutputFormat.java": [
                6,
                2
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/mapred/Container.java": [
                2,
                2
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/mapred/MapredParquetOutputCommitter.java": [
                3,
                0
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/metadata/BlockMetaData.java": [
                3,
                0
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/metadata/ColumnChunkMetaData.java": [
                1,
                0
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/metadata/FileMetaData.java": [
                3,
                0
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/metadata/GlobalMetaData.java": [
                3,
                0
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/metadata/ParquetMetadata.java": [
                3,
                0
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/util/ContextUtil.java": [
                1,
                20
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/util/SerializationUtil.java": [
                5,
                5
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/util/counters/BenchmarkCounter.java": [
                5,
                3
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/util/counters/CounterLoader.java": [
                1,
                0
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/util/counters/ICounter.java": [
                1,
                0
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/util/counters/mapred/MapRedCounterAdapter.java": [
                1,
                0
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/util/counters/mapred/MapRedCounterLoader.java": [
                1,
                0
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/util/counters/mapreduce/MapReduceCounterAdapter.java": [
                1,
                0
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/util/counters/mapreduce/MapReduceCounterLoader.java": [
                1,
                0
            ],
            "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/DeprecatedInputFormatTest.java": [
                1,
                0
            ],
            "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/DeprecatedOutputFormatTest.java": [
                1,
                0
            ],
            "parquet-hive/parquet-hive-binding/parquet-hive-binding-interface/src/main/java/org/apache/parquet/hive/HiveBinding.java": [
                3,
                3
            ],
            "parquet-hive/parquet-hive-storage-handler/src/main/java/org/apache/hadoop/hive/ql/io/parquet/read/DataWritableReadSupport.java": [
                3,
                1
            ],
            "parquet-hive/parquet-hive-storage-handler/src/main/java/org/apache/hadoop/hive/ql/io/parquet/serde/ArrayWritableObjectInspector.java": [
                3,
                2
            ],
            "parquet-hive/parquet-hive-storage-handler/src/main/java/org/apache/hadoop/hive/ql/io/parquet/serde/DeepParquetHiveMapInspector.java": [
                4,
                5
            ],
            "parquet-hive/parquet-hive-storage-handler/src/main/java/org/apache/hadoop/hive/ql/io/parquet/serde/ParquetHiveArrayInspector.java": [
                2,
                2
            ],
            "parquet-hive/parquet-hive-storage-handler/src/main/java/org/apache/hadoop/hive/ql/io/parquet/serde/StandardParquetHiveMapInspector.java": [
                2,
                2
            ],
            "parquet-pig/src/main/java/org/apache/parquet/pig/ParquetLoader.java": [
                6,
                1
            ],
            "parquet-pig/src/main/java/org/apache/parquet/pig/ParquetStorer.java": [
                3,
                0
            ],
            "parquet-pig/src/main/java/org/apache/parquet/pig/PigMetaData.java": [
                3,
                0
            ],
            "parquet-pig/src/main/java/org/apache/parquet/pig/PigSchemaConverter.java": [
                4,
                0
            ],
            "parquet-pig/src/main/java/org/apache/parquet/pig/SchemaConversionException.java": [
                3,
                0
            ],
            "parquet-pig/src/main/java/org/apache/parquet/pig/TupleReadSupport.java": [
                3,
                0
            ],
            "parquet-pig/src/main/java/org/apache/parquet/pig/convert/MapConverter.java": [
                11,
                0
            ],
            "parquet-pig/src/main/java/org/apache/parquet/pig/convert/ParentValueContainer.java": [
                3,
                0
            ],
            "parquet-pig/src/main/java/org/apache/parquet/pig/convert/TupleConverter.java": [
                23,
                0
            ],
            "parquet-pig/src/main/java/org/apache/parquet/pig/summary/BagSummaryData.java": [
                8,
                0
            ],
            "parquet-pig/src/main/java/org/apache/parquet/pig/summary/FieldSummaryData.java": [
                6,
                0
            ],
            "parquet-pig/src/main/java/org/apache/parquet/pig/summary/MapSummaryData.java": [
                7,
                0
            ],
            "parquet-pig/src/main/java/org/apache/parquet/pig/summary/NumberSummaryData.java": [
                3,
                0
            ],
            "parquet-pig/src/main/java/org/apache/parquet/pig/summary/StringSummaryData.java": [
                3,
                0
            ],
            "parquet-pig/src/main/java/org/apache/parquet/pig/summary/Summary.java": [
                3,
                0
            ],
            "parquet-pig/src/main/java/org/apache/parquet/pig/summary/SummaryData.java": [
                16,
                0
            ],
            "parquet-pig/src/main/java/org/apache/parquet/pig/summary/TupleSummaryData.java": [
                8,
                0
            ],
            "parquet-pig/src/test/java/org/apache/parquet/pig/PerfTest.java": [
                4,
                0
            ],
            "parquet-pig/src/test/java/org/apache/parquet/pig/PerfTest2.java": [
                4,
                0
            ],
            "parquet-pig/src/test/java/org/apache/parquet/pig/PerfTestReadAllCols.java": [
                4,
                0
            ],
            "parquet-pig/src/test/java/org/apache/parquet/pig/TupleConsumerPerfTest.java": [
                6,
                0
            ],
            "parquet-protobuf/src/main/java/org/apache/parquet/proto/ProtoMessageConverter.java": [
                3,
                0
            ],
            "parquet-protobuf/src/main/java/org/apache/parquet/proto/ProtoParquetOutputFormat.java": [
                6,
                1
            ],
            "parquet-protobuf/src/main/java/org/apache/parquet/proto/ProtoParquetReader.java": [
                0,
                5
            ],
            "parquet-protobuf/src/main/java/org/apache/parquet/proto/ProtoParquetWriter.java": [
                7,
                10
            ],
            "parquet-protobuf/src/main/java/org/apache/parquet/proto/ProtoReadSupport.java": [
                4,
                4
            ],
            "parquet-protobuf/src/main/java/org/apache/parquet/proto/ProtoRecordConverter.java": [
                1,
                2
            ],
            "parquet-protobuf/src/main/java/org/apache/parquet/proto/ProtoSchemaConverter.java": [
                3,
                0
            ],
            "parquet-protobuf/src/main/java/org/apache/parquet/proto/ProtoWriteSupport.java": [
                1,
                0
            ],
            "parquet-scrooge/src/main/java/org/apache/parquet/scrooge/ScroogeReadSupport.java": [
                1,
                0
            ],
            "parquet-scrooge/src/main/java/org/apache/parquet/scrooge/ScroogeRecordConverter.java": [
                0,
                3
            ],
            "parquet-scrooge/src/main/java/org/apache/parquet/scrooge/ScroogeStructConverter.java": [
                2,
                6
            ],
            "parquet-scrooge/src/test/java/org/apache/parquet/scrooge/ParquetScroogeSchemeTest.java": [
                2,
                0
            ],
            "parquet-thrift/src/main/java/org/apache/parquet/hadoop/thrift/AbstractThriftWriteSupport.java": [
                1,
                0
            ],
            "parquet-thrift/src/main/java/org/apache/parquet/hadoop/thrift/ParquetThriftBytesOutputFormat.java": [
                4,
                0
            ],
            "parquet-thrift/src/main/java/org/apache/parquet/hadoop/thrift/ParquetThriftInputFormat.java": [
                5,
                7
            ],
            "parquet-thrift/src/main/java/org/apache/parquet/hadoop/thrift/ParquetThriftOutputFormat.java": [
                3,
                0
            ],
            "parquet-thrift/src/main/java/org/apache/parquet/hadoop/thrift/ThriftReadSupport.java": [
                0,
                5
            ],
            "parquet-thrift/src/main/java/org/apache/parquet/hadoop/thrift/ThriftToParquetFileWriter.java": [
                6,
                4
            ],
            "parquet-thrift/src/main/java/org/apache/parquet/thrift/BufferedProtocolReadToWrite.java": [
                4,
                1
            ],
            "parquet-thrift/src/main/java/org/apache/parquet/thrift/ConvertedField.java": [
                0,
                2
            ],
            "parquet-thrift/src/main/java/org/apache/parquet/thrift/FieldIgnoredHandler.java": [
                2,
                1
            ],
            "parquet-thrift/src/main/java/org/apache/parquet/thrift/ParquetProtocol.java": [
                3,
                0
            ],
            "parquet-thrift/src/main/java/org/apache/parquet/thrift/ProtocolPipe.java": [
                3,
                0
            ],
            "parquet-thrift/src/main/java/org/apache/parquet/thrift/ProtocolReadToWrite.java": [
                4,
                1
            ],
            "parquet-thrift/src/main/java/org/apache/parquet/thrift/SkippableException.java": [
                3,
                0
            ],
            "parquet-thrift/src/main/java/org/apache/parquet/thrift/TBaseRecordConverter.java": [
                0,
                3
            ],
            "parquet-thrift/src/main/java/org/apache/parquet/thrift/ThriftMetaData.java": [
                4,
                0
            ],
            "parquet-thrift/src/main/java/org/apache/parquet/thrift/ThriftParquetReader.java": [
                5,
                7
            ],
            "parquet-thrift/src/main/java/org/apache/parquet/thrift/ThriftParquetWriter.java": [
                2,
                0
            ],
            "parquet-thrift/src/main/java/org/apache/parquet/thrift/ThriftRecordConverter.java": [
                34,
                5
            ],
            "parquet-thrift/src/main/java/org/apache/parquet/thrift/ThriftSchemaConvertVisitor.java": [
                2,
                0
            ],
            "parquet-thrift/src/main/java/org/apache/parquet/thrift/ThriftSchemaConverter.java": [
                0,
                6
            ],
            "parquet-thrift/src/main/java/org/apache/parquet/thrift/pig/ParquetThriftStorer.java": [
                3,
                0
            ],
            "parquet-thrift/src/main/java/org/apache/parquet/thrift/pig/TupleToThriftWriteSupport.java": [
                3,
                0
            ],
            "parquet-thrift/src/main/java/org/apache/parquet/thrift/projection/FieldsPath.java": [
                2,
                0
            ],
            "parquet-thrift/src/main/java/org/apache/parquet/thrift/projection/StrictFieldProjectionFilter.java": [
                2,
                6
            ],
            "parquet-thrift/src/main/java/org/apache/parquet/thrift/projection/ThriftProjectionException.java": [
                3,
                0
            ],
            "parquet-thrift/src/main/java/org/apache/parquet/thrift/projection/amend/ProtocolEventsAmender.java": [
                4,
                2
            ],
            "parquet-thrift/src/main/java/org/apache/parquet/thrift/projection/deprecated/DeprecatedFieldProjectionFilter.java": [
                1,
                0
            ],
            "parquet-thrift/src/main/java/org/apache/parquet/thrift/projection/deprecated/PathGlobPattern.java": [
                2,
                0
            ],
            "parquet-thrift/src/main/java/org/apache/parquet/thrift/struct/CompatibilityChecker.java": [
                2,
                0
            ],
            "parquet-thrift/src/main/java/org/apache/parquet/thrift/struct/CompatibilityRunner.java": [
                2,
                0
            ],
            "parquet-thrift/src/main/java/org/apache/parquet/thrift/struct/ThriftType.java": [
                3,
                0
            ],
            "parquet-thrift/src/main/java/org/apache/parquet/thrift/struct/ThriftTypeID.java": [
                3,
                0
            ]
        }
    },
    "ce4d1c96a9c7e5a08ebd69943249ccd6b01a3f6d": {
        "datetime": "2018-04-05T13:17:12-07:00",
        "summary": "PARQUET-1258: Update scm developer connection to github HTTPS.",
        "message": "PARQUET-1258: Update scm developer connection to github HTTPS.\n",
        "diff": {
            "pom.xml": null
        }
    },
    "031a6654009e3b82020012a18434c582bd74c73a": {
        "datetime": "2018-04-05T13:36:12-07:00",
        "summary": "[maven-release-plugin] prepare release apache-parquet-1.10.0",
        "message": "[maven-release-plugin] prepare release apache-parquet-1.10.0\n",
        "diff": {
            "parquet-arrow/pom.xml": null,
            "parquet-avro/pom.xml": null,
            "parquet-benchmarks/pom.xml": null,
            "parquet-cascading/pom.xml": null,
            "parquet-cascading3/pom.xml": null,
            "parquet-cli/pom.xml": null,
            "parquet-column/pom.xml": null,
            "parquet-common/pom.xml": null,
            "parquet-encoding/pom.xml": null,
            "parquet-generator/pom.xml": null,
            "parquet-hadoop-bundle/pom.xml": null,
            "parquet-hadoop/pom.xml": null,
            "parquet-hive-bundle/pom.xml": null,
            "parquet-hive/parquet-hive-binding/parquet-hive-0.10-binding/pom.xml": null,
            "parquet-hive/parquet-hive-binding/parquet-hive-0.12-binding/pom.xml": null,
            "parquet-hive/parquet-hive-binding/parquet-hive-binding-bundle/pom.xml": null,
            "parquet-hive/parquet-hive-binding/parquet-hive-binding-factory/pom.xml": null,
            "parquet-hive/parquet-hive-binding/parquet-hive-binding-interface/pom.xml": null,
            "parquet-hive/parquet-hive-binding/pom.xml": null,
            "parquet-hive/parquet-hive-storage-handler/pom.xml": null,
            "parquet-hive/pom.xml": null,
            "parquet-jackson/pom.xml": null,
            "parquet-pig-bundle/pom.xml": null,
            "parquet-pig/pom.xml": null,
            "parquet-protobuf/pom.xml": null,
            "parquet-scala/pom.xml": null,
            "parquet-scrooge/pom.xml": null,
            "parquet-thrift/pom.xml": null,
            "parquet-tools/pom.xml": null,
            "pom.xml": null
        }
    },
    "f93711241d528e1026916617d562d010b8e740f5": {
        "datetime": "2018-04-05T13:36:32-07:00",
        "summary": "[maven-release-plugin] prepare for next development iteration",
        "message": "[maven-release-plugin] prepare for next development iteration\n",
        "diff": {
            "parquet-arrow/pom.xml": null,
            "parquet-avro/pom.xml": null,
            "parquet-benchmarks/pom.xml": null,
            "parquet-cascading/pom.xml": null,
            "parquet-cascading3/pom.xml": null,
            "parquet-cli/pom.xml": null,
            "parquet-column/pom.xml": null,
            "parquet-common/pom.xml": null,
            "parquet-encoding/pom.xml": null,
            "parquet-generator/pom.xml": null,
            "parquet-hadoop-bundle/pom.xml": null,
            "parquet-hadoop/pom.xml": null,
            "parquet-hive-bundle/pom.xml": null,
            "parquet-hive/parquet-hive-binding/parquet-hive-0.10-binding/pom.xml": null,
            "parquet-hive/parquet-hive-binding/parquet-hive-0.12-binding/pom.xml": null,
            "parquet-hive/parquet-hive-binding/parquet-hive-binding-bundle/pom.xml": null,
            "parquet-hive/parquet-hive-binding/parquet-hive-binding-factory/pom.xml": null,
            "parquet-hive/parquet-hive-binding/parquet-hive-binding-interface/pom.xml": null,
            "parquet-hive/parquet-hive-binding/pom.xml": null,
            "parquet-hive/parquet-hive-storage-handler/pom.xml": null,
            "parquet-hive/pom.xml": null,
            "parquet-jackson/pom.xml": null,
            "parquet-pig-bundle/pom.xml": null,
            "parquet-pig/pom.xml": null,
            "parquet-protobuf/pom.xml": null,
            "parquet-scala/pom.xml": null,
            "parquet-scrooge/pom.xml": null,
            "parquet-thrift/pom.xml": null,
            "parquet-tools/pom.xml": null,
            "pom.xml": null
        }
    },
    "af977adc43a071a09652fea4ce3deba2d5b8d171": {
        "datetime": "2018-04-21T14:58:35+01:00",
        "summary": "PARQUET-1128: [Java] Upgrade the Apache Arrow version to 0.8.0 for SchemaConverter",
        "message": "PARQUET-1128: [Java] Upgrade the Apache Arrow version to 0.8.0 for SchemaConverter\n\nWhen I converted parquet(1.9.1-SNAPSHOT) schema to arrow(0.4.0) with SchemaConverter, this exception raised.\n```\njava.lang.NoClassDefFoundError: org/apache/arrow/vector/types/pojo/ArrowType$Struct_\n\n\tat net.wrap_trap.parquet_arrow.ParquetToArrowConverter.convertToArrow(ParquetToArrowConverter.java:67)\n\tat net.wrap_trap.parquet_arrow.ParquetToArrowConverter.convertToArrow(ParquetToArrowConverter.java:40)\n\tat net.wrap_trap.parquet_arrow.ParquetToArrowConverterTest.parquetToArrowConverterTest(ParquetToArrowConverterTest.java:27)\n```\n\nThis reason is that SchemaConverter refer to Apache Arrow 0.1.0.\nI upgrade the Apache Arrow version to 0.8.0(latest) for SchemaConverter.\n\nAuthor: Masayuki Takahashi <masayuki038@gmail.com>\n\nCloses #443 from masayuki038/PARQUET-1128 and squashes the following commits:\n\n8ba47813 [Masayuki Takahashi] PARQUET-1128: [Java] Upgrade the Apache Arrow version to 0.8.0 for SchemaConverter\nb80d793a [Masayuki Takahashi] PARQUET-1128: [Java] Upgrade the Apache Arrow version to 0.8.0 for SchemaConverter\n",
        "diff": {
            "parquet-arrow/pom.xml": null,
            "parquet-arrow/src/main/java/org/apache/parquet/arrow/schema/SchemaConverter.java": [
                105,
                122
            ],
            "parquet-arrow/src/test/java/org/apache/parquet/arrow/schema/TestSchemaConverter.java": [
                169,
                177
            ]
        }
    },
    "f84938441be49c665595c936ac631c3e5f171bf9": {
        "datetime": "2018-04-26T08:48:08-04:00",
        "summary": "PARQUET-968 Add Hive/Presto support in ProtoParquet",
        "message": "PARQUET-968 Add Hive/Presto support in ProtoParquet\n\nThis PR adds Hive (https://github.com/apache/hive) and Presto (https://github.com/prestodb/presto) support for parquet messages written with ProtoParquetWriter. Hive and other tools, such as Presto (used by AWS Athena), rely on specific LIST/MAP wrappers (as defined in the parquet spec: https://github.com/apache/parquet-format/blob/master/LogicalTypes.md). These wrappers are currently missing from the ProtoParquet schema. AvroParquet works just fine, because it adds these wrappers when it deals with arrays and maps. This PR brings these wrappers in parquet-proto, providing the same functionality that already exists in parquet-avro.\n\nThis is backward compatible. Messages written without the extra LIST/MAP wrappers are still being read successfully using the updated ProtoParquetReader.\n\nRegarding the change.\nGiven the following protobuf schema:\n\n```\nmessage ListOfPrimitives {\n    repeated int64 my_repeated_id = 1;\n}\n```\n\nOld parquet schema was:\n```\nmessage ListOfPrimitives {\n  repeated int64 my_repeated_id = 1;\n}\n```\n\nNew parquet schema is:\n```\nmessage ListOfPrimitives {\n  required group my_repeated_id (LIST) = 1 {\n    repeated group list {\n      required int64 element;\n    }\n  }\n}\n```\n---\n\nFor list of messages, the changes look like this:\n\nProtobuf schema:\n```\nmessage ListOfMessages {\n    string top_field = 1;\n    repeated MyInnerMessage first_array = 2;\n}\n\nmessage MyInnerMessage {\n    int32 inner_field = 1;\n}\n```\n\nOld parquet schema was:\n```\nmessage TestProto3.ListOfMessages {\n  optional binary top_field (UTF8) = 1;\n  repeated group first_array = 2 {\n    optional int32 inner_field = 1;\n  }\n}\n```\n\nThe expected parquet schema, compatible with Hive (and similar to parquet-avro) is the following (notice the LIST wrapper):\n\n```\nmessage TestProto3.ListOfMessages {\n  optional binary top_field (UTF8) = 1;\n  required group first_array (LIST) = 2 {\n    repeated group list {\n      optional group element {\n        optional int32 inner_field = 1;\n      }\n    }\n  }\n}\n```\n\n---\n\nSimilar for maps. Protobuf schema:\n```\nmessage TopMessage {\n    map<int64, MyInnerMessage> myMap = 1;\n}\n\nmessage MyInnerMessage {\n    int32 inner_field = 1;\n}\n```\n\nOld parquet schema:\n```\nmessage TestProto3.TopMessage {\n  repeated group myMap = 1 {\n    optional int64 key = 1;\n    optional group value = 2 {\n      optional int32 inner_field = 1;\n    }\n  }\n}\n```\n\nNew parquet schema (notice the `MAP` wrapper):\n```\nmessage TestProto3.TopMessage {\n  required group myMap (MAP) = 1 {\n    repeated group key_value {\n      required int64 key;\n      optional group value {\n        optional int32 inner_field = 1;\n      }\n    }\n  }\n}\n```\n\nJira: https://issues.apache.org/jira/browse/PARQUET-968\n\nAuthor: Constantin Muraru <cmuraru@adobe.com>\nAuthor: Beno\u00eet Hanotte <BenoitHanotte@users.noreply.github.com>\n\nCloses #411 from costimuraru/PARQUET-968 and squashes the following commits:\n\n16eafcb6 [Beno\u00eet Hanotte] PARQUET-968 add proto flag to enable writing using specs-compliant schemas (#2)\na8bd7041 [Constantin Muraru] Pick up commit from @andredasilvapinto\n5cf92487 [Constantin Muraru] PARQUET-968 Add Hive support in ProtoParquet\n",
        "diff": {
            "parquet-protobuf/src/main/java/org/apache/parquet/proto/ProtoMessageConverter.java": [
                1,
                125
            ],
            "parquet-protobuf/src/main/java/org/apache/parquet/proto/ProtoSchemaConverter.java": [
                36,
                133
            ],
            "parquet-protobuf/src/main/java/org/apache/parquet/proto/ProtoWriteSupport.java": [
                30,
                160
            ],
            "parquet-protobuf/src/test/java/org/apache/parquet/proto/ProtoInputOutputFormatTest.java": [
                0,
                120
            ],
            "parquet-protobuf/src/test/java/org/apache/parquet/proto/ProtoSchemaConverterTest.java": [
                14,
                205
            ],
            "parquet-protobuf/src/test/java/org/apache/parquet/proto/ProtoWriteSupportTest.java": [
                40,
                601
            ],
            "parquet-protobuf/src/test/java/org/apache/parquet/proto/utils/WriteUsingMR.java": [
                1,
                9
            ],
            "parquet-protobuf/src/test/resources/TestProto3.proto": null,
            "parquet-protobuf/src/test/resources/TestProtobuf.proto": null
        }
    },
    "e021734b62ea5ac273e516b4ac83727cbb99ec08": {
        "datetime": "2018-05-07T10:11:58+02:00",
        "summary": "PARQUET-1285: [Java] SchemaConverter should not convert from TimeUnit.SECOND and TimeUnit.NANOSECOND of Arrow (#469)",
        "message": "PARQUET-1285: [Java] SchemaConverter should not convert from TimeUnit.SECOND and TimeUnit.NANOSECOND of Arrow (#469)\n\n* PARQUET-1285: [Java] SchemaConverter should not convert from TimeUnit.SECOND AND TimeUnit.NANOSECOND of Arrow\r\n\r\nArrow's 'Time' definition is below:\r\n\r\n{ \"name\" : \"time\", \"unit\" : \"SECOND|MILLISECOND|MICROSECOND|NANOSECOND\", \"bitWidth\": /* integer: 32 or 64 */ }\r\nhttp://arrow.apache.org/docs/metadata.html\r\n\r\nBut Parquet only supports 'TIME_MILLIS' and 'TIME_MICROS'.\r\nhttps://github.com/Apache/parquet-format/blob/master/LogicalTypes.md\r\n\r\nTherefore SchemaConverter should not convert from TimeUnit.SECOND AND TimeUnit.NANOSECOND of Arrow to Parquet.\r\n\r\nAuthor: Masayuki Takahashi <masayuki038@gmail.com>\r\n\r\n* PARQUET-1285: [Java] SchemaConverter should not convert from TimeUnit.SECOND AND TimeUnit.NANOSECOND of Arrow\r\n\r\nSince the import statements were collected, I restored it.\r\n\r\nAuthor: Masayuki Takahashi <masayuki038@gmail.com>\r\n\r\n* PARQUET-1285: [Java] SchemaConverter should not convert from TimeUnit.SECOND AND TimeUnit.NANOSECOND of Arrow\r\n\r\nRemove unnecessary updates.\r\n\r\nAuthor: Masayuki Takahashi <masayuki038@gmail.com>\r\n\r\n* PARQUET-1285: [Java] SchemaConverter should not convert from TimeUnit.SECOND AND TimeUnit.NANOSECOND of Arrow\r\n\r\nRemove unnecessary package name\r\n\r\nAuthor: Masayuki Takahashi <masayuki038@gmail.com>\r\n\r\n* PARQUET-1285: [Java] SchemaConverter should not convert from TimeUnit.SECOND AND TimeUnit.NANOSECOND of Arrow\r\n\r\nAdd a conversion pattern from Parquet's TIME_MICROS  to Arrow's MICROSECOND\r\n\r\nAuthor: Masayuki Takahashi <masayuki038@gmail.com>\r\n\r\n* PARQUET-1285: [Java] SchemaConverter should not convert from TimeUnit.SECOND AND TimeUnit.NANOSECOND of Arrow\r\n\r\nFix to specify `expected` positions in assertEquals\r\n\r\nAuthor: Masayuki Takahashi <masayuki038@gmail.com>\r\n\r\n* PARQUET-1285: [Java] SchemaConverter should not convert from TimeUnit.SECOND AND TimeUnit.NANOSECOND of Arrow\r\n\r\nAdd a test to convert from Parquet's TIME_MICROS  to Arrow's MICROSECOND\r\n\r\nAuthor: Masayuki Takahashi <masayuki038@gmail.com>\r\n",
        "diff": {
            "parquet-arrow/src/main/java/org/apache/parquet/arrow/schema/SchemaConverter.java": [
                7,
                17
            ],
            "parquet-arrow/src/test/java/org/apache/parquet/arrow/schema/TestSchemaConverter.java": [
                7,
                72
            ]
        }
    },
    "9fa86cca1af7dabc21701247efd89f6085945bd2": {
        "datetime": "2018-05-10T13:27:51+02:00",
        "summary": "PARQUET-1293: Build failure when using Java 8 lambda expressions",
        "message": "PARQUET-1293: Build failure when using Java 8 lambda expressions\n",
        "diff": {
            "pom.xml": null
        }
    },
    "b635beb6efc07a97c143775c78a32d42b3b73c8e": {
        "datetime": "2018-05-13T19:31:02+02:00",
        "summary": "PARQUET-1297: SchemaConverter should not convert from Timestamp(TimeUnit.SECOND) and Timestamp(TimeUnit.NANOSECOND) of Arrow (#477)",
        "message": "PARQUET-1297: SchemaConverter should not convert from Timestamp(TimeUnit.SECOND) and Timestamp(TimeUnit.NANOSECOND) of Arrow (#477)\n\nArrow's 'Timestamp' definition is below:\r\n{\r\n  \"name\" : \"timestamp\",\r\n  \"unit\" : \"SECOND|MILLISECOND|MICROSECOND|NANOSECOND\"\r\n}\r\nhttp://arrow.apache.org/docs/metadata.html\r\n\r\nBut Parquet only supports 'TIMESTAMP_MILLIS' and 'TIMESTAMP_MICROS'.\r\n https://github.com/Apache/parquet-format/blob/master/LogicalTypes.md\r\n\r\nTherefore SchemaConverter should not convert from Timestamp(TimeUnit.SECOND) and Timestamp(TimeUnit.NANOSECOND) of Arrow to Parquet.\r\n\r\nRelated:\r\nhttps://issues.apache.org/jira/browse/PARQUET-1285\r\n\r\nAuthor: Masayuki Takahashi <masayuki038@gmail.com>",
        "diff": {
            "parquet-arrow/src/main/java/org/apache/parquet/arrow/schema/SchemaConverter.java": [
                6,
                11
            ],
            "parquet-arrow/src/test/java/org/apache/parquet/arrow/schema/TestSchemaConverter.java": [
                0,
                63
            ]
        }
    },
    "cab63690283db8b25e9d17141369a8735d11c511": {
        "datetime": "2018-05-15T21:19:56+02:00",
        "summary": "PARQUET-1296: Travis kills build after 10 minutes, because \"no output was received\"",
        "message": "PARQUET-1296: Travis kills build after 10 minutes, because \"no output was received\"\n\nUse pv to periodically print progress for Travis to prevent timeout due to lack of output.",
        "diff": {
            ".travis.yml": null
        }
    },
    "a287522ad677e8453ff931a2811b48a05d34072f": {
        "datetime": "2018-05-17T12:56:15+02:00",
        "summary": "PARQUET-1294: Update release scripts for the new Apache policy (#475)",
        "message": "PARQUET-1294: Update release scripts for the new Apache policy (#475)\n\n",
        "diff": {
            "dev/source-release.sh": null
        }
    },
    "94a8bf6d304d08e8a1fc181e7a06a545103e8ddb": {
        "datetime": "2018-05-24T13:46:11+02:00",
        "summary": "PARQUET-1253: Support for new logical type representation (#463)",
        "message": "PARQUET-1253: Support for new logical type representation (#463)\n\n",
        "diff": {
            "parquet-cascading3/src/test/java/org/apache/parquet/cascading/TestParquetTBaseScheme.java": [
                4,
                3
            ],
            "parquet-column/src/main/java/org/apache/parquet/schema/GroupType.java": [
                4,
                13
            ],
            "parquet-column/src/main/java/org/apache/parquet/schema/LogicalTypeAnnotation.java": [
                0,
                878
            ],
            "parquet-column/src/main/java/org/apache/parquet/schema/MessageTypeParser.java": [
                15,
                40
            ],
            "parquet-column/src/main/java/org/apache/parquet/schema/PrimitiveType.java": [
                18,
                46
            ],
            "parquet-column/src/main/java/org/apache/parquet/schema/Type.java": [
                10,
                30
            ],
            "parquet-column/src/main/java/org/apache/parquet/schema/Types.java": [
                14,
                65
            ],
            "parquet-column/src/test/java/org/apache/parquet/parser/TestParquetParser.java": [
                4,
                42
            ],
            "parquet-column/src/test/java/org/apache/parquet/schema/TestTypeBuilders.java": [
                3,
                44
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/format/converter/ParquetMetadataConverter.java": [
                82,
                256
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/metadata/ParquetMetadata.java": [
                5,
                10
            ],
            "parquet-hadoop/src/test/java/org/apache/parquet/format/converter/TestParquetMetadataConverter.java": [
                6,
                12
            ],
            "parquet-pig/src/main/java/org/apache/parquet/pig/PigSchemaConverter.java": [
                3,
                3
            ]
        }
    },
    "345e2d541128471641e76aaa44dd5046f199197d": {
        "datetime": "2018-05-31T16:38:43+02:00",
        "summary": "PARQUET-1304: Release 1.10 contains breaking changes for Hive (#485)",
        "message": "PARQUET-1304: Release 1.10 contains breaking changes for Hive (#485)\n\n",
        "diff": {
            "parquet-column/src/main/java/org/apache/parquet/column/values/ValuesReader.java": [
                0,
                70
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/values/bitpacking/BitPackingValuesReader.java": [
                0,
                1
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/values/bitpacking/ByteBitPackingValuesReader.java": [
                0,
                1
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/values/delta/DeltaBinaryPackingValuesReader.java": [
                0,
                2
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/values/plain/BooleanPlainValuesReader.java": [
                0,
                6
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/values/rle/RunLengthBitPackingHybridValuesReader.java": [
                0,
                3
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/values/rle/ZeroIntegerValuesReader.java": [
                2,
                1
            ],
            "parquet-column/src/test/java/org/apache/parquet/column/values/delta/DeltaBinaryPackingValuesWriterForIntegerTest.java": [
                0,
                8
            ],
            "parquet-column/src/test/java/org/apache/parquet/column/values/delta/DeltaBinaryPackingValuesWriterForLongTest.java": [
                0,
                8
            ],
            "parquet-column/src/test/java/org/apache/parquet/column/values/dictionary/TestDictionary.java": [
                0,
                5
            ],
            "parquet-common/src/main/java/org/apache/parquet/bytes/ByteBufferInputStream.java": [
                6,
                94
            ],
            "parquet-common/src/main/java/org/apache/parquet/bytes/BytesInput.java": [
                0,
                16
            ],
            "parquet-common/src/main/java/org/apache/parquet/bytes/MultiBufferInputStream.java": [
                1,
                1
            ],
            "parquet-common/src/test/java/org/apache/parquet/bytes/TestByteBufferInputStreams.java": [
                0,
                14
            ],
            "parquet-common/src/test/java/org/apache/parquet/bytes/TestDeprecatedBufferInputStream.java": [
                0,
                152
            ],
            "parquet-common/src/test/java/org/apache/parquet/bytes/TestSingleBufferInputStream.java": [
                1,
                1
            ]
        }
    },
    "aed9097640c7adffe1151b32e86b5efc3702c657": {
        "datetime": "2018-06-04T17:35:47+02:00",
        "summary": "PARQUET-1311: Update README.md (#487)",
        "message": "PARQUET-1311: Update README.md (#487)\n\nparquet-mr documentation was not up to date:\r\n- pointed to broken URLs\r\n- instructed to install old Thrift version\r\n- current version was stated as 1.8.1, although 1.10.0 is already released",
        "diff": {
            "README.md": null,
            "dev/README.md": null
        }
    },
    "3fd2492fcce073f0c36e4d7e23e34881557e6e5e": {
        "datetime": "2018-06-04T17:52:28+02:00",
        "summary": "PARQUET-1317: Fix ParquetMetadataConverter throw NPE (#489)",
        "message": "PARQUET-1317: Fix ParquetMetadataConverter throw NPE (#489)\n\n",
        "diff": {
            "parquet-hadoop/src/main/java/org/apache/parquet/format/converter/ParquetMetadataConverter.java": [
                2,
                2
            ]
        }
    },
    "a918c493296c88da94b36600213c7c188f2589b4": {
        "datetime": "2018-06-04T18:49:17+02:00",
        "summary": "PARQUET-1317: Fix ParquetMetadataConverter throw NPE (#491)",
        "message": "PARQUET-1317: Fix ParquetMetadataConverter throw NPE (#491)\n\nNew test case in TestParquetMetadataConverter to reproduce NPE and ensure backward compatibility",
        "diff": {
            "parquet-hadoop/src/test/java/org/apache/parquet/format/converter/TestParquetMetadataConverter.java": [
                0,
                16
            ]
        }
    },
    "9181e1d536bafedcb3587ca30e5b6e2d66f06bf0": {
        "datetime": "2018-06-05T11:16:05+02:00",
        "summary": "PARQUET-1309: Parquet Java uses incorrect stats and dictionary filter properties (#490)",
        "message": "PARQUET-1309: Parquet Java uses incorrect stats and dictionary filter properties (#490)\n\n",
        "diff": {
            "parquet-hadoop/src/main/java/org/apache/parquet/HadoopReadOptions.java": [
                2,
                2
            ]
        }
    },
    "74d650be63d9632b379d6621dfaecafe52e18f1b": {
        "datetime": "2018-06-06T11:14:13+02:00",
        "summary": "[PARQUET-1135][FOLLOW-UP] Update thrift and protoc version in README.md (#488)",
        "message": "[PARQUET-1135][FOLLOW-UP] Update thrift and protoc version in README.md (#488)\n\n",
        "diff": {
            "README.md": null
        }
    },
    "f2d58718a5c7759d0f46d68ac954bd1d8064d7be": {
        "datetime": "2018-06-12T11:47:43+02:00",
        "summary": "PARQUET-1321: LogicalTypeAnnotation.LogicalTypeAnnotationVisitor#visit methods should have a return value (#493)",
        "message": "PARQUET-1321: LogicalTypeAnnotation.LogicalTypeAnnotationVisitor#visit methods should have a return value (#493)\n\n",
        "diff": {
            "parquet-column/src/main/java/org/apache/parquet/schema/LogicalTypeAnnotation.java": [
                41,
                63
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/format/converter/ParquetMetadataConverter.java": [
                86,
                116
            ]
        }
    },
    "cc8bdf1d13639d12d02170d40cc4890180bbabc5": {
        "datetime": "2018-06-18T09:47:25+02:00",
        "summary": "PARQUET-952: Avro union with single type fails with 'is not a group' (#459)",
        "message": "PARQUET-952: Avro union with single type fails with 'is not a group' (#459)\n\n",
        "diff": {
            "parquet-avro/src/main/java/org/apache/parquet/avro/AvroSchemaConverter.java": [
                8,
                16
            ],
            "parquet-avro/src/test/java/org/apache/parquet/avro/TestReadWrite.java": [
                0,
                31
            ]
        }
    },
    "33ee5497490cbc97f3eabe9ef7a6391e4dbee8bc": {
        "datetime": "2018-06-25T08:24:15+02:00",
        "summary": "PARQUET-1335: Logical type names in parquet-mr are not consistent with parquet-format (#496)",
        "message": "PARQUET-1335: Logical type names in parquet-mr are not consistent with parquet-format (#496)\n\n",
        "diff": {
            "parquet-column/src/main/java/org/apache/parquet/schema/LogicalTypeAnnotation.java": [
                4,
                4
            ],
            "parquet-column/src/test/java/org/apache/parquet/parser/TestParquetParser.java": [
                13,
                13
            ]
        }
    },
    "dc61e510126aaa1a95a46fe39bf1529f394147e9": {
        "datetime": "2018-06-26T09:38:23+02:00",
        "summary": "PARQUET-1336: PrimitiveComparator should implements Serializable (#497)",
        "message": "PARQUET-1336: PrimitiveComparator should implements Serializable (#497)\n\n\r\n",
        "diff": {
            "parquet-column/src/main/java/org/apache/parquet/schema/PrimitiveComparator.java": [
                1,
                3
            ]
        }
    },
    "d320a457a9de67be25a03f79e1695d549a0145f3": {
        "datetime": "2018-07-03T15:24:53-07:00",
        "summary": "PARQUET-1341: Fix null count stats in unsigned-sort columns. (#499)",
        "message": "PARQUET-1341: Fix null count stats in unsigned-sort columns. (#499)\n\n* Fix null count stats in unsigned-sort columns.\r\n* Fix test case for old min/max values and unsigned ordering.\r\n",
        "diff": {
            "parquet-hadoop/src/main/java/org/apache/parquet/format/converter/ParquetMetadataConverter.java": [
                7,
                5
            ],
            "parquet-hadoop/src/test/java/org/apache/parquet/format/converter/TestParquetMetadataConverter.java": [
                1,
                3
            ]
        }
    },
    "94ae6c84d22ed33e158b3cc822ca4a0484c829c9": {
        "datetime": "2018-07-04T13:58:33+02:00",
        "summary": "PARQUET-1344: Type builders don't honor new logical types (#500)",
        "message": "PARQUET-1344: Type builders don't honor new logical types (#500)\n\n* PARQUET-1344: Type builders don't honor new logical types\r\n\r\nCall propert constructor when builder is caller with new logical type,\r\ncall the deprecated OriginalType version otherwise.\r\n\r\n* Use static imports in test\r\n",
        "diff": {
            "parquet-column/src/main/java/org/apache/parquet/schema/Types.java": [
                2,
                10
            ],
            "parquet-column/src/test/java/org/apache/parquet/schema/TestTypeBuilders.java": [
                0,
                29
            ]
        }
    },
    "e9e36cdc44a68662885e35773187cca00d20239e": {
        "datetime": "2018-07-09T10:10:24+02:00",
        "summary": "PARQUET-1335: Logical type names in parquet-mr are not consistent with parquet-format (#503)",
        "message": "PARQUET-1335: Logical type names in parquet-mr are not consistent with parquet-format (#503)\n\nAdd test case for STRING annotation and revert UTF8 annotations removed in PR#496",
        "diff": {
            "parquet-column/src/test/java/org/apache/parquet/parser/TestParquetParser.java": [
                5,
                23
            ]
        }
    },
    "55e94974e0547085a66c6242336e56230f996d52": {
        "datetime": "2018-08-07T17:56:42+02:00",
        "summary": "PARQUET-1371: Time/Timestamp UTC normalization parameter doesn't work (#511)",
        "message": "PARQUET-1371: Time/Timestamp UTC normalization parameter doesn't work (#511)\n\n",
        "diff": {
            "parquet-hadoop/src/main/java/org/apache/parquet/format/converter/ParquetMetadataConverter.java": [
                6,
                9
            ],
            "parquet-hadoop/src/test/java/org/apache/parquet/format/converter/TestParquetMetadataConverter.java": [
                2,
                59
            ]
        }
    },
    "45e3ce5fd218e4f7ec645c3f2947aa2459fe9c7b": {
        "datetime": "2018-08-07T09:35:38-07:00",
        "summary": "PARQUET-1368: ParquetFileReader should close its input stream for the failure in constructor (#510)",
        "message": "PARQUET-1368: ParquetFileReader should close its input stream for the failure in constructor (#510)\n\n",
        "diff": {
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ParquetFileReader.java": [
                1,
                8
            ]
        }
    },
    "d692ce3a4205a4274e97dce6add93c687e12a9c2": {
        "datetime": "2018-08-19T11:12:36+02:00",
        "summary": "PARQUET-1390: Upgrade Arrow to 0.10.0",
        "message": "PARQUET-1390: Upgrade Arrow to 0.10.0\n\nThis upgrades arrow from 0.8.0 to 0.10.0.\n\nThis required adding new SchemaConverter visitor methods for fixedSizeBinary data type and I pretty much guessed at how to implement those so would appreciate a review of that.\n\nAuthor: Andy Grove <andy.grove@rms.com>\n\nCloses #516 from agrove-rms/arrow_upgrade and squashes the following commits:\n\n4a922876 [Andy Grove] Add new visitor methods\n9535a162 [Andy Grove] Upgrade Arrow from 0.8.0 to 0.10.0\n",
        "diff": {
            "parquet-arrow/pom.xml": null,
            "parquet-arrow/src/main/java/org/apache/parquet/arrow/schema/SchemaConverter.java": [
                0,
                10
            ]
        }
    },
    "3d8426e9905352e20e76dc1499fc8d97832bb8bf": {
        "datetime": "2018-08-22T12:06:48+02:00",
        "summary": "[maven-release-plugin] prepare for next development iteration",
        "message": "[maven-release-plugin] prepare for next development iteration\n",
        "diff": {
            "pom.xml": null
        }
    },
    "59f5c72b442e36bccf8f633e17b3aaeabb14ad1d": {
        "datetime": "2018-08-22T12:06:48+02:00",
        "summary": "[maven-release-plugin] prepare release apache-parquet-format-2.5.0",
        "message": "[maven-release-plugin] prepare release apache-parquet-format-2.5.0\n",
        "diff": {
            "pom.xml": null
        }
    },
    "e846f7aa8d082b1cb894259a804071ed9356488b": {
        "datetime": "2018-08-22T12:06:48+02:00",
        "summary": "Revert \"[maven-release-plugin] prepare release apache-parquet-format-2.5.0\"",
        "message": "Revert \"[maven-release-plugin] prepare release apache-parquet-format-2.5.0\"\n\nThis reverts commit a5b842613309a60b59d07af5d02a76c00e9ef2ac.\n",
        "diff": {
            "pom.xml": null
        }
    },
    "06ffe24c5b72120d177c5fb91d1ac91b36c4b100": {
        "datetime": "2018-08-22T12:06:48+02:00",
        "summary": "[maven-release-plugin] prepare release apache-parquet-format-2.5.0",
        "message": "[maven-release-plugin] prepare release apache-parquet-format-2.5.0\n",
        "diff": {
            "pom.xml": null
        }
    },
    "ba5ad4261c1f4c6c8ce21b5919938c820bfeeeb4": {
        "datetime": "2018-08-22T12:06:48+02:00",
        "summary": "PARQUET-1258: Update scm developer connection to github (#90)",
        "message": "PARQUET-1258: Update scm developer connection to github (#90)\n\nAfter moving to gitbox the old apache repo is not working anymore.\r\nThe pom.xml had to be updated accordingly.",
        "diff": {
            "pom.xml": null
        }
    },
    "ad3a8d4e044fe88b0857313f330f621ec4fe2a6d": {
        "datetime": "2018-08-22T12:06:48+02:00",
        "summary": "PARQUET-1236: Align version of slf4j-api",
        "message": "PARQUET-1236: Align version of slf4j-api\n\nhttps://issues.apache.org/jira/browse/PARQUET-1236\n\nAuthor: 1028332163 <1028332163@qq.com>\n\nCloses #85 from PandaMonkey/master and squashes the following commits:\n\n158f082 [1028332163] align version of slf4j-api\n",
        "diff": {
            "pom.xml": null
        }
    },
    "75f0e42f11030707878a78399552cd282280f66a": {
        "datetime": "2018-08-22T12:06:48+02:00",
        "summary": "PARQUET-1201: Implement page indexes",
        "message": "PARQUET-1201: Implement page indexes\n\nAdded helper methods to read/write ColumnIndex and OffsetIndex objects.\n\nAuthor: Gabor Szadovszky <gabor.szadovszky@cloudera.com>\n\nCloses #81 from gszadovszky/PARQUET-1201 and squashes the following commits:\n\n573dada [Gabor Szadovszky] PARQUET-1201: Implement page indexes\n",
        "diff": {
            "src/main/java/org/apache/parquet/format/Util.java": [
                0,
                16
            ]
        }
    },
    "8293207fddbae56f1c8d876a2fea9849ca757cf7": {
        "datetime": "2018-08-22T12:06:48+02:00",
        "summary": "PARQUET-1197: Log rat failures",
        "message": "PARQUET-1197: Log rat failures\n\nAuthor: Gabor Szadovszky <gabor.szadovszky@cloudera.com>\n\nCloses #80 from gszadovszky/PARQUET-1197 and squashes the following commits:\n\nc97db9d [Gabor Szadovszky] PARQUET-1197: Log rat failures\n",
        "diff": {
            "pom.xml": null
        }
    },
    "40d263ffad47897fd0d61e559748ef08651e6b89": {
        "datetime": "2018-08-22T12:06:48+02:00",
        "summary": "PARQUET-1145: Add license to .gitignore",
        "message": "PARQUET-1145: Add license to .gitignore\n\nAlso removes .gitignore from the RAT whitelist.\n\nAuthor: Lars Volker <lv@cloudera.com>\n\nCloses #75 from lekv/license and squashes the following commits:\n\n04523ef [Lars Volker] Also add license to .travis.yml\nce471fd [Lars Volker] PARQUET-1145: Add license to .gitignore\n",
        "diff": {
            "pom.xml": null
        }
    },
    "9eae3e8747d0c8e9ecd786f23f3d6988d747acf8": {
        "datetime": "2018-08-22T12:06:48+02:00",
        "summary": "[maven-release-plugin] prepare for next development iteration",
        "message": "[maven-release-plugin] prepare for next development iteration\n",
        "diff": {
            "pom.xml": null
        }
    },
    "3df27ee1186dc3366cf8e424f37011e59c776ddf": {
        "datetime": "2018-08-22T12:06:48+02:00",
        "summary": "[maven-release-plugin] prepare release apache-parquet-format-2.4.0",
        "message": "[maven-release-plugin] prepare release apache-parquet-format-2.4.0\n",
        "diff": {
            "pom.xml": null
        }
    },
    "6cc4110a61a009e5cb949d70c2aa2006f848f5fa": {
        "datetime": "2018-08-22T12:06:48+02:00",
        "summary": "PARQUET-1144: Remove slf4j-nop.",
        "message": "PARQUET-1144: Remove slf4j-nop.\n\nAuthor: Ryan Blue <blue@apache.org>\n\nCloses #74 from rdblue/PARQUET-1144-remove-slf4j-nop and squashes the following commits:\n\nd5d5639 [Ryan Blue] PARQUET-1144: Remove slf4j-nop.\n",
        "diff": {
            "pom.xml": null
        }
    },
    "1b8292ad7865134c612345841a34e73d2141060c": {
        "datetime": "2018-08-22T12:06:48+02:00",
        "summary": "[maven-release-plugin] prepare for next development iteration",
        "message": "[maven-release-plugin] prepare for next development iteration\n",
        "diff": {
            "pom.xml": null
        }
    },
    "56c4fcd1a0832effa08d4315d31efb714cf954dd": {
        "datetime": "2018-08-22T12:06:48+02:00",
        "summary": "[maven-release-plugin] prepare release apache-parquet-format-2.4.0",
        "message": "[maven-release-plugin] prepare release apache-parquet-format-2.4.0\n",
        "diff": {
            "pom.xml": null
        }
    },
    "e281913d0b033faaa0d41ec484fd00dee9610afe": {
        "datetime": "2018-08-22T12:06:48+02:00",
        "summary": "PARQUET-906: Add LogicalType annotation.",
        "message": "PARQUET-906: Add LogicalType annotation.\n\nThis commit adds a `LogicalType` union and a field for this logical type to `SchemaElement`. Adding a new structure for logical types is needed for a few reasons:\n\n1. Adding to the ConvertedType enum is not forward-compatible. Adding new types to the `LogicalType` union is forward-compatible.\n2. Using a struct for each type allows additional metadata, like `isAdjustedToUTC`, without adding more fields to `SchemaElement` that don't apply to all types.\n3. Types without additional metadata can be updated later. For example, adding an `encoding` field to `StringType` when it is needed.\n\nAuthor: Ryan Blue <blue@apache.org>\n\nCloses #51 from rdblue/PARQUET-906-add-timestamp-adjustment-metadata and squashes the following commits:\n\nad8e91d [Ryan Blue] PARQUET-906: Clarify the use of NullType.\n7cc29f7 [Ryan Blue] PARQUET-906: Rename NULL to UNKNOWN.\n02f3868 [Ryan Blue] PARQUET-906: Update from comments on the PR.\nc0386e9 [Ryan Blue] PARQUET-906: Remove NULL ConvertedType.\n190bd8a [Ryan Blue] PARQUET-906: Update for review comments.\n8203b21 [Ryan Blue] PARQUET-906: Add copyright header to LogicalTypes.\n993102e [Ryan Blue] PARQUET-906: Remove the unreleased NULL ConvertedType.\n86a22b4 [Ryan Blue] PARQUET-906: Add LogicalType annotation.\n",
        "diff": {
            "src/main/java/org/apache/parquet/format/LogicalTypes.java": [
                0,
                55
            ]
        }
    },
    "c48cbb1228671be280b82124aa7d365336f696f3": {
        "datetime": "2018-08-22T12:06:48+02:00",
        "summary": "PARQUET-1049: Make thrift version a property in pom.xml",
        "message": "PARQUET-1049: Make thrift version a property in pom.xml\n\nAuthor: Zoltan Ivanfi <zi@cloudera.com>\n\nCloses #57 from zivanfi/PARQUET-1049 and squashes the following commits:\n\n8efc7a3 [Zoltan Ivanfi] PARQUET-1049: Make thrift version a property in pom.xml\n",
        "diff": {
            "pom.xml": null
        }
    },
    "ae52b4da4c96cb7abfeb81fec10f07d738b0a96e": {
        "datetime": "2018-08-22T12:06:48+02:00",
        "summary": "PARQUET-371: update thrift dependency to 0.9.3; do not shade slf4j",
        "message": "PARQUET-371: update thrift dependency to 0.9.3; do not shade slf4j\n\nAuthor: Julien Le Dem <julien@dremio.com>\nAuthor: Julien Le Dem <julien@apache.org>\n\nCloses #50 from julienledem/update_thrift and squashes the following commits:\n\nf5db375 [Julien Le Dem] update travis\ne30ad8f [Julien Le Dem] update thrift dependency; do not shade slf4j\n",
        "diff": {
            "pom.xml": null
        }
    },
    "73e936cf659c413660e2d32df031dcc98ece1d66": {
        "datetime": "2018-08-22T12:06:48+02:00",
        "summary": "PARQUET-609: Add Brotli to parquet's thrift definition",
        "message": "PARQUET-609: Add Brotli to parquet's thrift definition\n\nAuthor: Ryan Blue <blue@apache.org>\n\nCloses #40 from rdblue/PARQUET-609-add-brotli and squashes the following commits:\n\n061dcbc [Ryan Blue] PARQUET-609: Add Brotli compression to the format.\n4eb1ff0 [Ryan Blue] PARQUET-608: Add thrift.executable property.\n",
        "diff": {
            "pom.xml": null
        }
    },
    "5008c5a26f36a103f0ce62ec2be2060d7be69709": {
        "datetime": "2018-08-22T12:06:48+02:00",
        "summary": "PARQUET-450: Fix several typos in Parquet format documentation",
        "message": "PARQUET-450: Fix several typos in Parquet format documentation\n\nIt also changes parquet.thrift location to conform to maven layout and add a link to it from README.md\n\nAuthor: Laurent Goujon <lgoujon@twitter.com>\n\nCloses #36 from laurentgo/update-format-specification and squashes the following commits:\n\n244c119 [Laurent Goujon] Fix several typos/errors in Parquet documentation\n90a2be4 [Laurent Goujon] Fix thrift source path to match maven layout\n",
        "diff": {
            "pom.xml": null
        }
    },
    "43f122f815f88ef958881db6431689cac888df7e": {
        "datetime": "2018-08-22T12:06:48+02:00",
        "summary": "[maven-release-plugin] prepare for next development iteration",
        "message": "[maven-release-plugin] prepare for next development iteration\n",
        "diff": {
            "pom.xml": null
        }
    },
    "f6cd4cc2c2070470567f9dcdf2f63e5bf95da98b": {
        "datetime": "2018-08-22T12:06:48+02:00",
        "summary": "[maven-release-plugin] prepare release apache-parquet-format-2.3.1",
        "message": "[maven-release-plugin] prepare release apache-parquet-format-2.3.1\n",
        "diff": {
            "pom.xml": null
        }
    },
    "344b56803fea37af84b9c01c9b6dcff586779683": {
        "datetime": "2018-08-22T13:11:52+02:00",
        "summary": "PARQUET-1399: Move files to the module directory",
        "message": "PARQUET-1399: Move files to the module directory\n",
        "diff": {
            "pom.xml": null,
            "src/main/java/org/apache/parquet/format/InterningProtocol.java": [
                0,
                0
            ],
            "src/main/java/org/apache/parquet/format/LogicalTypes.java": [
                0,
                0
            ],
            "src/main/java/org/apache/parquet/format/Util.java": [
                0,
                0
            ],
            "src/main/java/org/apache/parquet/format/event/Consumers.java": [
                0,
                0
            ],
            "src/main/java/org/apache/parquet/format/event/EventBasedThriftReader.java": [
                0,
                0
            ],
            "src/main/java/org/apache/parquet/format/event/FieldConsumer.java": [
                0,
                0
            ],
            "src/main/java/org/apache/parquet/format/event/TypedConsumer.java": [
                0,
                0
            ],
            "src/test/java/org/apache/parquet/format/TestUtil.java": [
                0,
                0
            ]
        }
    },
    "863a081850e56bbbb38d7b68b478a3bd40779723": {
        "datetime": "2018-09-11T13:56:57+02:00",
        "summary": "PARQUET-1381: Add merge blocks command to parquet-tools (#512)",
        "message": "PARQUET-1381: Add merge blocks command to parquet-tools (#512)\n\nExisting implementation of merge command in parquet-tools didn't merge row groups, just placed one after the other. This commit adds API and command option to be able to merge small blocks into larger ones up to specified size limit.",
        "diff": {
            "parquet-column/src/main/java/org/apache/parquet/column/impl/ColumnReadStoreImpl.java": [
                1,
                1
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ColumnChunkPageWriteStore.java": [
                0,
                5
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ParquetFileReader.java": [
                21,
                72
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ParquetFileWriter.java": [
                0,
                115
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/util/BlocksCombiner.java": [
                0,
                106
            ],
            "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/TestParquetWriterMergeBlocks.java": [
                0,
                280
            ],
            "parquet-tools/src/main/java/org/apache/parquet/tools/command/MergeCommand.java": [
                2,
                73
            ]
        }
    },
    "b4198be200e7e2df82bc9a18d54c8cd16aa156ac": {
        "datetime": "2018-09-12T14:14:20+02:00",
        "summary": "PARQUET-1410: Refactor modules to use the new logical type API (#520)",
        "message": "PARQUET-1410: Refactor modules to use the new logical type API (#520)\n\n",
        "diff": {
            "parquet-arrow/src/main/java/org/apache/parquet/arrow/schema/SchemaConverter.java": [
                131,
                121
            ],
            "parquet-arrow/src/test/java/org/apache/parquet/arrow/schema/TestSchemaConverter.java": [
                8,
                19
            ],
            "parquet-avro/src/main/java/org/apache/parquet/avro/AvroSchemaConverter.java": [
                59,
                99
            ],
            "parquet-avro/src/test/java/org/apache/parquet/avro/TestAvroSchemaConverter.java": [
                7,
                7
            ],
            "parquet-cascading-common23/src/main/java/org/apache/parquet/cascading/convert/TupleConverter.java": [
                6,
                3
            ],
            "parquet-cli/src/main/java/org/apache/parquet/cli/Util.java": [
                0,
                10
            ],
            "parquet-cli/src/main/java/org/apache/parquet/cli/commands/ParquetMetadataCommand.java": [
                2,
                2
            ],
            "parquet-cli/src/main/java/org/apache/parquet/cli/commands/ShowDictionaryCommand.java": [
                2,
                2
            ],
            "parquet-cli/src/main/java/org/apache/parquet/cli/commands/ShowPagesCommand.java": [
                2,
                2
            ],
            "parquet-column/src/main/java/org/apache/parquet/filter2/predicate/ValidTypeMap.java": [
                4,
                3
            ],
            "parquet-column/src/main/java/org/apache/parquet/schema/ConversionPatterns.java": [
                14,
                14
            ],
            "parquet-column/src/main/java/org/apache/parquet/schema/GroupType.java": [
                8,
                28
            ],
            "parquet-column/src/main/java/org/apache/parquet/schema/LogicalTypeAnnotation.java": [
                14,
                97
            ],
            "parquet-column/src/main/java/org/apache/parquet/schema/MessageType.java": [
                4,
                4
            ],
            "parquet-column/src/main/java/org/apache/parquet/schema/OriginalType.java": [
                44,
                22
            ],
            "parquet-column/src/main/java/org/apache/parquet/schema/PrimitiveType.java": [
                96,
                117
            ],
            "parquet-column/src/main/java/org/apache/parquet/schema/Types.java": [
                38,
                98
            ],
            "parquet-column/src/test/java/org/apache/parquet/filter2/predicate/TestValidTypeMap.java": [
                4,
                3
            ],
            "parquet-column/src/test/java/org/apache/parquet/schema/TestMessageType.java": [
                1,
                1
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/format/converter/ParquetMetadataConverter.java": [
                102,
                145
            ],
            "parquet-hive/parquet-hive-storage-handler/src/main/java/org/apache/hadoop/hive/ql/io/parquet/convert/HiveSchemaConverter.java": [
                7,
                10
            ],
            "parquet-pig/src/main/java/org/apache/parquet/pig/PigSchemaConverter.java": [
                47,
                77
            ],
            "parquet-pig/src/main/java/org/apache/parquet/pig/convert/TupleConverter.java": [
                18,
                13
            ],
            "parquet-protobuf/src/main/java/org/apache/parquet/proto/ProtoMessageConverter.java": [
                17,
                28
            ],
            "parquet-protobuf/src/main/java/org/apache/parquet/proto/ProtoSchemaConverter.java": [
                22,
                23
            ],
            "parquet-protobuf/src/main/java/org/apache/parquet/proto/ProtoWriteSupport.java": [
                12,
                21
            ],
            "parquet-thrift/src/main/java/org/apache/parquet/thrift/ThriftSchemaConvertVisitor.java": [
                9,
                9
            ],
            "parquet-tools/src/main/java/org/apache/parquet/tools/command/DumpCommand.java": [
                1,
                0
            ],
            "parquet-tools/src/main/java/org/apache/parquet/tools/command/MetadataUtils.java": [
                0,
                212
            ],
            "parquet-tools/src/main/java/org/apache/parquet/tools/command/ShowMetaCommand.java": [
                6,
                23
            ],
            "parquet-tools/src/main/java/org/apache/parquet/tools/command/ShowSchemaCommand.java": [
                5,
                9
            ],
            "parquet-tools/src/main/java/org/apache/parquet/tools/read/SimpleRecordConverter.java": [
                23,
                33
            ],
            "parquet-tools/src/main/java/org/apache/parquet/tools/util/MetadataUtils.java": [
                4,
                5
            ]
        }
    },
    "1f79f9bd0ba61b8ec0bae1dec71ef7249d41eacd": {
        "datetime": "2018-09-18T13:38:56+02:00",
        "summary": "PARQUET-1353: Fix random data generator. (#504)",
        "message": "PARQUET-1353: Fix random data generator. (#504)\n\nThe random data generator used for tests used to repeat the same value\r\nover and over again.",
        "diff": {
            "parquet-hadoop/src/test/java/org/apache/parquet/statistics/RandomValues.java": [
                3,
                4
            ]
        }
    },
    "93767ca512524cbf51548430782f061773600971": {
        "datetime": "2018-09-20T11:13:18+02:00",
        "summary": "PARQUET-1417: BINARY_AS_SIGNED_INTEGER_COMPARATOR fails with IOBE for the same arrays with the different length (#522)",
        "message": "PARQUET-1417: BINARY_AS_SIGNED_INTEGER_COMPARATOR fails with IOBE for the same arrays with the different length (#522)\n\n",
        "diff": {
            "parquet-column/src/main/java/org/apache/parquet/schema/PrimitiveComparator.java": [
                3,
                3
            ],
            "parquet-column/src/test/java/org/apache/parquet/schema/TestPrimitiveComparator.java": [
                0,
                19
            ]
        }
    },
    "411e672401a3cdec7e724fef354257f6f8119a58": {
        "datetime": "2018-09-20T16:23:29+02:00",
        "summary": "PARQUET-1421: InternalParquetRecordWriter logs debug messages at the INFO level (#526)",
        "message": "PARQUET-1421: InternalParquetRecordWriter logs debug messages at the INFO level (#526)\n\nReduced log level of said messages to DEBUG.",
        "diff": {
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/InternalParquetRecordWriter.java": [
                2,
                2
            ]
        }
    },
    "797fc6f568757e7142b8d01e9dceae2d5518e4ab": {
        "datetime": "2018-09-21T17:08:39+02:00",
        "summary": "PARQUET-1418: Run integration tests in Travis (#524)",
        "message": "PARQUET-1418: Run integration tests in Travis (#524)\n\n",
        "diff": {
            ".travis.yml": null
        }
    },
    "412685f5814672a490b3a64ccfc1500a0100c378": {
        "datetime": "2018-09-24T13:57:52+02:00",
        "summary": "Merge commit '344b56803fea37af84b9c01c9b6dcff586779683' into merge_PARQUET-1399",
        "message": "Merge commit '344b56803fea37af84b9c01c9b6dcff586779683' into merge_PARQUET-1399\n",
        "diff": {
            "parquet-format-structures/pom.xml": null,
            "parquet-format-structures/src/main/java/org/apache/parquet/format/InterningProtocol.java": [
                0,
                234
            ],
            "parquet-format-structures/src/main/java/org/apache/parquet/format/LogicalTypes.java": [
                0,
                55
            ],
            "parquet-format-structures/src/main/java/org/apache/parquet/format/Util.java": [
                0,
                243
            ],
            "parquet-format-structures/src/main/java/org/apache/parquet/format/event/Consumers.java": [
                0,
                199
            ],
            "parquet-format-structures/src/main/java/org/apache/parquet/format/event/EventBasedThriftReader.java": [
                0,
                129
            ],
            "parquet-format-structures/src/main/java/org/apache/parquet/format/event/FieldConsumer.java": [
                0,
                43
            ],
            "parquet-format-structures/src/main/java/org/apache/parquet/format/event/TypedConsumer.java": [
                0,
                204
            ],
            "parquet-format-structures/src/test/java/org/apache/parquet/format/TestUtil.java": [
                0,
                83
            ]
        }
    },
    "a150f245f0783fbd7d52da04320d256c60087bdb": {
        "datetime": "2018-09-24T13:58:03+02:00",
        "summary": "PARQUET-1399: Move parquet-mr related code from parquet-format",
        "message": "PARQUET-1399: Move parquet-mr related code from parquet-format\n",
        "diff": {
            "parquet-avro/pom.xml": null,
            "parquet-common/pom.xml": null,
            "parquet-format-structures/pom.xml": null,
            "parquet-format-structures/src/main/java/org/apache/parquet/format/InterningProtocol.java": [
                3,
                0
            ],
            "parquet-format-structures/src/main/java/org/apache/parquet/format/Util.java": [
                8,
                1
            ],
            "parquet-format-structures/src/main/java/org/apache/parquet/format/event/Consumers.java": [
                9,
                3
            ],
            "parquet-format-structures/src/main/java/org/apache/parquet/format/event/EventBasedThriftReader.java": [
                9,
                6
            ],
            "parquet-format-structures/src/main/java/org/apache/parquet/format/event/FieldConsumer.java": [
                5,
                1
            ],
            "parquet-format-structures/src/main/java/org/apache/parquet/format/event/TypedConsumer.java": [
                7,
                8
            ],
            "parquet-hadoop/pom.xml": null,
            "parquet-pig/pom.xml": null,
            "parquet-protobuf/pom.xml": null,
            "parquet-thrift/pom.xml": null,
            "parquet-tools/pom.xml": null,
            "pom.xml": null
        }
    },
    "0569f5128d5e529b5114ba05db9b853625918b43": {
        "datetime": "2018-09-25T14:38:00+02:00",
        "summary": "Revert \"PARQUET-1353: Fix random data generator. (#504)\"",
        "message": "Revert \"PARQUET-1353: Fix random data generator. (#504)\"\n\nThis reverts commit 1f79f9bd0ba61b8ec0bae1dec71ef7249d41eacd because of\nconcerns raised in the code review after the pull request was merged.\n",
        "diff": {
            "parquet-hadoop/src/test/java/org/apache/parquet/statistics/RandomValues.java": [
                4,
                3
            ]
        }
    },
    "0d541fc6cfdc0de9f45d2d2d7606afdef1415750": {
        "datetime": "2018-10-04T15:26:49+02:00",
        "summary": "PARQUET-1388: Nanosecond precision time and timestamp - parquet-mr (#519)",
        "message": "PARQUET-1388: Nanosecond precision time and timestamp - parquet-mr (#519)\n\n",
        "diff": {
            "parquet-arrow/src/main/java/org/apache/parquet/arrow/schema/SchemaConverter.java": [
                0,
                9
            ],
            "parquet-arrow/src/test/java/org/apache/parquet/arrow/schema/TestSchemaConverter.java": [
                18,
                16
            ],
            "parquet-column/src/main/java/org/apache/parquet/schema/LogicalTypeAnnotation.java": [
                4,
                7
            ],
            "parquet-column/src/main/java/org/apache/parquet/schema/PrimitiveStringifier.java": [
                0,
                34
            ],
            "parquet-column/src/main/java/org/apache/parquet/schema/Types.java": [
                0,
                1
            ],
            "parquet-column/src/test/java/org/apache/parquet/parser/TestParquetParser.java": [
                0,
                5
            ],
            "parquet-column/src/test/java/org/apache/parquet/schema/TestPrimitiveStringifier.java": [
                0,
                38
            ],
            "parquet-column/src/test/java/org/apache/parquet/schema/TestTypeBuildersWithLogicalTypes.java": [
                0,
                408
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/format/converter/ParquetMetadataConverter.java": [
                1,
                13
            ],
            "parquet-hadoop/src/test/java/org/apache/parquet/format/converter/TestParquetMetadataConverter.java": [
                0,
                12
            ],
            "pom.xml": null
        }
    },
    "63003ac204369c077f8e7148799b22c2aa10d2d6": {
        "datetime": "2018-10-05T11:16:42+02:00",
        "summary": "PARQUET-1436: TimestampMicrosStringifier shows wrong microseconds for timestamps before 1970 (#529)",
        "message": "PARQUET-1436: TimestampMicrosStringifier shows wrong microseconds for timestamps before 1970 (#529)\n\n\r\n",
        "diff": {
            "parquet-column/src/main/java/org/apache/parquet/schema/PrimitiveStringifier.java": [
                34,
                23
            ],
            "parquet-column/src/test/java/org/apache/parquet/schema/TestPrimitiveStringifier.java": [
                4,
                4
            ]
        }
    },
    "716fb6b3514b05e7b5ad87dea2c3b2ccad4cef60": {
        "datetime": "2018-10-10T17:54:54+02:00",
        "summary": "PARQUET-1440: Parquet-tools: Parse int32 or int64 decimal values to big decimals with the proper scale (#530)",
        "message": "PARQUET-1440: Parquet-tools: Parse int32 or int64 decimal values to big decimals with the proper scale (#530)\n\n",
        "diff": {
            "parquet-tools/src/main/java/org/apache/parquet/tools/read/SimpleRecordConverter.java": [
                0,
                10
            ]
        }
    },
    "cded3e57fc7f1eaba1dfb312a873a9f30705d14f": {
        "datetime": "2018-10-15T15:06:58+02:00",
        "summary": "PARQUET-1383: Parquet tools should indicate UTC parameter for time/timestamp types (#513)",
        "message": "PARQUET-1383: Parquet tools should indicate UTC parameter for time/timestamp types (#513)\n\n",
        "diff": {
            "parquet-column/src/main/java/org/apache/parquet/schema/LogicalTypeAnnotation.java": [
                4,
                22
            ],
            "parquet-column/src/main/java/org/apache/parquet/schema/PrimitiveStringifier.java": [
                25,
                66
            ],
            "parquet-column/src/test/java/org/apache/parquet/schema/TestPrimitiveStringifier.java": [
                61,
                83
            ]
        }
    },
    "e7db9e20f52c925a207ea62d6dda6dc4e870294e": {
        "datetime": "2018-10-18T14:08:13+02:00",
        "summary": "PARQUET-1201: Column indexes (#527)",
        "message": "PARQUET-1201: Column indexes (#527)\n\nThis is a squashed feature branch merge including the changes listed below. The detailed history can be found in the 'column-indexes' branch.\r\n\r\n* PARQUET-1211: Column indexes: read/write API (#456)\r\n* PARQUET-1212: Column indexes: Show indexes in tools (#479)\r\n* PARQUET-1213: Column indexes: Limit index size (#480)\r\n* PARQUET-1214: Column indexes: Truncate min/max values (#481)\r\n* PARQUET-1364: Invalid row indexes for pages starting with nulls (#507)\r\n* PARQUET-1310: Column indexes: Filtering (#509)\r\n* PARQUET-1386: Fix issues of NaN and +-0.0 in case of float/double column indexes (#515)\r\n* PARQUET-1389: Improve value skipping at page synchronization (#514)\r\n* PARQUET-1381: Fix missing endRecord after merging columnIndex",
        "diff": {
            "parquet-cli/src/main/java/org/apache/parquet/cli/Main.java": [
                0,
                2
            ],
            "parquet-cli/src/main/java/org/apache/parquet/cli/commands/ShowColumnIndexCommand.java": [
                0,
                157
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/ColumnReader.java": [
                0,
                3
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/ParquetProperties.java": [
                3,
                17
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/impl/ColumnReadStoreImpl.java": [
                1,
                11
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/impl/ColumnReaderBase.java": [
                0,
                760
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/impl/ColumnReaderImpl.java": [
                657,
                23
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/impl/ColumnWriteStoreBase.java": [
                0,
                223
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/impl/ColumnWriteStoreV1.java": [
                105,
                10
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/impl/ColumnWriteStoreV2.java": [
                143,
                5
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/impl/ColumnWriterBase.java": [
                0,
                326
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/impl/ColumnWriterV1.java": [
                245,
                24
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/impl/ColumnWriterV2.java": [
                260,
                36
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/impl/SynchronizingColumnReader.java": [
                0,
                111
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/page/DataPage.java": [
                0,
                22
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/page/DataPageV1.java": [
                0,
                31
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/page/DataPageV2.java": [
                0,
                52
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/page/PageReadStore.java": [
                1,
                14
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/page/PageWriter.java": [
                1,
                16
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/values/ValuesReader.java": [
                0,
                12
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/values/delta/DeltaBinaryPackingValuesReader.java": [
                0,
                8
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/values/deltalengthbytearray/DeltaLengthByteArrayValuesReader.java": [
                3,
                9
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/values/plain/FixedLenByteArrayPlainValuesReader.java": [
                2,
                6
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/values/plain/PlainValuesReader.java": [
                12,
                24
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/values/rle/RunLengthBitPackingHybridValuesWriter.java": [
                2,
                7
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/values/rle/ZeroIntegerValuesReader.java": [
                0,
                4
            ],
            "parquet-column/src/main/java/org/apache/parquet/internal/column/columnindex/BinaryColumnIndexBuilder.java": [
                0,
                140
            ],
            "parquet-column/src/main/java/org/apache/parquet/internal/column/columnindex/BinaryTruncator.java": [
                0,
                208
            ],
            "parquet-column/src/main/java/org/apache/parquet/internal/column/columnindex/BooleanColumnIndexBuilder.java": [
                0,
                133
            ],
            "parquet-column/src/main/java/org/apache/parquet/internal/column/columnindex/BoundaryOrder.java": [
                0,
                352
            ],
            "parquet-column/src/main/java/org/apache/parquet/internal/column/columnindex/ColumnIndex.java": [
                0,
                60
            ],
            "parquet-column/src/main/java/org/apache/parquet/internal/column/columnindex/ColumnIndexBuilder.java": [
                0,
                636
            ],
            "parquet-column/src/main/java/org/apache/parquet/internal/column/columnindex/DoubleColumnIndexBuilder.java": [
                0,
                155
            ],
            "parquet-column/src/main/java/org/apache/parquet/internal/column/columnindex/FloatColumnIndexBuilder.java": [
                0,
                155
            ],
            "parquet-column/src/main/java/org/apache/parquet/internal/column/columnindex/IndexIterator.java": [
                0,
                98
            ],
            "parquet-column/src/main/java/org/apache/parquet/internal/column/columnindex/IntColumnIndexBuilder.java": [
                0,
                136
            ],
            "parquet-column/src/main/java/org/apache/parquet/internal/column/columnindex/LongColumnIndexBuilder.java": [
                0,
                136
            ],
            "parquet-column/src/main/java/org/apache/parquet/internal/column/columnindex/OffsetIndex.java": [
                0,
                64
            ],
            "parquet-column/src/main/java/org/apache/parquet/internal/column/columnindex/OffsetIndexBuilder.java": [
                0,
                175
            ],
            "parquet-column/src/main/java/org/apache/parquet/internal/filter2/columnindex/ColumnIndexFilter.java": [
                0,
                194
            ],
            "parquet-column/src/main/java/org/apache/parquet/internal/filter2/columnindex/ColumnIndexStore.java": [
                0,
                55
            ],
            "parquet-column/src/main/java/org/apache/parquet/internal/filter2/columnindex/RowRanges.java": [
                0,
                288
            ],
            "parquet-column/src/test/java/org/apache/parquet/column/impl/TestColumnReaderImpl.java": [
                4,
                4
            ],
            "parquet-column/src/test/java/org/apache/parquet/column/mem/TestMemColumn.java": [
                3,
                9
            ],
            "parquet-column/src/test/java/org/apache/parquet/column/page/mem/MemPageWriter.java": [
                0,
                6
            ],
            "parquet-column/src/test/java/org/apache/parquet/column/values/bitpacking/TestBitPackingColumn.java": [
                0,
                16
            ],
            "parquet-column/src/test/java/org/apache/parquet/column/values/delta/DeltaBinaryPackingValuesWriterForIntegerTest.java": [
                0,
                17
            ],
            "parquet-column/src/test/java/org/apache/parquet/column/values/delta/DeltaBinaryPackingValuesWriterForLongTest.java": [
                0,
                17
            ],
            "parquet-column/src/test/java/org/apache/parquet/column/values/deltalengthbytearray/TestDeltaLengthByteArray.java": [
                0,
                24
            ],
            "parquet-column/src/test/java/org/apache/parquet/column/values/deltastrings/TestDeltaByteArray.java": [
                0,
                19
            ],
            "parquet-column/src/test/java/org/apache/parquet/column/values/dictionary/TestDictionary.java": [
                0,
                105
            ],
            "parquet-column/src/test/java/org/apache/parquet/internal/column/columnindex/TestBinaryTruncator.java": [
                0,
                285
            ],
            "parquet-column/src/test/java/org/apache/parquet/internal/column/columnindex/TestBoundaryOrder.java": [
                0,
                487
            ],
            "parquet-column/src/test/java/org/apache/parquet/internal/column/columnindex/TestColumnIndexBuilder.java": [
                0,
                1546
            ],
            "parquet-column/src/test/java/org/apache/parquet/internal/column/columnindex/TestIndexIterator.java": [
                0,
                63
            ],
            "parquet-column/src/test/java/org/apache/parquet/internal/column/columnindex/TestOffsetIndexBuilder.java": [
                0,
                113
            ],
            "parquet-column/src/test/java/org/apache/parquet/internal/filter2/columnindex/TestColumnIndexFilter.java": [
                0,
                464
            ],
            "parquet-column/src/test/java/org/apache/parquet/internal/filter2/columnindex/TestRowRanges.java": [
                0,
                155
            ],
            "parquet-common/pom.xml": null,
            "parquet-hadoop/src/main/java/org/apache/parquet/HadoopReadOptions.java": [
                3,
                6
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/ParquetReadOptions.java": [
                1,
                19
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/format/converter/ParquetMetadataConverter.java": [
                0,
                108
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ColumnChunkPageReadStore.java": [
                25,
                90
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ColumnChunkPageWriteStore.java": [
                11,
                43
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ColumnIndexFilterUtils.java": [
                0,
                157
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ColumnIndexStoreImpl.java": [
                0,
                155
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/InternalParquetRecordReader.java": [
                3,
                3
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/InternalParquetRecordWriter.java": [
                2,
                2
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ParquetFileReader.java": [
                51,
                290
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ParquetFileWriter.java": [
                14,
                208
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ParquetInputFormat.java": [
                0,
                5
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ParquetOutputFormat.java": [
                1,
                16
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ParquetReader.java": [
                0,
                10
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ParquetWriter.java": [
                1,
                1
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/metadata/ColumnChunkMetaData.java": [
                2,
                39
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/internal/hadoop/metadata/IndexReference.java": [
                0,
                41
            ],
            "parquet-hadoop/src/test/java/org/apache/parquet/filter2/recordlevel/PhoneBookWriter.java": [
                13,
                94
            ],
            "parquet-hadoop/src/test/java/org/apache/parquet/format/converter/TestParquetMetadataConverter.java": [
                0,
                62
            ],
            "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/TestColumnChunkPageWriteStore.java": [
                5,
                89
            ],
            "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/TestColumnIndexFiltering.java": [
                0,
                442
            ],
            "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/TestParquetFileWriter.java": [
                0,
                146
            ],
            "parquet-tools/src/main/java/org/apache/parquet/tools/command/ColumnIndexCommand.java": [
                0,
                182
            ],
            "parquet-tools/src/main/java/org/apache/parquet/tools/command/Registry.java": [
                0,
                1
            ]
        }
    },
    "1e0760a1f9c138e3cb66143f1c9fdf8ee2e8eef7": {
        "datetime": "2018-11-07T09:44:06+01:00",
        "summary": "PARQUET-1414: Limit page size based on maximum row count (#531)",
        "message": "PARQUET-1414: Limit page size based on maximum row count (#531)\n\n\r\n",
        "diff": {
            "parquet-column/src/main/java/org/apache/parquet/column/ParquetProperties.java": [
                2,
                19
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/impl/ColumnWriteStoreBase.java": [
                3,
                12
            ],
            "parquet-column/src/test/java/org/apache/parquet/column/mem/TestMemColumn.java": [
                0,
                71
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ParquetOutputFormat.java": [
                0,
                15
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ParquetWriter.java": [
                0,
                11
            ]
        }
    },
    "b6fd45ee08e08b490c35825953b51cfd8fb1b072": {
        "datetime": "2018-11-07T11:19:10+01:00",
        "summary": "PARQUET-1305: Backward incompatible change introduced in 1.8 (#483)",
        "message": "PARQUET-1305: Backward incompatible change introduced in 1.8 (#483)\n\n",
        "diff": {
            "parquet-thrift/src/main/java/org/apache/parquet/thrift/struct/ThriftType.java": [
                4,
                4
            ],
            "parquet-thrift/src/test/java/org/apache/parquet/thrift/TestThriftSchemaConverter.java": [
                3,
                27
            ],
            "parquet-thrift/src/test/java/org/apache/parquet/thrift/struct/TestThriftType.java": [
                5,
                5
            ]
        }
    },
    "ca294f94a9908d25174648cd1c325a994af6a56d": {
        "datetime": "2018-11-07T12:31:43+01:00",
        "summary": "PARQUET-1452: Deprecate old logical types API (#535)",
        "message": "PARQUET-1452: Deprecate old logical types API (#535)\n\n",
        "diff": {
            "parquet-column/src/main/java/org/apache/parquet/internal/column/columnindex/BinaryTruncator.java": [
                12,
                25
            ],
            "parquet-column/src/main/java/org/apache/parquet/schema/DecimalMetadata.java": [
                3,
                8
            ],
            "parquet-column/src/main/java/org/apache/parquet/schema/LogicalTypeAnnotation.java": [
                0,
                16
            ],
            "parquet-column/src/main/java/org/apache/parquet/schema/OriginalType.java": [
                0,
                4
            ],
            "parquet-column/src/main/java/org/apache/parquet/schema/PrimitiveType.java": [
                0,
                1
            ]
        }
    },
    "7f561b6053e6808b5b2c2482d1aa61c22c7a90cc": {
        "datetime": "2018-11-08T09:23:32-08:00",
        "summary": "PARQUET-1414: Simplify next row count check calculation (#537)",
        "message": "PARQUET-1414: Simplify next row count check calculation (#537)\n\n",
        "diff": {
            "parquet-column/src/main/java/org/apache/parquet/column/impl/ColumnWriteStoreBase.java": [
                1,
                1
            ]
        }
    },
    "3201bd1915bc6adee45fec59e5eb58cde3793e32": {
        "datetime": "2018-11-12T11:13:31+01:00",
        "summary": "PARQUET-1435: Benchmark filtering column-indexes (#536)",
        "message": "PARQUET-1435: Benchmark filtering column-indexes (#536)\n\n",
        "diff": {
            "parquet-benchmarks/pom.xml": null,
            "parquet-benchmarks/src/main/java/org/apache/parquet/benchmarks/FilteringBenchmarks.java": [
                0,
                430
            ]
        }
    },
    "a69f2b30cd3c581588977ea4c93a53989e9c031c": {
        "datetime": "2018-11-19T13:15:39+01:00",
        "summary": "PARQUET-1365: Don't write page level statistics (#549)",
        "message": "PARQUET-1365: Don't write page level statistics (#549)\n\nPage level statistics were never used in production and became pointless after adding column indexes.",
        "diff": {
            "parquet-hadoop/src/main/java/org/apache/parquet/format/converter/ParquetMetadataConverter.java": [
                12,
                35
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ColumnChunkPageWriteStore.java": [
                3,
                1
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ParquetFileWriter.java": [
                3,
                2
            ],
            "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/TestColumnChunkPageWriteStore.java": [
                1,
                0
            ]
        }
    },
    "5250dac71600d42edfa324786593a7d56135aa26": {
        "datetime": "2018-11-19T13:18:28+01:00",
        "summary": "PARQUET-1456: Use page index, ParquetFileReader throw ArrayIndexOutOfBoundsException (#548)",
        "message": "PARQUET-1456: Use page index, ParquetFileReader throw ArrayIndexOutOfBoundsException (#548)\n\nThe usage of static caching in the page index implementation did not allow using multiple readers at the same time.",
        "diff": {
            "parquet-column/src/main/java/org/apache/parquet/internal/column/columnindex/ColumnIndexBuilder.java": [
                12,
                2
            ],
            "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/TestMultipleWriteRead.java": [
                0,
                250
            ]
        }
    },
    "542ab3e2b321d5f755f3e9c6b997a458f8cf0f5e": {
        "datetime": "2018-11-19T14:07:55-08:00",
        "summary": "PARQUET-1407: Avro: Fix binary values returned from dictionary encoding (#552)",
        "message": "PARQUET-1407: Avro: Fix binary values returned from dictionary encoding (#552)\n\n* PARQUET-1407: Add test case for PARQUET-1407 to demonstrate the issue\r\n* PARQUET-1407: Fix binary values from dictionary encoding.\r\n\r\nCloses #551.",
        "diff": {
            "parquet-avro/src/main/java/org/apache/parquet/avro/AvroConverters.java": [
                1,
                10
            ],
            "parquet-avro/src/test/java/org/apache/parquet/avro/TestReadWrite.java": [
                33,
                51
            ]
        }
    },
    "a7b5a4b24a3e17edce9273a0654e799075c86dbe": {
        "datetime": "2018-11-21T17:12:00+01:00",
        "summary": "PARQUET-1460: Fix javadoc errors and include javadoc checking in Travis checks (#554)",
        "message": "PARQUET-1460: Fix javadoc errors and include javadoc checking in Travis checks (#554)\n\n",
        "diff": {
            ".travis.yml": null,
            "parquet-benchmarks/src/main/java/org/apache/parquet/benchmarks/FilteringBenchmarks.java": [
                1,
                1
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ParquetFileReader.java": [
                2,
                2
            ]
        }
    },
    "97a880cfc4fc3c2c74ff1302bc6e4aab1582b6df": {
        "datetime": "2018-11-21T17:13:46+01:00",
        "summary": "Experiment.",
        "message": "Experiment.\n",
        "diff": {
            "parquet-benchmarks/run.sh": null,
            "parquet-benchmarks/src/main/java/org/apache/parquet/benchmarks/WriteBenchmarks.java": [
                8,
                8
            ],
            "parquet-benchmarks/src/main/java/org/apache/parquet/benchmarks/WriteBenchmarksParquet1.java": [
                0,
                159
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/InternalParquetRecordWriter.java": [
                1,
                1
            ]
        }
    },
    "4d9a2fd01f33858bd5eb392a5f7bd0967fbec3f8": {
        "datetime": "2018-11-21T18:27:42+01:00",
        "summary": "Revert \"Experiment.\"",
        "message": "Revert \"Experiment.\"\n\nThis reverts commit 97a880cfc4fc3c2c74ff1302bc6e4aab1582b6df.\n",
        "diff": {
            "parquet-benchmarks/run.sh": null,
            "parquet-benchmarks/src/main/java/org/apache/parquet/benchmarks/WriteBenchmarks.java": [
                8,
                8
            ],
            "parquet-benchmarks/src/main/java/org/apache/parquet/benchmarks/WriteBenchmarksParquet1.java": [
                159,
                0
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/InternalParquetRecordWriter.java": [
                1,
                1
            ]
        }
    },
    "b60b36a6c57f95d3cc366c235d016c17ca2d5f0d": {
        "datetime": "2018-11-21T18:28:57+01:00",
        "summary": "PARQUET-1434: Update CHANGES.md for 1.11.0 release.",
        "message": "PARQUET-1434: Update CHANGES.md for 1.11.0 release.\n",
        "diff": {
            "CHANGES.md": null
        }
    },
    "b873a0ab31da570bb615ab2253cf90a2f451b0e4": {
        "datetime": "2018-11-21T18:39:31+01:00",
        "summary": "[maven-release-plugin] prepare release apache-parquet-1.11.0",
        "message": "[maven-release-plugin] prepare release apache-parquet-1.11.0\n",
        "diff": {
            "parquet-arrow/pom.xml": null,
            "parquet-avro/pom.xml": null,
            "parquet-benchmarks/pom.xml": null,
            "parquet-cascading/pom.xml": null,
            "parquet-cascading3/pom.xml": null,
            "parquet-cli/pom.xml": null,
            "parquet-column/pom.xml": null,
            "parquet-common/pom.xml": null,
            "parquet-encoding/pom.xml": null,
            "parquet-format-structures/pom.xml": null,
            "parquet-generator/pom.xml": null,
            "parquet-hadoop-bundle/pom.xml": null,
            "parquet-hadoop/pom.xml": null,
            "parquet-hive-bundle/pom.xml": null,
            "parquet-hive/parquet-hive-binding/parquet-hive-0.10-binding/pom.xml": null,
            "parquet-hive/parquet-hive-binding/parquet-hive-0.12-binding/pom.xml": null,
            "parquet-hive/parquet-hive-binding/parquet-hive-binding-bundle/pom.xml": null,
            "parquet-hive/parquet-hive-binding/parquet-hive-binding-factory/pom.xml": null,
            "parquet-hive/parquet-hive-binding/parquet-hive-binding-interface/pom.xml": null,
            "parquet-hive/parquet-hive-binding/pom.xml": null,
            "parquet-hive/parquet-hive-storage-handler/pom.xml": null,
            "parquet-hive/pom.xml": null,
            "parquet-jackson/pom.xml": null,
            "parquet-pig-bundle/pom.xml": null,
            "parquet-pig/pom.xml": null,
            "parquet-protobuf/pom.xml": null,
            "parquet-scala/pom.xml": null,
            "parquet-scrooge/pom.xml": null,
            "parquet-thrift/pom.xml": null,
            "parquet-tools/pom.xml": null,
            "pom.xml": null
        }
    },
    "ca9a125ed70ba6d28b3218eb7c90e6b51738fbf3": {
        "datetime": "2018-11-21T18:39:42+01:00",
        "summary": "[maven-release-plugin] prepare for next development iteration",
        "message": "[maven-release-plugin] prepare for next development iteration\n",
        "diff": {
            "parquet-arrow/pom.xml": null,
            "parquet-avro/pom.xml": null,
            "parquet-benchmarks/pom.xml": null,
            "parquet-cascading/pom.xml": null,
            "parquet-cascading3/pom.xml": null,
            "parquet-cli/pom.xml": null,
            "parquet-column/pom.xml": null,
            "parquet-common/pom.xml": null,
            "parquet-encoding/pom.xml": null,
            "parquet-format-structures/pom.xml": null,
            "parquet-generator/pom.xml": null,
            "parquet-hadoop-bundle/pom.xml": null,
            "parquet-hadoop/pom.xml": null,
            "parquet-hive-bundle/pom.xml": null,
            "parquet-hive/parquet-hive-binding/parquet-hive-0.10-binding/pom.xml": null,
            "parquet-hive/parquet-hive-binding/parquet-hive-0.12-binding/pom.xml": null,
            "parquet-hive/parquet-hive-binding/parquet-hive-binding-bundle/pom.xml": null,
            "parquet-hive/parquet-hive-binding/parquet-hive-binding-factory/pom.xml": null,
            "parquet-hive/parquet-hive-binding/parquet-hive-binding-interface/pom.xml": null,
            "parquet-hive/parquet-hive-binding/pom.xml": null,
            "parquet-hive/parquet-hive-storage-handler/pom.xml": null,
            "parquet-hive/pom.xml": null,
            "parquet-jackson/pom.xml": null,
            "parquet-pig-bundle/pom.xml": null,
            "parquet-pig/pom.xml": null,
            "parquet-protobuf/pom.xml": null,
            "parquet-scala/pom.xml": null,
            "parquet-scrooge/pom.xml": null,
            "parquet-thrift/pom.xml": null,
            "parquet-tools/pom.xml": null,
            "pom.xml": null
        }
    },
    "44c167ead46fe430c9e21871c4c7f993153a88cb": {
        "datetime": "2018-11-23T12:59:50+01:00",
        "summary": "PARQUET-1461: Third party code does not compile after parquet-mr minor version update (#556)",
        "message": "PARQUET-1461: Third party code does not compile after parquet-mr minor version update (#556)\n\n",
        "diff": {
            "parquet-column/src/main/java/org/apache/parquet/column/values/ValuesReader.java": [
                1,
                11
            ],
            "parquet-column/src/test/java/org/apache/parquet/column/values/TestValuesReaderImpl.java": [
                0,
                150
            ]
        }
    },
    "fafc4fc85409f4f2e3b55cd6515b9b72ae16422e": {
        "datetime": "2018-11-23T13:03:34+01:00",
        "summary": "PARQUET-1434: Update CHANGES.md for 1.11.0 release candidate 2.",
        "message": "PARQUET-1434: Update CHANGES.md for 1.11.0 release candidate 2.\n",
        "diff": {
            "CHANGES.md": null
        }
    },
    "0098e48ba33fefcfd0dce434dfc0214b84546fd4": {
        "datetime": "2018-11-23T13:54:36+01:00",
        "summary": "PARQUET-1258: Update scm developer connection to github",
        "message": "PARQUET-1258: Update scm developer connection to github\n",
        "diff": {
            "pom.xml": null
        }
    },
    "10e63437cd69a8bb98edf30f5b299ab9b1a98fe7": {
        "datetime": "2018-11-23T14:04:43+01:00",
        "summary": "[maven-release-plugin] prepare release apache-parquet-1.11.0",
        "message": "[maven-release-plugin] prepare release apache-parquet-1.11.0\n",
        "diff": {
            "parquet-arrow/pom.xml": null,
            "parquet-avro/pom.xml": null,
            "parquet-benchmarks/pom.xml": null,
            "parquet-cascading/pom.xml": null,
            "parquet-cascading3/pom.xml": null,
            "parquet-cli/pom.xml": null,
            "parquet-column/pom.xml": null,
            "parquet-common/pom.xml": null,
            "parquet-encoding/pom.xml": null,
            "parquet-format-structures/pom.xml": null,
            "parquet-generator/pom.xml": null,
            "parquet-hadoop-bundle/pom.xml": null,
            "parquet-hadoop/pom.xml": null,
            "parquet-hive-bundle/pom.xml": null,
            "parquet-hive/parquet-hive-binding/parquet-hive-0.10-binding/pom.xml": null,
            "parquet-hive/parquet-hive-binding/parquet-hive-0.12-binding/pom.xml": null,
            "parquet-hive/parquet-hive-binding/parquet-hive-binding-bundle/pom.xml": null,
            "parquet-hive/parquet-hive-binding/parquet-hive-binding-factory/pom.xml": null,
            "parquet-hive/parquet-hive-binding/parquet-hive-binding-interface/pom.xml": null,
            "parquet-hive/parquet-hive-binding/pom.xml": null,
            "parquet-hive/parquet-hive-storage-handler/pom.xml": null,
            "parquet-hive/pom.xml": null,
            "parquet-jackson/pom.xml": null,
            "parquet-pig-bundle/pom.xml": null,
            "parquet-pig/pom.xml": null,
            "parquet-protobuf/pom.xml": null,
            "parquet-scala/pom.xml": null,
            "parquet-scrooge/pom.xml": null,
            "parquet-thrift/pom.xml": null,
            "parquet-tools/pom.xml": null,
            "pom.xml": null
        }
    },
    "7ccbe2841e3cdb070460913955114d25f7061258": {
        "datetime": "2018-11-23T14:05:01+01:00",
        "summary": "[maven-release-plugin] prepare for next development iteration",
        "message": "[maven-release-plugin] prepare for next development iteration\n",
        "diff": {
            "parquet-arrow/pom.xml": null,
            "parquet-avro/pom.xml": null,
            "parquet-benchmarks/pom.xml": null,
            "parquet-cascading/pom.xml": null,
            "parquet-cascading3/pom.xml": null,
            "parquet-cli/pom.xml": null,
            "parquet-column/pom.xml": null,
            "parquet-common/pom.xml": null,
            "parquet-encoding/pom.xml": null,
            "parquet-format-structures/pom.xml": null,
            "parquet-generator/pom.xml": null,
            "parquet-hadoop-bundle/pom.xml": null,
            "parquet-hadoop/pom.xml": null,
            "parquet-hive-bundle/pom.xml": null,
            "parquet-hive/parquet-hive-binding/parquet-hive-0.10-binding/pom.xml": null,
            "parquet-hive/parquet-hive-binding/parquet-hive-0.12-binding/pom.xml": null,
            "parquet-hive/parquet-hive-binding/parquet-hive-binding-bundle/pom.xml": null,
            "parquet-hive/parquet-hive-binding/parquet-hive-binding-factory/pom.xml": null,
            "parquet-hive/parquet-hive-binding/parquet-hive-binding-interface/pom.xml": null,
            "parquet-hive/parquet-hive-binding/pom.xml": null,
            "parquet-hive/parquet-hive-storage-handler/pom.xml": null,
            "parquet-hive/pom.xml": null,
            "parquet-jackson/pom.xml": null,
            "parquet-pig-bundle/pom.xml": null,
            "parquet-pig/pom.xml": null,
            "parquet-protobuf/pom.xml": null,
            "parquet-scala/pom.xml": null,
            "parquet-scrooge/pom.xml": null,
            "parquet-thrift/pom.xml": null,
            "parquet-tools/pom.xml": null,
            "pom.xml": null
        }
    },
    "5881701d730cf74440b8e4df68b9777db3b2ca27": {
        "datetime": "2018-12-04T14:28:00+01:00",
        "summary": "PARQUET-1462: Allow specifying new development version in prepare-release.sh (#557)",
        "message": "PARQUET-1462: Allow specifying new development version in prepare-release.sh (#557)\n\nBefore this change, prepare-release.sh only took the release version as a\r\nparameter, the new development version was asked interactively for each\r\nindividual pom.xml file, which made answering them tedious.",
        "diff": {
            "dev/prepare-release.sh": null
        }
    },
    "63b45f7244f0dcf1a05c94a30a7f860973e307d2": {
        "datetime": "2018-12-13T14:37:41+01:00",
        "summary": "PARQUET-1472: Dictionary filter fails on FIXED_LEN_BYTE_ARRAY (#562)",
        "message": "PARQUET-1472: Dictionary filter fails on FIXED_LEN_BYTE_ARRAY (#562)\n\n",
        "diff": {
            "parquet-hadoop/src/main/java/org/apache/parquet/filter2/dictionarylevel/DictionaryFilter.java": [
                21,
                32
            ],
            "parquet-hadoop/src/test/java/org/apache/parquet/filter2/dictionarylevel/DictionaryFilterTest.java": [
                8,
                169
            ]
        }
    },
    "94555e1f1dcd91bf371fd44dff8494385b699e09": {
        "datetime": "2018-12-13T16:58:07+01:00",
        "summary": "PARQUET-1474: Less verbose and lower level logging for missing column/offset indexes (#563)",
        "message": "PARQUET-1474: Less verbose and lower level logging for missing column/offset indexes (#563)\n\n",
        "diff": {
            "parquet-column/src/main/java/org/apache/parquet/internal/filter2/columnindex/ColumnIndexFilter.java": [
                2,
                2
            ]
        }
    },
    "3cb529cc23289a302588cf840825953e1aa1e618": {
        "datetime": "2018-12-13T18:28:11+01:00",
        "summary": "PARQUET-1476: Don't emit a warning message for files without new logical type (#577)",
        "message": "PARQUET-1476: Don't emit a warning message for files without new logical type (#577)\n\n",
        "diff": {
            "parquet-hadoop/src/main/java/org/apache/parquet/format/converter/ParquetMetadataConverter.java": [
                2,
                4
            ]
        }
    },
    "1c2bb3264b4e437a43f19a4fd80db5cb4e7fd01f": {
        "datetime": "2018-12-13T19:38:44+01:00",
        "summary": "Update CHANGES.md for 1.11.0 release candidate 2.",
        "message": "Update CHANGES.md for 1.11.0 release candidate 2.\n",
        "diff": {
            "CHANGES.md": null
        }
    },
    "a01a4dbbee892cbe920657e75f7750d33e277fbb": {
        "datetime": "2018-12-13T20:44:42+01:00",
        "summary": "[maven-release-plugin] prepare release apache-parquet-1.11.0",
        "message": "[maven-release-plugin] prepare release apache-parquet-1.11.0\n",
        "diff": {
            "parquet-arrow/pom.xml": null,
            "parquet-avro/pom.xml": null,
            "parquet-benchmarks/pom.xml": null,
            "parquet-cascading/pom.xml": null,
            "parquet-cascading3/pom.xml": null,
            "parquet-cli/pom.xml": null,
            "parquet-column/pom.xml": null,
            "parquet-common/pom.xml": null,
            "parquet-encoding/pom.xml": null,
            "parquet-format-structures/pom.xml": null,
            "parquet-generator/pom.xml": null,
            "parquet-hadoop-bundle/pom.xml": null,
            "parquet-hadoop/pom.xml": null,
            "parquet-hive-bundle/pom.xml": null,
            "parquet-hive/parquet-hive-binding/parquet-hive-0.10-binding/pom.xml": null,
            "parquet-hive/parquet-hive-binding/parquet-hive-0.12-binding/pom.xml": null,
            "parquet-hive/parquet-hive-binding/parquet-hive-binding-bundle/pom.xml": null,
            "parquet-hive/parquet-hive-binding/parquet-hive-binding-factory/pom.xml": null,
            "parquet-hive/parquet-hive-binding/parquet-hive-binding-interface/pom.xml": null,
            "parquet-hive/parquet-hive-binding/pom.xml": null,
            "parquet-hive/parquet-hive-storage-handler/pom.xml": null,
            "parquet-hive/pom.xml": null,
            "parquet-jackson/pom.xml": null,
            "parquet-pig-bundle/pom.xml": null,
            "parquet-pig/pom.xml": null,
            "parquet-protobuf/pom.xml": null,
            "parquet-scala/pom.xml": null,
            "parquet-scrooge/pom.xml": null,
            "parquet-thrift/pom.xml": null,
            "parquet-tools/pom.xml": null,
            "pom.xml": null
        }
    },
    "e7835e023a73ea6605908510707113ae447d4b9f": {
        "datetime": "2018-12-13T20:45:06+01:00",
        "summary": "[maven-release-plugin] prepare for next development iteration",
        "message": "[maven-release-plugin] prepare for next development iteration\n",
        "diff": {
            "parquet-arrow/pom.xml": null,
            "parquet-avro/pom.xml": null,
            "parquet-benchmarks/pom.xml": null,
            "parquet-cascading/pom.xml": null,
            "parquet-cascading3/pom.xml": null,
            "parquet-cli/pom.xml": null,
            "parquet-column/pom.xml": null,
            "parquet-common/pom.xml": null,
            "parquet-encoding/pom.xml": null,
            "parquet-format-structures/pom.xml": null,
            "parquet-generator/pom.xml": null,
            "parquet-hadoop-bundle/pom.xml": null,
            "parquet-hadoop/pom.xml": null,
            "parquet-hive-bundle/pom.xml": null,
            "parquet-hive/parquet-hive-binding/parquet-hive-0.10-binding/pom.xml": null,
            "parquet-hive/parquet-hive-binding/parquet-hive-0.12-binding/pom.xml": null,
            "parquet-hive/parquet-hive-binding/parquet-hive-binding-bundle/pom.xml": null,
            "parquet-hive/parquet-hive-binding/parquet-hive-binding-factory/pom.xml": null,
            "parquet-hive/parquet-hive-binding/parquet-hive-binding-interface/pom.xml": null,
            "parquet-hive/parquet-hive-binding/pom.xml": null,
            "parquet-hive/parquet-hive-storage-handler/pom.xml": null,
            "parquet-hive/pom.xml": null,
            "parquet-jackson/pom.xml": null,
            "parquet-pig-bundle/pom.xml": null,
            "parquet-pig/pom.xml": null,
            "parquet-protobuf/pom.xml": null,
            "parquet-scala/pom.xml": null,
            "parquet-scrooge/pom.xml": null,
            "parquet-thrift/pom.xml": null,
            "parquet-tools/pom.xml": null,
            "pom.xml": null
        }
    },
    "58edbd78ca93b360daee791376e4b1bcf01c5f61": {
        "datetime": "2019-01-07T16:46:06+01:00",
        "summary": "PARQUET-1478: Can't read spec compliant, 3-level lists via parquet-proto (#578)",
        "message": "PARQUET-1478: Can't read spec compliant, 3-level lists via parquet-proto (#578)\n\n",
        "diff": {
            "parquet-protobuf/src/main/java/org/apache/parquet/proto/ProtoMessageConverter.java": [
                1,
                1
            ],
            "parquet-protobuf/src/test/java/org/apache/parquet/proto/ProtoInputOutputFormatTest.java": [
                2,
                2
            ],
            "parquet-protobuf/src/test/java/org/apache/parquet/proto/utils/ReadUsingMR.java": [
                6,
                13
            ],
            "parquet-protobuf/src/test/java/org/apache/parquet/proto/utils/WriteUsingMR.java": [
                5,
                4
            ]
        }
    },
    "514083f43f5dffbc7ff8393b808f165c01c3a28a": {
        "datetime": "2019-01-09T13:40:01+01:00",
        "summary": "PARQUET-1489: Insufficient documentation for UserDefinedPredicate.keep(T) (#588)",
        "message": "PARQUET-1489: Insufficient documentation for UserDefinedPredicate.keep(T) (#588)\n\n",
        "diff": {
            "parquet-column/src/main/java/org/apache/parquet/filter2/predicate/UserDefinedPredicate.java": [
                1,
                4
            ]
        }
    },
    "797e32aca0eadd1d460e5f5cd477e37bc828b67d": {
        "datetime": "2019-01-09T13:42:00+01:00",
        "summary": "PARQUET-1487: Do not write original type for timezone-agnostic timestamps (#585)",
        "message": "PARQUET-1487: Do not write original type for timezone-agnostic timestamps (#585)\n\n\r\n",
        "diff": {
            "parquet-column/src/main/java/org/apache/parquet/schema/LogicalTypeAnnotation.java": [
                0,
                6
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/format/converter/ParquetMetadataConverter.java": [
                0,
                6
            ],
            "parquet-hadoop/src/test/java/org/apache/parquet/format/converter/TestParquetMetadataConverter.java": [
                13,
                67
            ]
        }
    },
    "19ad9611ab8557f16154ee0fda40f1313533ec15": {
        "datetime": "2019-01-09T16:09:58+01:00",
        "summary": "Update CHANGES.md for 1.11.0 release candidate 3.",
        "message": "Update CHANGES.md for 1.11.0 release candidate 3.\n",
        "diff": {
            "CHANGES.md": null
        }
    },
    "8be767d12cca295cf9858a521725fc440b0c6f93": {
        "datetime": "2019-01-09T16:20:05+01:00",
        "summary": "[maven-release-plugin] prepare release apache-parquet-1.11.0",
        "message": "[maven-release-plugin] prepare release apache-parquet-1.11.0\n",
        "diff": {
            "parquet-arrow/pom.xml": null,
            "parquet-avro/pom.xml": null,
            "parquet-benchmarks/pom.xml": null,
            "parquet-cascading/pom.xml": null,
            "parquet-cascading3/pom.xml": null,
            "parquet-cli/pom.xml": null,
            "parquet-column/pom.xml": null,
            "parquet-common/pom.xml": null,
            "parquet-encoding/pom.xml": null,
            "parquet-format-structures/pom.xml": null,
            "parquet-generator/pom.xml": null,
            "parquet-hadoop-bundle/pom.xml": null,
            "parquet-hadoop/pom.xml": null,
            "parquet-hive-bundle/pom.xml": null,
            "parquet-hive/parquet-hive-binding/parquet-hive-0.10-binding/pom.xml": null,
            "parquet-hive/parquet-hive-binding/parquet-hive-0.12-binding/pom.xml": null,
            "parquet-hive/parquet-hive-binding/parquet-hive-binding-bundle/pom.xml": null,
            "parquet-hive/parquet-hive-binding/parquet-hive-binding-factory/pom.xml": null,
            "parquet-hive/parquet-hive-binding/parquet-hive-binding-interface/pom.xml": null,
            "parquet-hive/parquet-hive-binding/pom.xml": null,
            "parquet-hive/parquet-hive-storage-handler/pom.xml": null,
            "parquet-hive/pom.xml": null,
            "parquet-jackson/pom.xml": null,
            "parquet-pig-bundle/pom.xml": null,
            "parquet-pig/pom.xml": null,
            "parquet-protobuf/pom.xml": null,
            "parquet-scala/pom.xml": null,
            "parquet-scrooge/pom.xml": null,
            "parquet-thrift/pom.xml": null,
            "parquet-tools/pom.xml": null,
            "pom.xml": null
        }
    },
    "63a9fa17eacf49e06063ecb733e29b91272d0037": {
        "datetime": "2019-01-09T16:20:30+01:00",
        "summary": "[maven-release-plugin] prepare for next development iteration",
        "message": "[maven-release-plugin] prepare for next development iteration\n",
        "diff": {
            "parquet-arrow/pom.xml": null,
            "parquet-avro/pom.xml": null,
            "parquet-benchmarks/pom.xml": null,
            "parquet-cascading/pom.xml": null,
            "parquet-cascading3/pom.xml": null,
            "parquet-cli/pom.xml": null,
            "parquet-column/pom.xml": null,
            "parquet-common/pom.xml": null,
            "parquet-encoding/pom.xml": null,
            "parquet-format-structures/pom.xml": null,
            "parquet-generator/pom.xml": null,
            "parquet-hadoop-bundle/pom.xml": null,
            "parquet-hadoop/pom.xml": null,
            "parquet-hive-bundle/pom.xml": null,
            "parquet-hive/parquet-hive-binding/parquet-hive-0.10-binding/pom.xml": null,
            "parquet-hive/parquet-hive-binding/parquet-hive-0.12-binding/pom.xml": null,
            "parquet-hive/parquet-hive-binding/parquet-hive-binding-bundle/pom.xml": null,
            "parquet-hive/parquet-hive-binding/parquet-hive-binding-factory/pom.xml": null,
            "parquet-hive/parquet-hive-binding/parquet-hive-binding-interface/pom.xml": null,
            "parquet-hive/parquet-hive-binding/pom.xml": null,
            "parquet-hive/parquet-hive-storage-handler/pom.xml": null,
            "parquet-hive/pom.xml": null,
            "parquet-jackson/pom.xml": null,
            "parquet-pig-bundle/pom.xml": null,
            "parquet-pig/pom.xml": null,
            "parquet-protobuf/pom.xml": null,
            "parquet-scala/pom.xml": null,
            "parquet-scrooge/pom.xml": null,
            "parquet-thrift/pom.xml": null,
            "parquet-tools/pom.xml": null,
            "pom.xml": null
        }
    },
    "3d8eae78291ace9d9a12839a932c52a785b0b308": {
        "datetime": "2019-01-11T13:54:42+01:00",
        "summary": "PARQUET-1490: Add branch-specific Travis steps (#590)",
        "message": "PARQUET-1490: Add branch-specific Travis steps (#590)\n\nThe possiblity of branch-specific scripts allows feature branches to build\r\nSNAPSHOT versions of parquet-format (and depend on them in the POM files). Even\r\nif such branch-specific scripts get merged into master accidentally, they will\r\nnot have any effect there.\r\n\r\nThe script for the main branch checks the POM files to make sure that SNAPSHOT\r\ndependencies are not added to or merged into master accidentally.",
        "diff": {
            ".travis.yml": null,
            "dev/travis-before_install-master.sh": null,
            "dev/travis-before_install.sh": null
        }
    },
    "6eb99bdb914274a5905f11b8560b458162031d78": {
        "datetime": "2019-01-14T10:59:13+01:00",
        "summary": "PARQUET-1280: [parquet-protobuf] Use maven protoc plugin (#506)",
        "message": "PARQUET-1280: [parquet-protobuf] Use maven protoc plugin (#506)\n\n",
        "diff": {
            "parquet-protobuf/pom.xml": null
        }
    },
    "87646359966f9708b040e97e228af4ef8c32a151": {
        "datetime": "2019-01-14T13:41:32+01:00",
        "summary": "PARQUET-1466: Upgrade to the latest guava 27.0-jre (#559)",
        "message": "PARQUET-1466: Upgrade to the latest guava 27.0-jre (#559)\n\n\r\n",
        "diff": {
            "parquet-cli/src/main/java/org/apache/parquet/cli/util/Expressions.java": [
                2,
                2
            ],
            "pom.xml": null
        }
    },
    "794d55ee2e7e874a9d387c8df05003bd01e98baf": {
        "datetime": "2019-01-14T15:33:51+01:00",
        "summary": "PARQUET-1475: Fix lack of cause propagation in DirectCodecFactory.ParquetCompressionCodecException. (#564)",
        "message": "PARQUET-1475: Fix lack of cause propagation in DirectCodecFactory.ParquetCompressionCodecException. (#564)\n\n",
        "diff": {
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/DirectCodecFactory.java": [
                1,
                1
            ]
        }
    },
    "e9c283728cfd634677975affa367e13c4bef6c2a": {
        "datetime": "2019-01-15T13:08:43+01:00",
        "summary": "PARQUET-1492: Remove protobuf build (#592)",
        "message": "PARQUET-1492: Remove protobuf build (#592)\n\nWe do not need to build protobuf (protoc) ourselves since we rely on maven protoc plugin to compile protobuf.\r\nThis should save about 10 minutes travis build time (time for building protobuf itself).",
        "diff": {
            "README.md": null,
            "dev/travis-before_install.sh": null
        }
    },
    "ee97f23bb683c324309857f87d93ff997c0c09c0": {
        "datetime": "2019-01-22T14:59:37+01:00",
        "summary": "PARQUET-1498: Add instructions to install thrift via homebrew (#595)",
        "message": "PARQUET-1498: Add instructions to install thrift via homebrew (#595)\n\n",
        "diff": {
            "README.md": null
        }
    },
    "4b40d96a13f3e9bf75f8b2aaa0bef901491f2789": {
        "datetime": "2019-01-23T16:45:55+01:00",
        "summary": "PARQUET-1502: Convert FIXED_LEN_BYTE_ARRAY to arrow type in logicalTypeAnnotation if it is not null (#593)",
        "message": "PARQUET-1502: Convert FIXED_LEN_BYTE_ARRAY to arrow type in logicalTypeAnnotation if it is not null (#593)\n\n",
        "diff": {
            "parquet-arrow/src/main/java/org/apache/parquet/arrow/schema/SchemaConverter.java": [
                1,
                11
            ],
            "parquet-arrow/src/test/java/org/apache/parquet/arrow/schema/TestSchemaConverter.java": [
                0,
                20
            ]
        }
    },
    "354fcc2aeafa6c782ee893203de96c159327463c": {
        "datetime": "2019-01-24T13:49:25+01:00",
        "summary": "[PARQUET-1506] Migrate  maven-thrift-plugin to thrift-maven-plugin (#600)",
        "message": "[PARQUET-1506] Migrate  maven-thrift-plugin to thrift-maven-plugin (#600)\n\nmaven-thrift-plugin (Aug 13, 2013) https://mvnrepository.com/artifact/org.apache.thrift.tools/maven-thrift-plugin/0.1.11\r\nthrift-maven-plugin (Jan 18, 2017) https://mvnrepository.com/artifact/org.apache.thrift/thrift-maven-plugin/0.10.0\r\n\r\nThe maven-thrift-plugin is the old one which has been migrated to the ASF\r\nand continued as thrift-maven-plugin:\r\nhttps://issues.apache.org/jira/browse/THRIFT-4083",
        "diff": {
            "parquet-format-structures/pom.xml": null
        }
    },
    "f36dd08505b5dc799d2e4e92328901796f7b3cb8": {
        "datetime": "2019-01-25T09:07:48+01:00",
        "summary": "[PARQUET-1500] Replace Closeables with try-with-resources (#597)",
        "message": "[PARQUET-1500] Replace Closeables with try-with-resources (#597)\n\n",
        "diff": {
            "parquet-common/src/main/java/org/apache/parquet/Closeables.java": [
                3,
                5
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/util/SerializationUtil.java": [
                32,
                14
            ]
        }
    },
    "1e62e2e2ca903d4109480bc87ceec1dc954b6c92": {
        "datetime": "2019-01-25T09:21:15+01:00",
        "summary": "PARQUET-1503: Remove Ints Utility Class (#598)",
        "message": "PARQUET-1503: Remove Ints Utility Class (#598)\n\n",
        "diff": {
            "parquet-column/src/main/java/org/apache/parquet/column/impl/ColumnWriterV2.java": [
                2,
                1
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/page/DataPageV1.java": [
                3,
                2
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/page/DataPageV2.java": [
                5,
                4
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/page/DictionaryPage.java": [
                2,
                1
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/values/rle/RunLengthBitPackingHybridValuesWriter.java": [
                2,
                1
            ],
            "parquet-common/src/main/java/org/apache/parquet/Ints.java": [
                0,
                2
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ColumnChunkPageReadStore.java": [
                5,
                2
            ]
        }
    },
    "d1e9f15d1e94956f38880fec2cf9491b8f9711e4": {
        "datetime": "2019-01-27T11:38:02-08:00",
        "summary": "PARQUET-1513: Update HiddenFileFilter to avoid extra startsWith (#606)",
        "message": "PARQUET-1513: Update HiddenFileFilter to avoid extra startsWith (#606)\n\n",
        "diff": {
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/util/HiddenFileFilter.java": [
                1,
                7
            ]
        }
    },
    "00a7a470dbf73d6ae3bdd0774706abcda353b178": {
        "datetime": "2019-01-27T21:25:53+01:00",
        "summary": "PARQUET-1504: Add an option to convert Int96 to Arrow Timestamp (#594)",
        "message": "PARQUET-1504: Add an option to convert Int96 to Arrow Timestamp (#594)\n\nPARQUET-1504: Add an option to convert Parquet Int96 to Arrow Timestamp",
        "diff": {
            "parquet-arrow/src/main/java/org/apache/parquet/arrow/schema/SchemaConverter.java": [
                2,
                14
            ],
            "parquet-arrow/src/test/java/org/apache/parquet/arrow/schema/TestSchemaConverter.java": [
                0,
                22
            ]
        }
    },
    "ddc77471e595f5335540c2385c9ab900510d485e": {
        "datetime": "2019-01-27T13:42:58-08:00",
        "summary": "PARQUET-1509: Note Hive deprecation in README. (#602)",
        "message": "PARQUET-1509: Note Hive deprecation in README. (#602)\n\n",
        "diff": {
            "README.md": null
        }
    },
    "d9a19621370608f4431394cc36bddc063d59cc5a": {
        "datetime": "2019-01-28T08:50:52-08:00",
        "summary": "PARQUET-1510: Fix notEq for optional columns with null values. (#603)",
        "message": "PARQUET-1510: Fix notEq for optional columns with null values. (#603)\n\nDictionaries cannot contain null values, so notEq filters cannot\r\nconclude that a block cannot match using only the dictionary. Instead,\r\nit must also check whether the block may have at least one null value.\r\nIf there are no null values, then the existing check is correct.",
        "diff": {
            "parquet-hadoop/src/main/java/org/apache/parquet/filter2/dictionarylevel/DictionaryFilter.java": [
                1,
                4
            ],
            "parquet-hadoop/src/test/java/org/apache/parquet/filter2/dictionarylevel/DictionaryFilterTest.java": [
                2,
                15
            ]
        }
    },
    "9d1006f853c99387834b10fc37e2c3548b2034d9": {
        "datetime": "2019-01-30T10:23:38+01:00",
        "summary": "[PARQUET-1507] Bump Apache Thrift to 0.12.0 (#601)",
        "message": "[PARQUET-1507] Bump Apache Thrift to 0.12.0 (#601)\n\n\r\n",
        "diff": {
            "README.md": null,
            "dev/travis-before_install.sh": null,
            "pom.xml": null
        }
    },
    "1b103da225d67bb8796e064fdf334ef363e0faa9": {
        "datetime": "2019-01-31T09:01:30-08:00",
        "summary": "PARQUET-1518: Use Jackson2 version 2.9.8 in parquet-cli (#609)",
        "message": "PARQUET-1518: Use Jackson2 version 2.9.8 in parquet-cli (#609)\n\nThere are some vulnerabilities:\r\nhttps://ossindex.sonatype.org/vuln/1205a1ec-0837-406f-b081-623b9fb02992\r\nhttps://ossindex.sonatype.org/vuln/b85a00e3-7d9b-49cf-9b19-b73f8ee60275\r\nhttps://ossindex.sonatype.org/vuln/4f7e98ad-2212-45d3-ac21-089b3b082e6c\r\nhttps://ossindex.sonatype.org/vuln/ab9013f0-09a2-4f01-bce5-751dc7437494\r\nhttps://ossindex.sonatype.org/vuln/3f596fc0-9615-4b93-b30a-d4e0532e667f\r\nhttps://ossindex.sonatype.org/vuln/4f7e98ad-2212-45d3-ac21-089b3b082e6c",
        "diff": {
            "pom.xml": null
        }
    },
    "51c4cc30f5df1f070a211cfed652aefdc096de69": {
        "datetime": "2019-02-01T10:49:32-08:00",
        "summary": "PARQUET-138: Allow merging more restrictive field in less restrictive field (#550)",
        "message": "PARQUET-138: Allow merging more restrictive field in less restrictive field (#550)\n\n* Allow merging more restrictive field in less restrictive field\r\n* Make class and function names more explicit\r\n",
        "diff": {
            "parquet-column/src/main/java/org/apache/parquet/schema/GroupType.java": [
                3,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/schema/PrimitiveType.java": [
                1,
                2
            ],
            "parquet-column/src/main/java/org/apache/parquet/schema/Type.java": [
                0,
                23
            ],
            "parquet-column/src/test/java/org/apache/parquet/schema/TestMessageType.java": [
                9,
                8
            ],
            "parquet-column/src/test/java/org/apache/parquet/schema/TestRepetitionType.java": [
                0,
                36
            ]
        }
    },
    "3537c88f7f7af8bdddaadd6d49ac920d6ad4d68b": {
        "datetime": "2019-02-05T16:18:34+01:00",
        "summary": "Add javax.annotation-api dependency for JDK >= 9 (#604)",
        "message": "Add javax.annotation-api dependency for JDK >= 9 (#604)\n\n",
        "diff": {
            "parquet-format-structures/pom.xml": null
        }
    },
    "82935e6da8c9f2801d77afba998d3de622e3e7f3": {
        "datetime": "2019-02-06T09:51:50+01:00",
        "summary": "PARQUET-1470: Inputstream leakage in ParquetFileWriter.appendFile (#611)",
        "message": "PARQUET-1470: Inputstream leakage in ParquetFileWriter.appendFile (#611)\n\n",
        "diff": {
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ParquetFileWriter.java": [
                1,
                3
            ]
        }
    },
    "5bd126557cdbfccef9d0b282230cdd671c003c4f": {
        "datetime": "2019-02-06T10:20:59+01:00",
        "summary": "PARQUET-1514: ParquetFileWriter Records Compressed Bytes instead of Uncompressed Bytes (#607)",
        "message": "PARQUET-1514: ParquetFileWriter Records Compressed Bytes instead of Uncompressed Bytes (#607)\n\n",
        "diff": {
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ParquetFileWriter.java": [
                3,
                3
            ]
        }
    },
    "714bb450856dc951bd361e0cf4a732775eb3cefd": {
        "datetime": "2019-02-07T13:26:47+01:00",
        "summary": "PARQUET-1505: Use Java 7 NIO StandardCharsets (#599)",
        "message": "PARQUET-1505: Use Java 7 NIO StandardCharsets (#599)\n\n",
        "diff": {
            "parquet-avro/src/test/java/org/apache/parquet/avro/TestReadWrite.java": [
                5,
                5
            ],
            "parquet-avro/src/test/java/org/apache/parquet/avro/TestReadWriteOldListBehavior.java": [
                6,
                6
            ],
            "parquet-cli/src/main/java/org/apache/parquet/cli/BaseCommand.java": [
                6,
                2
            ],
            "parquet-column/src/main/java/org/apache/parquet/io/api/Binary.java": [
                21,
                9
            ],
            "parquet-column/src/test/java/org/apache/parquet/column/values/dictionary/TestDictionary.java": [
                4,
                3
            ],
            "parquet-common/src/main/java/org/apache/parquet/bytes/BytesUtils.java": [
                0,
                3
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ParquetFileWriter.java": [
                2,
                2
            ]
        }
    },
    "6901a2040848c6b37fa61f4b0a76246445f396db": {
        "datetime": "2019-02-07T13:31:39+01:00",
        "summary": "PARQUET-1480 INT96 to avro not yet implemented error should mention deprecation (#579)",
        "message": "PARQUET-1480 INT96 to avro not yet implemented error should mention deprecation (#579)\n\n",
        "diff": {
            "parquet-avro/src/main/java/org/apache/parquet/avro/AvroSchemaConverter.java": [
                1,
                1
            ]
        }
    },
    "7dcdcdcf0eb5e91618c443d4a84973bf7883d79b": {
        "datetime": "2019-02-12T11:33:17+01:00",
        "summary": "PARQUET-1485: Fix Snappy direct memory leak (#581)",
        "message": "PARQUET-1485: Fix Snappy direct memory leak (#581)\n\n",
        "diff": {
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/codec/CleanUtil.java": [
                0,
                70
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/codec/SnappyCompressor.java": [
                2,
                25
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/codec/SnappyDecompressor.java": [
                4,
                27
            ]
        }
    },
    "9461845576fd762e6a9b8d17c551f38c351b017d": {
        "datetime": "2019-02-12T13:04:38+01:00",
        "summary": "PARQUET-1527:  [parquet-tools] cat command throw java.lang.ClassCastException (#612)",
        "message": "PARQUET-1527:  [parquet-tools] cat command throw java.lang.ClassCastException (#612)\n\n",
        "diff": {
            "parquet-tools/src/main/java/org/apache/parquet/tools/read/SimpleRecordConverter.java": [
                0,
                1
            ],
            "parquet-tools/src/test/java/org/apache/parquet/tools/read/TestSimpleRecordConverter.java": [
                0,
                139
            ]
        }
    },
    "dcfd53ae1e6c3cc47eec319f2a3394e4fd1ce403": {
        "datetime": "2019-02-13T16:59:37+01:00",
        "summary": "PARQUET-1529: Shade fastutil in all modules where used (#617)",
        "message": "PARQUET-1529: Shade fastutil in all modules where used (#617)\n\n",
        "diff": {
            "parquet-avro/pom.xml": null,
            "parquet-column/pom.xml": null,
            "parquet-hadoop/pom.xml": null
        }
    },
    "f2c5b9a616383d990b37a0114e569e1bc7e3bd61": {
        "datetime": "2019-02-14T13:48:52+01:00",
        "summary": "Update CHANGES.md for 1.11.0rc4",
        "message": "Update CHANGES.md for 1.11.0rc4\n",
        "diff": {
            "CHANGES.md": null
        }
    },
    "22a9f54d0a537bc6153cc485a3ed6fab9204b337": {
        "datetime": "2019-02-14T15:12:10+01:00",
        "summary": "[maven-release-plugin] prepare release apache-parquet-1.11.0",
        "message": "[maven-release-plugin] prepare release apache-parquet-1.11.0\n",
        "diff": {
            "parquet-arrow/pom.xml": null,
            "parquet-avro/pom.xml": null,
            "parquet-benchmarks/pom.xml": null,
            "parquet-cascading/pom.xml": null,
            "parquet-cascading3/pom.xml": null,
            "parquet-cli/pom.xml": null,
            "parquet-column/pom.xml": null,
            "parquet-common/pom.xml": null,
            "parquet-encoding/pom.xml": null,
            "parquet-format-structures/pom.xml": null,
            "parquet-generator/pom.xml": null,
            "parquet-hadoop-bundle/pom.xml": null,
            "parquet-hadoop/pom.xml": null,
            "parquet-hive-bundle/pom.xml": null,
            "parquet-hive/parquet-hive-binding/parquet-hive-0.10-binding/pom.xml": null,
            "parquet-hive/parquet-hive-binding/parquet-hive-0.12-binding/pom.xml": null,
            "parquet-hive/parquet-hive-binding/parquet-hive-binding-bundle/pom.xml": null,
            "parquet-hive/parquet-hive-binding/parquet-hive-binding-factory/pom.xml": null,
            "parquet-hive/parquet-hive-binding/parquet-hive-binding-interface/pom.xml": null,
            "parquet-hive/parquet-hive-binding/pom.xml": null,
            "parquet-hive/parquet-hive-storage-handler/pom.xml": null,
            "parquet-hive/pom.xml": null,
            "parquet-jackson/pom.xml": null,
            "parquet-pig-bundle/pom.xml": null,
            "parquet-pig/pom.xml": null,
            "parquet-protobuf/pom.xml": null,
            "parquet-scala/pom.xml": null,
            "parquet-scrooge/pom.xml": null,
            "parquet-thrift/pom.xml": null,
            "parquet-tools/pom.xml": null,
            "pom.xml": null
        }
    },
    "4cc22ddac29cf808b7a29d7747951a1bc69d1d09": {
        "datetime": "2019-02-14T15:12:28+01:00",
        "summary": "[maven-release-plugin] prepare for next development iteration",
        "message": "[maven-release-plugin] prepare for next development iteration\n",
        "diff": {
            "parquet-arrow/pom.xml": null,
            "parquet-avro/pom.xml": null,
            "parquet-benchmarks/pom.xml": null,
            "parquet-cascading/pom.xml": null,
            "parquet-cascading3/pom.xml": null,
            "parquet-cli/pom.xml": null,
            "parquet-column/pom.xml": null,
            "parquet-common/pom.xml": null,
            "parquet-encoding/pom.xml": null,
            "parquet-format-structures/pom.xml": null,
            "parquet-generator/pom.xml": null,
            "parquet-hadoop-bundle/pom.xml": null,
            "parquet-hadoop/pom.xml": null,
            "parquet-hive-bundle/pom.xml": null,
            "parquet-hive/parquet-hive-binding/parquet-hive-0.10-binding/pom.xml": null,
            "parquet-hive/parquet-hive-binding/parquet-hive-0.12-binding/pom.xml": null,
            "parquet-hive/parquet-hive-binding/parquet-hive-binding-bundle/pom.xml": null,
            "parquet-hive/parquet-hive-binding/parquet-hive-binding-factory/pom.xml": null,
            "parquet-hive/parquet-hive-binding/parquet-hive-binding-interface/pom.xml": null,
            "parquet-hive/parquet-hive-binding/pom.xml": null,
            "parquet-hive/parquet-hive-storage-handler/pom.xml": null,
            "parquet-hive/pom.xml": null,
            "parquet-jackson/pom.xml": null,
            "parquet-pig-bundle/pom.xml": null,
            "parquet-pig/pom.xml": null,
            "parquet-protobuf/pom.xml": null,
            "parquet-scala/pom.xml": null,
            "parquet-scrooge/pom.xml": null,
            "parquet-thrift/pom.xml": null,
            "parquet-tools/pom.xml": null,
            "pom.xml": null
        }
    },
    "f7998934020ea6f4949e347616431219343d8a15": {
        "datetime": "2019-02-25T13:23:32+01:00",
        "summary": "PARQUET-1533: TestSnappy() throws OOM exception with Parquet-1485 change (#622)",
        "message": "PARQUET-1533: TestSnappy() throws OOM exception with Parquet-1485 change (#622)\n\n\r\n",
        "diff": {
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/codec/SnappyCompressor.java": [
                22,
                4
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/codec/SnappyDecompressor.java": [
                22,
                4
            ]
        }
    },
    "ab42fe5180366120336fb3f8b9e6540aadb5da1b": {
        "datetime": "2019-02-25T13:42:46+01:00",
        "summary": "Revert \"PARQUET-1381: Add merge blocks command to parquet-tools (#512)\" (#621)",
        "message": "Revert \"PARQUET-1381: Add merge blocks command to parquet-tools (#512)\" (#621)\n\nThis reverts commit 863a081850e56bbbb38d7b68b478a3bd40779723.\r\n\r\nThe design of this feature has conceptional problems and also works incorrectly. See PARQUET-1381 for more details.",
        "diff": {
            "parquet-column/src/main/java/org/apache/parquet/column/impl/ColumnReadStoreImpl.java": [
                1,
                1
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ColumnChunkPageWriteStore.java": [
                5,
                0
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ParquetFileReader.java": [
                71,
                21
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ParquetFileWriter.java": [
                123,
                0
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/util/BlocksCombiner.java": [
                106,
                0
            ],
            "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/TestParquetWriterMergeBlocks.java": [
                280,
                0
            ],
            "parquet-tools/src/main/java/org/apache/parquet/tools/command/MergeCommand.java": [
                73,
                2
            ]
        }
    },
    "892dedb23591bb4e38a061d5ea607637fd4e210f": {
        "datetime": "2019-03-13T08:25:56+01:00",
        "summary": "PARQUET-1531: Page row count limit causes empty pages to be written from MessageColumnIO (#620)",
        "message": "PARQUET-1531: Page row count limit causes empty pages to be written from MessageColumnIO (#620)\n\n\r\n",
        "diff": {
            "parquet-benchmarks/src/main/java/org/apache/parquet/benchmarks/NestedNullWritingBenchmarks.java": [
                0,
                151
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/ColumnWriteStore.java": [
                1,
                11
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/impl/ColumnWriteStoreBase.java": [
                0,
                5
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/impl/ColumnWriterBase.java": [
                0,
                3
            ],
            "parquet-column/src/main/java/org/apache/parquet/io/MessageColumnIO.java": [
                0,
                7
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/example/ExampleParquetWriter.java": [
                0,
                16
            ],
            "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/TestParquetWriter.java": [
                1,
                42
            ]
        }
    },
    "acaf9e64a7a158e5cf2514b041473ba452e0d4d0": {
        "datetime": "2019-03-13T08:34:56+01:00",
        "summary": "Update CHANGES.md for 1.11.0rc5",
        "message": "Update CHANGES.md for 1.11.0rc5\n",
        "diff": {
            "CHANGES.md": null
        }
    },
    "e85dbd3774038d7f42d69c14fcd9884ff5a3cb48": {
        "datetime": "2019-03-13T11:08:34+01:00",
        "summary": "[maven-release-plugin] prepare release apache-parquet-1.11.0",
        "message": "[maven-release-plugin] prepare release apache-parquet-1.11.0\n",
        "diff": {
            "parquet-arrow/pom.xml": null,
            "parquet-avro/pom.xml": null,
            "parquet-benchmarks/pom.xml": null,
            "parquet-cascading/pom.xml": null,
            "parquet-cascading3/pom.xml": null,
            "parquet-cli/pom.xml": null,
            "parquet-column/pom.xml": null,
            "parquet-common/pom.xml": null,
            "parquet-encoding/pom.xml": null,
            "parquet-format-structures/pom.xml": null,
            "parquet-generator/pom.xml": null,
            "parquet-hadoop-bundle/pom.xml": null,
            "parquet-hadoop/pom.xml": null,
            "parquet-hive-bundle/pom.xml": null,
            "parquet-hive/parquet-hive-binding/parquet-hive-0.10-binding/pom.xml": null,
            "parquet-hive/parquet-hive-binding/parquet-hive-0.12-binding/pom.xml": null,
            "parquet-hive/parquet-hive-binding/parquet-hive-binding-bundle/pom.xml": null,
            "parquet-hive/parquet-hive-binding/parquet-hive-binding-factory/pom.xml": null,
            "parquet-hive/parquet-hive-binding/parquet-hive-binding-interface/pom.xml": null,
            "parquet-hive/parquet-hive-binding/pom.xml": null,
            "parquet-hive/parquet-hive-storage-handler/pom.xml": null,
            "parquet-hive/pom.xml": null,
            "parquet-jackson/pom.xml": null,
            "parquet-pig-bundle/pom.xml": null,
            "parquet-pig/pom.xml": null,
            "parquet-protobuf/pom.xml": null,
            "parquet-scala/pom.xml": null,
            "parquet-scrooge/pom.xml": null,
            "parquet-thrift/pom.xml": null,
            "parquet-tools/pom.xml": null,
            "pom.xml": null
        }
    },
    "ac650407f7023fb3ded180ebb471386f4d011118": {
        "datetime": "2019-03-13T12:55:48+01:00",
        "summary": "[maven-release-plugin] prepare for next development iteration",
        "message": "[maven-release-plugin] prepare for next development iteration\n",
        "diff": {
            "parquet-arrow/pom.xml": null,
            "parquet-avro/pom.xml": null,
            "parquet-benchmarks/pom.xml": null,
            "parquet-cascading/pom.xml": null,
            "parquet-cascading3/pom.xml": null,
            "parquet-cli/pom.xml": null,
            "parquet-column/pom.xml": null,
            "parquet-common/pom.xml": null,
            "parquet-encoding/pom.xml": null,
            "parquet-format-structures/pom.xml": null,
            "parquet-generator/pom.xml": null,
            "parquet-hadoop-bundle/pom.xml": null,
            "parquet-hadoop/pom.xml": null,
            "parquet-hive-bundle/pom.xml": null,
            "parquet-hive/parquet-hive-binding/parquet-hive-0.10-binding/pom.xml": null,
            "parquet-hive/parquet-hive-binding/parquet-hive-0.12-binding/pom.xml": null,
            "parquet-hive/parquet-hive-binding/parquet-hive-binding-bundle/pom.xml": null,
            "parquet-hive/parquet-hive-binding/parquet-hive-binding-factory/pom.xml": null,
            "parquet-hive/parquet-hive-binding/parquet-hive-binding-interface/pom.xml": null,
            "parquet-hive/parquet-hive-binding/pom.xml": null,
            "parquet-hive/parquet-hive-storage-handler/pom.xml": null,
            "parquet-hive/pom.xml": null,
            "parquet-jackson/pom.xml": null,
            "parquet-pig-bundle/pom.xml": null,
            "parquet-pig/pom.xml": null,
            "parquet-protobuf/pom.xml": null,
            "parquet-scala/pom.xml": null,
            "parquet-scrooge/pom.xml": null,
            "parquet-thrift/pom.xml": null,
            "parquet-tools/pom.xml": null,
            "pom.xml": null
        }
    },
    "3e3049d042ffe033544e49ccac18a5edfc24adf0": {
        "datetime": "2019-03-19T13:58:01+01:00",
        "summary": "PARQUET-1544: Possible over-shading of modules (#628)",
        "message": "PARQUET-1544: Possible over-shading of modules (#628)\n\n",
        "diff": {
            "parquet-avro/pom.xml": null
        }
    },
    "9bf25176133051d2f987f0c2bb56dfbd5a7fec2d": {
        "datetime": "2019-03-19T14:10:06+01:00",
        "summary": "Update CHANGES.md for 1.11.0rc6",
        "message": "Update CHANGES.md for 1.11.0rc6\n",
        "diff": {
            "CHANGES.md": null
        }
    },
    "9756b0e2b35437a09716707a81e2ac0c187112ed": {
        "datetime": "2019-03-19T14:24:33+01:00",
        "summary": "[maven-release-plugin] prepare release apache-parquet-1.11.0",
        "message": "[maven-release-plugin] prepare release apache-parquet-1.11.0\n",
        "diff": {
            "parquet-arrow/pom.xml": null,
            "parquet-avro/pom.xml": null,
            "parquet-benchmarks/pom.xml": null,
            "parquet-cascading/pom.xml": null,
            "parquet-cascading3/pom.xml": null,
            "parquet-cli/pom.xml": null,
            "parquet-column/pom.xml": null,
            "parquet-common/pom.xml": null,
            "parquet-encoding/pom.xml": null,
            "parquet-format-structures/pom.xml": null,
            "parquet-generator/pom.xml": null,
            "parquet-hadoop-bundle/pom.xml": null,
            "parquet-hadoop/pom.xml": null,
            "parquet-hive-bundle/pom.xml": null,
            "parquet-hive/parquet-hive-binding/parquet-hive-0.10-binding/pom.xml": null,
            "parquet-hive/parquet-hive-binding/parquet-hive-0.12-binding/pom.xml": null,
            "parquet-hive/parquet-hive-binding/parquet-hive-binding-bundle/pom.xml": null,
            "parquet-hive/parquet-hive-binding/parquet-hive-binding-factory/pom.xml": null,
            "parquet-hive/parquet-hive-binding/parquet-hive-binding-interface/pom.xml": null,
            "parquet-hive/parquet-hive-binding/pom.xml": null,
            "parquet-hive/parquet-hive-storage-handler/pom.xml": null,
            "parquet-hive/pom.xml": null,
            "parquet-jackson/pom.xml": null,
            "parquet-pig-bundle/pom.xml": null,
            "parquet-pig/pom.xml": null,
            "parquet-protobuf/pom.xml": null,
            "parquet-scala/pom.xml": null,
            "parquet-scrooge/pom.xml": null,
            "parquet-thrift/pom.xml": null,
            "parquet-tools/pom.xml": null,
            "pom.xml": null
        }
    },
    "811310d01bfe3dcb4ca95aa8eed9ed6d806bf7c1": {
        "datetime": "2019-03-19T14:24:51+01:00",
        "summary": "[maven-release-plugin] prepare for next development iteration",
        "message": "[maven-release-plugin] prepare for next development iteration\n",
        "diff": {
            "parquet-arrow/pom.xml": null,
            "parquet-avro/pom.xml": null,
            "parquet-benchmarks/pom.xml": null,
            "parquet-cascading/pom.xml": null,
            "parquet-cascading3/pom.xml": null,
            "parquet-cli/pom.xml": null,
            "parquet-column/pom.xml": null,
            "parquet-common/pom.xml": null,
            "parquet-encoding/pom.xml": null,
            "parquet-format-structures/pom.xml": null,
            "parquet-generator/pom.xml": null,
            "parquet-hadoop-bundle/pom.xml": null,
            "parquet-hadoop/pom.xml": null,
            "parquet-hive-bundle/pom.xml": null,
            "parquet-hive/parquet-hive-binding/parquet-hive-0.10-binding/pom.xml": null,
            "parquet-hive/parquet-hive-binding/parquet-hive-0.12-binding/pom.xml": null,
            "parquet-hive/parquet-hive-binding/parquet-hive-binding-bundle/pom.xml": null,
            "parquet-hive/parquet-hive-binding/parquet-hive-binding-factory/pom.xml": null,
            "parquet-hive/parquet-hive-binding/parquet-hive-binding-interface/pom.xml": null,
            "parquet-hive/parquet-hive-binding/pom.xml": null,
            "parquet-hive/parquet-hive-storage-handler/pom.xml": null,
            "parquet-hive/pom.xml": null,
            "parquet-jackson/pom.xml": null,
            "parquet-pig-bundle/pom.xml": null,
            "parquet-pig/pom.xml": null,
            "parquet-protobuf/pom.xml": null,
            "parquet-scala/pom.xml": null,
            "parquet-scrooge/pom.xml": null,
            "parquet-thrift/pom.xml": null,
            "parquet-tools/pom.xml": null,
            "pom.xml": null
        }
    },
    "c5561becfbc17bb1643e24faed87424a612ea7f1": {
        "datetime": "2019-03-31T19:17:36+02:00",
        "summary": "Correct brew formula for thirft (#626)",
        "message": "Correct brew formula for thirft (#626)\n\nbrew formula for thrift is `brew install thrift@0.12` not thrift@0.12.0\r\nsee https://formulae.brew.sh/formula/thrift",
        "diff": {
            "README.md": null
        }
    },
    "62dcc68acaf64012bf731e103be780956f1f446d": {
        "datetime": "2019-04-17T14:57:49+02:00",
        "summary": "PARQUET-1557: Replace deprecated Apache Avro methods (#633)",
        "message": "PARQUET-1557: Replace deprecated Apache Avro methods (#633)\n\n",
        "diff": {
            "parquet-avro/src/main/java/org/apache/parquet/avro/AvroIndexedRecordConverter.java": [
                1,
                1
            ],
            "parquet-avro/src/main/java/org/apache/parquet/avro/AvroRecordConverter.java": [
                1,
                1
            ],
            "parquet-avro/src/test/java/org/apache/parquet/avro/TestReflectInputOutputFormat.java": [
                2,
                2
            ],
            "parquet-avro/src/test/java/org/apache/parquet/avro/TestSpecificInputOutputFormat.java": [
                2,
                2
            ],
            "parquet-avro/src/test/java/org/apache/parquet/avro/TestSpecificReadWrite.java": [
                1,
                1
            ]
        }
    },
    "12f3fd2c3e8349f54ffc8814f083c8b001701f25": {
        "datetime": "2019-05-01T16:14:19+02:00",
        "summary": "PARQUET-1558: Use try-with-resource in Apache Avro tests (#634)",
        "message": "PARQUET-1558: Use try-with-resource in Apache Avro tests (#634)\n\nWe can use the try-with-resource pattern to implicitly close the\r\nresources such as readers and writers, provided by Avro and Parquet",
        "diff": {
            "parquet-avro/src/test/java/org/apache/parquet/avro/TestInputOutputFormat.java": [
                10,
                10
            ],
            "parquet-avro/src/test/java/org/apache/parquet/avro/TestReadWrite.java": [
                124,
                123
            ],
            "parquet-avro/src/test/java/org/apache/parquet/avro/TestReadWriteOldListBehavior.java": [
                72,
                61
            ],
            "parquet-avro/src/test/java/org/apache/parquet/avro/TestReflectInputOutputFormat.java": [
                38,
                38
            ],
            "parquet-avro/src/test/java/org/apache/parquet/avro/TestReflectReadWrite.java": [
                18,
                20
            ],
            "parquet-avro/src/test/java/org/apache/parquet/avro/TestSpecificInputOutputFormat.java": [
                38,
                38
            ],
            "parquet-avro/src/test/java/org/apache/parquet/avro/TestSpecificReadWrite.java": [
                72,
                81
            ],
            "parquet-avro/src/test/java/org/apache/parquet/avro/TestStringBehavior.java": [
                55,
                22
            ]
        }
    },
    "2c257f055f0ef30b2a200a7a2e471425534a7010": {
        "datetime": "2019-05-09T08:21:24+02:00",
        "summary": "PARQUET-1557: Replace deprecated Apache Avro methods (#636)",
        "message": "PARQUET-1557: Replace deprecated Apache Avro methods (#636)\n\nSome methods are deprecated in Avro 1.8.2 and are being removed in Avro 1.9.0. This commit removes references to these methods from Parquet.",
        "diff": {
            "parquet-cli/src/main/java/org/apache/parquet/cli/json/AvroJson.java": [
                1,
                1
            ],
            "parquet-cli/src/main/java/org/apache/parquet/cli/util/Schemas.java": [
                4,
                4
            ]
        }
    },
    "63cfb5624c012187b57fbf29a464bd587ad60c33": {
        "datetime": "2019-05-09T12:57:53+02:00",
        "summary": "PARQUET-1555: Bump snappy-java to 1.1.7.3 (#632)",
        "message": "PARQUET-1555: Bump snappy-java to 1.1.7.3 (#632)\n\n",
        "diff": {
            "parquet-hadoop/pom.xml": null
        }
    },
    "222b0918b80b72cb6e750adebb19e6da45547492": {
        "datetime": "2019-05-24T15:28:16+02:00",
        "summary": "PARQUET-1585: Update old external links in the code base (#644)",
        "message": "PARQUET-1585: Update old external links in the code base (#644)\n\n",
        "diff": {
            "dev/travis-before_install.sh": null,
            "parquet-cascading/pom.xml": null,
            "parquet-cascading3/pom.xml": null,
            "parquet-format-structures/pom.xml": null,
            "parquet-scala/pom.xml": null,
            "parquet-scrooge/pom.xml": null
        }
    },
    "96a01489e0eba6304d1b029ec715a6d20b9d3308": {
        "datetime": "2019-05-27T13:32:23+02:00",
        "summary": "PARQUET-1577 Remove duplicate license (#640)",
        "message": "PARQUET-1577 Remove duplicate license (#640)\n\n",
        "diff": {
            "parquet-avro/src/test/java/org/apache/parquet/avro/TestGenericLogicalTypes.java": [
                18,
                0
            ]
        }
    },
    "c3e1a849d02042b324e4f72e1e4bba6c2a8da5bc": {
        "datetime": "2019-05-27T13:59:52+02:00",
        "summary": "PARQUET-1536: [parquet-cli] Add simple tests for each command (#625)",
        "message": "PARQUET-1536: [parquet-cli] Add simple tests for each command (#625)\n\nCurrently, parquet-cli has no tests. At first, adding simple tests for each command.",
        "diff": {
            "parquet-cli/src/test/java/org/apache/parquet/cli/commands/AvroFileTest.java": [
                0,
                39
            ],
            "parquet-cli/src/test/java/org/apache/parquet/cli/commands/CSVFileTest.java": [
                0,
                51
            ],
            "parquet-cli/src/test/java/org/apache/parquet/cli/commands/CSVSchemaCommandTest.java": [
                0,
                39
            ],
            "parquet-cli/src/test/java/org/apache/parquet/cli/commands/CatCommandTest.java": [
                0,
                38
            ],
            "parquet-cli/src/test/java/org/apache/parquet/cli/commands/CheckParquet251CommandTest.java": [
                0,
                38
            ],
            "parquet-cli/src/test/java/org/apache/parquet/cli/commands/ConvertCSVCommandTest.java": [
                0,
                41
            ],
            "parquet-cli/src/test/java/org/apache/parquet/cli/commands/ConvertCommandTest.java": [
                0,
                41
            ],
            "parquet-cli/src/test/java/org/apache/parquet/cli/commands/FileTest.java": [
                0,
                57
            ],
            "parquet-cli/src/test/java/org/apache/parquet/cli/commands/ParquetFileTest.java": [
                0,
                101
            ],
            "parquet-cli/src/test/java/org/apache/parquet/cli/commands/ParquetMetadataCommandTest.java": [
                0,
                38
            ],
            "parquet-cli/src/test/java/org/apache/parquet/cli/commands/SchemaCommandTest.java": [
                0,
                38
            ],
            "parquet-cli/src/test/java/org/apache/parquet/cli/commands/ShowColumnIndexTest.java": [
                0,
                38
            ],
            "parquet-cli/src/test/java/org/apache/parquet/cli/commands/ShowDictionaryCommandTest.java": [
                0,
                39
            ],
            "parquet-cli/src/test/java/org/apache/parquet/cli/commands/ShowPagesCommandTest.java": [
                0,
                38
            ],
            "parquet-cli/src/test/java/org/apache/parquet/cli/commands/ToAvroCommandTest.java": [
                0,
                33
            ]
        }
    },
    "f1a719b264cec72e17db463aaa413d3871d068a6": {
        "datetime": "2019-05-27T16:22:31+02:00",
        "summary": "PARQUET-1534:  [parquet-cli] IllegalArgumentException on Windows (#627)",
        "message": "PARQUET-1534:  [parquet-cli] IllegalArgumentException on Windows (#627)\n\nCalling BaseCommand#qualifiedURI with Windows file path, java.net.URI.create throws IllegalArgumentException and the command execution is aborted.",
        "diff": {
            "parquet-cli/src/main/java/org/apache/parquet/cli/BaseCommand.java": [
                7,
                8
            ],
            "parquet-cli/src/test/java/org/apache/parquet/cli/BaseCommandTest.java": [
                0,
                100
            ]
        }
    },
    "882cbf8a9ae347b321c2edb5902af544d9fb6242": {
        "datetime": "2019-05-27T18:29:58+02:00",
        "summary": "PARQUET-1579 Add Github PR template (#642)",
        "message": "PARQUET-1579 Add Github PR template (#642)\n\n",
        "diff": {
            ".github/PULL_REQUEST_TEMPLATE.md": null,
            "pom.xml": null
        }
    },
    "1e5fda5310687b0856e74f00a4ea420b6b1ab34d": {
        "datetime": "2019-05-28T14:53:02+02:00",
        "summary": "PARQUET-1441: SchemaParseException: Can't redefine: list in AvroIndexedRecordConverter (#560)",
        "message": "PARQUET-1441: SchemaParseException: Can't redefine: list in AvroIndexedRecordConverter (#560)\n\nParquet Avro reader couldn't convert a schema where a group field name is reused\r\nin an inner structure. The converter created an Avro record schema in this case,\r\nbut in Avro record types should have a unique name, therefore the result was an invalid Avro\r\nschema. This patch fixes this case by adding a namespace for the record if the name was\r\ndefined before, this way making the record names unique.",
        "diff": {
            "parquet-avro/src/main/java/org/apache/parquet/avro/AvroSchemaConverter.java": [
                12,
                15
            ],
            "parquet-avro/src/test/java/org/apache/parquet/avro/AvroTestUtil.java": [
                2,
                6
            ],
            "parquet-avro/src/test/java/org/apache/parquet/avro/TestAvroSchemaConverter.java": [
                0,
                63
            ],
            "parquet-avro/src/test/java/org/apache/parquet/avro/TestReadWrite.java": [
                3,
                37
            ],
            "parquet-avro/src/test/resources/nested_array.avsc": null
        }
    },
    "54777b46da768df3ff88548c6b6b70bd52fba0dd": {
        "datetime": "2019-05-30T14:11:58+02:00",
        "summary": "PARQUET-1556 Use try-with-resource in Apache Avro tests (#639)",
        "message": "PARQUET-1556 Use try-with-resource in Apache Avro tests (#639)\n\n",
        "diff": {
            "parquet-avro/src/test/java/org/apache/parquet/avro/AvroTestUtil.java": [
                16,
                10
            ],
            "parquet-avro/src/test/java/org/apache/parquet/avro/TestArrayCompatibility.java": [
                4,
                5
            ],
            "parquet-avro/src/test/java/org/apache/parquet/avro/TestReadWrite.java": [
                61,
                66
            ],
            "parquet-avro/src/test/java/org/apache/parquet/avro/TestReadWriteOldListBehavior.java": [
                64,
                64
            ]
        }
    },
    "9d6fb45e54da65cbd407bb3e7bff0981aa9f8f9f": {
        "datetime": "2019-05-30T14:12:24+02:00",
        "summary": "PARQUET-1576 Bump Apache Avro to 1.9.0 (#638)",
        "message": "PARQUET-1576 Bump Apache Avro to 1.9.0 (#638)\n\n",
        "diff": {
            "parquet-avro/src/test/java/org/apache/parquet/avro/AvroTestUtil.java": [
                2,
                3
            ],
            "parquet-avro/src/test/java/org/apache/parquet/avro/TestAvroSchemaConverter.java": [
                11,
                11
            ],
            "parquet-avro/src/test/java/org/apache/parquet/avro/TestReflectLogicalTypes.java": [
                4,
                3
            ],
            "parquet-avro/src/test/java/org/apache/parquet/avro/TestSpecificReadWrite.java": [
                15,
                17
            ],
            "pom.xml": null
        }
    },
    "47398be76cfb6634000532e9432430c4676442dd": {
        "datetime": "2019-06-03T16:40:06+02:00",
        "summary": "PARQUET-1375: Upgrade to Jackson 2.9.9 (#616)",
        "message": "PARQUET-1375: Upgrade to Jackson 2.9.9 (#616)\n\n",
        "diff": {
            "parquet-cli/pom.xml": null,
            "parquet-cli/src/main/java/org/apache/parquet/cli/json/AvroJson.java": [
                8,
                5
            ],
            "parquet-cli/src/main/java/org/apache/parquet/cli/json/AvroJsonReader.java": [
                15,
                7
            ],
            "parquet-cli/src/main/java/org/apache/parquet/cli/util/Schemas.java": [
                1,
                1
            ],
            "parquet-hadoop/pom.xml": null,
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/metadata/ParquetMetadata.java": [
                6,
                7
            ],
            "parquet-jackson/README.md": null,
            "parquet-jackson/pom.xml": null,
            "parquet-pig/pom.xml": null,
            "parquet-pig/src/main/java/org/apache/parquet/pig/summary/StringSummaryData.java": [
                5,
                5
            ],
            "parquet-pig/src/main/java/org/apache/parquet/pig/summary/Summary.java": [
                4,
                0
            ],
            "parquet-pig/src/main/java/org/apache/parquet/pig/summary/SummaryData.java": [
                8,
                8
            ],
            "parquet-pig/src/test/java/org/apache/parquet/pig/summary/TestSummary.java": [
                3,
                1
            ],
            "parquet-scrooge/pom.xml": null,
            "parquet-thrift/pom.xml": null,
            "parquet-thrift/src/main/java/org/apache/parquet/thrift/struct/CompatibilityRunner.java": [
                1,
                1
            ],
            "parquet-thrift/src/main/java/org/apache/parquet/thrift/struct/JSON.java": [
                6,
                5
            ],
            "parquet-thrift/src/main/java/org/apache/parquet/thrift/struct/ThriftField.java": [
                2,
                2
            ],
            "parquet-thrift/src/main/java/org/apache/parquet/thrift/struct/ThriftType.java": [
                8,
                7
            ],
            "parquet-tools/src/main/java/org/apache/parquet/tools/json/JsonRecordFormatter.java": [
                1,
                1
            ],
            "parquet-tools/src/main/java/org/apache/parquet/tools/read/SimpleMapRecord.java": [
                1,
                1
            ],
            "parquet-tools/src/main/java/org/apache/parquet/tools/read/SimpleRecord.java": [
                2,
                2
            ],
            "parquet-tools/src/test/java/org/apache/parquet/tools/read/TestJsonRecordFormatter.java": [
                1,
                1
            ],
            "pom.xml": null
        }
    },
    "0b909ab3ed9fd9411092de359d4217aa6c9abc21": {
        "datetime": "2019-07-04T10:55:34+02:00",
        "summary": "PARQUET-1550: CleanUtil does not work in Java 11 (#654)",
        "message": "PARQUET-1550: CleanUtil does not work in Java 11 (#654)\n\nCleanUtil does not work in Java 11",
        "diff": {
            "parquet-hadoop/pom.xml": null,
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/codec/CleanUtil.java": [
                28,
                70
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/codec/SnappyCompressor.java": [
                4,
                4
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/codec/SnappyDecompressor.java": [
                6,
                6
            ]
        }
    },
    "f7e74ba94be0516ccc8f1178b44a9aaa6bbb10f0": {
        "datetime": "2019-07-08T21:33:24+02:00",
        "summary": "PARQUET-1604: Bump fastutil from 7.0.13 to 8.2.3 (#655)",
        "message": "PARQUET-1604: Bump fastutil from 7.0.13 to 8.2.3 (#655)\n\n",
        "diff": {
            "pom.xml": null
        }
    },
    "8ff867a2e183f50b7b2f2c6e51d07c5314577ce0": {
        "datetime": "2019-07-09T10:27:48+02:00",
        "summary": "PARQUET-1615: getRecordWriter shouldn't hardcode CREAT mode when new ParquetFileWriter (#660)",
        "message": "PARQUET-1615: getRecordWriter shouldn't hardcode CREAT mode when new ParquetFileWriter (#660)\n\n",
        "diff": {
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ParquetOutputFormat.java": [
                3,
                18
            ]
        }
    },
    "1487456830bcad1ec1bef25539cf2e5bd10ddf67": {
        "datetime": "2019-07-10T10:15:23+02:00",
        "summary": "PARQUET-1552: upgrade protoc-jar-maven-plugin to 3.8.0 to fix proxy issue (#659)",
        "message": "PARQUET-1552: upgrade protoc-jar-maven-plugin to 3.8.0 to fix proxy issue (#659)\n\n",
        "diff": {
            "parquet-protobuf/pom.xml": null
        }
    },
    "0861ddff9572fef8b9002d7ebaba3bf62455cee2": {
        "datetime": "2019-07-11T06:55:30+01:00",
        "summary": "PARQUET-1616: Enable Maven batch mode (#661)",
        "message": "PARQUET-1616: Enable Maven batch mode (#661)\n\n",
        "diff": {
            ".travis.yml": null
        }
    },
    "b34b077486473c46ff5199421c79cd2e797e5817": {
        "datetime": "2019-07-17T15:14:13+02:00",
        "summary": "PARQUET-1488: UserDefinedPredicate throw NPE (#663)",
        "message": "PARQUET-1488: UserDefinedPredicate throw NPE (#663)\n\n\r\n",
        "diff": {
            "parquet-column/src/main/java/org/apache/parquet/filter2/predicate/UserDefinedPredicate.java": [
                0,
                15
            ],
            "parquet-column/src/main/java/org/apache/parquet/internal/column/columnindex/ColumnIndexBuilder.java": [
                2,
                2
            ],
            "parquet-column/src/main/java/org/apache/parquet/internal/filter2/columnindex/ColumnIndexFilter.java": [
                2,
                2
            ],
            "parquet-generator/src/main/java/org/apache/parquet/filter2/IncrementallyUpdatedFilterPredicateGenerator.java": [
                1,
                1
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/filter2/dictionarylevel/DictionaryFilter.java": [
                2,
                2
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/filter2/statisticslevel/StatisticsFilter.java": [
                4,
                4
            ],
            "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/TestColumnIndexFiltering.java": [
                1,
                3
            ]
        }
    },
    "54d3703b0a460499d24f52b06dbc3ec8269c094a": {
        "datetime": "2019-07-23T11:26:54+02:00",
        "summary": "PARQUET-1600: Fix shebang in parquet-benchmarks/run.sh (#651)",
        "message": "PARQUET-1600: Fix shebang in parquet-benchmarks/run.sh (#651)\n\n",
        "diff": {
            "parquet-benchmarks/run.sh": null
        }
    },
    "14958d40c0c3d9590d24158c48a2a37106df36a9": {
        "datetime": "2019-07-23T11:30:17+02:00",
        "summary": "PARQUET-1606: Fix invalid tests scope (#657)",
        "message": "PARQUET-1606: Fix invalid tests scope (#657)\n\n",
        "diff": {
            "parquet-arrow/pom.xml": null
        }
    },
    "fcc5d1a5a669570de3daeafd3f3b7788aa618536": {
        "datetime": "2019-07-24T08:35:21+02:00",
        "summary": "PARQUET-1580: Page-level CRC checksum verfication for DataPageV1 (#647)",
        "message": "PARQUET-1580: Page-level CRC checksum verfication for DataPageV1 (#647)\n\n* Page-level checksums for DataPageV1\r\n\r\n* Got rid of redundant constant\r\n\r\n* Use more direct way of obtaining defaults\r\n\r\n* Revised implementation, updated tests, addressed review comments\r\n\r\n* Revert auto whitespace trimming\r\n\r\n* Variable rename for consistency\r\n\r\n* Revert whitespace changes\r\n\r\n* Revert more whitespace changes\r\n\r\n* Addressed code review comments\r\n\r\n* Enable writing out checksums by default\r\n\r\n* Added benchmarks\r\n\r\n* Addressed review comments\r\n\r\n* Addressed test failures\r\n\r\n* Added run script for checksum benchmarks\r\n\r\n* Addressed code review comments\r\n",
        "diff": {
            "parquet-benchmarks/run_checksums.sh": null,
            "parquet-benchmarks/src/main/java/org/apache/parquet/benchmarks/BenchmarkFiles.java": [
                0,
                22
            ],
            "parquet-benchmarks/src/main/java/org/apache/parquet/benchmarks/PageChecksumDataGenerator.java": [
                0,
                127
            ],
            "parquet-benchmarks/src/main/java/org/apache/parquet/benchmarks/PageChecksumReadBenchmarks.java": [
                0,
                179
            ],
            "parquet-benchmarks/src/main/java/org/apache/parquet/benchmarks/PageChecksumWriteBenchmarks.java": [
                0,
                160
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/ParquetProperties.java": [
                2,
                19
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/page/Page.java": [
                0,
                16
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/HadoopReadOptions.java": [
                5,
                10
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/ParquetReadOptions.java": [
                2,
                28
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/format/converter/ParquetMetadataConverter.java": [
                5,
                48
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ColumnChunkPageReadStore.java": [
                6,
                15
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ColumnChunkPageWriteStore.java": [
                4,
                32
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/InternalParquetRecordWriter.java": [
                1,
                1
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ParquetFileReader.java": [
                14,
                50
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ParquetFileWriter.java": [
                5,
                41
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ParquetInputFormat.java": [
                0,
                5
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ParquetOutputFormat.java": [
                1,
                17
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ParquetReader.java": [
                0,
                10
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ParquetWriter.java": [
                1,
                23
            ],
            "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/TestColumnChunkPageWriteStore.java": [
                0,
                1
            ],
            "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/TestDataPageV1Checksums.java": [
                0,
                563
            ],
            "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/TestParquetFileWriter.java": [
                0,
                4
            ],
            "parquet-tools/src/main/java/org/apache/parquet/tools/command/DumpCommand.java": [
                0,
                18
            ]
        }
    },
    "347178e135e821673107739bf3894a8306f57a47": {
        "datetime": "2019-07-24T17:11:55+02:00",
        "summary": "PARQUET-1605: Bump maven-javadoc-plugin from 2.9 to 3.1.0 (#656)",
        "message": "PARQUET-1605: Bump maven-javadoc-plugin from 2.9 to 3.1.0 (#656)\n\n* PARQUET-1605: Bump maven-javadoc-plugin from 2.9 to 3.1.0\r\n\r\n* Disable Doclint on the generated Thrift sources\r\n",
        "diff": {
            "parquet-format-structures/pom.xml": null,
            "pom.xml": null
        }
    },
    "93af6b4e8db84c813530cda763f378858e8c7700": {
        "datetime": "2019-07-25T15:15:35+02:00",
        "summary": "PARQUET-1303 correct ClassCastException for Avro @Stringable fields (#482)",
        "message": "PARQUET-1303 correct ClassCastException for Avro @Stringable fields (#482)\n\n\r\n",
        "diff": {
            "parquet-avro/src/main/java/org/apache/parquet/avro/AvroWriteSupport.java": [
                2,
                4
            ],
            "parquet-avro/src/test/java/org/apache/parquet/avro/TestReflectLogicalTypes.java": [
                4,
                14
            ],
            "parquet-avro/src/test/java/org/apache/parquet/avro/TestReflectReadWrite.java": [
                1,
                23
            ]
        }
    },
    "8ab68bcaafe8c6f08fabbeb40d1cfa2f3d5cb84e": {
        "datetime": "2019-07-26T11:30:13+02:00",
        "summary": "Revert \"PARQUET-1605: Bump maven-javadoc-plugin from 2.9 to 3.1.0 (#656)\"",
        "message": "Revert \"PARQUET-1605: Bump maven-javadoc-plugin from 2.9 to 3.1.0 (#656)\"\n\nThis reverts commit 347178e135e821673107739bf3894a8306f57a47.\n",
        "diff": {
            "parquet-format-structures/pom.xml": null,
            "pom.xml": null
        }
    },
    "0d9bad5fd1b3d79da530dcfba414877d737e5717": {
        "datetime": "2019-08-15T16:04:15+02:00",
        "summary": "PARQUET-1637: Builds are failing because default jdk changed to openjdk11 on Travis (#665)",
        "message": "PARQUET-1637: Builds are failing because default jdk changed to openjdk11 on Travis (#665)\n\n",
        "diff": {
            ".travis.yml": null
        }
    },
    "340d157bda4c33b7d126cad82e222a2cfb1b2953": {
        "datetime": "2019-09-05T08:56:31+02:00",
        "summary": "PARQUET-1530: Remove Dependency on commons-codec (#618)",
        "message": "PARQUET-1530: Remove Dependency on commons-codec (#618)\n\n",
        "diff": {
            "parquet-cli/pom.xml": null,
            "parquet-cli/src/main/java/org/apache/parquet/cli/Util.java": [
                11,
                6
            ],
            "parquet-cli/src/main/resources/META-INF/LICENSE": null,
            "parquet-column/pom.xml": null,
            "parquet-encoding/pom.xml": null,
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/util/SerializationUtil.java": [
                8,
                7
            ],
            "parquet-tools/src/main/resources/META-INF/LICENSE": null,
            "pom.xml": null
        }
    },
    "14c1e815dfcac7f2aa7bcebf24a7fa9c14cbf961": {
        "datetime": "2019-09-05T10:07:23+02:00",
        "summary": "PARQUET-1445: Remove Files.java (#584)",
        "message": "PARQUET-1445: Remove Files.java (#584)\n\n",
        "diff": {
            "parquet-common/src/main/java/org/apache/parquet/Files.java": [
                1,
                4
            ],
            "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/TestInputOutputFormatWithPadding.java": [
                6,
                3
            ],
            "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/example/TestInputOutputFormat.java": [
                6,
                9
            ],
            "parquet-thrift/src/test/java/org/apache/parquet/thrift/TestThriftRecordConverter.java": [
                4,
                4
            ]
        }
    },
    "be004864d5b243577fd9b650c3818d7105b2fffc": {
        "datetime": "2019-09-09T17:47:42+02:00",
        "summary": "PARQUET-1607: Remove duplicate maven-enforcer-plugin (#658)",
        "message": "PARQUET-1607: Remove duplicate maven-enforcer-plugin (#658)\n\n* PARQUET-1607: Remove duplicate maven-enforcer-plugin\r\n\r\n[WARNING] Some problems were encountered while building the effective model for org.apache.parquet:parquet-cascading3:jar:1.12.0-SNAPSHOT\r\n[WARNING] 'build.plugins.plugin.(groupId:artifactId)' must be unique but found duplicate declaration of plugin org.apache.maven.plugins:maven-enforcer-plugin @ org.apache.parquet:parquet-cascading3:[unknown-version], /home/travis/build/Fokko/parquet-mr/parquet-cascading3/pom.xml, line 167, column 15\r\n[WARNING]\r\n\r\n* Add exclusion for slf4j-log4j12\r\n",
        "diff": {
            "parquet-cascading3/pom.xml": null
        }
    },
    "e0ab7af5d2867544ce9d694d4968c473596e50dd": {
        "datetime": "2019-09-21T09:29:59+02:00",
        "summary": "PARQUET-1654: Remove unnecessary options when building thrift (#676)",
        "message": "PARQUET-1654: Remove unnecessary options when building thrift (#676)\n\n",
        "diff": {
            "README.md": null,
            "dev/travis-before_install.sh": null
        }
    },
    "e10a645230c633feae8bb533fa31c77d244e442e": {
        "datetime": "2019-09-21T09:34:06+02:00",
        "summary": "PARQUET-1649: Bump Jackson Databind to 2.9.9.3 (#674)",
        "message": "PARQUET-1649: Bump Jackson Databind to 2.9.9.3 (#674)\n\nhttps://issues.apache.org/jira/browse/PARQUET-1649",
        "diff": {
            "parquet-cli/pom.xml": null,
            "parquet-hadoop/pom.xml": null,
            "parquet-jackson/pom.xml": null,
            "parquet-pig/pom.xml": null,
            "parquet-thrift/pom.xml": null,
            "pom.xml": null
        }
    },
    "e9d87163c50bf91e7ae8c4382095fa641877fa07": {
        "datetime": "2019-09-22T08:59:37+02:00",
        "summary": "PARQUET-1601: Add zstd support to parquet-cli to-avro (#653)",
        "message": "PARQUET-1601: Add zstd support to parquet-cli to-avro (#653)\n\n",
        "diff": {
            "parquet-cli/pom.xml": null,
            "parquet-cli/src/main/java/org/apache/parquet/cli/util/Codecs.java": [
                0,
                2
            ],
            "parquet-cli/src/test/java/org/apache/parquet/cli/commands/AvroFileTest.java": [
                0,
                5
            ],
            "parquet-cli/src/test/java/org/apache/parquet/cli/commands/ToAvroCommandTest.java": [
                0,
                23
            ],
            "pom.xml": null
        }
    },
    "56f164fedbd47b5b2da0f39c820a55f32f944cf3": {
        "datetime": "2019-09-23T12:45:49+02:00",
        "summary": "PARQUET-1661: Upgrade to Avro 1.9.1 (#682)",
        "message": "PARQUET-1661: Upgrade to Avro 1.9.1 (#682)\n\n",
        "diff": {
            "pom.xml": null
        }
    },
    "76c40e7039069a71448f6f30e3de4e86302d17e7": {
        "datetime": "2019-09-24T06:59:59+02:00",
        "summary": "PARQUET-1542: Merge multiple I/O to one time I/O in method readFooter (#624)",
        "message": "PARQUET-1542: Merge multiple I/O to one time I/O in method readFooter (#624)\n\n\r\n",
        "diff": {
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ParquetFileReader.java": [
                1,
                9
            ]
        }
    },
    "0cb5ead05a2acdb6b492c370b72970764cb7f8d0": {
        "datetime": "2019-09-24T10:05:13+02:00",
        "summary": "PARQUET-1662: Upgrade Jackson to version 2.9.10 (#683)",
        "message": "PARQUET-1662: Upgrade Jackson to version 2.9.10 (#683)\n\n",
        "diff": {
            "pom.xml": null
        }
    },
    "6e072cfa9ff47d45c7ebcac3d03ce5877e33bb4a": {
        "datetime": "2019-09-24T10:13:50+02:00",
        "summary": "PARQUET-1665: Upgrade zstd-jni to 1.4.0-1 (#684)",
        "message": "PARQUET-1665: Upgrade zstd-jni to 1.4.0-1 (#684)\n\n",
        "diff": {
            "pom.xml": null
        }
    },
    "7c4d1ec859d46bead9f8ed9446d2d5875082211d": {
        "datetime": "2019-09-24T12:22:40+02:00",
        "summary": "PARQUET-1644: Clean up some benchmark code and docs. (#672)",
        "message": "PARQUET-1644: Clean up some benchmark code and docs. (#672)\n\n\r\n",
        "diff": {
            "parquet-benchmarks/README.md": null,
            "parquet-benchmarks/run.sh": null,
            "parquet-benchmarks/run_checksums.sh": null,
            "parquet-benchmarks/src/main/java/org/apache/parquet/benchmarks/BenchmarkFiles.java": [
                0,
                2
            ],
            "parquet-benchmarks/src/main/java/org/apache/parquet/benchmarks/DataGenerator.java": [
                8,
                1
            ],
            "parquet-benchmarks/src/main/java/org/apache/parquet/benchmarks/PageChecksumDataGenerator.java": [
                22,
                1
            ],
            "parquet-benchmarks/src/main/java/org/apache/parquet/benchmarks/PageChecksumReadBenchmarks.java": [
                23,
                40
            ],
            "parquet-benchmarks/src/main/java/org/apache/parquet/benchmarks/PageChecksumWriteBenchmarks.java": [
                19,
                37
            ],
            "parquet-benchmarks/src/main/java/org/apache/parquet/benchmarks/ReadBenchmarks.java": [
                0,
                25
            ],
            "parquet-benchmarks/src/main/java/org/apache/parquet/benchmarks/WriteBenchmarks.java": [
                1,
                10
            ]
        }
    },
    "600ffba714552e2e8a29ffa4e2eec40a15060a4b": {
        "datetime": "2019-10-02T15:08:05+02:00",
        "summary": "PARQUET-1669: Disable compiling all libraries when building thrift (#688)",
        "message": "PARQUET-1669: Disable compiling all libraries when building thrift (#688)\n\n",
        "diff": {
            "README.md": null,
            "dev/travis-before_install.sh": null
        }
    },
    "6db728711491e3ce214d11358d0769bf4075ff33": {
        "datetime": "2019-10-04T10:59:32+02:00",
        "summary": "PARQUET-1671: Upgrade Yetus to 0.11.0 (#689)",
        "message": "PARQUET-1671: Upgrade Yetus to 0.11.0 (#689)\n\n",
        "diff": {
            "parquet-common/pom.xml": null
        }
    },
    "7772644c555f5c86af07c6906b66a99c9330c098": {
        "datetime": "2019-10-06T22:55:27+02:00",
        "summary": "PARQUET-1673: Upgrade parquet-mr format version to 2.7.0 (#690)",
        "message": "PARQUET-1673: Upgrade parquet-mr format version to 2.7.0 (#690)\n\n",
        "diff": {
            "pom.xml": null
        }
    },
    "59ae0346cdda2c2fa00698276d9cba82a73c6856": {
        "datetime": "2019-10-07T10:36:05+03:00",
        "summary": "PARQUET-1578: Introduce Lambdas (#641)",
        "message": "PARQUET-1578: Introduce Lambdas (#641)\n\nTo improve on readability",
        "diff": {
            "parquet-avro/src/test/java/org/apache/parquet/avro/TestArrayCompatibility.java": [
                465,
                419
            ],
            "parquet-avro/src/test/java/org/apache/parquet/avro/TestAvroSchemaConverter.java": [
                30,
                5
            ],
            "parquet-column/src/main/java/org/apache/parquet/io/api/Binary.java": [
                6,
                1
            ],
            "parquet-column/src/test/java/org/apache/parquet/schema/TestTypeBuilders.java": [
                183,
                70
            ],
            "parquet-column/src/test/java/org/apache/parquet/schema/TestTypeUtil.java": [
                24,
                15
            ],
            "parquet-common/src/test/java/org/apache/parquet/bytes/TestByteBufferInputStreams.java": [
                36,
                14
            ],
            "parquet-common/src/test/java/org/apache/parquet/io/TestDelegatingSeekableInputStream.java": [
                30,
                13
            ],
            "parquet-common/src/test/java/org/apache/parquet/util/TestDynConstructors.java": [
                86,
                16
            ],
            "parquet-common/src/test/java/org/apache/parquet/util/TestDynMethods.java": [
                116,
                21
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ParquetFileReader.java": [
                29,
                23
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ParquetFileWriter.java": [
                7,
                1
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/PrintFooter.java": [
                9,
                5
            ],
            "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/TestMemoryManager.java": [
                6,
                1
            ],
            "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/TestParquetWriter.java": [
                10,
                7
            ],
            "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/TestParquetWriterAppendBlocks.java": [
                14,
                8
            ],
            "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/util/TestHadoop2ByteBufferReads.java": [
                12,
                6
            ]
        }
    },
    "10f57a3779264ba222288defd1472d66ac2ae135": {
        "datetime": "2019-10-07T11:24:51+02:00",
        "summary": "PARQUET-1596: PARQUET-1375 broke parquet-cli's to-avro command (#648)",
        "message": "PARQUET-1596: PARQUET-1375 broke parquet-cli's to-avro command (#648)\n\n* PARQUET-1596: PARQUET-1375 broke parquet-cli's to-avro command\r\n\r\nThe expected NPE:\r\n\r\ncat /Users/fokkodriesprong/Desktop/parquet-mr/parquet-cli/target/surefire-reports/org.apache.parquet.cli.commands.ToAvroCommandTest.txt\r\n-------------------------------------------------------------------------------\r\nTest set: org.apache.parquet.cli.commands.ToAvroCommandTest\r\n-------------------------------------------------------------------------------\r\nTests run: 2, Failures: 0, Errors: 1, Skipped: 0, Time elapsed: 0.154 sec <<< FAILURE!\r\ntestToAvroCommandFromJson(org.apache.parquet.cli.commands.ToAvroCommandTest)  Time elapsed: 0.052 sec  <<< ERROR!\r\njava.lang.NullPointerException\r\n\tat org.apache.hadoop.fs.FileSystem.getDefaultUri(FileSystem.java:180)\r\n\tat org.apache.hadoop.fs.FileSystem.get(FileSystem.java:361)\r\n\tat org.apache.hadoop.fs.FileSystem.getLocal(FileSystem.java:344)\r\n\tat org.apache.parquet.cli.BaseCommand.defaultFS(BaseCommand.java:81)\r\n\tat org.apache.parquet.cli.BaseCommand.qualifiedPath(BaseCommand.java:164)\r\n\tat org.apache.parquet.cli.BaseCommand.openSeekable(BaseCommand.java:215)\r\n\tat org.apache.parquet.cli.BaseCommand.getAvroSchema(BaseCommand.java:375)\r\n\tat org.apache.parquet.cli.commands.ToAvroCommand.run(ToAvroCommand.java:93)\r\n\tat org.apache.parquet.cli.commands.ToAvroCommandTest.testToAvroCommandFromJson(ToAvroCommandTest.java:72)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\r\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\r\n\tat java.lang.reflect.Method.invoke(Method.java:498)\r\n\tat org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:50)\r\n\tat org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)\r\n\tat org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:47)\r\n\tat org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)\r\n\tat org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)\r\n\tat org.junit.rules.ExternalResource$1.evaluate(ExternalResource.java:48)\r\n\tat org.junit.rules.ExternalResource$1.evaluate(ExternalResource.java:48)\r\n\tat org.junit.rules.RunRules.evaluate(RunRules.java:20)\r\n\tat org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:325)\r\n\tat org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:78)\r\n\tat org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:57)\r\n\tat org.junit.runners.ParentRunner$3.run(ParentRunner.java:290)\r\n\tat org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:71)\r\n\tat org.junit.runners.ParentRunner.runChildren(ParentRunner.java:288)\r\n\tat org.junit.runners.ParentRunner.access$000(ParentRunner.java:58)\r\n\tat org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:268)\r\n\tat org.junit.runners.ParentRunner.run(ParentRunner.java:363)\r\n\tat org.apache.maven.surefire.junit4.JUnit4TestSet.execute(JUnit4TestSet.java:53)\r\n\tat org.apache.maven.surefire.junit4.JUnit4Provider.executeTestSet(JUnit4Provider.java:123)\r\n\tat org.apache.maven.surefire.junit4.JUnit4Provider.invoke(JUnit4Provider.java:104)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\r\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\r\n\tat java.lang.reflect.Method.invoke(Method.java:498)\r\n\tat org.apache.maven.surefire.util.ReflectionUtils.invokeMethodWithArray(ReflectionUtils.java:164)\r\n\tat org.apache.maven.surefire.booter.ProviderFactory$ProviderProxy.invoke(ProviderFactory.java:110)\r\n\tat org.apache.maven.surefire.booter.SurefireStarter.invokeProvider(SurefireStarter.java:175)\r\n\tat org.apache.maven.surefire.booter.SurefireStarter.runSuitesInProcessWhenForked(SurefireStarter.java:107)\r\n\tat org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:68)\r\n",
        "diff": {
            "parquet-cli/src/main/java/org/apache/parquet/cli/BaseCommand.java": [
                1,
                3
            ],
            "parquet-cli/src/main/java/org/apache/parquet/cli/commands/ToAvroCommand.java": [
                11,
                11
            ],
            "parquet-cli/src/main/java/org/apache/parquet/cli/json/AvroJson.java": [
                1,
                3
            ],
            "parquet-cli/src/test/java/org/apache/parquet/cli/commands/ToAvroCommandTest.java": [
                1,
                39
            ],
            "pom.xml": null
        }
    },
    "52a502ebbf8a5525ea09d98fd75be7ccff08501c": {
        "datetime": "2019-10-14T20:42:54+02:00",
        "summary": "PARQUET-0000: Fix typo (#666)",
        "message": "PARQUET-0000: Fix typo (#666)\n\n",
        "diff": {
            "parquet-protobuf/src/main/java/org/apache/parquet/proto/ProtoSchemaConverter.java": [
                1,
                1
            ]
        }
    },
    "57bd24350663161b8a25c9f3385a2dc179039044": {
        "datetime": "2019-10-14T20:43:37+02:00",
        "summary": "PARQUET-0000: Improved formatting (#673)",
        "message": "PARQUET-0000: Improved formatting (#673)\n\n",
        "diff": {
            "parquet-tools/README.md": null
        }
    },
    "0c6a650a01d4075775af8aecdca14af78c5e7157": {
        "datetime": "2019-10-18T08:37:12+02:00",
        "summary": "PARQUET-1650: Implement unit test to validate column/offset indexes (#675)",
        "message": "PARQUET-1650: Implement unit test to validate column/offset indexes (#675)\n\n",
        "diff": {
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ColumnIndexValidator.java": [
                0,
                613
            ],
            "parquet-hadoop/src/test/java/org/apache/parquet/statistics/RandomValues.java": [
                3,
                43
            ],
            "parquet-hadoop/src/test/java/org/apache/parquet/statistics/TestColumnIndexes.java": [
                0,
                300
            ]
        }
    },
    "2117abcbd0ae316169e7f66655e0d202553bd290": {
        "datetime": "2019-10-22T15:24:20+02:00",
        "summary": "PARQUET-1682: Maintain forward compatibility for TIME/TIMESTAMP (#694)",
        "message": "PARQUET-1682: Maintain forward compatibility for TIME/TIMESTAMP (#694)\n\n",
        "diff": {
            "parquet-column/src/main/java/org/apache/parquet/schema/LogicalTypeAnnotation.java": [
                6,
                0
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/format/converter/ParquetMetadataConverter.java": [
                6,
                0
            ],
            "parquet-hadoop/src/test/java/org/apache/parquet/format/converter/TestParquetMetadataConverter.java": [
                4,
                4
            ]
        }
    },
    "2122a8a8e0fcc08307a5e1926b234bcfe3286ec1": {
        "datetime": "2019-10-23T07:33:33+02:00",
        "summary": "PARQUET-1683: Remove unnecessary string conversions (#695)",
        "message": "PARQUET-1683: Remove unnecessary string conversions (#695)\n\nRemove unnecessary string converting \r\nin readFooter method.",
        "diff": {
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ParquetFileReader.java": [
                3,
                2
            ]
        }
    },
    "4648b0609189e270c5b3bbf114b6057b943fc3be": {
        "datetime": "2019-10-23T15:22:20+02:00",
        "summary": "PARQUET-XXXX: Minor Javadoc improvements (#667)",
        "message": "PARQUET-XXXX: Minor Javadoc improvements (#667)\n\n",
        "diff": {
            "parquet-column/src/main/java/org/apache/parquet/schema/Types.java": [
                3,
                3
            ]
        }
    },
    "10b926f021a6a441685c01d3dfe32c7ef07b1900": {
        "datetime": "2019-10-23T15:24:00+02:00",
        "summary": "PARQUET-1444: Prefer ArrayList over LinkedList (#583)",
        "message": "PARQUET-1444: Prefer ArrayList over LinkedList (#583)\n\n",
        "diff": {
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ColumnChunkPageReadStore.java": [
                5,
                7
            ],
            "parquet-thrift/src/main/java/org/apache/parquet/thrift/BufferedProtocolReadToWrite.java": [
                2,
                2
            ],
            "parquet-thrift/src/main/java/org/apache/parquet/thrift/ParquetReadProtocol.java": [
                2,
                2
            ]
        }
    },
    "ca7d0e26fe69ca6044e7e801c00e5b0797d1497a": {
        "datetime": "2019-10-25T23:43:12+02:00",
        "summary": "PARQUET-1496: Update Scala to 2.12 (#693)",
        "message": "PARQUET-1496: Update Scala to 2.12 (#693)\n\n* PARQUET-1496: Update Scala to 2.12\r\n\r\nThis also includes updating Scrooge because it isn't compiled\r\nanymore against Scala 2.10\r\n\r\n* Fix the tests\r\n\r\n* Revert unrelated changes\r\n\r\nScroogeBinaryTest.java\r\nThriftParquetReader.java\r\n",
        "diff": {
            "parquet-scrooge/pom.xml": null,
            "parquet-scrooge/src/test/thrift/test.thrift": null,
            "parquet-thrift/src/test/thrift/test.thrift": null,
            "pom.xml": null
        }
    },
    "19b10acaba799098f374b32f405cd63ea7076f51": {
        "datetime": "2019-10-26T01:05:58+02:00",
        "summary": "PARQUET-1499: Add Java 11 to Travis (#596)",
        "message": "PARQUET-1499: Add Java 11 to Travis (#596)\n\nGot some weird warnings from generated code:\r\n\r\n[ERROR] Failed to execute goal org.apache.maven.plugins:maven-javadoc-plugin:2.9.1:javadoc (default-cli) on project parquet-format-structures: An error has occurred in JavaDocs report generation:\r\n[ERROR] Exit code: 1 - javadoc: error - The code being documented uses modules but the packages defined in http://docs.oracle.com/javase/7/docs/api/ are in the unnamed module.\r\n[ERROR] /home/travis/build/apache/parquet-mr/parquet-format-structures/target/generated-sources/thrift/org/apache/parquet/format/ColumnIndex.java:49: warning - invalid usage of tag <\r\n[ERROR] /home/travis/build/apache/parquet-mr/parquet-format-structures/target/generated-sources/thrift/org/apache/parquet/format/ColumnIndex.java:394: warning - invalid usage of tag <\r\n[ERROR] /home/travis/build/apache/parquet-mr/parquet-format-structures/target/generated-sources/thrift/org/apache/parquet/format/ColumnIndex.java:407: warning - invalid usage of tag <\r\n[ERROR] /home/travis/build/apache/parquet-mr/parquet-format-structures/target/generated-sources/thrift/org/apache/parquet/format/ColumnIndex.java:84: warning - invalid usage of tag <\r\n[ERROR] /home/travis/build/apache/parquet-mr/parquet-format-structures/target/generated-sources/thrift/org/apache/parquet/format/OffsetIndex.java:21: warning - invalid usage of tag <\r\n[ERROR] /home/travis/build/apache/parquet-mr/parquet-format-structures/target/generated-sources/thrift/org/apache/parquet/format/OffsetIndex.java:150: warning - invalid usage of tag <\r\n[ERROR] /home/travis/build/apache/parquet-mr/parquet-format-structures/target/generated-sources/thrift/org/apache/parquet/format/OffsetIndex.java:159: warning - invalid usage of tag <\r\n[ERROR] /home/travis/build/apache/parquet-mr/parquet-format-structures/target/generated-sources/thrift/org/apache/parquet/format/OffsetIndex.java:29: warning - invalid usage of tag <\r\n[ERROR] /home/travis/build/apache/parquet-mr/parquet-format-structures/target/generated-sources/thrift/org/apache/parquet/format/ColumnIndex.java:49: warning - invalid usage of tag <\r\n[ERROR] /home/travis/build/apache/parquet-mr/parquet-format-structures/target/generated-sources/thrift/org/apache/parquet/format/OffsetIndex.java:21: warning - invalid usage of tag <\r\n",
        "diff": {
            ".travis.yml": null,
            "dev/travis-before_install.sh": null,
            "parquet-format-structures/pom.xml": null,
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/codec/CleanUtil.java": [
                1,
                0
            ],
            "pom.xml": null
        }
    },
    "d1190abee3ff1f1183757f7e400d7b9b4025d95b": {
        "datetime": "2019-11-12T15:43:32+01:00",
        "summary": "PARQUET-1691: Build fails due to missing hadoop-lzo (#698)",
        "message": "PARQUET-1691: Build fails due to missing hadoop-lzo (#698)\n\nSee details about the root cause at https://github.com/twitter/hadoop-lzo/issues/140",
        "diff": {
            "parquet-protobuf/pom.xml": null,
            "parquet-thrift/pom.xml": null
        }
    },
    "e60f5f1659df9d97499bc87c9a3bd3a4fc7c9a69": {
        "datetime": "2019-11-12T16:56:59+01:00",
        "summary": "PARQUET-1687: Update release process (#697)",
        "message": "PARQUET-1687: Update release process (#697)\n\nUpdate prepare-release.sh to create RC tags and keep using the current\r\nRC version with SNAPSHOT for development.\r\nUpdate source-release.sh to retrieve the hash of the RC tag.\r\nCreate the new script finalize-release to create the final release tag\r\nand update the development version.\r\n",
        "diff": {
            "dev/finalize-release": null,
            "dev/prepare-release.sh": null,
            "dev/source-release.sh": null
        }
    },
    "76f90101376d2589fe6071c96ae9d0203b245c0d": {
        "datetime": "2019-11-13T10:14:24+01:00",
        "summary": "PARQUET-1685: Truncate Min/Max for Statistics (#696)",
        "message": "PARQUET-1685: Truncate Min/Max for Statistics (#696)\n\n* Remove unnecessary string converting in readFooter method",
        "diff": {
            "parquet-column/src/main/java/org/apache/parquet/column/ParquetProperties.java": [
                3,
                17
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/statistics/BinaryStatistics.java": [
                0,
                11
            ],
            "parquet-column/src/main/java/org/apache/parquet/internal/column/columnindex/BinaryTruncator.java": [
                8,
                8
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/format/converter/ParquetMetadataConverter.java": [
                7,
                57
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ParquetFileWriter.java": [
                3,
                10
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ParquetOutputFormat.java": [
                1,
                16
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ParquetWriter.java": [
                1,
                2
            ],
            "parquet-hadoop/src/test/java/org/apache/parquet/format/converter/TestParquetMetadataConverter.java": [
                0,
                66
            ]
        }
    },
    "7d474c740bb274585a8fb87493d085289c8e9bc1": {
        "datetime": "2019-11-13T13:36:51+01:00",
        "summary": "Update CHANGES.md for 1.11.0rc7",
        "message": "Update CHANGES.md for 1.11.0rc7\n",
        "diff": {
            "CHANGES.md": null
        }
    },
    "18519eb8e059865652eee3ff0e8593f126701da4": {
        "datetime": "2019-11-13T13:54:48+01:00",
        "summary": "[maven-release-plugin] prepare release apache-parquet-1.11.0-rc7",
        "message": "[maven-release-plugin] prepare release apache-parquet-1.11.0-rc7\n",
        "diff": {
            "parquet-arrow/pom.xml": null,
            "parquet-avro/pom.xml": null,
            "parquet-benchmarks/pom.xml": null,
            "parquet-cascading/pom.xml": null,
            "parquet-cascading3/pom.xml": null,
            "parquet-cli/pom.xml": null,
            "parquet-column/pom.xml": null,
            "parquet-common/pom.xml": null,
            "parquet-encoding/pom.xml": null,
            "parquet-format-structures/pom.xml": null,
            "parquet-generator/pom.xml": null,
            "parquet-hadoop-bundle/pom.xml": null,
            "parquet-hadoop/pom.xml": null,
            "parquet-hive-bundle/pom.xml": null,
            "parquet-hive/parquet-hive-binding/parquet-hive-0.10-binding/pom.xml": null,
            "parquet-hive/parquet-hive-binding/parquet-hive-0.12-binding/pom.xml": null,
            "parquet-hive/parquet-hive-binding/parquet-hive-binding-bundle/pom.xml": null,
            "parquet-hive/parquet-hive-binding/parquet-hive-binding-factory/pom.xml": null,
            "parquet-hive/parquet-hive-binding/parquet-hive-binding-interface/pom.xml": null,
            "parquet-hive/parquet-hive-binding/pom.xml": null,
            "parquet-hive/parquet-hive-storage-handler/pom.xml": null,
            "parquet-hive/pom.xml": null,
            "parquet-jackson/pom.xml": null,
            "parquet-pig-bundle/pom.xml": null,
            "parquet-pig/pom.xml": null,
            "parquet-protobuf/pom.xml": null,
            "parquet-scala/pom.xml": null,
            "parquet-scrooge/pom.xml": null,
            "parquet-thrift/pom.xml": null,
            "parquet-tools/pom.xml": null,
            "pom.xml": null
        }
    },
    "7bd38d170cdb07ba728a95696242fda6fa56a7ff": {
        "datetime": "2019-11-13T13:55:10+01:00",
        "summary": "[maven-release-plugin] prepare for next development iteration",
        "message": "[maven-release-plugin] prepare for next development iteration\n",
        "diff": {
            "parquet-arrow/pom.xml": null,
            "parquet-avro/pom.xml": null,
            "parquet-benchmarks/pom.xml": null,
            "parquet-cascading/pom.xml": null,
            "parquet-cascading3/pom.xml": null,
            "parquet-cli/pom.xml": null,
            "parquet-column/pom.xml": null,
            "parquet-common/pom.xml": null,
            "parquet-encoding/pom.xml": null,
            "parquet-format-structures/pom.xml": null,
            "parquet-generator/pom.xml": null,
            "parquet-hadoop-bundle/pom.xml": null,
            "parquet-hadoop/pom.xml": null,
            "parquet-hive-bundle/pom.xml": null,
            "parquet-hive/parquet-hive-binding/parquet-hive-0.10-binding/pom.xml": null,
            "parquet-hive/parquet-hive-binding/parquet-hive-0.12-binding/pom.xml": null,
            "parquet-hive/parquet-hive-binding/parquet-hive-binding-bundle/pom.xml": null,
            "parquet-hive/parquet-hive-binding/parquet-hive-binding-factory/pom.xml": null,
            "parquet-hive/parquet-hive-binding/parquet-hive-binding-interface/pom.xml": null,
            "parquet-hive/parquet-hive-binding/pom.xml": null,
            "parquet-hive/parquet-hive-storage-handler/pom.xml": null,
            "parquet-hive/pom.xml": null,
            "parquet-jackson/pom.xml": null,
            "parquet-pig-bundle/pom.xml": null,
            "parquet-pig/pom.xml": null,
            "parquet-protobuf/pom.xml": null,
            "parquet-scala/pom.xml": null,
            "parquet-scrooge/pom.xml": null,
            "parquet-thrift/pom.xml": null,
            "parquet-tools/pom.xml": null,
            "pom.xml": null
        }
    },
    "475b44646c00d3128e0dd6a896b48f5e2d0eef1a": {
        "datetime": "2019-12-06T09:46:05+01:00",
        "summary": "Prepare for next development iteration",
        "message": "Prepare for next development iteration\n",
        "diff": {
            "parquet-arrow/pom.xml": null,
            "parquet-avro/pom.xml": null,
            "parquet-benchmarks/pom.xml": null,
            "parquet-cascading/pom.xml": null,
            "parquet-cascading3/pom.xml": null,
            "parquet-cli/pom.xml": null,
            "parquet-column/pom.xml": null,
            "parquet-common/pom.xml": null,
            "parquet-encoding/pom.xml": null,
            "parquet-format-structures/pom.xml": null,
            "parquet-generator/pom.xml": null,
            "parquet-hadoop-bundle/pom.xml": null,
            "parquet-hadoop/pom.xml": null,
            "parquet-hive-bundle/pom.xml": null,
            "parquet-hive/parquet-hive-binding/parquet-hive-0.10-binding/pom.xml": null,
            "parquet-hive/parquet-hive-binding/parquet-hive-0.12-binding/pom.xml": null,
            "parquet-hive/parquet-hive-binding/parquet-hive-binding-bundle/pom.xml": null,
            "parquet-hive/parquet-hive-binding/parquet-hive-binding-factory/pom.xml": null,
            "parquet-hive/parquet-hive-binding/parquet-hive-binding-interface/pom.xml": null,
            "parquet-hive/parquet-hive-binding/pom.xml": null,
            "parquet-hive/parquet-hive-storage-handler/pom.xml": null,
            "parquet-hive/pom.xml": null,
            "parquet-jackson/pom.xml": null,
            "parquet-pig-bundle/pom.xml": null,
            "parquet-pig/pom.xml": null,
            "parquet-protobuf/pom.xml": null,
            "parquet-scala/pom.xml": null,
            "parquet-scrooge/pom.xml": null,
            "parquet-thrift/pom.xml": null,
            "parquet-tools/pom.xml": null,
            "pom.xml": null
        }
    },
    "4ca29c7114237d4bb039b7291fa2c8c182170109": {
        "datetime": "2019-12-12T17:42:31+01:00",
        "summary": "[PARQUET-1717] Convert i16 thrift to INT16 logical type instead (#706)",
        "message": "[PARQUET-1717] Convert i16 thrift to INT16 logical type instead (#706)\n\n* [PARQUET-1717] Convert i16 thrift to INT16 logical type instead of INT32 primitive\r\n\r\n* [Parquet-1717] Add unit test\r\nAdd unit test for i16 thrift type\r\n",
        "diff": {
            "parquet-thrift/src/main/java/org/apache/parquet/thrift/ThriftSchemaConvertVisitor.java": [
                1,
                1
            ],
            "parquet-thrift/src/test/java/org/apache/parquet/thrift/TestThriftSchemaConverter.java": [
                0,
                13
            ],
            "parquet-thrift/src/test/thrift/test.thrift": null
        }
    },
    "2c9ccf9cdf67b460ffbd97ed547963b81fb11a69": {
        "datetime": "2019-12-31T16:54:53+01:00",
        "summary": "PARQUET-1696: Remove unused hadoop-1 profile (#701)",
        "message": "PARQUET-1696: Remove unused hadoop-1 profile (#701)\n\n",
        "diff": {
            "pom.xml": null
        }
    },
    "3b4ecf2c7029d12265b3e97a1f8ea98da1c1e5c2": {
        "datetime": "2020-01-02T13:46:49+01:00",
        "summary": "PARQUET-1723: Read From Maps without using .contains(...) (#711)",
        "message": "PARQUET-1723: Read From Maps without using .contains(...) (#711)\n\n",
        "diff": {
            "parquet-column/src/main/java/org/apache/parquet/column/EncodingStats.java": [
                10,
                4
            ],
            "parquet-column/src/main/java/org/apache/parquet/schema/GroupType.java": [
                2,
                3
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/ParquetReadOptions.java": [
                5,
                4
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ColumnChunkPageReadStore.java": [
                2,
                3
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/MemoryManager.java": [
                3,
                1
            ]
        }
    },
    "b9f16e50244a4c7df9ea81baef5843a17d55d91c": {
        "datetime": "2020-01-02T13:52:37+01:00",
        "summary": "PARQUET-1724: Use ConcurrentHashMap for Cache in DictionaryPageReader (#712)",
        "message": "PARQUET-1724: Use ConcurrentHashMap for Cache in DictionaryPageReader (#712)\n\n",
        "diff": {
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/DictionaryPageReader.java": [
                34,
                33
            ]
        }
    },
    "1e15f604302ab96904eaa1c3d435d2a5b3632d3f": {
        "datetime": "2020-01-02T14:00:06+01:00",
        "summary": "PARQUET-1726: Use Java 8 Multi Exception Handling (#714)",
        "message": "PARQUET-1726: Use Java 8 Multi Exception Handling (#714)\n\n",
        "diff": {
            "parquet-avro/src/main/java/org/apache/parquet/avro/AvroConverters.java": [
                7,
                2
            ],
            "parquet-avro/src/main/java/org/apache/parquet/avro/AvroRecordConverter.java": [
                3,
                1
            ],
            "parquet-cli/src/main/java/org/apache/parquet/cli/json/AvroJson.java": [
                6,
                2
            ],
            "parquet-column/src/main/java/org/apache/parquet/CorruptDeltaByteArrays.java": [
                4,
                1
            ],
            "parquet-column/src/main/java/org/apache/parquet/CorruptStatistics.java": [
                11,
                1
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/impl/ColumnReadStoreImpl.java": [
                3,
                1
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/values/plain/BinaryPlainValuesReader.java": [
                6,
                2
            ],
            "parquet-column/src/main/java/org/apache/parquet/filter2/predicate/Operators.java": [
                3,
                1
            ],
            "parquet-common/src/main/java/org/apache/parquet/VersionParser.java": [
                4,
                1
            ],
            "parquet-common/src/main/java/org/apache/parquet/util/DynConstructors.java": [
                16,
                6
            ],
            "parquet-common/src/main/java/org/apache/parquet/util/DynMethods.java": [
                4,
                2
            ],
            "parquet-encoding/src/main/java/org/apache/parquet/column/values/bitpacking/Packer.java": [
                9,
                2
            ],
            "parquet-format-structures/src/main/java/org/apache/parquet/format/event/Consumers.java": [
                3,
                1
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/DirectCodecFactory.java": [
                6,
                2
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ParquetInputFormat.java": [
                7,
                4
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ParquetOutputFormat.java": [
                3,
                1
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/metadata/ParquetMetadata.java": [
                8,
                0
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/util/ContextUtil.java": [
                22,
                10
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/util/HadoopStreams.java": [
                10,
                3
            ],
            "parquet-pig/src/main/java/org/apache/parquet/pig/TupleWriteSupport.java": [
                3,
                1
            ],
            "parquet-pig/src/main/java/org/apache/parquet/pig/convert/TupleConverter.java": [
                4,
                3
            ],
            "parquet-pig/src/main/java/org/apache/parquet/pig/summary/SummaryData.java": [
                8,
                0
            ],
            "parquet-thrift/src/main/java/org/apache/parquet/hadoop/thrift/ThriftBytesWriteSupport.java": [
                3,
                1
            ],
            "parquet-thrift/src/main/java/org/apache/parquet/hadoop/thrift/ThriftReadSupport.java": [
                6,
                2
            ]
        }
    },
    "3d8ce063986ad623d6ade4b55f1bbb1eb39f7641": {
        "datetime": "2020-01-05T19:24:15+01:00",
        "summary": "PARQUET-1727: Do Not Swallow InterruptedException in ParquetLoader (#715)",
        "message": "PARQUET-1727: Do Not Swallow InterruptedException in ParquetLoader (#715)\n\n",
        "diff": {
            "parquet-pig/src/main/java/org/apache/parquet/pig/ParquetLoader.java": [
                2,
                3
            ]
        }
    },
    "cce6fdb3304894e23231b10e1c758631e52df2d8": {
        "datetime": "2020-01-05T19:25:13+01:00",
        "summary": "PARQUET-1732: Call toArray With Empty Array (#720)",
        "message": "PARQUET-1732: Call toArray With Empty Array (#720)\n\n",
        "diff": {
            "parquet-cli/src/main/java/org/apache/parquet/cli/csv/RecordBuilder.java": [
                1,
                1
            ],
            "parquet-cli/src/main/java/org/apache/parquet/cli/util/GetClassLoader.java": [
                1,
                1
            ],
            "parquet-column/src/main/java/org/apache/parquet/filter2/recordlevel/FilteringGroupConverter.java": [
                5,
                2
            ],
            "parquet-column/src/main/java/org/apache/parquet/internal/column/columnindex/BinaryColumnIndexBuilder.java": [
                2,
                2
            ],
            "parquet-column/src/main/java/org/apache/parquet/io/PrimitiveColumnIO.java": [
                1,
                1
            ],
            "parquet-column/src/main/java/org/apache/parquet/io/RecordReaderImplementation.java": [
                1,
                1
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/format/converter/ParquetMetadataConverter.java": [
                1,
                1
            ],
            "parquet-tools/src/main/java/org/apache/parquet/tools/command/MetadataUtils.java": [
                1,
                1
            ],
            "parquet-tools/src/main/java/org/apache/parquet/tools/util/MetadataUtils.java": [
                1,
                1
            ]
        }
    },
    "a7447f698e5d8a1fff5b1542a70e42273b1b6373": {
        "datetime": "2020-01-05T19:25:54+01:00",
        "summary": "PARQUET-1731: Use JDK 8 Facilities to Simplify FilteringRecordMaterializer (#719)",
        "message": "PARQUET-1731: Use JDK 8 Facilities to Simplify FilteringRecordMaterializer (#719)\n\n",
        "diff": {
            "parquet-column/src/main/java/org/apache/parquet/filter2/recordlevel/FilteringRecordMaterializer.java": [
                24,
                10
            ]
        }
    },
    "c697d80ec1f10b381d634a01b6dd9eda2ba125e2": {
        "datetime": "2020-01-05T21:12:10+01:00",
        "summary": "PARQUET-1730: Use switch Statement in AvroIndexedRecordConverter for Enums (#718)",
        "message": "PARQUET-1730: Use switch Statement in AvroIndexedRecordConverter for Enums (#718)\n\n",
        "diff": {
            "parquet-avro/src/main/java/org/apache/parquet/avro/AvroIndexedRecordConverter.java": [
                27,
                30
            ]
        }
    },
    "ce55c9b2c3db49bdf0c7c4f4450a00ba51dfcc7b": {
        "datetime": "2020-01-07T09:58:08+01:00",
        "summary": "PARQUET-1703: Update API compatibility check (#709)",
        "message": "PARQUET-1703: Update API compatibility check (#709)\n\n",
        "diff": {
            "dev/finalize-release": null,
            "parquet-benchmarks/pom.xml": null,
            "parquet-cli/pom.xml": null,
            "parquet-tools/pom.xml": null,
            "pom.xml": null
        }
    },
    "e430527cdab5d0f5019c2ef665bea6283b5787b4": {
        "datetime": "2020-01-08T16:14:44+01:00",
        "summary": "PARQUET-1741: Restore APIs to keep backward compatibility (#729)",
        "message": "PARQUET-1741: Restore APIs to keep backward compatibility (#729)\n\n* PARQUET-1741: Restore APIs to keep backward compatibility\r\n\r\n* deprecate unused method\r\n",
        "diff": {
            "parquet-column/src/main/java/org/apache/parquet/filter2/recordlevel/FilteringRecordMaterializer.java": [
                0,
                16
            ]
        }
    },
    "ac7840ced22902e3880089fb4c5a533535aae256": {
        "datetime": "2020-01-08T18:00:14+01:00",
        "summary": "PARQUET-1725: Replace Usage of Strings.join with JDK Functionality in\u2026 (#713)",
        "message": "PARQUET-1725: Replace Usage of Strings.join with JDK Functionality in\u2026 (#713)\n\n* PARQUET-1725: Replace Usage of Strings.join with JDK Functionality in ColumnPath Class\r\n\r\n* Applied refactoring to DictionaryPageReader as well\r\n\r\n* Remove Strings utility class join methods\r\n\r\n* Deprecate instead of remove join methods\r\n",
        "diff": {
            "parquet-common/src/main/java/org/apache/parquet/Strings.java": [
                0,
                6
            ],
            "parquet-common/src/main/java/org/apache/parquet/hadoop/metadata/ColumnPath.java": [
                3,
                1
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/DictionaryPageReader.java": [
                2,
                1
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ParquetFileWriter.java": [
                2,
                1
            ],
            "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/example/TestInputOutputFormat.java": [
                2,
                1
            ],
            "parquet-thrift/src/main/java/org/apache/parquet/thrift/struct/CompatibilityChecker.java": [
                3,
                1
            ],
            "parquet-thrift/src/test/java/org/apache/parquet/thrift/TestThriftRecordConverter.java": [
                3,
                2
            ]
        }
    },
    "72738f59920cb8a875757d5fbb0a70bd7115fdcf": {
        "datetime": "2020-01-09T09:31:39+01:00",
        "summary": "PARQUET-1735: Clean Up parquet-columns Module (#723)",
        "message": "PARQUET-1735: Clean Up parquet-columns Module (#723)\n\n* PARQUET-1735: Clean Up parquet-columns Module\r\n\r\n* Remove superfluous parentheses\r\n",
        "diff": {
            "parquet-column/src/main/java/org/apache/parquet/column/EncodingStats.java": [
                5,
                5
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/impl/ColumnReaderBase.java": [
                0,
                30
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/impl/ColumnWriteStoreBase.java": [
                1,
                3
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/values/bitpacking/ByteBitPackingValuesWriter.java": [
                1,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/values/delta/DeltaBinaryPackingValuesWriter.java": [
                3,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/values/delta/DeltaBinaryPackingValuesWriterForLong.java": [
                1,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/values/deltastrings/DeltaByteArrayReader.java": [
                3,
                1
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/values/deltastrings/DeltaByteArrayWriter.java": [
                1,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/values/dictionary/DictionaryValuesReader.java": [
                2,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/values/dictionary/DictionaryValuesWriter.java": [
                2,
                2
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/values/dictionary/IntList.java": [
                1,
                1
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/values/fallback/FallbackValuesWriter.java": [
                1,
                9
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/values/rle/ZeroIntegerValuesReader.java": [
                0,
                1
            ],
            "parquet-column/src/main/java/org/apache/parquet/example/DummyRecordConverter.java": [
                0,
                3
            ],
            "parquet-column/src/main/java/org/apache/parquet/example/data/Group.java": [
                0,
                2
            ],
            "parquet-column/src/main/java/org/apache/parquet/example/data/simple/SimpleGroup.java": [
                1,
                1
            ],
            "parquet-column/src/main/java/org/apache/parquet/filter2/predicate/FilterApi.java": [
                8,
                8
            ],
            "parquet-column/src/main/java/org/apache/parquet/filter2/predicate/LogicalInverter.java": [
                7,
                7
            ],
            "parquet-column/src/main/java/org/apache/parquet/filter2/predicate/PrimitiveToBoxedClass.java": [
                1,
                1
            ],
            "parquet-column/src/main/java/org/apache/parquet/filter2/predicate/SchemaCompatibilityValidator.java": [
                3,
                2
            ],
            "parquet-column/src/main/java/org/apache/parquet/filter2/predicate/ValidTypeMap.java": [
                4,
                4
            ],
            "parquet-column/src/main/java/org/apache/parquet/filter2/recordlevel/FilteringGroupConverter.java": [
                1,
                1
            ],
            "parquet-column/src/main/java/org/apache/parquet/filter2/recordlevel/IncrementallyUpdatedFilterPredicateBuilderBase.java": [
                2,
                2
            ],
            "parquet-column/src/main/java/org/apache/parquet/internal/column/columnindex/BinaryColumnIndexBuilder.java": [
                1,
                1
            ],
            "parquet-column/src/main/java/org/apache/parquet/internal/column/columnindex/BooleanColumnIndexBuilder.java": [
                1,
                1
            ],
            "parquet-column/src/main/java/org/apache/parquet/internal/column/columnindex/DoubleColumnIndexBuilder.java": [
                1,
                1
            ],
            "parquet-column/src/main/java/org/apache/parquet/internal/column/columnindex/FloatColumnIndexBuilder.java": [
                1,
                1
            ],
            "parquet-column/src/main/java/org/apache/parquet/internal/column/columnindex/IntColumnIndexBuilder.java": [
                1,
                1
            ],
            "parquet-column/src/main/java/org/apache/parquet/internal/column/columnindex/LongColumnIndexBuilder.java": [
                1,
                1
            ],
            "parquet-column/src/main/java/org/apache/parquet/io/ColumnIOFactory.java": [
                1,
                1
            ],
            "parquet-column/src/main/java/org/apache/parquet/io/GroupColumnIO.java": [
                5,
                7
            ],
            "parquet-column/src/main/java/org/apache/parquet/io/MessageColumnIO.java": [
                7,
                8
            ],
            "parquet-column/src/main/java/org/apache/parquet/io/RecordReaderImplementation.java": [
                5,
                5
            ],
            "parquet-column/src/main/java/org/apache/parquet/io/ValidatingRecordConsumer.java": [
                4,
                16
            ],
            "parquet-column/src/main/java/org/apache/parquet/io/api/Binary.java": [
                0,
                1
            ],
            "parquet-column/src/main/java/org/apache/parquet/schema/GroupType.java": [
                6,
                6
            ],
            "parquet-column/src/main/java/org/apache/parquet/schema/MessageType.java": [
                2,
                2
            ],
            "parquet-column/src/main/java/org/apache/parquet/schema/PrimitiveType.java": [
                1,
                0
            ],
            "parquet-column/src/main/java/org/apache/parquet/schema/Type.java": [
                2,
                1
            ],
            "parquet-column/src/main/java/org/apache/parquet/schema/Types.java": [
                42,
                48
            ],
            "parquet-column/src/test/java/org/apache/parquet/column/TestEncodingStats.java": [
                4,
                4
            ],
            "parquet-column/src/test/java/org/apache/parquet/column/impl/TestColumnReaderImpl.java": [
                2,
                2
            ],
            "parquet-column/src/test/java/org/apache/parquet/column/impl/TestCorruptDeltaByteArrays.java": [
                2,
                2
            ],
            "parquet-column/src/test/java/org/apache/parquet/column/mem/TestMemColumn.java": [
                2,
                1
            ],
            "parquet-column/src/test/java/org/apache/parquet/column/page/mem/MemPageStore.java": [
                2,
                2
            ],
            "parquet-column/src/test/java/org/apache/parquet/column/page/mem/MemPageWriter.java": [
                1,
                1
            ],
            "parquet-column/src/test/java/org/apache/parquet/column/statistics/TestStatistics.java": [
                2,
                2
            ],
            "parquet-column/src/test/java/org/apache/parquet/column/values/TestValuesReaderImpl.java": [
                2,
                0
            ],
            "parquet-column/src/test/java/org/apache/parquet/column/values/Utils.java": [
                1,
                0
            ],
            "parquet-column/src/test/java/org/apache/parquet/column/values/bitpacking/TestBitPackingColumn.java": [
                0,
                4
            ],
            "parquet-column/src/test/java/org/apache/parquet/column/values/delta/benchmark/BenchMarkTest.java": [
                2,
                0
            ],
            "parquet-column/src/test/java/org/apache/parquet/column/values/deltalengthbytearray/benchmark/BenchmarkDeltaLengthByteArray.java": [
                2,
                2
            ],
            "parquet-column/src/test/java/org/apache/parquet/column/values/deltastrings/TestDeltaByteArray.java": [
                2,
                0
            ],
            "parquet-column/src/test/java/org/apache/parquet/column/values/deltastrings/benchmark/BenchmarkDeltaByteArray.java": [
                4,
                4
            ],
            "parquet-column/src/test/java/org/apache/parquet/column/values/rle/RunLengthBitPackingHybridIntegrationTest.java": [
                12,
                0
            ],
            "parquet-column/src/test/java/org/apache/parquet/column/values/rle/TestRunLengthBitPackingHybridEncoder.java": [
                1,
                1
            ],
            "parquet-column/src/test/java/org/apache/parquet/filter2/predicate/TestLogicalInverseRewriter.java": [
                2,
                2
            ],
            "parquet-column/src/test/java/org/apache/parquet/filter2/predicate/TestLogicalInverter.java": [
                3,
                3
            ],
            "parquet-column/src/test/java/org/apache/parquet/io/ConverterConsumer.java": [
                2,
                2
            ],
            "parquet-column/src/test/java/org/apache/parquet/io/ExpectationValidatingConverter.java": [
                1,
                1
            ],
            "parquet-column/src/test/java/org/apache/parquet/io/TestColumnIO.java": [
                9,
                9
            ],
            "parquet-column/src/test/java/org/apache/parquet/io/TestFiltered.java": [
                3,
                3
            ],
            "parquet-column/src/test/java/org/apache/parquet/schema/TestTypeBuilders.java": [
                48,
                48
            ]
        }
    },
    "65eba5547a5a63a318eb8b5d3974e8980055b8c7": {
        "datetime": "2020-01-09T15:09:24+01:00",
        "summary": "PARQUET-1740: Make ParquetFileReader.getFilteredRecordCount public (#728)",
        "message": "PARQUET-1740: Make ParquetFileReader.getFilteredRecordCount public (#728)\n\n",
        "diff": {
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ParquetFileReader.java": [
                1,
                1
            ]
        }
    },
    "f0fc29fd3341046f7d46a4a02a7c9ec3d7cd3e46": {
        "datetime": "2020-01-10T07:08:01+01:00",
        "summary": "PARQUET-1744: Some filters throws ArrayIndexOutOfBoundsException (#732)",
        "message": "PARQUET-1744: Some filters throws ArrayIndexOutOfBoundsException (#732)\n\n",
        "diff": {
            "parquet-column/src/main/java/org/apache/parquet/internal/column/columnindex/BoundaryOrder.java": [
                0,
                32
            ],
            "parquet-column/src/test/java/org/apache/parquet/internal/column/columnindex/TestBoundaryOrder.java": [
                104,
                160
            ],
            "parquet-column/src/test/java/org/apache/parquet/internal/filter2/columnindex/TestColumnIndexFilter.java": [
                35,
                71
            ]
        }
    },
    "616e35f9e164a24104da148f713b2e8258a4f54f": {
        "datetime": "2020-01-10T13:52:50+01:00",
        "summary": "PARQUET-1593: Improve parquet-cli's example usage (#646)",
        "message": "PARQUET-1593: Improve parquet-cli's example usage (#646)\n\nThe following description is a bit weird since there's no command\r\ncalled \"create\" actually. This PR replaces the subcommand with an\r\nactually existent one.\r\n\r\n```\r\n  Examples:\r\n\r\n    # print information for create\r\n    parquet help create\r\n```",
        "diff": {
            "parquet-cli/src/main/java/org/apache/parquet/cli/Help.java": [
                4,
                7
            ]
        }
    },
    "d85a8f5dcfc1381655fcccaa81a2e83ba812f6a4": {
        "datetime": "2020-01-10T13:55:15+01:00",
        "summary": "PARQUET-1729: Avoid AutoBoxing in EncodingStats (#717)",
        "message": "PARQUET-1729: Avoid AutoBoxing in EncodingStats (#717)\n\n* PARQUET-1729: Avoid AutoBoxing in EncodingStats\r\n\r\n* Updated unit tests to more properly check stats value\r\n",
        "diff": {
            "parquet-column/src/main/java/org/apache/parquet/column/EncodingStats.java": [
                14,
                15
            ],
            "parquet-column/src/test/java/org/apache/parquet/column/TestEncodingStats.java": [
                17,
                17
            ]
        }
    },
    "e083fbb53cfd7514183fb2cd59521307a5420a94": {
        "datetime": "2020-01-12T19:29:40+01:00",
        "summary": "Update current release version (#733)",
        "message": "Update current release version (#733)\n\n",
        "diff": {
            "README.md": null
        }
    },
    "ad07d836e6da9a8ca8e5e1f19af42ad75ece2bb7": {
        "datetime": "2020-01-15T13:00:11+01:00",
        "summary": "PARQUET-1738: Remove unused imports (#726)",
        "message": "PARQUET-1738: Remove unused imports (#726)\n\n* PARQUET-1738: Remove unused imports from tests\r\n\r\n* PARQUET-1738: Remove unused imports from column\r\n\r\nCo-authored-by: Fokko Driesprong <fokko@driesprong.frl>\r\n",
        "diff": {
            "parquet-column/src/test/java/org/apache/parquet/column/values/deltastrings/TestDeltaByteArray.java": [
                0,
                1
            ],
            "parquet-column/src/test/java/org/apache/parquet/internal/column/columnindex/TestOffsetIndexBuilder.java": [
                2,
                0
            ]
        }
    },
    "8c1bc9bcdeeac8178fecf61d18dc56913907fd46": {
        "datetime": "2020-01-16T14:31:27+01:00",
        "summary": "PARQUET-1765: Invalid filteredRowCount in InternalParquetRecordReader (#747)",
        "message": "PARQUET-1765: Invalid filteredRowCount in InternalParquetRecordReader (#747)\n\n",
        "diff": {
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/InternalParquetRecordReader.java": [
                2,
                6
            ],
            "parquet-hadoop/src/test/java/org/apache/parquet/filter2/recordlevel/PhoneBookWriter.java": [
                0,
                8
            ],
            "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/TestColumnIndexFiltering.java": [
                0,
                50
            ]
        }
    },
    "d3e3118150d3fa5d2831443ddc944d7416b9a9f6": {
        "datetime": "2020-01-26T21:06:27+01:00",
        "summary": "PARQUET-1710: Use Objects.requireNonNull (#703)",
        "message": "PARQUET-1710: Use Objects.requireNonNull (#703)\n\n",
        "diff": {
            "parquet-cascading/src/main/java/org/apache/parquet/cascading/ParquetTupleScheme.java": [
                4,
                3
            ],
            "parquet-cascading3/src/main/java/org/apache/parquet/cascading/ParquetTupleScheme.java": [
                4,
                5
            ],
            "parquet-cascading3/src/main/java/org/apache/parquet/cascading/ParquetValueScheme.java": [
                6,
                14
            ],
            "parquet-cli/src/main/java/org/apache/parquet/cli/csv/AvroCSV.java": [
                4,
                4
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/ParquetProperties.java": [
                4,
                5
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/impl/ColumnReaderBase.java": [
                4,
                4
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/page/DictionaryPage.java": [
                4,
                3
            ],
            "parquet-column/src/main/java/org/apache/parquet/filter/AndRecordFilter.java": [
                2,
                4
            ],
            "parquet-column/src/main/java/org/apache/parquet/filter/ColumnPredicates.java": [
                3,
                4
            ],
            "parquet-column/src/main/java/org/apache/parquet/filter/ColumnRecordFilter.java": [
                3,
                3
            ],
            "parquet-column/src/main/java/org/apache/parquet/filter/NotRecordFilter.java": [
                1,
                4
            ],
            "parquet-column/src/main/java/org/apache/parquet/filter/OrRecordFilter.java": [
                3,
                4
            ],
            "parquet-column/src/main/java/org/apache/parquet/filter2/compat/FilterCompat.java": [
                4,
                5
            ],
            "parquet-column/src/main/java/org/apache/parquet/filter2/predicate/LogicalInverseRewriter.java": [
                2,
                3
            ],
            "parquet-column/src/main/java/org/apache/parquet/filter2/predicate/LogicalInverter.java": [
                2,
                2
            ],
            "parquet-column/src/main/java/org/apache/parquet/filter2/predicate/Operators.java": [
                18,
                15
            ],
            "parquet-column/src/main/java/org/apache/parquet/filter2/predicate/SchemaCompatibilityValidator.java": [
                4,
                3
            ],
            "parquet-column/src/main/java/org/apache/parquet/filter2/predicate/Statistics.java": [
                7,
                6
            ],
            "parquet-column/src/main/java/org/apache/parquet/filter2/recordlevel/FilteringGroupConverter.java": [
                6,
                6
            ],
            "parquet-column/src/main/java/org/apache/parquet/filter2/recordlevel/FilteringPrimitiveConverter.java": [
                3,
                3
            ],
            "parquet-column/src/main/java/org/apache/parquet/filter2/recordlevel/FilteringRecordMaterializer.java": [
                6,
                5
            ],
            "parquet-column/src/main/java/org/apache/parquet/filter2/recordlevel/IncrementallyUpdatedFilterPredicate.java": [
                3,
                3
            ],
            "parquet-column/src/main/java/org/apache/parquet/filter2/recordlevel/IncrementallyUpdatedFilterPredicateEvaluator.java": [
                3,
                2
            ],
            "parquet-column/src/main/java/org/apache/parquet/filter2/recordlevel/IncrementallyUpdatedFilterPredicateResetter.java": [
                3,
                2
            ],
            "parquet-column/src/main/java/org/apache/parquet/io/MessageColumnIO.java": [
                5,
                4
            ],
            "parquet-column/src/main/java/org/apache/parquet/schema/ColumnOrder.java": [
                2,
                2
            ],
            "parquet-column/src/main/java/org/apache/parquet/schema/Type.java": [
                6,
                5
            ],
            "parquet-column/src/main/java/org/apache/parquet/schema/Types.java": [
                6,
                6
            ],
            "parquet-column/src/test/java/org/apache/parquet/column/page/mem/MemPageReader.java": [
                4,
                2
            ],
            "parquet-common/src/main/java/org/apache/parquet/Preconditions.java": [
                0,
                4
            ],
            "parquet-common/src/main/java/org/apache/parquet/glob/WildcardPath.java": [
                4,
                3
            ],
            "parquet-common/src/main/java/org/apache/parquet/hadoop/metadata/ColumnPath.java": [
                3,
                2
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/filter2/compat/RowGroupFilter.java": [
                8,
                7
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/filter2/dictionarylevel/DictionaryFilter.java": [
                5,
                3
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/filter2/statisticslevel/StatisticsFilter.java": [
                4,
                3
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/DirectCodecFactory.java": [
                2,
                5
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/InternalParquetRecordReader.java": [
                2,
                2
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/InternalParquetRecordWriter.java": [
                2,
                2
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/MemoryManager.java": [
                3,
                3
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ParquetOutputFormat.java": [
                2,
                4
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ParquetReader.java": [
                8,
                7
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ParquetRecordWriter.java": [
                4,
                3
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/api/WriteSupport.java": [
                5,
                10
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/example/GroupWriteSupport.java": [
                4,
                2
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/metadata/FileMetaData.java": [
                3,
                6
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/metadata/GlobalMetaData.java": [
                3,
                6
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/util/HadoopStreams.java": [
                3,
                3
            ],
            "parquet-thrift/src/main/java/org/apache/parquet/thrift/ConvertedField.java": [
                5,
                5
            ],
            "parquet-thrift/src/main/java/org/apache/parquet/thrift/ThriftParquetReader.java": [
                6,
                5
            ],
            "parquet-thrift/src/main/java/org/apache/parquet/thrift/ThriftSchemaConvertVisitor.java": [
                2,
                3
            ],
            "parquet-thrift/src/main/java/org/apache/parquet/thrift/projection/deprecated/DeprecatedFieldProjectionFilter.java": [
                2,
                2
            ]
        }
    },
    "438cb3c761daf8d916a85c8742fb321905a07df8": {
        "datetime": "2020-01-26T21:11:26+01:00",
        "summary": "PARQUET-1749: Use Java 8 Streams for Empty PrimitiveIterator (#734)",
        "message": "PARQUET-1749: Use Java 8 Streams for Empty PrimitiveIterator (#734)\n\n",
        "diff": {
            "parquet-column/src/main/java/org/apache/parquet/internal/column/columnindex/IndexIterator.java": [
                11,
                2
            ]
        }
    },
    "184965087fb320d4a5f5849d27b365420a3ef1a0": {
        "datetime": "2020-02-03T14:56:51+01:00",
        "summary": "PARQUET-1737: Replace Test Class RandomStr with Apache Commons Lang (#725)",
        "message": "PARQUET-1737: Replace Test Class RandomStr with Apache Commons Lang (#725)\n\n",
        "diff": {
            "parquet-column/pom.xml": null,
            "parquet-column/src/test/java/org/apache/parquet/column/values/RandomStr.java": [
                51,
                0
            ],
            "parquet-column/src/test/java/org/apache/parquet/column/values/Utils.java": [
                7,
                5
            ]
        }
    },
    "1577037f172ce73050f466d714e3b1f24ed84082": {
        "datetime": "2020-02-03T14:59:23+01:00",
        "summary": "PARQUET-1751: Fix Protobuf Build Warning (#736)",
        "message": "PARQUET-1751: Fix Protobuf Build Warning (#736)\n\n",
        "diff": {
            "parquet-protobuf/src/test/resources/TestProto3.proto": null,
            "parquet-protobuf/src/test/resources/TestProtobuf.proto": null
        }
    },
    "17bef40022cb9830101cff4893c9054d2d7ddce6": {
        "datetime": "2020-02-10T13:34:41+01:00",
        "summary": "PARQUET-1782: Use Switch Statement in AvroRecordConverter (#752)",
        "message": "PARQUET-1782: Use Switch Statement in AvroRecordConverter (#752)\n\n* PARQUET-1782: Use Switch Statement in AvroRecordConverter\r\n\r\n* Changed Datum Class Initialization\r\n",
        "diff": {
            "parquet-avro/src/main/java/org/apache/parquet/avro/AvroRecordConverter.java": [
                32,
                38
            ]
        }
    },
    "3bbf66c2551bb9cc36b6a41d4b3820cd9fc72c77": {
        "datetime": "2020-02-12T12:38:19+01:00",
        "summary": "PARQUET-1622: Add implementation for BYTE_STREAM_SPLIT (#705)",
        "message": "PARQUET-1622: Add implementation for BYTE_STREAM_SPLIT (#705)\n\nThe patch adds an implementation and tests for the\r\nBYTE_STREAM_SPLIT encoding.",
        "diff": {
            "parquet-column/src/main/java/org/apache/parquet/column/Encoding.java": [
                0,
                16
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/ParquetProperties.java": [
                3,
                19
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/values/bytestreamsplit/ByteStreamSplitValuesReader.java": [
                0,
                100
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/values/bytestreamsplit/ByteStreamSplitValuesReaderForDouble.java": [
                0,
                37
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/values/bytestreamsplit/ByteStreamSplitValuesReaderForFloat.java": [
                0,
                37
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/values/bytestreamsplit/ByteStreamSplitValuesWriter.java": [
                0,
                142
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/values/factory/DefaultV1ValuesWriterFactory.java": [
                2,
                13
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/values/factory/DefaultV2ValuesWriterFactory.java": [
                2,
                13
            ],
            "parquet-column/src/test/java/org/apache/parquet/column/values/bytestreamsplit/ByteStreamSplitValuesEndToEndTest.java": [
                0,
                111
            ],
            "parquet-column/src/test/java/org/apache/parquet/column/values/bytestreamsplit/ByteStreamSplitValuesReaderTest.java": [
                0,
                193
            ],
            "parquet-column/src/test/java/org/apache/parquet/column/values/bytestreamsplit/ByteStreamSplitValuesWriterTest.java": [
                0,
                189
            ],
            "parquet-column/src/test/java/org/apache/parquet/column/values/factory/DefaultValuesWriterFactoryTest.java": [
                6,
                116
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ParquetWriter.java": [
                0,
                5
            ],
            "pom.xml": null
        }
    },
    "57f6b46dde5926cc602c583940dd6424f10b9a17": {
        "datetime": "2020-02-12T12:55:07+01:00",
        "summary": "PARQUET-1790: Add Api for writing DataPageV2 to ParquetFileWriter class (#756)",
        "message": "PARQUET-1790: Add Api for writing DataPageV2 to ParquetFileWriter class (#756)\n\n\r\n",
        "diff": {
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ParquetFileWriter.java": [
                1,
                73
            ],
            "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/TestParquetFileWriter.java": [
                0,
                83
            ]
        }
    },
    "474a2bedb167cc7ad1c438b630a6ab8d45c7ca23": {
        "datetime": "2020-02-14T09:40:24+01:00",
        "summary": "PARQUET-1796: Bump Avro from 1.9.1 to 1.9.2 (#759)",
        "message": "PARQUET-1796: Bump Avro from 1.9.1 to 1.9.2 (#759)\n\n",
        "diff": {
            "pom.xml": null
        }
    },
    "1eaf16df379c7f1951a50360d09af3b12eb16815": {
        "datetime": "2020-02-17T10:07:18+01:00",
        "summary": "PARQUET-1794: Random data generation may cause flaky tests (#758)",
        "message": "PARQUET-1794: Random data generation may cause flaky tests (#758)\n\n",
        "diff": {
            "parquet-column/src/test/java/org/apache/parquet/FixedBinaryTestUtils.java": [
                0,
                96
            ],
            "parquet-hadoop/pom.xml": null,
            "parquet-hadoop/src/test/java/org/apache/parquet/filter2/dictionarylevel/DictionaryFilterTest.java": [
                7,
                2
            ],
            "parquet-hadoop/src/test/java/org/apache/parquet/format/converter/TestParquetMetadataConverter.java": [
                2,
                3
            ],
            "parquet-hadoop/src/test/java/org/apache/parquet/statistics/RandomValues.java": [
                1,
                2
            ]
        }
    },
    "583063b47c2495ebcd4d87c9234faf5e3838dec5": {
        "datetime": "2020-02-24T09:35:52+01:00",
        "summary": "PARQUET-1802: Use job ClassLoader to load CompressionCodec class (#760)",
        "message": "PARQUET-1802: Use job ClassLoader to load CompressionCodec class (#760)\n\nThe MR job might be having a different ClassLoader then\r\nthe defining ClassLoader of the CodecFactory class.\r\nA CompressionCodec class that is not loadable via the\r\nCodecFactory ClassLoader might be loadable through the\r\njob ClassLoader.",
        "diff": {
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/CodecFactory.java": [
                1,
                7
            ]
        }
    },
    "a0c9e696d424d4289653cba5d6b1e70b25ae96be": {
        "datetime": "2020-02-25T10:53:13+01:00",
        "summary": "PARQUET-1791: Add 'prune' command to parquet-tools (#755)",
        "message": "PARQUET-1791: Add 'prune' command to parquet-tools (#755)\n\n\r\n",
        "diff": {
            "parquet-tools/src/main/java/org/apache/parquet/tools/command/PruneColumnsCommand.java": [
                0,
                168
            ],
            "parquet-tools/src/main/java/org/apache/parquet/tools/command/Registry.java": [
                0,
                1
            ],
            "parquet-tools/src/test/java/org/apache/parquet/tools/command/TestPruneColumnsCommand.java": [
                0,
                255
            ]
        }
    },
    "e3afb24a235bcfa6f8cb1335ed4ca34c46c38e96": {
        "datetime": "2020-02-25T14:25:04+01:00",
        "summary": "PARQUET-1759: InternalParquetRecordReader Use Singleton Set (#743)",
        "message": "PARQUET-1759: InternalParquetRecordReader Use Singleton Set (#743)\n\n",
        "diff": {
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/InternalParquetRecordReader.java": [
                5,
                2
            ]
        }
    },
    "7469e87dc63c0f672be7175946dc7af1219ec732": {
        "datetime": "2020-02-26T11:30:27+01:00",
        "summary": "PARQUET-1784: Column-wise configuration (#754)",
        "message": "PARQUET-1784: Column-wise configuration (#754)\n\n",
        "diff": {
            "parquet-column/src/main/java/org/apache/parquet/column/ColumnProperty.java": [
                0,
                137
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/ParquetProperties.java": [
                31,
                57
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/values/factory/DefaultValuesWriterFactory.java": [
                1,
                1
            ],
            "parquet-column/src/test/java/org/apache/parquet/column/values/factory/DefaultValuesWriterFactoryTest.java": [
                12,
                98
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ColumnConfigParser.java": [
                0,
                72
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ParquetOutputFormat.java": [
                14,
                8
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ParquetWriter.java": [
                0,
                12
            ]
        }
    },
    "806037c080dc477798d157cd4a54a81240a85d37": {
        "datetime": "2020-02-26T14:18:36+01:00",
        "summary": "PARQUET-41: Add bloom filter  (#757)",
        "message": "PARQUET-41: Add bloom filter  (#757)\n\n* PARQUET-1328: Add Bloom filter reader and writer (#587)\r\n* PARQUET-1516: Store Bloom filters near to footer (#608)\r\n* PARQUET-1391: Integrate Bloom filter logic (#619)\r\n* PARQUET-1660: align Bloom filter implementation with format (#686)\r\n",
        "diff": {
            "parquet-column/pom.xml": null,
            "parquet-column/src/main/java/org/apache/parquet/column/ParquetProperties.java": [
                7,
                93
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/impl/ColumnWriteStoreBase.java": [
                3,
                36
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/impl/ColumnWriteStoreV1.java": [
                2,
                11
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/impl/ColumnWriteStoreV2.java": [
                2,
                11
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/impl/ColumnWriterBase.java": [
                0,
                80
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/impl/ColumnWriterV1.java": [
                0,
                6
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/impl/ColumnWriterV2.java": [
                3,
                9
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/values/bloomfilter/BlockSplitBloomFilter.java": [
                0,
                382
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/values/bloomfilter/BloomFilter.java": [
                0,
                171
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/values/bloomfilter/BloomFilterWriteStore.java": [
                0,
                35
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/values/bloomfilter/BloomFilterWriter.java": [
                0,
                31
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/values/bloomfilter/HashFunction.java": [
                0,
                41
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/values/bloomfilter/XxHash.java": [
                0,
                40
            ],
            "parquet-column/src/test/java/org/apache/parquet/column/values/bloomfilter/TestBlockSplitBloomFilter.java": [
                0,
                229
            ],
            "parquet-format-structures/src/main/java/org/apache/parquet/format/Util.java": [
                0,
                8
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/HadoopReadOptions.java": [
                3,
                6
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/ParquetReadOptions.java": [
                1,
                20
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/filter2/bloomfilterlevel/BloomFilterImpl.java": [
                0,
                150
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/filter2/compat/RowGroupFilter.java": [
                4,
                12
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/format/converter/ParquetMetadataConverter.java": [
                1,
                38
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/BloomFilterReader.java": [
                0,
                70
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ColumnChunkPageWriteStore.java": [
                2,
                16
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/InternalParquetRecordWriter.java": [
                3,
                8
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ParquetFileReader.java": [
                0,
                50
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ParquetFileWriter.java": [
                2,
                64
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ParquetInputFormat.java": [
                3,
                8
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ParquetOutputFormat.java": [
                3,
                50
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ParquetReader.java": [
                3,
                13
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ParquetWriter.java": [
                3,
                33
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/metadata/ColumnChunkMetaData.java": [
                3,
                22
            ],
            "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/TestBloomFiltering.java": [
                0,
                257
            ],
            "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/TestColumnChunkPageWriteStore.java": [
                0,
                1
            ],
            "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/TestParquetFileWriter.java": [
                4,
                38
            ],
            "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/TestParquetWriter.java": [
                10,
                44
            ],
            "pom.xml": null
        }
    },
    "d69192809d0d5ec36c0d8c126c8bed09ee3cee35": {
        "datetime": "2020-02-28T15:22:34+01:00",
        "summary": "PARQUET-1803 Could not find FilleInputSplit in ParquetInputSplit (#761)",
        "message": "PARQUET-1803 Could not find FilleInputSplit in ParquetInputSplit (#761)\n\n",
        "diff": {
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ParquetInputSplit.java": [
                4,
                4
            ]
        }
    },
    "ab65823ae0fd6c3afae94c7fa0670cf9b46b5b85": {
        "datetime": "2020-03-09T12:52:39+01:00",
        "summary": "[PARQUET-1808]: Replacing multiple String Object creations with StringBuilder (#766)",
        "message": "[PARQUET-1808]: Replacing multiple String Object creations with StringBuilder (#766)\n\n",
        "diff": {
            "parquet-column/src/main/java/org/apache/parquet/example/data/simple/SimpleGroup.java": [
                17,
                21
            ],
            "parquet-column/src/main/java/org/apache/parquet/io/MessageColumnIO.java": [
                6,
                6
            ],
            "parquet-column/src/test/java/org/apache/parquet/io/ExpectationValidatingConverter.java": [
                7,
                7
            ],
            "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/TestInputFormat.java": [
                7,
                7
            ]
        }
    },
    "8e7dfde10cd9d71dd1bd79ccd25824cd58ec9809": {
        "datetime": "2020-03-13T07:56:28+01:00",
        "summary": "Add shangxinli to committers list (#767)",
        "message": "Add shangxinli to committers list (#767)\n\n",
        "diff": {
            "dev/COMMITTERS.md": null
        }
    },
    "7ddfb4d9d89fc7ae1d9ea0ef86aaa6dd5e81aa59": {
        "datetime": "2020-03-30T10:51:25+02:00",
        "summary": "PARQUET-1805: Refactor the configuration for bloom filters (#763)",
        "message": "PARQUET-1805: Refactor the configuration for bloom filters (#763)\n\n",
        "diff": {
            "parquet-column/src/main/java/org/apache/parquet/column/ParquetProperties.java": [
                36,
                54
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/impl/ColumnWriteStoreBase.java": [
                1,
                1
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/impl/ColumnWriterBase.java": [
                16,
                7
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ParquetOutputFormat.java": [
                39,
                9
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ParquetWriter.java": [
                25,
                32
            ],
            "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/TestBloomFiltering.java": [
                6,
                6
            ],
            "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/TestParquetWriter.java": [
                1,
                1
            ]
        }
    },
    "5d2bf2789041fc8ff6de48a590775aafe4457db3": {
        "datetime": "2020-03-31T09:27:11+02:00",
        "summary": "PARQUET-1743: Add equals API to BloomFilter interface (#773)",
        "message": "PARQUET-1743: Add equals API to BloomFilter interface (#773)\n\n",
        "diff": {
            "parquet-column/src/main/java/org/apache/parquet/column/values/bloomfilter/BlockSplitBloomFilter.java": [
                0,
                15
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/values/bloomfilter/BloomFilter.java": [
                0,
                8
            ],
            "parquet-column/src/test/java/org/apache/parquet/column/values/bloomfilter/TestBlockSplitBloomFilter.java": [
                0,
                20
            ]
        }
    },
    "d00b2f105f9f732e310ed43c7bfb318213e1ac81": {
        "datetime": "2020-04-01T11:49:46+02:00",
        "summary": "PARQUET-1821: Add 'column-size' command to parquet-cli and parquet-tools (#774)",
        "message": "PARQUET-1821: Add 'column-size' command to parquet-cli and parquet-tools (#774)\n\n",
        "diff": {
            "parquet-cli/src/main/java/org/apache/parquet/cli/Main.java": [
                0,
                2
            ],
            "parquet-cli/src/main/java/org/apache/parquet/cli/commands/ColumnSizeCommand.java": [
                0,
                137
            ],
            "parquet-cli/src/test/java/org/apache/parquet/cli/commands/ColumnSizeCommandTest.java": [
                0,
                91
            ],
            "parquet-cli/src/test/java/org/apache/parquet/cli/commands/ParquetFileTest.java": [
                0,
                8
            ],
            "parquet-tools/src/main/java/org/apache/parquet/tools/command/ColumnSizeCommand.java": [
                0,
                121
            ],
            "parquet-tools/src/main/java/org/apache/parquet/tools/command/Registry.java": [
                0,
                1
            ],
            "parquet-tools/src/test/java/org/apache/parquet/tools/command/TestColumnSizeCommand.java": [
                0,
                95
            ]
        }
    },
    "49e862704e7da7149493a953ccc18515d1eada88": {
        "datetime": "2020-04-11T09:01:27+02:00",
        "summary": "PARQUET-1599: Fix to-avro to respect the overwrite option (#650)",
        "message": "PARQUET-1599: Fix to-avro to respect the overwrite option (#650)\n\n* PARQUET-1599: Fix to-avro to respect the overwrite option\r\n\r\n* Address the same problem on SchemaCommand\r\n\r\n* Remove unused variables\r\n\r\n* Consolidate redundant try clauses",
        "diff": {
            "parquet-cli/src/main/java/org/apache/parquet/cli/BaseCommand.java": [
                1,
                23
            ],
            "parquet-cli/src/main/java/org/apache/parquet/cli/commands/SchemaCommand.java": [
                9,
                2
            ],
            "parquet-cli/src/main/java/org/apache/parquet/cli/commands/ToAvroCommand.java": [
                11,
                4
            ],
            "parquet-cli/src/test/java/org/apache/parquet/cli/commands/AvroFileTest.java": [
                7,
                16
            ],
            "parquet-cli/src/test/java/org/apache/parquet/cli/commands/SchemaCommandTest.java": [
                0,
                30
            ],
            "parquet-cli/src/test/java/org/apache/parquet/cli/commands/ToAvroCommandTest.java": [
                0,
                19
            ]
        }
    },
    "2d7b63bc0ca6a8224d3a9d9a61bd4c12b0edb66d": {
        "datetime": "2020-04-15T14:55:11+02:00",
        "summary": "PARQUET-1832: Travis fails with too long output (#777)",
        "message": "PARQUET-1832: Travis fails with too long output (#777)\n\n",
        "diff": {
            ".travis.yml": null,
            "parquet-benchmarks/src/main/resources/log4j.properties": null,
            "parquet-format-structures/pom.xml": null,
            "parquet-hadoop/src/test/java/org/apache/parquet/statistics/TestStatistics.java": [
                9,
                0
            ],
            "parquet-hadoop/src/test/resources/log4j.properties": null,
            "parquet-pig/src/test/resources/log4j.properties": null,
            "parquet-protobuf/src/test/resources/log4j.properties": null,
            "pom.xml": null
        }
    },
    "2affb3661c383bc816357141360d19e265909c90": {
        "datetime": "2020-04-20T15:16:17+02:00",
        "summary": "PARQUET-1699: upgrade yetus to 0.12.0 (#786)",
        "message": "PARQUET-1699: upgrade yetus to 0.12.0 (#786)\n\n",
        "diff": {
            "parquet-common/pom.xml": null
        }
    },
    "70d7f5249042bcc02bd6d9a4c8748f38823bd8a9": {
        "datetime": "2020-04-22T09:31:07+02:00",
        "summary": "PARQUET-1844: Eliminate using commons-lang (#787)",
        "message": "PARQUET-1844: Eliminate using commons-lang (#787)\n\n",
        "diff": {
            "parquet-cascading-common23/src/main/java/org/apache/parquet/cascading/TupleReadSupport.java": [
                4,
                5
            ],
            "parquet-cli/pom.xml": null,
            "parquet-cli/src/main/java/org/apache/parquet/cli/commands/ParquetMetadataCommand.java": [
                2,
                2
            ],
            "parquet-cli/src/main/java/org/apache/parquet/cli/commands/ShowPagesCommand.java": [
                2,
                2
            ],
            "parquet-cli/src/main/java/org/apache/parquet/cli/csv/CSVProperties.java": [
                4,
                13
            ],
            "parquet-hadoop/src/test/java/org/apache/parquet/filter2/dictionarylevel/DictionaryFilterTest.java": [
                2,
                3
            ],
            "pom.xml": null
        }
    },
    "3db93ea7b1e2a806bcbf395bc6b74754cb676c44": {
        "datetime": "2020-04-22T12:16:27+02:00",
        "summary": "PARQUET-1826: Document Hadoop configuration options (#781)",
        "message": "PARQUET-1826: Document Hadoop configuration options (#781)\n\n",
        "diff": {
            "parquet-hadoop/README.md": null,
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/MemoryManager.java": [
                2,
                2
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ParquetOutputFormat.java": [
                2,
                2
            ]
        }
    },
    "60e1cdab36d62ad175471a161df399911f7f71d6": {
        "datetime": "2020-04-22T20:48:33+02:00",
        "summary": "PARQUET-1842: Update jackson-databind version (#785)",
        "message": "PARQUET-1842: Update jackson-databind version (#785)\n\n",
        "diff": {
            "pom.xml": null
        }
    },
    "783c3b78aac41fc69e29ae5679dd8cdb1b38b568": {
        "datetime": "2020-04-26T11:44:39+02:00",
        "summary": "PARQUET-1763: Add SLF4J to TestCircularReferences (#746)",
        "message": "PARQUET-1763: Add SLF4J to TestCircularReferences (#746)\n\nCo-authored-by: David Mollitor <dmollitor@apache.org>",
        "diff": {
            "parquet-avro/src/test/java/org/apache/parquet/avro/TestCircularReferences.java": [
                1,
                5
            ]
        }
    },
    "1456c34e33251b808e8c14a155ea3d5e3327111d": {
        "datetime": "2020-04-28T09:20:49+02:00",
        "summary": "PARQUET-1756: Remove Dependency on Maven Plugin semantic-versioning (#741)",
        "message": "PARQUET-1756: Remove Dependency on Maven Plugin semantic-versioning (#741)\n\nCo-authored-by: David Mollitor <dmollitor@apache.org>",
        "diff": {
            "pom.xml": null
        }
    },
    "b835df9cba406c1b2f765c54b21025f7e604c167": {
        "datetime": "2020-05-02T15:26:38-07:00",
        "summary": "PARQUET-1853: Minimize shaded fastutil in parquet-avro (#790)",
        "message": "PARQUET-1853: Minimize shaded fastutil in parquet-avro (#790)\n\n",
        "diff": {
            "parquet-avro/pom.xml": null
        }
    },
    "94f89aad513521d4f15df034ec054dbde49c5ede": {
        "datetime": "2020-05-07T17:55:40+02:00",
        "summary": "PARQUET-1750: Reduce Memory Usage of RowRanges Class (#735)",
        "message": "PARQUET-1750: Reduce Memory Usage of RowRanges Class (#735)\n\n* PARQUET-1750: Reduce Memory Usage of RowRanges Class\r\n\r\n* Remove pre-initialized size constructor and add List constructor\r\n\r\nCo-authored-by: David Mollitor <dmollitor@apache.org>",
        "diff": {
            "parquet-column/src/main/java/org/apache/parquet/internal/filter2/columnindex/RowRanges.java": [
                13,
                31
            ]
        }
    },
    "a2459b68941cd1eefb3169e80004e1af434b2a80": {
        "datetime": "2020-05-07T17:57:17+02:00",
        "summary": "PARQUET-1728: Simplify NullPointerException Handling in AvroWriteSupport (#716)",
        "message": "PARQUET-1728: Simplify NullPointerException Handling in AvroWriteSupport (#716)\n\n* PARQUET-1728: Simplify NullPointerException Handling in AvroWriteSupport\r\n\r\n* Fixed issue whereby a Collection was being wrapped and not an Array\r\n\r\nCo-authored-by: David Mollitor <dmollitor@apache.org>",
        "diff": {
            "parquet-avro/src/main/java/org/apache/parquet/avro/AvroWriteSupport.java": [
                21,
                19
            ]
        }
    },
    "c6c553b412ac2fb9ad641803e918ddf5220cc757": {
        "datetime": "2020-05-07T17:58:41+02:00",
        "summary": "PARQUET-1775: Deprecate AvroParquetWriter Builder Hadoop Path (#750)",
        "message": "PARQUET-1775: Deprecate AvroParquetWriter Builder Hadoop Path (#750)\n\nCo-authored-by: David Mollitor <dmollitor@apache.org>",
        "diff": {
            "parquet-avro/src/main/java/org/apache/parquet/avro/AvroParquetWriter.java": [
                0,
                8
            ]
        }
    },
    "b2d366a83f293914195f9de86d918f8ddd944374": {
        "datetime": "2020-05-18T15:19:55+02:00",
        "summary": "PARQUET-1863: Configure protoc-jar-maven-plugin to add generated sources to test sources path (#792)",
        "message": "PARQUET-1863: Configure protoc-jar-maven-plugin to add generated sources to test sources path (#792)\n\nBy default, protoc-jar-maven-plugin adds generated source files into the\r\nmain sources path but it can be configured to add them to the test\r\nsources path instead.\r\n\r\nChange the plugin configuration to do so, and remove use of the now\r\nobsolete build-helper-maven-plugin:add-test-source goal.",
        "diff": {
            "parquet-protobuf/pom.xml": null
        }
    },
    "0acade062893cc0ac6e8cb7ed01470c38ea4bdb5": {
        "datetime": "2020-06-01T10:25:28-07:00",
        "summary": "PARQUET-1850: Fix dictionaryPageOffset flag setting in toParquetMetadata method",
        "message": "PARQUET-1850: Fix dictionaryPageOffset flag setting in toParquetMetadata method\n\n### Issue\n\ntoParquetMetadata method converts org.apache.parquet.hadoop.metadata.ParquetMetadata to org.apache.parquet.format.FileMetaData but this does not set the dictionary page offset bit in FileMetaData.\n\nWhen a FileMetaData object is serialized while writing to the footer and then deserialized, the dictionary offset is lost as the dictionary page offset bit was never set.\n\n### Fix\n\nThe flag is set to true when a dictionary page is used for encoding.\n\n### Tests\n\nA ParquetMetadata object is created with PLAIN_DICTIONARY encoding and dictionaryPageOffset is set to a non zero value.\n\nThe ParquetMetadata object is converted to FileMetaData using toParquetMetadata method.\nThe FileMetaData object is then serialized and deserialized to FileMetaData and converted back to ParquetMetadata using fromParquetMetadata method.\n\nThe new ParquetMetadata should have the same dictionaryPageOffset as the original ParquetMetadata object.\n\nAuthor: srinivasst <srinivasstxd@gmail.com>\n\nCloses #789 from srinivasst/ParquetConverterFix and squashes the following commits:\n\ne3d867e6 [srinivasst] Set dictionary page offset flag while setting the page offset\n79471854 [srinivasst] Fix dictionary flag setting in toParquetMetadata method in ParquetMetadataConverter class\n",
        "diff": {
            "parquet-hadoop/src/main/java/org/apache/parquet/format/converter/ParquetMetadataConverter.java": [
                1,
                3
            ],
            "parquet-hadoop/src/test/java/org/apache/parquet/format/converter/TestParquetMetadataConverter.java": [
                0,
                90
            ]
        }
    },
    "1c63c9392db49ec7922b459677e51196178fac8e": {
        "datetime": "2020-06-02T09:45:07+02:00",
        "summary": "PARQUET-1868: Fix bloom filter toggle in reader options builder (#795)",
        "message": "PARQUET-1868: Fix bloom filter toggle in reader options builder (#795)\n\n",
        "diff": {
            "parquet-hadoop/src/main/java/org/apache/parquet/ParquetReadOptions.java": [
                1,
                1
            ]
        }
    },
    "958ed6fa8aeb4bfbb10b98c3cd6117473c69f30e": {
        "datetime": "2020-06-02T18:10:28+02:00",
        "summary": "PARQUET-1684: Do not store default protobuf values as null for proto3 (#702)",
        "message": "PARQUET-1684: Do not store default protobuf values as null for proto3 (#702)\n\nCo-authored-by: Priyank Bagrecha <pbagrecha@roku.com>",
        "diff": {
            "parquet-protobuf/pom.xml": null,
            "parquet-protobuf/src/main/java/org/apache/parquet/proto/ProtoWriteSupport.java": [
                22,
                52
            ],
            "parquet-protobuf/src/test/java/org/apache/parquet/proto/ProtoInputOutputFormatTest.java": [
                0,
                294
            ],
            "parquet-protobuf/src/test/java/org/apache/parquet/proto/ProtoWriteSupportTest.java": [
                4,
                46
            ],
            "parquet-protobuf/src/test/java/org/apache/parquet/proto/TestUtils.java": [
                7,
                23
            ]
        }
    },
    "dc40b598a003dc8da38cadd576c9a36ece1eea1f": {
        "datetime": "2020-06-03T09:17:15+02:00",
        "summary": "PARQUET-1866: Replace Hadoop ZSTD with JNI-ZSTD (#793)",
        "message": "PARQUET-1866: Replace Hadoop ZSTD with JNI-ZSTD (#793)\n\n",
        "diff": {
            "parquet-common/src/main/java/org/apache/parquet/hadoop/metadata/CompressionCodecName.java": [
                1,
                1
            ],
            "parquet-hadoop/README.md": null,
            "parquet-hadoop/pom.xml": null,
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/CodecFactory.java": [
                1,
                3
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/codec/ZstandardCodec.java": [
                0,
                112
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/codec/ZstdCompressorStream.java": [
                0,
                62
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/codec/ZstdDecompressorStream.java": [
                0,
                47
            ],
            "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/TestZstandardCodec.java": [
                0,
                167
            ],
            "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/example/TestInputOutputFormat.java": [
                0,
                1
            ]
        }
    },
    "84c954d8a4feef2d9bdad7a236a7268ef71a1c25": {
        "datetime": "2020-06-04T08:56:31+02:00",
        "summary": "PARQUET-1827: UUID type currently not supported by parquet-mr (#778)",
        "message": "PARQUET-1827: UUID type currently not supported by parquet-mr (#778)\n\n",
        "diff": {
            "parquet-avro/README.md": null,
            "parquet-avro/src/main/java/org/apache/parquet/avro/AvroConverters.java": [
                0,
                16
            ],
            "parquet-avro/src/main/java/org/apache/parquet/avro/AvroRecordConverter.java": [
                8,
                7
            ],
            "parquet-avro/src/main/java/org/apache/parquet/avro/AvroSchemaConverter.java": [
                6,
                28
            ],
            "parquet-avro/src/main/java/org/apache/parquet/avro/AvroWriteSupport.java": [
                5,
                28
            ],
            "parquet-avro/src/test/java/org/apache/parquet/avro/AvroTestUtil.java": [
                3,
                18
            ],
            "parquet-avro/src/test/java/org/apache/parquet/avro/TestAvroSchemaConverter.java": [
                0,
                32
            ],
            "parquet-avro/src/test/java/org/apache/parquet/avro/TestGenericLogicalTypes.java": [
                3,
                46
            ],
            "parquet-avro/src/test/java/org/apache/parquet/avro/TestReflectLogicalTypes.java": [
                12,
                297
            ],
            "parquet-column/pom.xml": null,
            "parquet-column/src/main/java/org/apache/parquet/schema/LogicalTypeAnnotation.java": [
                0,
                44
            ],
            "parquet-column/src/main/java/org/apache/parquet/schema/PrimitiveStringifier.java": [
                0,
                27
            ],
            "parquet-column/src/main/java/org/apache/parquet/schema/PrimitiveType.java": [
                0,
                7
            ],
            "parquet-column/src/main/java/org/apache/parquet/schema/Types.java": [
                21,
                24
            ],
            "parquet-column/src/test/java/org/apache/parquet/schema/TestPrimitiveStringifier.java": [
                3,
                36
            ],
            "parquet-column/src/test/java/org/apache/parquet/schema/TestTypeBuildersWithLogicalTypes.java": [
                0,
                14
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/format/converter/ParquetMetadataConverter.java": [
                0,
                15
            ],
            "parquet-hadoop/src/test/java/org/apache/parquet/format/converter/TestParquetMetadataConverter.java": [
                0,
                3
            ],
            "parquet-hadoop/src/test/java/org/apache/parquet/statistics/TestColumnIndexes.java": [
                0,
                4
            ]
        }
    },
    "e4988f3489663b99ff35a8573bab5522d5e6dcf8": {
        "datetime": "2020-06-23T11:40:04+02:00",
        "summary": "Parquet-1872: Add TransCompression command to parquet-tools (#796)",
        "message": "Parquet-1872: Add TransCompression command to parquet-tools (#796)\n\n",
        "diff": {
            "parquet-cli/src/main/java/org/apache/parquet/cli/commands/TransCompressionCommand.java": [
                0,
                96
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ParquetFileReader.java": [
                1,
                1
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/util/CompressionConverter.java": [
                0,
                271
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/util/H1SeekableInputStream.java": [
                1,
                1
            ],
            "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/util/CompressionConveterTest.java": [
                0,
                319
            ],
            "parquet-tools/src/main/java/org/apache/parquet/tools/command/TransCompressionCommand.java": [
                0,
                92
            ]
        }
    },
    "00b42d5000499244c8403ca536821b19d5d216ae": {
        "datetime": "2020-06-30T11:49:30+02:00",
        "summary": "Parquet-1872: Add TransCompression command to parquet-tools - Add the command to registry to complete (#799)",
        "message": "Parquet-1872: Add TransCompression command to parquet-tools - Add the command to registry to complete (#799)\n\n",
        "diff": {
            "parquet-cli/src/main/java/org/apache/parquet/cli/Main.java": [
                0,
                2
            ],
            "parquet-tools/src/main/java/org/apache/parquet/tools/command/Registry.java": [
                0,
                1
            ]
        }
    },
    "2589cc821d2d470be1e79b86f511eb1f5fee4e5c": {
        "datetime": "2020-07-06T09:32:37+02:00",
        "summary": "PARQUET-1879: MapKeyValue is not a valid Logical Type (#798)",
        "message": "PARQUET-1879: MapKeyValue is not a valid Logical Type (#798)\n\n* Writing UNKNOWN logical type into the schema, causes a breakage\r\n  when parsing the file with Apache Arrow\r\n* Instead use the default, of falling back to null when that\r\n  backwards-compatibility only logical type is present, but still\r\n  write the original type",
        "diff": {
            "parquet-avro/src/test/java/org/apache/parquet/avro/TestAvroSchemaConverter.java": [
                5,
                5
            ],
            "parquet-avro/src/test/java/org/apache/parquet/avro/TestReadWrite.java": [
                2,
                2
            ],
            "parquet-column/src/main/java/org/apache/parquet/schema/ConversionPatterns.java": [
                2,
                3
            ],
            "parquet-column/src/main/java/org/apache/parquet/schema/Types.java": [
                3,
                5
            ],
            "parquet-column/src/test/java/org/apache/parquet/schema/TestTypeBuilders.java": [
                28,
                28
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/format/converter/ParquetMetadataConverter.java": [
                6,
                1
            ],
            "parquet-hadoop/src/test/java/org/apache/parquet/format/converter/TestParquetMetadataConverter.java": [
                0,
                105
            ],
            "parquet-hive/parquet-hive-storage-handler/src/test/java/org/apache/hadoop/hive/ql/io/parquet/TestHiveSchemaConverter.java": [
                5,
                5
            ],
            "parquet-pig/src/main/java/org/apache/parquet/pig/PigSchemaConverter.java": [
                1,
                2
            ],
            "parquet-pig/src/test/java/org/apache/parquet/pig/TestPigSchemaConverter.java": [
                10,
                10
            ],
            "parquet-pig/src/test/java/org/apache/parquet/pig/TestTupleRecordConsumer.java": [
                5,
                5
            ],
            "parquet-thrift/src/test/java/org/apache/parquet/hadoop/thrift/TestThriftToParquetFileWriter.java": [
                11,
                11
            ],
            "parquet-thrift/src/test/java/org/apache/parquet/thrift/TestParquetWriteProtocol.java": [
                15,
                15
            ],
            "parquet-thrift/src/test/java/org/apache/parquet/thrift/TestThriftSchemaConverter.java": [
                4,
                4
            ],
            "parquet-thrift/src/test/java/org/apache/parquet/thrift/TestThriftSchemaConverterProjectUnion.java": [
                6,
                6
            ]
        }
    },
    "fadbe6ef326faa5984d4d8d6df581a91c8c6cca2": {
        "datetime": "2020-07-22T22:05:38+02:00",
        "summary": "Parquet-1860: Add missing Builder Class to ProtoParquetWriter Class (#791)",
        "message": "Parquet-1860: Add missing Builder Class to ProtoParquetWriter Class (#791)\n\n* Add missing Builder support\r\n\r\nProtoParquetWriter only has basic constructors, that which call deprecated super constructors. We cannot set many other options (Write mode, encoding etc) as well. Extended the ParquetWriter.Builder class for builder support.\r\n\r\n* Add import for OutputFile\r\n\r\nParquet-1860 checks failed due ambiguous constructor. Added a missing import, and proceed to recheck.\r\n\r\n* Add Configuration import\r\n\r\nAdded missing import of class Configuration",
        "diff": {
            "parquet-protobuf/src/main/java/org/apache/parquet/proto/ProtoParquetWriter.java": [
                0,
                39
            ]
        }
    },
    "9a1fbc4ee3f63284a675eeac6c62e96ffc973575": {
        "datetime": "2020-07-22T22:06:50+02:00",
        "summary": "PARQUET-1778: Do Not Consider Class for Avro Generic Record Reader (#751)",
        "message": "PARQUET-1778: Do Not Consider Class for Avro Generic Record Reader (#751)\n\n",
        "diff": {
            "parquet-avro/src/main/java/org/apache/parquet/avro/AvroParquetReader.java": [
                0,
                32
            ],
            "parquet-avro/src/test/java/org/apache/parquet/avro/TestReadWrite.java": [
                0,
                46
            ]
        }
    },
    "65b95fb72be8f5a8a193a6f7bc4560fdcd742fc7": {
        "datetime": "2020-07-29T09:52:54+02:00",
        "summary": "PARQUET-1884: Encryption branch merge in master (#800)",
        "message": "PARQUET-1884: Encryption branch merge in master (#800)\n\n* PARQUET-1228: Format Structures encryption (#613)\r\n* PARQUET-1286: Crypto package (#614)\r\n* PARQUET-1818: Fix bloom/encryption collision in format-structures (#771)\r\n* PARQUET-1817: Crypto Properties Factory (#769)\r\n* PARQUET-1229: Parquet MR encryption (#776)\r\n* PARQUET-1807: Encryption: Interop and Function test suite for Java version (#782)\r\n* PARQUET-1373: Encryption key tools (#615)\r\n\r\nCo-authored-by: shangxinli <31421745+shangxinli@users.noreply.github.com>\r\nCo-authored-by: Maya Anderson <mayaa@il.ibm.com>",
        "diff": {
            ".gitmodules": null,
            ".travis.yml": null,
            "parquet-column/src/main/java/org/apache/parquet/internal/column/columnindex/OffsetIndex.java": [
                0,
                7
            ],
            "parquet-column/src/main/java/org/apache/parquet/internal/column/columnindex/OffsetIndexBuilder.java": [
                1,
                5
            ],
            "parquet-format-structures/src/main/java/org/apache/parquet/format/BlockCipher.java": [
                0,
                67
            ],
            "parquet-format-structures/src/main/java/org/apache/parquet/format/Util.java": [
                46,
                190
            ],
            "parquet-hadoop/README.md": null,
            "parquet-hadoop/pom.xml": null,
            "parquet-hadoop/src/main/java/org/apache/parquet/HadoopReadOptions.java": [
                3,
                29
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/ParquetReadOptions.java": [
                2,
                17
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/crypto/AADPrefixVerifier.java": [
                0,
                32
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/crypto/AesCipher.java": [
                0,
                158
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/crypto/AesCtrDecryptor.java": [
                0,
                128
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/crypto/AesCtrEncryptor.java": [
                0,
                98
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/crypto/AesGcmDecryptor.java": [
                0,
                119
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/crypto/AesGcmEncryptor.java": [
                0,
                84
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/crypto/AesMode.java": [
                0,
                35
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/crypto/ColumnDecryptionProperties.java": [
                0,
                104
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/crypto/ColumnEncryptionProperties.java": [
                0,
                186
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/crypto/DecryptionKeyRetriever.java": [
                0,
                39
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/crypto/DecryptionPropertiesFactory.java": [
                0,
                88
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/crypto/EncryptionPropertiesFactory.java": [
                0,
                93
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/crypto/FileDecryptionProperties.java": [
                0,
                254
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/crypto/FileEncryptionProperties.java": [
                0,
                278
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/crypto/InternalColumnDecryptionSetup.java": [
                0,
                74
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/crypto/InternalColumnEncryptionSetup.java": [
                0,
                82
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/crypto/InternalFileDecryptor.java": [
                0,
                315
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/crypto/InternalFileEncryptor.java": [
                0,
                196
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/crypto/KeyAccessDeniedException.java": [
                0,
                39
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/crypto/ModuleCipherFactory.java": [
                0,
                73
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/crypto/ParquetCipher.java": [
                0,
                42
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/crypto/ParquetCryptoRuntimeException.java": [
                0,
                42
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/crypto/TagVerificationException.java": [
                0,
                39
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/crypto/keytools/FileKeyMaterialStore.java": [
                0,
                72
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/crypto/keytools/FileKeyUnwrapper.java": [
                0,
                173
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/crypto/keytools/FileKeyWrapper.java": [
                0,
                158
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/crypto/keytools/HadoopFSKeyMaterialStore.java": [
                0,
                133
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/crypto/keytools/KeyMaterial.java": [
                0,
                210
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/crypto/keytools/KeyMetadata.java": [
                0,
                130
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/crypto/keytools/KeyToolkit.java": [
                0,
                372
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/crypto/keytools/KmsClient.java": [
                0,
                72
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/crypto/keytools/PropertiesDrivenCryptoFactory.java": [
                0,
                227
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/crypto/keytools/RemoteKmsClient.java": [
                0,
                229
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/crypto/keytools/TwoLevelCacheWithExpiration.java": [
                0,
                105
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/format/converter/ParquetMetadataConverter.java": [
                54,
                320
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ColumnChunkPageReadStore.java": [
                46,
                85
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ColumnChunkPageWriteStore.java": [
                21,
                144
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ColumnIndexFilterUtils.java": [
                0,
                5
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/DictionaryPageReader.java": [
                18,
                1
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/InternalParquetRecordWriter.java": [
                1,
                9
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ParquetFileReader.java": [
                44,
                231
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ParquetFileWriter.java": [
                32,
                217
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ParquetOutputFormat.java": [
                5,
                19
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ParquetReader.java": [
                5,
                13
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ParquetRecordReader.java": [
                1,
                1
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ParquetWriter.java": [
                6,
                22
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/metadata/BlockMetaData.java": [
                2,
                18
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/metadata/ColumnChunkMetaData.java": [
                2,
                164
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/metadata/FileMetaData.java": [
                0,
                11
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/util/HadoopInputFile.java": [
                0,
                4
            ],
            "parquet-hadoop/src/test/java/org/apache/parquet/crypto/DecryptionKeyRetrieverMock.java": [
                0,
                41
            ],
            "parquet-hadoop/src/test/java/org/apache/parquet/crypto/DecryptionPropertiesFactoryTest.java": [
                0,
                43
            ],
            "parquet-hadoop/src/test/java/org/apache/parquet/crypto/EncryptionPropertiesFactoryTest.java": [
                0,
                45
            ],
            "parquet-hadoop/src/test/java/org/apache/parquet/crypto/SampleDecryptionPropertiesFactory.java": [
                0,
                57
            ],
            "parquet-hadoop/src/test/java/org/apache/parquet/crypto/SampleEncryptionPropertiesFactory.java": [
                0,
                58
            ],
            "parquet-hadoop/src/test/java/org/apache/parquet/crypto/SingleRow.java": [
                0,
                139
            ],
            "parquet-hadoop/src/test/java/org/apache/parquet/crypto/TestPropertiesDrivenEncryption.java": [
                0,
                647
            ],
            "parquet-hadoop/src/test/java/org/apache/parquet/crypto/keytools/mocks/InMemoryKMS.java": [
                0,
                123
            ],
            "parquet-hadoop/src/test/java/org/apache/parquet/crypto/keytools/samples/VaultClient.java": [
                0,
                169
            ],
            "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/TestBloomFiltering.java": [
                23,
                91
            ],
            "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/TestColumnIndexFiltering.java": [
                21,
                101
            ],
            "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/TestEncryptionOptions.java": [
                0,
                680
            ],
            "pom.xml": null,
            "submodules/parquet-testing": null
        }
    },
    "5a7c0fe15869f1a3da9790851b988cfd743a8004": {
        "datetime": "2020-07-29T15:35:20+02:00",
        "summary": "PARQUET-1891: encryption fixes (#805)",
        "message": "PARQUET-1891: encryption fixes (#805)\n\n",
        "diff": {
            ".travis.yml": null,
            "parquet-hadoop/README.md": null,
            "parquet-hadoop/src/test/java/org/apache/parquet/crypto/keytools/samples/VaultClient.java": [
                2,
                1
            ]
        }
    },
    "4bf67a4ee7199a317a36b3ad1207408c5f8a12f4": {
        "datetime": "2020-07-30T09:06:18+02:00",
        "summary": "PARQUET-1890: Upgrade to Apache Avro 1.10.0 (#806)",
        "message": "PARQUET-1890: Upgrade to Apache Avro 1.10.0 (#806)\n\n",
        "diff": {
            "parquet-avro/src/test/java/org/apache/parquet/avro/TestReadWrite.java": [
                2,
                4
            ],
            "parquet-avro/src/test/java/org/apache/parquet/avro/TestStringBehavior.java": [
                13,
                13
            ],
            "pom.xml": null
        }
    },
    "64b79404efdfdf954bb7d80fb8f0d66d736b8638": {
        "datetime": "2020-08-24T14:41:31+02:00",
        "summary": "PARQUET-1896: Fix parquet-tools build (#809)",
        "message": "PARQUET-1896: Fix parquet-tools build (#809)\n\nJackson deps is not opted in as transitive dependency when we shade parquet-hadoop.\r\nIn consequence, jackson is missing from parquet-tools dependency tree.",
        "diff": {
            "parquet-tools/pom.xml": null
        }
    },
    "3d45fd5480b1b58074c5b53d0738774cf355d11e": {
        "datetime": "2020-08-25T11:33:11+02:00",
        "summary": "PARQUET-1455: [parquet-protobuf] Handle protobuf enum schema evolution and unknown enum value (#561)",
        "message": "PARQUET-1455: [parquet-protobuf] Handle protobuf enum schema evolution and unknown enum value (#561)\n\nProtobuf can set enum field using number, while a number does not\r\nmatch any enum value defined in the schema, it is still accepted\r\nand a label \"UNKNOWN_ENUM_<enumName>_<number>\" is generated when\r\nwe use protobuf reflection API (proto descriptors) to access it.\r\nAnd in parquet-protobuf, we rely on protobuf reflection API to\r\nconvert forward/backward between the two world.\r\n\r\nThere are two cases of unknown enum while using parquet-protobuf:\r\n  1. Protobuf already contains unknown enum when we write it to\r\n  parquet (eg1. sometmes people set enum fields using numbers; eg2\r\n  writer deserialize data from wire and the sender can have a newer\r\n  version of proto schema with new enum values). The behavior of\r\n  parquet-protobuf writer as before this patch is to write a label\r\n  \"UNKNOWN_ENUM_<number>\" as string in the enum column of parquet.\r\n  And when we read it back as protobuf, we found this unknown label\r\n  which does not match any enum def (even with the same schema as\r\n  the sender in eg2)\r\n  2. Protobuf contains valid value when write to parquet, but the\r\n  reader uses an outdated proto schema which misses some enum\r\n  values. So the not-in-old-schema enum values are \"unknown\" to the\r\n  reader.\r\n\r\nPrevious behavior of parquet-proto reader is to reject in both\r\ncases with some runtime exception.\r\n\r\nTo be able to handle the problems:\r\nWe keep enum (name -> number) mapping in the parquet metadata, so\r\nthat in read time, reader can discover the number and use protobuf\r\nreflection API to set enum number.\r\nKeep in mind though, for the case reading enum with outdated schema\r\n(case 2), the enum read back will have the right number, but the\r\nlabel is set to \"UNKNOW_ENUM_<number>\". So this feature is helpful\r\nonly if the user is using number to manipulate enum data.\r\nAnd for old data containing \"true\" unknown value (thus case 1)\r\ncreated before this patch (thus name -> number mapping is not\r\navailable), we now try to parse the string regarding to the\r\n\"UNKNOWN_ENUM_<number>\" pattern.\r\nIf we read old data created before this patch (thus name -> number\r\nis not available), with an outdated schema, and we find some enum\r\nvalue not defined in the schema nor following \"UNKNOWN_ENUM_*\"\r\npattern, we could either fail the job by raising an exception or\r\ntreat the value as unknown enum with number -1, by setting a flag\r\nin the configuration.\r\n\r\nThe name -> number mapping is a new metadata under the\r\n\"parquet.proto.enum\" namespace. The metadata for protobuf enum\r\n(label:number) mapping should follow some specific pattern, throw\r\nBadConfigurationException in read time if it is not.\r\n\r\nTests for enum schema evolution (read/write with different protobuf\r\nschema) are added.\r\n",
        "diff": {
            "parquet-protobuf/src/main/java/org/apache/parquet/proto/ProtoConstants.java": [
                0,
                40
            ],
            "parquet-protobuf/src/main/java/org/apache/parquet/proto/ProtoMessageConverter.java": [
                24,
                90
            ],
            "parquet-protobuf/src/main/java/org/apache/parquet/proto/ProtoReadSupport.java": [
                4,
                4
            ],
            "parquet-protobuf/src/main/java/org/apache/parquet/proto/ProtoRecordConverter.java": [
                8,
                23
            ],
            "parquet-protobuf/src/main/java/org/apache/parquet/proto/ProtoRecordMaterializer.java": [
                5,
                8
            ],
            "parquet-protobuf/src/main/java/org/apache/parquet/proto/ProtoWriteSupport.java": [
                3,
                51
            ],
            "parquet-protobuf/src/test/java/org/apache/parquet/proto/ProtoRecordConverterTest.java": [
                3,
                22
            ],
            "parquet-protobuf/src/test/java/org/apache/parquet/proto/ProtoSchemaEvolutionTest.java": [
                0,
                68
            ],
            "parquet-protobuf/src/test/java/org/apache/parquet/proto/TestUtils.java": [
                19,
                29
            ],
            "parquet-protobuf/src/test/resources/TestProto3SchemaV1.proto": null,
            "parquet-protobuf/src/test/resources/TestProto3SchemaV2.proto": null,
            "pom.xml": null
        }
    },
    "0a4e3eea991f7588c9c5e056e9d7b32a76eed5da": {
        "datetime": "2020-10-05T11:39:52+02:00",
        "summary": "PARQUET-313: Implement 3 level list writing rule for Parquet-Thrift (#222)",
        "message": "PARQUET-313: Implement 3 level list writing rule for Parquet-Thrift (#222)\n\n",
        "diff": {
            "parquet-scrooge/src/main/java/org/apache/parquet/scrooge/ScroogeReadSupport.java": [
                5,
                11
            ],
            "parquet-thrift/README.md": null,
            "parquet-thrift/src/main/java/org/apache/parquet/hadoop/thrift/AbstractThriftWriteSupport.java": [
                2,
                7
            ],
            "parquet-thrift/src/main/java/org/apache/parquet/hadoop/thrift/ParquetThriftBytesOutputFormat.java": [
                7,
                34
            ],
            "parquet-thrift/src/main/java/org/apache/parquet/hadoop/thrift/TBaseWriteSupport.java": [
                1,
                5
            ],
            "parquet-thrift/src/main/java/org/apache/parquet/hadoop/thrift/ThriftBytesWriteSupport.java": [
                7,
                30
            ],
            "parquet-thrift/src/main/java/org/apache/parquet/hadoop/thrift/ThriftReadSupport.java": [
                6,
                16
            ],
            "parquet-thrift/src/main/java/org/apache/parquet/hadoop/thrift/ThriftToParquetFileWriter.java": [
                1,
                3
            ],
            "parquet-thrift/src/main/java/org/apache/parquet/thrift/ParquetWriteProtocol.java": [
                29,
                116
            ],
            "parquet-thrift/src/main/java/org/apache/parquet/thrift/ThriftSchemaConvertVisitor.java": [
                7,
                37
            ],
            "parquet-thrift/src/main/java/org/apache/parquet/thrift/ThriftSchemaConverter.java": [
                5,
                20
            ],
            "parquet-thrift/src/test/java/org/apache/parquet/hadoop/thrift/TestThriftToParquetFileWriter.java": [
                9,
                74
            ],
            "parquet-thrift/src/test/java/org/apache/parquet/thrift/TestParquetWriteProtocol.java": [
                4,
                172
            ],
            "parquet-thrift/src/test/java/org/apache/parquet/thrift/TestThriftParquetReaderWriter.java": [
                3,
                13
            ]
        }
    },
    "0d09be68c289a56e9e547949a3d1ee6df10ef794": {
        "datetime": "2020-10-12T10:22:32+02:00",
        "summary": "PARQUET-1920: Fix Parquet writer's memory check interval calculation (#824)",
        "message": "PARQUET-1920: Fix Parquet writer's memory check interval calculation (#824)\n\nFix Parquet writer's memory check interval calculation, and throw helpful message while dealing with too large column chunks.",
        "diff": {
            "parquet-common/src/main/java/org/apache/parquet/bytes/BytesInput.java": [
                3,
                10
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/InternalParquetRecordWriter.java": [
                7,
                7
            ]
        }
    },
    "e49b83f151082170bad33a57d7c5a2aace2916f6": {
        "datetime": "2020-10-13T10:30:11+02:00",
        "summary": "PARQUET-1895: Update jackson-databind (#811)",
        "message": "PARQUET-1895: Update jackson-databind (#811)\n\n",
        "diff": {
            "pom.xml": null
        }
    },
    "fe9ab5d22c602776f44b027ad3cc05609eddba54": {
        "datetime": "2020-10-14T08:45:49+02:00",
        "summary": "PARQUET-1923: upgrade hadoop from 2.7.3 to 2.10.1 (#826)",
        "message": "PARQUET-1923: upgrade hadoop from 2.7.3 to 2.10.1 (#826)\n\n",
        "diff": {
            "pom.xml": null
        }
    },
    "bc4c97253b51811de4e1c18a3f4113172f37e7f3": {
        "datetime": "2020-10-21T22:12:27+02:00",
        "summary": "PARQUET-1924: Do not Instantiate a New LongHashFunction (#827)",
        "message": "PARQUET-1924: Do not Instantiate a New LongHashFunction (#827)\n\n",
        "diff": {
            "parquet-column/src/main/java/org/apache/parquet/column/values/bloomfilter/XxHash.java": [
                2,
                2
            ]
        }
    },
    "05605840dc6f45bbdb9ff9d730d5cbf996747454": {
        "datetime": "2020-10-21T22:14:52+02:00",
        "summary": "PARQUET-1910 fix broken cli (#814)",
        "message": "PARQUET-1910 fix broken cli (#814)\n\nCo-authored-by: Grisha Weintraub <grisha.weintraub@ibm.com>",
        "diff": {
            "parquet-cli/src/main/java/org/apache/parquet/cli/commands/TransCompressionCommand.java": [
                3,
                7
            ],
            "parquet-cli/src/test/java/org/apache/parquet/cli/MainTest.java": [
                0,
                34
            ],
            "parquet-cli/src/test/java/org/apache/parquet/cli/commands/TransCompressionCommandTest.java": [
                0,
                45
            ]
        }
    },
    "0dc3fbcae56e467f143848ea6ef31ed75bda88f2": {
        "datetime": "2020-10-22T10:23:43+02:00",
        "summary": "PARQUET-1528:  Add JSON support to `parquet-tools head` (#829)",
        "message": "PARQUET-1528:  Add JSON support to `parquet-tools head` (#829)\n\nReplace usage of deprecated OptionBuilder",
        "diff": {
            "parquet-tools/src/main/java/org/apache/parquet/tools/command/HeadCommand.java": [
                7,
                28
            ]
        }
    },
    "bebd309db3d4014eadbc9f0d9f6be87c0aec6ded": {
        "datetime": "2020-10-22T16:19:30+02:00",
        "summary": "PARQUET-1893: H2SeekableInputStream readFully() doesn't respect start and len (#807)",
        "message": "PARQUET-1893: H2SeekableInputStream readFully() doesn't respect start and len (#807)\n\n",
        "diff": {
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/util/H2SeekableInputStream.java": [
                1,
                1
            ]
        }
    },
    "14b7a8be8ac98c7f96fc3fd2d5c21cbddf736b64": {
        "datetime": "2020-10-22T16:54:29+02:00",
        "summary": "PARQUET-1917: Don't write values for oneOf fields that aren't set (#820)",
        "message": "PARQUET-1917: Don't write values for oneOf fields that aren't set (#820)\n\n",
        "diff": {
            "parquet-protobuf/src/main/java/org/apache/parquet/proto/ProtoWriteSupport.java": [
                0,
                6
            ],
            "parquet-protobuf/src/test/java/org/apache/parquet/proto/ProtoWriteSupportTest.java": [
                0,
                63
            ],
            "parquet-protobuf/src/test/resources/TestProto3.proto": null
        }
    },
    "472eebb09d035e5073c384c319ba549f74d79691": {
        "datetime": "2020-10-22T16:57:05+02:00",
        "summary": "PARQUET-1914: Allow ProtoParquetReader To Support InputFile (#817)",
        "message": "PARQUET-1914: Allow ProtoParquetReader To Support InputFile (#817)\n\n",
        "diff": {
            "parquet-protobuf/src/main/java/org/apache/parquet/proto/ProtoParquetReader.java": [
                7,
                29
            ],
            "parquet-protobuf/src/test/java/org/apache/parquet/proto/TestUtils.java": [
                1,
                6
            ]
        }
    },
    "a2c6ff0775fe9862fad197faa5aee7e80af52827": {
        "datetime": "2020-10-22T18:36:35+02:00",
        "summary": "[PARQUET-1930] Bump Apache Thrift to 0.13.0 (#834)",
        "message": "[PARQUET-1930] Bump Apache Thrift to 0.13.0 (#834)\n\n",
        "diff": {
            "README.md": null,
            "dev/travis-before_install.sh": null,
            "pom.xml": null
        }
    },
    "f8393a3489830397da29af02ecc3cf4a32722417": {
        "datetime": "2020-10-22T18:44:23+02:00",
        "summary": "[PARQUET-1931] Bump Junit to 4.13.1 (#835)",
        "message": "[PARQUET-1931] Bump Junit to 4.13.1 (#835)\n\nLooks like there is a vulnerability in Junit:\r\nhttps://github.com/Fokko/parquet-mr/pull/44",
        "diff": {
            "pom.xml": null
        }
    },
    "55a36b023ea445d6d6f0d03e34a62a102899a78a": {
        "datetime": "2020-10-22T18:45:30+02:00",
        "summary": "[PARQUET-1929] Bump Snappy to 1.1.8 (#833)",
        "message": "[PARQUET-1929] Bump Snappy to 1.1.8 (#833)\n\nFor performance improvements;\r\n\r\nthe released snappy-java bundles the latest Snappy v1.1.8 binaries with small performance improvements.\r\n\r\n- snappy-java release note: https://github.com/xerial/snappy-java/releases/tag/1.1.8\r\n- snappy release note: https://github.com/google/snappy/releases/tag/1.1.8",
        "diff": {
            "parquet-hadoop/pom.xml": null
        }
    },
    "358f1eb44b45795fccf1990255209867db0272b1": {
        "datetime": "2020-10-22T19:53:27+02:00",
        "summary": "[PARQUET-1932] Bump Fastutil to 8.4.2 (#836)",
        "message": "[PARQUET-1932] Bump Fastutil to 8.4.2 (#836)\n\n",
        "diff": {
            "pom.xml": null
        }
    },
    "1e5242004da1441f8c540ba67e03ca9838881e6e": {
        "datetime": "2020-11-12T09:31:32+01:00",
        "summary": "PARQUET-1944: Unable to download transitive dependency hadoop-lzo (#843)",
        "message": "PARQUET-1944: Unable to download transitive dependency hadoop-lzo (#843)\n\n",
        "diff": {
            "parquet-thrift/pom.xml": null
        }
    },
    "c6187e8d50a241ff83bb364526658d5ddce34b34": {
        "datetime": "2020-11-12T17:01:33+01:00",
        "summary": "PARQUET-1940: KEK length configuration (#838)",
        "message": "PARQUET-1940: KEK length configuration (#838)\n\n",
        "diff": {
            "parquet-hadoop/README.md": null,
            "parquet-hadoop/src/main/java/org/apache/parquet/crypto/keytools/FileKeyWrapper.java": [
                2,
                11
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/crypto/keytools/KeyToolkit.java": [
                0,
                6
            ]
        }
    },
    "f737105ca8cbc750f9bc7585461cf74750aafeb3": {
        "datetime": "2020-11-12T17:02:50+01:00",
        "summary": "PARQUET-1941: Bump Commons CLI from 1.3.1 to 1.4 (#839)",
        "message": "PARQUET-1941: Bump Commons CLI from 1.3.1 to 1.4 (#839)\n\n",
        "diff": {
            "parquet-tools/pom.xml": null
        }
    },
    "2908cffca9a91d5a5d12c25755ff4b8bcf51ac89": {
        "datetime": "2020-11-12T17:03:20+01:00",
        "summary": "PARQUET-1939: Fix remote KMS client ambiguity (#841)",
        "message": "PARQUET-1939: Fix remote KMS client ambiguity (#841)\n\n",
        "diff": {
            "parquet-hadoop/README.md": null,
            "parquet-hadoop/src/main/java/org/apache/parquet/crypto/keytools/KeyToolkit.java": [
                10,
                0
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/crypto/keytools/RemoteKmsClient.java": [
                84,
                36
            ],
            "parquet-hadoop/src/test/java/org/apache/parquet/crypto/TestPropertiesDrivenEncryption.java": [
                2,
                10
            ],
            "parquet-hadoop/src/test/java/org/apache/parquet/crypto/keytools/mocks/InMemoryKMS.java": [
                13,
                6
            ],
            "parquet-hadoop/src/test/java/org/apache/parquet/crypto/keytools/mocks/LocalWrapInMemoryKMS.java": [
                0,
                79
            ],
            "parquet-hadoop/src/test/java/org/apache/parquet/crypto/keytools/samples/VaultClient.java": [
                18,
                34
            ]
        }
    },
    "d291d05f1c9e3ee5ab87403d94cf13a5ab9cb04d": {
        "datetime": "2020-11-12T17:03:43+01:00",
        "summary": "PARQUET-1938: Key rotation - option to get KMS details from key material (#842)",
        "message": "PARQUET-1938: Key rotation - option to get KMS details from key material (#842)\n\n",
        "diff": {
            "parquet-hadoop/src/main/java/org/apache/parquet/crypto/keytools/FileKeyUnwrapper.java": [
                5,
                10
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/crypto/keytools/FileKeyWrapper.java": [
                11,
                21
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/crypto/keytools/HadoopFSKeyMaterialStore.java": [
                2,
                4
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/crypto/keytools/KeyToolkit.java": [
                3,
                29
            ]
        }
    },
    "89c5c25d44f8959d1a66493c06630ab0060cf346": {
        "datetime": "2020-11-12T17:05:33+01:00",
        "summary": "PARQUET-1915: Add nullify column (#819)",
        "message": "PARQUET-1915: Add nullify column (#819)\n\n",
        "diff": {
            "parquet-cli/src/main/java/org/apache/parquet/cli/Main.java": [
                0,
                3
            ],
            "parquet-cli/src/main/java/org/apache/parquet/cli/commands/ColumnMaskingCommand.java": [
                0,
                110
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/ColumnWriter.java": [
                0,
                1
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/impl/ColumnWriterBase.java": [
                0,
                1
            ],
            "parquet-column/src/test/java/org/apache/parquet/io/TestColumnIO.java": [
                0,
                1
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ColumnChunkPageWriteStore.java": [
                1,
                3
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ParquetFileWriter.java": [
                1,
                39
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/util/ColumnMasker.java": [
                0,
                242
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/util/CompressionConverter.java": [
                1,
                6
            ],
            "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/util/ColumnMaskerTest.java": [
                0,
                223
            ],
            "parquet-tools/src/main/java/org/apache/parquet/tools/command/ColumnMaskingCommand.java": [
                0,
                96
            ],
            "parquet-tools/src/main/java/org/apache/parquet/tools/command/PruneColumnsCommand.java": [
                1,
                1
            ],
            "parquet-tools/src/main/java/org/apache/parquet/tools/command/Registry.java": [
                0,
                1
            ]
        }
    },
    "5c6916c23cb2b9c225ea80328550ee0e11aee225": {
        "datetime": "2020-11-13T13:22:29-08:00",
        "summary": "PARQUET-1396: Example of using EncryptionPropertiesFactory and DecryptionPropertiesFactory (#808)",
        "message": "PARQUET-1396: Example of using EncryptionPropertiesFactory and DecryptionPropertiesFactory (#808)\n\n* Parquet-1396: Example of using EncryptionPropertiesFactory and DecryptionPropertiesFactory\r\n\r\n* Address feedbacks\r\n\r\n* Remove ExtType and add metadata to Type directly\r\n\r\n* Use Configuration to pass the setting\r\n\r\n* Address feedback\r\n\r\n* Replace file.toString() with file.getPath()\r\n\r\n* Address feedback\r\n\r\n* fix build error\r\n\r\n* Address more feedbacks",
        "diff": {
            "parquet-benchmarks/src/main/java/org/apache/parquet/benchmarks/NestedNullWritingBenchmarks.java": [
                0,
                5
            ],
            "parquet-common/src/main/java/org/apache/parquet/io/OutputFile.java": [
                0,
                1
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ParquetOutputFormat.java": [
                2,
                2
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ParquetWriter.java": [
                0,
                5
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/util/HadoopOutputFile.java": [
                0,
                5
            ],
            "parquet-hadoop/src/test/java/org/apache/parquet/crypto/propertiesfactory/SchemaControlEncryptionTest.java": [
                0,
                251
            ],
            "parquet-hadoop/src/test/java/org/apache/parquet/crypto/propertiesfactory/SchemaCryptoPropertiesFactory.java": [
                0,
                137
            ],
            "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/TestColumnChunkPageWriteStore.java": [
                0,
                5
            ]
        }
    },
    "bea6b669d8ff66d938efbefcd7efd5a3d0d8801c": {
        "datetime": "2020-12-07T10:47:07+01:00",
        "summary": "PARQUET-1928: Interpret Parquet INT96 type as FIXED[12] AVRO Schema (#831)",
        "message": "PARQUET-1928: Interpret Parquet INT96 type as FIXED[12] AVRO Schema (#831)\n\n* Add configuration flag to enable reading INT96 as fixed. The flag is defaulted to false to discourage use of INT96.",
        "diff": {
            "parquet-avro/src/main/java/org/apache/parquet/avro/AvroReadSupport.java": [
                0,
                4
            ],
            "parquet-avro/src/main/java/org/apache/parquet/avro/AvroSchemaConverter.java": [
                1,
                10
            ],
            "parquet-avro/src/test/java/org/apache/parquet/avro/TestAvroSchemaConverter.java": [
                0,
                26
            ]
        }
    },
    "a6fde11fd11aeb19c4e23a83ee2922b9acec3251": {
        "datetime": "2020-12-07T12:07:21+01:00",
        "summary": "PARQUET-1947: DeprecatedParquetInputFormat in CombineFileInputFormat \u2026 (#844)",
        "message": "PARQUET-1947: DeprecatedParquetInputFormat in CombineFileInputFormat \u2026 (#844)\n\n* PARQUET-1947: DeprecatedParquetInputFormat in CombineFileInputFormat would produce wrong data",
        "diff": {
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/mapred/DeprecatedParquetInputFormat.java": [
                0,
                1
            ],
            "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/DeprecatedInputFormatTest.java": [
                0,
                159
            ]
        }
    },
    "10df92187a02180bbc2f7134ba8c83a13063ee3a": {
        "datetime": "2020-12-14T11:30:30+01:00",
        "summary": "PARQUET-1801: Add parquet-tools 'prune' to parquet-cli (#846)",
        "message": "PARQUET-1801: Add parquet-tools 'prune' to parquet-cli (#846)\n\n",
        "diff": {
            "parquet-cli/src/main/java/org/apache/parquet/cli/Main.java": [
                1,
                2
            ],
            "parquet-cli/src/main/java/org/apache/parquet/cli/commands/PruneColumnsCommand.java": [
                0,
                81
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/util/ColumnPruner.java": [
                0,
                126
            ],
            "parquet-tools/src/main/java/org/apache/parquet/tools/command/PruneColumnsCommand.java": [
                98,
                3
            ],
            "parquet-tools/src/test/java/org/apache/parquet/tools/command/TestPruneColumnsCommand.java": [
                25,
                16
            ]
        }
    },
    "f01a1e5dc327ab5f2cffe0528aa67883c88f938c": {
        "datetime": "2020-12-14T15:35:53+01:00",
        "summary": "PARQUET-1952: Upgrade Avro to 1.10.1 (#848)",
        "message": "PARQUET-1952: Upgrade Avro to 1.10.1 (#848)\n\n",
        "diff": {
            "pom.xml": null
        }
    },
    "74af3a8a5404e3a56d3d8d6bf3ebc8c09ff5fa1d": {
        "datetime": "2021-01-05T11:50:16+01:00",
        "summary": "PARQUET-1954: TCP connection leak in parquet dump (#849)",
        "message": "PARQUET-1954: TCP connection leak in parquet dump (#849)\n\n",
        "diff": {
            "parquet-tools/src/main/java/org/apache/parquet/tools/command/DumpCommand.java": [
                51,
                42
            ]
        }
    },
    "02170613d12b5122b07149136382a71505fa39d8": {
        "datetime": "2021-01-07T10:44:38+01:00",
        "summary": "PARQUET-1951: Allow merge strategies to combine key values (#847)",
        "message": "PARQUET-1951: Allow merge strategies to combine key values (#847)\n\n",
        "diff": {
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ParquetFileWriter.java": [
                2,
                37
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/metadata/ConcatenatingKeyValueMetadataMergeStrategy.java": [
                0,
                61
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/metadata/GlobalMetaData.java": [
                12,
                16
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/metadata/KeyValueMetadataMergeStrategy.java": [
                0,
                42
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/metadata/StrictKeyValueMetadataMergeStrategy.java": [
                0,
                42
            ],
            "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/TestParquetFileWriter.java": [
                0,
                57
            ],
            "parquet-tools/src/main/java/org/apache/parquet/tools/command/MergeCommand.java": [
                5,
                74
            ]
        }
    },
    "2d0742ea586db444b30dd3a682e1dee9351954b0": {
        "datetime": "2021-01-10T19:43:32-08:00",
        "summary": "PARQUET-1949: Mark Parquet-1872 with note support bloom filter yet (#845)",
        "message": "PARQUET-1949: Mark Parquet-1872 with note support bloom filter yet (#845)\n\n",
        "diff": {
            "parquet-cli/src/main/java/org/apache/parquet/cli/commands/TransCompressionCommand.java": [
                1,
                1
            ],
            "parquet-tools/src/main/java/org/apache/parquet/tools/command/TransCompressionCommand.java": [
                1,
                1
            ]
        }
    },
    "7f5ff1b13b37ccb0528598a7a58420173f4949f7": {
        "datetime": "2021-01-12T11:37:35+01:00",
        "summary": "PARQUET-1666: Remove/deprecate unused modules (#851)",
        "message": "PARQUET-1666: Remove/deprecate unused modules (#851)\n\n",
        "diff": {
            "parquet-cascading-common23/src/main/java/org/apache/parquet/cascading/SchemaIntersection.java": [
                0,
                0
            ],
            "parquet-cascading-common23/src/main/java/org/apache/parquet/cascading/TupleReadSupport.java": [
                0,
                0
            ],
            "parquet-cascading-common23/src/main/java/org/apache/parquet/cascading/TupleWriteSupport.java": [
                0,
                0
            ],
            "parquet-cascading-common23/src/main/java/org/apache/parquet/cascading/convert/TupleConverter.java": [
                0,
                0
            ],
            "parquet-cascading-common23/src/main/java/org/apache/parquet/cascading/convert/TupleRecordMaterializer.java": [
                0,
                0
            ],
            "parquet-cascading-common23/src/test/java/org/apache/parquet/cascading/TestParquetTupleScheme.java": [
                0,
                0
            ],
            "parquet-cascading-common23/src/test/resources/names.txt": null,
            "parquet-cascading-common23/src/test/thrift/test.thrift": null,
            "parquet-cascading/.cache": null,
            "parquet-cascading/REVIEWERS.md": null,
            "parquet-cascading/pom.xml": null,
            "parquet-cascading/src/main/java/org/apache/parquet/cascading/ParquetTBaseScheme.java": [
                0,
                0
            ],
            "parquet-cascading/src/main/java/org/apache/parquet/cascading/ParquetTupleScheme.java": [
                0,
                0
            ],
            "parquet-cascading/src/main/java/org/apache/parquet/cascading/ParquetValueScheme.java": [
                0,
                0
            ],
            "parquet-cascading/src/test/java/org/apache/parquet/cascading/TestParquetTBaseScheme.java": [
                0,
                0
            ],
            "parquet-cascading3/REVIEWERS.md": null,
            "parquet-cascading3/pom.xml": null,
            "parquet-cascading3/src/main/java/org/apache/parquet/cascading/ParquetTBaseScheme.java": [
                0,
                0
            ],
            "parquet-cascading3/src/main/java/org/apache/parquet/cascading/ParquetTupleScheme.java": [
                0,
                0
            ],
            "parquet-cascading3/src/main/java/org/apache/parquet/cascading/ParquetValueScheme.java": [
                0,
                0
            ],
            "parquet-cascading3/src/test/java/org/apache/parquet/cascading/TestParquetTBaseScheme.java": [
                0,
                0
            ],
            "parquet-hive-bundle/pom.xml": null,
            "parquet-hive-bundle/src/main/resources/META-INF/LICENSE": null,
            "parquet-hive-bundle/src/main/resources/org/apache/parquet/bundle": null,
            "parquet-hive/REVIEWERS.md": null,
            "parquet-hive/parquet-hive-binding/parquet-hive-0.10-binding/pom.xml": null,
            "parquet-hive/parquet-hive-binding/parquet-hive-0.10-binding/src/main/java/org/apache/parquet/hive/internal/Hive010Binding.java": [
                167,
                0
            ],
            "parquet-hive/parquet-hive-binding/parquet-hive-0.12-binding/pom.xml": null,
            "parquet-hive/parquet-hive-binding/parquet-hive-0.12-binding/src/main/java/org/apache/parquet/hive/internal/Hive012Binding.java": [
                168,
                0
            ],
            "parquet-hive/parquet-hive-binding/parquet-hive-binding-bundle/pom.xml": null,
            "parquet-hive/parquet-hive-binding/parquet-hive-binding-bundle/src/assemble/uberjar.xml": null,
            "parquet-hive/parquet-hive-binding/parquet-hive-binding-bundle/src/main/resources/org/apache/parquet/bundle": null,
            "parquet-hive/parquet-hive-binding/parquet-hive-binding-factory/pom.xml": null,
            "parquet-hive/parquet-hive-binding/parquet-hive-binding-factory/src/main/java/org/apache/parquet/hive/HiveBindingFactory.java": [
                158,
                0
            ],
            "parquet-hive/parquet-hive-binding/parquet-hive-binding-factory/src/test/java/org/apache/parquet/hive/TestHiveBindingFactory.java": [
                139,
                0
            ],
            "parquet-hive/parquet-hive-binding/parquet-hive-binding-interface/pom.xml": null,
            "parquet-hive/parquet-hive-binding/parquet-hive-binding-interface/src/main/java/org/apache/parquet/hive/HiveBinding.java": [
                57,
                0
            ],
            "parquet-hive/parquet-hive-binding/parquet-hive-binding-interface/src/main/java/org/apache/parquet/hive/internal/AbstractHiveBinding.java": [
                54,
                0
            ],
            "parquet-hive/parquet-hive-binding/pom.xml": null,
            "parquet-hive/parquet-hive-storage-handler/pom.xml": null,
            "parquet-hive/parquet-hive-storage-handler/src/main/java/org/apache/hadoop/hive/ql/io/IOConstants.java": [
                29,
                0
            ],
            "parquet-hive/parquet-hive-storage-handler/src/main/java/org/apache/hadoop/hive/ql/io/parquet/MapredParquetInputFormat.java": [
                61,
                0
            ],
            "parquet-hive/parquet-hive-storage-handler/src/main/java/org/apache/hadoop/hive/ql/io/parquet/MapredParquetOutputFormat.java": [
                130,
                0
            ],
            "parquet-hive/parquet-hive-storage-handler/src/main/java/org/apache/hadoop/hive/ql/io/parquet/convert/ArrayWritableGroupConverter.java": [
                90,
                0
            ],
            "parquet-hive/parquet-hive-storage-handler/src/main/java/org/apache/hadoop/hive/ql/io/parquet/convert/DataWritableGroupConverter.java": [
                145,
                0
            ],
            "parquet-hive/parquet-hive-storage-handler/src/main/java/org/apache/hadoop/hive/ql/io/parquet/convert/DataWritableRecordConverter.java": [
                49,
                0
            ],
            "parquet-hive/parquet-hive-storage-handler/src/main/java/org/apache/hadoop/hive/ql/io/parquet/convert/ETypeConverter.java": [
                165,
                0
            ],
            "parquet-hive/parquet-hive-storage-handler/src/main/java/org/apache/hadoop/hive/ql/io/parquet/convert/HiveGroupConverter.java": [
                51,
                0
            ],
            "parquet-hive/parquet-hive-storage-handler/src/main/java/org/apache/hadoop/hive/ql/io/parquet/convert/HiveSchemaConverter.java": [
                137,
                0
            ],
            "parquet-hive/parquet-hive-storage-handler/src/main/java/org/apache/hadoop/hive/ql/io/parquet/read/DataWritableReadSupport.java": [
                156,
                0
            ],
            "parquet-hive/parquet-hive-storage-handler/src/main/java/org/apache/hadoop/hive/ql/io/parquet/read/ParquetRecordReaderWrapper.java": [
                228,
                0
            ],
            "parquet-hive/parquet-hive-storage-handler/src/main/java/org/apache/hadoop/hive/ql/io/parquet/serde/AbstractParquetMapInspector.java": [
                180,
                0
            ],
            "parquet-hive/parquet-hive-storage-handler/src/main/java/org/apache/hadoop/hive/ql/io/parquet/serde/ArrayWritableObjectInspector.java": [
                233,
                0
            ],
            "parquet-hive/parquet-hive-storage-handler/src/main/java/org/apache/hadoop/hive/ql/io/parquet/serde/DeepParquetHiveMapInspector.java": [
                88,
                0
            ],
            "parquet-hive/parquet-hive-storage-handler/src/main/java/org/apache/hadoop/hive/ql/io/parquet/serde/ParquetHiveArrayInspector.java": [
                190,
                0
            ],
            "parquet-hive/parquet-hive-storage-handler/src/main/java/org/apache/hadoop/hive/ql/io/parquet/serde/ParquetHiveSerDe.java": [
                279,
                0
            ],
            "parquet-hive/parquet-hive-storage-handler/src/main/java/org/apache/hadoop/hive/ql/io/parquet/serde/StandardParquetHiveMapInspector.java": [
                65,
                0
            ],
            "parquet-hive/parquet-hive-storage-handler/src/main/java/org/apache/hadoop/hive/ql/io/parquet/serde/primitive/ParquetByteInspector.java": [
                61,
                0
            ],
            "parquet-hive/parquet-hive-storage-handler/src/main/java/org/apache/hadoop/hive/ql/io/parquet/serde/primitive/ParquetPrimitiveInspectorFactory.java": [
                35,
                0
            ],
            "parquet-hive/parquet-hive-storage-handler/src/main/java/org/apache/hadoop/hive/ql/io/parquet/serde/primitive/ParquetShortInspector.java": [
                61,
                0
            ],
            "parquet-hive/parquet-hive-storage-handler/src/main/java/org/apache/hadoop/hive/ql/io/parquet/writable/BigDecimalWritable.java": [
                148,
                0
            ],
            "parquet-hive/parquet-hive-storage-handler/src/main/java/org/apache/hadoop/hive/ql/io/parquet/writable/BinaryWritable.java": [
                98,
                0
            ],
            "parquet-hive/parquet-hive-storage-handler/src/main/java/org/apache/hadoop/hive/ql/io/parquet/write/DataWritableWriteSupport.java": [
                66,
                0
            ],
            "parquet-hive/parquet-hive-storage-handler/src/main/java/org/apache/hadoop/hive/ql/io/parquet/write/DataWritableWriter.java": [
                159,
                0
            ],
            "parquet-hive/parquet-hive-storage-handler/src/main/java/org/apache/hadoop/hive/ql/io/parquet/write/ParquetRecordWriterWrapper.java": [
                98,
                0
            ],
            "parquet-hive/parquet-hive-storage-handler/src/main/java/org/apache/hadoop/hive/serde2/objectinspector/primitive/ParquetStringInspector.java": [
                101,
                0
            ],
            "parquet-hive/parquet-hive-storage-handler/src/main/java/org/apache/parquet/hive/DeprecatedParquetInputFormat.java": [
                42,
                0
            ],
            "parquet-hive/parquet-hive-storage-handler/src/main/java/org/apache/parquet/hive/DeprecatedParquetOutputFormat.java": [
                41,
                0
            ],
            "parquet-hive/parquet-hive-storage-handler/src/main/java/org/apache/parquet/hive/MapredParquetInputFormat.java": [
                41,
                0
            ],
            "parquet-hive/parquet-hive-storage-handler/src/main/java/org/apache/parquet/hive/MapredParquetOutputFormat.java": [
                40,
                0
            ],
            "parquet-hive/parquet-hive-storage-handler/src/main/java/org/apache/parquet/hive/serde/ParquetHiveSerDe.java": [
                30,
                0
            ],
            "parquet-hive/parquet-hive-storage-handler/src/test/java/org/apache/hadoop/hive/ql/io/parquet/TestHiveSchemaConverter.java": [
                143,
                0
            ],
            "parquet-hive/parquet-hive-storage-handler/src/test/java/org/apache/hadoop/hive/ql/io/parquet/TestMapredParquetInputFormat.java": [
                42,
                0
            ],
            "parquet-hive/parquet-hive-storage-handler/src/test/java/org/apache/hadoop/hive/ql/io/parquet/TestMapredParquetOutputFormat.java": [
                95,
                0
            ],
            "parquet-hive/parquet-hive-storage-handler/src/test/java/org/apache/hadoop/hive/ql/io/parquet/TestParquetSerDe.java": [
                145,
                0
            ],
            "parquet-hive/parquet-hive-storage-handler/src/test/java/org/apache/hadoop/hive/ql/io/parquet/serde/TestAbstractParquetMapInspector.java": [
                103,
                0
            ],
            "parquet-hive/parquet-hive-storage-handler/src/test/java/org/apache/hadoop/hive/ql/io/parquet/serde/TestDeepParquetHiveMapInspector.java": [
                95,
                0
            ],
            "parquet-hive/parquet-hive-storage-handler/src/test/java/org/apache/hadoop/hive/ql/io/parquet/serde/TestParquetHiveArrayInspector.java": [
                85,
                0
            ],
            "parquet-hive/parquet-hive-storage-handler/src/test/java/org/apache/hadoop/hive/ql/io/parquet/serde/TestStandardParquetHiveMapInspector.java": [
                93,
                0
            ],
            "parquet-hive/pom.xml": null,
            "parquet-scrooge/REVIEWERS.md": null,
            "parquet-scrooge/pom.xml": null,
            "parquet-scrooge/src/main/java/org/apache/parquet/scrooge/ParquetScroogeInputFormat.java": [
                0,
                0
            ],
            "parquet-scrooge/src/main/java/org/apache/parquet/scrooge/ParquetScroogeOutputFormat.java": [
                0,
                0
            ],
            "parquet-scrooge/src/main/java/org/apache/parquet/scrooge/ParquetScroogeScheme.java": [
                0,
                0
            ],
            "parquet-scrooge/src/main/java/org/apache/parquet/scrooge/ScroogeReadSupport.java": [
                0,
                0
            ],
            "parquet-scrooge/src/main/java/org/apache/parquet/scrooge/ScroogeRecordConverter.java": [
                0,
                0
            ],
            "parquet-scrooge/src/main/java/org/apache/parquet/scrooge/ScroogeSchemaConversionException.java": [
                0,
                0
            ],
            "parquet-scrooge/src/main/java/org/apache/parquet/scrooge/ScroogeStructConverter.java": [
                0,
                0
            ],
            "parquet-scrooge/src/main/java/org/apache/parquet/scrooge/ScroogeWriteSupport.java": [
                0,
                0
            ],
            "parquet-scrooge/src/test/java/org/apache/parquet/scrooge/ParquetScroogeSchemeTest.java": [
                0,
                0
            ],
            "parquet-scrooge/src/test/java/org/apache/parquet/scrooge/ScroogeBinaryTest.java": [
                0,
                0
            ],
            "parquet-scrooge/src/test/java/org/apache/parquet/scrooge/ScroogeStructConverterTest.java": [
                0,
                0
            ],
            "parquet-scrooge/src/test/java/org/apache/parquet/scrooge/TestCorruptScroogeRecords.java": [
                0,
                0
            ],
            "parquet-scrooge/src/test/resources/names.txt": null,
            "parquet-scrooge/src/test/thrift/test.thrift": null,
            "parquet-tools/README.md": null,
            "parquet-tools/REVIEWERS.md": null,
            "parquet-tools/pom.xml": null,
            "parquet-tools/src/main/assembly/assembly.xml": null,
            "parquet-tools/src/main/java/org/apache/parquet/tools/Main.java": [
                0,
                0
            ],
            "parquet-tools/src/main/java/org/apache/parquet/tools/command/ArgsOnlyCommand.java": [
                0,
                0
            ],
            "parquet-tools/src/main/java/org/apache/parquet/tools/command/CatCommand.java": [
                0,
                0
            ],
            "parquet-tools/src/main/java/org/apache/parquet/tools/command/ColumnIndexCommand.java": [
                0,
                0
            ],
            "parquet-tools/src/main/java/org/apache/parquet/tools/command/ColumnMaskingCommand.java": [
                0,
                0
            ],
            "parquet-tools/src/main/java/org/apache/parquet/tools/command/ColumnSizeCommand.java": [
                0,
                0
            ],
            "parquet-tools/src/main/java/org/apache/parquet/tools/command/Command.java": [
                0,
                0
            ],
            "parquet-tools/src/main/java/org/apache/parquet/tools/command/DumpCommand.java": [
                0,
                0
            ],
            "parquet-tools/src/main/java/org/apache/parquet/tools/command/HeadCommand.java": [
                0,
                0
            ],
            "parquet-tools/src/main/java/org/apache/parquet/tools/command/MergeCommand.java": [
                0,
                0
            ],
            "parquet-tools/src/main/java/org/apache/parquet/tools/command/MetadataUtils.java": [
                0,
                0
            ],
            "parquet-tools/src/main/java/org/apache/parquet/tools/command/PruneColumnsCommand.java": [
                0,
                0
            ],
            "parquet-tools/src/main/java/org/apache/parquet/tools/command/Registry.java": [
                0,
                0
            ],
            "parquet-tools/src/main/java/org/apache/parquet/tools/command/RowCountCommand.java": [
                0,
                0
            ],
            "parquet-tools/src/main/java/org/apache/parquet/tools/command/ShowMetaCommand.java": [
                0,
                0
            ],
            "parquet-tools/src/main/java/org/apache/parquet/tools/command/ShowSchemaCommand.java": [
                0,
                0
            ],
            "parquet-tools/src/main/java/org/apache/parquet/tools/command/SizeCommand.java": [
                0,
                0
            ],
            "parquet-tools/src/main/java/org/apache/parquet/tools/command/TransCompressionCommand.java": [
                0,
                0
            ],
            "parquet-tools/src/main/java/org/apache/parquet/tools/json/JsonRecordFormatter.java": [
                0,
                0
            ],
            "parquet-tools/src/main/java/org/apache/parquet/tools/read/SimpleListRecord.java": [
                0,
                0
            ],
            "parquet-tools/src/main/java/org/apache/parquet/tools/read/SimpleListRecordConverter.java": [
                0,
                0
            ],
            "parquet-tools/src/main/java/org/apache/parquet/tools/read/SimpleMapRecord.java": [
                0,
                0
            ],
            "parquet-tools/src/main/java/org/apache/parquet/tools/read/SimpleMapRecordConverter.java": [
                0,
                0
            ],
            "parquet-tools/src/main/java/org/apache/parquet/tools/read/SimpleReadSupport.java": [
                0,
                0
            ],
            "parquet-tools/src/main/java/org/apache/parquet/tools/read/SimpleRecord.java": [
                0,
                0
            ],
            "parquet-tools/src/main/java/org/apache/parquet/tools/read/SimpleRecordConverter.java": [
                0,
                0
            ],
            "parquet-tools/src/main/java/org/apache/parquet/tools/read/SimpleRecordMaterializer.java": [
                0,
                0
            ],
            "parquet-tools/src/main/java/org/apache/parquet/tools/util/MetadataUtils.java": [
                0,
                0
            ],
            "parquet-tools/src/main/java/org/apache/parquet/tools/util/PrettyPrintWriter.java": [
                0,
                0
            ],
            "parquet-tools/src/main/resources/META-INF/LICENSE": null,
            "parquet-tools/src/main/resources/META-INF/NOTICE": null,
            "parquet-tools/src/main/scripts/parquet-cat": null,
            "parquet-tools/src/main/scripts/parquet-dump": null,
            "parquet-tools/src/main/scripts/parquet-head": null,
            "parquet-tools/src/main/scripts/parquet-merge": null,
            "parquet-tools/src/main/scripts/parquet-meta": null,
            "parquet-tools/src/main/scripts/parquet-rowcount": null,
            "parquet-tools/src/main/scripts/parquet-schema": null,
            "parquet-tools/src/main/scripts/parquet-size": null,
            "parquet-tools/src/main/scripts/parquet-tools": null,
            "parquet-tools/src/test/java/org/apache/parquet/tools/command/TestColumnSizeCommand.java": [
                0,
                0
            ],
            "parquet-tools/src/test/java/org/apache/parquet/tools/read/TestJsonRecordFormatter.java": [
                0,
                0
            ],
            "parquet-tools/src/test/java/org/apache/parquet/tools/read/TestSimpleMapRecord.java": [
                0,
                0
            ],
            "parquet-tools/src/test/java/org/apache/parquet/tools/read/TestSimplePrimitiveRecord.java": [
                0,
                0
            ],
            "parquet-tools/src/test/java/org/apache/parquet/tools/read/TestSimpleRecordConverter.java": [
                0,
                0
            ],
            "pom.xml": null
        }
    },
    "e465c73d87f0b6ad190d494eea48394950fae759": {
        "datetime": "2021-01-13T13:00:50+01:00",
        "summary": "PARQUET-1851: fix parquet metadata converter NPE (#852)",
        "message": "PARQUET-1851: fix parquet metadata converter NPE (#852)\n\n",
        "diff": {
            "parquet-hadoop/src/main/java/org/apache/parquet/format/converter/ParquetMetadataConverter.java": [
                36,
                36
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ParquetFileWriter.java": [
                27,
                31
            ],
            "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/TestParquetFileWriter.java": [
                0,
                21
            ]
        }
    },
    "fdde49a847e0fa465a2988b13979391ee84524b8": {
        "datetime": "2021-01-13T13:50:08+01:00",
        "summary": "PARQUET-1961: Bump Jackson to 2.11.4 (#853)",
        "message": "PARQUET-1961: Bump Jackson to 2.11.4 (#853)\n\nTo consolidate the versions",
        "diff": {
            "pom.xml": null
        }
    },
    "358a60d17ffd49b718633d505fdb6b77ce64f7a0": {
        "datetime": "2021-01-20T17:02:15+01:00",
        "summary": "PARQUET-1963: DeprecatedParquetInputFormat in CombineFileInputFormat throw NPE when the first sub-split is empty (#854)",
        "message": "PARQUET-1963: DeprecatedParquetInputFormat in CombineFileInputFormat throw NPE when the first sub-split is empty (#854)\n\n",
        "diff": {
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/mapred/DeprecatedParquetInputFormat.java": [
                1,
                1
            ],
            "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/DeprecatedInputFormatTest.java": [
                3,
                7
            ]
        }
    },
    "ee30b13bb5c3f6848c76641d3b93c9858e6746cb": {
        "datetime": "2021-01-21T09:46:20+01:00",
        "summary": "PARQUET-1964: Properly handle missing/null filter (#856)",
        "message": "PARQUET-1964: Properly handle missing/null filter (#856)\n\n",
        "diff": {
            "parquet-column/src/main/java/org/apache/parquet/filter2/compat/FilterCompat.java": [
                0,
                11
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/InternalParquetRecordReader.java": [
                1,
                1
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ParquetFileReader.java": [
                18,
                20
            ],
            "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/TestColumnIndexFiltering.java": [
                0,
                4
            ]
        }
    },
    "217561a99f2b4b4382f1f2c69fbcd03fd9bbc3ff": {
        "datetime": "2021-01-27T09:57:35+01:00",
        "summary": "PARQUET-1926: Add LogicalType support to ThriftType (#832)",
        "message": "PARQUET-1926: Add LogicalType support to ThriftType (#832)\n\n",
        "diff": {
            "parquet-thrift/src/main/java/org/apache/parquet/thrift/ThriftSchemaConvertVisitor.java": [
                6,
                8
            ],
            "parquet-thrift/src/main/java/org/apache/parquet/thrift/struct/ThriftType.java": [
                0,
                16
            ],
            "parquet-thrift/src/test/java/org/apache/parquet/thrift/TestThriftMetaData.java": [
                1,
                2
            ],
            "parquet-thrift/src/test/java/org/apache/parquet/thrift/TestThriftRecordConverter.java": [
                1,
                2
            ],
            "parquet-thrift/src/test/java/org/apache/parquet/thrift/TestThriftSchemaConvertVisitor.java": [
                0,
                178
            ],
            "parquet-thrift/src/test/java/org/apache/parquet/thrift/struct/TestThriftType.java": [
                3,
                6
            ]
        }
    },
    "6262dec970c64f2b6d72f4839cca46d12b16d043": {
        "datetime": "2021-01-27T10:37:15+01:00",
        "summary": "[maven-release-plugin] prepare release apache-parquet-1.12.0-rc0",
        "message": "[maven-release-plugin] prepare release apache-parquet-1.12.0-rc0\n",
        "diff": {
            "parquet-arrow/pom.xml": null,
            "parquet-avro/pom.xml": null,
            "parquet-benchmarks/pom.xml": null,
            "parquet-cascading-deprecated/pom.xml": null,
            "parquet-cascading3-deprecated/pom.xml": null,
            "parquet-cli/pom.xml": null,
            "parquet-column/pom.xml": null,
            "parquet-common/pom.xml": null,
            "parquet-encoding/pom.xml": null,
            "parquet-format-structures/pom.xml": null,
            "parquet-generator/pom.xml": null,
            "parquet-hadoop-bundle/pom.xml": null,
            "parquet-hadoop/pom.xml": null,
            "parquet-jackson/pom.xml": null,
            "parquet-pig-bundle/pom.xml": null,
            "parquet-pig/pom.xml": null,
            "parquet-protobuf/pom.xml": null,
            "parquet-scala/pom.xml": null,
            "parquet-scrooge-deprecated/pom.xml": null,
            "parquet-thrift/pom.xml": null,
            "parquet-tools-deprecated/pom.xml": null,
            "pom.xml": null
        }
    },
    "c71717758cb77b4ba10aa50a2995ffc9d5a1f813": {
        "datetime": "2021-01-27T10:37:35+01:00",
        "summary": "[maven-release-plugin] prepare for next development iteration",
        "message": "[maven-release-plugin] prepare for next development iteration\n",
        "diff": {
            "parquet-arrow/pom.xml": null,
            "parquet-avro/pom.xml": null,
            "parquet-benchmarks/pom.xml": null,
            "parquet-cascading-deprecated/pom.xml": null,
            "parquet-cascading3-deprecated/pom.xml": null,
            "parquet-cli/pom.xml": null,
            "parquet-column/pom.xml": null,
            "parquet-common/pom.xml": null,
            "parquet-encoding/pom.xml": null,
            "parquet-format-structures/pom.xml": null,
            "parquet-generator/pom.xml": null,
            "parquet-hadoop-bundle/pom.xml": null,
            "parquet-hadoop/pom.xml": null,
            "parquet-jackson/pom.xml": null,
            "parquet-pig-bundle/pom.xml": null,
            "parquet-pig/pom.xml": null,
            "parquet-protobuf/pom.xml": null,
            "parquet-scala/pom.xml": null,
            "parquet-scrooge-deprecated/pom.xml": null,
            "parquet-thrift/pom.xml": null,
            "parquet-tools-deprecated/pom.xml": null,
            "pom.xml": null
        }
    },
    "64169af637813e9795c7d8971ead1f0f7373e4f6": {
        "datetime": "2021-01-27T15:42:13+01:00",
        "summary": "Update CHANGES.md for 1.12.0rc1",
        "message": "Update CHANGES.md for 1.12.0rc1\n\nMissed to update CHANGES.md for rc0 so we create rc1 with the updates\n",
        "diff": {
            "CHANGES.md": null
        }
    },
    "ad59c33e53276572c105b4ccac71293e988adc30": {
        "datetime": "2021-01-27T15:54:31+01:00",
        "summary": "[maven-release-plugin] prepare release apache-parquet-1.12.0-rc1",
        "message": "[maven-release-plugin] prepare release apache-parquet-1.12.0-rc1\n",
        "diff": {
            "parquet-arrow/pom.xml": null,
            "parquet-avro/pom.xml": null,
            "parquet-benchmarks/pom.xml": null,
            "parquet-cascading-deprecated/pom.xml": null,
            "parquet-cascading3-deprecated/pom.xml": null,
            "parquet-cli/pom.xml": null,
            "parquet-column/pom.xml": null,
            "parquet-common/pom.xml": null,
            "parquet-encoding/pom.xml": null,
            "parquet-format-structures/pom.xml": null,
            "parquet-generator/pom.xml": null,
            "parquet-hadoop-bundle/pom.xml": null,
            "parquet-hadoop/pom.xml": null,
            "parquet-jackson/pom.xml": null,
            "parquet-pig-bundle/pom.xml": null,
            "parquet-pig/pom.xml": null,
            "parquet-protobuf/pom.xml": null,
            "parquet-scala/pom.xml": null,
            "parquet-scrooge-deprecated/pom.xml": null,
            "parquet-thrift/pom.xml": null,
            "parquet-tools-deprecated/pom.xml": null,
            "pom.xml": null
        }
    },
    "5ee1e3b3bb596b666ec9da7acd09aa2c25d0e353": {
        "datetime": "2021-01-27T15:54:51+01:00",
        "summary": "[maven-release-plugin] prepare for next development iteration",
        "message": "[maven-release-plugin] prepare for next development iteration\n",
        "diff": {
            "parquet-arrow/pom.xml": null,
            "parquet-avro/pom.xml": null,
            "parquet-benchmarks/pom.xml": null,
            "parquet-cascading-deprecated/pom.xml": null,
            "parquet-cascading3-deprecated/pom.xml": null,
            "parquet-cli/pom.xml": null,
            "parquet-column/pom.xml": null,
            "parquet-common/pom.xml": null,
            "parquet-encoding/pom.xml": null,
            "parquet-format-structures/pom.xml": null,
            "parquet-generator/pom.xml": null,
            "parquet-hadoop-bundle/pom.xml": null,
            "parquet-hadoop/pom.xml": null,
            "parquet-jackson/pom.xml": null,
            "parquet-pig-bundle/pom.xml": null,
            "parquet-pig/pom.xml": null,
            "parquet-protobuf/pom.xml": null,
            "parquet-scala/pom.xml": null,
            "parquet-scrooge-deprecated/pom.xml": null,
            "parquet-thrift/pom.xml": null,
            "parquet-tools-deprecated/pom.xml": null,
            "pom.xml": null
        }
    },
    "a187fc757b7dc885423407e527f50cc4ffc4c542": {
        "datetime": "2021-01-27T21:53:20+01:00",
        "summary": "PARQUET-1736: Use StringBuilder instead of StringBuffer (#724)",
        "message": "PARQUET-1736: Use StringBuilder instead of StringBuffer (#724)\n\n",
        "diff": {
            "parquet-column/src/main/java/org/apache/parquet/schema/MessageTypeParser.java": [
                1,
                1
            ]
        }
    },
    "27448d822e294cdd274d2289ed737f2b9178f011": {
        "datetime": "2021-02-02T16:56:02+01:00",
        "summary": "PARQUET-1969: Test by GithubAction (#860)",
        "message": "PARQUET-1969: Test by GithubAction (#860)\n\n",
        "diff": {
            ".github/workflows/test.yml": null,
            "pom.xml": null
        }
    },
    "e6bca6f72db5b450c074676ac20dae9e33e93695": {
        "datetime": "2021-02-03T09:31:45+01:00",
        "summary": "PARQUET-1964: FOLLOWUP: Avoid constructing useless ArrayList (#855)",
        "message": "PARQUET-1964: FOLLOWUP: Avoid constructing useless ArrayList (#855)\n\n",
        "diff": {
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ParquetFileReader.java": [
                15,
                14
            ]
        }
    },
    "e7f9a666f1c55bd4084d49f027eecb745f8fe5ff": {
        "datetime": "2021-02-04T13:10:02+01:00",
        "summary": "PARQUET-1971: Further increase max difference of testMemoryManagerUpperLimit to 15% (#863)",
        "message": "PARQUET-1971: Further increase max difference of testMemoryManagerUpperLimit to 15% (#863)\n\n",
        "diff": {
            "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/TestMemoryManager.java": [
                6,
                6
            ]
        }
    },
    "2b73ce3790bcbbc2126751c1e25c839838fd2534": {
        "datetime": "2021-02-04T18:54:32+01:00",
        "summary": "PARQUET-1967: Upgrade Zstd-jni to 1.4.8-3 (#859)",
        "message": "PARQUET-1967: Upgrade Zstd-jni to 1.4.8-3 (#859)\n\n",
        "diff": {
            "pom.xml": null
        }
    },
    "279255df0c050aa95b5f5eb5963cf7eae5b8d180": {
        "datetime": "2021-02-09T09:27:19+01:00",
        "summary": "PARQUET-1973: Support ZSTD JNI BufferPool (#865)",
        "message": "PARQUET-1973: Support ZSTD JNI BufferPool (#865)\n\n",
        "diff": {
            "parquet-hadoop/README.md": null,
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/codec/ZstandardCodec.java": [
                2,
                20
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/codec/ZstdCompressorStream.java": [
                0,
                8
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/codec/ZstdDecompressorStream.java": [
                0,
                6
            ],
            "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/TestZstandardCodec.java": [
                5,
                12
            ]
        }
    },
    "d9185703bfe0a1d7063f0dc338161eed82e39a5f": {
        "datetime": "2021-02-09T15:48:18+01:00",
        "summary": "PARQUET-1969: FOLLOWUP: Remove/exchange Travis related references (#862)",
        "message": "PARQUET-1969: FOLLOWUP: Remove/exchange Travis related references (#862)\n\n",
        "diff": {
            ".github/workflows/test.yml": null,
            ".travis.yml": null,
            "README.md": null,
            "dev/travis-before_install-master.sh": null,
            "dev/travis-before_install.sh": null,
            "pom.xml": null
        }
    },
    "3be6273156247a52e295e002bc38217373b68b22": {
        "datetime": "2021-02-10T10:59:53+01:00",
        "summary": "PARQUET-1970: Make minor releases source compatible (#861)",
        "message": "PARQUET-1970: Make minor releases source compatible (#861)\n\n",
        "diff": {
            "parquet-column/src/main/java/org/apache/parquet/internal/column/columnindex/OffsetIndex.java": [
                2,
                4
            ],
            "parquet-common/src/main/java/org/apache/parquet/io/OutputFile.java": [
                1,
                3
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/crypto/keytools/PropertiesDrivenCryptoFactory.java": [
                0,
                3
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ParquetWriter.java": [
                2,
                3
            ],
            "pom.xml": null
        }
    },
    "646985d5fd28102e5638267415441cf4f43b480b": {
        "datetime": "2021-02-15T10:47:23+01:00",
        "summary": "PARQUET-1966: Fix build with JDK11 for JDK8 (#858)",
        "message": "PARQUET-1966: Fix build with JDK11 for JDK8 (#858)\n\n",
        "diff": {
            "pom.xml": null
        }
    },
    "2a23dcaa27adc643a199808773a0feb580b7d8a5": {
        "datetime": "2021-02-17T10:05:36+01:00",
        "summary": "PARQUET-1979: bloom_filter_offset is filled if there are no bloom filters (#869)",
        "message": "PARQUET-1979: bloom_filter_offset is filled if there are no bloom filters (#869)\n\n",
        "diff": {
            "parquet-hadoop/src/main/java/org/apache/parquet/format/converter/ParquetMetadataConverter.java": [
                2,
                7
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ParquetFileReader.java": [
                1,
                1
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/metadata/ColumnChunkMetaData.java": [
                3,
                5
            ],
            "parquet-hadoop/src/test/java/org/apache/parquet/format/converter/TestParquetMetadataConverter.java": [
                0,
                20
            ]
        }
    },
    "ab402f84e956d17ab67b63f91d01c63a92e7ae1e": {
        "datetime": "2021-02-23T22:56:01+01:00",
        "summary": "PARQUET-XXX: Fix typo in parquet-avro/README.md (#873)",
        "message": "PARQUET-XXX: Fix typo in parquet-avro/README.md (#873)\n\n",
        "diff": {
            "parquet-avro/README.md": null
        }
    },
    "434667566e140d7ca7e30b568156c43a06cc719f": {
        "datetime": "2021-02-24T12:12:59+01:00",
        "summary": "PARQUET-1984: Allow tests to run on windows (#870)",
        "message": "PARQUET-1984: Allow tests to run on windows (#870)\n\nCheck for \\r\\n lineendings instead of \\n\r\nChange file layout (backslash and slash) to check\r\nClose files / streams before deleting file",
        "diff": {
            "parquet-hadoop/src/test/java/org/apache/parquet/format/converter/TestParquetMetadataConverter.java": [
                2,
                2
            ],
            "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/DeprecatedInputFormatTest.java": [
                12,
                14
            ],
            "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/TestInputFormat.java": [
                7,
                5
            ],
            "parquet-hadoop/src/test/java/org/apache/parquet/statistics/TestStatistics.java": [
                11,
                11
            ],
            "parquet-thrift/src/test/java/org/apache/parquet/hadoop/thrift/TestParquetToThriftReadWriteAndProjection.java": [
                9,
                9
            ],
            "parquet-thrift/src/test/java/org/apache/parquet/thrift/TestThriftMetaData.java": [
                5,
                5
            ],
            "parquet-thrift/src/test/java/org/apache/parquet/thrift/TestThriftRecordConverter.java": [
                5,
                5
            ],
            "parquet-thrift/src/test/java/org/apache/parquet/thrift/struct/TestThriftType.java": [
                6,
                6
            ]
        }
    },
    "286b078c0a205e1064e61c2efd5598795d2d8bc9": {
        "datetime": "2021-02-25T10:56:21+01:00",
        "summary": "PARQUET-1977: Invalid data_page_offset (#868)",
        "message": "PARQUET-1977: Invalid data_page_offset (#868)\n\n",
        "diff": {
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/Offsets.java": [
                0,
                92
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ParquetFileWriter.java": [
                14,
                17
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/metadata/ColumnChunkMetaData.java": [
                1,
                2
            ],
            "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/TestParquetFileWriter.java": [
                5,
                19
            ]
        }
    },
    "3c023e027d663ce8758ff13f5889c152b9908baf": {
        "datetime": "2021-02-25T11:28:38+01:00",
        "summary": "Update CHANGES.md for 1.12.0rc2",
        "message": "Update CHANGES.md for 1.12.0rc2\n",
        "diff": {
            "CHANGES.md": null
        }
    },
    "d859b4435d139f1979f46cf63d2afdf32935ad51": {
        "datetime": "2021-02-25T11:42:54+01:00",
        "summary": "[maven-release-plugin] prepare release apache-parquet-1.12.0-rc2",
        "message": "[maven-release-plugin] prepare release apache-parquet-1.12.0-rc2\n",
        "diff": {
            "parquet-arrow/pom.xml": null,
            "parquet-avro/pom.xml": null,
            "parquet-benchmarks/pom.xml": null,
            "parquet-cascading-deprecated/pom.xml": null,
            "parquet-cascading3-deprecated/pom.xml": null,
            "parquet-cli/pom.xml": null,
            "parquet-column/pom.xml": null,
            "parquet-common/pom.xml": null,
            "parquet-encoding/pom.xml": null,
            "parquet-format-structures/pom.xml": null,
            "parquet-generator/pom.xml": null,
            "parquet-hadoop-bundle/pom.xml": null,
            "parquet-hadoop/pom.xml": null,
            "parquet-jackson/pom.xml": null,
            "parquet-pig-bundle/pom.xml": null,
            "parquet-pig/pom.xml": null,
            "parquet-protobuf/pom.xml": null,
            "parquet-scala/pom.xml": null,
            "parquet-scrooge-deprecated/pom.xml": null,
            "parquet-thrift/pom.xml": null,
            "parquet-tools-deprecated/pom.xml": null,
            "pom.xml": null
        }
    },
    "df63933531bcf260084b944582cddd31844b7757": {
        "datetime": "2021-02-25T11:43:12+01:00",
        "summary": "[maven-release-plugin] prepare for next development iteration",
        "message": "[maven-release-plugin] prepare for next development iteration\n",
        "diff": {
            "parquet-arrow/pom.xml": null,
            "parquet-avro/pom.xml": null,
            "parquet-benchmarks/pom.xml": null,
            "parquet-cascading-deprecated/pom.xml": null,
            "parquet-cascading3-deprecated/pom.xml": null,
            "parquet-cli/pom.xml": null,
            "parquet-column/pom.xml": null,
            "parquet-common/pom.xml": null,
            "parquet-encoding/pom.xml": null,
            "parquet-format-structures/pom.xml": null,
            "parquet-generator/pom.xml": null,
            "parquet-hadoop-bundle/pom.xml": null,
            "parquet-hadoop/pom.xml": null,
            "parquet-jackson/pom.xml": null,
            "parquet-pig-bundle/pom.xml": null,
            "parquet-pig/pom.xml": null,
            "parquet-protobuf/pom.xml": null,
            "parquet-scala/pom.xml": null,
            "parquet-scrooge-deprecated/pom.xml": null,
            "parquet-thrift/pom.xml": null,
            "parquet-tools-deprecated/pom.xml": null,
            "pom.xml": null
        }
    },
    "ecac528dd4848c0a75d198b37f48c4a3f4c76507": {
        "datetime": "2021-02-26T12:30:57+01:00",
        "summary": "[maven-release-plugin] prepare release apache-parquet-1.12.0-rc3",
        "message": "[maven-release-plugin] prepare release apache-parquet-1.12.0-rc3\n",
        "diff": {
            "parquet-arrow/pom.xml": null,
            "parquet-avro/pom.xml": null,
            "parquet-benchmarks/pom.xml": null,
            "parquet-cascading-deprecated/pom.xml": null,
            "parquet-cascading3-deprecated/pom.xml": null,
            "parquet-cli/pom.xml": null,
            "parquet-column/pom.xml": null,
            "parquet-common/pom.xml": null,
            "parquet-encoding/pom.xml": null,
            "parquet-format-structures/pom.xml": null,
            "parquet-generator/pom.xml": null,
            "parquet-hadoop-bundle/pom.xml": null,
            "parquet-hadoop/pom.xml": null,
            "parquet-jackson/pom.xml": null,
            "parquet-pig-bundle/pom.xml": null,
            "parquet-pig/pom.xml": null,
            "parquet-protobuf/pom.xml": null,
            "parquet-scala/pom.xml": null,
            "parquet-scrooge-deprecated/pom.xml": null,
            "parquet-thrift/pom.xml": null,
            "parquet-tools-deprecated/pom.xml": null,
            "pom.xml": null
        }
    },
    "548215e0c574643faca2a945cd0328b7b527466a": {
        "datetime": "2021-02-26T12:31:15+01:00",
        "summary": "[maven-release-plugin] prepare for next development iteration",
        "message": "[maven-release-plugin] prepare for next development iteration\n",
        "diff": {
            "parquet-arrow/pom.xml": null,
            "parquet-avro/pom.xml": null,
            "parquet-benchmarks/pom.xml": null,
            "parquet-cascading-deprecated/pom.xml": null,
            "parquet-cascading3-deprecated/pom.xml": null,
            "parquet-cli/pom.xml": null,
            "parquet-column/pom.xml": null,
            "parquet-common/pom.xml": null,
            "parquet-encoding/pom.xml": null,
            "parquet-format-structures/pom.xml": null,
            "parquet-generator/pom.xml": null,
            "parquet-hadoop-bundle/pom.xml": null,
            "parquet-hadoop/pom.xml": null,
            "parquet-jackson/pom.xml": null,
            "parquet-pig-bundle/pom.xml": null,
            "parquet-pig/pom.xml": null,
            "parquet-protobuf/pom.xml": null,
            "parquet-scala/pom.xml": null,
            "parquet-scrooge-deprecated/pom.xml": null,
            "parquet-thrift/pom.xml": null,
            "parquet-tools-deprecated/pom.xml": null,
            "pom.xml": null
        }
    },
    "862bac97bf62eb68e2ab3d2911d3b5f95fb6979e": {
        "datetime": "2021-02-26T17:16:50+01:00",
        "summary": "PARQUET-1975: Do not include brotli-codec for ARM64 (#872)",
        "message": "PARQUET-1975: Do not include brotli-codec for ARM64 (#872)\n\n",
        "diff": {
            "parquet-hadoop/pom.xml": null,
            "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/TestDirectCodecFactory.java": [
                2,
                7
            ]
        }
    },
    "2c6ceb330bbfd282715730b478714b84418c0749": {
        "datetime": "2021-02-28T09:00:38+01:00",
        "summary": "PARQUET-1988: Upgrade to ZSTD 1.4.8-6 (#874)",
        "message": "PARQUET-1988: Upgrade to ZSTD 1.4.8-6 (#874)\n\n* PARQUET-1988: Upgrade to ZSTD 1.4.8-5\r\n\r\n* Use 1.4.6",
        "diff": {
            "pom.xml": null
        }
    },
    "154d8f16842727a8d888b50ea05f36686153f43b": {
        "datetime": "2021-03-01T11:08:09+01:00",
        "summary": "PARQUET-1980: Re-introduce TravisCI for testing on ARM64 (#876)",
        "message": "PARQUET-1980: Re-introduce TravisCI for testing on ARM64 (#876)\n\n",
        "diff": {
            ".travis.yml": null
        }
    },
    "342b46223a78efb8233e2419f6b360460b398021": {
        "datetime": "2021-03-08T11:49:32+01:00",
        "summary": "PARQUET-1980 Update Maven profile from 'travis' to 'ci-test' (#879)",
        "message": "PARQUET-1980 Update Maven profile from 'travis' to 'ci-test' (#879)\n\n",
        "diff": {
            ".travis.yml": null
        }
    },
    "66ac28ce232c586626f53b72110276ea45ec5fa2": {
        "datetime": "2021-03-09T09:29:11+01:00",
        "summary": "PARQUET-1994: Upgrade ZSTD JNI to 1.4.9-1 (#880)",
        "message": "PARQUET-1994: Upgrade ZSTD JNI to 1.4.9-1 (#880)\n\n",
        "diff": {
            "pom.xml": null
        }
    },
    "d81b815fadc252bddb583d400e6097e56aa6708b": {
        "datetime": "2021-03-11T16:37:45+01:00",
        "summary": "PARQUET-1992: Manually download interop files inside the test and move encryption interop test to maven integration-test phase (#878)",
        "message": "PARQUET-1992: Manually download interop files inside the test and move encryption interop test to maven integration-test phase (#878)\n\n",
        "diff": {
            ".gitmodules": null,
            "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/ITTestEncryptionOptions.java": [
                0,
                50
            ],
            "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/TestEncryptionOptions.java": [
                8,
                61
            ],
            "pom.xml": null,
            "submodules/parquet-testing": null
        }
    },
    "184dbbee8317fbc40fb733b8183820b8413fd515": {
        "datetime": "2021-03-11T17:19:50+01:00",
        "summary": "Update CHANGES.md for 1.12.0rc3",
        "message": "Update CHANGES.md for 1.12.0rc3\n",
        "diff": {
            "CHANGES.md": null
        }
    },
    "5f2055c30674df8be55eabe7a03d935af1e45e8e": {
        "datetime": "2021-03-11T17:33:23+01:00",
        "summary": "[maven-release-plugin] prepare release apache-parquet-1.12.0-rc3",
        "message": "[maven-release-plugin] prepare release apache-parquet-1.12.0-rc3\n",
        "diff": {
            "parquet-arrow/pom.xml": null,
            "parquet-avro/pom.xml": null,
            "parquet-benchmarks/pom.xml": null,
            "parquet-cascading-deprecated/pom.xml": null,
            "parquet-cascading3-deprecated/pom.xml": null,
            "parquet-cli/pom.xml": null,
            "parquet-column/pom.xml": null,
            "parquet-common/pom.xml": null,
            "parquet-encoding/pom.xml": null,
            "parquet-format-structures/pom.xml": null,
            "parquet-generator/pom.xml": null,
            "parquet-hadoop-bundle/pom.xml": null,
            "parquet-hadoop/pom.xml": null,
            "parquet-jackson/pom.xml": null,
            "parquet-pig-bundle/pom.xml": null,
            "parquet-pig/pom.xml": null,
            "parquet-protobuf/pom.xml": null,
            "parquet-scala/pom.xml": null,
            "parquet-scrooge-deprecated/pom.xml": null,
            "parquet-thrift/pom.xml": null,
            "parquet-tools-deprecated/pom.xml": null,
            "pom.xml": null
        }
    },
    "bdf935a43bd377c8052840a4328cf5b7603aa70a": {
        "datetime": "2021-03-11T17:33:40+01:00",
        "summary": "[maven-release-plugin] prepare for next development iteration",
        "message": "[maven-release-plugin] prepare for next development iteration\n",
        "diff": {
            "parquet-arrow/pom.xml": null,
            "parquet-avro/pom.xml": null,
            "parquet-benchmarks/pom.xml": null,
            "parquet-cascading-deprecated/pom.xml": null,
            "parquet-cascading3-deprecated/pom.xml": null,
            "parquet-cli/pom.xml": null,
            "parquet-column/pom.xml": null,
            "parquet-common/pom.xml": null,
            "parquet-encoding/pom.xml": null,
            "parquet-format-structures/pom.xml": null,
            "parquet-generator/pom.xml": null,
            "parquet-hadoop-bundle/pom.xml": null,
            "parquet-hadoop/pom.xml": null,
            "parquet-jackson/pom.xml": null,
            "parquet-pig-bundle/pom.xml": null,
            "parquet-pig/pom.xml": null,
            "parquet-protobuf/pom.xml": null,
            "parquet-scala/pom.xml": null,
            "parquet-scrooge-deprecated/pom.xml": null,
            "parquet-thrift/pom.xml": null,
            "parquet-tools-deprecated/pom.xml": null,
            "pom.xml": null
        }
    },
    "0efbfaa9a7b02bbd2a5912313ca77a9550da8ea1": {
        "datetime": "2021-03-16T10:26:01+01:00",
        "summary": "PARQUET-1493: Fix protobuf plugin for proxies (#875)",
        "message": "PARQUET-1493: Fix protobuf plugin for proxies (#875)\n\n",
        "diff": {
            "parquet-protobuf/pom.xml": null
        }
    },
    "616c3d681c5506ebad83a7d3724e85da2154eac9": {
        "datetime": "2021-03-16T08:34:45-07:00",
        "summary": "PARQUET-1999: NPE might occur if OutputFile is implemented by the client (#881)",
        "message": "PARQUET-1999: NPE might occur if OutputFile is implemented by the client (#881)\n\n",
        "diff": {
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ParquetWriter.java": [
                1,
                2
            ],
            "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/TestParquetWriter.java": [
                4,
                45
            ]
        }
    },
    "27053b07b91e605e48d17e539ec9dd811770e2f8": {
        "datetime": "2021-03-17T09:16:34+01:00",
        "summary": "Update CHANGES.md for 1.12.0rc4",
        "message": "Update CHANGES.md for 1.12.0rc4\n",
        "diff": {
            "CHANGES.md": null
        }
    },
    "db75a6815f2ba1d1ee89d1a90aeb296f1f3a8f20": {
        "datetime": "2021-03-17T09:38:06+01:00",
        "summary": "[maven-release-plugin] prepare release apache-parquet-1.12.0-rc4",
        "message": "[maven-release-plugin] prepare release apache-parquet-1.12.0-rc4\n",
        "diff": {
            "parquet-arrow/pom.xml": null,
            "parquet-avro/pom.xml": null,
            "parquet-benchmarks/pom.xml": null,
            "parquet-cascading-deprecated/pom.xml": null,
            "parquet-cascading3-deprecated/pom.xml": null,
            "parquet-cli/pom.xml": null,
            "parquet-column/pom.xml": null,
            "parquet-common/pom.xml": null,
            "parquet-encoding/pom.xml": null,
            "parquet-format-structures/pom.xml": null,
            "parquet-generator/pom.xml": null,
            "parquet-hadoop-bundle/pom.xml": null,
            "parquet-hadoop/pom.xml": null,
            "parquet-jackson/pom.xml": null,
            "parquet-pig-bundle/pom.xml": null,
            "parquet-pig/pom.xml": null,
            "parquet-protobuf/pom.xml": null,
            "parquet-scala/pom.xml": null,
            "parquet-scrooge-deprecated/pom.xml": null,
            "parquet-thrift/pom.xml": null,
            "parquet-tools-deprecated/pom.xml": null,
            "pom.xml": null
        }
    },
    "86dd62bd3eaeb1b23fd80c8dd6aba9b466fe35a8": {
        "datetime": "2021-03-17T09:38:22+01:00",
        "summary": "[maven-release-plugin] prepare for next development iteration",
        "message": "[maven-release-plugin] prepare for next development iteration\n",
        "diff": {
            "parquet-arrow/pom.xml": null,
            "parquet-avro/pom.xml": null,
            "parquet-benchmarks/pom.xml": null,
            "parquet-cascading-deprecated/pom.xml": null,
            "parquet-cascading3-deprecated/pom.xml": null,
            "parquet-cli/pom.xml": null,
            "parquet-column/pom.xml": null,
            "parquet-common/pom.xml": null,
            "parquet-encoding/pom.xml": null,
            "parquet-format-structures/pom.xml": null,
            "parquet-generator/pom.xml": null,
            "parquet-hadoop-bundle/pom.xml": null,
            "parquet-hadoop/pom.xml": null,
            "parquet-jackson/pom.xml": null,
            "parquet-pig-bundle/pom.xml": null,
            "parquet-pig/pom.xml": null,
            "parquet-protobuf/pom.xml": null,
            "parquet-scala/pom.xml": null,
            "parquet-scrooge-deprecated/pom.xml": null,
            "parquet-thrift/pom.xml": null,
            "parquet-tools-deprecated/pom.xml": null,
            "pom.xml": null
        }
    },
    "d96b19bb97caf6f358579c9e22626553e8dc986d": {
        "datetime": "2021-03-17T15:12:46+01:00",
        "summary": "PARQUET-2001: Bump Avro from 1.10.1 to 1.10.2 (#882)",
        "message": "PARQUET-2001: Bump Avro from 1.10.1 to 1.10.2 (#882)\n\n",
        "diff": {
            "pom.xml": null
        }
    },
    "09845051b5ed97feef8cc0cd9b6c0c07d421fa6a": {
        "datetime": "2021-03-19T10:22:29+01:00",
        "summary": "PARQUET-2004: Bump Jackson to version 2.12.2 (#883)",
        "message": "PARQUET-2004: Bump Jackson to version 2.12.2 (#883)\n\n",
        "diff": {
            "pom.xml": null
        }
    },
    "5608695f5777de1eb0899d9075ec9411cfdf31d3": {
        "datetime": "2021-03-19T11:21:36+01:00",
        "summary": "PARQUET-1978: Provide a tool to show the complete footer (#867)",
        "message": "PARQUET-1978: Provide a tool to show the complete footer (#867)\n\n",
        "diff": {
            "parquet-cli/src/main/java/org/apache/parquet/cli/Main.java": [
                0,
                2
            ],
            "parquet-cli/src/main/java/org/apache/parquet/cli/commands/ShowFooterCommand.java": [
                0,
                144
            ],
            "parquet-cli/src/test/java/org/apache/parquet/cli/commands/ShowFooterCommandTest.java": [
                0,
                43
            ],
            "parquet-format-structures/src/main/java/org/apache/parquet/format/CliUtils.java": [
                0,
                55
            ]
        }
    },
    "8464284cc4fa790fdc66a8d2721572c2ec472d6a": {
        "datetime": "2021-03-25T12:50:18+01:00",
        "summary": "Prepare for next development iteration",
        "message": "Prepare for next development iteration\n",
        "diff": {
            "README.md": null,
            "parquet-arrow/pom.xml": null,
            "parquet-avro/pom.xml": null,
            "parquet-benchmarks/pom.xml": null,
            "parquet-cascading-deprecated/pom.xml": null,
            "parquet-cascading3-deprecated/pom.xml": null,
            "parquet-cli/pom.xml": null,
            "parquet-column/pom.xml": null,
            "parquet-common/pom.xml": null,
            "parquet-encoding/pom.xml": null,
            "parquet-format-structures/pom.xml": null,
            "parquet-generator/pom.xml": null,
            "parquet-hadoop-bundle/pom.xml": null,
            "parquet-hadoop/pom.xml": null,
            "parquet-jackson/pom.xml": null,
            "parquet-pig-bundle/pom.xml": null,
            "parquet-pig/pom.xml": null,
            "parquet-protobuf/pom.xml": null,
            "parquet-scala/pom.xml": null,
            "parquet-scrooge-deprecated/pom.xml": null,
            "parquet-thrift/pom.xml": null,
            "parquet-tools-deprecated/pom.xml": null,
            "pom.xml": null
        }
    },
    "24d581038f082039249b7874825c6ed4c05a961f": {
        "datetime": "2021-03-30T08:57:08-07:00",
        "summary": "PARQUET-2010: Fix japicmp issues (#885)",
        "message": "PARQUET-2010: Fix japicmp issues (#885)\n\n",
        "diff": {
            "parquet-cascading-deprecated/pom.xml": null,
            "parquet-cascading3-deprecated/pom.xml": null,
            "parquet-scrooge-deprecated/pom.xml": null
        }
    },
    "86240813839f3e15d5c4a0ea56215c616841b6c1": {
        "datetime": "2021-04-01T16:02:43+02:00",
        "summary": "PARQUET-2012 Mark ProtoParquetWriter constructors deprecated (#886)",
        "message": "PARQUET-2012 Mark ProtoParquetWriter constructors deprecated (#886)\n\n",
        "diff": {
            "parquet-protobuf/src/main/java/org/apache/parquet/proto/ProtoParquetWriter.java": [
                7,
                11
            ],
            "parquet-protobuf/src/test/java/org/apache/parquet/proto/TestUtils.java": [
                9,
                5
            ]
        }
    },
    "d23a9a79927a03ce6b8e192436c64ad34c36d67b": {
        "datetime": "2021-04-08T22:35:49+02:00",
        "summary": "PARQUET-2005: Upgrade thrift to 0.14.1 (#884)",
        "message": "PARQUET-2005: Upgrade thrift to 0.14.1 (#884)\n\n* PARQUET-2005: Upgrade thrift to 0.14.1\r\n\r\n* PARQUET-2005: Update thrift version in CI scripts and README\r\n\r\n* Update README.md\r\n\r\nCo-authored-by: Fokko Driesprong <fokko@driesprong.frl>\r\n\r\nCo-authored-by: Fokko Driesprong <fokko@driesprong.frl>",
        "diff": {
            "README.md": null,
            "dev/ci-before_install.sh": null,
            "parquet-format-structures/src/main/java/org/apache/parquet/format/CliUtils.java": [
                1,
                1
            ],
            "parquet-format-structures/src/main/java/org/apache/parquet/format/InterningProtocol.java": [
                0,
                5
            ],
            "parquet-format-structures/src/main/java/org/apache/parquet/format/Util.java": [
                2,
                3
            ],
            "parquet-thrift/src/main/java/org/apache/parquet/hadoop/thrift/ThriftBytesWriteSupport.java": [
                1,
                2
            ],
            "parquet-thrift/src/main/java/org/apache/parquet/thrift/BufferedProtocolReadToWrite.java": [
                0,
                5
            ],
            "parquet-thrift/src/main/java/org/apache/parquet/thrift/ParquetProtocol.java": [
                0,
                5
            ],
            "parquet-thrift/src/test/java/org/apache/parquet/thrift/TestProtocolReadToWrite.java": [
                2,
                3
            ],
            "pom.xml": null
        }
    },
    "1075e22e10b4e80c7d6e34267b2d3a192755b043": {
        "datetime": "2021-04-14T11:23:49+02:00",
        "summary": "PARQUET-2024: Remove KEYS file from parquet-mr repo (#891)",
        "message": "PARQUET-2024: Remove KEYS file from parquet-mr repo (#891)\n\n",
        "diff": {
            "KEYS": null
        }
    },
    "60c09f8549952cea31af5f175885687b88449c29": {
        "datetime": "2021-04-14T11:26:03+02:00",
        "summary": "PARQUET-2023 Do not pipe the mvn output to pv (#890)",
        "message": "PARQUET-2023 Do not pipe the mvn output to pv (#890)\n\n* PARQUET-2023 Do not pipe the mvn output to pv\r\n\r\nPiping to pv looses the exit status of mvn and the builds never fail\r\nUse SLF4J Simple log file to collect all Maven logs\r\nPrint the logs in case of build failure",
        "diff": {
            ".travis.yml": null
        }
    },
    "3f54ba09c36fec835d91d0ba1abfc4fd6e7fef3f": {
        "datetime": "2021-04-19T09:53:11+02:00",
        "summary": "PARQUET-1982: Random access to row groups in ParquetFileReader (#871)",
        "message": "PARQUET-1982: Random access to row groups in ParquetFileReader (#871)\n\nAdds a method readRowGroup(BlockMetaData) to allow random access to\r\nPageReadStores via BlockMetaData, which can be obtained using the\r\ngetRowGroups() method.\r\n\r\nThis is similar to the existing method\r\ngetDictionaryReader(BlockMetaData)\r\nthat already exists.\r\n\r\nWith random access the reader can be reused if for example someone\r\nneeds to go back a row group. This would improve performance\r\nbecause we don't need to open the file again and read the metadata.\r\n\r\nAdd test for filtered random access\r\nReads all pages of a row group\r\nChecks all columns of a page",
        "diff": {
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ParquetFileReader.java": [
                39,
                124
            ],
            "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/TestParquetReaderRandomAccess.java": [
                0,
                387
            ],
            "parquet-hadoop/src/test/java/org/apache/parquet/statistics/DataGenerationContext.java": [
                0,
                85
            ],
            "parquet-hadoop/src/test/java/org/apache/parquet/statistics/RandomValues.java": [
                2,
                2
            ],
            "parquet-hadoop/src/test/java/org/apache/parquet/statistics/TestStatistics.java": [
                56,
                0
            ]
        }
    },
    "8c0840365ab76070da0efc8bfe0559bc4e525e49": {
        "datetime": "2021-04-19T10:22:39+02:00",
        "summary": "PARQUET-2022: ZstdDecompressorStream should close `zstdInputStream` (#889)",
        "message": "PARQUET-2022: ZstdDecompressorStream should close `zstdInputStream` (#889)\n\n",
        "diff": {
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/codec/ZstdDecompressorStream.java": [
                0,
                9
            ],
            "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/TestZstandardCodec.java": [
                5,
                4
            ]
        }
    },
    "095c78fec3378189296d38fede1255b0a4d05fd4": {
        "datetime": "2021-04-19T17:46:01+02:00",
        "summary": "PARQUET-2025: Update Snappy version to 1.1.8.3 (#893)",
        "message": "PARQUET-2025: Update Snappy version to 1.1.8.3 (#893)\n\n",
        "diff": {
            "parquet-hadoop/pom.xml": null
        }
    },
    "907314ce317e59e25bbf572e891f7ce2a7c70a54": {
        "datetime": "2021-04-19T17:49:00+02:00",
        "summary": "PARQUET-2020: Remove deprecated modules (#888)",
        "message": "PARQUET-2020: Remove deprecated modules (#888)\n\nRemoves:\r\n\r\n- parquet-tools-deprecated\r\n- parquet-scrooge-deprecated\r\n- parquet-cascading-common23-deprecated\r\n- parquet-cascading-deprecated\r\n- parquet-cascading3-deprecated",
        "diff": {
            "parquet-cascading-common23-deprecated/src/main/java/org/apache/parquet/cascading/SchemaIntersection.java": [
                63,
                0
            ],
            "parquet-cascading-common23-deprecated/src/main/java/org/apache/parquet/cascading/TupleReadSupport.java": [
                81,
                0
            ],
            "parquet-cascading-common23-deprecated/src/main/java/org/apache/parquet/cascading/TupleWriteSupport.java": [
                106,
                0
            ],
            "parquet-cascading-common23-deprecated/src/main/java/org/apache/parquet/cascading/convert/TupleConverter.java": [
                112,
                0
            ],
            "parquet-cascading-common23-deprecated/src/main/java/org/apache/parquet/cascading/convert/TupleRecordMaterializer.java": [
                46,
                0
            ],
            "parquet-cascading-common23-deprecated/src/test/java/org/apache/parquet/cascading/TestParquetTupleScheme.java": [
                182,
                0
            ],
            "parquet-cascading-common23-deprecated/src/test/resources/names.txt": null,
            "parquet-cascading-common23-deprecated/src/test/thrift/test.thrift": null,
            "parquet-cascading-deprecated/.cache": null,
            "parquet-cascading-deprecated/REVIEWERS.md": null,
            "parquet-cascading-deprecated/pom.xml": null,
            "parquet-cascading-deprecated/src/main/java/org/apache/parquet/cascading/ParquetTBaseScheme.java": [
                81,
                0
            ],
            "parquet-cascading-deprecated/src/main/java/org/apache/parquet/cascading/ParquetTupleScheme.java": [
                189,
                0
            ],
            "parquet-cascading-deprecated/src/main/java/org/apache/parquet/cascading/ParquetValueScheme.java": [
                185,
                0
            ],
            "parquet-cascading-deprecated/src/test/java/org/apache/parquet/cascading/TestParquetTBaseScheme.java": [
                187,
                0
            ],
            "parquet-cascading3-deprecated/REVIEWERS.md": null,
            "parquet-cascading3-deprecated/pom.xml": null,
            "parquet-cascading3-deprecated/src/main/java/org/apache/parquet/cascading/ParquetTBaseScheme.java": [
                80,
                0
            ],
            "parquet-cascading3-deprecated/src/main/java/org/apache/parquet/cascading/ParquetTupleScheme.java": [
                190,
                0
            ],
            "parquet-cascading3-deprecated/src/main/java/org/apache/parquet/cascading/ParquetValueScheme.java": [
                192,
                0
            ],
            "parquet-cascading3-deprecated/src/test/java/org/apache/parquet/cascading/TestParquetTBaseScheme.java": [
                185,
                0
            ],
            "parquet-scrooge-deprecated/REVIEWERS.md": null,
            "parquet-scrooge-deprecated/pom.xml": null,
            "parquet-scrooge-deprecated/src/main/java/org/apache/parquet/scrooge/ParquetScroogeInputFormat.java": [
                31,
                0
            ],
            "parquet-scrooge-deprecated/src/main/java/org/apache/parquet/scrooge/ParquetScroogeOutputFormat.java": [
                39,
                0
            ],
            "parquet-scrooge-deprecated/src/main/java/org/apache/parquet/scrooge/ParquetScroogeScheme.java": [
                69,
                0
            ],
            "parquet-scrooge-deprecated/src/main/java/org/apache/parquet/scrooge/ScroogeReadSupport.java": [
                50,
                0
            ],
            "parquet-scrooge-deprecated/src/main/java/org/apache/parquet/scrooge/ScroogeRecordConverter.java": [
                69,
                0
            ],
            "parquet-scrooge-deprecated/src/main/java/org/apache/parquet/scrooge/ScroogeSchemaConversionException.java": [
                36,
                0
            ],
            "parquet-scrooge-deprecated/src/main/java/org/apache/parquet/scrooge/ScroogeStructConverter.java": [
                401,
                0
            ],
            "parquet-scrooge-deprecated/src/main/java/org/apache/parquet/scrooge/ScroogeWriteSupport.java": [
                70,
                0
            ],
            "parquet-scrooge-deprecated/src/test/java/org/apache/parquet/scrooge/ParquetScroogeSchemeTest.java": [
                235,
                0
            ],
            "parquet-scrooge-deprecated/src/test/java/org/apache/parquet/scrooge/ScroogeBinaryTest.java": [
                100,
                0
            ],
            "parquet-scrooge-deprecated/src/test/java/org/apache/parquet/scrooge/ScroogeStructConverterTest.java": [
                184,
                0
            ],
            "parquet-scrooge-deprecated/src/test/java/org/apache/parquet/scrooge/TestCorruptScroogeRecords.java": [
                69,
                0
            ],
            "parquet-scrooge-deprecated/src/test/resources/names.txt": null,
            "parquet-scrooge-deprecated/src/test/thrift/test.thrift": null,
            "parquet-tools-deprecated/README.md": null,
            "parquet-tools-deprecated/REVIEWERS.md": null,
            "parquet-tools-deprecated/pom.xml": null,
            "parquet-tools-deprecated/src/main/assembly/assembly.xml": null,
            "parquet-tools-deprecated/src/main/java/org/apache/parquet/tools/Main.java": [
                232,
                0
            ],
            "parquet-tools-deprecated/src/main/java/org/apache/parquet/tools/command/ArgsOnlyCommand.java": [
                56,
                0
            ],
            "parquet-tools-deprecated/src/main/java/org/apache/parquet/tools/command/CatCommand.java": [
                103,
                0
            ],
            "parquet-tools-deprecated/src/main/java/org/apache/parquet/tools/command/ColumnIndexCommand.java": [
                182,
                0
            ],
            "parquet-tools-deprecated/src/main/java/org/apache/parquet/tools/command/ColumnMaskingCommand.java": [
                96,
                0
            ],
            "parquet-tools-deprecated/src/main/java/org/apache/parquet/tools/command/ColumnSizeCommand.java": [
                121,
                0
            ],
            "parquet-tools-deprecated/src/main/java/org/apache/parquet/tools/command/Command.java": [
                31,
                0
            ],
            "parquet-tools-deprecated/src/main/java/org/apache/parquet/tools/command/DumpCommand.java": [
                397,
                0
            ],
            "parquet-tools-deprecated/src/main/java/org/apache/parquet/tools/command/HeadCommand.java": [
                121,
                0
            ],
            "parquet-tools-deprecated/src/main/java/org/apache/parquet/tools/command/MergeCommand.java": [
                251,
                0
            ],
            "parquet-tools-deprecated/src/main/java/org/apache/parquet/tools/command/MetadataUtils.java": [
                212,
                0
            ],
            "parquet-tools-deprecated/src/main/java/org/apache/parquet/tools/command/PruneColumnsCommand.java": [
                73,
                0
            ],
            "parquet-tools-deprecated/src/main/java/org/apache/parquet/tools/command/Registry.java": [
                68,
                0
            ],
            "parquet-tools-deprecated/src/main/java/org/apache/parquet/tools/command/RowCountCommand.java": [
                102,
                0
            ],
            "parquet-tools-deprecated/src/main/java/org/apache/parquet/tools/command/ShowMetaCommand.java": [
                95,
                0
            ],
            "parquet-tools-deprecated/src/main/java/org/apache/parquet/tools/command/ShowSchemaCommand.java": [
                109,
                0
            ],
            "parquet-tools-deprecated/src/main/java/org/apache/parquet/tools/command/SizeCommand.java": [
                145,
                0
            ],
            "parquet-tools-deprecated/src/main/java/org/apache/parquet/tools/command/TransCompressionCommand.java": [
                92,
                0
            ],
            "parquet-tools-deprecated/src/main/java/org/apache/parquet/tools/json/JsonRecordFormatter.java": [
                132,
                0
            ],
            "parquet-tools-deprecated/src/main/java/org/apache/parquet/tools/read/SimpleListRecord.java": [
                30,
                0
            ],
            "parquet-tools-deprecated/src/main/java/org/apache/parquet/tools/read/SimpleListRecordConverter.java": [
                34,
                0
            ],
            "parquet-tools-deprecated/src/main/java/org/apache/parquet/tools/read/SimpleMapRecord.java": [
                86,
                0
            ],
            "parquet-tools-deprecated/src/main/java/org/apache/parquet/tools/read/SimpleMapRecordConverter.java": [
                34,
                0
            ],
            "parquet-tools-deprecated/src/main/java/org/apache/parquet/tools/read/SimpleReadSupport.java": [
                41,
                0
            ],
            "parquet-tools-deprecated/src/main/java/org/apache/parquet/tools/read/SimpleRecord.java": [
                153,
                0
            ],
            "parquet-tools-deprecated/src/main/java/org/apache/parquet/tools/read/SimpleRecordConverter.java": [
                188,
                0
            ],
            "parquet-tools-deprecated/src/main/java/org/apache/parquet/tools/read/SimpleRecordMaterializer.java": [
                42,
                0
            ],
            "parquet-tools-deprecated/src/main/java/org/apache/parquet/tools/util/MetadataUtils.java": [
                234,
                0
            ],
            "parquet-tools-deprecated/src/main/java/org/apache/parquet/tools/util/PrettyPrintWriter.java": [
                1035,
                0
            ],
            "parquet-tools-deprecated/src/main/resources/META-INF/LICENSE": null,
            "parquet-tools-deprecated/src/main/resources/META-INF/NOTICE": null,
            "parquet-tools-deprecated/src/main/scripts/parquet-cat": null,
            "parquet-tools-deprecated/src/main/scripts/parquet-dump": null,
            "parquet-tools-deprecated/src/main/scripts/parquet-head": null,
            "parquet-tools-deprecated/src/main/scripts/parquet-merge": null,
            "parquet-tools-deprecated/src/main/scripts/parquet-meta": null,
            "parquet-tools-deprecated/src/main/scripts/parquet-rowcount": null,
            "parquet-tools-deprecated/src/main/scripts/parquet-schema": null,
            "parquet-tools-deprecated/src/main/scripts/parquet-size": null,
            "parquet-tools-deprecated/src/main/scripts/parquet-tools": null,
            "parquet-tools-deprecated/src/test/java/org/apache/parquet/tools/command/TestColumnSizeCommand.java": [
                95,
                0
            ],
            "parquet-tools-deprecated/src/test/java/org/apache/parquet/tools/read/TestJsonRecordFormatter.java": [
                231,
                0
            ],
            "parquet-tools-deprecated/src/test/java/org/apache/parquet/tools/read/TestSimpleMapRecord.java": [
                56,
                0
            ],
            "parquet-tools-deprecated/src/test/java/org/apache/parquet/tools/read/TestSimplePrimitiveRecord.java": [
                58,
                0
            ],
            "parquet-tools-deprecated/src/test/java/org/apache/parquet/tools/read/TestSimpleRecordConverter.java": [
                139,
                0
            ],
            "pom.xml": null
        }
    },
    "5d8fe214f16829fe258400d0c68ddaacc979b03a": {
        "datetime": "2021-04-19T17:50:41+02:00",
        "summary": "PARQUET-1448: Review of ParquetFileReader (#892)",
        "message": "PARQUET-1448: Review of ParquetFileReader (#892)\n\nCo-authored-by: David Mollitor <dmollitor@apache.org>",
        "diff": {
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ParquetFileReader.java": [
                30,
                21
            ]
        }
    },
    "89a9000e030f38c5da1d61d65b3ca560fa629d07": {
        "datetime": "2021-04-20T10:24:47+02:00",
        "summary": "PARQUET-2031: Upgrade to parquet-format 2.9.0 (#897)",
        "message": "PARQUET-2031: Upgrade to parquet-format 2.9.0 (#897)\n\n",
        "diff": {
            "pom.xml": null
        }
    },
    "8e40e69ce3e02cf4f8f0c624ff9e6173509961ee": {
        "datetime": "2021-04-22T09:32:13+02:00",
        "summary": "PARQUET-2030: Expose page size row check configurations to ParquetWriter.Builder (#895)",
        "message": "PARQUET-2030: Expose page size row check configurations to ParquetWriter.Builder (#895)\n\n",
        "diff": {
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ParquetWriter.java": [
                0,
                22
            ],
            "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/TestParquetWriter.java": [
                0,
                47
            ]
        }
    },
    "48f5195cfb2662f021e928211687192249752818": {
        "datetime": "2021-04-23T10:05:05-07:00",
        "summary": "[WIP] Refactor GroupReadSupport to unuse deprecated api (#894)",
        "message": "[WIP] Refactor GroupReadSupport to unuse deprecated api (#894)\n\nCo-authored-by: Luan <xuluan@ebay.com>",
        "diff": {
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/example/GroupReadSupport.java": [
                8,
                7
            ],
            "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/example/GroupReadSupportTest.java": [
                7,
                9
            ],
            "parquet-thrift/src/test/java/org/apache/parquet/hadoop/thrift/TestThriftToParquetFileWriter.java": [
                1,
                2
            ]
        }
    },
    "2ce35c73746cf091ed223da150daefd323a9ad3a": {
        "datetime": "2021-04-23T10:05:34-07:00",
        "summary": "PARQUET-2027: Fix calculating directory offset for merge (#896)",
        "message": "PARQUET-2027: Fix calculating directory offset for merge (#896)\n\n",
        "diff": {
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/Offsets.java": [
                3,
                5
            ],
            "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/TestParquetWriterAppendBlocks.java": [
                3,
                60
            ],
            "parquet-hadoop/src/test/resources/test-append_1.parquet": null,
            "parquet-hadoop/src/test/resources/test-append_2.parquet": null
        }
    },
    "10fd78252ea2f7beff8e5af5c6ee2917c9dceca2": {
        "datetime": "2021-04-26T17:25:12+02:00",
        "summary": "Revert \"[WIP] Refactor GroupReadSupport to unuse deprecated api (#894)\"",
        "message": "Revert \"[WIP] Refactor GroupReadSupport to unuse deprecated api (#894)\"\n\nReverting this because it contains backward incompatbile changes.\n\nThis reverts commit 48f5195cfb2662f021e928211687192249752818.\n",
        "diff": {
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/example/GroupReadSupport.java": [
                7,
                8
            ],
            "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/example/GroupReadSupportTest.java": [
                9,
                7
            ],
            "parquet-thrift/src/test/java/org/apache/parquet/hadoop/thrift/TestThriftToParquetFileWriter.java": [
                2,
                1
            ]
        }
    },
    "709fce1b72ef894febb1722d746f085b3d1050f8": {
        "datetime": "2021-05-04T14:43:50+02:00",
        "summary": "PARQUET-2038: Upgrade Jackson version used in parquet encryption. (#898)",
        "message": "PARQUET-2038: Upgrade Jackson version used in parquet encryption. (#898)\n\n",
        "diff": {
            "parquet-hadoop/src/main/java/org/apache/parquet/crypto/keytools/HadoopFSKeyMaterialStore.java": [
                5,
                6
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/crypto/keytools/KeyMaterial.java": [
                2,
                2
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/crypto/keytools/KeyMetadata.java": [
                2,
                2
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/crypto/keytools/LocalWrapKmsClient.java": [
                2,
                2
            ],
            "parquet-hadoop/src/test/java/org/apache/parquet/crypto/keytools/samples/VaultClient.java": [
                2,
                2
            ]
        }
    },
    "a3a1ad4e58518a469970b45ccef2fb64695c1894": {
        "datetime": "2021-05-11T10:39:39+02:00",
        "summary": "PARQUET-2044: Enable ZSTD buffer pool by default (#903)",
        "message": "PARQUET-2044: Enable ZSTD buffer pool by default (#903)\n\nThis PR aims to enable ZSTD buffer pool by default to improve the performance.\r\nThe default value of config and documentation is updated.\r\n",
        "diff": {
            "parquet-hadoop/README.md": null,
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/codec/ZstandardCodec.java": [
                1,
                1
            ]
        }
    },
    "c72862b61399ff516e968fbd02885e573d4be81c": {
        "datetime": "2021-05-12T10:08:05+02:00",
        "summary": "PARQUET-2037: Write INT96 with parquet-avro (#901)",
        "message": "PARQUET-2037: Write INT96 with parquet-avro (#901)\n\n",
        "diff": {
            "parquet-avro/README.md": null,
            "parquet-avro/src/main/java/org/apache/parquet/avro/AvroSchemaConverter.java": [
                24,
                46
            ],
            "parquet-avro/src/main/java/org/apache/parquet/avro/AvroWriteSupport.java": [
                0,
                3
            ],
            "parquet-avro/src/test/java/org/apache/parquet/avro/TestAvroSchemaConverter.java": [
                0,
                32
            ],
            "parquet-avro/src/test/resources/fixedToInt96.avsc": null
        }
    },
    "19348dc36bd2429fe7b4c34268ab9706bd9a08ca": {
        "datetime": "2021-05-14T10:15:28+02:00",
        "summary": "PARQUET-1922: Deprecate IOExceptionUtils (#825)",
        "message": "PARQUET-1922: Deprecate IOExceptionUtils (#825)\n\n",
        "diff": {
            "parquet-common/src/main/java/org/apache/parquet/IOExceptionUtils.java": [
                0,
                2
            ],
            "parquet-common/src/main/java/org/apache/parquet/bytes/LittleEndianDataOutputStream.java": [
                4,
                5
            ]
        }
    },
    "1007b053cceab0db7ed0b3d44b70d5882276eec4": {
        "datetime": "2021-05-17T11:23:27+02:00",
        "summary": "PARQUET-2048: Deprecate BaseRecordReader (#906)",
        "message": "PARQUET-2048: Deprecate BaseRecordReader (#906)\n\n",
        "diff": {
            "parquet-column/src/main/java/org/apache/parquet/io/BaseRecordReader.java": [
                1,
                6
            ]
        }
    },
    "8465ac60302702192733fb51369e0cd60c10f9db": {
        "datetime": "2021-05-17T11:25:20+02:00",
        "summary": "PARQUET-2046: Upgrade Apache POM to 23 (#904)",
        "message": "PARQUET-2046: Upgrade Apache POM to 23 (#904)\n\n* Updated for Apache POM 23\r\n* Put plugin back into project\r\n* Removed old version number\r\n* Updated enforcer rules",
        "diff": {
            "parquet-benchmarks/pom.xml": null,
            "parquet-cli/pom.xml": null,
            "parquet-format-structures/pom.xml": null,
            "parquet-protobuf/pom.xml": null,
            "pom.xml": null
        }
    },
    "875a4bbd82bd47f1d4d68a7e79c80941d8a76f7c": {
        "datetime": "2021-05-18T10:23:03+02:00",
        "summary": "PARQUET-1761: Lower Logging Level in ParquetOutputFormat (#745)",
        "message": "PARQUET-1761: Lower Logging Level in ParquetOutputFormat (#745)\n\n",
        "diff": {
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ParquetOutputFormat.java": [
                6,
                4
            ]
        }
    },
    "10794e63326606fe4abf5c726b8fff8683ca6c20": {
        "datetime": "2021-05-19T12:23:59+02:00",
        "summary": "PARQUET-2050: Expose repetition & definition level from ColumnIO (#908)",
        "message": "PARQUET-2050: Expose repetition & definition level from ColumnIO (#908)\n\n",
        "diff": {
            "parquet-column/src/main/java/org/apache/parquet/io/ColumnIO.java": [
                2,
                8
            ]
        }
    },
    "8ae7f31e36a298804435565e0cae584aac90f6d5": {
        "datetime": "2021-05-23T20:07:49-07:00",
        "summary": "PARQUET-2041: Add zstd to `parquet.compression` description of ParquetOutputFormat Javadoc (#899)",
        "message": "PARQUET-2041: Add zstd to `parquet.compression` description of ParquetOutputFormat Javadoc (#899)\n\nThe current Javadoc doesn't mention zstd.\r\n\r\nhttps://javadoc.io/doc/org.apache.parquet/parquet-hadoop/latest/org/apache/parquet/hadoop/ParquetOutputFormat.html\r\n\r\nThis PR aims to make Javadoc up-to-date by adding zstd.",
        "diff": {
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ParquetOutputFormat.java": [
                1,
                1
            ]
        }
    },
    "819443bc195b58735c7a2489795a219ca662c65e": {
        "datetime": "2021-05-26T09:43:22+02:00",
        "summary": "PARQUET-2052: Integer overflow when writing huge binary using dictionary encoding (#910)",
        "message": "PARQUET-2052: Integer overflow when writing huge binary using dictionary encoding (#910)\n\n",
        "diff": {
            "parquet-column/src/main/java/org/apache/parquet/column/values/dictionary/DictionaryValuesWriter.java": [
                3,
                3
            ],
            "parquet-column/src/test/java/org/apache/parquet/column/values/dictionary/TestDictionary.java": [
                0,
                15
            ],
            "pom.xml": null
        }
    },
    "45864ff1bb3f0762b1895c1245d7ace9a60191d1": {
        "datetime": "2021-06-10T09:52:02+02:00",
        "summary": "PARQUET-2057: Upgrade ZSTD-JNI to 1.5.0-1 (#914)",
        "message": "PARQUET-2057: Upgrade ZSTD-JNI to 1.5.0-1 (#914)\n\n",
        "diff": {
            "pom.xml": null
        }
    },
    "98ddadf0b8f283dec7c45937e01233869eac4467": {
        "datetime": "2021-06-11T10:23:48+02:00",
        "summary": "PARQUET-1633: Fix integer overflow (#902)",
        "message": "PARQUET-1633: Fix integer overflow (#902)\n\nUnit test:\r\n- Updated ParquetWriter to support setting row group size in long\r\n- Removed Xmx settings in the pom to allow more memory for the tests\r\n\r\nCo-authored-by: Gabor Szadovszky <gabor@apache.org>",
        "diff": {
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ParquetFileReader.java": [
                7,
                7
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ParquetWriter.java": [
                2,
                14
            ],
            "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/TestLargeColumnChunk.java": [
                0,
                142
            ],
            "pom.xml": null
        }
    },
    "bab3d53bff84a74743b2f62f5e394cbd9410b31f": {
        "datetime": "2021-06-22T09:52:43+02:00",
        "summary": "PARQUET-2054: fix TCP leaking when calling ParquetFileWriter.appendFile (#913)",
        "message": "PARQUET-2054: fix TCP leaking when calling ParquetFileWriter.appendFile (#913)\n\n* use try-with-resource statement for ParquetFileReader to call close explicitly",
        "diff": {
            "parquet-cli/src/main/java/org/apache/parquet/cli/commands/CheckParquet251Command.java": [
                4,
                2
            ],
            "parquet-cli/src/main/java/org/apache/parquet/cli/commands/SchemaCommand.java": [
                3,
                4
            ],
            "parquet-cli/src/main/java/org/apache/parquet/cli/commands/ShowDictionaryCommand.java": [
                42,
                43
            ],
            "parquet-cli/src/main/java/org/apache/parquet/cli/commands/ShowPagesCommand.java": [
                47,
                47
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ParquetFileWriter.java": [
                1,
                3
            ],
            "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/TestParquetFileWriter.java": [
                80,
                87
            ],
            "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/TestParquetWriter.java": [
                7,
                8
            ],
            "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/TestReadWriteEncodingStats.java": [
                21,
                22
            ]
        }
    },
    "c3009c1da0060257554df727ed0c0d448781ce14": {
        "datetime": "2021-06-22T09:58:50+02:00",
        "summary": "PARQUET-2051: Pass Configuration to AvroSchemaConverter as to not lose options (#912)",
        "message": "PARQUET-2051: Pass Configuration to AvroSchemaConverter as to not lose options (#912)\n\n",
        "diff": {
            "parquet-avro/src/main/java/org/apache/parquet/avro/AvroWriteSupport.java": [
                1,
                1
            ],
            "parquet-avro/src/test/java/org/apache/parquet/avro/TestAvroWriteSupport.java": [
                0,
                61
            ],
            "parquet-avro/src/test/resources/list_with_nulls.avsc": null
        }
    },
    "18df2ca255ccafa189dc70fa194214cab926a919": {
        "datetime": "2021-08-04T08:59:55+02:00",
        "summary": "PARQUET-2070: replace deprecated syntax in ProtoWriteSupport.java (#919)",
        "message": "PARQUET-2070: replace deprecated syntax in ProtoWriteSupport.java (#919)\n\n",
        "diff": {
            "README.md": null,
            "parquet-protobuf/src/main/java/org/apache/parquet/proto/ProtoWriteSupport.java": [
                7,
                1
            ]
        }
    },
    "d5924226007031b6aee8c94c577f9b9eaa037554": {
        "datetime": "2021-08-09T17:21:04+02:00",
        "summary": "PARQUET-2072: Do Not Determine Both Min/Max for Binary Stats (#920)",
        "message": "PARQUET-2072: Do Not Determine Both Min/Max for Binary Stats (#920)\n\n",
        "diff": {
            "parquet-column/src/main/java/org/apache/parquet/column/statistics/BinaryStatistics.java": [
                3,
                7
            ]
        }
    },
    "b2fdd888133ddd82bddf82aa0836697506e24f55": {
        "datetime": "2021-08-09T08:30:50-07:00",
        "summary": "PARQUET-2064: Make Range public accessible in RowRanges (#918)",
        "message": "PARQUET-2064: Make Range public accessible in RowRanges (#918)\n\n* PARQUET-2064: Make Range public accessible in RowRanges\r\n\r\n* Add comments\r\n\r\n* Move RowRange out of internal folder\r\n\r\n* Revert \"Move RowRange out of internal folder\"\r\n\r\nThis reverts commit 4f49c044aca816ff844ff8634de73244fd77cd44.",
        "diff": {
            "parquet-column/src/main/java/org/apache/parquet/internal/filter2/columnindex/RowRanges.java": [
                3,
                8
            ]
        }
    },
    "7bb1663b434e069f2b5f2832fccc15e14d41b034": {
        "datetime": "2021-08-10T09:36:50+02:00",
        "summary": "PARQUET-2063: Remove Compile Warnings from MemoryManager (#917)",
        "message": "PARQUET-2063: Remove Compile Warnings from MemoryManager (#917)\n\n",
        "diff": {
            "parquet-common/src/main/java/org/apache/parquet/ParquetRuntimeException.java": [
                3,
                0
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/MemoryManager.java": [
                12,
                14
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ParquetMemoryManagerRuntimeException.java": [
                0,
                38
            ],
            "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/TestMemoryManager.java": [
                2,
                2
            ]
        }
    },
    "e210d9fd4c8ebcd21cca0f57f646c4ac96a4b812": {
        "datetime": "2021-08-16T11:19:36+02:00",
        "summary": "PARQUET-2043: Fail for undeclared dependencies (#916)",
        "message": "PARQUET-2043: Fail for undeclared dependencies (#916)\n\nThe purpose of this change is to fail the build if some classes are\r\nused from not direct dependencies. Only classes from direct\r\ndependencies shall be used.\r\nAlso fixed some references that broke this rule.",
        "diff": {
            "parquet-arrow/pom.xml": null,
            "parquet-avro/pom.xml": null,
            "parquet-benchmarks/pom.xml": null,
            "parquet-cli/pom.xml": null,
            "parquet-column/pom.xml": null,
            "parquet-common/pom.xml": null,
            "parquet-encoding/pom.xml": null,
            "parquet-format-structures/pom.xml": null,
            "parquet-hadoop-bundle/pom.xml": null,
            "parquet-hadoop/pom.xml": null,
            "parquet-hadoop/src/test/java/org/apache/parquet/crypto/propertiesfactory/SchemaControlEncryptionTest.java": [
                8,
                7
            ],
            "parquet-jackson/pom.xml": null,
            "parquet-pig-bundle/pom.xml": null,
            "parquet-pig/pom.xml": null,
            "parquet-protobuf/pom.xml": null,
            "parquet-scala/pom.xml": null,
            "parquet-thrift/pom.xml": null,
            "pom.xml": null
        }
    },
    "cc1ae9f857920cf6982a59b3fd389277877fbb9e": {
        "datetime": "2021-08-16T11:20:55+02:00",
        "summary": "PARQUET-2059: Handle resource-intensive tests in CI (#915)",
        "message": "PARQUET-2059: Handle resource-intensive tests in CI (#915)\n\n",
        "diff": {
            "parquet-column/src/test/java/org/apache/parquet/ResourceIntensiveTestRule.java": [
                0,
                58
            ],
            "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/TestLargeColumnChunk.java": [
                3,
                6
            ],
            "pom.xml": null
        }
    },
    "5154d04f1ccc21811c0668bf68cfd19f91100907": {
        "datetime": "2021-08-16T11:23:04+02:00",
        "summary": "PARQUET-2073: Fix estimate remaining row count in ColumnWriteStoreBase. (#922)",
        "message": "PARQUET-2073: Fix estimate remaining row count in ColumnWriteStoreBase. (#922)\n\n",
        "diff": {
            "parquet-column/src/main/java/org/apache/parquet/column/impl/ColumnWriteStoreBase.java": [
                1,
                2
            ]
        }
    },
    "5f403501e9de05b6aa48f028191b4e78bb97fb12": {
        "datetime": "2021-09-09T11:17:04-07:00",
        "summary": "PARQUET-2078: Failed to read parquet file after writing with the same \u2026 (#925)",
        "message": "PARQUET-2078: Failed to read parquet file after writing with the same \u2026 (#925)\n\n* PARQUET-2078 Failed to read parquet file after writing with the same parquet version\r\n\r\n* PARQUET-2078 Failed to read parquet file after writing with the same parquet version\r\n\r\nRead path fix that make usage of this information:\r\nRowGroup[n].file_offset = RowGroup[n-1].file_offset + RowGroup[n-1].total_compressed_size\r\n\r\n* PARQUET-2078 Failed to read parquet file after writing with the same parquet version\r\n\r\naddressing review comments: more check on writer side.\r\n\r\n* PARQUET-2078 Failed to read parquet file after writing with the same parquet version\r\n\r\ntaking alignment padding and sumarry file into account\r\n\r\n* PARQUET-2078 Failed to read parquet file after writing with the same parquet version\r\n\r\nonly throw exception when: 1.footer(first column of block meta) encrypted and 2.file_offset corrupted\r\n\r\n* PARQUET-2078 Failed to read parquet file after writing with the same parquet version\r\n\r\nonly check firstColumnChunk.isSetMeta_data() for the first block\r\n\r\n* PARQUET-2078 Failed to read parquet file after writing with the same parquet version\r\n\r\naddress review comments: empty lines\r\n\r\n* PARQUET-2078 Failed to read parquet file after writing with the same parquet version\r\n\r\ncheck first rowgroup's file_offset too(SPARK-36696)\r\n\r\n* PARQUET-2078 Failed to read parquet file after writing with the same parquet version\r\n\r\nUsing Preconditions.checkState instead of assert in write path\r\nremove summary file footers case check in read path(which will never happen)\r\n\r\n* PARQUET-2078 Failed to read parquet file after writing with the same parquet version\r\n\r\nmore special case for first row group",
        "diff": {
            "parquet-column/src/main/java/org/apache/parquet/io/InvalidFileOffsetException.java": [
                0,
                29
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/format/converter/ParquetMetadataConverter.java": [
                8,
                88
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ParquetFileWriter.java": [
                0,
                1
            ],
            "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/TestParquetFileWriter.java": [
                0,
                83
            ]
        }
    },
    "cac8d5a7732c768b814f448413d5ac58e13a4ac3": {
        "datetime": "2021-09-14T11:46:34+02:00",
        "summary": "PARQUET-2083: Expose getFieldPath from ColumnIO (#926)",
        "message": "PARQUET-2083: Expose getFieldPath from ColumnIO (#926)\n\n",
        "diff": {
            "parquet-column/src/main/java/org/apache/parquet/io/ColumnIO.java": [
                1,
                1
            ]
        }
    },
    "b8d7019585b462e9950c98542e59c5ed5c6b0d13": {
        "datetime": "2021-09-14T11:47:01+02:00",
        "summary": "PARQUET-2084: Upgrade Thrift to 0.14.2 (#927)",
        "message": "PARQUET-2084: Upgrade Thrift to 0.14.2 (#927)\n\n",
        "diff": {
            "README.md": null,
            "dev/ci-before_install.sh": null,
            "pom.xml": null
        }
    },
    "455ebe40090af65294c12aa3ef3b3be9f6d143ef": {
        "datetime": "2021-09-28T16:46:04+02:00",
        "summary": "PARQUET-2096: Upgrade Thrift to 0.15.0 (#934)",
        "message": "PARQUET-2096: Upgrade Thrift to 0.15.0 (#934)\n\n",
        "diff": {
            "README.md": null,
            "dev/ci-before_install.sh": null,
            "pom.xml": null
        }
    },
    "98e3e1a770993903fbe37c8ac61321c8832d833f": {
        "datetime": "2021-09-30T09:32:06+02:00",
        "summary": "PARQUET-1968: FilterApi support In predicate (#923)",
        "message": "PARQUET-1968: FilterApi support In predicate (#923)\n\n",
        "diff": {
            "parquet-column/src/main/java/org/apache/parquet/column/MinMax.java": [
                0,
                56
            ],
            "parquet-column/src/main/java/org/apache/parquet/filter2/predicate/FilterApi.java": [
                0,
                53
            ],
            "parquet-column/src/main/java/org/apache/parquet/filter2/predicate/FilterPredicate.java": [
                0,
                8
            ],
            "parquet-column/src/main/java/org/apache/parquet/filter2/predicate/LogicalInverseRewriter.java": [
                0,
                12
            ],
            "parquet-column/src/main/java/org/apache/parquet/filter2/predicate/LogicalInverter.java": [
                0,
                12
            ],
            "parquet-column/src/main/java/org/apache/parquet/filter2/predicate/Operators.java": [
                1,
                80
            ],
            "parquet-column/src/main/java/org/apache/parquet/filter2/predicate/SchemaCompatibilityValidator.java": [
                0,
                19
            ],
            "parquet-column/src/main/java/org/apache/parquet/internal/column/columnindex/ColumnIndexBuilder.java": [
                0,
                70
            ],
            "parquet-column/src/main/java/org/apache/parquet/internal/filter2/columnindex/ColumnIndexFilter.java": [
                0,
                13
            ],
            "parquet-column/src/test/java/org/apache/parquet/internal/column/columnindex/TestColumnIndexBuilder.java": [
                0,
                182
            ],
            "parquet-column/src/test/java/org/apache/parquet/internal/filter2/columnindex/TestColumnIndexFilter.java": [
                0,
                55
            ],
            "parquet-generator/src/main/java/org/apache/parquet/filter2/IncrementallyUpdatedFilterPredicateGenerator.java": [
                0,
                65
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/filter2/bloomfilterlevel/BloomFilterImpl.java": [
                0,
                37
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/filter2/dictionarylevel/DictionaryFilter.java": [
                0,
                102
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/filter2/statisticslevel/StatisticsFilter.java": [
                0,
                69
            ],
            "parquet-hadoop/src/test/java/org/apache/parquet/filter2/TestFiltersWithMissingColumns.java": [
                0,
                10
            ],
            "parquet-hadoop/src/test/java/org/apache/parquet/filter2/compat/TestRowGroupFilter.java": [
                1,
                27
            ],
            "parquet-hadoop/src/test/java/org/apache/parquet/filter2/dictionarylevel/DictionaryFilterTest.java": [
                0,
                116
            ],
            "parquet-hadoop/src/test/java/org/apache/parquet/filter2/recordlevel/TestRecordLevelFilters.java": [
                1,
                35
            ],
            "parquet-hadoop/src/test/java/org/apache/parquet/filter2/statisticslevel/TestStatisticsFilter.java": [
                0,
                91
            ],
            "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/TestBloomFiltering.java": [
                0,
                26
            ],
            "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/TestColumnIndexFiltering.java": [
                0,
                39
            ]
        }
    },
    "1695d92cc07288713a9f2230f3aac61e2dc6a8e4": {
        "datetime": "2021-09-30T10:07:06+02:00",
        "summary": "PARQUET-2094: Handle negative values in page headers (#933)",
        "message": "PARQUET-2094: Handle negative values in page headers (#933)\n\n",
        "diff": {
            "parquet-format-structures/src/main/java/org/apache/parquet/format/InvalidParquetMetadataException.java": [
                0,
                30
            ],
            "parquet-format-structures/src/main/java/org/apache/parquet/format/MetadataValidator.java": [
                0,
                44
            ],
            "parquet-format-structures/src/main/java/org/apache/parquet/format/Util.java": [
                1,
                1
            ],
            "parquet-format-structures/src/test/java/org/apache/parquet/format/TestUtil.java": [
                1,
                19
            ]
        }
    },
    "1adc22804a700d78f8480667d083e91d6147339f": {
        "datetime": "2021-10-04T14:04:27-07:00",
        "summary": "PARQUET-2081: Encryption translation tool - Parquet-hadoop (#928)",
        "message": "PARQUET-2081: Encryption translation tool - Parquet-hadoop (#928)\n\n* PARQUET-2081: Encryption translation tool - Parquet-hadoop\r\n\r\nSummary:\r\nDesign doc - High Throughput CLAC Writer: https://docs.google.com/document/d/1-XdE8-QyDHnBsYrClwNsR8X3ks0JmKJ1-rXq7_th0hc\r\n\r\nAdded unit tests\r\n\r\nIntegration tests with real data\r\n\r\n* Address feedbacks\r\n\r\n* Address more comments\r\n\r\n* Revert the refactoring code to avoid execlusion in public api check\r\n\r\n* Address more feedbbacks\r\n\r\n* Refactor the code to have rewrite offset index always\r\n\r\n* Rename methods to reflect the change better\r\n\r\n* Use 'encrypt' flag to create different encrytion runtime\r\nAdd checking of encrypted column\r\n\r\n* Address comments\r\n\r\n* Address more comments",
        "diff": {
            "parquet-column/src/main/java/org/apache/parquet/internal/column/columnindex/OffsetIndexBuilder.java": [
                6,
                20
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/crypto/ColumnEncryptionProperties.java": [
                1,
                10
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/format/converter/ParquetMetadataConverter.java": [
                10,
                10
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ParquetFileReader.java": [
                1,
                1
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ParquetFileWriter.java": [
                8,
                71
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/metadata/ColumnChunkMetaData.java": [
                11,
                27
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/util/ColumnEncryptor.java": [
                0,
                329
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/util/ColumnMasker.java": [
                2,
                2
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/util/H2SeekableInputStream.java": [
                0,
                1
            ],
            "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/util/ColumnEncryptorTest.java": [
                0,
                293
            ],
            "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/util/CompressionConveterTest.java": [
                7,
                0
            ],
            "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/util/EncDecProperties.java": [
                0,
                99
            ],
            "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/util/TestFileHelper.java": [
                0,
                153
            ]
        }
    },
    "59e9f78b8b3a30073db202eb6432071ff71df0ec": {
        "datetime": "2021-11-02T10:43:48+01:00",
        "summary": "PARQUET-2101: Fix wrong descriptions about the default block size (#936)",
        "message": "PARQUET-2101: Fix wrong descriptions about the default block size (#936)\n\n",
        "diff": {
            "parquet-avro/src/main/java/org/apache/parquet/avro/AvroParquetWriter.java": [
                2,
                2
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ParquetWriter.java": [
                2,
                2
            ],
            "parquet-protobuf/src/main/java/org/apache/parquet/proto/ProtoParquetWriter.java": [
                2,
                2
            ]
        }
    },
    "89102ca80ca6ab20919a55bfd10d9c389112dcb3": {
        "datetime": "2021-11-11T09:12:50+01:00",
        "summary": "PARQUET-2102: Fix typo in ColumnIndexBase toString (#937)",
        "message": "PARQUET-2102: Fix typo in ColumnIndexBase toString (#937)\n\n",
        "diff": {
            "parquet-column/src/main/java/org/apache/parquet/internal/column/columnindex/ColumnIndexBuilder.java": [
                1,
                1
            ]
        }
    },
    "23a217a21ce4aaac8a92dca057e9352c51719f8f": {
        "datetime": "2021-11-24T08:57:42-08:00",
        "summary": "PARQUET-2040: Uniform encryption (#935)",
        "message": "PARQUET-2040: Uniform encryption (#935)\n\n* Initial commit\r\n\r\n* Uniform encryption - count and limit operations with same key\r\n\r\n* fix the limit value\r\n\r\nCo-authored-by: Gidon Gershinsky <ggershinsky@apple.com>",
        "diff": {
            "parquet-hadoop/src/main/java/org/apache/parquet/crypto/AesCipher.java": [
                9,
                15
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/crypto/AesCtrEncryptor.java": [
                1,
                7
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/crypto/AesGcmEncryptor.java": [
                1,
                8
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/crypto/keytools/PropertiesDrivenCryptoFactory.java": [
                13,
                41
            ],
            "parquet-hadoop/src/test/java/org/apache/parquet/crypto/TestPropertiesDrivenEncryption.java": [
                8,
                32
            ]
        }
    },
    "01a5d074829ad4cf4de1f662d54fe7bceb4bef63": {
        "datetime": "2021-11-24T09:30:03-08:00",
        "summary": "Improve Travis CI build Performance (#924)",
        "message": "Improve Travis CI build Performance (#924)\n\n",
        "diff": {
            ".travis.yml": null
        }
    },
    "1318a58b8ca9b1ecc8b17e9d3d7b3adb3d98b7c9": {
        "datetime": "2021-12-07T13:07:00-08:00",
        "summary": "PARQUET-2107: Fix Travis failures (#941)",
        "message": "PARQUET-2107: Fix Travis failures (#941)\n\n* PARQUET-2107: Fix Travis failures\r\n\r\n* PARQUET-2107: Fix according to review comment",
        "diff": {
            ".travis.yml": null
        }
    },
    "06bb358bcf8a0855c54f20122a57a88d9fde16c1": {
        "datetime": "2021-12-09T10:29:59+01:00",
        "summary": "PARQUET-2106: Refactoring lexicographic `BinaryComparator` to avoid `ByteBuffer.wrap` in the hot-path (#940)",
        "message": "PARQUET-2106: Refactoring lexicographic `BinaryComparator` to avoid `ByteBuffer.wrap` in the hot-path (#940)\n\n",
        "diff": {
            "parquet-column/src/main/java/org/apache/parquet/io/api/Binary.java": [
                4,
                125
            ],
            "parquet-column/src/main/java/org/apache/parquet/schema/PrimitiveComparator.java": [
                22,
                9
            ]
        }
    },
    "7398d9b522733c669d497c25495c9efa1c860994": {
        "datetime": "2021-12-16T15:01:35-08:00",
        "summary": "PARQUET-2105: Refactor the test code of creating the test file (#939)",
        "message": "PARQUET-2105: Refactor the test code of creating the test file (#939)\n\n",
        "diff": {
            "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/util/ColumnEncryptorTest.java": [
                41,
                63
            ],
            "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/util/EncDecProperties.java": [
                16,
                11
            ],
            "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/util/EncryptionTestFile.java": [
                0,
                38
            ],
            "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/util/TestFileBuilder.java": [
                0,
                198
            ],
            "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/util/TestFileHelper.java": [
                153,
                0
            ]
        }
    },
    "300200eb72b9f16df36d9a68cf762683234aeb08": {
        "datetime": "2022-01-24T21:30:19-08:00",
        "summary": "PARQUET-2112: Fix typo in MessageColumnIO (#943)",
        "message": "PARQUET-2112: Fix typo in MessageColumnIO (#943)\n\n* PARQUET-2112: Fix typo in MessageColumnIO\r\n\r\n* Address feedback",
        "diff": {
            "parquet-column/src/main/java/org/apache/parquet/io/MessageColumnIO.java": [
                11,
                11
            ]
        }
    },
    "ef35a5cf6aece9978034e7f704bf460d3cd68b10": {
        "datetime": "2022-02-22T09:06:43-08:00",
        "summary": "PARQUET-2128: Upgrade Thrift to 0.16.0 (#948)",
        "message": "PARQUET-2128: Upgrade Thrift to 0.16.0 (#948)\n\n",
        "diff": {
            "README.md": null,
            "dev/ci-before_install.sh": null,
            "pom.xml": null
        }
    },
    "2431c5c1333855c9efd532324dee5b771b0780bf": {
        "datetime": "2022-02-24T18:25:54-08:00",
        "summary": "PARQUET-2120: Make dictionary command handle pages without dictionary (#946)",
        "message": "PARQUET-2120: Make dictionary command handle pages without dictionary (#946)\n\n",
        "diff": {
            "parquet-cli/src/main/java/org/apache/parquet/cli/commands/ShowDictionaryCommand.java": [
                34,
                41
            ],
            "parquet-cli/src/test/java/org/apache/parquet/cli/commands/ShowDictionaryCommandTest.java": [
                0,
                11
            ]
        }
    },
    "c00479d538353348726cf78da835078024161e55": {
        "datetime": "2022-02-24T18:50:44-08:00",
        "summary": "PARQUET-2129: Add uncompressedSize to Meta Command (#949)",
        "message": "PARQUET-2129: Add uncompressedSize to Meta Command (#949)\n\n",
        "diff": {
            "parquet-cli/src/main/java/org/apache/parquet/cli/commands/ParquetMetadataCommand.java": [
                6,
                9
            ]
        }
    },
    "4d062dc37577e719dcecc666f8e837843e44a9be": {
        "datetime": "2022-03-04T09:15:14-08:00",
        "summary": "PARQUET-2121: Remove descriptions for the removed modules (#947)",
        "message": "PARQUET-2121: Remove descriptions for the removed modules (#947)\n\n* PARQUET-2121: Remove descriptions for the removed modules\r\n\r\n* Add '(deprecated)' to removed modules in README.md instead of removing their line",
        "diff": {
            ".gitignore": null,
            "README.md": null,
            "parquet-thrift/src/main/java/org/apache/parquet/hadoop/thrift/ThriftReadSupport.java": [
                6,
                3
            ],
            "parquet_cascading.md": null,
            "pom.xml": null
        }
    },
    "c7bff519094920a8609df6cbd98821a43ed779e3": {
        "datetime": "2022-03-19T17:00:24-07:00",
        "summary": "PARQUET-2117: Expose Row Index via ParquetReader and ParquetRecordReader (#945)",
        "message": "PARQUET-2117: Expose Row Index via ParquetReader and ParquetRecordReader (#945)\n\n* PARQUET-2117: Changes to generate row index in InternalParquetRecordReader, also expose the row index via ParquetReader or ParquetRecordReader\r\n\r\n - Add and populate rowIndexOffset field in BlockMetaData\r\n - Changes to generate row index in InternalParquetRecordReader, also expose the row index via ParquetReader or ParquetRecordReader\r\n - Add new unit tests and extend all the ColumnIndexFiltering and BloomFiltering unit tests to validate row indexes also.\r\n\r\n* address review comments\r\n\r\n* add test based on old parquet file without column indexes\r\n\r\n* address review comments - Return -1 when row index info not available, document the same, Return -1 when rowIndexOffset info not available in BlockMetadata\r\n\r\n* address review comments - Fix java doc style\r\n\r\n* address review comments from ggershinsky - early return and reduce indentation\r\n\r\n* fix build",
        "diff": {
            "parquet-column/src/main/java/org/apache/parquet/column/page/PageReadStore.java": [
                0,
                8
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/format/converter/ParquetMetadataConverter.java": [
                10,
                53
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ColumnChunkPageReadStore.java": [
                2,
                18
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/InternalParquetRecordReader.java": [
                1,
                54
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ParquetFileReader.java": [
                2,
                2
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ParquetReader.java": [
                0,
                10
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ParquetRecordReader.java": [
                0,
                7
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/metadata/BlockMetaData.java": [
                1,
                18
            ],
            "parquet-hadoop/src/test/java/org/apache/parquet/filter2/recordlevel/PhoneBookWriter.java": [
                2,
                17
            ],
            "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/TestBloomFiltering.java": [
                1,
                1
            ],
            "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/TestColumnIndexFiltering.java": [
                2,
                2
            ],
            "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/TestParquetReader.java": [
                0,
                181
            ],
            "parquet-hadoop/src/test/resources/test-file-with-no-column-indexes-1.parquet": null
        }
    },
    "4d7df6421179ede777d724f005ff66841b03e658": {
        "datetime": "2022-03-21T15:10:54-07:00",
        "summary": "PARQUET-2127: update jackson-databind to 2.13.2 (#952)",
        "message": "PARQUET-2127: update jackson-databind to 2.13.2 (#952)\n\n",
        "diff": {
            "pom.xml": null
        }
    },
    "fb3a9051a62acc65b20ec58f383a67566d76cc3d": {
        "datetime": "2022-04-14T09:08:36-07:00",
        "summary": "writer constructor with encryptor (#954)",
        "message": "writer constructor with encryptor (#954)\n\nCo-authored-by: Gidon Gershinsky <ggershinsky@apple.com>",
        "diff": {
            "parquet-hadoop/src/main/java/org/apache/parquet/crypto/InternalFileEncryptor.java": [
                4,
                8
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ParquetFileWriter.java": [
                11,
                39
            ]
        }
    },
    "f2f7c3ec8b22cbd119689ab321cafb659ccc59ec": {
        "datetime": "2022-05-09T15:04:30+03:00",
        "summary": "Fix ColumnIndexBuilder for notIn predicate (#961)",
        "message": "Fix ColumnIndexBuilder for notIn predicate (#961)\n\n",
        "diff": {
            "parquet-column/src/main/java/org/apache/parquet/internal/column/columnindex/ColumnIndexBuilder.java": [
                11,
                1
            ],
            "parquet-column/src/test/java/org/apache/parquet/internal/column/columnindex/TestColumnIndexBuilder.java": [
                50,
                50
            ],
            "parquet-column/src/test/java/org/apache/parquet/internal/filter2/columnindex/TestColumnIndexFilter.java": [
                5,
                5
            ]
        }
    },
    "0f88f6d87bab82483e7cc8233de2029b560ab1ff": {
        "datetime": "2022-05-11T08:12:21-07:00",
        "summary": "PARQUET-2127: update jackson-databind to 2.13.2.2 (#955)",
        "message": "PARQUET-2127: update jackson-databind to 2.13.2.2 (#955)\n\naddress the following cve https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2020-36518",
        "diff": {
            "pom.xml": null
        }
    },
    "e27983782d203ac6421bdce352623273e960c193": {
        "datetime": "2022-05-15T17:12:24-07:00",
        "summary": "Bump h2 from 1.4.193 to 2.1.210 in /parquet-column (#964)",
        "message": "Bump h2 from 1.4.193 to 2.1.210 in /parquet-column (#964)\n\nBumps [h2](https://github.com/h2database/h2database) from 1.4.193 to 2.1.210.\r\n- [Release notes](https://github.com/h2database/h2database/releases)\r\n- [Commits](https://github.com/h2database/h2database/compare/version-1.4.193...version-2.1.210)\r\n\r\n---\r\nupdated-dependencies:\r\n- dependency-name: com.h2database:h2\r\n  dependency-type: direct:development\r\n...\r\n\r\nSigned-off-by: dependabot[bot] <support@github.com>\r\n\r\nCo-authored-by: dependabot[bot] <49699333+dependabot[bot]@users.noreply.github.com>",
        "diff": {
            "parquet-column/pom.xml": null
        }
    },
    "3ba9da6ad95ce6b2b5afa34107134cbd6569c85e": {
        "datetime": "2022-05-15T17:12:37-07:00",
        "summary": "Bump protobuf-java from 3.5.1 to 3.16.1 in /parquet-protobuf (#965)",
        "message": "Bump protobuf-java from 3.5.1 to 3.16.1 in /parquet-protobuf (#965)\n\nBumps [protobuf-java](https://github.com/protocolbuffers/protobuf) from 3.5.1 to 3.16.1.\r\n- [Release notes](https://github.com/protocolbuffers/protobuf/releases)\r\n- [Changelog](https://github.com/protocolbuffers/protobuf/blob/main/generate_changelog.py)\r\n- [Commits](https://github.com/protocolbuffers/protobuf/compare/v3.5.1...v3.16.1)\r\n\r\n---\r\nupdated-dependencies:\r\n- dependency-name: com.google.protobuf:protobuf-java\r\n  dependency-type: direct:production\r\n...\r\n\r\nSigned-off-by: dependabot[bot] <support@github.com>\r\n\r\nCo-authored-by: dependabot[bot] <49699333+dependabot[bot]@users.noreply.github.com>",
        "diff": {
            "parquet-protobuf/pom.xml": null
        }
    },
    "8c8dd230f88f094c995d28a925f742fe02641207": {
        "datetime": "2022-05-15T17:12:49-07:00",
        "summary": "Bump commons-io from 2.4 to 2.7 in /parquet-hadoop (#966)",
        "message": "Bump commons-io from 2.4 to 2.7 in /parquet-hadoop (#966)\n\nBumps commons-io from 2.4 to 2.7.\r\n\r\n---\r\nupdated-dependencies:\r\n- dependency-name: commons-io:commons-io\r\n  dependency-type: direct:development\r\n...\r\n\r\nSigned-off-by: dependabot[bot] <support@github.com>\r\n\r\nCo-authored-by: dependabot[bot] <49699333+dependabot[bot]@users.noreply.github.com>",
        "diff": {
            "parquet-hadoop/pom.xml": null
        }
    },
    "dd43e6f8e1a8c1ef95ac1bb47ddc411435abeb58": {
        "datetime": "2022-05-15T17:12:58-07:00",
        "summary": "Bump commons-io from 2.4 to 2.7 in /parquet-cli (#967)",
        "message": "Bump commons-io from 2.4 to 2.7 in /parquet-cli (#967)\n\nBumps commons-io from 2.4 to 2.7.\r\n\r\n---\r\nupdated-dependencies:\r\n- dependency-name: commons-io:commons-io\r\n  dependency-type: direct:production\r\n...\r\n\r\nSigned-off-by: dependabot[bot] <support@github.com>\r\n\r\nCo-authored-by: dependabot[bot] <49699333+dependabot[bot]@users.noreply.github.com>",
        "diff": {
            "parquet-cli/pom.xml": null
        }
    },
    "a2da156b251d13bce1fa81eb95b555da04880bc1": {
        "datetime": "2022-05-18T08:50:41-07:00",
        "summary": "PARQUET-2148: Enable uniform decryption with plaintext footer (#969)",
        "message": "PARQUET-2148: Enable uniform decryption with plaintext footer (#969)\n\n* fix uniform decryption with plaintext footer\r\n\r\n* fix CI failure\r\n\r\nCo-authored-by: Gidon Gershinsky <ggershinsky@apple.com>",
        "diff": {
            "parquet-hadoop/src/main/java/org/apache/parquet/crypto/InternalFileDecryptor.java": [
                8,
                5
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/format/converter/ParquetMetadataConverter.java": [
                9,
                18
            ],
            "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/TestEncryptionOptions.java": [
                0,
                19
            ]
        }
    },
    "c797a85b37ced716efe36597344eb2f3fa06a1cf": {
        "datetime": "2022-06-10T10:21:51+03:00",
        "summary": "PARQUET-2154: `ParquetFileReader` should close its input stream when `filterRowGroups` throw Exception in constructor (#972)",
        "message": "PARQUET-2154: `ParquetFileReader` should close its input stream when `filterRowGroups` throw Exception in constructor (#972)\n\n* fix fd leak if filterRowGroups thrown IOE\r\n\r\nSigned-off-by: yangjie01 <yangjie01@baidu.com>\r\n\r\n* change to Exception",
        "diff": {
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ParquetFileReader.java": [
                3,
                24
            ]
        }
    },
    "e06384455567c56d5906fc3a152ab00fd8dfdf33": {
        "datetime": "2022-06-17T20:09:49-07:00",
        "summary": "PARQUET-2157: add bloom filter fpp config (#975)",
        "message": "PARQUET-2157: add bloom filter fpp config (#975)\n\n* add bloom filter fpp config\r\n\r\n* Trigger Build\r\n\r\n* add commons-lang dependecy in hadoop test\r\n\r\n* address comments\r\n\r\n* update doc\r\n\r\n* fix doc format\r\n\r\n* add one more space to break the line in md file\r\n\r\n* address comments\r\n\r\n* address comments\r\n\r\n* remove fpp 0.005 from the test",
        "diff": {
            "parquet-column/src/main/java/org/apache/parquet/column/ParquetProperties.java": [
                0,
                19
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/impl/ColumnWriterBase.java": [
                1,
                3
            ],
            "parquet-hadoop/README.md": null,
            "parquet-hadoop/pom.xml": null,
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ParquetOutputFormat.java": [
                2,
                6
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ParquetWriter.java": [
                0,
                5
            ],
            "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/TestParquetWriter.java": [
                0,
                62
            ]
        }
    },
    "5290bd5e0ee5dc30db0576e2bfc6eea335c465cf": {
        "datetime": "2022-06-29T22:21:45+03:00",
        "summary": "PARQUET-2161: Fix row index generation in combination with range filtering (#978)",
        "message": "PARQUET-2161: Fix row index generation in combination with range filtering (#978)\n\n* PARQUET-2161: Fix row index generation\r\n\r\nThe row indexes introduced in PARQUET-2117 are not computed correctly\r\nwhen:\r\n(1) range or offset metadata filter is applied, and\r\n(2) the first row group was eliminated by the filter\r\n\r\nFor example, if a file has two row groups with 10 rows each, and we\r\nattempt to only read the 2nd row group, we are going to produce row\r\nindexes 0, 1, 2, ..., 9 instead of expected 10, 11, ..., 19.\r\n\r\nThis happens because functions `filterFileMetaDataByStart`\r\nand `filterFileMetaDataByMidpoint` modify their input `FileMetaData`.\r\nTo return correct result, `generateRowGroupOffsets` has to be computed\r\nbefore these filters are applied.\r\n\r\n* Adjust assert message",
        "diff": {
            "parquet-hadoop/src/main/java/org/apache/parquet/format/converter/ParquetMetadataConverter.java": [
                2,
                6
            ],
            "parquet-hadoop/src/test/java/org/apache/parquet/filter2/recordlevel/PhoneBookWriter.java": [
                1,
                1
            ],
            "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/TestParquetReader.java": [
                2,
                19
            ]
        }
    },
    "e990eb3f14c39273e46a9fce07ec85d2edf7fccb": {
        "datetime": "2022-07-02T09:51:40-07:00",
        "summary": "PARQUET-2138: Add ShowBloomFilterCommand to parquet-cli (#958)",
        "message": "PARQUET-2138: Add ShowBloomFilterCommand to parquet-cli (#958)\n\n* PARQUET-2138: Add ShowBloomFilterCommand to parquet-cli\r\n\r\n* address comments",
        "diff": {
            "parquet-cli/src/main/java/org/apache/parquet/cli/Main.java": [
                0,
                2
            ],
            "parquet-cli/src/main/java/org/apache/parquet/cli/commands/ShowBloomFilterCommand.java": [
                0,
                133
            ],
            "parquet-cli/src/test/java/org/apache/parquet/cli/commands/ShowBloomFilterCommandTest.java": [
                0,
                41
            ]
        }
    },
    "19300bfbb416ae38378891868b714daa50d8769d": {
        "datetime": "2022-07-13T07:28:50-07:00",
        "summary": "PARQUET-1020 Add DynamicMessage writing support (#963)",
        "message": "PARQUET-1020 Add DynamicMessage writing support (#963)\n\n* PARQUET-1020 Add DynamicMessage writing support\r\n\r\n* PARQUET-1020 Remove useless set of Protobuf class name",
        "diff": {
            "parquet-protobuf/src/main/java/org/apache/parquet/proto/ProtoSchemaConverter.java": [
                3,
                7
            ],
            "parquet-protobuf/src/main/java/org/apache/parquet/proto/ProtoWriteSupport.java": [
                21,
                29
            ],
            "parquet-protobuf/src/test/java/org/apache/parquet/proto/ProtoWriteSupportTest.java": [
                0,
                35
            ]
        }
    },
    "1e1c383bda874e1722e001afa6116dc337ec0452": {
        "datetime": "2022-07-19T08:24:08-07:00",
        "summary": "PARQUET-2158: Upgrade Hadoop dependency to version 3.2.0 (#976)",
        "message": "PARQUET-2158: Upgrade Hadoop dependency to version 3.2.0 (#976)\n\n* PARQUET-2158: Upgrade Hadoop dependency to version 3.2.0\r\n\r\nThis updates Parquet's Hadoop dependency to 3.2.0.\r\nThis version adds compatibility with Java 11, as well\r\nas many other features and bug fixes.\r\n\r\n* PARQUET-2158. PathGlobPattern to compile/link with hadoop 3.2.0\r\n\r\nThe deprecated parquet-thrift class PathGlobPattern doesn't\r\ncompile against hadoop 3.x because in HADOOP-12436 the\r\nnominally private class org.apache.hadoop.fs.GlobPattern\r\nimplementation switched from using java.util.regex.Pattern\r\nto com.google.re2j.PatternSyntaxException.\r\n\r\nThe fact nobody has ever reported this problem implies that it\r\nis never used on any hadoop 3 release, ever.\r\n\r\nThis commit fixes the build by moving to the google classes.\r\nThe alternative strategy would actually be to fork the hadoop\r\nclass. This will work unless/until the hadoop project changes\r\nthe class again.\r\n\r\nIt may be time to consider removing entirely. Clearly nobody\r\nis actually using it.\r\n\r\n* PARQUET-2158. build auditing to cope with switch to google rej2j.\r\n\r\nDisables the API compatibility check and adds rej2j as a 'provided'\r\ndependency so that the relevant auditing checks do not fail.",
        "diff": {
            "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/TestInputFormat.java": [
                1,
                0
            ],
            "parquet-thrift/pom.xml": null,
            "parquet-thrift/src/main/java/org/apache/parquet/thrift/projection/deprecated/PathGlobPattern.java": [
                6,
                6
            ],
            "pom.xml": null
        }
    },
    "019361e0da0677360788f0ad96c520fb8c296d7d": {
        "datetime": "2022-07-19T18:42:24+03:00",
        "summary": "PARQUET-2155: Upgrade protobuf version to 3.17.3 (#973)",
        "message": "PARQUET-2155: Upgrade protobuf version to 3.17.3 (#973)\n\n* Upgrade protobuf version to 3.20.1\r\n\r\n* add Steve to co-author\r\n\r\n* change version to 3.17.3\r\n\r\nCo-authored-by: Steve Loughran <stevel@cloudera.com>",
        "diff": {
            "parquet-protobuf/pom.xml": null
        }
    },
    "3ed2dbb9ba40d93caaa5aa3149581f2108ac2bc0": {
        "datetime": "2022-07-24T12:48:28-07:00",
        "summary": "PARQUET-2134: Fix type checking in HadoopStreams.wrap (#951)",
        "message": "PARQUET-2134: Fix type checking in HadoopStreams.wrap (#951)\n\nHadoopStreams.wrap produces a wrong H2SeekableInputStream if the\r\npassed-in FSDataInputStream wraps another FSDataInputStream.\r\n\r\nSince [HDFS-14111](https://issues.apache.org/jira/browse/HDFS-14111) all\r\ninput streams in the hadoop codebase which implement `ByteBufferReadable`\r\nreturn true on the StreamCapabilities probe\r\n`stream.hasCapability(\"in:readbytebuffer\")`;\r\nthose which don't are forbidden to do so.\r\n\r\nThis means that on Hadoop 3.3.0+ the preferred way to probe for the API\r\nis to ask the stream.\r\n\r\nThe StreamCapabilities probe was added in Hadoop 2.9. Along with\r\nmaking all use of `ByteBufferReadable` non-reflective, this makes\r\nthe checks fairly straightforward.\r\n\r\nTests verify that if a stream implements `ByteBufferReadable' then\r\nit will be bonded to H2SeekableInputStream, even if multiply wrapped\r\nby FSDataInputStreams, and that if it doesn't, it won't.\r\n\r\nCo-authored-by: Steve Loughran <stevel@cloudera.com>\r\n\r\nCo-authored-by: Steve Loughran <stevel@cloudera.com>",
        "diff": {
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/util/H2SeekableInputStream.java": [
                1,
                1
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/util/HadoopStreams.java": [
                44,
                34
            ],
            "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/util/TestHadoop2ByteBufferReads.java": [
                0,
                47
            ]
        }
    },
    "0b5aaeaa4a10da487949d30d3d89e16c621a12c0": {
        "datetime": "2022-07-24T12:50:27-07:00",
        "summary": "Bump hadoop-common from 2.10.1 to 3.2.3 (#956)",
        "message": "Bump hadoop-common from 2.10.1 to 3.2.3 (#956)\n\nBumps hadoop-common from 2.10.1 to 3.2.3.\r\n\r\n---\r\nupdated-dependencies:\r\n- dependency-name: org.apache.hadoop:hadoop-common\r\n  dependency-type: direct:production\r\n...\r\n\r\nSigned-off-by: dependabot[bot] <support@github.com>\r\n\r\nCo-authored-by: dependabot[bot] <49699333+dependabot[bot]@users.noreply.github.com>",
        "diff": {
            "pom.xml": null
        }
    },
    "0819356a9dafd2ca07c5eab68e2bffeddc3bd3d9": {
        "datetime": "2022-07-25T19:55:49-07:00",
        "summary": "PARQUET-2167: Fix CLI serializing of footer with date fields (#980)",
        "message": "PARQUET-2167: Fix CLI serializing of footer with date fields (#980)\n\n",
        "diff": {
            "parquet-cli/pom.xml": null,
            "parquet-cli/src/main/java/org/apache/parquet/cli/commands/ShowFooterCommand.java": [
                0,
                2
            ],
            "parquet-cli/src/test/java/org/apache/parquet/cli/commands/FileTest.java": [
                0,
                1
            ],
            "parquet-cli/src/test/java/org/apache/parquet/cli/commands/ParquetFileTest.java": [
                10,
                18
            ],
            "pom.xml": null
        }
    },
    "438686c2ac8bbd576b3593bdc73d68df11612bd3": {
        "datetime": "2022-08-18T10:58:35+02:00",
        "summary": "PARQUET-2169: Upgrade Avro to version 1.11.1 (#981)",
        "message": "PARQUET-2169: Upgrade Avro to version 1.11.1 (#981)\n\n",
        "diff": {
            "pom.xml": null
        }
    },
    "6add62754b3d53e30376360f8d215da004fa8096": {
        "datetime": "2022-08-23T08:32:13-07:00",
        "summary": "Prevent IntelliJ from making unsolicited whitespace changes (#986)",
        "message": "Prevent IntelliJ from making unsolicited whitespace changes (#986)\n\nEvery time I make a PR on this project, I get a whole bunch of\r\ncomplaints about superfluous whitespace changes that I have to\r\nmanually revert. Those changes are caused by a flag in\r\n.editorconfig. By removing this flag, we should stop seeing those\r\ncompaints.",
        "diff": {
            ".editorconfig": null
        }
    },
    "34a55060ed94215f7070c5615dc5f140fe604737": {
        "datetime": "2022-09-17T07:00:12+01:00",
        "summary": "Upgrade Scala to 2.12.17 (#996)",
        "message": "Upgrade Scala to 2.12.17 (#996)\n\n",
        "diff": {
            "pom.xml": null
        }
    },
    "e0e66b4e61a42cdabc68403152f46a0b9c131001": {
        "datetime": "2022-09-19T10:04:04+02:00",
        "summary": "PARQUET-2192: Add Java 17 build test to GitHub action (#997)",
        "message": "PARQUET-2192: Add Java 17 build test to GitHub action (#997)\n\n",
        "diff": {
            ".github/workflows/test.yml": null,
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/package-info.java": [
                2,
                0
            ],
            "pom.xml": null
        }
    },
    "203120642dc501c83175a86739df722748dbbfc0": {
        "datetime": "2022-09-20T11:15:15+02:00",
        "summary": "PARQUET-2185 Add path object to ParquetReadOptions builder method (#994)",
        "message": "PARQUET-2185 Add path object to ParquetReadOptions builder method (#994)\n\nCo-authored-by: Atul Mohan <atul_mohan2@apple.com>",
        "diff": {
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ParquetReader.java": [
                1,
                1
            ]
        }
    },
    "53f65a81dc5c2067aa258dfe8d832a6ff9fd0e9c": {
        "datetime": "2022-09-22T06:21:31-07:00",
        "summary": "PARQUET-2160: Close ZstdInputStream to free off-heap memory in time. (#982)",
        "message": "PARQUET-2160: Close ZstdInputStream to free off-heap memory in time. (#982)\n\n* PARQUET-2160: Close ZstdInputStream to free off-heap memory in time.\r\n\r\n* Add comment.",
        "diff": {
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/CodecFactory.java": [
                1,
                12
            ]
        }
    },
    "3e74d30d44089f9faffb331bd6862e48d672af72": {
        "datetime": "2022-10-03T06:24:05-05:00",
        "summary": "doc uniform encr (#1001)",
        "message": "doc uniform encr (#1001)\n\nCo-authored-by: Gidon Gershinsky <ggershinsky@apple.com>",
        "diff": {
            "parquet-hadoop/README.md": null
        }
    },
    "704ef93ff6db938f6f693f8d662380de91b94a65": {
        "datetime": "2022-10-09T11:53:27-07:00",
        "summary": "PARQUET-2176: Column index/statistics truncation in ParquetWriter (#989)",
        "message": "PARQUET-2176: Column index/statistics truncation in ParquetWriter (#989)\n\n* PARQUET-2176 Set column index truncate length\r\n\r\n* PARQUET-2176 Set statistics truncate length\r\n\r\n* PARQUET-2176 Refactor creating test temp files",
        "diff": {
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ParquetFileWriter.java": [
                5,
                3
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ParquetWriter.java": [
                0,
                22
            ],
            "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/TestParquetWriterTruncation.java": [
                0,
                125
            ]
        }
    },
    "44dc3a4aef8e7746408381a7b11ff7ab8e888c3f": {
        "datetime": "2022-10-09T11:59:00-07:00",
        "summary": "Performance optimization to ByteBitPackingValuesReader (#962)",
        "message": "Performance optimization to ByteBitPackingValuesReader (#962)\n\nRemove object creation out of critical path\r\nMove less-used code into separate function to encourage JIT to inline\r\nmore frequently used code.",
        "diff": {
            "parquet-column/src/main/java/org/apache/parquet/column/values/bitpacking/ByteBitPackingValuesReader.java": [
                15,
                23
            ]
        }
    },
    "62b774cd0f0c60cfbe540bbfa60bee15929af5d4": {
        "datetime": "2022-10-09T12:12:41-07:00",
        "summary": "PARQUET-2142: parquet-cli without hadoop throws java.lang.NoSuchMethodError on any parquet file access command (#990)",
        "message": "PARQUET-2142: parquet-cli without hadoop throws java.lang.NoSuchMethodError on any parquet file access command (#990)\n\n",
        "diff": {
            "parquet-cli/README.md": null
        }
    },
    "d75596beaa5d6d0b07ff3004310dcd2be2469b07": {
        "datetime": "2022-11-02T07:45:32-07:00",
        "summary": "PARQUET-1711: support recursive proto schemas by limiting recursion depth (#995)",
        "message": "PARQUET-1711: support recursive proto schemas by limiting recursion depth (#995)\n\n* PARQUET-1711: support recursive proto schemas by limiting recursion depth\r\n\r\nThis approach could address the other recursion related issues (PARQUET-129, PARQUET-554).\r\n\r\n* PARQUET-1711: write recursive proto schemas with limited recursion depth\r\n\r\n* Make description a sentence.  This commit is here to set a co-author.\r\n\r\nCo-authored-by: matthieun <matthieu.nahoum@gmail.com>\r\n\r\nCo-authored-by: matthieun <matthieu.nahoum@gmail.com>",
        "diff": {
            "parquet-protobuf/README.md": null,
            "parquet-protobuf/pom.xml": null,
            "parquet-protobuf/src/main/java/org/apache/parquet/proto/ProtoSchemaConverter.java": [
                33,
                123
            ],
            "parquet-protobuf/src/main/java/org/apache/parquet/proto/ProtoWriteSupport.java": [
                10,
                22
            ],
            "parquet-protobuf/src/test/java/org/apache/parquet/proto/ProtoSchemaConverterTest.java": [
                220,
                414
            ],
            "parquet-protobuf/src/test/java/org/apache/parquet/proto/ProtoWriteSupportTest.java": [
                32,
                222
            ],
            "parquet-protobuf/src/test/java/org/apache/parquet/proto/TestUtils.java": [
                0,
                5
            ],
            "parquet-protobuf/src/test/resources/BinaryTree.par": null,
            "parquet-protobuf/src/test/resources/Struct.par": null,
            "parquet-protobuf/src/test/resources/Trees.proto": null,
            "parquet-protobuf/src/test/resources/Value.par": null,
            "parquet-protobuf/src/test/resources/WideTree.par": null
        }
    },
    "dd553305321fe90b375ace5c9a5ce661763a623d": {
        "datetime": "2022-11-02T09:32:10-07:00",
        "summary": "PARQUET-2196: Support LZ4_RAW codec (#1000)",
        "message": "PARQUET-2196: Support LZ4_RAW codec (#1000)\n\n* PARQUET-2196: Support LZ4_RAW codec\r\n\r\n* use SnappyUtil\r\n\r\n* address feedback and refine test cases\r\n\r\n* add interop test\r\n\r\n* address feedback\r\n\r\n* change interop test to read from resource\r\n\r\n* revert interop test to download from parquet-testing\r\n\r\n* make the test of compression codec generic\r\n\r\n* support snappy codec in the TestCompressionCodec\r\n\r\n* add comment and rename codec extension",
        "diff": {
            "parquet-cli/src/main/java/org/apache/parquet/cli/Util.java": [
                0,
                2
            ],
            "parquet-common/src/main/java/org/apache/parquet/hadoop/metadata/CompressionCodecName.java": [
                2,
                3
            ],
            "parquet-hadoop/pom.xml": null,
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/codec/Lz4RawCodec.java": [
                0,
                112
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/codec/Lz4RawCompressor.java": [
                0,
                44
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/codec/Lz4RawDecompressor.java": [
                0,
                46
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/codec/NonBlockedCompressor.java": [
                0,
                192
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/codec/NonBlockedDecompressor.java": [
                0,
                180
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/codec/SnappyCompressor.java": [
                133,
                5
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/codec/SnappyDecompressor.java": [
                126,
                8
            ],
            "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/codec/TestCompressionCodec.java": [
                0,
                177
            ],
            "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/codec/TestInteropReadLz4RawCodec.java": [
                0,
                129
            ]
        }
    },
    "d057b39d93014fe40f5067ee4a33621e65c91552": {
        "datetime": "2022-11-07T09:21:20-08:00",
        "summary": "PARQUET-2195: Add scan command to parquet-cli (#998)",
        "message": "PARQUET-2195: Add scan command to parquet-cli (#998)\n\n* PARQUET-2195: Add scan command to parquet-cli\r\n\r\n* Add ScanCommandTest\r\n\r\n* fix argument to use single file name",
        "diff": {
            "parquet-cli/README.md": null,
            "parquet-cli/src/main/java/org/apache/parquet/cli/Main.java": [
                0,
                2
            ],
            "parquet-cli/src/main/java/org/apache/parquet/cli/commands/ScanCommand.java": [
                0,
                91
            ],
            "parquet-cli/src/test/java/org/apache/parquet/cli/commands/ScanCommandTest.java": [
                0,
                38
            ]
        }
    },
    "c8c6386f836587cf527a56ff5741a48d40a979cb": {
        "datetime": "2022-12-03T10:36:18-08:00",
        "summary": "PARQUET-2177: Fix parquet-cli not to fail showing descriptions (#991)",
        "message": "PARQUET-2177: Fix parquet-cli not to fail showing descriptions (#991)\n\n",
        "diff": {
            "parquet-cli/src/main/java/org/apache/parquet/cli/Help.java": [
                4,
                7
            ],
            "parquet-cli/src/main/java/org/apache/parquet/cli/commands/ColumnMaskingCommand.java": [
                5,
                9
            ],
            "parquet-cli/src/main/java/org/apache/parquet/cli/commands/PruneColumnsCommand.java": [
                4,
                4
            ]
        }
    },
    "8206384a0b0ac66fdca689b0d3ff4fbd81e8b718": {
        "datetime": "2022-12-03T10:38:57-08:00",
        "summary": "PARQUET-2198 : Updating jackson data bind version to fix CVEs (#1005)",
        "message": "PARQUET-2198 : Updating jackson data bind version to fix CVEs (#1005)\n\n* Updating jackson data bind version to fix CVEs\r\n\r\nFixes  CVE-2022-42003 and  CVE-2022-42004\r\n\r\n* Update pom.xml\r\n\r\nupdated jackson version to 2.13.4\r\n\r\nCo-authored-by: Franti\u0161ek Hartman <frant.hartm@gmail.com>\r\n\r\nCo-authored-by: Franti\u0161ek Hartman <frant.hartm@gmail.com>",
        "diff": {
            "pom.xml": null
        }
    },
    "433de8df33fcf31927f7b51456be9f53e64d48b9": {
        "datetime": "2022-12-03T11:10:34-08:00",
        "summary": "nested encr info (#1009)",
        "message": "nested encr info (#1009)\n\nCo-authored-by: Gidon Gershinsky <ggershinsky@apple.com>",
        "diff": {
            "parquet-hadoop/README.md": null,
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ParquetFileWriter.java": [
                1,
                7
            ]
        }
    },
    "eb2122d4fc1234677b9651351938982f873cdfe3": {
        "datetime": "2023-01-09T21:26:56-08:00",
        "summary": "PARQUET-2224: Publish SBOM artifacts (#1017)",
        "message": "PARQUET-2224: Publish SBOM artifacts (#1017)\n\n",
        "diff": {
            "pom.xml": null
        }
    },
    "2fa8f94baeef538b460be38e3c933249d8a27675": {
        "datetime": "2023-01-14T16:50:21-08:00",
        "summary": "PARQUET-2219: ParquetFileReader skips empty row group (#1018)",
        "message": "PARQUET-2219: ParquetFileReader skips empty row group (#1018)\n\n* PARQUET-2219: ParquetFileReader skips empty row group\r\n\r\nThe parquet specs does not forbid empty row group and some\r\nimplementations are able to generate files with empty row group.\r\nThe commit aims to make ParquetFileReader robust by skipping\r\nempty row group while reading.\r\n\r\n* - test readNextFilteredRowGroup()\r\n- add test file for empty blocks next to each other\r\n\r\n* print file path in the warning",
        "diff": {
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ParquetEmptyBlockException.java": [
                0,
                41
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ParquetFileReader.java": [
                6,
                15
            ],
            "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/TestParquetReaderEmptyBlock.java": [
                0,
                170
            ],
            "parquet-hadoop/src/test/resources/test-empty-row-group_1.parquet": null,
            "parquet-hadoop/src/test/resources/test-empty-row-group_2.parquet": null,
            "parquet-hadoop/src/test/resources/test-empty-row-group_3.parquet": null
        }
    },
    "e763aca676d4154ef9dcd2cc1f6ac1c6d88db9ad": {
        "datetime": "2023-01-16T09:56:37+01:00",
        "summary": "PARQUET-2226: Support merge bloom filters (#1020)",
        "message": "PARQUET-2226: Support merge bloom filters (#1020)\n\n",
        "diff": {
            "parquet-column/src/main/java/org/apache/parquet/column/values/bloomfilter/BlockSplitBloomFilter.java": [
                0,
                27
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/values/bloomfilter/BloomFilter.java": [
                0,
                24
            ],
            "parquet-column/src/test/java/org/apache/parquet/column/values/bloomfilter/TestBlockSplitBloomFilter.java": [
                0,
                40
            ]
        }
    },
    "d6417dfad59c1423e358a5e859c332abd1244d2f": {
        "datetime": "2023-01-29T21:25:17+01:00",
        "summary": "PARQUET-2227: Refactor several file rewriters to use a new unified ParquetRewriter implementation (#1014)",
        "message": "PARQUET-2227: Refactor several file rewriters to use a new unified ParquetRewriter implementation (#1014)\n\n- A new ParquetRewriter is introduced to unify rewriting logic.\r\n- RewriteOptions is defined to provide essential settings.\r\n- CompressionConverter, ColumnPruner, ColumnMasker, and ColumnEncryptor\r\n  have been refactored.\r\n- Check conflicts in the RewriterOptions.\r\n- Rename EncryptorRunTime to ColumnChunkEncryptorRunTime.\r\n- Avoid redundant check in the ColumnChunkEncryptorRunTime.\r\n- Simplify MaskMode enum.\r\n- add mixed test cases for rewriter\r\n- add test case with encryption/pruning/transcodec\r\n- fix error message\r\n- rename createdBy to originalCreatedBy, add multiple inputs to RewriterOptions\r\n- rewriter keeps old writer version into original.created.by",
        "diff": {
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/rewrite/MaskMode.java": [
                0,
                38
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/rewrite/ParquetRewriter.java": [
                0,
                754
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/rewrite/RewriteOptions.java": [
                0,
                184
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/util/ColumnEncryptor.java": [
                247,
                8
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/util/ColumnMasker.java": [
                161,
                17
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/util/ColumnPruner.java": [
                91,
                7
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/util/CompressionConverter.java": [
                202,
                7
            ],
            "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/rewrite/ParquetRewriterTest.java": [
                0,
                428
            ],
            "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/util/CompressionConveterTest.java": [
                1,
                1
            ]
        }
    },
    "fd1326a8a56174320ea2f36d7c6c4e78105ab108": {
        "datetime": "2023-02-02T08:18:45+01:00",
        "summary": "PARQUET-2173: Fix parquet build against hadoop 3.3.3+ (#985)",
        "message": "PARQUET-2173: Fix parquet build against hadoop 3.3.3+ (#985)\n\n1.Exclude reload4j dependencies from hadoop modules so\r\navoiding parquet cli convergence issues.\r\n2.Add reload4j as a dependency to reject in compile scope.\r\n3.Expand slf4j artifact exclusion in hadoop-* dependencies\r\n\r\nThese changes are compatible with hadoop < 3.3.3; they simply\r\nensure that on later versions, the reload4j dependencies\r\ndon't get picked up.",
        "diff": {
            "pom.xml": null
        }
    },
    "c36be7b990f4e74d5560f494b53bb99c3c701749": {
        "datetime": "2023-02-10T14:22:55-08:00",
        "summary": "PARQUET-2229: ParquetRewriter masks and encrypts the same column (#1021)",
        "message": "PARQUET-2229: ParquetRewriter masks and encrypts the same column (#1021)\n\n",
        "diff": {
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/rewrite/ParquetRewriter.java": [
                13,
                15
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/rewrite/RewriteOptions.java": [
                8,
                0
            ],
            "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/rewrite/ParquetRewriterTest.java": [
                8,
                78
            ]
        }
    },
    "261f7d2679407c833545b56f4c85a4ae8b5c9ed4": {
        "datetime": "2023-02-15T11:58:32+01:00",
        "summary": "Fix notIn for columns with null values. (#1028)",
        "message": "Fix notIn for columns with null values. (#1028)\n\n",
        "diff": {
            "parquet-hadoop/src/main/java/org/apache/parquet/filter2/dictionarylevel/DictionaryFilter.java": [
                0,
                8
            ],
            "parquet-hadoop/src/test/java/org/apache/parquet/filter2/dictionarylevel/DictionaryFilterTest.java": [
                0,
                12
            ]
        }
    },
    "720aa3d3c1ce1ce5c5e2b7715cd8c5f11bdc8ede": {
        "datetime": "2023-02-21T11:43:09+01:00",
        "summary": "PARQUET-2228: ParquetRewriter supports more than one input file (#1026)",
        "message": "PARQUET-2228: ParquetRewriter supports more than one input file (#1026)\n\n",
        "diff": {
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/rewrite/ParquetRewriter.java": [
                25,
                87
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/rewrite/RewriteOptions.java": [
                1,
                87
            ],
            "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/rewrite/ParquetRewriterTest.java": [
                63,
                262
            ]
        }
    },
    "bf38e0fe549460936b310764a762749cb351ae6c": {
        "datetime": "2023-02-21T16:26:38+01:00",
        "summary": "PARQUET-2241: Fix ByteStreamSplitValuesReader with nulls (#1025)",
        "message": "PARQUET-2241: Fix ByteStreamSplitValuesReader with nulls (#1025)\n\nByteStreamSplitValuesReader depends on page.num_values\r\nwhich includes null values to compute the total stream\r\nlength. Then it throws if it fails to read enough bytes\r\nfrom the page buffer. This certainly happens if the page\r\ncontains null values.",
        "diff": {
            "parquet-avro/src/test/java/org/apache/parquet/avro/TestByteStreamSplitE2E.java": [
                0,
                114
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/values/bytestreamsplit/ByteStreamSplitValuesReader.java": [
                8,
                19
            ]
        }
    },
    "d1f59a03361c263de2302e0e77bd47184ad86df3": {
        "datetime": "2023-02-22T09:17:27+01:00",
        "summary": "PARQUET-2247: Fail-fast if CapacityByteArrayOutputStream write overflow (#1031)",
        "message": "PARQUET-2247: Fail-fast if CapacityByteArrayOutputStream write overflow (#1031)\n\n",
        "diff": {
            "parquet-common/src/main/java/org/apache/parquet/bytes/CapacityByteArrayOutputStream.java": [
                5,
                5
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ColumnChunkPageWriteStore.java": [
                2,
                2
            ]
        }
    },
    "65f540779d9117f578e9ad2eb99bb64007c1da85": {
        "datetime": "2023-02-23T07:14:32+01:00",
        "summary": "PARQUET-2243: Support zstd-jni in DirectCodecFactory (#1027)",
        "message": "PARQUET-2243: Support zstd-jni in DirectCodecFactory (#1027)\n\n",
        "diff": {
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/DirectCodecFactory.java": [
                0,
                4
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/DirectZstd.java": [
                0,
                144
            ],
            "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/TestDirectCodecFactory.java": [
                2,
                0
            ]
        }
    },
    "c9cfe821448a2f99797fda7f46c70a16cc1250a9": {
        "datetime": "2023-02-23T14:36:46+01:00",
        "summary": "PARQUET-2246: Add short circuit logic to column index filter. (#1030)",
        "message": "PARQUET-2246: Add short circuit logic to column index filter. (#1030)\n\nColumnIndexFilter can be optimized by adding short-circuit logic to\r\n`AND` and `OR` operations. It's not necessary to evaluating the\r\nright node in some cases:\r\n\r\n- If the left result row ranges of `AND` is empty\r\n- If the left result row ranges of `OR` is full range of the row-group",
        "diff": {
            "parquet-column/src/main/java/org/apache/parquet/internal/filter2/columnindex/ColumnIndexFilter.java": [
                2,
                12
            ]
        }
    },
    "79e29d44b7994bf817e4ef272dcfd54bf1c89618": {
        "datetime": "2023-02-27T08:43:29+01:00",
        "summary": "PARQUET-2230: Add a new rewrite command powered by ParquetRewriter (#1034)",
        "message": "PARQUET-2230: Add a new rewrite command powered by ParquetRewriter (#1034)\n\n",
        "diff": {
            "parquet-cli/README.md": null,
            "parquet-cli/src/main/java/org/apache/parquet/cli/Main.java": [
                0,
                2
            ],
            "parquet-cli/src/main/java/org/apache/parquet/cli/commands/PruneColumnsCommand.java": [
                1,
                1
            ],
            "parquet-cli/src/main/java/org/apache/parquet/cli/commands/RewriteCommand.java": [
                0,
                131
            ],
            "parquet-cli/src/test/java/org/apache/parquet/cli/commands/RewriteCommandTest.java": [
                0,
                41
            ]
        }
    },
    "4e9e79c895e61775066e11240729b574e2264b8b": {
        "datetime": "2023-02-27T08:45:46+01:00",
        "summary": "PARQUET-2251 Avoid generating Bloomfilter when all pages of a column are encoded by dictionary in parquet v1 (#1033)",
        "message": "PARQUET-2251 Avoid generating Bloomfilter when all pages of a column are encoded by dictionary in parquet v1 (#1033)\n\n",
        "diff": {
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ParquetFileWriter.java": [
                1,
                2
            ],
            "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/TestBloomFiltering.java": [
                1,
                17
            ],
            "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/TestStoreBloomFilter.java": [
                0,
                132
            ]
        }
    },
    "9fcf4cea0505aab216d5cd9528f51b083d5e761d": {
        "datetime": "2023-02-28T10:54:24+02:00",
        "summary": "PARQUET-2103: Fix crypto exception in print toPrettyJSON (#1019)",
        "message": "PARQUET-2103: Fix crypto exception in print toPrettyJSON (#1019)\n\n* fix bug\r\n\r\n* recover constructor\r\n\r\n* test fix\r\n\r\n* Update parquet-hadoop/src/main/java/org/apache/parquet/hadoop/metadata/FileMetaData.java\r\n\r\nCo-authored-by: Gang Wu <ustcwg@gmail.com>\r\n\r\n* deprecate and document API\r\n\r\n---------\r\n\r\nCo-authored-by: Gang Wu <ustcwg@gmail.com>",
        "diff": {
            "parquet-hadoop/src/main/java/org/apache/parquet/format/converter/ParquetMetadataConverter.java": [
                1,
                11
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/metadata/FileMetaData.java": [
                12,
                26
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/metadata/ParquetMetadata.java": [
                1,
                9
            ]
        }
    },
    "40bffcfddb929a8e8470a176e078c0782808534c": {
        "datetime": "2023-02-28T22:22:35-08:00",
        "summary": "Add Gang Wu as committer (#1037)",
        "message": "Add Gang Wu as committer (#1037)\n\n* Add Gang Wu as committer\r\n\r\n* Sort by name",
        "diff": {
            "dev/COMMITTERS.md": null
        }
    },
    "43ce92862d0a1371f55a7ee663de5b08703d502a": {
        "datetime": "2023-03-01T23:43:20+08:00",
        "summary": "PARQUET-2230: [CLI] Deprecate commands replaced by rewrite",
        "message": "PARQUET-2230: [CLI] Deprecate commands replaced by rewrite\n\nThis closes #1036 ",
        "diff": {
            "parquet-cli/README.md": null,
            "parquet-cli/src/main/java/org/apache/parquet/cli/commands/ColumnMaskingCommand.java": [
                1,
                2
            ],
            "parquet-cli/src/main/java/org/apache/parquet/cli/commands/PruneColumnsCommand.java": [
                2,
                3
            ],
            "parquet-cli/src/main/java/org/apache/parquet/cli/commands/RewriteCommand.java": [
                1,
                1
            ],
            "parquet-cli/src/main/java/org/apache/parquet/cli/commands/TransCompressionCommand.java": [
                2,
                3
            ]
        }
    },
    "d730fa7466f9fa15e1e4a4254f22af9c6783acdc": {
        "datetime": "2023-03-04T21:51:30+08:00",
        "summary": "PARQUET-2159: Vectorized BytePacker decoder using Java VectorAPI (#1011)",
        "message": "PARQUET-2159: Vectorized BytePacker decoder using Java VectorAPI (#1011)\n\n- Use Java 17 Vector API to perform bit-unpacking to enjoy 4x ~ 8x performance gain on certain architectures.\r\n- Add ParquetReadRouter to be adopted by different platforms or engines.\r\n- Add it as a plugin and use an individual profile to enable it.\r\n\r\nCo-authored-by: Fang-Xie <fang.xie@intel.com>\r\nCo-authored-by: guangzegu\u00a0<guangze.gu@intel.com>\r\nCo-authored-by: jiyu1021 <yu.ji@intel.com>\r\nCo-authored-by: jatin-bhateja <jatin.bhateja@intel.com>\r\n",
        "diff": {
            ".github/workflows/vector-plugins.yml": null,
            "README.md": null,
            "parquet-encoding/src/main/java/org/apache/parquet/column/values/bitpacking/BytePacker.java": [
                0,
                33
            ],
            "parquet-encoding/src/main/java/org/apache/parquet/column/values/bitpacking/Packer.java": [
                0,
                28
            ],
            "parquet-plugins/parquet-encoding-vector/pom.xml": null,
            "parquet-plugins/parquet-encoding-vector/src/main/java/org/apache/parquet/column/values/bitpacking/ByteBitPacking512VectorLE.java": [
                0,
                3010
            ],
            "parquet-plugins/parquet-encoding-vector/src/main/java/org/apache/parquet/column/values/bitpacking/ParquetReadRouter.java": [
                0,
                133
            ],
            "parquet-plugins/parquet-encoding-vector/src/main/java/org/apache/parquet/column/values/bitpacking/VectorSupport.java": [
                0,
                27
            ],
            "parquet-plugins/parquet-encoding-vector/src/test/java/org/apache/parquet/column/values/bitpacking/TestByteBitPacking512VectorLE.java": [
                0,
                169
            ],
            "parquet-plugins/parquet-encoding-vector/src/test/java/org/apache/parquet/column/values/bitpacking/TestParquetReadRouter.java": [
                0,
                59
            ],
            "parquet-plugins/parquet-plugins-benchmarks/pom.xml": null,
            "parquet-plugins/parquet-plugins-benchmarks/src/main/java/org/apache/parquet/plugins/benchmarks/ByteBitPackingVectorBenchmarks.java": [
                0,
                92
            ],
            "parquet-plugins/parquet-plugins-benchmarks/src/main/resources/log4j.properties": null,
            "pom.xml": null
        }
    },
    "cc145b3f4d82c7d4c67d45907163990c4bf084d6": {
        "datetime": "2023-03-06T16:24:12-08:00",
        "summary": "PARQUET-2252: Make row range methods public (#1038)",
        "message": "PARQUET-2252: Make row range methods public (#1038)\n\n",
        "diff": {
            "parquet-column/src/main/java/org/apache/parquet/internal/column/columnindex/IndexIterator.java": [
                3,
                3
            ],
            "parquet-column/src/main/java/org/apache/parquet/internal/filter2/columnindex/RowRanges.java": [
                13,
                20
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ParquetFileReader.java": [
                1,
                31
            ]
        }
    },
    "72442b5c5cbf4bf20258dd22432a5c39081193fc": {
        "datetime": "2023-03-11T22:06:57+08:00",
        "summary": "PARQUET-2164: Check size of buffered data to prevent page data from overflowing (#1032)",
        "message": "PARQUET-2164: Check size of buffered data to prevent page data from overflowing (#1032)\n\n- Use Math.addExact to detect overflow",
        "diff": {
            "parquet-common/src/main/java/org/apache/parquet/bytes/CapacityByteArrayOutputStream.java": [
                0,
                9
            ]
        }
    },
    "d38044f5395494e1543581a4b763f624305d3022": {
        "datetime": "2023-03-11T22:23:09+08:00",
        "summary": "PARQUET-2202: Review usage and implementation of Preconditions.checkargument method (#1035)",
        "message": "PARQUET-2202: Review usage and implementation of Preconditions.checkargument method (#1035)\n\n- Use %s format to avoid String concatenation\r\nEven when the check doesn't fail, String expression is evaluated.\r\nAvoid String evaluation using lazy String evaluation on fail.\r\n\r\n- checkArgument requires %s in string format\r\ncheckArgument implementation converts all parameters to String,\r\nand String.format elements must be referenced as %s\r\n\r\n- Avoid String.format calling to checkArgument\r\ncheckArguments method can format the message. Avoid error message\r\ncomposition unconditionally in frequently used code.\r\n\r\n- Avoid array creation calling varargs method\r\nEvery time you call to a method with varargs parameters, Java\r\ninternally allocates an Array. As performance improvement, creating\r\nan overloaded version of the method with 1, 2 and 3 parameters,\r\nyou can avoid the Array creation.\r\n\r\n- Avoid String concatenation calling to checkState\r\ncheckState method can format the message. Avoid error message\r\ncomposition unconditionally.",
        "diff": {
            "parquet-avro/src/main/java/org/apache/parquet/avro/AvroIndexedRecordConverter.java": [
                1,
                1
            ],
            "parquet-avro/src/main/java/org/apache/parquet/avro/AvroRecordConverter.java": [
                3,
                3
            ],
            "parquet-avro/src/main/java/org/apache/parquet/avro/AvroWriteSupport.java": [
                5,
                5
            ],
            "parquet-cli/src/main/java/org/apache/parquet/cli/BaseCommand.java": [
                6,
                6
            ],
            "parquet-cli/src/main/java/org/apache/parquet/cli/Util.java": [
                2,
                2
            ],
            "parquet-cli/src/main/java/org/apache/parquet/cli/commands/SchemaCommand.java": [
                1,
                1
            ],
            "parquet-cli/src/main/java/org/apache/parquet/cli/json/AvroJson.java": [
                8,
                8
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/ParquetProperties.java": [
                3,
                3
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/values/delta/DeltaBinaryPackingConfig.java": [
                1,
                1
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/values/dictionary/PlainValuesDictionary.java": [
                1,
                1
            ],
            "parquet-column/src/main/java/org/apache/parquet/filter2/predicate/PrimitiveToBoxedClass.java": [
                1,
                1
            ],
            "parquet-column/src/main/java/org/apache/parquet/filter2/recordlevel/FilteringGroupConverter.java": [
                1,
                1
            ],
            "parquet-column/src/main/java/org/apache/parquet/schema/LogicalTypeAnnotation.java": [
                2,
                2
            ],
            "parquet-column/src/main/java/org/apache/parquet/schema/PrimitiveType.java": [
                2,
                2
            ],
            "parquet-column/src/main/java/org/apache/parquet/schema/Types.java": [
                13,
                13
            ],
            "parquet-common/src/main/java/org/apache/parquet/Preconditions.java": [
                4,
                130
            ],
            "parquet-common/src/main/java/org/apache/parquet/bytes/CapacityByteArrayOutputStream.java": [
                2,
                2
            ],
            "parquet-common/src/main/java/org/apache/parquet/util/DynMethods.java": [
                3,
                3
            ],
            "parquet-common/src/test/java/org/apache/parquet/TestPreconditions.java": [
                4,
                192
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/format/converter/ParquetMetadataConverter.java": [
                1,
                1
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ParquetFileWriter.java": [
                1,
                1
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ParquetInputFormat.java": [
                1,
                1
            ]
        }
    },
    "1235003e742e6a76bf6cb8f7ed33e942fa12d0d5": {
        "datetime": "2023-03-17T09:35:27+08:00",
        "summary": "PARQUET-2258: Storing toString fields in FilterPredicate instances can lead to memory pressure ",
        "message": "PARQUET-2258: Storing toString fields in FilterPredicate instances can lead to memory pressure \n\nThis closes #1040 ",
        "diff": {
            "parquet-column/src/main/java/org/apache/parquet/filter2/predicate/Operators.java": [
                23,
                9
            ]
        }
    },
    "8cbbaefd83eec126b6bb2388f038c7b6ca6cf435": {
        "datetime": "2023-04-02T22:27:57+08:00",
        "summary": "PARQUET-2262: Fix local build failure due to missing surefire.argLine (#1045)",
        "message": "PARQUET-2262: Fix local build failure due to missing surefire.argLine (#1045)\n\n",
        "diff": {
            "pom.xml": null
        }
    },
    "a06afc9e05b97d489b693c7071d3a5ae73558176": {
        "datetime": "2023-04-06T12:34:11+08:00",
        "summary": "MINOR: Prepare for 1.14.0 development (#1047)",
        "message": "MINOR: Prepare for 1.14.0 development (#1047)\n\nSigned-off-by: Gang Wu <ustcwg@gmail.com>",
        "diff": {
            "CHANGES.md": null,
            "parquet-arrow/pom.xml": null,
            "parquet-avro/pom.xml": null,
            "parquet-benchmarks/pom.xml": null,
            "parquet-cli/pom.xml": null,
            "parquet-column/pom.xml": null,
            "parquet-common/pom.xml": null,
            "parquet-encoding/pom.xml": null,
            "parquet-format-structures/pom.xml": null,
            "parquet-generator/pom.xml": null,
            "parquet-hadoop-bundle/pom.xml": null,
            "parquet-hadoop/pom.xml": null,
            "parquet-jackson/pom.xml": null,
            "parquet-pig-bundle/pom.xml": null,
            "parquet-pig/pom.xml": null,
            "parquet-plugins/parquet-encoding-vector/pom.xml": null,
            "parquet-plugins/parquet-plugins-benchmarks/pom.xml": null,
            "parquet-protobuf/pom.xml": null,
            "parquet-scala/pom.xml": null,
            "parquet-thrift/pom.xml": null,
            "pom.xml": null
        }
    },
    "e9313638f765899555f748da211064363ae5978c": {
        "datetime": "2023-04-06T12:38:43+08:00",
        "summary": "PARQUET-2260: Bloom filter size shouldn't exceed the configured maxBytes (#1043)",
        "message": "PARQUET-2260: Bloom filter size shouldn't exceed the configured maxBytes (#1043)\n\nIf parquet.bloom.filter.max.bytes configuration is not a power of 2 value, the size of the bloom filter generated will exceed this value. For example, if set parquet.bloom.filter.max.bytes as 1024 * 1024+1= 1048577 , the bytes size of bloom filter generated will be 1024 * 1024 * 2 = 2097152. This does not match the definition of the parameter. This commit fixes the issue.",
        "diff": {
            "parquet-column/src/main/java/org/apache/parquet/column/impl/ColumnWriterBase.java": [
                1,
                1
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ParquetWriter.java": [
                0,
                11
            ],
            "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/TestParquetWriter.java": [
                17,
                56
            ]
        }
    },
    "a1fdcfaa60100ed6e176ecfd864922988b3c1efa": {
        "datetime": "2023-04-12T10:04:17+08:00",
        "summary": "MINOR: Fix description of 'parquet.writer.version'",
        "message": "MINOR: Fix description of 'parquet.writer.version'\n\nThis closes #1050 ",
        "diff": {
            "parquet-hadoop/README.md": null
        }
    },
    "ba68a3de26b6dbfd2a8f70fe0e6359e8eac3fd3c": {
        "datetime": "2023-04-13T21:12:57+02:00",
        "summary": "PARQUET-2263: Upgrade maven-shade-plugin to 3.4.1 (#1046)",
        "message": "PARQUET-2263: Upgrade maven-shade-plugin to 3.4.1 (#1046)\n\n* Upgrade maven-shade-plugin to 3.4.1\r\n\r\n* Update pom.xml\r\n\r\n* Update pom.xml\r\n\r\n* Update pom.xml\r\n\r\n* Update pom.xml\r\n\r\n---------\r\n\r\nCo-authored-by: Fokko Driesprong <fokko@apache.org>",
        "diff": {
            "parquet-avro/pom.xml": null,
            "parquet-thrift/pom.xml": null,
            "pom.xml": null
        }
    },
    "9c312d654f9eb8ac38e9ea59644f156ccac58e6b": {
        "datetime": "2023-04-13T21:20:40+02:00",
        "summary": "PARQUET-2272: Bump protobuf-java from 3.17.3 to 3.19.6 (#1003)",
        "message": "PARQUET-2272: Bump protobuf-java from 3.17.3 to 3.19.6 (#1003)\n\nBumps [protobuf-java](https://github.com/protocolbuffers/protobuf) from 3.17.3 to 3.19.6.\r\n- [Release notes](https://github.com/protocolbuffers/protobuf/releases)\r\n- [Changelog](https://github.com/protocolbuffers/protobuf/blob/main/generate_changelog.py)\r\n- [Commits](https://github.com/protocolbuffers/protobuf/compare/v3.17.3...v3.19.6)\r\n\r\n---\r\nupdated-dependencies:\r\n- dependency-name: com.google.protobuf:protobuf-java\r\n  dependency-type: direct:production\r\n...\r\n\r\nSigned-off-by: dependabot[bot] <support@github.com>\r\nCo-authored-by: dependabot[bot] <49699333+dependabot[bot]@users.noreply.github.com>",
        "diff": {
            "parquet-protobuf/pom.xml": null
        }
    },
    "370fb1426b04b74e6e917e168f8023e773128954": {
        "datetime": "2023-04-13T22:48:00+02:00",
        "summary": "PARQUET-2275: Upgrade `cyclonedx-maven-plugin` to 2.7.6 (#1057)",
        "message": "PARQUET-2275: Upgrade `cyclonedx-maven-plugin` to 2.7.6 (#1057)\n\nThis PR aims to upgrade `cyclonedx-maven-plugin` from `2.7.3` to `2.7.6` to bring the latest bug fixes.\r\n\r\n- https://github.com/CycloneDX/cyclonedx-maven-plugin/releases/tag/cyclonedx-maven-plugin-2.7.6\r\n- https://github.com/CycloneDX/cyclonedx-maven-plugin/releases/tag/cyclonedx-maven-plugin-2.7.5\r\n- https://github.com/CycloneDX/cyclonedx-maven-plugin/releases/tag/cyclonedx-maven-plugin-2.7.4\r\n\r\nHistorically, there was some issue reports on the previous versions with the latest Maven.\r\n- https://github.com/apache/spark/pull/40065\r\n- https://github.com/apache/arrow/issues/35086\r\n\r\nNow, 2.7.6 is verified in Apache Spark, ORC, Arrow community as of today.\r\n- [ORC-1407: Upgrade cyclonedx-maven-plugin to 2.7.6](https://github.com/apache/orc/pull/1463)\r\n- [SPARK-42382: Upgrade cyclonedx-maven-plugin to 2.7.6](https://github.com/apache/spark/pull/40726)\r\n- [GH-35086: Upgrade CycloneDX Maven plugin version](https://github.com/apache/arrow/pull/35092)",
        "diff": {
            "pom.xml": null
        }
    },
    "62f2bb61e32549dacc5a389de625f75fd774358a": {
        "datetime": "2023-04-14T09:57:57+08:00",
        "summary": "PARQUET-2269: Update version in README.md (#1053)",
        "message": "PARQUET-2269: Update version in README.md (#1053)\n\nAnd add myself to the list of committers",
        "diff": {
            "README.md": null,
            "dev/COMMITTERS.md": null
        }
    },
    "a533490dc8b86a1c01221c9e6a786a39de625c72": {
        "datetime": "2023-04-14T10:04:52+08:00",
        "summary": "PARQUET-2081: Fix support for rewriting files without ColumnIndexes (#1048)",
        "message": "PARQUET-2081: Fix support for rewriting files without ColumnIndexes (#1048)\n\nFix for failure when rewriting ColumnChunks that do not have a ColumnIndex populated",
        "diff": {
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ParquetFileWriter.java": [
                1,
                1
            ],
            "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/rewrite/ParquetRewriterTest.java": [
                5,
                80
            ]
        }
    },
    "8461a8e9c0e4d7ccea82956ab8e55474c9479bac": {
        "datetime": "2023-04-14T10:35:55+08:00",
        "summary": "PARQUET-2273: Remove Travis from the repository (#1055)",
        "message": "PARQUET-2273: Remove Travis from the repository (#1055)\n\nTravis isn't being used anymore, so I think we should clean up the `.travis.yml` file.",
        "diff": {
            ".travis.yml": null
        }
    },
    "cfa05406780de4df2a32da387bfe9c34de7b6a7b": {
        "datetime": "2023-04-14T11:27:33+08:00",
        "summary": "PARQUET-2265: Don't set default Model in AvroParquetWriter (#1049)",
        "message": "PARQUET-2265: Don't set default Model in AvroParquetWriter (#1049)\n\n- Don't set default Model in AvroParquetWriter\r\n- Test that data model is parsed from Configuration",
        "diff": {
            "parquet-avro/src/main/java/org/apache/parquet/avro/AvroParquetWriter.java": [
                1,
                1
            ],
            "parquet-avro/src/test/java/org/apache/parquet/avro/TestReadWrite.java": [
                0,
                85
            ]
        }
    },
    "2c5ffa6e90105e3ee2cb3b18b60ef0fe62df9d0e": {
        "datetime": "2023-04-14T10:10:52+02:00",
        "summary": "PARQUET-2267: Add dependabot to update dependencies (#1051)",
        "message": "PARQUET-2267: Add dependabot to update dependencies (#1051)\n\nMake life easier, and makes sure that we're using the latest dependencies.",
        "diff": {
            ".github/dependabot.yml": null
        }
    },
    "53ea34ac7eb98432a72e3c37cd48e4f02baf65ea": {
        "datetime": "2023-04-14T11:10:04+02:00",
        "summary": "Bump hadoop.version from 3.2.3 to 3.3.5 (#1065)",
        "message": "Bump hadoop.version from 3.2.3 to 3.3.5 (#1065)\n\nBumps `hadoop.version` from 3.2.3 to 3.3.5.\r\n\r\nUpdates `hadoop-mapreduce-client-core` from 3.2.3 to 3.3.5\r\n\r\nUpdates `hadoop-client` from 3.2.3 to 3.3.5\r\n\r\nUpdates `hadoop-common` from 3.2.3 to 3.3.5\r\n\r\nUpdates `hadoop-annotations` from 3.2.3 to 3.3.5\r\n\r\n---\r\nupdated-dependencies:\r\n- dependency-name: org.apache.hadoop:hadoop-mapreduce-client-core\r\n  dependency-type: direct:production\r\n  update-type: version-update:semver-minor\r\n- dependency-name: org.apache.hadoop:hadoop-client\r\n  dependency-type: direct:production\r\n  update-type: version-update:semver-minor\r\n- dependency-name: org.apache.hadoop:hadoop-common\r\n  dependency-type: direct:production\r\n  update-type: version-update:semver-minor\r\n- dependency-name: org.apache.hadoop:hadoop-annotations\r\n  dependency-type: direct:production\r\n  update-type: version-update:semver-minor\r\n...\r\n\r\nSigned-off-by: dependabot[bot] <support@github.com>\r\nCo-authored-by: dependabot[bot] <49699333+dependabot[bot]@users.noreply.github.com>",
        "diff": {
            "pom.xml": null
        }
    },
    "3c36aa6b42f04bd00eabff295b59f717348db607": {
        "datetime": "2023-04-14T11:10:47+02:00",
        "summary": "PARQUET-2278: Bump re2j from 1.1 to 1.7 (#1064)",
        "message": "PARQUET-2278: Bump re2j from 1.1 to 1.7 (#1064)\n\nBumps [re2j](https://github.com/google/re2j) from 1.1 to 1.7.\r\n- [Release notes](https://github.com/google/re2j/releases)\r\n- [Commits](https://github.com/google/re2j/compare/re2j-1.1...re2j-1.7)\r\n\r\n---\r\nupdated-dependencies:\r\n- dependency-name: com.google.re2j:re2j\r\n  dependency-type: direct:production\r\n  update-type: version-update:semver-minor\r\n...\r\n\r\nSigned-off-by: dependabot[bot] <support@github.com>\r\nCo-authored-by: dependabot[bot] <49699333+dependabot[bot]@users.noreply.github.com>",
        "diff": {
            "parquet-thrift/pom.xml": null
        }
    },
    "31d5250964c27e8e3cb26c251e929c61b7ec482d": {
        "datetime": "2023-04-14T11:11:24+02:00",
        "summary": "PARQUET-2279: Bump slf4j.version from 1.7.22 to 1.7.33 (#1061)",
        "message": "PARQUET-2279: Bump slf4j.version from 1.7.22 to 1.7.33 (#1061)\n\nBumps `slf4j.version` from 1.7.22 to 1.7.33.\r\n\r\nUpdates `slf4j-simple` from 1.7.22 to 1.7.33\r\n- [Release notes](https://github.com/qos-ch/slf4j/releases)\r\n- [Commits](https://github.com/qos-ch/slf4j/compare/v_1.7.22...v_1.7.33)\r\n\r\nUpdates `slf4j-api` from 1.7.22 to 1.7.33\r\n- [Release notes](https://github.com/qos-ch/slf4j/releases)\r\n- [Commits](https://github.com/qos-ch/slf4j/compare/v_1.7.22...v_1.7.33)\r\n\r\nUpdates `slf4j-log4j12` from 1.7.22 to 1.7.33\r\n- [Release notes](https://github.com/qos-ch/slf4j/releases)\r\n- [Commits](https://github.com/qos-ch/slf4j/compare/v_1.7.22...v_1.7.33)\r\n\r\n---\r\nupdated-dependencies:\r\n- dependency-name: org.slf4j:slf4j-simple\r\n  dependency-type: direct:production\r\n  update-type: version-update:semver-patch\r\n- dependency-name: org.slf4j:slf4j-api\r\n  dependency-type: direct:development\r\n  update-type: version-update:semver-patch\r\n- dependency-name: org.slf4j:slf4j-log4j12\r\n  dependency-type: direct:development\r\n  update-type: version-update:semver-patch\r\n...\r\n\r\nSigned-off-by: dependabot[bot] <support@github.com>\r\nCo-authored-by: dependabot[bot] <49699333+dependabot[bot]@users.noreply.github.com>",
        "diff": {
            "pom.xml": null
        }
    },
    "b5aa47ce6a5e93153adb3e3448ed1e263a83237c": {
        "datetime": "2023-04-14T11:12:20+02:00",
        "summary": "PARQUET-2280: Bump h2 from 2.1.210 to 2.1.214 (#1063)",
        "message": "PARQUET-2280: Bump h2 from 2.1.210 to 2.1.214 (#1063)\n\nBumps [h2](https://github.com/h2database/h2database) from 2.1.210 to 2.1.214.\r\n- [Release notes](https://github.com/h2database/h2database/releases)\r\n- [Commits](https://github.com/h2database/h2database/compare/version-2.1.210...version-2.1.214)\r\n\r\n---\r\nupdated-dependencies:\r\n- dependency-name: com.h2database:h2\r\n  dependency-type: direct:development\r\n  update-type: version-update:semver-patch\r\n...\r\n\r\nSigned-off-by: dependabot[bot] <support@github.com>\r\nCo-authored-by: dependabot[bot] <49699333+dependabot[bot]@users.noreply.github.com>",
        "diff": {
            "parquet-column/pom.xml": null
        }
    },
    "93ae1d886f6ae1f2fab9f1df0d137ef4cb1cd8a5": {
        "datetime": "2023-04-16T15:45:18+03:00",
        "summary": "update (#1070)",
        "message": "update (#1070)\n\n",
        "diff": {
            "dev/COMMITTERS.md": null
        }
    },
    "2ffe65145ee0d9da07870686a300e3a7ab6b34f9": {
        "datetime": "2023-04-17T18:23:54+02:00",
        "summary": "Bump jackson.version from 2.13.4 to 2.14.2 (#1069)",
        "message": "Bump jackson.version from 2.13.4 to 2.14.2 (#1069)\n\nBumps `jackson.version` from 2.13.4 to 2.14.2.\r\n\r\nUpdates `jackson-core` from 2.13.4 to 2.14.2\r\n- [Release notes](https://github.com/FasterXML/jackson-core/releases)\r\n- [Commits](https://github.com/FasterXML/jackson-core/compare/jackson-core-2.13.4...jackson-core-2.14.2)\r\n\r\nUpdates `jackson-annotations` from 2.13.4 to 2.14.2\r\n- [Release notes](https://github.com/FasterXML/jackson/releases)\r\n- [Commits](https://github.com/FasterXML/jackson/commits)\r\n\r\nUpdates `jackson-datatype-jsr310` from 2.13.4 to 2.14.2\r\n\r\n---\r\nupdated-dependencies:\r\n- dependency-name: com.fasterxml.jackson.core:jackson-core\r\n  dependency-type: direct:production\r\n  update-type: version-update:semver-minor\r\n- dependency-name: com.fasterxml.jackson.core:jackson-annotations\r\n  dependency-type: direct:production\r\n  update-type: version-update:semver-minor\r\n- dependency-name: com.fasterxml.jackson.datatype:jackson-datatype-jsr310\r\n  dependency-type: direct:production\r\n  update-type: version-update:semver-minor\r\n...\r\n\r\nSigned-off-by: dependabot[bot] <support@github.com>\r\nCo-authored-by: dependabot[bot] <49699333+dependabot[bot]@users.noreply.github.com>",
        "diff": {
            "pom.xml": null
        }
    },
    "7a426c4062e9b0f2cbaf0ebeede90969e0242bb7": {
        "datetime": "2023-04-17T20:26:34+02:00",
        "summary": "Bump jackson-databind from 2.13.4.2 to 2.14.2 (#1060)",
        "message": "Bump jackson-databind from 2.13.4.2 to 2.14.2 (#1060)\n\nBumps [jackson-databind](https://github.com/FasterXML/jackson) from 2.13.4.2 to 2.14.2.\r\n- [Release notes](https://github.com/FasterXML/jackson/releases)\r\n- [Commits](https://github.com/FasterXML/jackson/commits)\r\n\r\n---\r\nupdated-dependencies:\r\n- dependency-name: com.fasterxml.jackson.core:jackson-databind\r\n  dependency-type: direct:production\r\n  update-type: version-update:semver-minor\r\n...\r\n\r\nSigned-off-by: dependabot[bot] <support@github.com>\r\nCo-authored-by: dependabot[bot] <49699333+dependabot[bot]@users.noreply.github.com>",
        "diff": {
            "pom.xml": null
        }
    },
    "c12b174703aa7796b61e952c463a729d2929cba9": {
        "datetime": "2023-04-18T09:40:05+02:00",
        "summary": "PARQUET-2282: Don't initialize HadoopCodec (#1071)",
        "message": "PARQUET-2282: Don't initialize HadoopCodec (#1071)\n\nAt Iceberg we want to run Apache Flink without Hadoop, and\r\nby initializing HadoopCodec directly, but only if another\r\ncodec hasn't been provided.",
        "diff": {
            "parquet-hadoop/src/main/java/org/apache/parquet/ParquetReadOptions.java": [
                1,
                5
            ]
        }
    },
    "5e115b1fb4581cbd0a90aa4a8970eb1694082075": {
        "datetime": "2023-04-18T09:41:27+02:00",
        "summary": "PARQUET-2283: Remove Hadoop HiddenFileFilter (#1072)",
        "message": "PARQUET-2283: Remove Hadoop HiddenFileFilter (#1072)\n\nFor Iceberg/Flink we would like to run without the hadoop dependencies.\r\nThe use of the HiddenFileFilter is blocking this. This replaces the filter\r\nwith a nice stream.",
        "diff": {
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ParquetFileReader.java": [
                8,
                17
            ]
        }
    },
    "8544a8a13d0d6a08935fa90949567d94d51fdcf7": {
        "datetime": "2023-04-18T15:48:40+02:00",
        "summary": "Bump actions/setup-java from 1 to 3 (#1059)",
        "message": "Bump actions/setup-java from 1 to 3 (#1059)\n\n* Bump actions/setup-java from 1 to 3\r\n\r\nBumps [actions/setup-java](https://github.com/actions/setup-java) from 1 to 3.\r\n- [Release notes](https://github.com/actions/setup-java/releases)\r\n- [Commits](https://github.com/actions/setup-java/compare/v1...v3)\r\n\r\n---\r\nupdated-dependencies:\r\n- dependency-name: actions/setup-java\r\n  dependency-type: direct:production\r\n  update-type: version-update:semver-major\r\n...\r\n\r\nSigned-off-by: dependabot[bot] <support@github.com>\r\n\r\n* Add distribution\r\n\r\n* Add distribution\r\n\r\n* Change 1.8 to 8\r\n\r\n* Update vector-plugins.yml\r\n\r\n* Update test.yml\r\n\r\n* Update pom.xml\r\n\r\n---------\r\n\r\nSigned-off-by: dependabot[bot] <support@github.com>\r\nCo-authored-by: dependabot[bot] <49699333+dependabot[bot]@users.noreply.github.com>\r\nCo-authored-by: Fokko Driesprong <fokko@apache.org>",
        "diff": {
            ".github/workflows/test.yml": null,
            ".github/workflows/vector-plugins.yml": null,
            "pom.xml": null
        }
    },
    "11aea6bea692dded85fc8142444785aa7d7a70c2": {
        "datetime": "2023-04-23T20:56:48+02:00",
        "summary": "PARQUET-2291: Remove lingering japicmp exclusions (#1077)",
        "message": "PARQUET-2291: Remove lingering japicmp exclusions (#1077)\n\n* PARQUET-2291: Remove lingering japicmp exclusions\r\n\r\n* Update pom.xml\r\n\r\n* Update pom.xml",
        "diff": {
            "pom.xml": null
        }
    },
    "f70c5292f555a8a45baa4ac788e84a5bf31daa21": {
        "datetime": "2023-04-23T20:58:04+02:00",
        "summary": "PARQUET-2290: Add CI for Hadoop 2 (#1076)",
        "message": "PARQUET-2290: Add CI for Hadoop 2 (#1076)\n\n",
        "diff": {
            ".github/workflows/ci-hadoop2.yml": null,
            ".github/workflows/test.yml": null,
            "parquet-thrift/src/main/java/org/apache/parquet/thrift/projection/deprecated/PathGlobPattern.java": [
                12,
                0
            ],
            "pom.xml": null
        }
    },
    "47f1cf870389fe2778b32afbc7ee6575aca60162": {
        "datetime": "2023-04-25T16:29:45+02:00",
        "summary": "PARQUET-2290: Fix CI (#1082)",
        "message": "PARQUET-2290: Fix CI (#1082)\n\n* Update pom.xml\r\n\r\n* Update pom.xml",
        "diff": {
            "pom.xml": null
        }
    },
    "e365cd732f0e9f8ee6a853d725d33c794530c9de": {
        "datetime": "2023-04-26T18:43:19+02:00",
        "summary": "Bump fastutil from 8.4.2 to 8.5.12 (#1080)",
        "message": "Bump fastutil from 8.4.2 to 8.5.12 (#1080)\n\nBumps [fastutil](https://github.com/vigna/fastutil) from 8.4.2 to 8.5.12.\r\n- [Release notes](https://github.com/vigna/fastutil/releases)\r\n- [Changelog](https://github.com/vigna/fastutil/blob/master/CHANGES)\r\n- [Commits](https://github.com/vigna/fastutil/compare/8.4.2...8.5.12)\r\n\r\n---\r\nupdated-dependencies:\r\n- dependency-name: it.unimi.dsi:fastutil\r\n  dependency-type: direct:production\r\n  update-type: version-update:semver-minor\r\n...\r\n\r\nSigned-off-by: dependabot[bot] <support@github.com>\r\nCo-authored-by: dependabot[bot] <49699333+dependabot[bot]@users.noreply.github.com>",
        "diff": {
            "pom.xml": null
        }
    },
    "7ac7391c90cb98c2f71bd0f84061d4d1e5aea3c6": {
        "datetime": "2023-05-04T14:40:58+02:00",
        "summary": "Bump actions/setup-java from 1 to 3 (#1085)",
        "message": "Bump actions/setup-java from 1 to 3 (#1085)\n\n* Bump actions/setup-java from 1 to 3\r\n\r\nBumps [actions/setup-java](https://github.com/actions/setup-java) from 1 to 3.\r\n- [Release notes](https://github.com/actions/setup-java/releases)\r\n- [Commits](https://github.com/actions/setup-java/compare/v1...v3)\r\n\r\n---\r\nupdated-dependencies:\r\n- dependency-name: actions/setup-java\r\n  dependency-type: direct:production\r\n  update-type: version-update:semver-major\r\n...\r\n\r\nSigned-off-by: dependabot[bot] <support@github.com>\r\n\r\n* Add distribution\r\n\r\n---------\r\n\r\nSigned-off-by: dependabot[bot] <support@github.com>\r\nCo-authored-by: dependabot[bot] <49699333+dependabot[bot]@users.noreply.github.com>\r\nCo-authored-by: Fokko Driesprong <fokko@apache.org>",
        "diff": {
            ".github/workflows/ci-hadoop2.yml": null
        }
    },
    "ca51a21efa00575dbc8dc91c31ee1ba41c59ace7": {
        "datetime": "2023-05-05T09:32:52+02:00",
        "summary": "PARQUET-2292: Default SpecificRecord model reflects from MODEL$ field (#1078)",
        "message": "PARQUET-2292: Default SpecificRecord model reflects from MODEL$ field (#1078)\n\n",
        "diff": {
            "parquet-avro/pom.xml": null,
            "parquet-avro/src/main/java/org/apache/parquet/avro/AvroReadSupport.java": [
                2,
                22
            ],
            "parquet-avro/src/main/java/org/apache/parquet/avro/AvroRecordConverter.java": [
                0,
                78
            ],
            "parquet-avro/src/main/java/org/apache/parquet/avro/AvroWriteSupport.java": [
                2,
                22
            ],
            "parquet-avro/src/test/avro/logicalType.avsc": null,
            "parquet-avro/src/test/java/org/apache/parquet/avro/TestAvroRecordConverter.java": [
                0,
                202
            ],
            "parquet-avro/src/test/java/org/apache/parquet/avro/TestSpecificReadWrite.java": [
                0,
                42
            ],
            "pom.xml": null
        }
    },
    "dededb6b0e4b271794134ef948c15ff8e54aa902": {
        "datetime": "2023-05-06T00:14:47+02:00",
        "summary": "PARQUET-2276: Bring back support for Hadoop 2.7.3 (#1084)",
        "message": "PARQUET-2276: Bring back support for Hadoop 2.7.3 (#1084)\n\n* Bring back support for Hadoop 2.7.3\r\n\r\n* Simplify the code\r\n\r\n* Fix the naming\r\n\r\n* Comments",
        "diff": {
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/util/HadoopStreams.java": [
                7,
                55
            ],
            "pom.xml": null
        }
    },
    "9d9ac68706140f54b3f827f38a3c08725a4b9db2": {
        "datetime": "2023-05-09T07:28:30+03:00",
        "summary": "initial commit (#1089)",
        "message": "initial commit (#1089)\n\n",
        "diff": {
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ParquetRecordReader.java": [
                1,
                4
            ]
        }
    },
    "db2efeafa91426c63e13e69a947fd599f445cdd3": {
        "datetime": "2023-05-09T09:18:12+02:00",
        "summary": "PARQUET-2296: Bump easymock from 3.4 to 5.1.0 (#1088)",
        "message": "PARQUET-2296: Bump easymock from 3.4 to 5.1.0 (#1088)\n\nBumps [easymock](https://github.com/easymock/easymock) from 3.4 to 5.1.0.\r\n- [Release notes](https://github.com/easymock/easymock/releases)\r\n- [Changelog](https://github.com/easymock/easymock/blob/master/ReleaseNotes.md)\r\n- [Commits](https://github.com/easymock/easymock/compare/easymock-3.4...easymock-5.1.0)\r\n\r\n---\r\nupdated-dependencies:\r\n- dependency-name: org.easymock:easymock\r\n  dependency-type: direct:development\r\n  update-type: version-update:semver-major\r\n...\r\n\r\nSigned-off-by: dependabot[bot] <support@github.com>\r\nCo-authored-by: dependabot[bot] <49699333+dependabot[bot]@users.noreply.github.com>",
        "diff": {
            "pom.xml": null
        }
    },
    "cac8f7cf55b390c2ac5ef5d14a6aa72597b99284": {
        "datetime": "2023-05-09T09:18:33+02:00",
        "summary": "PARQUET-2295: Bump truth-proto-extension from 1.0 to 1.1.3 (#1087)",
        "message": "PARQUET-2295: Bump truth-proto-extension from 1.0 to 1.1.3 (#1087)\n\nBumps truth-proto-extension from 1.0 to 1.1.3.\r\n\r\n---\r\nupdated-dependencies:\r\n- dependency-name: com.google.truth.extensions:truth-proto-extension\r\n  dependency-type: direct:development\r\n  update-type: version-update:semver-minor\r\n...\r\n\r\nSigned-off-by: dependabot[bot] <support@github.com>\r\nCo-authored-by: dependabot[bot] <49699333+dependabot[bot]@users.noreply.github.com>",
        "diff": {
            "parquet-protobuf/pom.xml": null
        }
    },
    "9c502dccd87f2f8903c521fcd5357a4439e74d4c": {
        "datetime": "2023-05-20T22:45:47+08:00",
        "summary": "Update changelog (#1095)",
        "message": "Update changelog (#1095)\n\n",
        "diff": {
            "CHANGES.md": null
        }
    },
    "9b54b51f564df0e2f25a6265d37d88f566c49a34": {
        "datetime": "2023-05-23T17:10:12+08:00",
        "summary": "Bump jackson.version from 2.14.2 to 2.15.0 (#1093)",
        "message": "Bump jackson.version from 2.14.2 to 2.15.0 (#1093)\n\nBumps `jackson.version` from 2.14.2 to 2.15.0.\r\n\r\nUpdates `jackson-core` from 2.14.2 to 2.15.0\r\n- [Release notes](https://github.com/FasterXML/jackson-core/releases)\r\n- [Changelog](https://github.com/FasterXML/jackson-core/blob/jackson-core-2.15.0/release.properties)\r\n- [Commits](https://github.com/FasterXML/jackson-core/compare/jackson-core-2.14.2...jackson-core-2.15.0)\r\n\r\nUpdates `jackson-annotations` from 2.14.2 to 2.15.0\r\n- [Commits](https://github.com/FasterXML/jackson/commits)\r\n\r\nUpdates `jackson-datatype-jsr310` from 2.14.2 to 2.15.0\r\n\r\n---\r\nupdated-dependencies:\r\n- dependency-name: com.fasterxml.jackson.core:jackson-core\r\n  dependency-type: direct:production\r\n  update-type: version-update:semver-minor\r\n- dependency-name: com.fasterxml.jackson.core:jackson-annotations\r\n  dependency-type: direct:production\r\n  update-type: version-update:semver-minor\r\n- dependency-name: com.fasterxml.jackson.datatype:jackson-datatype-jsr310\r\n  dependency-type: direct:production\r\n  update-type: version-update:semver-minor\r\n...\r\n\r\nSigned-off-by: dependabot[bot] <support@github.com>\r\nCo-authored-by: dependabot[bot] <49699333+dependabot[bot]@users.noreply.github.com>",
        "diff": {
            "pom.xml": null
        }
    },
    "3ca98301b4fe76407f07bf19a90e1688796f091b": {
        "datetime": "2023-05-23T07:04:18-07:00",
        "summary": "Bump exec-maven-plugin from 1.2.1 to 3.1.0 (#1094)",
        "message": "Bump exec-maven-plugin from 1.2.1 to 3.1.0 (#1094)\n\nBumps [exec-maven-plugin](https://github.com/mojohaus/exec-maven-plugin) from 1.2.1 to 3.1.0.\r\n- [Release notes](https://github.com/mojohaus/exec-maven-plugin/releases)\r\n- [Commits](https://github.com/mojohaus/exec-maven-plugin/compare/exec-maven-plugin-1.2.1...exec-maven-plugin-3.1.0)\r\n\r\n---\r\nupdated-dependencies:\r\n- dependency-name: org.codehaus.mojo:exec-maven-plugin\r\n  dependency-type: direct:production\r\n  update-type: version-update:semver-major\r\n...\r\n\r\nSigned-off-by: dependabot[bot] <support@github.com>\r\nCo-authored-by: dependabot[bot] <49699333+dependabot[bot]@users.noreply.github.com>",
        "diff": {
            "parquet-column/pom.xml": null,
            "parquet-common/pom.xml": null,
            "parquet-encoding/pom.xml": null,
            "parquet-format-structures/pom.xml": null,
            "parquet-thrift/pom.xml": null
        }
    },
    "3dd45e5e20efbe7d4528c7454a8f91b933babcfb": {
        "datetime": "2023-05-23T07:04:50-07:00",
        "summary": "Bump guava from 27.0.1-jre to 31.1-jre (#1081)",
        "message": "Bump guava from 27.0.1-jre to 31.1-jre (#1081)\n\nBumps [guava](https://github.com/google/guava) from 27.0.1-jre to 31.1-jre.\r\n- [Release notes](https://github.com/google/guava/releases)\r\n- [Commits](https://github.com/google/guava/commits)\r\n\r\n---\r\nupdated-dependencies:\r\n- dependency-name: com.google.guava:guava\r\n  dependency-type: direct:production\r\n...\r\n\r\nSigned-off-by: dependabot[bot] <support@github.com>\r\nCo-authored-by: dependabot[bot] <49699333+dependabot[bot]@users.noreply.github.com>",
        "diff": {
            "pom.xml": null
        }
    },
    "10e62a8a559c62eac55bc88e5a7792df259ef6a4": {
        "datetime": "2023-05-23T07:21:38-07:00",
        "summary": "PARQUET-2212: Add ByteBuffer api for decryptors to allow direct memory to be decrypted (#1008)",
        "message": "PARQUET-2212: Add ByteBuffer api for decryptors to allow direct memory to be decrypted (#1008)\n\n* PARQUET-2212: Add ByteBuffer api for decryptors to allow direct memory to be decrypted\r\n\r\n* Address review comments and fix commons-lang3 dependency\r\n\r\n* Default direct buffer decryption to false (and revert commons-lang3 dependency to test scope)\r\n\r\n* Remove outdated comment\r\n\r\n* Address review comments.\r\n  Fix row count in TestPropertiedDrivnEncryption.\r\n  Add handling of V2 pages.\r\n  Document configuration parameter.",
        "diff": {
            "parquet-column/pom.xml": null,
            "parquet-common/src/main/java/org/apache/parquet/bytes/BytesInput.java": [
                0,
                5
            ],
            "parquet-format-structures/src/main/java/org/apache/parquet/format/BlockCipher.java": [
                7,
                16
            ],
            "parquet-hadoop/README.md": null,
            "parquet-hadoop/pom.xml": null,
            "parquet-hadoop/src/main/java/org/apache/parquet/HadoopReadOptions.java": [
                3,
                6
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/ParquetReadOptions.java": [
                1,
                19
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/crypto/AesCtrDecryptor.java": [
                0,
                42
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/crypto/AesGcmDecryptor.java": [
                0,
                32
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ColumnChunkPageReadStore.java": [
                27,
                83
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ParquetFileReader.java": [
                1,
                1
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ParquetInputFormat.java": [
                0,
                5
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ParquetReader.java": [
                1,
                12
            ],
            "parquet-hadoop/src/test/java/org/apache/parquet/crypto/TestPropertiesDrivenEncryption.java": [
                4,
                30
            ],
            "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/TestColumnChunkPageWriteStore.java": [
                5,
                17
            ],
            "pom.xml": null
        }
    },
    "97cf0b8cff8c4e2e829660f71e750f8d8f21d0a6": {
        "datetime": "2023-05-24T09:32:49+08:00",
        "summary": "PARQUET-2254: Support building bloom filter that adapts to the data",
        "message": "PARQUET-2254: Support building bloom filter that adapts to the data\n\nThis closes #1042 ",
        "diff": {
            "parquet-column/src/main/java/org/apache/parquet/column/ParquetProperties.java": [
                2,
                46
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/impl/ColumnWriterBase.java": [
                2,
                7
            ],
            "parquet-column/src/main/java/org/apache/parquet/column/values/bloomfilter/AdaptiveBlockSplitBloomFilter.java": [
                0,
                305
            ],
            "parquet-column/src/test/java/org/apache/parquet/column/values/bloomfilter/TestBlockSplitBloomFilter.java": [
                6,
                42
            ],
            "parquet-hadoop/README.md": null,
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ParquetFileWriter.java": [
                0,
                2
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ParquetOutputFormat.java": [
                0,
                12
            ],
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ParquetWriter.java": [
                0,
                22
            ],
            "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/TestAdaptiveBlockSplitBloomFiltering.java": [
                0,
                78
            ],
            "parquet-hadoop/src/test/java/org/apache/parquet/hadoop/TestBloomFiltering.java": [
                50,
                104
            ]
        }
    },
    "d5a4ce05643e6709312e3060838cb9236e882014": {
        "datetime": "2023-05-25T09:30:22+08:00",
        "summary": "PARQUET-2301: Add missing argument in ParquetRewriter logging (#1096)",
        "message": "PARQUET-2301: Add missing argument in ParquetRewriter logging (#1096)\n\n",
        "diff": {
            "parquet-hadoop/src/main/java/org/apache/parquet/hadoop/rewrite/ParquetRewriter.java": [
                1,
                2
            ]
        }
    },
    "30234f825a04954f09554b617be2d4510005c6da": {
        "datetime": "2023-05-29T10:26:17+08:00",
        "summary": "PARQUET-2302: Bump joda-time from 2.9.7 to 2.12.5 (#1101)",
        "message": "PARQUET-2302: Bump joda-time from 2.9.7 to 2.12.5 (#1101)\n\nBumps [joda-time](https://github.com/JodaOrg/joda-time) from 2.9.7 to 2.12.5.\r\n- [Release notes](https://github.com/JodaOrg/joda-time/releases)\r\n- [Changelog](https://github.com/JodaOrg/joda-time/blob/main/RELEASE-NOTES.txt)\r\n- [Commits](https://github.com/JodaOrg/joda-time/compare/v2.9.7...v2.12.5)\r\n\r\n---\r\nupdated-dependencies:\r\n- dependency-name: joda-time:joda-time\r\n  dependency-type: direct:development\r\n  update-type: version-update:semver-minor\r\n...\r\n\r\nSigned-off-by: dependabot[bot] <support@github.com>\r\nCo-authored-by: dependabot[bot] <49699333+dependabot[bot]@users.noreply.github.com>",
        "diff": {
            "parquet-pig/pom.xml": null,
            "parquet-thrift/pom.xml": null
        }
    },
    "4cdde5bf76a54421a8a96e8dfccd4549e11c92b8": {
        "datetime": "2023-05-29T10:27:26+08:00",
        "summary": "PARQUET-2303: Bump cyclonedx-maven-plugin from 2.7.6 to 2.7.9 (#1099)",
        "message": "PARQUET-2303: Bump cyclonedx-maven-plugin from 2.7.6 to 2.7.9 (#1099)\n\nBumps [cyclonedx-maven-plugin](https://github.com/CycloneDX/cyclonedx-maven-plugin) from 2.7.6 to 2.7.9.\r\n- [Release notes](https://github.com/CycloneDX/cyclonedx-maven-plugin/releases)\r\n- [Commits](https://github.com/CycloneDX/cyclonedx-maven-plugin/compare/cyclonedx-maven-plugin-2.7.6...cyclonedx-maven-plugin-2.7.9)\r\n\r\n---\r\nupdated-dependencies:\r\n- dependency-name: org.cyclonedx:cyclonedx-maven-plugin\r\n  dependency-type: direct:production\r\n  update-type: version-update:semver-patch\r\n...\r\n\r\nSigned-off-by: dependabot[bot] <support@github.com>\r\nCo-authored-by: dependabot[bot] <49699333+dependabot[bot]@users.noreply.github.com>",
        "diff": {
            "pom.xml": null
        }
    },
    "f15b9c42997e3e0af991462529942e044ace6651": {
        "datetime": "2023-05-29T10:28:15+08:00",
        "summary": "PARQUET-2304: Bump buildnumber-maven-plugin from 1.1 to 3.1.0 (#1100)",
        "message": "PARQUET-2304: Bump buildnumber-maven-plugin from 1.1 to 3.1.0 (#1100)\n\nBumps [buildnumber-maven-plugin](https://github.com/mojohaus/buildnumber-maven-plugin) from 1.1 to 3.1.0.\r\n- [Release notes](https://github.com/mojohaus/buildnumber-maven-plugin/releases)\r\n- [Commits](https://github.com/mojohaus/buildnumber-maven-plugin/compare/buildnumber-maven-plugin-1.1...3.1.0)\r\n\r\n---\r\nupdated-dependencies:\r\n- dependency-name: org.codehaus.mojo:buildnumber-maven-plugin\r\n  dependency-type: direct:production\r\n  update-type: version-update:semver-major\r\n...\r\n\r\nSigned-off-by: dependabot[bot] <support@github.com>\r\nCo-authored-by: dependabot[bot] <49699333+dependabot[bot]@users.noreply.github.com>",
        "diff": {
            "pom.xml": null
        }
    },
    "c4977579ab3b149ea045a177b039f055b5408e8f": {
        "datetime": "2023-06-05T14:54:17+08:00",
        "summary": "PARQUET-2307: Bump zero-allocation-hashing from 0.9 to 0.16 (#1105)",
        "message": "PARQUET-2307: Bump zero-allocation-hashing from 0.9 to 0.16 (#1105)\n\nBumps [zero-allocation-hashing](https://github.com/OpenHFT/Zero-Allocation-Hashing) from 0.9 to 0.16.\r\n- [Release notes](https://github.com/OpenHFT/Zero-Allocation-Hashing/releases)\r\n- [Commits](https://github.com/OpenHFT/Zero-Allocation-Hashing/compare/zero-allocation-hashing-0.9...zero-allocation-hashing-0.16)\r\n\r\n---\r\nupdated-dependencies:\r\n- dependency-name: net.openhft:zero-allocation-hashing\r\n  dependency-type: direct:development\r\n  update-type: version-update:semver-minor\r\n...\r\n\r\nSigned-off-by: dependabot[bot] <support@github.com>\r\nCo-authored-by: dependabot[bot] <49699333+dependabot[bot]@users.noreply.github.com>",
        "diff": {
            "pom.xml": null
        }
    },
    "9d80330ae4948787ac0bf4e4b0d990917f106440": {
        "datetime": "2023-06-07T10:22:34+08:00",
        "summary": "PARQUET-2308: Bump powermock.version from 2.0.2 to 2.0.9 (#1106)",
        "message": "PARQUET-2308: Bump powermock.version from 2.0.2 to 2.0.9 (#1106)\n\nBumps `powermock.version` from 2.0.2 to 2.0.9.\r\n\r\nUpdates `powermock-module-junit4` from 2.0.2 to 2.0.9\r\n- [Release notes](https://github.com/powermock/powermock/releases)\r\n- [Changelog](https://github.com/powermock/powermock/blob/release/2.x/docs/changelog.txt)\r\n- [Commits](https://github.com/powermock/powermock/compare/powermock-2.0.2...powermock-2.0.9)\r\n\r\nUpdates `powermock-core` from 2.0.2 to 2.0.9\r\n- [Release notes](https://github.com/powermock/powermock/releases)\r\n- [Changelog](https://github.com/powermock/powermock/blob/release/2.x/docs/changelog.txt)\r\n- [Commits](https://github.com/powermock/powermock/compare/powermock-2.0.2...powermock-2.0.9)\r\n\r\nUpdates `powermock-api-mockito2` from 2.0.2 to 2.0.9\r\n- [Release notes](https://github.com/powermock/powermock/releases)\r\n- [Changelog](https://github.com/powermock/powermock/blob/release/2.x/docs/changelog.txt)\r\n- [Commits](https://github.com/powermock/powermock/compare/powermock-2.0.2...powermock-2.0.9)\r\n\r\n---\r\nupdated-dependencies:\r\n- dependency-name: org.powermock:powermock-module-junit4\r\n  dependency-type: direct:development\r\n  update-type: version-update:semver-patch\r\n- dependency-name: org.powermock:powermock-core\r\n  dependency-type: direct:development\r\n  update-type: version-update:semver-patch\r\n- dependency-name: org.powermock:powermock-api-mockito2\r\n  dependency-type: direct:development\r\n  update-type: version-update:semver-patch\r\n...\r\n\r\nSigned-off-by: dependabot[bot] <support@github.com>\r\nCo-authored-by: dependabot[bot] <49699333+dependabot[bot]@users.noreply.github.com>",
        "diff": {
            "pom.xml": null
        }
    },
    "ac29db4611f86a07cc6877b416aa4b183e09b353": {
        "datetime": "2023-06-12T13:30:27+08:00",
        "summary": "PARQUET-2309: Bump site-maven-plugin from 0.8 to 0.12 (#1109)",
        "message": "PARQUET-2309: Bump site-maven-plugin from 0.8 to 0.12 (#1109)\n\nBumps [site-maven-plugin](https://github.com/github/maven-plugins) from 0.8 to 0.12.\r\n- [Commits](https://github.com/github/maven-plugins/compare/site-maven-plugin-0.8...github-maven-plugins-parent-0.12)\r\n\r\n---\r\nupdated-dependencies:\r\n- dependency-name: com.github.github:site-maven-plugin\r\n  dependency-type: direct:production\r\n  update-type: version-update:semver-minor\r\n...\r\n\r\nSigned-off-by: dependabot[bot] <support@github.com>\r\nCo-authored-by: dependabot[bot] <49699333+dependabot[bot]@users.noreply.github.com>",
        "diff": {
            "pom.xml": null
        }
    },
    "67bfa9188264edd530cf45ebf8e880056125364e": {
        "datetime": "2023-06-14T11:59:22+08:00",
        "summary": "PARQUET-2305: Allow Parquet to Proto conversion even though target schema has less fields (#1102)",
        "message": "PARQUET-2305: Allow Parquet to Proto conversion even though target schema has less fields (#1102)\n\nIf Parquet has any field which has been removed from the schema and Parquet to Proto conversion happens, it errors out due to Unknown fields. There could be some scenarios that we want to still convert PARQUET into the target proto schema object which has lesser fields. In this change using the ProtoParquetReader and specifying \"ignoreUnknownFields\" as an argument, the conversion can still be done which would ignore fields it can't convert and not error out.",
        "diff": {
            "parquet-protobuf/src/main/java/org/apache/parquet/proto/ProtoConstants.java": [
                0,
                6
            ],
            "parquet-protobuf/src/main/java/org/apache/parquet/proto/ProtoMessageConverter.java": [
                19,
                72
            ],
            "parquet-protobuf/src/main/java/org/apache/parquet/proto/ProtoParquetReader.java": [
                0,
                17
            ],
            "parquet-protobuf/src/test/java/org/apache/parquet/proto/ProtoSchemaEvolutionTest.java": [
                0,
                65
            ],
            "parquet-protobuf/src/test/java/org/apache/parquet/proto/TestUtils.java": [
                3,
                15
            ],
            "parquet-protobuf/src/test/resources/TestProto3SchemaV3.proto": null
        }
    },
    "141823a3c8d9151a837a986bb83adad3c92b26c5": {
        "datetime": "2023-06-16T17:06:11+08:00",
        "summary": "PARQUET-2312: Bump snappy-java from 1.1.8.3 to 1.1.10.1 in /parquet-hadoop (#1113)",
        "message": "PARQUET-2312: Bump snappy-java from 1.1.8.3 to 1.1.10.1 in /parquet-hadoop (#1113)\n\nBumps [snappy-java](https://github.com/xerial/snappy-java) from 1.1.8.3 to 1.1.10.1.\r\n- [Release notes](https://github.com/xerial/snappy-java/releases)\r\n- [Commits](https://github.com/xerial/snappy-java/compare/1.1.8.3...v1.1.10.1)\r\n\r\n---\r\nupdated-dependencies:\r\n- dependency-name: org.xerial.snappy:snappy-java\r\n  dependency-type: direct:production\r\n...\r\n\r\nSigned-off-by: dependabot[bot] <support@github.com>\r\nCo-authored-by: dependabot[bot] <49699333+dependabot[bot]@users.noreply.github.com>",
        "diff": {
            "parquet-hadoop/pom.xml": null
        }
    },
    "89260617326aa630284d7a88ed255954a1bc6dfb": {
        "datetime": "2023-06-19T13:32:56+08:00",
        "summary": "PARQUET-2314: Bump jackson.version from 2.15.0 to 2.15.2 (#1114)",
        "message": "PARQUET-2314: Bump jackson.version from 2.15.0 to 2.15.2 (#1114)\n\nBumps `jackson.version` from 2.15.0 to 2.15.2.\r\n\r\nUpdates `jackson-core` from 2.15.0 to 2.15.2\r\n- [Release notes](https://github.com/FasterXML/jackson-core/releases)\r\n- [Commits](https://github.com/FasterXML/jackson-core/compare/jackson-core-2.15.0...jackson-core-2.15.2)\r\n\r\nUpdates `jackson-annotations` from 2.15.0 to 2.15.2\r\n- [Commits](https://github.com/FasterXML/jackson/commits)\r\n\r\nUpdates `jackson-datatype-jsr310` from 2.15.0 to 2.15.2\r\n\r\n---\r\nupdated-dependencies:\r\n- dependency-name: com.fasterxml.jackson.core:jackson-core\r\n  dependency-type: direct:production\r\n  update-type: version-update:semver-patch\r\n- dependency-name: com.fasterxml.jackson.core:jackson-annotations\r\n  dependency-type: direct:production\r\n  update-type: version-update:semver-patch\r\n- dependency-name: com.fasterxml.jackson.datatype:jackson-datatype-jsr310\r\n  dependency-type: direct:production\r\n  update-type: version-update:semver-patch\r\n...\r\n\r\nSigned-off-by: dependabot[bot] <support@github.com>\r\nCo-authored-by: dependabot[bot] <49699333+dependabot[bot]@users.noreply.github.com>",
        "diff": {
            "pom.xml": null
        }
    },
    "e8c0959ea157ca4f06df818f6eab03cb103b4283": {
        "datetime": "2023-06-22T23:52:10+08:00",
        "summary": "PARQUET-2315: Expose local timestamp milli and micro to schema converter",
        "message": "PARQUET-2315: Expose local timestamp milli and micro to schema converter\n\nThis closes #1115 ",
        "diff": {
            "parquet-avro/src/main/java/org/apache/parquet/avro/AvroSchemaConverter.java": [
                6,
                22
            ],
            "parquet-avro/src/test/java/org/apache/parquet/avro/TestAvroSchemaConverter.java": [
                0,
                50
            ]
        }
    },
    "7dbd2c6f8c23340e4c366aee7d9baf55f9334d33": {
        "datetime": "2023-06-30T10:32:02+02:00",
        "summary": "PARQUET-2318: Implement a tool to list page headers (#1117)",
        "message": "PARQUET-2318: Implement a tool to list page headers (#1117)\n\nImplemented a new tool to retrieve the original Thrift page headers (in\r\njson format). It is attached to the existing command \"pages\" with the\r\noptions \"--raw\".\r\nAdditional changes:\r\n- Added default Hadoop configuration to support reading INT96 values\r\n- Added the profile \"local\" to parquet-cli so a standalone jar can be\r\n  generated which does not need a Hadoop environment to be used",
        "diff": {
            "parquet-cli/pom.xml": null,
            "parquet-cli/src/main/java/org/apache/parquet/cli/BaseCommand.java": [
                1,
                8
            ],
            "parquet-cli/src/main/java/org/apache/parquet/cli/commands/ShowFooterCommand.java": [
                48,
                3
            ],
            "parquet-cli/src/main/java/org/apache/parquet/cli/commands/ShowPagesCommand.java": [
                0,
                17
            ],
            "parquet-cli/src/main/java/org/apache/parquet/cli/rawpages/RawPagesReader.java": [
                0,
                92
            ],
            "parquet-cli/src/main/java/org/apache/parquet/cli/util/RawUtils.java": [
                0,
                85
            ]
        }
    },
    "7c4cb42a1c6f4fb2e4a00f208bc9d073e5f7a340": {
        "datetime": "2023-07-04T10:07:00+08:00",
        "summary": "PARQUET-1822: Avoid requiring Hadoop installation for reading/writing (#1111)",
        "message": "PARQUET-1822: Avoid requiring Hadoop installation for reading/writing (#1111)\n\n",
        "diff": {
            "parquet-avro/src/test/java/org/apache/parquet/avro/TestReadWrite.java": [
                24,
                48
            ],
            "parquet-common/src/main/java/org/apache/parquet/io/LocalInputFile.java": [
                0,
                102
            ],
            "parquet-common/src/main/java/org/apache/parquet/io/LocalOutputFile.java": [
                0,
                107
            ],
            "parquet-common/src/main/java/org/apache/parquet/io/OutputFile.java": [
                0,
                25
            ],
            "parquet-common/src/test/java/org/apache/parquet/io/TestLocalInputOutput.java": [
                0,
                92
            ]
        }
    },
    "a59f77c479a5dd3beefd108ab576deebbf025890": {
        "datetime": "2023-07-05T10:16:46+08:00",
        "summary": "PARQUET-2319: Upgrade Avro to version 1.11.2 (#1118)",
        "message": "PARQUET-2319: Upgrade Avro to version 1.11.2 (#1118)\n\n",
        "diff": {
            ".gitignore": null,
            "pom.xml": null
        }
    },
    "3a4eb2aabae6d1d6e6971073eee318c72d1ca28d": {
        "datetime": "2023-07-05T10:45:23+08:00",
        "summary": "PARQUET-2320: Bump jackson-databind from 2.14.2 to 2.15.2 (#1116)",
        "message": "PARQUET-2320: Bump jackson-databind from 2.14.2 to 2.15.2 (#1116)\n\nBumps [jackson-databind](https://github.com/FasterXML/jackson) from 2.14.2 to 2.15.2.\r\n- [Commits](https://github.com/FasterXML/jackson/commits)\r\n\r\n---\r\nupdated-dependencies:\r\n- dependency-name: com.fasterxml.jackson.core:jackson-databind\r\n  dependency-type: direct:production\r\n  update-type: version-update:semver-minor\r\n...\r\n\r\nSigned-off-by: dependabot[bot] <support@github.com>\r\nCo-authored-by: dependabot[bot] <49699333+dependabot[bot]@users.noreply.github.com>",
        "diff": {
            "pom.xml": null
        }
    }
}