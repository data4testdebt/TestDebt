{
    "OPENNLP-1": {
        "Key": "OPENNLP-1",
        "Summary": "Migrate OpenNLP Tools (and UIMA) sources to Apache",
        "Type": "Task",
        "Status": "Closed",
        "Priority": "Major",
        "Resolution": "Fixed",
        "Affects Version/s": "None",
        "Fix Version/s": "None",
        "Component/s": "None",
        "Assignee": "J\u00f6rn Kottmann",
        "Reporter": "J\u00f6rn Kottmann",
        "Created": "01/Dec/10 16:46",
        "Updated": "15/Dec/10 00:07",
        "Resolved": "15/Dec/10 00:07",
        "Description": "Migrate the OpenNLP Tools sources from Sourceforge to Apache.\nThe code is currently hosted over at Sourceforge:\nhttp://opennlp.cvs.sourceforge.net/viewvc/opennlp/\nAs part of this issue these two project folders should be imported:\nOpenNLP Tools:\nhttp://opennlp.cvs.sourceforge.net/viewvc/opennlp/opennlp/\nIf possible since 1.5.0 version tag.\nOpenNLP UIMA :\nhttp://opennlp.cvs.sourceforge.net/viewvc/opennlp/opennlp.uima/\nTo migrate the code the following steps should be performed:\n\nTag the whole OpenNLP repository over at sourceforge\nAttach the source code to the issues\nImport the source code into the new repo\nPerform code cleanup (all files already contain the license header)",
        "Issue Links": []
    },
    "OPENNLP-2": {
        "Key": "OPENNLP-2",
        "Summary": "Migrate OpenNLP Maxent sources to Apache",
        "Type": "Task",
        "Status": "Closed",
        "Priority": "Major",
        "Resolution": "Fixed",
        "Affects Version/s": "None",
        "Fix Version/s": "None",
        "Component/s": "None",
        "Assignee": "J\u00f6rn Kottmann",
        "Reporter": "J\u00f6rn Kottmann",
        "Created": "01/Dec/10 16:49",
        "Updated": "14/Dec/10 09:57",
        "Resolved": "14/Dec/10 09:57",
        "Description": "Migrate the OpenNLP Maxent sources from Sourceforge to Apache. \nThe code is currently located in this repository:\nhttp://maxent.cvs.sourceforge.net/viewvc/maxent/maxent/\nTo migrate the code the following steps should be performed: \n\nTag the whole Maxent repository over at sourceforge\nAttach the source code to the issues\nImport the source code into the new repo\nPerform code cleanup (all files already contain the license header)",
        "Issue Links": []
    },
    "OPENNLP-3": {
        "Key": "OPENNLP-3",
        "Summary": "Migrate the OpenNLP Tools Documentation from the wiki to Apache",
        "Type": "Task",
        "Status": "Closed",
        "Priority": "Major",
        "Resolution": "Fixed",
        "Affects Version/s": "None",
        "Fix Version/s": "None",
        "Component/s": "Documentation",
        "Assignee": "J\u00f6rn Kottmann",
        "Reporter": "J\u00f6rn Kottmann",
        "Created": "01/Dec/10 17:03",
        "Updated": "16/Dec/10 19:52",
        "Resolved": "16/Dec/10 19:52",
        "Description": "The OpenNLP Tools Documentation in the wiki at Sourceforge should\nbe migrated to Apache.\nThe Documentation is located here:\nhttps://sourceforge.net/apps/mediawiki/opennlp/index.php?title=Main_Page\nIt has yet to be decided how the documentation will be handled.",
        "Issue Links": []
    },
    "OPENNLP-4": {
        "Key": "OPENNLP-4",
        "Summary": "Create initial OpenNLP Project website",
        "Type": "Task",
        "Status": "Closed",
        "Priority": "Major",
        "Resolution": "Fixed",
        "Affects Version/s": "None",
        "Fix Version/s": "None",
        "Component/s": "Website",
        "Assignee": "J\u00f6rn Kottmann",
        "Reporter": "J\u00f6rn Kottmann",
        "Created": "01/Dec/10 17:07",
        "Updated": "02/May/13 02:29",
        "Resolved": "13/Dec/10 17:55",
        "Description": "Create a new website for the OpenNLP project over at Apache.\nHow that should be done was discussed here:\nhttp://mail-archives.apache.org/mod_mbox/incubator-opennlp-dev/201012.mbox/%3C4CF662BE.3020102@gmail.com%3E\nIt was decided to use the new Apache CMS.\nThe new site should be located here:\nhttp://svn.apache.org/repos/asf/incubator/opennlp/site/\nA request to the Infrastructure team to setup the new CMS is\nalready send: INFRA-3265",
        "Issue Links": []
    },
    "OPENNLP-5": {
        "Key": "OPENNLP-5",
        "Summary": "Create status page",
        "Type": "New Feature",
        "Status": "Closed",
        "Priority": "Major",
        "Resolution": "Fixed",
        "Affects Version/s": "None",
        "Fix Version/s": "None",
        "Component/s": "None",
        "Assignee": "Grant Ingersoll",
        "Reporter": "Thilo Goetz",
        "Created": "02/Dec/10 17:03",
        "Updated": "13/Dec/10 15:38",
        "Resolved": "13/Dec/10 15:38",
        "Description": null,
        "Issue Links": []
    },
    "OPENNLP-6": {
        "Key": "OPENNLP-6",
        "Summary": "Create a new OpenNLP project logo for the site",
        "Type": "Improvement",
        "Status": "Closed",
        "Priority": "Minor",
        "Resolution": "Fixed",
        "Affects Version/s": "None",
        "Fix Version/s": "1.8.0",
        "Component/s": "Website",
        "Assignee": "Bruno P. Kinoshita",
        "Reporter": "J\u00f6rn Kottmann",
        "Created": "02/Dec/10 23:01",
        "Updated": "05/May/17 22:43",
        "Resolved": "05/May/17 22:43",
        "Description": "The current logo was not changed for a long time (if ever). \nLets create a new fresh looking logo.",
        "Issue Links": [
            "/jira/browse/OPENNLP-999"
        ]
    },
    "OPENNLP-7": {
        "Key": "OPENNLP-7",
        "Summary": "Transfer the opennlp domains to Apache",
        "Type": "Task",
        "Status": "Closed",
        "Priority": "Minor",
        "Resolution": "Fixed",
        "Affects Version/s": "None",
        "Fix Version/s": "1.6.0",
        "Component/s": "Website",
        "Assignee": null,
        "Reporter": "J\u00f6rn Kottmann",
        "Created": "03/Dec/10 09:04",
        "Updated": "16/Jan/17 14:44",
        "Resolved": "16/Jan/17 14:44",
        "Description": "The following domains exist:\nopennlp.com\nopennlp.org\nThey are both owned by John Dowding.\nIt would be nice if these domains could be transfered\nto Apache one day.",
        "Issue Links": []
    },
    "OPENNLP-8": {
        "Key": "OPENNLP-8",
        "Summary": "SentenceDetectorME.getSentenceProbabilities() array is not always equal to number of returned sentences",
        "Type": "Bug",
        "Status": "Closed",
        "Priority": "Major",
        "Resolution": "Cannot Reproduce",
        "Affects Version/s": "tools-1.5.0-sourceforge",
        "Fix Version/s": "None",
        "Component/s": "Sentence Detector",
        "Assignee": "J\u00f6rn Kottmann",
        "Reporter": "J\u00f6rn Kottmann",
        "Created": "09/Dec/10 23:36",
        "Updated": "24/Jan/11 11:16",
        "Resolved": "24/Jan/11 11:16",
        "Description": "Miao Chen:\n\"The sentence detector returns me two sentences: \"2.1.4\" and \"About JAVA\npackage\" (which I can accept \nBut the getSentenceProbabilities() returns me only one probability (which is\n0.9924560093213692), and I don't know which \"sentence\" this probability is\nfor. This method is supposed to return an array of probabilities, but in\nthis case only one probability is returned.\"",
        "Issue Links": []
    },
    "OPENNLP-9": {
        "Key": "OPENNLP-9",
        "Summary": "Training name finder only with names fails",
        "Type": "Bug",
        "Status": "Closed",
        "Priority": "Major",
        "Resolution": "Fixed",
        "Affects Version/s": "tools-1.5.0-sourceforge",
        "Fix Version/s": "tools-1.5.1-incubating",
        "Component/s": "Name Finder",
        "Assignee": "William Colen",
        "Reporter": "J\u00f6rn Kottmann",
        "Created": "09/Dec/10 23:40",
        "Updated": "13/Jan/11 20:39",
        "Resolved": "15/Dec/10 17:56",
        "Description": "A. Allen:\n\"I followed the instructions\nin the wiki and used pieces of the sample code, but keep getting the\nfollowing:\nIndexing events using cutoff of 5\nComputing event counts...  done. 29376 events\nIndexing...  done.\nSorting and merging events... done. Reduced 29376 events to 8313.\nDone indexing.\nIncorporating indexed data for training...\ndone.\nNumber of Event Tokens: 8313\n    Number of Outcomes: 1\n  Number of Predicates: 11869\n...done.\nComputing model parameters...\nPerforming 100 iterations.\n  1:  .. loglikelihood=0.0 1.0\n  2:  .. loglikelihood=0.0 1.0\nException in thread \"main\" java.lang.IllegalArgumentException: Model not\ncompatible with name finder!\nat\nopennlp.tools.namefind.TokenNameFinderModel.<init>(TokenNameFinderModel.java:50)\nat opennlp.tools.namefind.NameFinderME.train(NameFinderME.java:350)\nat opennlp.tools.namefind.NameFinderME.train(NameFinderME.java:356)\nat NameTrainer.main(NameTrainer.java:21)\nMy training data looks like this:\n<START:person>Neil Abercrombie<END>\n<START:person>Anibal Acevedo-Vila<END>\n<START:person>Gary Ackerman<END>\n<START:person>Robert Aderholt<END>\n<START:person>Daniel Akaka<END>\n<START:person>Todd Akin<END>\n<START:person>Lamar Alexander<END>\n<START:person>Rodney Alexander<END>\n\"",
        "Issue Links": []
    },
    "OPENNLP-10": {
        "Key": "OPENNLP-10",
        "Summary": "Add incubator disclaimer to website, or remove notice if not necessary",
        "Type": "Improvement",
        "Status": "Closed",
        "Priority": "Major",
        "Resolution": "Fixed",
        "Affects Version/s": "tools-1.5.1-incubating",
        "Fix Version/s": "None",
        "Component/s": "Website",
        "Assignee": "James Kosin",
        "Reporter": "J\u00f6rn Kottmann",
        "Created": "13/Dec/10 17:58",
        "Updated": "16/Dec/10 23:43",
        "Resolved": "16/Dec/10 23:33",
        "Description": "The website has a \"fixme\" to add an incubator disclaimer. The disclaimer should be added to the website.",
        "Issue Links": []
    },
    "OPENNLP-11": {
        "Key": "OPENNLP-11",
        "Summary": "Add a small icon to links which point to external sites",
        "Type": "Improvement",
        "Status": "Closed",
        "Priority": "Minor",
        "Resolution": "Fixed",
        "Affects Version/s": "None",
        "Fix Version/s": "None",
        "Component/s": "Website",
        "Assignee": "James Kosin",
        "Reporter": "J\u00f6rn Kottmann",
        "Created": "13/Dec/10 18:04",
        "Updated": "22/Dec/10 09:37",
        "Resolved": "22/Dec/10 01:03",
        "Description": "The website contains links which point to external sites. These links should be marked with a small icon like its done over at pdfbox or uima.",
        "Issue Links": []
    },
    "OPENNLP-12": {
        "Key": "OPENNLP-12",
        "Summary": "Fix w3c validator warnings and errors",
        "Type": "Bug",
        "Status": "Closed",
        "Priority": "Minor",
        "Resolution": "Fixed",
        "Affects Version/s": "None",
        "Fix Version/s": "None",
        "Component/s": "Website",
        "Assignee": "J\u00f6rn Kottmann",
        "Reporter": "J\u00f6rn Kottmann",
        "Created": "13/Dec/10 18:29",
        "Updated": "13/Dec/10 19:15",
        "Resolved": "13/Dec/10 19:15",
        "Description": "All warnings and errors reported by the w3c validator should be fixed:\nhttp://validator.w3.org/",
        "Issue Links": []
    },
    "OPENNLP-13": {
        "Key": "OPENNLP-13",
        "Summary": "Write a website howto which explains how to change and publish it",
        "Type": "Improvement",
        "Status": "Closed",
        "Priority": "Minor",
        "Resolution": "Fixed",
        "Affects Version/s": "None",
        "Fix Version/s": "None",
        "Component/s": "Website",
        "Assignee": null,
        "Reporter": "J\u00f6rn Kottmann",
        "Created": "13/Dec/10 19:37",
        "Updated": "21/Jan/11 15:29",
        "Resolved": "21/Jan/11 15:29",
        "Description": "Write a howto which describes how to update and publish the website.\nIt should at least contain the following:\n\nLinks to markdown reference docs, and tutorials\nLinks to the w3c validators\nA step by step rule list how to do changes",
        "Issue Links": []
    },
    "OPENNLP-14": {
        "Key": "OPENNLP-14",
        "Summary": "Apache License Text",
        "Type": "Improvement",
        "Status": "Closed",
        "Priority": "Trivial",
        "Resolution": "Fixed",
        "Affects Version/s": "None",
        "Fix Version/s": "None",
        "Component/s": "Website",
        "Assignee": null,
        "Reporter": "James Kosin",
        "Created": "14/Dec/10 02:40",
        "Updated": "13/Jan/11 20:38",
        "Resolved": "14/Dec/10 03:42",
        "Description": "Is there an easy way to get the license text as .html so we can bring into the website, instead of displaying the plain text of the license?",
        "Issue Links": []
    },
    "OPENNLP-15": {
        "Key": "OPENNLP-15",
        "Summary": "Add support for the CoNLL 03 data format",
        "Type": "Improvement",
        "Status": "Closed",
        "Priority": "Major",
        "Resolution": "Fixed",
        "Affects Version/s": "tools-1.5.0-sourceforge",
        "Fix Version/s": "tools-1.5.1-incubating",
        "Component/s": "Name Finder",
        "Assignee": "J\u00f6rn Kottmann",
        "Reporter": "J\u00f6rn Kottmann",
        "Created": "14/Dec/10 10:42",
        "Updated": "12/Jan/11 14:25",
        "Resolved": "12/Jan/11 14:25",
        "Description": "Adding support to convert CoNLL 03 Reurters Support to NameFinder.\nWork on this issue began over at sourceforge:\nhttp://sourceforge.net/tracker/?func=detail&aid=3081785&group_id=3368&atid=353368",
        "Issue Links": []
    },
    "OPENNLP-16": {
        "Key": "OPENNLP-16",
        "Summary": "BeamSearch class is missing a junit test",
        "Type": "Improvement",
        "Status": "Closed",
        "Priority": "Major",
        "Resolution": "Fixed",
        "Affects Version/s": "tools-1.5.0-sourceforge",
        "Fix Version/s": "tools-1.5.2-incubating",
        "Component/s": "Build, Packaging and Test",
        "Assignee": "J\u00f6rn Kottmann",
        "Reporter": "J\u00f6rn Kottmann",
        "Created": "14/Dec/10 10:49",
        "Updated": "08/Aug/11 13:55",
        "Resolved": "08/Aug/11 13:55",
        "Description": "BeamFinder is missing a test class to make sure any modifications don't disturb the functionality of the classes that use this important class.\nIssues is migrated from SourceForge:\nhttps://sourceforge.net/tracker/?func=detail&aid=3044654&group_id=3368&atid=103368",
        "Issue Links": []
    },
    "OPENNLP-17": {
        "Key": "OPENNLP-17",
        "Summary": "Add support for custom feature generator configuration embedded in the model package",
        "Type": "Improvement",
        "Status": "Closed",
        "Priority": "Major",
        "Resolution": "Fixed",
        "Affects Version/s": "tools-1.5.0-sourceforge",
        "Fix Version/s": "tools-1.5.2-incubating",
        "Component/s": "Chunker,                                            Name Finder,                                            POS Tagger",
        "Assignee": "J\u00f6rn Kottmann",
        "Reporter": "J\u00f6rn Kottmann",
        "Created": "14/Dec/10 11:12",
        "Updated": "02/May/13 02:29",
        "Resolved": "31/May/11 13:37",
        "Description": "Add support for custom feature generator configuration embedded in the model package.\nThe configuration of the feature generators for the name finder component can be quite complex and the configuration must\nbe always done twice once for training and once for tagging. Doing it twice at two different points in time makes\nthe feature generation very error prone. Small mistakes lead to a drop in detection performance which might\nbe difficult to notice. \nTo solve this issue add the configuration to the model, then it must only be specified during training and\ncan be loaded from the model during tagging.\nAnother advantage is that custom feature generation is difficult to use otherwise, because the integration\ncode must deal itself with setting up the feature generators. In some cases the user even does not have control\nover the code, or does not want to change it, e.g. in the UIMA wrappers.\nThe same logic should be used for the POS Tagger and Chunker.\nThe issues is migrated from SourceForge:\nhttps://sourceforge.net/tracker/?func=detail&aid=1941380&group_id=3368&atid=353368",
        "Issue Links": [
            "/jira/browse/OPENNLP-78"
        ]
    },
    "OPENNLP-18": {
        "Key": "OPENNLP-18",
        "Summary": "Make the License and Notice files comply with Apache rules.",
        "Type": "Improvement",
        "Status": "Closed",
        "Priority": "Major",
        "Resolution": "Fixed",
        "Affects Version/s": "None",
        "Fix Version/s": "tools-1.5.1-incubating",
        "Component/s": "None",
        "Assignee": "Thilo Goetz",
        "Reporter": "J\u00f6rn Kottmann",
        "Created": "14/Dec/10 16:34",
        "Updated": "25/Jan/11 12:02",
        "Resolved": "21/Jan/11 10:57",
        "Description": "All released files which are shipped need to contain LICENSE and NOTICE files.\nOpenNLP will ship the following files:\n\nA binary distribution containing all jars, documentation, etc.\nA source distribution, basically an svn extract\nJar files via the incubator maven repository\n\nThe binary distribution additionally contains the JWNL library which\nis licensed under BSD. The BSD License must be contained in the LICENSE\nfile for the binary distribution. JWNLdoes not has to be mentioned in the\nNOTICE file sind the JWNL distribution does not contain such a Notice file.\nDepending on how the statistical models will be distributed we need to\nput LICENSE and NOTICE files in this distribution also, but that is not covered by\nthis jira issue.",
        "Issue Links": []
    },
    "OPENNLP-19": {
        "Key": "OPENNLP-19",
        "Summary": "Refactor the build and align it with the apache way of building",
        "Type": "Improvement",
        "Status": "Closed",
        "Priority": "Major",
        "Resolution": "Fixed",
        "Affects Version/s": "None",
        "Fix Version/s": "None",
        "Component/s": "Build, Packaging and Test",
        "Assignee": "J\u00f6rn Kottmann",
        "Reporter": "J\u00f6rn Kottmann",
        "Created": "14/Dec/10 16:37",
        "Updated": "21/Jan/11 11:22",
        "Resolved": "21/Jan/11 11:22",
        "Description": "The build should be refactored. There should be one parent pom which can be used to build\nall OpenNLP projects. Details still have to be discussed.\nThe build files still contain all the SourceForge references, these should be removed and replaced\nwith the new Apache references.\nAlso remove the old ant build from maxent.",
        "Issue Links": [
            "/jira/browse/OPENNLP-52"
        ]
    },
    "OPENNLP-20": {
        "Key": "OPENNLP-20",
        "Summary": "Remove old website and documentation from maxent and opennlp projects",
        "Type": "Improvement",
        "Status": "Closed",
        "Priority": "Minor",
        "Resolution": "Fixed",
        "Affects Version/s": "None",
        "Fix Version/s": "tools-1.5.1-incubating,                                            maxent-3.0.1-incubating",
        "Component/s": "None",
        "Assignee": null,
        "Reporter": "J\u00f6rn Kottmann",
        "Created": "14/Dec/10 16:44",
        "Updated": "13/Jan/11 20:45",
        "Resolved": "13/Jan/11 20:45",
        "Description": "The websites inside the maxent and tools project should be removed, also all the old README files containing\ndocumentation.",
        "Issue Links": []
    },
    "OPENNLP-21": {
        "Key": "OPENNLP-21",
        "Summary": "Cleanup: Fix javadoc warnings in opennlp-tools project",
        "Type": "Improvement",
        "Status": "Closed",
        "Priority": "Minor",
        "Resolution": "Fixed",
        "Affects Version/s": "None",
        "Fix Version/s": "tools-1.5.2-incubating",
        "Component/s": "None",
        "Assignee": "J\u00f6rn Kottmann",
        "Reporter": "J\u00f6rn Kottmann",
        "Created": "14/Dec/10 16:46",
        "Updated": "25/May/11 09:42",
        "Resolved": "25/May/11 09:42",
        "Description": "There are a couple of javadoc warnings in the opennlp-tools project, fix these.",
        "Issue Links": []
    },
    "OPENNLP-22": {
        "Key": "OPENNLP-22",
        "Summary": "Cleanup: Remove author names from source code",
        "Type": "Improvement",
        "Status": "Closed",
        "Priority": "Major",
        "Resolution": "Fixed",
        "Affects Version/s": "None",
        "Fix Version/s": "None",
        "Component/s": "None",
        "Assignee": "J\u00f6rn Kottmann",
        "Reporter": "J\u00f6rn Kottmann",
        "Created": "14/Dec/10 16:48",
        "Updated": "16/Dec/10 20:35",
        "Resolved": "16/Dec/10 16:52",
        "Description": "Author mentions imply individual ownership but we strive for community ownership. The author mentions are also not accurate because files are maintained by others than the author also. The author is still tracked in jira and of course svn.",
        "Issue Links": []
    },
    "OPENNLP-23": {
        "Key": "OPENNLP-23",
        "Summary": "Add a code conventions page to the website",
        "Type": "Improvement",
        "Status": "Closed",
        "Priority": "Major",
        "Resolution": "Fixed",
        "Affects Version/s": "None",
        "Fix Version/s": "None",
        "Component/s": "Website",
        "Assignee": "J\u00f6rn Kottmann",
        "Reporter": "J\u00f6rn Kottmann",
        "Created": "14/Dec/10 16:50",
        "Updated": "21/Nov/11 15:30",
        "Resolved": "21/Nov/11 15:30",
        "Description": "There should be a short page explaining the OpenNLP code conventions and offering downloads for format files which can be used by the major IDEs.",
        "Issue Links": []
    },
    "OPENNLP-24": {
        "Key": "OPENNLP-24",
        "Summary": "Cleanup: Reformat code to comply with code conventions",
        "Type": "Improvement",
        "Status": "Closed",
        "Priority": "Major",
        "Resolution": "Fixed",
        "Affects Version/s": "None",
        "Fix Version/s": "None",
        "Component/s": "None",
        "Assignee": "J\u00f6rn Kottmann",
        "Reporter": "J\u00f6rn Kottmann",
        "Created": "14/Dec/10 16:53",
        "Updated": "25/Jan/11 15:13",
        "Resolved": "25/Jan/11 15:13",
        "Description": "Some parts of OpenNLP code do not comply at all with the conventions, these parts should be reformatted. Other parts are optional.",
        "Issue Links": []
    },
    "OPENNLP-25": {
        "Key": "OPENNLP-25",
        "Summary": "Add a news section to the website",
        "Type": "Improvement",
        "Status": "Closed",
        "Priority": "Major",
        "Resolution": "Fixed",
        "Affects Version/s": "None",
        "Fix Version/s": "None",
        "Component/s": "Website",
        "Assignee": "James Kosin",
        "Reporter": "J\u00f6rn Kottmann",
        "Created": "14/Dec/10 16:55",
        "Updated": "17/Dec/10 00:24",
        "Resolved": "17/Dec/10 00:05",
        "Description": "Add a news section to the website where we can report project news.",
        "Issue Links": []
    },
    "OPENNLP-26": {
        "Key": "OPENNLP-26",
        "Summary": "Improve the description of the mailing lists on the website",
        "Type": "Improvement",
        "Status": "Closed",
        "Priority": "Major",
        "Resolution": "Fixed",
        "Affects Version/s": "None",
        "Fix Version/s": "None",
        "Component/s": "Website",
        "Assignee": "James Kosin",
        "Reporter": "J\u00f6rn Kottmann",
        "Created": "14/Dec/10 16:58",
        "Updated": "22/Dec/10 09:38",
        "Resolved": "22/Dec/10 01:01",
        "Description": "Explain the Mailing Lists in more detail. It should point out the difference between user and dev.\nIt should mention the commit list.  And there should be a pointer to the ML archives.",
        "Issue Links": []
    },
    "OPENNLP-27": {
        "Key": "OPENNLP-27",
        "Summary": "Add an overview site about what the various components can do",
        "Type": "Improvement",
        "Status": "Closed",
        "Priority": "Major",
        "Resolution": "Won't Fix",
        "Affects Version/s": "None",
        "Fix Version/s": "None",
        "Component/s": "Website",
        "Assignee": null,
        "Reporter": "J\u00f6rn Kottmann",
        "Created": "14/Dec/10 17:02",
        "Updated": "16/Jan/17 14:56",
        "Resolved": "16/Jan/17 14:56",
        "Description": "The website should have an overview page which explains in detail and with samples\nthe NLP tasks OpenNLP can solve. \nE.g. what is Named Entity Recognition ?",
        "Issue Links": []
    },
    "OPENNLP-28": {
        "Key": "OPENNLP-28",
        "Summary": "Add checkout instructions to the source code site",
        "Type": "Improvement",
        "Status": "Closed",
        "Priority": "Major",
        "Resolution": "Fixed",
        "Affects Version/s": "None",
        "Fix Version/s": "None",
        "Component/s": "Website",
        "Assignee": "James Kosin",
        "Reporter": "J\u00f6rn Kottmann",
        "Created": "14/Dec/10 17:04",
        "Updated": "29/Dec/10 16:13",
        "Resolved": "29/Dec/10 16:13",
        "Description": "The source code page was created before the code was actually imported. The code is now in the\nrepo and the source code page should be updated to explain how to check out the code.",
        "Issue Links": []
    },
    "OPENNLP-29": {
        "Key": "OPENNLP-29",
        "Summary": "Add multi threading support to GIS training",
        "Type": "Improvement",
        "Status": "Closed",
        "Priority": "Major",
        "Resolution": "Fixed",
        "Affects Version/s": "None",
        "Fix Version/s": "tools-1.5.2-incubating,                                            maxent-3.0.2-incubating",
        "Component/s": "Machine Learning",
        "Assignee": "J\u00f6rn Kottmann",
        "Reporter": "J\u00f6rn Kottmann",
        "Created": "14/Dec/10 17:08",
        "Updated": "23/May/11 14:12",
        "Resolved": "23/May/11 14:12",
        "Description": "The GIS training is famous for taking quite some time to finish. Now days CPUs have many cores. \nThe training algorithm should be updated to use multiple CPU cores to perform the training.\nThere are various approaches to solve this tasks, we will document them in the wiki and\ndiscuss them on the mailing list.",
        "Issue Links": [
            "/jira/browse/OPENNLP-39"
        ]
    },
    "OPENNLP-30": {
        "Key": "OPENNLP-30",
        "Summary": "Add evaluation support to chunker component",
        "Type": "Improvement",
        "Status": "Closed",
        "Priority": "Major",
        "Resolution": "Fixed",
        "Affects Version/s": "None",
        "Fix Version/s": "tools-1.5.1-incubating",
        "Component/s": "Chunker",
        "Assignee": "William Colen",
        "Reporter": "J\u00f6rn Kottmann",
        "Created": "14/Dec/10 17:11",
        "Updated": "21/Jan/11 10:49",
        "Resolved": "19/Jan/11 12:41",
        "Description": "Add support for evaluating the tagging performance of the chunker.",
        "Issue Links": []
    },
    "OPENNLP-31": {
        "Key": "OPENNLP-31",
        "Summary": "Add evaluation support to the parser component",
        "Type": "Improvement",
        "Status": "Closed",
        "Priority": "Major",
        "Resolution": "Fixed",
        "Affects Version/s": "None",
        "Fix Version/s": "1.6.0",
        "Component/s": "Parser",
        "Assignee": "Rodrigo Agerri",
        "Reporter": "J\u00f6rn Kottmann",
        "Created": "14/Dec/10 17:14",
        "Updated": "12/May/14 12:49",
        "Resolved": "12/May/14 12:49",
        "Description": "Add support for evaluating the tagging performance of the parser.\nIssues is migrated from SourceForge:\nhttps://sourceforge.net/tracker/?func=detail&aid=2557289&group_id=3368&atid=353368",
        "Issue Links": []
    },
    "OPENNLP-32": {
        "Key": "OPENNLP-32",
        "Summary": "Write more documentation for the parser",
        "Type": "Improvement",
        "Status": "Closed",
        "Priority": "Major",
        "Resolution": "Fixed",
        "Affects Version/s": "None",
        "Fix Version/s": "1.9.3",
        "Component/s": "Documentation",
        "Assignee": "Suneel Marthi",
        "Reporter": "J\u00f6rn Kottmann",
        "Created": "14/Dec/10 17:16",
        "Updated": "25/Jan/20 00:33",
        "Resolved": "25/Jan/20 00:33",
        "Description": "Write more documentation for the parser. It should cover the same topic as the\ndocumentation for the other components. \nThe following sections are still missing:\n\nNo general introduction, it should be explained what parsing is, ideally with a few images\n  of parse trees\nExplain how to navigate in the parse tree with the Parse class, that should be\n  explained based on a sample parse tree \nAdd a section about how the training api can be used\nRemove all todos, and open jira issues for them if they are not solved with this issue",
        "Issue Links": [
            "https://github.com/apache/opennlp/pull/359"
        ]
    },
    "OPENNLP-33": {
        "Key": "OPENNLP-33",
        "Summary": "Write documentation for the document categorizer component",
        "Type": "Improvement",
        "Status": "Closed",
        "Priority": "Major",
        "Resolution": "Fixed",
        "Affects Version/s": "None",
        "Fix Version/s": "tools-1.5.2-incubating",
        "Component/s": "Documentation",
        "Assignee": "J\u00f6rn Kottmann",
        "Reporter": "J\u00f6rn Kottmann",
        "Created": "14/Dec/10 17:18",
        "Updated": "23/May/11 13:26",
        "Resolved": "23/May/11 13:26",
        "Description": "Write initial documentation for the document categorizer component.\nThe issue is migrated from SourceForge:\nhttps://sourceforge.net/tracker/?func=detail&aid=3028436&group_id=3368&atid=103368",
        "Issue Links": []
    },
    "OPENNLP-34": {
        "Key": "OPENNLP-34",
        "Summary": "Create a tool to Create a namefinder Dictionary",
        "Type": "Improvement",
        "Status": "Closed",
        "Priority": "Major",
        "Resolution": "Fixed",
        "Affects Version/s": "None",
        "Fix Version/s": "tools-1.5.0-sourceforge",
        "Component/s": "Name Finder",
        "Assignee": "James Kosin",
        "Reporter": "J\u00f6rn Kottmann",
        "Created": "14/Dec/10 17:20",
        "Updated": "16/Dec/10 09:48",
        "Resolved": "16/Dec/10 09:48",
        "Description": "I'm in the process of creating a tool to help create a name-finder dictionary to help the dictionary name finder. Without a dictionary, the name-finder seems a bit light to just popular names and may get confused with less popular names.\nI'm hoping this will help.\nMore to come or even comments are welcome here.\nIssue is migrated from SourceForge:\nhttps://sourceforge.net/tracker/?func=detail&aid=3030336&group_id=3368&atid=103368",
        "Issue Links": []
    },
    "OPENNLP-35": {
        "Key": "OPENNLP-35",
        "Summary": "UIMA Name Finder Trainer needs cutoff and iterations params",
        "Type": "Improvement",
        "Status": "Closed",
        "Priority": "Major",
        "Resolution": "Won't Fix",
        "Affects Version/s": "None",
        "Fix Version/s": "None",
        "Component/s": "UIMA Integration",
        "Assignee": null,
        "Reporter": "J\u00f6rn Kottmann",
        "Created": "14/Dec/10 17:23",
        "Updated": "07/Jul/11 08:35",
        "Resolved": "07/Jul/11 08:35",
        "Description": "The Name Finder Trainer Uima Integration should have a parameter to set the cutoff and iterations parameter.",
        "Issue Links": []
    },
    "OPENNLP-36": {
        "Key": "OPENNLP-36",
        "Summary": "Refactor the coreference package",
        "Type": "Improvement",
        "Status": "Closed",
        "Priority": "Major",
        "Resolution": "Won't Fix",
        "Affects Version/s": "None",
        "Fix Version/s": "None",
        "Component/s": "Coref",
        "Assignee": null,
        "Reporter": "J\u00f6rn Kottmann",
        "Created": "14/Dec/10 17:28",
        "Updated": "16/Jan/17 14:33",
        "Resolved": "16/Jan/17 14:33",
        "Description": "The coref package should be re-factored and aligned with the approches taken for the other components.\nThis issue is just an umbrella to link all coref refactoring issues together.",
        "Issue Links": [
            "/jira/browse/OPENNLP-37",
            "/jira/browse/OPENNLP-48",
            "/jira/browse/OPENNLP-55",
            "/jira/browse/OPENNLP-56",
            "/jira/browse/OPENNLP-54"
        ]
    },
    "OPENNLP-37": {
        "Key": "OPENNLP-37",
        "Summary": "Add evaluation support to the coref component",
        "Type": "Improvement",
        "Status": "Closed",
        "Priority": "Major",
        "Resolution": "Won't Fix",
        "Affects Version/s": "None",
        "Fix Version/s": "None",
        "Component/s": "Coref",
        "Assignee": null,
        "Reporter": "J\u00f6rn Kottmann",
        "Created": "14/Dec/10 17:29",
        "Updated": "16/Jan/17 14:33",
        "Resolved": "16/Jan/17 14:33",
        "Description": "Add support for evaluating the performance of the coreference resolution component.",
        "Issue Links": [
            "/jira/browse/OPENNLP-36"
        ]
    },
    "OPENNLP-38": {
        "Key": "OPENNLP-38",
        "Summary": "ClassCastException when Perceptron model is serialized",
        "Type": "Bug",
        "Status": "Closed",
        "Priority": "Major",
        "Resolution": "Fixed",
        "Affects Version/s": "maxent-3.0.0-sourceforge",
        "Fix Version/s": "maxent-3.0.1-incubating",
        "Component/s": "Machine Learning",
        "Assignee": "J\u00f6rn Kottmann",
        "Reporter": "J\u00f6rn Kottmann",
        "Created": "14/Dec/10 17:34",
        "Updated": "14/Dec/10 17:35",
        "Resolved": "14/Dec/10 17:35",
        "Description": "Saving a perceptron model fails with a class cast exception in the PerceptronModelWriter, because the map is now an IndexHashTable instead of a java.util.HashMap.\nIssue is migrated from SourceForge:\nhttps://sourceforge.net/tracker/?func=detail&aid=3077040&group_id=5961&atid=105961",
        "Issue Links": []
    },
    "OPENNLP-39": {
        "Key": "OPENNLP-39",
        "Summary": "Refactor the maxent package",
        "Type": "Improvement",
        "Status": "Closed",
        "Priority": "Major",
        "Resolution": "Fixed",
        "Affects Version/s": "None",
        "Fix Version/s": "1.6.0",
        "Component/s": "Machine Learning",
        "Assignee": null,
        "Reporter": "J\u00f6rn Kottmann",
        "Created": "14/Dec/10 17:39",
        "Updated": "13/Feb/14 22:39",
        "Resolved": "13/Feb/14 22:39",
        "Description": "The maxent package did not received any\nbigger maintenance or refactoring in the last years.\nQuite a few things queued up and should be done now\nin a single refactoring together with a small redesign.\nThis issue is just an umbrella issue to track the status of the\nrefactoring effort.",
        "Issue Links": [
            "/jira/browse/OPENNLP-29",
            "/jira/browse/OPENNLP-118",
            "/jira/browse/OPENNLP-119",
            "/jira/browse/OPENNLP-120",
            "/jira/browse/OPENNLP-165"
        ]
    },
    "OPENNLP-40": {
        "Key": "OPENNLP-40",
        "Summary": "Java compatibility level should be 1.5",
        "Type": "Bug",
        "Status": "Closed",
        "Priority": "Major",
        "Resolution": "Fixed",
        "Affects Version/s": "tools-1.5.1-incubating,                                            maxent-3.0.1-incubating",
        "Fix Version/s": "tools-1.5.1-incubating",
        "Component/s": "Build, Packaging and Test",
        "Assignee": "William Colen",
        "Reporter": "William Colen",
        "Created": "15/Dec/10 13:14",
        "Updated": "09/Feb/11 20:51",
        "Resolved": "15/Dec/10 18:42",
        "Description": "Some code is not compatible with Java 1.5 and we should keep the Java compatibility level to 1.5. Need to fix the code and enforce the compatibility level validation at build time.",
        "Issue Links": []
    },
    "OPENNLP-41": {
        "Key": "OPENNLP-41",
        "Summary": "Unit test ArgumentParserTest.testSimpleArgumentsUsage can ocasionally fail",
        "Type": "Bug",
        "Status": "Closed",
        "Priority": "Major",
        "Resolution": "Fixed",
        "Affects Version/s": "tools-1.5.1-incubating",
        "Fix Version/s": "tools-1.5.1-incubating",
        "Component/s": "Build, Packaging and Test",
        "Assignee": "J\u00f6rn Kottmann",
        "Reporter": "William Colen",
        "Created": "15/Dec/10 23:46",
        "Updated": "24/Jan/11 14:10",
        "Resolved": "24/Jan/11 10:54",
        "Description": "The test opennlp.tools.cmdline.ArgumentParserTest.testSimpleArgumentsUsage() is failing here. Is it happening to anyone else?\nI checked the ArgumentParser class. The method createUsage(Class<T> argProxyInterface) works by getting the methods of the argProxyInterface class using the getMethods() method.\nThe javadoc of getMethods() method says: \"... The elements in the array returned are not sorted and are not in any particular order. ...\".\nSo we can't expect the usage string to be the same to everybody. To me it is \"[-iterations num] [-alphaNumOpt true|false] -encoding charset\", but the expected is \"-encoding charset [-iterations num] [-alphaNumOpt true|false]\", so my build fails.",
        "Issue Links": []
    },
    "OPENNLP-42": {
        "Key": "OPENNLP-10 Add incubator disclaimer to website, or remove notice if not necessary",
        "Summary": "Sponsor Name Needed",
        "Type": "Sub-task",
        "Status": "Closed",
        "Priority": "Minor",
        "Resolution": "Fixed",
        "Affects Version/s": "None",
        "Fix Version/s": "None",
        "Component/s": "Website",
        "Assignee": "James Kosin",
        "Reporter": "James Kosin",
        "Created": "16/Dec/10 01:12",
        "Updated": "16/Dec/10 23:28",
        "Resolved": "16/Dec/10 23:28",
        "Description": "The Incubator Disclaimer requires a sponsor name?\nWhat name or names do I use?",
        "Issue Links": [
            "/jira/browse/OPENNLP-43"
        ]
    },
    "OPENNLP-43": {
        "Key": "OPENNLP-10 Add incubator disclaimer to website, or remove notice if not necessary",
        "Summary": "Add Incubator Diclaimer Text",
        "Type": "Sub-task",
        "Status": "Closed",
        "Priority": "Minor",
        "Resolution": "Fixed",
        "Affects Version/s": "None",
        "Fix Version/s": "None",
        "Component/s": "Website",
        "Assignee": "James Kosin",
        "Reporter": "James Kosin",
        "Created": "16/Dec/10 01:14",
        "Updated": "16/Dec/10 23:32",
        "Resolved": "16/Dec/10 23:32",
        "Description": "Incorporate the required disclaimer to the web-site.",
        "Issue Links": [
            "/jira/browse/OPENNLP-42"
        ]
    },
    "OPENNLP-44": {
        "Key": "OPENNLP-44",
        "Summary": "Add an bin/opennlp.bat start file for windows users",
        "Type": "Improvement",
        "Status": "Closed",
        "Priority": "Major",
        "Resolution": "Fixed",
        "Affects Version/s": "None",
        "Fix Version/s": "tools-1.5.1-incubating",
        "Component/s": "Command Line Interface",
        "Assignee": "James Kosin",
        "Reporter": "J\u00f6rn Kottmann",
        "Created": "16/Dec/10 21:44",
        "Updated": "26/Jan/11 00:34",
        "Resolved": "26/Jan/11 00:33",
        "Description": "There should be an opennlp.bat file to start opennlp the same way on windows \nas the \"bin/opennlp\" shell script on unix like systems does.",
        "Issue Links": []
    },
    "OPENNLP-45": {
        "Key": "OPENNLP-45",
        "Summary": "Convert the documentation to docbook",
        "Type": "Improvement",
        "Status": "Closed",
        "Priority": "Major",
        "Resolution": "Fixed",
        "Affects Version/s": "None",
        "Fix Version/s": "tools-1.5.1-incubating",
        "Component/s": "Documentation",
        "Assignee": "J\u00f6rn Kottmann",
        "Reporter": "J\u00f6rn Kottmann",
        "Created": "20/Dec/10 22:39",
        "Updated": "13/Jan/11 18:15",
        "Resolved": "13/Jan/11 18:15",
        "Description": "The documentation previously hosted in the wiki should be converted into a docbook which\ncan be automatically included in the distribution and published on our website.",
        "Issue Links": []
    },
    "OPENNLP-46": {
        "Key": "OPENNLP-46",
        "Summary": "Write documentation for the CONLL02 converter",
        "Type": "Improvement",
        "Status": "Closed",
        "Priority": "Major",
        "Resolution": "Fixed",
        "Affects Version/s": "None",
        "Fix Version/s": "tools-1.5.3",
        "Component/s": "Documentation",
        "Assignee": "J\u00f6rn Kottmann",
        "Reporter": "J\u00f6rn Kottmann",
        "Created": "20/Dec/10 23:47",
        "Updated": "05/Jul/12 17:02",
        "Resolved": "05/Jul/12 17:02",
        "Description": "It should be documented how the converter for the CONLL02 data can be used,\nand where the data can be retrieved.",
        "Issue Links": []
    },
    "OPENNLP-47": {
        "Key": "OPENNLP-47",
        "Summary": "Rewrite the CONLL06 documentation based on the tutorial",
        "Type": "Improvement",
        "Status": "Open",
        "Priority": "Major",
        "Resolution": "Unresolved",
        "Affects Version/s": "tools-1.5.1-incubating",
        "Fix Version/s": "None",
        "Component/s": "Documentation",
        "Assignee": null,
        "Reporter": "J\u00f6rn Kottmann",
        "Created": "21/Dec/10 00:36",
        "Updated": "21/Jun/18 11:57",
        "Resolved": null,
        "Description": "The CONLL06 documentation should be rewritten the reflect the new converters\nwhich have been added to OpenNLP after its initial write.",
        "Issue Links": []
    },
    "OPENNLP-48": {
        "Key": "OPENNLP-48",
        "Summary": "Write documentation for the coreference component",
        "Type": "Improvement",
        "Status": "Closed",
        "Priority": "Major",
        "Resolution": "Won't Fix",
        "Affects Version/s": "None",
        "Fix Version/s": "None",
        "Component/s": "Documentation",
        "Assignee": null,
        "Reporter": "J\u00f6rn Kottmann",
        "Created": "21/Dec/10 00:38",
        "Updated": "16/Jan/17 14:38",
        "Resolved": "16/Jan/17 14:38",
        "Description": "As part of the coref refactoring documentation should be written which explains\nhow to use and train the coreference component.",
        "Issue Links": [
            "/jira/browse/OPENNLP-36"
        ]
    },
    "OPENNLP-49": {
        "Key": "OPENNLP-49",
        "Summary": "Write documentation for the uima integration",
        "Type": "Improvement",
        "Status": "Open",
        "Priority": "Major",
        "Resolution": "Unresolved",
        "Affects Version/s": "None",
        "Fix Version/s": "None",
        "Component/s": "Documentation,                                            UIMA Integration",
        "Assignee": null,
        "Reporter": "J\u00f6rn Kottmann",
        "Created": "21/Dec/10 13:57",
        "Updated": "16/Jan/17 15:02",
        "Resolved": null,
        "Description": "There should be some documentation which explains how to use the uima integration.",
        "Issue Links": []
    },
    "OPENNLP-50": {
        "Key": "OPENNLP-50",
        "Summary": "Add build instructions to the website",
        "Type": "Improvement",
        "Status": "Closed",
        "Priority": "Major",
        "Resolution": "Fixed",
        "Affects Version/s": "None",
        "Fix Version/s": "None",
        "Component/s": "Website",
        "Assignee": "J\u00f6rn Kottmann",
        "Reporter": "J\u00f6rn Kottmann",
        "Created": "21/Dec/10 13:59",
        "Updated": "02/Feb/11 19:05",
        "Resolved": "02/Feb/11 19:05",
        "Description": "The website should contain a page in the Developer section which explains\nhow to build OpenNLP from source.",
        "Issue Links": []
    },
    "OPENNLP-51": {
        "Key": "OPENNLP-51",
        "Summary": "Add a language detection analysis engine based on doccat",
        "Type": "Improvement",
        "Status": "Closed",
        "Priority": "Minor",
        "Resolution": "Fixed",
        "Affects Version/s": "None",
        "Fix Version/s": "tools-1.5.1-incubating",
        "Component/s": "UIMA Integration",
        "Assignee": "J\u00f6rn Kottmann",
        "Reporter": "J\u00f6rn Kottmann",
        "Created": "21/Dec/10 14:07",
        "Updated": "27/Jan/11 13:26",
        "Resolved": "27/Jan/11 13:26",
        "Description": "Every CAS View in UIMA has a language field, there should be a special doccat based analylsis\nengine which can assign the output of doccat to this language field.",
        "Issue Links": []
    },
    "OPENNLP-52": {
        "Key": "OPENNLP-52",
        "Summary": "Missing main POM.xml file for projects",
        "Type": "Bug",
        "Status": "Closed",
        "Priority": "Major",
        "Resolution": "Fixed",
        "Affects Version/s": "tools-1.5.1-incubating,                                            maxent-3.0.1-incubating",
        "Fix Version/s": "None",
        "Component/s": "Build, Packaging and Test",
        "Assignee": "J\u00f6rn Kottmann",
        "Reporter": "James Kosin",
        "Created": "22/Dec/10 01:34",
        "Updated": "22/Dec/10 09:24",
        "Resolved": "22/Dec/10 09:24",
        "Description": "The main ..\\opennlp\\pom.xml file seems to be devorced from the source tree in trunk.\nI'm not sure if this is by design.  If so, this bug may be ignored.  I had to fix for NetBeans by checking out the incubator/opennlp/opennlp branch into the current source tree area on my system to fix the issue.\nJames",
        "Issue Links": [
            "/jira/browse/OPENNLP-19"
        ]
    },
    "OPENNLP-53": {
        "Key": "OPENNLP-53",
        "Summary": "Parser should have simple interface to process a tokenized input sentence",
        "Type": "Improvement",
        "Status": "Open",
        "Priority": "Major",
        "Resolution": "Unresolved",
        "Affects Version/s": "None",
        "Fix Version/s": "None",
        "Component/s": "Parser",
        "Assignee": null,
        "Reporter": "J\u00f6rn Kottmann",
        "Created": "22/Dec/10 10:04",
        "Updated": "20/Jan/11 21:26",
        "Resolved": null,
        "Description": "The parser expects a tokenized sentence as input, but currently it must be converted to a string where each\ntoken is separated by a white space.\nThis interface turned out to be inconvenient if the input if the input sentence is\nprovided as a list of strings or a string with a token span list. In both case\na new string must be created. In this new string the offsets of the individual tokens\nmust be remember in order to retrieve the parse tree out of the Parse objects.\nCreate a more convenient way of interacting with an already tokenized sentence which\nis not in a whitespace separated format.",
        "Issue Links": [
            "/jira/browse/OPENNLP-71"
        ]
    },
    "OPENNLP-54": {
        "Key": "OPENNLP-54",
        "Summary": "Identify a corpus the coref package could be trained on for regression testing",
        "Type": "Question",
        "Status": "Closed",
        "Priority": "Major",
        "Resolution": "Fixed",
        "Affects Version/s": "None",
        "Fix Version/s": "None",
        "Component/s": "Coref",
        "Assignee": null,
        "Reporter": "J\u00f6rn Kottmann",
        "Created": "22/Dec/10 10:12",
        "Updated": "07/Jul/11 08:34",
        "Resolved": "07/Jul/11 08:34",
        "Description": "We have to find a corpus where the coref package can be trained on for regression testing which is\npublic or could be at least made available to all committers.\nThis issue should also log on which corpus the coref package was trained on previously.",
        "Issue Links": [
            "/jira/browse/OPENNLP-36"
        ]
    },
    "OPENNLP-55": {
        "Key": "OPENNLP-55",
        "Summary": "Make a zip model package to group all coref models",
        "Type": "Improvement",
        "Status": "Closed",
        "Priority": "Major",
        "Resolution": "Won't Fix",
        "Affects Version/s": "None",
        "Fix Version/s": "None",
        "Component/s": "Coref",
        "Assignee": null,
        "Reporter": "J\u00f6rn Kottmann",
        "Created": "22/Dec/10 10:15",
        "Updated": "16/Jan/17 14:32",
        "Resolved": "16/Jan/17 14:32",
        "Description": "It should be possible to initialize the coref component from one model package instead\nof all these individual models. \nFinish the work on the coref model package which was started over at SourceForge.",
        "Issue Links": [
            "/jira/browse/OPENNLP-36"
        ]
    },
    "OPENNLP-56": {
        "Key": "OPENNLP-56",
        "Summary": "Define and implement a training file format for the coref component",
        "Type": "Improvement",
        "Status": "Closed",
        "Priority": "Major",
        "Resolution": "Won't Fix",
        "Affects Version/s": "None",
        "Fix Version/s": "None",
        "Component/s": "Coref",
        "Assignee": null,
        "Reporter": "J\u00f6rn Kottmann",
        "Created": "22/Dec/10 10:18",
        "Updated": "16/Jan/17 14:32",
        "Resolved": "16/Jan/17 14:32",
        "Description": "The coref component should have a file format for its training data. Currently it can only be trained via the wordfreak data bridge.",
        "Issue Links": [
            "/jira/browse/OPENNLP-36"
        ]
    },
    "OPENNLP-57": {
        "Key": "OPENNLP-57",
        "Summary": "Reaccuring Task to Update NEWS!",
        "Type": "Task",
        "Status": "Closed",
        "Priority": "Minor",
        "Resolution": "Fixed",
        "Affects Version/s": "None",
        "Fix Version/s": "None",
        "Component/s": "Website",
        "Assignee": "James Kosin",
        "Reporter": "James Kosin",
        "Created": "24/Dec/10 02:54",
        "Updated": "21/Jan/11 10:48",
        "Resolved": "21/Jan/11 10:48",
        "Description": "This is a reminder to update the news at least once a month with our progress to the website.",
        "Issue Links": []
    },
    "OPENNLP-58": {
        "Key": "OPENNLP-58",
        "Summary": "Apache License To Website (conform to requirements)",
        "Type": "Task",
        "Status": "Closed",
        "Priority": "Trivial",
        "Resolution": "Fixed",
        "Affects Version/s": "None",
        "Fix Version/s": "None",
        "Component/s": "Website",
        "Assignee": "James Kosin",
        "Reporter": "James Kosin",
        "Created": "24/Dec/10 04:26",
        "Updated": "04/Jan/11 00:44",
        "Resolved": "04/Jan/11 00:44",
        "Description": "Move a complete copy of the Apache License to the website as a .mdtext file.\nWelcomes possible submittion to Apache for all use.",
        "Issue Links": []
    },
    "OPENNLP-59": {
        "Key": "OPENNLP-59",
        "Summary": "Bad precision using FMeasure",
        "Type": "Bug",
        "Status": "Closed",
        "Priority": "Major",
        "Resolution": "Fixed",
        "Affects Version/s": "tools-1.5.1-incubating",
        "Fix Version/s": "tools-1.5.1-incubating",
        "Component/s": "None",
        "Assignee": "William Colen",
        "Reporter": "William Colen",
        "Created": "05/Jan/11 16:36",
        "Updated": "19/Jan/11 11:31",
        "Resolved": "19/Jan/11 11:30",
        "Description": "I noticed bad precision in FMeasure results. I think the issue is that the current implementation is summing divisions. It computes the precision and recall for every sample, and after adds the results for each sample to compute the overall result. By doing that, the error related to each division are summed and can impact the final result.\nI found the problem while implementing the ChunkerEvaluator. To verify the evaluator I tried to compare the results we get using OpenNLP and the Perl script conlleval available at http://www.cnts.ua.ac.be/conll2000/chunking/output.html. The results were always different if I process more than one sentence, because the implementation was using FMeasure.updateScores() that was summing divisions.\nTo solve that and have the same results provided by conll I basically stopped using the Mean class.",
        "Issue Links": []
    },
    "OPENNLP-60": {
        "Key": "OPENNLP-60",
        "Summary": "Create ChunkConverter for Portuguese Bosque AD format",
        "Type": "Improvement",
        "Status": "Closed",
        "Priority": "Minor",
        "Resolution": "Fixed",
        "Affects Version/s": "tools-1.5.1-incubating",
        "Fix Version/s": "tools-1.5.1-incubating",
        "Component/s": "Chunker",
        "Assignee": "William Colen",
        "Reporter": "William Colen",
        "Created": "06/Jan/11 02:28",
        "Updated": "19/Jan/11 12:37",
        "Resolved": "19/Jan/11 12:37",
        "Description": "Create a converter to extract data to train Chunker from Portuguese Bosque AD format.",
        "Issue Links": []
    },
    "OPENNLP-61": {
        "Key": "OPENNLP-61",
        "Summary": "Create Chunk tool documentantion",
        "Type": "Improvement",
        "Status": "Closed",
        "Priority": "Major",
        "Resolution": "Fixed",
        "Affects Version/s": "tools-1.5.1-incubating",
        "Fix Version/s": "tools-1.5.1-incubating",
        "Component/s": "Documentation",
        "Assignee": "William Colen",
        "Reporter": "William Colen",
        "Created": "06/Jan/11 20:07",
        "Updated": "19/Jan/11 12:36",
        "Resolved": "19/Jan/11 12:36",
        "Description": "Move the documentation from Wiki to Docbook.",
        "Issue Links": []
    },
    "OPENNLP-62": {
        "Key": "OPENNLP-62",
        "Summary": "Chunker should output chunks also as Spans",
        "Type": "Improvement",
        "Status": "Closed",
        "Priority": "Major",
        "Resolution": "Fixed",
        "Affects Version/s": "None",
        "Fix Version/s": "tools-1.5.1-incubating",
        "Component/s": "Chunker",
        "Assignee": "William Colen",
        "Reporter": "J\u00f6rn Kottmann",
        "Created": "12/Jan/11 12:10",
        "Updated": "28/Jan/11 12:40",
        "Resolved": "28/Jan/11 12:35",
        "Description": "The chunker currently takes a string array as input and outputs a tag for each input string.\nThe interface should be extended in a way that it can output an array of Spans instead, where\neach Span contains the type, and the begin/end offset in the input array. Like the name finder\ndoes. Like its done by ChunkSample.getPhrasesAsSpanList().",
        "Issue Links": []
    },
    "OPENNLP-63": {
        "Key": "OPENNLP-63",
        "Summary": "Move the Arvores Deitadas format classes to a sub package",
        "Type": "Improvement",
        "Status": "Closed",
        "Priority": "Major",
        "Resolution": "Fixed",
        "Affects Version/s": "None",
        "Fix Version/s": "None",
        "Component/s": "Chunker",
        "Assignee": "William Colen",
        "Reporter": "J\u00f6rn Kottmann",
        "Created": "12/Jan/11 12:22",
        "Updated": "19/Jan/11 12:39",
        "Resolved": "19/Jan/11 12:32",
        "Description": "The Arvores Deitadas classes should be moved to a sub package of the opennlp.tools.formats package, \ne.g. formats.ad. All classes have been added after the 1.5.0 release and moving them will not break\nbackward compatibility.",
        "Issue Links": []
    },
    "OPENNLP-64": {
        "Key": "OPENNLP-64",
        "Summary": "Write more documentation for the pos tagger",
        "Type": "Improvement",
        "Status": "Closed",
        "Priority": "Major",
        "Resolution": "Fixed",
        "Affects Version/s": "None",
        "Fix Version/s": "tools-1.5.1-incubating",
        "Component/s": "Documentation",
        "Assignee": "J\u00f6rn Kottmann",
        "Reporter": "J\u00f6rn Kottmann",
        "Created": "13/Jan/11 20:24",
        "Updated": "01/Feb/11 10:02",
        "Resolved": "01/Feb/11 10:02",
        "Description": "The documentation for the pos tagger should be extended.",
        "Issue Links": []
    },
    "OPENNLP-65": {
        "Key": "OPENNLP-65",
        "Summary": "Add documentation about CONLL2000 to the corpora documentation",
        "Type": "Improvement",
        "Status": "Closed",
        "Priority": "Major",
        "Resolution": "Fixed",
        "Affects Version/s": "None",
        "Fix Version/s": "tools-1.5.1-incubating",
        "Component/s": "Documentation",
        "Assignee": "William Colen",
        "Reporter": "J\u00f6rn Kottmann",
        "Created": "13/Jan/11 20:28",
        "Updated": "19/Jan/11 12:47",
        "Resolved": "19/Jan/11 12:31",
        "Description": "Add CONLL 2000 section to the corpora page. It should explain how to get the data, how\nto train the chunker on that data, and report the evaluation results of chunker according\nto the CONLL shared task.",
        "Issue Links": []
    },
    "OPENNLP-66": {
        "Key": "OPENNLP-66",
        "Summary": "Configure the maven-eclipse-plugin to automatically import the eclipes code style file",
        "Type": "Improvement",
        "Status": "Closed",
        "Priority": "Trivial",
        "Resolution": "Fixed",
        "Affects Version/s": "None",
        "Fix Version/s": "None",
        "Component/s": "Build, Packaging and Test",
        "Assignee": "J\u00f6rn Kottmann",
        "Reporter": "J\u00f6rn Kottmann",
        "Created": "19/Jan/11 14:32",
        "Updated": "25/Jan/11 14:14",
        "Resolved": "25/Jan/11 14:14",
        "Description": "After a svn checkout was done the opennlp project must be imported into eclipse (if that is the desired IDE). Eclipse uses a standard code style for the newly imported OpenNLP project, since we are all lazy the maven-eclipse-plugin should fetch the OpenNLP code style file from our website (or some ohter location) and also import it into eclipse. \nThe link explains how that can be configured:\nhttp://maven.apache.org/plugins/maven-eclipse-plugin/examples/load-code-styles.html",
        "Issue Links": []
    },
    "OPENNLP-67": {
        "Key": "OPENNLP-67",
        "Summary": "NameFinderMe detecting organisations in an HTML sample with limited training",
        "Type": "Question",
        "Status": "Closed",
        "Priority": "Major",
        "Resolution": "Fixed",
        "Affects Version/s": "tools-1.5.0-sourceforge",
        "Fix Version/s": "None",
        "Component/s": "Name Finder",
        "Assignee": null,
        "Reporter": "Paul",
        "Created": "19/Jan/11 20:39",
        "Updated": "25/Jan/11 12:39",
        "Resolved": "25/Jan/11 12:39",
        "Description": "I have attached a patch named htmltest.patch.  \nThe patch contains a test named NameFinderMEHtmlTest and 2 embedded resources named html1.train and html.html.  Obviously html1.train is the training sample which is a sample HTML document marked up with <START:organization> Org <END> tags.  html.html is the same HTML document without the training mark up.  The HTML has been preprocess with all the line break characters removed. \nIn the NameFinderMEHtmlTest I am training the data and then using find to retrieve the names. \nWas my assumption wrong in thinking that NameFinderME would find the exact names from the html?  I mean exact in this context because both the training html and the test html are the same.  The NameFinderMEHtmlTest fails because it does not find the first name, it does find part of the name.  Is this because it has limited training or is the find method performing badly against html document?\nI am new to opennlp so there is an element of guess work as to which streams etc. I should be using.",
        "Issue Links": []
    },
    "OPENNLP-68": {
        "Key": "OPENNLP-68",
        "Summary": "Make statistical models available as maven artifacts and deploy them on the maven repo",
        "Type": "Improvement",
        "Status": "Closed",
        "Priority": "Major",
        "Resolution": "Won't Fix",
        "Affects Version/s": "tools-1.5.0-sourceforge",
        "Fix Version/s": "None",
        "Component/s": "Build, Packaging and Test",
        "Assignee": null,
        "Reporter": "Olivier Grisel",
        "Created": "20/Jan/11 10:36",
        "Updated": "16/Jan/17 14:39",
        "Resolved": "16/Jan/17 14:39",
        "Description": "This would be really useful for third party application developers who use opennlp as a library to be able to load default models from the classpath.\nFor each model, we need to write a very short pom.xml file that will then be used by maven to build and deploy a versioned\njar that holds the model (the .bin.gz file in folder src/main/resource/opennlp/ for instance).",
        "Issue Links": []
    },
    "OPENNLP-69": {
        "Key": "OPENNLP-69",
        "Summary": "The createPear.xml ant script is broken and cannot produce the pear package",
        "Type": "Bug",
        "Status": "Closed",
        "Priority": "Major",
        "Resolution": "Fixed",
        "Affects Version/s": "None",
        "Fix Version/s": "tools-1.5.1-incubating",
        "Component/s": "UIMA Integration",
        "Assignee": "J\u00f6rn Kottmann",
        "Reporter": "J\u00f6rn Kottmann",
        "Created": "20/Jan/11 21:01",
        "Updated": "20/Jan/11 21:06",
        "Resolved": "20/Jan/11 21:06",
        "Description": "A few things in the build changed and need the script needs to be updated, first the version of the uima jar must be updated to 1.5.1 and the dependencies must be copied again to the target folder, this was commented out earlier.",
        "Issue Links": []
    },
    "OPENNLP-70": {
        "Key": "OPENNLP-70",
        "Summary": "Add support for coref to the uima integration layer",
        "Type": "Improvement",
        "Status": "Closed",
        "Priority": "Major",
        "Resolution": "Won't Fix",
        "Affects Version/s": "None",
        "Fix Version/s": "None",
        "Component/s": "UIMA Integration",
        "Assignee": null,
        "Reporter": "J\u00f6rn Kottmann",
        "Created": "20/Jan/11 21:20",
        "Updated": "16/Jan/17 14:34",
        "Resolved": "16/Jan/17 14:34",
        "Description": "The UIMA Integration does not had any support for coref. It should be added.",
        "Issue Links": []
    },
    "OPENNLP-71": {
        "Key": "OPENNLP-71",
        "Summary": "UIMA parser integration needs a special token map to extract the results form the parser",
        "Type": "Improvement",
        "Status": "Open",
        "Priority": "Minor",
        "Resolution": "Unresolved",
        "Affects Version/s": "None",
        "Fix Version/s": "None",
        "Component/s": "Parser,                                            UIMA Integration",
        "Assignee": null,
        "Reporter": "J\u00f6rn Kottmann",
        "Created": "20/Jan/11 21:24",
        "Updated": "07/Feb/12 12:49",
        "Resolved": null,
        "Description": "It is planned to improve the parser interface to ease the integration into programms which already have\ntokenized data in a string array, such as the uima parser integration. As soon as that work is done, the new\ninterface should be used by the the uima integration instead of the custom and slow token mapping solution.",
        "Issue Links": [
            "/jira/browse/OPENNLP-53"
        ]
    },
    "OPENNLP-72": {
        "Key": "OPENNLP-72",
        "Summary": "OpenNLP must work independent of the platform local",
        "Type": "Bug",
        "Status": "Closed",
        "Priority": "Major",
        "Resolution": "Fixed",
        "Affects Version/s": "None",
        "Fix Version/s": "1.6.0",
        "Component/s": "None",
        "Assignee": "J\u00f6rn Kottmann",
        "Reporter": "J\u00f6rn Kottmann",
        "Created": "20/Jan/11 21:32",
        "Updated": "03/Jan/14 14:14",
        "Resolved": "03/Jan/14 14:14",
        "Description": "The OpenNLP feature generation must produce the exact same results independent of the platform local.\nThe feature generation code frequently uses String.toLowerCase() which depending on the local might\nproduce different results, e.g. when used with a turkish local. That should of course not be the case,\nsince the lower cased string will not match the feature which is in the statistical model and might not\nhave been generated on a machine with a turkish local.\nInstead the method Characters.toLowerCase(...) should be used, because it is only using the UnicodeData file\nand cannot perform locale-sensitive mappings.",
        "Issue Links": []
    },
    "OPENNLP-73": {
        "Key": "OPENNLP-73",
        "Summary": "Write a release note for our first (1.5.1-incubating) release here",
        "Type": "Task",
        "Status": "Closed",
        "Priority": "Major",
        "Resolution": "Fixed",
        "Affects Version/s": "None",
        "Fix Version/s": "tools-1.5.1-incubating",
        "Component/s": "Build, Packaging and Test",
        "Assignee": "J\u00f6rn Kottmann",
        "Reporter": "J\u00f6rn Kottmann",
        "Created": "20/Jan/11 22:24",
        "Updated": "28/Jan/11 10:02",
        "Resolved": "28/Jan/11 10:02",
        "Description": "We need to write a release note which can be included in our distribution\nand be published on our website.",
        "Issue Links": []
    },
    "OPENNLP-74": {
        "Key": "OPENNLP-74",
        "Summary": "Add the OpenNLP Project to the hudson continuous integration server",
        "Type": "Task",
        "Status": "Closed",
        "Priority": "Minor",
        "Resolution": "Fixed",
        "Affects Version/s": "None",
        "Fix Version/s": "None",
        "Component/s": "Build, Packaging and Test",
        "Assignee": "J\u00f6rn Kottmann",
        "Reporter": "J\u00f6rn Kottmann",
        "Created": "20/Jan/11 23:59",
        "Updated": "09/Feb/11 21:58",
        "Resolved": "09/Feb/11 21:58",
        "Description": "The OpenNLP Project should be build frequently by the hudson integration server to ensure that everything is in a good state.",
        "Issue Links": []
    },
    "OPENNLP-75": {
        "Key": "OPENNLP-75",
        "Summary": "The jar names inside the pear file have changed and cannot be found",
        "Type": "Bug",
        "Status": "Closed",
        "Priority": "Major",
        "Resolution": "Fixed",
        "Affects Version/s": "None",
        "Fix Version/s": "tools-1.5.1-incubating",
        "Component/s": "UIMA Integration",
        "Assignee": "J\u00f6rn Kottmann",
        "Reporter": "J\u00f6rn Kottmann",
        "Created": "21/Jan/11 00:30",
        "Updated": "21/Jan/11 19:16",
        "Resolved": "21/Jan/11 19:16",
        "Description": "The jar names on the classpath do not match the actual jar names anymore.\nThe classpath inside the install.xml file should be changed to the new names.\nThat is the produced error:\nCaused by: java.lang.ClassNotFoundException:\nopennlp.tools.sentdetect.SentenceModel\n\tat java.net.URLClassLoader$1.run(URLClassLoader.java:202)\n\tat java.security.AccessController.doPrivileged(Native Method)\n\tat java.net.URLClassLoader.findClass(URLClassLoader.java:190)\n\tat java.lang.ClassLoader.loadClass(ClassLoader.java:307)\n\tat org.apache.uima.internal.util.UIMAClassLoader.loadClass(UIMAClassLoader.java:151)\n\tat java.lang.ClassLoader.loadClass(ClassLoader.java:248)",
        "Issue Links": []
    },
    "OPENNLP-76": {
        "Key": "OPENNLP-76",
        "Summary": "Remove all the AUTHOR files",
        "Type": "Task",
        "Status": "Closed",
        "Priority": "Major",
        "Resolution": "Fixed",
        "Affects Version/s": "None",
        "Fix Version/s": "tools-1.5.1-incubating,                                            maxent-3.0.1-incubating",
        "Component/s": "None",
        "Assignee": "J\u00f6rn Kottmann",
        "Reporter": "J\u00f6rn Kottmann",
        "Created": "21/Jan/11 15:55",
        "Updated": "21/Jan/11 15:59",
        "Resolved": "21/Jan/11 15:59",
        "Description": "All AUTHOR files should be removed, OpenNLP is now developed by a community, but the AUTHOR file indicate that the code is owned by the listed authors. Credit for committers and contributes will be given on the website on the Team page.",
        "Issue Links": []
    },
    "OPENNLP-77": {
        "Key": "OPENNLP-77",
        "Summary": "Add missing contributors to the Team page",
        "Type": "Task",
        "Status": "Closed",
        "Priority": "Major",
        "Resolution": "Fixed",
        "Affects Version/s": "None",
        "Fix Version/s": "None",
        "Component/s": "Website",
        "Assignee": "J\u00f6rn Kottmann",
        "Reporter": "J\u00f6rn Kottmann",
        "Created": "21/Jan/11 15:57",
        "Updated": "03/May/11 17:35",
        "Resolved": "03/May/11 17:35",
        "Description": "The Team paeg should also give credit to people who contributed to OpenNLP.\nNamely these people are missing:\nGann Bierner\nEric Friedman\nJoao Cavalcanti",
        "Issue Links": []
    },
    "OPENNLP-78": {
        "Key": "OPENNLP-78",
        "Summary": "NameFinder and Dictionary Integration",
        "Type": "New Feature",
        "Status": "Closed",
        "Priority": "Minor",
        "Resolution": "Won't Fix",
        "Affects Version/s": "None",
        "Fix Version/s": "None",
        "Component/s": "Name Finder",
        "Assignee": "James Kosin",
        "Reporter": "James Kosin",
        "Created": "23/Jan/11 01:11",
        "Updated": "16/Jan/17 15:03",
        "Resolved": "16/Jan/17 15:03",
        "Description": "Now that we have a NameFinder Dictionary and improved NameFinder tools; it would be nice to be able to integrate the dictionary and model to help improve the finding of names.\nThis way, the name finder could be trained more on the surrounding text instead of attempting to memorize common names in the news that occur frequently.\nI've already got the name finder corpus, created the dictionaries with the data from the US Census.\nI just need to implement some method to help train the model; or be able to use the dictionaries post model creation to help with the finding of names.",
        "Issue Links": [
            "/jira/browse/OPENNLP-17"
        ]
    },
    "OPENNLP-79": {
        "Key": "OPENNLP-79",
        "Summary": "Add support to convert for the Leipzig corpus into doccat training data",
        "Type": "Improvement",
        "Status": "Closed",
        "Priority": "Major",
        "Resolution": "Fixed",
        "Affects Version/s": "None",
        "Fix Version/s": "tools-1.5.1-incubating",
        "Component/s": "Doccat",
        "Assignee": "J\u00f6rn Kottmann",
        "Reporter": "J\u00f6rn Kottmann",
        "Created": "24/Jan/11 11:00",
        "Updated": "25/Jan/11 12:03",
        "Resolved": "25/Jan/11 12:03",
        "Description": "Add a converter which can convert the Leipzig corpus into training data for the document categorizer which\ncan be used to train a language detection model.",
        "Issue Links": []
    },
    "OPENNLP-80": {
        "Key": "OPENNLP-80",
        "Summary": "Move bin/opennlp distribution scripts to new location, and place working dev scripts in bin",
        "Type": "Improvement",
        "Status": "Closed",
        "Priority": "Minor",
        "Resolution": "Fixed",
        "Affects Version/s": "None",
        "Fix Version/s": "None",
        "Component/s": "Build, Packaging and Test",
        "Assignee": "J\u00f6rn Kottmann",
        "Reporter": "J\u00f6rn Kottmann",
        "Created": "24/Jan/11 14:13",
        "Updated": "24/Jan/11 14:36",
        "Resolved": "24/Jan/11 14:36",
        "Description": "It turned out that many users would like to use the common bin/opennlp scripts to run opennlp in its checked out project layout. The current scripts only work with the layout in the binary distribution. To solve this the distribution scripts should be move inside the opennlp-distr project and new scripts which are compatible with the checked project layout placed inside the bin folder.\nThe new script should be based on maven. Since maven is required anyway to build OpenNLP.",
        "Issue Links": []
    },
    "OPENNLP-81": {
        "Key": "OPENNLP-81",
        "Summary": "Add a cli tool for the doccat evaluation support",
        "Type": "Improvement",
        "Status": "Closed",
        "Priority": "Minor",
        "Resolution": "Fixed",
        "Affects Version/s": "None",
        "Fix Version/s": "1.6.0",
        "Component/s": "Command Line Interface,                                            Doccat",
        "Assignee": "William Colen",
        "Reporter": "J\u00f6rn Kottmann",
        "Created": "25/Jan/11 11:06",
        "Updated": "21/Oct/14 22:45",
        "Resolved": "11/Apr/14 00:35",
        "Description": "There should be a command line tool which can be used to evaluate the document categorizer model\non a test file.",
        "Issue Links": []
    },
    "OPENNLP-82": {
        "Key": "OPENNLP-82",
        "Summary": "Development bin/opennlp script should print out the stack trace when an exception is thrown",
        "Type": "Improvement",
        "Status": "Closed",
        "Priority": "Major",
        "Resolution": "Fixed",
        "Affects Version/s": "None",
        "Fix Version/s": "None",
        "Component/s": "Build, Packaging and Test",
        "Assignee": null,
        "Reporter": "J\u00f6rn Kottmann",
        "Created": "25/Jan/11 11:56",
        "Updated": "25/Jan/11 11:56",
        "Resolved": "25/Jan/11 11:56",
        "Description": "Add the -e script to maven, to make it print out the stack trace.",
        "Issue Links": []
    },
    "OPENNLP-83": {
        "Key": "OPENNLP-83",
        "Summary": "Maxent/Perceptron models should support equals",
        "Type": "Improvement",
        "Status": "Closed",
        "Priority": "Minor",
        "Resolution": "Fixed",
        "Affects Version/s": "None",
        "Fix Version/s": "1.7.1",
        "Component/s": "Machine Learning",
        "Assignee": "J\u00f6rn Kottmann",
        "Reporter": "J\u00f6rn Kottmann",
        "Created": "25/Jan/11 12:35",
        "Updated": "11/Jan/17 09:52",
        "Resolved": "10/Jan/17 17:37",
        "Description": "The models should implement the equals method, to test if two models are identical or not. This method would be important for many tests where we want to check if the model is still the same after serializing and deserializing it.",
        "Issue Links": [
            "https://github.com/apache/opennlp/pull/40"
        ]
    },
    "OPENNLP-84": {
        "Key": "OPENNLP-84",
        "Summary": "Sentence Detector documentation says sentDetect() but means sentPosDetect()",
        "Type": "Bug",
        "Status": "Closed",
        "Priority": "Trivial",
        "Resolution": "Fixed",
        "Affects Version/s": "None",
        "Fix Version/s": "tools-1.5.1-incubating",
        "Component/s": "Documentation",
        "Assignee": "J\u00f6rn Kottmann",
        "Reporter": "J\u00f6rn Kottmann",
        "Created": "25/Jan/11 13:27",
        "Updated": "25/Jan/11 13:28",
        "Resolved": "25/Jan/11 13:28",
        "Description": "The Sentence Detector documentation explains the sentPosDetect method but accidentally says sentDetect(). \nTo fix this issue refer to the correct method in the documentation.",
        "Issue Links": []
    },
    "OPENNLP-85": {
        "Key": "OPENNLP-85",
        "Summary": "Refactor ChunkSample class",
        "Type": "Improvement",
        "Status": "Closed",
        "Priority": "Trivial",
        "Resolution": "Fixed",
        "Affects Version/s": "tools-1.5.1-incubating",
        "Fix Version/s": "tools-1.5.1-incubating",
        "Component/s": "Chunker",
        "Assignee": "William Colen",
        "Reporter": "William Colen",
        "Created": "25/Jan/11 15:47",
        "Updated": "25/Jan/11 23:46",
        "Resolved": "25/Jan/11 23:46",
        "Description": "The class needs some improvements:\n1. Internally it works with Lists, but all methods outputs Arrays, it is always making Lists to Arrays conversions. Better to work with arrays directly.\n2. Create a static method to create spans of phrase chunks \n3. Add javadoc",
        "Issue Links": []
    },
    "OPENNLP-86": {
        "Key": "OPENNLP-86",
        "Summary": "Write a REAMDE which will replace the CHANGES files we used over at SourceForge",
        "Type": "Task",
        "Status": "Closed",
        "Priority": "Major",
        "Resolution": "Fixed",
        "Affects Version/s": "None",
        "Fix Version/s": "None",
        "Component/s": "Build, Packaging and Test",
        "Assignee": "J\u00f6rn Kottmann",
        "Reporter": "J\u00f6rn Kottmann",
        "Created": "25/Jan/11 16:44",
        "Updated": "27/Jan/11 12:38",
        "Resolved": "27/Jan/11 12:38",
        "Description": "There should be a README file which can be part of our distribution which basically replaces the CHANGES file and contains other information, such as how to build from source, minimum required versions of the JRE and Maven.",
        "Issue Links": []
    },
    "OPENNLP-87": {
        "Key": "OPENNLP-87",
        "Summary": "Add a page to the website which documents the process to make a release",
        "Type": "Task",
        "Status": "Closed",
        "Priority": "Major",
        "Resolution": "Fixed",
        "Affects Version/s": "None",
        "Fix Version/s": "tools-1.5.2-incubating",
        "Component/s": "Website",
        "Assignee": "J\u00f6rn Kottmann",
        "Reporter": "J\u00f6rn Kottmann",
        "Created": "25/Jan/11 16:47",
        "Updated": "22/Aug/11 14:00",
        "Resolved": "22/Aug/11 14:00",
        "Description": "There should be documentation the project website which documents how to make a release. It should be possible for every committer to produce a release with this documentation.",
        "Issue Links": []
    },
    "OPENNLP-88": {
        "Key": "OPENNLP-88",
        "Summary": "use bloom filters where appropriate (e.g. language models)",
        "Type": "Improvement",
        "Status": "Closed",
        "Priority": "Minor",
        "Resolution": "Won't Fix",
        "Affects Version/s": "None",
        "Fix Version/s": "None",
        "Component/s": "None",
        "Assignee": null,
        "Reporter": "Jason Baldridge",
        "Created": "25/Jan/11 21:10",
        "Updated": "16/Jan/17 15:04",
        "Resolved": "16/Jan/17 15:04",
        "Description": "Bloom filters can be used to drastically reduce the memory requirements for certain kinds of models. For example, see the following papers on using bloom filters to create highly compact language models:\nhttp://homepages.inf.ed.ac.uk/miles/papers/emnlp07.pdf\nhttp://homepages.inf.ed.ac.uk/miles/papers/acl07.pdf\nIt would be good to find/create an implementation of bloom filters for such uses in OpenNLP.",
        "Issue Links": []
    },
    "OPENNLP-89": {
        "Key": "OPENNLP-89",
        "Summary": "ChunkerME needs unit tests",
        "Type": "Improvement",
        "Status": "Closed",
        "Priority": "Major",
        "Resolution": "Fixed",
        "Affects Version/s": "tools-1.5.1-incubating",
        "Fix Version/s": "tools-1.5.1-incubating",
        "Component/s": "Chunker",
        "Assignee": "William Colen",
        "Reporter": "William Colen",
        "Created": "25/Jan/11 21:11",
        "Updated": "25/Jan/11 23:47",
        "Resolved": "25/Jan/11 23:47",
        "Description": "The class ChunkerME has no tests. Create some JUnit tests for it.",
        "Issue Links": []
    },
    "OPENNLP-90": {
        "Key": "OPENNLP-90",
        "Summary": "Method ChunkerME.topKSequences(List<String>, List<String>) fails with a class cast exception.",
        "Type": "Bug",
        "Status": "Closed",
        "Priority": "Major",
        "Resolution": "Fixed",
        "Affects Version/s": "tools-1.5.1-incubating",
        "Fix Version/s": "tools-1.5.1-incubating",
        "Component/s": "None",
        "Assignee": "William Colen",
        "Reporter": "William Colen",
        "Created": "25/Jan/11 23:16",
        "Updated": "26/Jan/11 00:26",
        "Resolved": "26/Jan/11 00:26",
        "Description": "The method topKSequences(List<String> sentence, List<String> tags) fails with a class cast exception because the bestSequences method expects an array of String arrays in additionalContext argument, but the topKSequences was setting a array of lists.",
        "Issue Links": []
    },
    "OPENNLP-91": {
        "Key": "OPENNLP-91",
        "Summary": "Binary distribution broken",
        "Type": "Bug",
        "Status": "Closed",
        "Priority": "Major",
        "Resolution": "Fixed",
        "Affects Version/s": "tools-1.5.1-incubating",
        "Fix Version/s": "tools-1.5.1-incubating",
        "Component/s": "Build, Packaging and Test",
        "Assignee": "James Kosin",
        "Reporter": "James Kosin",
        "Created": "26/Jan/11 02:12",
        "Updated": "26/Jan/11 03:03",
        "Resolved": "26/Jan/11 03:03",
        "Description": "When running the shell script (or batch file) the opennlp-tools jar file is expecting the lib directory to be under where the opennlp-tools jar file is located.  This either leads to a messy arrangement or multiple lib directories.  I'm going to leave the layout as it is now and change the opennlp-tools pom file to not include a lib directory for searching for dependancies.\nI'll verify before committing.",
        "Issue Links": []
    },
    "OPENNLP-92": {
        "Key": "OPENNLP-92",
        "Summary": "Packaging of distr and docs project should be of type \"pom\"",
        "Type": "Improvement",
        "Status": "Closed",
        "Priority": "Minor",
        "Resolution": "Fixed",
        "Affects Version/s": "None",
        "Fix Version/s": "None",
        "Component/s": "Build, Packaging and Test",
        "Assignee": "J\u00f6rn Kottmann",
        "Reporter": "J\u00f6rn Kottmann",
        "Created": "26/Jan/11 09:48",
        "Updated": "26/Jan/11 09:49",
        "Resolved": "26/Jan/11 09:49",
        "Description": "Add the following elements to the two poms:\n<packaging>pom</packaging>",
        "Issue Links": []
    },
    "OPENNLP-93": {
        "Key": "OPENNLP-93",
        "Summary": "Add a development bin/opennlp.bat script for our windows users",
        "Type": "Improvement",
        "Status": "Closed",
        "Priority": "Minor",
        "Resolution": "Fixed",
        "Affects Version/s": "None",
        "Fix Version/s": "None",
        "Component/s": "Build, Packaging and Test",
        "Assignee": "James Kosin",
        "Reporter": "J\u00f6rn Kottmann",
        "Created": "26/Jan/11 10:24",
        "Updated": "26/Jan/11 23:43",
        "Resolved": "26/Jan/11 23:43",
        "Description": "There should be a maven based opennlp.bat file in the opennlp-tools/bin directory for our windows users.",
        "Issue Links": []
    },
    "OPENNLP-94": {
        "Key": "OPENNLP-94",
        "Summary": "The Parser Analysis Engine should link the produced parse annotations to its parent",
        "Type": "Improvement",
        "Status": "Closed",
        "Priority": "Minor",
        "Resolution": "Fixed",
        "Affects Version/s": "None",
        "Fix Version/s": "None",
        "Component/s": "UIMA Integration",
        "Assignee": "J\u00f6rn Kottmann",
        "Reporter": "J\u00f6rn Kottmann",
        "Created": "26/Jan/11 10:33",
        "Updated": "20/Feb/12 13:54",
        "Resolved": "20/Feb/12 13:54",
        "Description": "The Parser AE currently just outputs parse annotations which have a type. To reconstruct the actual parse tree the locations of the annotations must be used. The parse annotation should have an additional feature value which holds a link to the parent (or surrounding) parse annotation.",
        "Issue Links": []
    },
    "OPENNLP-95": {
        "Key": "OPENNLP-95",
        "Summary": "All java listings in the docbook should use code highlighting",
        "Type": "Bug",
        "Status": "Closed",
        "Priority": "Trivial",
        "Resolution": "Fixed",
        "Affects Version/s": "None",
        "Fix Version/s": "None",
        "Component/s": "Documentation",
        "Assignee": "J\u00f6rn Kottmann",
        "Reporter": "J\u00f6rn Kottmann",
        "Created": "26/Jan/11 11:46",
        "Updated": "26/Jan/11 11:47",
        "Resolved": "26/Jan/11 11:47",
        "Description": null,
        "Issue Links": []
    },
    "OPENNLP-96": {
        "Key": "OPENNLP-96",
        "Summary": "Update docbkx maven plugin to 2.0.11 version",
        "Type": "Improvement",
        "Status": "Closed",
        "Priority": "Minor",
        "Resolution": "Fixed",
        "Affects Version/s": "None",
        "Fix Version/s": "None",
        "Component/s": "Documentation",
        "Assignee": "J\u00f6rn Kottmann",
        "Reporter": "J\u00f6rn Kottmann",
        "Created": "26/Jan/11 11:49",
        "Updated": "26/Jan/11 11:51",
        "Resolved": "26/Jan/11 11:51",
        "Description": "We should use the latest version of the plugin. The update causes a regression with the highlighter which needs slightly changed configuration now.",
        "Issue Links": []
    },
    "OPENNLP-97": {
        "Key": "OPENNLP-97",
        "Summary": "Use maven changes plugin to pull the release notes from jira",
        "Type": "Improvement",
        "Status": "Closed",
        "Priority": "Minor",
        "Resolution": "Fixed",
        "Affects Version/s": "None",
        "Fix Version/s": "tools-1.5.1-incubating",
        "Component/s": "Build, Packaging and Test",
        "Assignee": "J\u00f6rn Kottmann",
        "Reporter": "J\u00f6rn Kottmann",
        "Created": "26/Jan/11 14:15",
        "Updated": "26/Jan/11 14:40",
        "Resolved": "26/Jan/11 14:40",
        "Description": "To make the release easier and more automatic the changes report from jira should be automatically downloaded when making a release.",
        "Issue Links": []
    },
    "OPENNLP-98": {
        "Key": "OPENNLP-98",
        "Summary": "Source distribution is almost empty",
        "Type": "Bug",
        "Status": "Closed",
        "Priority": "Major",
        "Resolution": "Fixed",
        "Affects Version/s": "None",
        "Fix Version/s": "None",
        "Component/s": "Build, Packaging and Test",
        "Assignee": "J\u00f6rn Kottmann",
        "Reporter": "J\u00f6rn Kottmann",
        "Created": "26/Jan/11 14:42",
        "Updated": "27/Jan/11 10:19",
        "Resolved": "27/Jan/11 10:19",
        "Description": "When building with the apache-release profile the created source distribution is almost empty. Make sure all the projects and files end up in the source distribution.",
        "Issue Links": []
    },
    "OPENNLP-99": {
        "Key": "OPENNLP-99",
        "Summary": "EventStream should extend Iterator<Event>",
        "Type": "New Feature",
        "Status": "Closed",
        "Priority": "Major",
        "Resolution": "Won't Fix",
        "Affects Version/s": "maxent-3.0.0-sourceforge",
        "Fix Version/s": "None",
        "Component/s": "Machine Learning",
        "Assignee": "J\u00f6rn Kottmann",
        "Reporter": "Steven Bethard",
        "Created": "26/Jan/11 17:18",
        "Updated": "31/Jan/11 11:48",
        "Resolved": "31/Jan/11 11:48",
        "Description": "[As requested, brought over from Sourceforge.]\nConceptually, EventStream is just an Iterator<Event>. You would get better interoperability with other Java libraries if EventStream were declared as such. If you didn't care about backwards compatibility, I'd say just get rid of EventStream entirely and use Iterator<Event> everywhere instead.\nIf you care about backwards compatibility, you could at least declare AbstractEventStream as implementing Iterator<Event> - it declares all of hasNext(), next() and remove(). I believe that shouldn't break anything, and should make all the current EventStream implementations into Iterator<Event>s.\nWhy do I want this? Because, when using OpenNLP maxent from Scala, if a RealValueFileEventStream were an Iterator<Event>, I could write:\n  for (event <- stream) \n{\n    ...\n  }\n\nBut since it's not, I instead have to wrap it in an Iterator:\n\n  val events = new Iterator[Event] {\n    def hasNext = stream.hasNext\n    def next = stream.next\n  }\n  for (event <- events) {    ...  }\n\nOr write the while loop version:\n  while (stream.hasNext) \n{\n    val event = stream.next\n    ...\n  }",
        "Issue Links": []
    },
    "OPENNLP-100": {
        "Key": "OPENNLP-100",
        "Summary": "Maven release plugin does not work",
        "Type": "Improvement",
        "Status": "Closed",
        "Priority": "Major",
        "Resolution": "Fixed",
        "Affects Version/s": "None",
        "Fix Version/s": "None",
        "Component/s": "Build, Packaging and Test",
        "Assignee": "J\u00f6rn Kottmann",
        "Reporter": "J\u00f6rn Kottmann",
        "Created": "27/Jan/11 10:31",
        "Updated": "27/Jan/11 13:09",
        "Resolved": "27/Jan/11 13:09",
        "Description": "It would be nice to use the maven release plugin to make our release. Try to figure out what must be done to get it working.",
        "Issue Links": []
    },
    "OPENNLP-101": {
        "Key": "OPENNLP-101",
        "Summary": "Training a perceptron/maxent model should be cancelable via interrupts",
        "Type": "Improvement",
        "Status": "Open",
        "Priority": "Major",
        "Resolution": "Unresolved",
        "Affects Version/s": "None",
        "Fix Version/s": "None",
        "Component/s": "Machine Learning",
        "Assignee": "William Colen",
        "Reporter": "J\u00f6rn Kottmann",
        "Created": "27/Jan/11 12:40",
        "Updated": "04/Feb/14 14:00",
        "Resolved": null,
        "Description": "Training a model is usually a long running operation and it should be possible to cancel this operation. A good way to implement this would be to react to thread interrupts and just stop training when one was set.",
        "Issue Links": []
    },
    "OPENNLP-102": {
        "Key": "OPENNLP-102",
        "Summary": "Create reusable sequence detection classes",
        "Type": "Improvement",
        "Status": "Closed",
        "Priority": "Minor",
        "Resolution": "Won't Fix",
        "Affects Version/s": "None",
        "Fix Version/s": "None",
        "Component/s": "None",
        "Assignee": null,
        "Reporter": "J\u00f6rn Kottmann",
        "Created": "27/Jan/11 14:34",
        "Updated": "03/Jan/17 10:41",
        "Resolved": "03/Jan/17 10:41",
        "Description": "There is a common pattern that in many places a piece of code needs to detect a BIO sequences and create spans out of these. It turned out that writing this code is error prone and testing it with unit tests is complex.\nWe should create reusable classes which can perform the sequence detection and can be used in all the places where it is required.\nHaving common code also makes difficult to do performance optimizations possible, like mapping via perfect hashing instead of string parsing or regular expressions.",
        "Issue Links": []
    },
    "OPENNLP-103": {
        "Key": "OPENNLP-103",
        "Summary": "New mailing list for JIRA issues",
        "Type": "Improvement",
        "Status": "Closed",
        "Priority": "Minor",
        "Resolution": "Fixed",
        "Affects Version/s": "None",
        "Fix Version/s": "None",
        "Component/s": "None",
        "Assignee": "James Kosin",
        "Reporter": "James Kosin",
        "Created": "27/Jan/11 21:30",
        "Updated": "29/Jan/11 00:11",
        "Resolved": "29/Jan/11 00:11",
        "Description": "With lots of JIRA issues, it is difficult to follow development conversations amoungst the numerous JIRA issues.\nWe have decided a new list just for JIRA issues would be helpful.\nopennlp-jira\nor something similar would be good.",
        "Issue Links": []
    },
    "OPENNLP-104": {
        "Key": "OPENNLP-104",
        "Summary": "Code Styling for NetBeans",
        "Type": "Improvement",
        "Status": "Closed",
        "Priority": "Minor",
        "Resolution": "Won't Fix",
        "Affects Version/s": "None",
        "Fix Version/s": "None",
        "Component/s": "None",
        "Assignee": "James Kosin",
        "Reporter": "James Kosin",
        "Created": "27/Jan/11 21:57",
        "Updated": "11/Jan/17 12:36",
        "Resolved": "11/Jan/17 12:36",
        "Description": "A default set of code styling defaults are needed for NetBeans IDE like the ones for Eclipse.\n\n\n\nCurrent NetBeans Lacks the ability to Export/Import these settings, however, we need them regarless.\n\n\n\nI'll be attaching a zip file with a majority of the NetBeans defaults (as images); can someone look over the settings and comment?\nThanks",
        "Issue Links": []
    },
    "OPENNLP-105": {
        "Key": "OPENNLP-105",
        "Summary": "Deprecate the methods which take a List in the POS Tagger interfaces",
        "Type": "Improvement",
        "Status": "Closed",
        "Priority": "Trivial",
        "Resolution": "Fixed",
        "Affects Version/s": "None",
        "Fix Version/s": "tools-1.5.1-incubating",
        "Component/s": "POS Tagger",
        "Assignee": "J\u00f6rn Kottmann",
        "Reporter": "J\u00f6rn Kottmann",
        "Created": "28/Jan/11 11:55",
        "Updated": "28/Jan/11 12:06",
        "Resolved": "28/Jan/11 12:06",
        "Description": "All the methods in the POS Tagger interface which take a List should be deprecated, having List and String array methods does not has an advantage. Users can easily call List.toArray to do the conversation them self.",
        "Issue Links": []
    },
    "OPENNLP-106": {
        "Key": "OPENNLP-106",
        "Summary": "Extend the Span class to have a probability/confidence",
        "Type": "Improvement",
        "Status": "Closed",
        "Priority": "Minor",
        "Resolution": "Duplicate",
        "Affects Version/s": "None",
        "Fix Version/s": "1.6.0",
        "Component/s": "None",
        "Assignee": "Martin Wiesner",
        "Reporter": "J\u00f6rn Kottmann",
        "Created": "28/Jan/11 12:34",
        "Updated": "26/Feb/23 13:26",
        "Resolved": "26/Feb/23 13:26",
        "Description": "The Span object is frequently used to report results which are created by probability models. The Span object should be extended\nwith a probability field to contain the confidence score.",
        "Issue Links": [
            "/jira/browse/OPENNLP-684"
        ]
    },
    "OPENNLP-107": {
        "Key": "OPENNLP-107",
        "Summary": "Deprecate the methods which take a List in the Chunker interfaces",
        "Type": "Improvement",
        "Status": "Closed",
        "Priority": "Major",
        "Resolution": "Fixed",
        "Affects Version/s": "None",
        "Fix Version/s": "tools-1.5.1-incubating",
        "Component/s": "None",
        "Assignee": "William Colen",
        "Reporter": "William Colen",
        "Created": "28/Jan/11 13:06",
        "Updated": "28/Jan/11 13:13",
        "Resolved": "28/Jan/11 13:13",
        "Description": "All the methods in the Chunker interface which take a List should be deprecated.",
        "Issue Links": []
    },
    "OPENNLP-108": {
        "Key": "OPENNLP-108",
        "Summary": "Write the OpenNLP White Paper",
        "Type": "Task",
        "Status": "Open",
        "Priority": "Major",
        "Resolution": "Unresolved",
        "Affects Version/s": "None",
        "Fix Version/s": "None",
        "Component/s": "Documentation",
        "Assignee": null,
        "Reporter": "J\u00f6rn Kottmann",
        "Created": "28/Jan/11 14:13",
        "Updated": "09/Jan/17 15:02",
        "Resolved": null,
        "Description": "There should be an OpenNLP White Paper which documents OpenNLP in a way it is needed for academic papers and theses.",
        "Issue Links": []
    },
    "OPENNLP-109": {
        "Key": "OPENNLP-109",
        "Summary": "Migrate maxent documentation to new docbook",
        "Type": "Task",
        "Status": "Closed",
        "Priority": "Major",
        "Resolution": "Fixed",
        "Affects Version/s": "None",
        "Fix Version/s": "None",
        "Component/s": "Documentation",
        "Assignee": "J\u00f6rn Kottmann",
        "Reporter": "J\u00f6rn Kottmann",
        "Created": "28/Jan/11 15:50",
        "Updated": "28/Jan/11 16:04",
        "Resolved": "28/Jan/11 16:04",
        "Description": "The maxent About page should be ported to the new docbook.",
        "Issue Links": []
    },
    "OPENNLP-110": {
        "Key": "OPENNLP-110",
        "Summary": "The documentation should shortly explain what opennlp is at the beginning",
        "Type": "Improvement",
        "Status": "Closed",
        "Priority": "Major",
        "Resolution": "Fixed",
        "Affects Version/s": "None",
        "Fix Version/s": "None",
        "Component/s": "Documentation",
        "Assignee": "J\u00f6rn Kottmann",
        "Reporter": "J\u00f6rn Kottmann",
        "Created": "28/Jan/11 16:05",
        "Updated": "28/Jan/11 16:06",
        "Resolved": "28/Jan/11 16:06",
        "Description": null,
        "Issue Links": []
    },
    "OPENNLP-111": {
        "Key": "OPENNLP-111",
        "Summary": "Write documentation about the detokenizer",
        "Type": "Improvement",
        "Status": "Closed",
        "Priority": "Minor",
        "Resolution": "Fixed",
        "Affects Version/s": "None",
        "Fix Version/s": "None",
        "Component/s": "Documentation",
        "Assignee": "J\u00f6rn Kottmann",
        "Reporter": "J\u00f6rn Kottmann",
        "Created": "31/Jan/11 19:26",
        "Updated": "31/Jan/11 20:16",
        "Resolved": "31/Jan/11 20:16",
        "Description": "There should be documentation about the detokenizer in our docbook.",
        "Issue Links": []
    },
    "OPENNLP-112": {
        "Key": "OPENNLP-112",
        "Summary": "Windows Batch File OPENNLP.BAT",
        "Type": "Improvement",
        "Status": "Closed",
        "Priority": "Major",
        "Resolution": "Fixed",
        "Affects Version/s": "tools-1.5.0-sourceforge",
        "Fix Version/s": "None",
        "Component/s": "Build, Packaging and Test",
        "Assignee": "James Kosin",
        "Reporter": "James Kosin",
        "Created": "31/Jan/11 23:54",
        "Updated": "02/Feb/11 22:50",
        "Resolved": "02/Feb/11 22:49",
        "Description": "The OPENNLP_HOME environment variable really needs the location of the installed binary libraries or (jar files).\nThe default right now assumes that the user ran the opennlp.bat file from the directory above the bin directory the batch file is located in.  This may not be the case and cause the improper path to be passed to java for running.\nWindows XP and newer contain batch file extensions that allow us to extract the path from the default environment.  Unfortunately, any OS before XP may require manual adjustments to the script (batch file) provided.",
        "Issue Links": []
    },
    "OPENNLP-113": {
        "Key": "OPENNLP-113",
        "Summary": "Updated opennlp tools included version to 1.5.1",
        "Type": "Improvement",
        "Status": "Closed",
        "Priority": "Major",
        "Resolution": "Fixed",
        "Affects Version/s": "None",
        "Fix Version/s": "None",
        "Component/s": "None",
        "Assignee": "J\u00f6rn Kottmann",
        "Reporter": "J\u00f6rn Kottmann",
        "Created": "01/Feb/11 10:50",
        "Updated": "01/Feb/11 10:51",
        "Resolved": "01/Feb/11 10:51",
        "Description": "The version in the included Version class must be updated to 1.5.1.",
        "Issue Links": []
    },
    "OPENNLP-114": {
        "Key": "OPENNLP-114",
        "Summary": "Binary distribution should contain uima xml descriptor files",
        "Type": "Improvement",
        "Status": "Closed",
        "Priority": "Major",
        "Resolution": "Fixed",
        "Affects Version/s": "None",
        "Fix Version/s": "None",
        "Component/s": "Build, Packaging and Test",
        "Assignee": "J\u00f6rn Kottmann",
        "Reporter": "J\u00f6rn Kottmann",
        "Created": "01/Feb/11 10:54",
        "Updated": "01/Feb/11 11:17",
        "Resolved": "01/Feb/11 11:17",
        "Description": "The binary distribution should contain the sample UIMA xml descriptor files and type system.",
        "Issue Links": []
    },
    "OPENNLP-115": {
        "Key": "OPENNLP-115",
        "Summary": "ObjectStream API usage in our documentation should be improved",
        "Type": "Bug",
        "Status": "Closed",
        "Priority": "Minor",
        "Resolution": "Fixed",
        "Affects Version/s": "tools-1.5.1-incubating",
        "Fix Version/s": "tools-1.5.2-incubating",
        "Component/s": "Documentation",
        "Assignee": "J\u00f6rn Kottmann",
        "Reporter": "J\u00f6rn Kottmann",
        "Created": "01/Feb/11 12:02",
        "Updated": "11/Jul/11 13:03",
        "Resolved": "11/Jul/11 13:03",
        "Description": "In our documentation the ObjectStream API should used with full error handling, to get quality code into user applications which do copy and paste.",
        "Issue Links": []
    },
    "OPENNLP-116": {
        "Key": "OPENNLP-116",
        "Summary": "Define low level Classifier API which only works on ordered int features",
        "Type": "Improvement",
        "Status": "Closed",
        "Priority": "Major",
        "Resolution": "Won't Fix",
        "Affects Version/s": "None",
        "Fix Version/s": "None",
        "Component/s": "Machine Learning",
        "Assignee": null,
        "Reporter": "J\u00f6rn Kottmann",
        "Created": "01/Feb/11 12:09",
        "Updated": "16/Jan/17 14:40",
        "Resolved": "16/Jan/17 14:40",
        "Description": "The maxent/perceptron code currently performs a mapping from String features to low level int features. Most of the code is clearly separated between these two different features, but the separation is not complete. There should be a clearly separated API for \ndealing with high level features and low level features. The API should also contain support to map high level features to low level features.\nGoal of the separation is to allow also non-string features to be mapped to the low level int features, non string features could be hash int features, or hash long features. Or a different representation of a string e.g. UTF-8 bytes.\nIn previous discussions it turned out that having both levels of API are valuable.",
        "Issue Links": []
    },
    "OPENNLP-117": {
        "Key": "OPENNLP-117",
        "Summary": "Extend download page with a maven dependency samples",
        "Type": "Improvement",
        "Status": "Closed",
        "Priority": "Minor",
        "Resolution": "Fixed",
        "Affects Version/s": "None",
        "Fix Version/s": "None",
        "Component/s": "Website",
        "Assignee": "J\u00f6rn Kottmann",
        "Reporter": "J\u00f6rn Kottmann",
        "Created": "01/Feb/11 12:13",
        "Updated": "24/May/11 13:08",
        "Resolved": "24/May/11 13:08",
        "Description": "After the release the download page should be extended with a section which explains how to add our three jar files as a maven dependency to a project. Since OpenNLP is mostly used as a library many users will be searching for this information.",
        "Issue Links": []
    },
    "OPENNLP-118": {
        "Key": "OPENNLP-118",
        "Summary": "The maxent package EventStream should be similar to the ObjectStream",
        "Type": "Improvement",
        "Status": "Closed",
        "Priority": "Major",
        "Resolution": "Fixed",
        "Affects Version/s": "None",
        "Fix Version/s": "1.6.0",
        "Component/s": "Machine Learning",
        "Assignee": "J\u00f6rn Kottmann",
        "Reporter": "J\u00f6rn Kottmann",
        "Created": "01/Feb/11 12:25",
        "Updated": "20/Feb/14 10:26",
        "Resolved": "20/Feb/14 10:26",
        "Description": "The EventStream in the maxent package should be changed in a way that it is similar to the ObjectStream in the tools package.\nIt also needs to throw exceptions, needs a close method, and maybe should support the reset, to start from the begin of the stream again.",
        "Issue Links": [
            "/jira/browse/OPENNLP-39"
        ]
    },
    "OPENNLP-119": {
        "Key": "OPENNLP-119",
        "Summary": "Restructure the maxent package and rename it to opennlp machine learning",
        "Type": "Improvement",
        "Status": "Closed",
        "Priority": "Minor",
        "Resolution": "Fixed",
        "Affects Version/s": "None",
        "Fix Version/s": "1.6.0",
        "Component/s": "Machine Learning",
        "Assignee": "J\u00f6rn Kottmann",
        "Reporter": "J\u00f6rn Kottmann",
        "Created": "01/Feb/11 12:28",
        "Updated": "03/Jan/14 13:47",
        "Resolved": "03/Jan/14 13:47",
        "Description": "The maxent package now also contains the perceptron ml code. The whole package should be restructured and renamed to opennlp machine learning. The package names should be changed to reflect this. It was proposed to name them opennlp.ml, but org.apache.opennlp.ml is also an option which should be considered.",
        "Issue Links": [
            "/jira/browse/OPENNLP-39"
        ]
    },
    "OPENNLP-120": {
        "Key": "OPENNLP-120",
        "Summary": "The maxent packages contains lots of old and unmaintained classes",
        "Type": "Improvement",
        "Status": "Closed",
        "Priority": "Minor",
        "Resolution": "Fixed",
        "Affects Version/s": "None",
        "Fix Version/s": "1.6.0",
        "Component/s": "Machine Learning",
        "Assignee": "J\u00f6rn Kottmann",
        "Reporter": "J\u00f6rn Kottmann",
        "Created": "01/Feb/11 12:32",
        "Updated": "06/Jan/14 16:22",
        "Resolved": "06/Jan/14 16:22",
        "Description": "Remove the classes which are broken or no longer used. All the old code has to be updated as part of the maxent refactoring, to ease this task only the things which are necessary should be re-factored, everything else should be dropped.\nThe code which is used by opennlp-tools is mostly only the code which is needed for training and testing, but almost none of the utility classes.\nTask: Discuss what could be removed and then remove it.",
        "Issue Links": [
            "/jira/browse/OPENNLP-39"
        ]
    },
    "OPENNLP-121": {
        "Key": "OPENNLP-121",
        "Summary": "Create test data which can be used for regression testing",
        "Type": "Improvement",
        "Status": "Closed",
        "Priority": "Major",
        "Resolution": "Duplicate",
        "Affects Version/s": "None",
        "Fix Version/s": "None",
        "Component/s": "Machine Learning",
        "Assignee": null,
        "Reporter": "J\u00f6rn Kottmann",
        "Created": "01/Feb/11 12:40",
        "Updated": "29/Aug/11 12:26",
        "Resolved": "29/Aug/11 12:26",
        "Description": "The maxent package has virtually no tests. We should create free test data (maybe just generated data) to train the maxent model and then create a regression test that ensures that the behavior of the code did not change.",
        "Issue Links": []
    },
    "OPENNLP-122": {
        "Key": "OPENNLP-122",
        "Summary": "Training code should not fail if trained with zero events",
        "Type": "Improvement",
        "Status": "Closed",
        "Priority": "Major",
        "Resolution": "Won't Fix",
        "Affects Version/s": "None",
        "Fix Version/s": "None",
        "Component/s": "Machine Learning",
        "Assignee": null,
        "Reporter": "J\u00f6rn Kottmann",
        "Created": "01/Feb/11 12:44",
        "Updated": "08/Nov/16 13:19",
        "Resolved": "08/Nov/16 13:19",
        "Description": "The current maxent training code fails with a NullPointerException when trained with zero training\nevents. That should either fail in a nicer way or do not fail at all and just return some kind of empty model.",
        "Issue Links": [
            "/jira/browse/OPENNLP-488"
        ]
    },
    "OPENNLP-123": {
        "Key": "OPENNLP-123",
        "Summary": "Feature cutoff should only be done by data indexers",
        "Type": "Improvement",
        "Status": "Closed",
        "Priority": "Minor",
        "Resolution": "Fixed",
        "Affects Version/s": "None",
        "Fix Version/s": "1.7.1",
        "Component/s": "Machine Learning",
        "Assignee": "Suneel Marthi",
        "Reporter": "J\u00f6rn Kottmann",
        "Created": "01/Feb/11 12:47",
        "Updated": "16/Jan/17 14:28",
        "Resolved": "16/Jan/17 14:28",
        "Description": "Currently the data indexers and the maxent training code can cutoff features. The feature cutoff should be removed from the maxent training code and only be done by the data indexers.",
        "Issue Links": [
            "https://github.com/apache/opennlp/pull/65"
        ]
    },
    "OPENNLP-124": {
        "Key": "OPENNLP-124",
        "Summary": "Maxent/Perceptron training should report progess back via an API",
        "Type": "Improvement",
        "Status": "Open",
        "Priority": "Major",
        "Resolution": "Unresolved",
        "Affects Version/s": "None",
        "Fix Version/s": "None",
        "Component/s": "Machine Learning",
        "Assignee": null,
        "Reporter": "J\u00f6rn Kottmann",
        "Created": "01/Feb/11 13:01",
        "Updated": "26/Jan/17 15:05",
        "Resolved": null,
        "Description": "Currently any training progress is printed to the console. The code should be changed to report the training progress back via an API. A command line training tool could use this API to print the status messages to the console. Other applications, e.g. a training server could use the reported results to display them to a user in a ui interface.",
        "Issue Links": []
    },
    "OPENNLP-125": {
        "Key": "OPENNLP-125",
        "Summary": "POS Tagger context generator should use feature generation classes",
        "Type": "Improvement",
        "Status": "Closed",
        "Priority": "Minor",
        "Resolution": "Fixed",
        "Affects Version/s": "None",
        "Fix Version/s": "1.8.0",
        "Component/s": "POS Tagger",
        "Assignee": "J\u00f6rn Kottmann",
        "Reporter": "J\u00f6rn Kottmann",
        "Created": "01/Feb/11 13:06",
        "Updated": "08/Mar/17 10:47",
        "Resolved": "08/Mar/17 10:47",
        "Description": "As part of the name finder refactoring a number of reusable feature generator classes have been created. The POS Tagger should use these classes and drop custom feature generation code as much as possible.",
        "Issue Links": [
            "https://github.com/apache/opennlp/pull/120"
        ]
    },
    "OPENNLP-126": {
        "Key": "OPENNLP-126",
        "Summary": "Source distribution top folder name should be apache-opennlp-src",
        "Type": "Bug",
        "Status": "Closed",
        "Priority": "Minor",
        "Resolution": "Fixed",
        "Affects Version/s": "None",
        "Fix Version/s": "None",
        "Component/s": "Build, Packaging and Test",
        "Assignee": "J\u00f6rn Kottmann",
        "Reporter": "J\u00f6rn Kottmann",
        "Created": "01/Feb/11 14:28",
        "Updated": "01/Feb/11 14:29",
        "Resolved": "01/Feb/11 14:29",
        "Description": "The top level folder in the distribution zip file should be named apache-opennlp-src.",
        "Issue Links": []
    },
    "OPENNLP-127": {
        "Key": "OPENNLP-127",
        "Summary": "POSTagger should check that tag dict only contains mappings to valid model outcomes",
        "Type": "Bug",
        "Status": "Closed",
        "Priority": "Minor",
        "Resolution": "Fixed",
        "Affects Version/s": "None",
        "Fix Version/s": "tools-1.5.2-incubating",
        "Component/s": "POS Tagger",
        "Assignee": "J\u00f6rn Kottmann",
        "Reporter": "J\u00f6rn Kottmann",
        "Created": "01/Feb/11 15:08",
        "Updated": "29/Jul/11 21:25",
        "Resolved": "30/May/11 08:28",
        "Description": "Currently a tag dict could contain a mapping to a pos tag which cannot occur because it is not an outcome of the underlying statistical model. The POSModel code should validate that the tag dict only contains valid tags, and if not throw an exception.\nA POSTagger with such an invalid model might fail during runtime.",
        "Issue Links": [
            "/jira/browse/OPENNLP-241"
        ]
    },
    "OPENNLP-128": {
        "Key": "OPENNLP-128",
        "Summary": "Add a getting involved page to the website",
        "Type": "Improvement",
        "Status": "Closed",
        "Priority": "Minor",
        "Resolution": "Fixed",
        "Affects Version/s": "None",
        "Fix Version/s": "None",
        "Component/s": "Website",
        "Assignee": "J\u00f6rn Kottmann",
        "Reporter": "J\u00f6rn Kottmann",
        "Created": "02/Feb/11 19:29",
        "Updated": "21/Nov/11 15:30",
        "Resolved": "21/Nov/11 15:30",
        "Description": "The website should describe how people can get involved into the development of OpenNLP.",
        "Issue Links": []
    },
    "OPENNLP-129": {
        "Key": "OPENNLP-129",
        "Summary": "Maven build should output compiler warnings",
        "Type": "Improvement",
        "Status": "Closed",
        "Priority": "Trivial",
        "Resolution": "Fixed",
        "Affects Version/s": "None",
        "Fix Version/s": "None",
        "Component/s": "Build, Packaging and Test",
        "Assignee": "J\u00f6rn Kottmann",
        "Reporter": "J\u00f6rn Kottmann",
        "Created": "09/Feb/11 18:41",
        "Updated": "09/Feb/11 20:11",
        "Resolved": "09/Feb/11 20:11",
        "Description": "The maven build shout log compiler warnings to the console. There should be no compiler warnings at\nall in our code, in some places we have them. To measure them they should be logged\nto the console and reported by the hudson build.",
        "Issue Links": []
    },
    "OPENNLP-130": {
        "Key": "OPENNLP-130",
        "Summary": "Building docbook fails without internet connection or unavailable dtd servers",
        "Type": "Bug",
        "Status": "Closed",
        "Priority": "Major",
        "Resolution": "Fixed",
        "Affects Version/s": "None",
        "Fix Version/s": "None",
        "Component/s": "Documentation",
        "Assignee": "J\u00f6rn Kottmann",
        "Reporter": "J\u00f6rn Kottmann",
        "Created": "10/Feb/11 00:48",
        "Updated": "10/Feb/11 08:39",
        "Resolved": "10/Feb/11 08:39",
        "Description": "The docbook build should not depend on servers on the internet. Instead the dtds should be retrieved from a jar file in the local maven repository.",
        "Issue Links": []
    },
    "OPENNLP-131": {
        "Key": "OPENNLP-131",
        "Summary": "Update versions in opennlp uima descriptors to 1.5.1",
        "Type": "Task",
        "Status": "Closed",
        "Priority": "Minor",
        "Resolution": "Fixed",
        "Affects Version/s": "None",
        "Fix Version/s": "None",
        "Component/s": "UIMA Integration",
        "Assignee": "J\u00f6rn Kottmann",
        "Reporter": "J\u00f6rn Kottmann",
        "Created": "23/Feb/11 12:18",
        "Updated": "23/Feb/11 13:11",
        "Resolved": "23/Feb/11 12:30",
        "Description": "Update all the versions in the descriptors to 1.5.1.",
        "Issue Links": []
    },
    "OPENNLP-132": {
        "Key": "OPENNLP-132",
        "Summary": "Add a sandbox area to subversion",
        "Type": "Task",
        "Status": "Closed",
        "Priority": "Minor",
        "Resolution": "Fixed",
        "Affects Version/s": "None",
        "Fix Version/s": "None",
        "Component/s": "None",
        "Assignee": "J\u00f6rn Kottmann",
        "Reporter": "J\u00f6rn Kottmann",
        "Created": "23/Feb/11 19:43",
        "Updated": "23/Feb/11 19:48",
        "Resolved": "23/Feb/11 19:48",
        "Description": "We decided to create a sandbox which might host various opennlp related projects/tools one day.",
        "Issue Links": []
    },
    "OPENNLP-133": {
        "Key": "OPENNLP-133",
        "Summary": "The UIMA Integration should depend on 2.3.1 instead of 2.3.0-incubating",
        "Type": "Task",
        "Status": "Closed",
        "Priority": "Major",
        "Resolution": "Fixed",
        "Affects Version/s": "None",
        "Fix Version/s": "tools-1.5.1-incubating",
        "Component/s": "UIMA Integration",
        "Assignee": "J\u00f6rn Kottmann",
        "Reporter": "J\u00f6rn Kottmann",
        "Created": "23/Feb/11 20:03",
        "Updated": "01/Mar/11 13:19",
        "Resolved": "01/Mar/11 13:19",
        "Description": "Update the dependency to the new version.",
        "Issue Links": []
    },
    "OPENNLP-134": {
        "Key": "OPENNLP-134",
        "Summary": "Prepare the opennlp-1.5.1 release candiate 1",
        "Type": "Task",
        "Status": "Closed",
        "Priority": "Major",
        "Resolution": "Fixed",
        "Affects Version/s": "None",
        "Fix Version/s": "None",
        "Component/s": "None",
        "Assignee": "J\u00f6rn Kottmann",
        "Reporter": "J\u00f6rn Kottmann",
        "Created": "23/Feb/11 23:07",
        "Updated": "02/Mar/11 16:56",
        "Resolved": "02/Mar/11 16:56",
        "Description": "Create our first release candiate. The preparation will basically update the poms to the next version and create a tag. If the rc is discarded the updates to the poms must be rolled back.",
        "Issue Links": []
    },
    "OPENNLP-135": {
        "Key": "OPENNLP-135",
        "Summary": "MD5 and SHA1 hash files should be automatically generated for the distribution artifacts",
        "Type": "Improvement",
        "Status": "Closed",
        "Priority": "Major",
        "Resolution": "Fixed",
        "Affects Version/s": "None",
        "Fix Version/s": "tools-1.5.1-incubating",
        "Component/s": "Build, Packaging and Test",
        "Assignee": "J\u00f6rn Kottmann",
        "Reporter": "J\u00f6rn Kottmann",
        "Created": "25/Feb/11 10:36",
        "Updated": "01/Mar/11 12:34",
        "Resolved": "01/Mar/11 12:34",
        "Description": "The maven build should automatically generate the md5 and sha1 checksum files for the source and binary distribution files.\nThe following addition to the opennlp-distr/pom will do that:\n<plugin>\n        <artifactId>maven-antrun-plugin</artifactId>\n        <version>1.6</version>\n        <executions>\n          <execution>\n            <id>generate checksums for binary artifacts</id>\n            <goals><goal>run</goal></goals>\n            <phase>verify</phase>\n            <configuration>\n              <target>\n                <checksum algorithm=\"sha1\" format=\"MD5SUM\">\n                  <fileset dir=\"${project.build.directory}\">\n                    <include name=\"*.zip\" />\n                    <include name=\"*.gz\" />\n                  </fileset>\n                </checksum>\n                <checksum algorithm=\"md5\" format=\"MD5SUM\">\n                  <fileset dir=\"${project.build.directory}\">\n                    <include name=\"*.zip\" />\n                    <include name=\"*.gz\" />\n                  </fileset>\n                </checksum>\n              </target>\n            </configuration>\n          </execution>\n        </executions>\n      </plugin>",
        "Issue Links": []
    },
    "OPENNLP-136": {
        "Key": "OPENNLP-136",
        "Summary": "Website should link to our wiki space",
        "Type": "Improvement",
        "Status": "Closed",
        "Priority": "Minor",
        "Resolution": "Fixed",
        "Affects Version/s": "None",
        "Fix Version/s": "None",
        "Component/s": "Website",
        "Assignee": "J\u00f6rn Kottmann",
        "Reporter": "J\u00f6rn Kottmann",
        "Created": "25/Feb/11 14:02",
        "Updated": "04/May/11 11:46",
        "Resolved": "04/May/11 11:44",
        "Description": "The website should contain a link to our wiki space which is here:\nhttps://cwiki.apache.org/OPENNLP/",
        "Issue Links": []
    },
    "OPENNLP-137": {
        "Key": "OPENNLP-137",
        "Summary": "Training cmd line tools should measure total training time",
        "Type": "Improvement",
        "Status": "Closed",
        "Priority": "Minor",
        "Resolution": "Fixed",
        "Affects Version/s": "None",
        "Fix Version/s": "1.7.1",
        "Component/s": "Command Line Interface",
        "Assignee": "Peter Thygesen",
        "Reporter": "J\u00f6rn Kottmann",
        "Created": "28/Feb/11 10:04",
        "Updated": "16/Jul/17 08:25",
        "Resolved": "14/Jan/17 16:57",
        "Description": "The command line tools for training a component should measure the total training time and output it at the end of the training.",
        "Issue Links": [
            "/jira/browse/OPENNLP-1117",
            "https://github.com/apache/opennlp/pull/44"
        ]
    },
    "OPENNLP-138": {
        "Key": "OPENNLP-138",
        "Summary": "The Name Finder always creates/uses two sets of feature generators",
        "Type": "Bug",
        "Status": "Closed",
        "Priority": "Blocker",
        "Resolution": "Fixed",
        "Affects Version/s": "tools-1.5.0-sourceforge",
        "Fix Version/s": "tools-1.5.1-incubating",
        "Component/s": "Name Finder",
        "Assignee": "J\u00f6rn Kottmann",
        "Reporter": "J\u00f6rn Kottmann",
        "Created": "01/Mar/11 11:51",
        "Updated": "02/Mar/11 09:35",
        "Resolved": "01/Mar/11 12:34",
        "Description": "The NameFinderME during initialization either creates default feature generators or uses a set of feature generators provided by the user. In both cases the NameFinderME code calls the DefaultNameContextGenerator() constructor and then adds the feature generators to the context generator. The code ignores the fact that DefaultNameContextGenerator creates default feature generators on its own. The add call does not replace the existing feature generation, but really adds them, so now there are two sets of feature generators.",
        "Issue Links": []
    },
    "OPENNLP-139": {
        "Key": "OPENNLP-139",
        "Summary": "Prepare the opennlp-1.5.1 Release Candiate 2",
        "Type": "Task",
        "Status": "Closed",
        "Priority": "Major",
        "Resolution": "Fixed",
        "Affects Version/s": "None",
        "Fix Version/s": "None",
        "Component/s": "None",
        "Assignee": "J\u00f6rn Kottmann",
        "Reporter": "J\u00f6rn Kottmann",
        "Created": "02/Mar/11 17:01",
        "Updated": "16/Mar/11 08:42",
        "Resolved": "16/Mar/11 08:42",
        "Description": "Prepare the second release candidate.",
        "Issue Links": []
    },
    "OPENNLP-140": {
        "Key": "OPENNLP-140",
        "Summary": "Root folder in distributables should contain version, e.g. apache-opennlp-1.5.1",
        "Type": "Improvement",
        "Status": "Closed",
        "Priority": "Minor",
        "Resolution": "Fixed",
        "Affects Version/s": "None",
        "Fix Version/s": "tools-1.5.1-incubating",
        "Component/s": "Build, Packaging and Test",
        "Assignee": "J\u00f6rn Kottmann",
        "Reporter": "J\u00f6rn Kottmann",
        "Created": "02/Mar/11 22:49",
        "Updated": "16/Mar/11 09:08",
        "Resolved": "16/Mar/11 09:08",
        "Description": "Most apache projects have to the version included in the root folder name e.g. apache-opennlp-1.5.1 instead\nof just apache-opennlp. We should also do that.",
        "Issue Links": []
    },
    "OPENNLP-141": {
        "Key": "OPENNLP-141",
        "Summary": "Tokenizers alpha numeric optimization only recognizes a-z as alpha chars",
        "Type": "Bug",
        "Status": "Closed",
        "Priority": "Minor",
        "Resolution": "Fixed",
        "Affects Version/s": "tools-1.5.0-sourceforge",
        "Fix Version/s": "2.2.0",
        "Component/s": "Tokenizer",
        "Assignee": "Martin Wiesner",
        "Reporter": "J\u00f6rn Kottmann",
        "Created": "03/Mar/11 13:06",
        "Updated": "22/Apr/23 17:39",
        "Resolved": "02/Mar/23 06:20",
        "Description": "The Tokenizer has an optimization which skips tokens which are only made of numerics or alpha chars. In foreign languages the alpha chars contain umlauts and other letters which are not included in the a-z range.",
        "Issue Links": [
            "/jira/browse/OPENNLP-1474"
        ]
    },
    "OPENNLP-142": {
        "Key": "OPENNLP-142",
        "Summary": "NameFinderTrainer: Invalid tag in training data error is hard to find",
        "Type": "Improvement",
        "Status": "Closed",
        "Priority": "Trivial",
        "Resolution": "Fixed",
        "Affects Version/s": "None",
        "Fix Version/s": "tools-1.5.2-incubating",
        "Component/s": "Name Finder",
        "Assignee": "J\u00f6rn Kottmann",
        "Reporter": "J\u00f6rn Kottmann",
        "Created": "04/Mar/11 11:11",
        "Updated": "30/May/11 12:22",
        "Resolved": "30/May/11 12:22",
        "Description": "When the Name Finder is trained with a training file which has multiple <START> tags in a row or is missing an <END> tag the training fails with an error message like this:\n\"Found unexpected annotation <START:organization> while handling a name sequence.\"\nNow it is difficult to figure out where in the training data the mistake actually is. To make that easier the error message should also contain tokens before and after the tag.",
        "Issue Links": []
    },
    "OPENNLP-143": {
        "Key": "OPENNLP-143",
        "Summary": "createPear.sh fails because the opennlp uima jar file is referenced by its snapshot file name",
        "Type": "Bug",
        "Status": "Closed",
        "Priority": "Major",
        "Resolution": "Fixed",
        "Affects Version/s": "None",
        "Fix Version/s": "tools-1.5.1-incubating",
        "Component/s": "UIMA Integration",
        "Assignee": "J\u00f6rn Kottmann",
        "Reporter": "J\u00f6rn Kottmann",
        "Created": "04/Mar/11 15:25",
        "Updated": "16/Mar/11 15:35",
        "Resolved": "16/Mar/11 15:35",
        "Description": "The createPear.sh script fails because the opennlp uima jar file is referenced by its full name\nincluding the version with the snapshot tag. The snapshot tag is not included in the release version\nof 1.5.1 and therefore the jar file cannot be found.\nThe file should be referenced with referencing the version at all, then it will also work for\nfuture versions.\nIt work when the script is modified like this:\n<file name=\"target/opennlp-uima-*.jar\"/>",
        "Issue Links": []
    },
    "OPENNLP-144": {
        "Key": "OPENNLP-144",
        "Summary": "POSTaggerME should be able to use a custom Sequence Validator",
        "Type": "Improvement",
        "Status": "Closed",
        "Priority": "Minor",
        "Resolution": "Fixed",
        "Affects Version/s": "None",
        "Fix Version/s": "tools-1.5.2-incubating",
        "Component/s": "POS Tagger",
        "Assignee": "J\u00f6rn Kottmann",
        "Reporter": "J\u00f6rn Kottmann",
        "Created": "15/Mar/11 14:05",
        "Updated": "31/May/11 11:20",
        "Resolved": "31/May/11 11:20",
        "Description": "The POSTaggerME uses a Sequence Validator to limit the output to a \"valid\" sequence. it should be possible to pass in a custom sequence validator. The passed-in sequence validator might be created by a researcher to test a new method of sequence validation or some pre-defined OpenNLP sequence validation.",
        "Issue Links": []
    },
    "OPENNLP-145": {
        "Key": "OPENNLP-145",
        "Summary": "Prepare the opennlp-1.5.1 Release Candiate 3",
        "Type": "Task",
        "Status": "Closed",
        "Priority": "Major",
        "Resolution": "Fixed",
        "Affects Version/s": "None",
        "Fix Version/s": "None",
        "Component/s": "None",
        "Assignee": "J\u00f6rn Kottmann",
        "Reporter": "J\u00f6rn Kottmann",
        "Created": "16/Mar/11 08:42",
        "Updated": "16/Mar/11 10:52",
        "Resolved": "16/Mar/11 10:52",
        "Description": "One more RC.",
        "Issue Links": []
    },
    "OPENNLP-146": {
        "Key": "OPENNLP-146",
        "Summary": "Prepare the opennlp-1.5.1 Release Candiate 4",
        "Type": "Task",
        "Status": "Closed",
        "Priority": "Major",
        "Resolution": "Fixed",
        "Affects Version/s": "None",
        "Fix Version/s": "None",
        "Component/s": "None",
        "Assignee": "J\u00f6rn Kottmann",
        "Reporter": "J\u00f6rn Kottmann",
        "Created": "16/Mar/11 11:14",
        "Updated": "18/Mar/11 15:04",
        "Resolved": "18/Mar/11 15:04",
        "Description": null,
        "Issue Links": []
    },
    "OPENNLP-147": {
        "Key": "OPENNLP-147",
        "Summary": "Prepare the opennlp-1.5.1 Release Candiate 5",
        "Type": "Task",
        "Status": "Closed",
        "Priority": "Major",
        "Resolution": "Fixed",
        "Affects Version/s": "None",
        "Fix Version/s": "None",
        "Component/s": "None",
        "Assignee": "J\u00f6rn Kottmann",
        "Reporter": "J\u00f6rn Kottmann",
        "Created": "21/Mar/11 10:03",
        "Updated": "03/May/11 12:47",
        "Resolved": "03/May/11 12:47",
        "Description": "Create the next RC:",
        "Issue Links": []
    },
    "OPENNLP-148": {
        "Key": "OPENNLP-148",
        "Summary": "NOTICE file is missing JWNL and UIMA notice",
        "Type": "Bug",
        "Status": "Closed",
        "Priority": "Major",
        "Resolution": "Fixed",
        "Affects Version/s": "None",
        "Fix Version/s": "None",
        "Component/s": "Build, Packaging and Test",
        "Assignee": "J\u00f6rn Kottmann",
        "Reporter": "J\u00f6rn Kottmann",
        "Created": "30/Mar/11 09:05",
        "Updated": "26/Apr/11 08:11",
        "Resolved": "30/Mar/11 09:06",
        "Description": "Add the JWNL and Apache UIMA notice to our notice file which is shipped inside the binary distribution.",
        "Issue Links": []
    },
    "OPENNLP-149": {
        "Key": "OPENNLP-149",
        "Summary": "POSTaggerTrainer cmd line tool prints wrong parameter name in help message",
        "Type": "Bug",
        "Status": "Closed",
        "Priority": "Minor",
        "Resolution": "Fixed",
        "Affects Version/s": "None",
        "Fix Version/s": "tools-1.5.1-incubating",
        "Component/s": "Command Line Interface",
        "Assignee": "J\u00f6rn Kottmann",
        "Reporter": "J\u00f6rn Kottmann",
        "Created": "31/Mar/11 14:19",
        "Updated": "31/Mar/11 14:20",
        "Resolved": "31/Mar/11 14:20",
        "Description": "The POSTaggerTrainer tool prints -model instead of -model-type in the help message. To solve this issue fix the print statement to print out the correct parameter name.",
        "Issue Links": []
    },
    "OPENNLP-150": {
        "Key": "OPENNLP-150",
        "Summary": "UIMA Trainers' descriptors miss the language parameter",
        "Type": "Bug",
        "Status": "Closed",
        "Priority": "Major",
        "Resolution": "Fixed",
        "Affects Version/s": "None",
        "Fix Version/s": "tools-1.5.1-incubating",
        "Component/s": "UIMA Integration",
        "Assignee": "J\u00f6rn Kottmann",
        "Reporter": "Tommaso Teofili",
        "Created": "02/Apr/11 11:24",
        "Updated": "13/Apr/11 09:24",
        "Resolved": "13/Apr/11 09:24",
        "Description": "The trainers' descriptors miss the language parameter which is instead required by the used implementation as a mandatory parameter needed to train the (language dependent) models",
        "Issue Links": []
    },
    "OPENNLP-151": {
        "Key": "OPENNLP-151",
        "Summary": "TokenizerTrainer throws NPE",
        "Type": "Bug",
        "Status": "Closed",
        "Priority": "Major",
        "Resolution": "Fixed",
        "Affects Version/s": "None",
        "Fix Version/s": "tools-1.5.1-incubating",
        "Component/s": "UIMA Integration",
        "Assignee": "J\u00f6rn Kottmann",
        "Reporter": "J\u00f6rn Kottmann",
        "Created": "05/Apr/11 17:49",
        "Updated": "05/Apr/11 17:51",
        "Resolved": "05/Apr/11 17:51",
        "Description": "\"Just today I was testing the TokenizerTrainer and I found a bug there with\nthe isSkipAlphaNumerics parameter: in the initialize() method, I see that\nit's defined as a local variable too so the instance variable gets never\nassigned and this causes a NPE on the collectionProcessComplete().\nThe fix is in just removing the \"Boolean\" type definition at line 111 of\nTokenizerTrainer [1] which allows assignment of configuration parameter\nvalue to the instance variable.\n[1] :\nhttp://svn.apache.org/viewvc/incubator/opennlp/trunk/opennlp-uima/src/main/java/opennlp/uima/tokenize/TokenizerTrainer.java?view=markup\n\" (Tommaso Teofili)",
        "Issue Links": []
    },
    "OPENNLP-152": {
        "Key": "OPENNLP-152",
        "Summary": "English language detokenization model",
        "Type": "Improvement",
        "Status": "Closed",
        "Priority": "Minor",
        "Resolution": "Fixed",
        "Affects Version/s": "tools-1.5.1-incubating",
        "Fix Version/s": "tools-1.5.2-incubating",
        "Component/s": "Tokenizer",
        "Assignee": "J\u00f6rn Kottmann",
        "Reporter": "Lee Hinman",
        "Created": "12/Apr/11 16:30",
        "Updated": "17/May/11 09:12",
        "Resolved": "17/May/11 09:12",
        "Description": "Here's the english language detokenization model I've been working on and using for a while.",
        "Issue Links": []
    },
    "OPENNLP-153": {
        "Key": "OPENNLP-153",
        "Summary": "Prepare the opennlp-1.5.1 Release Candiate 6",
        "Type": "Task",
        "Status": "Closed",
        "Priority": "Major",
        "Resolution": "Fixed",
        "Affects Version/s": "None",
        "Fix Version/s": "None",
        "Component/s": "None",
        "Assignee": "J\u00f6rn Kottmann",
        "Reporter": "J\u00f6rn Kottmann",
        "Created": "13/Apr/11 08:53",
        "Updated": "26/Apr/11 07:18",
        "Resolved": "26/Apr/11 07:18",
        "Description": null,
        "Issue Links": []
    },
    "OPENNLP-154": {
        "Key": "OPENNLP-154",
        "Summary": "normalization in perceptron",
        "Type": "Bug",
        "Status": "Closed",
        "Priority": "Minor",
        "Resolution": "Fixed",
        "Affects Version/s": "maxent-3.0.1-incubating",
        "Fix Version/s": "tools-1.5.2-incubating,                                            maxent-3.0.2-incubating",
        "Component/s": "Machine Learning",
        "Assignee": "Jason Baldridge",
        "Reporter": "Jason Baldridge",
        "Created": "14/Apr/11 03:21",
        "Updated": "22/Jun/11 10:23",
        "Resolved": "22/Jun/11 10:23",
        "Description": "I found some issues with the way perceptron output was normalized. It was sort of a strange way to handle negative numbers that didn't really work.",
        "Issue Links": []
    },
    "OPENNLP-155": {
        "Key": "OPENNLP-155",
        "Summary": "unreliable training set accuracy in perceptron",
        "Type": "Improvement",
        "Status": "Closed",
        "Priority": "Minor",
        "Resolution": "Fixed",
        "Affects Version/s": "maxent-3.0.1-incubating",
        "Fix Version/s": "tools-1.5.1-incubating,                                            maxent-3.0.1-incubating",
        "Component/s": "Machine Learning",
        "Assignee": "Jason Baldridge",
        "Reporter": "Jason Baldridge",
        "Created": "14/Apr/11 03:24",
        "Updated": "08/Jun/11 08:01",
        "Resolved": "08/Jun/11 04:42",
        "Description": "The training accuracies reported during perceptron training were much higher than final training accuracy, which turned out to be an artifact of the way training examples were ordered.",
        "Issue Links": []
    },
    "OPENNLP-156": {
        "Key": "OPENNLP-156",
        "Summary": "improve command line apps (ModelTrainer and ModelApplier) for maxent",
        "Type": "Improvement",
        "Status": "Closed",
        "Priority": "Minor",
        "Resolution": "Fixed",
        "Affects Version/s": "maxent-3.0.1-incubating",
        "Fix Version/s": "tools-1.5.1-incubating,                                            maxent-3.0.1-incubating",
        "Component/s": "Machine Learning",
        "Assignee": "J\u00f6rn Kottmann",
        "Reporter": "Jason Baldridge",
        "Created": "14/Apr/11 03:35",
        "Updated": "26/Apr/11 06:55",
        "Resolved": "26/Apr/11 06:55",
        "Description": "Several improvements needed:\n\nOutput was mirroring WEKA file output, which includes lots of extra stuff \u2013 better to just kick out what the model says. Output should be given for one event per line, with the most probable label first followed by its probability, then the next most probable, followed by its probability, etc. This means the best label can be plucked out easily as the first label on each line, but a user has access to the full distribution if desired.\n\n\nModelTrainer allowed perceptron option, but then wrote model to disk as a GISModel.\n\n\nModelTrainer didn't pass options for cutoffs and number of iterations to the Perceptron trainer.\n\n\nModelApplier usage didn't get printed when no arguments were given.",
        "Issue Links": []
    },
    "OPENNLP-157": {
        "Key": "OPENNLP-157",
        "Summary": "incorrect link for en-ner-time.bin on model download page",
        "Type": "Bug",
        "Status": "Closed",
        "Priority": "Trivial",
        "Resolution": "Fixed",
        "Affects Version/s": "tools-1.5.0-sourceforge,                                            tools-1.5.1-incubating",
        "Fix Version/s": "None",
        "Component/s": "Website",
        "Assignee": "J\u00f6rn Kottmann",
        "Reporter": "Michael Wojcik",
        "Created": "23/Apr/11 15:02",
        "Updated": "04/May/11 11:05",
        "Resolved": "04/May/11 11:05",
        "Description": "The link for en-ner-time.bin on the Sourceforge models download page (http://opennlp.sourceforge.net/models-1.5/, which the Apache download page links to) is wrong. It links to http://opennlp.sourceforge.net/models-1.5/en-sent.bin instead. Clearly just a cut-and-paste error when the page was created.\nI did a quick visual scan of the other links (using WebDeveloper's View link details) and didn't see any other errors.",
        "Issue Links": []
    },
    "OPENNLP-158": {
        "Key": "OPENNLP-158",
        "Summary": "Prepare the opennlp-1.5.1 Release Candiate 7",
        "Type": "Task",
        "Status": "Closed",
        "Priority": "Major",
        "Resolution": "Fixed",
        "Affects Version/s": "None",
        "Fix Version/s": "None",
        "Component/s": "None",
        "Assignee": "J\u00f6rn Kottmann",
        "Reporter": "J\u00f6rn Kottmann",
        "Created": "26/Apr/11 07:20",
        "Updated": "10/May/11 13:46",
        "Resolved": "10/May/11 13:46",
        "Description": "One more RC to include the recent changes to maxent.",
        "Issue Links": []
    },
    "OPENNLP-159": {
        "Key": "OPENNLP-159",
        "Summary": "Wrong link in models download area",
        "Type": "Bug",
        "Status": "Closed",
        "Priority": "Trivial",
        "Resolution": "Fixed",
        "Affects Version/s": "None",
        "Fix Version/s": "None",
        "Component/s": "Website",
        "Assignee": "J\u00f6rn Kottmann",
        "Reporter": "Jason Baldridge",
        "Created": "27/Apr/11 21:34",
        "Updated": "04/May/11 11:04",
        "Resolved": "04/May/11 11:04",
        "Description": "There's a bug in the en-ner-time.bin link on that SourceForge page; it points to http://opennlp.sourceforge.net/models-1.5/en-sent.bin.",
        "Issue Links": []
    },
    "OPENNLP-160": {
        "Key": "OPENNLP-160",
        "Summary": "Add other resources page to web-site",
        "Type": "Improvement",
        "Status": "Closed",
        "Priority": "Minor",
        "Resolution": "Fixed",
        "Affects Version/s": "None",
        "Fix Version/s": "None",
        "Component/s": "Website",
        "Assignee": "J\u00f6rn Kottmann",
        "Reporter": "James Kosin",
        "Created": "27/Apr/11 22:19",
        "Updated": "19/Nov/11 15:23",
        "Resolved": "19/Nov/11 15:23",
        "Description": "Add a page with external links to other resources on other sites for good examples or demonstations of OpenNLP usage.",
        "Issue Links": []
    },
    "OPENNLP-161": {
        "Key": "OPENNLP-161",
        "Summary": "SentenceDetectorEvaluator has incorrect validation for number of command line arguments",
        "Type": "Bug",
        "Status": "Closed",
        "Priority": "Minor",
        "Resolution": "Fixed",
        "Affects Version/s": "tools-1.5.1-incubating",
        "Fix Version/s": "tools-1.5.2-incubating",
        "Component/s": "Sentence Detector",
        "Assignee": null,
        "Reporter": "Stanislav Peshterliev",
        "Created": "30/Apr/11 15:24",
        "Updated": "03/May/11 12:44",
        "Resolved": "03/May/11 12:44",
        "Description": "When I execute\n\nopennlp SentenceDetectorEvaluator -encoding UTF-8 -model pt.sentdetect.model -data pt.sentdetect.test\n\n\nthe result is \n\nUsage: opennlp SentenceDetectorEvaluator -encoding charset -model model -data testData\n\n\nI got the usage message although the right number of arguments.  After short investigation I have found out that in the class SentenceDetectorEvaluatorTool, the validation for number of arguments is incorrect.\n\n    if (args.length != 4) {\n      System.out.println(getHelp());\n      throw new TerminateToolException(1);\n    }\n\n\nActually args.length is 6. Changing the condition to args.length < 6 solves the problem.",
        "Issue Links": []
    },
    "OPENNLP-162": {
        "Key": "OPENNLP-162",
        "Summary": "Update download page to host the 1.5.1 release",
        "Type": "Task",
        "Status": "Closed",
        "Priority": "Major",
        "Resolution": "Fixed",
        "Affects Version/s": "None",
        "Fix Version/s": "None",
        "Component/s": "Website",
        "Assignee": "J\u00f6rn Kottmann",
        "Reporter": "J\u00f6rn Kottmann",
        "Created": "02/May/11 17:10",
        "Updated": "03/May/11 18:35",
        "Resolved": "03/May/11 18:35",
        "Description": "Our first release is out, now the download page needs to be updated to publish this release.",
        "Issue Links": []
    },
    "OPENNLP-163": {
        "Key": "OPENNLP-163",
        "Summary": "Add a news item about the 1.5.1-incubating release to the web site",
        "Type": "Task",
        "Status": "Closed",
        "Priority": "Major",
        "Resolution": "Fixed",
        "Affects Version/s": "None",
        "Fix Version/s": "None",
        "Component/s": "Website",
        "Assignee": "James Kosin",
        "Reporter": "J\u00f6rn Kottmann",
        "Created": "02/May/11 19:21",
        "Updated": "03/May/11 07:52",
        "Resolved": "03/May/11 01:57",
        "Description": "We should announce the release of opennnlp-1.5.1-incubating on our web site.",
        "Issue Links": []
    },
    "OPENNLP-164": {
        "Key": "OPENNLP-164",
        "Summary": "Add 1.5.1-incubating documentation to the website",
        "Type": "Task",
        "Status": "Closed",
        "Priority": "Major",
        "Resolution": "Fixed",
        "Affects Version/s": "None",
        "Fix Version/s": "None",
        "Component/s": "Website",
        "Assignee": "J\u00f6rn Kottmann",
        "Reporter": "J\u00f6rn Kottmann",
        "Created": "02/May/11 19:24",
        "Updated": "03/May/11 17:26",
        "Resolved": "03/May/11 17:26",
        "Description": "The website documentation page should contains links which point to our javadoc and docbook documentation.",
        "Issue Links": []
    },
    "OPENNLP-165": {
        "Key": "OPENNLP-165",
        "Summary": "Remove slack feature from GISTrainer",
        "Type": "Improvement",
        "Status": "Closed",
        "Priority": "Trivial",
        "Resolution": "Fixed",
        "Affects Version/s": "None",
        "Fix Version/s": "maxent-3.0.2-incubating",
        "Component/s": "Machine Learning",
        "Assignee": "J\u00f6rn Kottmann",
        "Reporter": "J\u00f6rn Kottmann",
        "Created": "03/May/11 10:57",
        "Updated": "03/May/11 14:58",
        "Resolved": "03/May/11 14:58",
        "Description": "The GISTrainer once used a slack variable, but some time ago this was disabled in the code via a flag. The flag and slack variable computation code should be removed from the GISTrainer",
        "Issue Links": [
            "/jira/browse/OPENNLP-39"
        ]
    },
    "OPENNLP-166": {
        "Key": "OPENNLP-166",
        "Summary": "Remove slack parameter from GISModel",
        "Type": "Improvement",
        "Status": "Closed",
        "Priority": "Minor",
        "Resolution": "Fixed",
        "Affects Version/s": "None",
        "Fix Version/s": "1.7.1",
        "Component/s": "Machine Learning",
        "Assignee": "J\u00f6rn Kottmann",
        "Reporter": "J\u00f6rn Kottmann",
        "Created": "03/May/11 12:40",
        "Updated": "18/Jan/17 14:53",
        "Resolved": "18/Jan/17 14:53",
        "Description": "The support for a slack parameter inside the model should be removed from the GISModel class. Only old models which have been trained prior maxent 3.0 can have such a slack parameter or correction constant. The training code since maxent 3.0 always sets the correction constant to 1 to support backward compatibility with old models.\nSince the removal will break backward compatibility it should be aligned with the opennlp-ml redesign.\nThe support to train models with a slack parameter has been completely removed in OPENNLP-165.",
        "Issue Links": [
            "https://github.com/apache/opennlp/pull/72"
        ]
    },
    "OPENNLP-167": {
        "Key": "OPENNLP-167",
        "Summary": "Remove build instructions from source page",
        "Type": "Improvement",
        "Status": "Closed",
        "Priority": "Trivial",
        "Resolution": "Fixed",
        "Affects Version/s": "None",
        "Fix Version/s": "None",
        "Component/s": "Website",
        "Assignee": "James Kosin",
        "Reporter": "J\u00f6rn Kottmann",
        "Created": "03/May/11 19:34",
        "Updated": "04/May/11 07:41",
        "Resolved": "04/May/11 04:22",
        "Description": "The build instructions should be removed from the source page, because there is now a separate page for them.",
        "Issue Links": []
    },
    "OPENNLP-168": {
        "Key": "OPENNLP-168",
        "Summary": "opennlp-uima jar file is missing in binary distribution",
        "Type": "Bug",
        "Status": "Closed",
        "Priority": "Major",
        "Resolution": "Fixed",
        "Affects Version/s": "tools-1.5.1-incubating",
        "Fix Version/s": "tools-1.5.2-incubating",
        "Component/s": "Build, Packaging and Test",
        "Assignee": "J\u00f6rn Kottmann",
        "Reporter": "J\u00f6rn Kottmann",
        "Created": "06/May/11 11:22",
        "Updated": "06/May/11 11:35",
        "Resolved": "06/May/11 11:35",
        "Description": "The opennlp-uima jar file is not included in our binary distribution, but it should be.\nFix the assembly script to also include the opennlp-uima jar file in the distribution.",
        "Issue Links": []
    },
    "OPENNLP-169": {
        "Key": "OPENNLP-169",
        "Summary": "NameFinder should use combo iterator",
        "Type": "Improvement",
        "Status": "Closed",
        "Priority": "Minor",
        "Resolution": "Fixed",
        "Affects Version/s": "tools-1.5.1-incubating",
        "Fix Version/s": "tools-1.5.2-incubating",
        "Component/s": "UIMA Integration",
        "Assignee": "J\u00f6rn Kottmann",
        "Reporter": "J\u00f6rn Kottmann",
        "Created": "10/May/11 13:50",
        "Updated": "10/May/11 13:53",
        "Resolved": "10/May/11 13:53",
        "Description": "The POS Tagger and other components have been updated to use an improved combo iterator to iterator over the sentences and tokens inside a CAS. The name finder was never updated to use this new combo iterator also, but it should be, since the combo iterator is especially for large documents faster than the currently implemented approach.",
        "Issue Links": []
    },
    "OPENNLP-170": {
        "Key": "OPENNLP-170",
        "Summary": "OpenNLP Maxent miscalculates for real values < 1",
        "Type": "Bug",
        "Status": "Closed",
        "Priority": "Major",
        "Resolution": "Fixed",
        "Affects Version/s": "maxent-3.0.0-sourceforge",
        "Fix Version/s": "tools-1.5.2-incubating,                                            maxent-3.0.2-incubating",
        "Component/s": "Machine Learning",
        "Assignee": "J\u00f6rn Kottmann",
        "Reporter": "Assaf Urieli",
        "Created": "12/May/11 09:29",
        "Updated": "24/Aug/11 21:50",
        "Resolved": "24/Aug/11 21:50",
        "Description": "When using predicates with real values, entering real values predA=0.1 predB=0.2 gives different results than predA=10, predB=20\nHowever, using predA=1, predB=2 gives the same results as predA=10, predB=20.\nTest below:\npackage openMaxentTest;\nimport java.io.StringReader;\nimport junit.framework.TestCase;\nimport opennlp.maxent.GIS;\nimport opennlp.maxent.PlainTextByLineDataStream;\nimport opennlp.maxent.RealBasicEventStream;\nimport opennlp.model.EventStream;\nimport opennlp.model.MaxentModel;\nimport opennlp.model.OnePassRealValueDataIndexer;\nimport opennlp.model.RealValueFileEventStream;\npublic class ScaleDoesntMatterTest extends TestCase {\n\t/**\n\nThis test sets out to prove that the scale you use on real valued predicates\ndoesn't matter when it comes the probability assigned to each outcome.\nStrangely, if we use (1,2) and (10,20) there's no difference.\nIf we use (0.1,0.2) and (10,20) there is a difference.\n@throws Exception\n\t */\n\tpublic void testScaleResults() throws Exception \n{\n\t\tString smallValues = \"predA=0.1 predB=0.2 A\\n\" +\n\t\t\t\t\"predB=0.3 predA=0.1 B\\n\";\n\t\t\n\t\tString smallTest = \"predA=0.2 predB=0.2\";\n\t\t\n\t\tString largeValues = \"predA=10 predB=20 A\\n\" +\n\t\t\t\t\"predB=30 predA=10 B\\n\";\n\t\t\n\t\tString largeTest = \"predA=20 predB=20\";\n\t\t\n\t\tStringReader smallReader = new StringReader(smallValues);\n\t\tEventStream smallEventStream = new RealBasicEventStream(new PlainTextByLineDataStream(smallReader));\n\n\t\tMaxentModel smallModel = GIS.trainModel(2, new OnePassRealValueDataIndexer(smallEventStream,0), false);\n\t\tString[] contexts = smallTest.split(\" \");\n\t\tfloat[] values = RealValueFileEventStream.parseContexts(contexts);\n\t\tdouble[] ocs = smallModel.eval(contexts, values);\n\t\t\n\t\tString smallResults = smallModel.getAllOutcomes(ocs);\n\t\tSystem.out.println(\"smallResults: \" + smallResults);\n\t\t\n\t\tStringReader largeReader = new StringReader(largeValues);\n\t\tEventStream largeEventStream = new RealBasicEventStream(new PlainTextByLineDataStream(largeReader));\n\n\t\tMaxentModel largeModel = GIS.trainModel(2, new OnePassRealValueDataIndexer(largeEventStream,0), false);\n\t\tcontexts = largeTest.split(\" \");\n\t\tvalues = RealValueFileEventStream.parseContexts(contexts);\n\t\tocs = largeModel.eval(contexts, values);\n\t\t\n\t\tString largeResults = smallModel.getAllOutcomes(ocs);\n\t\tSystem.out.println(\"largeResults: \" + largeResults);\n\t\t\n\t\tassertEquals(smallResults, largeResults);\n\t\t\n\t}\n}\n\nThe problem concerns the correctionConstant in GISTrainer, which is set to be an integer. I implemented the following fix in class GISTrainer:\n    // determine the correction constant and its inverse\n    //int correctionConstant = 1;\n    float correctionConstant = 0;\n    for (int ci = 0; ci < contexts.length; ci++) {\n      if (values == null || values[ci] == null) {\n        if (contexts[ci].length > correctionConstant) \n{\n          correctionConstant = contexts[ci].length;\n        }\n      }\n      else {\n        float cl = values[ci][0];\n        for (int vi=1;vi<values[ci].length;vi++) \n{\n          cl+=values[ci][vi];\n        }\n\n        if (cl > correctionConstant) \n{\n          //correctionConstant=(int) Math.ceil(cl);\n          correctionConstant= cl;\n        }\n      }\n    }\nI'd be curious to know if there's a reason for using an integer correctionConstant.\nRgds,\nAssaf Urieli",
        "Issue Links": []
    },
    "OPENNLP-171": {
        "Key": "OPENNLP-171",
        "Summary": "DictionarySerializer should not close the InputStream",
        "Type": "Bug",
        "Status": "Closed",
        "Priority": "Minor",
        "Resolution": "Fixed",
        "Affects Version/s": "tools-1.5.1-incubating",
        "Fix Version/s": "tools-1.5.2-incubating",
        "Component/s": "None",
        "Assignee": "J\u00f6rn Kottmann",
        "Reporter": "J\u00f6rn Kottmann",
        "Created": "12/May/11 12:37",
        "Updated": "12/May/11 12:39",
        "Resolved": "12/May/11 12:39",
        "Description": "The DictionarySerializer closes the passed Input Stream after the dictionary is read. The Input Stream should stay open, because it is the responsibility of the one who created the Input Stream to close it.",
        "Issue Links": []
    },
    "OPENNLP-172": {
        "Key": "OPENNLP-172",
        "Summary": "Replace the regex token class feature generation with the Character class/unicode based implementation",
        "Type": "Improvement",
        "Status": "Closed",
        "Priority": "Minor",
        "Resolution": "Fixed",
        "Affects Version/s": "tools-1.5.1-incubating",
        "Fix Version/s": "tools-1.5.2-incubating",
        "Component/s": "Name Finder",
        "Assignee": "J\u00f6rn Kottmann",
        "Reporter": "J\u00f6rn Kottmann",
        "Created": "16/May/11 12:47",
        "Updated": "17/May/11 11:15",
        "Resolved": "17/May/11 11:15",
        "Description": "The token class feature is computed with the help of regular expression, the regular expressions do not detect all-letter sequences correctly when they contain other letters than A to Z. The new token class feature method uses unicode to detect letters and that works better and is faster.  \nThe old regular expression based token class feature computation should be replaced with the new fast token class method.\nAn evaluation on our spanish data showed that his change will reduce the recall of the spanish person model by 2% and precision is identical. But when the model is retrained with this fix applied the recall increases by 6%, and precision is still identical.\nRecall and Precision are identical on my test data for english, because it usually do not contain \"special\" characters.\nThe speed up of the name finder will be roughly 10%.\nA measurement on the Leipzig corpus with 300K sentences increased the throughput from 556 sent/s to 618 sent/s.",
        "Issue Links": []
    },
    "OPENNLP-173": {
        "Key": "OPENNLP-173",
        "Summary": "Add a test for the StringPattern class",
        "Type": "Test",
        "Status": "Closed",
        "Priority": "Trivial",
        "Resolution": "Fixed",
        "Affects Version/s": "tools-1.5.1-incubating",
        "Fix Version/s": "tools-1.5.2-incubating",
        "Component/s": "None",
        "Assignee": "J\u00f6rn Kottmann",
        "Reporter": "J\u00f6rn Kottmann",
        "Created": "17/May/11 09:08",
        "Updated": "17/May/11 09:09",
        "Resolved": "17/May/11 09:09",
        "Description": "There should be a test to validate the StringPattern class.",
        "Issue Links": []
    },
    "OPENNLP-174": {
        "Key": "OPENNLP-174",
        "Summary": "Add english pos tagdict and parser head rule file to new lang folder",
        "Type": "Improvement",
        "Status": "Closed",
        "Priority": "Minor",
        "Resolution": "Fixed",
        "Affects Version/s": "tools-1.5.1-incubating",
        "Fix Version/s": "tools-1.5.2-incubating",
        "Component/s": "Parser,                                            POS Tagger",
        "Assignee": "J\u00f6rn Kottmann",
        "Reporter": "J\u00f6rn Kottmann",
        "Created": "17/May/11 09:20",
        "Updated": "17/May/11 09:22",
        "Resolved": "17/May/11 09:22",
        "Description": "Add the two files to the lang folder.",
        "Issue Links": []
    },
    "OPENNLP-175": {
        "Key": "OPENNLP-175",
        "Summary": "Add support to influence all available machine learning settings during training of all our components",
        "Type": "Improvement",
        "Status": "Closed",
        "Priority": "Major",
        "Resolution": "Fixed",
        "Affects Version/s": "None",
        "Fix Version/s": "tools-1.5.2-incubating",
        "Component/s": "Chunker,                                            Doccat,                                            Machine Learning,                                            Name Finder,                                            Parser,                                            POS Tagger,                                            Sentence Detector,                                            Tokenizer",
        "Assignee": "J\u00f6rn Kottmann",
        "Reporter": "J\u00f6rn Kottmann",
        "Created": "18/May/11 11:42",
        "Updated": "24/May/11 11:34",
        "Resolved": "24/May/11 11:34",
        "Description": "There are quite some settings which influence the training of a classification model. Currenlty it is difficult to control these settings and many can only be changed through re-compiling. To improve the situation a user should be able to pass an object which contains all the machine learning settings to the various train methods and the  command line interface should be extended to accept a properties file which contains all the machine learning settings.\nThe settings also contain the training algorithm which enables us to use either maxent or perceptron in all our components.\nThe solution which will be implemented was discussed in this thread:\nhttp://mail-archives.apache.org/mod_mbox/incubator-opennlp-dev/201105.mbox/%3C4DD284DA.1000900@gmail.com%3E",
        "Issue Links": []
    },
    "OPENNLP-176": {
        "Key": "OPENNLP-176",
        "Summary": "Switch language codes to ISO 639-3 codes",
        "Type": "Improvement",
        "Status": "Closed",
        "Priority": "Major",
        "Resolution": "Fixed",
        "Affects Version/s": "None",
        "Fix Version/s": "1.8.0",
        "Component/s": "None",
        "Assignee": null,
        "Reporter": "J\u00f6rn Kottmann",
        "Created": "18/May/11 20:18",
        "Updated": "14/May/18 16:51",
        "Resolved": "17/Feb/17 10:05",
        "Description": "To cover more languages than with our two letters codes and to make understanding the codes easier OpenNLP should use ISO 639-3 codes.\nThis change will break backward compatibility and could be done with a bigger changes, e.g. for 1.6.0.\nWe discussed the switch in this thread:\nhttp://mail-archives.apache.org/mod_mbox/incubator-opennlp-dev/201105.mbox/%3CBANLkTi=QhB-yQa82BnQJr=f+P-=f2BGj6g@mail.gmail.com%3E",
        "Issue Links": [
            "https://github.com/apache/opennlp/pull/114",
            "https://github.com/apache/opennlp/pull/114"
        ]
    },
    "OPENNLP-177": {
        "Key": "OPENNLP-177",
        "Summary": "Add cross validation support to doccat",
        "Type": "Improvement",
        "Status": "Closed",
        "Priority": "Major",
        "Resolution": "Fixed",
        "Affects Version/s": "None",
        "Fix Version/s": "None",
        "Component/s": "Doccat",
        "Assignee": "William Colen",
        "Reporter": "J\u00f6rn Kottmann",
        "Created": "18/May/11 20:23",
        "Updated": "09/Mar/15 20:44",
        "Resolved": "11/Apr/14 03:26",
        "Description": "Doccat should support cross validation in order to measure the performance on a data set without test data.",
        "Issue Links": []
    },
    "OPENNLP-178": {
        "Key": "OPENNLP-178",
        "Summary": "Add cross validation cmd line tool for the name finder",
        "Type": "Improvement",
        "Status": "Closed",
        "Priority": "Major",
        "Resolution": "Fixed",
        "Affects Version/s": "None",
        "Fix Version/s": "tools-1.5.2-incubating",
        "Component/s": "Command Line Interface,                                            Name Finder",
        "Assignee": "William Colen",
        "Reporter": "J\u00f6rn Kottmann",
        "Created": "18/May/11 20:24",
        "Updated": "22/Jun/11 13:18",
        "Resolved": "03/Jun/11 06:42",
        "Description": "The cmd line interface should have a cross validation tool for the name finder.",
        "Issue Links": []
    },
    "OPENNLP-179": {
        "Key": "OPENNLP-179",
        "Summary": "Add cross validation cmd line tool for the POS Tagger",
        "Type": "Improvement",
        "Status": "Closed",
        "Priority": "Major",
        "Resolution": "Fixed",
        "Affects Version/s": "None",
        "Fix Version/s": "tools-1.5.2-incubating",
        "Component/s": "Command Line Interface,                                            POS Tagger",
        "Assignee": "William Colen",
        "Reporter": "J\u00f6rn Kottmann",
        "Created": "18/May/11 20:26",
        "Updated": "30/May/11 08:52",
        "Resolved": "29/May/11 17:43",
        "Description": "The cmd line interface should have a cross validation tool for the pos tagger.",
        "Issue Links": []
    },
    "OPENNLP-180": {
        "Key": "OPENNLP-180",
        "Summary": "Remove old deprecated main methods",
        "Type": "Task",
        "Status": "Closed",
        "Priority": "Minor",
        "Resolution": "Fixed",
        "Affects Version/s": "None",
        "Fix Version/s": "tools-1.5.2-incubating",
        "Component/s": "None",
        "Assignee": "J\u00f6rn Kottmann",
        "Reporter": "J\u00f6rn Kottmann",
        "Created": "19/May/11 09:46",
        "Updated": "19/May/11 10:11",
        "Resolved": "19/May/11 10:11",
        "Description": "In 1.5.0 a new cmd line interface was introduced and is now widely used. All the old and partly buggy main methods should be removed.",
        "Issue Links": []
    },
    "OPENNLP-181": {
        "Key": "OPENNLP-181",
        "Summary": "Update OpenNLP Tools version to 1.5.2",
        "Type": "Task",
        "Status": "Closed",
        "Priority": "Minor",
        "Resolution": "Fixed",
        "Affects Version/s": "None",
        "Fix Version/s": "tools-1.5.2-incubating",
        "Component/s": "None",
        "Assignee": "J\u00f6rn Kottmann",
        "Reporter": "J\u00f6rn Kottmann",
        "Created": "19/May/11 12:22",
        "Updated": "19/May/11 12:28",
        "Resolved": "19/May/11 12:28",
        "Description": "Update the version class to output 1.5.2 instead of 1.5.1.",
        "Issue Links": []
    },
    "OPENNLP-182": {
        "Key": "OPENNLP-182",
        "Summary": "Refactor the NameFinderEventStream class",
        "Type": "Task",
        "Status": "Closed",
        "Priority": "Minor",
        "Resolution": "Fixed",
        "Affects Version/s": "None",
        "Fix Version/s": "tools-1.5.2-incubating",
        "Component/s": "Name Finder",
        "Assignee": "J\u00f6rn Kottmann",
        "Reporter": "J\u00f6rn Kottmann",
        "Created": "24/May/11 12:52",
        "Updated": "24/May/11 13:37",
        "Resolved": "24/May/11 13:37",
        "Description": "The class should be refactored to use the new abstract event stream in the util package instead.",
        "Issue Links": []
    },
    "OPENNLP-183": {
        "Key": "OPENNLP-183",
        "Summary": "Add perceptron sequence training support to the name finder",
        "Type": "New Feature",
        "Status": "Closed",
        "Priority": "Major",
        "Resolution": "Fixed",
        "Affects Version/s": "None",
        "Fix Version/s": "tools-1.5.2-incubating",
        "Component/s": "Name Finder",
        "Assignee": "J\u00f6rn Kottmann",
        "Reporter": "J\u00f6rn Kottmann",
        "Created": "24/May/11 12:59",
        "Updated": "06/Jul/11 09:22",
        "Resolved": "06/Jul/11 09:22",
        "Description": "The name finder should also support the perceptron sequence training.",
        "Issue Links": []
    },
    "OPENNLP-184": {
        "Key": "OPENNLP-184",
        "Summary": "Make the Bigram Name Feature Generator public",
        "Type": "Improvement",
        "Status": "Closed",
        "Priority": "Minor",
        "Resolution": "Fixed",
        "Affects Version/s": "None",
        "Fix Version/s": "tools-1.5.2-incubating",
        "Component/s": "Name Finder",
        "Assignee": "J\u00f6rn Kottmann",
        "Reporter": "J\u00f6rn Kottmann",
        "Created": "24/May/11 13:01",
        "Updated": "25/May/11 07:39",
        "Resolved": "25/May/11 07:39",
        "Description": "The name finder uses a Bigram Name Feature Generator which is an inner class of the Default Name Context Generator. This class should be made public and moved to the featuregen package.",
        "Issue Links": []
    },
    "OPENNLP-185": {
        "Key": "OPENNLP-185",
        "Summary": "SimplePerceptronSequenceTrainer is re-creating the pmap on every sequence update",
        "Type": "Bug",
        "Status": "Closed",
        "Priority": "Major",
        "Resolution": "Fixed",
        "Affects Version/s": "None",
        "Fix Version/s": "tools-1.5.2-incubating,                                            maxent-3.0.2-incubating",
        "Component/s": "Machine Learning",
        "Assignee": "J\u00f6rn Kottmann",
        "Reporter": "J\u00f6rn Kottmann",
        "Created": "24/May/11 18:18",
        "Updated": "24/May/11 18:20",
        "Resolved": "24/May/11 18:20",
        "Description": "SimplePerceptronSequenceTrainer is re-creating the pmap on every sequence update. That makes the training unusable slow.\nTo fix the issue avoid the creation of the pmap for every sequence update.",
        "Issue Links": []
    },
    "OPENNLP-186": {
        "Key": "OPENNLP-186",
        "Summary": "Small refactoring of Arvores Deitadas Format classes.",
        "Type": "Improvement",
        "Status": "Closed",
        "Priority": "Minor",
        "Resolution": "Fixed",
        "Affects Version/s": "None",
        "Fix Version/s": "tools-1.5.2-incubating",
        "Component/s": "Chunker",
        "Assignee": "William Colen",
        "Reporter": "William Colen",
        "Created": "27/May/11 01:05",
        "Updated": "27/May/11 01:11",
        "Resolved": "27/May/11 01:11",
        "Description": "Some small refactoring to make it clear how to use the Arvores Deitadas formatters.\n\nRename the class ContractionUtility to PortugueseContractionUtility and move it to 'ad' package;\nRename the class ADParagraphStream to ADSentenceStream. Improved the corpus parsing;\nMove tests related to Arvores Deitadas to 'ad' package.",
        "Issue Links": []
    },
    "OPENNLP-187": {
        "Key": "OPENNLP-187",
        "Summary": "Add util method to POS Tagger which can build the ngram dictionary",
        "Type": "Improvement",
        "Status": "Closed",
        "Priority": "Minor",
        "Resolution": "Fixed",
        "Affects Version/s": "None",
        "Fix Version/s": "tools-1.5.2-incubating",
        "Component/s": "POS Tagger",
        "Assignee": "J\u00f6rn Kottmann",
        "Reporter": "J\u00f6rn Kottmann",
        "Created": "30/May/11 08:49",
        "Updated": "31/May/11 11:15",
        "Resolved": "31/May/11 11:15",
        "Description": "The POS Tagger has support for an ngram dictionary, the code which creates the ngram dictionary inside POSTaggerTrainer should be refactored and moved to a util method. Additionally the cmd line interface should be extended to train with the ngram dictionary.",
        "Issue Links": []
    },
    "OPENNLP-188": {
        "Key": "OPENNLP-188",
        "Summary": "Remove deprecated classes from POS Tagger",
        "Type": "Task",
        "Status": "Closed",
        "Priority": "Minor",
        "Resolution": "Fixed",
        "Affects Version/s": "None",
        "Fix Version/s": "tools-1.5.2-incubating",
        "Component/s": "POS Tagger",
        "Assignee": "J\u00f6rn Kottmann",
        "Reporter": "J\u00f6rn Kottmann",
        "Created": "30/May/11 09:04",
        "Updated": "30/May/11 09:17",
        "Resolved": "30/May/11 09:17",
        "Description": "The POSEventGenerator, POSEventCollector and POSEventStream classes are deprecated for a while now and should be removed.",
        "Issue Links": []
    },
    "OPENNLP-189": {
        "Key": "OPENNLP-189",
        "Summary": "Version class should output a version which is injected by the maven build",
        "Type": "Improvement",
        "Status": "Closed",
        "Priority": "Major",
        "Resolution": "Fixed",
        "Affects Version/s": "None",
        "Fix Version/s": "tools-1.5.2-incubating",
        "Component/s": "Build, Packaging and Test",
        "Assignee": "J\u00f6rn Kottmann",
        "Reporter": "J\u00f6rn Kottmann",
        "Created": "30/May/11 09:31",
        "Updated": "17/Mar/18 20:13",
        "Resolved": "30/May/11 11:42",
        "Description": "The Version class currently outputs a hardcoded version, which need to manually be updated to the current version after every release, to eliminate this step the build should automatically inject the version of the opennlp-tools pom file.",
        "Issue Links": [
            "https://github.com/apache/opennlp/pull/307"
        ]
    },
    "OPENNLP-190": {
        "Key": "OPENNLP-190",
        "Summary": "Update Apache parent pom to version 9",
        "Type": "Task",
        "Status": "Closed",
        "Priority": "Minor",
        "Resolution": "Fixed",
        "Affects Version/s": "None",
        "Fix Version/s": "tools-1.5.2-incubating,                                            maxent-3.0.2-incubating",
        "Component/s": "Build, Packaging and Test",
        "Assignee": "J\u00f6rn Kottmann",
        "Reporter": "J\u00f6rn Kottmann",
        "Created": "30/May/11 13:20",
        "Updated": "30/May/11 13:26",
        "Resolved": "30/May/11 13:26",
        "Description": "Lets update to the latest version (9) of the Apache parent pom.",
        "Issue Links": []
    },
    "OPENNLP-191": {
        "Key": "OPENNLP-191",
        "Summary": "The rat plugin create a report for every subproject, but we just want a single report",
        "Type": "Bug",
        "Status": "Closed",
        "Priority": "Minor",
        "Resolution": "Fixed",
        "Affects Version/s": "None",
        "Fix Version/s": "1.6.0",
        "Component/s": "Build, Packaging and Test",
        "Assignee": "J\u00f6rn Kottmann",
        "Reporter": "J\u00f6rn Kottmann",
        "Created": "30/May/11 13:39",
        "Updated": "28/Dec/16 23:33",
        "Resolved": "28/Dec/16 23:33",
        "Description": "The Apache RAT plugin currently create a report for every single subproject. Having many different reports makes it more difficult to publish and review them when doing a release, therefor the setup of the plugin should be changed to only produce a single report which includes everything.",
        "Issue Links": []
    },
    "OPENNLP-192": {
        "Key": "OPENNLP-192",
        "Summary": "The rat plugin should allow unapproved licenses during development",
        "Type": "Improvement",
        "Status": "Closed",
        "Priority": "Minor",
        "Resolution": "Fixed",
        "Affects Version/s": "None",
        "Fix Version/s": "tools-1.5.2-incubating",
        "Component/s": "Build, Packaging and Test",
        "Assignee": "J\u00f6rn Kottmann",
        "Reporter": "J\u00f6rn Kottmann",
        "Created": "30/May/11 14:38",
        "Updated": "30/May/11 14:41",
        "Resolved": "30/May/11 14:41",
        "Description": "The build currently fails if there is one file with an unapproved license inside the project folder. The rat setup should be changed to be strict about licenses when we do a release, and allow test without license header during development.\nChange the setup of the rat plugin to allow unapproved licenses during development, and non when the apache-release profile is activated.",
        "Issue Links": []
    },
    "OPENNLP-193": {
        "Key": "OPENNLP-193",
        "Summary": "Update POS Tagger cmd line trainer tool to use new xml tag dict format",
        "Type": "Task",
        "Status": "Closed",
        "Priority": "Minor",
        "Resolution": "Fixed",
        "Affects Version/s": "None",
        "Fix Version/s": "1.6.0",
        "Component/s": "Command Line Interface,                                            POS Tagger",
        "Assignee": null,
        "Reporter": "J\u00f6rn Kottmann",
        "Created": "31/May/11 08:37",
        "Updated": "21/Oct/14 22:45",
        "Resolved": "13/Mar/14 15:29",
        "Description": "The POS Tagger trainer cmd line tool uses still the old tag dict format for backward compatibility reasons. The format was replaced by a new xml based dictionary.\nUpdate the POS Tagger trainer tool to only use the new xml based dictionary format.",
        "Issue Links": []
    },
    "OPENNLP-194": {
        "Key": "OPENNLP-194",
        "Summary": "The docbook contains many lines which are too long",
        "Type": "Bug",
        "Status": "Closed",
        "Priority": "Minor",
        "Resolution": "Fixed",
        "Affects Version/s": "None",
        "Fix Version/s": "tools-1.5.2-incubating",
        "Component/s": "Documentation",
        "Assignee": "J\u00f6rn Kottmann",
        "Reporter": "J\u00f6rn Kottmann",
        "Created": "31/May/11 09:41",
        "Updated": "31/May/11 11:14",
        "Resolved": "31/May/11 11:14",
        "Description": "The docbook contains many lines which are too long to be displayed nicely in a browser, the lines should be manually wrapped.",
        "Issue Links": []
    },
    "OPENNLP-195": {
        "Key": "OPENNLP-195",
        "Summary": "Add train method to TokenNameFinder that takes TrainingParameters, generatorDescriptor and resourceMap.",
        "Type": "Improvement",
        "Status": "Closed",
        "Priority": "Major",
        "Resolution": "Fixed",
        "Affects Version/s": "None",
        "Fix Version/s": "tools-1.5.2-incubating",
        "Component/s": "Name Finder",
        "Assignee": "William Colen",
        "Reporter": "William Colen",
        "Created": "03/Jun/11 05:26",
        "Updated": "06/Jul/11 13:04",
        "Resolved": "06/Jul/11 12:59",
        "Description": "Can't train TokenNameFinder using the params argument and the generatorDescriptor and resourceMap.",
        "Issue Links": []
    },
    "OPENNLP-196": {
        "Key": "OPENNLP-196",
        "Summary": "POS Tagger Sequence streams calls generateEvents in a loop",
        "Type": "Bug",
        "Status": "Closed",
        "Priority": "Trivial",
        "Resolution": "Fixed",
        "Affects Version/s": "tools-1.5.1-incubating",
        "Fix Version/s": "tools-1.5.2-incubating",
        "Component/s": "POS Tagger",
        "Assignee": "J\u00f6rn Kottmann",
        "Reporter": "J\u00f6rn Kottmann",
        "Created": "06/Jun/11 09:10",
        "Updated": "06/Jun/11 10:34",
        "Resolved": "06/Jun/11 10:34",
        "Description": "The POS Tagger Sequence Stream class the generateEvents in a loop, but one call is enough.\nTo fix this issue remove the loop around generateEvents.",
        "Issue Links": []
    },
    "OPENNLP-197": {
        "Key": "OPENNLP-197",
        "Summary": "The UIMA \"Sentence Detector Trainer\" may build erratic models depending on the covered text format of the sentence annotations.",
        "Type": "Question",
        "Status": "Closed",
        "Priority": "Major",
        "Resolution": "Fixed",
        "Affects Version/s": "None",
        "Fix Version/s": "None",
        "Component/s": "UIMA Integration",
        "Assignee": "J\u00f6rn Kottmann",
        "Reporter": "Nicolas Hernandez",
        "Created": "07/Jun/11 13:08",
        "Updated": "07/Jul/11 08:30",
        "Resolved": "07/Jul/11 08:30",
        "Description": "In the opennlp-uima subproject, the \"Sentence Detector Training\" component asks for a Sentence annotation type as a parameter. \nThe component does not check whether each corresponding sentence is written in its own line. \nAs a matter of fact the built model would not work as expected.",
        "Issue Links": []
    },
    "OPENNLP-198": {
        "Key": "OPENNLP-198",
        "Summary": "Develop a demonstration web app for our website",
        "Type": "Task",
        "Status": "Open",
        "Priority": "Major",
        "Resolution": "Unresolved",
        "Affects Version/s": "None",
        "Fix Version/s": "None",
        "Component/s": "Website",
        "Assignee": null,
        "Reporter": "J\u00f6rn Kottmann",
        "Created": "07/Jun/11 14:02",
        "Updated": "04/Oct/19 16:15",
        "Resolved": null,
        "Description": "We should add a demonstration web app to our website, so potential new user have a chance to try out OpenNLP before they need to download it. The initial version of the web app does not need to support every component in OpenNLP, but should support a few.\nIt seems to be possible to request a virtual machine from the infra team to run our web app on.",
        "Issue Links": [
            "https://github.com/apache/opennlp/pull/233",
            "https://github.com/apache/opennlp/pull/233"
        ]
    },
    "OPENNLP-199": {
        "Key": "OPENNLP-199",
        "Summary": "Refactor the PerceptronTrainer class to address a couple of problems",
        "Type": "Improvement",
        "Status": "Closed",
        "Priority": "Major",
        "Resolution": "Fixed",
        "Affects Version/s": "maxent-3.0.1-incubating",
        "Fix Version/s": "tools-1.5.2-incubating,                                            maxent-3.0.2-incubating",
        "Component/s": "Machine Learning",
        "Assignee": "Jason Baldridge",
        "Reporter": "J\u00f6rn Kottmann",
        "Created": "08/Jun/11 07:56",
        "Updated": "22/Aug/11 12:08",
        "Resolved": "22/Aug/11 12:08",
        "Description": "Changed the update to be the actual perceptron update: when a label\n  that is not the gold label is chosen for an event, the parameters\n  associated with that label are decremented, and the parameters\n  associated with the gold label are incremented. I checked this\n  empirically on several datasets, and it works better than the\n  previous update (and it involves fewer updates).\n\n\nstepsize is decreased by stepsize/1.05 on every iteration, ensuring\n  better stability toward the end of training. This is actually the\n  main reason that the training set accuracy obtained during parameter\n  update continued to be different from that computed when parameters\n  aren't updated. Now, the parameters don't jump as much in later\n  iterations, so things settle down and those two accuracies converge\n  if enough iterations are allowed.\n\n\nTraining set accuracy is computed once per iteration.\n\n\nTraining stops if the current training set accuracy changes less\n  than a given tolerance from the accuracies obtained in each of the\n  previous three iterations.\n\n\nAveraging is done differently than before. Rather than doing an\n  immediate update, parameters are simply accumulated after iterations\n  (this makes the code much easier to understand/maintain). Also, not\n  every iteration is used, as this tends to give to much weight to the\n  final iterations, which don't actually differ that much from one\n  another. I tried a few things and found a simple method that works\n  well: sum the parameters from the first 20 iterations and then sum\n  parameters from any further iterations that are perfect squares (25,\n  36, 49, etc). This gets a good (diverse) sample of parameters for\n  averaging since the distance between subsequent parameter sets gets\n  larger as the number of iterations gets bigger.\n\n\nAdded ListEventStream to make a stream out of List<Event>\n\n\nAdded some helper methods, e.g. maxIndex, to simplify the code in\n  the main algorithm.\n\n\nThe training stats aren't shown for every iteration. Now it is just\n  the first 10 and then every 10th iteration after that.\n\n\nmodelDistribution, params, evalParams and others are no longer class\n  variables. They have been pushed into the findParameters\n  method. Other variables could/should be made non-global too, but\n  leaving as is for now.",
        "Issue Links": []
    },
    "OPENNLP-200": {
        "Key": "OPENNLP-200",
        "Summary": "Addition of prepositional phrase attachment dataset and unit test for it",
        "Type": "New Feature",
        "Status": "Closed",
        "Priority": "Minor",
        "Resolution": "Fixed",
        "Affects Version/s": "None",
        "Fix Version/s": "tools-1.5.2-incubating,                                            maxent-3.0.2-incubating",
        "Component/s": "Machine Learning",
        "Assignee": "J\u00f6rn Kottmann",
        "Reporter": "Jason Baldridge",
        "Created": "08/Jun/11 16:16",
        "Updated": "29/Aug/11 08:56",
        "Resolved": "29/Aug/11 08:56",
        "Description": "I have obtained permission from Adwait Ratnaparkhi to include his prepositional phrase attachment dataset in the distribution as a test case. Jorn correctly points out that we need to see whether this is ASF compliant. Here is the original dataset:\nhttp://sites.google.com/site/adwaitratnaparkhi/publications/ppa.tar.gz?attredirects=0",
        "Issue Links": []
    },
    "OPENNLP-201": {
        "Key": "OPENNLP-201",
        "Summary": "Sentence Detector Trainer stops reading data when it contains two empty lines",
        "Type": "Bug",
        "Status": "Closed",
        "Priority": "Major",
        "Resolution": "Fixed",
        "Affects Version/s": "tools-1.5.1-incubating",
        "Fix Version/s": "tools-1.5.2-incubating",
        "Component/s": "Sentence Detector",
        "Assignee": "J\u00f6rn Kottmann",
        "Reporter": "J\u00f6rn Kottmann",
        "Created": "09/Jun/11 08:02",
        "Updated": "09/Jun/11 09:33",
        "Resolved": "09/Jun/11 09:33",
        "Description": "The Sentence Detector Trainer stops reading the training data when the input stream contains two or more empty lines. Empty lines are used to mark document boundaries.\nTo fix this issue the training data reading code should treat multiple empty lines in the same way as one empty line.",
        "Issue Links": []
    },
    "OPENNLP-202": {
        "Key": "OPENNLP-202",
        "Summary": "Refactor the sentence detector to correctly detect white spaces",
        "Type": "Improvement",
        "Status": "Closed",
        "Priority": "Major",
        "Resolution": "Fixed",
        "Affects Version/s": "tools-1.5.1-incubating",
        "Fix Version/s": "tools-1.5.2-incubating",
        "Component/s": "Sentence Detector",
        "Assignee": "J\u00f6rn Kottmann",
        "Reporter": "J\u00f6rn Kottmann",
        "Created": "09/Jun/11 21:45",
        "Updated": "06/Jul/11 09:32",
        "Resolved": "06/Jul/11 09:32",
        "Description": "The Sentence Detector code needs a robust mechanism to detect the precense of a white space. In OpenNLP white spaces should be detected with StringUtil.isWhitespace, but the Sentence Detector either call Chracter.isWhitespace or equals a character with the space character.\nTo fix this issue refactor the code to always use StringUtil.isWhitespace to detect whites spaces.",
        "Issue Links": []
    },
    "OPENNLP-203": {
        "Key": "OPENNLP-203",
        "Summary": "UIMA Sentence Detector Trainer builds models which do not split correctly the sentences",
        "Type": "Bug",
        "Status": "Closed",
        "Priority": "Major",
        "Resolution": "Fixed",
        "Affects Version/s": "tools-1.5.1-incubating",
        "Fix Version/s": "tools-1.5.2-incubating",
        "Component/s": "Sentence Detector,                                            UIMA Integration",
        "Assignee": "J\u00f6rn Kottmann",
        "Reporter": "Nicolas Hernandez",
        "Created": "22/Jun/11 10:02",
        "Updated": "06/Jul/11 09:20",
        "Resolved": "06/Jul/11 09:20",
        "Description": "The models trained with the UIMA component give wrong begin/end offset despite the fact they manage to split text in sentences. \nI observed that the begin of a current sentence starts including as a first token the punctuation character of the previous one while the\nprevious one does not include it as its last one.",
        "Issue Links": []
    },
    "OPENNLP-204": {
        "Key": "OPENNLP-204",
        "Summary": "UIMA POSTaggerTrainer wrongly parses token annotations",
        "Type": "Bug",
        "Status": "Closed",
        "Priority": "Major",
        "Resolution": "Fixed",
        "Affects Version/s": "tools-1.5.1-incubating",
        "Fix Version/s": "tools-1.5.2-incubating",
        "Component/s": "POS Tagger,                                            UIMA Integration",
        "Assignee": "J\u00f6rn Kottmann",
        "Reporter": "Nicolas Hernandez",
        "Created": "24/Jun/11 11:28",
        "Updated": "24/Jun/11 11:48",
        "Resolved": "24/Jun/11 11:37",
        "Description": "Affects the opennlp-uima package, in particular the opennlp/uima/postag/POSTaggerTrainer.java class.\nThis AE is expected to parse token annotations and to build two data structures. The first one is an array of the token coveredTexts and the second an array of associated tags (the tags are specified by a feature structure path set in parameter). \nIn practice, the tag value of the current token is wrongly added to the token array. \nThis can be easily solved by changing the name of the data structure: from `tokens` to `tags` at line 200.",
        "Issue Links": []
    },
    "OPENNLP-205": {
        "Key": "OPENNLP-205",
        "Summary": "Refactor the SentenceDetectorME class to do the mapping of end-of-sent positions to spans better",
        "Type": "Improvement",
        "Status": "Open",
        "Priority": "Major",
        "Resolution": "Unresolved",
        "Affects Version/s": "None",
        "Fix Version/s": "None",
        "Component/s": "Sentence Detector",
        "Assignee": null,
        "Reporter": "J\u00f6rn Kottmann",
        "Created": "27/Jun/11 08:16",
        "Updated": "27/Jun/11 08:16",
        "Resolved": null,
        "Description": "The SentenceDectorME class should be refactored to improve the mapping of end-of-sent positions to spans better. The current code tries to eliminate white spaces between to sentences, but this code fails in case the UseTokenEnd option is set to false. If set to true the sentence detector might not work correctly in all cases.",
        "Issue Links": []
    },
    "OPENNLP-206": {
        "Key": "OPENNLP-206",
        "Summary": "Create the Corpus Server project in the sandbox",
        "Type": "Task",
        "Status": "Closed",
        "Priority": "Minor",
        "Resolution": "Fixed",
        "Affects Version/s": "None",
        "Fix Version/s": "None",
        "Component/s": "None",
        "Assignee": "J\u00f6rn Kottmann",
        "Reporter": "J\u00f6rn Kottmann",
        "Created": "27/Jun/11 19:25",
        "Updated": "06/Jul/11 22:20",
        "Resolved": "06/Jul/11 22:20",
        "Description": "Lets create the first dummy version of the Corpus Server in the sandbox which implements the interface as described in the proposal.\nIt should do the following things:\n\nImplement the proposed restful interface\nStore CASes in-memory to be a little functional",
        "Issue Links": []
    },
    "OPENNLP-207": {
        "Key": "OPENNLP-207",
        "Summary": "Add search support to Corpus Server based on Lucas",
        "Type": "Task",
        "Status": "Closed",
        "Priority": "Major",
        "Resolution": "Fixed",
        "Affects Version/s": "None",
        "Fix Version/s": "None",
        "Component/s": "Corpus Server",
        "Assignee": "J\u00f6rn Kottmann",
        "Reporter": "Tommaso Teofili",
        "Created": "30/Jun/11 11:10",
        "Updated": "26/Aug/11 09:02",
        "Resolved": "26/Aug/11 09:02",
        "Description": "The Corpus Server needs CAS indexing and searching capabilities.\nThe index must be updated when a CAS is added and when a CAS is changed; this could be achieved by using Lucas, eventually with little changes.\nWe need to have one index loaded and concurrently update it (with Lucas) and query it (with Lucene APIs); the search method should return a list of matched CAS references.",
        "Issue Links": []
    },
    "OPENNLP-208": {
        "Key": "OPENNLP-208",
        "Summary": "Create a CorpusStore which uses Apache Derby for persisting CASes",
        "Type": "Task",
        "Status": "Closed",
        "Priority": "Major",
        "Resolution": "Fixed",
        "Affects Version/s": "None",
        "Fix Version/s": "None",
        "Component/s": "None",
        "Assignee": "J\u00f6rn Kottmann",
        "Reporter": "Tommaso Teofili",
        "Created": "30/Jun/11 12:55",
        "Updated": "16/Aug/11 11:26",
        "Resolved": "16/Aug/11 11:26",
        "Description": "Create a CorpusStore for the CorpusServer which uses Apache Derby as persistence layer (currently only the in-memory implementation is present) to store CASes.",
        "Issue Links": []
    },
    "OPENNLP-209": {
        "Key": "OPENNLP-209",
        "Summary": "Create a dummy Wikinews importer",
        "Type": "Task",
        "Status": "Closed",
        "Priority": "Minor",
        "Resolution": "Fixed",
        "Affects Version/s": "None",
        "Fix Version/s": "None",
        "Component/s": "None",
        "Assignee": "J\u00f6rn Kottmann",
        "Reporter": "J\u00f6rn Kottmann",
        "Created": "30/Jun/11 14:03",
        "Updated": "04/Jul/11 17:42",
        "Resolved": "04/Jul/11 17:42",
        "Description": "The dummy Wikinews importer should be able to upload xml files into the Corpus Server. The dummy will include a few Wikinews sample xmi files.",
        "Issue Links": []
    },
    "OPENNLP-210": {
        "Key": "OPENNLP-210",
        "Summary": "Add support to create a task queue for the CorpusServer",
        "Type": "Task",
        "Status": "Closed",
        "Priority": "Major",
        "Resolution": "Fixed",
        "Affects Version/s": "None",
        "Fix Version/s": "None",
        "Component/s": "Corpus Server",
        "Assignee": "J\u00f6rn Kottmann",
        "Reporter": "Tommaso Teofili",
        "Created": "30/Jun/11 15:14",
        "Updated": "29/Aug/11 12:25",
        "Resolved": "29/Aug/11 12:25",
        "Description": "A task queue should be used to load CASes extracted with the CAS search API to be passed to an annotator.\nWhile being processed by an annotator CASes should not be available to other annotators.",
        "Issue Links": []
    },
    "OPENNLP-211": {
        "Key": "OPENNLP-211",
        "Summary": "Add a Wikinews parser to the wikinews-importer",
        "Type": "Task",
        "Status": "Closed",
        "Priority": "Major",
        "Resolution": "Fixed",
        "Affects Version/s": "None",
        "Fix Version/s": "None",
        "Component/s": "None",
        "Assignee": "J\u00f6rn Kottmann",
        "Reporter": "J\u00f6rn Kottmann",
        "Created": "04/Jul/11 10:29",
        "Updated": "31/Oct/11 20:12",
        "Resolved": "31/Oct/11 20:12",
        "Description": "The current wikinews-importer can only load existing XMI files, that should be fixed by adding a proper wikinews parser wich can turn the wikinews dump into UIMA CASes.",
        "Issue Links": []
    },
    "OPENNLP-212": {
        "Key": "OPENNLP-212",
        "Summary": "Add Detokenizer configuration for Portuguese",
        "Type": "New Feature",
        "Status": "Closed",
        "Priority": "Minor",
        "Resolution": "Fixed",
        "Affects Version/s": "tools-1.5.2-incubating",
        "Fix Version/s": "tools-1.5.2-incubating",
        "Component/s": "Tokenizer",
        "Assignee": "William Colen",
        "Reporter": "William Colen",
        "Created": "04/Jul/11 19:08",
        "Updated": "04/Jul/11 19:14",
        "Resolved": "04/Jul/11 19:14",
        "Description": "Create a initial pt-detokenizer.xml based on the english version. This is file is necessary to train Tokenizer component.",
        "Issue Links": []
    },
    "OPENNLP-213": {
        "Key": "OPENNLP-213",
        "Summary": "Name type should accept larger variety of characters",
        "Type": "Improvement",
        "Status": "Closed",
        "Priority": "Major",
        "Resolution": "Fixed",
        "Affects Version/s": "tools-1.5.2-incubating",
        "Fix Version/s": "tools-1.5.2-incubating",
        "Component/s": "Name Finder",
        "Assignee": "William Colen",
        "Reporter": "William Colen",
        "Created": "04/Jul/11 19:24",
        "Updated": "06/Jul/11 12:55",
        "Resolved": "04/Jul/11 21:12",
        "Description": "Name type should accept larger variety of characters. Today it is restricted to alphanumeric. For example <START:prop-name> is not accepted.\nMaybe the only restriction should be '>' and ':'.",
        "Issue Links": []
    },
    "OPENNLP-214": {
        "Key": "OPENNLP-214",
        "Summary": "Update jira version in opennlp-distr for release notes generation",
        "Type": "Task",
        "Status": "Closed",
        "Priority": "Minor",
        "Resolution": "Fixed",
        "Affects Version/s": "tools-1.5.1-incubating",
        "Fix Version/s": "tools-1.5.2-incubating",
        "Component/s": "Build, Packaging and Test",
        "Assignee": "J\u00f6rn Kottmann",
        "Reporter": "J\u00f6rn Kottmann",
        "Created": "06/Jul/11 09:38",
        "Updated": "06/Jul/11 13:04",
        "Resolved": "06/Jul/11 13:04",
        "Description": "The version in the opennlp-distr pom should be updated to point to tools-1.5.2-incubating.",
        "Issue Links": []
    },
    "OPENNLP-215": {
        "Key": "OPENNLP-215",
        "Summary": "Add Tokenizer Training API section",
        "Type": "Improvement",
        "Status": "Closed",
        "Priority": "Major",
        "Resolution": "Fixed",
        "Affects Version/s": "None",
        "Fix Version/s": "tools-1.5.3",
        "Component/s": "Documentation",
        "Assignee": "Aliaksandr Autayeu",
        "Reporter": "J\u00f6rn Kottmann",
        "Created": "11/Jul/11 12:28",
        "Updated": "01/Dec/11 20:38",
        "Resolved": "01/Dec/11 20:38",
        "Description": "The documentation is lacking a section for the tokenizer which explains how the training api can be used. This section should be written in a similar fashion as in other components, e.g. sentence detector or name finder.",
        "Issue Links": []
    },
    "OPENNLP-216": {
        "Key": "OPENNLP-216",
        "Summary": "Add Detokenizer API section",
        "Type": "Improvement",
        "Status": "Resolved",
        "Priority": "Major",
        "Resolution": "Fixed",
        "Affects Version/s": "None",
        "Fix Version/s": "1.9.4",
        "Component/s": "Documentation",
        "Assignee": "Martin Wiesner",
        "Reporter": "J\u00f6rn Kottmann",
        "Created": "11/Jul/11 12:41",
        "Updated": "09/Dec/22 11:05",
        "Resolved": "09/Dec/22 11:05",
        "Description": "The documentation is lacking a section about the detokenizer API.",
        "Issue Links": []
    },
    "OPENNLP-217": {
        "Key": "OPENNLP-217",
        "Summary": "Add Detokenizer Dictionary section",
        "Type": "Improvement",
        "Status": "Resolved",
        "Priority": "Major",
        "Resolution": "Fixed",
        "Affects Version/s": "None",
        "Fix Version/s": "1.9.4",
        "Component/s": "Documentation",
        "Assignee": null,
        "Reporter": "J\u00f6rn Kottmann",
        "Created": "11/Jul/11 12:43",
        "Updated": "09/Dec/22 14:04",
        "Resolved": "09/Dec/22 14:04",
        "Description": "The documentation is lacking a section about the detokenizer dictionary.",
        "Issue Links": []
    },
    "OPENNLP-218": {
        "Key": "OPENNLP-218",
        "Summary": "Add a chunker training api section",
        "Type": "Improvement",
        "Status": "Closed",
        "Priority": "Major",
        "Resolution": "Fixed",
        "Affects Version/s": "None",
        "Fix Version/s": "tools-1.5.3",
        "Component/s": "Chunker,                                            Documentation",
        "Assignee": "Aliaksandr Autayeu",
        "Reporter": "J\u00f6rn Kottmann",
        "Created": "11/Jul/11 13:11",
        "Updated": "01/Dec/11 20:40",
        "Resolved": "01/Dec/11 20:40",
        "Description": "The chunker documentation currently lacks a sections which describes how to train the chunker via its API.",
        "Issue Links": []
    },
    "OPENNLP-219": {
        "Key": "OPENNLP-219",
        "Summary": "Add a parser training api section",
        "Type": "Improvement",
        "Status": "Closed",
        "Priority": "Major",
        "Resolution": "Fixed",
        "Affects Version/s": "None",
        "Fix Version/s": "1.7.0",
        "Component/s": "Documentation,                                            Parser",
        "Assignee": "Rodrigo Agerri",
        "Reporter": "J\u00f6rn Kottmann",
        "Created": "11/Jul/11 13:19",
        "Updated": "17/Sep/15 12:43",
        "Resolved": "08/Sep/15 12:24",
        "Description": "The documentation still lacks a section about the parser training api.",
        "Issue Links": []
    },
    "OPENNLP-220": {
        "Key": "OPENNLP-220",
        "Summary": "Detailed evaluator output",
        "Type": "Improvement",
        "Status": "Closed",
        "Priority": "Minor",
        "Resolution": "Fixed",
        "Affects Version/s": "tools-1.5.2-incubating",
        "Fix Version/s": "tools-1.5.2-incubating",
        "Component/s": "Chunker,                                            Name Finder,                                            POS Tagger,                                            Sentence Detector,                                            Tokenizer",
        "Assignee": "William Colen",
        "Reporter": "William Colen",
        "Created": "11/Jul/11 18:08",
        "Updated": "02/May/13 02:29",
        "Resolved": "13/Jul/11 18:06",
        "Description": "CLI evaluation tools (Evaluator and CrossValidator) should optionally print details of false positives and negatives and wrong tags. Will add the optional argument -printerrors to the CLI tools.",
        "Issue Links": [
            "/jira/browse/OPENNLP-221"
        ]
    },
    "OPENNLP-221": {
        "Key": "OPENNLP-221",
        "Summary": "Evaluator CLI tools should use the Parameters interface",
        "Type": "Improvement",
        "Status": "Closed",
        "Priority": "Minor",
        "Resolution": "Fixed",
        "Affects Version/s": "tools-1.5.2-incubating",
        "Fix Version/s": "tools-1.5.2-incubating",
        "Component/s": "Name Finder,                                            POS Tagger,                                            Sentence Detector,                                            Tokenizer",
        "Assignee": "William Colen",
        "Reporter": "William Colen",
        "Created": "11/Jul/11 18:16",
        "Updated": "02/May/13 02:29",
        "Resolved": "13/Jul/11 13:42",
        "Description": "Some CLI evaluation tools are not using the Parameters interface to describe arguments. It is easier to set optional parameters if the tool is using the interface.",
        "Issue Links": [
            "/jira/browse/OPENNLP-220"
        ]
    },
    "OPENNLP-222": {
        "Key": "OPENNLP-222",
        "Summary": "Add a parser for the BioNLP/NLPBA 2004 shared task",
        "Type": "New Feature",
        "Status": "Closed",
        "Priority": "Minor",
        "Resolution": "Fixed",
        "Affects Version/s": "None",
        "Fix Version/s": "tools-1.5.2-incubating",
        "Component/s": "Name Finder",
        "Assignee": "J\u00f6rn Kottmann",
        "Reporter": "J\u00f6rn Kottmann",
        "Created": "12/Jul/11 15:17",
        "Updated": "12/Jul/11 15:58",
        "Resolved": "12/Jul/11 15:58",
        "Description": "Add native support to parse the BioNLP/NLPBA 2004 shared task named entity recognition data.\nThe task description and train/eval data can be found here:\nhttp://www-tsujii.is.s.u-tokyo.ac.jp/GENIA/ERtask/report.html",
        "Issue Links": []
    },
    "OPENNLP-223": {
        "Key": "OPENNLP-223",
        "Summary": "Update README for the 1.5.2 release",
        "Type": "Task",
        "Status": "Closed",
        "Priority": "Major",
        "Resolution": "Fixed",
        "Affects Version/s": "None",
        "Fix Version/s": "tools-1.5.2-incubating",
        "Component/s": "Build, Packaging and Test",
        "Assignee": "J\u00f6rn Kottmann",
        "Reporter": "J\u00f6rn Kottmann",
        "Created": "12/Jul/11 16:20",
        "Updated": "22/Aug/11 12:24",
        "Resolved": "12/Jul/11 22:21",
        "Description": "The README must be updated to report about the changes in the 1.5.2 release.",
        "Issue Links": [
            "/jira/browse/OPENNLP-259"
        ]
    },
    "OPENNLP-224": {
        "Key": "OPENNLP-224",
        "Summary": "CLI tools that uses Pameters interface should print detailed usage information",
        "Type": "Improvement",
        "Status": "Closed",
        "Priority": "Minor",
        "Resolution": "Fixed",
        "Affects Version/s": "tools-1.5.2-incubating",
        "Fix Version/s": "tools-1.5.2-incubating",
        "Component/s": "Command Line Interface",
        "Assignee": "William Colen",
        "Reporter": "William Colen",
        "Created": "13/Jul/11 14:00",
        "Updated": "13/Jul/11 18:52",
        "Resolved": "13/Jul/11 18:52",
        "Description": "We should add arguments description to the usage of the CL tools. Today we have the description annotation but it is not used.\nToday the command outputs:\n\u2014\n$ bin/opennlp SentenceDetectorEvaluator\nUsage: opennlp SentenceDetectorEvaluator -data testData -model model [-printErrors isPrintErrors] [-encoding charsetName]\n\u2014\nBut should output:\n\u2014\n$ bin/opennlp SentenceDetectorEvaluator\nUsage: opennlp SentenceDetectorEvaluator -data testData -model model [-printErrors isPrintErrors] [-encoding charsetName]\nDescription:\n\t-data testData\n\t\tthe data to be used during evaluation\n\t-model model\n\t\tthe model file to be evaluated\n\t-printErrors isPrintErrors\n\t\tif true will print false negatives and positives\n\t-encoding charsetName\n\t\tspecifies the encoding which should be used for reading and writing text. If not specified the system default will be used.\n\u2014",
        "Issue Links": []
    },
    "OPENNLP-225": {
        "Key": "OPENNLP-225",
        "Summary": "Restore the abbreviation dictionary support in SentenceDetector",
        "Type": "Improvement",
        "Status": "Closed",
        "Priority": "Minor",
        "Resolution": "Fixed",
        "Affects Version/s": "tools-1.5.2-incubating",
        "Fix Version/s": "tools-1.5.2-incubating",
        "Component/s": "Command Line Interface,                                            Sentence Detector",
        "Assignee": "William Colen",
        "Reporter": "William Colen",
        "Created": "13/Jul/11 19:06",
        "Updated": "02/May/13 02:29",
        "Resolved": "22/Jul/11 16:30",
        "Description": "Today the abbreviation dictionary features of SentenceDetector are only usable though the API. We should add mechanism to allow training with an abbreviation dictionary from command line, and also add the dictionary to the model as we do with POS Tagger.",
        "Issue Links": [
            "/jira/browse/OPENNLP-227"
        ]
    },
    "OPENNLP-226": {
        "Key": "OPENNLP-226",
        "Summary": "Evaluators should allow tools to register a report interface",
        "Type": "New Feature",
        "Status": "Closed",
        "Priority": "Minor",
        "Resolution": "Fixed",
        "Affects Version/s": "tools-1.5.2-incubating",
        "Fix Version/s": "tools-1.5.2-incubating",
        "Component/s": "Chunker,                                            Command Line Interface,                                            Name Finder,                                            POS Tagger,                                            Sentence Detector,                                            Tokenizer",
        "Assignee": "William Colen",
        "Reporter": "William Colen",
        "Created": "14/Jul/11 15:39",
        "Updated": "25/Aug/11 13:49",
        "Resolved": "25/Aug/11 13:49",
        "Description": "OPENNLP-220 introduced the -misclassified argument that enables evaluators to print misclassified items while using the command line evaluators. We should expand it to allow any other tool that uses evaluators to register an interface to get that information.",
        "Issue Links": []
    },
    "OPENNLP-227": {
        "Key": "OPENNLP-227",
        "Summary": "Refactoring the Command Line Parameter interfaces",
        "Type": "Improvement",
        "Status": "Closed",
        "Priority": "Minor",
        "Resolution": "Fixed",
        "Affects Version/s": "tools-1.5.2-incubating",
        "Fix Version/s": "tools-1.5.2-incubating",
        "Component/s": "Command Line Interface",
        "Assignee": "William Colen",
        "Reporter": "William Colen",
        "Created": "15/Jul/11 13:30",
        "Updated": "02/May/13 02:29",
        "Resolved": "22/Jul/11 16:29",
        "Description": "Refactoring the Command Line Parameter interfaces as described at https://cwiki.apache.org/OPENNLP/command-line-parameter-interfaces.html",
        "Issue Links": [
            "/jira/browse/OPENNLP-225"
        ]
    },
    "OPENNLP-228": {
        "Key": "OPENNLP-228",
        "Summary": "Name Finder Sequence validator should be configurable via API",
        "Type": "Improvement",
        "Status": "Closed",
        "Priority": "Minor",
        "Resolution": "Fixed",
        "Affects Version/s": "None",
        "Fix Version/s": "tools-1.5.2-incubating",
        "Component/s": "Name Finder",
        "Assignee": "J\u00f6rn Kottmann",
        "Reporter": "J\u00f6rn Kottmann",
        "Created": "18/Jul/11 10:36",
        "Updated": "19/Jul/11 08:42",
        "Resolved": "19/Jul/11 08:42",
        "Description": "The name finder uses a sequence validator to only create valid name sequences. A user might want to further restrict the possible sequences, for this purpose it is necessary to pass in a custom sequence validator.\nThe Name Finder ME constructor should be extended to accept a custom user defined sequence validator, and should make the current sequence validator public.",
        "Issue Links": []
    },
    "OPENNLP-229": {
        "Key": "OPENNLP-229",
        "Summary": "Write a test case for the NameFinderSequenceValidator class",
        "Type": "Task",
        "Status": "Closed",
        "Priority": "Minor",
        "Resolution": "Fixed",
        "Affects Version/s": "None",
        "Fix Version/s": "1.8.0",
        "Component/s": "Name Finder",
        "Assignee": "Peter Thygesen",
        "Reporter": "J\u00f6rn Kottmann",
        "Created": "18/Jul/11 10:46",
        "Updated": "17/Feb/17 13:47",
        "Resolved": "17/Feb/17 13:47",
        "Description": "The NameFinderSequenceValidator is public now, and that makes it possible to write a test for it. The test should check that the sequence validation works as expected.",
        "Issue Links": [
            "https://github.com/apache/opennlp/pull/125"
        ]
    },
    "OPENNLP-230": {
        "Key": "OPENNLP-230",
        "Summary": "Name Finder should calculate probs for spans differently",
        "Type": "Bug",
        "Status": "Closed",
        "Priority": "Minor",
        "Resolution": "Fixed",
        "Affects Version/s": "tools-1.5.1-incubating",
        "Fix Version/s": "tools-1.5.2-incubating",
        "Component/s": "Name Finder",
        "Assignee": "J\u00f6rn Kottmann",
        "Reporter": "J\u00f6rn Kottmann",
        "Created": "18/Jul/11 19:49",
        "Updated": "19/Jul/11 08:42",
        "Resolved": "19/Jul/11 08:42",
        "Description": "The name finder has a method to calculate the probability of a named entity. The method also supports named entites which span multiple tokens. The name finder does sequence labeling, and has a prob per token. To compute the prob of a name span, it simply multiplies the probs of the tokens covered by the span.\nInstead of multiplying it should calculate the arithmetic mean of the token probabilities.",
        "Issue Links": []
    },
    "OPENNLP-231": {
        "Key": "OPENNLP-231",
        "Summary": "POS Tagger cross validator tool is not evaluating models that includes ngram dictionaries.",
        "Type": "Improvement",
        "Status": "Closed",
        "Priority": "Minor",
        "Resolution": "Fixed",
        "Affects Version/s": "tools-1.5.2-incubating",
        "Fix Version/s": "tools-1.5.2-incubating",
        "Component/s": "Command Line Interface,                                            POS Tagger",
        "Assignee": "William Colen",
        "Reporter": "William Colen",
        "Created": "18/Jul/11 20:23",
        "Updated": "23/Aug/11 13:37",
        "Resolved": "23/Aug/11 13:37",
        "Description": "The parameter -ngram is present on POS Tagger trainer tool, but it is not present on CV tool.",
        "Issue Links": []
    },
    "OPENNLP-232": {
        "Key": "OPENNLP-232",
        "Summary": "Add fold parameter to cross validator tools",
        "Type": "Improvement",
        "Status": "Closed",
        "Priority": "Minor",
        "Resolution": "Fixed",
        "Affects Version/s": "tools-1.5.2-incubating",
        "Fix Version/s": "tools-1.5.2-incubating",
        "Component/s": "Command Line Interface",
        "Assignee": "William Colen",
        "Reporter": "William Colen",
        "Created": "18/Jul/11 21:22",
        "Updated": "19/Jul/11 05:05",
        "Resolved": "19/Jul/11 05:05",
        "Description": "Should add -fold parameter to CV tools. Default should be 10.",
        "Issue Links": []
    },
    "OPENNLP-233": {
        "Key": "OPENNLP-233",
        "Summary": "Parser produces \"log probabilities\" that are positive",
        "Type": "Task",
        "Status": "Closed",
        "Priority": "Major",
        "Resolution": "Fixed",
        "Affects Version/s": "tools-1.5.1-incubating",
        "Fix Version/s": "tools-1.5.2-incubating",
        "Component/s": "Command Line Interface,                                            Parser",
        "Assignee": "J\u00f6rn Kottmann",
        "Reporter": "Chris Brew",
        "Created": "18/Jul/11 23:45",
        "Updated": "21/Jul/11 16:32",
        "Resolved": "21/Jul/11 08:40",
        "Description": "Using the distributed version and the binary model from the sourceforge site, I see the following bad behaviour. This is bad because probabilities always should be <= 1, so log probabilities should be <= 0, which they clearly are not.\nScript started on Mon Jul 18 19:34:36 2011\nbash-3.2$ bin/opennlp Parser -k 2 models/en-parser-chunking.bin \nLoading Parser model ... done (14.573s)\nThe old are wise .\n0 0.06948959676790605 (TOP (S (NP (DT The) (JJ old)) (VP (VBP are) (ADJP (JJ wise))) (. .)))\n1 -1.3788870933108204 (TOP (S (NP (DT The) (JJ old)) (VP (VBP are) (ADVP (RB wise))) (. .)))\nThe young are foolish .\n0 0.2094212498812974 (TOP (S (NP (DT The) (JJ young)) (VP (VBP are) (ADJP (JJ foolish))) (. .)))\n1 -2.2380713063683784 (TOP (S (NP (DT The) (NNP young)) (VP (VBP are) (ADJP (JJ foolish))) (. .)))\n^D\nAverage: 0.1 sent/s \nTotal: 4 sent\nRuntime: 57.565s\nbash-3.2$ exit\nScript done on Mon Jul 18 19:35:56 2011",
        "Issue Links": []
    },
    "OPENNLP-234": {
        "Key": "OPENNLP-234",
        "Summary": "Create Abbreviation Dictionary implementation and command line tools to build it",
        "Type": "New Feature",
        "Status": "Closed",
        "Priority": "Minor",
        "Resolution": "Invalid",
        "Affects Version/s": "None",
        "Fix Version/s": "None",
        "Component/s": "Command Line Interface,                                            Sentence Detector,                                            Tokenizer",
        "Assignee": "William Colen",
        "Reporter": "William Colen",
        "Created": "19/Jul/11 15:25",
        "Updated": "21/Jul/11 17:43",
        "Resolved": "21/Jul/11 17:43",
        "Description": "Will add an abbreviation dictionary implementation and a CL tool to build it from a plain file.",
        "Issue Links": []
    },
    "OPENNLP-235": {
        "Key": "OPENNLP-235",
        "Summary": "Create an OpenNLP Plugin for the UIMA Cas Editor",
        "Type": "New Feature",
        "Status": "Closed",
        "Priority": "Minor",
        "Resolution": "Fixed",
        "Affects Version/s": "None",
        "Fix Version/s": "None",
        "Component/s": "Cas Editor OpenNLP Plugin",
        "Assignee": "J\u00f6rn Kottmann",
        "Reporter": "J\u00f6rn Kottmann",
        "Created": "19/Jul/11 16:05",
        "Updated": "28/Sep/11 10:44",
        "Resolved": "28/Sep/11 10:44",
        "Description": "The UIMA Cas Editor is a UIMA based annotation tool. Annotating texts could be easier with an OpenNLP Plugin for it to automatically suggest what could be tagged, and then ask the user to confirm/reject. This idea is taken from the discussions we had about the OpenNLP Annotations project.\nThe first version should have support for the Name Finder.",
        "Issue Links": []
    },
    "OPENNLP-236": {
        "Key": "OPENNLP-236",
        "Summary": "Create a command line tool to create dictionaries",
        "Type": "Improvement",
        "Status": "Closed",
        "Priority": "Minor",
        "Resolution": "Fixed",
        "Affects Version/s": "tools-1.5.2-incubating",
        "Fix Version/s": "tools-1.5.2-incubating",
        "Component/s": "Command Line Interface",
        "Assignee": "William Colen",
        "Reporter": "William Colen",
        "Created": "21/Jul/11 20:34",
        "Updated": "27/Jul/11 14:09",
        "Resolved": "27/Jul/11 14:09",
        "Description": "Should create a command line tool to create dictionaries. The input should be a plain text and the output a serialized Dictionary.",
        "Issue Links": []
    },
    "OPENNLP-237": {
        "Key": "OPENNLP-237",
        "Summary": "Add abbreviation dictionary support to Tokenizer",
        "Type": "Improvement",
        "Status": "Closed",
        "Priority": "Minor",
        "Resolution": "Fixed",
        "Affects Version/s": "tools-1.5.2-incubating",
        "Fix Version/s": "tools-1.5.2-incubating",
        "Component/s": "Tokenizer",
        "Assignee": "William Colen",
        "Reporter": "William Colen",
        "Created": "22/Jul/11 16:36",
        "Updated": "27/Jul/11 14:04",
        "Resolved": "27/Jul/11 14:04",
        "Description": "The Tokenizer component can take advantage of using an abbreviation dictionary in context generator.\nAlthough it modifies the default tokenizer context generator it won't break compatibility with old models because the features would be applied only if the dictionary is present.",
        "Issue Links": []
    },
    "OPENNLP-238": {
        "Key": "OPENNLP-238",
        "Summary": "BestSequence method in BeamSearch can cause NullPointerException if it can not find a valid sequence",
        "Type": "Bug",
        "Status": "Closed",
        "Priority": "Major",
        "Resolution": "Not A Problem",
        "Affects Version/s": "tools-1.5.2-incubating",
        "Fix Version/s": "None",
        "Component/s": "POS Tagger",
        "Assignee": "William Colen",
        "Reporter": "William Colen",
        "Created": "26/Jul/11 03:11",
        "Updated": "09/Aug/11 08:28",
        "Resolved": "09/Aug/11 08:28",
        "Description": "I am using the standard sequence validator of POS Tagger with a TagDictionary. Sometimes there are no outcome that matches with the tags in the dictionary. That is causing a NullPointerException in bestSequence method.\nI think we should add an extra validation: if the heap 'next' still empty after advancing all valid sequences (line 159) we should let it advance invalid sequences. It would make the POS Tagger more robust.",
        "Issue Links": [
            "/jira/browse/OPENNLP-241"
        ]
    },
    "OPENNLP-239": {
        "Key": "OPENNLP-239",
        "Summary": "Case Sensitivie Flag & Custom Tag Dictionary",
        "Type": "New Feature",
        "Status": "Closed",
        "Priority": "Major",
        "Resolution": "Fixed",
        "Affects Version/s": "tools-1.5.1-incubating",
        "Fix Version/s": "tools-1.5.2-incubating",
        "Component/s": "Parser",
        "Assignee": "James Kosin",
        "Reporter": "mark meiklejohn",
        "Created": "26/Jul/11 18:47",
        "Updated": "23/Aug/11 11:05",
        "Resolved": "22/Aug/11 22:43",
        "Description": "Unable to set case sensitive flag as per TreebankParser 1.3.1 or use a custom tag dictionary",
        "Issue Links": []
    },
    "OPENNLP-240": {
        "Key": "OPENNLP-240",
        "Summary": "Full-Stop detection not working during full NLP parse",
        "Type": "Bug",
        "Status": "Closed",
        "Priority": "Major",
        "Resolution": "Not A Problem",
        "Affects Version/s": "tools-1.5.1-incubating",
        "Fix Version/s": "None",
        "Component/s": "Parser",
        "Assignee": "J\u00f6rn Kottmann",
        "Reporter": "mark meiklejohn",
        "Created": "26/Jul/11 18:55",
        "Updated": "08/Aug/11 16:55",
        "Resolved": "08/Aug/11 16:55",
        "Description": "There seems to be an issue with OpenNLP detecting the full stop at the end of the sentence\n(TOP (S (NP (PRP I)) (VP (VBP intend) (S (VP (TO to) (VP (VB quit) (NP (NP (NN smoking)) (NP (DT this) (NN month.)))))))))\nAlthough it does work fine with the tokenizer on its own\n[I, intend, to, quit, smoking, this, month, .]",
        "Issue Links": []
    },
    "OPENNLP-241": {
        "Key": "OPENNLP-241",
        "Summary": "Model validations is only performed if instatiated from  Input Stream.",
        "Type": "Bug",
        "Status": "Closed",
        "Priority": "Minor",
        "Resolution": "Fixed",
        "Affects Version/s": "tools-1.5.2-incubating",
        "Fix Version/s": "tools-1.5.2-incubating",
        "Component/s": "Chunker,                                            Coref,                                            Doccat,                                            Name Finder,                                            Parser,                                            POS Tagger,                                            Sentence Detector,                                            Tokenizer",
        "Assignee": null,
        "Reporter": "William Colen",
        "Created": "29/Jul/11 21:19",
        "Updated": "29/Aug/11 19:41",
        "Resolved": "29/Aug/11 19:41",
        "Description": "Models are not validated if instantiated with the constructor the cross validator, or training code uses.\nThe validation is only performed when it is loaded from an Input Stream.\nFor example the POS Model does not validate the dictionary tagset while training or executing cross validation, only during execution tool or evaluation.",
        "Issue Links": [
            "/jira/browse/OPENNLP-238",
            "/jira/browse/OPENNLP-127"
        ]
    },
    "OPENNLP-242": {
        "Key": "OPENNLP-242",
        "Summary": "Chunker evaluation tools are not using SenquenceValidator",
        "Type": "Bug",
        "Status": "Closed",
        "Priority": "Minor",
        "Resolution": "Fixed",
        "Affects Version/s": "tools-1.5.2-incubating",
        "Fix Version/s": "tools-1.5.2-incubating",
        "Component/s": "Chunker",
        "Assignee": "William Colen",
        "Reporter": "William Colen",
        "Created": "02/Aug/11 23:46",
        "Updated": "23/Aug/11 04:54",
        "Resolved": "23/Aug/11 04:54",
        "Description": "Chunker evaluation tools are not using a sequence validator. Should use the same the runtime tool uses.",
        "Issue Links": []
    },
    "OPENNLP-243": {
        "Key": "OPENNLP-243",
        "Summary": "Ship maxent as an OSGi bundle",
        "Type": "Task",
        "Status": "Closed",
        "Priority": "Minor",
        "Resolution": "Fixed",
        "Affects Version/s": "None",
        "Fix Version/s": "tools-1.5.2-incubating,                                            maxent-3.0.2-incubating",
        "Component/s": "Machine Learning",
        "Assignee": "J\u00f6rn Kottmann",
        "Reporter": "J\u00f6rn Kottmann",
        "Created": "03/Aug/11 17:23",
        "Updated": "22/Aug/11 13:18",
        "Resolved": "22/Aug/11 13:18",
        "Description": "Many projects use OSGi today and need to repackage maxent to make it accessible within OSGi. Maxent will fully support OSGi when the jar file includes an OSGi manifest.mf file.",
        "Issue Links": []
    },
    "OPENNLP-244": {
        "Key": "OPENNLP-244",
        "Summary": "Write documentation for the BIONLP converter",
        "Type": "Improvement",
        "Status": "Open",
        "Priority": "Minor",
        "Resolution": "Unresolved",
        "Affects Version/s": "None",
        "Fix Version/s": "None",
        "Component/s": "Documentation",
        "Assignee": null,
        "Reporter": "J\u00f6rn Kottmann",
        "Created": "09/Aug/11 11:49",
        "Updated": "09/Jan/17 15:04",
        "Resolved": null,
        "Description": "Write documentation for the BioNLP/NLPBA 2004 converter.",
        "Issue Links": []
    },
    "OPENNLP-245": {
        "Key": "OPENNLP-245",
        "Summary": "Improve Dictionary Testing",
        "Type": "Task",
        "Status": "Closed",
        "Priority": "Major",
        "Resolution": "Fixed",
        "Affects Version/s": "None",
        "Fix Version/s": "tools-1.5.2-incubating",
        "Component/s": "None",
        "Assignee": "James Kosin",
        "Reporter": "James Kosin",
        "Created": "16/Aug/11 00:10",
        "Updated": "29/Aug/11 12:42",
        "Resolved": "29/Aug/11 12:36",
        "Description": "Expand the Dictionary Tests to include testing for case sensitive and insensitive dictionaries.",
        "Issue Links": []
    },
    "OPENNLP-246": {
        "Key": "OPENNLP-246",
        "Summary": "NameFinder documentation fix",
        "Type": "Bug",
        "Status": "Closed",
        "Priority": "Minor",
        "Resolution": "Fixed",
        "Affects Version/s": "tools-1.5.1-incubating",
        "Fix Version/s": "tools-1.5.2-incubating",
        "Component/s": "Documentation,                                            Name Finder",
        "Assignee": "J\u00f6rn Kottmann",
        "Reporter": "Peter Harrington",
        "Created": "16/Aug/11 01:38",
        "Updated": "16/Aug/11 18:41",
        "Resolved": "16/Aug/11 18:41",
        "Description": "I have a patch to fix a few issues with the documentation in:\ndocs/manual/opennlp.html",
        "Issue Links": []
    },
    "OPENNLP-247": {
        "Key": "OPENNLP-247",
        "Summary": "Sample classes should override equals method",
        "Type": "Improvement",
        "Status": "Closed",
        "Priority": "Minor",
        "Resolution": "Fixed",
        "Affects Version/s": "tools-1.5.2-incubating",
        "Fix Version/s": "tools-1.5.2-incubating",
        "Component/s": "Chunker,                                            Doccat,                                            POS Tagger,                                            Sentence Detector,                                            Tokenizer",
        "Assignee": "William Colen",
        "Reporter": "William Colen",
        "Created": "16/Aug/11 22:27",
        "Updated": "17/Aug/11 11:26",
        "Resolved": "17/Aug/11 11:26",
        "Description": "All Sample classes, for example ChunkSample, should override equals method.",
        "Issue Links": []
    },
    "OPENNLP-248": {
        "Key": "OPENNLP-248",
        "Summary": "Span.equals does not check span type correctly if one has null type",
        "Type": "Bug",
        "Status": "Closed",
        "Priority": "Major",
        "Resolution": "Fixed",
        "Affects Version/s": "tools-1.5.2-incubating",
        "Fix Version/s": "tools-1.5.2-incubating",
        "Component/s": "None",
        "Assignee": "William Colen",
        "Reporter": "William Colen",
        "Created": "17/Aug/11 11:33",
        "Updated": "17/Aug/11 16:38",
        "Resolved": "17/Aug/11 16:38",
        "Description": "Span a1 = new Span(100, 1000, \"test\");\nSpan d1 = new Span(100, 1000);\na1.equals(d1) returns false\nd1.equals(a1) returns true",
        "Issue Links": []
    },
    "OPENNLP-249": {
        "Key": "OPENNLP-249",
        "Summary": "Corpus Server lucas indexer should index full article text",
        "Type": "Improvement",
        "Status": "Closed",
        "Priority": "Minor",
        "Resolution": "Fixed",
        "Affects Version/s": "None",
        "Fix Version/s": "None",
        "Component/s": "None",
        "Assignee": "J\u00f6rn Kottmann",
        "Reporter": "J\u00f6rn Kottmann",
        "Created": "17/Aug/11 16:05",
        "Updated": "17/Aug/11 16:06",
        "Resolved": "17/Aug/11 16:06",
        "Description": "Extend the current lucas mapping file to index the full article text also.",
        "Issue Links": []
    },
    "OPENNLP-250": {
        "Key": "OPENNLP-250",
        "Summary": "Corpus Server fails to retrieve cas if its id contains certain characters",
        "Type": "Bug",
        "Status": "Closed",
        "Priority": "Major",
        "Resolution": "Fixed",
        "Affects Version/s": "None",
        "Fix Version/s": "None",
        "Component/s": "None",
        "Assignee": "J\u00f6rn Kottmann",
        "Reporter": "J\u00f6rn Kottmann",
        "Created": "17/Aug/11 16:13",
        "Updated": "17/Aug/11 16:19",
        "Resolved": "17/Aug/11 16:19",
        "Description": "The Corpus Server fails to construct a correct SQL statement when the id of the CAS contains certain characters.",
        "Issue Links": []
    },
    "OPENNLP-251": {
        "Key": "OPENNLP-251",
        "Summary": "Add tool to corpus server to do a search",
        "Type": "Improvement",
        "Status": "Closed",
        "Priority": "Minor",
        "Resolution": "Fixed",
        "Affects Version/s": "None",
        "Fix Version/s": "None",
        "Component/s": "Corpus Server",
        "Assignee": "J\u00f6rn Kottmann",
        "Reporter": "J\u00f6rn Kottmann",
        "Created": "17/Aug/11 17:56",
        "Updated": "18/Aug/11 20:32",
        "Resolved": "18/Aug/11 20:32",
        "Description": "The corpus server tools should be extended with a tool to issue a search query.",
        "Issue Links": []
    },
    "OPENNLP-252": {
        "Key": "OPENNLP-252",
        "Summary": "Create a plugin for the cas editor which gives access to the corpus server",
        "Type": "Improvement",
        "Status": "Closed",
        "Priority": "Major",
        "Resolution": "Fixed",
        "Affects Version/s": "None",
        "Fix Version/s": "None",
        "Component/s": "Cas Editor Corpus Server Plugin",
        "Assignee": "J\u00f6rn Kottmann",
        "Reporter": "J\u00f6rn Kottmann",
        "Created": "17/Aug/11 18:09",
        "Updated": "10/Oct/11 14:39",
        "Resolved": "10/Oct/11 14:39",
        "Description": "The proposed plugin should have two views. One to explorer the contents of a corpus via searching, and one which can get work items from a task queue.\nChanges made to a CAS should be saved back to the Corpus Server.",
        "Issue Links": []
    },
    "OPENNLP-253": {
        "Key": "OPENNLP-253",
        "Summary": "Add text similarity / relevance / syntactic match component based on parse trees",
        "Type": "Improvement",
        "Status": "Closed",
        "Priority": "Major",
        "Resolution": "Fixed",
        "Affects Version/s": "None",
        "Fix Version/s": "None",
        "Component/s": "Parser",
        "Assignee": "J\u00f6rn Kottmann",
        "Reporter": "Boris Galitsky",
        "Created": "17/Aug/11 23:56",
        "Updated": "11/Oct/11 15:39",
        "Resolved": "11/Oct/11 15:39",
        "Description": "Proposed component relies on openNLP parser, and gives search engineers a simple relevance verification tool which relies on machine learning of syntactic parse trees.\nThe value for search engineers community is that they dont have to be familiar with NLP to use syntactic generalization component, which does parsing/chunking by openNLP and then graph-based learning for relevance assessment (proposed component).\nOne of the expected usage scenario is that a search library like lucene is used, and this component would accept / reject irrelevant search results (according to the proposed syntactic generalization measure).\nThis code has been deployed commercially over last 2 years at datran.com and zvents.com and is serving > 20 mln users monthly.\nThere is a number of publications on this project, including \nhttp://portal.acm.org/citation.cfm?id=1881190\nhttp://www.aaai.org/ocs/index.php/FLAIRS/FLAIRS11/paper/view/2573",
        "Issue Links": []
    },
    "OPENNLP-254": {
        "Key": "OPENNLP-254",
        "Summary": "Fixed Lucas index handling in corpus server",
        "Type": "Bug",
        "Status": "Closed",
        "Priority": "Major",
        "Resolution": "Fixed",
        "Affects Version/s": "None",
        "Fix Version/s": "None",
        "Component/s": "Corpus Server",
        "Assignee": "J\u00f6rn Kottmann",
        "Reporter": "J\u00f6rn Kottmann",
        "Created": "18/Aug/11 20:09",
        "Updated": "18/Aug/11 20:14",
        "Resolved": "18/Aug/11 20:14",
        "Description": "The lucene index is overwritten when the corpus server is restarted, this has to do with a flag which is passed to the lucene Index Writer, this create flag needs to be configurable, depending on if an index needs to be created, or is just appended.",
        "Issue Links": []
    },
    "OPENNLP-255": {
        "Key": "OPENNLP-255",
        "Summary": "Span.hashCode() does not include the member type in hash calculation",
        "Type": "Bug",
        "Status": "Closed",
        "Priority": "Major",
        "Resolution": "Fixed",
        "Affects Version/s": "tools-1.5.2-incubating",
        "Fix Version/s": "tools-1.5.2-incubating",
        "Component/s": "None",
        "Assignee": null,
        "Reporter": "William Colen",
        "Created": "18/Aug/11 21:33",
        "Updated": "22/Aug/11 13:50",
        "Resolved": "22/Aug/11 13:50",
        "Description": "Should include the member type in hashCode calculation.",
        "Issue Links": []
    },
    "OPENNLP-256": {
        "Key": "OPENNLP-256",
        "Summary": "Create a detailed FMeasure results listener",
        "Type": "New Feature",
        "Status": "Closed",
        "Priority": "Minor",
        "Resolution": "Fixed",
        "Affects Version/s": "tools-1.5.2-incubating",
        "Fix Version/s": "tools-1.5.2-incubating",
        "Component/s": "Chunker,                                            Name Finder",
        "Assignee": "William Colen",
        "Reporter": "William Colen",
        "Created": "19/Aug/11 01:05",
        "Updated": "25/Aug/11 13:50",
        "Resolved": "25/Aug/11 13:50",
        "Description": "Create a evaluation listener that would output detailed FMeasure for samples that uses typed span. For example, it lets the user know individual precision and recall for person, organization, date in a NameFinder model.",
        "Issue Links": []
    },
    "OPENNLP-257": {
        "Key": "OPENNLP-257",
        "Summary": "Move all the parameter classes in opennlp.tools.cmdline into the params sub-package",
        "Type": "Task",
        "Status": "Closed",
        "Priority": "Minor",
        "Resolution": "Fixed",
        "Affects Version/s": "None",
        "Fix Version/s": "tools-1.5.2-incubating",
        "Component/s": "Command Line Interface",
        "Assignee": "J\u00f6rn Kottmann",
        "Reporter": "J\u00f6rn Kottmann",
        "Created": "19/Aug/11 09:31",
        "Updated": "19/Aug/11 09:36",
        "Resolved": "19/Aug/11 09:36",
        "Description": "Small refactoring: Move all the parameter classes into the params sub-package.",
        "Issue Links": []
    },
    "OPENNLP-258": {
        "Key": "OPENNLP-258",
        "Summary": "Refactor cross validation and training code to always use the new Training Parameters object",
        "Type": "Improvement",
        "Status": "Closed",
        "Priority": "Trivial",
        "Resolution": "Fixed",
        "Affects Version/s": "None",
        "Fix Version/s": "tools-1.5.2-incubating",
        "Component/s": "None",
        "Assignee": "J\u00f6rn Kottmann",
        "Reporter": "J\u00f6rn Kottmann",
        "Created": "22/Aug/11 10:27",
        "Updated": "29/Aug/11 11:08",
        "Resolved": "29/Aug/11 11:08",
        "Description": "For backward compatibility OpenNLP still needs to support the direct passing of the iterations and cutoff params to many methods in code which is related to training a component. The iterations and cutoff of parameters should always be wrapped in a Training Parameters object, and then the new methods should be called.",
        "Issue Links": []
    },
    "OPENNLP-259": {
        "Key": "OPENNLP-259",
        "Summary": "Make the 1.5.2 release",
        "Type": "Task",
        "Status": "Closed",
        "Priority": "Major",
        "Resolution": "Fixed",
        "Affects Version/s": "None",
        "Fix Version/s": "None",
        "Component/s": "None",
        "Assignee": "J\u00f6rn Kottmann",
        "Reporter": "J\u00f6rn Kottmann",
        "Created": "22/Aug/11 12:19",
        "Updated": "28/Nov/11 14:20",
        "Resolved": "28/Nov/11 14:20",
        "Description": "This issue groups all smaller changes which are necessary to create the next release.",
        "Issue Links": [
            "/jira/browse/OPENNLP-223"
        ]
    },
    "OPENNLP-260": {
        "Key": "OPENNLP-260",
        "Summary": "Update Apache parent pom to version 10",
        "Type": "Improvement",
        "Status": "Closed",
        "Priority": "Minor",
        "Resolution": "Fixed",
        "Affects Version/s": "None",
        "Fix Version/s": "tools-1.5.2-incubating,                                            maxent-3.0.2-incubating",
        "Component/s": "Build, Packaging and Test",
        "Assignee": "J\u00f6rn Kottmann",
        "Reporter": "J\u00f6rn Kottmann",
        "Created": "22/Aug/11 12:48",
        "Updated": "22/Aug/11 13:03",
        "Resolved": "22/Aug/11 13:03",
        "Description": "The parent pom should be updated to version 10. Workarounds for fixed issues in the new pom should be removed.",
        "Issue Links": []
    },
    "OPENNLP-261": {
        "Key": "OPENNLP-261",
        "Summary": "Wirte Analysis Engines to read and write CAS from/to the Corpus Server",
        "Type": "Task",
        "Status": "Closed",
        "Priority": "Major",
        "Resolution": "Won't Fix",
        "Affects Version/s": "None",
        "Fix Version/s": "None",
        "Component/s": "Corpus Server",
        "Assignee": null,
        "Reporter": "J\u00f6rn Kottmann",
        "Created": "22/Aug/11 17:27",
        "Updated": "16/Jan/17 14:31",
        "Resolved": "16/Jan/17 14:31",
        "Description": "We need to write an Analysis Engine to read CASes from the Corpus Server, and one to write analysis results back into the Corpus Server.",
        "Issue Links": []
    },
    "OPENNLP-262": {
        "Key": "OPENNLP-262",
        "Summary": "Deprecate methods which still use cutoff and iterations args",
        "Type": "Task",
        "Status": "Closed",
        "Priority": "Major",
        "Resolution": "Fixed",
        "Affects Version/s": "None",
        "Fix Version/s": "tools-1.5.2-incubating",
        "Component/s": "None",
        "Assignee": "J\u00f6rn Kottmann",
        "Reporter": "J\u00f6rn Kottmann",
        "Created": "23/Aug/11 22:33",
        "Updated": "26/Aug/11 12:31",
        "Resolved": "26/Aug/11 12:31",
        "Description": "All methods which still use the iterations and cutoff argument should be deprecated and the related method with the TrainingParameters argument should be called.",
        "Issue Links": []
    },
    "OPENNLP-263": {
        "Key": "OPENNLP-263",
        "Summary": "Add OSGi support to the opennlp tools",
        "Type": "Improvement",
        "Status": "Closed",
        "Priority": "Major",
        "Resolution": "Fixed",
        "Affects Version/s": "None",
        "Fix Version/s": "tools-1.5.2-incubating",
        "Component/s": "None",
        "Assignee": "J\u00f6rn Kottmann",
        "Reporter": "J\u00f6rn Kottmann",
        "Created": "23/Aug/11 22:35",
        "Updated": "25/Aug/11 09:39",
        "Resolved": "25/Aug/11 09:39",
        "Description": "Add OSGi support to the tools jar also, it needs to include an OSGi enabled manifest file. The support will not be perfect because coref and the custom class loading feature in the name finder will not work.\nThis limitation should be listed as known issue.",
        "Issue Links": []
    },
    "OPENNLP-264": {
        "Key": "OPENNLP-264",
        "Summary": "Code Cleanup: Remove unnecessary casts",
        "Type": "Task",
        "Status": "Closed",
        "Priority": "Major",
        "Resolution": "Fixed",
        "Affects Version/s": "None",
        "Fix Version/s": "tools-1.5.2-incubating",
        "Component/s": "None",
        "Assignee": "J\u00f6rn Kottmann",
        "Reporter": "J\u00f6rn Kottmann",
        "Created": "24/Aug/11 08:33",
        "Updated": "24/Aug/11 08:36",
        "Resolved": "24/Aug/11 08:36",
        "Description": "Use the eclipse code clean up tool to remove all unnecessary casts.",
        "Issue Links": []
    },
    "OPENNLP-265": {
        "Key": "OPENNLP-265",
        "Summary": "Code Cleanup: Add missing '@Override' annotations",
        "Type": "Task",
        "Status": "Closed",
        "Priority": "Major",
        "Resolution": "Fixed",
        "Affects Version/s": "None",
        "Fix Version/s": "tools-1.5.2-incubating",
        "Component/s": "None",
        "Assignee": "J\u00f6rn Kottmann",
        "Reporter": "J\u00f6rn Kottmann",
        "Created": "24/Aug/11 08:44",
        "Updated": "24/Aug/11 08:51",
        "Resolved": "24/Aug/11 08:51",
        "Description": "Add all missing @Override annotations.",
        "Issue Links": []
    },
    "OPENNLP-266": {
        "Key": "OPENNLP-266",
        "Summary": "Code Cleanup: Organize imports",
        "Type": "Task",
        "Status": "Closed",
        "Priority": "Major",
        "Resolution": "Fixed",
        "Affects Version/s": "None",
        "Fix Version/s": "tools-1.5.2-incubating",
        "Component/s": "None",
        "Assignee": "J\u00f6rn Kottmann",
        "Reporter": "J\u00f6rn Kottmann",
        "Created": "24/Aug/11 08:53",
        "Updated": "24/Aug/11 08:54",
        "Resolved": "24/Aug/11 08:54",
        "Description": null,
        "Issue Links": []
    },
    "OPENNLP-267": {
        "Key": "OPENNLP-267",
        "Summary": "Code Cleanup: Remove trailing white spaces",
        "Type": "Task",
        "Status": "Closed",
        "Priority": "Major",
        "Resolution": "Won't Fix",
        "Affects Version/s": "None",
        "Fix Version/s": "None",
        "Component/s": "None",
        "Assignee": "J\u00f6rn Kottmann",
        "Reporter": "J\u00f6rn Kottmann",
        "Created": "24/Aug/11 09:06",
        "Updated": "24/Aug/11 09:15",
        "Resolved": "24/Aug/11 09:15",
        "Description": "Remove all trailing white spaces. This is needed for other cleanups, for example the one to fix incorrect indentions.",
        "Issue Links": []
    },
    "OPENNLP-268": {
        "Key": "OPENNLP-268",
        "Summary": "Make constants in StringPattern constant",
        "Type": "Improvement",
        "Status": "Closed",
        "Priority": "Trivial",
        "Resolution": "Fixed",
        "Affects Version/s": "None",
        "Fix Version/s": "tools-1.5.2-incubating",
        "Component/s": "None",
        "Assignee": "J\u00f6rn Kottmann",
        "Reporter": "J\u00f6rn Kottmann",
        "Created": "24/Aug/11 09:58",
        "Updated": "24/Aug/11 09:59",
        "Resolved": "24/Aug/11 09:59",
        "Description": "The StringPattern defines a couple of constants, but they are not static final.",
        "Issue Links": []
    },
    "OPENNLP-269": {
        "Key": "OPENNLP-269",
        "Summary": "Finish DocumentCategorizerTrainer",
        "Type": "Bug",
        "Status": "Closed",
        "Priority": "Major",
        "Resolution": "Won't Fix",
        "Affects Version/s": "None",
        "Fix Version/s": "None",
        "Component/s": "UIMA Integration",
        "Assignee": null,
        "Reporter": "J\u00f6rn Kottmann",
        "Created": "24/Aug/11 10:16",
        "Updated": "03/Jan/17 09:45",
        "Resolved": "03/Jan/17 09:45",
        "Description": "The UIMA document categorizer trainer is still work in progress and does not work the way it is implemented currently, especially the code to extract the document category and the code to train the model is missing.",
        "Issue Links": []
    },
    "OPENNLP-270": {
        "Key": "OPENNLP-270",
        "Summary": "Maven felix bundle plugin is used in build without specifying a version of it",
        "Type": "Bug",
        "Status": "Closed",
        "Priority": "Major",
        "Resolution": "Fixed",
        "Affects Version/s": "None",
        "Fix Version/s": "tools-1.5.2-incubating",
        "Component/s": "Build, Packaging and Test",
        "Assignee": "J\u00f6rn Kottmann",
        "Reporter": "J\u00f6rn Kottmann",
        "Created": "24/Aug/11 10:19",
        "Updated": "24/Aug/11 20:55",
        "Resolved": "24/Aug/11 20:55",
        "Description": "Add a version for the bundle plugin to our parent pom. The missing version leads to inconsistent builds, for example it does not build anymore on our build server.",
        "Issue Links": []
    },
    "OPENNLP-271": {
        "Key": "OPENNLP-271",
        "Summary": "Remove redundant null check in TokenizerCrossValidatorTool",
        "Type": "Improvement",
        "Status": "Closed",
        "Priority": "Trivial",
        "Resolution": "Fixed",
        "Affects Version/s": "None",
        "Fix Version/s": "tools-1.5.2-incubating",
        "Component/s": "None",
        "Assignee": "J\u00f6rn Kottmann",
        "Reporter": "J\u00f6rn Kottmann",
        "Created": "25/Aug/11 08:41",
        "Updated": "25/Aug/11 08:45",
        "Resolved": "25/Aug/11 08:45",
        "Description": null,
        "Issue Links": []
    },
    "OPENNLP-272": {
        "Key": "OPENNLP-272",
        "Summary": "AnnotatorUtils getRequiredFeature method does not include feature name in exception message",
        "Type": "Improvement",
        "Status": "Closed",
        "Priority": "Trivial",
        "Resolution": "Fixed",
        "Affects Version/s": "None",
        "Fix Version/s": "tools-1.5.2-incubating",
        "Component/s": "UIMA Integration",
        "Assignee": "J\u00f6rn Kottmann",
        "Reporter": "J\u00f6rn Kottmann",
        "Created": "25/Aug/11 08:47",
        "Updated": "25/Aug/11 08:48",
        "Resolved": "25/Aug/11 08:48",
        "Description": "The exception thrown in this message contains null, instad of the feature name. To fix this pass the feature name instead of null a reference.",
        "Issue Links": []
    },
    "OPENNLP-273": {
        "Key": "OPENNLP-273",
        "Summary": "Remove unnecessary null check from equals methods",
        "Type": "Improvement",
        "Status": "Closed",
        "Priority": "Trivial",
        "Resolution": "Fixed",
        "Affects Version/s": "None",
        "Fix Version/s": "tools-1.5.2-incubating",
        "Component/s": "None",
        "Assignee": "J\u00f6rn Kottmann",
        "Reporter": "J\u00f6rn Kottmann",
        "Created": "25/Aug/11 08:56",
        "Updated": "25/Aug/11 08:59",
        "Resolved": "25/Aug/11 08:59",
        "Description": "There is an unnecessary null check in StringLists and Dictionaries equals methods. Remove them.",
        "Issue Links": []
    },
    "OPENNLP-274": {
        "Key": "OPENNLP-274",
        "Summary": "Chunker feature generation should use caching like the POS Tagger or Name Finder",
        "Type": "Improvement",
        "Status": "Closed",
        "Priority": "Minor",
        "Resolution": "Won't Fix",
        "Affects Version/s": "None",
        "Fix Version/s": "1.7.1",
        "Component/s": "Chunker",
        "Assignee": "William Colen",
        "Reporter": "J\u00f6rn Kottmann",
        "Created": "25/Aug/11 17:36",
        "Updated": "03/Jan/17 15:04",
        "Resolved": "03/Jan/17 15:04",
        "Description": "The chunker feature generation is currently not cached. The caching should be implemented in the same fashion as it is done for the POS Tagger or Name Finder.",
        "Issue Links": [
            "https://github.com/apache/opennlp/pull/26"
        ]
    },
    "OPENNLP-275": {
        "Key": "OPENNLP-275",
        "Summary": "Clarify if the chunker feature generation code in the chunker and parser can be unified",
        "Type": "Task",
        "Status": "Open",
        "Priority": "Minor",
        "Resolution": "Unresolved",
        "Affects Version/s": "None",
        "Fix Version/s": "None",
        "Component/s": "Chunker,                                            Parser",
        "Assignee": null,
        "Reporter": "J\u00f6rn Kottmann",
        "Created": "25/Aug/11 17:38",
        "Updated": "25/Aug/11 17:38",
        "Resolved": null,
        "Description": "Currently two different feature generation classes are used, when the chunker is used stand alone, and as part of the parser. Lets figure out if this code can be merged into one common feature generation class, or configurable feature generation.",
        "Issue Links": []
    },
    "OPENNLP-276": {
        "Key": "OPENNLP-276",
        "Summary": "Add test code to the corpus server",
        "Type": "Improvement",
        "Status": "Closed",
        "Priority": "Major",
        "Resolution": "Won't Fix",
        "Affects Version/s": "None",
        "Fix Version/s": "None",
        "Component/s": "Corpus Server",
        "Assignee": null,
        "Reporter": "J\u00f6rn Kottmann",
        "Created": "26/Aug/11 09:03",
        "Updated": "16/Jan/17 14:31",
        "Resolved": "16/Jan/17 14:31",
        "Description": "Add test code to the Corpus Server, which can test its basic functionality.",
        "Issue Links": []
    },
    "OPENNLP-277": {
        "Key": "OPENNLP-277",
        "Summary": "Lucene Index query code should be enhanced",
        "Type": "Improvement",
        "Status": "Closed",
        "Priority": "Major",
        "Resolution": "Fixed",
        "Affects Version/s": "None",
        "Fix Version/s": "None",
        "Component/s": "Corpus Server",
        "Assignee": "J\u00f6rn Kottmann",
        "Reporter": "J\u00f6rn Kottmann",
        "Created": "26/Aug/11 09:06",
        "Updated": "19/Jan/12 14:49",
        "Resolved": "19/Jan/12 14:49",
        "Description": "The Index query code must be enhanced.\nCurrently it has the following issues:\n\nIndex reader is created on every request, which is only good enough for testing\nLucene analyzers do not match the analyzers used to write to the index",
        "Issue Links": []
    },
    "OPENNLP-278": {
        "Key": "OPENNLP-278",
        "Summary": "Link to Arvores Deitadas in documentation is broken",
        "Type": "Bug",
        "Status": "Closed",
        "Priority": "Minor",
        "Resolution": "Fixed",
        "Affects Version/s": "None",
        "Fix Version/s": "tools-1.5.2-incubating",
        "Component/s": "Documentation",
        "Assignee": "J\u00f6rn Kottmann",
        "Reporter": "J\u00f6rn Kottmann",
        "Created": "26/Aug/11 22:44",
        "Updated": "27/Aug/11 08:42",
        "Resolved": "27/Aug/11 08:42",
        "Description": "The link in the Arvores Deitadas documentation to http://www.linguateca.pt does not work. It tries to attach the link to the local file URL.",
        "Issue Links": []
    },
    "OPENNLP-279": {
        "Key": "OPENNLP-279",
        "Summary": "CONLL03 documation link to LDC should be a html link",
        "Type": "Bug",
        "Status": "Closed",
        "Priority": "Minor",
        "Resolution": "Fixed",
        "Affects Version/s": "None",
        "Fix Version/s": "tools-1.5.2-incubating",
        "Component/s": "Documentation",
        "Assignee": "J\u00f6rn Kottmann",
        "Reporter": "J\u00f6rn Kottmann",
        "Created": "26/Aug/11 22:55",
        "Updated": "27/Aug/11 08:43",
        "Resolved": "27/Aug/11 08:43",
        "Description": "The link to LDC should be a html link.",
        "Issue Links": []
    },
    "OPENNLP-280": {
        "Key": "OPENNLP-280",
        "Summary": "Leipzig corpora links seem to be broken",
        "Type": "Bug",
        "Status": "Closed",
        "Priority": "Minor",
        "Resolution": "Fixed",
        "Affects Version/s": "None",
        "Fix Version/s": "tools-1.5.2-incubating",
        "Component/s": "Documentation",
        "Assignee": "J\u00f6rn Kottmann",
        "Reporter": "J\u00f6rn Kottmann",
        "Created": "26/Aug/11 22:57",
        "Updated": "27/Aug/11 08:43",
        "Resolved": "27/Aug/11 08:43",
        "Description": "When clicking on the link to the leipzig corpora the CONLL section is shown. That is likely be because the ids are incorrect.",
        "Issue Links": []
    },
    "OPENNLP-281": {
        "Key": "OPENNLP-281",
        "Summary": "Create a backup tool for the corpus server",
        "Type": "New Feature",
        "Status": "Closed",
        "Priority": "Major",
        "Resolution": "Fixed",
        "Affects Version/s": "None",
        "Fix Version/s": "None",
        "Component/s": "Corpus Server",
        "Assignee": "J\u00f6rn Kottmann",
        "Reporter": "J\u00f6rn Kottmann",
        "Created": "27/Aug/11 14:34",
        "Updated": "29/Aug/11 12:24",
        "Resolved": "29/Aug/11 12:24",
        "Description": "Create a tool which can download a corpus from the corpus server and save its contents into a zip archive.",
        "Issue Links": []
    },
    "OPENNLP-282": {
        "Key": "OPENNLP-282",
        "Summary": "All entities in the list should be selected in the AnnotationEditor on selection",
        "Type": "Improvement",
        "Status": "Closed",
        "Priority": "Major",
        "Resolution": "Fixed",
        "Affects Version/s": "None",
        "Fix Version/s": "None",
        "Component/s": "Cas Editor OpenNLP Plugin",
        "Assignee": "J\u00f6rn Kottmann",
        "Reporter": "J\u00f6rn Kottmann",
        "Created": "29/Aug/11 12:31",
        "Updated": "27/Sep/11 15:21",
        "Resolved": "27/Sep/11 15:21",
        "Description": "Currently only non-confirmed entities are selected in the Annotation Editor when they are selected in the entity list. Fix the code to also selected confirmed entities in the Annotation Editor.",
        "Issue Links": []
    },
    "OPENNLP-283": {
        "Key": "OPENNLP-283",
        "Summary": "Add reject entity support to the name finder job and name finder view",
        "Type": "Improvement",
        "Status": "Closed",
        "Priority": "Major",
        "Resolution": "Won't Fix",
        "Affects Version/s": "None",
        "Fix Version/s": "None",
        "Component/s": "Cas Editor OpenNLP Plugin",
        "Assignee": null,
        "Reporter": "J\u00f6rn Kottmann",
        "Created": "29/Aug/11 12:34",
        "Updated": "06/Dec/11 13:37",
        "Resolved": "06/Dec/11 13:37",
        "Description": "Currently it is only possible to confirm an entity in the name finder view. In some cases entity must be rejected, because they cause lots of false positive hits. Add functionality to reject entities to the name finder job and name finder view.",
        "Issue Links": []
    },
    "OPENNLP-284": {
        "Key": "OPENNLP-284",
        "Summary": "Add efficient keyboard support to the name finder view",
        "Type": "Improvement",
        "Status": "Closed",
        "Priority": "Major",
        "Resolution": "Fixed",
        "Affects Version/s": "None",
        "Fix Version/s": "None",
        "Component/s": "Cas Editor OpenNLP Plugin",
        "Assignee": "J\u00f6rn Kottmann",
        "Reporter": "J\u00f6rn Kottmann",
        "Created": "29/Aug/11 12:35",
        "Updated": "13/Oct/11 13:57",
        "Resolved": "13/Oct/11 13:57",
        "Description": "Usually a user does not want to use a mouse to confirm/reject entities in the text. Add keyboard support which allows rapid confirmation or rejection of entities in the text.",
        "Issue Links": []
    },
    "OPENNLP-285": {
        "Key": "OPENNLP-285",
        "Summary": "Model should be loaded form configured path instead of hard-coded class path location",
        "Type": "Improvement",
        "Status": "Closed",
        "Priority": "Major",
        "Resolution": "Fixed",
        "Affects Version/s": "None",
        "Fix Version/s": "None",
        "Component/s": "Cas Editor OpenNLP Plugin",
        "Assignee": "J\u00f6rn Kottmann",
        "Reporter": "J\u00f6rn Kottmann",
        "Created": "29/Aug/11 13:38",
        "Updated": "29/Aug/11 17:00",
        "Resolved": "29/Aug/11 17:00",
        "Description": "Currently the model is loaded from a hard-coded class path location. Change this to load the model instead form the configured lcoation in the preference page.",
        "Issue Links": []
    },
    "OPENNLP-286": {
        "Key": "OPENNLP-286",
        "Summary": "Write a test for the POSDictionary to test the case sensitive/insensitive flag",
        "Type": "Improvement",
        "Status": "Closed",
        "Priority": "Trivial",
        "Resolution": "Fixed",
        "Affects Version/s": "None",
        "Fix Version/s": "tools-1.5.2-incubating",
        "Component/s": "POS Tagger",
        "Assignee": "J\u00f6rn Kottmann",
        "Reporter": "J\u00f6rn Kottmann",
        "Created": "31/Aug/11 08:28",
        "Updated": "28/Sep/11 12:28",
        "Resolved": "28/Sep/11 12:28",
        "Description": "The test should be part of the existing POSDictionaryTest class.\nAnd should test the following:\n\nLoading an xml dict with the case sensitive flag works in both cases\nWhen writing the dictionary the tag is serialized correctly",
        "Issue Links": []
    },
    "OPENNLP-287": {
        "Key": "OPENNLP-287",
        "Summary": "Extend POS Tagger documentation with more information about the tag dictionary",
        "Type": "Improvement",
        "Status": "Open",
        "Priority": "Minor",
        "Resolution": "Unresolved",
        "Affects Version/s": "None",
        "Fix Version/s": "None",
        "Component/s": "Documentation,                                            POS Tagger",
        "Assignee": null,
        "Reporter": "J\u00f6rn Kottmann",
        "Created": "31/Aug/11 09:02",
        "Updated": "17/Apr/15 14:53",
        "Resolved": null,
        "Description": "Extend the POS Tagger tag dictionary section as described in the documentation.",
        "Issue Links": []
    },
    "OPENNLP-288": {
        "Key": "OPENNLP-288",
        "Summary": "Loading a tag dictionary in the old format does not work with case insensitive",
        "Type": "Bug",
        "Status": "Closed",
        "Priority": "Minor",
        "Resolution": "Fixed",
        "Affects Version/s": "None",
        "Fix Version/s": "tools-1.5.2-incubating",
        "Component/s": "POS Tagger",
        "Assignee": "J\u00f6rn Kottmann",
        "Reporter": "J\u00f6rn Kottmann",
        "Created": "31/Aug/11 09:12",
        "Updated": "28/Sep/11 11:37",
        "Resolved": "28/Sep/11 11:37",
        "Description": "When loading a tag dictionary with the case flag set to case insensitive, look ups fail if the tokens in the tag dict are not all lower case. \nTo fix this lower case all tokens when the flag is set to case insensitive.",
        "Issue Links": []
    },
    "OPENNLP-289": {
        "Key": "OPENNLP-289",
        "Summary": "TokenNameFinderEvaluatorTool and  ChunkerEvaluatorTool are not printing usage correctly",
        "Type": "Improvement",
        "Status": "Closed",
        "Priority": "Major",
        "Resolution": "Fixed",
        "Affects Version/s": "tools-1.5.2-incubating",
        "Fix Version/s": "tools-1.5.2-incubating",
        "Component/s": "Chunker,                                            Name Finder",
        "Assignee": "William Colen",
        "Reporter": "William Colen",
        "Created": "31/Aug/11 15:08",
        "Updated": "31/Aug/11 15:16",
        "Resolved": "31/Aug/11 15:16",
        "Description": "The optional command line argument -detailedF is missing from NameFinder and Chunker evaluators.",
        "Issue Links": []
    },
    "OPENNLP-290": {
        "Key": "OPENNLP-290",
        "Summary": "Eclipse demo project",
        "Type": "Improvement",
        "Status": "Closed",
        "Priority": "Minor",
        "Resolution": "Fixed",
        "Affects Version/s": "tools-1.5.1-incubating",
        "Fix Version/s": "None",
        "Component/s": "Documentation",
        "Assignee": null,
        "Reporter": "Erel Segal Halevi",
        "Created": "31/Aug/11 15:17",
        "Updated": "09/Mar/15 20:44",
        "Resolved": "31/Aug/11 15:17",
        "Description": "I have created an Eclipse project with simple demo programs, based on the documentation: http://incubator.apache.org/opennlp/documentation.html\nAs a new user, I think such project can be of great help.",
        "Issue Links": []
    },
    "OPENNLP-291": {
        "Key": "OPENNLP-291",
        "Summary": "DetailedF listener not working for TokenNameFinder",
        "Type": "Improvement",
        "Status": "Closed",
        "Priority": "Major",
        "Resolution": "Fixed",
        "Affects Version/s": "tools-1.5.2-incubating",
        "Fix Version/s": "tools-1.5.2-incubating",
        "Component/s": "Name Finder",
        "Assignee": "William Colen",
        "Reporter": "William Colen",
        "Created": "31/Aug/11 17:19",
        "Updated": "31/Aug/11 17:30",
        "Resolved": "31/Aug/11 17:30",
        "Description": "Wrong hierarchy for TokenNameFinderDetailedFMeasureListener causes a runtime exception.",
        "Issue Links": []
    },
    "OPENNLP-292": {
        "Key": "OPENNLP-292",
        "Summary": "Remove CL argument specifying if abbreviation dictionary is case sensitive from SentenceDetector and Tokenizer training tools",
        "Type": "Improvement",
        "Status": "Closed",
        "Priority": "Major",
        "Resolution": "Fixed",
        "Affects Version/s": "tools-1.5.2-incubating",
        "Fix Version/s": "tools-1.5.2-incubating",
        "Component/s": "Sentence Detector,                                            Tokenizer",
        "Assignee": "William Colen",
        "Reporter": "William Colen",
        "Created": "01/Sep/11 03:34",
        "Updated": "01/Sep/11 20:27",
        "Resolved": "01/Sep/11 20:27",
        "Description": "It is not possible to change the case sensitivity while loading a tool anymore. We should remove the argument from parameters.",
        "Issue Links": []
    },
    "OPENNLP-293": {
        "Key": "OPENNLP-293",
        "Summary": "Deprecate Dictionary constructor that takes InputStream and case sensitivity as argument",
        "Type": "Improvement",
        "Status": "Closed",
        "Priority": "Minor",
        "Resolution": "Fixed",
        "Affects Version/s": "tools-1.5.2-incubating",
        "Fix Version/s": "tools-1.5.2-incubating",
        "Component/s": "None",
        "Assignee": "William Colen",
        "Reporter": "William Colen",
        "Created": "01/Sep/11 03:39",
        "Updated": "01/Sep/11 21:16",
        "Resolved": "01/Sep/11 21:16",
        "Description": "Now the dictionary case sensitivity is determined during its creation. Using the Dictionary constructor that sets the case sensitivity has no effects. We should document it and mark the constructor as deprecated.",
        "Issue Links": []
    },
    "OPENNLP-294": {
        "Key": "OPENNLP-294",
        "Summary": "Name Finder Evaluator does not clear adaptive data",
        "Type": "Bug",
        "Status": "Closed",
        "Priority": "Major",
        "Resolution": "Fixed",
        "Affects Version/s": "None",
        "Fix Version/s": "tools-1.5.2-incubating",
        "Component/s": "Name Finder",
        "Assignee": "J\u00f6rn Kottmann",
        "Reporter": "J\u00f6rn Kottmann",
        "Created": "02/Sep/11 08:30",
        "Updated": "30/Sep/11 14:09",
        "Resolved": "30/Sep/11 14:09",
        "Description": "The name finder evaluator does not clear the adaptive data when the clear adaptive data flag is set on the input name sample.",
        "Issue Links": []
    },
    "OPENNLP-295": {
        "Key": "OPENNLP-295",
        "Summary": "Sentence Detectors sent span array and probability array does not match",
        "Type": "Bug",
        "Status": "Closed",
        "Priority": "Minor",
        "Resolution": "Fixed",
        "Affects Version/s": "tools-1.5.1-incubating",
        "Fix Version/s": "tools-1.5.2-incubating",
        "Component/s": "Sentence Detector",
        "Assignee": "J\u00f6rn Kottmann",
        "Reporter": "J\u00f6rn Kottmann",
        "Created": "08/Sep/11 09:10",
        "Updated": "08/Sep/11 09:17",
        "Resolved": "08/Sep/11 09:17",
        "Description": "In the case that the input sentence does not contain and end of sentence character the input text is returned. In this case the returned probability array is just empty.\nTo fix this return a probability of one.",
        "Issue Links": []
    },
    "OPENNLP-296": {
        "Key": "OPENNLP-296",
        "Summary": "SentenceDetectorEvaluator example broken",
        "Type": "Bug",
        "Status": "Closed",
        "Priority": "Trivial",
        "Resolution": "Duplicate",
        "Affects Version/s": "tools-1.5.0-sourceforge,                                            tools-1.5.1-incubating",
        "Fix Version/s": "None",
        "Component/s": "Command Line Interface,                                            Documentation,                                            Sentence Detector",
        "Assignee": null,
        "Reporter": "Florian Salbrechter",
        "Created": "21/Sep/11 13:09",
        "Updated": "22/Sep/11 09:25",
        "Resolved": "22/Sep/11 09:21",
        "Description": "I tried to execute the SentenceDetectorEvaluator as described in:\nhttp://incubator.apache.org/opennlp/documentation/manual/opennlp.html#tools.sentdetect.eval.tool\nwith\nbin/opennlp SentenceDetectorEvaluator -encoding UTF-8 -model en-sent.bin -data en-sent.eval\nbut I always got the following message:\n\"Usage: opennlp SentenceDetectorEvaluator -encoding charset -model model -data testData\"\nI looked up the source (SentenceDetectorEvaluatorTool.java) and I think I found the problem:\nif (args.length != 4) {\n      System.out.println(getHelp());\n      throw new TerminateToolException(1);\n}\nThe argument count check is wrong...should be 6!\nFlo",
        "Issue Links": []
    },
    "OPENNLP-297": {
        "Key": "OPENNLP-297",
        "Summary": "Add more descriptive documentation on the Span class",
        "Type": "Improvement",
        "Status": "Closed",
        "Priority": "Trivial",
        "Resolution": "Fixed",
        "Affects Version/s": "None",
        "Fix Version/s": "tools-1.5.2-incubating",
        "Component/s": "None",
        "Assignee": "James Kosin",
        "Reporter": "James Kosin",
        "Created": "23/Sep/11 00:51",
        "Updated": "28/Sep/11 09:21",
        "Resolved": "28/Sep/11 09:21",
        "Description": "The Span class does not detail that the end of the Span reported is actually the index past the end of the span and not considered part of the span itself.\nThis JIRA hopes to better document and remove some ambiguities in the interface.",
        "Issue Links": []
    },
    "OPENNLP-298": {
        "Key": "OPENNLP-298",
        "Summary": "Span.contains(index) reports a value equal to end as being part of the span.",
        "Type": "Bug",
        "Status": "Closed",
        "Priority": "Minor",
        "Resolution": "Fixed",
        "Affects Version/s": "None",
        "Fix Version/s": "tools-1.5.2-incubating",
        "Component/s": "None",
        "Assignee": "James Kosin",
        "Reporter": "James Kosin",
        "Created": "23/Sep/11 01:01",
        "Updated": "23/Sep/11 01:54",
        "Resolved": "23/Sep/11 01:53",
        "Description": "An index passed into contains() method with a value equal to getEnd() returns true when the actual index should return false.",
        "Issue Links": []
    },
    "OPENNLP-299": {
        "Key": "OPENNLP-299",
        "Summary": "Index mapping file should be configurable per corpus",
        "Type": "Improvement",
        "Status": "Closed",
        "Priority": "Minor",
        "Resolution": "Fixed",
        "Affects Version/s": "None",
        "Fix Version/s": "None",
        "Component/s": "Corpus Server",
        "Assignee": "J\u00f6rn Kottmann",
        "Reporter": "J\u00f6rn Kottmann",
        "Created": "26/Sep/11 10:56",
        "Updated": "27/Sep/11 17:09",
        "Resolved": "27/Sep/11 17:09",
        "Description": "The Corpus Server currently has a \"hard-coded\" index mapping file. The index mapping should be done per corpus, because it depends on the type system and that is also defined per corpus.",
        "Issue Links": []
    },
    "OPENNLP-300": {
        "Key": "OPENNLP-300",
        "Summary": "Enhance Cas Import tool to import a directory of xmi files",
        "Type": "Improvement",
        "Status": "Closed",
        "Priority": "Minor",
        "Resolution": "Fixed",
        "Affects Version/s": "None",
        "Fix Version/s": "None",
        "Component/s": "Corpus Server",
        "Assignee": "J\u00f6rn Kottmann",
        "Reporter": "J\u00f6rn Kottmann",
        "Created": "26/Sep/11 11:41",
        "Updated": "26/Sep/11 11:50",
        "Resolved": "26/Sep/11 11:50",
        "Description": "The Cas Impoter tool can currently only import a single xmi file. It should be capable of importing all xmi files in a directory.",
        "Issue Links": []
    },
    "OPENNLP-301": {
        "Key": "OPENNLP-301",
        "Summary": "UIMA descriptors still use old IBM Watson name space",
        "Type": "Bug",
        "Status": "Closed",
        "Priority": "Minor",
        "Resolution": "Fixed",
        "Affects Version/s": "tools-1.5.1-incubating",
        "Fix Version/s": "tools-1.5.2-incubating",
        "Component/s": "UIMA Integration",
        "Assignee": "J\u00f6rn Kottmann",
        "Reporter": "J\u00f6rn Kottmann",
        "Created": "27/Sep/11 09:50",
        "Updated": "27/Sep/11 09:59",
        "Resolved": "27/Sep/11 09:59",
        "Description": "Replace all old name spaces in the UIMA descriptors with the new apache uima name space.",
        "Issue Links": []
    },
    "OPENNLP-302": {
        "Key": "OPENNLP-302",
        "Summary": "Cas Editor plugin jars do not include the OSGi manifest",
        "Type": "Bug",
        "Status": "Closed",
        "Priority": "Minor",
        "Resolution": "Fixed",
        "Affects Version/s": "None",
        "Fix Version/s": "None",
        "Component/s": "Cas Editor Corpus Server Plugin,                                            Cas Editor OpenNLP Plugin",
        "Assignee": "J\u00f6rn Kottmann",
        "Reporter": "J\u00f6rn Kottmann",
        "Created": "27/Sep/11 15:11",
        "Updated": "27/Sep/11 15:17",
        "Resolved": "27/Sep/11 15:17",
        "Description": "Fix the build to incldue the generated OSGi MANIFEST.MF file.",
        "Issue Links": []
    },
    "OPENNLP-303": {
        "Key": "OPENNLP-303",
        "Summary": "Name finder should use token annoations from CAS instead of Simple Tokenizer",
        "Type": "Improvement",
        "Status": "Closed",
        "Priority": "Major",
        "Resolution": "Fixed",
        "Affects Version/s": "None",
        "Fix Version/s": "None",
        "Component/s": "Cas Editor OpenNLP Plugin",
        "Assignee": "J\u00f6rn Kottmann",
        "Reporter": "J\u00f6rn Kottmann",
        "Created": "29/Sep/11 11:07",
        "Updated": "13/Oct/11 12:27",
        "Resolved": "13/Oct/11 12:27",
        "Description": "The name finder currently uses the Simple Tokenizer to split a sentence into its tokens. This does not work in many cases, because the tokenization must be done differently.\nTo fix this, the name finder plugin should use the token annotations which are in the CAS.",
        "Issue Links": []
    },
    "OPENNLP-304": {
        "Key": "OPENNLP-304",
        "Summary": "Add a privacy policy to our website",
        "Type": "Improvement",
        "Status": "Closed",
        "Priority": "Major",
        "Resolution": "Fixed",
        "Affects Version/s": "None",
        "Fix Version/s": "None",
        "Component/s": "Website",
        "Assignee": "James Kosin",
        "Reporter": "J\u00f6rn Kottmann",
        "Created": "29/Sep/11 13:13",
        "Updated": "21/Apr/12 03:21",
        "Resolved": "21/Apr/12 03:19",
        "Description": "The website should have a privacy policy. As far as I know all http requests to it are logged.",
        "Issue Links": []
    },
    "OPENNLP-305": {
        "Key": "OPENNLP-305",
        "Summary": "Update leipzig format parsing code to work with their latest release",
        "Type": "Bug",
        "Status": "Closed",
        "Priority": "Major",
        "Resolution": "Fixed",
        "Affects Version/s": "None",
        "Fix Version/s": "tools-1.5.2-incubating",
        "Component/s": "Doccat",
        "Assignee": "J\u00f6rn Kottmann",
        "Reporter": "J\u00f6rn Kottmann",
        "Created": "30/Sep/11 11:09",
        "Updated": "31/Oct/11 23:49",
        "Resolved": "31/Oct/11 23:49",
        "Description": "The Leipzig project added more content and changed the encoding and language codes. The leipzig parser code should always assume the content is encoded in UTF-8 and do not place a restriction on the language code which is used as a category.",
        "Issue Links": []
    },
    "OPENNLP-306": {
        "Key": "OPENNLP-306",
        "Summary": "Language code for Swedish is wrong on the models download page (should be sv, not se)",
        "Type": "Bug",
        "Status": "Closed",
        "Priority": "Minor",
        "Resolution": "Won't Fix",
        "Affects Version/s": "None",
        "Fix Version/s": "None",
        "Component/s": "Website",
        "Assignee": "J\u00f6rn Kottmann",
        "Reporter": "Magnus Melin",
        "Created": "30/Sep/11 11:16",
        "Updated": "08/Sep/15 14:06",
        "Resolved": "08/Sep/15 14:06",
        "Description": "On the models download page -  http://opennlp.sourceforge.net/models-1.5/ the language code for Swedish is wrong. \n(Also the file names are equally wrongly named.)\nThe language code for Swedish is sv and nothing else. http://en.wikipedia.org/wiki/List_of_ISO_639-1_codes",
        "Issue Links": []
    },
    "OPENNLP-307": {
        "Key": "OPENNLP-307",
        "Summary": "UIMA Tokenizer Trainer should have support for an additional training data file",
        "Type": "Improvement",
        "Status": "Closed",
        "Priority": "Minor",
        "Resolution": "Fixed",
        "Affects Version/s": "None",
        "Fix Version/s": "tools-1.5.2-incubating",
        "Component/s": "UIMA Integration",
        "Assignee": "J\u00f6rn Kottmann",
        "Reporter": "J\u00f6rn Kottmann",
        "Created": "30/Sep/11 11:22",
        "Updated": "31/Oct/11 23:49",
        "Resolved": "31/Oct/11 23:49",
        "Description": "Currently the Tokenizer Trainer can only be trained with CASes. It should have support to load an additional training file in the OpenNLP tokenizer training format to complement the data in the CAS.",
        "Issue Links": []
    },
    "OPENNLP-308": {
        "Key": "OPENNLP-308",
        "Summary": "Update version in UIMA sample descriptors",
        "Type": "Task",
        "Status": "Closed",
        "Priority": "Minor",
        "Resolution": "Fixed",
        "Affects Version/s": "None",
        "Fix Version/s": "tools-1.5.2-incubating",
        "Component/s": "UIMA Integration",
        "Assignee": "J\u00f6rn Kottmann",
        "Reporter": "J\u00f6rn Kottmann",
        "Created": "30/Sep/11 11:30",
        "Updated": "06/Oct/11 18:05",
        "Resolved": "06/Oct/11 18:05",
        "Description": "All versions in the sample descriptors should be updated to 1.5.2-incubating.",
        "Issue Links": []
    },
    "OPENNLP-309": {
        "Key": "OPENNLP-309",
        "Summary": "facilitating the specialization of POSDictionary",
        "Type": "Improvement",
        "Status": "Closed",
        "Priority": "Minor",
        "Resolution": "Fixed",
        "Affects Version/s": "None",
        "Fix Version/s": "1.6.0",
        "Component/s": "POS Tagger",
        "Assignee": "William Colen",
        "Reporter": "Riccardo Tasso",
        "Created": "04/Oct/11 09:46",
        "Updated": "21/Oct/14 22:48",
        "Resolved": "13/Mar/14 14:58",
        "Description": "The train method in POSTaggerME receives in input a POSDictionary. This makes the implementation of custom dictionaries painful.\nI suggest to replace the POSDictionary input as a TagDictionary.\nAnother improvement may also be the declaration of POSDictionary fields as protected, to help the extension of this class.",
        "Issue Links": []
    },
    "OPENNLP-310": {
        "Key": "OPENNLP-310",
        "Summary": "Bind preference to a type system",
        "Type": "Improvement",
        "Status": "Closed",
        "Priority": "Major",
        "Resolution": "Fixed",
        "Affects Version/s": "None",
        "Fix Version/s": "None",
        "Component/s": "Cas Editor OpenNLP Plugin",
        "Assignee": "J\u00f6rn Kottmann",
        "Reporter": "J\u00f6rn Kottmann",
        "Created": "05/Oct/11 18:26",
        "Updated": "13/Oct/11 13:56",
        "Resolved": "13/Oct/11 13:56",
        "Description": "Currently all preferences are global, but many of these preferences are only valid for the current type system.\nTo improve this save all of these type system dependent preferences in a type system scope.\nThis issue is blocked by UIMA-2245.",
        "Issue Links": [
            "/jira/browse/UIMA-2245"
        ]
    },
    "OPENNLP-311": {
        "Key": "OPENNLP-311",
        "Summary": "Add support to load a model from a web server via http",
        "Type": "Improvement",
        "Status": "Closed",
        "Priority": "Major",
        "Resolution": "Fixed",
        "Affects Version/s": "None",
        "Fix Version/s": "None",
        "Component/s": "Cas Editor OpenNLP Plugin",
        "Assignee": "J\u00f6rn Kottmann",
        "Reporter": "J\u00f6rn Kottmann",
        "Created": "05/Oct/11 18:27",
        "Updated": "01/Nov/11 14:30",
        "Resolved": "01/Nov/11 14:30",
        "Description": "An OpenNLP model must currently be placed in a file in the workspace. It should additionally be possible\nto load a model via http from a web server.",
        "Issue Links": []
    },
    "OPENNLP-312": {
        "Key": "OPENNLP-312",
        "Summary": "Remove confirmed names from name finder view",
        "Type": "Improvement",
        "Status": "Closed",
        "Priority": "Major",
        "Resolution": "Fixed",
        "Affects Version/s": "None",
        "Fix Version/s": "None",
        "Component/s": "Cas Editor OpenNLP Plugin",
        "Assignee": "J\u00f6rn Kottmann",
        "Reporter": "J\u00f6rn Kottmann",
        "Created": "05/Oct/11 18:28",
        "Updated": "13/Oct/11 08:48",
        "Resolved": "13/Oct/11 08:48",
        "Description": "When a user confirms a new the name finder running in the background is sometimes able to find more names,\nthe user now needs to scan through the entire list again to determine if there is a new annotation between already\nconfirmed annotation. To ease up this process the name finder view should only contain name suggestions.\nThe already confirmed names are already listed in the editor outline.",
        "Issue Links": []
    },
    "OPENNLP-313": {
        "Key": "OPENNLP-313",
        "Summary": "Add a view to assist with tokenization",
        "Type": "Improvement",
        "Status": "Closed",
        "Priority": "Major",
        "Resolution": "Won't Fix",
        "Affects Version/s": "None",
        "Fix Version/s": "None",
        "Component/s": "Cas Editor OpenNLP Plugin",
        "Assignee": null,
        "Reporter": "J\u00f6rn Kottmann",
        "Created": "05/Oct/11 18:29",
        "Updated": "16/Jan/17 14:28",
        "Resolved": "16/Jan/17 14:28",
        "Description": "The CasEditor OpenNLP plugin should have a view for the tokenizer to assit a user with tokenizing a text.",
        "Issue Links": []
    },
    "OPENNLP-314": {
        "Key": "OPENNLP-314",
        "Summary": "Update eclipse plugins to UIMA version 2.4.0-SNAPSHOT",
        "Type": "Task",
        "Status": "Closed",
        "Priority": "Minor",
        "Resolution": "Fixed",
        "Affects Version/s": "None",
        "Fix Version/s": "None",
        "Component/s": "Cas Editor Corpus Server Plugin,                                            Cas Editor OpenNLP Plugin",
        "Assignee": "J\u00f6rn Kottmann",
        "Reporter": "J\u00f6rn Kottmann",
        "Created": "06/Oct/11 12:13",
        "Updated": "10/Oct/11 12:03",
        "Resolved": "10/Oct/11 12:03",
        "Description": "Update the UIMA dependencies for both eclipse plugin to version 2.4.0-SNAPSHOT.",
        "Issue Links": []
    },
    "OPENNLP-315": {
        "Key": "OPENNLP-315",
        "Summary": "Invalid (or non) configuration leads to various exceptions in the Name Finder and Sentence Detector view",
        "Type": "Bug",
        "Status": "Closed",
        "Priority": "Major",
        "Resolution": "Fixed",
        "Affects Version/s": "None",
        "Fix Version/s": "None",
        "Component/s": "Cas Editor OpenNLP Plugin",
        "Assignee": "J\u00f6rn Kottmann",
        "Reporter": "J\u00f6rn Kottmann",
        "Created": "06/Oct/11 13:49",
        "Updated": "13/Oct/11 13:56",
        "Resolved": "13/Oct/11 13:56",
        "Description": "If some aspect of the configuration is incorrect the Name Finder and Sentence Detector view just start throwing exceptions in the background.\nIn the case the configuration is invalid or the view it not configured at all it should show a meaningful error messages explaining the issue.",
        "Issue Links": []
    },
    "OPENNLP-316": {
        "Key": "OPENNLP-316",
        "Summary": "Evaluator and CrossValidator programs of the main analyzers throw exceptions",
        "Type": "Bug",
        "Status": "Closed",
        "Priority": "Major",
        "Resolution": "Fixed",
        "Affects Version/s": "tools-1.5.2-incubating",
        "Fix Version/s": "tools-1.5.2-incubating",
        "Component/s": "Chunker,                                            POS Tagger,                                            Sentence Detector,                                            Tokenizer",
        "Assignee": "William Colen",
        "Reporter": "Nicolas Hernandez",
        "Created": "06/Oct/11 15:46",
        "Updated": "11/Oct/11 12:20",
        "Resolved": "11/Oct/11 09:59",
        "Description": "Evaluator and CrossValidator programs of the main analyzers throw an exception when running\n(test performed on the 1.5.3 dist via command line)\nIt seems that the SentenceDetector, Tokenizer, PosTagger and the\nchunker (at least) throw a java.lang.NullPointerException if the\nmisclassified parameter is set to false or not present for the\nEvaluator programs. \nThe Evaluator programs works (provide a result) when the\nmisclassified parameter is set.\nThe CrossValidator programs do not work at all.\nI have not test the other opennlp programs.\nSee below some example of the runs.\nI tested on the examples from the documentation and also with my data. \nFor the SentenceDetector I tested with with 1 000 and 1 000 000 sentences per line.\nTell if you want more details or anything\n$opennlp SentenceDetectorEvaluator -encoding UTF-8 -model\ndata/model/fr-sent.bin -data data/test/fr-sent.test\nLoading Sentence Detector model ... done (0,013s)\nEvaluating ...  in thread \"main\" java.lang.NullPointerException\n       at opennlp.tools.util.eval.Evaluator.evaluateSample(Evaluator.java:80)\n       at opennlp.tools.util.eval.Evaluator.evaluate(Evaluator.java:98)\n       at opennlp.tools.cmdline.sentdetect.SentenceDetectorEvaluatorTool.run(SentenceDetectorEvaluatorTool.java:80)\n       at opennlp.tools.cmdline.CLI.main(CLI.java:191)\n$opennlp SentenceDetectorCrossValidator -encoding UTF-8 -lang fr -data\ndata/train/fr-sent.train -misclassified true\nIndexing events using cutoff of 5\n       Computing event counts...  done. 0 events\n       Indexing...  done.\nSorting and merging events... Done indexing.\nIncorporating indexed data for training...\nException in thread \"main\" java.lang.NullPointerException\n       at opennlp.maxent.GISTrainer.trainModel(GISTrainer.java:263)\n       at opennlp.maxent.GIS.trainModel(GIS.java:256)\n       at opennlp.model.TrainUtil.train(TrainUtil.java:182)\n       at opennlp.tools.sentdetect.SentenceDetectorME.train(SentenceDetectorME.java:283)\n       at opennlp.tools.sentdetect.SDCrossValidator.evaluate(SDCrossValidator.java:104)\n       at opennlp.tools.cmdline.sentdetect.SentenceDetectorCrossValidatorTool.run(SentenceDetectorCrossValidatorTool.java:98)\n       at opennlp.tools.cmdline.CLI.main(CLI.java:191)\n$ opennlp TokenizerMEEvaluator -encoding UTF-8 -model\ndata/model/fr-token.bin -data data/test/fr-token.test\nLoading Tokenizer model ... done (0,428s)\nEvaluating ... Exception in thread \"main\" java.lang.NullPointerException\n       at opennlp.tools.util.eval.Evaluator.evaluateSample(Evaluator.java:76)\n       at opennlp.tools.util.eval.Evaluator.evaluate(Evaluator.java:98)\n       at opennlp.tools.cmdline.tokenizer.TokenizerMEEvaluatorTool.run(TokenizerMEEvaluatorTool.java:81)\n       at opennlp.tools.cmdline.CLI.main(CLI.java:191)\n$ opennlp TokenizerCrossValidator -encoding UTF-8 -lang fr -data\ndata/train/fr-token.train\nIndexing events using cutoff of 5\n       Computing event counts...  done. 100333 events\n       Indexing...  done.\nSorting and merging events... done. Reduced 100333 events to 30168.\nDone indexing.\nIncorporating indexed data for training...\ndone.\n       Number of Event Tokens: 30168\n           Number of Outcomes: 2\n         Number of Predicates: 8287\n...done.\nComputing model parameters ...\nPerforming 100 iterations.\n 1:  ... loglikelihood=-69545.53606709359      0.9337805108987073\n 2:  ... loglikelihood=-18987.123809719425     0.9497872085953774\n...\n 98:  ... loglikelihood=-607.4216932752298      0.9989534848952987\n 99:  ... loglikelihood=-603.2346954947699      0.9989734185163406\n100:  ... loglikelihood=-599.1235213848983      0.9989833853268616\nException in thread \"main\" java.lang.NullPointerException\n       at opennlp.tools.util.eval.Evaluator.evaluateSample(Evaluator.java:76)\n       at opennlp.tools.util.eval.Evaluator.evaluate(Evaluator.java:98)\n       at opennlp.tools.tokenize.TokenizerCrossValidator.evaluate(TokenizerCrossValidator.java:98)\n       at opennlp.tools.cmdline.tokenizer.TokenizerCrossValidatorTool.run(TokenizerCrossValidatorTool.java:94)",
        "Issue Links": []
    },
    "OPENNLP-317": {
        "Key": "OPENNLP-317",
        "Summary": "opennlp.uima.Chunk feature name \"type\" not allowed",
        "Type": "Bug",
        "Status": "Closed",
        "Priority": "Minor",
        "Resolution": "Fixed",
        "Affects Version/s": "None",
        "Fix Version/s": "tools-1.5.2-incubating",
        "Component/s": "UIMA Integration",
        "Assignee": "J\u00f6rn Kottmann",
        "Reporter": "Jens Grivolla",
        "Created": "06/Oct/11 16:24",
        "Updated": "06/Oct/11 18:02",
        "Resolved": "06/Oct/11 18:02",
        "Description": "JCasGen complains when compiling the provided example type system: The feature name 'type' is reserved. Rename to chunkType?",
        "Issue Links": []
    },
    "OPENNLP-318": {
        "Key": "OPENNLP-318",
        "Summary": "Build of the UIMA Integration needs to inject version number",
        "Type": "Improvement",
        "Status": "Closed",
        "Priority": "Minor",
        "Resolution": "Fixed",
        "Affects Version/s": "None",
        "Fix Version/s": "tools-1.5.3",
        "Component/s": "UIMA Integration",
        "Assignee": "J\u00f6rn Kottmann",
        "Reporter": "J\u00f6rn Kottmann",
        "Created": "06/Oct/11 18:08",
        "Updated": "15/Nov/11 23:24",
        "Resolved": "15/Nov/11 23:24",
        "Description": "Currently the version numbers in the descriptors need to be manually updated. To improve this the build should inject the current version number into the xml descriptors.",
        "Issue Links": []
    },
    "OPENNLP-319": {
        "Key": "OPENNLP-319",
        "Summary": "Refactor name finder preference page to make it easy to use",
        "Type": "Improvement",
        "Status": "Closed",
        "Priority": "Major",
        "Resolution": "Fixed",
        "Affects Version/s": "None",
        "Fix Version/s": "None",
        "Component/s": "Cas Editor OpenNLP Plugin",
        "Assignee": "J\u00f6rn Kottmann",
        "Reporter": "J\u00f6rn Kottmann",
        "Created": "06/Oct/11 21:31",
        "Updated": "16/Jan/12 11:40",
        "Resolved": "16/Jan/12 11:40",
        "Description": "Currently the Name Finder Preference Page has a few text fields to configure them. This should be improved with better and more advanced controls, error handling also needs to be added.",
        "Issue Links": []
    },
    "OPENNLP-320": {
        "Key": "OPENNLP-320",
        "Summary": "Name Finder recall boosting should not force stop words to be names",
        "Type": "Improvement",
        "Status": "Closed",
        "Priority": "Minor",
        "Resolution": "Won't Fix",
        "Affects Version/s": "None",
        "Fix Version/s": "None",
        "Component/s": "Cas Editor OpenNLP Plugin",
        "Assignee": null,
        "Reporter": "J\u00f6rn Kottmann",
        "Created": "10/Oct/11 00:15",
        "Updated": "16/Jan/17 14:30",
        "Resolved": "16/Jan/17 14:30",
        "Description": "The Name Finder which is used by the Name Finder View is boosted to detect almost all \"confirmed\" entity tokens as names. It should be possible to define a stop word dictionary which contains tokens which should not be \"boosted\".",
        "Issue Links": []
    },
    "OPENNLP-321": {
        "Key": "OPENNLP-321",
        "Summary": "Type system preferences should be stored locally",
        "Type": "Bug",
        "Status": "Closed",
        "Priority": "Major",
        "Resolution": "Fixed",
        "Affects Version/s": "None",
        "Fix Version/s": "None",
        "Component/s": "Cas Editor Corpus Server Plugin",
        "Assignee": "J\u00f6rn Kottmann",
        "Reporter": "J\u00f6rn Kottmann",
        "Created": "10/Oct/11 14:40",
        "Updated": "10/Oct/11 14:41",
        "Resolved": "10/Oct/11 14:41",
        "Description": "The type system scoped preferences of the Cas Editor need to be persistently stored locally, and not in-memory only.",
        "Issue Links": []
    },
    "OPENNLP-322": {
        "Key": "OPENNLP-322",
        "Summary": "remove dependencies from relevance component",
        "Type": "Bug",
        "Status": "Closed",
        "Priority": "Major",
        "Resolution": "Fixed",
        "Affects Version/s": "None",
        "Fix Version/s": "None",
        "Component/s": "Similarity",
        "Assignee": "Boris Galitsky",
        "Reporter": "Boris Galitsky",
        "Created": "11/Oct/11 19:27",
        "Updated": "15/Nov/11 08:57",
        "Resolved": "24/Oct/11 19:30",
        "Description": "remove spring, make compatible with 1.5.2",
        "Issue Links": []
    },
    "OPENNLP-323": {
        "Key": "OPENNLP-323",
        "Summary": "change syntactic generalization algorithm for relevance component to take chunking results from OpenNLP 1.5.2",
        "Type": "Bug",
        "Status": "Closed",
        "Priority": "Major",
        "Resolution": "Fixed",
        "Affects Version/s": "None",
        "Fix Version/s": "None",
        "Component/s": "Similarity",
        "Assignee": "Boris Galitsky",
        "Reporter": "Boris Galitsky",
        "Created": "11/Oct/11 19:31",
        "Updated": "15/Nov/11 08:58",
        "Resolved": "25/Oct/11 17:32",
        "Description": "Change algorithm to get chunking results and then match them for each phrase type separately",
        "Issue Links": []
    },
    "OPENNLP-324": {
        "Key": "OPENNLP-324",
        "Summary": "Name Finder should only boost terms where the first letter is upper case",
        "Type": "Improvement",
        "Status": "Closed",
        "Priority": "Major",
        "Resolution": "Fixed",
        "Affects Version/s": "None",
        "Fix Version/s": "None",
        "Component/s": "Cas Editor OpenNLP Plugin",
        "Assignee": "J\u00f6rn Kottmann",
        "Reporter": "J\u00f6rn Kottmann",
        "Created": "13/Oct/11 14:12",
        "Updated": "06/Dec/11 13:34",
        "Resolved": "06/Dec/11 13:34",
        "Description": "The name finder should only boost terms where the first letter is upper case. This feature should be enabled by default, but an option to disable it is needed, because it might not work well for every user, depending on the entity type and language.",
        "Issue Links": []
    },
    "OPENNLP-325": {
        "Key": "OPENNLP-325",
        "Summary": "Name finder should implement a strategy to eliminate overlapping names",
        "Type": "Improvement",
        "Status": "Closed",
        "Priority": "Minor",
        "Resolution": "Won't Fix",
        "Affects Version/s": "None",
        "Fix Version/s": "None",
        "Component/s": "Cas Editor OpenNLP Plugin",
        "Assignee": null,
        "Reporter": "J\u00f6rn Kottmann",
        "Created": "13/Oct/11 14:22",
        "Updated": "16/Jan/17 14:29",
        "Resolved": "16/Jan/17 14:29",
        "Description": "The name finder currently outputs overlapping name annotations. The user has to choose which one he wants to confirm.\nThere should be an option that the name finder eliminates overlapping name annotations, and only offers one name candidate.",
        "Issue Links": []
    },
    "OPENNLP-326": {
        "Key": "OPENNLP-326",
        "Summary": "Sentence detector should support a list of paragraph annotation",
        "Type": "Improvement",
        "Status": "Closed",
        "Priority": "Minor",
        "Resolution": "Fixed",
        "Affects Version/s": "None",
        "Fix Version/s": "None",
        "Component/s": "Cas Editor OpenNLP Plugin",
        "Assignee": "J\u00f6rn Kottmann",
        "Reporter": "J\u00f6rn Kottmann",
        "Created": "13/Oct/11 14:26",
        "Updated": "17/Oct/11 13:37",
        "Resolved": "17/Oct/11 13:37",
        "Description": "The sentence detector currently only supports a single paragraph annotation, this should be extended to multiple paragraph annotation.\nFor example there could be a paragraph annotation and a lead annotation.",
        "Issue Links": []
    },
    "OPENNLP-327": {
        "Key": "OPENNLP-327",
        "Summary": "Doccats bag of word feature generator should not use numbers as features",
        "Type": "Improvement",
        "Status": "Open",
        "Priority": "Minor",
        "Resolution": "Unresolved",
        "Affects Version/s": "None",
        "Fix Version/s": "None",
        "Component/s": "Doccat",
        "Assignee": "J\u00f6rn Kottmann",
        "Reporter": "J\u00f6rn Kottmann",
        "Created": "17/Oct/11 08:48",
        "Updated": "20/May/16 12:37",
        "Resolved": null,
        "Description": "It turned out that Doccats bag of word feature generator can be very sensitive to numbers when used for language identification. Therefore numbers should not be included in the bag of words.",
        "Issue Links": []
    },
    "OPENNLP-328": {
        "Key": "OPENNLP-328",
        "Summary": "Sentence Detector should not suggest sentences which exist already in the CAS",
        "Type": "Improvement",
        "Status": "Closed",
        "Priority": "Major",
        "Resolution": "Fixed",
        "Affects Version/s": "None",
        "Fix Version/s": "None",
        "Component/s": "Cas Editor OpenNLP Plugin",
        "Assignee": "J\u00f6rn Kottmann",
        "Reporter": "J\u00f6rn Kottmann",
        "Created": "17/Oct/11 13:45",
        "Updated": "06/Dec/11 13:37",
        "Resolved": "06/Dec/11 13:37",
        "Description": "The sentence detector should not suggest sentences which exist already in the CAS. This should be implemented similar to the name finder view.",
        "Issue Links": []
    },
    "OPENNLP-329": {
        "Key": "OPENNLP-329",
        "Summary": "Converter Issue with output redirection",
        "Type": "Bug",
        "Status": "Closed",
        "Priority": "Major",
        "Resolution": "Fixed",
        "Affects Version/s": "None",
        "Fix Version/s": "None",
        "Component/s": "Command Line Interface",
        "Assignee": "James Kosin",
        "Reporter": "James Kosin",
        "Created": "18/Oct/11 00:27",
        "Updated": "15/Nov/11 08:59",
        "Resolved": "18/Oct/11 02:44",
        "Description": "Output from the converters and scripts can get mixed in with converted text output causing training and validation issues.\nJust need to verify and comment the script files and possibly outputters for the converters to be sure no unwanted text is output to the System.out path.",
        "Issue Links": []
    },
    "OPENNLP-330": {
        "Key": "OPENNLP-330",
        "Summary": "Fix junit tests so that they work with new chunking algo and data structure of OpenNLP 1.5",
        "Type": "Bug",
        "Status": "Closed",
        "Priority": "Major",
        "Resolution": "Fixed",
        "Affects Version/s": "None",
        "Fix Version/s": "None",
        "Component/s": "Similarity",
        "Assignee": "Boris Galitsky",
        "Reporter": "Boris Galitsky",
        "Created": "20/Oct/11 21:18",
        "Updated": "06/Jan/14 17:28",
        "Resolved": "06/Jan/14 17:11",
        "Description": null,
        "Issue Links": []
    },
    "OPENNLP-331": {
        "Key": "OPENNLP-331",
        "Summary": "disagreement between POS of parser and POStagger",
        "Type": "Bug",
        "Status": "Closed",
        "Priority": "Major",
        "Resolution": "Won't Fix",
        "Affects Version/s": "None",
        "Fix Version/s": "None",
        "Component/s": "Similarity",
        "Assignee": "Boris Galitsky",
        "Reporter": "Boris Galitsky",
        "Created": "21/Oct/11 22:21",
        "Updated": "03/Jan/17 10:17",
        "Resolved": "03/Jan/17 10:17",
        "Description": "ParserTool.parseLine(sentence, parser, 1) gives:\nHow can I get short focus zoom lens for digital camera\ntype = S\n\ttype = WHADVP\n\t\ttype = WRB, word = How\n\ttype = SQ\n\t\ttype = MD, word = can\n\t\ttype = NP\n\t\t\ttype = PRP, word = I\n\t\ttype = VP\n\t\t\ttype = VB, word = get\n\t\t\ttype = NP\n\t\t\t\ttype = JJ, word = short\n\t\t\t\ttype = NN, word = focus\n\t\t\t\ttype = NN, word = zoom   // ZOOM is NOUN: correct\n\t\t\t\ttype = NN, word = lens\n\t\t\ttype = PP\n\t\t\t\ttype = IN, word = for\n\t\t\t\ttype = NP\n\t\t\t\t\ttype = JJ, word = digital\n\t\t\t\t\ttype = NN, word = camera\nBUT\nnew POSTaggerME(model).tag(toks);\n gives\n[WRB, MD, PRP, VB, JJ, NN, VBN, NN, IN, JJ, NN]\n                                        ****\n                     VBN is a problem!  \nzoom is NOT VBN - Verb, past participle",
        "Issue Links": []
    },
    "OPENNLP-332": {
        "Key": "OPENNLP-332",
        "Summary": "opennlp.tools.parser.Parse.equals doesn't guard against IndexOutOfBoundsException",
        "Type": "Bug",
        "Status": "Closed",
        "Priority": "Major",
        "Resolution": "Fixed",
        "Affects Version/s": "None",
        "Fix Version/s": "tools-1.5.2-incubating",
        "Component/s": "Parser",
        "Assignee": "J\u00f6rn Kottmann",
        "Reporter": "Ben Podgursky",
        "Created": "24/Oct/11 09:24",
        "Updated": "31/Oct/11 23:48",
        "Resolved": "31/Oct/11 23:48",
        "Description": "New to the project, and I'm running into a problem with the equals method on a Parse.  It seems like if the label, span, and text between two nodes are equivalent, it assumes the other Parse has at least as many parts as that one, and only checks until there (I think this is actually a correctness bug, since the other Parse could have additional parts.)",
        "Issue Links": []
    },
    "OPENNLP-333": {
        "Key": "OPENNLP-333",
        "Summary": "NameFinderME not working for single name at beginning of sentence",
        "Type": "Bug",
        "Status": "Closed",
        "Priority": "Major",
        "Resolution": "Not A Problem",
        "Affects Version/s": "tools-1.5.1-incubating",
        "Fix Version/s": "None",
        "Component/s": "Name Finder",
        "Assignee": null,
        "Reporter": "Josh Smith",
        "Created": "25/Oct/11 21:56",
        "Updated": "15/Nov/11 23:35",
        "Resolved": "15/Nov/11 23:35",
        "Description": "For sentences that begin with a single name (ie first/last name only), NameFinderME returns an empty array of Spans. If the second word is also part of the name, the Span is returned properly. If the sentence is reversed such that the name is last, the Span is returned correctly.\nFor example,\n\"John is my name\" -> []\n\"John Doe is my name\" -> [0..2]\n\"My name is John\" -> [3..4]",
        "Issue Links": []
    },
    "OPENNLP-334": {
        "Key": "OPENNLP-334",
        "Summary": "POSTagger cmd line trainers dict parameter has an invalid description",
        "Type": "Bug",
        "Status": "Closed",
        "Priority": "Minor",
        "Resolution": "Fixed",
        "Affects Version/s": "None",
        "Fix Version/s": "tools-1.5.2-incubating",
        "Component/s": "Command Line Interface,                                            POS Tagger",
        "Assignee": "J\u00f6rn Kottmann",
        "Reporter": "J\u00f6rn Kottmann",
        "Created": "28/Oct/11 14:04",
        "Updated": "01/Nov/11 08:36",
        "Resolved": "01/Nov/11 08:36",
        "Description": "The Command Line Trainer for the POSTagger has an invalid description for the dictionary parameter. It says \"The feature generator descriptor file\", but we expect a tag dict in the xml format to be passed here.",
        "Issue Links": []
    },
    "OPENNLP-335": {
        "Key": "OPENNLP-335",
        "Summary": "CoNLL 02 NameFinderConverter can not export all tag types",
        "Type": "Bug",
        "Status": "Closed",
        "Priority": "Major",
        "Resolution": "Fixed",
        "Affects Version/s": "tools-1.5.0-sourceforge,                                            tools-1.5.1-incubating,                                            tools-1.5.2-incubating",
        "Fix Version/s": "tools-1.5.2-incubating",
        "Component/s": "Name Finder",
        "Assignee": "James Kosin",
        "Reporter": "James Kosin",
        "Created": "29/Oct/11 12:42",
        "Updated": "29/Oct/11 15:16",
        "Resolved": "29/Oct/11 15:16",
        "Description": "The NameFinderConverter factory for the CoNLL 2002 data format does not support exporting a data set with all tag types.\nYou can only export based on one type only, person, misc, organization, or location.",
        "Issue Links": []
    },
    "OPENNLP-336": {
        "Key": "OPENNLP-336",
        "Summary": "Update OpenNLP version in RELEASE_NOTES",
        "Type": "Improvement",
        "Status": "Closed",
        "Priority": "Minor",
        "Resolution": "Fixed",
        "Affects Version/s": "tools-1.5.2-incubating",
        "Fix Version/s": "tools-1.5.2-incubating",
        "Component/s": "Build, Packaging and Test",
        "Assignee": "William Colen",
        "Reporter": "William Colen",
        "Created": "29/Oct/11 19:10",
        "Updated": "29/Oct/11 19:12",
        "Resolved": "29/Oct/11 19:12",
        "Description": "Release notes refers to OpenNLP 1.5.1, should be updated to 1.5.2.",
        "Issue Links": []
    },
    "OPENNLP-337": {
        "Key": "OPENNLP-337",
        "Summary": "Move the Porter Stemmer to OpenNLP Tools",
        "Type": "New Feature",
        "Status": "Closed",
        "Priority": "Major",
        "Resolution": "Fixed",
        "Affects Version/s": "None",
        "Fix Version/s": "tools-1.5.3",
        "Component/s": "None",
        "Assignee": "Boris Galitsky",
        "Reporter": "J\u00f6rn Kottmann",
        "Created": "31/Oct/11 09:09",
        "Updated": "26/Jun/13 07:38",
        "Resolved": "13/Jul/12 07:54",
        "Description": "The similarity package contribution contains a Porter Stemmer this stemmer should be moved to opennlp tools and a test for it needs to be written.",
        "Issue Links": []
    },
    "OPENNLP-338": {
        "Key": "OPENNLP-338",
        "Summary": "Add L-BFGS parameter estimation training to maxent",
        "Type": "New Feature",
        "Status": "Closed",
        "Priority": "Major",
        "Resolution": "Fixed",
        "Affects Version/s": "None",
        "Fix Version/s": "tools-1.5.3",
        "Component/s": "Machine Learning",
        "Assignee": "Hyosup Shim",
        "Reporter": "J\u00f6rn Kottmann",
        "Created": "31/Oct/11 09:52",
        "Updated": "03/Apr/13 09:04",
        "Resolved": "04/Oct/12 15:23",
        "Description": "Add support for the L-BFGS algorithm to train a maxent classifier.",
        "Issue Links": [
            "/jira/browse/OPENNLP-569"
        ]
    },
    "OPENNLP-339": {
        "Key": "OPENNLP-339",
        "Summary": "Queue Collection Reader should have an option to reset queue",
        "Type": "New Feature",
        "Status": "Closed",
        "Priority": "Major",
        "Resolution": "Fixed",
        "Affects Version/s": "None",
        "Fix Version/s": "None",
        "Component/s": "Corpus Server",
        "Assignee": "J\u00f6rn Kottmann",
        "Reporter": "J\u00f6rn Kottmann",
        "Created": "31/Oct/11 13:10",
        "Updated": "05/Mar/12 16:10",
        "Resolved": "05/Mar/12 16:10",
        "Description": "The Queue Collection reader should have an option to reset/create the queue when it is initialized. With this support a training pipeline can reset the queue every time the training is done.",
        "Issue Links": []
    },
    "OPENNLP-340": {
        "Key": "OPENNLP-340",
        "Summary": "Corpus Server should have the ability to delete a CAS",
        "Type": "New Feature",
        "Status": "Closed",
        "Priority": "Major",
        "Resolution": "Fixed",
        "Affects Version/s": "None",
        "Fix Version/s": "None",
        "Component/s": "Corpus Server",
        "Assignee": "J\u00f6rn Kottmann",
        "Reporter": "J\u00f6rn Kottmann",
        "Created": "31/Oct/11 13:11",
        "Updated": "13/Mar/12 14:48",
        "Resolved": "13/Mar/12 14:48",
        "Description": "It should be possible to delete a CAS on the Corpus Server.",
        "Issue Links": []
    },
    "OPENNLP-341": {
        "Key": "OPENNLP-341",
        "Summary": "Add format support for MUC 6 and 7 data",
        "Type": "New Feature",
        "Status": "Closed",
        "Priority": "Minor",
        "Resolution": "Fixed",
        "Affects Version/s": "1.6.0",
        "Fix Version/s": "1.6.0",
        "Component/s": "Formats",
        "Assignee": "J\u00f6rn Kottmann",
        "Reporter": "J\u00f6rn Kottmann",
        "Created": "31/Oct/11 19:57",
        "Updated": "22/May/15 10:18",
        "Resolved": "22/May/15 10:18",
        "Description": "Add support to parse MUC 6 and 7 data files to the formats package.\nThe data can be used to produce training data for the name finder and coref.\nWe should implement format support for both.",
        "Issue Links": []
    },
    "OPENNLP-342": {
        "Key": "OPENNLP-342",
        "Summary": "Add formats support for the French Treebank",
        "Type": "New Feature",
        "Status": "Closed",
        "Priority": "Minor",
        "Resolution": "Fixed",
        "Affects Version/s": "1.6.0",
        "Fix Version/s": "1.6.0",
        "Component/s": "Formats",
        "Assignee": null,
        "Reporter": "J\u00f6rn Kottmann",
        "Created": "31/Oct/11 20:33",
        "Updated": "21/May/15 13:46",
        "Resolved": "21/May/15 13:46",
        "Description": "The OpenNLP formats package should have support for the French TreeBank. It can be obtained without paying for it for research purposes.\nHere is more information about it.\nhttp://www.llf.cnrs.fr/Gens/Abeille/French-Treebank-fr.php",
        "Issue Links": []
    },
    "OPENNLP-343": {
        "Key": "OPENNLP-343",
        "Summary": "Source distribution contains pom backup files from maven release plugin",
        "Type": "Bug",
        "Status": "Closed",
        "Priority": "Minor",
        "Resolution": "Fixed",
        "Affects Version/s": "None",
        "Fix Version/s": "tools-1.5.2-incubating",
        "Component/s": "Build, Packaging and Test",
        "Assignee": "J\u00f6rn Kottmann",
        "Reporter": "J\u00f6rn Kottmann",
        "Created": "01/Nov/11 09:07",
        "Updated": "08/Nov/11 00:19",
        "Resolved": "08/Nov/11 00:19",
        "Description": "The OpenNLP source distribution contains a backup file for each pom.xml and the release.properties file. These files are created by the maven release plugin and should not be included in our source distribution.\nTo fix this issue ensure that these files are excluded.",
        "Issue Links": []
    },
    "OPENNLP-344": {
        "Key": "OPENNLP-344",
        "Summary": "Build should inject version into the RELEASE_NOTES.html file",
        "Type": "Bug",
        "Status": "Closed",
        "Priority": "Trivial",
        "Resolution": "Fixed",
        "Affects Version/s": "None",
        "Fix Version/s": "tools-1.5.3",
        "Component/s": "Build, Packaging and Test",
        "Assignee": "J\u00f6rn Kottmann",
        "Reporter": "J\u00f6rn Kottmann",
        "Created": "01/Nov/11 09:39",
        "Updated": "15/Nov/11 23:38",
        "Resolved": "15/Nov/11 23:38",
        "Description": "The build process should automatically inject the version in the RELEASE_NOTES.html file.",
        "Issue Links": []
    },
    "OPENNLP-345": {
        "Key": "OPENNLP-345",
        "Summary": "Name Finder View throws exception when an annotation is added",
        "Type": "Bug",
        "Status": "Closed",
        "Priority": "Major",
        "Resolution": "Fixed",
        "Affects Version/s": "None",
        "Fix Version/s": "None",
        "Component/s": "Cas Editor OpenNLP Plugin",
        "Assignee": "J\u00f6rn Kottmann",
        "Reporter": "J\u00f6rn Kottmann",
        "Created": "01/Nov/11 11:46",
        "Updated": "01/Nov/11 14:15",
        "Resolved": "01/Nov/11 14:15",
        "Description": "The name finder view throws an exception when an entity annotation is added and nothing is selected in the name finder view.\nHere is the exception:\norg.eclipse.core.runtime.AssertionFailedException: null argument:\nat org.eclipse.core.runtime.Assert.isNotNull(Assert.java:85)\nat org.eclipse.core.runtime.Assert.isNotNull(Assert.java:73)\nat org.eclipse.jface.viewers.StructuredSelection.<init>(StructuredSelection.java:74)\nat org.apache.opennlp.caseditor.namefinder.EntityContentProvider$ConfirmedEntityListener.added(EntityContentProvider.java:166)\nat org.apache.uima.caseditor.editor.AbstractDocument.fireAddedFeatureStructure(AbstractDocument.java:63)\nat org.apache.uima.caseditor.editor.DocumentUimaImpl.addFeatureStructure(DocumentUimaImpl.java:104)\nat org.apache.uima.caseditor.editor.AnnotationDocument.addFeatureStructure(AnnotationDocument.java:106)\nat org.apache.uima.caseditor.editor.QuickTypeSelectionDialog.annotateAndClose(QuickTypeSelectionDialog.java:181)\nat org.apache.uima.caseditor.editor.QuickTypeSelectionDialog.access$300(QuickTypeSelectionDialog.java:67)\nat org.apache.uima.caseditor.editor.QuickTypeSelectionDialog$6.keyPressed(QuickTypeSelectionDialog.java:308)\nat org.eclipse.swt.widgets.TypedListener.handleEvent(TypedListener.java:161)\nat org.eclipse.swt.widgets.EventTable.sendEvent(EventTable.java:84)\nat org.eclipse.swt.widgets.Display.sendEvent(Display.java:3783)\nat org.eclipse.swt.widgets.Widget.sendEvent(Widget.java:1375)\nat org.eclipse.swt.widgets.Widget.sendEvent(Widget.java:1398)\nat org.eclipse.swt.widgets.Widget.sendEvent(Widget.java:1383)\nat org.eclipse.swt.widgets.Widget.sendKeyEvent(Widget.java:1412)\nat org.eclipse.swt.widgets.Widget.sendKeyEvent(Widget.java:1408)\nat org.eclipse.swt.widgets.Tree.sendKeyEvent(Tree.java:2506)\nat org.eclipse.swt.widgets.Control.keyDown(Control.java:2118)\nat org.eclipse.swt.widgets.Composite.keyDown(Composite.java:600)\nat org.eclipse.swt.widgets.Tree.keyDown(Tree.java:1886)\nat org.eclipse.swt.widgets.Display.windowProc(Display.java:4985)\nat org.eclipse.swt.internal.cocoa.OS.objc_msgSendSuper(Native Method)\nat org.eclipse.swt.widgets.Widget.callSuper(Widget.java:220)\nat org.eclipse.swt.widgets.Widget.windowSendEvent(Widget.java:1959)\nat org.eclipse.swt.widgets.Shell.windowSendEvent(Shell.java:2025)\nat org.eclipse.swt.widgets.Display.windowProc(Display.java:5047)\nat org.eclipse.swt.internal.cocoa.OS.objc_msgSendSuper(Native Method)\nat org.eclipse.swt.widgets.Display.applicationSendEvent(Display.java:4589)\nat org.eclipse.swt.widgets.Display.applicationProc(Display.java:4666)\nat org.eclipse.swt.internal.cocoa.OS.objc_msgSend(Native Method)\nat org.eclipse.swt.internal.cocoa.NSApplication.sendEvent(NSApplication.java:115)\nat org.eclipse.swt.widgets.Display.readAndDispatch(Display.java:3281)\nat org.eclipse.ui.internal.Workbench.runEventLoop(Workbench.java:2640)\nat org.eclipse.ui.internal.Workbench.runUI(Workbench.java:2604)\nat org.eclipse.ui.internal.Workbench.access$4(Workbench.java:2438)\nat org.eclipse.ui.internal.Workbench$7.run(Workbench.java:671)\nat org.eclipse.core.databinding.observable.Realm.runWithDefault(Realm.java:332)\nat org.eclipse.ui.internal.Workbench.createAndRunWorkbench(Workbench.java:664)\nat org.eclipse.ui.PlatformUI.createAndRunWorkbench(PlatformUI.java:149)\nat org.eclipse.ui.internal.ide.application.IDEApplication.start(IDEApplication.java:115)\nat org.eclipse.equinox.internal.app.EclipseAppHandle.run(EclipseAppHandle.java:196)\nat org.eclipse.core.runtime.internal.adaptor.EclipseAppLauncher.runApplication(EclipseAppLauncher.java:110)\nat org.eclipse.core.runtime.internal.adaptor.EclipseAppLauncher.start(EclipseAppLauncher.java:79)\nat org.eclipse.core.runtime.adaptor.EclipseStarter.run(EclipseStarter.java:369)\nat org.eclipse.core.runtime.adaptor.EclipseStarter.run(EclipseStarter.java:179)\nat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)\nat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)\nat java.lang.reflect.Method.invoke(Method.java:597)\nat org.eclipse.equinox.launcher.Main.invokeFramework(Main.java:620)\nat org.eclipse.equinox.launcher.Main.basicRun(Main.java:575)\nat org.eclipse.equinox.launcher.Main.run(Main.java:1408)",
        "Issue Links": []
    },
    "OPENNLP-346": {
        "Key": "OPENNLP-346",
        "Summary": "Corpus Explorer view should save last used server in settigns",
        "Type": "Bug",
        "Status": "Closed",
        "Priority": "Minor",
        "Resolution": "Fixed",
        "Affects Version/s": "None",
        "Fix Version/s": "None",
        "Component/s": "Cas Editor Corpus Server Plugin",
        "Assignee": "J\u00f6rn Kottmann",
        "Reporter": "J\u00f6rn Kottmann",
        "Created": "01/Nov/11 14:12",
        "Updated": "01/Nov/11 16:01",
        "Resolved": "01/Nov/11 16:01",
        "Description": "The Corpus Explorer view needs to save the last used sever in the settigns, otherwise a user always needs to enter the server after eclipse was restarted.",
        "Issue Links": []
    },
    "OPENNLP-347": {
        "Key": "OPENNLP-347",
        "Summary": "Corpus Explorer view should use a combo box for the queries, and remember the last n queries",
        "Type": "Bug",
        "Status": "Closed",
        "Priority": "Major",
        "Resolution": "Fixed",
        "Affects Version/s": "None",
        "Fix Version/s": "None",
        "Component/s": "Cas Editor Corpus Server Plugin",
        "Assignee": "J\u00f6rn Kottmann",
        "Reporter": "J\u00f6rn Kottmann",
        "Created": "01/Nov/11 14:14",
        "Updated": "01/Nov/11 17:57",
        "Resolved": "01/Nov/11 17:57",
        "Description": "The query is often switched between a few common ones. The make this easier the view should remember the last n queries, and over them in a combo.",
        "Issue Links": []
    },
    "OPENNLP-348": {
        "Key": "OPENNLP-348",
        "Summary": "Corpus Explorer view does not support double click to open a CAS",
        "Type": "Bug",
        "Status": "Closed",
        "Priority": "Major",
        "Resolution": "Fixed",
        "Affects Version/s": "None",
        "Fix Version/s": "None",
        "Component/s": "Cas Editor Corpus Server Plugin",
        "Assignee": "J\u00f6rn Kottmann",
        "Reporter": "J\u00f6rn Kottmann",
        "Created": "01/Nov/11 15:12",
        "Updated": "01/Nov/11 15:28",
        "Resolved": "01/Nov/11 15:28",
        "Description": "It should be possible to open a CAS by double clicking the Corpus Explorer View instead of using hte Open button. The Open button should also be removed.",
        "Issue Links": []
    },
    "OPENNLP-349": {
        "Key": "OPENNLP-349",
        "Summary": "Corpus Explorer view should use a virtual table to display search results",
        "Type": "Improvement",
        "Status": "Closed",
        "Priority": "Major",
        "Resolution": "Won't Fix",
        "Affects Version/s": "None",
        "Fix Version/s": "None",
        "Component/s": "Cas Editor Corpus Server Plugin",
        "Assignee": null,
        "Reporter": "J\u00f6rn Kottmann",
        "Created": "01/Nov/11 16:05",
        "Updated": "16/Jan/17 14:27",
        "Resolved": "16/Jan/17 14:27",
        "Description": "A Corpus could contain a quite large number of CASes. If a user does a search which returns them all it might not be suitable to load all references to CASes into memory. To avoid this the table should be virtual and pull the result from the server on demand.",
        "Issue Links": []
    },
    "OPENNLP-350": {
        "Key": "OPENNLP-350",
        "Summary": "Corpus Explorer should not query server in the UI thread",
        "Type": "Improvement",
        "Status": "Closed",
        "Priority": "Major",
        "Resolution": "Fixed",
        "Affects Version/s": "None",
        "Fix Version/s": "None",
        "Component/s": "Cas Editor Corpus Server Plugin",
        "Assignee": "J\u00f6rn Kottmann",
        "Reporter": "J\u00f6rn Kottmann",
        "Created": "02/Nov/11 09:46",
        "Updated": "02/Nov/11 12:51",
        "Resolved": "02/Nov/11 12:51",
        "Description": "The corpus explorer should not query to the server in the ui thread. To fix this create a background job which fetches the results. While the job is running the corpus explorer view should display something which indicates this to the user.",
        "Issue Links": []
    },
    "OPENNLP-351": {
        "Key": "OPENNLP-351",
        "Summary": "Corpus Explorer should trigger search when enter is pressed or and old query is chosen form the combo",
        "Type": "Improvement",
        "Status": "Closed",
        "Priority": "Minor",
        "Resolution": "Fixed",
        "Affects Version/s": "None",
        "Fix Version/s": "None",
        "Component/s": "Cas Editor Corpus Server Plugin",
        "Assignee": "J\u00f6rn Kottmann",
        "Reporter": "J\u00f6rn Kottmann",
        "Created": "02/Nov/11 13:51",
        "Updated": "02/Nov/11 13:52",
        "Resolved": "02/Nov/11 13:52",
        "Description": "Corpus Explorer should trigger search when enter is pressed or and old query is chosen form the combo.",
        "Issue Links": []
    },
    "OPENNLP-352": {
        "Key": "OPENNLP-352",
        "Summary": "Corpus Server Plugin should save session preferences",
        "Type": "Improvement",
        "Status": "Closed",
        "Priority": "Minor",
        "Resolution": "Won't Fix",
        "Affects Version/s": "None",
        "Fix Version/s": "None",
        "Component/s": "Cas Editor Corpus Server Plugin",
        "Assignee": "J\u00f6rn Kottmann",
        "Reporter": "J\u00f6rn Kottmann",
        "Created": "02/Nov/11 13:54",
        "Updated": "16/Jan/17 14:27",
        "Resolved": "16/Jan/17 14:27",
        "Description": "The session preferences should be saved in the same way as the (stored) preferences are saved.",
        "Issue Links": []
    },
    "OPENNLP-353": {
        "Key": "OPENNLP-353",
        "Summary": "Sentence Detector View should display beging and end of sentence",
        "Type": "Improvement",
        "Status": "Closed",
        "Priority": "Minor",
        "Resolution": "Fixed",
        "Affects Version/s": "None",
        "Fix Version/s": "None",
        "Component/s": "Cas Editor OpenNLP Plugin",
        "Assignee": "J\u00f6rn Kottmann",
        "Reporter": "J\u00f6rn Kottmann",
        "Created": "02/Nov/11 15:45",
        "Updated": "02/Nov/11 15:47",
        "Resolved": "02/Nov/11 15:47",
        "Description": "The Sentence Detector View should always show the begin and end of an sentence and cutout the middle of the sentence to accomplish that.",
        "Issue Links": []
    },
    "OPENNLP-354": {
        "Key": "OPENNLP-354",
        "Summary": "Corpus Explorer should specify timeout for server connection and report errors",
        "Type": "Improvement",
        "Status": "Closed",
        "Priority": "Minor",
        "Resolution": "Fixed",
        "Affects Version/s": "None",
        "Fix Version/s": "None",
        "Component/s": "Cas Editor Corpus Server Plugin",
        "Assignee": "J\u00f6rn Kottmann",
        "Reporter": "J\u00f6rn Kottmann",
        "Created": "03/Nov/11 13:57",
        "Updated": "03/Nov/11 13:57",
        "Resolved": "03/Nov/11 13:57",
        "Description": "The connection timeout will ensure that the connection attemp fails in case the server is not available or cannot be reached through network problems. If an error occurs the user should be notified about it.",
        "Issue Links": []
    },
    "OPENNLP-355": {
        "Key": "OPENNLP-355",
        "Summary": "Add Chunker API description to docbook",
        "Type": "Improvement",
        "Status": "Closed",
        "Priority": "Minor",
        "Resolution": "Fixed",
        "Affects Version/s": "None",
        "Fix Version/s": "tools-1.5.2-incubating",
        "Component/s": "Documentation",
        "Assignee": "William Colen",
        "Reporter": "William Colen",
        "Created": "07/Nov/11 12:18",
        "Updated": "08/Nov/11 11:32",
        "Resolved": "08/Nov/11 11:32",
        "Description": null,
        "Issue Links": []
    },
    "OPENNLP-356": {
        "Key": "OPENNLP-356",
        "Summary": "OpenNLP views need to register cas editor input change listener",
        "Type": "Bug",
        "Status": "Closed",
        "Priority": "Major",
        "Resolution": "Fixed",
        "Affects Version/s": "None",
        "Fix Version/s": "None",
        "Component/s": "Cas Editor OpenNLP Plugin",
        "Assignee": "J\u00f6rn Kottmann",
        "Reporter": "J\u00f6rn Kottmann",
        "Created": "07/Nov/11 13:04",
        "Updated": "17/Nov/11 12:23",
        "Resolved": "17/Nov/11 12:23",
        "Description": "Eclipse might reuse an existing Cas Editor instance, in this case the views must also be updated. To detect this event all views should implement the new input change listener.",
        "Issue Links": []
    },
    "OPENNLP-357": {
        "Key": "OPENNLP-357",
        "Summary": "Missing SVN properties",
        "Type": "Bug",
        "Status": "Closed",
        "Priority": "Major",
        "Resolution": "Fixed",
        "Affects Version/s": "None",
        "Fix Version/s": "None",
        "Component/s": "None",
        "Assignee": "J\u00f6rn Kottmann",
        "Reporter": "Sebb",
        "Created": "07/Nov/11 17:34",
        "Updated": "15/Nov/11 08:56",
        "Resolved": "07/Nov/11 22:32",
        "Description": "Various missing or incorrect SVN properties detected in https://svn.apache.org/repos/asf/incubator/opennlp/tags/opennlp-1.5.2-incubating-rc4/\n which are probably present in trunk.\nSee attached patch which may be used to fix them.",
        "Issue Links": []
    },
    "OPENNLP-358": {
        "Key": "OPENNLP-358",
        "Summary": "Remove left over .cvsignore from subversion",
        "Type": "Bug",
        "Status": "Closed",
        "Priority": "Trivial",
        "Resolution": "Fixed",
        "Affects Version/s": "None",
        "Fix Version/s": "tools-1.5.2-incubating",
        "Component/s": "None",
        "Assignee": "J\u00f6rn Kottmann",
        "Reporter": "J\u00f6rn Kottmann",
        "Created": "07/Nov/11 18:13",
        "Updated": "08/Nov/11 00:19",
        "Resolved": "08/Nov/11 00:19",
        "Description": "There is one left over .cvsignore which is not needed anymore and should be removed.\nIt is located here:\nopennlp-uima\\src\\main\\java\\opennlp\\uima\\namefind",
        "Issue Links": []
    },
    "OPENNLP-359": {
        "Key": "OPENNLP-359",
        "Summary": "Generate a tar.gz package of the source distribution",
        "Type": "Bug",
        "Status": "Closed",
        "Priority": "Trivial",
        "Resolution": "Fixed",
        "Affects Version/s": "None",
        "Fix Version/s": "tools-1.5.2-incubating",
        "Component/s": "Build, Packaging and Test",
        "Assignee": "J\u00f6rn Kottmann",
        "Reporter": "J\u00f6rn Kottmann",
        "Created": "07/Nov/11 18:24",
        "Updated": "08/Nov/11 00:19",
        "Resolved": "08/Nov/11 00:19",
        "Description": "It is not consistent to have a tar.gz and zip package for the binary distribution and only a zip package for the source distribution. To fix this build also a tar.gz distribution of the source package.",
        "Issue Links": []
    },
    "OPENNLP-360": {
        "Key": "OPENNLP-360",
        "Summary": "Remove UIMA reference from NOTICE file",
        "Type": "Task",
        "Status": "Closed",
        "Priority": "Minor",
        "Resolution": "Fixed",
        "Affects Version/s": "None",
        "Fix Version/s": "tools-1.5.2-incubating",
        "Component/s": "Build, Packaging and Test",
        "Assignee": "J\u00f6rn Kottmann",
        "Reporter": "J\u00f6rn Kottmann",
        "Created": "07/Nov/11 18:28",
        "Updated": "08/Nov/11 00:20",
        "Resolved": "08/Nov/11 00:20",
        "Description": "We got the following feedback during a release review from sebb:\n\"\"This product depends on Apache UIMA developed at\nThe Apache Software Foundation (http://www.apache.org/), licensed\nunder the Apache License 2.0 (see LICENSE file).\"\nThis should be removed; NOTICE files are for required notices only;\nUIMA is covered under the earlier ASF paragraph.\"\nTo fix this issue remove the mentioned paragraph.",
        "Issue Links": []
    },
    "OPENNLP-361": {
        "Key": "OPENNLP-361",
        "Summary": "handling spaces in JAVA_HOME",
        "Type": "Bug",
        "Status": "Closed",
        "Priority": "Major",
        "Resolution": "Fixed",
        "Affects Version/s": "tools-1.5.3",
        "Fix Version/s": "tools-1.5.3",
        "Component/s": "Command Line Interface",
        "Assignee": "James Kosin",
        "Reporter": "Aliaksandr Autayeu",
        "Created": "08/Nov/11 17:12",
        "Updated": "12/Nov/11 09:43",
        "Resolved": "12/Nov/11 00:47",
        "Description": "If JAVA_HOME contains spaces, opennlp.bat fails to execute java.",
        "Issue Links": []
    },
    "OPENNLP-362": {
        "Key": "OPENNLP-362",
        "Summary": "JavaDoc warnings",
        "Type": "Improvement",
        "Status": "Closed",
        "Priority": "Minor",
        "Resolution": "Fixed",
        "Affects Version/s": "tools-1.5.3,                                            maxent-3.0.3",
        "Fix Version/s": "tools-1.5.3",
        "Component/s": "None",
        "Assignee": "J\u00f6rn Kottmann",
        "Reporter": "Aliaksandr Autayeu",
        "Created": "08/Nov/11 17:14",
        "Updated": "08/Nov/11 19:56",
        "Resolved": "08/Nov/11 19:28",
        "Description": "There are various JavaDoc warning on compilation",
        "Issue Links": []
    },
    "OPENNLP-363": {
        "Key": "OPENNLP-363",
        "Summary": "performance-issues: manual array or collection copy,  appending strings, string creation, extra .toString()",
        "Type": "Improvement",
        "Status": "Closed",
        "Priority": "Minor",
        "Resolution": "Fixed",
        "Affects Version/s": "tools-1.5.3,                                            maxent-3.0.3",
        "Fix Version/s": "None",
        "Component/s": "None",
        "Assignee": "J\u00f6rn Kottmann",
        "Reporter": "Aliaksandr Autayeu",
        "Created": "08/Nov/11 19:42",
        "Updated": "09/Nov/11 09:47",
        "Resolved": "09/Nov/11 09:02",
        "Description": "There are multiple performance nuisances: manual array or collection copy, appending strings, string creation, extra .toString() calls.",
        "Issue Links": []
    },
    "OPENNLP-364": {
        "Key": "OPENNLP-364",
        "Summary": "Use StringBuilder instead of StringBuffer",
        "Type": "Improvement",
        "Status": "Closed",
        "Priority": "Minor",
        "Resolution": "Fixed",
        "Affects Version/s": "tools-1.5.3,                                            maxent-3.0.3",
        "Fix Version/s": "tools-1.5.3",
        "Component/s": "None",
        "Assignee": "J\u00f6rn Kottmann",
        "Reporter": "Aliaksandr Autayeu",
        "Created": "08/Nov/11 21:46",
        "Updated": "08/Nov/11 22:03",
        "Resolved": "08/Nov/11 21:56",
        "Description": "There are local StringBuffer instances used in several places. StringBuilder is preferred:\nWhere possible, it is recommended that this class be used in preference to StringBuffer as it will be faster under most implementations.\nMore support:\nhttp://en.wikipedia.org/wiki/String_Buffer:\nThe StringBuilder class, introduced in J2SE 5.0, differs from StringBuffer in that it is unsynchronized. When only a single thread at a time will access the object, using a StringBuilder processes more efficiently than using a StringBuffer.\nhttp://stackoverflow.com/questions/355089/stringbuilder-and-stringbuffer-in-java:\nA test run gives the numbers of 2241 ms for StringBuffer vs 753 ms for StringBuilder.\nhttp://littletutorials.com/2008/07/16/stringbuffer-vs-stringbuilder-performance-comparison/:\nSo StringBuilder is faster by a good percentage (34% on my machine in this case) but remember that it is not thread safe.\nThread-safety is not threatened, as all proposed changes consider local variables.",
        "Issue Links": []
    },
    "OPENNLP-365": {
        "Key": "OPENNLP-365",
        "Summary": "Java5 nuisances: boxing\\unboxing, extra casts, shorter loops",
        "Type": "Improvement",
        "Status": "Closed",
        "Priority": "Minor",
        "Resolution": "Fixed",
        "Affects Version/s": "tools-1.5.3,                                            maxent-3.0.3",
        "Fix Version/s": "tools-1.5.3",
        "Component/s": "None",
        "Assignee": "J\u00f6rn Kottmann",
        "Reporter": "Aliaksandr Autayeu",
        "Created": "08/Nov/11 22:47",
        "Updated": "09/Nov/11 09:45",
        "Resolved": "09/Nov/11 08:42",
        "Description": "Several unnecessary boxing\\unboxing, extra casts and old loops improved: code reads much better.",
        "Issue Links": []
    },
    "OPENNLP-366": {
        "Key": "OPENNLP-366",
        "Summary": "Java5: generics to avoid casts",
        "Type": "Improvement",
        "Status": "Closed",
        "Priority": "Minor",
        "Resolution": "Fixed",
        "Affects Version/s": "tools-1.5.3,                                            maxent-3.0.3",
        "Fix Version/s": "tools-1.5.3",
        "Component/s": "None",
        "Assignee": "J\u00f6rn Kottmann",
        "Reporter": "Aliaksandr Autayeu",
        "Created": "08/Nov/11 23:28",
        "Updated": "09/Nov/11 09:43",
        "Resolved": "09/Nov/11 08:26",
        "Description": "In several places Java5 generics can be used to avoid casts and make the code safer and more readable",
        "Issue Links": []
    },
    "OPENNLP-367": {
        "Key": "OPENNLP-367",
        "Summary": "File Encoding Issues",
        "Type": "Bug",
        "Status": "Closed",
        "Priority": "Major",
        "Resolution": "Fixed",
        "Affects Version/s": "tools-1.5.2-incubating",
        "Fix Version/s": "tools-1.5.3",
        "Component/s": "Command Line Interface",
        "Assignee": "James Kosin",
        "Reporter": "James Kosin",
        "Created": "10/Nov/11 04:09",
        "Updated": "20/Jan/12 04:30",
        "Resolved": "20/Jan/12 04:30",
        "Description": "The input and output encodings are not working correctly or are not properly handled.  A good example is the CoNLL 2002 data if correctly encoded in UTF-8 does not correctly work for training without specifying -Dfile.encoding=UTF-8 for the Java Command.\nWe already specify the input and expected output encoding on the cmdline interface with the -encoding paramter.  For some reason this isn't being followed.\nI'll work on fixing this for the next major release...",
        "Issue Links": []
    },
    "OPENNLP-368": {
        "Key": "OPENNLP-368",
        "Summary": "loops improved in opennlp-tools",
        "Type": "Improvement",
        "Status": "Closed",
        "Priority": "Minor",
        "Resolution": "Fixed",
        "Affects Version/s": "tools-1.5.3",
        "Fix Version/s": "None",
        "Component/s": "None",
        "Assignee": null,
        "Reporter": "Aliaksandr Autayeu",
        "Created": "10/Nov/11 16:14",
        "Updated": "21/Feb/14 17:39",
        "Resolved": "21/Feb/14 17:39",
        "Description": "Many old-style indexed loops replaced with Java5 for each loops to improve code readability and reduce possibility of bugs.",
        "Issue Links": []
    },
    "OPENNLP-369": {
        "Key": "OPENNLP-369",
        "Summary": "loops improved in maxent",
        "Type": "Improvement",
        "Status": "Closed",
        "Priority": "Minor",
        "Resolution": "Fixed",
        "Affects Version/s": "maxent-3.0.3",
        "Fix Version/s": "tools-1.5.3,                                            maxent-3.0.3",
        "Component/s": "Machine Learning",
        "Assignee": "J\u00f6rn Kottmann",
        "Reporter": "Aliaksandr Autayeu",
        "Created": "10/Nov/11 16:49",
        "Updated": "11/Nov/11 13:24",
        "Resolved": "11/Nov/11 13:24",
        "Description": "Many old-style indexed loops where refactored to new Java5 loopsto improve code readability.",
        "Issue Links": []
    },
    "OPENNLP-370": {
        "Key": "OPENNLP-370",
        "Summary": "Generics in GISModelWriter.compressOutcomes",
        "Type": "Improvement",
        "Status": "Closed",
        "Priority": "Minor",
        "Resolution": "Fixed",
        "Affects Version/s": "maxent-3.0.3",
        "Fix Version/s": "tools-1.5.3",
        "Component/s": "Machine Learning",
        "Assignee": "J\u00f6rn Kottmann",
        "Reporter": "Aliaksandr Autayeu",
        "Created": "10/Nov/11 17:12",
        "Updated": "11/Nov/11 08:53",
        "Resolved": "11/Nov/11 08:53",
        "Description": "There is a bit of code with casts in GISModelWriter which can be improved by using generics.",
        "Issue Links": []
    },
    "OPENNLP-371": {
        "Key": "OPENNLP-371",
        "Summary": "Confusing error message in tokenizer training",
        "Type": "Improvement",
        "Status": "Closed",
        "Priority": "Minor",
        "Resolution": "Fixed",
        "Affects Version/s": "tools-1.5.3",
        "Fix Version/s": "1.7.2",
        "Component/s": "Tokenizer",
        "Assignee": "J\u00f6rn Kottmann",
        "Reporter": "Aliaksandr Autayeu",
        "Created": "12/Nov/11 15:33",
        "Updated": "31/Jan/17 11:58",
        "Resolved": "31/Jan/17 11:58",
        "Description": "The following error message\njava.lang.IllegalArgumentException: The maxent model is not compatible with the tokenizer!\n\tat opennlp.tools.util.model.BaseModel.checkArtifactMap(BaseModel.java:275)\n\tat opennlp.tools.tokenize.TokenizerModel.<init>(TokenizerModel.java:73)\n\tat opennlp.tools.tokenize.TokenizerME.train(TokenizerME.java:267)\n\tat opennlp.tools.tokenize.TokenizerME.train(TokenizerME.java:231)\n\tat opennlp.tools.tokenize.TokenizerME.train(TokenizerME.java:293)\n\tat opennlp.tools.tokenize.TokenizerTestUtil.createMaxentTokenModel(TokenizerTestUtil.java:67)\n\tat opennlp.tools.tokenize.TokenizerMETest.testTokenizer(TokenizerMETest.java:54)\n... cut\nmight be confusing. \nDue to error in my conversion tool, I tried to train a tokenizer model on data without <SPLIT>s, which resulted in a model with one outcome only. This model did not pass validation in ModelUtil.validateOutcomes(), which is correct, however, the error message is a bit confusing and it took some time to understood what is going on. \nI would agree, that a model with different outcomes than expected is incompatible with the tool, but with less outcomes? Is the model with less outcomes than expected really incompatible? For example, with POS tagger I have corpora and models which use a subset of PTB tagset. \nHowever, in case of tokenizer this incompatibility makes sense (model with 1 outcome does not work) and in this case the message might be improved to indicate the cause better. Something like: \"The maxent model is not compatible with the tokenizer: outcome XXX is not found\". \nPlease, advice. Thank you!",
        "Issue Links": [
            "https://github.com/apache/opennlp/pull/106"
        ]
    },
    "OPENNLP-372": {
        "Key": "OPENNLP-372",
        "Summary": "Banner with version for CLI tool",
        "Type": "Improvement",
        "Status": "Closed",
        "Priority": "Minor",
        "Resolution": "Fixed",
        "Affects Version/s": "tools-1.5.3",
        "Fix Version/s": "tools-1.5.3",
        "Component/s": "Command Line Interface",
        "Assignee": "J\u00f6rn Kottmann",
        "Reporter": "Aliaksandr Autayeu",
        "Created": "12/Nov/11 18:31",
        "Updated": "15/Nov/11 08:29",
        "Resolved": "15/Nov/11 08:29",
        "Description": "It would be nice to add banner with version to CLI tool, like in attached patch.",
        "Issue Links": []
    },
    "OPENNLP-373": {
        "Key": "OPENNLP-373",
        "Summary": "Add the incubator disclaimer",
        "Type": "Task",
        "Status": "Closed",
        "Priority": "Major",
        "Resolution": "Fixed",
        "Affects Version/s": "tools-1.5.2-incubating",
        "Fix Version/s": "tools-1.5.2-incubating",
        "Component/s": "None",
        "Assignee": "J\u00f6rn Kottmann",
        "Reporter": "J\u00f6rn Kottmann",
        "Created": "14/Nov/11 16:53",
        "Updated": "15/Nov/11 15:07",
        "Resolved": "15/Nov/11 15:07",
        "Description": "The distribution and subversion tags should contain the incubator disclaimer.",
        "Issue Links": []
    },
    "OPENNLP-374": {
        "Key": "OPENNLP-374",
        "Summary": "Fix typo in tokenizer documentation",
        "Type": "Bug",
        "Status": "Closed",
        "Priority": "Trivial",
        "Resolution": "Not A Problem",
        "Affects Version/s": "None",
        "Fix Version/s": "None",
        "Component/s": "Documentation",
        "Assignee": "J\u00f6rn Kottmann",
        "Reporter": "J\u00f6rn Kottmann",
        "Created": "15/Nov/11 09:01",
        "Updated": "15/Nov/11 23:55",
        "Resolved": "15/Nov/11 23:55",
        "Description": "Ben Rhelp:\n\"In the documentation:\nhttp://incubator.apache.org/opennlp/documentation/manual/opennlp.html#tools.namefind.recognition.api\nI think the example should be as follows (String->String[] and \"years\"->\"years\",)\n    String[] sentence = new String[]\n{\n            \"Pierre\",\n            \"Vinken\",\n            \"is\",\n            \"61\",\n            \"years\",\n            \"old\",\n            \".\"\n            }\n;\nIn\nhttp://incubator.apache.org/opennlp/documentation/manual/opennlp.html#tools.tokenizer.api\nTokenizer tokenizer = new TokenizerME(model);\nshould be\nTokenizerME tokenizer = new TokenizerME(model);\"",
        "Issue Links": []
    },
    "OPENNLP-375": {
        "Key": "OPENNLP-375",
        "Summary": "UIMA based trainers should support maxent properties file",
        "Type": "Improvement",
        "Status": "Closed",
        "Priority": "Minor",
        "Resolution": "Fixed",
        "Affects Version/s": "None",
        "Fix Version/s": "tools-1.5.3",
        "Component/s": "UIMA Integration",
        "Assignee": "J\u00f6rn Kottmann",
        "Reporter": "J\u00f6rn Kottmann",
        "Created": "15/Nov/11 12:53",
        "Updated": "21/Nov/11 13:13",
        "Resolved": "21/Nov/11 13:13",
        "Description": "All trainers in the UIMA Integration should support the new machine learning settings properties file to configure the machine learning trainer.",
        "Issue Links": []
    },
    "OPENNLP-376": {
        "Key": "OPENNLP-376",
        "Summary": "UIMA Name Finder trainer should support feature generation xml file",
        "Type": "Improvement",
        "Status": "Closed",
        "Priority": "Minor",
        "Resolution": "Fixed",
        "Affects Version/s": "None",
        "Fix Version/s": "tools-1.5.3",
        "Component/s": "UIMA Integration",
        "Assignee": "J\u00f6rn Kottmann",
        "Reporter": "J\u00f6rn Kottmann",
        "Created": "15/Nov/11 12:55",
        "Updated": "21/Nov/11 13:13",
        "Resolved": "21/Nov/11 13:13",
        "Description": "The name finder supports custom feature generation via a xml based description file. The UIMA Integration for the name finder should be able to use this file to train a new model.",
        "Issue Links": []
    },
    "OPENNLP-377": {
        "Key": "OPENNLP-377",
        "Summary": "All project names should start with \"Apache OpenNLP\"",
        "Type": "Improvement",
        "Status": "Closed",
        "Priority": "Trivial",
        "Resolution": "Fixed",
        "Affects Version/s": "None",
        "Fix Version/s": "tools-1.5.2-incubating",
        "Component/s": "Build, Packaging and Test",
        "Assignee": "J\u00f6rn Kottmann",
        "Reporter": "J\u00f6rn Kottmann",
        "Created": "15/Nov/11 14:38",
        "Updated": "15/Nov/11 15:07",
        "Resolved": "15/Nov/11 15:07",
        "Description": "All project names start currently with \"OpenNLP\". This should be changed into \"Apache OpenNLP\".\nThe project name from mavens pom is used in some places, e.g. NOTICE files.",
        "Issue Links": []
    },
    "OPENNLP-378": {
        "Key": "OPENNLP-378",
        "Summary": "Update OpenNLP one sentence description to be compliant with branding requirements",
        "Type": "Improvement",
        "Status": "Closed",
        "Priority": "Trivial",
        "Resolution": "Fixed",
        "Affects Version/s": "None",
        "Fix Version/s": "tools-1.5.2-incubating",
        "Component/s": "Documentation,                                            Website",
        "Assignee": "J\u00f6rn Kottmann",
        "Reporter": "J\u00f6rn Kottmann",
        "Created": "15/Nov/11 15:04",
        "Updated": "15/Nov/11 15:34",
        "Resolved": "15/Nov/11 15:34",
        "Description": "To be compliant with the branding requirements the OpenNLP one sentence description should be changed.\nFrom\n\"OpenNLP is a machine learning based toolkit for the processing of natural language text.\"\nto\n\"The Apache OpenNLP library is a machine learning based toolkit for the processing of natural language text.",
        "Issue Links": []
    },
    "OPENNLP-379": {
        "Key": "OPENNLP-379",
        "Summary": "Remove leading empty line in embedded NOTICE file",
        "Type": "Improvement",
        "Status": "Closed",
        "Priority": "Trivial",
        "Resolution": "Won't Fix",
        "Affects Version/s": "tools-1.5.2-incubating",
        "Fix Version/s": "None",
        "Component/s": "Build, Packaging and Test",
        "Assignee": null,
        "Reporter": "J\u00f6rn Kottmann",
        "Created": "15/Nov/11 15:39",
        "Updated": "23/Dec/16 18:01",
        "Resolved": "23/Dec/16 18:01",
        "Description": "The build injects a NOTICE file into the jar files, these NOTICE file contains a leading empty line.\nTo fix this issue, remove the leading empty line from these NOTICE files.",
        "Issue Links": []
    },
    "OPENNLP-380": {
        "Key": "OPENNLP-380",
        "Summary": "Remove old left over assembly folders",
        "Type": "Improvement",
        "Status": "Closed",
        "Priority": "Trivial",
        "Resolution": "Fixed",
        "Affects Version/s": "None",
        "Fix Version/s": "tools-1.5.3",
        "Component/s": "Build, Packaging and Test",
        "Assignee": "J\u00f6rn Kottmann",
        "Reporter": "J\u00f6rn Kottmann",
        "Created": "15/Nov/11 15:56",
        "Updated": "15/Nov/11 23:49",
        "Resolved": "15/Nov/11 23:49",
        "Description": "Various sub-projects contain left over assembly folders and descriptors. These should be removed, because they are not used by the build.",
        "Issue Links": []
    },
    "OPENNLP-381": {
        "Key": "OPENNLP-381",
        "Summary": "Error messages for command line arguments introduced into command line tools",
        "Type": "Improvement",
        "Status": "Closed",
        "Priority": "Major",
        "Resolution": "Fixed",
        "Affects Version/s": "tools-1.5.3",
        "Fix Version/s": "tools-1.5.3",
        "Component/s": "Command Line Interface",
        "Assignee": "J\u00f6rn Kottmann",
        "Reporter": "Aliaksandr Autayeu",
        "Created": "16/Nov/11 00:26",
        "Updated": "16/Nov/11 09:59",
        "Resolved": "16/Nov/11 09:59",
        "Description": "Command line tools do not report error messages, resorting always to showing help. This is a bit confusing. Attached patch improves this.",
        "Issue Links": []
    },
    "OPENNLP-382": {
        "Key": "OPENNLP-382",
        "Summary": "Old way of encoding parameter processing replaced with new one",
        "Type": "Improvement",
        "Status": "Closed",
        "Priority": "Minor",
        "Resolution": "Fixed",
        "Affects Version/s": "tools-1.5.3",
        "Fix Version/s": "tools-1.5.3",
        "Component/s": "Command Line Interface",
        "Assignee": "J\u00f6rn Kottmann",
        "Reporter": "Aliaksandr Autayeu",
        "Created": "16/Nov/11 00:28",
        "Updated": "16/Nov/11 09:57",
        "Resolved": "16/Nov/11 09:57",
        "Description": "There are remains of old way of getting encoding in two places. They are updated to a new method. The static CmdLineUtil.getEncoding method is removed as unused.",
        "Issue Links": []
    },
    "OPENNLP-383": {
        "Key": "OPENNLP-383",
        "Summary": "Model compatibility check fails if model contains an unknown artifact",
        "Type": "Bug",
        "Status": "Open",
        "Priority": "Minor",
        "Resolution": "Unresolved",
        "Affects Version/s": "tools-1.5.1-incubating",
        "Fix Version/s": "None",
        "Component/s": "None",
        "Assignee": null,
        "Reporter": "J\u00f6rn Kottmann",
        "Created": "16/Nov/11 10:26",
        "Updated": "11/Sep/12 13:08",
        "Resolved": null,
        "Description": "The BaseModel class has a check to ensure that a model is matching the component which is loading it. This check is not performed when the model contains an artifact for which no serializer is available. In this case an exception is thrown which indicates that the artifact type is not known.\nIn the case of an unknown artifact the model should remember the error and continue until the manifest was loaded to perform the component compatibility check. Only if the check passes the actual error should be reported.",
        "Issue Links": []
    },
    "OPENNLP-384": {
        "Key": "OPENNLP-384",
        "Summary": "UIMA trainer should extend CasAnnotator_ImplBase instead of CasConsumer_ImplBase",
        "Type": "Improvement",
        "Status": "Closed",
        "Priority": "Minor",
        "Resolution": "Won't Fix",
        "Affects Version/s": "None",
        "Fix Version/s": "None",
        "Component/s": "UIMA Integration",
        "Assignee": null,
        "Reporter": "J\u00f6rn Kottmann",
        "Created": "16/Nov/11 13:46",
        "Updated": "16/Jan/17 14:34",
        "Resolved": "16/Jan/17 14:34",
        "Description": "Cas Consumers are deprecated in UIMA and Analysis Engines should be used also for components which only consume CASes.\nWhile doing the update a common base class for trainer AEs should be created.",
        "Issue Links": []
    },
    "OPENNLP-385": {
        "Key": "OPENNLP-385",
        "Summary": "OpenNLP UIMA integration module should have unit tests",
        "Type": "Task",
        "Status": "Open",
        "Priority": "Major",
        "Resolution": "Unresolved",
        "Affects Version/s": "None",
        "Fix Version/s": "None",
        "Component/s": "UIMA Integration",
        "Assignee": null,
        "Reporter": "Tommaso Teofili",
        "Created": "16/Nov/11 13:52",
        "Updated": "16/Dec/11 09:59",
        "Resolved": null,
        "Description": "OpenNLP UIMA integration module should have unit tests for basic things like: type systems, dummy executions (with small sample models), training, etc.",
        "Issue Links": []
    },
    "OPENNLP-386": {
        "Key": "OPENNLP-386",
        "Summary": "UIMA trainer should be able to dump the training data in the OpenNLP format to a file",
        "Type": "Improvement",
        "Status": "Closed",
        "Priority": "Minor",
        "Resolution": "Fixed",
        "Affects Version/s": "None",
        "Fix Version/s": "tools-1.5.3",
        "Component/s": "UIMA Integration",
        "Assignee": "J\u00f6rn Kottmann",
        "Reporter": "J\u00f6rn Kottmann",
        "Created": "16/Nov/11 15:12",
        "Updated": "21/Nov/11 13:19",
        "Resolved": "21/Nov/11 13:19",
        "Description": "The UIMA Integration is a great tool to train models with data in the Corpus Server (or any other source of annotated CASes), but it is currently not possible to use the evaluation tools in such a setup.\nTo make this easier the UIMA trainers should have an option to dump the training data in the OpenNLP format into a file. The user can then take this file and use it as input to the OpenNLP command line tools, such as evaluation, cross evaluation or trainers, e.g. to test a different feature generation.",
        "Issue Links": []
    },
    "OPENNLP-387": {
        "Key": "OPENNLP-387",
        "Summary": "Demonstration on how similarity component improves search accuracy. A query is run through Bing search API, and less relevant hits are sorted out by similarity measure between the query and the snippet",
        "Type": "Improvement",
        "Status": "Closed",
        "Priority": "Major",
        "Resolution": "Abandoned",
        "Affects Version/s": "1.6.0",
        "Fix Version/s": "None",
        "Component/s": "Similarity",
        "Assignee": "Boris Galitsky",
        "Reporter": "Boris Galitsky",
        "Created": "16/Nov/11 20:09",
        "Updated": "22/Apr/23 17:31",
        "Resolved": "22/Apr/23 17:31",
        "Description": "Right now we use a fancy domain to demonstrate the usability of similarity component, such as content generation based on web mining. I believe it also makes sense to use a simpler case such as search relevance improvement by use of similarity component. We get search candidates by TF*IDF and then apply OpenNLP parsing and then Similarity component to assess relevance of a snippet to an answer.",
        "Issue Links": []
    },
    "OPENNLP-388": {
        "Key": "OPENNLP-388",
        "Summary": "Add a view to assist with Part of Speech labeling",
        "Type": "Improvement",
        "Status": "Closed",
        "Priority": "Major",
        "Resolution": "Won't Fix",
        "Affects Version/s": "None",
        "Fix Version/s": "None",
        "Component/s": "Cas Editor OpenNLP Plugin",
        "Assignee": null,
        "Reporter": "J\u00f6rn Kottmann",
        "Created": "17/Nov/11 12:35",
        "Updated": "16/Jan/17 14:28",
        "Resolved": "16/Jan/17 14:28",
        "Description": "There should be a view which can assit the user with the labeling of Part of Speech tags.\nDetails of how that should be implemented still need to be worked out.",
        "Issue Links": []
    },
    "OPENNLP-389": {
        "Key": "OPENNLP-389",
        "Summary": "Add a view to assist with chunking",
        "Type": "Improvement",
        "Status": "Closed",
        "Priority": "Major",
        "Resolution": "Won't Fix",
        "Affects Version/s": "None",
        "Fix Version/s": "None",
        "Component/s": "Cas Editor OpenNLP Plugin",
        "Assignee": null,
        "Reporter": "J\u00f6rn Kottmann",
        "Created": "17/Nov/11 12:35",
        "Updated": "16/Jan/17 14:28",
        "Resolved": "16/Jan/17 14:28",
        "Description": "Add a view to assist the user with shallow parsing or chunking.\nDetails of how that should be implemented still need to be worked out.",
        "Issue Links": []
    },
    "OPENNLP-390": {
        "Key": "OPENNLP-390",
        "Summary": "Add a view to assist with parsing",
        "Type": "Improvement",
        "Status": "Closed",
        "Priority": "Major",
        "Resolution": "Won't Fix",
        "Affects Version/s": "None",
        "Fix Version/s": "None",
        "Component/s": "Cas Editor OpenNLP Plugin",
        "Assignee": null,
        "Reporter": "J\u00f6rn Kottmann",
        "Created": "17/Nov/11 12:36",
        "Updated": "16/Jan/17 14:29",
        "Resolved": "16/Jan/17 14:29",
        "Description": "There should be a view which can assit the user with parsing a sentence.\nDetails of how that should be implemented still need to be worked out.",
        "Issue Links": []
    },
    "OPENNLP-391": {
        "Key": "OPENNLP-391",
        "Summary": "Add a view to assist with coreference resolution",
        "Type": "Improvement",
        "Status": "Closed",
        "Priority": "Major",
        "Resolution": "Won't Fix",
        "Affects Version/s": "None",
        "Fix Version/s": "None",
        "Component/s": "Cas Editor OpenNLP Plugin",
        "Assignee": null,
        "Reporter": "J\u00f6rn Kottmann",
        "Created": "17/Nov/11 12:41",
        "Updated": "16/Jan/17 14:28",
        "Resolved": "16/Jan/17 14:28",
        "Description": "There should be a view which can assit the user with coreference resolution.\nDetails of how that should be implemented still need to be worked out.",
        "Issue Links": []
    },
    "OPENNLP-392": {
        "Key": "OPENNLP-392",
        "Summary": "Sentence and Entity list loose selection after confirm",
        "Type": "Improvement",
        "Status": "Closed",
        "Priority": "Minor",
        "Resolution": "Fixed",
        "Affects Version/s": "None",
        "Fix Version/s": "None",
        "Component/s": "Cas Editor OpenNLP Plugin",
        "Assignee": "J\u00f6rn Kottmann",
        "Reporter": "J\u00f6rn Kottmann",
        "Created": "17/Nov/11 16:17",
        "Updated": "18/Nov/11 11:43",
        "Resolved": "18/Nov/11 11:43",
        "Description": "After a user confirmed a sentence or an entity the selection in the list is lost. Update the implementation to maintain the selection. A user should be able to label via continuously pressing \"Enter\".",
        "Issue Links": []
    },
    "OPENNLP-393": {
        "Key": "OPENNLP-393",
        "Summary": "Add a contributions wanted page to our website",
        "Type": "Task",
        "Status": "Closed",
        "Priority": "Major",
        "Resolution": "Fixed",
        "Affects Version/s": "None",
        "Fix Version/s": "None",
        "Component/s": "Website",
        "Assignee": "Bruno P. Kinoshita",
        "Reporter": "J\u00f6rn Kottmann",
        "Created": "19/Nov/11 15:58",
        "Updated": "16/May/17 13:35",
        "Resolved": "11/May/17 14:28",
        "Description": "OpenNLP would like to get more contributions from the community to encourage people to contribute more we should add a page which lists things which should be done in OpenNLP.",
        "Issue Links": [
            "/jira/browse/OPENNLP-999",
            "https://github.com/apache/opennlp-site/pull/5"
        ]
    },
    "OPENNLP-394": {
        "Key": "OPENNLP-394",
        "Summary": "Name Finder cross validation should be done on a document level",
        "Type": "Bug",
        "Status": "Closed",
        "Priority": "Major",
        "Resolution": "Fixed",
        "Affects Version/s": "None",
        "Fix Version/s": "tools-1.5.3",
        "Component/s": "Name Finder",
        "Assignee": "J\u00f6rn Kottmann",
        "Reporter": "J\u00f6rn Kottmann",
        "Created": "21/Nov/11 13:03",
        "Updated": "22/Nov/11 14:04",
        "Resolved": "22/Nov/11 14:04",
        "Description": "The Name Finder Cross Validate tool should do the cross validation on a document level, and not sentence level.\nThe name finder has adaptive data per document to generate features based on previously detected names. This data cannot be computed correctly when the cross validation is done on a sentence level.\nTo fix this enhance the implementation to work on a document level.",
        "Issue Links": []
    },
    "OPENNLP-395": {
        "Key": "OPENNLP-395",
        "Summary": "UIMA Name Finder trainer does not set clear adaptive data flag correctly",
        "Type": "Bug",
        "Status": "Closed",
        "Priority": "Major",
        "Resolution": "Fixed",
        "Affects Version/s": "None",
        "Fix Version/s": "tools-1.5.3",
        "Component/s": "Name Finder,                                            UIMA Integration",
        "Assignee": "J\u00f6rn Kottmann",
        "Reporter": "J\u00f6rn Kottmann",
        "Created": "21/Nov/11 13:05",
        "Updated": "21/Nov/11 13:20",
        "Resolved": "21/Nov/11 13:20",
        "Description": "The Name Finde Trainer integration does not set the clear adaptive data flag correctly.",
        "Issue Links": []
    },
    "OPENNLP-396": {
        "Key": "OPENNLP-396",
        "Summary": "Name Finder evaluator does not work with old data format",
        "Type": "Bug",
        "Status": "Closed",
        "Priority": "Major",
        "Resolution": "Fixed",
        "Affects Version/s": "None",
        "Fix Version/s": "tools-1.5.3",
        "Component/s": "Name Finder",
        "Assignee": "J\u00f6rn Kottmann",
        "Reporter": "J\u00f6rn Kottmann",
        "Created": "21/Nov/11 14:07",
        "Updated": "21/Nov/11 19:59",
        "Resolved": "21/Nov/11 19:59",
        "Description": "The Name Finder evaluator does not work with the old training format. In the old format the start tag does not include a type.\nIn this case the reference span has \"null\" as type and the returned type from the Name Finder has \"default\" as the type value.",
        "Issue Links": []
    },
    "OPENNLP-397": {
        "Key": "OPENNLP-397",
        "Summary": "IndexHashTable can be improved",
        "Type": "Improvement",
        "Status": "Closed",
        "Priority": "Minor",
        "Resolution": "Won't Fix",
        "Affects Version/s": "maxent-3.0.3",
        "Fix Version/s": "None",
        "Component/s": "Machine Learning",
        "Assignee": "J\u00f6rn Kottmann",
        "Reporter": "Catalin Mititelu",
        "Created": "21/Nov/11 14:23",
        "Updated": "08/Nov/16 12:02",
        "Resolved": "08/Nov/16 12:02",
        "Description": "Running a profiler on POSTagger with an maxent model showed me a lot of CPU usage on IndexHashTable class. This class can be optimized to be faster.",
        "Issue Links": []
    },
    "OPENNLP-398": {
        "Key": "OPENNLP-398",
        "Summary": "Add a sample trainer parameter file to the lang package",
        "Type": "Improvement",
        "Status": "Closed",
        "Priority": "Minor",
        "Resolution": "Fixed",
        "Affects Version/s": "None",
        "Fix Version/s": "tools-1.5.3",
        "Component/s": "Machine Learning",
        "Assignee": "J\u00f6rn Kottmann",
        "Reporter": "J\u00f6rn Kottmann",
        "Created": "21/Nov/11 16:54",
        "Updated": "21/Nov/11 16:54",
        "Resolved": "21/Nov/11 16:54",
        "Description": "There should be a sample file for trainer params in the lang package.",
        "Issue Links": []
    },
    "OPENNLP-399": {
        "Key": "OPENNLP-399",
        "Summary": "Feature generator xml description should support definition of suffix and prefix generator",
        "Type": "Improvement",
        "Status": "Closed",
        "Priority": "Minor",
        "Resolution": "Fixed",
        "Affects Version/s": "None",
        "Fix Version/s": "tools-1.5.3",
        "Component/s": "Name Finder",
        "Assignee": "J\u00f6rn Kottmann",
        "Reporter": "J\u00f6rn Kottmann",
        "Created": "22/Nov/11 09:35",
        "Updated": "22/Nov/11 11:23",
        "Resolved": "22/Nov/11 11:23",
        "Description": "It should be possible to define the prefix and suffix feature generators inside the feature generator xml description.",
        "Issue Links": []
    },
    "OPENNLP-400": {
        "Key": "OPENNLP-400",
        "Summary": "Add a sample feature generator description for German",
        "Type": "Improvement",
        "Status": "Closed",
        "Priority": "Minor",
        "Resolution": "Fixed",
        "Affects Version/s": "None",
        "Fix Version/s": "tools-1.5.3",
        "Component/s": "Name Finder",
        "Assignee": "J\u00f6rn Kottmann",
        "Reporter": "J\u00f6rn Kottmann",
        "Created": "22/Nov/11 10:28",
        "Updated": "22/Nov/11 10:29",
        "Resolved": "22/Nov/11 10:29",
        "Description": "Add a feature generator descriptor which is optimized for German. Compared to English it is important to use the Suffix and Prefix feature generators.",
        "Issue Links": []
    },
    "OPENNLP-401": {
        "Key": "OPENNLP-401",
        "Summary": "Name Finder view should not set selection when annotation in editor was added",
        "Type": "Improvement",
        "Status": "Closed",
        "Priority": "Minor",
        "Resolution": "Fixed",
        "Affects Version/s": "None",
        "Fix Version/s": "None",
        "Component/s": "Cas Editor OpenNLP Plugin",
        "Assignee": "J\u00f6rn Kottmann",
        "Reporter": "J\u00f6rn Kottmann",
        "Created": "22/Nov/11 12:22",
        "Updated": "22/Nov/11 14:03",
        "Resolved": "22/Nov/11 14:03",
        "Description": "The Name Finder view sets the selection if an annotation in the editor or another view was confirmed. In this case the editor might jump to the newly selected annotation which causes the loose of focus. The user needs to scroll back to the last edit location, which can be an annoying experience.",
        "Issue Links": []
    },
    "OPENNLP-402": {
        "Key": "OPENNLP-402",
        "Summary": "CLI tools and formats refactored",
        "Type": "Improvement",
        "Status": "Closed",
        "Priority": "Major",
        "Resolution": "Fixed",
        "Affects Version/s": "tools-1.5.3",
        "Fix Version/s": "tools-1.5.3",
        "Component/s": "Command Line Interface,                                            Formats",
        "Assignee": "J\u00f6rn Kottmann",
        "Reporter": "Aliaksandr Autayeu",
        "Created": "22/Nov/11 23:51",
        "Updated": "26/Mar/18 13:01",
        "Resolved": "20/Dec/12 23:04",
        "Description": "Proposed patch refactors CLI tools and simplifies the code by introducing hierarchy and removing a lot of code duplication. It also introduces better error and help messages, including help for formats and listing available formats in various tools, which are now able to work with formats directly. This, in turn, eliminates the need to keep converted files on disk.",
        "Issue Links": []
    },
    "OPENNLP-403": {
        "Key": "OPENNLP-403",
        "Summary": "Token feature generation is not working when using feature generator descriptor",
        "Type": "Bug",
        "Status": "Closed",
        "Priority": "Major",
        "Resolution": "Fixed",
        "Affects Version/s": "tools-1.5.2-incubating",
        "Fix Version/s": "tools-1.5.3",
        "Component/s": "Name Finder",
        "Assignee": "J\u00f6rn Kottmann",
        "Reporter": "J\u00f6rn Kottmann",
        "Created": "23/Nov/11 09:58",
        "Updated": "23/Nov/11 10:08",
        "Resolved": "23/Nov/11 10:08",
        "Description": "The xml feature generator descriptor does not map the token feature generator correctly.",
        "Issue Links": []
    },
    "OPENNLP-404": {
        "Key": "OPENNLP-404",
        "Summary": "Explain generic usage of OpenNLP in introduction",
        "Type": "Improvement",
        "Status": "Closed",
        "Priority": "Minor",
        "Resolution": "Fixed",
        "Affects Version/s": "None",
        "Fix Version/s": "tools-1.5.3",
        "Component/s": "Documentation",
        "Assignee": "Aliaksandr Autayeu",
        "Reporter": "J\u00f6rn Kottmann",
        "Created": "30/Nov/11 10:27",
        "Updated": "01/Dec/11 20:42",
        "Resolved": "01/Dec/11 20:42",
        "Description": "The introduction of the docbook should be extended and explain the generic usage of OpenNLP.",
        "Issue Links": []
    },
    "OPENNLP-405": {
        "Key": "OPENNLP-405",
        "Summary": "Name Finder view should list ambiguous entity with highest confidence first.",
        "Type": "Improvement",
        "Status": "Closed",
        "Priority": "Minor",
        "Resolution": "Won't Fix",
        "Affects Version/s": "None",
        "Fix Version/s": "None",
        "Component/s": "Cas Editor OpenNLP Plugin",
        "Assignee": null,
        "Reporter": "J\u00f6rn Kottmann",
        "Created": "30/Nov/11 14:30",
        "Updated": "16/Jan/17 14:30",
        "Resolved": "16/Jan/17 14:30",
        "Description": "The name finder might be unsure about the type of an entity mention. In this case both proposed entities are shown in the entity list. In this list the entity with the highest confidence should be listed first.",
        "Issue Links": []
    },
    "OPENNLP-406": {
        "Key": "OPENNLP-406",
        "Summary": "Dev version 0.0.0-SNAPSHOT should never fail model loading",
        "Type": "Improvement",
        "Status": "Closed",
        "Priority": "Minor",
        "Resolution": "Fixed",
        "Affects Version/s": "None",
        "Fix Version/s": "tools-1.5.3",
        "Component/s": "None",
        "Assignee": "J\u00f6rn Kottmann",
        "Reporter": "J\u00f6rn Kottmann",
        "Created": "01/Dec/11 11:01",
        "Updated": "01/Dec/11 11:21",
        "Resolved": "01/Dec/11 11:21",
        "Description": "When OpenNLP is running in a debugger it uses 0.0.0-SNAPSHOT as the version. In this version it should never fail loading any models.",
        "Issue Links": []
    },
    "OPENNLP-407": {
        "Key": "OPENNLP-407",
        "Summary": "Restore old Name Finder tool which is needed by TreebankLinker",
        "Type": "Improvement",
        "Status": "Closed",
        "Priority": "Minor",
        "Resolution": "Fixed",
        "Affects Version/s": "None",
        "Fix Version/s": "tools-1.5.3",
        "Component/s": "Coref",
        "Assignee": "J\u00f6rn Kottmann",
        "Reporter": "J\u00f6rn Kottmann",
        "Created": "01/Dec/11 11:46",
        "Updated": "01/Dec/11 11:47",
        "Resolved": "01/Dec/11 11:47",
        "Description": "In 1.4 the Name Finder could process parsed sentences and add the detected names to it. This tool was removed in 1.5, but is still needed to run the TreebankLinker.\nLets restore this tool and update it to work with the new name finder models.",
        "Issue Links": []
    },
    "OPENNLP-408": {
        "Key": "OPENNLP-408",
        "Summary": "Sentence Detector view should not set selection when something in the editor is changed",
        "Type": "Improvement",
        "Status": "Closed",
        "Priority": "Major",
        "Resolution": "Fixed",
        "Affects Version/s": "None",
        "Fix Version/s": "None",
        "Component/s": "Cas Editor OpenNLP Plugin",
        "Assignee": "J\u00f6rn Kottmann",
        "Reporter": "J\u00f6rn Kottmann",
        "Created": "01/Dec/11 15:47",
        "Updated": "01/Dec/11 15:53",
        "Resolved": "01/Dec/11 15:53",
        "Description": "The text in the editor is selected again after an annotation changed. The Sentence Detector view should not do that. Selection should only be updated when the Sentence Detector view is currently active.",
        "Issue Links": []
    },
    "OPENNLP-409": {
        "Key": "OPENNLP-409",
        "Summary": "Name Finder view needs to indicate inside the Annotation Editor which type the entity will have",
        "Type": "Improvement",
        "Status": "Closed",
        "Priority": "Major",
        "Resolution": "Won't Fix",
        "Affects Version/s": "None",
        "Fix Version/s": "None",
        "Component/s": "Cas Editor OpenNLP Plugin",
        "Assignee": "J\u00f6rn Kottmann",
        "Reporter": "J\u00f6rn Kottmann",
        "Created": "01/Dec/11 16:07",
        "Updated": "16/Jan/17 14:28",
        "Resolved": "16/Jan/17 14:28",
        "Description": "Currently the Name Finder view selects the covered text of the entity which will be created, but it is unknown to the user which type the new entity will have. Once in the while the proposed entity type is incorrect. Therefore the user needs to check by looking at the name finder view which type the entity will have which cumbersome, because the user always looses the focus.\nIt should be indicated directly in the Annotation Editor which type the proposed entity will have.",
        "Issue Links": []
    },
    "OPENNLP-410": {
        "Key": "OPENNLP-410",
        "Summary": "Refactor the Entity class to make it reusable",
        "Type": "Improvement",
        "Status": "Closed",
        "Priority": "Minor",
        "Resolution": "Fixed",
        "Affects Version/s": "None",
        "Fix Version/s": "None",
        "Component/s": "Cas Editor OpenNLP Plugin",
        "Assignee": "J\u00f6rn Kottmann",
        "Reporter": "J\u00f6rn Kottmann",
        "Created": "02/Dec/11 11:36",
        "Updated": "02/Dec/11 13:17",
        "Resolved": "02/Dec/11 13:17",
        "Description": "The Entity class was created for the name finder view, and the semantics of it changed after the first testing of the view. Now it is just a potential annotation which a user might add to the CAS and is also used by the sentence detector view.\nTo reflect this the class should be renamed to PotentialAnnotation and old left over artifacts should be removed.",
        "Issue Links": []
    },
    "OPENNLP-411": {
        "Key": "OPENNLP-411",
        "Summary": "Update Cas Editor Plugins to be based on 2.4.0",
        "Type": "Task",
        "Status": "Closed",
        "Priority": "Minor",
        "Resolution": "Fixed",
        "Affects Version/s": "None",
        "Fix Version/s": "None",
        "Component/s": "Cas Editor Corpus Server Plugin,                                            Cas Editor OpenNLP Plugin",
        "Assignee": "J\u00f6rn Kottmann",
        "Reporter": "J\u00f6rn Kottmann",
        "Created": "08/Dec/11 12:21",
        "Updated": "02/Mar/12 08:37",
        "Resolved": "02/Mar/12 08:37",
        "Description": "The Cas Editor is now released as part of Apache UIMA 2.4.0. The two Cas Editor plugins should be updated to depend on the release version. This will lower the entry barrier for new users because they do not need to download and build a UIMA trunk version.",
        "Issue Links": []
    },
    "OPENNLP-412": {
        "Key": "OPENNLP-412",
        "Summary": "Code Style Checking Plugins",
        "Type": "Improvement",
        "Status": "Closed",
        "Priority": "Minor",
        "Resolution": "Fixed",
        "Affects Version/s": "None",
        "Fix Version/s": "None",
        "Component/s": "Build, Packaging and Test",
        "Assignee": null,
        "Reporter": "James Kosin",
        "Created": "16/Dec/11 03:17",
        "Updated": "18/Dec/11 03:46",
        "Resolved": "18/Dec/11 03:46",
        "Description": "Would be nice to include and use a plugin to validate style.\nMaven supports here:\nhttp://maven.apache.org/plugins/maven-checkstyle-plugin/",
        "Issue Links": []
    },
    "OPENNLP-413": {
        "Key": "OPENNLP-413",
        "Summary": "demonstration how sensitive syntactic match is compared to bag-of-words approach",
        "Type": "Improvement",
        "Status": "Closed",
        "Priority": "Major",
        "Resolution": "Fixed",
        "Affects Version/s": "None",
        "Fix Version/s": "None",
        "Component/s": "Similarity",
        "Assignee": "Boris Galitsky",
        "Reporter": "Boris Galitsky",
        "Created": "19/Dec/11 11:23",
        "Updated": "03/Apr/13 08:43",
        "Resolved": "22/Mar/12 17:27",
        "Description": "per Jason's recommendation:  have you done\n> standard similarity based on the standard bag-of-words model?\nI do simple bag-of-words with its own list of stopwords and compare two approaches on the pair of  cases:\n1) similar words but different meaning\n2) different words but similar meaning",
        "Issue Links": []
    },
    "OPENNLP-414": {
        "Key": "OPENNLP-414",
        "Summary": "Measure of phrase meaningfulness by web mining and search results similarity",
        "Type": "New Feature",
        "Status": "Closed",
        "Priority": "Major",
        "Resolution": "Fixed",
        "Affects Version/s": "None",
        "Fix Version/s": "None",
        "Component/s": "Similarity",
        "Assignee": "Boris Galitsky",
        "Reporter": "Boris Galitsky",
        "Created": "19/Dec/11 15:05",
        "Updated": "03/Apr/13 08:43",
        "Resolved": "22/Mar/12 17:25",
        "Description": "State-of-art speech recognition systems like Nuance, Dragon, Google, etc give a set of speech-to-text results, some of them are meaningful, and some are not. This component does semantic confirmation/rejection of speech recognition candidates based on their presence on the web. This is one more application of Similarity component to solve problems which are hard to tackle otherwise.",
        "Issue Links": []
    },
    "OPENNLP-415": {
        "Key": "OPENNLP-415",
        "Summary": "NameFinder Dictionary Search Not Working Correctly",
        "Type": "Bug",
        "Status": "Closed",
        "Priority": "Major",
        "Resolution": "Fixed",
        "Affects Version/s": "tools-1.5.1-incubating,                                            tools-1.5.2-incubating",
        "Fix Version/s": "tools-1.5.3",
        "Component/s": "Name Finder",
        "Assignee": "James Kosin",
        "Reporter": "James Kosin",
        "Created": "21/Dec/11 04:30",
        "Updated": "21/Dec/11 05:27",
        "Resolved": "21/Dec/11 05:26",
        "Description": "With a case_sensitive=\"false\" dictionary, the DictionaryNameFinder wrongly doesn't find the correct name.\nThanks to Loic Descotte for finding this bug.\nA Dictionary containing \"tamato\" and a sentence containing \"Tamato\" does not correctly find the name.\nThe bug was traced to a reworked MetaDictionary that tries to filter the sentece tokens based on presence in the dictionary.  This new dictionary however is case sensitive.",
        "Issue Links": []
    },
    "OPENNLP-416": {
        "Key": "OPENNLP-416",
        "Summary": "openlp.ml sandbox code should compile",
        "Type": "Task",
        "Status": "Closed",
        "Priority": "Major",
        "Resolution": "Fixed",
        "Affects Version/s": "None",
        "Fix Version/s": "None",
        "Component/s": "Machine Learning",
        "Assignee": "Jason Baldridge",
        "Reporter": "Jason Baldridge",
        "Created": "30/Dec/11 20:07",
        "Updated": "18/Feb/14 13:27",
        "Resolved": "18/Feb/14 13:24",
        "Description": "The test code needs to get the org.apache.opennlp.ml prefix. The pom needs to be updated to work.",
        "Issue Links": []
    },
    "OPENNLP-417": {
        "Key": "OPENNLP-417",
        "Summary": "Back-to-Back <START><END> tags get improperly set when tagging",
        "Type": "Bug",
        "Status": "Closed",
        "Priority": "Major",
        "Resolution": "Fixed",
        "Affects Version/s": "tools-1.5.1-incubating,                                            tools-1.5.2-incubating",
        "Fix Version/s": "tools-1.5.3",
        "Component/s": "Name Finder",
        "Assignee": "James Kosin",
        "Reporter": "James Kosin",
        "Created": "05/Jan/12 03:33",
        "Updated": "05/Jan/12 04:53",
        "Resolved": "05/Jan/12 04:50",
        "Description": "1) Special thanks go to Angel Luis Jimenez Martinez for both finding the problem, and finding the one line of code that caused this problem.\nThis only affects the TokenNameFinder when parsing user input and tagging the output.\nThe problem was when the name finder model returns the spans, it would properly find the Spans and return them; however, it would improperly label the Spans when constructing them, if they where back-to-back.\nThis can cause the NameFinder to improperly report the wrong tag in this situation.",
        "Issue Links": []
    },
    "OPENNLP-418": {
        "Key": "OPENNLP-418",
        "Summary": "CrossValidator tools argument parser not working with minimun arguments",
        "Type": "Bug",
        "Status": "Closed",
        "Priority": "Major",
        "Resolution": "Fixed",
        "Affects Version/s": "tools-1.5.3",
        "Fix Version/s": "tools-1.5.3",
        "Component/s": "Command Line Interface",
        "Assignee": "Aliaksandr Autayeu",
        "Reporter": "William Colen",
        "Created": "16/Jan/12 13:42",
        "Updated": "22/Jan/12 20:35",
        "Resolved": "22/Jan/12 10:52",
        "Description": "The minimun arguments to run a cross validator tool from command line are \"lang\" and \"data\", but using only these causes an exception:\n$ bin/opennlp SentenceDetectorCrossValidator -lang pt -data sent.txt\nException in thread \"main\" java.lang.IllegalArgumentException: Passed args must be valid!\n\tat opennlp.tools.cmdline.ArgumentParser.parse(ArgumentParser.java:385)\n\tat opennlp.tools.cmdline.AbstractTrainerTool.run(AbstractTrainerTool.java:46)\n\tat opennlp.tools.cmdline.sentdetect.SentenceDetectorCrossValidatorTool.run(SentenceDetectorCrossValidatorTool.java:49)\n\tat opennlp.tools.cmdline.CLI.main(CLI.java:212)",
        "Issue Links": []
    },
    "OPENNLP-419": {
        "Key": "OPENNLP-419",
        "Summary": "readme.txt + more code comments for similarity component",
        "Type": "Improvement",
        "Status": "Closed",
        "Priority": "Major",
        "Resolution": "Fixed",
        "Affects Version/s": "None",
        "Fix Version/s": "None",
        "Component/s": "Similarity",
        "Assignee": "Boris Galitsky",
        "Reporter": "Boris Galitsky",
        "Created": "20/Jan/12 23:33",
        "Updated": "03/Apr/13 08:43",
        "Resolved": "23/Mar/12 18:48",
        "Description": "write readme.txt which will introduce potential users to the Component",
        "Issue Links": []
    },
    "OPENNLP-420": {
        "Key": "OPENNLP-420",
        "Summary": "Caching for parsing, chunking and phrase grouping",
        "Type": "Improvement",
        "Status": "Closed",
        "Priority": "Major",
        "Resolution": "Fixed",
        "Affects Version/s": "None",
        "Fix Version/s": "None",
        "Component/s": "Similarity",
        "Assignee": "Boris Galitsky",
        "Reporter": "Boris Galitsky",
        "Created": "20/Jan/12 23:58",
        "Updated": "03/Apr/13 08:43",
        "Resolved": "23/Mar/12 18:33",
        "Description": "to speed up similarity computation, store parsing results in a hash, so that if a sentence has been parsed, chunked and prepared for matching once, we store it in a hash.\nwhen the Processor is instantiated, hash is deserialized. When the processor is closed, this hash is serialized.",
        "Issue Links": []
    },
    "OPENNLP-421": {
        "Key": "OPENNLP-421",
        "Summary": "Large dictionaries cause JVM OutOfMemoryError: PermGen due to String interning",
        "Type": "Bug",
        "Status": "Open",
        "Priority": "Minor",
        "Resolution": "Unresolved",
        "Affects Version/s": "tools-1.5.2-incubating",
        "Fix Version/s": "None",
        "Component/s": "Name Finder",
        "Assignee": null,
        "Reporter": "Jay Hacker",
        "Created": "01/Feb/12 20:07",
        "Updated": "16/Sep/13 10:35",
        "Resolved": null,
        "Description": "The current implementation of StringList:\nhttps://svn.apache.org/viewvc/incubator/opennlp/branches/opennlp-1.5.2-incubating/opennlp-tools/src/main/java/opennlp/tools/util/StringList.java?view=markup \ncalls intern() on every String.  Presumably this is an attempt to reduce memory usage for duplicate tokens.  Interned Strings are stored in the JVM's permanent generation, which has a small fixed size (seems to be about 83 MB on modern 64-bit JVMs: http://www.oracle.com/technetwork/java/javase/tech/vmoptions-jsp-140102.html).  Once this fills up, the JVM crashes with an OutOfMemoryError: PermGen space.  \nThe size of the PermGen can be increased with the -XX:MaxPermSize= option to the JVM.  However, this option is non-standard and not well known, and it would be nice if OpenNLP worked out of the box without deep JVM tuning.\nThis immediate problem could be fixed by simply not interning Strings.  Looking at the Dictionary and DictionaryNameFinder code as a whole, however, there is a huge amount of room for performance improvement.  Currently, DictionaryNameFinder.find works something like this:\nfor every token in every tokenlist in the dictionary:\n    copy it into a \"meta dictionary\" of single tokens\nfor every possible subsequence of tokens in the sentence:        // of which there are O(N^2)\n    copy the sequence into a new array\n    if the last token is in the \"meta dictionary\":\n        make a StringList from the tokens\n        look it up in the dictionary\nDictionary itself is very heavyweight: it's a Set<StringListWrapper>, which wraps StringList, which wraps Array<String>.  Every entry in the dictionary requires at least four allocated objects (in addition to the Strings): Array, StringList, StringListWrapper, and HashMap.Entry.  Even contains and remove allocate new objects!\nFrom this comment in DictionaryNameFinder:\n        // TODO: improve performance here\nIt seems like improvements would be welcome.    Removing some of the object overhead would more than make up for interning strings.  Should I create a new Jira ticket to propose a more efficient design?",
        "Issue Links": []
    },
    "OPENNLP-422": {
        "Key": "OPENNLP-422",
        "Summary": "Include a formater that creates a stream of SentenceSample from AD corpus",
        "Type": "Improvement",
        "Status": "Closed",
        "Priority": "Minor",
        "Resolution": "Fixed",
        "Affects Version/s": "tools-1.5.3",
        "Fix Version/s": "tools-1.5.3",
        "Component/s": "Formats",
        "Assignee": "William Colen",
        "Reporter": "William Colen",
        "Created": "03/Feb/12 22:55",
        "Updated": "05/Feb/12 14:05",
        "Resolved": "05/Feb/12 14:05",
        "Description": "This can be used to train a Portuguese Sentence Detector model.",
        "Issue Links": []
    },
    "OPENNLP-423": {
        "Key": "OPENNLP-423",
        "Summary": "Improve Portuguese NameSample and ChunkSample formatters",
        "Type": "Improvement",
        "Status": "Closed",
        "Priority": "Minor",
        "Resolution": "Fixed",
        "Affects Version/s": "tools-1.5.3",
        "Fix Version/s": "tools-1.5.3",
        "Component/s": "Formats",
        "Assignee": "William Colen",
        "Reporter": "William Colen",
        "Created": "04/Feb/12 01:47",
        "Updated": "05/Feb/12 10:07",
        "Resolved": "05/Feb/12 10:07",
        "Description": "I found some issues with the Portuguese NameSample and ChunkSample formaters.",
        "Issue Links": []
    },
    "OPENNLP-424": {
        "Key": "OPENNLP-424",
        "Summary": "Include a formatter that creates a stream of POSSample from AD corpus",
        "Type": "Improvement",
        "Status": "Closed",
        "Priority": "Minor",
        "Resolution": "Fixed",
        "Affects Version/s": "tools-1.5.3",
        "Fix Version/s": "tools-1.5.3",
        "Component/s": "Formats",
        "Assignee": "William Colen",
        "Reporter": "William Colen",
        "Created": "04/Feb/12 16:10",
        "Updated": "04/Feb/12 19:13",
        "Resolved": "04/Feb/12 19:11",
        "Description": "This can be used to train a Portuguese POS Tagger model",
        "Issue Links": []
    },
    "OPENNLP-425": {
        "Key": "OPENNLP-425",
        "Summary": "Create sample descriptor for Parser Analysis Engine",
        "Type": "Improvement",
        "Status": "Closed",
        "Priority": "Minor",
        "Resolution": "Fixed",
        "Affects Version/s": "tools-1.5.2-incubating",
        "Fix Version/s": "tools-1.5.3",
        "Component/s": "Parser,                                            UIMA Integration",
        "Assignee": "J\u00f6rn Kottmann",
        "Reporter": "J\u00f6rn Kottmann",
        "Created": "07/Feb/12 12:51",
        "Updated": "10/Feb/12 09:06",
        "Resolved": "10/Feb/12 09:06",
        "Description": "Write a sample descriptor for the parser and define the Parser type in the sample OpenNLP type system.",
        "Issue Links": []
    },
    "OPENNLP-426": {
        "Key": "OPENNLP-426",
        "Summary": "Parse.insert method should not throw an InternalError",
        "Type": "Improvement",
        "Status": "Closed",
        "Priority": "Major",
        "Resolution": "Fixed",
        "Affects Version/s": "None",
        "Fix Version/s": "tools-1.5.3",
        "Component/s": "Parser",
        "Assignee": "J\u00f6rn Kottmann",
        "Reporter": "J\u00f6rn Kottmann",
        "Created": "07/Feb/12 16:01",
        "Updated": "08/Feb/12 08:27",
        "Resolved": "08/Feb/12 08:27",
        "Description": "The Parse.insert method should not throw an InternalError to indicate that it cannot handle the passed in Parse object.\nThe appropriate exception in this case would IllegalArgumentException.",
        "Issue Links": []
    },
    "OPENNLP-427": {
        "Key": "OPENNLP-427",
        "Summary": "UIMA Parser integration fails if document does not has sentences or tokens",
        "Type": "Bug",
        "Status": "Closed",
        "Priority": "Minor",
        "Resolution": "Fixed",
        "Affects Version/s": "None",
        "Fix Version/s": "tools-1.5.3",
        "Component/s": "Parser,                                            UIMA Integration",
        "Assignee": "J\u00f6rn Kottmann",
        "Reporter": "J\u00f6rn Kottmann",
        "Created": "08/Feb/12 09:40",
        "Updated": "08/Feb/12 09:54",
        "Resolved": "08/Feb/12 09:54",
        "Description": "The Parser integration should not do anything when the CAS is missing the necessary input sentences and tokens.\nCurrently it throws exceptions when this happens.",
        "Issue Links": []
    },
    "OPENNLP-428": {
        "Key": "OPENNLP-428",
        "Summary": "make EOS character set configurable",
        "Type": "Improvement",
        "Status": "Closed",
        "Priority": "Minor",
        "Resolution": "Fixed",
        "Affects Version/s": "None",
        "Fix Version/s": "tools-1.5.3",
        "Component/s": "Sentence Detector",
        "Assignee": "William Colen",
        "Reporter": "Katrin Tomanek",
        "Created": "09/Feb/12 10:10",
        "Updated": "05/Jul/12 17:03",
        "Resolved": "18/Mar/12 14:58",
        "Description": "Currently, the EOS symbols to be used by the sentence detector cannot be configured (at the moment, a user would have to make changes in opennlp.tools.sentdetect.lang.Factory\nSince it is important to use the same EOS symbols during training and during testing/prediction, the EOS symbols should be stored with the model's properties",
        "Issue Links": []
    },
    "OPENNLP-429": {
        "Key": "OPENNLP-429",
        "Summary": "Create a Factory to customize the POS Tagger",
        "Type": "New Feature",
        "Status": "Closed",
        "Priority": "Minor",
        "Resolution": "Fixed",
        "Affects Version/s": "tools-1.5.3",
        "Fix Version/s": "tools-1.5.3",
        "Component/s": "Command Line Interface,                                            POS Tagger",
        "Assignee": "William Colen",
        "Reporter": "William Colen",
        "Created": "09/Feb/12 13:14",
        "Updated": "22/Feb/12 19:43",
        "Resolved": "22/Feb/12 19:43",
        "Description": "Should provide a mechanism to customize the POS Tagger using a factory. The component should get the following objects from the factory:\n\nContext Generator\nSequence Validator\nPOS Dictionary implementation\n\nOne issue to solve is how to initialize the objects. For example, the Sequence Validator might be initialized using a POS Dictionary.",
        "Issue Links": []
    },
    "OPENNLP-430": {
        "Key": "OPENNLP-430",
        "Summary": "It is missing a way to set case sensitivity while creating a POSDictionary",
        "Type": "Improvement",
        "Status": "Closed",
        "Priority": "Minor",
        "Resolution": "Fixed",
        "Affects Version/s": "tools-1.5.3",
        "Fix Version/s": "tools-1.5.3",
        "Component/s": "POS Tagger",
        "Assignee": "William Colen",
        "Reporter": "William Colen",
        "Created": "09/Feb/12 20:38",
        "Updated": "09/Feb/12 20:45",
        "Resolved": "09/Feb/12 20:45",
        "Description": "It is missing a way to set case sensitivity while creating a POSDictionary. We should add an argument to the constructor like we do with Dictionary.",
        "Issue Links": []
    },
    "OPENNLP-431": {
        "Key": "OPENNLP-431",
        "Summary": "Debugging is slow if using a POSDictionary",
        "Type": "Bug",
        "Status": "Closed",
        "Priority": "Minor",
        "Resolution": "Fixed",
        "Affects Version/s": "tools-1.5.3",
        "Fix Version/s": "tools-1.5.3",
        "Component/s": "POS Tagger",
        "Assignee": "William Colen",
        "Reporter": "William Colen",
        "Created": "09/Feb/12 21:01",
        "Updated": "27/Feb/12 16:26",
        "Resolved": "27/Feb/12 16:26",
        "Description": "Debugging is too slow if using a POSDictionary because of its toString() method. The IDE calls it to show variables values. The current implementation of toString creates a huge string with all dictionary entries.\nWe should reduce it to just a few entries.",
        "Issue Links": []
    },
    "OPENNLP-432": {
        "Key": "OPENNLP-432",
        "Summary": "POSModel validation should inform the invalid POS tags of the POSDictionary",
        "Type": "Improvement",
        "Status": "Closed",
        "Priority": "Minor",
        "Resolution": "Fixed",
        "Affects Version/s": "tools-1.5.3",
        "Fix Version/s": "tools-1.5.3",
        "Component/s": "POS Tagger",
        "Assignee": "William Colen",
        "Reporter": "William Colen",
        "Created": "10/Feb/12 02:24",
        "Updated": "10/Feb/12 02:27",
        "Resolved": "10/Feb/12 02:27",
        "Description": "POSModel validation should inform the invalid POS tags of the POSDictionary. Today it simply fails with an exception if the dictionary contains invalid tags, but would be helpful to specify which tags are invalid.",
        "Issue Links": []
    },
    "OPENNLP-433": {
        "Key": "OPENNLP-433",
        "Summary": "Parser should insert all nodes into CAS",
        "Type": "Improvement",
        "Status": "Closed",
        "Priority": "Trivial",
        "Resolution": "Fixed",
        "Affects Version/s": "None",
        "Fix Version/s": "tools-1.5.3",
        "Component/s": "Parser,                                            UIMA Integration",
        "Assignee": "J\u00f6rn Kottmann",
        "Reporter": "J\u00f6rn Kottmann",
        "Created": "10/Feb/12 08:49",
        "Updated": "07/Mar/12 07:10",
        "Resolved": "07/Mar/12 07:10",
        "Description": "The parser currently does not insert all nodes into the CAS. To reconstruct the original Parse tree all nodes must be present in the CAS.",
        "Issue Links": []
    },
    "OPENNLP-434": {
        "Key": "OPENNLP-434",
        "Summary": "Create a Factory to customize the Sentence Detector",
        "Type": "New Feature",
        "Status": "Closed",
        "Priority": "Minor",
        "Resolution": "Fixed",
        "Affects Version/s": "tools-1.5.3",
        "Fix Version/s": "tools-1.5.3",
        "Component/s": "Command Line Interface,                                            Sentence Detector",
        "Assignee": "William Colen",
        "Reporter": "William Colen",
        "Created": "16/Feb/12 12:59",
        "Updated": "27/Feb/12 16:28",
        "Resolved": "27/Feb/12 16:28",
        "Description": "Implement a mechanism to customize Sentence Detector using a factory. We should use the code infrastructure created for issue #429.\nThe plan is:\n\ncreate a SentenceDetectorFactory\n\t\ncreate a SentenceDetectorFactory object by passing the language code (for backward compatibility), the abbreviations (Set<String> ?) and the EOS characters\ngetters for the ContextGenerator, EOSScanner, EOSChars, Abbreviation Dictionary\nthe default implementation would use the existent Factory class from lang package\n\n\nwe need to decide if we keep the language dependent factory as is",
        "Issue Links": []
    },
    "OPENNLP-435": {
        "Key": "OPENNLP-435",
        "Summary": "Support loading custom format factory classes in CLI",
        "Type": "Improvement",
        "Status": "Closed",
        "Priority": "Minor",
        "Resolution": "Fixed",
        "Affects Version/s": "None",
        "Fix Version/s": "tools-1.5.3",
        "Component/s": "Command Line Interface",
        "Assignee": "J\u00f6rn Kottmann",
        "Reporter": "J\u00f6rn Kottmann",
        "Created": "16/Feb/12 15:07",
        "Updated": "19/Dec/12 20:13",
        "Resolved": "19/Dec/12 20:13",
        "Description": "It should be possible to use a class name of a sample stream factory instead of a format name. The sample stream factory class will then be loaded from the class path.\nThis feature is useful for users who need to implement sample streams to process data in a proprietary formats.",
        "Issue Links": []
    },
    "OPENNLP-436": {
        "Key": "OPENNLP-436",
        "Summary": "Auto Taxonomy Learner for Search Relevance Improvement based on Similarity",
        "Type": "New Feature",
        "Status": "Open",
        "Priority": "Major",
        "Resolution": "Unresolved",
        "Affects Version/s": "None",
        "Fix Version/s": "None",
        "Component/s": "Similarity",
        "Assignee": "Boris Galitsky",
        "Reporter": "Boris Galitsky",
        "Created": "16/Feb/12 23:01",
        "Updated": "16/Feb/12 23:01",
        "Resolved": null,
        "Description": "Similarity assessment by means of syntactic generalization improves search relevance. To further improve it in a vertical domain, we use a taxonomy. To build it automatically from a seed, we also use Similarity component + web mining of search engine API results.",
        "Issue Links": []
    },
    "OPENNLP-437": {
        "Key": "OPENNLP-437",
        "Summary": "OpenNLP TLP: Update source code section to new subversion location",
        "Type": "Task",
        "Status": "Closed",
        "Priority": "Major",
        "Resolution": "Fixed",
        "Affects Version/s": "None",
        "Fix Version/s": "tools-1.5.3",
        "Component/s": "Website",
        "Assignee": "Aliaksandr Autayeu",
        "Reporter": "J\u00f6rn Kottmann",
        "Created": "17/Feb/12 09:03",
        "Updated": "24/Feb/12 08:33",
        "Resolved": "20/Feb/12 00:48",
        "Description": "The source code page on our web site needs to point to the new subversion repository.",
        "Issue Links": []
    },
    "OPENNLP-438": {
        "Key": "OPENNLP-438",
        "Summary": "OpenNLP TLP: mailing lists",
        "Type": "Task",
        "Status": "Closed",
        "Priority": "Major",
        "Resolution": "Fixed",
        "Affects Version/s": "None",
        "Fix Version/s": "None",
        "Component/s": "Build, Packaging and Test,                                            Website",
        "Assignee": null,
        "Reporter": "J\u00f6rn Kottmann",
        "Created": "17/Feb/12 09:04",
        "Updated": "03/Jan/14 13:53",
        "Resolved": "03/Jan/14 13:53",
        "Description": "Update mailing list references on website and inside our pom files to point to the new tlp lists.",
        "Issue Links": []
    },
    "OPENNLP-439": {
        "Key": "OPENNLP-439",
        "Summary": "OpenNLP TLP: Remove Incubator disclaimer",
        "Type": "Task",
        "Status": "Closed",
        "Priority": "Major",
        "Resolution": "Fixed",
        "Affects Version/s": "None",
        "Fix Version/s": "tools-1.5.3",
        "Component/s": "Website",
        "Assignee": "Aliaksandr Autayeu",
        "Reporter": "J\u00f6rn Kottmann",
        "Created": "17/Feb/12 09:05",
        "Updated": "24/Feb/12 08:32",
        "Resolved": "20/Feb/12 00:42",
        "Description": "We are now a TLP. Lets remove the incubator disclaimer!",
        "Issue Links": []
    },
    "OPENNLP-440": {
        "Key": "OPENNLP-440",
        "Summary": "OpenNLP TLP: Remove \"incubating\" from 1.5.3 version",
        "Type": "Task",
        "Status": "Closed",
        "Priority": "Major",
        "Resolution": "Fixed",
        "Affects Version/s": "None",
        "Fix Version/s": "None",
        "Component/s": "Build, Packaging and Test",
        "Assignee": null,
        "Reporter": "J\u00f6rn Kottmann",
        "Created": "17/Feb/12 09:07",
        "Updated": "24/Feb/12 08:36",
        "Resolved": "24/Feb/12 08:36",
        "Description": "The incubating label should be removed from all mentions of the 1.5.3 version.",
        "Issue Links": []
    },
    "OPENNLP-441": {
        "Key": "OPENNLP-441",
        "Summary": "OpenNLP TLP: Add a tlp news item to the website",
        "Type": "Task",
        "Status": "Closed",
        "Priority": "Major",
        "Resolution": "Fixed",
        "Affects Version/s": "None",
        "Fix Version/s": "None",
        "Component/s": "Website",
        "Assignee": null,
        "Reporter": "J\u00f6rn Kottmann",
        "Created": "17/Feb/12 09:08",
        "Updated": "24/Feb/12 08:31",
        "Resolved": "24/Feb/12 08:31",
        "Description": "Lets announce our new TLP status as a news item.",
        "Issue Links": []
    },
    "OPENNLP-442": {
        "Key": "OPENNLP-442",
        "Summary": "OpenNLP TLP: Update incubator status site",
        "Type": "Task",
        "Status": "Closed",
        "Priority": "Major",
        "Resolution": "Fixed",
        "Affects Version/s": "None",
        "Fix Version/s": "None",
        "Component/s": "None",
        "Assignee": null,
        "Reporter": "J\u00f6rn Kottmann",
        "Created": "17/Feb/12 09:10",
        "Updated": "06/Jan/14 16:41",
        "Resolved": "06/Jan/14 16:41",
        "Description": "Update the Incubator site\nUpdate the Incubator status page\nUpdate the podling status page. All sections should now be filled in including EXIT. Take some time to read carefully since this page forms the final public record for graduation.\nEdit the Incubator website to remove the podling from the list in project.xml. Here explains how.",
        "Issue Links": []
    },
    "OPENNLP-443": {
        "Key": "OPENNLP-443",
        "Summary": "OpenNLP TLP: Post announcement about new mailing lists",
        "Type": "Task",
        "Status": "Closed",
        "Priority": "Major",
        "Resolution": "Fixed",
        "Affects Version/s": "None",
        "Fix Version/s": "None",
        "Component/s": "None",
        "Assignee": null,
        "Reporter": "J\u00f6rn Kottmann",
        "Created": "17/Feb/12 09:12",
        "Updated": "23/Feb/12 15:12",
        "Resolved": "23/Feb/12 15:12",
        "Description": "As soon we have our new mailing lists we need to post an announcement to tell our users.",
        "Issue Links": []
    },
    "OPENNLP-444": {
        "Key": "OPENNLP-444",
        "Summary": "OpenNLP: Notify public mailing list archives about our new lists",
        "Type": "Task",
        "Status": "Closed",
        "Priority": "Major",
        "Resolution": "Fixed",
        "Affects Version/s": "None",
        "Fix Version/s": "None",
        "Component/s": "None",
        "Assignee": "J\u00f6rn Kottmann",
        "Reporter": "J\u00f6rn Kottmann",
        "Created": "17/Feb/12 09:13",
        "Updated": "06/Jan/14 16:39",
        "Resolved": "06/Jan/14 16:39",
        "Description": "Inform all the public ml archives about our new lists.",
        "Issue Links": []
    },
    "OPENNLP-445": {
        "Key": "OPENNLP-445",
        "Summary": "OpenNLP TLP: Update source location in POM",
        "Type": "Task",
        "Status": "Closed",
        "Priority": "Major",
        "Resolution": "Fixed",
        "Affects Version/s": "None",
        "Fix Version/s": "tools-1.5.3",
        "Component/s": "Build, Packaging and Test",
        "Assignee": "Aliaksandr Autayeu",
        "Reporter": "J\u00f6rn Kottmann",
        "Created": "17/Feb/12 09:14",
        "Updated": "07/May/12 09:13",
        "Resolved": "20/Feb/12 00:40",
        "Description": "The source location in our pom files must be updated.",
        "Issue Links": []
    },
    "OPENNLP-446": {
        "Key": "OPENNLP-446",
        "Summary": "OpenNLP TLP: Work out a reporting schedule with the Board.",
        "Type": "Task",
        "Status": "Closed",
        "Priority": "Major",
        "Resolution": "Fixed",
        "Affects Version/s": "None",
        "Fix Version/s": "None",
        "Component/s": "None",
        "Assignee": "J\u00f6rn Kottmann",
        "Reporter": "J\u00f6rn Kottmann",
        "Created": "17/Feb/12 09:15",
        "Updated": "22/Feb/12 04:07",
        "Resolved": "20/Feb/12 13:58",
        "Description": "Lets figure out in which reporting schedule OpenNLP should go.",
        "Issue Links": []
    },
    "OPENNLP-447": {
        "Key": "OPENNLP-447",
        "Summary": "Transfer the podling website",
        "Type": "Task",
        "Status": "Closed",
        "Priority": "Major",
        "Resolution": "Fixed",
        "Affects Version/s": "None",
        "Fix Version/s": "None",
        "Component/s": "Website",
        "Assignee": null,
        "Reporter": "Aliaksandr Autayeu",
        "Created": "20/Feb/12 17:44",
        "Updated": "24/Feb/12 08:32",
        "Resolved": "24/Feb/12 08:32",
        "Description": "Transfer the podling website to opennlp.apache.org",
        "Issue Links": []
    },
    "OPENNLP-448": {
        "Key": "OPENNLP-448",
        "Summary": "Add Arvores Deitadas TokenSampleStream",
        "Type": "New Feature",
        "Status": "Closed",
        "Priority": "Minor",
        "Resolution": "Fixed",
        "Affects Version/s": "tools-1.5.3",
        "Fix Version/s": "tools-1.5.3",
        "Component/s": "Formats",
        "Assignee": "William Colen",
        "Reporter": "William Colen",
        "Created": "23/Feb/12 17:58",
        "Updated": "27/Feb/12 16:25",
        "Resolved": "27/Feb/12 16:25",
        "Description": "Add Arvores Deitadas TokenSampleStream to train a tokenizer model using corpus in AD format.",
        "Issue Links": []
    },
    "OPENNLP-449": {
        "Key": "OPENNLP-449",
        "Summary": "Implement a fine-grained evaluation report for POS Tagger",
        "Type": "New Feature",
        "Status": "Closed",
        "Priority": "Minor",
        "Resolution": "Fixed",
        "Affects Version/s": "tools-1.5.3",
        "Fix Version/s": "tools-1.5.3",
        "Component/s": "POS Tagger",
        "Assignee": "William Colen",
        "Reporter": "William Colen",
        "Created": "26/Feb/12 22:39",
        "Updated": "18/Mar/12 15:06",
        "Resolved": "18/Mar/12 15:01",
        "Description": "Implement a fine-grained evaluation report for the POS Tagger.\nIt would be activated by a new CLI parameter: reportOutputFile.\nI will attach an example output.",
        "Issue Links": []
    },
    "OPENNLP-450": {
        "Key": "OPENNLP-450",
        "Summary": "Add additional context support to POS Tagger",
        "Type": "Improvement",
        "Status": "Closed",
        "Priority": "Major",
        "Resolution": "Fixed",
        "Affects Version/s": "tools-1.5.3",
        "Fix Version/s": "tools-1.5.3",
        "Component/s": "POS Tagger",
        "Assignee": "William Colen",
        "Reporter": "William Colen",
        "Created": "27/Feb/12 13:39",
        "Updated": "18/Mar/12 15:06",
        "Resolved": "18/Mar/12 15:00",
        "Description": "Some applications would benefit from having additional context support in POS Tagger. For example, I could improve the model accuracy by using output from Name Finder.\nThe change would be to include a field String[][] additionalContext to the POSSample, and modify the code to allow the POS Tagger use it during training and runtime.",
        "Issue Links": []
    },
    "OPENNLP-451": {
        "Key": "OPENNLP-451",
        "Summary": "Wrong NameType in TimeNameFinder.xml",
        "Type": "Bug",
        "Status": "Closed",
        "Priority": "Major",
        "Resolution": "Fixed",
        "Affects Version/s": "tools-1.5.2-incubating",
        "Fix Version/s": "1.6.0",
        "Component/s": "Name Finder",
        "Assignee": "J\u00f6rn Kottmann",
        "Reporter": "Joseph B. Martin",
        "Created": "27/Feb/12 19:01",
        "Updated": "16/Sep/13 10:38",
        "Resolved": "16/Sep/13 10:38",
        "Description": "In apache-opennlp-1.5.2-incubating-src/opennlp-uima/descriptors/TimeNameFinder.xml: \nUnder analysisEngineDescription/analysisEngineMetaData/configurationParameterSettings, the name \"opennlp.uima.NameType\" has a value of \"opennlp.uima.Person\".  It should be set to \"opennlp.uima.Time\" instead.  This bug causes the annotator to classify time phrases such as \"this afternoon\" and \"tomorrow morning\" as Persons instead of Times.",
        "Issue Links": []
    },
    "OPENNLP-452": {
        "Key": "OPENNLP-452",
        "Summary": "Running the POSTaggerCrossValidator with -ngram argument causes an exception",
        "Type": "Bug",
        "Status": "Closed",
        "Priority": "Major",
        "Resolution": "Fixed",
        "Affects Version/s": "tools-1.5.3",
        "Fix Version/s": "tools-1.5.3",
        "Component/s": "POS Tagger",
        "Assignee": "William Colen",
        "Reporter": "William Colen",
        "Created": "29/Feb/12 20:09",
        "Updated": "19/Mar/12 16:20",
        "Resolved": "19/Mar/12 16:20",
        "Description": "I tried to execute POSTaggerCrossValidator with the -ngram parameter and it caused a UnsupportedOperationException.\nSometimes it is interesting for some training tools to pre-process the corpus to artifacts before training, for example dictionaries.\nCrossValidationPartitioner.TrainingSampleStream should support the reset operation to allow this functionality.\nDoes anybody know why it does not support resetting?",
        "Issue Links": []
    },
    "OPENNLP-453": {
        "Key": "OPENNLP-453",
        "Summary": "Add Apache Feather logo to web-site",
        "Type": "Improvement",
        "Status": "Closed",
        "Priority": "Trivial",
        "Resolution": "Fixed",
        "Affects Version/s": "None",
        "Fix Version/s": "None",
        "Component/s": "Website",
        "Assignee": "James Kosin",
        "Reporter": "James Kosin",
        "Created": "01/Mar/12 05:54",
        "Updated": "07/Mar/12 23:36",
        "Resolved": "07/Mar/12 03:59",
        "Description": "When moving the web-site, the incubator logo was removed.\nIt would be nice to add the apache logo and link to http://www.apache.org with the feather logo.",
        "Issue Links": []
    },
    "OPENNLP-454": {
        "Key": "OPENNLP-454",
        "Summary": "Create DOAP for our website",
        "Type": "Task",
        "Status": "Closed",
        "Priority": "Major",
        "Resolution": "Duplicate",
        "Affects Version/s": "None",
        "Fix Version/s": "None",
        "Component/s": "Website",
        "Assignee": "J\u00f6rn Kottmann",
        "Reporter": "J\u00f6rn Kottmann",
        "Created": "01/Mar/12 07:25",
        "Updated": "03/Apr/13 09:43",
        "Resolved": "03/Apr/13 09:43",
        "Description": "We are missing a DOAP file.\nSee here for more details:\nhttp://projects.apache.org/doap.html",
        "Issue Links": [
            "/jira/browse/OPENNLP-498"
        ]
    },
    "OPENNLP-455": {
        "Key": "OPENNLP-455",
        "Summary": "Add the required link for \"Security\" reporting to Apache security page",
        "Type": "Improvement",
        "Status": "Closed",
        "Priority": "Trivial",
        "Resolution": "Fixed",
        "Affects Version/s": "None",
        "Fix Version/s": "None",
        "Component/s": "Website",
        "Assignee": "James Kosin",
        "Reporter": "James Kosin",
        "Created": "02/Mar/12 03:17",
        "Updated": "02/Mar/12 07:19",
        "Resolved": "02/Mar/12 03:29",
        "Description": "http://www.apache.org/foundation/marks/pmcs.html\nOutlines we need to have a link for Security to point to either our information on how to report or to link to Apache's Security site information.\nFor now lets do the latter; since, we don't have the infastructure setup to do our own security just yet.",
        "Issue Links": []
    },
    "OPENNLP-456": {
        "Key": "OPENNLP-456",
        "Summary": "Trademark Complience",
        "Type": "Improvement",
        "Status": "Closed",
        "Priority": "Minor",
        "Resolution": "Fixed",
        "Affects Version/s": "None",
        "Fix Version/s": "None",
        "Component/s": "Website",
        "Assignee": "James Kosin",
        "Reporter": "James Kosin",
        "Created": "03/Mar/12 00:21",
        "Updated": "08/Mar/12 07:28",
        "Resolved": "07/Mar/12 23:35",
        "Description": "Need to add trademark (TM) to the current OpenNLP logo and add blurb to the site about the trademark.\nAlso partially depends on OPENNLP-453 about using the feather logo to link back to the ASF home page.",
        "Issue Links": []
    },
    "OPENNLP-457": {
        "Key": "OPENNLP-457",
        "Summary": "Create Corpus cmd line tool should support type system imports",
        "Type": "Improvement",
        "Status": "Closed",
        "Priority": "Minor",
        "Resolution": "Fixed",
        "Affects Version/s": "None",
        "Fix Version/s": "None",
        "Component/s": "Corpus Server",
        "Assignee": "J\u00f6rn Kottmann",
        "Reporter": "J\u00f6rn Kottmann",
        "Created": "05/Mar/12 08:30",
        "Updated": "05/Mar/12 08:34",
        "Resolved": "05/Mar/12 08:34",
        "Description": "The Corpus Server needs a type system for every corpus it contains. This type system needs to be provided when a new corpus is created. The Corpus Server tools contains a command line tool which can do that. This tool should resolve a type system during the import to be able to transmit also the imported type system, otherwise an incomplete type system might be send to the corpus server.",
        "Issue Links": []
    },
    "OPENNLP-458": {
        "Key": "OPENNLP-458",
        "Summary": "Corpus Server needs to check that corpus exist",
        "Type": "Bug",
        "Status": "Closed",
        "Priority": "Minor",
        "Resolution": "Fixed",
        "Affects Version/s": "None",
        "Fix Version/s": "None",
        "Component/s": "Corpus Server",
        "Assignee": "J\u00f6rn Kottmann",
        "Reporter": "J\u00f6rn Kottmann",
        "Created": "05/Mar/12 13:17",
        "Updated": "05/Mar/12 13:20",
        "Resolved": "05/Mar/12 13:20",
        "Description": "The Corpus Server assumes that a corpus exists but does not check if it really does. If it does not exist the user might get weird results.\nTo fix this always check if a corpus exists.",
        "Issue Links": []
    },
    "OPENNLP-459": {
        "Key": "OPENNLP-459",
        "Summary": "Corpus Server searching does not work properly when there are multiple corpora",
        "Type": "Bug",
        "Status": "Closed",
        "Priority": "Major",
        "Resolution": "Fixed",
        "Affects Version/s": "None",
        "Fix Version/s": "None",
        "Component/s": "Corpus Server",
        "Assignee": "J\u00f6rn Kottmann",
        "Reporter": "J\u00f6rn Kottmann",
        "Created": "05/Mar/12 14:05",
        "Updated": "05/Mar/12 14:20",
        "Resolved": "05/Mar/12 14:20",
        "Description": "The current implementation tries to reuse a searcher if possible. This does not take into account for which corpus the server was created.\nTo fix this create a searcher for every corpus and use the correct searcher depending on the corpus.",
        "Issue Links": []
    },
    "OPENNLP-460": {
        "Key": "OPENNLP-460",
        "Summary": "Queue Collection Reader descriptor doesn't fit to implementation",
        "Type": "Bug",
        "Status": "Closed",
        "Priority": "Major",
        "Resolution": "Fixed",
        "Affects Version/s": "None",
        "Fix Version/s": "None",
        "Component/s": "Corpus Server",
        "Assignee": "J\u00f6rn Kottmann",
        "Reporter": "J\u00f6rn Kottmann",
        "Created": "05/Mar/12 17:43",
        "Updated": "05/Mar/12 17:43",
        "Resolved": "05/Mar/12 17:43",
        "Description": "The Corpus Queue Collection Reader xml descriptor file is out of sync with the implementation. Update the descriptor to fit the implementation.",
        "Issue Links": []
    },
    "OPENNLP-461": {
        "Key": "OPENNLP-461",
        "Summary": "Corpus Explorer view fails to remember queries",
        "Type": "Bug",
        "Status": "Closed",
        "Priority": "Major",
        "Resolution": "Fixed",
        "Affects Version/s": "None",
        "Fix Version/s": "None",
        "Component/s": "Cas Editor Corpus Server Plugin",
        "Assignee": "J\u00f6rn Kottmann",
        "Reporter": "J\u00f6rn Kottmann",
        "Created": "07/Mar/12 07:12",
        "Updated": "07/Mar/12 08:28",
        "Resolved": "07/Mar/12 08:28",
        "Description": "The Corpus Explorer view can remember the last entered queries, but it this feature is broken somehow. If a remembered query is selected an empty string is shown in the query text box.",
        "Issue Links": []
    },
    "OPENNLP-462": {
        "Key": "OPENNLP-462",
        "Summary": "Sentence Detector View should not try to label headlines, bylines, etc.",
        "Type": "Improvement",
        "Status": "Closed",
        "Priority": "Minor",
        "Resolution": "Won't Fix",
        "Affects Version/s": "None",
        "Fix Version/s": "None",
        "Component/s": "Cas Editor OpenNLP Plugin",
        "Assignee": null,
        "Reporter": "J\u00f6rn Kottmann",
        "Created": "08/Mar/12 13:37",
        "Updated": "16/Jan/17 14:30",
        "Resolved": "16/Jan/17 14:30",
        "Description": "Currently the sentence detector can be limited to detect text within annotations (e.g. paragraphs). Depending on the use case the user might just want to specify a (additional) list of annotations which should not intersect with sentences.",
        "Issue Links": []
    },
    "OPENNLP-463": {
        "Key": "OPENNLP-463",
        "Summary": "Docs incosistent with latest code",
        "Type": "Improvement",
        "Status": "Closed",
        "Priority": "Minor",
        "Resolution": "Fixed",
        "Affects Version/s": "tools-1.5.2-incubating,                                            tools-1.5.3",
        "Fix Version/s": "tools-1.5.3",
        "Component/s": "Name Finder",
        "Assignee": "William Colen",
        "Reporter": "Jim Piliouras",
        "Created": "09/Mar/12 18:42",
        "Updated": "13/Mar/12 15:45",
        "Resolved": "13/Mar/12 15:28",
        "Description": "The docs state that one can pass null resources to the TokenNameFinderCrossValidator but that is not the case...At the very least one has to pass an empty Map rather than null, otherwise there will be a NPE right after the first 100 iterations of training finish! Passing an empty map does the trick...Thanks William! \nAt the very least you can add a null-check and create an empty map accordingly rather than letting the user do it...",
        "Issue Links": []
    },
    "OPENNLP-464": {
        "Key": "OPENNLP-464",
        "Summary": "Name Finder should show proper error message in case a model fails to load",
        "Type": "Bug",
        "Status": "Closed",
        "Priority": "Minor",
        "Resolution": "Fixed",
        "Affects Version/s": "None",
        "Fix Version/s": "None",
        "Component/s": "Cas Editor OpenNLP Plugin",
        "Assignee": "J\u00f6rn Kottmann",
        "Reporter": "J\u00f6rn Kottmann",
        "Created": "12/Mar/12 14:13",
        "Updated": "12/Mar/12 14:33",
        "Resolved": "12/Mar/12 14:33",
        "Description": "If a name finder model cannot be loaded for some reason the name finder view should show the actual error message and not a NPE.",
        "Issue Links": []
    },
    "OPENNLP-465": {
        "Key": "OPENNLP-465",
        "Summary": "Sentence Detector should be triggered by preference changes",
        "Type": "Bug",
        "Status": "Closed",
        "Priority": "Minor",
        "Resolution": "Fixed",
        "Affects Version/s": "None",
        "Fix Version/s": "None",
        "Component/s": "Cas Editor OpenNLP Plugin",
        "Assignee": "J\u00f6rn Kottmann",
        "Reporter": "J\u00f6rn Kottmann",
        "Created": "12/Mar/12 14:35",
        "Updated": "12/Mar/12 14:54",
        "Resolved": "12/Mar/12 14:54",
        "Description": "The sentence detector view should be triggered by a preference change. This way the processing might succeed after an error was fixed or can report an error again. If this is not done the view remains stuck at the error until a new CAS is opened (or the current one re-opened).",
        "Issue Links": []
    },
    "OPENNLP-466": {
        "Key": "OPENNLP-466",
        "Summary": "TokenNameFinderCrossValidator hangs when passed a NameEvaluationErrorListener...",
        "Type": "Bug",
        "Status": "Closed",
        "Priority": "Major",
        "Resolution": "Not A Problem",
        "Affects Version/s": "tools-1.5.3",
        "Fix Version/s": "None",
        "Component/s": "Name Finder",
        "Assignee": "William Colen",
        "Reporter": "Jim Piliouras",
        "Created": "12/Mar/12 18:32",
        "Updated": "13/Mar/12 20:08",
        "Resolved": "13/Mar/12 20:06",
        "Description": "TokenNameFinderCrossValidator works fine if passed null or any other listener except a \"NameEvaluationErrorListener\", for  the l\"listeners\" parameter (last vararglist parameter in the constructor)...I have tested it with DetailedFMeasureListener and null and it works fine. When trying to pass an array with the 2 listeners i want (DetailedFMeasureListener, NameEvaluationErrorListener) it just hangs after the processing the last partition of data, rather than showing the F-score! It is not a show stopper because i can simply pass null and get my F-score, but it would be nice if could see the misclassifications as well...",
        "Issue Links": []
    },
    "OPENNLP-467": {
        "Key": "OPENNLP-467",
        "Summary": "Corpus Server should log creation of a queue",
        "Type": "Improvement",
        "Status": "Closed",
        "Priority": "Trivial",
        "Resolution": "Fixed",
        "Affects Version/s": "None",
        "Fix Version/s": "None",
        "Component/s": "Corpus Server",
        "Assignee": "J\u00f6rn Kottmann",
        "Reporter": "J\u00f6rn Kottmann",
        "Created": "13/Mar/12 08:42",
        "Updated": "13/Mar/12 08:45",
        "Resolved": "13/Mar/12 08:45",
        "Description": "The creation of a queue should be logged.",
        "Issue Links": []
    },
    "OPENNLP-468": {
        "Key": "OPENNLP-468",
        "Summary": "Corpus Servers search doesn't find documents",
        "Type": "Bug",
        "Status": "Closed",
        "Priority": "Major",
        "Resolution": "Won't Fix",
        "Affects Version/s": "None",
        "Fix Version/s": "None",
        "Component/s": "Corpus Server",
        "Assignee": "J\u00f6rn Kottmann",
        "Reporter": "J\u00f6rn Kottmann",
        "Created": "13/Mar/12 08:56",
        "Updated": "16/Jan/17 14:31",
        "Resolved": "16/Jan/17 14:31",
        "Description": "The Corpus Servers search functionality often does not find documents. It seems to depend on the search term.",
        "Issue Links": []
    },
    "OPENNLP-469": {
        "Key": "OPENNLP-469",
        "Summary": "Headers for commits list are wrong for \"Reply To:\"",
        "Type": "Bug",
        "Status": "Closed",
        "Priority": "Major",
        "Resolution": "Fixed",
        "Affects Version/s": "None",
        "Fix Version/s": "None",
        "Component/s": "Website",
        "Assignee": "J\u00f6rn Kottmann",
        "Reporter": "James Kosin",
        "Created": "14/Mar/12 04:09",
        "Updated": "19/Mar/12 09:40",
        "Resolved": "19/Mar/12 09:40",
        "Description": "The headers for the commits list are improperly marking the \"Reply To:\" field with the wrong list.\nList-Help: <commits-help@opennlp.apache.org>\nList-Unsubscribe: <commits-unsubscribe@opennlp.apache.org>\nList-Post: <commits@opennlp.apache.org>\nList-Id: <commits.opennlp.apache.org>\nReply-To: opennlp-dev@opennlp.apache.org\nDelivered-To: mailing list commits@opennlp.apache.org\n\u2014 correction \u2014\nReply-To: dev@opennlp.apache.org",
        "Issue Links": []
    },
    "OPENNLP-470": {
        "Key": "OPENNLP-470",
        "Summary": "CLI for SimpleTokenizer is broken",
        "Type": "Bug",
        "Status": "Closed",
        "Priority": "Major",
        "Resolution": "Fixed",
        "Affects Version/s": "None",
        "Fix Version/s": "tools-1.5.3",
        "Component/s": "Command Line Interface,                                            Tokenizer",
        "Assignee": "Aliaksandr Autayeu",
        "Reporter": "James Kosin",
        "Created": "15/Mar/12 01:44",
        "Updated": "27/Jul/12 11:33",
        "Resolved": "26/Jul/12 06:43",
        "Description": "opennlp SimpleTokenizer < sentences_file.txt\nAlways returns usage... probably because there are no required arguments; but, it should now that, shouldn't it?",
        "Issue Links": []
    },
    "OPENNLP-471": {
        "Key": "OPENNLP-471",
        "Summary": "DictionaryNameFinder has HASHing issues",
        "Type": "Bug",
        "Status": "Closed",
        "Priority": "Major",
        "Resolution": "Fixed",
        "Affects Version/s": "None",
        "Fix Version/s": "tools-1.5.3",
        "Component/s": "Name Finder",
        "Assignee": "James Kosin",
        "Reporter": "James Kosin",
        "Created": "15/Mar/12 03:47",
        "Updated": "25/Apr/12 01:54",
        "Resolved": "25/Apr/12 01:54",
        "Description": "The DictionaryNameFinder has issues finding multi-token names when the dictionary is searched a token at a time by the find() method.  If, the dictionary doesn't have a single (or shorter) token match available in the dictionary.\nHaving a dictionary with \n{\"folic\", \"acid\"}\n without an entry for \n{\"folic\"}\n will cause the find() method to totally skip the fact there is a longer match possible.\nThanks to Jim for pushing this and to my debugging skills to find.\nTwo possiblilites come to mind:\n1)  I don't really like, is we turn it into a larger problem by trying longer matches when shorter ones don't match.  Unfortunately, this turns quickly into a race to see who can wait longer.\n2)  A way of returning a possible match that may need exploring, or a look-ahead type system to say we don't match \"folic\" but if you have \"acid\" after \"folic\" we have a match for that in the dictionary.\n3)  Leave it as is and modify the dictionary to add shorter terms to the dictionary... maybe marking as not-a-valid entry so we can know we need a longer match.",
        "Issue Links": []
    },
    "OPENNLP-472": {
        "Key": "OPENNLP-472",
        "Summary": "Split the Corpus Servers REST interface from the implementation",
        "Type": "Improvement",
        "Status": "Closed",
        "Priority": "Major",
        "Resolution": "Fixed",
        "Affects Version/s": "None",
        "Fix Version/s": "None",
        "Component/s": "Corpus Server",
        "Assignee": "J\u00f6rn Kottmann",
        "Reporter": "J\u00f6rn Kottmann",
        "Created": "15/Mar/12 10:43",
        "Updated": "26/Jun/12 12:25",
        "Resolved": "26/Jun/12 12:25",
        "Description": "The Corpus Server defines a REST interface against clients can be programmed. It would be nice to be able to reuse this interface (and the clients) with a different corpus server implementation e.g. using a different data base with a Solr server.\nThe REST interface and the implementation should be split and it should be easy to provide a different implementation.",
        "Issue Links": []
    },
    "OPENNLP-473": {
        "Key": "OPENNLP-473",
        "Summary": "Implement a directory training file reader stream",
        "Type": "Improvement",
        "Status": "Closed",
        "Priority": "Minor",
        "Resolution": "Fixed",
        "Affects Version/s": "None",
        "Fix Version/s": "tools-1.5.3",
        "Component/s": "None",
        "Assignee": "J\u00f6rn Kottmann",
        "Reporter": "J\u00f6rn Kottmann",
        "Created": "15/Mar/12 13:55",
        "Updated": "15/Mar/12 14:04",
        "Resolved": "15/Mar/12 14:04",
        "Description": "In various corpora (e.g. OntoNotes) the training data is split into one file per document. To produce a single training data stream out of these the directories must be crawled for all document sample files. This could be done in a stream which reads in a document from disk and outputs it as a String object.",
        "Issue Links": []
    },
    "OPENNLP-474": {
        "Key": "OPENNLP-474",
        "Summary": "Name Finders cross validation is broken",
        "Type": "Bug",
        "Status": "Closed",
        "Priority": "Minor",
        "Resolution": "Fixed",
        "Affects Version/s": "None",
        "Fix Version/s": "tools-1.5.3",
        "Component/s": "Name Finder",
        "Assignee": "J\u00f6rn Kottmann",
        "Reporter": "J\u00f6rn Kottmann",
        "Created": "15/Mar/12 14:52",
        "Updated": "15/Mar/12 14:57",
        "Resolved": "15/Mar/12 14:57",
        "Description": "The recent refactory of the cmd line code broke the cross validation of the name finder.",
        "Issue Links": []
    },
    "OPENNLP-475": {
        "Key": "OPENNLP-475",
        "Summary": "CorpusStore only works with bytes expect getTypeSystem",
        "Type": "Improvement",
        "Status": "Closed",
        "Priority": "Minor",
        "Resolution": "Fixed",
        "Affects Version/s": "None",
        "Fix Version/s": "None",
        "Component/s": "Corpus Server",
        "Assignee": "J\u00f6rn Kottmann",
        "Reporter": "J\u00f6rn Kottmann",
        "Created": "16/Mar/12 09:53",
        "Updated": "16/Mar/12 10:02",
        "Resolved": "16/Mar/12 10:02",
        "Description": "To make the interface uniform all methods should only work with byte arrays instead of the UIMA types. Change getTypeSystem to return a byte array instead of a TypeSystemDescription object.",
        "Issue Links": []
    },
    "OPENNLP-476": {
        "Key": "OPENNLP-476",
        "Summary": "Convert Corpus Server into an OSGi application",
        "Type": "Improvement",
        "Status": "Closed",
        "Priority": "Minor",
        "Resolution": "Fixed",
        "Affects Version/s": "None",
        "Fix Version/s": "None",
        "Component/s": "Corpus Server",
        "Assignee": "J\u00f6rn Kottmann",
        "Reporter": "J\u00f6rn Kottmann",
        "Created": "16/Mar/12 10:28",
        "Updated": "26/Jun/12 12:48",
        "Resolved": "26/Jun/12 12:48",
        "Description": "To make it easy to provide a different implementation for the Corpus Server it should be converted into an OSGi application which can be hosted in an OSGi application runtime such as Apache Karaf.",
        "Issue Links": []
    },
    "OPENNLP-477": {
        "Key": "OPENNLP-477",
        "Summary": "DictionaryNameFinder evaluation always returns 0, 0, -1",
        "Type": "Bug",
        "Status": "Closed",
        "Priority": "Major",
        "Resolution": "Fixed",
        "Affects Version/s": "tools-1.5.2-incubating",
        "Fix Version/s": "tools-1.5.3",
        "Component/s": "Name Finder",
        "Assignee": "William Colen",
        "Reporter": "Jim Piliouras",
        "Created": "17/Mar/12 18:26",
        "Updated": "19/Mar/12 18:23",
        "Resolved": "17/Mar/12 19:43",
        "Description": "The NameFinderEvaluator expects typed spans, but the DictionaryNameFinder outputs the old untyped spans. As a result, evaluation for the DictionaryNameFinder always returns 0, 0, -1 regardless of finding loads of entities.",
        "Issue Links": []
    },
    "OPENNLP-478": {
        "Key": "OPENNLP-478",
        "Summary": "NameSample should create typed span",
        "Type": "Bug",
        "Status": "Closed",
        "Priority": "Major",
        "Resolution": "Fixed",
        "Affects Version/s": "tools-1.5.3",
        "Fix Version/s": "tools-1.5.3",
        "Component/s": "Name Finder",
        "Assignee": "William Colen",
        "Reporter": "William Colen",
        "Created": "17/Mar/12 19:48",
        "Updated": "07/May/12 12:46",
        "Resolved": "27/Mar/12 16:10",
        "Description": "NameFinder uses the type from span everywhere. When reading a corpus without type information we should set a default type value instead of leaving it null.\nLeaving it null causes the evaluation listeners and the evaluation itself to fail comparing the predicted values and the expected. Predicted names will always have a type.",
        "Issue Links": []
    },
    "OPENNLP-479": {
        "Key": "OPENNLP-479",
        "Summary": "Features related to abbreviation dictionary are not properly collected by DefaultSDContextGenerator",
        "Type": "Bug",
        "Status": "Closed",
        "Priority": "Major",
        "Resolution": "Fixed",
        "Affects Version/s": "tools-1.5.3",
        "Fix Version/s": "tools-1.5.3",
        "Component/s": "Sentence Detector",
        "Assignee": "William Colen",
        "Reporter": "William Colen",
        "Created": "18/Mar/12 14:54",
        "Updated": "04/Jan/13 15:46",
        "Resolved": "08/May/12 19:24",
        "Description": "The documentation is not clear about if the entries in abbreviation dictionary should include the EOS character. For example \"mr\" or \"mr.\". Also, part of the collector code expects the dictionary to include the EOS character, and others don't.",
        "Issue Links": []
    },
    "OPENNLP-480": {
        "Key": "OPENNLP-480",
        "Summary": "Create a project for the Tagging Server in the sandbox",
        "Type": "New Feature",
        "Status": "Closed",
        "Priority": "Minor",
        "Resolution": "Won't Fix",
        "Affects Version/s": "None",
        "Fix Version/s": "None",
        "Component/s": "None",
        "Assignee": null,
        "Reporter": "J\u00f6rn Kottmann",
        "Created": "21/Mar/12 19:49",
        "Updated": "16/Jan/17 14:35",
        "Resolved": "16/Jan/17 14:35",
        "Description": "The Tagging Server will be a RESTful service which can expose OpenNLP models via a REST interface. The tagging sever should support all the major components.",
        "Issue Links": []
    },
    "OPENNLP-481": {
        "Key": "OPENNLP-481",
        "Summary": "ADTokenSampleStream is not handling hyphenated tokens correctly",
        "Type": "Bug",
        "Status": "Closed",
        "Priority": "Major",
        "Resolution": "Fixed",
        "Affects Version/s": "tools-1.5.3",
        "Fix Version/s": "tools-1.5.3",
        "Component/s": "Formats",
        "Assignee": "William Colen",
        "Reporter": "William Colen",
        "Created": "23/Mar/12 00:34",
        "Updated": "13/Jul/12 03:57",
        "Resolved": "13/Jul/12 03:57",
        "Description": "Hyphenated tokens are not handled, for example \"aprova-se\" should be separated in two tokens. ADTokenSampleStream relies on a DictionaryDetokenizer, that don't know that \"aprova-\" \"se\" should be merged.",
        "Issue Links": []
    },
    "OPENNLP-482": {
        "Key": "OPENNLP-482",
        "Summary": "Create a Factory to customize the Tokenizer",
        "Type": "New Feature",
        "Status": "Closed",
        "Priority": "Major",
        "Resolution": "Fixed",
        "Affects Version/s": "tools-1.5.3",
        "Fix Version/s": "tools-1.5.3",
        "Component/s": "Tokenizer",
        "Assignee": "William Colen",
        "Reporter": "William Colen",
        "Created": "23/Mar/12 16:45",
        "Updated": "08/May/12 19:26",
        "Resolved": "08/May/12 19:26",
        "Description": null,
        "Issue Links": []
    },
    "OPENNLP-483": {
        "Key": "OPENNLP-483",
        "Summary": "Refactor the DefaultTokenContextGenerator to make it easier to create a sub-class",
        "Type": "Improvement",
        "Status": "Closed",
        "Priority": "Major",
        "Resolution": "Fixed",
        "Affects Version/s": "tools-1.5.3",
        "Fix Version/s": "tools-1.5.3",
        "Component/s": "Tokenizer",
        "Assignee": "William Colen",
        "Reporter": "William Colen",
        "Created": "24/Mar/12 00:36",
        "Updated": "24/Mar/12 00:37",
        "Resolved": "24/Mar/12 00:37",
        "Description": "Refactor the DefaultTokenContextGenerator to make it easier to create a sub-class. Basically we need to change members visibility to protected and create a method that creates the default context in a list, so subclasses can use this method without array-list conversions.",
        "Issue Links": []
    },
    "OPENNLP-484": {
        "Key": "OPENNLP-484",
        "Summary": "Improve features related to abbreviation dictionary in Tokenizer",
        "Type": "Improvement",
        "Status": "Closed",
        "Priority": "Major",
        "Resolution": "Fixed",
        "Affects Version/s": "tools-1.5.3",
        "Fix Version/s": "tools-1.5.3",
        "Component/s": "Tokenizer",
        "Assignee": "William Colen",
        "Reporter": "William Colen",
        "Created": "27/Mar/12 16:50",
        "Updated": "08/May/12 19:23",
        "Resolved": "08/May/12 19:23",
        "Description": "I noticed, after doing some benchmark, that we can improve Tokenizer effectiveness by changing a little how features related with the abbreviation dictionary are collected.",
        "Issue Links": []
    },
    "OPENNLP-485": {
        "Key": "OPENNLP-485",
        "Summary": "Improve the AD NameSample formater",
        "Type": "Improvement",
        "Status": "Closed",
        "Priority": "Major",
        "Resolution": "Fixed",
        "Affects Version/s": "tools-1.5.3",
        "Fix Version/s": "tools-1.5.3",
        "Component/s": "Formats",
        "Assignee": "William Colen",
        "Reporter": "William Colen",
        "Created": "27/Mar/12 16:59",
        "Updated": "08/May/12 19:26",
        "Resolved": "08/May/12 19:26",
        "Description": "We need to improve how contractions are handled: some are expanded to more than 2 tokens. Also should force tokenization of named entities that has punctuations.",
        "Issue Links": []
    },
    "OPENNLP-486": {
        "Key": "OPENNLP-486",
        "Summary": "Corferencer should be integrated into the command line interface",
        "Type": "Improvement",
        "Status": "Closed",
        "Priority": "Major",
        "Resolution": "Fixed",
        "Affects Version/s": "None",
        "Fix Version/s": "tools-1.5.3",
        "Component/s": "Command Line Interface,                                            Coref",
        "Assignee": "J\u00f6rn Kottmann",
        "Reporter": "J\u00f6rn Kottmann",
        "Created": "30/Mar/12 12:08",
        "Updated": "12/Apr/12 07:51",
        "Resolved": "12/Apr/12 07:51",
        "Description": "The current TreebankLinker should be integrated into the new command line interface.",
        "Issue Links": []
    },
    "OPENNLP-487": {
        "Key": "OPENNLP-487",
        "Summary": "Write a cmd line training tool for the Coreferencer",
        "Type": "Improvement",
        "Status": "Closed",
        "Priority": "Major",
        "Resolution": "Won't Fix",
        "Affects Version/s": "None",
        "Fix Version/s": "None",
        "Component/s": "Command Line Interface,                                            Coref",
        "Assignee": null,
        "Reporter": "J\u00f6rn Kottmann",
        "Created": "30/Mar/12 14:00",
        "Updated": "16/Jan/17 14:32",
        "Resolved": "16/Jan/17 14:32",
        "Description": "It should be possible to train the Coreference Resolution component via the command line. For this a new command line training tool must be implemented.",
        "Issue Links": []
    },
    "OPENNLP-488": {
        "Key": "OPENNLP-488",
        "Summary": "Doccat training tool throws NullPointer error",
        "Type": "Bug",
        "Status": "Closed",
        "Priority": "Major",
        "Resolution": "Fixed",
        "Affects Version/s": "None",
        "Fix Version/s": "None",
        "Component/s": "Doccat",
        "Assignee": "Tommaso Teofili",
        "Reporter": "Erik Andersson",
        "Created": "31/Mar/12 19:51",
        "Updated": "15/Dec/16 15:20",
        "Resolved": "09/Mar/16 10:24",
        "Description": "When following the example in the OpenNLP 1.5.2 documentation I get a NullPointerException.\nhttp://opennlp.apache.org/documentation/1.5.2-incubating/manual/opennlp.html#tools.doccat.training.tool\n$ bin/opennlp DoccatTrainer -encoding UTF-8 -lang en -data en-doccat.train -model en-doccat.bin\nIndexing events using cutoff of 5\n        Computing event counts...  done. 2 events\n        Indexing...  Dropped event GMDecrease:[bow=Major, bow=acquisitions, bow=that, bow=have, bow=a, bow=lower, bow=gross, bow=margin, bow=than, bow=the, bow=existing, bow=network, bow=also, bow=had, bow=a, bow=negative, bow=impact, bow=on, bow=the, bow=overall, bow=gross, bow=margin,, bow=but, bow=it, bow=should, bow=improve, bow=following, bow=the, bow=implementation, bow=of, bow=its, bow=integration, bow=strategies, bow=.]\nDropped event GMIncrease:[bow=The, bow=upward, bow=movement, bow=of, bow=gross, bow=margin, bow=resulted, bow=from, bow=amounts, bow=pursuant, bow=to, bow=adjustments, bow=to, bow=obligations, bow=towards, bow=dealers, bow=.]\ndone.\nSorting and merging events... Done indexing.\nIncorporating indexed data for training...\nException in thread \"main\" java.lang.NullPointerException\n        at opennlp.maxent.GISTrainer.trainModel(GISTrainer.java:263)\n        at opennlp.maxent.GIS.trainModel(GIS.java:256)\n        at opennlp.model.TrainUtil.train(TrainUtil.java:182)\n        at opennlp.tools.doccat.DocumentCategorizerME.train(DocumentCategorizerME.java:154)\n        at opennlp.tools.doccat.DocumentCategorizerME.train(DocumentCategorizerME.java:176)\n        at opennlp.tools.doccat.DocumentCategorizerME.train(DocumentCategorizerME.java:192)\n        at opennlp.tools.cmdline.doccat.DoccatTrainerTool.run(DoccatTrainerTool.java:91)\n        at opennlp.tools.cmdline.CLI.main(CLI.java:191)\nThe file \"en-doccat.train\" is UTF-8 encoded in UNIX format and looks like this:\nGMDecrease  Major acquisitions that have a lower gross margin than the existing network also had a negative impact on the overall gross margin, but it should improve following the implementation of its integration strategies .\nGMIncrease  The upward movement of gross margin resulted from amounts pursuant to adjustments to obligations towards dealers .",
        "Issue Links": [
            "/jira/browse/OPENNLP-122",
            "/jira/browse/OPENNLP-837"
        ]
    },
    "OPENNLP-489": {
        "Key": "OPENNLP-489",
        "Summary": "endMarker never checked when parsing wikinews page",
        "Type": "Bug",
        "Status": "Closed",
        "Priority": "Minor",
        "Resolution": "Fixed",
        "Affects Version/s": "None",
        "Fix Version/s": "None",
        "Component/s": "Wikinews Importer",
        "Assignee": "J\u00f6rn Kottmann",
        "Reporter": "Prokopis Prokopidis",
        "Created": "02/Apr/12 12:57",
        "Updated": "03/Aug/12 10:32",
        "Resolved": "04/Apr/12 07:43",
        "Description": "Hi,\nI am testing the Wikinews Importer, thanks for making it available.\nI think that in the following code of WikinewsConverter.java\nint cutIndex = -1;\nfor (String endMarker : endOfArtilceMarkers) {\n  int endMarkerIndex = pageText.indexOf(endMarker);\n  if (endMarkerIndex != -1) \n{\n    cutIndex = endMarkerIndex;\n    break;\n  }\n}\nif (cutIndex == -1)\n  cutIndex = pageText.length();\nif an endMarker1 has already been detected, another endMarker2 from the endOfArtilceMarkers list will not be checked, even if it appears before endMarker1 in the wiki text. Perhaps this check can be rewritten like\nint cutIndex = pageText.length();\nfor (String endMarker : endOfArtilceMarkers) {\n  int endMarkerIndex = pageText.indexOf(endMarker);\n  if (endMarkerIndex != -1 && endMarkerIndex < cutIndex) \n{\n    cutIndex = endMarkerIndex;\n    }\n}\nif (cutIndex < pageText.length()) {\n  pageText = pageText.substring(0, cutIndex);\n}",
        "Issue Links": []
    },
    "OPENNLP-490": {
        "Key": "OPENNLP-490",
        "Summary": "Add MERGE_BOTH option to Detokenizer",
        "Type": "New Feature",
        "Status": "Closed",
        "Priority": "Minor",
        "Resolution": "Fixed",
        "Affects Version/s": "tools-1.5.3",
        "Fix Version/s": "tools-1.5.3",
        "Component/s": "Tokenizer",
        "Assignee": "William Colen",
        "Reporter": "William Colen",
        "Created": "03/Apr/12 14:14",
        "Updated": "08/May/12 19:22",
        "Resolved": "08/May/12 19:22",
        "Description": "An MERGE_BOTH option would be useful to train using some corpus. For example in a Portuguese corpus we have:\n... devolva - me o livro .... (give the book back to me)\nWe need to detokenize it as \"devolva-me o livro\". Configure \"-\" token as MERGE_BOTH in the detokenizer dictionary would be helpful.",
        "Issue Links": []
    },
    "OPENNLP-491": {
        "Key": "OPENNLP-491",
        "Summary": "Chunking parser throws NPE when incomplete parse has zero tokens",
        "Type": "Bug",
        "Status": "Closed",
        "Priority": "Minor",
        "Resolution": "Fixed",
        "Affects Version/s": "None",
        "Fix Version/s": "tools-1.5.3",
        "Component/s": "Parser",
        "Assignee": "J\u00f6rn Kottmann",
        "Reporter": "J\u00f6rn Kottmann",
        "Created": "03/Apr/12 14:34",
        "Updated": "03/Apr/12 14:39",
        "Resolved": "03/Apr/12 14:39",
        "Description": "The chunker parser throws a NPE when the incomplete input parse has zero tokens. To fix this it should just return the incomplete input parse.",
        "Issue Links": []
    },
    "OPENNLP-492": {
        "Key": "OPENNLP-492",
        "Summary": "Method getTokensOrderedByFrequency in POSTaggerFineGrainedReportListener probably has a typo.",
        "Type": "Bug",
        "Status": "Closed",
        "Priority": "Minor",
        "Resolution": "Fixed",
        "Affects Version/s": "None",
        "Fix Version/s": "tools-1.5.3",
        "Component/s": "Command Line Interface,                                            POS Tagger",
        "Assignee": "William Colen",
        "Reporter": "Piotr Iwaniuk",
        "Created": "04/Apr/12 05:54",
        "Updated": "05/Apr/12 13:06",
        "Resolved": "04/Apr/12 21:19",
        "Description": "Checking the code with FindBugs warned about calling equals between object of different classes (variable o1 and number 02). It seems to be a sneaky typo. Looking at the rest of the code, it shouldn't change result of comparison, but may reduce performance.",
        "Issue Links": []
    },
    "OPENNLP-493": {
        "Key": "OPENNLP-493",
        "Summary": "TokenNameFinderTrainer should have an option to only use certain name types for training",
        "Type": "Improvement",
        "Status": "Closed",
        "Priority": "Minor",
        "Resolution": "Fixed",
        "Affects Version/s": "None",
        "Fix Version/s": "tools-1.5.3",
        "Component/s": "Command Line Interface,                                            Name Finder",
        "Assignee": "J\u00f6rn Kottmann",
        "Reporter": "J\u00f6rn Kottmann",
        "Created": "04/Apr/12 13:05",
        "Updated": "27/Apr/12 11:10",
        "Resolved": "27/Apr/12 10:54",
        "Description": "Training data produced from a corpus (e.g. conll, muc) often contain many name types, but usually the training should just be done for one name type (or a few selected ones). To make this easier the name finder trainer should have an optional argument to specify the types to use for training.",
        "Issue Links": []
    },
    "OPENNLP-494": {
        "Key": "OPENNLP-494",
        "Summary": "Merging results from several name-finders",
        "Type": "New Feature",
        "Status": "Closed",
        "Priority": "Major",
        "Resolution": "Won't Fix",
        "Affects Version/s": "tools-1.5.3",
        "Fix Version/s": "None",
        "Component/s": "Name Finder",
        "Assignee": null,
        "Reporter": "Jim Piliouras",
        "Created": "04/Apr/12 15:18",
        "Updated": "16/Jan/17 15:07",
        "Resolved": "16/Jan/17 15:07",
        "Description": "Made some small changes to the TokenNameFinderEvaluator class which hopefully allow merging of results from several name-finders. It just does that by calling the find method of all supplied name-finders. The only break is the fact that Java does not allow varargs anywhere but at the end of the argument list so i could not use \"TokenNameFinder... namefinders\" as the first parameter in the constructor - i had to pass an array instead. I think it's worth reversing the order of arguments  but that is a break too...",
        "Issue Links": []
    },
    "OPENNLP-495": {
        "Key": "OPENNLP-495",
        "Summary": "DictionaryNameFinder only outputs Spans of type \"default\"",
        "Type": "Improvement",
        "Status": "Closed",
        "Priority": "Major",
        "Resolution": "Fixed",
        "Affects Version/s": "tools-1.5.3",
        "Fix Version/s": "tools-1.5.3",
        "Component/s": "Name Finder",
        "Assignee": "J\u00f6rn Kottmann",
        "Reporter": "Jim Piliouras",
        "Created": "11/Apr/12 13:46",
        "Updated": "07/May/12 09:14",
        "Resolved": "12/Apr/12 14:25",
        "Description": "The DictionaryNameFinder always creates prediction Spans of type: default. Since we want to start merging results from several name-finders it makes sense to have them all output the same tag, otherwise it is impossible to properly merge the results. I mean they will be merged but half will be with default tag and some with the other user-specified tag. They can't be evaluated like that...they have to be consistent. That is very easy to fix...All i did was to create a global, mutable, String field and I am checking whether it is null before creating the Span. If it is then the usual happens (you get the default tag), if it isn't however the Span is created with whatever tag the user has supplied. In other words, a simple setter method can be used to set what tag to use in the DictionaryNameFinder Object. Of course this only works for single-type entities but then again dictionaries tend to be single-type \"repositories\". I am confident that you can commit this soon...all i did was add a field, a setter method for that field and an 'if statement' before creating the Span. What can possibly go wrong?",
        "Issue Links": []
    },
    "OPENNLP-496": {
        "Key": "OPENNLP-496",
        "Summary": "DictionaryNameFinder only deals with a single physical dictionary, thus a single type of entities",
        "Type": "Improvement",
        "Status": "Open",
        "Priority": "Major",
        "Resolution": "Unresolved",
        "Affects Version/s": "tools-1.5.3",
        "Fix Version/s": "None",
        "Component/s": "Name Finder",
        "Assignee": null,
        "Reporter": "Jim Piliouras",
        "Created": "13/Apr/12 13:42",
        "Updated": "12/Sep/12 16:20",
        "Resolved": null,
        "Description": "The Dictionary itself should store the type of entities it includes - NOT the finder. All the code (global field, extra constructor,getter method) should go in the Dictionary class. This will allow passing several actual xml dictionaries to the finder and the fidner can assign the correct type depending on which dictionary gave the prediction. This is extremely simple to do , in fact all the code needed is almost identical to yesterday's patch (OPENNLP-495). Since opennlp-495 has already been commited i will provide new patches for the latest head revision. One of the patches will revert the DictioanryNameFinder to its original state without breaking anything.",
        "Issue Links": []
    },
    "OPENNLP-497": {
        "Key": "OPENNLP-497",
        "Summary": "create maven script, release notes",
        "Type": "New Feature",
        "Status": "Closed",
        "Priority": "Major",
        "Resolution": "Fixed",
        "Affects Version/s": "None",
        "Fix Version/s": "None",
        "Component/s": "Similarity",
        "Assignee": "Boris Galitsky",
        "Reporter": "Boris Galitsky",
        "Created": "16/Apr/12 10:39",
        "Updated": "03/Apr/13 08:42",
        "Resolved": "14/Nov/12 23:22",
        "Description": null,
        "Issue Links": []
    },
    "OPENNLP-498": {
        "Key": "OPENNLP-498",
        "Summary": "Apache project branding requirements: DOAP file [PATCH]",
        "Type": "Improvement",
        "Status": "Closed",
        "Priority": "Major",
        "Resolution": "Fixed",
        "Affects Version/s": "None",
        "Fix Version/s": "None",
        "Component/s": "None",
        "Assignee": "J\u00f6rn Kottmann",
        "Reporter": "Shane Curcuru",
        "Created": "16/Apr/12 17:05",
        "Updated": "03/Apr/13 09:49",
        "Resolved": "03/Apr/13 09:49",
        "Description": "Attached.  Re: http://www.apache.org/foundation/marks/pmcs\nSee Also: http://projects.apache.org/create.html",
        "Issue Links": [
            "/jira/browse/OPENNLP-454"
        ]
    },
    "OPENNLP-499": {
        "Key": "OPENNLP-499",
        "Summary": "Span Comparable implementation should be consistent with equals",
        "Type": "Bug",
        "Status": "Closed",
        "Priority": "Major",
        "Resolution": "Fixed",
        "Affects Version/s": "tools-1.5.3",
        "Fix Version/s": "tools-1.5.3",
        "Component/s": "Name Finder",
        "Assignee": "William Colen",
        "Reporter": "William Colen",
        "Created": "18/Apr/12 14:44",
        "Updated": "18/Apr/12 22:26",
        "Resolved": "18/Apr/12 22:26",
        "Description": "Span Comparable implementation should be consistent with equals. Now it is inconsistent because it is not checking the type.",
        "Issue Links": []
    },
    "OPENNLP-500": {
        "Key": "OPENNLP-500",
        "Summary": "Improve OSGi support for OpenNLP extensions",
        "Type": "Improvement",
        "Status": "Closed",
        "Priority": "Major",
        "Resolution": "Fixed",
        "Affects Version/s": "None",
        "Fix Version/s": "tools-1.5.3",
        "Component/s": "None",
        "Assignee": "J\u00f6rn Kottmann",
        "Reporter": "J\u00f6rn Kottmann",
        "Created": "20/Apr/12 09:38",
        "Updated": "11/Sep/12 13:36",
        "Resolved": "11/Sep/12 13:36",
        "Description": "We have very basic OSGi support currently. We simply export all the packages we have and don't use any other OSGi features. This works well for anything we do, expect the places where we try to access classes by class name, e.g. to load custom factories via Class.forName(...). Most users will just be happy with that.\nSuch calls do not work in an OSGi environment because the class we try to load is not on \"our\" class path.\nIn OSGi this is done via services and we need to use them if we are running in an OSGI environment.\nAnyway, OpenNLP needs to work with and without OSGi.\nI suggest that we make OSGi an optional dependency and write code which can detect if the OSGi classes are there or not.\nTo instantiate a user class we would need to do something like this:\n\nTry to load via Class.forName(...)\nIf cannot be found, check if running in an OSGi environment\nIf so try to get an OSGi service which provides an instance to the user class",
        "Issue Links": []
    },
    "OPENNLP-501": {
        "Key": "OPENNLP-501",
        "Summary": "Detokenizer should be able to output a detokenized string with or without split markers",
        "Type": "Improvement",
        "Status": "Open",
        "Priority": "Minor",
        "Resolution": "Unresolved",
        "Affects Version/s": "None",
        "Fix Version/s": "None",
        "Component/s": "Tokenizer",
        "Assignee": "J\u00f6rn Kottmann",
        "Reporter": "J\u00f6rn Kottmann",
        "Created": "20/Apr/12 09:40",
        "Updated": "14/Mar/13 15:46",
        "Resolved": null,
        "Description": "The OpenNLP detokenizer can currently only output detokenization operations, but some people just would like to get a detokenized string with or without split markers.",
        "Issue Links": []
    },
    "OPENNLP-502": {
        "Key": "OPENNLP-502",
        "Summary": "Doccat trainer should use default feature generator if non is provided",
        "Type": "Bug",
        "Status": "Closed",
        "Priority": "Major",
        "Resolution": "Fixed",
        "Affects Version/s": "None",
        "Fix Version/s": "tools-1.5.3",
        "Component/s": "Doccat",
        "Assignee": "J\u00f6rn Kottmann",
        "Reporter": "J\u00f6rn Kottmann",
        "Created": "20/Apr/12 14:22",
        "Updated": "20/Apr/12 14:51",
        "Resolved": "20/Apr/12 14:51",
        "Description": "The Doccat trainer method has a var arg for feature generators. In the case no feature generator is provided the default one should be used, instead of none.",
        "Issue Links": []
    },
    "OPENNLP-503": {
        "Key": "OPENNLP-503",
        "Summary": "Team Page for project team still contains Incubator information.",
        "Type": "Improvement",
        "Status": "Closed",
        "Priority": "Trivial",
        "Resolution": "Fixed",
        "Affects Version/s": "None",
        "Fix Version/s": "None",
        "Component/s": "Website",
        "Assignee": "James Kosin",
        "Reporter": "James Kosin",
        "Created": "21/Apr/12 01:19",
        "Updated": "25/Apr/12 01:51",
        "Resolved": "25/Apr/12 01:51",
        "Description": "Jorn needs to be mentioned as the current Chair for the project.\nNeed to find out what to do with the mentors or what new roles they would like or need to take on in the project.",
        "Issue Links": []
    },
    "OPENNLP-504": {
        "Key": "OPENNLP-504",
        "Summary": "Add a FAQ page to our site",
        "Type": "Improvement",
        "Status": "Resolved",
        "Priority": "Minor",
        "Resolution": "Fixed",
        "Affects Version/s": "None",
        "Fix Version/s": "None",
        "Component/s": "Website",
        "Assignee": "Bruno P. Kinoshita",
        "Reporter": "James Kosin",
        "Created": "25/Apr/12 02:01",
        "Updated": "09/Dec/22 18:29",
        "Resolved": "09/Dec/22 18:29",
        "Description": "Collect and assemble a FAQ page for our site.\nMost questions start out:\n  Where can I get the models?\n  Where do I start getting to know OpenNLP?\n  etc.",
        "Issue Links": [
            "/jira/browse/OPENNLP-999",
            "https://github.com/apache/opennlp-site/pull/8",
            "https://github.com/apache/opennlp-site/pull/8"
        ]
    },
    "OPENNLP-505": {
        "Key": "OPENNLP-505",
        "Summary": "Models should also have constructors which accept URL and File objects",
        "Type": "Improvement",
        "Status": "Closed",
        "Priority": "Minor",
        "Resolution": "Fixed",
        "Affects Version/s": "None",
        "Fix Version/s": "tools-1.5.3",
        "Component/s": "Chunker,                                            Doccat,                                            Parser,                                            POS Tagger,                                            Sentence Detector,                                            Tokenizer",
        "Assignee": "J\u00f6rn Kottmann",
        "Reporter": "J\u00f6rn Kottmann",
        "Created": "27/Apr/12 13:51",
        "Updated": "13/Jul/12 09:08",
        "Resolved": "13/Jul/12 09:08",
        "Description": "Add a URL and a File constructor to all models.\nFurther information can be found in this thread:\nhttp://mail-archives.apache.org/mod_mbox/opennlp-dev/201204.mbox/%3C4F9A5E8C.4000104%40gmail.com%3E",
        "Issue Links": []
    },
    "OPENNLP-506": {
        "Key": "OPENNLP-290 Eclipse demo project",
        "Summary": "Exception in thread \"main\" java.io.FileNotFoundException: models\\en-parser-chunking.bin (The system cannot find the file specified)",
        "Type": "Sub-task",
        "Status": "Closed",
        "Priority": "Major",
        "Resolution": "Not A Problem",
        "Affects Version/s": "tools-1.5.2-incubating",
        "Fix Version/s": "None",
        "Component/s": "Parser",
        "Assignee": null,
        "Reporter": "Divya Seekunta",
        "Created": "06/May/12 09:42",
        "Updated": "02/Nov/16 18:28",
        "Resolved": "02/Nov/16 18:28",
        "Description": "I have tried running the demo application. The parser works fine but at the end I have the error message: Exception in thread \"main\" java.io.FileNotFoundException: models\\en-parser-chunking.bin (The system cannot find the file specified).\nI have downloaded the models and placed the zip files in the models folder.\nCould you please help?\nThanks",
        "Issue Links": []
    },
    "OPENNLP-507": {
        "Key": "OPENNLP-507",
        "Summary": "Parse.toString should output the default format and not just the covered text",
        "Type": "Improvement",
        "Status": "Closed",
        "Priority": "Minor",
        "Resolution": "Fixed",
        "Affects Version/s": "None",
        "Fix Version/s": "tools-1.5.3",
        "Component/s": "Parser",
        "Assignee": "J\u00f6rn Kottmann",
        "Reporter": "J\u00f6rn Kottmann",
        "Created": "07/May/12 08:08",
        "Updated": "07/May/12 09:12",
        "Resolved": "07/May/12 09:12",
        "Description": "The toString method in OpenNLP is used to output the default training format. The Parse.toString method just outputs the covered text.\nTo fix this a new method getCoveredText should be created and used instead of Parse.toString trhough the OpenNLP code base.",
        "Issue Links": []
    },
    "OPENNLP-508": {
        "Key": "OPENNLP-508",
        "Summary": "Add an option to create or expand a TagDictionary with training data",
        "Type": "New Feature",
        "Status": "Closed",
        "Priority": "Major",
        "Resolution": "Fixed",
        "Affects Version/s": "tools-1.5.3",
        "Fix Version/s": "tools-1.5.3",
        "Component/s": "POS Tagger",
        "Assignee": "William Colen",
        "Reporter": "William Colen",
        "Created": "08/May/12 19:48",
        "Updated": "01/Aug/12 13:33",
        "Resolved": "01/Aug/12 13:33",
        "Description": "It would be useful if we could expand or create the TagDictionary while training a POS Tagger model.\nI propose that we add a new command line argument, -tagDictCutoff, that would trigger the creation / expansion of the dictionary. The cutoff would represent the minimun number of occurrences that a word tag pair would occur in the training data before it is added to the dictionary. \nFurther information can be found on this conversation: http://mail-archives.apache.org/mod_mbox/opennlp-dev/201205.mbox/%3CCA%2BiWThJNQzLSc3NmDLbEzaORDWnFgbk_id3SJjuELVRSoMTJzQ%40mail.gmail.com%3E",
        "Issue Links": []
    },
    "OPENNLP-509": {
        "Key": "OPENNLP-509",
        "Summary": "opennlp.tools.parser.Parse.getParent() returning incorrect object",
        "Type": "Bug",
        "Status": "Closed",
        "Priority": "Major",
        "Resolution": "Fixed",
        "Affects Version/s": "tools-1.5.2-incubating",
        "Fix Version/s": "2.2.0",
        "Component/s": "Parser",
        "Assignee": "Martin Wiesner",
        "Reporter": "Ofer Tal",
        "Created": "16/May/12 18:13",
        "Updated": "09/Mar/23 14:19",
        "Resolved": "09/Mar/23 14:16",
        "Description": "After parsing a sentence with opennlp.tools.parser.Parse.parse() some (many) Parse children do not have the correct parent set.\nDetails:\ngiven a Parse node in the tree (let's assume it is in a variable named p)\nWhen iterating over the Parse[] returned by p.getChildren(), checking p.equals(children[i].getParent()) returns false in many, if not all of the nodes.\nMore background \u2013\nto create the parse tree, I used the code:\n\nopennlp.tools.parser.Parse p = new opennlp.tools.parser.Parse(parseSentence, new opennlp.tools.util.Span(0, parseSentence.Length), opennlp.tools.parser.AbstractBottomUpParser.INC_NODE, 1, null);\n\n            // create a parse object for each token and add it to the parent\n            int start = 0;\n            foreach (string token in tokenizedSentence)\n            {\n                {\n                    opennlp.tools.parser.Parse tokenParse = new opennlp.tools.parser.Parse(parseSentence,\n                                                            new opennlp.tools.util.Span(start, start + token.Length),\n                                                            opennlp.tools.parser.AbstractBottomUpParser.TOK_NODE,\n                                                            0,\n                                                            0);                    \n                    p.insert(tokenParse);\n                    start += token.Length + 1;\n                }\n            }\n\n            // fetch 1 possible parse trees\n            opennlp.tools.parser.Parse[] parses = parser.parse(p, 1);",
        "Issue Links": []
    },
    "OPENNLP-510": {
        "Key": "OPENNLP-510",
        "Summary": "Maven dependency on jwnl is broken",
        "Type": "Bug",
        "Status": "Closed",
        "Priority": "Blocker",
        "Resolution": "Fixed",
        "Affects Version/s": "tools-1.5.2-incubating,                                            tools-1.5.3",
        "Fix Version/s": "tools-1.5.3",
        "Component/s": "Build, Packaging and Test",
        "Assignee": "William Colen",
        "Reporter": "Fergal Monaghan",
        "Created": "22/May/12 12:49",
        "Updated": "03/Apr/13 11:43",
        "Resolved": "28/Feb/13 23:57",
        "Description": "Dependency in tools pom for jwnl has groupID and version of a no-longer available version of jwnl. An individual developer may be able to sidestep this with manual fixes to the local Maven repositroy, but this completely breaks continuous integration/build servers etc.. The attached patch fixes this by simply updating the dependency to the latest groupID and version for jwnl.",
        "Issue Links": []
    },
    "OPENNLP-511": {
        "Key": "OPENNLP-511",
        "Summary": "Create license files and SHA1 files for each jar",
        "Type": "Improvement",
        "Status": "Closed",
        "Priority": "Major",
        "Resolution": "Won't Fix",
        "Affects Version/s": "None",
        "Fix Version/s": "None",
        "Component/s": "None",
        "Assignee": null,
        "Reporter": "Lance Norskog",
        "Created": "03/Jun/12 05:44",
        "Updated": "09/Jan/17 09:21",
        "Resolved": "09/Jan/17 09:21",
        "Description": "The Solr trunk build system expects some files along with each jar.\n\na LICENSE-ASL file\na NOTICE file\na SHA1 file\n\nI have attached a patch with LICENSE and NOTICE files for 1.5.3-incubating. I don't know how to make Maven create sha1 files for the individual jars but it's probably some simple XML-fiddling.",
        "Issue Links": []
    },
    "OPENNLP-512": {
        "Key": "OPENNLP-512",
        "Summary": "Create sample descriptor for doccat Language Detector AE",
        "Type": "Improvement",
        "Status": "Closed",
        "Priority": "Trivial",
        "Resolution": "Fixed",
        "Affects Version/s": "None",
        "Fix Version/s": "tools-1.5.3",
        "Component/s": "UIMA Integration",
        "Assignee": "J\u00f6rn Kottmann",
        "Reporter": "J\u00f6rn Kottmann",
        "Created": "08/Jun/12 12:29",
        "Updated": "08/Jun/12 13:27",
        "Resolved": "08/Jun/12 13:27",
        "Description": "There should be a sample UIMA descriptor for the doccat based Langauge Detector AE.",
        "Issue Links": []
    },
    "OPENNLP-513": {
        "Key": "OPENNLP-513",
        "Summary": "Add support to drop a corpus to the Corpus Server",
        "Type": "Bug",
        "Status": "Closed",
        "Priority": "Major",
        "Resolution": "Won't Fix",
        "Affects Version/s": "None",
        "Fix Version/s": "None",
        "Component/s": "Corpus Server",
        "Assignee": null,
        "Reporter": "J\u00f6rn Kottmann",
        "Created": "26/Jun/12 12:49",
        "Updated": "16/Jan/17 14:30",
        "Resolved": "16/Jan/17 14:30",
        "Description": "The Corpus Server should provide support to drop a corpus which is no longer needed or was accidentally created. The support for this should be added to the API, the default implementation and the tools.",
        "Issue Links": []
    },
    "OPENNLP-514": {
        "Key": "OPENNLP-514",
        "Summary": "Pos tag separator char should be configurable in the cli",
        "Type": "Improvement",
        "Status": "Open",
        "Priority": "Minor",
        "Resolution": "Unresolved",
        "Affects Version/s": "None",
        "Fix Version/s": "None",
        "Component/s": "Command Line Interface,                                            POS Tagger",
        "Assignee": null,
        "Reporter": "J\u00f6rn Kottmann",
        "Created": "27/Jun/12 08:47",
        "Updated": "10/Dec/12 08:20",
        "Resolved": null,
        "Description": "The POS Tagger default format parser already supports a configurable word-tag separator char. It should optionally be possible to specify the separator char on the command line.",
        "Issue Links": []
    },
    "OPENNLP-515": {
        "Key": "OPENNLP-515",
        "Summary": "Request for multi-words expressions (MWE) support in serialization formats",
        "Type": "Improvement",
        "Status": "Open",
        "Priority": "Minor",
        "Resolution": "Unresolved",
        "Affects Version/s": "tools-1.5.3",
        "Fix Version/s": "None",
        "Component/s": "Chunker,                                            Command Line Interface,                                            Doccat,                                            Name Finder,                                            Parser,                                            POS Tagger",
        "Assignee": null,
        "Reporter": "Nicolas Hernandez",
        "Created": "27/Jun/12 14:46",
        "Updated": "16/Jan/17 14:33",
        "Resolved": null,
        "Description": "Multi-words expressions (MWE) are expressions with whitespace-separated words like \"traffic light\", \"in order to\", \"two thousand and one\", \"Jules Verne\"...\nSo far, by using the CLI to train a model (in particular a POS model), there was no way to specify what is a simple or a multi-word expressions. \nBy convention, users use the underscore character to concat the words of MWE and make MWE a token.\nConsequently a model trained by the API on the same data can be distinct since this preprocessing is not required.\nWe need to offer to the users the possibility to set by parameter in the CLI what is the MWE separator char sequence.\nThis concerns both trainers and labelers.\nA default MWE separator should be specified which will be used when serializing data with MWEs.",
        "Issue Links": []
    },
    "OPENNLP-516": {
        "Key": "OPENNLP-516",
        "Summary": "CreateModel should use PerceptronModelWriter when -perceptron option is specified",
        "Type": "Bug",
        "Status": "Closed",
        "Priority": "Trivial",
        "Resolution": "Fixed",
        "Affects Version/s": "None",
        "Fix Version/s": "tools-1.5.3",
        "Component/s": "Machine Learning",
        "Assignee": "J\u00f6rn Kottmann",
        "Reporter": "Koji Sekiguchi",
        "Created": "29/Jun/12 02:51",
        "Updated": "25/Jul/12 23:47",
        "Resolved": "25/Jul/12 22:09",
        "Description": "It seems that CreateModel in maxent sample always uses SuffixSensitiveGISModelWriter even if -perceptron option is used. As a result, Predict w/ -perceptron option outputs a broken result.",
        "Issue Links": []
    },
    "OPENNLP-517": {
        "Key": "OPENNLP-517",
        "Summary": "Sentence Detector Trainer Analysis Engine should support custom end-of-sentence chars",
        "Type": "Improvement",
        "Status": "Closed",
        "Priority": "Minor",
        "Resolution": "Fixed",
        "Affects Version/s": "None",
        "Fix Version/s": "tools-1.5.3",
        "Component/s": "Sentence Detector,                                            UIMA Integration",
        "Assignee": "J\u00f6rn Kottmann",
        "Reporter": "J\u00f6rn Kottmann",
        "Created": "06/Jul/12 10:01",
        "Updated": "10/Jul/12 07:56",
        "Resolved": "10/Jul/12 07:56",
        "Description": "The Sentence Detector Trainer UIMA integration should offer support for the new configurable end-of-sentence characters.",
        "Issue Links": []
    },
    "OPENNLP-518": {
        "Key": "OPENNLP-518",
        "Summary": "Model loading via URLs should support loading from files",
        "Type": "Bug",
        "Status": "Closed",
        "Priority": "Minor",
        "Resolution": "Won't Fix",
        "Affects Version/s": "None",
        "Fix Version/s": "None",
        "Component/s": "Cas Editor OpenNLP Plugin",
        "Assignee": null,
        "Reporter": "J\u00f6rn Kottmann",
        "Created": "10/Jul/12 09:13",
        "Updated": "16/Jan/17 14:29",
        "Resolved": "16/Jan/17 14:29",
        "Description": "Loading a model from http via a URL works already. The URL detection should also be able to detect file URLs and therefore support loading of models from file URLs.",
        "Issue Links": []
    },
    "OPENNLP-519": {
        "Key": "OPENNLP-519",
        "Summary": "Language Detector sample descriptor does not specify a resource manager configuration",
        "Type": "Bug",
        "Status": "Closed",
        "Priority": "Minor",
        "Resolution": "Fixed",
        "Affects Version/s": "None",
        "Fix Version/s": "tools-1.5.3",
        "Component/s": "UIMA Integration",
        "Assignee": "J\u00f6rn Kottmann",
        "Reporter": "J\u00f6rn Kottmann",
        "Created": "10/Jul/12 13:26",
        "Updated": "10/Jul/12 13:26",
        "Resolved": "10/Jul/12 13:26",
        "Description": "The Language Detector sample is missing the resource manager configuration. To make using the sample easy the missing configuration needs to be added.",
        "Issue Links": []
    },
    "OPENNLP-520": {
        "Key": "OPENNLP-520",
        "Summary": "Artifacts of legacy models are not correctly validated by tools that implements the factory mechanism",
        "Type": "Bug",
        "Status": "Closed",
        "Priority": "Major",
        "Resolution": "Fixed",
        "Affects Version/s": "tools-1.5.3",
        "Fix Version/s": "tools-1.5.3",
        "Component/s": "None",
        "Assignee": "William Colen",
        "Reporter": "William Colen",
        "Created": "11/Jul/12 15:28",
        "Updated": "11/Jul/12 17:02",
        "Resolved": "11/Jul/12 17:02",
        "Description": "Models that does not explicitly specify a Factory (legacy models doesn't), does not have all artifacts validated.",
        "Issue Links": []
    },
    "OPENNLP-521": {
        "Key": "OPENNLP-521",
        "Summary": "Skip POSTag dictionary validation during runtime",
        "Type": "Improvement",
        "Status": "Closed",
        "Priority": "Minor",
        "Resolution": "Fixed",
        "Affects Version/s": "tools-1.5.3",
        "Fix Version/s": "tools-1.5.3",
        "Component/s": "POS Tagger",
        "Assignee": "William Colen",
        "Reporter": "William Colen",
        "Created": "11/Jul/12 19:19",
        "Updated": "11/Jul/12 19:32",
        "Resolved": "11/Jul/12 19:32",
        "Description": "The POS Tagger tool validates a POS Dictionary by checking if the POS tags in the dictionary are known by the model. Depending on the dictionary size it can take several seconds to validate it. We should have a mechanism to validate it only once, during model creation.",
        "Issue Links": []
    },
    "OPENNLP-522": {
        "Key": "OPENNLP-522",
        "Summary": "Improve exceptions in BaseModel",
        "Type": "Improvement",
        "Status": "Closed",
        "Priority": "Minor",
        "Resolution": "Fixed",
        "Affects Version/s": "None",
        "Fix Version/s": "tools-1.5.3",
        "Component/s": "None",
        "Assignee": "J\u00f6rn Kottmann",
        "Reporter": "Daniel Naber",
        "Created": "12/Jul/12 20:58",
        "Updated": "12/Jul/12 22:06",
        "Resolved": "12/Jul/12 21:55",
        "Description": "Attaching patch that 1) makes the snapshot version check more verbose 2) sets the causing exception at several places so the user gets clean stack traces with \"Caused by...\" information 3) fixes one typo in a parameter name",
        "Issue Links": []
    },
    "OPENNLP-523": {
        "Key": "OPENNLP-523",
        "Summary": "Add a French detokenizer dictionary",
        "Type": "Improvement",
        "Status": "Closed",
        "Priority": "Minor",
        "Resolution": "Fixed",
        "Affects Version/s": "None",
        "Fix Version/s": "tools-1.5.3",
        "Component/s": "Tokenizer",
        "Assignee": null,
        "Reporter": "J\u00f6rn Kottmann",
        "Created": "13/Jul/12 09:45",
        "Updated": "11/Sep/12 13:04",
        "Resolved": "11/Sep/12 13:04",
        "Description": "Add a detokenizer dictionary for French.",
        "Issue Links": []
    },
    "OPENNLP-524": {
        "Key": "OPENNLP-524",
        "Summary": "Tokenizer does not load 1.5.0 sourceforge model",
        "Type": "Bug",
        "Status": "Closed",
        "Priority": "Major",
        "Resolution": "Fixed",
        "Affects Version/s": "None",
        "Fix Version/s": "tools-1.5.3",
        "Component/s": "Tokenizer",
        "Assignee": "William Colen",
        "Reporter": "J\u00f6rn Kottmann",
        "Created": "13/Jul/12 14:23",
        "Updated": "19/Jul/12 14:58",
        "Resolved": "17/Jul/12 20:48",
        "Description": "I am doing some testing (of trunk) and run into this issue.\nThe tokenizer refuses to load the model from the sourceforge\nsite.\nI am getting this exception:\nCaused by: java.lang.IllegalArgumentException: opennlp.tools.util.InvalidFormatException: alphaNumericPattern is a mandatory property!\n    at opennlp.tools.util.model.BaseModel.checkArtifactMap(BaseModel.java:470)\n    at opennlp.tools.util.model.BaseModel.loadModel(BaseModel.java:241)\n    at opennlp.tools.util.model.BaseModel.<init>(BaseModel.java:181)\n    at opennlp.tools.tokenize.TokenizerModel.<init>(TokenizerModel.java:125)\n    at opennlp.tools.cmdline.tokenizer.TokenizerModelLoader.loadModel(TokenizerModelLoader.java:39)\n    at opennlp.tools.cmdline.tokenizer.TokenizerModelLoader.loadModel(TokenizerModelLoader.java:31)\n    at opennlp.tools.cmdline.ModelLoader.load(ModelLoader.java:62)\n    at opennlp.tools.cmdline.tokenizer.TokenizerMETool.run(TokenizerMETool.java:41)\n    at opennlp.tools.cmdline.CLI.main(CLI.java:225)\n    ... 6 more\nCaused by: opennlp.tools.util.InvalidFormatException: alphaNumericPattern is a mandatory property!\n    at opennlp.tools.tokenize.TokenizerFactory.validateArtifactMap(TokenizerFactory.java:98)\n    at opennlp.tools.util.model.BaseModel.validateArtifactMap(BaseModel.java:451)\n    at opennlp.tools.tokenize.TokenizerModel.validateArtifactMap(TokenizerModel.java:148)\n    at opennlp.tools.util.model.BaseModel.checkArtifactMap(BaseModel.java:468)\n    ... 14 more",
        "Issue Links": []
    },
    "OPENNLP-525": {
        "Key": "OPENNLP-525",
        "Summary": "Exception cleanup in opennlp-tools",
        "Type": "Improvement",
        "Status": "Closed",
        "Priority": "Minor",
        "Resolution": "Fixed",
        "Affects Version/s": "None",
        "Fix Version/s": "tools-1.5.3",
        "Component/s": "None",
        "Assignee": "Aliaksandr Autayeu",
        "Reporter": "Daniel Naber",
        "Created": "18/Jul/12 20:45",
        "Updated": "21/Jul/12 10:09",
        "Resolved": "21/Jul/12 10:09",
        "Description": "As a follow-up to OPENNLP-522 I looked through the exceptions throw in opennlp-tools and tried to improve them, i.e. adding better error messages and not losing the causing exception. I must admit I'm not sure if it's really needed to show the cause in CLI.java or if that always happens anyway (as there are e.printStackTrace() statements in the code). The patch also contains one or two small typo fixes.",
        "Issue Links": []
    },
    "OPENNLP-526": {
        "Key": "OPENNLP-526",
        "Summary": "Exception cleanup in opennlp-maxent/uima",
        "Type": "Improvement",
        "Status": "Closed",
        "Priority": "Minor",
        "Resolution": "Fixed",
        "Affects Version/s": "None",
        "Fix Version/s": "tools-1.5.3",
        "Component/s": "None",
        "Assignee": "Aliaksandr Autayeu",
        "Reporter": "Daniel Naber",
        "Created": "19/Jul/12 22:03",
        "Updated": "21/Jul/12 10:24",
        "Resolved": "21/Jul/12 10:24",
        "Description": "Final follow-up to OPENNLP-525: small exception cleanups in uima and maxent: mostly typo fixes and slightly more verbose exception messages + not losing cause of exception",
        "Issue Links": []
    },
    "OPENNLP-527": {
        "Key": "OPENNLP-527",
        "Summary": "No way to close FileEventStreams",
        "Type": "Bug",
        "Status": "Closed",
        "Priority": "Major",
        "Resolution": "Fixed",
        "Affects Version/s": "maxent-3.0.2-incubating",
        "Fix Version/s": "tools-1.5.3",
        "Component/s": "Machine Learning",
        "Assignee": "J\u00f6rn Kottmann",
        "Reporter": "Steven Bethard",
        "Created": "24/Jul/12 19:13",
        "Updated": "25/Jul/12 22:30",
        "Resolved": "25/Jul/12 21:40",
        "Description": "So I noticed this bug because RealValueFileEventStream.main does not close the EventStream that it opens, leaving a new file open every time it is called.\nI thought I could work around this by inlining the RealValueFileEventStream.main code, but it turns out that RealValueFileEventStream doesn't have a close method so there's nothing you can do. It's superclass, FileEventStream, opens up a FileInputStream, but doesn't expose that in any way.\nSo, as far as I can tell, there's no way to close one of these event streams.\nI think the simplest solution would be to add a .close() method to FileEventStream (and have it implement java.io.Closeable). Then RealValueFileEventStream would inherit that method.",
        "Issue Links": []
    },
    "OPENNLP-528": {
        "Key": "OPENNLP-528",
        "Summary": "Corpus Server should be able to update the Type System for a corpus",
        "Type": "Improvement",
        "Status": "Closed",
        "Priority": "Minor",
        "Resolution": "Fixed",
        "Affects Version/s": "None",
        "Fix Version/s": "None",
        "Component/s": "Corpus Server",
        "Assignee": "J\u00f6rn Kottmann",
        "Reporter": "J\u00f6rn Kottmann",
        "Created": "31/Jul/12 12:56",
        "Updated": "01/Aug/12 07:29",
        "Resolved": "01/Aug/12 07:29",
        "Description": "The CS should have a rest method to update the Type System of a corpus.",
        "Issue Links": []
    },
    "OPENNLP-529": {
        "Key": "OPENNLP-529",
        "Summary": "AD formatter is not working with Amazonia corpus",
        "Type": "Bug",
        "Status": "Closed",
        "Priority": "Major",
        "Resolution": "Fixed",
        "Affects Version/s": "tools-1.5.3",
        "Fix Version/s": "tools-1.5.3",
        "Component/s": "Formats",
        "Assignee": "William Colen",
        "Reporter": "William Colen",
        "Created": "01/Aug/12 14:01",
        "Updated": "01/Aug/12 14:13",
        "Resolved": "01/Aug/12 14:13",
        "Description": "AD formatter is not working with Amazonia corpus. Some sentences in this corpus does not have a root element. This causes some sentences to have missing nodes because the current code thinks the sentence has ended.\nOne solution is to create a fake root element and add child nodes to it before starting processing, so we don't need to change the part of the code that is already tested and working.",
        "Issue Links": []
    },
    "OPENNLP-530": {
        "Key": "OPENNLP-530",
        "Summary": "AD NameFinder formatter is not working correctly with contractions",
        "Type": "Bug",
        "Status": "Closed",
        "Priority": "Major",
        "Resolution": "Fixed",
        "Affects Version/s": "tools-1.5.3",
        "Fix Version/s": "tools-1.5.3",
        "Component/s": "Formats",
        "Assignee": "William Colen",
        "Reporter": "William Colen",
        "Created": "01/Aug/12 14:20",
        "Updated": "01/Aug/12 16:52",
        "Resolved": "01/Aug/12 16:52",
        "Description": "To recognize a contraction the AD parser was looking for \"<sam->\" and \"<-sam>\" tags, but Amazonia corpus sometime omit the second tag and it is causing issues while parsing the corpus.",
        "Issue Links": []
    },
    "OPENNLP-531": {
        "Key": "OPENNLP-531",
        "Summary": "Article output directory should be configurable",
        "Type": "Bug",
        "Status": "Closed",
        "Priority": "Minor",
        "Resolution": "Fixed",
        "Affects Version/s": "None",
        "Fix Version/s": "None",
        "Component/s": "Wikinews Importer",
        "Assignee": "J\u00f6rn Kottmann",
        "Reporter": "J\u00f6rn Kottmann",
        "Created": "03/Aug/12 10:33",
        "Updated": "03/Aug/12 10:35",
        "Resolved": "03/Aug/12 10:35",
        "Description": "The directory in which the articles are dumped is hard coded, but it should be configurable.",
        "Issue Links": []
    },
    "OPENNLP-532": {
        "Key": "OPENNLP-532",
        "Summary": "Add start scripts to the corpus-server-tools and wikinews-importer",
        "Type": "Improvement",
        "Status": "Closed",
        "Priority": "Minor",
        "Resolution": "Won't Fix",
        "Affects Version/s": "None",
        "Fix Version/s": "None",
        "Component/s": "Corpus Server,                                            Wikinews Importer",
        "Assignee": null,
        "Reporter": "J\u00f6rn Kottmann",
        "Created": "03/Aug/12 10:36",
        "Updated": "16/Jan/17 14:31",
        "Resolved": "16/Jan/17 14:31",
        "Description": "Add start scripts. To easily start the tools from the command line a maven based start script should be added.",
        "Issue Links": []
    },
    "OPENNLP-533": {
        "Key": "OPENNLP-533",
        "Summary": "TypeSystem uses UIMA-reserved keyword blocking JCasGen from generating needed classes",
        "Type": "Bug",
        "Status": "Closed",
        "Priority": "Minor",
        "Resolution": "Fixed",
        "Affects Version/s": "tools-1.5.3",
        "Fix Version/s": "1.6.0",
        "Component/s": "UIMA Integration",
        "Assignee": "J\u00f6rn Kottmann",
        "Reporter": "Fergal Monaghan",
        "Created": "15/Aug/12 09:50",
        "Updated": "17/Jan/14 17:59",
        "Resolved": "03/Jan/14 13:43",
        "Description": "OpenNLP 1.5.3's UIMA TypeSystem uses the reserved keyword \"type\" for one of the features of it's Parse type:\nhttps://svn.apache.org/repos/asf/opennlp/trunk/opennlp-uima/descriptors/TypeSystem.xml\n\"...\n\t<name>Apache OpenNLP TypeSystem</name>\n...\n\t<types>\n...\n\t\t<typeDescription>\n\t\t\t<name>opennlp.uima.Parse</name>\n\t\t\t<supertypeName>uima.tcas.Annotation</supertypeName>\n\t\t\t<features>\n\t\t\t\t<featureDescription>\n\t\t\t\t\t<name>type</name>\n...\"\nThis makes it incompatible with UIMA 2.4.0's JCasGen for generating necessary Java classes from a TypeSystem at runtime:\nhttp://svn.apache.org/viewvc/uima/uimaj/trunk/uimaj-tools/src/main/java/org/apache/uima/tools/jcasgen/Jg.java?revision=1338200&view=markup\nLine 105: \"reservedFeatureNames.add(\"Type\");\"\nThis results in the below exception in projects that need to use OpenNLP's UIMA Integration with JCasGen.\nOne simple fix to this would be to change \"type\" to \"parseType\" (as per the \"chunkType\" feature of the Chunk type). I have attached a Patch that implements this fix.\nThanks,\nFergal.\n=====\n[INFO] Scanning for projects...\n[INFO] \n[INFO] ------------------------------------------------------------------------\n[INFO] Building Example Annotator 0.0.1\n[INFO] ------------------------------------------------------------------------\n...\n[INFO] \n[INFO] >>> exec-maven-plugin:1.2.1.jbossorg-3:java (jcasgen) @ ExampleAnnotator >>>\n[INFO] \n[INFO] <<< exec-maven-plugin:1.2.1.jbossorg-3:java (jcasgen) @ ExampleAnnotator <<<\n[INFO] \n[INFO] \u2014 exec-maven-plugin:1.2.1.jbossorg-3:java (jcasgen) @ ExampleAnnotator \u2014\n14-Aug-2012 17:57:01 org.apache.uima.tools.jcasgen.UimaLoggerProgressMonitor subTask(35)\nINFO:  >>JCasGen Replacing: 'opennlp.uima.Sentence'.\n14-Aug-2012 17:57:01 org.apache.uima.tools.jcasgen.UimaLoggerProgressMonitor subTask(35)\nINFO:  >>JCasGen Replacing: 'opennlp.uima.Sentence_Type'.\n14-Aug-2012 17:57:01 org.apache.uima.tools.jcasgen.UimaLoggerProgressMonitor subTask(35)\nINFO:  >>JCasGen Replacing: 'opennlp.uima.Token'.\n14-Aug-2012 17:57:01 org.apache.uima.tools.jcasgen.UimaLoggerProgressMonitor subTask(35)\nINFO:  >>JCasGen Replacing: 'opennlp.uima.Token_Type'.\n14-Aug-2012 17:57:01 org.apache.uima.tools.jcasgen.UimaLoggerProgressMonitor subTask(35)\nINFO:  >>JCasGen Replacing: 'opennlp.uima.Chunk'.\n14-Aug-2012 17:57:01 org.apache.uima.tools.jcasgen.UimaLoggerProgressMonitor subTask(35)\nINFO:  >>JCasGen Replacing: 'opennlp.uima.Chunk_Type'.\n14-Aug-2012 17:57:01 org.apache.uima.tools.jcasgen.UimaLoggerProgressMonitor subTask(35)\nINFO:  >>JCasGen Replacing: 'opennlp.uima.Person'.\n14-Aug-2012 17:57:01 org.apache.uima.tools.jcasgen.UimaLoggerProgressMonitor subTask(35)\nINFO:  >>JCasGen Replacing: 'opennlp.uima.Person_Type'.\n14-Aug-2012 17:57:01 org.apache.uima.tools.jcasgen.UimaLoggerProgressMonitor subTask(35)\nINFO:  >>JCasGen Replacing: 'opennlp.uima.Organization'.\n14-Aug-2012 17:57:01 org.apache.uima.tools.jcasgen.UimaLoggerProgressMonitor subTask(35)\nINFO:  >>JCasGen Replacing: 'opennlp.uima.Organization_Type'.\n14-Aug-2012 17:57:01 org.apache.uima.tools.jcasgen.UimaLoggerProgressMonitor subTask(35)\nINFO:  >>JCasGen Replacing: 'opennlp.uima.Location'.\n14-Aug-2012 17:57:01 org.apache.uima.tools.jcasgen.UimaLoggerProgressMonitor subTask(35)\nINFO:  >>JCasGen Replacing: 'opennlp.uima.Location_Type'.\n14-Aug-2012 17:57:01 org.apache.uima.tools.jcasgen.UimaLoggerProgressMonitor subTask(35)\nINFO:  >>JCasGen Replacing: 'opennlp.uima.Date'.\n14-Aug-2012 17:57:01 org.apache.uima.tools.jcasgen.UimaLoggerProgressMonitor subTask(35)\nINFO:  >>JCasGen Replacing: 'opennlp.uima.Date_Type'.\n14-Aug-2012 17:57:01 org.apache.uima.tools.jcasgen.UimaLoggerProgressMonitor subTask(35)\nINFO:  >>JCasGen Replacing: 'opennlp.uima.Time'.\n14-Aug-2012 17:57:01 org.apache.uima.tools.jcasgen.UimaLoggerProgressMonitor subTask(35)\nINFO:  >>JCasGen Replacing: 'opennlp.uima.Time_Type'.\n14-Aug-2012 17:57:01 org.apache.uima.tools.jcasgen.UimaLoggerProgressMonitor subTask(35)\nINFO:  >>JCasGen Replacing: 'opennlp.uima.Money'.\n14-Aug-2012 17:57:01 org.apache.uima.tools.jcasgen.UimaLoggerProgressMonitor subTask(35)\nINFO:  >>JCasGen Replacing: 'opennlp.uima.Money_Type'.\n14-Aug-2012 17:57:01 org.apache.uima.tools.jcasgen.UimaLoggerProgressMonitor subTask(35)\nINFO:  >>JCasGen Replacing: 'opennlp.uima.Percentage'.\n14-Aug-2012 17:57:01 org.apache.uima.tools.jcasgen.UimaLoggerProgressMonitor subTask(35)\nINFO:  >>JCasGen Replacing: 'opennlp.uima.Percentage_Type'.\n14-Aug-2012 17:57:01 org.apache.uima.tools.jcasgen.LogThrowErrorImpl newError(37)\nSEVERE: JCasGen: The feature name 'type', specified in Type 'opennlp.uima.Parse' is reserved. Please choose another name.\n[WARNING] \njava.lang.reflect.InvocationTargetException\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)\n\tat java.lang.reflect.Method.invoke(Method.java:597)\n\tat org.codehaus.mojo.exec.ExecJavaMojo$1.run(ExecJavaMojo.java:297)\n\tat java.lang.Thread.run(Thread.java:662)\nCaused by: org.apache.uima.tools.jcasgen.Jg$ErrorExit\n\tat org.apache.uima.tools.jcasgen.LogThrowErrorImpl.newError(LogThrowErrorImpl.java:39)\n\tat org.apache.uima.tools.jcasgen.JCasTypeTemplate.generate(JCasTypeTemplate.java:90)\n\tat org.apache.uima.tools.jcasgen.Jg.generateClassesFromTemplate(Jg.java:665)\n\tat org.apache.uima.tools.jcasgen.Jg.generateAllTypesFromTemplates(Jg.java:605)\n\tat org.apache.uima.tools.jcasgen.Jg.mainGenerateAllTypesFromTemplates(Jg.java:370)\n\tat org.apache.uima.tools.jcasgen.Jg.mainForCde(Jg.java:347)\n\tat org.uimafit.util.JCasGenPomFriendly.generate(JCasGenPomFriendly.java:89)\n\tat org.uimafit.util.JCasGenPomFriendly.main(JCasGenPomFriendly.java:76)\n\t... 6 more\n[INFO] ------------------------------------------------------------------------\n[INFO] BUILD FAILURE\n[INFO] ------------------------------------------------------------------------\n[INFO] Total time: 12.864s\n[INFO] Finished at: Tue Aug 14 17:57:01 BST 2012\n[INFO] Final Memory: 10M/107M\n[INFO] ------------------------------------------------------------------------\n[ERROR] Failed to execute goal org.codehaus.mojo:exec-maven-plugin:1.2.1.jbossorg-3:java (jcasgen) on project ExampleAnnotator: An exception occurred while executing the Java class. null: InvocationTargetException: ErrorExit -> [Help 1]\n[ERROR] \n[ERROR] To see the full stack trace of the errors, re-run Maven with the -e switch.\n[ERROR] Re-run Maven using the -X switch to enable full debug logging.\n[ERROR] \n[ERROR] For more information about the errors and possible solutions, please read the following articles:\n[ERROR] [Help 1] http://cwiki.apache.org/confluence/display/MAVEN/MojoExecutionException",
        "Issue Links": []
    },
    "OPENNLP-534": {
        "Key": "OPENNLP-534",
        "Summary": "Parser training no longer has option to learn/generate function tags",
        "Type": "Bug",
        "Status": "Closed",
        "Priority": "Minor",
        "Resolution": "Fixed",
        "Affects Version/s": "None",
        "Fix Version/s": "tools-1.5.3",
        "Component/s": "Parser",
        "Assignee": "J\u00f6rn Kottmann",
        "Reporter": "Tim Miller",
        "Created": "20/Aug/12 15:53",
        "Updated": "23/Aug/12 14:45",
        "Resolved": "23/Aug/12 08:39",
        "Description": "In version 1.5.*, the ability to train the parser to learn function tags (e.g., the -SBJ on a constituent NP-SBJ).  In previous versions, this could be accomplished by using the -fun flag in the training call.  That flag seems to have been left off in the transition to the new ParserTrainer architecture.  Restoring this functionality would be trivial \u2013 it simply triggered a call to Parse.useFunctionTags(true).",
        "Issue Links": []
    },
    "OPENNLP-535": {
        "Key": "OPENNLP-535",
        "Summary": "Tokenizer trainer should create a trace file during training",
        "Type": "Improvement",
        "Status": "Closed",
        "Priority": "Minor",
        "Resolution": "Fixed",
        "Affects Version/s": "None",
        "Fix Version/s": "tools-1.5.3",
        "Component/s": "UIMA Integration",
        "Assignee": null,
        "Reporter": "J\u00f6rn Kottmann",
        "Created": "11/Sep/12 12:10",
        "Updated": "11/Sep/12 13:01",
        "Resolved": "11/Sep/12 13:01",
        "Description": "The UIMA OpenNLP Tokenizer Trainer should have an option to create a trace file. The file should contain the training data in the OpenNLP format.",
        "Issue Links": []
    },
    "OPENNLP-536": {
        "Key": "OPENNLP-536",
        "Summary": "Sentence Detector trainer should create a trace file during training",
        "Type": "Improvement",
        "Status": "Closed",
        "Priority": "Minor",
        "Resolution": "Fixed",
        "Affects Version/s": "None",
        "Fix Version/s": "tools-1.5.3",
        "Component/s": "UIMA Integration",
        "Assignee": "J\u00f6rn Kottmann",
        "Reporter": "J\u00f6rn Kottmann",
        "Created": "11/Sep/12 13:14",
        "Updated": "11/Sep/12 14:03",
        "Resolved": "11/Sep/12 14:03",
        "Description": "The UIMA OpenNLP Sentence Detector trainer should have an option to create a sample trace file during training.",
        "Issue Links": []
    },
    "OPENNLP-537": {
        "Key": "OPENNLP-537",
        "Summary": "make an access to generic search engines to demonstrate search results re-ranking",
        "Type": "Bug",
        "Status": "Closed",
        "Priority": "Major",
        "Resolution": "Fixed",
        "Affects Version/s": "None",
        "Fix Version/s": "None",
        "Component/s": "Similarity",
        "Assignee": "Boris Galitsky",
        "Reporter": "Boris Galitsky",
        "Created": "19/Sep/12 17:32",
        "Updated": "03/Apr/13 08:44",
        "Resolved": "19/Sep/12 18:48",
        "Description": "Before I used Bing and Yahoo search engine APIs, neither of them are free now and",
        "Issue Links": []
    },
    "OPENNLP-538": {
        "Key": "OPENNLP-538",
        "Summary": "Another illustration for similarity component: converting natural language task into Java code",
        "Type": "New Feature",
        "Status": "Closed",
        "Priority": "Major",
        "Resolution": "Fixed",
        "Affects Version/s": "None",
        "Fix Version/s": "None",
        "Component/s": "Similarity",
        "Assignee": null,
        "Reporter": "Boris Galitsky",
        "Created": "19/Sep/12 22:00",
        "Updated": "03/Apr/13 08:44",
        "Resolved": "02/Oct/12 22:57",
        "Description": "This is one more application area for Similarity and OpenNLP, translator from NL task into a code, illustrating how NL understanding can improve the efficiency of programming",
        "Issue Links": []
    },
    "OPENNLP-539": {
        "Key": "OPENNLP-539",
        "Summary": "Create a factory to customize the Chunker",
        "Type": "Bug",
        "Status": "Closed",
        "Priority": "Minor",
        "Resolution": "Fixed",
        "Affects Version/s": "tools-1.5.3",
        "Fix Version/s": "tools-1.5.3",
        "Component/s": "Chunker",
        "Assignee": "William Colen",
        "Reporter": "William Colen",
        "Created": "02/Oct/12 14:38",
        "Updated": "09/Oct/12 22:50",
        "Resolved": "09/Oct/12 22:50",
        "Description": "Create the mechanism to extend the Chunker, like we already do for other components, like the POS Tagger.",
        "Issue Links": []
    },
    "OPENNLP-540": {
        "Key": "OPENNLP-540",
        "Summary": "SOLR request handler for search results re-ranking based on 'Similarity'",
        "Type": "New Feature",
        "Status": "Closed",
        "Priority": "Major",
        "Resolution": "Fixed",
        "Affects Version/s": "None",
        "Fix Version/s": "None",
        "Component/s": "Similarity",
        "Assignee": "Boris Galitsky",
        "Reporter": "Boris Galitsky",
        "Created": "02/Oct/12 22:54",
        "Updated": "03/Apr/13 08:44",
        "Resolved": "03/Oct/12 19:53",
        "Description": "Similarity component helps to improve search relevance by assuring syntactic similarity between questions and answers. Now we have a request handler for SOLR to do search results re-ranking. This is one of the ways OpenNLP is integrated into SOLR",
        "Issue Links": []
    },
    "OPENNLP-541": {
        "Key": "OPENNLP-541",
        "Summary": "Improve ADChunkSampleStream",
        "Type": "Bug",
        "Status": "Closed",
        "Priority": "Minor",
        "Resolution": "Fixed",
        "Affects Version/s": "tools-1.5.3",
        "Fix Version/s": "tools-1.5.3",
        "Component/s": "Chunker,                                            Formats",
        "Assignee": "William Colen",
        "Reporter": "William Colen",
        "Created": "09/Oct/12 22:55",
        "Updated": "20/Dec/12 11:36",
        "Resolved": "20/Dec/12 11:36",
        "Description": "I notice a few issues with the formatter from AD to Chunk. It was not working correctly for some longer chunks, sometimes it would create a new chunk instead of continuing it.\nAlso, I changed a little the visibility and created some methods to make it easier to customize this formatter.",
        "Issue Links": []
    },
    "OPENNLP-542": {
        "Key": "OPENNLP-542",
        "Summary": "Missing arguments for TokenNameFinderConverter",
        "Type": "Bug",
        "Status": "Closed",
        "Priority": "Major",
        "Resolution": "Won't Fix",
        "Affects Version/s": "None",
        "Fix Version/s": "None",
        "Component/s": "Command Line Interface",
        "Assignee": null,
        "Reporter": "Rog\u00e9rio Pereira Ara\u00fajo",
        "Created": "23/Oct/12 14:51",
        "Updated": "03/Apr/13 08:55",
        "Resolved": "03/Apr/13 08:55",
        "Description": "The documentation gives this example of command line for TokenNameFinderConverter\nbin/opennlp TokenNameFinderConverter ad -encoding ISO-8859-1 -data amazonia.ad \\ -lang pt -types per > corpus.txt\nBut for apache-opennlp-1.5.2-incubating the tool is reporting the following:\nUsage: opennlp TokenNameFinderConverter ad -encoding encoding -data sampleData\nArguments description:\n\t-encoding encoding\n\t-data sampleData\nIs there any workarounds?",
        "Issue Links": []
    },
    "OPENNLP-543": {
        "Key": "OPENNLP-543",
        "Summary": "Documentation of OpenNLP Traning Format",
        "Type": "Bug",
        "Status": "Closed",
        "Priority": "Major",
        "Resolution": "Won't Fix",
        "Affects Version/s": "None",
        "Fix Version/s": "None",
        "Component/s": "None",
        "Assignee": null,
        "Reporter": "Marc Schreiber",
        "Created": "30/Oct/12 13:52",
        "Updated": "16/Jan/17 14:44",
        "Resolved": "16/Jan/17 14:44",
        "Description": "Is there any documentation about the training formats which OpenNLP supports?\nI'm working on a project where we need our own models because the project concentrates on specific domains. It would be really great if there is any help for building your own models. \nIf there is no documentation I would offer my help for creating such a documentation but I need someone who helps me with the training formats.",
        "Issue Links": []
    },
    "OPENNLP-544": {
        "Key": "OPENNLP-544",
        "Summary": "Added an interface for opennlp.tools.util.Span",
        "Type": "Improvement",
        "Status": "Closed",
        "Priority": "Trivial",
        "Resolution": "Won't Fix",
        "Affects Version/s": "tools-1.5.3",
        "Fix Version/s": "None",
        "Component/s": "Tokenizer",
        "Assignee": null,
        "Reporter": "Chris Fournier",
        "Created": "31/Oct/12 14:27",
        "Updated": "23/Dec/16 18:21",
        "Resolved": "23/Dec/16 18:21",
        "Description": "Added an interface, opennlp.tools.util.Spannable, to allow for the creation of objects that can span text and fulfill the same functionality as Span without necessarily needing to extend it (currently implemented only by opennlp.tools.util.Span).",
        "Issue Links": []
    },
    "OPENNLP-545": {
        "Key": "OPENNLP-545",
        "Summary": "Add Word Sense Disambiguation (WSD) component",
        "Type": "New Feature",
        "Status": "Open",
        "Priority": "Major",
        "Resolution": "Unresolved",
        "Affects Version/s": "None",
        "Fix Version/s": "None",
        "Component/s": "wsd",
        "Assignee": null,
        "Reporter": "Pei Chen",
        "Created": "07/Nov/12 22:16",
        "Updated": "11/Jan/17 12:38",
        "Resolved": null,
        "Description": "Add Word Sense Disambiguation (WSD) component",
        "Issue Links": []
    },
    "OPENNLP-546": {
        "Key": "OPENNLP-546",
        "Summary": "Add TokenizerPTB",
        "Type": "New Feature",
        "Status": "Open",
        "Priority": "Minor",
        "Resolution": "Unresolved",
        "Affects Version/s": "None",
        "Fix Version/s": "None",
        "Component/s": "Tokenizer",
        "Assignee": null,
        "Reporter": "Pei Chen",
        "Created": "07/Nov/12 22:18",
        "Updated": "11/Jan/17 12:32",
        "Resolved": null,
        "Description": "Add Tokenizer based on Penn Tree Bank rules.",
        "Issue Links": [
            "/jira/browse/CTAKES-99"
        ]
    },
    "OPENNLP-547": {
        "Key": "OPENNLP-547",
        "Summary": "Add a dependency parser component",
        "Type": "Improvement",
        "Status": "Open",
        "Priority": "Major",
        "Resolution": "Unresolved",
        "Affects Version/s": "None",
        "Fix Version/s": "None",
        "Component/s": "None",
        "Assignee": "Rodrigo Agerri",
        "Reporter": "J\u00f6rn Kottmann",
        "Created": "07/Nov/12 23:55",
        "Updated": "18/Nov/20 17:28",
        "Resolved": null,
        "Description": "It would be nice to add a dependency parser component to OpenNLP.",
        "Issue Links": []
    },
    "OPENNLP-548": {
        "Key": "OPENNLP-548",
        "Summary": "integrate with Bing Azure API for web/image/video search",
        "Type": "New Feature",
        "Status": "Open",
        "Priority": "Major",
        "Resolution": "Unresolved",
        "Affects Version/s": "None",
        "Fix Version/s": "None",
        "Component/s": "Similarity",
        "Assignee": "Boris Galitsky",
        "Reporter": "Boris Galitsky",
        "Created": "14/Nov/12 23:31",
        "Updated": "14/Nov/12 23:31",
        "Resolved": null,
        "Description": "Bing changed its search API few months ago. New API required a key. To obtain a free key, there is a 5000 requests per month limit, and one needs to open a Windows Azure account",
        "Issue Links": []
    },
    "OPENNLP-549": {
        "Key": "OPENNLP-549",
        "Summary": "Inconsistent handling of lower-/upper- case POS tags in the JWNLDictionary.getLemmas method",
        "Type": "Improvement",
        "Status": "Closed",
        "Priority": "Major",
        "Resolution": "Fixed",
        "Affects Version/s": "tools-1.5.2-incubating",
        "Fix Version/s": "tools-1.5.3",
        "Component/s": "Coref",
        "Assignee": "Aliaksandr Autayeu",
        "Reporter": "Gleb Alexeyev",
        "Created": "16/Nov/12 11:05",
        "Updated": "19/Dec/12 22:19",
        "Resolved": "22/Nov/12 17:48",
        "Description": "JWNLDictionary.getLemmas method has a code that maps string-valued POS tags to net.didion.jwnl.data.POS instances, and this code clearly has a bug (for example, it maps tags starting with \"N\" both to POS.NOUN and POS.VERB). Please see the patch below (the patch assumes Penn TreeBank tags).\nIndex: src/main/java/opennlp/tools/coref/mention/JWNLDictionary.java\n===================================================================\n\u2014 src/main/java/opennlp/tools/coref/mention/JWNLDictionary.java\t(revision 1410284)\n+++ src/main/java/opennlp/tools/coref/mention/JWNLDictionary.java\t(working copy)\n@@ -84,10 +84,10 @@\n       if (tag.startsWith(\"N\") || tag.startsWith(\"n\")) \n{\n         pos = POS.NOUN;\n       }\n\nelse if (tag.startsWith(\"N\") || tag.startsWith(\"v\")) {\n+      else if (tag.startsWith(\"V\") || tag.startsWith(\"v\")) \n{\n         pos = POS.VERB;\n       }\nelse if (tag.startsWith(\"J\") || tag.startsWith(\"a\")) {\n+      else if (tag.startsWith(\"J\") || tag.startsWith(\"j\")) \n{\n         pos = POS.ADJECTIVE;\n       }\n       else if (tag.startsWith(\"R\") || tag.startsWith(\"r\")) {",
        "Issue Links": []
    },
    "OPENNLP-550": {
        "Key": "OPENNLP-550",
        "Summary": "No more recent nightly builds?",
        "Type": "Bug",
        "Status": "Closed",
        "Priority": "Minor",
        "Resolution": "Not A Problem",
        "Affects Version/s": "None",
        "Fix Version/s": "None",
        "Component/s": "None",
        "Assignee": null,
        "Reporter": "Daniel Naber",
        "Created": "22/Nov/12 15:17",
        "Updated": "09/Apr/13 14:51",
        "Resolved": "09/Apr/13 14:51",
        "Description": "It seems to me that the nightly builds stopped at Oct 10, or am I missing something? For example \nhttps://repository.apache.org/content/groups/snapshots/org/apache/opennlp/opennlp-distr/1.5.3-SNAPSHOT/ contains no recent builds.",
        "Issue Links": []
    },
    "OPENNLP-551": {
        "Key": "OPENNLP-551",
        "Summary": "add format support for evalita 07/09 NER datasets",
        "Type": "Improvement",
        "Status": "Closed",
        "Priority": "Minor",
        "Resolution": "Fixed",
        "Affects Version/s": "None",
        "Fix Version/s": "1.6.0",
        "Component/s": "Formats",
        "Assignee": "J\u00f6rn Kottmann",
        "Reporter": "Rodrigo Agerri",
        "Created": "19/Dec/12 12:02",
        "Updated": "17/Apr/13 12:20",
        "Resolved": "15/Apr/13 14:58",
        "Description": "Format conversion support for Evalita 07/09 NER datasets. These datasets follow the CoNLL 2003 formats except for the fact that instead of MISC category they use GPE (geopolitical entity).",
        "Issue Links": []
    },
    "OPENNLP-552": {
        "Key": "OPENNLP-552",
        "Summary": "Remove the legacy META-INF folder from  opennlp-maxent",
        "Type": "Improvement",
        "Status": "Closed",
        "Priority": "Trivial",
        "Resolution": "Fixed",
        "Affects Version/s": "None",
        "Fix Version/s": "tools-1.5.3,                                            maxent-3.0.3",
        "Component/s": "Machine Learning",
        "Assignee": null,
        "Reporter": "J\u00f6rn Kottmann",
        "Created": "19/Dec/12 21:45",
        "Updated": "19/Dec/12 22:18",
        "Resolved": "19/Dec/12 22:18",
        "Description": "The META-INF folder contains a MANIFEST which was used a long time ago to print an error message if java -jar is used to start the maxent jar file. The mechanism is no longer in place since a couple of releases. \nLets remove the META-INF folder.",
        "Issue Links": []
    },
    "OPENNLP-553": {
        "Key": "OPENNLP-553",
        "Summary": "Quasinewton trainer test should not write model to current working directory",
        "Type": "Improvement",
        "Status": "Closed",
        "Priority": "Major",
        "Resolution": "Fixed",
        "Affects Version/s": "None",
        "Fix Version/s": "tools-1.5.3,                                            maxent-3.0.3",
        "Component/s": "Machine Learning",
        "Assignee": "J\u00f6rn Kottmann",
        "Reporter": "J\u00f6rn Kottmann",
        "Created": "19/Dec/12 22:05",
        "Updated": "19/Dec/12 22:17",
        "Resolved": "19/Dec/12 22:17",
        "Description": "The QNTrainerTest writes a test model to the current working directory, which appears to be the opennlp-maxent folder. Modify the test to keep the model in-memory.",
        "Issue Links": []
    },
    "OPENNLP-554": {
        "Key": "OPENNLP-554",
        "Summary": "Java Update 7_10 breaks -jar with wildcard support",
        "Type": "Bug",
        "Status": "Closed",
        "Priority": "Minor",
        "Resolution": "Fixed",
        "Affects Version/s": "tools-1.5.3",
        "Fix Version/s": "tools-1.5.3",
        "Component/s": "Command Line Interface",
        "Assignee": "James Kosin",
        "Reporter": "James Kosin",
        "Created": "20/Dec/12 03:54",
        "Updated": "21/Dec/12 19:57",
        "Resolved": "21/Dec/12 19:57",
        "Description": "The 7u10 update to the Java VM breaks our usage of the opennlp-tools-*.jar to specify the jar files.  This means the CLI interface is broken on PCs with this newer version.",
        "Issue Links": []
    },
    "OPENNLP-555": {
        "Key": "OPENNLP-555",
        "Summary": "Saving a CAS just fails silently if there is a problem",
        "Type": "Bug",
        "Status": "Closed",
        "Priority": "Minor",
        "Resolution": "Fixed",
        "Affects Version/s": "None",
        "Fix Version/s": "None",
        "Component/s": "Cas Editor Corpus Server Plugin",
        "Assignee": "J\u00f6rn Kottmann",
        "Reporter": "J\u00f6rn Kottmann",
        "Created": "07/Jan/13 17:06",
        "Updated": "07/Jan/13 17:07",
        "Resolved": "07/Jan/13 17:07",
        "Description": "The Document Provider handling the saving of a CAS back to the Corpus Server should not fail silently if there is a problem. Instead it should throw a Core Exception to indicate the user about the problem.",
        "Issue Links": []
    },
    "OPENNLP-556": {
        "Key": "OPENNLP-556",
        "Summary": "CLI parser could report the bad parameters and flag them for the user",
        "Type": "Improvement",
        "Status": "Open",
        "Priority": "Minor",
        "Resolution": "Unresolved",
        "Affects Version/s": "tools-1.5.1-incubating,                                            tools-1.5.2-incubating,                                            tools-1.5.3",
        "Fix Version/s": "None",
        "Component/s": "Command Line Interface",
        "Assignee": null,
        "Reporter": "James Kosin",
        "Created": "11/Jan/13 02:58",
        "Updated": "11/Jan/13 12:24",
        "Resolved": null,
        "Description": "A mis-typed parameter can cause the parser to spit out the usage data e.g.:\n  -model-type\ninstead of the proper:\n  -type\nWill cause the CLI to only spit out the usage for the command and not tell the user what is likely to be wrong... in this case a mis-typed parameter caused the problem.\nMaybe only outputting usage data when no parameters, in most cases, and other times outputting the problem or place of the error.",
        "Issue Links": []
    },
    "OPENNLP-557": {
        "Key": "OPENNLP-557",
        "Summary": "Polish NLP",
        "Type": "New Feature",
        "Status": "Closed",
        "Priority": "Minor",
        "Resolution": "Won't Fix",
        "Affects Version/s": "None",
        "Fix Version/s": "None",
        "Component/s": "None",
        "Assignee": null,
        "Reporter": "Tomek",
        "Created": "14/Jan/13 14:49",
        "Updated": "08/Apr/13 14:35",
        "Resolved": "08/Apr/13 14:35",
        "Description": "Hi,\nrecently we have developed some NLP tools for Polish language.\nWe have implemented some OpenNLP interfaces (which we wanted to include in OpenNLP project):\n-Sentence detector\n-Tokenizer\n-Document Categorizer  (it needs to include in project tc.xml and cache.db files ,which are included in package)\n-Part-of-Speech Tagger\n-Chunker\n-Keyword Extractor\ndownload package: \nhttps://dl.dropbox.com/u/4021344/polishNLP.7z\npackage consist manual (manual/open_nlp_manual.html), javadoc, compiled java libraries , sources, cache.db and tc.xml files (used in document categorizer).\nTomek",
        "Issue Links": []
    },
    "OPENNLP-558": {
        "Key": "OPENNLP-558",
        "Summary": "machine learning train parameters  while training name finder",
        "Type": "Question",
        "Status": "Closed",
        "Priority": "Major",
        "Resolution": "Abandoned",
        "Affects Version/s": "None",
        "Fix Version/s": "None",
        "Component/s": "Name Finder",
        "Assignee": null,
        "Reporter": "prathamesh",
        "Created": "23/Jan/13 11:16",
        "Updated": "09/Apr/13 14:43",
        "Resolved": "09/Apr/13 14:43",
        "Description": "what should be machine learning train parameters  while training name finder can u please provide example",
        "Issue Links": []
    },
    "OPENNLP-559": {
        "Key": "OPENNLP-559",
        "Summary": "Enable UIMA Parser module",
        "Type": "Improvement",
        "Status": "Closed",
        "Priority": "Major",
        "Resolution": "Fixed",
        "Affects Version/s": "None",
        "Fix Version/s": "tools-1.5.3",
        "Component/s": "UIMA Integration",
        "Assignee": "J\u00f6rn Kottmann",
        "Reporter": "Alex Cichowski",
        "Created": "24/Jan/13 12:38",
        "Updated": "27/Feb/13 09:50",
        "Resolved": "23/Feb/13 13:05",
        "Description": "The Parser module (presumably likely to be an important component for many projects?) is missing from the OpenNlpTextAnalyzer.xml pipeline.\nopennlp-uima\\descriptors\\Parser.xml is present in e.g. SVN revision 1432812 but not referenced in OpenNlpTextAnalyzer.xml and createPear.xml.\nThe attached patches add Parser.xml to the OpenNlpTextAnalyzer pipeline.",
        "Issue Links": []
    },
    "OPENNLP-560": {
        "Key": "OPENNLP-560",
        "Summary": "Add training format support for the brat format",
        "Type": "New Feature",
        "Status": "Closed",
        "Priority": "Minor",
        "Resolution": "Fixed",
        "Affects Version/s": "None",
        "Fix Version/s": "1.6.0",
        "Component/s": "Formats",
        "Assignee": "J\u00f6rn Kottmann",
        "Reporter": "J\u00f6rn Kottmann",
        "Created": "12/Feb/13 14:28",
        "Updated": "16/Sep/13 15:08",
        "Resolved": "16/Sep/13 15:08",
        "Description": "The brat rapid annotation tool defines its own format to store annotations. It would be nice to have format support to directly train OpenNLP on the brat format.\nMore information about the tool can be found here:\nhttp://brat.nlplab.org/",
        "Issue Links": []
    },
    "OPENNLP-561": {
        "Key": "OPENNLP-561",
        "Summary": "Prepare for Tools release 1.5.3",
        "Type": "Task",
        "Status": "Closed",
        "Priority": "Major",
        "Resolution": "Fixed",
        "Affects Version/s": "tools-1.5.3,                                            maxent-3.0.3",
        "Fix Version/s": "tools-1.5.3,                                            maxent-3.0.3",
        "Component/s": "Build, Packaging and Test",
        "Assignee": "William Colen",
        "Reporter": "William Colen",
        "Created": "15/Feb/13 10:49",
        "Updated": "17/Apr/13 13:40",
        "Resolved": "17/Apr/13 13:40",
        "Description": "This JIRA will be used for tasks related to the release process.",
        "Issue Links": []
    },
    "OPENNLP-562": {
        "Key": "OPENNLP-562",
        "Summary": "invoking .find() on a RegexNameFinder instance brings back Spans with identical start/end indices",
        "Type": "Bug",
        "Status": "Closed",
        "Priority": "Major",
        "Resolution": "Fixed",
        "Affects Version/s": "tools-1.5.2-incubating",
        "Fix Version/s": "tools-1.5.3",
        "Component/s": "Name Finder",
        "Assignee": "James Kosin",
        "Reporter": "Jim Piliouras",
        "Created": "20/Feb/13 19:18",
        "Updated": "22/Feb/13 04:05",
        "Resolved": "21/Feb/13 05:41",
        "Description": "The RegexNameFinder class has a serious bug...Whenever it finds something it produces a Span with the same start/end index. This happens because 'sentencePosTokenMap' stores the same position for the start and end of the token.Conceptually this fine, after all it is the same token, however later on matcher.start()/end() is invoked to determine what to ask from the map.Well, if we've stored the same position we will get the same number and the Span will be ruined, right? The trick here is to store i+1 for the endIndex for that token in the map. That is essentially the position of next token, but since we're expecting tokenized text anyway everything is fine...Untokenized text breaks the system anyway so in my opinion it is safe to apply the forthcoming patch. A dirty approach would be to leave the map as is and simply replace 'matcher.end()' with 'matcher.end()+1' when we're doing the lookup.",
        "Issue Links": []
    },
    "OPENNLP-563": {
        "Key": "OPENNLP-563",
        "Summary": "JIRA No Longer Tracking Sources",
        "Type": "Improvement",
        "Status": "Closed",
        "Priority": "Minor",
        "Resolution": "Fixed",
        "Affects Version/s": "None",
        "Fix Version/s": "1.7.0",
        "Component/s": "None",
        "Assignee": null,
        "Reporter": "James Kosin",
        "Created": "21/Feb/13 05:48",
        "Updated": "03/Jan/17 09:49",
        "Resolved": "03/Jan/17 07:03",
        "Description": "JIRA doesn't seem to be tracking changes to the SVN repo and marking activity towards JIRA issues.\nAre we doing something wrong?  Or did an upgrade break something?",
        "Issue Links": []
    },
    "OPENNLP-564": {
        "Key": "OPENNLP-564",
        "Summary": "DeTokenizer Rule File for german language",
        "Type": "New Feature",
        "Status": "Closed",
        "Priority": "Major",
        "Resolution": "Fixed",
        "Affects Version/s": "tools-1.5.2-incubating",
        "Fix Version/s": "tools-1.5.3",
        "Component/s": "Tokenizer",
        "Assignee": "J\u00f6rn Kottmann",
        "Reporter": "Andreas Niekler",
        "Created": "14/Mar/13 13:23",
        "Updated": "03/Apr/13 11:39",
        "Resolved": "03/Apr/13 11:38",
        "Description": "Producing training data for german language needs a pattern file for detokenizer.",
        "Issue Links": []
    },
    "OPENNLP-565": {
        "Key": "OPENNLP-565",
        "Summary": "Add MASC format support",
        "Type": "Improvement",
        "Status": "Closed",
        "Priority": "Minor",
        "Resolution": "Fixed",
        "Affects Version/s": "None",
        "Fix Version/s": "2.0.0",
        "Component/s": "Formats",
        "Assignee": null,
        "Reporter": "J\u00f6rn Kottmann",
        "Created": "22/Mar/13 14:20",
        "Updated": "07/Jun/22 11:59",
        "Resolved": "07/Jun/22 11:59",
        "Description": "Add format support for the MASC corpus. The corpus contains annotations for most of the components in OpenNLP and would be a great source of freely available training data for testing.\nThe corpus can be found here:\nhttp://www.anc.org/MASC/About.html#format",
        "Issue Links": [
            "https://github.com/apache/opennlp/pull/364"
        ]
    },
    "OPENNLP-566": {
        "Key": "OPENNLP-566",
        "Summary": "Parse thicket is a structure to represent syntactic relations in a paragraph",
        "Type": "New Feature",
        "Status": "Open",
        "Priority": "Major",
        "Resolution": "Unresolved",
        "Affects Version/s": "similarity-0.0.1",
        "Fix Version/s": "None",
        "Component/s": "Similarity",
        "Assignee": "Boris Galitsky",
        "Reporter": "Boris Galitsky",
        "Created": "29/Mar/13 01:45",
        "Updated": "29/Mar/13 01:45",
        "Resolved": null,
        "Description": "Per  paper\n http://link.springer.com/chapter/10.1007%2F978-3-642-35786-2_12\nParse Thicket Representation for Multi-sentence Search\nBoris A. Galitsky, Sergei O. Kuznetsov, Daniel Usikov\nAbstract\nWe develop a graph representation and learning technique for parse structures for sentences and paragraphs of text. This technique is used to improve relevance answering complex questions where an answer is included in multiple sentences. We introduce Parse Thicket as a sum of syntactic parse trees augmented by a number of arcs for inter-sentence word-word relations such as coreference and taxonomic. These arcs are also derived from other sources, including Rhetoric Structure theory, and respective indexing rules are introduced, which identify inter-sentence relations and joins phrases connected by these relations in the search index. Generalization of syntactic parse trees (as a similarity measure between sentences) is defined as a set of maximum common sub-trees for two parse trees. Generalization of a pair of parse thickets to measure relevance of a question and an answer, distributed in multiple sentences, is defined as a set of maximal common sub-parse thickets. The proposed approach is evaluated in the product search domain of eBay.com, where user query includes product names, features and expressions for user needs, and the query keywords occur in different sentences of text. We demonstrate that search relevance is improved by single sentence-level generalization, and further increased by parse thicket generalization. The proposed approach is evaluated in the product search domain of eBay.com, where user query includes product names, features and expressions for user needs, and the query keywords occur in different sentences of text.",
        "Issue Links": []
    },
    "OPENNLP-567": {
        "Key": "OPENNLP-567",
        "Summary": "Error in opennlp.tools.util.Span.toString() end bracket should be \"]\" not \")\"",
        "Type": "Bug",
        "Status": "Closed",
        "Priority": "Trivial",
        "Resolution": "Won't Fix",
        "Affects Version/s": "tools-1.5.3",
        "Fix Version/s": "None",
        "Component/s": "None",
        "Assignee": "J\u00f6rn Kottmann",
        "Reporter": "Krishna Sankar",
        "Created": "02/Apr/13 02:47",
        "Updated": "03/Apr/13 21:12",
        "Resolved": "03/Apr/13 21:12",
        "Description": "public String toString() \n{\n    StringBuffer toStringBuffer = new StringBuffer(15);\n    toStringBuffer.append(\"[\");\n    toStringBuffer.append(getStart());\n    toStringBuffer.append(\"..\");\n    toStringBuffer.append(getEnd());\n    toStringBuffer.append(\")\"); <-- this should be \"]\"\n\n    return toStringBuffer.toString();\n  }",
        "Issue Links": []
    },
    "OPENNLP-568": {
        "Key": "OPENNLP-568",
        "Summary": "Doccat command line tagger should assume whitespace tokenized input",
        "Type": "Bug",
        "Status": "Closed",
        "Priority": "Major",
        "Resolution": "Fixed",
        "Affects Version/s": "tools-1.5.2-incubating",
        "Fix Version/s": "tools-1.5.3",
        "Component/s": "Command Line Interface,                                            Doccat",
        "Assignee": "J\u00f6rn Kottmann",
        "Reporter": "J\u00f6rn Kottmann",
        "Created": "02/Apr/13 20:39",
        "Updated": "02/Apr/13 20:46",
        "Resolved": "02/Apr/13 20:46",
        "Description": "The DoccatTool should read the doccat default format from stdin. The default format is whitespace tokenized, but the DoccatTool uses the Simple Tokenizer to tokenize the input text.\nTo fix this issue use the Whitespace Tokenizer instead of the Simple Tokenizer.",
        "Issue Links": []
    },
    "OPENNLP-569": {
        "Key": "OPENNLP-569",
        "Summary": "Fix remaining issue in L-BFGS parameter estimation to get it stable",
        "Type": "Improvement",
        "Status": "Closed",
        "Priority": "Major",
        "Resolution": "Fixed",
        "Affects Version/s": "tools-1.5.3,                                            maxent-3.0.3",
        "Fix Version/s": "1.6.0",
        "Component/s": "Machine Learning",
        "Assignee": "Hyosup Shim",
        "Reporter": "J\u00f6rn Kottmann",
        "Created": "03/Apr/13 09:04",
        "Updated": "27/Apr/14 15:22",
        "Resolved": "27/Apr/14 15:22",
        "Description": "Enhance the L-BFGS parameter estimation code to at least perform as well as the GIS training. The work on this issue should bring the implementation to a level where the experimental flag can be removed.\nFor remaining problems see this issue: OPENNLP-338.",
        "Issue Links": [
            "/jira/browse/OPENNLP-338",
            "/jira/browse/OPENNLP-671"
        ]
    },
    "OPENNLP-570": {
        "Key": "OPENNLP-570",
        "Summary": "German Abbreviation Dictionary",
        "Type": "Improvement",
        "Status": "Open",
        "Priority": "Minor",
        "Resolution": "Unresolved",
        "Affects Version/s": "1.6.0",
        "Fix Version/s": "None",
        "Component/s": "Tokenizer",
        "Assignee": null,
        "Reporter": "Andreas Niekler",
        "Created": "03/Apr/13 13:02",
        "Updated": "03/Apr/13 13:06",
        "Resolved": null,
        "Description": "An abbreviation dictionary for german tokenisation. Please comment on the possibility to include multi token abbreviations like prof. dr. or dipl. ing. and so on.",
        "Issue Links": []
    },
    "OPENNLP-571": {
        "Key": "OPENNLP-571",
        "Summary": "Tokenizer Model for german text",
        "Type": "Wish",
        "Status": "Open",
        "Priority": "Minor",
        "Resolution": "Unresolved",
        "Affects Version/s": "1.6.0",
        "Fix Version/s": "None",
        "Component/s": "Tokenizer",
        "Assignee": null,
        "Reporter": "Andreas Niekler",
        "Created": "03/Apr/13 13:09",
        "Updated": "26/Feb/23 14:42",
        "Resolved": null,
        "Description": "I created a tokenizer model with proper deTokenisation rules for differnt sorts of quotes. The model is based on 300.000 example sentences of the german version from the leipzig corpora collection. I don't know if there might be any copyright protection issue because those sentences are crawled from the web. If the content of the model is not in a form that would enable one to reconstruct the sentences everything is fine. Please comment on those thougts. If everything is ok i will contribute the model for futher testing by the openNLP Team.",
        "Issue Links": []
    },
    "OPENNLP-572": {
        "Key": "OPENNLP-572",
        "Summary": "Integrate the snowball into the stemmer package",
        "Type": "Improvement",
        "Status": "Closed",
        "Priority": "Minor",
        "Resolution": "Fixed",
        "Affects Version/s": "None",
        "Fix Version/s": "1.6.0",
        "Component/s": "Stemmer",
        "Assignee": "J\u00f6rn Kottmann",
        "Reporter": "J\u00f6rn Kottmann",
        "Created": "05/Apr/13 11:33",
        "Updated": "20/Nov/13 11:49",
        "Resolved": "20/Nov/13 11:49",
        "Description": "The stemmer API currently only support the Porter Stemmer, it would be much more useful for multilingual use cases if it would also support the snowball stemmers.\nThe snowball stemmers can be included in its source form in OpenNLP and be adapted to our stemmer interface.",
        "Issue Links": []
    },
    "OPENNLP-573": {
        "Key": "OPENNLP-573",
        "Summary": "Remove deprecated 1.4 API from OpenNLP Tools",
        "Type": "Improvement",
        "Status": "Closed",
        "Priority": "Minor",
        "Resolution": "Fixed",
        "Affects Version/s": "None",
        "Fix Version/s": "1.6.0",
        "Component/s": "None",
        "Assignee": "J\u00f6rn Kottmann",
        "Reporter": "J\u00f6rn Kottmann",
        "Created": "09/Apr/13 15:02",
        "Updated": "06/Jan/14 11:01",
        "Resolved": "06/Jan/14 11:01",
        "Description": "Its time to remove backward compatibility for OpenNLP 1.4. The 1.4 support still allows the loading of the old models in the way it was done before the 1.5 model refactoring.",
        "Issue Links": []
    },
    "OPENNLP-574": {
        "Key": "OPENNLP-574",
        "Summary": "Integrate the Apache Mahout classifiers",
        "Type": "Improvement",
        "Status": "Closed",
        "Priority": "Minor",
        "Resolution": "Won't Fix",
        "Affects Version/s": "None",
        "Fix Version/s": "1.7.1",
        "Component/s": "None",
        "Assignee": "J\u00f6rn Kottmann",
        "Reporter": "J\u00f6rn Kottmann",
        "Created": "10/Apr/13 20:20",
        "Updated": "17/Jan/17 21:59",
        "Resolved": "17/Jan/17 21:59",
        "Description": "The Apache Mahout implements a Logicstic Regression and HMM classifiers which could be used by the OpenNLP components. As soon as the machine learning is plugable in OpenNLP a sandbox component should be added which can integrate the Mahout classifiers.",
        "Issue Links": []
    },
    "OPENNLP-575": {
        "Key": "OPENNLP-575",
        "Summary": "Move the coref component into the sandbox",
        "Type": "Task",
        "Status": "Closed",
        "Priority": "Major",
        "Resolution": "Fixed",
        "Affects Version/s": "None",
        "Fix Version/s": "1.6.0",
        "Component/s": "Coref",
        "Assignee": "J\u00f6rn Kottmann",
        "Reporter": "J\u00f6rn Kottmann",
        "Created": "19/Apr/13 09:38",
        "Updated": "08/May/13 10:05",
        "Resolved": "08/May/13 10:05",
        "Description": "The coref component is not longer maintained and should be moved into the sandbox. Hopefully we find a new maintainer and can get it back into a state which is suitable for inclusion in opennlp-tools.",
        "Issue Links": []
    },
    "OPENNLP-576": {
        "Key": "OPENNLP-576",
        "Summary": "AbstractNameFinder.initialize(UimaContext) is missing a call to super.initialize(UimaContext)",
        "Type": "Bug",
        "Status": "Closed",
        "Priority": "Trivial",
        "Resolution": "Fixed",
        "Affects Version/s": "None",
        "Fix Version/s": "1.6.0",
        "Component/s": "UIMA Integration",
        "Assignee": "J\u00f6rn Kottmann",
        "Reporter": "Alex Cichowski",
        "Created": "01/May/13 16:18",
        "Updated": "17/May/13 13:01",
        "Resolved": "17/May/13 13:01",
        "Description": null,
        "Issue Links": []
    },
    "OPENNLP-577": {
        "Key": "OPENNLP-577",
        "Summary": "GisModel eval ignores presence of the first feature",
        "Type": "Bug",
        "Status": "Closed",
        "Priority": "Major",
        "Resolution": "Invalid",
        "Affects Version/s": "maxent-3.0.3",
        "Fix Version/s": "None",
        "Component/s": "Machine Learning",
        "Assignee": null,
        "Reporter": "Michael Lambert",
        "Created": "02/May/13 14:01",
        "Updated": "06/Jun/13 12:46",
        "Resolved": "02/May/13 14:03",
        "Description": "On line 181 of GISModel.java in the eval function, there is a check whose intention seems to be to ignore any incoming predicates that have a value of zero.  Instead, it ignores an incoming predicates that have a parameter index of zero:\nThe line in question:\n    if (context[ci] >= 0) {\nI believe that this should be:\n    if (values[ci] >= 0) {",
        "Issue Links": []
    },
    "OPENNLP-578": {
        "Key": "OPENNLP-578",
        "Summary": "Error writing model file due to a java writeUTF method problem",
        "Type": "Bug",
        "Status": "Closed",
        "Priority": "Major",
        "Resolution": "Won't Fix",
        "Affects Version/s": "maxent-3.0.3",
        "Fix Version/s": "None",
        "Component/s": "Machine Learning",
        "Assignee": null,
        "Reporter": "Nicolas Hernandez",
        "Created": "14/May/13 07:39",
        "Updated": "31/Jan/17 10:10",
        "Resolved": "31/Jan/17 10:10",
        "Description": "Using the POSTaggerTrainer command line to build a model for predicting lemma \n(led by curiosity since the approach may not be the best one for this task),  \nI ve got an error writing the model file due to a java writeUTF method problem [1]. \nMore specifically, the problem is due to fact that java.io.DataOutputStream is not able to serialize strings larger\nthan 64KB.\n[2] presents the problem and gives some workarounds. \nSolution to handle the problem may require to modify the binary format.\nThe class which seems concerned is \nopennlp-maxent/src/main/java/opennlp/maxent/io/BinaryGISModelWriter.java \n[1] Writing pos tagger model ... failed\nError during writing model file '/tmp/train-lemma.model'\nencoded string too long: 153687 bytes\njava.io.UTFDataFormatException: encoded string too long: 153687 bytes\nat java.io.DataOutputStream.writeUTF(DataOutputStream.java:364)\nat java.io.DataOutputStream.writeUTF(DataOutputStream.java:323)\nat opennlp.maxent.io.BinaryGISModelWriter.writeUTF(BinaryGISModelWriter.java:73)\n[2] http://www.drillio.com/en/software-development/java/encoded-string-too-long-64kb-limit/",
        "Issue Links": []
    },
    "OPENNLP-579": {
        "Key": "OPENNLP-579",
        "Summary": "Framework to dynamically link N-best matches from external data to named entities by type (EntityLinker framework)",
        "Type": "Wish",
        "Status": "Closed",
        "Priority": "Minor",
        "Resolution": "Fixed",
        "Affects Version/s": "1.6.0",
        "Fix Version/s": "1.6.0",
        "Component/s": "Entity Linker",
        "Assignee": "J\u00f6rn Kottmann",
        "Reporter": "Mark Giaconia",
        "Created": "21/May/13 23:14",
        "Updated": "20/Nov/14 16:30",
        "Resolved": "20/Nov/14 16:30",
        "Description": "A framework for integrating/linking external data to named entities. For instance, geocoding or georeferencing location entities to geonames gazateers can be implemented as an EntityLinker. Initially created ticket to specifically solve the georeferencing/geolocating/geotagging problem, but the framework should allow linkage of any external data to any entity type. Commercial applications that do this are expensive, and there are many free gazateers one could use to create solutions with OpenNLP. \nUPDATE: The current implementation of the GeoEntityLinker uses Lucene to store the Gazateers, and provides utils for indexing them. The impl returns lat, long (and other gaz fields) for toponyms extracted with NER.\nAll extracted toponyms are scored in four ways: fuzzy string matching, binning by location, context modeling, and country-mention proximity. These scores enable a good means of deciding what's worth keeping from the gaz.",
        "Issue Links": []
    },
    "OPENNLP-580": {
        "Key": "OPENNLP-580",
        "Summary": "Add name finder factory support to instantiate a highly modified name finder via a model",
        "Type": "Improvement",
        "Status": "Closed",
        "Priority": "Major",
        "Resolution": "Fixed",
        "Affects Version/s": "None",
        "Fix Version/s": "1.6.0",
        "Component/s": "Name Finder",
        "Assignee": "J\u00f6rn Kottmann",
        "Reporter": "J\u00f6rn Kottmann",
        "Created": "29/May/13 08:57",
        "Updated": "21/Oct/14 22:20",
        "Resolved": "12/Mar/14 14:43",
        "Description": "Most components in OpenNLP support a user defined factory to customize most aspects of it. The name finder does not support a user defined factory yet. To change this implement a name finder factory in the style of the already existing factories.",
        "Issue Links": []
    },
    "OPENNLP-581": {
        "Key": "OPENNLP-581",
        "Summary": "Add Pluggable Machine Learning support",
        "Type": "Improvement",
        "Status": "Closed",
        "Priority": "Major",
        "Resolution": "Fixed",
        "Affects Version/s": "None",
        "Fix Version/s": "1.6.0",
        "Component/s": "None",
        "Assignee": "William Colen",
        "Reporter": "J\u00f6rn Kottmann",
        "Created": "30/May/13 20:35",
        "Updated": "17/Jan/14 18:25",
        "Resolved": "17/Jan/14 18:25",
        "Description": "The OpenNLP Tools can currently only use the classifiers inside the Maxent library. It should be possible to plugin 3rd party machine learning libraries which can be integrated as seamlessly as the Maxent library.\nTo achieve this two these tasks need to be solved:\n\nDefine a MachineLearningFactory which is capable of instantiating a Trainer and Classifer based on a given parameter properties file. The Algorithm name could be the name of the factory to use. Additional the code in OpenNLP Tools need to be refactored to use the factory interface instead of the TrainUtil.\n\n\nRefactor the OpenNLP Tools to use an interface instead of the AbstractModel the interface can be identical to the current MaxentModel with additional support for serialization.\n\n\nTo avoid an interface layer between OpenNLP Tools and Maxent the maxent classes should be moved to opennlp.tools.ml.",
        "Issue Links": []
    },
    "OPENNLP-582": {
        "Key": "OPENNLP-582",
        "Summary": "Add lemmatizer functionality",
        "Type": "New Feature",
        "Status": "Closed",
        "Priority": "Major",
        "Resolution": "Fixed",
        "Affects Version/s": "1.6.0",
        "Fix Version/s": "1.6.0",
        "Component/s": "Lemmatizer",
        "Assignee": "Rodrigo Agerri",
        "Reporter": "Rodrigo Agerri",
        "Created": "17/Jun/13 12:26",
        "Updated": "20/Nov/13 10:35",
        "Resolved": "20/Nov/13 10:16",
        "Description": "Will add new functionality to perform dictionary based lemmatization. It will look up a word form and pos tag in a dictionary and produce the corresponding lemma.",
        "Issue Links": []
    },
    "OPENNLP-583": {
        "Key": "OPENNLP-583",
        "Summary": "JavaDoc Security Vulnerabilities",
        "Type": "Bug",
        "Status": "Closed",
        "Priority": "Major",
        "Resolution": "Fixed",
        "Affects Version/s": "tools-1.5.3,                                            maxent-3.0.3",
        "Fix Version/s": "None",
        "Component/s": "Documentation,                                            Website",
        "Assignee": "Aliaksandr Autayeu",
        "Reporter": "James Kosin",
        "Created": "21/Jun/13 23:37",
        "Updated": "09/Mar/15 20:43",
        "Resolved": "22/Jun/13 13:51",
        "Description": "Hi All,\nOracle has announced [1], [2] a frame injection vulnerability in Javadoc\ngenerated by Java 5, Java 6 and Java 7 before update 22.\nThe infrastructure team has completed a scan of our current project\nwebsites and identified over 6000 instances of vulnerable Javadoc\ndistributed across most TLPs. The chances are the project(s) you\ncontribute to is(are) affected. A list of projects and the number of\naffected Javadoc instances per project is provided at the end of this\ne-mail.\nPlease take the necessary steps to fix any currently published Javadoc\nand to ensure that any future Javadoc published by your project does not\ncontain the vulnerability. The announcement by Oracle includes a link to\na tool that can be used to fix Javadoc without regeneration.\nThe infrastructure team is investigating options for preventing the\npublication of vulnerable Javadoc.\nThe issue is public and may be discussed freely on your project's dev list.\nThanks,\nMark (ASF Infra)\n[1]\nhttp://www.oracle.com/technetwork/topics/security/javacpujun2013-1899847.html\n[2] http://www.kb.cert.org/vuls/id/225657\nProject\t\t\tInstances\nabdera.apache.org\t1\naccumulo.apache.org\t2\nactivemq.apache.org\t105\nany23.apache.org\t13\narchiva.apache.org\t4\narchive.apache.org\t13\naries.apache.org\t7\navro.apache.org\t\t23\naxis.apache.org\t\t5\nbeehive.apache.org\t16\nbval.apache.org\t\t12\ncamel.apache.org\t786\ncayenne.apache.org\t4\nchemistry.apache.org\t6\nclick.apache.org\t3\ncocoon.apache.org\t6\ncommons.apache.org\t34\ncontinuum.apache.org\t9\ncreadur.apache.org\t19\ncrunch.apache.org\t4\nctakes.apache.org\t2\ncurator.apache.org\t4\ncxf.apache.org\t\t6\ndb.apache.org\t\t39\ndirectory.apache.org\t4\nempire-db.apache.org\t1\nfelix.apache.org\t5\nflume.apache.org\t5\ngeronimo.apache.org\t241\ngiraph.apache.org\t6\ngora.apache.org\t\t3\nhadoop.apache.org\t21\nhbase.apache.org\t2\nhive.apache.org\t\t4\nhivemind.apache.org\t10\nincubator.apache.org\t355\njackrabbit.apache.org\t9\njakarta.apache.org\t39\njames.apache.org\t53\njena.apache.org\t\t5\njuddi.apache.org\t3\nlenya.apache.org\t46\nlogging.apache.org\t111\nlucene.apache.org\t713\nmanifoldcf.apache.org\t112\nmarmotta.apache.org\t1\nmaven.apache.org\t1623\nmaventest.apache.org\t1178\nmina.apache.org\t\t2\nmrunit.apache.org\t3\nmyfaces.apache.org\t348\nnutch.apache.org\t8\noltu.apache.org\t\t11\noodt.apache.org\t\t1\nooo-site.apache.org\t1\noozie.apache.org\t10\nopenjpa.apache.org\t20\n==> opennlp.apache.org\t9  <==\npdfbox.apache.org\t1\npig.apache.org\t\t7\npivot.apache.org\t1\npoi.apache.org\t\t1\nportals.apache.org\t35\nriver.apache.org\t2\nsantuario.apache.org\t1\nshale.apache.org\t55\nshiro.apache.org\t3\nsling.apache.org\t2\nsqoop.apache.org\t4\nstruts.apache.org\t190\nsubversion.apache.org\t3\nsynapse.apache.org\t1\nsyncope.apache.org\t2\ntapestry.apache.org\t6\ntika.apache.org\t\t9\ntiles.apache.org\t12\nturbine.apache.org\t100\ntuscany.apache.org\t4\nuima.apache.org\t\t12\nvelocity.apache.org\t41\nwhirr.apache.org\t2\nwicket.apache.org\t3\nwink.apache.org\t\t13\nws.apache.org\t\t22\nxalan.apache.org\t1\nxerces.apache.org\t5\nxml.apache.org\t\t1\nxmlbeans.apache.org\t3\nzookeeper.apache.org\t18",
        "Issue Links": []
    },
    "OPENNLP-584": {
        "Key": "OPENNLP-584",
        "Summary": "PorterStemmer class needs to be public",
        "Type": "Bug",
        "Status": "Closed",
        "Priority": "Major",
        "Resolution": "Fixed",
        "Affects Version/s": "None",
        "Fix Version/s": "1.6.0",
        "Component/s": "Stemmer",
        "Assignee": "J\u00f6rn Kottmann",
        "Reporter": "J\u00f6rn Kottmann",
        "Created": "26/Jun/13 07:37",
        "Updated": "01/Jul/13 13:19",
        "Resolved": "01/Jul/13 13:19",
        "Description": "The PorterStemmer class was accidentally labeled as package private. It should be changed to public so it can be used outside of the stemmer package.",
        "Issue Links": []
    },
    "OPENNLP-585": {
        "Key": "OPENNLP-585",
        "Summary": "Add a Brat NER service to the Tagging Server",
        "Type": "Improvement",
        "Status": "Closed",
        "Priority": "Major",
        "Resolution": "Won't Fix",
        "Affects Version/s": "None",
        "Fix Version/s": "None",
        "Component/s": "None",
        "Assignee": "J\u00f6rn Kottmann",
        "Reporter": "J\u00f6rn Kottmann",
        "Created": "04/Jul/13 13:55",
        "Updated": "18/Oct/16 18:11",
        "Resolved": "18/Oct/16 18:11",
        "Description": "Add a Brat annotation tool NER tagging service to the Tagging Server. It should be possible to configure multiple services via blueprint and choose one via a URL parameter.",
        "Issue Links": []
    },
    "OPENNLP-586": {
        "Key": "OPENNLP-586",
        "Summary": "GeoEntityLinker does not provide a method for setting the properties file location in order to get the database connection, it is currently hard coded",
        "Type": "Improvement",
        "Status": "Closed",
        "Priority": "Minor",
        "Resolution": "Invalid",
        "Affects Version/s": "1.6.0",
        "Fix Version/s": "1.6.0",
        "Component/s": "Name Finder",
        "Assignee": null,
        "Reporter": "Mark Giaconia",
        "Created": "17/Jul/13 11:10",
        "Updated": "17/Jul/13 11:39",
        "Resolved": "17/Jul/13 11:39",
        "Description": "GeoEntityLinker does not provide a method for setting the properties file location, it is currently hard coded",
        "Issue Links": [
            "/jira/browse/OPENNLP-588"
        ]
    },
    "OPENNLP-587": {
        "Key": "OPENNLP-587",
        "Summary": "EntityLinker framework has no documentation",
        "Type": "Documentation",
        "Status": "Open",
        "Priority": "Minor",
        "Resolution": "Unresolved",
        "Affects Version/s": "1.6.0",
        "Fix Version/s": "None",
        "Component/s": "Entity Linker",
        "Assignee": null,
        "Reporter": "Mark Giaconia",
        "Created": "17/Jul/13 11:11",
        "Updated": "02/Nov/16 22:33",
        "Resolved": null,
        "Description": "EntityLinker framework has no documentation",
        "Issue Links": []
    },
    "OPENNLP-588": {
        "Key": "OPENNLP-579 Framework to dynamically link N-best matches from external data to named entities by type (EntityLinker framework)",
        "Summary": "GeoEntityLinker does not provide a method for setting the properties file location in order to get the database connection, it is currently hard coded",
        "Type": "Sub-task",
        "Status": "Closed",
        "Priority": "Minor",
        "Resolution": "Implemented",
        "Affects Version/s": "1.6.0",
        "Fix Version/s": "1.6.0",
        "Component/s": "Name Finder",
        "Assignee": "J\u00f6rn Kottmann",
        "Reporter": "Mark Giaconia",
        "Created": "17/Jul/13 11:38",
        "Updated": "19/Sep/13 19:01",
        "Resolved": "27/Jul/13 12:32",
        "Description": "GeoEntityLinker does not provide a method for setting the properties file location in order to get the database connection, it is currently hard coded",
        "Issue Links": [
            "/jira/browse/OPENNLP-586"
        ]
    },
    "OPENNLP-589": {
        "Key": "OPENNLP-589",
        "Summary": "Text format of Events inconsistent across different implementations of EventStreamReaders",
        "Type": "Bug",
        "Status": "Open",
        "Priority": "Major",
        "Resolution": "Unresolved",
        "Affects Version/s": "maxent-3.0.3",
        "Fix Version/s": "None",
        "Component/s": "Machine Learning",
        "Assignee": null,
        "Reporter": "Marcin Junczys-Dowmunt",
        "Created": "22/Jul/13 11:25",
        "Updated": "22/Jul/13 11:29",
        "Resolved": null,
        "Description": "BasicEventStream expects events to be written to text files as:\ncontext1 context2 context3 ... outcome\nFileEventStream expects events to be written to text files as:\noutcome context1 context2 context3 ...\ntoString() of Event creates:\noutcome [context1 context2 context3 ...] (note the square brackets, which are part of context predicates when breaking on spaces).\nThis is highly confusing and took me some time to understand. I guess this should be unified?",
        "Issue Links": []
    },
    "OPENNLP-590": {
        "Key": "OPENNLP-590",
        "Summary": "Tokenizer is not getting trained...",
        "Type": "Bug",
        "Status": "Closed",
        "Priority": "Minor",
        "Resolution": "Won't Fix",
        "Affects Version/s": "tools-1.5.3",
        "Fix Version/s": "None",
        "Component/s": "Tokenizer",
        "Assignee": null,
        "Reporter": "Hayri Volkan Agun",
        "Created": "26/Jul/13 13:54",
        "Updated": "06/Jan/14 16:50",
        "Resolved": "06/Jan/14 16:50",
        "Description": "Trying to train a tokenizer for Turkish from API, which doesn't learn an obvious pattern. No abbreviation dictionary is used and is either necessary for learning. The sample stream is in UTF-8. \nThe code sample I used is below:\nCharset charset = Charset.forName(\"UTF-8\");\nObjectStream<String> lineStream = new PlainTextByLineStream(new FileInputStream(trainFilename),\n                      charset);\nObjectStream<TokenSample> sampleStream = new TokenSampleStream(lineStream);\nTokenizerModel model;\nTokenizerFactory factory = new TokenizerFactory(\"tr\",null,false, null);\nString tr = factory.getLanguageCode();\nmodel = TokenizerME.train(sampleStream, factory ,TrainingParameters.defaultParams());\ntry (OutputStream modelOut = new    FileOutputStream(WordOptions.OPENNLPTOKENMODELFILENAME)) {\n   model.serialize(modelOut);\n   modelOut.close();\n}\nsampleStream.close();",
        "Issue Links": []
    },
    "OPENNLP-591": {
        "Key": "OPENNLP-591",
        "Summary": "[PATCH] Typos in Name Finder docs",
        "Type": "Bug",
        "Status": "Closed",
        "Priority": "Trivial",
        "Resolution": "Fixed",
        "Affects Version/s": "None",
        "Fix Version/s": "1.6.0",
        "Component/s": "None",
        "Assignee": null,
        "Reporter": "Bruno P. Kinoshita",
        "Created": "03/Aug/13 23:28",
        "Updated": "23/Aug/13 13:52",
        "Resolved": "23/Aug/13 13:52",
        "Description": "Hello, I think there are few typos in the Name Finder documentation page. Since I'm not a native speaker it would be good an extra pair of eyes reviewing my patch. Thanks for the awesome tool.",
        "Issue Links": []
    },
    "OPENNLP-592": {
        "Key": "OPENNLP-592",
        "Summary": "When I attempt to run `bin/opennlp Parser models/en-parser-chunking.bin` I get an error for out of memory on the heap although I give it 4 gigs, is this normal?",
        "Type": "Question",
        "Status": "Closed",
        "Priority": "Minor",
        "Resolution": "Not A Problem",
        "Affects Version/s": "tools-1.5.3",
        "Fix Version/s": "None",
        "Component/s": "Parser",
        "Assignee": null,
        "Reporter": "Dan Zimmerman",
        "Created": "05/Aug/13 19:37",
        "Updated": "17/Apr/15 13:14",
        "Resolved": "17/Apr/15 13:14",
        "Description": "So I recently checked out from the svn repo `https://svn.apache.org/repos/asf/opennlp/tags/opennlp-1.5.3-rc3` and ran `mvn install` from inside the `opennpl` directory. That finished successfully, all test were successful. Next I downloaded all the english models from `http://opennlp.sourceforge.net/models-1.5/`. Finally, I moved all the model bins into `opennpl-tools/models` and I went into `opennpl-tools` and ran `bin/opennlp Parser models/en-parser-chunking.bin` and received the following backtrace:\n[ERROR] Failed to execute goal org.codehaus.mojo:exec-maven-plugin:1.2.1:java (default-cli) on project opennlp-tools: An exception occured while executing the Java class. null: InvocationTargetException: Java heap space -> [Help 1]\norg.apache.maven.lifecycle.LifecycleExecutionException: Failed to execute goal org.codehaus.mojo:exec-maven-plugin:1.2.1:java (default-cli) on project opennlp-tools: An exception occured while executing the Java class. null\n\tat org.apache.maven.lifecycle.internal.MojoExecutor.execute(MojoExecutor.java:216)\n\tat org.apache.maven.lifecycle.internal.MojoExecutor.execute(MojoExecutor.java:153)\n\tat org.apache.maven.lifecycle.internal.MojoExecutor.execute(MojoExecutor.java:145)\n\tat org.apache.maven.lifecycle.internal.LifecycleModuleBuilder.buildProject(LifecycleModuleBuilder.java:84)\n\tat org.apache.maven.lifecycle.internal.LifecycleModuleBuilder.buildProject(LifecycleModuleBuilder.java:59)\n\tat org.apache.maven.lifecycle.internal.LifecycleStarter.singleThreadedBuild(LifecycleStarter.java:183)\n\tat org.apache.maven.lifecycle.internal.LifecycleStarter.execute(LifecycleStarter.java:161)\n\tat org.apache.maven.DefaultMaven.doExecute(DefaultMaven.java:318)\n\tat org.apache.maven.DefaultMaven.execute(DefaultMaven.java:153)\n\tat org.apache.maven.cli.MavenCli.execute(MavenCli.java:555)\n\tat org.apache.maven.cli.MavenCli.doMain(MavenCli.java:214)\n\tat org.apache.maven.cli.MavenCli.main(MavenCli.java:158)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)\n\tat java.lang.reflect.Method.invoke(Method.java:597)\n\tat org.codehaus.plexus.classworlds.launcher.Launcher.launchEnhanced(Launcher.java:290)\n\tat org.codehaus.plexus.classworlds.launcher.Launcher.launch(Launcher.java:230)\n\tat org.codehaus.plexus.classworlds.launcher.Launcher.mainWithExitCode(Launcher.java:414)\n\tat org.codehaus.plexus.classworlds.launcher.Launcher.main(Launcher.java:357)\nCaused by: org.apache.maven.plugin.MojoExecutionException: An exception occured while executing the Java class. null\n\tat org.codehaus.mojo.exec.ExecJavaMojo.execute(ExecJavaMojo.java:352)\n\tat org.apache.maven.plugin.DefaultBuildPluginManager.executeMojo(DefaultBuildPluginManager.java:106)\n\tat org.apache.maven.lifecycle.internal.MojoExecutor.execute(MojoExecutor.java:208)\n\t... 19 more\nCaused by: java.lang.reflect.InvocationTargetException\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)\n\tat java.lang.reflect.Method.invoke(Method.java:597)\n\tat org.codehaus.mojo.exec.ExecJavaMojo$1.run(ExecJavaMojo.java:297)\n\tat java.lang.Thread.run(Thread.java:680)\nCaused by: java.lang.OutOfMemoryError: Java heap space\n\tat java.io.DataInputStream.readUTF(DataInputStream.java:644)\n\tat java.io.DataInputStream.readUTF(DataInputStream.java:547)\n\tat opennlp.model.BinaryFileDataReader.readUTF(BinaryFileDataReader.java:61)\n\tat opennlp.model.AbstractModelReader.readUTF(AbstractModelReader.java:82)\n\tat opennlp.model.AbstractModelReader.getPredicates(AbstractModelReader.java:119)\n\tat opennlp.maxent.io.GISModelReader.constructModel(GISModelReader.java:74)\n\tat opennlp.model.GenericModelReader.constructModel(GenericModelReader.java:59)\n\tat opennlp.model.AbstractModelReader.getModel(AbstractModelReader.java:87)\n\tat opennlp.tools.util.model.GenericModelSerializer.create(GenericModelSerializer.java:35)\n\tat opennlp.tools.util.model.GenericModelSerializer.create(GenericModelSerializer.java:31)\n\tat opennlp.tools.util.model.BaseModel.loadModel(BaseModel.java:231)\n\tat opennlp.tools.util.model.BaseModel.<init>(BaseModel.java:181)\n\tat opennlp.tools.parser.ParserModel.<init>(ParserModel.java:152)\n\tat opennlp.tools.cmdline.parser.ParserModelLoader.loadModel(ParserModelLoader.java:41)\n\tat opennlp.tools.cmdline.parser.ParserModelLoader.loadModel(ParserModelLoader.java:32)\n\tat opennlp.tools.cmdline.ModelLoader.load(ModelLoader.java:62)\n\tat opennlp.tools.cmdline.parser.ParserTool.run(ParserTool.java:93)\n\tat opennlp.tools.cmdline.CLI.main(CLI.java:225)\n\t... 6 more\nI then edited my POM file and changed the allowed memory on the `maven-surefire-plugin` plugin to 2 gigabytes and the same thing occurred, and then the same for 4 gigabytes. Is this normal behavior? Am I doing something horribly wrong? In advanced, I apologize if this is a silly question!",
        "Issue Links": []
    },
    "OPENNLP-593": {
        "Key": "OPENNLP-593",
        "Summary": "Version 1.5 models cannot be loaded with OpenNLP 1.6",
        "Type": "Bug",
        "Status": "Closed",
        "Priority": "Major",
        "Resolution": "Fixed",
        "Affects Version/s": "1.6.0",
        "Fix Version/s": "1.6.0",
        "Component/s": "Name Finder",
        "Assignee": "J\u00f6rn Kottmann",
        "Reporter": "Mark Giaconia",
        "Created": "18/Aug/13 13:12",
        "Updated": "19/Sep/13 19:02",
        "Resolved": "21/Aug/13 12:40",
        "Description": "IInvalidFormatException thrown on line 407 in BaseModel class if version numbers do not match.\nWhen the check for equality is commented out, the models seem to work (but perhaps improperly).\nAre the 1.5 models really INcompatible with OpenNLP 1.6, or does this check need to be fixed?",
        "Issue Links": []
    },
    "OPENNLP-594": {
        "Key": "OPENNLP-594",
        "Summary": "opennlp.tools.parser.Parse.remove() throws IndexOutOfBoundsException",
        "Type": "Bug",
        "Status": "Closed",
        "Priority": "Minor",
        "Resolution": "Fixed",
        "Affects Version/s": "tools-1.5.3",
        "Fix Version/s": "1.6.0",
        "Component/s": "Parser",
        "Assignee": "J\u00f6rn Kottmann",
        "Reporter": "Ioan Barbulescu",
        "Created": "25/Aug/13 08:21",
        "Updated": "17/Sep/13 14:37",
        "Resolved": "16/Sep/13 15:21",
        "Description": "Parse.remove() throws IndexOutOfBoundsException if you attempt to remove the last child node of the current node (i.e. if you call remove(0) and this node has only one sub-node).\nSome background info: I was trying to remove the TK nodes from a parse.\nI attached the diff file for the change fixing the bug.\nThe change is simple: a supplementary check:\n if(! parts.isEmpty()) \nbefore rebuilding the span.\nThank you\nIoan\nP.S. this is my first reported bug, so please be gentle  Please tell me if something is wrong with this issue, so that I fix it.",
        "Issue Links": []
    },
    "OPENNLP-595": {
        "Key": "OPENNLP-595",
        "Summary": "Name Finder CV should print ids for misclassified samples",
        "Type": "Improvement",
        "Status": "Closed",
        "Priority": "Minor",
        "Resolution": "Fixed",
        "Affects Version/s": "None",
        "Fix Version/s": "1.6.0",
        "Component/s": "Name Finder",
        "Assignee": "J\u00f6rn Kottmann",
        "Reporter": "J\u00f6rn Kottmann",
        "Created": "16/Sep/13 10:44",
        "Updated": "16/Sep/13 10:55",
        "Resolved": "16/Sep/13 10:55",
        "Description": "The Name Finder Cross Validator tool has an option to print out misclassified samples. The print out includes the reference, predication, tps, and fps. The output is very useful to find mistakes in the training data.\nThe only problem with the current design is that without an id it is hard to locate the sample within the training data.\nTo fix this the print out should optionally (if available) also print out an id which can be used to locate the sample.",
        "Issue Links": []
    },
    "OPENNLP-596": {
        "Key": "OPENNLP-596",
        "Summary": "Brat format parser always creates name spans which are one token too short",
        "Type": "Improvement",
        "Status": "Closed",
        "Priority": "Major",
        "Resolution": "Fixed",
        "Affects Version/s": "None",
        "Fix Version/s": "1.6.0",
        "Component/s": "Formats,                                            Name Finder",
        "Assignee": "J\u00f6rn Kottmann",
        "Reporter": "J\u00f6rn Kottmann",
        "Created": "16/Sep/13 10:53",
        "Updated": "16/Sep/13 10:55",
        "Resolved": "16/Sep/13 10:55",
        "Description": "The brat name sample stream has a bug which always creates name spans which are one token too short.",
        "Issue Links": []
    },
    "OPENNLP-597": {
        "Key": "OPENNLP-597",
        "Summary": "Code in tools/parser throws some NullPointerExceptions when dealing with poor training data",
        "Type": "Bug",
        "Status": "Closed",
        "Priority": "Minor",
        "Resolution": "Won't Fix",
        "Affects Version/s": "tools-1.5.3",
        "Fix Version/s": "1.6.0",
        "Component/s": "Parser",
        "Assignee": null,
        "Reporter": "Ioan Barbulescu",
        "Created": "17/Sep/13 14:36",
        "Updated": "01/Oct/13 14:21",
        "Resolved": "01/Oct/13 14:21",
        "Description": "I was trying to train the Treebank Parser with some new data.\nTruth to be told, the data was in poor format. Specifically, instead of \"(RRB RRB)\", it contained \"( RRB)\".\nThe same for LRB constructions.\nDue to this input data, the parsing code was throwing some NullPointerException errors.\nThe fixes consist in some supplementary \"if()\"s, to safeguard against null pointers.\nFixes are in 3 files, attached as diff. The diff was created by svn, run in the opennlp-tool/.../parser directory.",
        "Issue Links": []
    },
    "OPENNLP-598": {
        "Key": "OPENNLP-598",
        "Summary": "Opennlp supports RRB/LRB and RCB/LCB, but not RSB/LSB",
        "Type": "Bug",
        "Status": "Closed",
        "Priority": "Minor",
        "Resolution": "Fixed",
        "Affects Version/s": "tools-1.5.3",
        "Fix Version/s": "1.6.0",
        "Component/s": "Parser",
        "Assignee": "J\u00f6rn Kottmann",
        "Reporter": "Ioan Barbulescu",
        "Created": "18/Sep/13 17:59",
        "Updated": "10/Jan/14 12:58",
        "Resolved": "02/Jan/14 12:41",
        "Description": "OpenNlp supports Right / Left Round Bracket and Right / Left Curly Bracket, but not Right / Left Square Bracket.\nFix is simple, by adding the corresponding \"if()\"s in 3 files: \ntools/parser/chunking/BuildContextGenerator\ntools/parser/Parse\ntools/tokenize/lang/en/TokenSampleStream\nImportant NOTE:\nI attach the patch for this fix, made by svn diff in trunk/.\nHowever, please note that this patch includes also the changes for the fix of OPENNLP-597.\nUnfortunately, I cannot really go around this, as the changes for OPENNLP-597 were not yet merged, at the moment when I opened OPENNLP-598.\nIf this is a problem, I will re-create this patch, after OPENNLP-597 is closed & its changes merged.\nThank you.",
        "Issue Links": []
    },
    "OPENNLP-599": {
        "Key": "OPENNLP-599",
        "Summary": "Add an option to the Name Finder Cross Validator to filter name types",
        "Type": "Improvement",
        "Status": "Closed",
        "Priority": "Minor",
        "Resolution": "Fixed",
        "Affects Version/s": "None",
        "Fix Version/s": "1.6.0",
        "Component/s": "Command Line Interface,                                            Name Finder",
        "Assignee": "J\u00f6rn Kottmann",
        "Reporter": "J\u00f6rn Kottmann",
        "Created": "19/Sep/13 18:27",
        "Updated": "19/Sep/13 18:59",
        "Resolved": "19/Sep/13 18:59",
        "Description": "The Name Finder Trainer has an option to filter out types in the training data, the same option should be supported on the cross validator.",
        "Issue Links": []
    },
    "OPENNLP-600": {
        "Key": "OPENNLP-600",
        "Summary": "java.io.IOException with POSTaggerTrainer.conllx when -gram option is used",
        "Type": "Bug",
        "Status": "Closed",
        "Priority": "Major",
        "Resolution": "Fixed",
        "Affects Version/s": "tools-1.5.3",
        "Fix Version/s": "1.6.0",
        "Component/s": "POS Tagger",
        "Assignee": null,
        "Reporter": "Giorgio Valoti",
        "Created": "20/Sep/13 10:07",
        "Updated": "18/Feb/14 13:04",
        "Resolved": "18/Feb/14 13:04",
        "Description": "If the -ngram option is used this exception is thrown:\nBuilding ngram dictionary ... IO error while building NGram Dictionary: Stream not marked\nStream not marked\njava.io.IOException: Stream not marked\n       at java.io.BufferedReader.reset(BufferedReader.java:485)\n       at opennlp.tools.util.PlainTextByLineStream.reset(PlainTextByLineStream.java:79)\n       at opennlp.tools.util.FilterObjectStream.reset(FilterObjectStream.java:43)\n       at opennlp.tools.util.FilterObjectStream.reset(FilterObjectStream.java:43)\n       at opennlp.tools.cmdline.postag.POSTaggerTrainerTool.run(POSTaggerTrainerTool.java:80)\n       at opennlp.tools.cmdline.CLI.main(CLI.java:222)",
        "Issue Links": []
    },
    "OPENNLP-601": {
        "Key": "OPENNLP-601",
        "Summary": "NameSampleTypeFilter drops the id of the NameSample object",
        "Type": "Bug",
        "Status": "Closed",
        "Priority": "Trivial",
        "Resolution": "Fixed",
        "Affects Version/s": "None",
        "Fix Version/s": "1.6.0",
        "Component/s": "Command Line Interface,                                            Name Finder",
        "Assignee": null,
        "Reporter": "J\u00f6rn Kottmann",
        "Created": "23/Sep/13 12:22",
        "Updated": "23/Sep/13 13:06",
        "Resolved": "23/Sep/13 13:06",
        "Description": "The NameFinderTypeFilter filters out annotations which do not match the type list. This filter needs to create a new NameSample object instance, during the creation the id of the NameSample objetc is ignore.\nTo fix this pass the id correctly to the newly created NameSample object.",
        "Issue Links": []
    },
    "OPENNLP-602": {
        "Key": "OPENNLP-602",
        "Summary": "SentenceDetector should support new line as and end of sentence char",
        "Type": "Improvement",
        "Status": "Closed",
        "Priority": "Minor",
        "Resolution": "Fixed",
        "Affects Version/s": "tools-1.5.3",
        "Fix Version/s": "1.6.0",
        "Component/s": "Sentence Detector",
        "Assignee": "J\u00f6rn Kottmann",
        "Reporter": "J\u00f6rn Kottmann",
        "Created": "02/Oct/13 14:28",
        "Updated": "04/Feb/14 13:06",
        "Resolved": "04/Feb/14 13:06",
        "Description": "The Sentence Detector should have support to consider new line chars as the end of a sentence. This will probably require special handling in the training code to assume that there is an new line char if any other eos is missing.",
        "Issue Links": []
    },
    "OPENNLP-603": {
        "Key": "OPENNLP-603",
        "Summary": "Add a token cluster feature generator",
        "Type": "Improvement",
        "Status": "Closed",
        "Priority": "Minor",
        "Resolution": "Fixed",
        "Affects Version/s": "None",
        "Fix Version/s": "1.6.0",
        "Component/s": "Name Finder",
        "Assignee": "J\u00f6rn Kottmann",
        "Reporter": "J\u00f6rn Kottmann",
        "Created": "09/Oct/13 17:36",
        "Updated": "18/Oct/13 12:23",
        "Resolved": "18/Oct/13 12:23",
        "Description": "Add a feature generator which can lookup the token cluster from a dictionary. Depending on the data set this can increase the performance up to a few percent f1 measure. \nSee for example this paper:\nwww.aclweb.org/anthology/P10-1040.pdf\u200e\nA powerful tool to produce token clusters is for example:\nhttps://code.google.com/p/word2vec/",
        "Issue Links": []
    },
    "OPENNLP-604": {
        "Key": "OPENNLP-604",
        "Summary": "Add a document begin feature generator",
        "Type": "Improvement",
        "Status": "Closed",
        "Priority": "Minor",
        "Resolution": "Fixed",
        "Affects Version/s": "None",
        "Fix Version/s": "1.6.0",
        "Component/s": "Name Finder",
        "Assignee": "J\u00f6rn Kottmann",
        "Reporter": "J\u00f6rn Kottmann",
        "Created": "09/Oct/13 19:06",
        "Updated": "14/Oct/13 14:57",
        "Resolved": "14/Oct/13 14:57",
        "Description": "Add a feature generator which can compute a document begin feature. The feature should be similar to the sentence boundary features.",
        "Issue Links": []
    },
    "OPENNLP-605": {
        "Key": "OPENNLP-605",
        "Summary": "Change GeneratorFactory class to allow registering custom feature generators",
        "Type": "Improvement",
        "Status": "Closed",
        "Priority": "Major",
        "Resolution": "Fixed",
        "Affects Version/s": "tools-1.5.3",
        "Fix Version/s": "1.6.0",
        "Component/s": "Name Finder",
        "Assignee": "J\u00f6rn Kottmann",
        "Reporter": "WB",
        "Created": "16/Oct/13 07:43",
        "Updated": "21/Oct/14 22:19",
        "Resolved": "12/Mar/14 14:42",
        "Description": "I am trying to setup the OpenNLP NameFinder in a project with an XML feature generator descriptor and some non-standard features. The XML descriptor has support for custom feature generators:\n<generators>\n  <cache>\n    <generators>\n      ...\n      <custom class=\"com.example.MyFeatureGenerator\"/>\n   </cache>\n</generators>\nHowever, it is not possible to pass parameters to the custom feature generator, and registering new feature generators is currently not possible due to access restrictions in the opennlp.tools.util.featuregen.GeneratorFactory class. Lifting some access restrictions (private to public) would solve the issue.\nSee also: http://stackoverflow.com/questions/19375053/using-custom-feature-generators-with-parameters-in-opennlp",
        "Issue Links": []
    },
    "OPENNLP-606": {
        "Key": "OPENNLP-606",
        "Summary": "en-ner-location.bin file has error",
        "Type": "Bug",
        "Status": "Closed",
        "Priority": "Critical",
        "Resolution": "Not A Problem",
        "Affects Version/s": "None",
        "Fix Version/s": "None",
        "Component/s": "None",
        "Assignee": null,
        "Reporter": "cometta",
        "Created": "20/Oct/13 05:03",
        "Updated": "25/Jan/14 18:28",
        "Resolved": "21/Oct/13 06:52",
        "Description": "i try using this file en-ner-location.bin in FileInputStream and get error   java.io.EOFException: Unexpected end of ZLIB input stream  .   Then i tested with another file es-ner-location.bin , which working fine without error.   Can help to fix en-ner-location.bin",
        "Issue Links": []
    },
    "OPENNLP-607": {
        "Key": "OPENNLP-607",
        "Summary": "A framework that supports rapid NER model generation from user data",
        "Type": "Wish",
        "Status": "Closed",
        "Priority": "Minor",
        "Resolution": "Implemented",
        "Affects Version/s": "None",
        "Fix Version/s": "None",
        "Component/s": "Machine Learning",
        "Assignee": "Mark Giaconia",
        "Reporter": "Mark Giaconia",
        "Created": "21/Oct/13 09:54",
        "Updated": "09/Mar/15 20:44",
        "Resolved": "21/Nov/13 21:24",
        "Description": "Users would be able to specify a set of sentences from their data, a set of known entities, and a validation class to build a model. This would allow for \"quick turn\" extraction of named entities, and allow for iterative refinement of models.",
        "Issue Links": []
    },
    "OPENNLP-608": {
        "Key": "OPENNLP-579 Framework to dynamically link N-best matches from external data to named entities by type (EntityLinker framework)",
        "Summary": "EntityLinker framework should provide the means to return multiple types of scores for linkedspans",
        "Type": "Sub-task",
        "Status": "Closed",
        "Priority": "Minor",
        "Resolution": "Implemented",
        "Affects Version/s": "1.6.0",
        "Fix Version/s": "1.6.0",
        "Component/s": "Entity Linker",
        "Assignee": "Mark Giaconia",
        "Reporter": "Mark Giaconia",
        "Created": "21/Oct/13 23:21",
        "Updated": "06/Nov/13 12:14",
        "Resolved": "22/Oct/13 11:36",
        "Description": "Currently the entitylinker LinkedSpan<BaseLink> only has fields for two scores. The BaseLink class should expose a hashmap<String, Double> in order to allow users to score in multiple ways. The GeoEntityLinker will return a FuzzyString matching score based on Dice coef, a CountryContext score, a GeoHashBinning score, and a database rank score. With these scores a user can define downstream logic per business needs.",
        "Issue Links": []
    },
    "OPENNLP-609": {
        "Key": "OPENNLP-579 Framework to dynamically link N-best matches from external data to named entities by type (EntityLinker framework)",
        "Summary": "EntityLinkerProperties should support String path, and InputStream as input",
        "Type": "Sub-task",
        "Status": "Closed",
        "Priority": "Minor",
        "Resolution": "Implemented",
        "Affects Version/s": "1.6.0",
        "Fix Version/s": "1.6.0",
        "Component/s": "Entity Linker",
        "Assignee": "Mark Giaconia",
        "Reporter": "Mark Giaconia",
        "Created": "24/Oct/13 10:26",
        "Updated": "06/Nov/13 12:15",
        "Resolved": "24/Oct/13 23:43",
        "Description": "EntityLinkerProperties should support string and InputStream as input. Currently it only supports File... EntityLinkerProperties(File propertiesfile)",
        "Issue Links": []
    },
    "OPENNLP-610": {
        "Key": "OPENNLP-579 Framework to dynamically link N-best matches from external data to named entities by type (EntityLinker framework)",
        "Summary": "EntityLinkerFactory should return one EntityLinker for simplicity",
        "Type": "Sub-task",
        "Status": "Closed",
        "Priority": "Minor",
        "Resolution": "Implemented",
        "Affects Version/s": "1.6.0",
        "Fix Version/s": "1.6.0",
        "Component/s": "Entity Linker",
        "Assignee": "Mark Giaconia",
        "Reporter": "Mark Giaconia",
        "Created": "25/Oct/13 09:41",
        "Updated": "06/Nov/13 12:16",
        "Resolved": "29/Oct/13 11:52",
        "Description": "EntityLinkerFactory currently return a list of Linkers. This is complicated. EntityLinkerFactory should return one EntityLinker for simplicity",
        "Issue Links": []
    },
    "OPENNLP-611": {
        "Key": "OPENNLP-611",
        "Summary": "Update Build to Java 7",
        "Type": "Dependency upgrade",
        "Status": "Closed",
        "Priority": "Major",
        "Resolution": "Implemented",
        "Affects Version/s": "1.6.0",
        "Fix Version/s": "1.6.0",
        "Component/s": "None",
        "Assignee": "Mark Giaconia",
        "Reporter": "Mark Giaconia",
        "Created": "29/Oct/13 09:48",
        "Updated": "18/Feb/14 13:21",
        "Resolved": "22/Nov/13 12:20",
        "Description": "Currently the CI server builds with java 1.5. Team consensus is to upgrade to 1.7 so code can utilize current funtionality.",
        "Issue Links": []
    },
    "OPENNLP-612": {
        "Key": "OPENNLP-612",
        "Summary": "OpenNLP link to JIRA site broken from web-pages link.",
        "Type": "Documentation",
        "Status": "Closed",
        "Priority": "Minor",
        "Resolution": "Fixed",
        "Affects Version/s": "None",
        "Fix Version/s": "None",
        "Component/s": "Documentation",
        "Assignee": "James Kosin",
        "Reporter": "James Kosin",
        "Created": "01/Nov/13 01:55",
        "Updated": "02/Nov/13 03:15",
        "Resolved": "02/Nov/13 03:14",
        "Description": "From: Andy McMurry\n===\nwould submit JIRA issue, but I can't \nhttps://opennlp.apache.org/get-involved.html\npoints to \nhttps://opennlp.apache.org/issues.apache.org/jira/browse/OPENNLP\n==\nBroken Link",
        "Issue Links": []
    },
    "OPENNLP-613": {
        "Key": "OPENNLP-613",
        "Summary": "I want help to OpenNLP support PT-BR Language",
        "Type": "Question",
        "Status": "Closed",
        "Priority": "Major",
        "Resolution": "Invalid",
        "Affects Version/s": "None",
        "Fix Version/s": "None",
        "Component/s": "None",
        "Assignee": null,
        "Reporter": "Alexandre Oliveira",
        "Created": "04/Nov/13 16:57",
        "Updated": "16/Jan/17 14:35",
        "Resolved": "16/Jan/17 14:35",
        "Description": "Hi,\nHow I can help to create pre-trained models to PT-BR?\nRegards,\nAlexandre",
        "Issue Links": []
    },
    "OPENNLP-614": {
        "Key": "OPENNLP-579 Framework to dynamically link N-best matches from external data to named entities by type (EntityLinker framework)",
        "Summary": "Move GeoEntityLinker to Addons in Sandbox. Leave EntityLinker fwk in tools",
        "Type": "Sub-task",
        "Status": "Closed",
        "Priority": "Minor",
        "Resolution": "Done",
        "Affects Version/s": "1.6.0",
        "Fix Version/s": "1.6.0",
        "Component/s": "Entity Linker",
        "Assignee": "Mark Giaconia",
        "Reporter": "Mark Giaconia",
        "Created": "06/Nov/13 11:37",
        "Updated": "07/Nov/13 02:44",
        "Resolved": "06/Nov/13 11:49",
        "Description": "Create an addons module in the sandbox and move all GeoEntityLinker classes into the addons project. Leave only the EntityLinker framework classes in opennlp tools.",
        "Issue Links": []
    },
    "OPENNLP-615": {
        "Key": "OPENNLP-579 Framework to dynamically link N-best matches from external data to named entities by type (EntityLinker framework)",
        "Summary": "GeoEntityLinker should score toponyms based on surrounding context via a model",
        "Type": "Sub-task",
        "Status": "Closed",
        "Priority": "Major",
        "Resolution": "Implemented",
        "Affects Version/s": "1.6.0",
        "Fix Version/s": "1.6.0",
        "Component/s": "Entity Linker",
        "Assignee": "Mark Giaconia",
        "Reporter": "Mark Giaconia",
        "Created": "09/Nov/13 14:33",
        "Updated": "12/Jan/14 14:58",
        "Resolved": "14/Nov/13 00:21",
        "Description": "As per the concept in this paper http://www.jasonbaldridge.com/papers/speriosu-baldridge-acl2013.pdf\nthe GeoEntityLinker addon should allow a user to score toponyms based on a model. For instance, if the gazateer returns an ambiguous name associated to multiple countries, X and Y, then features should be generated from around the name, and those features should be used as a test set against a categorizer for the country returned and a score generated.\nThis functionality also implies the need for a rapid way to generate the models based on user defined data, because countries and location mentions have content that is highly variant. Also, this method will be configurable in the GeoEntityLinker.\nThe Sandbox contains a model-builder-prototype that I plan to use to generate the models based on user data and the countrycontext data that the GeoEntityLinker requires, which will make it easy to get started.",
        "Issue Links": []
    },
    "OPENNLP-616": {
        "Key": "OPENNLP-616",
        "Summary": "TokenNameFinderTrianer is running in command prompt but while executing program no result found in console",
        "Type": "Test",
        "Status": "Closed",
        "Priority": "Major",
        "Resolution": "Won't Fix",
        "Affects Version/s": "tools-1.5.3",
        "Fix Version/s": "None",
        "Component/s": "Name Finder",
        "Assignee": null,
        "Reporter": "Chetan M",
        "Created": "13/Nov/13 07:51",
        "Updated": "13/Nov/13 13:03",
        "Resolved": "13/Nov/13 13:03",
        "Description": "my ner-person-train file contents are\nMr . <START:person> Vinken <END> is chairman of Elsevier N.V. , the Dutch publishing group . <START:person> Rudolph Agnew <END> , 55 years old and former chairman of Consolidated Gold Fields PLC , was named a director of this British industrial conglomerate .\nafter that i'm running following cmd in commandprompt\nF:\\apache-opennlp-1.5.3\\bin>opennlp TokenNameFinderTrainer -encoding UTF-8 -model en-ner-person.bin -lang en -data en-ner-person.train\nthe above command is successfully running After that i'm executing following program in eclipse\npublic static void findName() throws IOException {\nInputStream is = new FileInputStream(\"F:/apache-opennlp-1.5.3/bin/en-ner-person.bin\");\n          TokenNameFinderModel model = new TokenNameFinderModel(is);\n\t  is.close();\n\tNameFinderME nameFinder = new NameFinderME(model);\n\t\tString []sentence = new String[]\n{\n\t\t\t    \"Mike\",\n\t\t\t    \"Sagar\",\n\t\t\t    \"Jack\",\n\t\t\t    \"Smith\",\n\t\t\t    \"is\",\n\t\t\t    \"a\",\n\t\t\t    \"good\",\n\t\t\t    \"Sachin\",\n\t\t\t    \"person\"\n\t\t\t    }\n;\n\t\t\tSpan nameSpans[] = nameFinder.find(sentence);\n\t\t\tfor(Span s: nameSpans)\n\t\t\t\tSystem.out.println(s.toString());\n\t}\nBut I'm not getting any result. Can any one suggest me to resolve this problem",
        "Issue Links": []
    },
    "OPENNLP-617": {
        "Key": "OPENNLP-617",
        "Summary": "Able to train successfully \"en-ner-person.bin\" but could not able to run NameFinder.",
        "Type": "Question",
        "Status": "Closed",
        "Priority": "Minor",
        "Resolution": "Fixed",
        "Affects Version/s": "tools-1.5.3",
        "Fix Version/s": "tools-1.5.3",
        "Component/s": "Name Finder",
        "Assignee": null,
        "Reporter": "Chetan M",
        "Created": "13/Nov/13 12:12",
        "Updated": "29/Mar/19 20:47",
        "Resolved": "29/Mar/19 20:47",
        "Description": "Hi,\n     I am new to openNLP and trying to execute a small program on name finder and its training.\n       Using Java program, i have created \"en-ner-person.bin\" file successfully with custom UTF-8 .train file. No Errors has thrown. \nBut when we run sample Name finder java program, it doesn't throw any errors and results. It's hanged with blank screen.\nPlease assist us how to make this training and sample name finder to execute properly.\nregards,\nchetan.",
        "Issue Links": []
    },
    "OPENNLP-618": {
        "Key": "OPENNLP-618",
        "Summary": "Tokenize \"can't\"",
        "Type": "Question",
        "Status": "Closed",
        "Priority": "Major",
        "Resolution": "Won't Fix",
        "Affects Version/s": "None",
        "Fix Version/s": "None",
        "Component/s": "None",
        "Assignee": null,
        "Reporter": "tonylxc",
        "Created": "14/Nov/13 21:42",
        "Updated": "11/Mar/14 14:09",
        "Resolved": "18/Feb/14 13:26",
        "Description": "When I use OpenNLP's tokenizer to tokenize this sentence \"I can't do it.\", I get tokens like \"[I] [ca] [n't] [do] [it] [.]\". Isn't it supposed to be something like \"[I] [can] ['] [t] [do] [it] [.]\" or \"[I] [can't] [do] [it] [.]\"? I know LanguageTool's tokenizer gives tokens like \"[I] [can] ['] [t] [do] [it] [.]\".",
        "Issue Links": []
    },
    "OPENNLP-619": {
        "Key": "OPENNLP-619",
        "Summary": "OPENNLP.BAT: change -Xmx4096m to -Xmx1024m",
        "Type": "Bug",
        "Status": "Closed",
        "Priority": "Minor",
        "Resolution": "Fixed",
        "Affects Version/s": "tools-1.5.3",
        "Fix Version/s": "1.6.0",
        "Component/s": "None",
        "Assignee": "J\u00f6rn Kottmann",
        "Reporter": "Yee Fan Tan",
        "Created": "15/Nov/13 17:03",
        "Updated": "09/Mar/15 20:53",
        "Resolved": "09/Mar/15 20:53",
        "Description": "On Windows with 32-bit Java 6, with the original -Xmx4096 in the command, I get the following error message:\nError occurred during initialization of VM\nThe size of the object heap + VM data exceeds the maximum representable size\nTo allow it to run on this environment, the switch should be changed to -Xmx1024. The shell script also uses -Xmx1024.\nThanks.",
        "Issue Links": []
    },
    "OPENNLP-620": {
        "Key": "OPENNLP-620",
        "Summary": "Removed the left over Spanish Token Chunker cmd line tool",
        "Type": "Task",
        "Status": "Closed",
        "Priority": "Minor",
        "Resolution": "Fixed",
        "Affects Version/s": "None",
        "Fix Version/s": "1.6.0",
        "Component/s": "None",
        "Assignee": "J\u00f6rn Kottmann",
        "Reporter": "J\u00f6rn Kottmann",
        "Created": "20/Nov/13 10:33",
        "Updated": "20/Nov/13 10:34",
        "Resolved": "20/Nov/13 10:34",
        "Description": null,
        "Issue Links": []
    },
    "OPENNLP-621": {
        "Key": "OPENNLP-621",
        "Summary": "Stabilize Coreference Resolution Component. Currently does not build due to compilation errors",
        "Type": "Task",
        "Status": "Closed",
        "Priority": "Major",
        "Resolution": "Fixed",
        "Affects Version/s": "1.6.0",
        "Fix Version/s": "None",
        "Component/s": "Coref",
        "Assignee": "Mark Giaconia",
        "Reporter": "Mark Giaconia",
        "Created": "24/Nov/13 02:47",
        "Updated": "12/Mar/14 11:30",
        "Resolved": "12/Mar/14 11:30",
        "Description": "Currently the Coref module will not build due to the change of moving ml into tools. Coref is important functionality, and it should be patched.",
        "Issue Links": []
    },
    "OPENNLP-622": {
        "Key": "OPENNLP-622",
        "Summary": "Extend Morfologik Addon",
        "Type": "New Feature",
        "Status": "Closed",
        "Priority": "Minor",
        "Resolution": "Fixed",
        "Affects Version/s": "1.6.0",
        "Fix Version/s": "1.7.0",
        "Component/s": "None",
        "Assignee": "William Colen",
        "Reporter": "William Colen",
        "Created": "01/Dec/13 16:43",
        "Updated": "20/Dec/16 16:08",
        "Resolved": "20/Dec/16 16:08",
        "Description": "Extends Morfologik Addon functionalities by:\n\nAdding a Tag Dictionary implementation\nAdding support to build Morfologik binary dictionaries from CLI\nAdding a POSTaggerFactory extension to load a Morfologik binary dictionary embedded in a POS Tagger model bundle",
        "Issue Links": []
    },
    "OPENNLP-623": {
        "Key": "OPENNLP-623",
        "Summary": "Add OntoNotes format support",
        "Type": "Improvement",
        "Status": "Closed",
        "Priority": "Minor",
        "Resolution": "Fixed",
        "Affects Version/s": "None",
        "Fix Version/s": "1.6.0",
        "Component/s": "Formats",
        "Assignee": "J\u00f6rn Kottmann",
        "Reporter": "J\u00f6rn Kottmann",
        "Created": "02/Dec/13 16:27",
        "Updated": "27/Feb/14 09:56",
        "Resolved": "27/Feb/14 09:56",
        "Description": "Add native formats support for OntoNotes to OpenNLP. It should be possible to train the POS Tagger, Parser and Name Finder on the OntoNotes data.",
        "Issue Links": []
    },
    "OPENNLP-624": {
        "Key": "OPENNLP-624",
        "Summary": "Add a liblinear integration to the addons",
        "Type": "Improvement",
        "Status": "Closed",
        "Priority": "Major",
        "Resolution": "Fixed",
        "Affects Version/s": "None",
        "Fix Version/s": "1.6.0",
        "Component/s": "Machine Learning",
        "Assignee": "J\u00f6rn Kottmann",
        "Reporter": "J\u00f6rn Kottmann",
        "Created": "03/Dec/13 15:09",
        "Updated": "02/Jan/14 11:58",
        "Resolved": "02/Jan/14 11:58",
        "Description": "Add a liblinear integration as an OpenNLp addon. The Java port of the library is licensed under BSD and can be distributed as part of an Apache project.",
        "Issue Links": []
    },
    "OPENNLP-625": {
        "Key": "OPENNLP-625",
        "Summary": "Integrate morfologik-stemming (including fsa) into OpenNLP Tools",
        "Type": "Improvement",
        "Status": "Closed",
        "Priority": "Major",
        "Resolution": "Won't Fix",
        "Affects Version/s": "None",
        "Fix Version/s": "None",
        "Component/s": "None",
        "Assignee": null,
        "Reporter": "J\u00f6rn Kottmann",
        "Created": "03/Dec/13 16:39",
        "Updated": "31/Jan/17 10:09",
        "Resolved": "31/Jan/17 10:09",
        "Description": "Integrate morfologik-stemming into OpenNLP Tools. The morfologik-stemming library is already used in our addons for the lemmatizer and pos dicitonary. The fsa part of it can be used to create memory efficient dictionaries.\nIt would be nice to integrate morfologik-stemming directly into OpenNLP Tools to have it available as a tool across the existing components.",
        "Issue Links": []
    },
    "OPENNLP-626": {
        "Key": "OPENNLP-579 Framework to dynamically link N-best matches from external data to named entities by type (EntityLinker framework)",
        "Summary": "GeoEntityLinker should use proper Lucene language Analyzers on NGA Geonames",
        "Type": "Sub-task",
        "Status": "Closed",
        "Priority": "Minor",
        "Resolution": "Implemented",
        "Affects Version/s": "1.6.0",
        "Fix Version/s": "1.6.0",
        "Component/s": "Entity Linker",
        "Assignee": "Mark Giaconia",
        "Reporter": "Mark Giaconia",
        "Created": "11/Dec/13 13:43",
        "Updated": "28/Jan/14 14:16",
        "Resolved": "12/Jan/14 14:42",
        "Description": "Currently the standard lucene analyzer is used to index all rows in the NGA Geonames. The Geonames dataset contains language codes, and many names are in native language characters. Lucene has many analyzers to handle this, so the code should integrate these analyzers at index and query time to better support non English text.",
        "Issue Links": []
    },
    "OPENNLP-627": {
        "Key": "OPENNLP-627",
        "Summary": "Major performance degradation with large chunk of data",
        "Type": "Bug",
        "Status": "Closed",
        "Priority": "Major",
        "Resolution": "Won't Fix",
        "Affects Version/s": "1.6.0",
        "Fix Version/s": "None",
        "Component/s": "Name Finder",
        "Assignee": null,
        "Reporter": "Vihari Piratla",
        "Created": "31/Dec/13 18:58",
        "Updated": "03/Jan/17 10:30",
        "Resolved": "03/Jan/17 10:30",
        "Description": "I have  a web page corpus from which I wish to extract some name entities. When I try to do NER on each and every line individually, it took around 6 sec and when I loaded the whole corpus and tried to do NER on this data then it took 600 sec for the same task and for the same data. Is this a bug? This is the web-page that I am trying to extract names from: www.sec.gov/Archives/edgar/data/1326801/000119312512034517/d287954ds1.htm",
        "Issue Links": []
    },
    "OPENNLP-628": {
        "Key": "OPENNLP-628",
        "Summary": "Parse thicket-based content generator",
        "Type": "Improvement",
        "Status": "Closed",
        "Priority": "Major",
        "Resolution": "Fixed",
        "Affects Version/s": "None",
        "Fix Version/s": "None",
        "Component/s": "Similarity",
        "Assignee": "Boris Galitsky",
        "Reporter": "Boris Galitsky",
        "Created": "06/Jan/14 17:43",
        "Updated": "09/Mar/15 20:44",
        "Resolved": "18/Feb/14 18:39",
        "Description": "Use web mining, relevance verification and discourse models to write a 40-60 page essay on a topic. Demo is available at \nhttp://173.255.254.250/cgRequestForm.html",
        "Issue Links": []
    },
    "OPENNLP-629": {
        "Key": "OPENNLP-629",
        "Summary": "Third person singular verbs are wrongly tagged as NNS instead of VBG",
        "Type": "Bug",
        "Status": "Closed",
        "Priority": "Minor",
        "Resolution": "Won't Fix",
        "Affects Version/s": "tools-1.5.3",
        "Fix Version/s": "None",
        "Component/s": "Parser",
        "Assignee": null,
        "Reporter": "Ioan Barbulescu",
        "Created": "10/Jan/14 13:20",
        "Updated": "09/Jan/17 15:16",
        "Resolved": "09/Jan/17 15:16",
        "Description": "Hi team\nIn many cases, verbs (third person, singular) are wrongly tagged as \"NNS\" instead of being tagged as VBG.\nFor example, for \"the dog barks\", we get the following parsing results:\n-0.4873670715270621 = DT/0.9543650543068872 NN/0.9934635416261295 NNS/0.6478473815054814 \n-2.3176263333647076 = DT/0.9543650543068872 NN/0.9934635416261295 ./0.10389656993335769 \n-2.5438814602384756 = DT/0.9543650543068872 NN/0.9934635416261295 POS/0.08285903227408052 \n-3.1472424852917578 = DT/0.9543650543068872 NN/0.9934635416261295 VBG/0.045321418371414506 \n-3.3093737662787484 = DT/0.9543650543068872 NN/0.9934635416261295 RB/0.03853814197383135 \n-3.785492750117388 = DT/0.9543650543068872 NN/0.9934635416261295 IN/0.023939491699927738 \n-4.419574088556415 = DT/0.9543650543068872 NN/0.9934635416261295 NN/0.0126980460743554 \n-4.641227787202645 = DT/0.9543650543068872 NN/0.9934635416261295 WDT/0.010173582713485872 \n-4.645517470925252 = DT/0.9543650543068872 NN/0.9934635416261295 :/0.010130034731632277 \n-5.319832699567059 = DT/0.9543650543068872 NN/0.9934635416261295 ''/0.005161305328825757 \n(TOP (NP (DT the) (NN dog) (NNS barks)))\n2.6064504449697834\n(TOP (S (NP (DT the) (NN dog)) (NNS barks)))\n1.9485980564427359\nThe biggest probability for the third term is found for NNS - by far - 0.64.\nIn comparison, VBG is found with a probability of only 0.04.\nThis parsing error manifests itself consistently, for most occurrences of the third person / singular verbs, regardless the context.\nAm I missing something? \nMaybe there is some supplementary configuration that controls this?\nCan this be fixed only through code, or we need to patch our training data set?\nThank you so much.\nBR,\nIoan",
        "Issue Links": []
    },
    "OPENNLP-630": {
        "Key": "OPENNLP-630",
        "Summary": "Add a cmdline interface for the Entity Linker",
        "Type": "New Feature",
        "Status": "Closed",
        "Priority": "Major",
        "Resolution": "Fixed",
        "Affects Version/s": "None",
        "Fix Version/s": "1.6.0",
        "Component/s": "Entity Linker",
        "Assignee": "J\u00f6rn Kottmann",
        "Reporter": "J\u00f6rn Kottmann",
        "Created": "10/Jan/14 14:01",
        "Updated": "29/Oct/14 16:07",
        "Resolved": "29/Oct/14 16:07",
        "Description": "The Entity Linker should have a command line interface. The command line tool should be capable of running an entity linker over some sample data.",
        "Issue Links": []
    },
    "OPENNLP-631": {
        "Key": "OPENNLP-631",
        "Summary": "EntityLinkerFactory.getLinker does not work in OSGi environment",
        "Type": "Bug",
        "Status": "Closed",
        "Priority": "Major",
        "Resolution": "Fixed",
        "Affects Version/s": "None",
        "Fix Version/s": "1.6.0",
        "Component/s": "Entity Linker",
        "Assignee": "J\u00f6rn Kottmann",
        "Reporter": "J\u00f6rn Kottmann",
        "Created": "14/Jan/14 22:43",
        "Updated": "21/Feb/14 15:34",
        "Resolved": "21/Feb/14 15:34",
        "Description": "The EntityLinkerFactory.getLinker method uses Class.forName to instantiate a class configured in the properties file. That will not work if OpenNLP is running in an OSGi environment.\nTo fix this the factory should use the ExtensionLoader util class.",
        "Issue Links": []
    },
    "OPENNLP-632": {
        "Key": "OPENNLP-632",
        "Summary": "Improve the stream handling in the EntityLinkerProperties constructors",
        "Type": "Bug",
        "Status": "Closed",
        "Priority": "Major",
        "Resolution": "Fixed",
        "Affects Version/s": "None",
        "Fix Version/s": "1.6.0",
        "Component/s": "Entity Linker",
        "Assignee": "Mark Giaconia",
        "Reporter": "J\u00f6rn Kottmann",
        "Created": "14/Jan/14 22:46",
        "Updated": "12/Mar/14 11:13",
        "Resolved": "12/Mar/14 11:13",
        "Description": "The stream handling in the various constructors should be improved.\nThe constructor taking an InputStream should not close it, that is the responsibility of the caller. The constructor taking a File object should use a try catch statement to ensure the stream is closed even when loading the property file fails.",
        "Issue Links": []
    },
    "OPENNLP-633": {
        "Key": "OPENNLP-633",
        "Summary": "Add sample training param files for all trainer types",
        "Type": "Improvement",
        "Status": "Closed",
        "Priority": "Minor",
        "Resolution": "Fixed",
        "Affects Version/s": "None",
        "Fix Version/s": "1.6.0",
        "Component/s": "Machine Learning",
        "Assignee": "J\u00f6rn Kottmann",
        "Reporter": "J\u00f6rn Kottmann",
        "Created": "17/Jan/14 17:53",
        "Updated": "17/Jan/14 17:58",
        "Resolved": "17/Jan/14 17:58",
        "Description": "The lang package should contain trainer param sample files for each trainer.",
        "Issue Links": []
    },
    "OPENNLP-634": {
        "Key": "OPENNLP-634",
        "Summary": "Deprecated TrainerFactory.isSequenceTraining",
        "Type": "Improvement",
        "Status": "Closed",
        "Priority": "Minor",
        "Resolution": "Fixed",
        "Affects Version/s": "None",
        "Fix Version/s": "1.6.0",
        "Component/s": "Machine Learning",
        "Assignee": "J\u00f6rn Kottmann",
        "Reporter": "J\u00f6rn Kottmann",
        "Created": "17/Jan/14 18:31",
        "Updated": "17/Jan/14 18:36",
        "Resolved": "17/Jan/14 18:36",
        "Description": "The method is as of now deprecated and should not be used any longer.\nAs part of this issue updated all invocations to it.",
        "Issue Links": []
    },
    "OPENNLP-635": {
        "Key": "OPENNLP-635",
        "Summary": "TrainerFactory.isSupportSequence fails to recognize a pluggable sequence trainer",
        "Type": "Bug",
        "Status": "Closed",
        "Priority": "Major",
        "Resolution": "Fixed",
        "Affects Version/s": "None",
        "Fix Version/s": "1.6.0",
        "Component/s": "Machine Learning",
        "Assignee": "J\u00f6rn Kottmann",
        "Reporter": "J\u00f6rn Kottmann",
        "Created": "17/Jan/14 18:43",
        "Updated": "17/Jan/14 19:24",
        "Resolved": "17/Jan/14 19:24",
        "Description": "The new pluggable trainer support should support event and sequence trainers. The method to test if a trainer is a sequence trainer fails to recognize a pluggable trainer as a sequence trainer even so it is one.",
        "Issue Links": []
    },
    "OPENNLP-636": {
        "Key": "OPENNLP-636",
        "Summary": "TrainerFactory uses Class.forName and will not work well in an OSGi environment",
        "Type": "Bug",
        "Status": "Closed",
        "Priority": "Minor",
        "Resolution": "Fixed",
        "Affects Version/s": "None",
        "Fix Version/s": "1.6.0",
        "Component/s": "Machine Learning",
        "Assignee": "J\u00f6rn Kottmann",
        "Reporter": "J\u00f6rn Kottmann",
        "Created": "17/Jan/14 19:25",
        "Updated": "20/Feb/14 10:24",
        "Resolved": "20/Feb/14 10:24",
        "Description": "Remove the usage of Class.forName from the TrainerFactory class to make it compatible with OSGi.",
        "Issue Links": []
    },
    "OPENNLP-637": {
        "Key": "OPENNLP-579 Framework to dynamically link N-best matches from external data to named entities by type (EntityLinker framework)",
        "Summary": "GeoEntityLinker should dedupe entries returned from Gazateers",
        "Type": "Sub-task",
        "Status": "Closed",
        "Priority": "Major",
        "Resolution": "Fixed",
        "Affects Version/s": "1.6.0",
        "Fix Version/s": "1.6.0",
        "Component/s": "Entity Linker",
        "Assignee": "Mark Giaconia",
        "Reporter": "Mark Giaconia",
        "Created": "18/Jan/14 14:47",
        "Updated": "28/Jan/14 14:17",
        "Resolved": "28/Jan/14 14:07",
        "Description": "Gazateers can have dupes, especially when returning a subset of fields. The GeoEntityLinker addon appears to return many duplicates from the GeoNames Gazateer. Deduping should be performed on a Span by Span basis.",
        "Issue Links": []
    },
    "OPENNLP-638": {
        "Key": "OPENNLP-579 Framework to dynamically link N-best matches from external data to named entities by type (EntityLinker framework)",
        "Summary": "EntityLinker setEntityLinkerProperties should throw Exception and be renamed to init(props)",
        "Type": "Sub-task",
        "Status": "Closed",
        "Priority": "Major",
        "Resolution": "Fixed",
        "Affects Version/s": "1.6.0",
        "Fix Version/s": "1.6.0",
        "Component/s": "Entity Linker",
        "Assignee": "Mark Giaconia",
        "Reporter": "Mark Giaconia",
        "Created": "18/Jan/14 14:52",
        "Updated": "28/Jan/14 14:16",
        "Resolved": "18/Jan/14 20:01",
        "Description": "In order for exceptions to be reported as soon as possible, the setEntityLinkerProperties method in the EntityLinker interface should throw exceptions and be renamed to init(), so during EntityLinker factory reflective instantiation, the error is thrown from the Factory. \nDocumentation should reflect that EntityLinker impls should inittialize external resources in this method, hence the name change to init(..)",
        "Issue Links": []
    },
    "OPENNLP-639": {
        "Key": "OPENNLP-579 Framework to dynamically link N-best matches from external data to named entities by type (EntityLinker framework)",
        "Summary": "GazateerSearcher cacheing the wrong value",
        "Type": "Sub-task",
        "Status": "Closed",
        "Priority": "Major",
        "Resolution": "Fixed",
        "Affects Version/s": "1.6.0",
        "Fix Version/s": "1.6.0",
        "Component/s": "Entity Linker",
        "Assignee": "Mark Giaconia",
        "Reporter": "Mark Giaconia",
        "Created": "18/Jan/14 19:24",
        "Updated": "28/Jan/14 14:15",
        "Resolved": "28/Jan/14 14:09",
        "Description": "Place name was being cached rather than query string",
        "Issue Links": []
    },
    "OPENNLP-640": {
        "Key": "OPENNLP-640",
        "Summary": "TokenNameFinderEvaluator (brat) is missing -nameTypes argument",
        "Type": "Bug",
        "Status": "Closed",
        "Priority": "Minor",
        "Resolution": "Fixed",
        "Affects Version/s": "None",
        "Fix Version/s": "1.6.0",
        "Component/s": "Name Finder",
        "Assignee": "J\u00f6rn Kottmann",
        "Reporter": "Peter Thygesen",
        "Created": "21/Jan/14 14:06",
        "Updated": "29/Jan/14 10:14",
        "Resolved": "27/Jan/14 12:08",
        "Description": "It should be possible to specify the \"name type\" that corresponds to the model being evaluated. Otherwise you get lots of false negatives when evaluating data files containing multiple annotation types.",
        "Issue Links": []
    },
    "OPENNLP-641": {
        "Key": "OPENNLP-641",
        "Summary": "Add sequence classification support",
        "Type": "Improvement",
        "Status": "Closed",
        "Priority": "Major",
        "Resolution": "Fixed",
        "Affects Version/s": "None",
        "Fix Version/s": "1.6.0",
        "Component/s": "Machine Learning",
        "Assignee": "J\u00f6rn Kottmann",
        "Reporter": "J\u00f6rn Kottmann",
        "Created": "27/Jan/14 11:30",
        "Updated": "21/Oct/14 22:18",
        "Resolved": "12/Mar/14 14:43",
        "Description": "The current machine learning integration doesn't support sequence models. That are models which classify an entire sequence at once compared to the classification support we have right now which can only make a single decision at a time.",
        "Issue Links": []
    },
    "OPENNLP-642": {
        "Key": "OPENNLP-642",
        "Summary": "Remove deprecated iteration and cutoff params",
        "Type": "Improvement",
        "Status": "Closed",
        "Priority": "Minor",
        "Resolution": "Fixed",
        "Affects Version/s": "None",
        "Fix Version/s": "1.6.0",
        "Component/s": "Command Line Interface",
        "Assignee": "J\u00f6rn Kottmann",
        "Reporter": "J\u00f6rn Kottmann",
        "Created": "27/Jan/14 12:51",
        "Updated": "27/Jan/14 14:19",
        "Resolved": "27/Jan/14 14:19",
        "Description": "The deprecated iterations and cutoff parameters have been replaced by a properties file (or TrainingParameters object) which can contain all necessary parameters for a certain machine learning implementation.\nRemove all deprecated API which is still using them. Also remove the parameters from the command line interface.",
        "Issue Links": []
    },
    "OPENNLP-643": {
        "Key": "OPENNLP-643",
        "Summary": "Provide default rule based (regex) name finders (phone num, url, email, coords)",
        "Type": "New Feature",
        "Status": "Closed",
        "Priority": "Minor",
        "Resolution": "Fixed",
        "Affects Version/s": "1.6.0",
        "Fix Version/s": "1.6.0",
        "Component/s": "Name Finder",
        "Assignee": "Mark Giaconia",
        "Reporter": "Mark Giaconia",
        "Created": "29/Jan/14 12:20",
        "Updated": "11/Mar/14 11:09",
        "Resolved": "11/Mar/14 11:09",
        "Description": "It would be nice if OpenNLP came with some basic rule based namefinders (RegexNameFinders) for basic types. Initially I would like to create an engine that runs phonenum,. email,  url, MGRS, and DD Lat Lon.\nAlso, we need a framework for loading additional regexes other than the defaults mentioned above.\nHere is my initial thought... a class that has a set of default types and patterns in a map that runs the RegexNameFinder, with optional constructors to override the map, or read from a config file.\nLet me know what you think...\n/**\n *\n\nConstructs a set of RegexNameFinders from configuration or from a provided Map\n */\npublic class RuleBasedEntityFinderEngine {\n\n  private static final String PHONE_REGEX = \"\";\n  private static final String EMAIL_REGEX = \"\";\n  private static final String URL_REGEX = \"\";\n  private static final String MGRS_REGEX = \"\";\n  private static final String DDLATLON_REGEX = \"\";\n  private static final String PHONE_REGEX_TYPE = \"phone number\";\n  private static final String EMAIL_REGEX_TYPE = \"email\";\n  private static final String URL_REGEX_TYPE = \"url\";\n  private static final String MGRS_REGEX_TYPE = \"MGRS coord\";\n  private static final String DDLATLON_REGEX_TYPE = \"DD coord\";\n  private Map<String, Pattern[]> typePatternMap = new HashMap<>();\n  Properties properties;\n  /**\n\nLoads a set of patterns via configuration. The file should have the entity\ntype with no spaces, followed by the regex. For types that have multiple\nregexes, duplicate the type on each line. for example: phone_num <phonenum\nregex1>\nphone_num <phonenum regex2>\nemail <regex1>\nEach entry will be loaded in order from top to bottom of file, so if order\nmatters list regexes accordingly from top to bottom\n   *\n@param properties      the inputStream of props from which to load the\nregexes from\n@param includeDefaults when true, adds the defaults to the map. if there is\nkey collision in the map, the default will override.\n@throws IOException\n   */\n  public RuleBasedEntityFinderEngine(InputStream properties, boolean includeDefaults) throws IOException \n{\n    this.properties = new Properties();\n    this.properties.load(properties);\n    init();\n  }\n\n  /**\n   *\n\n@param typePatternMap  a map of name types (i.e. phone number, email...) to\nan array of regex Patterns. This map is the basis\nfor instantiating regexnamefinders\n@param includeDefaults when true, add the defaults to the map. if there is\nkey collision in the map, the default will override.\n   */\n  public RuleBasedEntityFinderEngine(Map<String, Pattern[]> typePatternMap, boolean includeDefaults) \nUnknown macro: {    this.typePatternMap = typePatternMap;    if (includeDefaults) {\n      init();\n    }  } \n\n  /**\n\nloads default regexs and types into the map\n   */\n  private void init() {\n    if (properties != null) \n{\n      //get the regexes from config somewhere\n      /**\n       *TODO\n       */\n    }\n else {\n\n      typePatternMap.put(PHONE_REGEX_TYPE, new Pattern[]\n{Pattern.compile(PHONE_REGEX)}\n);\n      typePatternMap.put(EMAIL_REGEX_TYPE, new Pattern[]\n{Pattern.compile(EMAIL_REGEX)}\n);\n      typePatternMap.put(URL_REGEX_TYPE, new Pattern[]\n{Pattern.compile(URL_REGEX)}\n);\n      typePatternMap.put(MGRS_REGEX_TYPE, new Pattern[]\n{Pattern.compile(MGRS_REGEX)}\n);\n      typePatternMap.put(DDLATLON_REGEX_TYPE, new Pattern[]\n{Pattern.compile(DDLATLON_REGEX)}\n);\n      //load the default regexes\n    }\n  }\n  public Map<String, Span[]> find(String[] tokens) {\n    Map<String, Span[]> outSpans = new HashMap<>();\n    if (typePatternMap != null) {\n      for (Map.Entry<String, Pattern[]> finder : typePatternMap.entrySet()) \n{\n        RegexNameFinder nf = new RegexNameFinder(finder.getValue(), finder.getKey());\n        Span[] spans = nf.find(tokens);\n        outSpans.put(finder.getKey(), spans);\n      }\n    }\n    return outSpans;\n  }\n  public Map<String, Pattern[]> getTypePatternMap() \n{\n    init();\n    return typePatternMap;\n  }\n}",
        "Issue Links": []
    },
    "OPENNLP-644": {
        "Key": "OPENNLP-644",
        "Summary": "W2VClassesDictionary serialization is broken",
        "Type": "Bug",
        "Status": "Closed",
        "Priority": "Major",
        "Resolution": "Fixed",
        "Affects Version/s": "None",
        "Fix Version/s": "1.6.0",
        "Component/s": "Name Finder",
        "Assignee": "J\u00f6rn Kottmann",
        "Reporter": "J\u00f6rn Kottmann",
        "Created": "31/Jan/14 00:30",
        "Updated": "31/Jan/14 00:32",
        "Resolved": "31/Jan/14 00:32",
        "Description": "The dictionary is mistakenly serialized in the correct format. Each entry should be written in its own line, instead all entries are written after each other without any separator char.",
        "Issue Links": []
    },
    "OPENNLP-645": {
        "Key": "OPENNLP-645",
        "Summary": "OpenNLP UIMA Annotators won't build",
        "Type": "Bug",
        "Status": "Closed",
        "Priority": "Major",
        "Resolution": "Fixed",
        "Affects Version/s": "1.6.0",
        "Fix Version/s": "1.6.0",
        "Component/s": "UIMA Integration",
        "Assignee": "Mark Giaconia",
        "Reporter": "Mark Giaconia",
        "Created": "06/Feb/14 01:09",
        "Updated": "06/Feb/14 09:49",
        "Resolved": "06/Feb/14 09:49",
        "Description": "Two classes failed to build. reported via stack overflow.",
        "Issue Links": []
    },
    "OPENNLP-646": {
        "Key": "OPENNLP-646",
        "Summary": "Brat SpanAnnotations with empty covered text",
        "Type": "Wish",
        "Status": "Closed",
        "Priority": "Minor",
        "Resolution": "Fixed",
        "Affects Version/s": "None",
        "Fix Version/s": "1.6.0",
        "Component/s": "Formats",
        "Assignee": "J\u00f6rn Kottmann",
        "Reporter": "Peter Thygesen",
        "Created": "07/Feb/14 22:43",
        "Updated": "18/Feb/14 11:42",
        "Resolved": "18/Feb/14 11:42",
        "Description": "The class BratDocument's static parseDocument generated SpanAnnotations with empty covered text\u2026 I think that is a little messy. was this done in order to save memory? Otherwise I think you should rewrite the getCoveredText so it looks like opennlp.util.Span's CharSequence Span.getCoveredText(CharSequence text) \nincluded a patch that compiles on current trunk.\nWe could also fix SpanAnnotationParser to read the \"covered\" text but I think I should look more like the opennlp api.",
        "Issue Links": []
    },
    "OPENNLP-647": {
        "Key": "OPENNLP-647",
        "Summary": "Build Server still reporting issues to opennlp-dev@incubator.apache.org",
        "Type": "Improvement",
        "Status": "Closed",
        "Priority": "Minor",
        "Resolution": "Fixed",
        "Affects Version/s": "None",
        "Fix Version/s": "None",
        "Component/s": "Build, Packaging and Test",
        "Assignee": "J\u00f6rn Kottmann",
        "Reporter": "James Kosin",
        "Created": "13/Feb/14 02:30",
        "Updated": "13/Feb/14 09:48",
        "Resolved": "13/Feb/14 09:48",
        "Description": "Hi,\nthe OpenNLP Jenkins job still posts to \"opennlp-dev@incubator.apache.org\".\nCheers,\n\u2013 Richard",
        "Issue Links": []
    },
    "OPENNLP-648": {
        "Key": "OPENNLP-648",
        "Summary": "Add a name finder feature generator descriptor for the German CONLL 03 shared task",
        "Type": "Improvement",
        "Status": "Closed",
        "Priority": "Minor",
        "Resolution": "Fixed",
        "Affects Version/s": "None",
        "Fix Version/s": "1.6.0",
        "Component/s": "Name Finder",
        "Assignee": "J\u00f6rn Kottmann",
        "Reporter": "J\u00f6rn Kottmann",
        "Created": "20/Feb/14 15:00",
        "Updated": "20/Feb/14 15:04",
        "Resolved": "20/Feb/14 15:04",
        "Description": "Add a sample descriptor file to optimize the name finder feature generation for the German CONLL 03 shared task.",
        "Issue Links": []
    },
    "OPENNLP-649": {
        "Key": "OPENNLP-649",
        "Summary": "Loading trained model (DoccatModel) throws exception",
        "Type": "Bug",
        "Status": "Closed",
        "Priority": "Critical",
        "Resolution": "Not A Problem",
        "Affects Version/s": "tools-1.5.3",
        "Fix Version/s": "None",
        "Component/s": "Doccat",
        "Assignee": "J\u00f6rn Kottmann",
        "Reporter": "Saed Hammad",
        "Created": "21/Feb/14 22:27",
        "Updated": "24/Feb/14 09:09",
        "Resolved": "24/Feb/14 09:09",
        "Description": "loading traindModel (bin file) throws exception I used this code to load the bin file :\nInputStream inputStream = DocumentCategrizer.class.getClassLoader().getResourceAsStream(\"trainedModel/en-sport.bin\");\n        DoccatModel doccatModel = new DoccatModel(inputStream);\nand this is the exception I'm facing :\nSEVERE: null\nopennlp.tools.util.InvalidFormatException: Entry name must have type extension: \n\tat opennlp.tools.util.model.BaseModel.getEntryExtension(BaseModel.java:324)\n\tat opennlp.tools.util.model.BaseModel.loadModel(BaseModel.java:222)\n\tat opennlp.tools.util.model.BaseModel.<init>(BaseModel.java:181)\n\tat opennlp.tools.doccat.DoccatModel.<init>(DoccatModel.java:48)",
        "Issue Links": []
    },
    "OPENNLP-650": {
        "Key": "OPENNLP-650",
        "Summary": "Parser command-line tool exception on input line of solely whitespace.",
        "Type": "Improvement",
        "Status": "Closed",
        "Priority": "Major",
        "Resolution": "Fixed",
        "Affects Version/s": "tools-1.5.3",
        "Fix Version/s": "1.6.0",
        "Component/s": "Parser",
        "Assignee": "J\u00f6rn Kottmann",
        "Reporter": "Aaron Binns",
        "Created": "23/Feb/14 19:10",
        "Updated": "21/Oct/14 22:47",
        "Resolved": "24/Feb/14 08:59",
        "Description": "In the Parser command-line tool, if an input line is comprised of solely whitespace, then you get an array index exception in parseLine\n    String text = sb.substring(0, sb.length() - 1);\nbecause the whitespace doesn't produce any tokens thus sb.length() is 0, and you wind up with an end position of -1.\nSimple solution is to .trim() the input string in ParserTool.",
        "Issue Links": []
    },
    "OPENNLP-651": {
        "Key": "OPENNLP-651",
        "Summary": "Prepare the 1.6.0 release",
        "Type": "Task",
        "Status": "Closed",
        "Priority": "Major",
        "Resolution": "Fixed",
        "Affects Version/s": "None",
        "Fix Version/s": "1.6.0",
        "Component/s": "None",
        "Assignee": "J\u00f6rn Kottmann",
        "Reporter": "J\u00f6rn Kottmann",
        "Created": "24/Feb/14 09:40",
        "Updated": "28/Dec/16 23:34",
        "Resolved": "28/Dec/16 23:34",
        "Description": "This issue will track all the work that has to be done to get the trunk into a state that can be released, e.g. update to NOTICE files, LICENSE updates, build fixes, etc.",
        "Issue Links": []
    },
    "OPENNLP-652": {
        "Key": "OPENNLP-652",
        "Summary": "Add 20Newsgroups format support to the doccat component",
        "Type": "Improvement",
        "Status": "Closed",
        "Priority": "Minor",
        "Resolution": "Fixed",
        "Affects Version/s": "None",
        "Fix Version/s": "1.8.4",
        "Component/s": "Doccat,                                            Formats",
        "Assignee": "J\u00f6rn Kottmann",
        "Reporter": "J\u00f6rn Kottmann",
        "Created": "27/Feb/14 11:37",
        "Updated": "21/Nov/17 08:50",
        "Resolved": "21/Nov/17 08:50",
        "Description": "It would be nice to have formats support for the 20Newsgroups data. The data would be nice to have for a real demonstration of the doccat component.",
        "Issue Links": [
            "https://github.com/apache/opennlp/pull/287"
        ]
    },
    "OPENNLP-653": {
        "Key": "OPENNLP-653",
        "Summary": "Entity linker factory should not require the \"entity type\" parameter",
        "Type": "Improvement",
        "Status": "Closed",
        "Priority": "Minor",
        "Resolution": "Fixed",
        "Affects Version/s": "None",
        "Fix Version/s": "1.6.0",
        "Component/s": "Entity Linker",
        "Assignee": "Mark Giaconia",
        "Reporter": "J\u00f6rn Kottmann",
        "Created": "27/Feb/14 13:06",
        "Updated": "12/Mar/14 10:50",
        "Resolved": "12/Mar/14 10:50",
        "Description": "The current implementation of the Entity Linker Factory requires the caller to pass in the entity type. This parameter, if needed, should be stored inside the passed in properties.",
        "Issue Links": []
    },
    "OPENNLP-654": {
        "Key": "OPENNLP-654",
        "Summary": "Remove the entitylinker.domain package",
        "Type": "Task",
        "Status": "Closed",
        "Priority": "Minor",
        "Resolution": "Fixed",
        "Affects Version/s": "None",
        "Fix Version/s": "1.6.0",
        "Component/s": "Entity Linker",
        "Assignee": "Mark Giaconia",
        "Reporter": "J\u00f6rn Kottmann",
        "Created": "27/Feb/14 13:13",
        "Updated": "10/Mar/14 21:40",
        "Resolved": "10/Mar/14 21:40",
        "Description": "The entitylinker.domain package just contain two classes which hold information about the result. To be uniform with other components it would be better if the two classes are moved to the entitylinker package and the entitylinker.domain package is removed.",
        "Issue Links": []
    },
    "OPENNLP-655": {
        "Key": "OPENNLP-655",
        "Summary": "Entity Linker Factory should not throw \"Exception\"",
        "Type": "Task",
        "Status": "Closed",
        "Priority": "Major",
        "Resolution": "Fixed",
        "Affects Version/s": "None",
        "Fix Version/s": "1.6.0",
        "Component/s": "Entity Linker",
        "Assignee": "Mark Giaconia",
        "Reporter": "J\u00f6rn Kottmann",
        "Created": "27/Feb/14 14:04",
        "Updated": "11/Mar/14 10:50",
        "Resolved": "11/Mar/14 10:50",
        "Description": "The entity linker factory should not just throw Exception. Other components just throw IOException during instantiation if something goes wrong. Or Runtime Exceptions, e.g. if class loading fails.\nWould it be sufficient to declare IOException?",
        "Issue Links": []
    },
    "OPENNLP-656": {
        "Key": "OPENNLP-656",
        "Summary": "Avoid code duplication in EntityLinkerProperties constructors and optimize exception handling",
        "Type": "Task",
        "Status": "Closed",
        "Priority": "Trivial",
        "Resolution": "Fixed",
        "Affects Version/s": "None",
        "Fix Version/s": "1.6.0",
        "Component/s": "Entity Linker",
        "Assignee": "J\u00f6rn Kottmann",
        "Reporter": "J\u00f6rn Kottmann",
        "Created": "27/Feb/14 14:08",
        "Updated": "27/Feb/14 14:18",
        "Resolved": "27/Feb/14 14:18",
        "Description": "A few lines of code are duplicated in the constructors, and the exception handling is not optimal. IOException should not be caught and rethrown.",
        "Issue Links": []
    },
    "OPENNLP-657": {
        "Key": "OPENNLP-657",
        "Summary": "Donation of nlp-utils to Apache OpenNLP",
        "Type": "Task",
        "Status": "Closed",
        "Priority": "Major",
        "Resolution": "Fixed",
        "Affects Version/s": "None",
        "Fix Version/s": "None",
        "Component/s": "None",
        "Assignee": null,
        "Reporter": "Tommaso Teofili",
        "Created": "28/Feb/14 09:10",
        "Updated": "10/Mar/14 13:17",
        "Resolved": "10/Mar/14 12:29",
        "Description": "As discussed on the user list (http://markmail.org/message/zio3jbrakj5qz5au) this is the issue to track the donation of nlp-utils (https://github.com/tteofili/nlp-utils) to Apache OpenNLP.\nMain interested components are language modeling and ngram.",
        "Issue Links": []
    },
    "OPENNLP-658": {
        "Key": "OPENNLP-658",
        "Summary": "Make the sequence codec in the name finder configurable",
        "Type": "Improvement",
        "Status": "Closed",
        "Priority": "Major",
        "Resolution": "Fixed",
        "Affects Version/s": "None",
        "Fix Version/s": "1.6.0",
        "Component/s": "Name Finder",
        "Assignee": "J\u00f6rn Kottmann",
        "Reporter": "J\u00f6rn Kottmann",
        "Created": "28/Feb/14 16:34",
        "Updated": "07/Mar/14 10:26",
        "Resolved": "07/Mar/14 10:26",
        "Description": "The name finder should have the ability to change the sequence codec. The name finder uses by default IOB2. It should be possible to use other codecs such as BILOU as well.",
        "Issue Links": []
    },
    "OPENNLP-659": {
        "Key": "OPENNLP-659",
        "Summary": "Language models",
        "Type": "New Feature",
        "Status": "Closed",
        "Priority": "Minor",
        "Resolution": "Fixed",
        "Affects Version/s": "tools-1.5.3",
        "Fix Version/s": "1.7.0",
        "Component/s": "None",
        "Assignee": "Tommaso Teofili",
        "Reporter": "Martin Wunderlich",
        "Created": "01/Mar/14 10:30",
        "Updated": "03/Nov/16 19:37",
        "Resolved": "08/Feb/16 15:52",
        "Description": "This feature request is for inclusion of n-gramm language models in OpenNLP. The language models could either be preconstructed from existing corpora for various languages or they could be built by the user based on sample texts. There should be unigram, bigram and trigram LMs at least, with absolute and relative frequencies for each n-gram.",
        "Issue Links": [
            "/jira/browse/OPENNLP-741"
        ]
    },
    "OPENNLP-660": {
        "Key": "OPENNLP-660",
        "Summary": "Stoplist",
        "Type": "New Feature",
        "Status": "Open",
        "Priority": "Minor",
        "Resolution": "Unresolved",
        "Affects Version/s": "tools-1.5.3",
        "Fix Version/s": "None",
        "Component/s": "Parser,                                            Stemmer",
        "Assignee": null,
        "Reporter": "Martin Wunderlich",
        "Created": "01/Mar/14 10:33",
        "Updated": "17/May/15 20:43",
        "Resolved": null,
        "Description": "This feature request is for inclusion of list of stop words for various languages. These stop word lists can be used to reduce the noise caused by by frequent but irrelevant words, e.g. when tokenizing texts. The list could be a simple list of words for a first iteration, but could also include multi-stopwords, which will apply to n-grams (i.e. a word in the list will serve to \"stop\" a multi-word n-gram).",
        "Issue Links": []
    },
    "OPENNLP-661": {
        "Key": "OPENNLP-661",
        "Summary": "Remove opennlp-ml from the sandbox",
        "Type": "Task",
        "Status": "Closed",
        "Priority": "Major",
        "Resolution": "Fixed",
        "Affects Version/s": "None",
        "Fix Version/s": "None",
        "Component/s": "None",
        "Assignee": "J\u00f6rn Kottmann",
        "Reporter": "J\u00f6rn Kottmann",
        "Created": "05/Mar/14 12:37",
        "Updated": "05/Mar/14 12:49",
        "Resolved": "05/Mar/14 12:49",
        "Description": "The OpenNLP machine learning code was integrated into the openlp-tools project. The opennlp-ml project should be removed from the sandbox.",
        "Issue Links": []
    },
    "OPENNLP-662": {
        "Key": "OPENNLP-662",
        "Summary": "Remove jwnl and maxent inclusions from bin.xml assembly file",
        "Type": "Task",
        "Status": "Closed",
        "Priority": "Trivial",
        "Resolution": "Fixed",
        "Affects Version/s": "None",
        "Fix Version/s": "1.6.0",
        "Component/s": "Build, Packaging and Test",
        "Assignee": "J\u00f6rn Kottmann",
        "Reporter": "J\u00f6rn Kottmann",
        "Created": "05/Mar/14 15:55",
        "Updated": "05/Mar/14 15:56",
        "Resolved": "05/Mar/14 15:56",
        "Description": "The build outputs the following warning.\n[WARNING] The following patterns were never triggered in this artifact inclusion filter:\no  'org.apache.opennlp:opennlp-maxent'\no  'net.sf.jwordnet:jwnl'\nTo fix this the maxent and jwnl includes should be removed. Both are no longer shipped with OpenNLP in this form.",
        "Issue Links": []
    },
    "OPENNLP-663": {
        "Key": "OPENNLP-663",
        "Summary": "Add a method to retrieve the pos tags from the pos tagger",
        "Type": "Improvement",
        "Status": "Closed",
        "Priority": "Minor",
        "Resolution": "Fixed",
        "Affects Version/s": "None",
        "Fix Version/s": "1.6.0",
        "Component/s": "POS Tagger",
        "Assignee": "J\u00f6rn Kottmann",
        "Reporter": "J\u00f6rn Kottmann",
        "Created": "06/Mar/14 09:55",
        "Updated": "13/Mar/14 14:43",
        "Resolved": "13/Mar/14 14:43",
        "Description": "It should be possible for a user to retrieve a list of pos tags from the pos tagger.\nShould the tags be returned from the model or from POSTaggerME ?",
        "Issue Links": []
    },
    "OPENNLP-664": {
        "Key": "OPENNLP-664",
        "Summary": "GeoEntityLinker addon should not use stoplist when indexing GeoNames in Lucene",
        "Type": "Bug",
        "Status": "Closed",
        "Priority": "Major",
        "Resolution": "Fixed",
        "Affects Version/s": "1.6.0",
        "Fix Version/s": "1.6.0",
        "Component/s": "Entity Linker",
        "Assignee": "Mark Giaconia",
        "Reporter": "Mark Giaconia",
        "Created": "07/Mar/14 12:06",
        "Updated": "07/Mar/14 12:16",
        "Resolved": "07/Mar/14 12:16",
        "Description": "Currently some country codes are stopwords when using a standardanalyzer in lucene, for instance India's country code is \"in\", which is a stopword. This confounds the result of queries in which country code derived from country context processing is used as a condition in the search.",
        "Issue Links": []
    },
    "OPENNLP-665": {
        "Key": "OPENNLP-665",
        "Summary": "remove parser.lang.en.HeadRules specific casting for Parser",
        "Type": "Bug",
        "Status": "Closed",
        "Priority": "Major",
        "Resolution": "Fixed",
        "Affects Version/s": "tools-1.5.3",
        "Fix Version/s": "1.6.0",
        "Component/s": "Parser",
        "Assignee": "Rodrigo Agerri",
        "Reporter": "Rodrigo Agerri",
        "Created": "10/Mar/14 09:54",
        "Updated": "06/May/14 08:38",
        "Resolved": "04/Apr/14 13:19",
        "Description": "To train a parser.chunking.Parser, both from the CLI or using the API, the headRule class used is always the parser.lang.en.HeadRules class. This class performs two functions: \n1. It hardcodes the headrules for Noun Phrases. \n2. It reads a headRules file to load the headRules for the rest of the constituents. \nWhile trying to train parsers for other languages, it is now only possible to train with the lang.en.HeadRules class.",
        "Issue Links": []
    },
    "OPENNLP-666": {
        "Key": "OPENNLP-666",
        "Summary": "[sandbox/nlputils] Support for strict CFGs non terminal rules expansion",
        "Type": "Improvement",
        "Status": "Closed",
        "Priority": "Major",
        "Resolution": "Fixed",
        "Affects Version/s": "None",
        "Fix Version/s": "None",
        "Component/s": "None",
        "Assignee": "Tommaso Teofili",
        "Reporter": "Tommaso Teofili",
        "Created": "11/Mar/14 08:19",
        "Updated": "26/Mar/14 12:47",
        "Resolved": "26/Mar/14 12:46",
        "Description": "Currently ContextFreeGrammar expands non terminal rules by randomly selecting one of the matching rules, however it'd be good to be able to use a stricter behavior just based on the first matching rule.",
        "Issue Links": []
    },
    "OPENNLP-667": {
        "Key": "OPENNLP-667",
        "Summary": "Using in UIMA",
        "Type": "Question",
        "Status": "Closed",
        "Priority": "Major",
        "Resolution": "Won't Fix",
        "Affects Version/s": "None",
        "Fix Version/s": "None",
        "Component/s": "None",
        "Assignee": null,
        "Reporter": "Charles Jalin",
        "Created": "18/Mar/14 08:16",
        "Updated": "19/Mar/14 09:15",
        "Resolved": "18/Mar/14 20:45",
        "Description": "Hello\nI have build the OpenNLP and I have the OpenNLPTextAnalyzer.pear.\nI don't find documentation over how to integrate in UIMA pipeline. Can you help me?\nThanks for your attention.\nRegards.",
        "Issue Links": []
    },
    "OPENNLP-668": {
        "Key": "OPENNLP-668",
        "Summary": "Models in spanish",
        "Type": "Question",
        "Status": "Closed",
        "Priority": "Major",
        "Resolution": "Won't Fix",
        "Affects Version/s": "None",
        "Fix Version/s": "None",
        "Component/s": "None",
        "Assignee": null,
        "Reporter": "Charles Jalin",
        "Created": "18/Mar/14 08:17",
        "Updated": "19/Mar/14 09:16",
        "Resolved": "18/Mar/14 20:45",
        "Description": "Hello,\nIs there spanish models for openNLP 1.5?\nThanks for your help.\nRegards.",
        "Issue Links": []
    },
    "OPENNLP-669": {
        "Key": "OPENNLP-669",
        "Summary": "Java 1.8 incompatibility and Build failures",
        "Type": "Bug",
        "Status": "Closed",
        "Priority": "Major",
        "Resolution": "Fixed",
        "Affects Version/s": "1.6.0",
        "Fix Version/s": "1.6.0",
        "Component/s": "Build, Packaging and Test,                                            Documentation",
        "Assignee": "James Kosin",
        "Reporter": "James Kosin",
        "Created": "21/Mar/14 01:50",
        "Updated": "23/Mar/15 19:38",
        "Resolved": "20/Nov/14 16:29",
        "Description": "I just wanted to let everyone know, the OpenNLP project is not compatible with the new Java 1.8.\nI get two (2) issues:\n1)    Fails test:\n   Failed tests:\ntestPerceptronOnPrepAttachDataWithStepSizeDecrease(opennlp.tools\n   .ml.perceptron.PerceptronPrepAttachTest):\n   expected:<0.7756870512503095> but was:\n   <0.7766773953948998>\n2)    Java document generation fails miserably.\n [ERROR] *    <li>.bin --> the file is binary\n[ERROR] ^\n[ERROR]\nC:\\Users\\jkosin\\Documents\\Projects\\OpenNLP\\opennlp\\opennlp-tools\\src\\mai\nn\\java\\opennlp\\tools\\ml\\perceptron\\SuffixSensitivePerceptronModelWriter.java:41:\n     error: bad use of '>'\n[ERROR] *    <li>.bin --> the file is binary\n[ERROR] ^\n[ERROR]\nC:\\Users\\jkosin\\Documents\\Projects\\OpenNLP\\opennlp\\opennlp-tools\\src\\mai\n   n\\java\\opennlp\\tools\\postag\\POSModel.java:64: error: reference not found\nThe second for javadoc errors are probably due to more stringent checking in javadoc.\nThe first... is a bit disconcerting and troubling.  I'm going to check into this; because this error shouldn't be happening.",
        "Issue Links": [
            "/jira/browse/EMAIL-136"
        ]
    },
    "OPENNLP-670": {
        "Key": "OPENNLP-670",
        "Summary": "Failed to write model after training TokenNameFinder",
        "Type": "Bug",
        "Status": "Closed",
        "Priority": "Major",
        "Resolution": "Fixed",
        "Affects Version/s": "1.6.0",
        "Fix Version/s": "1.6.0",
        "Component/s": "Name Finder",
        "Assignee": "Vinh Khuc",
        "Reporter": "Vinh Khuc",
        "Created": "01/Apr/14 03:04",
        "Updated": "02/May/14 13:20",
        "Resolved": "03/Apr/14 08:03",
        "Description": "For OpenNLP's revision 1582319, TokenNameFinder failed to write model to file after training using MaxEnt with the following command (assuming the current directory is trunk\\opennlp-tools)\nbin\\opennlp TokenNameFinderTrainer -lang nl -data nl-per.train -params lang\\ml\\MaxentTrainerParams.txt -model maxent-test.bin",
        "Issue Links": []
    },
    "OPENNLP-671": {
        "Key": "OPENNLP-671",
        "Summary": "Add L1-regularization into L-BFGS",
        "Type": "Improvement",
        "Status": "Closed",
        "Priority": "Major",
        "Resolution": "Fixed",
        "Affects Version/s": "tools-1.5.3,                                            maxent-3.0.3",
        "Fix Version/s": "1.6.0",
        "Component/s": "Machine Learning",
        "Assignee": null,
        "Reporter": "Vinh Khuc",
        "Created": "05/Apr/14 05:14",
        "Updated": "28/Apr/14 14:18",
        "Resolved": "27/Apr/14 15:18",
        "Description": "L1-regularization is useful during training Maximum Entropy models since it pushes parameters of irrelevant features to zero. Hence, the parameter vector will be sparse and the trained model will be compact. \nWhen the number of features is much larger than the number of training examples, L1 often gives better accuracy than L2.\nThe implementation of L1-regularization for L-BFGS will follow the method described in the paper:\nhttp://research.microsoft.com/en-us/um/people/jfgao/paper/icml07scalable.pdf",
        "Issue Links": [
            "/jira/browse/OPENNLP-569"
        ]
    },
    "OPENNLP-672": {
        "Key": "OPENNLP-672",
        "Summary": "Allow setting the feature generator from CLI tools",
        "Type": "Improvement",
        "Status": "Closed",
        "Priority": "Minor",
        "Resolution": "Fixed",
        "Affects Version/s": "1.6.0",
        "Fix Version/s": "1.6.0",
        "Component/s": "Doccat",
        "Assignee": "William Colen",
        "Reporter": "William Colen",
        "Created": "11/Apr/14 03:40",
        "Updated": "20/Nov/14 16:31",
        "Resolved": "11/Apr/14 03:45",
        "Description": null,
        "Issue Links": []
    },
    "OPENNLP-673": {
        "Key": "OPENNLP-673",
        "Summary": "Doccat NGramFeatureGenerator not working",
        "Type": "Bug",
        "Status": "Closed",
        "Priority": "Major",
        "Resolution": "Fixed",
        "Affects Version/s": "tools-1.5.3",
        "Fix Version/s": "1.6.0",
        "Component/s": "Doccat",
        "Assignee": "William Colen",
        "Reporter": "William Colen",
        "Created": "11/Apr/14 13:18",
        "Updated": "13/May/14 12:47",
        "Resolved": "13/May/14 12:47",
        "Description": "Training a document categorizer module using NGramFeatureGenerator always fails. All events are dropped.\n(...)\nDropped event talk.religion.misc:[From:,  (...)\nDropped event talk.religion.misc:[From:, (...)\ndone.\nSorting and merging events... \nException in thread \"main\" java.lang.NullPointerException\n\tat opennlp.tools.ml.maxent.GISTrainer.trainModel(GISTrainer.java:264)\n\tat opennlp.tools.ml.maxent.GIS.trainModel(GIS.java:298)\n\tat opennlp.tools.ml.maxent.GIS.doTrain(GIS.java:83)\n\tat opennlp.tools.ml.maxent.GIS.doTrain(GIS.java:1)\n\tat opennlp.tools.ml.AbstractEventTrainer.train(AbstractEventTrainer.java:93)\n\tat opennlp.tools.ml.model.TrainUtil.train(TrainUtil.java:53)\n\tat opennlp.tools.doccat.DocumentCategorizerME.train(DocumentCategorizerME.java:116)\n\tat opennlp.tools.doccat.DoccatCrossValidator.evaluate(DoccatCrossValidator.java:72)\n\tat opennlp.tools.cmdline.doccat.DoccatCrossValidatorTool.run(DoccatCrossValidatorTool.java:99)\n\tat opennlp.tools.cmdline.CLI.main(CLI.java:224)\nDone indexing.\nIncorporating indexed data for training...",
        "Issue Links": []
    },
    "OPENNLP-674": {
        "Key": "OPENNLP-674",
        "Summary": "Add component factory support to Doccat module",
        "Type": "Improvement",
        "Status": "Closed",
        "Priority": "Minor",
        "Resolution": "Fixed",
        "Affects Version/s": "1.6.0",
        "Fix Version/s": "1.6.0",
        "Component/s": "Doccat",
        "Assignee": "William Colen",
        "Reporter": "William Colen",
        "Created": "16/Apr/14 14:50",
        "Updated": "13/May/14 16:10",
        "Resolved": "13/May/14 16:10",
        "Description": null,
        "Issue Links": []
    },
    "OPENNLP-675": {
        "Key": "OPENNLP-675",
        "Summary": "Absence of logging and usage of System.out",
        "Type": "New Feature",
        "Status": "Closed",
        "Priority": "Major",
        "Resolution": "Fixed",
        "Affects Version/s": "None",
        "Fix Version/s": "1.7.1",
        "Component/s": "Sentence Detector,                                            Tokenizer",
        "Assignee": "J\u00f6rn Kottmann",
        "Reporter": "Eugene Prystupa",
        "Created": "20/Apr/14 00:25",
        "Updated": "20/Jan/23 07:30",
        "Resolved": "19/Jan/17 16:18",
        "Description": "There seems to be no concept of logging used by the libraries. Instead System.out.println is hard-coded in many places where debug information using a logging framework would do it.\nThis makes awkward to use the modules integrated into a different application (as it spams our logs or console). \nIs the usage of System.out in core classes (like GISTrainer) by choice? Or is it simply a technical debt? I am happy to work on it and provide a patch if this is a technical debt.",
        "Issue Links": [
            "/jira/browse/OPENNLP-1447",
            "https://github.com/apache/opennlp/pull/5",
            "https://github.com/apache/opennlp/pull/71",
            "https://cwiki.apache.org/confluence/pages/viewpage.action?pageId=69408987"
        ]
    },
    "OPENNLP-676": {
        "Key": "OPENNLP-676",
        "Summary": "POSTagger UIMA AE broken because of AnnotationComboIterator",
        "Type": "Bug",
        "Status": "Closed",
        "Priority": "Major",
        "Resolution": "Fixed",
        "Affects Version/s": "tools-1.5.3",
        "Fix Version/s": "1.6.0",
        "Component/s": "Name Finder,                                            POS Tagger,                                            UIMA Integration",
        "Assignee": "J\u00f6rn Kottmann",
        "Reporter": "Hugo Mougard",
        "Created": "24/Apr/14 17:46",
        "Updated": "27/Oct/14 23:24",
        "Resolved": "27/Oct/14 23:19",
        "Description": "The AnnotationComboIterator helper class used by the UIMA POSTagger accesses its iterators unsafely.\nThe consequence is that the AE breaks even on very simple CASes such as the CAS showcased on this repository (text of 9 letters, 2 sentence annotations and 9 token annotations): https://github.com/m09/postagger-iterator-bug/blob/master/in.xmi\nThe repository linked above contains an example program that crashes on my setup. It's fully maven 3 aware so you can normally launch it quite easily.\nHere is a patch that should address the issue: https://raw.githubusercontent.com/m09/postagger-iterator-bug/master/iterator.patch",
        "Issue Links": []
    },
    "OPENNLP-677": {
        "Key": "OPENNLP-677",
        "Summary": "Parser fails to load 1.5.0 en-parser-chunking.bin model file",
        "Type": "Bug",
        "Status": "Closed",
        "Priority": "Major",
        "Resolution": "Fixed",
        "Affects Version/s": "1.6.0",
        "Fix Version/s": "1.6.0",
        "Component/s": "Parser",
        "Assignee": "J\u00f6rn Kottmann",
        "Reporter": "J\u00f6rn Kottmann",
        "Created": "28/Apr/14 11:24",
        "Updated": "28/Apr/14 13:06",
        "Resolved": "28/Apr/14 13:06",
        "Description": "The Parser should be able to load the 1.5.x model files, but it fails with this error message:\nModel has invalid format\nUnknown artifact format: headrules\nopennlp.tools.util.InvalidFormatException: Unknown artifact format: headrules\n\tat opennlp.tools.util.model.BaseModel.finishLoadingArtifacts(BaseModel.java:330)\n\tat opennlp.tools.util.model.BaseModel.loadModel(BaseModel.java:256)\n\tat opennlp.tools.util.model.BaseModel.<init>(BaseModel.java:179)\n\tat opennlp.tools.parser.ParserModel.<init>(ParserModel.java:140)\n\tat opennlp.tools.cmdline.parser.ParserModelLoader.loadModel(ParserModelLoader.java:41)\n\tat opennlp.tools.cmdline.parser.ParserModelLoader.loadModel(ParserModelLoader.java:1)\n\tat opennlp.tools.cmdline.ModelLoader.load(ModelLoader.java:62)\n\tat opennlp.tools.cmdline.parser.ParserTool.run(ParserTool.java:90)\n\tat opennlp.tools.cmdline.CLI.main(CLI.java:227)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:606)\n\tat org.codehaus.mojo.exec.ExecJavaMojo$1.run(ExecJavaMojo.java:293)\n\tat java.lang.Thread.run(Thread.java:744)",
        "Issue Links": []
    },
    "OPENNLP-678": {
        "Key": "OPENNLP-678",
        "Summary": "Remove all trailing white spaces",
        "Type": "Improvement",
        "Status": "Closed",
        "Priority": "Trivial",
        "Resolution": "Fixed",
        "Affects Version/s": "None",
        "Fix Version/s": "1.6.0",
        "Component/s": "None",
        "Assignee": "J\u00f6rn Kottmann",
        "Reporter": "J\u00f6rn Kottmann",
        "Created": "28/Apr/14 11:41",
        "Updated": "02/May/14 13:58",
        "Resolved": "02/May/14 13:58",
        "Description": "The OpenNLP source code contains many lines which have one or more white space characters at the end of the line.\nIt would be nice to remove these before the next release. We will then continue doing this refactoring before each release.\nTodays diff tools can diff the source code and ignore white space only differences.",
        "Issue Links": []
    },
    "OPENNLP-679": {
        "Key": "OPENNLP-679",
        "Summary": "Return Doccat prob distributions over categories as Map and SortedMap",
        "Type": "Improvement",
        "Status": "Closed",
        "Priority": "Trivial",
        "Resolution": "Fixed",
        "Affects Version/s": "1.6.0",
        "Fix Version/s": "1.6.0",
        "Component/s": "Doccat",
        "Assignee": "Mark Giaconia",
        "Reporter": "Mark Giaconia",
        "Created": "29/Apr/14 00:38",
        "Updated": "13/May/14 12:57",
        "Resolved": "13/May/14 12:57",
        "Description": "currently it takes several calls to get the probability for each category after classfying the input text. New methods returning maps can reduce this to one call. The Doccat interface should also contain these new method signatures",
        "Issue Links": []
    },
    "OPENNLP-680": {
        "Key": "OPENNLP-680",
        "Summary": "Add documentation for training a name finder on the OntoNotes dataset",
        "Type": "Improvement",
        "Status": "Closed",
        "Priority": "Minor",
        "Resolution": "Fixed",
        "Affects Version/s": "1.6.0",
        "Fix Version/s": "1.6.0",
        "Component/s": "Documentation,                                            Name Finder",
        "Assignee": "J\u00f6rn Kottmann",
        "Reporter": "J\u00f6rn Kottmann",
        "Created": "29/Apr/14 16:54",
        "Updated": "02/May/14 13:58",
        "Resolved": "02/May/14 13:58",
        "Description": "There should be some documentation which explains on how to train a Name Finder model on the OntoNotes data.",
        "Issue Links": []
    },
    "OPENNLP-681": {
        "Key": "OPENNLP-681",
        "Summary": "Add year to docbook manual header",
        "Type": "Improvement",
        "Status": "Closed",
        "Priority": "Trivial",
        "Resolution": "Fixed",
        "Affects Version/s": "None",
        "Fix Version/s": "1.6.0",
        "Component/s": "Documentation",
        "Assignee": "J\u00f6rn Kottmann",
        "Reporter": "J\u00f6rn Kottmann",
        "Created": "29/Apr/14 18:19",
        "Updated": "29/Apr/14 18:23",
        "Resolved": "29/Apr/14 18:23",
        "Description": null,
        "Issue Links": []
    },
    "OPENNLP-682": {
        "Key": "OPENNLP-682",
        "Summary": "Add comments to the L-BFGS trainer sample param files",
        "Type": "Improvement",
        "Status": "Closed",
        "Priority": "Trivial",
        "Resolution": "Fixed",
        "Affects Version/s": "None",
        "Fix Version/s": "1.6.0",
        "Component/s": "Machine Learning",
        "Assignee": "Vinh Khuc",
        "Reporter": "J\u00f6rn Kottmann",
        "Created": "30/Apr/14 08:52",
        "Updated": "15/May/14 21:11",
        "Resolved": "15/May/14 21:11",
        "Description": "The L-BFGS sample params file qn-trainer-l1.params should contain a comment explaining the possible parameters.\nWhich range should be used for L1? Why is L2 set to zero? Are there other parameters which could be set, but are not used in the sample?\nA similar description should be created for the L2 file. It would also be nice if the L2 file could be renamed to the same naming schema as the L1 (qn-trainer-l1.params) file.",
        "Issue Links": []
    },
    "OPENNLP-683": {
        "Key": "OPENNLP-683",
        "Summary": "Rule Based Lemmatization",
        "Type": "New Feature",
        "Status": "Open",
        "Priority": "Minor",
        "Resolution": "Unresolved",
        "Affects Version/s": "1.6.0",
        "Fix Version/s": "None",
        "Component/s": "Lemmatizer",
        "Assignee": "Ajay Bhat",
        "Reporter": "Ajay Bhat",
        "Created": "03/May/14 17:50",
        "Updated": "12/May/14 13:47",
        "Resolved": null,
        "Description": "The current SimpleLemmatizer uses a dictionary lookup for lemmatization. \nRule based lemmatization could also be implemented:\nhttp://ailab.ijs.si/dunja/SiKDD2004/Papers/Pillson-Lematization.pdf\nI'd like to know if the above paper (cited by 33 sources) is okay for implementing and commiting to Opennlp.",
        "Issue Links": []
    },
    "OPENNLP-684": {
        "Key": "OPENNLP-684",
        "Summary": "Span object should include probability.",
        "Type": "Improvement",
        "Status": "Closed",
        "Priority": "Minor",
        "Resolution": "Fixed",
        "Affects Version/s": "1.6.0",
        "Fix Version/s": "1.6.0",
        "Component/s": "Chunker,                                            Name Finder,                                            POS Tagger,                                            Sentence Detector",
        "Assignee": "Mark Giaconia",
        "Reporter": "Mark Giaconia",
        "Created": "09/May/14 10:51",
        "Updated": "26/Feb/23 13:26",
        "Resolved": "29/Oct/14 07:11",
        "Description": "Currently users must use the probs() method on the impls of NameFinderME and SentenceDetectorME in order to get the probs for the returned Spans. It would be better if the Spans were returned with a prob double as an internal field. This way, users who need the probs would still be able to use the Interfaces as well.",
        "Issue Links": [
            "/jira/browse/OPENNLP-106"
        ]
    },
    "OPENNLP-685": {
        "Key": "OPENNLP-684 Span object should include probability.",
        "Summary": "NameFinderME#find should return Spans with probabilities.",
        "Type": "Sub-task",
        "Status": "Closed",
        "Priority": "Minor",
        "Resolution": "Fixed",
        "Affects Version/s": "1.6.0",
        "Fix Version/s": "1.6.0",
        "Component/s": "Name Finder",
        "Assignee": "Mark Giaconia",
        "Reporter": "Mark Giaconia",
        "Created": "09/May/14 10:55",
        "Updated": "13/May/14 12:57",
        "Resolved": "13/May/14 12:57",
        "Description": "Since Span objects will be able to store probs, the NameFInder should return probs with each Span.",
        "Issue Links": []
    },
    "OPENNLP-686": {
        "Key": "OPENNLP-684 Span object should include probability.",
        "Summary": "SentenceDetectorME should return Spans with Probabilities",
        "Type": "Sub-task",
        "Status": "Closed",
        "Priority": "Minor",
        "Resolution": "Fixed",
        "Affects Version/s": "1.6.0",
        "Fix Version/s": "1.6.0",
        "Component/s": "Sentence Detector",
        "Assignee": "Mark Giaconia",
        "Reporter": "Mark Giaconia",
        "Created": "09/May/14 10:57",
        "Updated": "13/May/14 12:58",
        "Resolved": "13/May/14 12:58",
        "Description": "SentenceDetector should return its Spans including the Probability for each Span. This will enable use of the interface even for those that need the probs.",
        "Issue Links": []
    },
    "OPENNLP-687": {
        "Key": "OPENNLP-687",
        "Summary": "FMeasure change to avoid duplication of true positives in the prediction Spans",
        "Type": "Bug",
        "Status": "Closed",
        "Priority": "Major",
        "Resolution": "Fixed",
        "Affects Version/s": "tools-1.5.3",
        "Fix Version/s": "1.6.0",
        "Component/s": "None",
        "Assignee": "Rodrigo Agerri",
        "Reporter": "Rodrigo Agerri",
        "Created": "12/May/14 11:06",
        "Updated": "04/Jun/14 07:54",
        "Resolved": "04/Jun/14 07:54",
        "Description": "As a follow-up of OPENNLP-31, it has been noticed that the FMeasure is calculated in a way that the same prediction can be matched more than once. \nIt is proposed to modify the FMeasure class to remove a prediction Span after being matched with a reference Span. \nThis change will mean that the FMeasure class will look like the provisional ParseEval class, so that the ParseEval class can be removed. \nBefore going ahead and change this we need to ascertain that the F results do not change for other components (chunker, namefinder, etc.)",
        "Issue Links": []
    },
    "OPENNLP-688": {
        "Key": "OPENNLP-688",
        "Summary": "ParserEvaluator options",
        "Type": "Improvement",
        "Status": "Open",
        "Priority": "Minor",
        "Resolution": "Unresolved",
        "Affects Version/s": "tools-1.5.3",
        "Fix Version/s": "None",
        "Component/s": "Parser",
        "Assignee": "Rodrigo Agerri",
        "Reporter": "Rodrigo Agerri",
        "Created": "12/May/14 12:12",
        "Updated": "12/May/14 12:12",
        "Resolved": null,
        "Description": "ParserEvaluator currently calculates Bracketing FMeasure with no exceptions as to which constituents should be considered. EVALB distributes a set of exceptions in a COLLINS.prm parameter file which are the most commonly used in the literature when evaluating Penn Treebank parsers. These parameters allow to ignore punctuation, trace nodes, etc. to evaluate a parser. \nIt would be nice to add the functionalities to pass these options to the current implementation of the ParserEvaluator.",
        "Issue Links": []
    },
    "OPENNLP-689": {
        "Key": "OPENNLP-689",
        "Summary": "ParserEvaluator test case",
        "Type": "Test",
        "Status": "Closed",
        "Priority": "Minor",
        "Resolution": "Fixed",
        "Affects Version/s": "tools-1.5.3",
        "Fix Version/s": "2.1.1",
        "Component/s": "Parser",
        "Assignee": "Bruno P. Kinoshita",
        "Reporter": "Rodrigo Agerri",
        "Created": "12/May/14 12:14",
        "Updated": "30/Nov/22 16:12",
        "Resolved": "30/Nov/22 14:59",
        "Description": "Add a test case for the ParserEvaluator (follow up of OPENNLP-31). Use the content of the main method in that class.",
        "Issue Links": []
    },
    "OPENNLP-690": {
        "Key": "OPENNLP-690",
        "Summary": "ParserEvaluator Documentation",
        "Type": "Documentation",
        "Status": "Closed",
        "Priority": "Minor",
        "Resolution": "Fixed",
        "Affects Version/s": "tools-1.5.3",
        "Fix Version/s": "1.7.0",
        "Component/s": "Parser",
        "Assignee": "Rodrigo Agerri",
        "Reporter": "Rodrigo Agerri",
        "Created": "12/May/14 12:15",
        "Updated": "07/Sep/15 15:34",
        "Resolved": "07/Sep/15 15:34",
        "Description": "Add documentation for ParserEvaluator, both CLI and API.",
        "Issue Links": []
    },
    "OPENNLP-691": {
        "Key": "OPENNLP-691",
        "Summary": "LinkedSpan and Span should provide constructor that takes probability arg",
        "Type": "Improvement",
        "Status": "Closed",
        "Priority": "Trivial",
        "Resolution": "Fixed",
        "Affects Version/s": "1.6.0",
        "Fix Version/s": "1.6.0",
        "Component/s": "Entity Linker,                                            Name Finder",
        "Assignee": "Mark Giaconia",
        "Reporter": "Mark Giaconia",
        "Created": "12/May/14 18:52",
        "Updated": "12/May/14 19:46",
        "Resolved": "12/May/14 19:46",
        "Description": "Since Spans should return a probability field, then Spans should have a new constructor to support passing in the prob. There should also be a setter and getter for prob inside Span, in case the value of prob is affected by downstream processing.",
        "Issue Links": []
    },
    "OPENNLP-692": {
        "Key": "OPENNLP-692",
        "Summary": "GeoEntityLinker should utilize log4j logging",
        "Type": "Improvement",
        "Status": "Closed",
        "Priority": "Minor",
        "Resolution": "Fixed",
        "Affects Version/s": "addons-1.6.0",
        "Fix Version/s": "addons-1.6.0",
        "Component/s": "Entity Linker",
        "Assignee": "Mark Giaconia",
        "Reporter": "Mark Giaconia",
        "Created": "12/May/14 19:10",
        "Updated": "12/May/14 19:38",
        "Resolved": "12/May/14 19:38",
        "Description": "Currently there are System.out calls inside the GeoEntityLinker. This is causing problems on systems where large amounts of processing in performed... log files are bloating.",
        "Issue Links": []
    },
    "OPENNLP-693": {
        "Key": "OPENNLP-693",
        "Summary": "GeoEntityLinker point clustering scorer should use standard Lucene spatial geohash",
        "Type": "Improvement",
        "Status": "Closed",
        "Priority": "Minor",
        "Resolution": "Fixed",
        "Affects Version/s": "addons-1.6.0",
        "Fix Version/s": "addons-1.6.0",
        "Component/s": "Entity Linker",
        "Assignee": "Mark Giaconia",
        "Reporter": "Mark Giaconia",
        "Created": "12/May/14 19:25",
        "Updated": "12/May/14 19:45",
        "Resolved": "12/May/14 19:45",
        "Description": "Lucene spatial provides an efficient geohash function. Since lucene is already a dependency the lucene spatial geohash function should be used rather than the current implementation.",
        "Issue Links": []
    },
    "OPENNLP-694": {
        "Key": "OPENNLP-694",
        "Summary": "GeoEntityLinker gazatteerSearcher should sanitize lucene query strings",
        "Type": "Improvement",
        "Status": "Closed",
        "Priority": "Minor",
        "Resolution": "Fixed",
        "Affects Version/s": "addons-1.6.0",
        "Fix Version/s": "addons-1.6.0",
        "Component/s": "Entity Linker",
        "Assignee": "Mark Giaconia",
        "Reporter": "Mark Giaconia",
        "Created": "12/May/14 19:29",
        "Updated": "12/May/14 19:45",
        "Resolved": "12/May/14 19:45",
        "Description": "Currently the GeoEntityLinker takes Namefinder results and passes them directly to the GazetteerSearcher class. Noisy NER results can cause lucene syntax errors to be thrown and logged. A simple regex cleanup of the input would be helpful.",
        "Issue Links": []
    },
    "OPENNLP-695": {
        "Key": "OPENNLP-695",
        "Summary": "Add extra information to DocumentSample",
        "Type": "Improvement",
        "Status": "Closed",
        "Priority": "Minor",
        "Resolution": "Fixed",
        "Affects Version/s": "1.6.0",
        "Fix Version/s": "1.6.0",
        "Component/s": "Doccat",
        "Assignee": "William Colen",
        "Reporter": "William Colen",
        "Created": "13/May/14 16:13",
        "Updated": "20/Jan/15 20:49",
        "Resolved": "20/Jan/15 20:49",
        "Description": "Often a document has additional information fields, such as title, sender, date, key words. We should add field to the DocumentSample where to store this information, and change the API in such a way that users could implement feature generators using this information.",
        "Issue Links": []
    },
    "OPENNLP-696": {
        "Key": "OPENNLP-696",
        "Summary": "Snowball Stemmer tests",
        "Type": "Test",
        "Status": "Closed",
        "Priority": "Minor",
        "Resolution": "Fixed",
        "Affects Version/s": "1.6.0",
        "Fix Version/s": "1.7.1",
        "Component/s": "Stemmer",
        "Assignee": "J\u00f6rn Kottmann",
        "Reporter": "Ajay Bhat",
        "Created": "15/May/14 09:27",
        "Updated": "14/Jan/17 19:47",
        "Resolved": "14/Jan/17 19:47",
        "Description": "Added Snowball Stemmer Tests \nChanged Snowball Stemmer to accept String for stemming instead of CharSequence.",
        "Issue Links": [
            "https://github.com/apache/opennlp/pull/59"
        ]
    },
    "OPENNLP-697": {
        "Key": "OPENNLP-697",
        "Summary": "Tokenizer class is hardcoded in the DocumentSampleStream class.",
        "Type": "Bug",
        "Status": "Closed",
        "Priority": "Major",
        "Resolution": "Won't Fix",
        "Affects Version/s": "1.6.0",
        "Fix Version/s": "1.7.1",
        "Component/s": "Doccat,                                            Tokenizer",
        "Assignee": null,
        "Reporter": "Praveena B",
        "Created": "16/May/14 06:27",
        "Updated": "20/Jan/17 14:25",
        "Resolved": "20/Jan/17 14:25",
        "Description": "While training the DocumentCategorizerME it is possible to set the type of Tokenizer that the categorizer should use.\ni,e doccatFactory.setTokenizer(SemicolonTokenizer.INSTANCE); \nBut the Tokenizer class is hardcoded to WhitespaceTokenizer in the DocumentSampleStream class. \nSo it is not possible to modify the default tokenizing behaviour even after setting it in the doccatFactory.",
        "Issue Links": []
    },
    "OPENNLP-698": {
        "Key": "OPENNLP-698",
        "Summary": "GeoEntityLinker GazetteerSearcher should properly handle multi-token location names",
        "Type": "Bug",
        "Status": "Closed",
        "Priority": "Major",
        "Resolution": "Fixed",
        "Affects Version/s": "addons-1.6.0",
        "Fix Version/s": "addons-1.6.0",
        "Component/s": "Entity Linker",
        "Assignee": "Mark Giaconia",
        "Reporter": "Mark Giaconia",
        "Created": "19/May/14 12:42",
        "Updated": "20/May/14 12:51",
        "Resolved": "20/May/14 12:51",
        "Description": "The GazetteerSearcher class is not finding multi token names because of a  bug in the fomating of the names prior to being passed to lucene.",
        "Issue Links": []
    },
    "OPENNLP-699": {
        "Key": "OPENNLP-699",
        "Summary": "MarkableFIleInputStreamFactory is not public",
        "Type": "Improvement",
        "Status": "Closed",
        "Priority": "Trivial",
        "Resolution": "Fixed",
        "Affects Version/s": "1.6.0",
        "Fix Version/s": "1.6.0",
        "Component/s": "Command Line Interface",
        "Assignee": "Mark Giaconia",
        "Reporter": "Mark Giaconia",
        "Created": "19/May/14 21:27",
        "Updated": "21/Oct/14 22:19",
        "Resolved": "20/Oct/14 20:49",
        "Description": "Addons need to use MarkableFIleInputStreamFactory\n, but since it is not public it is not accessible as it is set to package private. Unless there is a reason for it to be package private it should be public.",
        "Issue Links": []
    },
    "OPENNLP-700": {
        "Key": "OPENNLP-700",
        "Summary": "Remove the experimental flag from L-BFGS trainer",
        "Type": "Improvement",
        "Status": "Closed",
        "Priority": "Minor",
        "Resolution": "Fixed",
        "Affects Version/s": "tools-1.5.3,                                            maxent-3.0.3",
        "Fix Version/s": "1.6.0",
        "Component/s": "Machine Learning",
        "Assignee": "Vinh Khuc",
        "Reporter": "Vinh Khuc",
        "Created": "27/May/14 01:57",
        "Updated": "16/Jun/14 21:31",
        "Resolved": "16/Jun/14 21:31",
        "Description": "The current L-BFGS trainer is marked with the experimental flag, i.e. the current algorithm name is MAXENT_QN_EXPERIMENTAL. The work on this issue should make sure that L-BFGS trainer's performance is stable at least with some common NLP corpora so that the experimental flag can be safely removed.",
        "Issue Links": []
    },
    "OPENNLP-701": {
        "Key": "OPENNLP-701",
        "Summary": "Polish language support - Maxent binaries",
        "Type": "New Feature",
        "Status": "Closed",
        "Priority": "Minor",
        "Resolution": "Won't Fix",
        "Affects Version/s": "None",
        "Fix Version/s": "None",
        "Component/s": "None",
        "Assignee": null,
        "Reporter": "Chris Krol / IBM",
        "Created": "09/Jun/14 09:59",
        "Updated": "26/Dec/16 12:58",
        "Resolved": "26/Dec/16 12:58",
        "Description": "Hi, \nCurrently I'm working at IBM Poland and my manager approved the idea of contributing various Maxent binaries for Polish language (sentence split, sentence detection, POS tagging and morphological analysis, NER). \nYou could possibly put them on your download page. \nWe trained them using the Golden Standard human-annotated Polish National Corpus (GPL 3.0). \nWould this be also possible to give some credit (or any) to the fact that the job's been done at IBM?\nI've already sent a mail to the devs,  but haven't seen any response for two weeks now.",
        "Issue Links": []
    },
    "OPENNLP-702": {
        "Key": "OPENNLP-702",
        "Summary": "DictionaryNameFinder Not Finding Longest Match When Name Ends in a Number",
        "Type": "Bug",
        "Status": "Closed",
        "Priority": "Major",
        "Resolution": "Won't Fix",
        "Affects Version/s": "None",
        "Fix Version/s": "None",
        "Component/s": "Name Finder,                                            Tokenizer",
        "Assignee": null,
        "Reporter": "rhead",
        "Created": "11/Jun/14 04:34",
        "Updated": "06/Feb/17 23:50",
        "Resolved": "06/Feb/17 23:50",
        "Description": "Here's my dictionary:\n\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<dictionary case_sensitive=\"false\">\n  <entry>\n    <token>vitamin</token>\n    <token>b12</token>\n  </entry>\n  <entry>\n    <token>vitamin</token>\n    <token>b</token>\n  </entry>\n  <entry>\n    <token>john</token>\n    <token>doe</token>\n  </entry>\n  <entry>\n    <token>john</token>\n    <token>d</token>\n  </entry>\n</dictionary>\n\n\nWhen ran on this sentence using a DictionaryNameFinder: My name is john doe, aka john d. I\nlike vitamin b12.\nThe following tokens are found: john doe, john d, vitamin b\nAs you can see, when the 2nd token ends in a number, the longest match is discarded.\n(Originally from: http://mail-archives.apache.org/mod_mbox/opennlp-users/201406.mbox/%3C1402268906.31205.YahooMailNeo%40web121102.mail.ne1.yahoo.com%3E)",
        "Issue Links": []
    },
    "OPENNLP-703": {
        "Key": "OPENNLP-703",
        "Summary": "Parallel computing the objective function and its gradient for MAXENT_QN",
        "Type": "Improvement",
        "Status": "Closed",
        "Priority": "Major",
        "Resolution": "Fixed",
        "Affects Version/s": "tools-1.5.3,                                            maxent-3.0.3",
        "Fix Version/s": "1.6.0",
        "Component/s": "Machine Learning",
        "Assignee": "Vinh Khuc",
        "Reporter": "Vinh Khuc",
        "Created": "16/Jun/14 04:38",
        "Updated": "04/Aug/14 04:29",
        "Resolved": "04/Aug/14 04:29",
        "Description": "Although the current L-BFGS trainer runs in a sequential manner, Maxent's objective function (i.e. the negative log-likelihood function) and its gradient can be computed in parallel. This JIRA will focus on improving the training time of MAXENT_QN.",
        "Issue Links": []
    },
    "OPENNLP-704": {
        "Key": "OPENNLP-704",
        "Summary": "IllegalStateException: Must be started first! in SentenceDetectorTool",
        "Type": "Bug",
        "Status": "Closed",
        "Priority": "Trivial",
        "Resolution": "Fixed",
        "Affects Version/s": "1.6.0",
        "Fix Version/s": "1.6.0",
        "Component/s": "Command Line Interface",
        "Assignee": "Vinh Khuc",
        "Reporter": "Eugen Hanussek",
        "Created": "04/Jul/14 10:00",
        "Updated": "05/Aug/14 03:48",
        "Resolved": "05/Aug/14 03:48",
        "Description": "trying to use the cmd-line tool, see doku, I get the exception:\n\nC:\\proj\\apache-opennlp-1.6.0-SNAPSHOT\\bin>opennlp SentenceDetector de-sent.bin < en-sent-input.txt\nLoading Sentence Detector model ... done (0,078s)\nPierre Vinken, 61 years old, will join the board as a nonexecutive director Nov.\n29. Mr.\nVinken is\nchairman of Elsevier N.V., the Dutch publishing group.\nRudolph Agnew, 55 years\nold and former chairman of Consolidated Gold Fields PLC, was named a director of this\nBritish industrial conglomerate.\nException in thread \"main\" java.lang.IllegalStateException: Must be started first!\n        at opennlp.tools.cmdline.PerformanceMonitor.incrementCounter(PerformanceMonitor.java:68)\n        at opennlp.tools.cmdline.sentdetect.SentenceDetectorTool.run(SentenceDetectorTool.java:76)\n        at opennlp.tools.cmdline.CLI.main(CLI.java:227)\n\n\nI fixed it localy in SentenceDetectorTool:\n\n...\n  public void run(String[] args) {\n\n...\n      PerformanceMonitor perfMon = new PerformanceMonitor(System.err, \"sent\");\n\n      try {\n        perfMon.start();     // <==== the fix\n...",
        "Issue Links": []
    },
    "OPENNLP-705": {
        "Key": "OPENNLP-705",
        "Summary": "integrate Similarity with VerbNet",
        "Type": "Wish",
        "Status": "Open",
        "Priority": "Major",
        "Resolution": "Unresolved",
        "Affects Version/s": "None",
        "Fix Version/s": "None",
        "Component/s": "None",
        "Assignee": "Boris Galitsky",
        "Reporter": "Boris Galitsky",
        "Created": "08/Jul/14 23:56",
        "Updated": "09/Dec/22 15:48",
        "Resolved": null,
        "Description": "When matching two parse trees, features of the verbs other than POS needs to be taken into account for more accurate matching",
        "Issue Links": []
    },
    "OPENNLP-706": {
        "Key": "OPENNLP-706",
        "Summary": "GeoEntityLinker should handle hierarchical location names via improved indexing",
        "Type": "Improvement",
        "Status": "Open",
        "Priority": "Major",
        "Resolution": "Unresolved",
        "Affects Version/s": "1.6.0",
        "Fix Version/s": "None",
        "Component/s": "Entity Linker",
        "Assignee": "Mark Giaconia",
        "Reporter": "Mark Giaconia",
        "Created": "11/Jul/14 00:48",
        "Updated": "13/Aug/14 12:32",
        "Resolved": null,
        "Description": "Currently the GeoEntitylinker (Geotagger) EntityLinker does not handle hierarchical location references such as Berlin, Germany or Hartford, Connecticut. This can be fixed by creating a hierarchy field in the index and querying this field whenever a multi-token name is found.",
        "Issue Links": []
    },
    "OPENNLP-707": {
        "Key": "OPENNLP-707",
        "Summary": "GeoEntityLinker (geotagger) Country context should be based on the indexed data",
        "Type": "Improvement",
        "Status": "Open",
        "Priority": "Major",
        "Resolution": "Unresolved",
        "Affects Version/s": "1.6.0",
        "Fix Version/s": "None",
        "Component/s": "Entity Linker",
        "Assignee": "Mark Giaconia",
        "Reporter": "Mark Giaconia",
        "Created": "11/Jul/14 00:51",
        "Updated": "11/Jul/14 00:51",
        "Resolved": null,
        "Description": "Currently a static countrycontext.txt file is used for context discover that improves location name resolution. This file should be built while the indexing is taking place so it is consistent with the index.",
        "Issue Links": []
    },
    "OPENNLP-708": {
        "Key": "OPENNLP-708",
        "Summary": "GeoEntityLinker should maintain an index of Regions",
        "Type": "Improvement",
        "Status": "Open",
        "Priority": "Major",
        "Resolution": "Unresolved",
        "Affects Version/s": "1.6.0",
        "Fix Version/s": "None",
        "Component/s": "Entity Linker",
        "Assignee": "Mark Giaconia",
        "Reporter": "Mark Giaconia",
        "Created": "11/Jul/14 00:53",
        "Updated": "11/Jul/14 00:53",
        "Resolved": null,
        "Description": "Currently the GeoEntityLinker does not understand region references such as North Africa, or continental references such as South America. This can be fixed by adding a region type to the index and context files.",
        "Issue Links": []
    },
    "OPENNLP-709": {
        "Key": "OPENNLP-709",
        "Summary": "GeoEnttiyLinker should only use one lucene index with some standard fields",
        "Type": "Improvement",
        "Status": "Open",
        "Priority": "Major",
        "Resolution": "Unresolved",
        "Affects Version/s": "1.6.0",
        "Fix Version/s": "None",
        "Component/s": "Entity Linker",
        "Assignee": "Mark Giaconia",
        "Reporter": "Mark Giaconia",
        "Created": "11/Jul/14 00:55",
        "Updated": "11/Jul/14 00:55",
        "Resolved": null,
        "Description": "Currently the GeoEntityLinker uses two separate indexes for gazetteer data (one for USGS and another for Geonames). There is no reason for this and it makes retrieval difficult. At index creation time, a set of common fields should be generated and stored along with the rest of the source specific fields.",
        "Issue Links": []
    },
    "OPENNLP-710": {
        "Key": "OPENNLP-710",
        "Summary": "GeoEntityLinker should provide a score for hierarchy similarity",
        "Type": "Improvement",
        "Status": "Open",
        "Priority": "Minor",
        "Resolution": "Unresolved",
        "Affects Version/s": "addons-1.6.0",
        "Fix Version/s": "None",
        "Component/s": "Entity Linker",
        "Assignee": "Mark Giaconia",
        "Reporter": "Mark Giaconia",
        "Created": "11/Jul/14 01:00",
        "Updated": "11/Jul/14 01:00",
        "Resolved": null,
        "Description": "Since hierarchical references should be performed, there should be a score associated with how similar the search term (name) is to the contents of the hierarchy field. This score, like all others will be added to the scoreMap of a LinkedSpan's BaseLink object.",
        "Issue Links": []
    },
    "OPENNLP-711": {
        "Key": "OPENNLP-711",
        "Summary": "SentenceDetectorME::sentPosDetect() with useTokenEnd=false",
        "Type": "Bug",
        "Status": "Closed",
        "Priority": "Minor",
        "Resolution": "Fixed",
        "Affects Version/s": "1.6.0",
        "Fix Version/s": "1.6.0",
        "Component/s": "Sentence Detector",
        "Assignee": "J\u00f6rn Kottmann",
        "Reporter": "Eugen Hanussek",
        "Created": "07/Aug/14 11:38",
        "Updated": "20/Nov/14 16:31",
        "Resolved": "20/Oct/14 22:11",
        "Description": "I trained the SentenceModel with a german korpus and wondered about the results for the following input (a mark indicates the expected split):\n\n\"I am hungry.Ich bin Mr. Bean.Ein guter Satz.\"\n             ^                ^\n\n\nThe result was 3 sentences. Good, but the split was not at the eosChar. It was after the token with the eosChar: \"I am hungry.Ich\" , \"bin Mr. Bean.Ein\", ...\nAfter some debugging I found out that I have to set useTokenEnd=false in the SentenceDetectorFactory-ctor.\nAnd then I found a little bug in SentenceDetectorME when the span is calculated:\n\n  public Span[] sentPosDetect(String s) {\n...\n      if (bestOutcome.equals(SPLIT) && isAcceptableBreak(s, index, cint)) {\n        if (index != cint) {\n          if (useTokenEnd) {\n            positions.add(getFirstNonWS(s, getFirstWS(s,cint + 1)));\n          }\n          else {\n            positions.add(getFirstNonWS(s,cint)); // this should be positions.add(getFirstNonWS(s,cint + 1)); \n          }\n          sentProbs.add(probs[model.getIndex(bestOutcome)]);\n        }\n        index = cint + 1;\n      }\n...\n\n\nThis change has only impact on models with useTokenEnd=false",
        "Issue Links": []
    },
    "OPENNLP-712": {
        "Key": "OPENNLP-712",
        "Summary": "Creating a date time recognizer",
        "Type": "New Feature",
        "Status": "Open",
        "Priority": "Minor",
        "Resolution": "Unresolved",
        "Affects Version/s": "None",
        "Fix Version/s": "None",
        "Component/s": "None",
        "Assignee": null,
        "Reporter": "Ravi Jadhav",
        "Created": "10/Sep/14 06:59",
        "Updated": "05/Jul/17 01:22",
        "Resolved": null,
        "Description": "As per discussion in one of the mailing lists, It would be great if we develop a date time recognizer for opennlp. I am looking at how it is done is Stanford NLP and found that there is a SUTime library in stanford nlp package. This research paper discusses it in detail ( http://www-nlp.stanford.edu/pubs/lrec2012-sutime.pdf ) . I would love to work on creating something similar. Looking forward to get responses from people who are interested in working on this.",
        "Issue Links": []
    },
    "OPENNLP-713": {
        "Key": "OPENNLP-713",
        "Summary": "nlp-utils testing and javadoc",
        "Type": "Improvement",
        "Status": "Closed",
        "Priority": "Major",
        "Resolution": "Fixed",
        "Affects Version/s": "None",
        "Fix Version/s": "None",
        "Component/s": "None",
        "Assignee": "Tommaso Teofili",
        "Reporter": "Tommaso Teofili",
        "Created": "16/Sep/14 07:24",
        "Updated": "16/Dec/16 09:53",
        "Resolved": "09/Mar/16 10:26",
        "Description": "Some packages in nlp-utils (sandbox) currently don't have enough (if at all, see languagemodel) unit testing, also javadoc should be improved.\nOn a side note, ngram support could be generalized from Strings to use generics.",
        "Issue Links": []
    },
    "OPENNLP-714": {
        "Key": "OPENNLP-714",
        "Summary": "NameFinder Brown Clustering Features",
        "Type": "New Feature",
        "Status": "Closed",
        "Priority": "Minor",
        "Resolution": "Fixed",
        "Affects Version/s": "1.6.0",
        "Fix Version/s": "1.6.0",
        "Component/s": "Name Finder",
        "Assignee": "Rodrigo Agerri",
        "Reporter": "Rodrigo Agerri",
        "Created": "03/Oct/14 11:40",
        "Updated": "09/Mar/15 20:46",
        "Resolved": "09/Mar/15 12:34",
        "Description": "Adding brown clustering features. These features have shown to provide very good results (Ratinov and Roth 2009, Turian et al 2010). The hierarchical clusters can be created with https://github.com/percyliang/brown-cluster tool. \nThe Brown features duplicate each active token feature by each of the paths in the class we extract as features from the clusters.",
        "Issue Links": []
    },
    "OPENNLP-715": {
        "Key": "OPENNLP-715",
        "Summary": "Clark clusters NameFinder features",
        "Type": "New Feature",
        "Status": "Closed",
        "Priority": "Minor",
        "Resolution": "Fixed",
        "Affects Version/s": "1.6.0",
        "Fix Version/s": "1.6.0",
        "Component/s": "Name Finder",
        "Assignee": "Rodrigo Agerri",
        "Reporter": "Rodrigo Agerri",
        "Created": "03/Oct/14 11:43",
        "Updated": "09/Mar/15 21:20",
        "Resolved": "09/Mar/15 13:57",
        "Description": "Add token based features from Clark clusters (Clark 2003). This feature is actually the same as the one implemented in the WordClusterFeatureGenerator, but we should somehow make them separate (perhaps implementing a dynamic prefix id for each one, as in the dictionary features) as it has been shown that the combination of these clustering-based features improve results. \nClark clusters can be generated using this tool: \nhttps://github.com/ninjin/clark_pos_induction",
        "Issue Links": []
    },
    "OPENNLP-716": {
        "Key": "OPENNLP-716",
        "Summary": "Local features benefitial for cluster based features",
        "Type": "New Feature",
        "Status": "Closed",
        "Priority": "Minor",
        "Resolution": "Fixed",
        "Affects Version/s": "1.6.0",
        "Fix Version/s": "1.6.0",
        "Component/s": "Name Finder",
        "Assignee": "Rodrigo Agerri",
        "Reporter": "Rodrigo Agerri",
        "Created": "03/Oct/14 11:45",
        "Updated": "09/Mar/15 20:46",
        "Resolved": "09/Mar/15 12:46",
        "Description": "Add local features (Ratinov and Roth 2009) which are benefitial when they interact with Brown clusters, e.g., previous 2 predictions.",
        "Issue Links": []
    },
    "OPENNLP-717": {
        "Key": "OPENNLP-717",
        "Summary": "NameFinder trainer creates model always with default feature generator",
        "Type": "Bug",
        "Status": "Closed",
        "Priority": "Major",
        "Resolution": "Fixed",
        "Affects Version/s": "1.6.0",
        "Fix Version/s": "1.6.0",
        "Component/s": "Name Finder",
        "Assignee": "Rodrigo Agerri",
        "Reporter": "Rodrigo Agerri",
        "Created": "06/Oct/14 11:18",
        "Updated": "08/Oct/14 16:23",
        "Resolved": "08/Oct/14 16:23",
        "Description": "While adding new features to name finder  (e.g., OPENNLP-714) it was noticed that the NameFinder trainer performance degraded after adding more features than those contained in the default generator. \nIt turned out that at the moment of creating the TokenNameFinderModel, the feature generator parameter was not the one used for the training, but a default one (null).  As a result, the init() method in TokenNameFinderModel always created the model with the default feature generator. \nSolution: add a getter in the TokenNameFinderFactory class to have access to the featureGenerator created for each implementation of the factory, and then use that getter as a parameter when creating the models after training. It has been implemented and tested and it works. \nIf you find this solution ok, I will push the commit.",
        "Issue Links": []
    },
    "OPENNLP-718": {
        "Key": "OPENNLP-718",
        "Summary": "TrainNameFinder CLI trains wiht default features if not -factory is provided",
        "Type": "Bug",
        "Status": "Closed",
        "Priority": "Major",
        "Resolution": "Fixed",
        "Affects Version/s": "1.6.0",
        "Fix Version/s": "1.6.0",
        "Component/s": "Name Finder",
        "Assignee": "Rodrigo Agerri",
        "Reporter": "Rodrigo Agerri",
        "Created": "09/Oct/14 09:46",
        "Updated": "10/Oct/14 14:11",
        "Resolved": "10/Oct/14 12:44",
        "Description": "The TrainNameFinder CLI requires to provide a -factory parameter when a feature generator is provided via the -featuregen parameter. If not -factory is provided, at the moment of creating the TokenNameFinderFactory in the TokenNameFinderTrainerTool class (line 207), the TokenNameFinderFactory is created with the default TokenNameFinderFactory() constructor. That means that the featureGenerator  defaults to null and the TokenNameFinderFactory.createContext() provides the default context generator. \nI see several possible solutions: \n1. Provide the TokenNameFinderFactory as a default subclass if not custom factory is added via -factory. This way it is not compulsory to provide a custom factory and the training process will take the feature generator provided by -featuregen.\n2. Maintain current behaviour, e.g., training with default feature generator, but providing a warning so that the user can decide what to do. \n3. Maintain current behaviour, but break with an exception advising to provide a factory. \nMaybe there are any others. \nComments?",
        "Issue Links": []
    },
    "OPENNLP-719": {
        "Key": "OPENNLP-719",
        "Summary": "Type argument does not override the samples",
        "Type": "Bug",
        "Status": "Closed",
        "Priority": "Major",
        "Resolution": "Fixed",
        "Affects Version/s": "tools-1.5.3,                                            1.6.0",
        "Fix Version/s": "1.7.1",
        "Component/s": "Name Finder",
        "Assignee": "William Colen",
        "Reporter": "Gustavo Knuppe",
        "Created": "10/Oct/14 11:50",
        "Updated": "19/Jan/17 00:25",
        "Resolved": "19/Jan/17 00:25",
        "Description": "The argument \"type\" in the class NameFinderEventStream should override the type of the samples. It seems that this parameter has no use at the moment.",
        "Issue Links": [
            "https://github.com/apache/opennlp/pull/33",
            "https://github.com/apache/opennlp/pull/34",
            "https://github.com/apache/opennlp/pull/48",
            "https://github.com/apache/opennlp/pull/73"
        ]
    },
    "OPENNLP-720": {
        "Key": "OPENNLP-720",
        "Summary": "Solve Java 8 compilation errors",
        "Type": "Bug",
        "Status": "Closed",
        "Priority": "Major",
        "Resolution": "Fixed",
        "Affects Version/s": "1.6.0",
        "Fix Version/s": "1.6.0",
        "Component/s": "Build, Packaging and Test",
        "Assignee": "J\u00f6rn Kottmann",
        "Reporter": "J\u00f6rn Kottmann",
        "Created": "13/Oct/14 21:32",
        "Updated": "20/Oct/14 20:03",
        "Resolved": "20/Oct/14 20:03",
        "Description": "A user repoted that there are a couple of errors when compiling with Java 8 and our javadocs.",
        "Issue Links": []
    },
    "OPENNLP-721": {
        "Key": "OPENNLP-721",
        "Summary": "GeneratorFactory not reading properly custom artifact serializer mappings",
        "Type": "Bug",
        "Status": "Closed",
        "Priority": "Major",
        "Resolution": "Fixed",
        "Affects Version/s": "1.6.0",
        "Fix Version/s": "1.6.0",
        "Component/s": "Name Finder",
        "Assignee": "Rodrigo Agerri",
        "Reporter": "Rodrigo Agerri",
        "Created": "14/Oct/14 09:26",
        "Updated": "16/Oct/14 20:34",
        "Resolved": "16/Oct/14 20:34",
        "Description": "GeneratorFactory.extractCustomArtifactSerializerMappings() xpath expression does not find any custom elements (line 646). The expression of the xPath.evaluate() method should be '//custom' instead of 'custom'.",
        "Issue Links": []
    },
    "OPENNLP-722": {
        "Key": "OPENNLP-722",
        "Summary": "PerceptronPrepAttachTest fails only on Java 8",
        "Type": "Bug",
        "Status": "Closed",
        "Priority": "Minor",
        "Resolution": "Fixed",
        "Affects Version/s": "1.6.0",
        "Fix Version/s": "1.6.0",
        "Component/s": "Build, Packaging and Test",
        "Assignee": "J\u00f6rn Kottmann",
        "Reporter": "J\u00f6rn Kottmann",
        "Created": "16/Oct/14 16:15",
        "Updated": "21/Oct/14 20:54",
        "Resolved": "21/Oct/14 20:54",
        "Description": "The test PerceptronPrepAttachTest.testPerceptronOnPrepAttachDataWithStepSizeDecrease fails if executed on Java 8.\nIt would be really nice to track down the cause of that.",
        "Issue Links": []
    },
    "OPENNLP-723": {
        "Key": "OPENNLP-723",
        "Summary": "Add PCFGs support to nlp-utils",
        "Type": "New Feature",
        "Status": "Closed",
        "Priority": "Major",
        "Resolution": "Fixed",
        "Affects Version/s": "None",
        "Fix Version/s": "None",
        "Component/s": "Parser",
        "Assignee": "Tommaso Teofili",
        "Reporter": "Tommaso Teofili",
        "Created": "18/Oct/14 06:41",
        "Updated": "18/Oct/14 06:44",
        "Resolved": "18/Oct/14 06:44",
        "Description": "Probabilistic context free grammars can be used for building parse trees so it'd be nice to have them as an alternative algorithm to build a Parser. The initial implementation will be in-memory and not lexicalized so it would be better to put it into the sandbox and move it in \"tools\" once it's mature and performant enough.",
        "Issue Links": []
    },
    "OPENNLP-724": {
        "Key": "OPENNLP-724",
        "Summary": "Resource loading in CLI TokenNameFinderTrainer passes a null xml descriptor",
        "Type": "Bug",
        "Status": "Closed",
        "Priority": "Minor",
        "Resolution": "Fixed",
        "Affects Version/s": "1.6.0",
        "Fix Version/s": "1.6.0",
        "Component/s": "Name Finder",
        "Assignee": "Rodrigo Agerri",
        "Reporter": "Rodrigo Agerri",
        "Created": "22/Oct/14 07:58",
        "Updated": "23/Oct/14 08:29",
        "Resolved": "23/Oct/14 08:29",
        "Description": "Command line TokenNameFinderTrainer passes am XML descriptor when loading external resources via the -resources parameter (line 100). \nSimple solution is to create the input stream from file.",
        "Issue Links": []
    },
    "OPENNLP-725": {
        "Key": "OPENNLP-725",
        "Summary": "TokenNameFinderTrainer CLI not loading resources",
        "Type": "Bug",
        "Status": "Closed",
        "Priority": "Major",
        "Resolution": "Fixed",
        "Affects Version/s": "1.6.0",
        "Fix Version/s": "1.6.0",
        "Component/s": "Name Finder",
        "Assignee": "Rodrigo Agerri",
        "Reporter": "Rodrigo Agerri",
        "Created": "22/Oct/14 08:23",
        "Updated": "20/Nov/14 18:29",
        "Resolved": "03/Nov/14 16:23",
        "Description": "Passing an XML featuregen descriptor to the CLI TokenNameFinderTrainer with a line such as \n<w2vwordcluster dict=\"word2vec-test.txt\" />\nand with the -resource parameter properly set, the loadResources() method does not  get the right serializer to create the resource (line 130 of TokenNameFinderTrainerTool class). It looks in the ArtifactSerializers map created at the beginning of the method but does not find a value for the key (which is the file extension of the lexicon?). \nProposed solution: get the appropriate serializer from the element class (e.g. w2vwordcluster). \nAny comments?",
        "Issue Links": []
    },
    "OPENNLP-726": {
        "Key": "OPENNLP-726",
        "Summary": "broken build for java 8 because of DocLint",
        "Type": "Bug",
        "Status": "Closed",
        "Priority": "Major",
        "Resolution": "Not A Problem",
        "Affects Version/s": "1.6.0",
        "Fix Version/s": "None",
        "Component/s": "Build, Packaging and Test",
        "Assignee": "J\u00f6rn Kottmann",
        "Reporter": "Hugo Mougard",
        "Created": "28/Oct/14 07:37",
        "Updated": "30/Oct/14 09:13",
        "Resolved": "30/Oct/14 09:13",
        "Description": "In Java 8, there is a new tool called DocLint, which checks if the javadoc is complete and prevents packaging otherwise during maven javadoc:jar and site generation.\nThis problem has broken many projects and indeed on my machine OpenNLP doesn't build without some tweaking because of that (I'm using Java 8).\nSee http://stackoverflow.com/a/22981151/1027951 for a solution using maven profiles to activate a switch only when the jdk is > 1.8",
        "Issue Links": []
    },
    "OPENNLP-727": {
        "Key": "OPENNLP-727",
        "Summary": "IKVM Parser bug",
        "Type": "Bug",
        "Status": "Closed",
        "Priority": "Major",
        "Resolution": "Cannot Reproduce",
        "Affects Version/s": "tools-1.5.3",
        "Fix Version/s": "None",
        "Component/s": "Parser",
        "Assignee": null,
        "Reporter": "Gustavo Knuppe",
        "Created": "28/Oct/14 20:02",
        "Updated": "08/Jul/15 09:03",
        "Resolved": "08/Jul/15 02:48",
        "Description": "The OpenNLP IKVM version is returning a invalid result in the parser, this problem occurs only using the ikvm version, when I reproduce the same test using java, I get the expected/valid result.\nDetails:\nModel: en-parser-chunking.bin (1.5.3)\nSentence: \"How much fruit do animals eat ?\"\nJava result: \"(TOP (SBAR (WHADJP (WRB How)) (S (NP (JJ much) (NN fruit)) (VP (VBP do) (S (NP (NNS animals)) (VP (VB eat))))) (. ?)))\"\nIKVM result: \"(TOP (SBAR (WHADVP (WRB How)) (S (NP (JJ much) (NN fruit)) (VP (VBP do) (S (NP (NNS animals)) (VP (VB eat))))) (. ?)))\"\nThis problem is likely caused by IKVM, but I think important to leave an open issue since this must happen to all users.",
        "Issue Links": []
    },
    "OPENNLP-728": {
        "Key": "OPENNLP-728",
        "Summary": "Fix Java 8 Javadoc errors in the geocoder",
        "Type": "Bug",
        "Status": "Closed",
        "Priority": "Major",
        "Resolution": "Fixed",
        "Affects Version/s": "None",
        "Fix Version/s": "None",
        "Component/s": "Entity Linker",
        "Assignee": "J\u00f6rn Kottmann",
        "Reporter": "J\u00f6rn Kottmann",
        "Created": "29/Oct/14 18:44",
        "Updated": "29/Oct/14 18:46",
        "Resolved": "29/Oct/14 18:46",
        "Description": "There are a very few erros when compiling th geocoder with Java 8.",
        "Issue Links": []
    },
    "OPENNLP-729": {
        "Key": "OPENNLP-729",
        "Summary": "TokenNameFinderCrossValidator uses full training data",
        "Type": "Bug",
        "Status": "Closed",
        "Priority": "Major",
        "Resolution": "Fixed",
        "Affects Version/s": "1.6.0",
        "Fix Version/s": "1.6.0",
        "Component/s": "Name Finder",
        "Assignee": "Rodrigo Agerri",
        "Reporter": "Rodrigo Agerri",
        "Created": "10/Nov/14 10:06",
        "Updated": "11/Nov/14 16:15",
        "Resolved": "11/Nov/14 16:15",
        "Description": "TokenNameFinderCrossValidator trains with the full training data for every fold. \nChanging the samples parameter in line 222 of TokenNameFinderCrossValidator class solves the issue.",
        "Issue Links": []
    },
    "OPENNLP-730": {
        "Key": "OPENNLP-730",
        "Summary": "PerceptronSequenceTrainer not working",
        "Type": "Bug",
        "Status": "Closed",
        "Priority": "Major",
        "Resolution": "Fixed",
        "Affects Version/s": "1.6.0",
        "Fix Version/s": "1.6.0",
        "Component/s": "Name Finder",
        "Assignee": "J\u00f6rn Kottmann",
        "Reporter": "Rodrigo Agerri",
        "Created": "12/Nov/14 11:10",
        "Updated": "22/Jan/15 08:54",
        "Resolved": "22/Jan/15 08:54",
        "Description": "When trying to train PerceptronSequenceModel (first tried with NameFinder) an Model not compatible with NameFinder error exception is thrown.",
        "Issue Links": []
    },
    "OPENNLP-731": {
        "Key": "OPENNLP-731",
        "Summary": "Integrate SAMpLes engine",
        "Type": "Wish",
        "Status": "Open",
        "Priority": "Minor",
        "Resolution": "Unresolved",
        "Affects Version/s": "None",
        "Fix Version/s": "None",
        "Component/s": "None",
        "Assignee": null,
        "Reporter": "Giuseppe Laurenza",
        "Created": "17/Nov/14 10:25",
        "Updated": "12/Dec/22 09:17",
        "Resolved": null,
        "Description": "Sentiment Analysis with MultiPle LanguagES [SAMpLes] is an engine that provided algorithms for sentiment analysis, voting phrases with a range from 1,0 to 5,0. The particularity of this engine is that it use \"Online-Reviews with a vote\" to build the dictionary. It comes with two complete dictionaries for english and italian languages and with the functions to generate a custom dictionary using a personal dataset.",
        "Issue Links": []
    },
    "OPENNLP-732": {
        "Key": "OPENNLP-732",
        "Summary": "Adding details of snapshots apache repository in maven dependency",
        "Type": "Documentation",
        "Status": "Closed",
        "Priority": "Major",
        "Resolution": "Fixed",
        "Affects Version/s": "None",
        "Fix Version/s": "1.6.0",
        "Component/s": "Documentation",
        "Assignee": "Rodrigo Agerri",
        "Reporter": "Rodrigo Agerri",
        "Created": "20/Nov/14 09:58",
        "Updated": "20/Nov/14 10:29",
        "Resolved": "20/Nov/14 10:29",
        "Description": "Add documentation to add the snapshot version (trunk) as a maven dependency to a pom. This facilitates the use of current trunk via API.",
        "Issue Links": []
    },
    "OPENNLP-733": {
        "Key": "OPENNLP-733",
        "Summary": "Move opennlp/pom.xml to root directory to follow maven conventions",
        "Type": "Improvement",
        "Status": "Closed",
        "Priority": "Major",
        "Resolution": "Fixed",
        "Affects Version/s": "1.6.0",
        "Fix Version/s": "1.6.0",
        "Component/s": "Build, Packaging and Test",
        "Assignee": "J\u00f6rn Kottmann",
        "Reporter": "J\u00f6rn Kottmann",
        "Created": "20/Nov/14 19:32",
        "Updated": "20/Nov/14 20:00",
        "Resolved": "20/Nov/14 20:00",
        "Description": "The main pom.xml file is commonly placed at the project root in maven projects. \nOpenNLP never followed that convention and placed it at opennlp/pom.xml to make it easily available in eclipse. An eclipse workspace doesn't support file at the root level.\nThe majority of maven users and tools expects the pom.xml at the root level. Lets move it to the root level.",
        "Issue Links": []
    },
    "OPENNLP-734": {
        "Key": "OPENNLP-734",
        "Summary": "Rat fails the -Dapache-release build",
        "Type": "Improvement",
        "Status": "Closed",
        "Priority": "Trivial",
        "Resolution": "Fixed",
        "Affects Version/s": "1.6.0",
        "Fix Version/s": "1.6.0",
        "Component/s": "None",
        "Assignee": "J\u00f6rn Kottmann",
        "Reporter": "J\u00f6rn Kottmann",
        "Created": "20/Nov/14 21:04",
        "Updated": "02/Dec/14 16:50",
        "Resolved": "02/Dec/14 16:49",
        "Description": "OpenNLP contains a couple of new files which don't have an AL 2.0 header. The header is necessary to pass the rat audit. We should try to fix all the rat reported problems.",
        "Issue Links": []
    },
    "OPENNLP-735": {
        "Key": "OPENNLP-735",
        "Summary": "Update to the latest apache parent pom (version 14)",
        "Type": "Improvement",
        "Status": "Closed",
        "Priority": "Minor",
        "Resolution": "Fixed",
        "Affects Version/s": "None",
        "Fix Version/s": "1.6.0",
        "Component/s": "Build, Packaging and Test",
        "Assignee": "J\u00f6rn Kottmann",
        "Reporter": "J\u00f6rn Kottmann",
        "Created": "20/Nov/14 21:31",
        "Updated": "20/Nov/14 21:33",
        "Resolved": "20/Nov/14 21:33",
        "Description": "The build should be updated to the latest apache parent pom. This will update many maven plugins to their more recent versions.",
        "Issue Links": []
    },
    "OPENNLP-736": {
        "Key": "OPENNLP-736",
        "Summary": "Update Apache parent pom to version 16",
        "Type": "Improvement",
        "Status": "Closed",
        "Priority": "Major",
        "Resolution": "Fixed",
        "Affects Version/s": "1.6.0",
        "Fix Version/s": "1.6.0",
        "Component/s": "Build, Packaging and Test",
        "Assignee": "William Colen",
        "Reporter": "William Colen",
        "Created": "28/Nov/14 16:43",
        "Updated": "02/Dec/14 16:42",
        "Resolved": "02/Dec/14 16:42",
        "Description": "The parent pom should be updated to version 16 because some of the old dependencies are not currently available.",
        "Issue Links": []
    },
    "OPENNLP-737": {
        "Key": null,
        "Summary": null,
        "Type": null,
        "Status": null,
        "Priority": null,
        "Resolution": null,
        "Affects Version/s": null,
        "Fix Version/s": null,
        "Component/s": null,
        "Assignee": null,
        "Reporter": null,
        "Created": null,
        "Updated": null,
        "Resolved": null,
        "Description": null,
        "Issue Links": []
    },
    "OPENNLP-738": {
        "Key": "OPENNLP-738",
        "Summary": "AbstractDataIndexer#sortAndMerge sets up callers for a NullPointerException",
        "Type": "Bug",
        "Status": "Closed",
        "Priority": "Major",
        "Resolution": "Won't Fix",
        "Affects Version/s": "None",
        "Fix Version/s": "None",
        "Component/s": "None",
        "Assignee": null,
        "Reporter": "Chris Lewis",
        "Created": "14/Dec/14 21:56",
        "Updated": "16/Jan/17 14:36",
        "Resolved": "16/Jan/17 14:36",
        "Description": "In its constructor, the OnePassDataIndexer calls sortAndMerge of its parent class, AbstractDataIndexer (source file opennlp-tools/src/main/java/opennlp/tools/ml/model/AbstractDataIndexer.java). A quick read through the source of these two classes shows that the member variable contexts is only initialized by this method, otherwise it remains null. Note that in the case of sort being true (which it is as called) and there being fewer than two events, the method returns early thus leaving contexts unilitialized. Note also that getContexts exposes this variable, and that GIS.trainModel delegates to the trainModel method of GISTrainer. Line 263 attempts to dereference contexts.length, which will be null in the case of fewer than two events in the stream, and thus result in a NullPointerException.\nI'm not an expert in the algorithms relying on this code, but some googling shows a few incidents that lead back to this behavior, including at least the tickets OPENNLP-316 and OPENNLP-488. It may be the case that all uses of this code cannot possibly function correctly without >= 2 events, but I don't know that. As such, being the non-expert on the natural constraints of the inputs to sortAndMerge, I'd like to suggest 2 possible improvements: 1) default the contexts and other private arrays that are set in the >= 2 path of this code to non-null defaults or 2) throw an explicit IllegalArgumentException that states >= 2 events are required for the calculation.\nThe latter is not as desirable as the former (for which I've attached a patch), but at least it provides a targeted, unambiguous reason for why an exception is being thrown.\nAlso I apologize for not specifying the version or component, as I'm not clear on how the project source is organized with respect to the published artifacts. This issue is present in trunk whose parent pom claims a version of 1.6.1-SNAPSHOT.",
        "Issue Links": []
    },
    "OPENNLP-739": {
        "Key": "OPENNLP-739",
        "Summary": "Chunker runtime fails with an IllegalStateException",
        "Type": "Bug",
        "Status": "Closed",
        "Priority": "Major",
        "Resolution": "Fixed",
        "Affects Version/s": "1.6.0",
        "Fix Version/s": "1.6.0",
        "Component/s": "Chunker",
        "Assignee": "William Colen",
        "Reporter": "William Colen",
        "Created": "17/Dec/14 16:41",
        "Updated": "19/Dec/14 11:54",
        "Resolved": "19/Dec/14 11:54",
        "Description": "Exception in thread \"main\" java.lang.IllegalStateException: Must be started first!\nat opennlp.tools.cmdline.PerformanceMonitor.incrementCounter(PerformanceMonitor.java:68)\nat opennlp.tools.cmdline.PerformanceMonitor.incrementCounter(PerformanceMonitor.java:77)\nat opennlp.tools.cmdline.chunker.ChunkerMETool.run(ChunkerMETool.java:77)\nat opennlp.tools.cmdline.CLI.main(CLI.java:227)",
        "Issue Links": []
    },
    "OPENNLP-740": {
        "Key": "OPENNLP-740",
        "Summary": "Add svn:ignore for IntelliJ IDEA configuration files",
        "Type": "Task",
        "Status": "Closed",
        "Priority": "Major",
        "Resolution": "Fixed",
        "Affects Version/s": "None",
        "Fix Version/s": "1.6.0",
        "Component/s": "Build, Packaging and Test",
        "Assignee": "Tommaso Teofili",
        "Reporter": "Tommaso Teofili",
        "Created": "17/Jan/15 14:35",
        "Updated": "22/Jan/15 08:55",
        "Resolved": "17/Jan/15 14:37",
        "Description": "Add svn:ignore for the configuration files generated by IntelliJ IDEA (*.iml files and .idea directory).",
        "Issue Links": []
    },
    "OPENNLP-741": {
        "Key": "OPENNLP-741",
        "Summary": "Add language modeling support",
        "Type": "New Feature",
        "Status": "Closed",
        "Priority": "Major",
        "Resolution": "Duplicate",
        "Affects Version/s": "None",
        "Fix Version/s": "None",
        "Component/s": "None",
        "Assignee": "Tommaso Teofili",
        "Reporter": "Tommaso Teofili",
        "Created": "19/Jan/15 08:08",
        "Updated": "07/Aug/15 08:33",
        "Resolved": "10/Mar/15 10:11",
        "Description": "As discussed when nlp-utils was donated to OpenNLP (OPENNLP-657) I'd like to add language modeling support by moving the related classes to opennlp-tools. \nThis will require a proper integration with the ngram package so that e.g. a language model can be created upon an NgramModel and similar use cases; also Ngram probabilities util will have to be moved to the ngram package so that it can be both used within language models and (eventually) directly called to calculate ngram probabilities.",
        "Issue Links": [
            "/jira/browse/OPENNLP-659"
        ]
    },
    "OPENNLP-742": {
        "Key": "OPENNLP-742",
        "Summary": "Adding serialVersionUID to POSModel Class",
        "Type": "Improvement",
        "Status": "Closed",
        "Priority": "Major",
        "Resolution": "Won't Fix",
        "Affects Version/s": "1.6.0",
        "Fix Version/s": "None",
        "Component/s": "POS Tagger",
        "Assignee": null,
        "Reporter": "Nishant Kelkar",
        "Created": "21/Jan/15 08:36",
        "Updated": "03/Jan/17 10:29",
        "Resolved": "03/Jan/17 10:29",
        "Description": "I had a custom POSModel that I serialized and store as a .bin file using Java 1.7. Now, I want to deserialize and use it in a POSTaggerME using Java 1.6. However, I get the following error at the point that I read in the binary file:\njava.lang.UnsupportedClassVersionError: opennlp/tools/postag/POSModel : Unsupported major.minor version 51.0\n\tat java.lang.ClassLoader.defineClass1(Native Method)\n\tat java.lang.ClassLoader.defineClassCond(ClassLoader.java:637)\n\tat java.lang.ClassLoader.defineClass(ClassLoader.java:621)\n\tat java.security.SecureClassLoader.defineClass(SecureClassLoader.java:141)\n\tat java.net.URLClassLoader.defineClass(URLClassLoader.java:283)\n\tat java.net.URLClassLoader.access$000(URLClassLoader.java:58)\n\tat java.net.URLClassLoader$1.run(URLClassLoader.java:197)\n\tat java.security.AccessController.doPrivileged(Native Method)\n\tat java.net.URLClassLoader.findClass(URLClassLoader.java:190)\n\tat java.lang.ClassLoader.loadClass(ClassLoader.java:306)\n\tat sun.misc.Launcher$AppClassLoader.loadClass(Launcher.java:301)\n\tat java.lang.ClassLoader.loadClass(ClassLoader.java:247)\nAccording to the following StackOverflow post, it should be possible to resolve this by manually assigning a serialVersionUID to the POSModel class (which is what I call the serialize() method on):\nhttp://stackoverflow.com/questions/893433/does-using-compilers-from-different-jdk-versions-on-the-same-source-file-break\nI'm using the following dependency:\n    <dependency>\n      <groupId>org.apache.opennlp</groupId>\n      <artifactId>opennlp-tools</artifactId>\n      <version>1.6.0-SNAPSHOT</version>\n    </dependency>",
        "Issue Links": []
    },
    "OPENNLP-743": {
        "Key": "OPENNLP-743",
        "Summary": "The chunker training data format is incorrectly/insufficiently described.",
        "Type": "Documentation",
        "Status": "Closed",
        "Priority": "Minor",
        "Resolution": "Fixed",
        "Affects Version/s": "1.7.0",
        "Fix Version/s": "1.7.1",
        "Component/s": "Chunker",
        "Assignee": "William Colen",
        "Reporter": "Zuzana Neverilova",
        "Created": "27/Jan/15 07:33",
        "Updated": "02/Jan/17 21:28",
        "Resolved": "02/Jan/17 21:28",
        "Description": "The chunker training data format is described as follows: The train data consist of three columns separated by spaces. Each word has been put on a separate line and there is an empty line after each sentence. However, in the example, several spaces are between tokens and tag. First, it looks like tabs (which are not allowed), second several spaces are not allowed as well (apparently, the line String is splitted(\" \")). Suggestion: emphasize that columns are separated by one space and tabs are not allowed.",
        "Issue Links": [
            "https://github.com/apache/opennlp/pull/25"
        ]
    },
    "OPENNLP-744": {
        "Key": "OPENNLP-744",
        "Summary": "Brat parser crashes if .ann file contain attribute annotations",
        "Type": "Bug",
        "Status": "Closed",
        "Priority": "Minor",
        "Resolution": "Fixed",
        "Affects Version/s": "1.6.0",
        "Fix Version/s": "1.6.0",
        "Component/s": "Formats",
        "Assignee": null,
        "Reporter": "J\u00f6rn Kottmann",
        "Created": "28/Jan/15 09:12",
        "Updated": "30/Jan/15 23:12",
        "Resolved": "30/Jan/15 23:12",
        "Description": "A brat .ann annotation file that contains an attribute annotations crashes the parser. A parser for attribute annotation lines is missing in the brat formats support.\nTo fix this support for attribute annotations has to be added.",
        "Issue Links": []
    },
    "OPENNLP-745": {
        "Key": "OPENNLP-745",
        "Summary": "ObjectStream should extend AutoClosable",
        "Type": "Improvement",
        "Status": "Closed",
        "Priority": "Minor",
        "Resolution": "Fixed",
        "Affects Version/s": "None",
        "Fix Version/s": "1.6.0",
        "Component/s": "None",
        "Assignee": "J\u00f6rn Kottmann",
        "Reporter": "J\u00f6rn Kottmann",
        "Created": "28/Jan/15 10:16",
        "Updated": "30/Jan/15 23:12",
        "Resolved": "30/Jan/15 23:12",
        "Description": "An ObjectStream is usually connected to an underlying system resource that must be closed. In Java 7 the new try-with-resources statement was introduced. In order to use it with the streams the ObjectStream interface has to extend the AutoCloseable interface.",
        "Issue Links": []
    },
    "OPENNLP-746": {
        "Key": "OPENNLP-746",
        "Summary": "Add unit test for NGramModel",
        "Type": "Test",
        "Status": "Closed",
        "Priority": "Minor",
        "Resolution": "Fixed",
        "Affects Version/s": "None",
        "Fix Version/s": "1.7.0",
        "Component/s": "POS Tagger",
        "Assignee": "Tommaso Teofili",
        "Reporter": "Tommaso Teofili",
        "Created": "29/Jan/15 08:00",
        "Updated": "09/Mar/15 20:45",
        "Resolved": "29/Jan/15 08:02",
        "Description": "It'd be good to have a unit test for NGramModel.",
        "Issue Links": []
    },
    "OPENNLP-747": {
        "Key": "OPENNLP-747",
        "Summary": "Maven compiler plugin should not overwrite version from partent pom",
        "Type": "Improvement",
        "Status": "Closed",
        "Priority": "Minor",
        "Resolution": "Fixed",
        "Affects Version/s": "None",
        "Fix Version/s": "1.6.0",
        "Component/s": "Build, Packaging and Test",
        "Assignee": "J\u00f6rn Kottmann",
        "Reporter": "J\u00f6rn Kottmann",
        "Created": "29/Jan/15 08:35",
        "Updated": "22/May/15 10:22",
        "Resolved": "22/May/15 10:22",
        "Description": "The compiler plugin sets the version to 2.3.2. There might have been a reason for this a couple of years back, but today it is probably better to remove it and see if the project can be built with the version specified in the parent pom.",
        "Issue Links": []
    },
    "OPENNLP-748": {
        "Key": "OPENNLP-748",
        "Summary": "Replace hard coded paths in the GazetteerIndexer.main with arguments",
        "Type": "Improvement",
        "Status": "Closed",
        "Priority": "Minor",
        "Resolution": "Fixed",
        "Affects Version/s": "None",
        "Fix Version/s": "None",
        "Component/s": "Entity Linker",
        "Assignee": null,
        "Reporter": "J\u00f6rn Kottmann",
        "Created": "30/Jan/15 07:32",
        "Updated": "17/Jan/17 19:34",
        "Resolved": "17/Jan/17 19:34",
        "Description": "The GazetteerIndexer has a main method which builds the Lucene index based on a couple of input files and writes the index to an output path. All those paths are hard coded. To be able to use this tool without adapting the code it would be much better if all paths can be passed in via command line arguments.",
        "Issue Links": []
    },
    "OPENNLP-749": {
        "Key": "OPENNLP-749",
        "Summary": "Entity Linker cmd line tools throws NPE",
        "Type": "Bug",
        "Status": "Closed",
        "Priority": "Major",
        "Resolution": "Fixed",
        "Affects Version/s": "None",
        "Fix Version/s": "1.6.0",
        "Component/s": "Entity Linker",
        "Assignee": null,
        "Reporter": "J\u00f6rn Kottmann",
        "Created": "30/Jan/15 14:25",
        "Updated": "30/Jan/15 23:07",
        "Resolved": "30/Jan/15 23:07",
        "Description": "The cmd line tool for the Entity Linker throws the following NPE:\nException in thread \"main\" java.lang.NullPointerException\n\tat opennlp.tools.util.Span.spansToStrings(Span.java:368)\n\tat opennlp.addons.geoentitylinker.GeoEntityLinker.find(GeoEntityLinker.java:64)\n\tat opennlp.tools.cmdline.entitylinker.EntityLinkerTool.run(EntityLinkerTool.java:124)\n\tat opennlp.tools.cmdline.CLI.main(CLI.java:227)\nThe reason for this is that the token spans array which is passed to the entity linker implementation contains null values.\nThe problem seems to be in the EntityLinker tool, line 115. The array index must be ti instead of i.",
        "Issue Links": []
    },
    "OPENNLP-750": {
        "Key": "OPENNLP-750",
        "Summary": "Geocoder initialization should fail if country context file is missing",
        "Type": "Bug",
        "Status": "Open",
        "Priority": "Minor",
        "Resolution": "Unresolved",
        "Affects Version/s": "None",
        "Fix Version/s": "addons-1.6.0",
        "Component/s": "Entity Linker",
        "Assignee": "Mark Giaconia",
        "Reporter": "J\u00f6rn Kottmann",
        "Created": "30/Jan/15 14:56",
        "Updated": "30/Nov/19 11:39",
        "Resolved": null,
        "Description": "The geocoder doesn't work properly without a country context file. If the user tries to specify a country context file in the entitylinker.properties but that file can't be loaded (e.g. IOException) then the initialization should fail.",
        "Issue Links": []
    },
    "OPENNLP-751": {
        "Key": "OPENNLP-751",
        "Summary": "Chunker trainer doesn't write beam size into the model",
        "Type": "Bug",
        "Status": "Closed",
        "Priority": "Minor",
        "Resolution": "Fixed",
        "Affects Version/s": "None",
        "Fix Version/s": "1.6.0",
        "Component/s": "Chunker",
        "Assignee": "J\u00f6rn Kottmann",
        "Reporter": "J\u00f6rn Kottmann",
        "Created": "31/Jan/15 14:16",
        "Updated": "07/Apr/15 13:18",
        "Resolved": "07/Apr/15 13:18",
        "Description": "The beam size is retrieved from the parameter file but not passed as an argument to the model in the ChunkerME.train method. \nAdditionally it uses the NameFinderME default beam size instead of the ChunkerME default beam size.",
        "Issue Links": []
    },
    "OPENNLP-752": {
        "Key": "OPENNLP-752",
        "Summary": "Summarization Module",
        "Type": "New Feature",
        "Status": "Closed",
        "Priority": "Minor",
        "Resolution": "Fixed",
        "Affects Version/s": "None",
        "Fix Version/s": "None",
        "Component/s": "Summarizer",
        "Assignee": "J\u00f6rn Kottmann",
        "Reporter": "Ram Soma",
        "Created": "02/Feb/15 06:35",
        "Updated": "12/Feb/15 15:11",
        "Resolved": "11/Feb/15 08:56",
        "Description": "This is an issue regarding integrating the summarization module attached to this issue into the opennlp package.\nThe attached code needs some refactoring before integration into the package. But I would like to get some early feedback to see if we are on the right track.",
        "Issue Links": []
    },
    "OPENNLP-753": {
        "Key": "OPENNLP-753",
        "Summary": "USGS Indexer fails with ArrayIndexOutOfBoundsException",
        "Type": "Bug",
        "Status": "Open",
        "Priority": "Major",
        "Resolution": "Unresolved",
        "Affects Version/s": "None",
        "Fix Version/s": "None",
        "Component/s": "Entity Linker",
        "Assignee": null,
        "Reporter": "J\u00f6rn Kottmann",
        "Created": "02/Feb/15 07:45",
        "Updated": "02/Feb/15 07:45",
        "Resolved": null,
        "Description": "While indexing a recent version of the USGS data (NationalFile_20141202.txt) the following exception is thrown:\njava.lang.ArrayIndexOutOfBoundsException: 2\n\tat opennlp.addons.geoentitylinker.indexing.USGSProcessor.readFile(USGSProcessor.java:77)\n\tat opennlp.addons.geoentitylinker.indexing.USGSProcessor.process(USGSProcessor.java:54)\n\tat opennlp.addons.geoentitylinker.indexing.GazetteerIndexer.index(GazetteerIndexer.java:168)\n\tat opennlp.addons.geoentitylinker.indexing.GazetteerIndexer.main(GazetteerIndexer.java:44)\nA couple of lines in this file are now shorter than the expected minimum length. I added a few lines to print those out:\nSkipped line: 2717280|Sullivan Field\nSkipped line: Sullivan Field\nSkipped line: Sullivan Field\nSkipped line: |Airport|FL|12|Alachua|001|294359N|0823358W|29.7330798|-82.5661417|||||28|92|Newberry|10/16/2014|",
        "Issue Links": []
    },
    "OPENNLP-754": {
        "Key": "OPENNLP-754",
        "Summary": "Typo in status message during indexing",
        "Type": "Bug",
        "Status": "Closed",
        "Priority": "Trivial",
        "Resolution": "Fixed",
        "Affects Version/s": "None",
        "Fix Version/s": "addons-1.6.0",
        "Component/s": "Entity Linker",
        "Assignee": "J\u00f6rn Kottmann",
        "Reporter": "J\u00f6rn Kottmann",
        "Created": "02/Feb/15 07:53",
        "Updated": "02/Feb/15 07:59",
        "Resolved": "02/Feb/15 07:59",
        "Description": "The USGS Processor prints the following line during indexing:\nsuccessfully wrote Region entries to country oontext file\nBut it should be ... context ...",
        "Issue Links": []
    },
    "OPENNLP-755": {
        "Key": "OPENNLP-755",
        "Summary": "Add support to use a stop word list in query building",
        "Type": "Improvement",
        "Status": "Open",
        "Priority": "Major",
        "Resolution": "Unresolved",
        "Affects Version/s": "None",
        "Fix Version/s": "None",
        "Component/s": "Entity Linker",
        "Assignee": null,
        "Reporter": "J\u00f6rn Kottmann",
        "Created": "02/Feb/15 14:51",
        "Updated": "25/Mar/18 21:57",
        "Resolved": null,
        "Description": "The geocoder in it's current version might create queries which match on terms on which the matching shouldn't happen. These terms could be listed in a stop word list. This stop word list could be used to construct queries which match only the desired terms.\nFor example:\n<START> New York City <END> is not in Slovenia\nThis currently matches a hotel called \"BTC City\".\nThe index is searched for all terms in the mention. The problem here is if only \"City\" matches the response will be kind of bad. Or if only \"New\" and \"City\" matches.\nMany place names contain the word \"City\" and that doesn't help much to disambiguate the matches.\nThere should be some special logic dealing with stop words.\nThe stop words could be removed form the location mention, or better only used for boosting.\nFor the case above it could be like this:\n\nMUST match York\nSHOULD match New OR City\n\nIf a name only consists out of stop words e.g. \"New City\" we could require that the mention only matches the entire name.",
        "Issue Links": []
    },
    "OPENNLP-756": {
        "Key": "OPENNLP-756",
        "Summary": "GeoEntityLinker Admin Boundary context generator should allow regex for more flexibility and better discovery of location context",
        "Type": "Improvement",
        "Status": "Open",
        "Priority": "Major",
        "Resolution": "Unresolved",
        "Affects Version/s": "addons-1.6.0",
        "Fix Version/s": "addons-1.6.0",
        "Component/s": "Entity Linker",
        "Assignee": "Mark Giaconia",
        "Reporter": "Mark Giaconia",
        "Created": "02/Feb/15 22:03",
        "Updated": "09/Jun/16 20:11",
        "Resolved": null,
        "Description": "Currently the way the AdminBoundaryContextGenerator discovers Country, Province, and County mentions is inflexible and misses a lot of mentions. The GeoEntityLinker should support regexes in the countrycontext file so that it will find more mentions based on user defined extensions via regex. This change propagates to several other classes called within the GeoEntityLinker",
        "Issue Links": []
    },
    "OPENNLP-757": {
        "Key": "OPENNLP-757",
        "Summary": "Supervised WSD techniques",
        "Type": "New Feature",
        "Status": "Open",
        "Priority": "Major",
        "Resolution": "Unresolved",
        "Affects Version/s": "None",
        "Fix Version/s": "None",
        "Component/s": "wsd",
        "Assignee": "Mondher Bouazizi",
        "Reporter": "Mondher Bouazizi",
        "Created": "12/Feb/15 09:56",
        "Updated": "03/Jul/15 16:42",
        "Resolved": null,
        "Description": "The objective of Word Sense Disambiguation (WSD) is to determine which sense of a word is meant in a particular context. Therefore, WSD is a classification task, where the classes are the different senses of the ambiguous word.\nDifferent techniques are proposed in the academic literature, which fall mainly into two categories: Supervised and Unsupervised.\nFor this component, we focus on supervised techniques: these approaches use machine-learning techniques to learn a classifier from labeled training sets.\nThe object of this project is to create a WSD solution (for English) that implements some supervised techniques. For example:\n\nDecision Lists\nDecision Trees\nNaive Bayes\nNeural Networks\nExemplar-Based or Instance-Based Learning\nSupport Vector Machines\nEnsemble Methods\nSemi-supervised Disambiguation\nEtc.",
        "Issue Links": []
    },
    "OPENNLP-758": {
        "Key": "OPENNLP-758",
        "Summary": "Unsupervised WSD techniques",
        "Type": "New Feature",
        "Status": "Open",
        "Priority": "Major",
        "Resolution": "Unresolved",
        "Affects Version/s": "None",
        "Fix Version/s": "None",
        "Component/s": "wsd",
        "Assignee": "Anthony Beylerian",
        "Reporter": "Mondher Bouazizi",
        "Created": "12/Feb/15 09:57",
        "Updated": "11/Aug/15 17:15",
        "Resolved": null,
        "Description": "The objective of Word Sense Disambiguation (WSD) is to determine which sense of a word is meant in a particular context. Therefore, WSD is a classification task, where the classes are the different senses of the ambiguous word.\nDifferent techniques are proposed in the academic literature, which fall mainly into two categories: Supervised and Unsupervised.\nFor this component, we focus on unsupervised techniques: these methods are based on unlabeled data, and do not exploit any manually tagged data.\nThe object of this project is to create a WSD solution (for English) that implements some unsupervised techniques. For example:\n\nContext Clustering\nWord Clustering\nCooccurrence Graphs\nOverlap of Sense Definitions\nSelectional Preferences\nStructural Approaches\nEtc.",
        "Issue Links": []
    },
    "OPENNLP-759": {
        "Key": "OPENNLP-759",
        "Summary": "Speed up GIS training by saving Executor in the GISTrainer",
        "Type": "Improvement",
        "Status": "Closed",
        "Priority": "Minor",
        "Resolution": "Fixed",
        "Affects Version/s": "maxent-3.0.3",
        "Fix Version/s": "1.7.0",
        "Component/s": "Machine Learning",
        "Assignee": "J\u00f6rn Kottmann",
        "Reporter": "Daniel Russ",
        "Created": "02/Mar/15 20:57",
        "Updated": "20/Dec/16 15:16",
        "Resolved": "20/Dec/16 15:16",
        "Description": "In GISTrainer.nextIteration(double) an ExecutorService is created and shutdown.  I don't see a reason to create a ExecutorService for each iteration.  \nIf you create the ExecutorService in the TrainModels(int, dataindexer, Prior, int, int) method you can save it as a field in GISTrainer or pass it as an argument to findParameters(int, double).\nTo test it out, I made a MyGIS and MyGISTrainer classes with the fixes.  There was a 5% speedup with 100 my dataset and 100 iterations of GIS.\nI would be happy to share the code with you.  (I can not share my data though, sorry data-use agreements).",
        "Issue Links": []
    },
    "OPENNLP-760": {
        "Key": "OPENNLP-760",
        "Summary": "probabilistic lemmatizer",
        "Type": "New Feature",
        "Status": "Closed",
        "Priority": "Minor",
        "Resolution": "Fixed",
        "Affects Version/s": "None",
        "Fix Version/s": "1.7.0",
        "Component/s": "Lemmatizer",
        "Assignee": "Rodrigo Agerri",
        "Reporter": "Rodrigo Agerri",
        "Created": "06/Mar/15 07:53",
        "Updated": "21/May/16 09:57",
        "Resolved": "18/Feb/16 21:24",
        "Description": "Current SimpleLemmatizer is dictionary-based. A probabilistic lemmatizer works better for unknown words and can be combined with dictionaries.\nThe method we will implement here is based on: \nGrzegorz Chrupa\u0142a. 2008. Towards a Machine-Learning Architecture for Lexical Functional Grammar Parsing. PhD dissertation, Dublin City University. http://grzegorz.chrupala.me/papers/phd-single.pdf",
        "Issue Links": []
    },
    "OPENNLP-761": {
        "Key": "OPENNLP-761",
        "Summary": "Chunker cmd line tools should not overwrite the beam size",
        "Type": "Bug",
        "Status": "Closed",
        "Priority": "Minor",
        "Resolution": "Fixed",
        "Affects Version/s": "None",
        "Fix Version/s": "1.6.0",
        "Component/s": "Chunker,                                            Command Line Interface",
        "Assignee": "J\u00f6rn Kottmann",
        "Reporter": "J\u00f6rn Kottmann",
        "Created": "06/Mar/15 13:42",
        "Updated": "06/Mar/15 13:44",
        "Resolved": "06/Mar/15 13:44",
        "Description": "The Chunker command line tools overwrite the beam size which is stored in the model with the default beam size. This should not be done.\nThe chunker and the chunker eval tools are affected.",
        "Issue Links": []
    },
    "OPENNLP-762": {
        "Key": "OPENNLP-762",
        "Summary": "POS Tagger beam size in params file is ignored",
        "Type": "Bug",
        "Status": "Closed",
        "Priority": "Major",
        "Resolution": "Fixed",
        "Affects Version/s": "1.6.0",
        "Fix Version/s": "1.6.0",
        "Component/s": "POS Tagger",
        "Assignee": "J\u00f6rn Kottmann",
        "Reporter": "J\u00f6rn Kottmann",
        "Created": "06/Mar/15 14:43",
        "Updated": "06/Mar/15 15:02",
        "Resolved": "06/Mar/15 15:02",
        "Description": "The beam size specified in the params is ignored. The POS Tagger should store the beam size in manifest. Furthermore the POSTaggerME constructor taking a model and the beam size and cache size doesn't work properly, because the BeamSearch is set up in the POSModel and not anymore in the POSTaggerME.\nThis issue is affecting the parser performance.",
        "Issue Links": []
    },
    "OPENNLP-763": {
        "Key": "OPENNLP-763",
        "Summary": "Parser should use new APIs for training POS Tagger and Chunker",
        "Type": "Bug",
        "Status": "Closed",
        "Priority": "Minor",
        "Resolution": "Fixed",
        "Affects Version/s": "None",
        "Fix Version/s": "1.6.0",
        "Component/s": "Parser",
        "Assignee": "J\u00f6rn Kottmann",
        "Reporter": "J\u00f6rn Kottmann",
        "Created": "09/Mar/15 19:50",
        "Updated": "09/Mar/15 20:21",
        "Resolved": "09/Mar/15 20:21",
        "Description": "The Parser is still using old and deprecated APIs to train the POS Tagger and Chunker. Especially setting the beam size of the POS Tagger and Chunker doesn't work in those deprecated code paths and lead to a performance difference between the current 1.6.0 RC2 and the 1.5.3 release.\nThe Parser should be updated to use the new 1.6.0 API for training. The new code path was broken too, but should be in a good state since the fixes in OPENNLP-762.",
        "Issue Links": []
    },
    "OPENNLP-764": {
        "Key": "OPENNLP-764",
        "Summary": "UIMA NameFinder Annotator should call clearAdaptiveData",
        "Type": "Bug",
        "Status": "Closed",
        "Priority": "Major",
        "Resolution": "Invalid",
        "Affects Version/s": "1.7.0",
        "Fix Version/s": "None",
        "Component/s": "UIMA Integration",
        "Assignee": "Tommaso Teofili",
        "Reporter": "Pablo Duboue (KeaText)",
        "Created": "31/Mar/15 18:50",
        "Updated": "04/Nov/15 14:52",
        "Resolved": "04/Nov/15 14:52",
        "Description": "Following the documentation (http://opennlp.apache.org/documentation/1.5.3/manual/opennlp.html#tools.namefind.recognition.api) and the discussion in OPENNLP-627, the adaptive data has to be called after each document has been processed.\nThis is missing in the UIMA integration, causing severe degradation when processing more than a few thousand documents.\nThe following patch fixes it:\nIndex: opennlp-uima/src/main/java/opennlp/uima/namefind/NameFinder.java\n===================================================================\n\u2014 opennlp-uima/src/main/java/opennlp/uima/namefind/NameFinder.java    (revision 1670422)\n+++ opennlp-uima/src/main/java/opennlp/uima/namefind/NameFinder.java    (working copy)\n@@ -169,6 +169,8 @@\n       documentConfidence.add(prob);\n     }\n+    mNameFinder.clearAdaptiveData();\n+\n     return names;\n   }",
        "Issue Links": []
    },
    "OPENNLP-765": {
        "Key": "OPENNLP-765",
        "Summary": "Add evaluation test for CONLL-X data",
        "Type": "Improvement",
        "Status": "Closed",
        "Priority": "Trivial",
        "Resolution": "Fixed",
        "Affects Version/s": "None",
        "Fix Version/s": "1.6.0",
        "Component/s": "Build, Packaging and Test",
        "Assignee": "J\u00f6rn Kottmann",
        "Reporter": "J\u00f6rn Kottmann",
        "Created": "15/Apr/15 12:29",
        "Updated": "15/Apr/15 13:41",
        "Resolved": "15/Apr/15 13:41",
        "Description": "The CONLL-X data contain pos tags and can be used to evaluate the POS Tagger. Currently the data is used to evaluate a release candidate in our manual test plan. \nIt would be nice to automate this manual evaluation and have a JUnit test which fails if the output doesn't match the expectation.",
        "Issue Links": []
    },
    "OPENNLP-766": {
        "Key": "OPENNLP-766",
        "Summary": "Add evaluation test for CONLL 2002 data",
        "Type": "Improvement",
        "Status": "Closed",
        "Priority": "Trivial",
        "Resolution": "Fixed",
        "Affects Version/s": "None",
        "Fix Version/s": "1.6.0",
        "Component/s": "Build, Packaging and Test",
        "Assignee": null,
        "Reporter": "J\u00f6rn Kottmann",
        "Created": "15/Apr/15 15:10",
        "Updated": "15/Apr/15 15:19",
        "Resolved": "15/Apr/15 15:19",
        "Description": "The CONLL 2002 data contains named entities and can be used to evaluate the Name Finder. Currently the data is used to evaluate a release candidate in our manual test plan.\nIt would be nice to automate this manual evaluation and have a JUnit test which fails if the output doesn't match the expectation.",
        "Issue Links": []
    },
    "OPENNLP-767": {
        "Key": "OPENNLP-767",
        "Summary": "Code clean up",
        "Type": "Improvement",
        "Status": "Closed",
        "Priority": "Trivial",
        "Resolution": "Fixed",
        "Affects Version/s": "None",
        "Fix Version/s": "1.6.0",
        "Component/s": "None",
        "Assignee": "J\u00f6rn Kottmann",
        "Reporter": "J\u00f6rn Kottmann",
        "Created": "16/Apr/15 13:12",
        "Updated": "30/Apr/15 12:05",
        "Resolved": "30/Apr/15 12:05",
        "Description": "The usuall release code clean up should be performed.\nRun the eclipse tool with the following settings:\n\nRemove unused imports\nRemove trailing white spaces on all lines",
        "Issue Links": []
    },
    "OPENNLP-768": {
        "Key": "OPENNLP-768",
        "Summary": "Add cross validation to the parser",
        "Type": "Improvement",
        "Status": "Closed",
        "Priority": "Minor",
        "Resolution": "Pending Closed",
        "Affects Version/s": "None",
        "Fix Version/s": "1.6.0",
        "Component/s": "Parser",
        "Assignee": "J\u00f6rn Kottmann",
        "Reporter": "J\u00f6rn Kottmann",
        "Created": "17/Apr/15 13:16",
        "Updated": "13/May/15 12:16",
        "Resolved": "13/May/15 12:16",
        "Description": "All components in OpenNLP can be evaluated via cross validation. Since there is now evaluation support for the parser it would be nice to add a cross validator using the existing evaluation support.",
        "Issue Links": []
    },
    "OPENNLP-769": {
        "Key": "OPENNLP-769",
        "Summary": "Add evaluation tests for OntoNotes 4",
        "Type": "Improvement",
        "Status": "Closed",
        "Priority": "Trivial",
        "Resolution": "Fixed",
        "Affects Version/s": "None",
        "Fix Version/s": "1.6.0",
        "Component/s": "Name Finder,                                            Parser,                                            POS Tagger",
        "Assignee": "J\u00f6rn Kottmann",
        "Reporter": "J\u00f6rn Kottmann",
        "Created": "17/Apr/15 14:06",
        "Updated": "30/Apr/15 12:05",
        "Resolved": "30/Apr/15 12:05",
        "Description": "The OntoNotes corpus can be used to train all components in OpenNLP. For now it would be nice to add evaluation tests for the Pos Tagger, Name Finder and Parser.",
        "Issue Links": []
    },
    "OPENNLP-770": {
        "Key": "OPENNLP-770",
        "Summary": "Add evaluation test for CONLL 2000 data (Chunker)",
        "Type": "Improvement",
        "Status": "Closed",
        "Priority": "Trivial",
        "Resolution": "Fixed",
        "Affects Version/s": "1.6.0",
        "Fix Version/s": "1.6.0",
        "Component/s": "Build, Packaging and Test",
        "Assignee": "William Colen",
        "Reporter": "William Colen",
        "Created": "30/Apr/15 03:39",
        "Updated": "30/Apr/15 04:25",
        "Resolved": "30/Apr/15 04:25",
        "Description": null,
        "Issue Links": []
    },
    "OPENNLP-771": {
        "Key": "OPENNLP-771",
        "Summary": "Add evaluation test using Arvores Deitadas corpus",
        "Type": "Improvement",
        "Status": "Closed",
        "Priority": "Trivial",
        "Resolution": "Fixed",
        "Affects Version/s": "1.6.0",
        "Fix Version/s": "1.6.0",
        "Component/s": "Build, Packaging and Test",
        "Assignee": "William Colen",
        "Reporter": "William Colen",
        "Created": "30/Apr/15 03:40",
        "Updated": "30/Apr/15 04:25",
        "Resolved": "30/Apr/15 04:25",
        "Description": null,
        "Issue Links": []
    },
    "OPENNLP-772": {
        "Key": "OPENNLP-772",
        "Summary": "Japanese end of sentence fix",
        "Type": "Improvement",
        "Status": "Closed",
        "Priority": "Minor",
        "Resolution": "Fixed",
        "Affects Version/s": "tools-1.5.3",
        "Fix Version/s": "1.7.0",
        "Component/s": "Sentence Detector",
        "Assignee": "J\u00f6rn Kottmann",
        "Reporter": "Bar Perach",
        "Created": "08/May/15 20:21",
        "Updated": "20/Dec/16 22:38",
        "Resolved": "20/Dec/16 22:38",
        "Description": "the end of sentence characters list was wrong for japanese\nremoved duplicate code\nIndex: opennlp-tools/src/main/java/opennlp/tools/sentdetect/lang/Factory.java\n===================================================================\n\u2014 opennlp-tools/src/main/java/opennlp/tools/sentdetect/lang/Factory.java\t(revision 1678426)\n+++ opennlp-tools/src/main/java/opennlp/tools/sentdetect/lang/Factory.java\t(local)\n@@ -36,14 +36,12 @@\n   public static final char[] thEosCharacters = new char[] \n{ ' ','\\n' }\n;\n+  // TODO add more sentence enders\n+  public static final char[] jpEosCharacters = new char[] \n{'\u3002', '\uff01', '\uff1f'}\n;\n+\n   public EndOfSentenceScanner createEndOfSentenceScanner(String languageCode) {\n\nif (\"th\".equals(languageCode)) {\nreturn new DefaultEndOfSentenceScanner(new char[]\n{' ','\\n'}\n);\n} else if(\"pt\".equals(languageCode)) \n{\n-      return new DefaultEndOfSentenceScanner(ptEosCharacters);\n-    }\n\n\nreturn new DefaultEndOfSentenceScanner(defaultEosCharacters);\n+    return new DefaultEndOfSentenceScanner(getEOSCharacters(languageCode));\n   }\n\n   public EndOfSentenceScanner createEndOfSentenceScanner(\n@@ -76,6 +74,8 @@\n       return thEosCharacters;\n     } else if (\"pt\".equals(languageCode)) \n{\n       return ptEosCharacters;\n+    }\n else if (\"jp\".equals(languageCode)) \n{\n+      return jpEosCharacters;\n     }\n\n     return defaultEosCharacters;",
        "Issue Links": []
    },
    "OPENNLP-773": {
        "Key": "OPENNLP-773",
        "Summary": "OpenNLP documentation -- update in the method to be used",
        "Type": "Improvement",
        "Status": "Closed",
        "Priority": "Trivial",
        "Resolution": "Fixed",
        "Affects Version/s": "None",
        "Fix Version/s": "1.7.1",
        "Component/s": "Doccat",
        "Assignee": "Suneel Marthi",
        "Reporter": "Anshu Pitlia",
        "Created": "11/May/15 13:35",
        "Updated": "03/Jan/17 04:31",
        "Resolved": "03/Jan/17 04:31",
        "Description": "In the open nlp maual, the following link--https://opennlp.apache.org/documentation/1.5.3/manual/opennlp.html#tools.doccat.classifying.api\nThere is the error in the method to be used to get the best outcome. I saw the API here, https://opennlp.apache.org/documentation/1.5.3/apidocs/opennlp-tools/opennlp/tools/doccat/DocumentCategorizerME.html,\n and found no such method exists. AFAIK, it should be \ndouble[] outcomes = myCategorizer.categorize(inputText);\n\tString category = myCategorizer.getBestCategory(outcomes);\nAnyway when we are correcting this, we can correct one line above it for the typo--\nDocumentCategorizerME myCategorizer = new Document*Categorier*ME(m);\nto be DocumentCategorizerME myCategorizer = new Document*Categorizer*ME(m);",
        "Issue Links": [
            "https://github.com/apache/opennlp/pull/27"
        ]
    },
    "OPENNLP-774": {
        "Key": "OPENNLP-774",
        "Summary": "OntoNotes evaluation tests fail",
        "Type": "Bug",
        "Status": "Closed",
        "Priority": "Minor",
        "Resolution": "Pending Closed",
        "Affects Version/s": "None",
        "Fix Version/s": "1.6.0",
        "Component/s": "Build, Packaging and Test",
        "Assignee": "J\u00f6rn Kottmann",
        "Reporter": "J\u00f6rn Kottmann",
        "Created": "13/May/15 12:11",
        "Updated": "13/May/15 12:12",
        "Resolved": "13/May/15 12:12",
        "Description": "The expected scores for some tests are incorrect.",
        "Issue Links": []
    },
    "OPENNLP-775": {
        "Key": "OPENNLP-775",
        "Summary": "Add support for lowercased word cluster dictionaries",
        "Type": "Improvement",
        "Status": "Closed",
        "Priority": "Major",
        "Resolution": "Fixed",
        "Affects Version/s": "None",
        "Fix Version/s": "1.6.0",
        "Component/s": "None",
        "Assignee": "Rodrigo Agerri",
        "Reporter": "Peter Thygesen",
        "Created": "14/May/15 16:24",
        "Updated": "22/May/15 12:41",
        "Resolved": "22/May/15 12:41",
        "Description": "Current version will only work with case sensitive dictionaries",
        "Issue Links": []
    },
    "OPENNLP-776": {
        "Key": "OPENNLP-776",
        "Summary": "Model Objects should be Serializable",
        "Type": "Improvement",
        "Status": "Closed",
        "Priority": "Minor",
        "Resolution": "Fixed",
        "Affects Version/s": "tools-1.5.3",
        "Fix Version/s": "1.7.0",
        "Component/s": "None",
        "Assignee": "J\u00f6rn Kottmann",
        "Reporter": "Tristan Nixon",
        "Created": "14/May/15 20:05",
        "Updated": "07/Dec/16 22:46",
        "Resolved": "07/Dec/16 22:46",
        "Description": "Marking model objects (ParserModel, SentenceModel, etc.) as Serializable can enable a number of features offered by other Java frameworks (my own use case is described below). You've already got a good mechanism for (de-)serialization, but it cannot be leveraged by other frameworks without implementing the Serializable interface. I'm attaching a patch to BaseModel that implements the methods in the java.io.Externalizable interface as wrappers to the existing (de-)serialization methods. This simple change can open up a number of useful opportunities for integrating OpenNLP with other frameworks.\nMy use case is that I am incorporating OpenNLP into a Spark application. This requires that components of the system be distributed between the driver and worker nodes within the cluster. In order to do this, Spark uses Java serialization API to transmit objects between nodes. This is far more efficient than instantiating models on each node independently.",
        "Issue Links": []
    },
    "OPENNLP-777": {
        "Key": "OPENNLP-777",
        "Summary": "Naive Bayesian Classifier",
        "Type": "New Feature",
        "Status": "Closed",
        "Priority": "Minor",
        "Resolution": "Fixed",
        "Affects Version/s": "None",
        "Fix Version/s": "1.7.0",
        "Component/s": "Machine Learning",
        "Assignee": "Tommaso Teofili",
        "Reporter": "Cohan Sujay Carlos",
        "Created": "19/May/15 13:44",
        "Updated": "03/Nov/16 06:21",
        "Resolved": "18/Jan/16 08:47",
        "Description": "I thought it would be nice to have a Naive Bayesian classifier in OpenNLP (it lacks one at present).\nImplementation details:  We have a production-hardened piece of Java code for a multinomial Naive Bayesian classifier (with default Laplace smoothing) that we'd like to contribute.  The code is Java 1.5 compatible.  I'd have to write an adapter to make the interface compatible with the ME classifier in OpenNLP.  I expect the patch to be available 1 to 3 weeks from now.\nBelow is the email trail of a discussion in the dev mailing list around this dated May 19th, 2015.\n<snip>\nTommaso Teofili via opennlp.apache.org \nto dev \nHi Cohan,\nI think that'd be a very valuable contribution, as NB is one of the\nfoundation algorithms, often used as basis for comparisons.\nIt would be good if you could create a Jira issue and provide more details\nabout the implementation and, eventually, a patch.\nThanks and regards,\nTommaso\n</snip>\n2015-05-19 9:57 GMT+02:00 Cohan Sujay Carlos \n> I have a question for the OpenNLP project team.\n>\n> I was wondering if there is a Naive Bayesian classifier implementation in\n> OpenNLP that I've not come across, or if there are plans to implement one.\n>\n> If it is the latter, I should love to contribute an implementation.\n>\n> There is an ME classifier already available in OpenNLP, of course, but I\n> felt that there was an unmet need for a Naive Bayesian (NB) classifier\n> implementation to be offered as well.\n>\n> An NB classifier could be bootstrapped up with partially labelled training\n> data as explained in the Nigam, McCallum, et al paper of 2000 \"Text\n> Classification from Labeled and Unlabeled Documents using EM\".\n>\n> So, if there isn't an NB code base out there already, I'd be happy to\n> contribute a very solid implementation that we've used in production for a\n> good 5 years.\n>\n> I'd have to adapt it to load the same training data format as the ME\n> classifier, but I guess that shouldn't be very difficult to do.\n>\n> I was wondering if there was some interest in adding an NB implementation\n> and I'd love to know who could I coordinate with if there is?\n>\n> Cohan Sujay Carlos\n> CEO, Aiaioo Labs, India",
        "Issue Links": []
    },
    "OPENNLP-778": {
        "Key": "OPENNLP-778",
        "Summary": "Parser is not configured correctly for 1.5.x models",
        "Type": "Bug",
        "Status": "Closed",
        "Priority": "Major",
        "Resolution": "Fixed",
        "Affects Version/s": "1.6.0",
        "Fix Version/s": "1.6.0",
        "Component/s": "Parser",
        "Assignee": "J\u00f6rn Kottmann",
        "Reporter": "J\u00f6rn Kottmann",
        "Created": "20/May/15 12:20",
        "Updated": "20/May/15 12:23",
        "Resolved": "20/May/15 12:23",
        "Description": "The Parser in 1.6.0 sets a couple of parameters during training time which are stored inside the model.\nTwo of those parameters:\n\nPOS Tagger beam size\nCustom chunker sequence validation\n\nAre not set up for 1.5.x models.\nTo fix this issue the ParserModel should be modified to detect when a 1.5.x model is loaded and then inject those settings into the model.",
        "Issue Links": []
    },
    "OPENNLP-779": {
        "Key": "OPENNLP-779",
        "Summary": "Event hash compuation is broken",
        "Type": "Bug",
        "Status": "Closed",
        "Priority": "Trivial",
        "Resolution": "Fixed",
        "Affects Version/s": "1.6.0",
        "Fix Version/s": "1.6.0",
        "Component/s": "Machine Learning",
        "Assignee": "J\u00f6rn Kottmann",
        "Reporter": "J\u00f6rn Kottmann",
        "Created": "21/May/15 10:56",
        "Updated": "21/May/15 10:58",
        "Resolved": "21/May/15 10:58",
        "Description": "The trainer computes a hash of all events used to train a model. This hash is valuable to debug problems with the model performance.",
        "Issue Links": []
    },
    "OPENNLP-780": {
        "Key": "OPENNLP-780",
        "Summary": "Add formats support for NKJP",
        "Type": "Improvement",
        "Status": "Closed",
        "Priority": "Minor",
        "Resolution": "Fixed",
        "Affects Version/s": "None",
        "Fix Version/s": "None",
        "Component/s": "Formats",
        "Assignee": null,
        "Reporter": "J\u00f6rn Kottmann",
        "Created": "21/May/15 13:43",
        "Updated": "19/Jan/23 11:29",
        "Resolved": "19/Jan/23 11:29",
        "Description": "It would be nice to have formats support for the Polish NKJP corpus.\nThe corpus can be found here and is licensed under GPL v3:\nhttp://nkjp.pl/index.php?page=14&lang=1",
        "Issue Links": []
    },
    "OPENNLP-781": {
        "Key": "OPENNLP-781",
        "Summary": "Remove old deprecated classes from maxent package",
        "Type": "Improvement",
        "Status": "Closed",
        "Priority": "Minor",
        "Resolution": "Fixed",
        "Affects Version/s": "None",
        "Fix Version/s": "1.6.0",
        "Component/s": "Machine Learning",
        "Assignee": "J\u00f6rn Kottmann",
        "Reporter": "J\u00f6rn Kottmann",
        "Created": "22/May/15 10:08",
        "Updated": "22/May/15 10:13",
        "Resolved": "22/May/15 10:13",
        "Description": "The maxent package was moved to a new package and stil has some old classes which should be removed.\nFor example\n\nBinToAscii\nMain\nModelDomain\n\nand more.",
        "Issue Links": []
    },
    "OPENNLP-782": {
        "Key": "OPENNLP-782",
        "Summary": "Update NOTICE file for binary distribution",
        "Type": "Improvement",
        "Status": "Closed",
        "Priority": "Minor",
        "Resolution": "Fixed",
        "Affects Version/s": "1.6.0",
        "Fix Version/s": "1.6.0",
        "Component/s": "Build, Packaging and Test",
        "Assignee": null,
        "Reporter": "J\u00f6rn Kottmann",
        "Created": "22/May/15 10:29",
        "Updated": "22/May/15 10:30",
        "Resolved": "22/May/15 10:30",
        "Description": "The binary distribution NOTICE has to be updated. It should contain the notice  for the snowball stemmers and the JWNL notice should be removed.",
        "Issue Links": []
    },
    "OPENNLP-783": {
        "Key": "OPENNLP-783",
        "Summary": "OSGi descriptor needs to specify Java 7 as minimum and not 5",
        "Type": "Bug",
        "Status": "Closed",
        "Priority": "Minor",
        "Resolution": "Fixed",
        "Affects Version/s": "1.6.0",
        "Fix Version/s": "1.6.0",
        "Component/s": "Build, Packaging and Test",
        "Assignee": "J\u00f6rn Kottmann",
        "Reporter": "J\u00f6rn Kottmann",
        "Created": "22/May/15 12:43",
        "Updated": "22/May/15 12:53",
        "Resolved": "22/May/15 12:53",
        "Description": "The OSGi descriptor should be updated to specify Java 7 as the minimum.",
        "Issue Links": []
    },
    "OPENNLP-784": {
        "Key": "OPENNLP-784",
        "Summary": "The brat annotation config parser fails to recognize tabs as whitespace",
        "Type": "Bug",
        "Status": "Closed",
        "Priority": "Minor",
        "Resolution": "Fixed",
        "Affects Version/s": "1.6.0",
        "Fix Version/s": "1.6.0",
        "Component/s": "Formats",
        "Assignee": "J\u00f6rn Kottmann",
        "Reporter": "J\u00f6rn Kottmann",
        "Created": "28/May/15 11:08",
        "Updated": "28/May/15 11:41",
        "Resolved": "28/May/15 11:41",
        "Description": "The brat annotation config parser splits the lines b space char. This doesn't work well because brat also supports the usage of tabs.\nIn case there is tab the parser fails.",
        "Issue Links": []
    },
    "OPENNLP-785": {
        "Key": "OPENNLP-785",
        "Summary": "Name Finder ignores custom factory",
        "Type": "Bug",
        "Status": "Closed",
        "Priority": "Major",
        "Resolution": "Fixed",
        "Affects Version/s": "1.6.0",
        "Fix Version/s": "1.6.0",
        "Component/s": "Name Finder",
        "Assignee": "J\u00f6rn Kottmann",
        "Reporter": "J\u00f6rn Kottmann",
        "Created": "28/May/15 14:57",
        "Updated": "29/May/15 08:11",
        "Resolved": "29/May/15 08:11",
        "Description": "The factory passed in during training is not stored in the model and it is not used when the name finder is applied. \nTherefore using a custom factory is not possible due to this bug.",
        "Issue Links": []
    },
    "OPENNLP-786": {
        "Key": "OPENNLP-786",
        "Summary": "Depricate EventStream",
        "Type": "Improvement",
        "Status": "Closed",
        "Priority": "Major",
        "Resolution": "Fixed",
        "Affects Version/s": "1.6.0",
        "Fix Version/s": "1.6.0",
        "Component/s": "Machine Learning",
        "Assignee": "J\u00f6rn Kottmann",
        "Reporter": "Daniel Russ",
        "Created": "28/May/15 15:53",
        "Updated": "28/May/15 21:32",
        "Resolved": "28/May/15 21:32",
        "Description": "GIS No longer  accepts an EventStream in GIS.trainModel(...).  There is no need for the EventStream class anymore.  There are 2 AbstractEventStream classes.  opennlp.tools.ml.model.AbstractEventStream and opennlp.tools.utils.EventStream. Remove or Deprecate opennlp.tools.ml.model.AbstractEventStream to avoid confusion.",
        "Issue Links": []
    },
    "OPENNLP-787": {
        "Key": "OPENNLP-787",
        "Summary": "WordClusterDictionary should reuse the cluster id objects",
        "Type": "Improvement",
        "Status": "Closed",
        "Priority": "Minor",
        "Resolution": "Fixed",
        "Affects Version/s": "1.6.0",
        "Fix Version/s": "1.6.0",
        "Component/s": "Name Finder",
        "Assignee": "J\u00f6rn Kottmann",
        "Reporter": "J\u00f6rn Kottmann",
        "Created": "03/Jun/15 07:47",
        "Updated": "03/Jun/15 09:08",
        "Resolved": "03/Jun/15 07:50",
        "Description": "A word cluster contains much more tokens than cluster ids. The cluster id objects should be reused and not created over and over again for each token.",
        "Issue Links": []
    },
    "OPENNLP-788": {
        "Key": "OPENNLP-788",
        "Summary": "Add a language detection component",
        "Type": "Improvement",
        "Status": "Closed",
        "Priority": "Major",
        "Resolution": "Fixed",
        "Affects Version/s": "None",
        "Fix Version/s": "1.8.1",
        "Component/s": "None",
        "Assignee": "William Colen",
        "Reporter": "J\u00f6rn Kottmann",
        "Created": "04/Jun/15 12:50",
        "Updated": "16/Jun/17 10:46",
        "Resolved": "16/Jun/17 10:46",
        "Description": "Many of the components in OpenNLP are sensitive to the input language. It would be nice if OpenNLP would have a component to detect the language of an input text.\nTwo commonly used solutions today are:\nApache Tikas Language Identifier\nLanguage Detection from Shuyo, Nakatani",
        "Issue Links": [
            "https://github.com/apache/opennlp/pull/143",
            "https://github.com/apache/opennlp/pull/230"
        ]
    },
    "OPENNLP-789": {
        "Key": "OPENNLP-789",
        "Summary": "Add javadoc to WSDisambiguator",
        "Type": "Improvement",
        "Status": "Open",
        "Priority": "Major",
        "Resolution": "Unresolved",
        "Affects Version/s": "None",
        "Fix Version/s": "None",
        "Component/s": "wsd",
        "Assignee": "Anthony Beylerian",
        "Reporter": "J\u00f6rn Kottmann",
        "Created": "30/Jun/15 08:58",
        "Updated": "05/Aug/15 08:09",
        "Resolved": null,
        "Description": "The WSDisambiguator is the main interface for the wsd component. It should have much more javadocs explaining what it does and what wsd is.\nAdditionally add at least short javadocs to each class and method in the disambiguator package. One sentence is the minimum here.",
        "Issue Links": []
    },
    "OPENNLP-790": {
        "Key": "OPENNLP-790",
        "Summary": "Add an evaluator to the WSDisambiguator component",
        "Type": "Task",
        "Status": "Open",
        "Priority": "Major",
        "Resolution": "Unresolved",
        "Affects Version/s": "None",
        "Fix Version/s": "None",
        "Component/s": "wsd",
        "Assignee": null,
        "Reporter": "Anthony Beylerian",
        "Created": "01/Jul/15 09:46",
        "Updated": "28/Jul/15 09:55",
        "Resolved": null,
        "Description": "The WSDisambiguator needs an evaluator to measure the performance of its different implementations.",
        "Issue Links": []
    },
    "OPENNLP-791": {
        "Key": "OPENNLP-791",
        "Summary": "WSD One Sense per Context Cluster",
        "Type": "Task",
        "Status": "Open",
        "Priority": "Major",
        "Resolution": "Unresolved",
        "Affects Version/s": "None",
        "Fix Version/s": "None",
        "Component/s": "wsd",
        "Assignee": null,
        "Reporter": "Anthony Beylerian",
        "Created": "09/Jul/15 21:30",
        "Updated": "26/Aug/15 17:18",
        "Resolved": null,
        "Description": "Context clustering approach using phrasal clusters : \nhttp://nlp.cs.rpi.edu/paper/wsd.pdf\nhttp://storage.googleapis.com/books/ngrams/books/datasetsv2.html\nhttp://webdocs.cs.ualberta.ca/~bergsma/PhrasalClusters/",
        "Issue Links": []
    },
    "OPENNLP-792": {
        "Key": "OPENNLP-792",
        "Summary": "Documentation for WSD OSCC",
        "Type": "Task",
        "Status": "Open",
        "Priority": "Minor",
        "Resolution": "Unresolved",
        "Affects Version/s": "None",
        "Fix Version/s": "None",
        "Component/s": "wsd",
        "Assignee": null,
        "Reporter": "Anthony Beylerian",
        "Created": "09/Jul/15 21:33",
        "Updated": "26/Aug/15 16:24",
        "Resolved": null,
        "Description": null,
        "Issue Links": []
    },
    "OPENNLP-793": {
        "Key": "OPENNLP-793",
        "Summary": "Change de default behavior when the sentence model has a abbreviation dictionary.",
        "Type": "Improvement",
        "Status": "Open",
        "Priority": "Minor",
        "Resolution": "Unresolved",
        "Affects Version/s": "None",
        "Fix Version/s": "None",
        "Component/s": "Sentence Detector",
        "Assignee": null,
        "Reporter": "Gustavo Knuppe",
        "Created": "09/Jul/15 22:06",
        "Updated": "09/Jul/15 22:08",
        "Resolved": null,
        "Description": "When a sentece model has a abbreviation dictionary the default behavior of the SentenceDetectorME should deal with the abbreviations (even if the model is poorly trained).",
        "Issue Links": []
    },
    "OPENNLP-794": {
        "Key": "OPENNLP-794",
        "Summary": "WSD module CLI support",
        "Type": "Task",
        "Status": "Open",
        "Priority": "Minor",
        "Resolution": "Unresolved",
        "Affects Version/s": "None",
        "Fix Version/s": "None",
        "Component/s": "wsd",
        "Assignee": null,
        "Reporter": "Anthony Beylerian",
        "Created": "13/Jul/15 14:55",
        "Updated": "12/Aug/15 13:38",
        "Resolved": null,
        "Description": "The WSD component needs to run from the CLI, will need to add the required classes to support it.",
        "Issue Links": []
    },
    "OPENNLP-795": {
        "Key": "OPENNLP-795",
        "Summary": "Semcor Parser/Converter",
        "Type": "Task",
        "Status": "Closed",
        "Priority": "Major",
        "Resolution": "Fixed",
        "Affects Version/s": "None",
        "Fix Version/s": "None",
        "Component/s": "wsd",
        "Assignee": null,
        "Reporter": "Anthony Beylerian",
        "Created": "13/Jul/15 14:58",
        "Updated": "16/Dec/16 09:52",
        "Resolved": "23/Aug/15 13:29",
        "Description": "We need a parser/converter for Semcor.\nThis is useful to be able to evaluate WSD related approaches.",
        "Issue Links": []
    },
    "OPENNLP-796": {
        "Key": "OPENNLP-796",
        "Summary": "Senseval-3 Parser/Converter",
        "Type": "Task",
        "Status": "Closed",
        "Priority": "Major",
        "Resolution": "Implemented",
        "Affects Version/s": "None",
        "Fix Version/s": "1.6.0",
        "Component/s": "wsd",
        "Assignee": null,
        "Reporter": "Anthony Beylerian",
        "Created": "13/Jul/15 14:59",
        "Updated": "16/Jan/17 15:20",
        "Resolved": "16/Jan/17 15:20",
        "Description": "We need a parser/converter for Senseval-3.\nThis is useful to be able to evaluate WSD related approaches.",
        "Issue Links": []
    },
    "OPENNLP-797": {
        "Key": "OPENNLP-797",
        "Summary": "WSD - IMS all word dismbiguation",
        "Type": "Task",
        "Status": "Closed",
        "Priority": "Major",
        "Resolution": "Fixed",
        "Affects Version/s": "None",
        "Fix Version/s": "None",
        "Component/s": "None",
        "Assignee": null,
        "Reporter": "Mondher Bouazizi",
        "Created": "14/Jul/15 15:09",
        "Updated": "15/Dec/16 15:21",
        "Resolved": "21/Aug/15 08:38",
        "Description": "Create the all word disambiguation for the IMS approach.",
        "Issue Links": []
    },
    "OPENNLP-798": {
        "Key": "OPENNLP-798",
        "Summary": "Division by Zero exception in the EvalParameters.",
        "Type": "Bug",
        "Status": "Closed",
        "Priority": "Major",
        "Resolution": "Won't Fix",
        "Affects Version/s": "None",
        "Fix Version/s": "None",
        "Component/s": "Machine Learning",
        "Assignee": null,
        "Reporter": "Gustavo Knuppe",
        "Created": "21/Jul/15 02:12",
        "Updated": "26/Dec/16 12:54",
        "Resolved": "26/Dec/16 12:54",
        "Description": "The EvalParameters(Context[] params, int numOutcomes) constructor rises a division by zero exception.",
        "Issue Links": []
    },
    "OPENNLP-799": {
        "Key": "OPENNLP-799",
        "Summary": "NewlineSentenceDetector is not working,",
        "Type": "Bug",
        "Status": "Closed",
        "Priority": "Major",
        "Resolution": "Fixed",
        "Affects Version/s": "1.6.0",
        "Fix Version/s": "1.7.0",
        "Component/s": "Sentence Detector",
        "Assignee": "J\u00f6rn Kottmann",
        "Reporter": "Gustavo Knuppe",
        "Created": "21/Jul/15 23:45",
        "Updated": "29/Jul/15 08:26",
        "Resolved": "29/Jul/15 08:26",
        "Description": "The NewlineSentenceDetector does not work because of a small comparison error.\nThe attached path fixes the problem, and also adds a class with some tests.",
        "Issue Links": []
    },
    "OPENNLP-800": {
        "Key": "OPENNLP-800",
        "Summary": "Explain how to retrieve probs from the name finder for names and for non recognized names",
        "Type": "Bug",
        "Status": "Closed",
        "Priority": "Minor",
        "Resolution": "Won't Fix",
        "Affects Version/s": "tools-1.5.3",
        "Fix Version/s": "None",
        "Component/s": "Name Finder",
        "Assignee": null,
        "Reporter": "Prakash Mathiyalagan",
        "Created": "24/Jul/15 11:08",
        "Updated": "16/Jan/17 14:47",
        "Resolved": "16/Jan/17 14:47",
        "Description": "Explain how to retrieve probs from the name finder for names and for non recognized names",
        "Issue Links": []
    },
    "OPENNLP-801": {
        "Key": "OPENNLP-801",
        "Summary": "WSD should not include pre-processing",
        "Type": "Improvement",
        "Status": "Open",
        "Priority": "Major",
        "Resolution": "Unresolved",
        "Affects Version/s": "None",
        "Fix Version/s": "None",
        "Component/s": "wsd",
        "Assignee": null,
        "Reporter": "J\u00f6rn Kottmann",
        "Created": "28/Jul/15 09:31",
        "Updated": "28/Aug/15 08:28",
        "Resolved": null,
        "Description": "The wsd component currently contains pre-processing code. This should be removed and it should instead expect already processed inputs. E.g. tokenized sentences with pos tags and maybe lemmas.",
        "Issue Links": []
    },
    "OPENNLP-802": {
        "Key": "OPENNLP-802",
        "Summary": "Implement the MFS Approach for WSD module",
        "Type": "Task",
        "Status": "Closed",
        "Priority": "Major",
        "Resolution": "Fixed",
        "Affects Version/s": "None",
        "Fix Version/s": "None",
        "Component/s": "wsd",
        "Assignee": null,
        "Reporter": "Mondher Bouazizi",
        "Created": "01/Aug/15 10:04",
        "Updated": "16/Dec/16 09:52",
        "Resolved": "21/Aug/15 08:35",
        "Description": "The WSDisambiguator needs a baseline to compare the implemented approaches with.\nLesk presents a good baseline, however Senseval and Semeval workshops demonstrated that MFS presents a better and more challenging baseline.",
        "Issue Links": []
    },
    "OPENNLP-803": {
        "Key": "OPENNLP-803",
        "Summary": "Geoentity Linker should use OpenNLP 1.6.0",
        "Type": "Improvement",
        "Status": "Closed",
        "Priority": "Minor",
        "Resolution": "Fixed",
        "Affects Version/s": "None",
        "Fix Version/s": "None",
        "Component/s": "Entity Linker",
        "Assignee": "J\u00f6rn Kottmann",
        "Reporter": "J\u00f6rn Kottmann",
        "Created": "03/Aug/15 08:42",
        "Updated": "06/Aug/15 09:57",
        "Resolved": "06/Aug/15 09:57",
        "Description": "The dependency of OpenNLP Tools should be updated to the latest release 1.6.0 instead of using the SNAPSHOT of it.",
        "Issue Links": []
    },
    "OPENNLP-804": {
        "Key": "OPENNLP-804",
        "Summary": "WSD component should depend on 1.6.0 opennlp tools release",
        "Type": "Bug",
        "Status": "Closed",
        "Priority": "Minor",
        "Resolution": "Fixed",
        "Affects Version/s": "None",
        "Fix Version/s": "None",
        "Component/s": "wsd",
        "Assignee": "J\u00f6rn Kottmann",
        "Reporter": "J\u00f6rn Kottmann",
        "Created": "06/Aug/15 09:55",
        "Updated": "06/Aug/15 09:56",
        "Resolved": "06/Aug/15 09:56",
        "Description": "Update the dependency from opennlp-tools 1.6.0-SNAPSHOT to 1.6.0.",
        "Issue Links": []
    },
    "OPENNLP-805": {
        "Key": "OPENNLP-805",
        "Summary": "GazetteerIndexer.main should have parameters for hard coded pathes",
        "Type": "Improvement",
        "Status": "Closed",
        "Priority": "Minor",
        "Resolution": "Fixed",
        "Affects Version/s": "None",
        "Fix Version/s": "None",
        "Component/s": "Entity Linker",
        "Assignee": "J\u00f6rn Kottmann",
        "Reporter": "J\u00f6rn Kottmann",
        "Created": "06/Aug/15 13:09",
        "Updated": "28/Nov/19 21:08",
        "Resolved": "06/Aug/15 13:28",
        "Description": "The indexer needs to read a couple of files. All of them are hard coded currently. To make the indexer useful for various setups they should be passed in as command line arguments.",
        "Issue Links": []
    },
    "OPENNLP-806": {
        "Key": "OPENNLP-806",
        "Summary": "Add missing semantic relations for WSD",
        "Type": "Improvement",
        "Status": "Closed",
        "Priority": "Minor",
        "Resolution": "Fixed",
        "Affects Version/s": "None",
        "Fix Version/s": "None",
        "Component/s": "None",
        "Assignee": null,
        "Reporter": "Anthony Beylerian",
        "Created": "08/Aug/15 19:59",
        "Updated": "15/Dec/16 15:21",
        "Resolved": "21/Aug/15 08:36",
        "Description": "Lesk can use more semantic relations for gloss overlaps. This includes :\ncoordinate terms\nentailments",
        "Issue Links": []
    },
    "OPENNLP-807": {
        "Key": "OPENNLP-807",
        "Summary": "Integrate the WSD component into OpenNLP Tools",
        "Type": "Bug",
        "Status": "Open",
        "Priority": "Major",
        "Resolution": "Unresolved",
        "Affects Version/s": "None",
        "Fix Version/s": "None",
        "Component/s": "wsd",
        "Assignee": "Anthony Beylerian",
        "Reporter": "J\u00f6rn Kottmann",
        "Created": "12/Aug/15 13:45",
        "Updated": "24/Aug/15 21:29",
        "Resolved": null,
        "Description": "It would be nice to ship the wsd component as part of OpenNLp Tools. Since we have a zero dependencies for the tools package we might need to ship some implementations as addons.\nIs there one  implementation of it that has zero dependencies?",
        "Issue Links": []
    },
    "OPENNLP-808": {
        "Key": "OPENNLP-808",
        "Summary": "Parser is not thread safe",
        "Type": "Bug",
        "Status": "Closed",
        "Priority": "Major",
        "Resolution": "Not A Problem",
        "Affects Version/s": "tools-1.5.3,                                            1.6.0",
        "Fix Version/s": "None",
        "Component/s": "Parser",
        "Assignee": null,
        "Reporter": "Fergal Monaghan",
        "Created": "17/Aug/15 11:25",
        "Updated": "15/Dec/16 15:19",
        "Resolved": "15/Dec/16 15:19",
        "Description": "I'm actually not sure if this is really a \"Major\" \"Bug\" as I have listed it, perhaps it is by design. However even in this case this issue should possibly be listed as an \"Improvement\".\nSteps to recreate:\n1. Run 2 or more threads simultaneously which make calls to the same parser object with the same piece of text.\n2. One of a couple of things happens:\n(a) Either: line 281 of opennlp.tools.parser.AbstractBottomUpParser throws a java.util.ConcurrentModificationException from java.util.ArrayList iterator due to the `odh` field being global/shared in the object and not local to the method.\n(b) Or: the opennlp.tools.postag.DefaultPOSContextGenerator.getContext method throws a NullPointerException from line 77 of the opennlp.tools.util.Cache.clear method, since the underlying opennlp.tools.util.DoubleLinkedListElement is altered out from underneath it.\nUnless there are serious memory reasons for doing so, I would propose that such fields could be made local to the method since thread safety may take precedence over the memory saved in this case. As is, any code that calls the parser has to be enclosed in a giant synchronized block, and all applications using the parser have serious performance issues/cannot make use of modern hardware. I could be way of the mark here though if there is method to the madness",
        "Issue Links": []
    },
    "OPENNLP-809": {
        "Key": "OPENNLP-809",
        "Summary": "Detokenize instead of splitting string with whitespaces",
        "Type": "Bug",
        "Status": "Open",
        "Priority": "Major",
        "Resolution": "Unresolved",
        "Affects Version/s": "1.6.0",
        "Fix Version/s": "None",
        "Component/s": "Name Finder",
        "Assignee": "J\u00f6rn Kottmann",
        "Reporter": "Damiano",
        "Created": "29/Aug/15 14:32",
        "Updated": "27/Apr/16 08:42",
        "Resolved": null,
        "Description": "Hello,\nI do not understand why you are splitting the tokens with a whitespace in RegexNameFinder. It is pointless to me. \nWhen we call `find(String[] token)` you rebuilt the string by appending a whitespace at the end of each token. Why?\nI am saying that because maybe the original string has been tokenized by the SimpleTokenizer, and, as you know this tokenizer adds (for example) a whitespace within a word and a point. Example:\nOriginal:\nI am visiting Rome.\nTokenized:\nI am visiting Rome*[SPLIT]*.\nRegex is applied to: \nI am visiting Rome . \n(instead of the original)\nIn this version you have introduced a find() method that allows a String instead of String[], but in this case someone pass the original string not the rebuilt string, so the result are different.\nWhy do not apply a detokenize method to do the EXACT inverse operation of the tokenization? (and get the original string again instead of a modified string)\nThanks.",
        "Issue Links": []
    },
    "OPENNLP-810": {
        "Key": "OPENNLP-810",
        "Summary": "UIMA POS Tagger tries to set probability to the wrong feature",
        "Type": "Bug",
        "Status": "Closed",
        "Priority": "Minor",
        "Resolution": "Fixed",
        "Affects Version/s": "1.6.0",
        "Fix Version/s": "1.7.0",
        "Component/s": "UIMA Integration",
        "Assignee": "J\u00f6rn Kottmann",
        "Reporter": "Donatas Remeika",
        "Created": "02/Sep/15 07:10",
        "Updated": "03/Sep/15 15:09",
        "Resolved": "03/Sep/15 07:31",
        "Description": "UIMA POSTagger incorrectly tries to set pos probability to pos feature and breaks because of incompatible types.\nChanged to probabilityFeature.",
        "Issue Links": []
    },
    "OPENNLP-811": {
        "Key": "OPENNLP-811",
        "Summary": "add namefinder word representation features documentation",
        "Type": "Documentation",
        "Status": "Closed",
        "Priority": "Minor",
        "Resolution": "Fixed",
        "Affects Version/s": "1.6.0",
        "Fix Version/s": "1.7.0",
        "Component/s": "Name Finder",
        "Assignee": "Rodrigo Agerri",
        "Reporter": "Rodrigo Agerri",
        "Created": "02/Sep/15 12:38",
        "Updated": "04/Sep/15 14:00",
        "Resolved": "04/Sep/15 14:00",
        "Description": "New features have been added to the NameFinder Adaptive Feature Generator which allow to substantially improve performance (e.g. OPENNLP-715). The documentation should be updated accordingly.",
        "Issue Links": []
    },
    "OPENNLP-812": {
        "Key": "OPENNLP-812",
        "Summary": "Add lemmatizer documentation section",
        "Type": "Documentation",
        "Status": "Closed",
        "Priority": "Minor",
        "Resolution": "Fixed",
        "Affects Version/s": "1.6.0",
        "Fix Version/s": "1.7.0",
        "Component/s": "Lemmatizer",
        "Assignee": "Rodrigo Agerri",
        "Reporter": "Rodrigo Agerri",
        "Created": "02/Sep/15 12:39",
        "Updated": "17/Sep/15 12:44",
        "Resolved": "08/Sep/15 13:37",
        "Description": "The Lemmatizer (currently only dictionary-based) lacks documentation.",
        "Issue Links": []
    },
    "OPENNLP-813": {
        "Key": "OPENNLP-813",
        "Summary": "Lemmatizer serialization",
        "Type": "Wish",
        "Status": "Closed",
        "Priority": "Minor",
        "Resolution": "Invalid",
        "Affects Version/s": "1.6.0",
        "Fix Version/s": "None",
        "Component/s": "Lemmatizer",
        "Assignee": null,
        "Reporter": "Damiano",
        "Created": "08/Sep/15 07:38",
        "Updated": "22/Apr/23 17:55",
        "Resolved": "22/Apr/23 17:55",
        "Description": "Hello,\nwhy should we not implement the serialization for SimpleLemmatizer?",
        "Issue Links": []
    },
    "OPENNLP-814": {
        "Key": "OPENNLP-814",
        "Summary": "Lemmatizer CLI tool",
        "Type": "New Feature",
        "Status": "Closed",
        "Priority": "Major",
        "Resolution": "Fixed",
        "Affects Version/s": "None",
        "Fix Version/s": "1.7.0",
        "Component/s": "Lemmatizer",
        "Assignee": "Rodrigo Agerri",
        "Reporter": "Rodrigo Agerri",
        "Created": "08/Sep/15 12:50",
        "Updated": "28/Sep/16 13:14",
        "Resolved": "28/Sep/16 13:14",
        "Description": "The lemmatizer lacks a CLI tool to test it on the command line. We should add one.",
        "Issue Links": []
    },
    "OPENNLP-815": {
        "Key": "OPENNLP-815",
        "Summary": "unhandled exception",
        "Type": "Bug",
        "Status": "Closed",
        "Priority": "Minor",
        "Resolution": "Won't Fix",
        "Affects Version/s": "tools-1.5.3",
        "Fix Version/s": "None",
        "Component/s": "None",
        "Assignee": null,
        "Reporter": "songwanging",
        "Created": "10/Sep/15 16:34",
        "Updated": "09/Jan/17 15:14",
        "Resolved": "09/Jan/17 15:14",
        "Description": "In method run() of class CensusDictionaryCreatorTool(opennlp-tools\\src\\main\\java\\opennlp\\tools\\cmdline\\namefind\\CensusDictionaryCreatorTool.java)\nThe catch block in the following code snippet, caught an IOException, while it performs no actions to handle its expected exception, which makes\nitself useless. \nTo fix this bug, developers should add more code into the catch block to handle this exception.\n try \n{\n  ...\n    }\n finally {\n      try \n{\n        sampleStream.close();\n      }\n catch(IOException e) \n{\n        // sorry this can fail..\n      }\n    }\n ...\n}",
        "Issue Links": []
    },
    "OPENNLP-816": {
        "Key": "OPENNLP-816",
        "Summary": "useless else if branch",
        "Type": "Bug",
        "Status": "Closed",
        "Priority": "Minor",
        "Resolution": "Won't Fix",
        "Affects Version/s": "tools-1.5.3",
        "Fix Version/s": "None",
        "Component/s": "None",
        "Assignee": null,
        "Reporter": "songwanging",
        "Created": "10/Sep/15 17:01",
        "Updated": "26/Dec/16 12:56",
        "Resolved": "26/Dec/16 12:56",
        "Description": "In method getFeatures of class SimilarityModel(opennlp-tools\\src\\main\\java\\opennlp\\tools\\coref\\sim\\SimilarityModel.java)\nThe else_if branch presented in the following code snippet, tries to extract features from Context, while this else_if branch examined a condiction without further actions, which makes itself useless. \nTo fix this bug, we should add more specific code to extract features, or directly delete this else_if branch.  \n private List<String> getFeatures(Context np1, Context np2) {\n    ...\n    else if (isNumber(np2)) {}\n    else \n{\n     ...\n         }\n    }\n      else \n{\n      //System.err.println(\"unknown group for \" + np1.headToken);\n    }\n   ...\n}",
        "Issue Links": []
    },
    "OPENNLP-817": {
        "Key": "OPENNLP-817",
        "Summary": "Add support for creating probabilistic CFG from samples",
        "Type": "Improvement",
        "Status": "Open",
        "Priority": "Major",
        "Resolution": "Unresolved",
        "Affects Version/s": "None",
        "Fix Version/s": "None",
        "Component/s": "None",
        "Assignee": "Tommaso Teofili",
        "Reporter": "Tommaso Teofili",
        "Created": "12/Sep/15 07:17",
        "Updated": "12/Sep/15 07:17",
        "Resolved": null,
        "Description": "It'd be good to be able to create a PCFG from existing samples of expansions, like e.g. parse trees.",
        "Issue Links": []
    },
    "OPENNLP-818": {
        "Key": "OPENNLP-818",
        "Summary": "Descriptor xml: ExternalResourceDependency cannot take a Dictionary",
        "Type": "Bug",
        "Status": "Closed",
        "Priority": "Minor",
        "Resolution": "Fixed",
        "Affects Version/s": "None",
        "Fix Version/s": "1.7.0",
        "Component/s": "UIMA Integration",
        "Assignee": "J\u00f6rn Kottmann",
        "Reporter": "Peter Thygesen",
        "Created": "17/Sep/15 07:29",
        "Updated": "04/Nov/15 14:56",
        "Resolved": "23/Sep/15 14:44",
        "Description": "I wrote a small flow with a descriptor for a DictionaryNameFinder.\nI can get it to work with configurationParameters and a configurationParameterSettings with reference to a dictionary xml file.\nBut that gives me a warning:\nWARNING: The unmanaged resource models/names.dic was accessed.This feature is deprecated, and support may be removed in future versions.\nI can't get externalResourceDependencies to work. I have been told that it is not implemented for Dictionaries.\nPlease provide support for Dictionaries in externalResourceDependencies.",
        "Issue Links": []
    },
    "OPENNLP-819": {
        "Key": "OPENNLP-819",
        "Summary": "Leipzig corpus reader should be able to train a language identification model",
        "Type": "Improvement",
        "Status": "Closed",
        "Priority": "Minor",
        "Resolution": "Fixed",
        "Affects Version/s": "None",
        "Fix Version/s": "1.7.0",
        "Component/s": "Doccat",
        "Assignee": "J\u00f6rn Kottmann",
        "Reporter": "J\u00f6rn Kottmann",
        "Created": "17/Sep/15 12:11",
        "Updated": "17/Sep/15 13:02",
        "Resolved": "17/Sep/15 13:02",
        "Description": "In its current state the Leipzig corpus reader can only read from one language file. In order to create a model that can detect many languages all the input files must be converted and merged together.\nIt would be much easier to train a language identification model if the corpus reader could just read many sentences files form a directory.\nThis issue will change the Leipzig reader to read from all sentences file in a specified directory. The language category should be extracted from the file name itself.",
        "Issue Links": []
    },
    "OPENNLP-820": {
        "Key": "OPENNLP-820",
        "Summary": "parser is mistagging quotes",
        "Type": "Bug",
        "Status": "Closed",
        "Priority": "Major",
        "Resolution": "Won't Fix",
        "Affects Version/s": "1.6.0",
        "Fix Version/s": "None",
        "Component/s": "Parser",
        "Assignee": null,
        "Reporter": "Steven Owens",
        "Created": "03/Oct/15 20:51",
        "Updated": "17/Jan/17 21:45",
        "Resolved": "17/Jan/17 21:45",
        "Description": "the parser is mistagging quotes (both single and double) with the default English model. I notice most on opening quotes but it happens to closing quotes. \nex. (TOP (NP (NP-S-NP (NN \"))(ADVP-C-NP (RB Here))(. ?)(. \")))  both double quotes should be labeled ''(two single quotes).\nsame sentence labeled with the part of speech tagger using the default English model: \"_`` Here_RB ?. \"_''",
        "Issue Links": []
    },
    "OPENNLP-821": {
        "Key": "OPENNLP-821",
        "Summary": "Add support for mallet classifiers",
        "Type": "New Feature",
        "Status": "Closed",
        "Priority": "Minor",
        "Resolution": "Fixed",
        "Affects Version/s": "None",
        "Fix Version/s": "None",
        "Component/s": "Machine Learning",
        "Assignee": "J\u00f6rn Kottmann",
        "Reporter": "J\u00f6rn Kottmann",
        "Created": "09/Oct/15 12:43",
        "Updated": "04/Nov/15 14:37",
        "Resolved": "04/Nov/15 14:37",
        "Description": "It would be nice to have support in OpenNLP to train and use Mallet classifiers. The support should be packaged in an addon/sandbox project since it pulls in dependencies which are not compatible and can't be distributed. It would still be nice to at least share the code so it can be used in an experimental way.",
        "Issue Links": []
    },
    "OPENNLP-822": {
        "Key": "OPENNLP-822",
        "Summary": "The Name Finder models should always include the default feature generator config",
        "Type": "Improvement",
        "Status": "Closed",
        "Priority": "Minor",
        "Resolution": "Fixed",
        "Affects Version/s": "None",
        "Fix Version/s": "1.7.0",
        "Component/s": "Name Finder",
        "Assignee": "J\u00f6rn Kottmann",
        "Reporter": "J\u00f6rn Kottmann",
        "Created": "20/Oct/15 11:28",
        "Updated": "04/Nov/15 14:36",
        "Resolved": "04/Nov/15 14:36",
        "Description": "The Name Finder is often trained with default feature generation. In that case the default name finder configuration should be included in the model.\nIncluding it in the model will make it simple to change the default configuration in a later releases.",
        "Issue Links": []
    },
    "OPENNLP-823": {
        "Key": "OPENNLP-823",
        "Summary": "Remove deprecated constructors from the TokenNameFinderME",
        "Type": "Improvement",
        "Status": "Closed",
        "Priority": "Minor",
        "Resolution": "Fixed",
        "Affects Version/s": "None",
        "Fix Version/s": "1.7.0",
        "Component/s": "Name Finder",
        "Assignee": "J\u00f6rn Kottmann",
        "Reporter": "J\u00f6rn Kottmann",
        "Created": "04/Nov/15 14:43",
        "Updated": "05/Nov/15 15:10",
        "Resolved": "05/Nov/15 15:10",
        "Description": "The TokenNameFinderME is now completely configured via the loaded model. The left over option in the deprecated constructors only work in some cases, but not all. It would be better to remove these options to ensure it works as intended in all situations.",
        "Issue Links": []
    },
    "OPENNLP-824": {
        "Key": "OPENNLP-824",
        "Summary": "UIMA Name Finder integration should support multipe type models",
        "Type": "Improvement",
        "Status": "Closed",
        "Priority": "Minor",
        "Resolution": "Fixed",
        "Affects Version/s": "1.6.0",
        "Fix Version/s": "1.7.0",
        "Component/s": "None",
        "Assignee": "J\u00f6rn Kottmann",
        "Reporter": "J\u00f6rn Kottmann",
        "Created": "04/Nov/15 16:45",
        "Updated": "30/Dec/16 18:51",
        "Resolved": "30/Dec/16 18:51",
        "Description": "The UIMA Name Finder integration should support models that have multiple types. \nThe configuration uses the opennlp.uima.NameType parameter to map the (single) model type to an UIMA TS type.\nThis notion should be extended as follows:\n\nmodel_type:ts_type\nmodel_type1:ts_type1,model_type2:ts_type2, ..., model_typenN:ts_typeN,\nts_type (same behavior as before)",
        "Issue Links": []
    },
    "OPENNLP-825": {
        "Key": "OPENNLP-825",
        "Summary": "Make classifier abstract for WSD component",
        "Type": "Bug",
        "Status": "Closed",
        "Priority": "Major",
        "Resolution": "Abandoned",
        "Affects Version/s": "None",
        "Fix Version/s": "None",
        "Component/s": "wsd",
        "Assignee": null,
        "Reporter": "Anthony Beylerian",
        "Created": "07/Nov/15 17:45",
        "Updated": "22/Apr/23 17:27",
        "Resolved": "22/Apr/23 17:27",
        "Description": null,
        "Issue Links": []
    },
    "OPENNLP-826": {
        "Key": "OPENNLP-826",
        "Summary": "Support feature space augmentation for domain specific features in WSD",
        "Type": "Improvement",
        "Status": "Open",
        "Priority": "Major",
        "Resolution": "Unresolved",
        "Affects Version/s": "None",
        "Fix Version/s": "None",
        "Component/s": "wsd",
        "Assignee": null,
        "Reporter": "Anthony Beylerian",
        "Created": "07/Nov/15 17:46",
        "Updated": "07/Nov/15 17:50",
        "Resolved": null,
        "Description": null,
        "Issue Links": []
    },
    "OPENNLP-827": {
        "Key": "OPENNLP-827",
        "Summary": "WSD unit tests",
        "Type": "Test",
        "Status": "Open",
        "Priority": "Minor",
        "Resolution": "Unresolved",
        "Affects Version/s": "None",
        "Fix Version/s": "None",
        "Component/s": "wsd",
        "Assignee": null,
        "Reporter": "Anthony Beylerian",
        "Created": "07/Nov/15 17:47",
        "Updated": "26/Feb/23 14:44",
        "Resolved": null,
        "Description": null,
        "Issue Links": []
    },
    "OPENNLP-828": {
        "Key": "OPENNLP-828",
        "Summary": "Test coarse WSD on OntoNotes",
        "Type": "Test",
        "Status": "Open",
        "Priority": "Minor",
        "Resolution": "Unresolved",
        "Affects Version/s": "None",
        "Fix Version/s": "None",
        "Component/s": "wsd",
        "Assignee": null,
        "Reporter": "Anthony Beylerian",
        "Created": "07/Nov/15 17:49",
        "Updated": "07/Nov/15 17:49",
        "Resolved": null,
        "Description": null,
        "Issue Links": []
    },
    "OPENNLP-829": {
        "Key": "OPENNLP-829",
        "Summary": "Cleanup Doccat package javadoc",
        "Type": "Improvement",
        "Status": "Closed",
        "Priority": "Major",
        "Resolution": "Fixed",
        "Affects Version/s": "None",
        "Fix Version/s": "1.7.0",
        "Component/s": "Doccat",
        "Assignee": "Tommaso Teofili",
        "Reporter": "Tommaso Teofili",
        "Created": "16/Jan/16 07:07",
        "Updated": "03/Nov/16 06:21",
        "Resolved": "09/Mar/16 10:01",
        "Description": "Doccat package has a bunch of undocumented methods and classes, also some methods are never used and therefore it may make sense to eventually prune them.\nMissing javadoc for classes and public methods should be added.",
        "Issue Links": []
    },
    "OPENNLP-830": {
        "Key": "OPENNLP-830",
        "Summary": "Huge runtime improvement on training (POS, Chunk, ...)",
        "Type": "Improvement",
        "Status": "Closed",
        "Priority": "Major",
        "Resolution": "Fixed",
        "Affects Version/s": "1.6.0",
        "Fix Version/s": "1.7.0",
        "Component/s": "Machine Learning,                                            POS Tagger",
        "Assignee": "J\u00f6rn Kottmann",
        "Reporter": "Julien Subercaze",
        "Created": "16/Jan/16 22:55",
        "Updated": "28/Oct/16 15:55",
        "Resolved": "27/Oct/16 20:25",
        "Description": "opennlp.tools.ml.model.IndexHashTable is custom-made Hashtable that is used to store mapping index. This Hashtable is heavily used in openlp.tools.ml.* (i.e. every model) and leads to disastrous performance.\nThis hashtable is probably legacy some legacy and is highly inefficient. A simple drop-in replacement by a java.util.HashMap wrapper solves the issue, doesn't break compatibility and does not add any dependency.\nTraining a pos-tagger on a large dataset with custom tags, I see a factor 5 improvement. It also seems to improve all ML models training pipeline.\nSee : https://github.com/jsubercaze/opennlp/blob/trunk/opennlp-tools/src/main/java/opennlp/tools/ml/model/IndexHashTable.java\nFor a quick fix.",
        "Issue Links": []
    },
    "OPENNLP-831": {
        "Key": "OPENNLP-831",
        "Summary": "NER model creation is taking much time for large files",
        "Type": "Improvement",
        "Status": "Closed",
        "Priority": "Minor",
        "Resolution": "Won't Fix",
        "Affects Version/s": "1.6.0",
        "Fix Version/s": "None",
        "Component/s": "Name Finder",
        "Assignee": null,
        "Reporter": "Rakesh",
        "Created": "29/Jan/16 10:11",
        "Updated": "03/Jan/17 10:44",
        "Resolved": "03/Jan/17 10:44",
        "Description": "opennlp 1.6 is taking huge amount of time (nearly 6 hours ) to train a set of sentences (sentences count = 20000) . Each sentence may vary in length .You must try to decrease the training time. Is there any way to decrease the training time.If yes please let me know.",
        "Issue Links": []
    },
    "OPENNLP-832": {
        "Key": "OPENNLP-832",
        "Summary": "Lemmatizer tests",
        "Type": "Bug",
        "Status": "Closed",
        "Priority": "Major",
        "Resolution": "Fixed",
        "Affects Version/s": "None",
        "Fix Version/s": "1.7.0",
        "Component/s": "Lemmatizer",
        "Assignee": "Rodrigo Agerri",
        "Reporter": "Rodrigo Agerri",
        "Created": "18/Feb/16 15:05",
        "Updated": "05/Oct/16 15:03",
        "Resolved": "05/Oct/16 15:03",
        "Description": "Issue OPENNLP-760 will provide a statistical lemmatizer. We should add unit tests for that component.",
        "Issue Links": []
    },
    "OPENNLP-833": {
        "Key": "OPENNLP-833",
        "Summary": "Document the new statistical lemmatizer",
        "Type": "Documentation",
        "Status": "Closed",
        "Priority": "Major",
        "Resolution": "Fixed",
        "Affects Version/s": "1.7.0",
        "Fix Version/s": "1.7.0",
        "Component/s": "Lemmatizer",
        "Assignee": "Rodrigo Agerri",
        "Reporter": "Rodrigo Agerri",
        "Created": "18/Feb/16 21:22",
        "Updated": "29/Sep/16 13:59",
        "Resolved": "29/Sep/16 13:59",
        "Description": null,
        "Issue Links": []
    },
    "OPENNLP-834": {
        "Key": "OPENNLP-834",
        "Summary": "Create constant for Threads parameter",
        "Type": "Improvement",
        "Status": "Closed",
        "Priority": "Trivial",
        "Resolution": "Fixed",
        "Affects Version/s": "1.6.0",
        "Fix Version/s": "1.7.0",
        "Component/s": "Machine Learning",
        "Assignee": "J\u00f6rn Kottmann",
        "Reporter": "Jeff Zemerick",
        "Created": "02/Mar/16 12:22",
        "Updated": "16/Dec/16 09:53",
        "Resolved": "19/Oct/16 17:40",
        "Description": "There is a \"Threads\" parameter that sets the number of threads to use during model training. This task is to make it a constant value in the TrainingParameters class.",
        "Issue Links": []
    },
    "OPENNLP-835": {
        "Key": "OPENNLP-835",
        "Summary": "Various bugs in SequenceStreamEventStream",
        "Type": "Bug",
        "Status": "Closed",
        "Priority": "Major",
        "Resolution": "Fixed",
        "Affects Version/s": "1.6.0",
        "Fix Version/s": "1.7.0",
        "Component/s": "None",
        "Assignee": "J\u00f6rn Kottmann",
        "Reporter": "Steven Taschuk",
        "Created": "03/Mar/16 22:29",
        "Updated": "02/Nov/16 22:34",
        "Resolved": "27/Apr/16 08:41",
        "Description": "The class SequenceStreamEventStream has a few bugs.\n(1) It truncates the stream early if any sequence is empty.\n(2) After reset, it will emit the remaining elements from the underlying sequence that was being iterated over before the reset, and then start over from the beginning.\n(3) It leaks memory by not discarding references to objects it doesn't need anymore.",
        "Issue Links": []
    },
    "OPENNLP-836": {
        "Key": "OPENNLP-836",
        "Summary": "Inconsistent download links on website",
        "Type": "Improvement",
        "Status": "Closed",
        "Priority": "Minor",
        "Resolution": "Fixed",
        "Affects Version/s": "None",
        "Fix Version/s": "None",
        "Component/s": "Website",
        "Assignee": "J\u00f6rn Kottmann",
        "Reporter": "Jeff Zemerick",
        "Created": "04/Mar/16 15:05",
        "Updated": "07/Dec/16 22:42",
        "Resolved": "07/Dec/16 22:41",
        "Description": "The top Google search result for \"download opennlp\" goes to http://opennlp.apache.org/download.html but the mirror download links there seem to be broken. The \"Download\" link on the OpenNLP page goes to http://opennlp.apache.org/cgi-bin/download.cgi where the user has to drill down through the list of Apache projects to find the OpenNLP downloads.",
        "Issue Links": []
    },
    "OPENNLP-837": {
        "Key": "OPENNLP-837",
        "Summary": "Fail when non-sufficient amounts of training data are provided for training",
        "Type": "Bug",
        "Status": "Closed",
        "Priority": "Major",
        "Resolution": "Fixed",
        "Affects Version/s": "None",
        "Fix Version/s": "1.7.0",
        "Component/s": "Machine Learning",
        "Assignee": "Tommaso Teofili",
        "Reporter": "Tommaso Teofili",
        "Created": "09/Mar/16 10:23",
        "Updated": "26/Apr/16 19:57",
        "Resolved": "14/Mar/16 07:52",
        "Description": "When the amounts of training data are not sufficient in order to train a  model the user should be made aware of that with an informative message, e.g. a warning when using the command line, an exception when calling the APIs programmatically.",
        "Issue Links": [
            "/jira/browse/OPENNLP-488"
        ]
    },
    "OPENNLP-838": {
        "Key": "OPENNLP-838",
        "Summary": "modify the parameter model",
        "Type": "Improvement",
        "Status": "Open",
        "Priority": "Major",
        "Resolution": "Unresolved",
        "Affects Version/s": "None",
        "Fix Version/s": "None",
        "Component/s": "wsd",
        "Assignee": null,
        "Reporter": "Anthony Beylerian",
        "Created": "13/Mar/16 08:08",
        "Updated": "13/Mar/16 08:08",
        "Resolved": null,
        "Description": "The parameters in the WSD component should be changed to a map similar to TrainingParameters",
        "Issue Links": []
    },
    "OPENNLP-839": {
        "Key": "OPENNLP-839",
        "Summary": "filter by windowsize in the default context generators for IMS and OSCC",
        "Type": "Improvement",
        "Status": "Open",
        "Priority": "Minor",
        "Resolution": "Unresolved",
        "Affects Version/s": "None",
        "Fix Version/s": "None",
        "Component/s": "wsd",
        "Assignee": null,
        "Reporter": "Anthony Beylerian",
        "Created": "13/Mar/16 08:35",
        "Updated": "13/Mar/16 08:35",
        "Resolved": null,
        "Description": null,
        "Issue Links": []
    },
    "OPENNLP-840": {
        "Key": "OPENNLP-840",
        "Summary": "Sentiment Analysis",
        "Type": "New Feature",
        "Status": "Reopened",
        "Priority": "Major",
        "Resolution": "Unresolved",
        "Affects Version/s": "None",
        "Fix Version/s": "None",
        "Component/s": "None",
        "Assignee": "Chris A. Mattmann",
        "Reporter": "Mondher Bouazizi",
        "Created": "13/Mar/16 08:37",
        "Updated": "27/Jun/17 01:55",
        "Resolved": null,
        "Description": "The objective of the \"Sentiment Analysis\" component is to determine the sentiment of the author towards the object of his text.\nDifferent techniques are proposed in the academic literature, and some state of the art approaches present very high accuracy.\nSentiment analysis can have different granularity levels:\n\nBinary classification: in this case, the text is to be classified into two classes which are \"positive\" and \"negative\".\nTernary classification: in addition to the two classes present in the binary classification, a third class is added which is \"neutral\".\nMulti-class sentiment analysis: the two classes \"positive\" and \"negative\" are further divided into sub-classes (e.g., \"love\" happiness\", etc. for the positive class; and \"hate\", \"anger\", etc. for the negative class). Therefore the classification objective is to determine the sentiment sub-class instead of the main polarity\n\nIn this component, we will implement some of the state of the art approaches, in particular the one presented here[1]. approaches use machine-learning techniques to learn a classifier from labeled training sets.\n-----------------------------------------------\n[1] http://www.ieice.org/ken/paper/20160129DbfF/eng/",
        "Issue Links": [
            "https://github.com/apache/opennlp/pull/231"
        ]
    },
    "OPENNLP-841": {
        "Key": "OPENNLP-841",
        "Summary": "Add support for the feature augmentation technique",
        "Type": "Improvement",
        "Status": "Open",
        "Priority": "Minor",
        "Resolution": "Unresolved",
        "Affects Version/s": "None",
        "Fix Version/s": "None",
        "Component/s": "wsd",
        "Assignee": null,
        "Reporter": "Anthony Beylerian",
        "Created": "13/Mar/16 08:42",
        "Updated": "13/Mar/16 08:42",
        "Resolved": null,
        "Description": "With the augmentation technique it is possible to improve performances by combining domain-related information, to the training that uses general-domain information.\nfor reference :\nhttp://www.aclweb.org/anthology/D08-1105",
        "Issue Links": []
    },
    "OPENNLP-842": {
        "Key": "OPENNLP-842",
        "Summary": "Sentiment Quantification",
        "Type": "New Feature",
        "Status": "Open",
        "Priority": "Major",
        "Resolution": "Unresolved",
        "Affects Version/s": "None",
        "Fix Version/s": "None",
        "Component/s": "None",
        "Assignee": null,
        "Reporter": "Mondher Bouazizi",
        "Created": "13/Mar/16 08:50",
        "Updated": "13/Mar/16 09:11",
        "Resolved": null,
        "Description": "In addition to the sentiment analysis Component [1], a sentiment quantifier is required. In many cases, particularly for long texts, multiple sentiment are present. The classification task might be able to detect the most dominant sentiment in the text. However, it is as much important to detect the other sentiments and attribute different sentiment scores to these sentiments.\nTherefore, the objective of this component is to attribute sentiment scores after ternary classification: if a text is classified as positive for example, the positive sentiment sub-classes (e.g., \"love\", \"happiness\", \"fun\", etc.) are attributed different scores showing how much each one of them appears in the text. The work [2] presents a good start point, and further iteration on the idea are to be made.\n-------------------------------------------------\n[1] OPENNLP-840\n[2] http://www.ieice.org/ken/paper/20160129DbfF/eng/",
        "Issue Links": []
    },
    "OPENNLP-843": {
        "Key": "OPENNLP-843",
        "Summary": "Unify supervised wsd methods under same class",
        "Type": "Task",
        "Status": "Closed",
        "Priority": "Major",
        "Resolution": "Fixed",
        "Affects Version/s": "None",
        "Fix Version/s": "None",
        "Component/s": "wsd",
        "Assignee": "Anthony Beylerian",
        "Reporter": "Anthony Beylerian",
        "Created": "18/Mar/16 14:50",
        "Updated": "15/Dec/16 15:20",
        "Resolved": "07/Jun/16 09:28",
        "Description": "IMS and OSCC can be unified under a single disambiguator class with different context generators",
        "Issue Links": []
    },
    "OPENNLP-844": {
        "Key": "OPENNLP-844",
        "Summary": "Support N-Gram Range for feature extraction in Doccat",
        "Type": "Improvement",
        "Status": "Closed",
        "Priority": "Major",
        "Resolution": "Fixed",
        "Affects Version/s": "None",
        "Fix Version/s": "1.7.0",
        "Component/s": "None",
        "Assignee": "Rodrigo Agerri",
        "Reporter": "Madhawa Gunasekara",
        "Created": "03/Apr/16 18:41",
        "Updated": "03/Nov/16 09:12",
        "Resolved": "29/Apr/16 15:16",
        "Description": null,
        "Issue Links": []
    },
    "OPENNLP-845": {
        "Key": "OPENNLP-845",
        "Summary": "Evaluator.evaluateSample() sends the wrong argument to listener.correctlyClassified()",
        "Type": "Bug",
        "Status": "Closed",
        "Priority": "Major",
        "Resolution": "Fixed",
        "Affects Version/s": "None",
        "Fix Version/s": "1.7.0",
        "Component/s": "None",
        "Assignee": "Suneel Marthi",
        "Reporter": "Dave Kincaid",
        "Created": "21/Apr/16 17:00",
        "Updated": "26/Dec/16 13:43",
        "Resolved": "26/Dec/16 13:43",
        "Description": "When the evalation of a sample The implementation of Evaluator.evaluateSample() puts the predicted document into the first argument in the call to listener.correctlyClassified instead of the sample being evaluated. This causes any extra information in the document sample to be lost.\nThe call should be listener.correctlyClassified(sample, predicted)",
        "Issue Links": [
            "https://github.com/apache/opennlp/pull/22"
        ]
    },
    "OPENNLP-846": {
        "Key": "OPENNLP-846",
        "Summary": "The output results do not contain all entities that we think should have been found",
        "Type": "Question",
        "Status": "Closed",
        "Priority": "Critical",
        "Resolution": "Not A Problem",
        "Affects Version/s": "None",
        "Fix Version/s": "None",
        "Component/s": "Name Finder",
        "Assignee": null,
        "Reporter": "Ren",
        "Created": "21/Apr/16 21:56",
        "Updated": "05/Nov/16 12:00",
        "Resolved": "05/Nov/16 12:00",
        "Description": "We use \"OpenNLP\" using C# to find (Person, Location, Organization). The output results do not contain all entities that we think should have been found.\nSome examples - \nExample-1\n\"Holding placards and banners the Left Democratic Front (LDF) demanded the resignation of Finance Minister KM Mani who is facing a vigilance probe in\"\n\torganization - Left Democratic Front (LDF)\n\tperson - KM Mani\nExample-2\n\"USA Opposition Walks Out of Assembly; Demands Resignation of Finance Minister Opposition parties in Washington DC today walked out of the Assembly boycotting Governor P Sathasivam\"\n\tperson - P Sathasivam\n\tLocation - USA and Washington DC",
        "Issue Links": []
    },
    "OPENNLP-847": {
        "Key": "OPENNLP-847",
        "Summary": "Remove deprecated train methods from the NameFinderME",
        "Type": "Bug",
        "Status": "Closed",
        "Priority": "Minor",
        "Resolution": "Fixed",
        "Affects Version/s": "1.6.0",
        "Fix Version/s": "1.7.0",
        "Component/s": "Name Finder",
        "Assignee": "J\u00f6rn Kottmann",
        "Reporter": "J\u00f6rn Kottmann",
        "Created": "26/Apr/16 20:47",
        "Updated": "20/May/16 21:58",
        "Resolved": "20/May/16 21:58",
        "Description": "The NameFinderME has a set of deprecated train method. Those methods allow to train models which can't be used afterwards because the corresponding constructors where already removed.",
        "Issue Links": []
    },
    "OPENNLP-848": {
        "Key": "OPENNLP-848",
        "Summary": "Name Finder Trainer should print amount of tokens, sentences and names",
        "Type": "Improvement",
        "Status": "Closed",
        "Priority": "Trivial",
        "Resolution": "Fixed",
        "Affects Version/s": "None",
        "Fix Version/s": "1.7.0",
        "Component/s": "Command Line Interface,                                            Name Finder",
        "Assignee": "J\u00f6rn Kottmann",
        "Reporter": "J\u00f6rn Kottmann",
        "Created": "21/May/16 11:17",
        "Updated": "21/May/16 11:31",
        "Resolved": "21/May/16 11:31",
        "Description": "The Name Finder Trainer cli tool should count the amount of training data passed in and print a short summary at the end of the training.",
        "Issue Links": []
    },
    "OPENNLP-849": {
        "Key": "OPENNLP-849",
        "Summary": "Improve handling of InputStreams in TokenNameFinderTrainerTool",
        "Type": "Improvement",
        "Status": "Closed",
        "Priority": "Trivial",
        "Resolution": "Fixed",
        "Affects Version/s": "None",
        "Fix Version/s": "1.7.0",
        "Component/s": "Command Line Interface",
        "Assignee": "J\u00f6rn Kottmann",
        "Reporter": "J\u00f6rn Kottmann",
        "Created": "21/May/16 11:35",
        "Updated": "21/May/16 11:55",
        "Resolved": "21/May/16 11:55",
        "Description": "There are a couple of streams that are not closed after they are used and a few streams can be simplified with try-with-resources.",
        "Issue Links": []
    },
    "OPENNLP-850": {
        "Key": "OPENNLP-850",
        "Summary": "Create a brat name finder annotation service",
        "Type": "New Feature",
        "Status": "Closed",
        "Priority": "Minor",
        "Resolution": "Fixed",
        "Affects Version/s": "None",
        "Fix Version/s": "1.7.0",
        "Component/s": "None",
        "Assignee": "J\u00f6rn Kottmann",
        "Reporter": "J\u00f6rn Kottmann",
        "Created": "25/May/16 13:04",
        "Updated": "18/Oct/16 18:08",
        "Resolved": "18/Oct/16 18:08",
        "Description": "The brat annotation service integrates with the brat annotation tool and can annotate documents. \nThe current approach with the tagging-server is rather difficult to use, because the installation of it into an OSGi server is not trivial and it requires a blueprint xml configuration file.\nThe brat annotator should be build in a similar fashion as the OpenNLP command line interface.",
        "Issue Links": []
    },
    "OPENNLP-851": {
        "Key": "OPENNLP-851",
        "Summary": "GeoEntityLinker should use latest version of Lucene (6.0.0)",
        "Type": "Bug",
        "Status": "Open",
        "Priority": "Minor",
        "Resolution": "Unresolved",
        "Affects Version/s": "addons-1.6.0",
        "Fix Version/s": "None",
        "Component/s": "Entity Linker",
        "Assignee": "Mark Giaconia",
        "Reporter": "Mark Giaconia",
        "Created": "07/Jun/16 19:53",
        "Updated": "04/Dec/19 00:29",
        "Resolved": null,
        "Description": "GeoEntityLinker gazetteer indexer should use latest versions of lucene",
        "Issue Links": []
    },
    "OPENNLP-852": {
        "Key": "OPENNLP-852",
        "Summary": "CountryContextFile should support multiple regexes",
        "Type": "Improvement",
        "Status": "Open",
        "Priority": "Major",
        "Resolution": "Unresolved",
        "Affects Version/s": "addons-1.6.0",
        "Fix Version/s": "None",
        "Component/s": "Entity Linker",
        "Assignee": "Mark Giaconia",
        "Reporter": "Mark Giaconia",
        "Created": "07/Jun/16 19:55",
        "Updated": "01/Apr/19 04:54",
        "Resolved": null,
        "Description": "This will require reindexing all data, and constructing a new file format. This will be a big improvement in terms of recall of general location context.",
        "Issue Links": []
    },
    "OPENNLP-853": {
        "Key": "OPENNLP-853",
        "Summary": "Profiler",
        "Type": "New Feature",
        "Status": "Closed",
        "Priority": "Major",
        "Resolution": "Abandoned",
        "Affects Version/s": "None",
        "Fix Version/s": "None",
        "Component/s": "None",
        "Assignee": null,
        "Reporter": "Anthony Beylerian",
        "Created": "09/Jun/16 10:47",
        "Updated": "22/Apr/23 17:27",
        "Resolved": "22/Apr/23 17:27",
        "Description": "The profiler aims to return information about age and gender in input text samples.\nIt will integrate with a Tika parser : \nhttps://issues.apache.org/jira/browse/TIKA-2000\nLater we hope to add personality aspects such as:\n[extroverted, stable, agreeable, conscientious, open]\nMore details can be found here :\nhttps://github.com/beylerian/profiler",
        "Issue Links": []
    },
    "OPENNLP-854": {
        "Key": "OPENNLP-854",
        "Summary": "Character changes during Sentence Detector Training",
        "Type": "Bug",
        "Status": "Closed",
        "Priority": "Major",
        "Resolution": "Won't Fix",
        "Affects Version/s": "tools-1.5.3",
        "Fix Version/s": "None",
        "Component/s": "Sentence Detector",
        "Assignee": null,
        "Reporter": "dave hey",
        "Created": "28/Jun/16 18:53",
        "Updated": "31/Jan/17 11:51",
        "Resolved": "31/Jan/17 11:51",
        "Description": "When I try to learn a model for detecting Sentences for Persian language, the Unicode character U+0641 changes to something else and every occurrences of this char in the input text is changing to an unknown character in output text.",
        "Issue Links": []
    },
    "OPENNLP-855": {
        "Key": "OPENNLP-855",
        "Summary": "A parser that combines Apache OpenNLP and Apache Tika and provides facilities for automatically deriving sentiment from text.",
        "Type": "New Feature",
        "Status": "Open",
        "Priority": "Major",
        "Resolution": "Unresolved",
        "Affects Version/s": "None",
        "Fix Version/s": "None",
        "Component/s": "Parser",
        "Assignee": null,
        "Reporter": "Anastasija Mensikova",
        "Created": "03/Jul/16 12:15",
        "Updated": "09/Feb/17 21:51",
        "Resolved": null,
        "Description": "A new project that implements a parser that uses Apache OpenNLP and Apache Tika to perform Sentiment Analysis.",
        "Issue Links": [
            "https://github.com/apache/opennlp/pull/3",
            "https://github.com/apache/opennlp/pull/101"
        ]
    },
    "OPENNLP-856": {
        "Key": "OPENNLP-856",
        "Summary": "Refactor AdaptiveFeatureGenerator and FeatureGeneratorAdapter",
        "Type": "Improvement",
        "Status": "Closed",
        "Priority": "Minor",
        "Resolution": "Fixed",
        "Affects Version/s": "1.7.0",
        "Fix Version/s": "1.7.0",
        "Component/s": "Name Finder",
        "Assignee": "J\u00f6rn Kottmann",
        "Reporter": "Jeff Zemerick",
        "Created": "05/Jul/16 22:37",
        "Updated": "30/Dec/16 19:31",
        "Resolved": "22/Dec/16 16:40",
        "Description": "Under the package opennlp.tools.util.featuregen there is an interface AdaptiveFeatureGenerator and an abstract class FeatureGeneratorAdapter. The interface defines the createFeatures(), updateAdaptiveData(), and clearAdaptiveData() methods. The abstract class implements this interface to provide default implementations of the updateAdaptiveData() and clearAdaptiveData() functions. Feature generators then either implement the interface or extend the abstract class.\nThe purpose of this task is to refactor these classes to remove confusion caused by the similarity between the interface and the abstract class. This task deprecates the AdaptiveFeatureGenerator interface in favor of the abstract class FeatureGeneratorAdapter.\nDefault methods will be added to the AdaptiveFeatureGenerator interface to maintain backward compatibility. To support the default methods the version of the Java compiler will be set to 1.8.",
        "Issue Links": [
            "https://github.com/apache/opennlp/pull/4"
        ]
    },
    "OPENNLP-857": {
        "Key": "OPENNLP-857",
        "Summary": "ParserTool should take use Tokenizer instance. It should not use java.util.StringTokenizer",
        "Type": "Improvement",
        "Status": "Closed",
        "Priority": "Major",
        "Resolution": "Fixed",
        "Affects Version/s": "1.6.0",
        "Fix Version/s": "1.7.0",
        "Component/s": "Parser",
        "Assignee": "J\u00f6rn Kottmann",
        "Reporter": "Tristan Nixon",
        "Created": "09/Jul/16 20:57",
        "Updated": "15/Dec/16 15:20",
        "Resolved": "02/Nov/16 18:26",
        "Description": "It would be nice if the ParserTool would make use of a real tokenizer. In addition to being the \"right\" thing to do, it would obviate issues like OPENNLP-240 when using the parser tool.\nWhile I realize that java.util.StringTokenizer effectively does the same work as WhitespaceTokenizer, it seems odd to use the former when the latter exists.\nTo this end, I'm attaching a patch that adds an additional method\npublic static Parse[] parseLine(String line, Parser parser, Tokenizer tokenizer, int numParses)\nI've left the existing method\npublic static Parse[] parseLine(String line, Parser parser, int numParses)\nin for convenience and backwards compatibility. It simply calls the new method with WhitespaceTokenizer.INSTANCE\nFor good measure, I've added a new command-line argument -tk, which takes the name of a tokenizer model. If none is specified, it will fall back on the current behavior of using the whitespace tokenizer.",
        "Issue Links": []
    },
    "OPENNLP-858": {
        "Key": "OPENNLP-858",
        "Summary": "NameFinder multiple lines",
        "Type": "New Feature",
        "Status": "Open",
        "Priority": "Major",
        "Resolution": "Unresolved",
        "Affects Version/s": "None",
        "Fix Version/s": "None",
        "Component/s": "Name Finder",
        "Assignee": null,
        "Reporter": "Omri Shiv",
        "Created": "26/Jul/16 17:10",
        "Updated": "26/Jul/16 17:10",
        "Resolved": null,
        "Description": "It would be great if the NameFinder would work over multiple lines. When feeding in documents to training, sometimes entities span multiple lines. Additionally, when predicting, it would be great to keep the formatting the original document had.",
        "Issue Links": []
    },
    "OPENNLP-859": {
        "Key": "OPENNLP-859",
        "Summary": "Cannot get entities from trained model using DictionaryFeatureGenerator",
        "Type": "Question",
        "Status": "Closed",
        "Priority": "Major",
        "Resolution": "Feedback Received",
        "Affects Version/s": "1.6.0",
        "Fix Version/s": "None",
        "Component/s": "Name Finder",
        "Assignee": null,
        "Reporter": "Damiano Porta",
        "Created": "16/Aug/16 15:20",
        "Updated": "16/Dec/22 12:45",
        "Resolved": "16/Dec/22 12:45",
        "Description": "Hello,\nI have created the following training data.\ntrain.txt\nCiao mi chiamo <START:person> Damiano <END> ed abito a Roma  .\nil mio indirizzo \u00e8 via del <START:person> Corso <END> nella provincia di Roma .\nil mio cap \u00e8 lo 00144 nella capitale e e il mio nome \u00e8  <START:person> john <END> .\nAbito a Roma in via tar dei tali 10 , <START:person> Mario <END> \u00e8 il mio amico .\nOggi ho incontrato <START:person> giovanni <END> e siamo andati a giocare a calcio .\n\n\nAnd then this code:\ntest.java\n\n        Charset charset = Charset.forName(\"UTF-8\");\n        ObjectStream<String> lineStream =\n                        new PlainTextByLineStream(new FileInputStream(\"/home/damiano/person.train\"), charset);\n        ObjectStream<NameSample> sampleStream = new NameSampleDataStream(lineStream);\n\n        TokenNameFinderModel model;\n\n        Dictionary dictionary = new Dictionary();\n        dictionary.put(new StringList(new String[]{\"giovanni\"}));\n        dictionary.put(new StringList(new String[]{\"maria\"}));\n        dictionary.put(new StringList(new String[]{\"luca\"}));\n      \n        BufferedOutputStream aa = null;\n          \n        AdaptiveFeatureGenerator featureGenerator = new CachedFeatureGenerator(\n                 new AdaptiveFeatureGenerator[]{                                 \n                    new WindowFeatureGenerator(new TokenFeatureGenerator(), 2, 2),\n                    new WindowFeatureGenerator(new TokenClassFeatureGenerator(true), 2, 2),\n                    new OutcomePriorFeatureGenerator(),\n                    new PreviousMapFeatureGenerator(),\n                    new BigramNameFeatureGenerator(),\n                    new SentenceFeatureGenerator(true, false),\n                    new DictionaryFeatureGenerator(\"person\", dictionary)\n                   });\n\n        try {\n            model = NameFinderME.train(\"it\", \"person\", sampleStream, TrainingParameters.defaultParams(),\n                    featureGenerator, Collections.<String, Object>emptyMap());\n        }\n        finally {\n          sampleStream.close();\n        }\n\n        // Save trained model\n        try (BufferedOutputStream modelOut = new BufferedOutputStream(new FileOutputStream(\"/home/damiano/it-person-custom.bin\"))) {\n          model.serialize(modelOut);\n        }\n                \n        // Read the trained model\n        try (InputStream modelIn = new FileInputStream(\"/home/damiano/it-person-custom.bin\")) {\n\n            TokenNameFinderModel nerModel = new TokenNameFinderModel(modelIn);\n\n            NameFinderME nameFinder = new NameFinderME(nerModel, featureGenerator, NameFinderME.DEFAULT_BEAM_SIZE);\n          \n            String sentence[] = new String[]{\n                \"Ciao\", \"mi\", \"chiamo\", \"Damiano\", \"e\", \"sono\", \"di\", \"Roma\", \".\"\n            };\n            \n            Span nameSpans[] = nameFinder.find(sentence);                     \n          \n            System.out.println(Arrays.toString(Span.spansToStrings(nameSpans, sentence)));\n        }      \n\n\nWhen i try \n\n\"Ciao\", \"mi\", \"chiamo\", \"Damiano\", \"e\", \"sono\", \"di\", \"Roma\", \".\"\n\n\nit correctly detect \"Damiano\" as PERSON, but if i change it with:\n\n\"Ciao\", \"mi\", \"chiamo\", \"maria\", \"e\", \"sono\", \"di\", \"Roma\", \".\"\n\n\nit does not detect \"maria\" as PERSON but I added \"maria\" in the dictionary so it should get it. Why not ?\nThanks!",
        "Issue Links": []
    },
    "OPENNLP-860": {
        "Key": "OPENNLP-860",
        "Summary": "Migrate to git",
        "Type": "Task",
        "Status": "Closed",
        "Priority": "Major",
        "Resolution": "Fixed",
        "Affects Version/s": "None",
        "Fix Version/s": "None",
        "Component/s": "None",
        "Assignee": "J\u00f6rn Kottmann",
        "Reporter": "J\u00f6rn Kottmann",
        "Created": "18/Aug/16 12:46",
        "Updated": "15/Dec/16 14:22",
        "Resolved": "15/Dec/16 14:22",
        "Description": "The git repository is now available. There are a couple of things that should be done to finish this:\n\nDiscuss repository with Infra (currently we only have trunk)\nUpdate the website with new git links and instructions\nUpdate the build to work with git\nAnnounce the change on the dev list for everyone who is not involved in the migration",
        "Issue Links": []
    },
    "OPENNLP-861": {
        "Key": "OPENNLP-861",
        "Summary": "Add Chi-Squared Data Indexer for Feature Selection",
        "Type": "New Feature",
        "Status": "Open",
        "Priority": "Minor",
        "Resolution": "Unresolved",
        "Affects Version/s": "1.6.0",
        "Fix Version/s": "None",
        "Component/s": "Machine Learning",
        "Assignee": null,
        "Reporter": "Joey Hong",
        "Created": "25/Aug/16 20:33",
        "Updated": "02/Nov/16 22:31",
        "Resolved": null,
        "Description": "Text classification will naturally produce a lot of features. A lot of them are independent of the category, and provide no real information gain in the classification.\nThe Chi-Squared feature selection method will allow features that do not pass a threshold for dependency to be removed from the feature list, keeping the feature list a reasonable size without significantly affecting the classification accuracy.",
        "Issue Links": []
    },
    "OPENNLP-862": {
        "Key": "OPENNLP-862",
        "Summary": "BRAT format packages do not handle punctuation correctly when training NER model",
        "Type": "Improvement",
        "Status": "Open",
        "Priority": "Minor",
        "Resolution": "Unresolved",
        "Affects Version/s": "1.6.0",
        "Fix Version/s": "None",
        "Component/s": "Formats",
        "Assignee": "J\u00f6rn Kottmann",
        "Reporter": "Gregory Werner",
        "Created": "28/Sep/16 13:32",
        "Updated": "25/Jan/17 14:47",
        "Resolved": null,
        "Description": "BRAT does not require preprocessing of text files in order to add annotations to text documents.  And this is great because I can feed documents from corpora I am given directly into BRAT.  If I have a line such as:\nResidence:   Athens, Georgia\nI would provide 2 annotations in BRAT, Athens and Georgia, and BRAT would generate the offset and everything would be fine.  \nIt appears though that I only get 1 entity correctly processed (and the other dropped) in OpenNLP with TokenNameFinderTrainer.brat, Georgia, because the comma is not separated from Athens.  I have 789 annotated raw, non pre-processed text documents from past efforts. I believe that OpenNLP should be able to handle lines like the above in the case of the BRAT format code.\nIt appears that BratNameSampleStream uses the WhitespaceTokenizer and that is what creates Athens, as a token.  I find that the SimpleTokenizer might perform better with BRAT through my limited testing of raw documents if the current general approach is held.",
        "Issue Links": []
    },
    "OPENNLP-863": {
        "Key": "OPENNLP-863",
        "Summary": "Create a tool to generate a man page for the CLI",
        "Type": "Improvement",
        "Status": "Closed",
        "Priority": "Minor",
        "Resolution": "Fixed",
        "Affects Version/s": "1.7.0",
        "Fix Version/s": "1.7.0",
        "Component/s": "Documentation",
        "Assignee": "William Colen",
        "Reporter": "William Colen",
        "Created": "15/Oct/16 22:00",
        "Updated": "20/Dec/16 15:32",
        "Resolved": "20/Dec/16 15:32",
        "Description": "The man page could be a Docbook that is appended to the current Docbook.",
        "Issue Links": []
    },
    "OPENNLP-864": {
        "Key": "OPENNLP-864",
        "Summary": "BRAT Name Finder shoud use same parameters as other tools",
        "Type": "Improvement",
        "Status": "Closed",
        "Priority": "Minor",
        "Resolution": "Fixed",
        "Affects Version/s": "None",
        "Fix Version/s": "1.7.0",
        "Component/s": "Command Line Interface",
        "Assignee": "J\u00f6rn Kottmann",
        "Reporter": "J\u00f6rn Kottmann",
        "Created": "17/Oct/16 22:42",
        "Updated": "18/Oct/16 17:58",
        "Resolved": "18/Oct/16 17:58",
        "Description": "The Brat Name Finder Annotator should change the command line interface to the same style as it is used in the brat format package.\nThe annotator needs to configure the tokenizer and sentence detector in case the user doesn't want to use defaults.",
        "Issue Links": []
    },
    "OPENNLP-865": {
        "Key": "OPENNLP-865",
        "Summary": "Add brat format support documentation for name finder",
        "Type": "Improvement",
        "Status": "Closed",
        "Priority": "Major",
        "Resolution": "Fixed",
        "Affects Version/s": "None",
        "Fix Version/s": "1.7.1",
        "Component/s": "Documentation,                                            Name Finder",
        "Assignee": "Peter Thygesen",
        "Reporter": "J\u00f6rn Kottmann",
        "Created": "18/Oct/16 09:52",
        "Updated": "08/Jan/17 18:04",
        "Resolved": "08/Jan/17 18:04",
        "Description": "It is possible to train the Name Finder with brat .ann and .txt files. The documentation should explain how this works so new users can use this feature.",
        "Issue Links": [
            "https://github.com/apache/opennlp/pull/35"
        ]
    },
    "OPENNLP-866": {
        "Key": "OPENNLP-866",
        "Summary": "Brat annotation server port should be configurable",
        "Type": "Improvement",
        "Status": "Closed",
        "Priority": "Minor",
        "Resolution": "Fixed",
        "Affects Version/s": "None",
        "Fix Version/s": "1.7.0",
        "Component/s": "None",
        "Assignee": null,
        "Reporter": "J\u00f6rn Kottmann",
        "Created": "18/Oct/16 19:18",
        "Updated": "18/Oct/16 19:19",
        "Resolved": "18/Oct/16 19:19",
        "Description": "There should be an option to change the default port of the brat annotation service.",
        "Issue Links": []
    },
    "OPENNLP-867": {
        "Key": "OPENNLP-867",
        "Summary": "Move brat ner annotator to opennlp.git",
        "Type": "Task",
        "Status": "Closed",
        "Priority": "Minor",
        "Resolution": "Fixed",
        "Affects Version/s": "1.7.0",
        "Fix Version/s": "1.7.0",
        "Component/s": "Name Finder",
        "Assignee": "J\u00f6rn Kottmann",
        "Reporter": "J\u00f6rn Kottmann",
        "Created": "19/Oct/16 21:25",
        "Updated": "02/Nov/16 18:07",
        "Resolved": "02/Nov/16 18:07",
        "Description": "The brat ner annotator service should be included in the OpenNLP Tools release distribution. For that it has to be moved from opennlp-sandbox.git to opennlp.git",
        "Issue Links": []
    },
    "OPENNLP-868": {
        "Key": "OPENNLP-868",
        "Summary": "OntoNotes4NameFinderEval.evalEnglishPersonNameFinder test fail",
        "Type": "Bug",
        "Status": "Closed",
        "Priority": "Trivial",
        "Resolution": "Fixed",
        "Affects Version/s": "1.6.0",
        "Fix Version/s": "1.7.0",
        "Component/s": "Name Finder",
        "Assignee": "J\u00f6rn Kottmann",
        "Reporter": "J\u00f6rn Kottmann",
        "Created": "19/Oct/16 21:46",
        "Updated": "19/Oct/16 22:02",
        "Resolved": "19/Oct/16 22:02",
        "Description": "For some reason does this test fail in the latest trunk and 1.6.0 version. Both compute exactly this 0.8299903903167106 F1 value.\nThe test should be updated to not fail anymore.",
        "Issue Links": []
    },
    "OPENNLP-869": {
        "Key": "OPENNLP-869",
        "Summary": "Remove \"Couldn't find parse for\" from parser",
        "Type": "Improvement",
        "Status": "Closed",
        "Priority": "Minor",
        "Resolution": "Fixed",
        "Affects Version/s": "1.6.0",
        "Fix Version/s": "1.7.0",
        "Component/s": "Parser",
        "Assignee": "J\u00f6rn Kottmann",
        "Reporter": "J\u00f6rn Kottmann",
        "Created": "20/Oct/16 14:22",
        "Updated": "27/Oct/16 20:20",
        "Resolved": "27/Oct/16 20:20",
        "Description": "The message is printed to stdout and might confuse users. The parser is intended to be used solely by API and in case a parse can't be found the application using it has to handle this case (e.g. inform the user).",
        "Issue Links": []
    },
    "OPENNLP-870": {
        "Key": "OPENNLP-870",
        "Summary": "Please Make ContextGenerator a Generic Type",
        "Type": "Improvement",
        "Status": "Closed",
        "Priority": "Minor",
        "Resolution": "Fixed",
        "Affects Version/s": "None",
        "Fix Version/s": "1.7.0",
        "Component/s": "Machine Learning",
        "Assignee": "J\u00f6rn Kottmann",
        "Reporter": "Daniel Russ",
        "Created": "21/Oct/16 13:37",
        "Updated": "25/Dec/16 20:35",
        "Resolved": "25/Dec/16 20:35",
        "Description": "public interface ContextGenerator<T> {\n  /**\n\nBuilds up the list of contextual predicates given an Object.\n   */\n  public String[] getContext(T o);\n}\n\nIf this is a generic method, it makes writing ContextGenerators easier to debug at compile time.",
        "Issue Links": [
            "https://github.com/apache/opennlp/pull/19"
        ]
    },
    "OPENNLP-871": {
        "Key": "OPENNLP-871",
        "Summary": "Clean up code base for release",
        "Type": "Improvement",
        "Status": "Closed",
        "Priority": "Trivial",
        "Resolution": "Fixed",
        "Affects Version/s": "None",
        "Fix Version/s": "1.7.0",
        "Component/s": "None",
        "Assignee": "Suneel Marthi",
        "Reporter": "J\u00f6rn Kottmann",
        "Created": "28/Oct/16 16:20",
        "Updated": "25/Dec/16 20:35",
        "Resolved": "25/Dec/16 20:34",
        "Description": "The usual pre-release code clea nup with tools like eclipse/intellij should be performed.\nClean ups:\n\nRemove unused imports\nRemove unnecessary casts\nRemove trailing white spaces",
        "Issue Links": [
            "https://github.com/apache/opennlp/pull/11",
            "https://github.com/apache/opennlp/pull/12",
            "https://github.com/apache/opennlp/pull/17",
            "https://github.com/apache/opennlp/pull/20"
        ]
    },
    "OPENNLP-872": {
        "Key": "OPENNLP-872",
        "Summary": "Use try with resourcs where possible",
        "Type": "Improvement",
        "Status": "Closed",
        "Priority": "Trivial",
        "Resolution": "Fixed",
        "Affects Version/s": "None",
        "Fix Version/s": "1.7.0",
        "Component/s": "None",
        "Assignee": "J\u00f6rn Kottmann",
        "Reporter": "J\u00f6rn Kottmann",
        "Created": "28/Oct/16 19:51",
        "Updated": "28/Oct/16 21:55",
        "Resolved": "28/Oct/16 21:55",
        "Description": "Try with resources should be used where it is possible or currently missing. This will help to improve the resource handling (and places where it is not so great) and will make the code more readable.",
        "Issue Links": []
    },
    "OPENNLP-873": {
        "Key": "OPENNLP-873",
        "Summary": "ChunkerCrossValidator should use model beam size",
        "Type": "Improvement",
        "Status": "Closed",
        "Priority": "Minor",
        "Resolution": "Fixed",
        "Affects Version/s": "1.6.0",
        "Fix Version/s": "1.7.0",
        "Component/s": "Chunker",
        "Assignee": "J\u00f6rn Kottmann",
        "Reporter": "J\u00f6rn Kottmann",
        "Created": "31/Oct/16 17:17",
        "Updated": "31/Oct/16 17:25",
        "Resolved": "31/Oct/16 17:25",
        "Description": "The Chunker Cross Validator currently uses a deprecated method to instantiate the ChunkerME with the default beam size. The user can provide the beam size as part of the model, and that value should also be used for cross validation. \nThis change can influence the outcome of the cross validation, because now the specified beam size is used and not the default.",
        "Issue Links": []
    },
    "OPENNLP-874": {
        "Key": "OPENNLP-874",
        "Summary": "Refactor usage of deprecated training API",
        "Type": "Improvement",
        "Status": "Closed",
        "Priority": "Minor",
        "Resolution": "Fixed",
        "Affects Version/s": "1.6.0",
        "Fix Version/s": "1.7.0",
        "Component/s": "None",
        "Assignee": "J\u00f6rn Kottmann",
        "Reporter": "J\u00f6rn Kottmann",
        "Created": "31/Oct/16 17:28",
        "Updated": "31/Oct/16 18:30",
        "Resolved": "31/Oct/16 18:30",
        "Description": "Most the OpenNLP components still use traning API which was deprecated. This usage can be replaced with the new API and that has to be done so the old API can be removed.",
        "Issue Links": []
    },
    "OPENNLP-875": {
        "Key": "OPENNLP-875",
        "Summary": "Remove deprecated training API",
        "Type": "Improvement",
        "Status": "Closed",
        "Priority": "Trivial",
        "Resolution": "Fixed",
        "Affects Version/s": "1.6.0",
        "Fix Version/s": "1.7.0",
        "Component/s": "Machine Learning",
        "Assignee": "J\u00f6rn Kottmann",
        "Reporter": "J\u00f6rn Kottmann",
        "Created": "31/Oct/16 17:38",
        "Updated": "01/Nov/16 10:17",
        "Resolved": "01/Nov/16 10:17",
        "Description": "Some parts of the training API were deprecated with the 1.6.0 release, and those parts should be removed. They have never available in the new opennlp.tools.ml package without being deprecated and should have no to very little usage around our user base. The migration to the new API is also very easy and can be done quickly.",
        "Issue Links": []
    },
    "OPENNLP-876": {
        "Key": "OPENNLP-876",
        "Summary": "Deprecate opennlp.tools.util.BeamSearch",
        "Type": "Improvement",
        "Status": "Closed",
        "Priority": "Minor",
        "Resolution": "Fixed",
        "Affects Version/s": "1.6.0",
        "Fix Version/s": "1.7.0",
        "Component/s": "Machine Learning",
        "Assignee": "J\u00f6rn Kottmann",
        "Reporter": "J\u00f6rn Kottmann",
        "Created": "02/Nov/16 14:23",
        "Updated": "02/Nov/16 17:30",
        "Resolved": "02/Nov/16 17:30",
        "Description": "The was copied to the opennlp.tools.ml package and should be removed, to avoid breaking user code it has to be deprecated before it can be removed.",
        "Issue Links": []
    },
    "OPENNLP-877": {
        "Key": "OPENNLP-877",
        "Summary": "Automate SourceForge model regression test",
        "Type": "Improvement",
        "Status": "Closed",
        "Priority": "Minor",
        "Resolution": "Fixed",
        "Affects Version/s": "1.6.0",
        "Fix Version/s": "1.7.0",
        "Component/s": "Build, Packaging and Test",
        "Assignee": "J\u00f6rn Kottmann",
        "Reporter": "J\u00f6rn Kottmann",
        "Created": "02/Nov/16 17:35",
        "Updated": "19/Dec/16 09:40",
        "Resolved": "19/Dec/16 09:40",
        "Description": "This tests has to be done always manually and it would be nice to have it automated. The more tests we can automate the less time has to be invested to perform manual tests for each RC (time core contributors often don't have or could better spent on other tasks).",
        "Issue Links": []
    },
    "OPENNLP-878": {
        "Key": "OPENNLP-878",
        "Summary": "Remove deprecated POSDictionaryWriter class",
        "Type": "Improvement",
        "Status": "Closed",
        "Priority": "Minor",
        "Resolution": "Fixed",
        "Affects Version/s": "1.7.0",
        "Fix Version/s": "1.7.0",
        "Component/s": "POS Tagger",
        "Assignee": "J\u00f6rn Kottmann",
        "Reporter": "J\u00f6rn Kottmann",
        "Created": "02/Nov/16 21:28",
        "Updated": "02/Nov/16 21:33",
        "Resolved": "02/Nov/16 21:33",
        "Description": "This class has been replaced with the new Dictionary for 1.5.x already. It is no longer used and should be removed.",
        "Issue Links": []
    },
    "OPENNLP-879": {
        "Key": "OPENNLP-879",
        "Summary": "Use PriorityQueue instead of Heap in BeamSearch",
        "Type": "Improvement",
        "Status": "Closed",
        "Priority": "Trivial",
        "Resolution": "Fixed",
        "Affects Version/s": "None",
        "Fix Version/s": "1.7.0",
        "Component/s": "Machine Learning",
        "Assignee": "J\u00f6rn Kottmann",
        "Reporter": "J\u00f6rn Kottmann",
        "Created": "02/Nov/16 22:11",
        "Updated": "07/Nov/16 18:53",
        "Resolved": "07/Nov/16 18:53",
        "Description": "It was pointed out in OPENNLP-830 that we can just use PriorityQueue in BeamSeach instead of the cutstom Heap implementation. This class is slightly faster of around 2- 3% with the Name Finder, not speed increase with the POSTagger.\nIn the end this will allow us to remove the custom Heap implementations and the Java version will be maintained for us.",
        "Issue Links": []
    },
    "OPENNLP-880": {
        "Key": "OPENNLP-880",
        "Summary": "Refactor the GIS trainer integration",
        "Type": "Improvement",
        "Status": "Closed",
        "Priority": "Minor",
        "Resolution": "Fixed",
        "Affects Version/s": "None",
        "Fix Version/s": "1.7.1",
        "Component/s": "None",
        "Assignee": null,
        "Reporter": "J\u00f6rn Kottmann",
        "Created": "07/Nov/16 09:12",
        "Updated": "09/Jan/17 22:57",
        "Resolved": "09/Jan/17 22:57",
        "Description": "The GIS code was never reshaped to fit properly into the new Training API. There are a couple of issues e.g. not using parameters which should be fixed.\nTODO: Update this description and list the changes",
        "Issue Links": [
            "https://github.com/apache/opennlp/pull/14"
        ]
    },
    "OPENNLP-881": {
        "Key": "OPENNLP-881",
        "Summary": "Improve errror reporting in Brat format parser",
        "Type": "Improvement",
        "Status": "Closed",
        "Priority": "Minor",
        "Resolution": "Fixed",
        "Affects Version/s": "None",
        "Fix Version/s": "1.7.0",
        "Component/s": "Formats",
        "Assignee": "J\u00f6rn Kottmann",
        "Reporter": "J\u00f6rn Kottmann",
        "Created": "07/Nov/16 16:26",
        "Updated": "21/Dec/16 10:25",
        "Resolved": "21/Dec/16 10:25",
        "Description": "The Brat format parser process lots of different files usually. In case there is an error it should always include the file name in the exception so the user has a chance to track down the error easily (e.g. without modifying OpenNLP code).",
        "Issue Links": []
    },
    "OPENNLP-882": {
        "Key": "OPENNLP-882",
        "Summary": "Remove deprecated code from opennlp.tools.util.PlainTextByLineStream",
        "Type": "Improvement",
        "Status": "Closed",
        "Priority": "Major",
        "Resolution": "Fixed",
        "Affects Version/s": "1.7.0",
        "Fix Version/s": "1.7.0",
        "Component/s": "None",
        "Assignee": "William Colen",
        "Reporter": "William Colen",
        "Created": "09/Nov/16 22:13",
        "Updated": "21/Dec/16 01:10",
        "Resolved": "21/Dec/16 01:10",
        "Description": "We can refactor opennlp.tools.util.PlainTextByLineStream by removing deprecated constructors. This change affect many classes all over the code.",
        "Issue Links": [
            "/jira/browse/OPENNLP-888"
        ]
    },
    "OPENNLP-883": {
        "Key": "OPENNLP-883",
        "Summary": "Remove deprecated methods from the POS Tagger",
        "Type": "Improvement",
        "Status": "Closed",
        "Priority": "Major",
        "Resolution": "Fixed",
        "Affects Version/s": "None",
        "Fix Version/s": "1.7.0",
        "Component/s": "POS Tagger",
        "Assignee": "J\u00f6rn Kottmann",
        "Reporter": "J\u00f6rn Kottmann",
        "Created": "10/Nov/16 00:13",
        "Updated": "22/Nov/16 00:40",
        "Resolved": "22/Nov/16 00:40",
        "Description": "All deprecated methods which can be removed will be removed.",
        "Issue Links": []
    },
    "OPENNLP-884": {
        "Key": "OPENNLP-884",
        "Summary": "Remove deprecated methods from the Chunker",
        "Type": "Improvement",
        "Status": "Closed",
        "Priority": "Major",
        "Resolution": "Fixed",
        "Affects Version/s": "None",
        "Fix Version/s": "1.7.0",
        "Component/s": "Chunker",
        "Assignee": "J\u00f6rn Kottmann",
        "Reporter": "J\u00f6rn Kottmann",
        "Created": "10/Nov/16 00:14",
        "Updated": "22/Nov/16 00:31",
        "Resolved": "22/Nov/16 00:31",
        "Description": "All deprecated methods which can be removed will be removed.",
        "Issue Links": []
    },
    "OPENNLP-885": {
        "Key": "OPENNLP-885",
        "Summary": "Remove deprecated methods from Doccat",
        "Type": "Improvement",
        "Status": "Closed",
        "Priority": "Major",
        "Resolution": "Fixed",
        "Affects Version/s": "None",
        "Fix Version/s": "1.7.0",
        "Component/s": "Doccat",
        "Assignee": "J\u00f6rn Kottmann",
        "Reporter": "J\u00f6rn Kottmann",
        "Created": "10/Nov/16 00:16",
        "Updated": "15/Dec/16 16:55",
        "Resolved": "15/Dec/16 16:55",
        "Description": "All deprecated methods which can be removed will be removed.",
        "Issue Links": []
    },
    "OPENNLP-886": {
        "Key": "OPENNLP-886",
        "Summary": "Remove deprecated methods from the parser",
        "Type": "Improvement",
        "Status": "Closed",
        "Priority": "Major",
        "Resolution": "Fixed",
        "Affects Version/s": "None",
        "Fix Version/s": "1.7.0",
        "Component/s": "Parser",
        "Assignee": "J\u00f6rn Kottmann",
        "Reporter": "J\u00f6rn Kottmann",
        "Created": "10/Nov/16 00:17",
        "Updated": "20/Dec/16 22:11",
        "Resolved": "20/Dec/16 22:11",
        "Description": "All deprecated methods which can be removed will be removed.",
        "Issue Links": []
    },
    "OPENNLP-887": {
        "Key": "OPENNLP-887",
        "Summary": "Replace the Cache class with a LinkedHashMap",
        "Type": "Improvement",
        "Status": "Closed",
        "Priority": "Minor",
        "Resolution": "Fixed",
        "Affects Version/s": "None",
        "Fix Version/s": "1.7.0",
        "Component/s": "None",
        "Assignee": "Suneel Marthi",
        "Reporter": "J\u00f6rn Kottmann",
        "Created": "10/Nov/16 00:21",
        "Updated": "19/Dec/16 22:30",
        "Resolved": "19/Dec/16 22:30",
        "Description": "The existing cache implementation could be replaced with java.util.LinkedHashMap. This change would replace our custom implementation with an implementation which will be maintained for us.\nTo have the same behaviour as our implementation LinkedHashMap must be subclasses. The LinkedHashMap.removeEldestEntry must be overwritten and return true if size limit is reached.\nThis could be something like this:\nimport java.util.LinkedHashMap;\nimport java.util.Iterator;\nimport java.util.Map;\npublic class Cache<K, V> extends LinkedHashMap<K,V> {\n    private final int capacity;\n    public Cache(int capacity) \n{\n        this.capacity = capacity;\n    }\n\n    @Override\n    protected boolean removeEldestEntry(Map.Entry<K,V> eldest) \n{\n        return this.size() > this.capacity;\n    }\n}",
        "Issue Links": [
            "https://github.com/apache/opennlp/pull/9"
        ]
    },
    "OPENNLP-888": {
        "Key": "OPENNLP-888",
        "Summary": "CLONE - Remove deprecated code from opennlp.tools.util.PlainTextByLineStream",
        "Type": "Improvement",
        "Status": "Closed",
        "Priority": "Major",
        "Resolution": "Abandoned",
        "Affects Version/s": "1.7.0",
        "Fix Version/s": "1.7.0",
        "Component/s": "None",
        "Assignee": "William Colen",
        "Reporter": "Brandon Tristan Reid",
        "Created": "17/Nov/16 13:17",
        "Updated": "17/Nov/16 13:19",
        "Resolved": "17/Nov/16 13:19",
        "Description": "We can refactor opennlp.tools.util.PlainTextByLineStream by removing deprecated constructors. This change affect many classes all over the code.",
        "Issue Links": [
            "/jira/browse/OPENNLP-882"
        ]
    },
    "OPENNLP-889": {
        "Key": "OPENNLP-889",
        "Summary": "Add release notes for 1.7.0",
        "Type": "Documentation",
        "Status": "Closed",
        "Priority": "Major",
        "Resolution": "Fixed",
        "Affects Version/s": "1.7.0",
        "Fix Version/s": "1.7.0",
        "Component/s": "None",
        "Assignee": "J\u00f6rn Kottmann",
        "Reporter": "Rodrigo Agerri",
        "Created": "23/Nov/16 11:55",
        "Updated": "27/Dec/16 10:59",
        "Resolved": "27/Dec/16 10:59",
        "Description": "Update documentation on release notes for the incoming 1.7.0 release.",
        "Issue Links": []
    },
    "OPENNLP-890": {
        "Key": "OPENNLP-890",
        "Summary": "Create CLI for language model API",
        "Type": "Task",
        "Status": "Closed",
        "Priority": "Major",
        "Resolution": "Fixed",
        "Affects Version/s": "None",
        "Fix Version/s": "1.7.2",
        "Component/s": "Command Line Interface",
        "Assignee": "Tommaso Teofili",
        "Reporter": "Tommaso Teofili",
        "Created": "06/Dec/16 16:11",
        "Updated": "27/Jan/17 14:43",
        "Resolved": "27/Jan/17 14:39",
        "Description": "It should be possible to use LanguageModel API from CLI, therefore a runner like the existing ones for other APIs should be created for language modelling.",
        "Issue Links": []
    },
    "OPENNLP-891": {
        "Key": "OPENNLP-891",
        "Summary": "Make the TokenClassFeatureGenerator construction configurable",
        "Type": "Task",
        "Status": "Closed",
        "Priority": "Minor",
        "Resolution": "Fixed",
        "Affects Version/s": "None",
        "Fix Version/s": "1.7.0",
        "Component/s": "Name Finder",
        "Assignee": "J\u00f6rn Kottmann",
        "Reporter": "Jeff Zemerick",
        "Created": "13/Dec/16 22:02",
        "Updated": "15/Dec/16 15:17",
        "Resolved": "15/Dec/16 15:17",
        "Description": "Add a boolean field for configuring the generateWordAndClassFeature argument of the TokenClassFeatureGenerator constructor. There is a currently a TODO in the code for this change.",
        "Issue Links": [
            "https://github.com/apache/opennlp/pull/8"
        ]
    },
    "OPENNLP-892": {
        "Key": "OPENNLP-892",
        "Summary": "Add a Entity-Relationship Extraction component",
        "Type": "New Feature",
        "Status": "Open",
        "Priority": "Major",
        "Resolution": "Unresolved",
        "Affects Version/s": "None",
        "Fix Version/s": "None",
        "Component/s": "None",
        "Assignee": null,
        "Reporter": "J\u00f6rn Kottmann",
        "Created": "15/Dec/16 14:32",
        "Updated": "23/Jul/19 20:27",
        "Resolved": null,
        "Description": "It would be very nice to have support for entity relation extraction in OpenNLP.",
        "Issue Links": []
    },
    "OPENNLP-893": {
        "Key": "OPENNLP-893",
        "Summary": "opennlp.sh should add all jars in lib folder to classpath",
        "Type": "Improvement",
        "Status": "Closed",
        "Priority": "Minor",
        "Resolution": "Fixed",
        "Affects Version/s": "None",
        "Fix Version/s": "1.7.0",
        "Component/s": "Build, Packaging and Test",
        "Assignee": "Peter Thygesen",
        "Reporter": "J\u00f6rn Kottmann",
        "Created": "19/Dec/16 21:36",
        "Updated": "19/Dec/16 22:52",
        "Resolved": "19/Dec/16 22:52",
        "Description": "opennlp command did not load my jar containing some custom feature generators even though I placed it in the lib folder.\ntrunk:\n$JAVACMD Xmx1024m -jar $OPENNLP_HOME/lib/opennlp-tools*.jar $@\nwill not load any other jars.\nI made a patch that loads alle the *.jars in lib.",
        "Issue Links": []
    },
    "OPENNLP-894": {
        "Key": "OPENNLP-894",
        "Summary": "Switch from Java 7 to Java 8",
        "Type": "Improvement",
        "Status": "Closed",
        "Priority": "Major",
        "Resolution": "Fixed",
        "Affects Version/s": "None",
        "Fix Version/s": "1.7.0",
        "Component/s": "Build, Packaging and Test",
        "Assignee": "Suneel Marthi",
        "Reporter": "J\u00f6rn Kottmann",
        "Created": "19/Dec/16 23:48",
        "Updated": "20/Dec/16 14:12",
        "Resolved": "20/Dec/16 14:12",
        "Description": "Java 7 is now End Of Life and OpenNLP should be updated to use Java 8.\n\nUpdate the POMs\nAdd comment to README / NOTES files",
        "Issue Links": [
            "https://github.com/apache/opennlp/pull/10"
        ]
    },
    "OPENNLP-895": {
        "Key": "OPENNLP-895",
        "Summary": "Include brat and morfologik modules in distribution",
        "Type": "Task",
        "Status": "Closed",
        "Priority": "Major",
        "Resolution": "Fixed",
        "Affects Version/s": "None",
        "Fix Version/s": "1.7.0",
        "Component/s": "None",
        "Assignee": "Suneel Marthi",
        "Reporter": "J\u00f6rn Kottmann",
        "Created": "20/Dec/16 22:19",
        "Updated": "24/Dec/16 17:34",
        "Resolved": "24/Dec/16 16:28",
        "Description": "Two new modules where added to the main project and need to be included in the distribution.\nThis also includes updating the NOTICE / LICENSE files accordingly.",
        "Issue Links": [
            "https://github.com/apache/opennlp/pull/18"
        ]
    },
    "OPENNLP-896": {
        "Key": "OPENNLP-896",
        "Summary": "Update compatibility check to still load 1.5.x models",
        "Type": "Bug",
        "Status": "Closed",
        "Priority": "Minor",
        "Resolution": "Fixed",
        "Affects Version/s": "None",
        "Fix Version/s": "1.7.0",
        "Component/s": "None",
        "Assignee": "J\u00f6rn Kottmann",
        "Reporter": "J\u00f6rn Kottmann",
        "Created": "21/Dec/16 09:18",
        "Updated": "21/Dec/16 10:48",
        "Resolved": "21/Dec/16 10:48",
        "Description": null,
        "Issue Links": []
    },
    "OPENNLP-897": {
        "Key": "OPENNLP-897",
        "Summary": "Update brat annotator to jersey 2.x",
        "Type": "Improvement",
        "Status": "Closed",
        "Priority": "Minor",
        "Resolution": "Fixed",
        "Affects Version/s": "None",
        "Fix Version/s": "1.7.0",
        "Component/s": "None",
        "Assignee": "J\u00f6rn Kottmann",
        "Reporter": "J\u00f6rn Kottmann",
        "Created": "21/Dec/16 13:53",
        "Updated": "25/Dec/16 20:07",
        "Resolved": "25/Dec/16 20:07",
        "Description": null,
        "Issue Links": []
    },
    "OPENNLP-898": {
        "Key": "OPENNLP-898",
        "Summary": "Rename opennlp package to org.apache.opennlp",
        "Type": "Improvement",
        "Status": "Closed",
        "Priority": "Major",
        "Resolution": "Won't Fix",
        "Affects Version/s": "1.6.0",
        "Fix Version/s": "1.7.1",
        "Component/s": "Build, Packaging and Test",
        "Assignee": "Suneel Marthi",
        "Reporter": "J\u00f6rn Kottmann",
        "Created": "21/Dec/16 18:02",
        "Updated": "02/Jan/17 23:07",
        "Resolved": "02/Jan/17 23:07",
        "Description": "Disadvantage of this change is that it will break all user code",
        "Issue Links": [
            "https://github.com/apache/opennlp/pull/23"
        ]
    },
    "OPENNLP-899": {
        "Key": "OPENNLP-899",
        "Summary": "Replace deprecated code from Tokenizer Trainer",
        "Type": "Improvement",
        "Status": "Closed",
        "Priority": "Major",
        "Resolution": "Fixed",
        "Affects Version/s": "1.6.0",
        "Fix Version/s": "1.7.0",
        "Component/s": "Tokenizer",
        "Assignee": "Suneel Marthi",
        "Reporter": "Suneel Marthi",
        "Created": "21/Dec/16 18:12",
        "Updated": "22/Dec/16 15:51",
        "Resolved": "22/Dec/16 15:51",
        "Description": "Replace deprecated code from Tokenizer module",
        "Issue Links": [
            "https://github.com/apache/opennlp/pull/13"
        ]
    },
    "OPENNLP-900": {
        "Key": "OPENNLP-900",
        "Summary": "DictionaryLemmatizer dictionary and LemmatizerME training format different",
        "Type": "Bug",
        "Status": "Closed",
        "Priority": "Minor",
        "Resolution": "Fixed",
        "Affects Version/s": "1.6.0,                                            1.7.0",
        "Fix Version/s": "1.7.0",
        "Component/s": "Lemmatizer",
        "Assignee": null,
        "Reporter": "Daniel Russ",
        "Created": "22/Dec/16 15:31",
        "Updated": "22/Dec/16 16:32",
        "Resolved": "22/Dec/16 16:32",
        "Description": "The LemmatizerME training data has a format of word\\tpos\\tlemma.\nThe DictionaryLemmatizer format is word\\tlemma\\tpos.\nCan we make them the same.",
        "Issue Links": [
            "https://github.com/apache/opennlp/pull/16"
        ]
    },
    "OPENNLP-901": {
        "Key": "OPENNLP-901",
        "Summary": "Replace references to deprecated NameFinderME.train()",
        "Type": "Improvement",
        "Status": "Closed",
        "Priority": "Major",
        "Resolution": "Fixed",
        "Affects Version/s": "1.6.0",
        "Fix Version/s": "1.7.0",
        "Component/s": "Name Finder",
        "Assignee": "Suneel Marthi",
        "Reporter": "Suneel Marthi",
        "Created": "24/Dec/16 04:15",
        "Updated": "25/Dec/16 19:28",
        "Resolved": "25/Dec/16 19:27",
        "Description": "Replace references to deprecated NameFinderME.train() and remove the deprecated method.",
        "Issue Links": [
            "https://github.com/apache/opennlp/pull/21"
        ]
    },
    "OPENNLP-902": {
        "Key": "OPENNLP-902",
        "Summary": "Morfologi Add-On should be compatible with Tools 1.7.0",
        "Type": "Improvement",
        "Status": "Closed",
        "Priority": "Major",
        "Resolution": "Fixed",
        "Affects Version/s": "1.7.0",
        "Fix Version/s": "1.7.0",
        "Component/s": "Morfologik Addon",
        "Assignee": "William Colen",
        "Reporter": "William Colen",
        "Created": "27/Dec/16 14:09",
        "Updated": "28/Dec/16 03:46",
        "Resolved": "28/Dec/16 03:46",
        "Description": null,
        "Issue Links": []
    },
    "OPENNLP-903": {
        "Key": "OPENNLP-903",
        "Summary": "Upgrade UIMA module to OpenNLP 1.7.0",
        "Type": "Task",
        "Status": "Closed",
        "Priority": "Major",
        "Resolution": "Fixed",
        "Affects Version/s": "None",
        "Fix Version/s": "1.7.0",
        "Component/s": "UIMA Integration",
        "Assignee": "Tommaso Teofili",
        "Reporter": "Tommaso Teofili",
        "Created": "27/Dec/16 14:13",
        "Updated": "30/Dec/16 18:52",
        "Resolved": "27/Dec/16 14:17",
        "Description": "OpenNLP UIMA integration should not depend on hardcoded version of opennlp-tools.",
        "Issue Links": []
    },
    "OPENNLP-904": {
        "Key": "OPENNLP-904",
        "Summary": "Adding new functionality to know all possible lemmas given a word and pos tag pair",
        "Type": "New Feature",
        "Status": "Closed",
        "Priority": "Minor",
        "Resolution": "Fixed",
        "Affects Version/s": "None",
        "Fix Version/s": "1.8.0",
        "Component/s": "Lemmatizer",
        "Assignee": "Rodrigo Agerri",
        "Reporter": "Rodrigo Agerri",
        "Created": "30/Dec/16 15:00",
        "Updated": "03/Mar/17 09:37",
        "Resolved": "03/Mar/17 09:12",
        "Description": "Currently the various lemmatizers (DictionaryLemmatizer, LemmatizerME and MorfologikLemmatizer) do not allow to obtain all posible lemmas given a word and postag pair. This functionality is useful and should be added.",
        "Issue Links": [
            "https://github.com/apache/opennlp/pull/112"
        ]
    },
    "OPENNLP-905": {
        "Key": "OPENNLP-905",
        "Summary": "Binary distribution is missing LICENSE and NOTICE files",
        "Type": "Bug",
        "Status": "Closed",
        "Priority": "Major",
        "Resolution": "Fixed",
        "Affects Version/s": "1.7.0",
        "Fix Version/s": "1.7.0",
        "Component/s": "Build, Packaging and Test",
        "Assignee": "J\u00f6rn Kottmann",
        "Reporter": "J\u00f6rn Kottmann",
        "Created": "31/Dec/16 16:54",
        "Updated": "31/Dec/16 18:52",
        "Resolved": "31/Dec/16 18:50",
        "Description": null,
        "Issue Links": []
    },
    "OPENNLP-906": {
        "Key": "OPENNLP-906",
        "Summary": "Third-party chunker model from 1.6.0 fails to load in 1.7.0-rc-1",
        "Type": "Bug",
        "Status": "Closed",
        "Priority": "Major",
        "Resolution": "Fixed",
        "Affects Version/s": "1.7.0",
        "Fix Version/s": "1.7.0",
        "Component/s": "Chunker",
        "Assignee": "J\u00f6rn Kottmann",
        "Reporter": "Richard Eckart de Castilho",
        "Created": "31/Dec/16 18:14",
        "Updated": "31/Dec/16 19:49",
        "Resolved": "31/Dec/16 19:49",
        "Description": "I have tried upgrading DKPro Core to the RC1 and most of\nthe tests work, however, in one case I get this message:\n\nCaused by: opennlp.tools.util.InvalidFormatException: Model version 1.6.0 is not supported by this (1.7.0) version of OpenNLP!\n        at opennlp.tools.util.model.BaseModel.validateArtifactMap(BaseModel.java:428)\n        at opennlp.tools.chunker.ChunkerModel.validateArtifactMap(ChunkerModel.java:88)\n        at opennlp.tools.util.model.BaseModel.checkArtifactMap(BaseModel.java:493)\n        ... 48 more\n\n\nThe problematic model is a third-party chunker model:\nhttp://ixa2.si.ehu.es/ixa-pipes/models/chunk-models-1.1.0.tar.gz\nfile: en-perceptron-conll00.bin\nI believe that 1.6.0 models should still work for 1.7.0, right?",
        "Issue Links": []
    },
    "OPENNLP-907": {
        "Key": "OPENNLP-907",
        "Summary": "Binary distribution misplaced issuesFixed folder",
        "Type": "Bug",
        "Status": "Closed",
        "Priority": "Major",
        "Resolution": "Fixed",
        "Affects Version/s": "1.7.0",
        "Fix Version/s": "1.7.1",
        "Component/s": "Build, Packaging and Test",
        "Assignee": "William Colen",
        "Reporter": "William Colen",
        "Created": "02/Jan/17 11:34",
        "Updated": "02/Jan/17 12:28",
        "Resolved": "02/Jan/17 12:28",
        "Description": null,
        "Issue Links": []
    },
    "OPENNLP-908": {
        "Key": "OPENNLP-908",
        "Summary": "Remove deprecated code form opennlp.util package",
        "Type": "Improvement",
        "Status": "Closed",
        "Priority": "Trivial",
        "Resolution": "Fixed",
        "Affects Version/s": "1.7.0",
        "Fix Version/s": "1.7.1",
        "Component/s": "None",
        "Assignee": "J\u00f6rn Kottmann",
        "Reporter": "J\u00f6rn Kottmann",
        "Created": "02/Jan/17 12:47",
        "Updated": "03/Jan/17 04:13",
        "Resolved": "02/Jan/17 21:11",
        "Description": "There are a few classes which are not used anymore or have been moved to other places. Lets remove that code now.",
        "Issue Links": [
            "https://github.com/apache/opennlp/pull/24"
        ]
    },
    "OPENNLP-909": {
        "Key": "OPENNLP-909",
        "Summary": "Create a README.md for Github",
        "Type": "Improvement",
        "Status": "Closed",
        "Priority": "Major",
        "Resolution": "Fixed",
        "Affects Version/s": "1.7.0",
        "Fix Version/s": "1.7.1",
        "Component/s": "None",
        "Assignee": "Suneel Marthi",
        "Reporter": "J\u00f6rn Kottmann",
        "Created": "02/Jan/17 13:23",
        "Updated": "03/Jan/17 20:56",
        "Resolved": "03/Jan/17 20:55",
        "Description": null,
        "Issue Links": [
            "https://github.com/apache/opennlp/pull/32"
        ]
    },
    "OPENNLP-910": {
        "Key": "OPENNLP-910",
        "Summary": "Add checkstyle",
        "Type": "Improvement",
        "Status": "Closed",
        "Priority": "Minor",
        "Resolution": "Implemented",
        "Affects Version/s": "None",
        "Fix Version/s": "1.7.1",
        "Component/s": "Build, Packaging and Test",
        "Assignee": "Suneel Marthi",
        "Reporter": "J\u00f6rn Kottmann",
        "Created": "02/Jan/17 19:10",
        "Updated": "07/Jan/17 15:08",
        "Resolved": "06/Jan/17 22:18",
        "Description": "It would be nice if checkstyle could enforce a few of our code style rules, this will give us easier to merge PRs and will improve the code base.\nOne thing we should add is no tab indentation.",
        "Issue Links": [
            "https://github.com/apache/opennlp/pull/29",
            "https://github.com/apache/opennlp/pull/36",
            "https://github.com/apache/opennlp/pull/37"
        ]
    },
    "OPENNLP-911": {
        "Key": "OPENNLP-911",
        "Summary": "Enable Travis CI integration",
        "Type": "New Feature",
        "Status": "Closed",
        "Priority": "Major",
        "Resolution": "Implemented",
        "Affects Version/s": "1.7.0",
        "Fix Version/s": "1.7.1",
        "Component/s": "Build, Packaging and Test",
        "Assignee": "Suneel Marthi",
        "Reporter": "Suneel Marthi",
        "Created": "03/Jan/17 04:13",
        "Updated": "03/Jan/17 08:33",
        "Resolved": "03/Jan/17 08:33",
        "Description": "Enable Travis CI Integration",
        "Issue Links": [
            "https://github.com/apache/opennlp/pull/28"
        ]
    },
    "OPENNLP-912": {
        "Key": "OPENNLP-912",
        "Summary": "Add a rule based sentence detector",
        "Type": "Improvement",
        "Status": "Open",
        "Priority": "Major",
        "Resolution": "Unresolved",
        "Affects Version/s": "None",
        "Fix Version/s": "None",
        "Component/s": "None",
        "Assignee": null,
        "Reporter": "J\u00f6rn Kottmann",
        "Created": "03/Jan/17 11:04",
        "Updated": "28/Mar/22 14:41",
        "Resolved": null,
        "Description": "It would be nice to offer a simpler rule based sentence detector, in some languages this might work rather well.",
        "Issue Links": []
    },
    "OPENNLP-913": {
        "Key": "OPENNLP-913",
        "Summary": "Add non-AL 2.0 data to OpenNLP for testing",
        "Type": "Improvement",
        "Status": "Open",
        "Priority": "Major",
        "Resolution": "Unresolved",
        "Affects Version/s": "None",
        "Fix Version/s": "None",
        "Component/s": "None",
        "Assignee": null,
        "Reporter": "J\u00f6rn Kottmann",
        "Created": "03/Jan/17 16:18",
        "Updated": "08/Feb/17 12:28",
        "Resolved": null,
        "Description": "There are a couple of CONLL datasets which are used for testing. It would be nice to see what can be added to our git repository, even tough we can never release it.",
        "Issue Links": []
    },
    "OPENNLP-914": {
        "Key": "OPENNLP-914",
        "Summary": "Fix indentation and whitspaces throughout the code base",
        "Type": "Improvement",
        "Status": "Closed",
        "Priority": "Minor",
        "Resolution": "Fixed",
        "Affects Version/s": "None",
        "Fix Version/s": "1.7.1",
        "Component/s": "None",
        "Assignee": "J\u00f6rn Kottmann",
        "Reporter": "J\u00f6rn Kottmann",
        "Created": "03/Jan/17 16:34",
        "Updated": "06/Jan/17 22:14",
        "Resolved": "06/Jan/17 22:14",
        "Description": null,
        "Issue Links": [
            "https://github.com/apache/opennlp/pull/30"
        ]
    },
    "OPENNLP-915": {
        "Key": "OPENNLP-915",
        "Summary": "Replace occurrences of junit.framework.* with org.junit.*",
        "Type": "Improvement",
        "Status": "Closed",
        "Priority": "Major",
        "Resolution": "Fixed",
        "Affects Version/s": "1.7.0",
        "Fix Version/s": "1.7.1",
        "Component/s": "Build, Packaging and Test",
        "Assignee": "Suneel Marthi",
        "Reporter": "Suneel Marthi",
        "Created": "03/Jan/17 17:36",
        "Updated": "03/Jan/17 18:56",
        "Resolved": "03/Jan/17 18:53",
        "Description": "Replace occurrences of junit.framework.* with org.junit.*",
        "Issue Links": [
            "https://github.com/apache/opennlp/pull/31"
        ]
    },
    "OPENNLP-916": {
        "Key": "OPENNLP-916",
        "Summary": "Create a Release Process page",
        "Type": "Task",
        "Status": "Closed",
        "Priority": "Critical",
        "Resolution": "Fixed",
        "Affects Version/s": "None",
        "Fix Version/s": "1.7.1",
        "Component/s": "Build, Packaging and Test",
        "Assignee": "William Colen",
        "Reporter": "William Colen",
        "Created": "04/Jan/17 17:37",
        "Updated": "11/Jan/17 09:51",
        "Resolved": "10/Jan/17 21:32",
        "Description": "Create a Release Process page.\nAs suggested by chrismattmann:\nReplicate http://wiki.apache.org/tika/ReleaseProcess (let's fork it and make one for OpenNLP).\nhere's another good one to look at\nhttps://cwiki.apache.org/confluence/display/OODT/Release+Process",
        "Issue Links": []
    },
    "OPENNLP-917": {
        "Key": "OPENNLP-917",
        "Summary": "-lang parameter is not recognized during the evaluation of a postagger",
        "Type": "Bug",
        "Status": "Closed",
        "Priority": "Major",
        "Resolution": "Fixed",
        "Affects Version/s": "1.7.0",
        "Fix Version/s": "1.7.1",
        "Component/s": "Command Line Interface",
        "Assignee": "Suneel Marthi",
        "Reporter": "Damiano Porta",
        "Created": "05/Jan/17 12:54",
        "Updated": "08/Jan/17 19:40",
        "Resolved": "08/Jan/17 19:40",
        "Description": "Hello,\nI think the documentation reports a wrong command to evaluate a postagger.\nThe -lang parameter only works during the training, not for evaluation. It is not recognized.\nhttps://opennlp.apache.org/documentation/1.7.0/manual/opennlp.html#tools.postagger.eval",
        "Issue Links": [
            "https://github.com/apache/opennlp/pull/38"
        ]
    },
    "OPENNLP-918": {
        "Key": "OPENNLP-918",
        "Summary": "Remove deprecated IndexHashTable class",
        "Type": "Improvement",
        "Status": "Closed",
        "Priority": "Minor",
        "Resolution": "Fixed",
        "Affects Version/s": "None",
        "Fix Version/s": "1.7.1",
        "Component/s": "None",
        "Assignee": "J\u00f6rn Kottmann",
        "Reporter": "J\u00f6rn Kottmann",
        "Created": "09/Jan/17 20:46",
        "Updated": "09/Jan/17 22:56",
        "Resolved": "09/Jan/17 22:56",
        "Description": "The class is deprecated and should be removed. It was replaced with java.util.HashMap in 1.7.0.",
        "Issue Links": [
            "https://github.com/apache/opennlp/pull/39"
        ]
    },
    "OPENNLP-919": {
        "Key": "OPENNLP-919",
        "Summary": "Fix/Suppresse \"Possible heap pollution from parameterized vararg type\" warning",
        "Type": "Improvement",
        "Status": "Closed",
        "Priority": "Minor",
        "Resolution": "Fixed",
        "Affects Version/s": "None",
        "Fix Version/s": "1.7.1",
        "Component/s": "None",
        "Assignee": null,
        "Reporter": "J\u00f6rn Kottmann",
        "Created": "09/Jan/17 20:52",
        "Updated": "17/Jan/17 17:26",
        "Resolved": "17/Jan/17 17:26",
        "Description": "The warning should either be fixed, or if false alarm be suppressed.",
        "Issue Links": [
            "https://github.com/apache/opennlp/pull/70"
        ]
    },
    "OPENNLP-920": {
        "Key": "OPENNLP-920",
        "Summary": "Enforce TypeSafety in SequenceTrainer",
        "Type": "Bug",
        "Status": "Closed",
        "Priority": "Minor",
        "Resolution": "Fixed",
        "Affects Version/s": "1.7.0",
        "Fix Version/s": "1.7.1",
        "Component/s": "Machine Learning",
        "Assignee": "Suneel Marthi",
        "Reporter": "Suneel Marthi",
        "Created": "10/Jan/17 03:50",
        "Updated": "10/Jan/17 17:36",
        "Resolved": "10/Jan/17 17:36",
        "Description": null,
        "Issue Links": [
            "https://github.com/apache/opennlp/pull/41"
        ]
    },
    "OPENNLP-921": {
        "Key": "OPENNLP-921",
        "Summary": "Add Intellij code style file to Code Conventions page",
        "Type": "Task",
        "Status": "Closed",
        "Priority": "Major",
        "Resolution": "Fixed",
        "Affects Version/s": "None",
        "Fix Version/s": "1.7.1",
        "Component/s": "Website",
        "Assignee": "Suneel Marthi",
        "Reporter": "J\u00f6rn Kottmann",
        "Created": "10/Jan/17 08:39",
        "Updated": "14/Jan/17 21:53",
        "Resolved": "14/Jan/17 21:52",
        "Description": "It would be nice to have an Intellij code style file which can be imported to get everything set up.",
        "Issue Links": []
    },
    "OPENNLP-922": {
        "Key": "OPENNLP-922",
        "Summary": "Refactor all hashCode and equals methods",
        "Type": "Improvement",
        "Status": "Closed",
        "Priority": "Minor",
        "Resolution": "Fixed",
        "Affects Version/s": "None",
        "Fix Version/s": "1.7.1",
        "Component/s": "None",
        "Assignee": "J\u00f6rn Kottmann",
        "Reporter": "J\u00f6rn Kottmann",
        "Created": "10/Jan/17 09:53",
        "Updated": "10/Jan/17 18:02",
        "Resolved": "10/Jan/17 18:02",
        "Description": "In many places Objects.hash can be used instead of some IDE generated code. This will make the implementations much more readable.",
        "Issue Links": [
            "https://github.com/apache/opennlp/pull/42"
        ]
    },
    "OPENNLP-923": {
        "Key": "OPENNLP-923",
        "Summary": "Warp all lines longer than 110 chars and enforce it",
        "Type": "Improvement",
        "Status": "Closed",
        "Priority": "Minor",
        "Resolution": "Fixed",
        "Affects Version/s": "None",
        "Fix Version/s": "1.7.1",
        "Component/s": "None",
        "Assignee": "J\u00f6rn Kottmann",
        "Reporter": "J\u00f6rn Kottmann",
        "Created": "10/Jan/17 09:55",
        "Updated": "12/Jan/17 14:43",
        "Resolved": "12/Jan/17 09:56",
        "Description": "Fix all too long lines and enable a checkstyle to enforce a hard limit of 110. The code convention specifies a maximum of 100 and this leaves us a little room for minor violations.",
        "Issue Links": [
            "https://github.com/apache/opennlp/pull/49",
            "https://github.com/apache/opennlp/pull/51"
        ]
    },
    "OPENNLP-924": {
        "Key": "OPENNLP-924",
        "Summary": "Remove all old and leftover main methods",
        "Type": "Improvement",
        "Status": "Closed",
        "Priority": "Minor",
        "Resolution": "Fixed",
        "Affects Version/s": "None",
        "Fix Version/s": "1.7.1",
        "Component/s": "None",
        "Assignee": "Suneel Marthi",
        "Reporter": "J\u00f6rn Kottmann",
        "Created": "10/Jan/17 09:57",
        "Updated": "10/Jan/17 19:57",
        "Resolved": "10/Jan/17 19:57",
        "Description": "The cmdline package was introduced to rebuild the entire command line interface. All left over main methods haven't been tested for a long time and should be removed. \nThey are not part of our public API, should be safe to remove without deprecation. A special notice has to be placed in the README file to inform users.",
        "Issue Links": [
            "https://github.com/apache/opennlp/pull/45"
        ]
    },
    "OPENNLP-925": {
        "Key": "OPENNLP-925",
        "Summary": "Add import ordering to code conventions page",
        "Type": "Improvement",
        "Status": "Closed",
        "Priority": "Minor",
        "Resolution": "Fixed",
        "Affects Version/s": "None",
        "Fix Version/s": "1.7.1",
        "Component/s": "Website",
        "Assignee": "Suneel Marthi",
        "Reporter": "J\u00f6rn Kottmann",
        "Created": "10/Jan/17 10:13",
        "Updated": "14/Jan/17 22:27",
        "Resolved": "14/Jan/17 22:27",
        "Description": "The import order should be defined to avoid constant changing of import ordering depending on the one editing the code. \nIt is possible to export this in Eclipse. The file to configure it should be added as well. And the Intellij config should contain this as well.\nThe import order should be: java, javax, org, com, opennlp",
        "Issue Links": []
    },
    "OPENNLP-926": {
        "Key": "OPENNLP-926",
        "Summary": "Replace CRLF with LF line endings",
        "Type": "Improvement",
        "Status": "Closed",
        "Priority": "Minor",
        "Resolution": "Fixed",
        "Affects Version/s": "None",
        "Fix Version/s": "1.7.1",
        "Component/s": "None",
        "Assignee": "J\u00f6rn Kottmann",
        "Reporter": "J\u00f6rn Kottmann",
        "Created": "10/Jan/17 14:20",
        "Updated": "11/Jan/17 09:53",
        "Resolved": "11/Jan/17 09:53",
        "Description": "This should be consistent in all source files.\nConsider adding a checkstyle to automatically enforce this, even tough this will break git core.autocrlf feature.",
        "Issue Links": [
            "https://github.com/apache/opennlp/pull/46"
        ]
    },
    "OPENNLP-927": {
        "Key": "OPENNLP-927",
        "Summary": "Merge TrainingParameters and PluggableParameters",
        "Type": "New Feature",
        "Status": "Closed",
        "Priority": "Minor",
        "Resolution": "Fixed",
        "Affects Version/s": "1.7.0",
        "Fix Version/s": "1.7.1",
        "Component/s": "Machine Learning",
        "Assignee": "Daniel Russ",
        "Reporter": "Daniel Russ",
        "Created": "10/Jan/17 15:24",
        "Updated": "19/Jan/17 04:45",
        "Resolved": "19/Jan/17 04:45",
        "Description": "The PluggableParameters class was added to pull out the get(Int/String/Boolean)Parameters() methods from the AbstractTrainer.  Merge the functionality of the PluggableParameters into the TrainingParameters.",
        "Issue Links": [
            "https://github.com/apache/opennlp/pull/55"
        ]
    },
    "OPENNLP-928": {
        "Key": "OPENNLP-928",
        "Summary": "Deprecate UIMA training AEs",
        "Type": "Improvement",
        "Status": "Closed",
        "Priority": "Major",
        "Resolution": "Fixed",
        "Affects Version/s": "None",
        "Fix Version/s": "1.7.1",
        "Component/s": "UIMA Integration",
        "Assignee": null,
        "Reporter": "J\u00f6rn Kottmann",
        "Created": "10/Jan/17 16:42",
        "Updated": "14/Jan/17 19:52",
        "Resolved": "14/Jan/17 19:52",
        "Description": "Training via UIMA never really worked well, I propose to remove that code at some point. \nLets ask our users if anyone needs that and if there is no interest it is better to remove it, and if there is interest we could try to come up with a better solution.",
        "Issue Links": [
            "https://github.com/apache/opennlp/pull/58"
        ]
    },
    "OPENNLP-929": {
        "Key": "OPENNLP-929",
        "Summary": "GIS not indexing",
        "Type": "Bug",
        "Status": "Closed",
        "Priority": "Critical",
        "Resolution": "Fixed",
        "Affects Version/s": "None",
        "Fix Version/s": "1.7.1",
        "Component/s": "Machine Learning",
        "Assignee": null,
        "Reporter": "Daniel Russ",
        "Created": "10/Jan/17 17:28",
        "Updated": "10/Jan/17 22:25",
        "Resolved": "10/Jan/17 22:25",
        "Description": "If the user calls the GIS.train(ObjectStream<Event>) methods, the trainer is not indexing.",
        "Issue Links": [
            "https://github.com/apache/opennlp/pull/43"
        ]
    },
    "OPENNLP-930": {
        "Key": "OPENNLP-930",
        "Summary": "Write test for RegexNameFinderFactory",
        "Type": "Task",
        "Status": "Closed",
        "Priority": "Minor",
        "Resolution": "Fixed",
        "Affects Version/s": "None",
        "Fix Version/s": "1.7.1",
        "Component/s": "Name Finder",
        "Assignee": "Suneel Marthi",
        "Reporter": "J\u00f6rn Kottmann",
        "Created": "10/Jan/17 18:38",
        "Updated": "14/Jan/17 19:29",
        "Resolved": "14/Jan/17 19:29",
        "Description": "The main method in that class was kind of testing it, but now it was removed and the code has to used to write a JUnit test\nThe main method can be found in revision: \nb7ce303e349329cbee3eb45a064f0a2ce3179d0e",
        "Issue Links": [
            "https://github.com/apache/opennlp/pull/50"
        ]
    },
    "OPENNLP-931": {
        "Key": "OPENNLP-931",
        "Summary": "Deprecated old or unused format readers in ml package",
        "Type": "Task",
        "Status": "Closed",
        "Priority": "Major",
        "Resolution": "Fixed",
        "Affects Version/s": "None",
        "Fix Version/s": "1.7.1",
        "Component/s": "Machine Learning",
        "Assignee": null,
        "Reporter": "J\u00f6rn Kottmann",
        "Created": "10/Jan/17 18:40",
        "Updated": "15/Jan/17 21:47",
        "Resolved": "15/Jan/17 21:47",
        "Description": "There are some rather old and never used format readers in the ml package. They need to be deprecated and later removed.",
        "Issue Links": [
            "https://github.com/apache/opennlp/pull/64"
        ]
    },
    "OPENNLP-932": {
        "Key": "OPENNLP-932",
        "Summary": "Use checkstyle suppressions file instead of maven exclude",
        "Type": "Improvement",
        "Status": "Closed",
        "Priority": "Minor",
        "Resolution": "Fixed",
        "Affects Version/s": "None",
        "Fix Version/s": "1.7.1",
        "Component/s": "Build, Packaging and Test",
        "Assignee": "J\u00f6rn Kottmann",
        "Reporter": "J\u00f6rn Kottmann",
        "Created": "11/Jan/17 09:21",
        "Updated": "14/Jan/17 18:47",
        "Resolved": "14/Jan/17 18:47",
        "Description": "The excludes should be part of the checkstyle config otherwise this has to be configured for other tools using the checkstyle file too such as our IDEs.",
        "Issue Links": [
            "https://github.com/apache/opennlp/pull/47",
            "https://github.com/apache/opennlp/pull/52",
            "https://github.com/apache/opennlp/pull/57"
        ]
    },
    "OPENNLP-933": {
        "Key": "OPENNLP-933",
        "Summary": "Replace leipzig corpus data with wikinews",
        "Type": "Improvement",
        "Status": "Open",
        "Priority": "Major",
        "Resolution": "Unresolved",
        "Affects Version/s": "None",
        "Fix Version/s": "None",
        "Component/s": "None",
        "Assignee": null,
        "Reporter": "J\u00f6rn Kottmann",
        "Created": "12/Jan/17 10:58",
        "Updated": "12/Jan/17 10:58",
        "Resolved": null,
        "Description": "Wikinews is available in many languages and licensed under cc-a 2.5 which is classified as class b license at Apache. It should be ok to include that for testing resources to ensure OpenNLP works properly.\nThis data can be used for testing existing models and it can be partly automatically annotated to test training of all our components.",
        "Issue Links": []
    },
    "OPENNLP-934": {
        "Key": "OPENNLP-934",
        "Summary": "Replace leipzig corpus data with wikinews",
        "Type": "Improvement",
        "Status": "Closed",
        "Priority": "Major",
        "Resolution": "Duplicate",
        "Affects Version/s": "None",
        "Fix Version/s": "1.7.1",
        "Component/s": "None",
        "Assignee": null,
        "Reporter": "J\u00f6rn Kottmann",
        "Created": "12/Jan/17 10:59",
        "Updated": "15/Jan/17 23:13",
        "Resolved": "15/Jan/17 23:13",
        "Description": "Wikinews is available in many languages and licensed under cc-a 2.5 which is classified as class b license at Apache. It should be ok to include that for testing resources to ensure OpenNLP works properly.\nThis data can be used for testing existing models and it can be partly automatically annotated to test training of all our components.",
        "Issue Links": []
    },
    "OPENNLP-935": {
        "Key": "OPENNLP-935",
        "Summary": "TwoPassDataIndexer should not swallow IOExceptions",
        "Type": "Bug",
        "Status": "Closed",
        "Priority": "Major",
        "Resolution": "Fixed",
        "Affects Version/s": "None",
        "Fix Version/s": "1.7.1",
        "Component/s": "Machine Learning",
        "Assignee": "J\u00f6rn Kottmann",
        "Reporter": "J\u00f6rn Kottmann",
        "Created": "12/Jan/17 13:34",
        "Updated": "15/Jan/17 16:17",
        "Resolved": "15/Jan/17 16:17",
        "Description": "The exception should not be caught at all, if there is an IOException it has to be passed up the call stack to the cmd line interface or user code calling some variant of the train methods.\nNote: In the TwoPassDataIndexer the index methods code is duplicated and this should be fixed on both variants.",
        "Issue Links": [
            "https://github.com/apache/opennlp/pull/52"
        ]
    },
    "OPENNLP-936": {
        "Key": "OPENNLP-936",
        "Summary": "Add thread safe versions of some tools (ME sentence detection, tokenization, pos tagging)",
        "Type": "Improvement",
        "Status": "Open",
        "Priority": "Minor",
        "Resolution": "Unresolved",
        "Affects Version/s": "1.7.1",
        "Fix Version/s": "None",
        "Component/s": "POS Tagger",
        "Assignee": null,
        "Reporter": "Thilo Goetz",
        "Created": "12/Jan/17 14:04",
        "Updated": "08/Jan/23 08:50",
        "Resolved": null,
        "Description": "As discussed on the mailing list, add thread safe versions of maximum entropy sentence detection, tokenization and pos tagging.",
        "Issue Links": [
            "/jira/browse/OPENNLP-1439",
            "https://github.com/apache/opennlp/pull/69",
            "https://github.com/apache/opennlp/pull/69"
        ]
    },
    "OPENNLP-937": {
        "Key": "OPENNLP-937",
        "Summary": "CLI trainers and cross eval should print an error if training data is insufficient",
        "Type": "Bug",
        "Status": "Closed",
        "Priority": "Minor",
        "Resolution": "Fixed",
        "Affects Version/s": "None",
        "Fix Version/s": "1.7.1",
        "Component/s": "Command Line Interface",
        "Assignee": "J\u00f6rn Kottmann",
        "Reporter": "J\u00f6rn Kottmann",
        "Created": "13/Jan/17 12:55",
        "Updated": "15/Jan/17 20:15",
        "Resolved": "15/Jan/17 20:15",
        "Description": "Currently the InsufficientTrainingDataException stack trace is printed to the console. We should catch this exception and provide the user with some help to deal with this problem.\nWe get often questions about this on the ml and a helpful error could probably answer it without having people (the few who bother) ask for help.",
        "Issue Links": [
            "https://github.com/apache/opennlp/pull/62"
        ]
    },
    "OPENNLP-938": {
        "Key": "OPENNLP-938",
        "Summary": "Add letsmt format support",
        "Type": "Improvement",
        "Status": "Closed",
        "Priority": "Minor",
        "Resolution": "Fixed",
        "Affects Version/s": "None",
        "Fix Version/s": "1.7.1",
        "Component/s": "Formats",
        "Assignee": "J\u00f6rn Kottmann",
        "Reporter": "J\u00f6rn Kottmann",
        "Created": "13/Jan/17 13:49",
        "Updated": "19/Jan/17 22:35",
        "Resolved": "19/Jan/17 22:35",
        "Description": null,
        "Issue Links": [
            "https://github.com/apache/opennlp/pull/56"
        ]
    },
    "OPENNLP-939": {
        "Key": "OPENNLP-939",
        "Summary": "Add moses formats support",
        "Type": "Improvement",
        "Status": "Closed",
        "Priority": "Major",
        "Resolution": "Fixed",
        "Affects Version/s": "None",
        "Fix Version/s": "1.7.2",
        "Component/s": "Formats",
        "Assignee": "J\u00f6rn Kottmann",
        "Reporter": "J\u00f6rn Kottmann",
        "Created": "13/Jan/17 13:50",
        "Updated": "25/Jan/17 14:45",
        "Resolved": "25/Jan/17 14:45",
        "Description": null,
        "Issue Links": [
            "https://github.com/apache/opennlp/pull/63"
        ]
    },
    "OPENNLP-940": {
        "Key": "OPENNLP-940",
        "Summary": "Use multiple threads to speed up ontonotes eval tests",
        "Type": "Improvement",
        "Status": "Closed",
        "Priority": "Trivial",
        "Resolution": "Fixed",
        "Affects Version/s": "None",
        "Fix Version/s": "1.7.1",
        "Component/s": "Build, Packaging and Test",
        "Assignee": "J\u00f6rn Kottmann",
        "Reporter": "J\u00f6rn Kottmann",
        "Created": "14/Jan/17 20:19",
        "Updated": "16/Jan/17 16:46",
        "Resolved": "16/Jan/17 16:46",
        "Description": "It would be very nice if those tests could run in less time, so they can be executed more frequently.",
        "Issue Links": [
            "https://github.com/apache/opennlp/pull/61"
        ]
    },
    "OPENNLP-941": {
        "Key": "OPENNLP-941",
        "Summary": "Add eval support to detokenizer",
        "Type": "Improvement",
        "Status": "Resolved",
        "Priority": "Major",
        "Resolution": "Fixed",
        "Affects Version/s": "None",
        "Fix Version/s": "1.9.0",
        "Component/s": "Tokenizer",
        "Assignee": null,
        "Reporter": "J\u00f6rn Kottmann",
        "Created": "15/Jan/17 17:01",
        "Updated": "16/Dec/22 12:40",
        "Resolved": "16/Dec/22 12:40",
        "Description": "It would be nice to be able to evaluate a detokenizer on tokenizer training data.",
        "Issue Links": [
            "https://github.com/apache/opennlp/pull/308"
        ]
    },
    "OPENNLP-942": {
        "Key": "OPENNLP-942",
        "Summary": "Replace IntegerPool with auto boxing",
        "Type": "Improvement",
        "Status": "Closed",
        "Priority": "Trivial",
        "Resolution": "Fixed",
        "Affects Version/s": "None",
        "Fix Version/s": "1.7.1",
        "Component/s": "Sentence Detector",
        "Assignee": "J\u00f6rn Kottmann",
        "Reporter": "J\u00f6rn Kottmann",
        "Created": "15/Jan/17 20:30",
        "Updated": "16/Jan/17 04:45",
        "Resolved": "16/Jan/17 04:45",
        "Description": "This should run well on a modern JVM. Integer.valueOf is caching  ints internally partly, so this should be almost the same.\nAs part of this change IntegerPool should be deprecated.",
        "Issue Links": [
            "https://github.com/apache/opennlp/pull/66"
        ]
    },
    "OPENNLP-943": {
        "Key": "OPENNLP-943",
        "Summary": "Add checkstyle for diamond operator usage",
        "Type": "Improvement",
        "Status": "Closed",
        "Priority": "Trivial",
        "Resolution": "Fixed",
        "Affects Version/s": "None",
        "Fix Version/s": "None",
        "Component/s": "None",
        "Assignee": null,
        "Reporter": "J\u00f6rn Kottmann",
        "Created": "15/Jan/17 21:53",
        "Updated": "15/Jan/17 22:01",
        "Resolved": "15/Jan/17 22:01",
        "Description": null,
        "Issue Links": []
    },
    "OPENNLP-944": {
        "Key": "OPENNLP-944",
        "Summary": "Remove deprecated Indexer code from ML",
        "Type": "Improvement",
        "Status": "Closed",
        "Priority": "Major",
        "Resolution": "Fixed",
        "Affects Version/s": "1.7.0",
        "Fix Version/s": "1.7.2",
        "Component/s": "Machine Learning",
        "Assignee": "Suneel Marthi",
        "Reporter": "Suneel Marthi",
        "Created": "15/Jan/17 23:48",
        "Updated": "31/Jan/17 10:15",
        "Resolved": "31/Jan/17 10:15",
        "Description": null,
        "Issue Links": [
            "https://github.com/apache/opennlp/pull/96",
            "https://github.com/apache/opennlp/pull/102"
        ]
    },
    "OPENNLP-945": {
        "Key": "OPENNLP-945",
        "Summary": "Enable Coveralls.io code coverage for OpenNLP",
        "Type": "Improvement",
        "Status": "Closed",
        "Priority": "Major",
        "Resolution": "Fixed",
        "Affects Version/s": "1.7.0",
        "Fix Version/s": "1.7.1",
        "Component/s": "Build, Packaging and Test",
        "Assignee": "Suneel Marthi",
        "Reporter": "Suneel Marthi",
        "Created": "16/Jan/17 21:36",
        "Updated": "20/Jan/17 20:46",
        "Resolved": "17/Jan/17 03:17",
        "Description": null,
        "Issue Links": [
            "https://github.com/apache/opennlp/pull/67",
            "https://github.com/apache/opennlp/pull/68",
            "https://github.com/apache/opennlp/pull/80"
        ]
    },
    "OPENNLP-946": {
        "Key": "OPENNLP-946",
        "Summary": "GISTrainer should extend AbstractEventTrainer",
        "Type": "Improvement",
        "Status": "Closed",
        "Priority": "Minor",
        "Resolution": "Fixed",
        "Affects Version/s": "None",
        "Fix Version/s": "1.7.2",
        "Component/s": "Machine Learning",
        "Assignee": "Suneel Marthi",
        "Reporter": "J\u00f6rn Kottmann",
        "Created": "17/Jan/17 13:29",
        "Updated": "01/Feb/17 15:21",
        "Resolved": "31/Jan/17 11:40",
        "Description": "This should be refactored to make it fit into the ml framework. Currently GIS only fits in and then calls GISTrainer.\nLets do the following:\n\nGISTrainer will extend AbstractEventTrainer\nGIS will be deprecated",
        "Issue Links": [
            "https://github.com/apache/opennlp/pull/104",
            "https://github.com/apache/opennlp/pull/108"
        ]
    },
    "OPENNLP-947": {
        "Key": "OPENNLP-947",
        "Summary": "Organize imports according to new order",
        "Type": "Improvement",
        "Status": "Closed",
        "Priority": "Trivial",
        "Resolution": "Fixed",
        "Affects Version/s": "None",
        "Fix Version/s": "1.7.1",
        "Component/s": "None",
        "Assignee": "Suneel Marthi",
        "Reporter": "J\u00f6rn Kottmann",
        "Created": "17/Jan/17 18:04",
        "Updated": "19/Jan/17 14:38",
        "Resolved": "19/Jan/17 14:38",
        "Description": "It would be nice to do this for the code base and enforce it via checkstyle. We can tell people to make sure their IDE is configured correctly and everything will be fine.",
        "Issue Links": [
            "https://github.com/apache/opennlp/pull/74"
        ]
    },
    "OPENNLP-948": {
        "Key": "OPENNLP-948",
        "Summary": "Objects.requireNonNull should be used for argument checking",
        "Type": "Improvement",
        "Status": "Closed",
        "Priority": "Trivial",
        "Resolution": "Fixed",
        "Affects Version/s": "None",
        "Fix Version/s": "1.7.1",
        "Component/s": "None",
        "Assignee": "J\u00f6rn Kottmann",
        "Reporter": "J\u00f6rn Kottmann",
        "Created": "19/Jan/17 19:21",
        "Updated": "19/Jan/17 22:34",
        "Resolved": "19/Jan/17 22:34",
        "Description": null,
        "Issue Links": [
            "https://github.com/apache/opennlp/pull/76"
        ]
    },
    "OPENNLP-949": {
        "Key": "OPENNLP-949",
        "Summary": "Extend eval tests to run more ml algorithms",
        "Type": "Improvement",
        "Status": "Closed",
        "Priority": "Minor",
        "Resolution": "Fixed",
        "Affects Version/s": "None",
        "Fix Version/s": "1.7.1",
        "Component/s": "Build, Packaging and Test",
        "Assignee": "J\u00f6rn Kottmann",
        "Reporter": "J\u00f6rn Kottmann",
        "Created": "19/Jan/17 19:41",
        "Updated": "20/Jan/17 14:49",
        "Resolved": "20/Jan/17 14:49",
        "Description": null,
        "Issue Links": [
            "https://github.com/apache/opennlp/pull/77"
        ]
    },
    "OPENNLP-950": {
        "Key": "OPENNLP-950",
        "Summary": "Deprecate DocumentCategorizer.categorzie(String) variants",
        "Type": "Improvement",
        "Status": "Closed",
        "Priority": "Minor",
        "Resolution": "Fixed",
        "Affects Version/s": "None",
        "Fix Version/s": "1.7.1",
        "Component/s": "Doccat",
        "Assignee": "Suneel Marthi",
        "Reporter": "J\u00f6rn Kottmann",
        "Created": "20/Jan/17 14:24",
        "Updated": "20/Jan/17 15:59",
        "Resolved": "20/Jan/17 15:59",
        "Description": "The user is supposed to pass tokenized text to the Document Categorizer, therefore the methods and mechanism which deal with untokenized text should be deprecated so it can be removed in the future.\nDocumentCategorizer.categorize(String)\nDocumentCategorizer.categorize(String, Map<String, Object>)\nAnd also DoccatFactory tokenizer methods.",
        "Issue Links": [
            "https://github.com/apache/opennlp/pull/79"
        ]
    },
    "OPENNLP-951": {
        "Key": "OPENNLP-951",
        "Summary": "Add a central RAT-exclude file",
        "Type": "Improvement",
        "Status": "Closed",
        "Priority": "Major",
        "Resolution": "Fixed",
        "Affects Version/s": "1.7.1",
        "Fix Version/s": "1.7.2",
        "Component/s": "Build, Packaging and Test",
        "Assignee": "Suneel Marthi",
        "Reporter": "William Colen",
        "Created": "20/Jan/17 21:33",
        "Updated": "25/Jan/17 14:55",
        "Resolved": "25/Jan/17 14:55",
        "Description": "The project needs a central rat-exclude file and configure that in parent pom.",
        "Issue Links": [
            "https://github.com/apache/opennlp/pull/85"
        ]
    },
    "OPENNLP-952": {
        "Key": "OPENNLP-952",
        "Summary": "Add checkstyle rule to verify presence of AL header",
        "Type": "Improvement",
        "Status": "Closed",
        "Priority": "Trivial",
        "Resolution": "Fixed",
        "Affects Version/s": "None",
        "Fix Version/s": "1.7.2",
        "Component/s": "Build, Packaging and Test",
        "Assignee": "J\u00f6rn Kottmann",
        "Reporter": "J\u00f6rn Kottmann",
        "Created": "20/Jan/17 22:17",
        "Updated": "24/Jan/17 10:00",
        "Resolved": "24/Jan/17 10:00",
        "Description": null,
        "Issue Links": [
            "https://github.com/apache/opennlp/pull/83"
        ]
    },
    "OPENNLP-953": {
        "Key": "OPENNLP-953",
        "Summary": "Remove deprecated format readers and writer",
        "Type": "Improvement",
        "Status": "Closed",
        "Priority": "Minor",
        "Resolution": "Fixed",
        "Affects Version/s": "None",
        "Fix Version/s": "1.7.2",
        "Component/s": "Machine Learning",
        "Assignee": "J\u00f6rn Kottmann",
        "Reporter": "J\u00f6rn Kottmann",
        "Created": "22/Jan/17 18:32",
        "Updated": "24/Jan/17 10:00",
        "Resolved": "24/Jan/17 10:00",
        "Description": null,
        "Issue Links": [
            "https://github.com/apache/opennlp/pull/82"
        ]
    },
    "OPENNLP-954": {
        "Key": "OPENNLP-954",
        "Summary": "Fix ConlllX Maxent Qn evaluation test",
        "Type": "Bug",
        "Status": "Closed",
        "Priority": "Minor",
        "Resolution": "Fixed",
        "Affects Version/s": "None",
        "Fix Version/s": "1.7.2",
        "Component/s": "None",
        "Assignee": "J\u00f6rn Kottmann",
        "Reporter": "J\u00f6rn Kottmann",
        "Created": "22/Jan/17 18:33",
        "Updated": "24/Jan/17 10:00",
        "Resolved": "24/Jan/17 10:00",
        "Description": null,
        "Issue Links": [
            "https://github.com/apache/opennlp/pull/81"
        ]
    },
    "OPENNLP-955": {
        "Key": "OPENNLP-955",
        "Summary": "DocumentBegin XML is not mapped to the correct context generator",
        "Type": "Bug",
        "Status": "Closed",
        "Priority": "Major",
        "Resolution": "Fixed",
        "Affects Version/s": "1.7.2",
        "Fix Version/s": "1.7.2",
        "Component/s": "None",
        "Assignee": "William Colen",
        "Reporter": "William Colen",
        "Created": "23/Jan/17 20:52",
        "Updated": "24/Jan/17 12:10",
        "Resolved": "24/Jan/17 12:10",
        "Description": "DocumentBegin XML is not mapped to the correct context generator. It refers to PreviousMapFeatureGenerator.",
        "Issue Links": [
            "https://github.com/apache/opennlp/pull/84"
        ]
    },
    "OPENNLP-956": {
        "Key": "OPENNLP-956",
        "Summary": "Javadoc issues with Java 8",
        "Type": "Bug",
        "Status": "Closed",
        "Priority": "Major",
        "Resolution": "Won't Fix",
        "Affects Version/s": "1.7.1",
        "Fix Version/s": "1.8.4",
        "Component/s": "Build, Packaging and Test",
        "Assignee": "Suneel Marthi",
        "Reporter": "William Colen",
        "Created": "24/Jan/17 11:53",
        "Updated": "26/Dec/17 18:54",
        "Resolved": "26/Dec/17 18:54",
        "Description": null,
        "Issue Links": []
    },
    "OPENNLP-957": {
        "Key": "OPENNLP-957",
        "Summary": "Create a normalizer feature generator",
        "Type": "Improvement",
        "Status": "Reopened",
        "Priority": "Major",
        "Resolution": "Unresolved",
        "Affects Version/s": "None",
        "Fix Version/s": "None",
        "Component/s": "None",
        "Assignee": "William Colen",
        "Reporter": "William Colen",
        "Created": "24/Jan/17 13:55",
        "Updated": "21/Dec/22 15:10",
        "Resolved": null,
        "Description": "Create an aggregate feature generator that can modify the the tokens. For example:\n\nNumbers: 9838749 -> 9999999\nInterjection: hellllloooooo -> hello\nURL: http://opennlp.apache.org -> $URL$\nEmail: users@opennlp.apache.org -> $EMAIL$\n...",
        "Issue Links": [
            "https://github.com/apache/opennlp/pull/99"
        ]
    },
    "OPENNLP-958": {
        "Key": "OPENNLP-958",
        "Summary": "Add a NameFinder feature generator that works with POS Tags",
        "Type": "Bug",
        "Status": "Closed",
        "Priority": "Major",
        "Resolution": "Fixed",
        "Affects Version/s": "1.7.1",
        "Fix Version/s": "1.8.0",
        "Component/s": "Name Finder",
        "Assignee": "William Colen",
        "Reporter": "William Colen",
        "Created": "24/Jan/17 21:08",
        "Updated": "09/May/17 09:39",
        "Resolved": "09/May/17 09:39",
        "Description": null,
        "Issue Links": [
            "https://github.com/apache/opennlp/pull/87",
            "https://github.com/apache/opennlp/pull/170"
        ]
    },
    "OPENNLP-959": {
        "Key": "OPENNLP-959",
        "Summary": "BRAT parser should never place a sentence split inside an annotation",
        "Type": "Bug",
        "Status": "Closed",
        "Priority": "Minor",
        "Resolution": "Fixed",
        "Affects Version/s": "None",
        "Fix Version/s": "1.7.2",
        "Component/s": "Formats",
        "Assignee": "J\u00f6rn Kottmann",
        "Reporter": "J\u00f6rn Kottmann",
        "Created": "25/Jan/17 14:27",
        "Updated": "25/Jan/17 14:54",
        "Resolved": "25/Jan/17 14:54",
        "Description": "Spans which contain named entities or other things never go across sentences. The sentence segmenter somtimes makes mistakes and places a sentence boundary inside a name. This should be corrected by the brat parser.",
        "Issue Links": [
            "https://github.com/apache/opennlp/pull/88"
        ]
    },
    "OPENNLP-960": {
        "Key": "OPENNLP-960",
        "Summary": "Cmdline converter tools don't print usage",
        "Type": "Bug",
        "Status": "Closed",
        "Priority": "Minor",
        "Resolution": "Won't Fix",
        "Affects Version/s": "None",
        "Fix Version/s": "None",
        "Component/s": "Command Line Interface",
        "Assignee": null,
        "Reporter": "J\u00f6rn Kottmann",
        "Created": "25/Jan/17 14:41",
        "Updated": "09/Feb/17 10:45",
        "Resolved": "09/Feb/17 10:45",
        "Description": "The converters should print the full usage so a user knows which parameters can be passed in.",
        "Issue Links": []
    },
    "OPENNLP-961": {
        "Key": "OPENNLP-961",
        "Summary": "BRAT parser fails on files that contain events",
        "Type": "Bug",
        "Status": "Closed",
        "Priority": "Major",
        "Resolution": "Fixed",
        "Affects Version/s": "None",
        "Fix Version/s": "1.7.2",
        "Component/s": "Formats",
        "Assignee": "J\u00f6rn Kottmann",
        "Reporter": "J\u00f6rn Kottmann",
        "Created": "25/Jan/17 14:44",
        "Updated": "30/Jan/17 14:00",
        "Resolved": "30/Jan/17 14:00",
        "Description": "The brat format allows to annotate events, if a file contains these events the brat parser fails. Even tough a user might only want to look at the entities in that file.\nUpdate the brat parser to parse or ignore the events.",
        "Issue Links": [
            "https://github.com/apache/opennlp/pull/94"
        ]
    },
    "OPENNLP-962": {
        "Key": "OPENNLP-962",
        "Summary": "Dictionary should implement SerializableArtifact",
        "Type": "Improvement",
        "Status": "Closed",
        "Priority": "Minor",
        "Resolution": "Fixed",
        "Affects Version/s": "1.7.1",
        "Fix Version/s": "1.7.2",
        "Component/s": "Parser",
        "Assignee": "Suneel Marthi",
        "Reporter": "J\u00f6rn Kottmann",
        "Created": "25/Jan/17 15:03",
        "Updated": "27/Jan/17 19:08",
        "Resolved": "27/Jan/17 19:08",
        "Description": "The Dictionary should implement this interface to use the new more robust serialization mechanism.",
        "Issue Links": [
            "https://github.com/apache/opennlp/pull/90"
        ]
    },
    "OPENNLP-963": {
        "Key": "OPENNLP-963",
        "Summary": "Both AbstractTrainer and AbstractEventTrainer defined a reportMap",
        "Type": "Bug",
        "Status": "Closed",
        "Priority": "Minor",
        "Resolution": "Fixed",
        "Affects Version/s": "1.7.1",
        "Fix Version/s": "1.7.2",
        "Component/s": "Machine Learning",
        "Assignee": "Daniel Russ",
        "Reporter": "Daniel Russ",
        "Created": "25/Jan/17 18:24",
        "Updated": "26/Jan/17 16:52",
        "Resolved": "26/Jan/17 16:51",
        "Description": "Both AbstractEventTrainer and AbstractTrainer hold a references to different reportMaps. This can cause a NullPointerException when addToReport is called.",
        "Issue Links": [
            "https://github.com/apache/opennlp/pull/89"
        ]
    },
    "OPENNLP-964": {
        "Key": "OPENNLP-964",
        "Summary": "Model packages should ignore NOTICE and LICENSE files",
        "Type": "Improvement",
        "Status": "Closed",
        "Priority": "Minor",
        "Resolution": "Fixed",
        "Affects Version/s": "None",
        "Fix Version/s": "1.8.0",
        "Component/s": "None",
        "Assignee": "J\u00f6rn Kottmann",
        "Reporter": "J\u00f6rn Kottmann",
        "Created": "25/Jan/17 18:25",
        "Updated": "09/Feb/17 09:40",
        "Resolved": "09/Feb/17 09:40",
        "Description": "To be able to directly distribute models from Apache OpenNLP those packages need to contain a LICENSE and NOTICE file. The model loading fails currently if those are present.",
        "Issue Links": [
            "https://github.com/apache/opennlp/pull/113"
        ]
    },
    "OPENNLP-965": {
        "Key": "OPENNLP-965",
        "Summary": "Replace Charset.forName(\"UTF-8\") with constant",
        "Type": "Improvement",
        "Status": "Closed",
        "Priority": "Trivial",
        "Resolution": "Fixed",
        "Affects Version/s": "None",
        "Fix Version/s": "1.7.2",
        "Component/s": "None",
        "Assignee": "J\u00f6rn Kottmann",
        "Reporter": "J\u00f6rn Kottmann",
        "Created": "26/Jan/17 21:31",
        "Updated": "27/Jan/17 11:00",
        "Resolved": "27/Jan/17 11:00",
        "Description": null,
        "Issue Links": [
            "https://github.com/apache/opennlp/pull/91"
        ]
    },
    "OPENNLP-966": {
        "Key": "OPENNLP-966",
        "Summary": "Remove deprecated trainers from UIMA integration",
        "Type": "Improvement",
        "Status": "Closed",
        "Priority": "Major",
        "Resolution": "Fixed",
        "Affects Version/s": "None",
        "Fix Version/s": "1.7.2",
        "Component/s": "UIMA Integration",
        "Assignee": "J\u00f6rn Kottmann",
        "Reporter": "J\u00f6rn Kottmann",
        "Created": "26/Jan/17 22:00",
        "Updated": "27/Jan/17 13:07",
        "Resolved": "27/Jan/17 13:07",
        "Description": null,
        "Issue Links": [
            "https://github.com/apache/opennlp/pull/92"
        ]
    },
    "OPENNLP-967": {
        "Key": "OPENNLP-967",
        "Summary": "Add forbiddenapis to maven build",
        "Type": "Improvement",
        "Status": "Closed",
        "Priority": "Minor",
        "Resolution": "Fixed",
        "Affects Version/s": "None",
        "Fix Version/s": "1.7.2",
        "Component/s": "Build, Packaging and Test",
        "Assignee": "J\u00f6rn Kottmann",
        "Reporter": "J\u00f6rn Kottmann",
        "Created": "26/Jan/17 22:17",
        "Updated": "27/Jan/17 13:05",
        "Resolved": "27/Jan/17 13:05",
        "Description": null,
        "Issue Links": [
            "https://github.com/apache/opennlp/pull/93"
        ]
    },
    "OPENNLP-968": {
        "Key": "OPENNLP-968",
        "Summary": "Make detailedF output the default for Eval and CV",
        "Type": "Bug",
        "Status": "Closed",
        "Priority": "Major",
        "Resolution": "Fixed",
        "Affects Version/s": "None",
        "Fix Version/s": "1.7.2",
        "Component/s": "Command Line Interface",
        "Assignee": "William Colen",
        "Reporter": "William Colen",
        "Created": "27/Jan/17 14:54",
        "Updated": "29/Jan/17 14:29",
        "Resolved": "29/Jan/17 14:29",
        "Description": null,
        "Issue Links": [
            "https://github.com/apache/opennlp/pull/98"
        ]
    },
    "OPENNLP-969": {
        "Key": "OPENNLP-969",
        "Summary": "Trainers should have a Constructor that takes a TrainingParamer",
        "Type": "Improvement",
        "Status": "Closed",
        "Priority": "Minor",
        "Resolution": "Fixed",
        "Affects Version/s": "1.7.1",
        "Fix Version/s": "1.7.2",
        "Component/s": "Machine Learning",
        "Assignee": "Daniel Russ",
        "Reporter": "Daniel Russ",
        "Created": "27/Jan/17 18:22",
        "Updated": "27/Jan/17 22:01",
        "Resolved": "27/Jan/17 22:01",
        "Description": "Every time we construct a trainer, we construct, then init. Have an optional Constructor that takes a TrainingParameter and calls the init method.",
        "Issue Links": [
            "https://github.com/apache/opennlp/pull/95"
        ]
    },
    "OPENNLP-970": {
        "Key": "OPENNLP-970",
        "Summary": "NameFinder should have a detailed output with confusion matrix",
        "Type": "Bug",
        "Status": "Closed",
        "Priority": "Major",
        "Resolution": "Fixed",
        "Affects Version/s": "None",
        "Fix Version/s": "1.7.2",
        "Component/s": "Name Finder",
        "Assignee": "William Colen",
        "Reporter": "William Colen",
        "Created": "27/Jan/17 18:46",
        "Updated": "30/Jan/17 18:19",
        "Resolved": "30/Jan/17 18:19",
        "Description": null,
        "Issue Links": [
            "https://github.com/apache/opennlp/pull/97"
        ]
    },
    "OPENNLP-971": {
        "Key": "OPENNLP-971",
        "Summary": "Remove static training methods from GIS",
        "Type": "Improvement",
        "Status": "Closed",
        "Priority": "Minor",
        "Resolution": "Won't Fix",
        "Affects Version/s": "1.7.1",
        "Fix Version/s": "None",
        "Component/s": "Machine Learning",
        "Assignee": null,
        "Reporter": "Daniel Russ",
        "Created": "27/Jan/17 20:48",
        "Updated": "09/Feb/17 10:45",
        "Resolved": "06/Feb/17 19:14",
        "Description": "The pluggable TrainingParameters has been implemented.  There is no reason to call the static train methods on GIS.  They should be Deprecated in 1.7.3, and removed in a later version.",
        "Issue Links": []
    },
    "OPENNLP-972": {
        "Key": "OPENNLP-972",
        "Summary": "LM CLI should both calculate probability and suggest next tokens",
        "Type": "Bug",
        "Status": "Closed",
        "Priority": "Major",
        "Resolution": "Fixed",
        "Affects Version/s": "None",
        "Fix Version/s": "1.7.2",
        "Component/s": "Command Line Interface",
        "Assignee": "Tommaso Teofili",
        "Reporter": "Tommaso Teofili",
        "Created": "28/Jan/17 22:28",
        "Updated": "29/Jan/17 06:55",
        "Resolved": "29/Jan/17 06:55",
        "Description": "LanguageModelTool\u00a0uses LanguageModel#calculateProbability API however it may be useful to provide also the result of the LanguageModel#predictNextTokens API there.\nAlso LMTool should probably be NgramLanguageModelTool as to make it specific to the ngram based implementation.",
        "Issue Links": [
            "https://github.com/apache/opennlp/pull/100"
        ]
    },
    "OPENNLP-973": {
        "Key": "OPENNLP-973",
        "Summary": "DataIndexers should respect PrintMessages parameter",
        "Type": "Bug",
        "Status": "Closed",
        "Priority": "Minor",
        "Resolution": "Fixed",
        "Affects Version/s": "None",
        "Fix Version/s": "1.7.2",
        "Component/s": "Machine Learning",
        "Assignee": "J\u00f6rn Kottmann",
        "Reporter": "J\u00f6rn Kottmann",
        "Created": "01/Feb/17 14:16",
        "Updated": "01/Feb/17 15:50",
        "Resolved": "01/Feb/17 15:50",
        "Description": null,
        "Issue Links": [
            "https://github.com/apache/opennlp/pull/107"
        ]
    },
    "OPENNLP-974": {
        "Key": "OPENNLP-974",
        "Summary": "DataIndexer Param can't be set to a class name",
        "Type": "Bug",
        "Status": "Closed",
        "Priority": "Minor",
        "Resolution": "Fixed",
        "Affects Version/s": "1.7.2",
        "Fix Version/s": "1.8.0",
        "Component/s": "Machine Learning",
        "Assignee": "Daniel Russ",
        "Reporter": "J\u00f6rn Kottmann",
        "Created": "03/Feb/17 08:41",
        "Updated": "09/Feb/17 11:25",
        "Resolved": "09/Feb/17 11:25",
        "Description": "The DataIndexer factory is capable of loading a DataIndexer by its class name. The TrainerFactory validation method rejects that as invalid. The validation should be updated to allow this.",
        "Issue Links": []
    },
    "OPENNLP-975": {
        "Key": "OPENNLP-975",
        "Summary": "Add format support for conll-u",
        "Type": "Improvement",
        "Status": "Closed",
        "Priority": "Minor",
        "Resolution": "Fixed",
        "Affects Version/s": "None",
        "Fix Version/s": "1.8.0",
        "Component/s": "Formats",
        "Assignee": "J\u00f6rn Kottmann",
        "Reporter": "J\u00f6rn Kottmann",
        "Created": "05/Feb/17 20:14",
        "Updated": "07/Feb/17 14:45",
        "Resolved": "07/Feb/17 14:45",
        "Description": "The format support is needed to train on Universial Dependency files:\nhttps://lindat.mff.cuni.cz/repository/xmlui/handle/11234/1-1827",
        "Issue Links": [
            "https://github.com/apache/opennlp/pull/111"
        ]
    },
    "OPENNLP-976": {
        "Key": "OPENNLP-976",
        "Summary": "Add formats support for germeval2014",
        "Type": "Improvement",
        "Status": "Open",
        "Priority": "Major",
        "Resolution": "Unresolved",
        "Affects Version/s": "None",
        "Fix Version/s": "None",
        "Component/s": "Formats",
        "Assignee": "Suneel Marthi",
        "Reporter": "J\u00f6rn Kottmann",
        "Created": "06/Feb/17 13:33",
        "Updated": "23/Oct/17 22:19",
        "Resolved": null,
        "Description": "Details about the format can be found here:\nhttps://sites.google.com/site/germeval2014ner/data",
        "Issue Links": []
    },
    "OPENNLP-977": {
        "Key": "OPENNLP-977",
        "Summary": "TrainerFactory uses Deprecated methods",
        "Type": "Bug",
        "Status": "Closed",
        "Priority": "Minor",
        "Resolution": "Fixed",
        "Affects Version/s": "1.8.0",
        "Fix Version/s": "1.8.0",
        "Component/s": "Machine Learning",
        "Assignee": "Daniel Russ",
        "Reporter": "Daniel Russ",
        "Created": "06/Feb/17 17:21",
        "Updated": "09/Feb/17 10:47",
        "Resolved": "07/Feb/17 18:54",
        "Description": "getEventTrainer/getEventModelSequenceTrainer use maps instead of Training Parameters.  Also EventModelSequenceTrainer uses maps instead of TrainingParameters.  This is not an outward facing interface to most users.  All init(Map<String,String>,Map<String,String>) methods should be deprecated in favor of init(TraingParameters, Map<String,String>",
        "Issue Links": []
    },
    "OPENNLP-978": {
        "Key": "OPENNLP-978",
        "Summary": "Improve Name Finder default settings",
        "Type": "Improvement",
        "Status": "Closed",
        "Priority": "Minor",
        "Resolution": "Fixed",
        "Affects Version/s": "None",
        "Fix Version/s": "1.8.0",
        "Component/s": "Name Finder",
        "Assignee": "J\u00f6rn Kottmann",
        "Reporter": "J\u00f6rn Kottmann",
        "Created": "06/Feb/17 23:56",
        "Updated": "14/Feb/17 08:49",
        "Resolved": "14/Feb/17 08:49",
        "Description": "The Name Finder should use by default Perceptron and cutoff zero.",
        "Issue Links": [
            "https://github.com/apache/opennlp/pull/117"
        ]
    },
    "OPENNLP-979": {
        "Key": "OPENNLP-979",
        "Summary": "Update Lemmatizer documentation according to OPENNLP-904",
        "Type": "Documentation",
        "Status": "Closed",
        "Priority": "Minor",
        "Resolution": "Fixed",
        "Affects Version/s": "None",
        "Fix Version/s": "1.8.0",
        "Component/s": "None",
        "Assignee": "Rodrigo Agerri",
        "Reporter": "Rodrigo Agerri",
        "Created": "07/Feb/17 11:20",
        "Updated": "22/May/17 02:31",
        "Resolved": "22/May/17 02:31",
        "Description": "Documentation needs to be changed to reflect the changes in the Lemmatizer API implemented in OPENNLP-904",
        "Issue Links": [
            "https://github.com/apache/opennlp/pull/210"
        ]
    },
    "OPENNLP-980": {
        "Key": "OPENNLP-980",
        "Summary": "Deprecate low-level feature constructors and methods",
        "Type": "Improvement",
        "Status": "Closed",
        "Priority": "Minor",
        "Resolution": "Fixed",
        "Affects Version/s": "None",
        "Fix Version/s": "1.8.0",
        "Component/s": "Machine Learning",
        "Assignee": "J\u00f6rn Kottmann",
        "Reporter": "J\u00f6rn Kottmann",
        "Created": "08/Feb/17 09:17",
        "Updated": "09/Feb/17 09:41",
        "Resolved": "09/Feb/17 09:41",
        "Description": "The methods should be deprecated so the visibility to them can be reduced later. The internals should not be exposed as much so it is possible to change the implementations without breaking user code.",
        "Issue Links": []
    },
    "OPENNLP-981": {
        "Key": "OPENNLP-981",
        "Summary": "Training EventStream Hash was removed from event trainer",
        "Type": "Bug",
        "Status": "Closed",
        "Priority": "Minor",
        "Resolution": "Fixed",
        "Affects Version/s": "1.7.2",
        "Fix Version/s": "1.8.0",
        "Component/s": "Machine Learning",
        "Assignee": null,
        "Reporter": "Daniel Russ",
        "Created": "09/Feb/17 14:42",
        "Updated": "16/Feb/17 02:31",
        "Resolved": "09/Feb/17 18:16",
        "Description": null,
        "Issue Links": []
    },
    "OPENNLP-982": {
        "Key": "OPENNLP-982",
        "Summary": "Ensure 1.5.x  and newer models are still compatible",
        "Type": "Improvement",
        "Status": "Closed",
        "Priority": "Trivial",
        "Resolution": "Fixed",
        "Affects Version/s": "None",
        "Fix Version/s": "1.8.0",
        "Component/s": "None",
        "Assignee": "J\u00f6rn Kottmann",
        "Reporter": "J\u00f6rn Kottmann",
        "Created": "09/Feb/17 17:45",
        "Updated": "17/Feb/17 12:45",
        "Resolved": "17/Feb/17 12:45",
        "Description": null,
        "Issue Links": [
            "https://github.com/apache/opennlp/pull/129"
        ]
    },
    "OPENNLP-983": {
        "Key": "OPENNLP-983",
        "Summary": "Allow length for Prefix and Suffix feature generators to be set",
        "Type": "Improvement",
        "Status": "Closed",
        "Priority": "Minor",
        "Resolution": "Fixed",
        "Affects Version/s": "None",
        "Fix Version/s": "1.8.0",
        "Component/s": "Name Finder",
        "Assignee": null,
        "Reporter": "Jeff Zemerick",
        "Created": "09/Feb/17 23:11",
        "Updated": "21/Feb/17 19:38",
        "Resolved": "21/Feb/17 19:38",
        "Description": "Allow the length for PrefixFeatureGenerator and the SuffixFeatureGenerator to be configurable. Additionally, prevent these generators from creating duplicate features when the length is larger than the token's size.",
        "Issue Links": [
            "https://github.com/apache/opennlp/pull/121"
        ]
    },
    "OPENNLP-984": {
        "Key": "OPENNLP-984",
        "Summary": "Remove the type parameter from the pos tagger trainer",
        "Type": "Improvement",
        "Status": "Closed",
        "Priority": "Minor",
        "Resolution": "Fixed",
        "Affects Version/s": "None",
        "Fix Version/s": "1.8.0",
        "Component/s": "Command Line Interface,                                            POS Tagger",
        "Assignee": "J\u00f6rn Kottmann",
        "Reporter": "J\u00f6rn Kottmann",
        "Created": "10/Feb/17 15:33",
        "Updated": "13/Feb/17 10:17",
        "Resolved": "13/Feb/17 10:17",
        "Description": null,
        "Issue Links": [
            "https://github.com/apache/opennlp/pull/122"
        ]
    },
    "OPENNLP-985": {
        "Key": "OPENNLP-985",
        "Summary": "A condition that is always true.",
        "Type": "Bug",
        "Status": "Resolved",
        "Priority": "Trivial",
        "Resolution": "Fixed",
        "Affects Version/s": "None",
        "Fix Version/s": "2.1.1",
        "Component/s": "wsd",
        "Assignee": "Bruno P. Kinoshita",
        "Reporter": "JC",
        "Created": "11/Feb/17 18:18",
        "Updated": "13/Feb/23 14:15",
        "Resolved": "13/Feb/23 14:15",
        "Description": "I've found a code smell or typo in a recent github snapshot. (opennlp-snadbox)\nPath: opennlp-wsd/src/main/java/opennlp/tools/disambiguator/datareader/Paragraph.java\n\n85   public boolean contains(String wordTag) {\n86 \n87     for (Sentence isentence : this.getSsentences()) {\n88       for (Word iword : isentence.getIwords()) {\n89         if (iword.equals(iword))\n90           return true;\n91       }\n92     }\n93 \n94     return false;\n95   }\n\n\nLine 89 is always true. This might be a trivial issue but wanted to report just in case. Thanks!",
        "Issue Links": [
            "https://github.com/apache/opennlp-sandbox/pull/1"
        ]
    },
    "OPENNLP-986": {
        "Key": "OPENNLP-986",
        "Summary": "Use stupid backoff by default in NGramLanguageModel",
        "Type": "Improvement",
        "Status": "Closed",
        "Priority": "Major",
        "Resolution": "Fixed",
        "Affects Version/s": "None",
        "Fix Version/s": "1.8.0",
        "Component/s": "None",
        "Assignee": "Tommaso Teofili",
        "Reporter": "Tommaso Teofili",
        "Created": "14/Feb/17 11:37",
        "Updated": "16/Feb/17 02:31",
        "Resolved": "15/Feb/17 09:50",
        "Description": "NGramLanguageModel\u00a0is already using Stupid Backoff discounting when it contains more than 1M ngrams.\nHowever since the not very good performance of Laplace smoothing for smaller models, it'd be better to simply use Stupid Backoff in all cases.",
        "Issue Links": [
            "https://github.com/apache/opennlp/pull/124"
        ]
    },
    "OPENNLP-987": {
        "Key": "OPENNLP-987",
        "Summary": "TrainerFactory.getEventTrainer() does not take a TrainingParameter",
        "Type": "Bug",
        "Status": "Closed",
        "Priority": "Minor",
        "Resolution": "Duplicate",
        "Affects Version/s": "1.7.2",
        "Fix Version/s": "1.8.0",
        "Component/s": "Machine Learning",
        "Assignee": null,
        "Reporter": "Daniel Russ",
        "Created": "14/Feb/17 20:47",
        "Updated": "14/Feb/17 21:19",
        "Resolved": "14/Feb/17 21:19",
        "Description": "When creating a trainer, the client creates a TrainingParameter object.  Unfortunately, the TrainerFactory does not use it.",
        "Issue Links": []
    },
    "OPENNLP-988": {
        "Key": "OPENNLP-988",
        "Summary": "TokenNameFinderEvaluator CLI should support nameTypes argument",
        "Type": "Improvement",
        "Status": "Closed",
        "Priority": "Major",
        "Resolution": "Works for Me",
        "Affects Version/s": "1.8.0",
        "Fix Version/s": "1.8.0",
        "Component/s": "Name Finder",
        "Assignee": "William Colen",
        "Reporter": "William Colen",
        "Created": "15/Feb/17 15:47",
        "Updated": "15/Feb/17 15:51",
        "Resolved": "15/Feb/17 15:51",
        "Description": "One can specify the name types to use for training. The same way, one could specify the name types to use for evaluating that model.",
        "Issue Links": []
    },
    "OPENNLP-989": {
        "Key": "OPENNLP-989",
        "Summary": "NameFinderSequenceValidator should not return true for CONT following a START of a different name type",
        "Type": "Bug",
        "Status": "Closed",
        "Priority": "Minor",
        "Resolution": "Fixed",
        "Affects Version/s": "1.7.2",
        "Fix Version/s": "1.8.0",
        "Component/s": "Name Finder",
        "Assignee": "Peter Thygesen",
        "Reporter": "Peter Thygesen",
        "Created": "15/Feb/17 20:32",
        "Updated": "02/Mar/17 20:29",
        "Resolved": "02/Mar/17 20:29",
        "Description": "Writing the unittest for NameFinderSequenceValidator it was discovered that Start followed by a Continue of a different type was validated as correct (valid).\nThe simple test for continue in NameFinderSequenceValidator does not take the name type into account.",
        "Issue Links": [
            "https://github.com/apache/opennlp/pull/126"
        ]
    },
    "OPENNLP-990": {
        "Key": "OPENNLP-990",
        "Summary": "Add checkstyle for array style to be String[] array",
        "Type": "Improvement",
        "Status": "Closed",
        "Priority": "Trivial",
        "Resolution": "Fixed",
        "Affects Version/s": "None",
        "Fix Version/s": "1.8.0",
        "Component/s": "None",
        "Assignee": "Peter Thygesen",
        "Reporter": "J\u00f6rn Kottmann",
        "Created": "15/Feb/17 20:53",
        "Updated": "16/Feb/17 16:09",
        "Resolved": "16/Feb/17 16:09",
        "Description": null,
        "Issue Links": [
            "https://github.com/apache/opennlp/pull/127"
        ]
    },
    "OPENNLP-991": {
        "Key": "OPENNLP-991",
        "Summary": "Validate all passed in language codes",
        "Type": "Improvement",
        "Status": "Open",
        "Priority": "Minor",
        "Resolution": "Unresolved",
        "Affects Version/s": "None",
        "Fix Version/s": "None",
        "Component/s": "None",
        "Assignee": null,
        "Reporter": "J\u00f6rn Kottmann",
        "Created": "17/Feb/17 12:42",
        "Updated": "17/Feb/17 12:43",
        "Resolved": null,
        "Description": "Currently language codes are specified to be ISO-639-3 but internally this never gets validated. If a user provides an incorrect code it will be just accepted and stored in the model.",
        "Issue Links": []
    },
    "OPENNLP-992": {
        "Key": "OPENNLP-992",
        "Summary": "Distribution package should include example parameters file",
        "Type": "Improvement",
        "Status": "Closed",
        "Priority": "Major",
        "Resolution": "Fixed",
        "Affects Version/s": "1.8.0",
        "Fix Version/s": "1.8.0",
        "Component/s": "Build, Packaging and Test",
        "Assignee": "Suneel Marthi",
        "Reporter": "William Colen",
        "Created": "21/Feb/17 17:53",
        "Updated": "21/Feb/17 19:26",
        "Resolved": "21/Feb/17 18:49",
        "Description": "The contents of lang/ml should be included in the distribution for convenience.",
        "Issue Links": [
            "https://github.com/apache/opennlp/pull/131"
        ]
    },
    "OPENNLP-993": {
        "Key": "OPENNLP-993",
        "Summary": "DocumentCategorizerME does not load tokenizer specified in model manifest",
        "Type": "Bug",
        "Status": "Closed",
        "Priority": "Critical",
        "Resolution": "Won't Fix",
        "Affects Version/s": "1.7.1",
        "Fix Version/s": "1.8.0",
        "Component/s": "Doccat",
        "Assignee": "Suneel Marthi",
        "Reporter": "Jonathan Ackerman",
        "Created": "21/Feb/17 19:57",
        "Updated": "27/Feb/17 21:53",
        "Resolved": "23/Feb/17 10:06",
        "Description": "DocumentCategorizerME no longer loads the tokenizer specified in the model manifest. Instead it always uses a WhitespaceTokenizer.\nThis appears to due to a change in 1.7.1 where the constructors for the DoccatFactory were modified to create a WhitespaceTokenizer.\nThis means the logic in the DoccatFactory.getTokenizer() method does try to load the tokenizer in model's manifest as \"tokenizer\" is not null when getTokenizer() is first called.",
        "Issue Links": []
    },
    "OPENNLP-994": {
        "Key": "OPENNLP-994",
        "Summary": "Remove deprecated methods from the Document Categorizer",
        "Type": "Improvement",
        "Status": "Closed",
        "Priority": "Major",
        "Resolution": "Fixed",
        "Affects Version/s": "1.7.1",
        "Fix Version/s": "1.8.0",
        "Component/s": "Doccat",
        "Assignee": "Suneel Marthi",
        "Reporter": "J\u00f6rn Kottmann",
        "Created": "22/Feb/17 09:07",
        "Updated": "27/Feb/17 22:24",
        "Resolved": "27/Feb/17 22:24",
        "Description": "The tokenizer inside the Document Categorizer will be removed. The user is responsible to tokenize the input text himself and then passing tokenized text to the categorizer.",
        "Issue Links": [
            "https://github.com/apache/opennlp/pull/133"
        ]
    },
    "OPENNLP-995": {
        "Key": "OPENNLP-995",
        "Summary": "Add a PR Review Template for contributors",
        "Type": "Improvement",
        "Status": "Closed",
        "Priority": "Major",
        "Resolution": "Fixed",
        "Affects Version/s": "1.7.2",
        "Fix Version/s": "1.8.0",
        "Component/s": "Build, Packaging and Test",
        "Assignee": "Suneel Marthi",
        "Reporter": "Suneel Marthi",
        "Created": "22/Feb/17 22:30",
        "Updated": "23/Feb/17 12:50",
        "Resolved": "23/Feb/17 12:49",
        "Description": null,
        "Issue Links": [
            "https://github.com/apache/opennlp/pull/132"
        ]
    },
    "OPENNLP-996": {
        "Key": "OPENNLP-996",
        "Summary": "Remove heap memory settings from Opennlp-tools",
        "Type": "Improvement",
        "Status": "Closed",
        "Priority": "Major",
        "Resolution": "Fixed",
        "Affects Version/s": "1.7.0",
        "Fix Version/s": "1.8.0",
        "Component/s": "Build, Packaging and Test",
        "Assignee": "Suneel Marthi",
        "Reporter": "Suneel Marthi",
        "Created": "26/Feb/17 17:27",
        "Updated": "26/Feb/17 17:58",
        "Resolved": "26/Feb/17 17:58",
        "Description": "The present argLine in opennlp-tools doesn't work with Jacoco plugin and Intellij debugger, and its not really needed with today's JVMs.",
        "Issue Links": [
            "https://github.com/apache/opennlp/pull/134"
        ]
    },
    "OPENNLP-997": {
        "Key": "OPENNLP-997",
        "Summary": "Exclude the generated stemmer code from the coverage report",
        "Type": "Improvement",
        "Status": "Closed",
        "Priority": "Minor",
        "Resolution": "Fixed",
        "Affects Version/s": "None",
        "Fix Version/s": "1.8.0",
        "Component/s": "Stemmer",
        "Assignee": "Suneel Marthi",
        "Reporter": "J\u00f6rn Kottmann",
        "Created": "27/Feb/17 22:23",
        "Updated": "28/Feb/17 13:31",
        "Resolved": "28/Feb/17 13:31",
        "Description": "The stemmer code is generated and should be excluded from the coverage report.",
        "Issue Links": [
            "https://github.com/apache/opennlp/pull/135"
        ]
    },
    "OPENNLP-998": {
        "Key": "OPENNLP-998",
        "Summary": "Maven build fails on MacOS",
        "Type": "Bug",
        "Status": "Closed",
        "Priority": "Minor",
        "Resolution": "Fixed",
        "Affects Version/s": "None",
        "Fix Version/s": "None",
        "Component/s": "Build, Packaging and Test",
        "Assignee": null,
        "Reporter": "Madhav Sharan",
        "Created": "28/Feb/17 22:30",
        "Updated": "07/Mar/17 13:09",
        "Resolved": "06/Mar/17 21:03",
        "Description": "While building \"opennlp-distr\" I get error \"group id is too big\" on MacOS.\nIt can be fixed by using \"posix\" mode instead of \"gnu\" on - \nhttps://github.com/apache/opennlp/blob/master/opennlp-distr/pom.xml#L75\nAny specific reason to use \"gnu\"? I was reading online and as per people comments \"posix\" works on both windows and unix. I can raise a PR if it can be changed to posix.\n```\n[ERROR] Failed to execute goal org.apache.maven.plugins:maven-assembly-plugin:2.6:single (bundle-project-sources) on project opennlp-distr: Execution bundle-project-sources of goal org.apache.maven.plugins:maven-assembly-plugin:2.6:single failed: group id '703763885' is too big ( > 2097151 ). Use STAR or POSIX extensions to overcome this limit -> [Help 1]\n[ERROR] \n```",
        "Issue Links": [
            "https://github.com/apache/opennlp/pull/136"
        ]
    },
    "OPENNLP-999": {
        "Key": "OPENNLP-999",
        "Summary": "RFE update web site layout",
        "Type": "Improvement",
        "Status": "Closed",
        "Priority": "Minor",
        "Resolution": "Fixed",
        "Affects Version/s": "None",
        "Fix Version/s": "None",
        "Component/s": "Website",
        "Assignee": "Bruno P. Kinoshita",
        "Reporter": "Bruno P. Kinoshita",
        "Created": "04/Mar/17 06:36",
        "Updated": "10/May/17 08:41",
        "Resolved": "10/May/17 08:41",
        "Description": "Started a thread in the dev-mailing list recently, and it didn't get a negative feedback, so filing this issue as placeholder for discussion.\nOpenNLP web site has an old layout, while most new ASF projects are migrating to Jekyll, Maven Site + Fluid Skin, or other new solutions.\nhttp://mail-archives.apache.org/mod_mbox/opennlp-dev/201703.mbox/browser\nThere is a current POC available at https://kinow.github.io/opennlp/, using Apache Maven Site plug-in and Fluid Skin.",
        "Issue Links": [
            "/jira/browse/OPENNLP-504",
            "/jira/browse/OPENNLP-6",
            "/jira/browse/OPENNLP-393",
            "https://github.com/apache/opennlp-site/pull/1",
            "https://github.com/apache/opennlp-site/pull/2",
            "https://github.com/apache/opennlp/pull/163",
            "https://github.com/apache/opennlp/pull/182"
        ]
    },
    "OPENNLP-1000": {
        "Key": "OPENNLP-1000",
        "Summary": "Write a test case for the BilouNameFinderSequenceValidator class",
        "Type": "Task",
        "Status": "Closed",
        "Priority": "Minor",
        "Resolution": "Fixed",
        "Affects Version/s": "None",
        "Fix Version/s": "1.8.0",
        "Component/s": "Name Finder",
        "Assignee": "Peter Thygesen",
        "Reporter": "Peter Thygesen",
        "Created": "07/Mar/17 23:14",
        "Updated": "16/Mar/17 10:47",
        "Resolved": "16/Mar/17 10:47",
        "Description": "The BilouNameFinderSequenceValidator is missing a test.",
        "Issue Links": [
            "https://github.com/apache/opennlp/pull/139"
        ]
    },
    "OPENNLP-1001": {
        "Key": "OPENNLP-1001",
        "Summary": "Chunker SequenceValidator should have access to both token and POS tag",
        "Type": "Improvement",
        "Status": "Closed",
        "Priority": "Major",
        "Resolution": "Fixed",
        "Affects Version/s": "None",
        "Fix Version/s": "1.8.0",
        "Component/s": "Chunker",
        "Assignee": "William Colen",
        "Reporter": "William Colen",
        "Created": "09/Mar/17 23:36",
        "Updated": "07/May/17 19:11",
        "Resolved": "07/May/17 19:11",
        "Description": null,
        "Issue Links": [
            "https://github.com/apache/opennlp/pull/137"
        ]
    },
    "OPENNLP-1002": {
        "Key": "OPENNLP-1002",
        "Summary": "Remove deprecated GIS class",
        "Type": "Improvement",
        "Status": "Closed",
        "Priority": "Minor",
        "Resolution": "Fixed",
        "Affects Version/s": "None",
        "Fix Version/s": "1.8.0",
        "Component/s": "Machine Learning",
        "Assignee": "J\u00f6rn Kottmann",
        "Reporter": "J\u00f6rn Kottmann",
        "Created": "10/Mar/17 15:49",
        "Updated": "13/Mar/17 16:27",
        "Resolved": "13/Mar/17 16:27",
        "Description": null,
        "Issue Links": [
            "https://github.com/apache/opennlp/pull/138",
            "https://github.com/apache/opennlp/pull/140"
        ]
    },
    "OPENNLP-1003": {
        "Key": "OPENNLP-1003",
        "Summary": "Write a test case for the BioCodec class",
        "Type": "Task",
        "Status": "Closed",
        "Priority": "Minor",
        "Resolution": "Fixed",
        "Affects Version/s": "1.7.2",
        "Fix Version/s": "1.8.0",
        "Component/s": "Name Finder",
        "Assignee": "Peter Thygesen",
        "Reporter": "Peter Thygesen",
        "Created": "14/Mar/17 21:49",
        "Updated": "15/Mar/17 09:33",
        "Resolved": "15/Mar/17 09:33",
        "Description": "BioCodec is missing a test.",
        "Issue Links": [
            "https://github.com/apache/opennlp/pull/141"
        ]
    },
    "OPENNLP-1004": {
        "Key": "OPENNLP-1004",
        "Summary": "Write a test case for the BilouCodec class",
        "Type": "Task",
        "Status": "Closed",
        "Priority": "Minor",
        "Resolution": "Fixed",
        "Affects Version/s": "1.7.2",
        "Fix Version/s": "1.8.0",
        "Component/s": "Name Finder",
        "Assignee": "Peter Thygesen",
        "Reporter": "Peter Thygesen",
        "Created": "14/Mar/17 21:50",
        "Updated": "16/Mar/17 10:48",
        "Resolved": "16/Mar/17 10:48",
        "Description": "BilouCodec is missing a test.",
        "Issue Links": [
            "https://github.com/apache/opennlp/pull/142"
        ]
    },
    "OPENNLP-1005": {
        "Key": "OPENNLP-1005",
        "Summary": "Implement areOutcomesCompatible for BilouCodec",
        "Type": "Improvement",
        "Status": "Closed",
        "Priority": "Minor",
        "Resolution": "Fixed",
        "Affects Version/s": "1.7.2",
        "Fix Version/s": "1.8.0",
        "Component/s": "Name Finder",
        "Assignee": "Peter Thygesen",
        "Reporter": "Peter Thygesen",
        "Created": "14/Mar/17 21:51",
        "Updated": "29/Apr/17 18:50",
        "Resolved": "28/Apr/17 17:27",
        "Description": "areOutcomesCompatible is not implemented. Current version just returns true.\nWrite an implementation inspired by BioCodec.\nAlso fix. References to BioCodec tags, they should be replaced by BilouCodec tags.",
        "Issue Links": [
            "https://github.com/apache/opennlp/pull/144"
        ]
    },
    "OPENNLP-1006": {
        "Key": "OPENNLP-1006",
        "Summary": "Refactor usage of tag constants in sequence validators",
        "Type": "Improvement",
        "Status": "Closed",
        "Priority": "Minor",
        "Resolution": "Fixed",
        "Affects Version/s": "None",
        "Fix Version/s": "1.8.0",
        "Component/s": "Name Finder",
        "Assignee": "Peter Thygesen",
        "Reporter": "Peter Thygesen",
        "Created": "15/Mar/17 16:55",
        "Updated": "16/Apr/17 21:57",
        "Resolved": "11/Apr/17 21:43",
        "Description": "NameFinderME tags should not be used in the codec classes. Use the codecs own tags.",
        "Issue Links": [
            "https://github.com/apache/opennlp/pull/148"
        ]
    },
    "OPENNLP-1007": {
        "Key": "OPENNLP-1007",
        "Summary": "Typo in EvaluationMonitor method signature",
        "Type": "Bug",
        "Status": "Closed",
        "Priority": "Minor",
        "Resolution": "Fixed",
        "Affects Version/s": "None",
        "Fix Version/s": "2.1.1",
        "Component/s": "Command Line Interface",
        "Assignee": "Martin Wiesner",
        "Reporter": "William Colen",
        "Created": "16/Mar/17 13:53",
        "Updated": "30/Nov/22 15:39",
        "Resolved": "30/Nov/22 15:39",
        "Description": "opennlp.tools.util.eval.EvaluationMonitor#missclassified",
        "Issue Links": []
    },
    "OPENNLP-1008": {
        "Key": "OPENNLP-1008",
        "Summary": "Add evaluation test for Conll 03",
        "Type": "Improvement",
        "Status": "Open",
        "Priority": "Minor",
        "Resolution": "Unresolved",
        "Affects Version/s": "None",
        "Fix Version/s": "None",
        "Component/s": "Name Finder",
        "Assignee": null,
        "Reporter": "J\u00f6rn Kottmann",
        "Created": "17/Mar/17 13:30",
        "Updated": "06/Jun/17 20:11",
        "Resolved": null,
        "Description": null,
        "Issue Links": []
    },
    "OPENNLP-1009": {
        "Key": "OPENNLP-1009",
        "Summary": "Experiment with deep learning based algorithms in OpenNLP",
        "Type": "Task",
        "Status": "Closed",
        "Priority": "Major",
        "Resolution": "Abandoned",
        "Affects Version/s": "None",
        "Fix Version/s": "None",
        "Component/s": "None",
        "Assignee": null,
        "Reporter": "Tommaso Teofili",
        "Created": "17/Mar/17 14:06",
        "Updated": "22/Apr/23 17:18",
        "Resolved": "22/Apr/23 17:18",
        "Description": "It'd be interesting to experiment with deep learning algorithms in OpenNLP.\nPossible experiments can include using recurrent and / or convolutional neural networks for NER, language detection, document categorization, etc.\nWe could just leverage such algorithms during the training phase and let the prediction phase as it is, as ti minimize impact on API / users.\nFrom the tooling perspective we could start experimenting with DeepLearning4J and Nd4j.",
        "Issue Links": [
            "https://github.com/apache/opennlp-sandbox/pull/20"
        ]
    },
    "OPENNLP-1010": {
        "Key": "OPENNLP-1010",
        "Summary": "NaiveBayes serialized models are not working",
        "Type": "Bug",
        "Status": "Closed",
        "Priority": "Major",
        "Resolution": "Fixed",
        "Affects Version/s": "1.7.2",
        "Fix Version/s": "1.7.2",
        "Component/s": "Machine Learning",
        "Assignee": "William Colen",
        "Reporter": "William Colen",
        "Created": "18/Mar/17 02:21",
        "Updated": "14/Apr/17 12:46",
        "Resolved": "14/Apr/17 12:46",
        "Description": "The behaviour of a serialized model is different from a model that was never serialized. For example, sometimes using the serialized we get only one outcome, while it was working perfectly during cross validation (when we use it before serializing).\nThe attached test reproduces it. It compares the outcome array of a model that was never serialized and the same model that was serialized and loaded.",
        "Issue Links": [
            "https://github.com/apache/opennlp/pull/154"
        ]
    },
    "OPENNLP-1011": {
        "Key": "OPENNLP-1011",
        "Summary": "Fix POS Tagger evaluation tests",
        "Type": "Bug",
        "Status": "Closed",
        "Priority": "Major",
        "Resolution": "Fixed",
        "Affects Version/s": "None",
        "Fix Version/s": "1.8.0",
        "Component/s": "POS Tagger",
        "Assignee": "J\u00f6rn Kottmann",
        "Reporter": "J\u00f6rn Kottmann",
        "Created": "22/Mar/17 19:03",
        "Updated": "16/Apr/17 21:57",
        "Resolved": "09/Apr/17 21:26",
        "Description": null,
        "Issue Links": [
            "https://github.com/apache/opennlp/pull/145"
        ]
    },
    "OPENNLP-1012": {
        "Key": "OPENNLP-1012",
        "Summary": "Write a test case for NameSampleTypeFilter",
        "Type": "Test",
        "Status": "Closed",
        "Priority": "Minor",
        "Resolution": "Fixed",
        "Affects Version/s": "None",
        "Fix Version/s": "1.8.0",
        "Component/s": "Name Finder",
        "Assignee": "Peter Thygesen",
        "Reporter": "Peter Thygesen",
        "Created": "28/Mar/17 15:11",
        "Updated": "16/Apr/17 21:57",
        "Resolved": "11/Apr/17 21:43",
        "Description": "Test is missing.",
        "Issue Links": [
            "https://github.com/apache/opennlp/pull/149",
            "https://github.com/apache/opennlp/pull/150"
        ]
    },
    "OPENNLP-1013": {
        "Key": "OPENNLP-1013",
        "Summary": "[OpenNLP][R Language][1.5.3-2] Bug when using French models",
        "Type": "Bug",
        "Status": "Closed",
        "Priority": "Major",
        "Resolution": "Won't Fix",
        "Affects Version/s": "tools-1.5.3",
        "Fix Version/s": "None",
        "Component/s": "POS Tagger",
        "Assignee": null,
        "Reporter": "Iuri Deolindo Nogueira",
        "Created": "31/Mar/17 08:34",
        "Updated": "11/Jul/17 09:10",
        "Resolved": "11/Jul/17 09:10",
        "Description": "When using French models in R language, I'm receving a \"subscript out of bound\" issue. I'm going to detail:\n-------------------------\nWell, I'm using French models to NLP in R environment. To get the french models, I'm using binaries compiled and develloped by Nicolas:\nhttps://sites.google.com/site/nicolashernandez/resources/opennlp\nhttp://enicolashernandez.blogspot.fr/2012/12/apache-opennlp-fr-models.html\nhttps://drive.google.com/drive/folders/0B4AyWQriFkxgWHR6QzlvcmxmdE0\n-------------------------\nThe problem it happens only with the POS function. This is how I call the function and respective issue:\nMaxent_POS_Tag_Annotator(language = \"fr\", probs = TRUE, model = paste0(<path_folder_with_bins>, \"fr-pos.bin\"))\nIssue: \nError in environment(f)$meta[[tag]] : subscript out of bounds\n-------------------------\nHowever, if I deleted the language parameter, the issue does not happen anymore:\nMaxent_POS_Tag_Annotator(probs = TRUE, model = paste0(<path_folder_with_bins>, \"fr-pos.bin\"))",
        "Issue Links": []
    },
    "OPENNLP-1014": {
        "Key": "OPENNLP-1014",
        "Summary": "Add more tests for featuregen",
        "Type": "Improvement",
        "Status": "Closed",
        "Priority": "Minor",
        "Resolution": "Fixed",
        "Affects Version/s": "1.7.2",
        "Fix Version/s": "1.8.0",
        "Component/s": "Build, Packaging and Test,                                            Name Finder",
        "Assignee": "Suneel Marthi",
        "Reporter": "Koji Sekiguchi",
        "Created": "07/Apr/17 01:26",
        "Updated": "16/Apr/17 21:57",
        "Resolved": "11/Apr/17 19:22",
        "Description": "Very simple and trivial ones, but important and useful for the robustness.\nI'll post PR soon.",
        "Issue Links": [
            "https://github.com/apache/opennlp/pull/151"
        ]
    },
    "OPENNLP-1015": {
        "Key": "OPENNLP-1015",
        "Summary": "Add tests for DataIndexers",
        "Type": "Test",
        "Status": "Closed",
        "Priority": "Minor",
        "Resolution": "Fixed",
        "Affects Version/s": "None",
        "Fix Version/s": "1.8.0",
        "Component/s": "Build, Packaging and Test,                                            Name Finder",
        "Assignee": "Koji Sekiguchi",
        "Reporter": "Koji Sekiguchi",
        "Created": "07/Apr/17 12:48",
        "Updated": "27/Apr/17 08:29",
        "Resolved": "27/Apr/17 08:29",
        "Description": "Seeing DataIndexers, I thought we could refactor them. However, when I tried to do it, I realized there is no tests for DataIndexers.\nBefore refactoring, they should have their tests. I'll post PR soon.",
        "Issue Links": [
            "https://github.com/apache/opennlp/pull/152"
        ]
    },
    "OPENNLP-1016": {
        "Key": "OPENNLP-1016",
        "Summary": "Add more tests for StringList",
        "Type": "Test",
        "Status": "Closed",
        "Priority": "Trivial",
        "Resolution": "Fixed",
        "Affects Version/s": "None",
        "Fix Version/s": "1.8.0",
        "Component/s": "Build, Packaging and Test",
        "Assignee": "Koji Sekiguchi",
        "Reporter": "Koji Sekiguchi",
        "Created": "10/Apr/17 05:15",
        "Updated": "27/Apr/17 08:30",
        "Resolved": "27/Apr/17 08:30",
        "Description": "I added some tests for StringList to check:\n\nthe constructor which uses String.intern()\nhashCode which should return different hashCodes if the contents are different\ntoString (testToString() already exists, but I saw it doesn't check anything   )\n\nI'll post PR soon.",
        "Issue Links": [
            "https://github.com/apache/opennlp/pull/153"
        ]
    },
    "OPENNLP-1017": {
        "Key": "OPENNLP-1017",
        "Summary": "OpenNlp NameFinderCrossValidation gives InsufficientTrainingDataException",
        "Type": "Bug",
        "Status": "Closed",
        "Priority": "Major",
        "Resolution": "Cannot Reproduce",
        "Affects Version/s": "None",
        "Fix Version/s": "None",
        "Component/s": "None",
        "Assignee": null,
        "Reporter": "Saurabh Jain",
        "Created": "11/Apr/17 14:34",
        "Updated": "08/Aug/17 14:13",
        "Resolved": "29/Jun/17 22:00",
        "Description": "OpenNlp NameFinderCrossValidation gives InsufficientTrainingDataException.\nWith nfold value 3, I tried to cross validate NameFinder training data. After doing a research I got to know that first partition is assinged null data.",
        "Issue Links": []
    },
    "OPENNLP-1018": {
        "Key": "OPENNLP-1018",
        "Summary": "Add more tests for ObjectStreams",
        "Type": "Test",
        "Status": "Closed",
        "Priority": "Trivial",
        "Resolution": "Fixed",
        "Affects Version/s": "None",
        "Fix Version/s": "1.8.0",
        "Component/s": "Build, Packaging and Test",
        "Assignee": "Koji Sekiguchi",
        "Reporter": "Koji Sekiguchi",
        "Created": "14/Apr/17 03:28",
        "Updated": "18/Apr/17 04:55",
        "Resolved": "18/Apr/17 04:43",
        "Description": "Some ObjectStreams such as FileEventStream and RealValueFileEventStream don't have tests. Other ObjectStreams such as PlainTextByLineStream have tests but don't check null (when they exhausted) or reset.",
        "Issue Links": [
            "https://github.com/apache/opennlp/pull/164"
        ]
    },
    "OPENNLP-1019": {
        "Key": "OPENNLP-1019",
        "Summary": "Parser Eval Test is not correctly checking the result",
        "Type": "Bug",
        "Status": "Closed",
        "Priority": "Minor",
        "Resolution": "Fixed",
        "Affects Version/s": "None",
        "Fix Version/s": "1.8.0",
        "Component/s": "Build, Packaging and Test,                                            Parser",
        "Assignee": "J\u00f6rn Kottmann",
        "Reporter": "J\u00f6rn Kottmann",
        "Created": "14/Apr/17 08:51",
        "Updated": "16/Apr/17 21:57",
        "Resolved": "15/Apr/17 17:53",
        "Description": "The parser eval test is not using Assert.assertEquals correctly to test the result.",
        "Issue Links": [
            "https://github.com/apache/opennlp/pull/155"
        ]
    },
    "OPENNLP-1020": {
        "Key": "OPENNLP-1020",
        "Summary": "MockInputStreamFactory.createInputStream should create a new InputStream",
        "Type": "Bug",
        "Status": "Closed",
        "Priority": "Minor",
        "Resolution": "Fixed",
        "Affects Version/s": "1.7.2",
        "Fix Version/s": "1.8.0",
        "Component/s": "Build, Packaging and Test",
        "Assignee": "Koji Sekiguchi",
        "Reporter": "Koji Sekiguchi",
        "Created": "14/Apr/17 10:14",
        "Updated": "17/Apr/17 01:50",
        "Resolved": "17/Apr/17 01:48",
        "Description": "Working on OPENNLP-1018, if I added a test for reset() of PlainTextByLineStream to the existing PlainTextByLineStreamTest, it doesn't work because it uses MockInputStreamFactory and call MockInputStreamFactory.createInputStream() in reset() but MockInputStreamFactory.createInputStream() doesn't create a new input stream but just returns input stream which it holds instead.",
        "Issue Links": [
            "https://github.com/apache/opennlp/pull/156"
        ]
    },
    "OPENNLP-1021": {
        "Key": "OPENNLP-1021",
        "Summary": "Reduce number of folds in OntoNotes Cross Evaluation tests",
        "Type": "Improvement",
        "Status": "Closed",
        "Priority": "Minor",
        "Resolution": "Fixed",
        "Affects Version/s": "None",
        "Fix Version/s": "1.8.0",
        "Component/s": "Build, Packaging and Test",
        "Assignee": "J\u00f6rn Kottmann",
        "Reporter": "J\u00f6rn Kottmann",
        "Created": "14/Apr/17 11:03",
        "Updated": "08/May/17 13:38",
        "Resolved": "08/May/17 13:38",
        "Description": "Reduce the number of folds from 10 to 5 in the OntoNotes Cross Evaluation based tests.",
        "Issue Links": [
            "https://github.com/apache/opennlp/pull/184"
        ]
    },
    "OPENNLP-1022": {
        "Key": "OPENNLP-1022",
        "Summary": "Fix documentation to remove references to 'Save XXXModel to database'",
        "Type": "Bug",
        "Status": "Closed",
        "Priority": "Trivial",
        "Resolution": "Fixed",
        "Affects Version/s": "1.7.2",
        "Fix Version/s": "1.8.0",
        "Component/s": "Documentation",
        "Assignee": "Suneel Marthi",
        "Reporter": "Suneel Marthi",
        "Created": "15/Apr/17 16:24",
        "Updated": "17/Apr/17 01:49",
        "Resolved": "17/Apr/17 01:49",
        "Description": "Fix documentation to remove references to 'Save XXXModel to database' since its not supported today and is up to  the user to implement that.",
        "Issue Links": [
            "https://github.com/apache/opennlp/pull/158"
        ]
    },
    "OPENNLP-1023": {
        "Key": "OPENNLP-1023",
        "Summary": "Remove unused HashList class",
        "Type": "Improvement",
        "Status": "Closed",
        "Priority": "Minor",
        "Resolution": "Fixed",
        "Affects Version/s": "1.7.2",
        "Fix Version/s": "1.8.0",
        "Component/s": "None",
        "Assignee": "Jeff Zemerick",
        "Reporter": "Jeff Zemerick",
        "Created": "15/Apr/17 19:32",
        "Updated": "16/Apr/17 21:57",
        "Resolved": "16/Apr/17 20:31",
        "Description": "Remove unused HashList class.",
        "Issue Links": [
            "https://github.com/apache/opennlp/pull/159"
        ]
    },
    "OPENNLP-1024": {
        "Key": "OPENNLP-1024",
        "Summary": "Add unit tests and javadocs for DirectorySampleStream",
        "Type": "Improvement",
        "Status": "Closed",
        "Priority": "Minor",
        "Resolution": "Fixed",
        "Affects Version/s": "None",
        "Fix Version/s": "1.8.0",
        "Component/s": "None",
        "Assignee": "Jeff Zemerick",
        "Reporter": "Jeff Zemerick",
        "Created": "15/Apr/17 20:38",
        "Updated": "16/Apr/17 21:57",
        "Resolved": "16/Apr/17 21:25",
        "Description": "Add unit tests and javadocs for DirectorySampleStream.",
        "Issue Links": [
            "https://github.com/apache/opennlp/pull/160"
        ]
    },
    "OPENNLP-1025": {
        "Key": "OPENNLP-1025",
        "Summary": "Add unit test and javadocs for FileToStringSampleStream",
        "Type": "Improvement",
        "Status": "Closed",
        "Priority": "Minor",
        "Resolution": "Fixed",
        "Affects Version/s": "None",
        "Fix Version/s": "1.8.0",
        "Component/s": "None",
        "Assignee": "Jeff Zemerick",
        "Reporter": "Jeff Zemerick",
        "Created": "16/Apr/17 11:33",
        "Updated": "16/Apr/17 21:57",
        "Resolved": "16/Apr/17 21:26",
        "Description": "Add unit test and javadocs for FileToStringSampleStream.",
        "Issue Links": [
            "https://github.com/apache/opennlp/pull/161"
        ]
    },
    "OPENNLP-1026": {
        "Key": "OPENNLP-1026",
        "Summary": "Replace references and usages of opennlp.tools.util.Heap with java.util.PriorityQueue",
        "Type": "Improvement",
        "Status": "Closed",
        "Priority": "Major",
        "Resolution": "Fixed",
        "Affects Version/s": "1.7.0",
        "Fix Version/s": "1.8.0",
        "Component/s": "Parser",
        "Assignee": "Suneel Marthi",
        "Reporter": "Suneel Marthi",
        "Created": "16/Apr/17 23:52",
        "Updated": "03/May/17 09:47",
        "Resolved": "03/May/17 09:47",
        "Description": "Replace references and invocations of opennlp.tools.util.Heap with java.util.Queue",
        "Issue Links": [
            "https://github.com/apache/opennlp/pull/162",
            "https://github.com/apache/opennlp/pull/187"
        ]
    },
    "OPENNLP-1027": {
        "Key": "OPENNLP-1027",
        "Summary": "Add tests for Event",
        "Type": "Test",
        "Status": "Closed",
        "Priority": "Trivial",
        "Resolution": "Fixed",
        "Affects Version/s": "None",
        "Fix Version/s": "1.8.0",
        "Component/s": "Build, Packaging and Test",
        "Assignee": "Koji Sekiguchi",
        "Reporter": "Koji Sekiguchi",
        "Created": "18/Apr/17 05:37",
        "Updated": "18/Apr/17 22:42",
        "Resolved": "18/Apr/17 22:42",
        "Description": "When I worked on OPENNLP-1018, I realized this one. This is very trivial, but I think small PR is more preferable than large one, so I open this.",
        "Issue Links": [
            "https://github.com/apache/opennlp/pull/165"
        ]
    },
    "OPENNLP-1028": {
        "Key": "OPENNLP-1028",
        "Summary": "Add tests for FeatureGenerators in doccat",
        "Type": "Test",
        "Status": "Closed",
        "Priority": "Minor",
        "Resolution": "Fixed",
        "Affects Version/s": "None",
        "Fix Version/s": "1.8.0",
        "Component/s": "Build, Packaging and Test,                                            Doccat",
        "Assignee": "Koji Sekiguchi",
        "Reporter": "Koji Sekiguchi",
        "Created": "18/Apr/17 08:17",
        "Updated": "19/Apr/17 20:10",
        "Resolved": "19/Apr/17 20:10",
        "Description": "FeatureGenerators in doccat don't have test.",
        "Issue Links": [
            "https://github.com/apache/opennlp/pull/166"
        ]
    },
    "OPENNLP-1029": {
        "Key": "OPENNLP-1029",
        "Summary": "Add tests to check for InsufficientTrainingDataException",
        "Type": "Test",
        "Status": "Closed",
        "Priority": "Minor",
        "Resolution": "Fixed",
        "Affects Version/s": "None",
        "Fix Version/s": "1.8.0",
        "Component/s": "Build, Packaging and Test",
        "Assignee": "Jeff Zemerick",
        "Reporter": "Jeff Zemerick",
        "Created": "18/Apr/17 17:30",
        "Updated": "19/Apr/17 18:14",
        "Resolved": "19/Apr/17 18:14",
        "Description": "InsufficientTrainingDataException exceptions are thrown when creating models without enough training data. Add tests to verify that InsufficientTrainingDataException is thrown in these instances.",
        "Issue Links": [
            "https://github.com/apache/opennlp/pull/167"
        ]
    },
    "OPENNLP-1030": {
        "Key": "OPENNLP-1030",
        "Summary": "Add unit test for TokenNameFinderTool",
        "Type": "Test",
        "Status": "Closed",
        "Priority": "Minor",
        "Resolution": "Fixed",
        "Affects Version/s": "None",
        "Fix Version/s": "1.8.0",
        "Component/s": "Build, Packaging and Test",
        "Assignee": "Jeff Zemerick",
        "Reporter": "Jeff Zemerick",
        "Created": "19/Apr/17 00:14",
        "Updated": "19/Apr/17 00:45",
        "Resolved": "19/Apr/17 00:45",
        "Description": "Add unit test for TokenNameFinderTool.",
        "Issue Links": [
            "https://github.com/apache/opennlp/pull/168"
        ]
    },
    "OPENNLP-1031": {
        "Key": "OPENNLP-1031",
        "Summary": "Use getIntParameter when getting beam size",
        "Type": "Improvement",
        "Status": "Closed",
        "Priority": "Trivial",
        "Resolution": "Fixed",
        "Affects Version/s": "None",
        "Fix Version/s": "1.8.0",
        "Component/s": "Chunker,                                            Lemmatizer,                                            Name Finder,                                            POS Tagger",
        "Assignee": "Koji Sekiguchi",
        "Reporter": "Koji Sekiguchi",
        "Created": "19/Apr/17 03:14",
        "Updated": "19/Apr/17 09:01",
        "Resolved": "19/Apr/17 09:01",
        "Description": "In the training codes, to get beam size, they get String value first then convert it to int, but they should use getIntParameter instead.",
        "Issue Links": [
            "https://github.com/apache/opennlp/pull/169"
        ]
    },
    "OPENNLP-1032": {
        "Key": "OPENNLP-1032",
        "Summary": "Add tests for TrainingParameters",
        "Type": "Test",
        "Status": "Closed",
        "Priority": "Trivial",
        "Resolution": "Fixed",
        "Affects Version/s": "None",
        "Fix Version/s": "1.8.0",
        "Component/s": "Build, Packaging and Test",
        "Assignee": "Koji Sekiguchi",
        "Reporter": "Koji Sekiguchi",
        "Created": "19/Apr/17 03:25",
        "Updated": "20/Apr/17 01:19",
        "Resolved": "20/Apr/17 01:19",
        "Description": "When I worked on OPENNLP-1031, I thought we need this...",
        "Issue Links": [
            "https://github.com/apache/opennlp/pull/171"
        ]
    },
    "OPENNLP-1033": {
        "Key": "OPENNLP-1033",
        "Summary": "Add unit tests for missing coverage in the opennlp.tools.ngram package",
        "Type": "Test",
        "Status": "Closed",
        "Priority": "Major",
        "Resolution": "Fixed",
        "Affects Version/s": "None",
        "Fix Version/s": "1.8.0",
        "Component/s": "Build, Packaging and Test",
        "Assignee": "Jeff Zemerick",
        "Reporter": "Jeff Zemerick",
        "Created": "19/Apr/17 15:54",
        "Updated": "19/Apr/17 19:55",
        "Resolved": "19/Apr/17 19:55",
        "Description": "Add unit tests for missing coverage in the opennlp.tools.ngram package.",
        "Issue Links": [
            "https://github.com/apache/opennlp/pull/172"
        ]
    },
    "OPENNLP-1034": {
        "Key": "OPENNLP-1034",
        "Summary": "Improve resource loading for custom feature generators",
        "Type": "Improvement",
        "Status": "Closed",
        "Priority": "Minor",
        "Resolution": "Fixed",
        "Affects Version/s": "None",
        "Fix Version/s": "1.8.0",
        "Component/s": "Name Finder,                                            POS Tagger",
        "Assignee": "J\u00f6rn Kottmann",
        "Reporter": "J\u00f6rn Kottmann",
        "Created": "19/Apr/17 16:31",
        "Updated": "21/Apr/17 09:36",
        "Resolved": "21/Apr/17 09:36",
        "Description": "Currently the feature generators are matched in the TokenNameFinderTool which is part of the cmd line interface. To improve this the logic should be moved to the GeneratorFactory.",
        "Issue Links": [
            "https://github.com/apache/opennlp/pull/173"
        ]
    },
    "OPENNLP-1035": {
        "Key": "OPENNLP-1035",
        "Summary": "Add unit tests and javadocs for BrownBigramFeatureGenerator",
        "Type": "Test",
        "Status": "Closed",
        "Priority": "Minor",
        "Resolution": "Fixed",
        "Affects Version/s": "None",
        "Fix Version/s": "1.8.0",
        "Component/s": "Build, Packaging and Test",
        "Assignee": "Jeff Zemerick",
        "Reporter": "Jeff Zemerick",
        "Created": "19/Apr/17 23:41",
        "Updated": "25/Apr/17 12:06",
        "Resolved": "25/Apr/17 12:06",
        "Description": "Add unit tests and javadocs for BrownBigramFeatureGenerator.",
        "Issue Links": [
            "https://github.com/apache/opennlp/pull/174"
        ]
    },
    "OPENNLP-1036": {
        "Key": "OPENNLP-1036",
        "Summary": "Use Object values in TrainingParameters instead of String",
        "Type": "Improvement",
        "Status": "Closed",
        "Priority": "Minor",
        "Resolution": "Fixed",
        "Affects Version/s": "None",
        "Fix Version/s": "1.8.0",
        "Component/s": "Chunker,                                            Doccat,                                            Lemmatizer,                                            Name Finder,                                            POS Tagger,                                            Sentence Detector,                                            Tokenizer",
        "Assignee": "Koji Sekiguchi",
        "Reporter": "Koji Sekiguchi",
        "Created": "20/Apr/17 07:02",
        "Updated": "21/Apr/17 15:43",
        "Resolved": "21/Apr/17 15:43",
        "Description": "When I worked on OPENNLP-1032, I realized that TrainingParameters manages parameters as Map<String,String>. So, users have to set their int parameters like this:\n\ntrainParam.put(\"name\", \"100\");\n\n\nbut it should look like this:\n\ntrainParam.put(\"name\", 100);",
        "Issue Links": [
            "https://github.com/apache/opennlp/pull/176"
        ]
    },
    "OPENNLP-1037": {
        "Key": "OPENNLP-1037",
        "Summary": "OpenNLP build fails if only the eval tests are run",
        "Type": "Bug",
        "Status": "Closed",
        "Priority": "Minor",
        "Resolution": "Fixed",
        "Affects Version/s": "None",
        "Fix Version/s": "1.8.0",
        "Component/s": "Build, Packaging and Test",
        "Assignee": "Peter Thygesen",
        "Reporter": "J\u00f6rn Kottmann",
        "Created": "20/Apr/17 08:55",
        "Updated": "05/May/17 22:36",
        "Resolved": "05/May/17 22:36",
        "Description": "The eval tests usually only run a few selected tests, this results in zero tests run in the opennlp-uima (and other) modules.\nRunning zero tests should not fail the build.\nTo reproduce this:\n\nGo to top level\nRun some eval tests",
        "Issue Links": [
            "https://github.com/apache/opennlp/pull/193"
        ]
    },
    "OPENNLP-1038": {
        "Key": "OPENNLP-1038",
        "Summary": "Psychological and stylistic text analysis features",
        "Type": "New Feature",
        "Status": "Open",
        "Priority": "Major",
        "Resolution": "Unresolved",
        "Affects Version/s": "None",
        "Fix Version/s": "None",
        "Component/s": "None",
        "Assignee": null,
        "Reporter": "Madhav Sharan",
        "Created": "21/Apr/17 00:21",
        "Updated": "10/May/17 20:18",
        "Resolved": null,
        "Description": "I tried to find a free version of LIWC but could not find one.\nThere are such features in tika-similarity coded in python. They are proved useful in some Memex projects. My plan is to integrate it in OpenNLP\n[0] https://github.com/chrismattmann/tika-similarity#similarity-based-on-stylisticauthorship-features",
        "Issue Links": []
    },
    "OPENNLP-1039": {
        "Key": "OPENNLP-1039",
        "Summary": "PerceptronTrainer should call super.isValid() in its isValid()",
        "Type": "Bug",
        "Status": "Closed",
        "Priority": "Trivial",
        "Resolution": "Fixed",
        "Affects Version/s": "None",
        "Fix Version/s": "1.8.0",
        "Component/s": "None",
        "Assignee": "Koji Sekiguchi",
        "Reporter": "Koji Sekiguchi",
        "Created": "21/Apr/17 09:38",
        "Updated": "24/Apr/17 02:01",
        "Resolved": "24/Apr/17 02:01",
        "Description": "The current implementation of PerceptronTrainer#isValid() is:\n\n  public boolean isValid() {\n    String algorithmName = getAlgorithm();\n    return !(algorithmName != null && !(PERCEPTRON_VALUE.equals(algorithmName)));\n  }\n\n\nbut it should call super.isValid() to check iterations and cutoff parameters because PerceptronTrainer uses them.\nAnd if possible, I'd like to rewrite the last line (return statement) because I needed a few minutes to understand it as it has three exclamation points in one line.",
        "Issue Links": [
            "https://github.com/apache/opennlp/pull/177"
        ]
    },
    "OPENNLP-1040": {
        "Key": "OPENNLP-1040",
        "Summary": "Add test data verificatin for OntoNotes4 eval tests",
        "Type": "Improvement",
        "Status": "Closed",
        "Priority": "Minor",
        "Resolution": "Fixed",
        "Affects Version/s": "None",
        "Fix Version/s": "1.8.0",
        "Component/s": "Build, Packaging and Test",
        "Assignee": "J\u00f6rn Kottmann",
        "Reporter": "J\u00f6rn Kottmann",
        "Created": "21/Apr/17 10:52",
        "Updated": "24/Apr/17 11:07",
        "Resolved": "24/Apr/17 11:07",
        "Description": "It should be verified before the test is run if the data has the expected checksum.",
        "Issue Links": [
            "https://github.com/apache/opennlp/pull/178"
        ]
    },
    "OPENNLP-1041": {
        "Key": "OPENNLP-1041",
        "Summary": "SF Eval tests should use BeforeClass to verify test data",
        "Type": "Improvement",
        "Status": "Closed",
        "Priority": "Trivial",
        "Resolution": "Fixed",
        "Affects Version/s": "None",
        "Fix Version/s": "1.8.0",
        "Component/s": "Build, Packaging and Test",
        "Assignee": "J\u00f6rn Kottmann",
        "Reporter": "J\u00f6rn Kottmann",
        "Created": "21/Apr/17 12:34",
        "Updated": "24/Apr/17 10:36",
        "Resolved": "24/Apr/17 10:36",
        "Description": "The SF Eval tests currently use a normal @Test method to verify the test data, this should be changed to @BeforeClass to ensure this runs before executing other tests.",
        "Issue Links": [
            "https://github.com/apache/opennlp/pull/179"
        ]
    },
    "OPENNLP-1042": {
        "Key": "OPENNLP-1042",
        "Summary": "Parser Evaluator ignores tokenizaion of the parse tree",
        "Type": "Bug",
        "Status": "Closed",
        "Priority": "Minor",
        "Resolution": "Fixed",
        "Affects Version/s": "None",
        "Fix Version/s": "1.8.0",
        "Component/s": "Parser",
        "Assignee": "J\u00f6rn Kottmann",
        "Reporter": "J\u00f6rn Kottmann",
        "Created": "21/Apr/17 13:23",
        "Updated": "05/May/17 22:49",
        "Resolved": "05/May/17 22:48",
        "Description": "The Parser Evaluator assumes that the string inside the Parse object is white space tokenized, this might not always be the case. The Parse tree contains a node for each token and this information has to be used to cut the sentence string into tokens.",
        "Issue Links": [
            "https://github.com/apache/opennlp/pull/180"
        ]
    },
    "OPENNLP-1043": {
        "Key": "OPENNLP-1043",
        "Summary": "OntoNotes tests data is loaded in different oder on different machines",
        "Type": "Bug",
        "Status": "Closed",
        "Priority": "Major",
        "Resolution": "Fixed",
        "Affects Version/s": "None",
        "Fix Version/s": "1.8.0",
        "Component/s": "Build, Packaging and Test",
        "Assignee": "J\u00f6rn Kottmann",
        "Reporter": "J\u00f6rn Kottmann",
        "Created": "21/Apr/17 14:12",
        "Updated": "24/Apr/17 10:08",
        "Resolved": "24/Apr/17 09:59",
        "Description": "The OntoNotes test is scanning the directory tree for training data files using File.listFiles the order of the returned files is not specifed and varies from machine to machine. This causes test failures or different results in some tests.",
        "Issue Links": [
            "https://github.com/apache/opennlp/pull/181"
        ]
    },
    "OPENNLP-1044": {
        "Key": "OPENNLP-1044",
        "Summary": "Add validate() which checks validity of parameters in the process of the framework",
        "Type": "Improvement",
        "Status": "Closed",
        "Priority": "Minor",
        "Resolution": "Fixed",
        "Affects Version/s": "None",
        "Fix Version/s": "1.8.0",
        "Component/s": "None",
        "Assignee": "Koji Sekiguchi",
        "Reporter": "Koji Sekiguchi",
        "Created": "24/Apr/17 04:54",
        "Updated": "08/May/17 02:07",
        "Resolved": "08/May/17 02:07",
        "Description": "When I worked on OPENNLP-1039, I saw the client codes throw IllegalArgumentException when isValid() returns false, but I think such kind of methods should throw the Exception by themselves and the timing of use should be controlled by the framework.\nSo it should look like:\n\npublic abstract class AbstractTrainer {\n  @Depracated\n  public boolean isValid() { ... }\n\n  // if the subclass overrides this, it should call super.validate();\n  public void validate() throws IllegalArgumentException {\n    // default implementation here\n  }\n\n  // this is the controller of the flow of training...\n  public final void train() {\n    // initializing \n    init();\n\n    // validating parameters\n    validate();\n  }\n}",
        "Issue Links": [
            "https://github.com/apache/opennlp/pull/192"
        ]
    },
    "OPENNLP-1045": {
        "Key": "OPENNLP-1045",
        "Summary": "Add documentation for development with Git (at ASF, GitHub, etc) for OpenNLP",
        "Type": "Documentation",
        "Status": "Closed",
        "Priority": "Minor",
        "Resolution": "Done",
        "Affects Version/s": "None",
        "Fix Version/s": "None",
        "Component/s": "Website",
        "Assignee": "Bruno P. Kinoshita",
        "Reporter": "Bruno P. Kinoshita",
        "Created": "24/Apr/17 11:26",
        "Updated": "03/Apr/18 23:30",
        "Resolved": "03/Apr/18 23:30",
        "Description": "We need to add documentation for developers, explaining the process to work with Git in Apache OpenNLP.\nListing things like proper way to commit (e.g. include JIRA issue whenever possible in the commit message), how to handle and merge pull requests (e.g. empty commits, merge with fast-forward, etc), and so it goes.",
        "Issue Links": [
            "https://github.com/apache/opennlp-site/pull/11",
            "https://github.com/apache/opennlp-site/pull/21",
            "https://github.com/apache/opennlp-site/pull/25",
            "https://github.com/apache/opennlp-site/pull/11"
        ]
    },
    "OPENNLP-1046": {
        "Key": "OPENNLP-1046",
        "Summary": "Fix OntoNotes4 Parser eval regression",
        "Type": "Bug",
        "Status": "Closed",
        "Priority": "Minor",
        "Resolution": "Fixed",
        "Affects Version/s": "None",
        "Fix Version/s": "1.8.0",
        "Component/s": "Parser",
        "Assignee": "J\u00f6rn Kottmann",
        "Reporter": "J\u00f6rn Kottmann",
        "Created": "26/Apr/17 08:33",
        "Updated": "26/Apr/17 13:38",
        "Resolved": "26/Apr/17 13:38",
        "Description": "During a re-factoring of the command line ParserTool a bug was introduced which incorrectly concats tokens, the tokens should be \"a b c d\" but they are joined as \"a b c d \" (additional space at the end).",
        "Issue Links": [
            "https://github.com/apache/opennlp/pull/185"
        ]
    },
    "OPENNLP-1047": {
        "Key": "OPENNLP-1047",
        "Summary": "Add detokenizer and sentence detection abbreviations for Irish",
        "Type": "New Feature",
        "Status": "Closed",
        "Priority": "Minor",
        "Resolution": "Fixed",
        "Affects Version/s": "None",
        "Fix Version/s": "1.8.0",
        "Component/s": "Tokenizer",
        "Assignee": "J\u00f6rn Kottmann",
        "Reporter": "Jim Regan",
        "Created": "28/Apr/17 23:00",
        "Updated": "03/May/17 10:09",
        "Resolved": "03/May/17 10:09",
        "Description": null,
        "Issue Links": [
            "https://github.com/apache/opennlp/pull/188"
        ]
    },
    "OPENNLP-1048": {
        "Key": "OPENNLP-1048",
        "Summary": "Add stemmer for Irish",
        "Type": "New Feature",
        "Status": "Closed",
        "Priority": "Minor",
        "Resolution": "Fixed",
        "Affects Version/s": "None",
        "Fix Version/s": "1.8.0",
        "Component/s": "Stemmer",
        "Assignee": null,
        "Reporter": "Jim Regan",
        "Created": "28/Apr/17 23:12",
        "Updated": "03/May/17 10:17",
        "Resolved": "03/May/17 10:17",
        "Description": null,
        "Issue Links": [
            "https://github.com/apache/opennlp/pull/189"
        ]
    },
    "OPENNLP-1049": {
        "Key": "OPENNLP-1049",
        "Summary": "Rename snowball stemmer classes for Java naming conformance",
        "Type": "Improvement",
        "Status": "Resolved",
        "Priority": "Trivial",
        "Resolution": "Won't Do",
        "Affects Version/s": "None",
        "Fix Version/s": "None",
        "Component/s": "Stemmer",
        "Assignee": "Jeff Zemerick",
        "Reporter": "Jeff Zemerick",
        "Created": "30/Apr/17 19:10",
        "Updated": "19/Dec/17 22:58",
        "Resolved": "19/Dec/17 22:58",
        "Description": "Rename snowball stemmer classes for Java naming conformance, e.g. rename `turkishStemmer` to `TurkishStemmer`. This should not affect any implementations because all of the stemmers are accessed through the `SnowballStemmer()` constructor.",
        "Issue Links": [
            "https://github.com/apache/opennlp/pull/190",
            "https://github.com/apache/opennlp/pull/190"
        ]
    },
    "OPENNLP-1050": {
        "Key": "OPENNLP-1050",
        "Summary": "Add formats support for Irish Sentence Bank",
        "Type": "New Feature",
        "Status": "Closed",
        "Priority": "Minor",
        "Resolution": "Fixed",
        "Affects Version/s": "None",
        "Fix Version/s": "1.8.1",
        "Component/s": "Formats",
        "Assignee": "J\u00f6rn Kottmann",
        "Reporter": "Jim Regan",
        "Created": "30/Apr/17 20:14",
        "Updated": "24/May/17 14:58",
        "Resolved": "24/May/17 14:58",
        "Description": null,
        "Issue Links": [
            "https://github.com/apache/opennlp/pull/191"
        ]
    },
    "OPENNLP-1051": {
        "Key": "OPENNLP-1051",
        "Summary": "Add implementations of Tokenizer and SentenceDetector using BreakIterator",
        "Type": "Task",
        "Status": "Closed",
        "Priority": "Minor",
        "Resolution": "Won't Do",
        "Affects Version/s": "None",
        "Fix Version/s": "None",
        "Component/s": "Sentence Detector,                                            Tokenizer",
        "Assignee": "Jeff Zemerick",
        "Reporter": "Jeff Zemerick",
        "Created": "07/May/17 18:58",
        "Updated": "09/May/17 12:47",
        "Resolved": "09/May/17 12:47",
        "Description": "Add implementations of Tokenizer and SentenceDetector using BreakIterator.",
        "Issue Links": [
            "https://github.com/apache/opennlp/pull/194"
        ]
    },
    "OPENNLP-1052": {
        "Key": "OPENNLP-1052",
        "Summary": "Prepare the 1.8.0 release",
        "Type": "Task",
        "Status": "Closed",
        "Priority": "Major",
        "Resolution": "Fixed",
        "Affects Version/s": "None",
        "Fix Version/s": "1.8.0",
        "Component/s": "None",
        "Assignee": "William Colen",
        "Reporter": "William Colen",
        "Created": "09/May/17 15:47",
        "Updated": "09/May/17 16:15",
        "Resolved": "09/May/17 16:14",
        "Description": null,
        "Issue Links": [
            "https://github.com/apache/opennlp/pull/195"
        ]
    },
    "OPENNLP-1053": {
        "Key": "OPENNLP-1053",
        "Summary": "DOAP has moved",
        "Type": "Bug",
        "Status": "Closed",
        "Priority": "Major",
        "Resolution": "Fixed",
        "Affects Version/s": "None",
        "Fix Version/s": "None",
        "Component/s": "None",
        "Assignee": "Jeff Zemerick",
        "Reporter": "Sebb",
        "Created": "10/May/17 09:36",
        "Updated": "16/May/17 13:35",
        "Resolved": "14/May/17 10:53",
        "Description": "The DOAP used to be located at:\nhttp://opennlp.apache.org/doap_opennlp.rdf\nIt has disappeared.\nPlease either replace it, or update the link here:\nhttps://svn.apache.org/repos/asf/comdev/projects.apache.org/data/projects.xml",
        "Issue Links": [
            "https://github.com/apache/opennlp-site/pull/6"
        ]
    },
    "OPENNLP-1054": {
        "Key": "OPENNLP-1054",
        "Summary": "Remove deprecated code from the util package",
        "Type": "Improvement",
        "Status": "Closed",
        "Priority": "Minor",
        "Resolution": "Fixed",
        "Affects Version/s": "None",
        "Fix Version/s": "1.8.1",
        "Component/s": "None",
        "Assignee": "J\u00f6rn Kottmann",
        "Reporter": "J\u00f6rn Kottmann",
        "Created": "10/May/17 14:45",
        "Updated": "19/May/17 10:19",
        "Resolved": "19/May/17 10:19",
        "Description": null,
        "Issue Links": [
            "https://github.com/apache/opennlp/pull/196"
        ]
    },
    "OPENNLP-1055": {
        "Key": "OPENNLP-1055",
        "Summary": "POSTagger.train causing error",
        "Type": "Bug",
        "Status": "Closed",
        "Priority": "Major",
        "Resolution": "Cannot Reproduce",
        "Affects Version/s": "None",
        "Fix Version/s": "1.8.1",
        "Component/s": "None",
        "Assignee": "Suneel Marthi",
        "Reporter": "zaheen mumtaz",
        "Created": "11/May/17 12:53",
        "Updated": "29/Jun/17 21:56",
        "Resolved": "29/Jun/17 21:53",
        "Description": "i am trying to create urdu POS tagger model. how to train my ur-pos.bin fille according to my train data...i work on it alot but have error at line \nmodel = POSTaggerME.train(\"en\", sampleStream, TrainingParameters.defaultParams(), factory);\nerror is following:\nException in thread \"main\" java.lang.NoClassDefFoundError: opennlp/model/TrainUtil\n\tat opennlp.tools.postag.POSTaggerME.train(POSTaggerME.java:332)\n\tat myproject.TaggerDictionaryTest.testTrainTaggerWithDictionary(TaggerDictionaryTest.java:98)\n\tat myproject.TaggerDictionaryTest.main(TaggerDictionaryTest.java:40)\nCaused by: java.lang.ClassNotFoundException: opennlp.model.TrainUtil\n\tat java.net.URLClassLoader.findClass(Unknown Source)\n\tat java.lang.ClassLoader.loadClass(Unknown Source)\n\tat sun.misc.Launcher$AppClassLoader.loadClass(Unknown Source)\n\tat java.lang.ClassLoader.loadClass(Unknown Source)\n\t... 3 more\nhow to resolve this error",
        "Issue Links": []
    },
    "OPENNLP-1056": {
        "Key": "OPENNLP-1056",
        "Summary": "DictionaryLemmatizer throws a NullPointerException",
        "Type": "Bug",
        "Status": "Closed",
        "Priority": "Major",
        "Resolution": "Fixed",
        "Affects Version/s": "1.8.0",
        "Fix Version/s": "1.8.0",
        "Component/s": "Lemmatizer",
        "Assignee": null,
        "Reporter": "Daniel Russ",
        "Created": "11/May/17 13:31",
        "Updated": "11/May/17 15:39",
        "Resolved": "11/May/17 15:39",
        "Description": "If the word/POS combination are not found in the dictionary, the Lemmatizer throws a NPE.",
        "Issue Links": [
            "https://github.com/apache/opennlp/pull/197"
        ]
    },
    "OPENNLP-1057": {
        "Key": "OPENNLP-1057",
        "Summary": "Add all Eval tests to the Eval profile",
        "Type": "Bug",
        "Status": "Closed",
        "Priority": "Major",
        "Resolution": "Fixed",
        "Affects Version/s": "None",
        "Fix Version/s": "1.8.0",
        "Component/s": "Build, Packaging and Test",
        "Assignee": "Peter Thygesen",
        "Reporter": "Peter Thygesen",
        "Created": "12/May/17 20:22",
        "Updated": "17/May/17 14:57",
        "Resolved": "17/May/17 14:57",
        "Description": "Running the Eval profile (-D OPENNLP_DATA_DIR=path) only runs the normal tests and the SourceForgeEval. Change the include pattern to include all Eval test.",
        "Issue Links": [
            "https://github.com/apache/opennlp/pull/200"
        ]
    },
    "OPENNLP-1058": {
        "Key": "OPENNLP-1058",
        "Summary": "Improve the README.md on github",
        "Type": "Improvement",
        "Status": "Closed",
        "Priority": "Trivial",
        "Resolution": "Fixed",
        "Affects Version/s": "None",
        "Fix Version/s": "1.8.0",
        "Component/s": "None",
        "Assignee": "Anthony Beylerian",
        "Reporter": "Anthony Beylerian",
        "Created": "13/May/17 17:24",
        "Updated": "15/May/17 18:33",
        "Resolved": "15/May/17 18:33",
        "Description": null,
        "Issue Links": [
            "https://github.com/apache/opennlp/pull/198"
        ]
    },
    "OPENNLP-1059": {
        "Key": "OPENNLP-1059",
        "Summary": "Parser not loading POS Tagger correctly for old models",
        "Type": "Bug",
        "Status": "Closed",
        "Priority": "Major",
        "Resolution": "Fixed",
        "Affects Version/s": "None",
        "Fix Version/s": "1.8.0",
        "Component/s": "Parser",
        "Assignee": "J\u00f6rn Kottmann",
        "Reporter": "J\u00f6rn Kottmann",
        "Created": "15/May/17 14:04",
        "Updated": "17/May/17 13:25",
        "Resolved": "17/May/17 13:25",
        "Description": "The parser is loading the POS Tagger with the new Context Generator for 1.5.x models, but it should load the old Context Generator instead. This leads to incorrectly detected pos tags in the output.",
        "Issue Links": [
            "https://github.com/apache/opennlp/pull/199",
            "https://github.com/apache/opennlp/pull/207"
        ]
    },
    "OPENNLP-1060": {
        "Key": "OPENNLP-1060",
        "Summary": "The parser eval test is using wrong data to compute the hash",
        "Type": "Bug",
        "Status": "Closed",
        "Priority": "Minor",
        "Resolution": "Fixed",
        "Affects Version/s": "None",
        "Fix Version/s": "1.8.0",
        "Component/s": "Build, Packaging and Test,                                            Parser",
        "Assignee": "J\u00f6rn Kottmann",
        "Reporter": "J\u00f6rn Kottmann",
        "Created": "15/May/17 18:42",
        "Updated": "16/May/17 08:06",
        "Resolved": "16/May/17 08:06",
        "Description": "The SourceForgeModelEval test for the parser is using Parse.toString to compute the hash of the parser output, but it should be using Parse.show.",
        "Issue Links": []
    },
    "OPENNLP-1061": {
        "Key": "OPENNLP-1061",
        "Summary": "DictionaryLemmatizer to read dictionaries containing more than one lemma for a word and postag pair",
        "Type": "Bug",
        "Status": "Closed",
        "Priority": "Major",
        "Resolution": "Fixed",
        "Affects Version/s": "None",
        "Fix Version/s": "1.8.0",
        "Component/s": "Lemmatizer",
        "Assignee": "Rodrigo Agerri",
        "Reporter": "Rodrigo Agerri",
        "Created": "16/May/17 08:01",
        "Updated": "16/May/17 13:36",
        "Resolved": "16/May/17 13:36",
        "Description": "Currently the DictionaryLemmatizer as per O-904 allows, in theory, to read dictionaries that contain several lemma entries for a word,postag pair. However, the constructor does not read properly such formatted dictionaries. This should be fixed.",
        "Issue Links": [
            "https://github.com/apache/opennlp/pull/202"
        ]
    },
    "OPENNLP-1062": {
        "Key": "OPENNLP-1062",
        "Summary": "Create an eval test for the lemmatizer",
        "Type": "Improvement",
        "Status": "Closed",
        "Priority": "Major",
        "Resolution": "Fixed",
        "Affects Version/s": "None",
        "Fix Version/s": "1.8.0",
        "Component/s": "None",
        "Assignee": "J\u00f6rn Kottmann",
        "Reporter": "J\u00f6rn Kottmann",
        "Created": "16/May/17 08:34",
        "Updated": "16/May/17 13:03",
        "Resolved": "16/May/17 13:03",
        "Description": "There should be two evaluation tests for the lemmatizer:\n\nTrain on the Spanish UD corpus and measure the accuracy\nLoad a 1.8.0 model and test on the leipzig corpus",
        "Issue Links": [
            "https://github.com/apache/opennlp/pull/203"
        ]
    },
    "OPENNLP-1063": {
        "Key": "OPENNLP-1063",
        "Summary": "Update Morfologik dependency to 2.1.3",
        "Type": "Improvement",
        "Status": "Closed",
        "Priority": "Major",
        "Resolution": "Fixed",
        "Affects Version/s": "None",
        "Fix Version/s": "1.8.0",
        "Component/s": "Morfologik Addon",
        "Assignee": "William Colen",
        "Reporter": "William Colen",
        "Created": "16/May/17 12:15",
        "Updated": "16/May/17 13:12",
        "Resolved": "16/May/17 13:12",
        "Description": null,
        "Issue Links": [
            "https://github.com/apache/opennlp/pull/204"
        ]
    },
    "OPENNLP-1064": {
        "Key": "OPENNLP-1064",
        "Summary": "Disable ConllXPosTaggerEval.evalDutchMaxentQn test",
        "Type": "Improvement",
        "Status": "Closed",
        "Priority": "Minor",
        "Resolution": "Fixed",
        "Affects Version/s": "None",
        "Fix Version/s": "1.8.0",
        "Component/s": "Build, Packaging and Test",
        "Assignee": "J\u00f6rn Kottmann",
        "Reporter": "J\u00f6rn Kottmann",
        "Created": "17/May/17 08:03",
        "Updated": "17/May/17 14:56",
        "Resolved": "17/May/17 14:56",
        "Description": "The test needs a lot of memory and a long time to run. It is also believed that it is unlikely to find bugs the other POS tagger tests with less data wouldn't find. \nTherefore the test is disabled by default (but can still be run) to make it easier to run all the other eval tests.",
        "Issue Links": [
            "https://github.com/apache/opennlp/pull/205"
        ]
    },
    "OPENNLP-1065": {
        "Key": "OPENNLP-1065",
        "Summary": "Eval tests should use Iso 639-3 language codes",
        "Type": "Improvement",
        "Status": "Closed",
        "Priority": "Minor",
        "Resolution": "Fixed",
        "Affects Version/s": "None",
        "Fix Version/s": "1.8.1",
        "Component/s": "Build, Packaging and Test",
        "Assignee": "J\u00f6rn Kottmann",
        "Reporter": "J\u00f6rn Kottmann",
        "Created": "17/May/17 08:41",
        "Updated": "08/Jun/17 10:32",
        "Resolved": "08/Jun/17 10:32",
        "Description": null,
        "Issue Links": [
            "https://github.com/apache/opennlp/pull/206"
        ]
    },
    "OPENNLP-1066": {
        "Key": "OPENNLP-1066",
        "Summary": "Add MorfologikLemmatizer constructor that takes existing dictionary",
        "Type": "Improvement",
        "Status": "Closed",
        "Priority": "Minor",
        "Resolution": "Fixed",
        "Affects Version/s": "None",
        "Fix Version/s": "1.8.0",
        "Component/s": "Morfologik Addon",
        "Assignee": "William Colen",
        "Reporter": "William Colen",
        "Created": "17/May/17 14:31",
        "Updated": "18/May/17 14:46",
        "Resolved": "18/May/17 14:46",
        "Description": null,
        "Issue Links": [
            "https://github.com/apache/opennlp/pull/208"
        ]
    },
    "OPENNLP-1067": {
        "Key": "OPENNLP-1067",
        "Summary": "Use a variable to replace OpenNLP version in pages",
        "Type": "Improvement",
        "Status": "Resolved",
        "Priority": "Major",
        "Resolution": "Fixed",
        "Affects Version/s": "None",
        "Fix Version/s": "None",
        "Component/s": "Website",
        "Assignee": "Bruno P. Kinoshita",
        "Reporter": "Bruno P. Kinoshita",
        "Created": "19/May/17 08:33",
        "Updated": "22/May/17 01:43",
        "Resolved": "22/May/17 01:43",
        "Description": "Currently, we have to update several pages after a release, in order to update the site.\nThis could be automated with a Maven variable + some JBake-fu.",
        "Issue Links": [
            "https://github.com/apache/opennlp-site/pull/14"
        ]
    },
    "OPENNLP-1068": {
        "Key": "OPENNLP-1068",
        "Summary": "Update maven changes plugin to use \"current version\"",
        "Type": "Improvement",
        "Status": "Closed",
        "Priority": "Minor",
        "Resolution": "Fixed",
        "Affects Version/s": "None",
        "Fix Version/s": "1.8.1",
        "Component/s": "Build, Packaging and Test",
        "Assignee": "J\u00f6rn Kottmann",
        "Reporter": "J\u00f6rn Kottmann",
        "Created": "19/May/17 09:13",
        "Updated": "19/May/17 11:22",
        "Resolved": "19/May/17 11:22",
        "Description": "The jira version is currently listed by id in the opennlp-distr pom, this should be changed to use the current version instead so it is no longer necessary to manually update the version after every release.",
        "Issue Links": [
            "https://github.com/apache/opennlp/pull/212"
        ]
    },
    "OPENNLP-1069": {
        "Key": "OPENNLP-1069",
        "Summary": "Add docs to website",
        "Type": "Improvement",
        "Status": "Closed",
        "Priority": "Major",
        "Resolution": "Fixed",
        "Affects Version/s": "None",
        "Fix Version/s": "1.8.1",
        "Component/s": "Website",
        "Assignee": "William Colen",
        "Reporter": "William Colen",
        "Created": "19/May/17 23:29",
        "Updated": "21/May/17 22:32",
        "Resolved": "21/May/17 22:32",
        "Description": null,
        "Issue Links": [
            "https://github.com/apache/opennlp-site/pull/15"
        ]
    },
    "OPENNLP-1070": {
        "Key": "OPENNLP-1070",
        "Summary": "Website should declare fixed locale and date format",
        "Type": "Improvement",
        "Status": "Closed",
        "Priority": "Major",
        "Resolution": "Fixed",
        "Affects Version/s": "None",
        "Fix Version/s": "1.8.1",
        "Component/s": "Website",
        "Assignee": "William Colen",
        "Reporter": "William Colen",
        "Created": "20/May/17 11:21",
        "Updated": "21/May/17 22:32",
        "Resolved": "21/May/17 22:32",
        "Description": null,
        "Issue Links": [
            "https://github.com/apache/opennlp-site/pull/16"
        ]
    },
    "OPENNLP-1071": {
        "Key": "OPENNLP-1071",
        "Summary": "Fix year of copyright notice",
        "Type": "Bug",
        "Status": "Closed",
        "Priority": "Major",
        "Resolution": "Fixed",
        "Affects Version/s": "None",
        "Fix Version/s": "1.8.1",
        "Component/s": "Website",
        "Assignee": "William Colen",
        "Reporter": "William Colen",
        "Created": "21/May/17 21:09",
        "Updated": "21/May/17 22:33",
        "Resolved": "21/May/17 22:33",
        "Description": null,
        "Issue Links": [
            "https://github.com/apache/opennlp-site/pull/17"
        ]
    },
    "OPENNLP-1072": {
        "Key": "OPENNLP-1072",
        "Summary": "Update opennlp-site checkout instruction",
        "Type": "Bug",
        "Status": "Closed",
        "Priority": "Major",
        "Resolution": "Fixed",
        "Affects Version/s": "1.8.0",
        "Fix Version/s": "1.8.1",
        "Component/s": "Website",
        "Assignee": "William Colen",
        "Reporter": "William Colen",
        "Created": "21/May/17 22:02",
        "Updated": "21/May/17 22:33",
        "Resolved": "21/May/17 22:33",
        "Description": null,
        "Issue Links": [
            "https://github.com/apache/opennlp-site/pull/18"
        ]
    },
    "OPENNLP-1073": {
        "Key": "OPENNLP-1073",
        "Summary": "Add 1.8.0 release news",
        "Type": "Improvement",
        "Status": "Closed",
        "Priority": "Major",
        "Resolution": "Fixed",
        "Affects Version/s": "None",
        "Fix Version/s": "1.8.1",
        "Component/s": "Website",
        "Assignee": "William Colen",
        "Reporter": "William Colen",
        "Created": "21/May/17 22:27",
        "Updated": "22/May/17 00:44",
        "Resolved": "22/May/17 00:44",
        "Description": null,
        "Issue Links": [
            "https://github.com/apache/opennlp-site/pull/19"
        ]
    },
    "OPENNLP-1074": {
        "Key": "OPENNLP-1074",
        "Summary": "Decrease visibility of deprecated eval methods",
        "Type": "Improvement",
        "Status": "Closed",
        "Priority": "Major",
        "Resolution": "Fixed",
        "Affects Version/s": "None",
        "Fix Version/s": "1.8.1",
        "Component/s": "Machine Learning",
        "Assignee": "J\u00f6rn Kottmann",
        "Reporter": "J\u00f6rn Kottmann",
        "Created": "22/May/17 13:56",
        "Updated": "24/May/17 15:15",
        "Resolved": "24/May/17 15:15",
        "Description": "The visibility of those methods have to be decreased to future refactorings of those components are possible without breaking backward compatibility.",
        "Issue Links": [
            "https://github.com/apache/opennlp/pull/214"
        ]
    },
    "OPENNLP-1075": {
        "Key": "OPENNLP-1075",
        "Summary": "Add support to train the sentence detector and tokenizer on the UD corpus",
        "Type": "Improvement",
        "Status": "Closed",
        "Priority": "Minor",
        "Resolution": "Fixed",
        "Affects Version/s": "None",
        "Fix Version/s": "1.8.1",
        "Component/s": "Formats",
        "Assignee": "J\u00f6rn Kottmann",
        "Reporter": "J\u00f6rn Kottmann",
        "Created": "23/May/17 15:27",
        "Updated": "24/May/17 14:58",
        "Resolved": "24/May/17 14:58",
        "Description": "The UD corpus contains the original text in a comment field and that can be used to produce training data for the tokenizer and sentence detector.",
        "Issue Links": [
            "https://github.com/apache/opennlp/pull/215"
        ]
    },
    "OPENNLP-1076": {
        "Key": "OPENNLP-1076",
        "Summary": "SentenceSample should validate if spans are inside the text",
        "Type": "Improvement",
        "Status": "Closed",
        "Priority": "Minor",
        "Resolution": "Fixed",
        "Affects Version/s": "None",
        "Fix Version/s": "1.8.1",
        "Component/s": "Sentence Detector",
        "Assignee": "J\u00f6rn Kottmann",
        "Reporter": "J\u00f6rn Kottmann",
        "Created": "24/May/17 10:02",
        "Updated": "24/May/17 10:25",
        "Resolved": "24/May/17 10:25",
        "Description": "The SentenceSample should validate if the provided Spans to mark sentence boundaries are within bounds of the provided document text. If the spans are outside of the document text an IllegalArgumentException should be thrown to make the code fail fast. Otherwise code which processes the SentenceSamples will fail later and make it slightly harder to find the actual bug.",
        "Issue Links": [
            "https://github.com/apache/opennlp/pull/216"
        ]
    },
    "OPENNLP-1077": {
        "Key": "OPENNLP-1077",
        "Summary": "Make BratNameSampleStream constructors public",
        "Type": "Improvement",
        "Status": "Closed",
        "Priority": "Major",
        "Resolution": "Fixed",
        "Affects Version/s": "1.8.0",
        "Fix Version/s": "1.8.1",
        "Component/s": "Formats",
        "Assignee": "Daniel Russ",
        "Reporter": "Daniel Russ",
        "Created": "24/May/17 19:40",
        "Updated": "06/Jun/17 20:09",
        "Resolved": "06/Jun/17 20:09",
        "Description": "Reading in Brat formatted data without using the CLI or the BratAnnotationService is difficult because the Constructor is public and the Factory requires the program to supply the command line argument as a String[].",
        "Issue Links": [
            "https://github.com/apache/opennlp/pull/217"
        ]
    },
    "OPENNLP-1078": {
        "Key": "OPENNLP-1078",
        "Summary": "Irish Sentence Bank format support throws NPE",
        "Type": "Bug",
        "Status": "Closed",
        "Priority": "Minor",
        "Resolution": "Fixed",
        "Affects Version/s": "None",
        "Fix Version/s": "1.8.1",
        "Component/s": "Formats",
        "Assignee": "J\u00f6rn Kottmann",
        "Reporter": "J\u00f6rn Kottmann",
        "Created": "24/May/17 20:29",
        "Updated": "06/Jun/17 20:10",
        "Resolved": "06/Jun/17 20:10",
        "Description": "It happens when trying to match the surface form with its lemma, on line 245 of\nIrishSentenceBankDocument.java:\nint rsize = flx.get(flexidx).size();",
        "Issue Links": [
            "https://github.com/apache/opennlp/pull/219"
        ]
    },
    "OPENNLP-1079": {
        "Key": "OPENNLP-1079",
        "Summary": "Refactor BratNameSampleStream",
        "Type": "Improvement",
        "Status": "Closed",
        "Priority": "Minor",
        "Resolution": "Fixed",
        "Affects Version/s": "None",
        "Fix Version/s": "1.8.1",
        "Component/s": "None",
        "Assignee": "Daniel Russ",
        "Reporter": "Daniel Russ",
        "Created": "25/May/17 17:45",
        "Updated": "06/Jun/17 20:09",
        "Resolved": "06/Jun/17 20:09",
        "Description": "Create a BratAnnotationParser that parses a BratDocument and creates a List<NameSample>   The NameSampleStream,read() method would call this directly.\nConsider Making the changes for the other formats as well.",
        "Issue Links": [
            "https://github.com/apache/opennlp/pull/218"
        ]
    },
    "OPENNLP-1080": {
        "Key": "OPENNLP-1080",
        "Summary": "TwoPassDataIndexer should use binary format",
        "Type": "Improvement",
        "Status": "Open",
        "Priority": "Minor",
        "Resolution": "Unresolved",
        "Affects Version/s": "None",
        "Fix Version/s": "None",
        "Component/s": "Machine Learning",
        "Assignee": "J\u00f6rn Kottmann",
        "Reporter": "J\u00f6rn Kottmann",
        "Created": "29/May/17 10:15",
        "Updated": "21/Jun/17 13:02",
        "Resolved": null,
        "Description": "The TwoPassDataIndexer should use a binary format instead of the current string format to improve read/write performance of the events. Further it should use a check-sum to guarantee that the data read back from disk is the same as was written.",
        "Issue Links": []
    },
    "OPENNLP-1081": {
        "Key": "OPENNLP-1081",
        "Summary": "Fix Dictionary support to GeneratorFactory::extractArtifactSerializerMappings",
        "Type": "Bug",
        "Status": "Closed",
        "Priority": "Major",
        "Resolution": "Fixed",
        "Affects Version/s": "1.8.0",
        "Fix Version/s": "1.8.1",
        "Component/s": "Name Finder",
        "Assignee": "Peter Thygesen",
        "Reporter": "Peter Thygesen",
        "Created": "29/May/17 11:20",
        "Updated": "06/Jun/17 10:45",
        "Resolved": "06/Jun/17 10:45",
        "Description": "GeneratorFactory.extractArtifactSerializerMappings does not support Dictionaries. \nE.g.\nfeature.xml\n<generators>\n    <cache>\n        <generators>\n...\n              <dictionary dict=\"locations.dict\"/>\n   </generators>\n    </cache>\n</generators>\nrunning opennlp TokenNameFinderTrainer.brat \n-resources /my/resources\n-featuregen feature.xml\nresults in:\nFeatureGeneratorCreationError: opennlp.tools.util.InvalidFormatException: No dictionary resource for key: locations.dict\nEven though the file is present in the resources folder.",
        "Issue Links": [
            "https://github.com/apache/opennlp/pull/220"
        ]
    },
    "OPENNLP-1082": {
        "Key": "OPENNLP-1082",
        "Summary": "SentenceSampleStream should add EOS to samples if missing",
        "Type": "Improvement",
        "Status": "Reopened",
        "Priority": "Major",
        "Resolution": "Unresolved",
        "Affects Version/s": "None",
        "Fix Version/s": "None",
        "Component/s": "Sentence Detector",
        "Assignee": "William Colen",
        "Reporter": "William Colen",
        "Created": "29/May/17 14:26",
        "Updated": "21/Jun/18 13:19",
        "Resolved": null,
        "Description": null,
        "Issue Links": [
            "https://github.com/apache/opennlp/pull/221",
            "https://github.com/apache/opennlp/pull/234",
            "https://github.com/apache/opennlp/pull/234",
            "https://github.com/apache/opennlp/pull/243"
        ]
    },
    "OPENNLP-1083": {
        "Key": "OPENNLP-1083",
        "Summary": "Conll-u Samples not handling contractions",
        "Type": "Bug",
        "Status": "Closed",
        "Priority": "Major",
        "Resolution": "Fixed",
        "Affects Version/s": "None",
        "Fix Version/s": "1.8.1",
        "Component/s": "Formats",
        "Assignee": "William Colen",
        "Reporter": "William Colen",
        "Created": "30/May/17 02:42",
        "Updated": "01/Jun/17 05:09",
        "Resolved": "01/Jun/17 05:09",
        "Description": null,
        "Issue Links": [
            "https://github.com/apache/opennlp/pull/222"
        ]
    },
    "OPENNLP-1084": {
        "Key": "OPENNLP-1084",
        "Summary": "Write documentation for training langdetect with leipzig",
        "Type": "Documentation",
        "Status": "Closed",
        "Priority": "Major",
        "Resolution": "Fixed",
        "Affects Version/s": "None",
        "Fix Version/s": "1.8.1",
        "Component/s": "Documentation,                                            Website",
        "Assignee": "William Colen",
        "Reporter": "Peter Thygesen",
        "Created": "30/May/17 08:44",
        "Updated": "04/Jul/17 04:16",
        "Resolved": "04/Jul/17 04:16",
        "Description": "The chapter about Leipzig Doccat Converter is wrong and will be obsolete with new langdetect.",
        "Issue Links": []
    },
    "OPENNLP-1085": {
        "Key": "OPENNLP-1085",
        "Summary": "Add BaseModel.serialize(File)",
        "Type": "Improvement",
        "Status": "Closed",
        "Priority": "Minor",
        "Resolution": "Fixed",
        "Affects Version/s": "None",
        "Fix Version/s": "1.8.1",
        "Component/s": "Machine Learning",
        "Assignee": "J\u00f6rn Kottmann",
        "Reporter": "J\u00f6rn Kottmann",
        "Created": "30/May/17 08:44",
        "Updated": "01/Jun/17 05:08",
        "Resolved": "01/Jun/17 05:08",
        "Description": "A a convenience method to write a model directly to a File.",
        "Issue Links": [
            "https://github.com/apache/opennlp/pull/224"
        ]
    },
    "OPENNLP-1086": {
        "Key": "OPENNLP-1086",
        "Summary": "Refactor the Data Indexer code",
        "Type": "Improvement",
        "Status": "Closed",
        "Priority": "Minor",
        "Resolution": "Fixed",
        "Affects Version/s": "None",
        "Fix Version/s": "1.8.1",
        "Component/s": "Machine Learning",
        "Assignee": "J\u00f6rn Kottmann",
        "Reporter": "J\u00f6rn Kottmann",
        "Created": "30/May/17 08:58",
        "Updated": "06/Jun/17 20:11",
        "Resolved": "06/Jun/17 20:11",
        "Description": "The Data Indexer code was never changed much since its first write and has lots of potential to be improved with Java 8.",
        "Issue Links": [
            "https://github.com/apache/opennlp/pull/223"
        ]
    },
    "OPENNLP-1087": {
        "Key": "OPENNLP-1087",
        "Summary": "Add convenience methods to load models from Path",
        "Type": "Improvement",
        "Status": "Closed",
        "Priority": "Minor",
        "Resolution": "Fixed",
        "Affects Version/s": "None",
        "Fix Version/s": "1.8.1",
        "Component/s": "None",
        "Assignee": "J\u00f6rn Kottmann",
        "Reporter": "J\u00f6rn Kottmann",
        "Created": "31/May/17 21:49",
        "Updated": "02/Jun/17 08:52",
        "Resolved": "02/Jun/17 08:52",
        "Description": "Add a convenience methods to load models from a Path. Some of our users need that and their code will look slightly nicer if they can directly instantiate a model from a Path.",
        "Issue Links": [
            "https://github.com/apache/opennlp/pull/225"
        ]
    },
    "OPENNLP-1088": {
        "Key": "OPENNLP-1088",
        "Summary": "Reduce surefire fork count for eval tests",
        "Type": "Improvement",
        "Status": "Closed",
        "Priority": "Trivial",
        "Resolution": "Fixed",
        "Affects Version/s": "None",
        "Fix Version/s": "1.8.1",
        "Component/s": "Build, Packaging and Test",
        "Assignee": "J\u00f6rn Kottmann",
        "Reporter": "J\u00f6rn Kottmann",
        "Created": "06/Jun/17 12:57",
        "Updated": "06/Jun/17 20:06",
        "Resolved": "06/Jun/17 20:06",
        "Description": "The test need a lot of memory and are also CPU intensive. I suggest we reduce the setting from 1.0C to 0.5C to make it run on a 4 core (with HT) CPU and 32 GB ram machine",
        "Issue Links": [
            "https://github.com/apache/opennlp/pull/226"
        ]
    },
    "OPENNLP-1089": {
        "Key": "OPENNLP-1089",
        "Summary": "Reduce printing of iterations in JUnit tests",
        "Type": "Improvement",
        "Status": "Closed",
        "Priority": "Trivial",
        "Resolution": "Won't Do",
        "Affects Version/s": "None",
        "Fix Version/s": "2.2.0",
        "Component/s": "Build, Packaging and Test",
        "Assignee": "J\u00f6rn Kottmann",
        "Reporter": "J\u00f6rn Kottmann",
        "Created": "08/Jun/17 10:57",
        "Updated": "22/Apr/23 17:39",
        "Resolved": "04/Mar/23 08:07",
        "Description": "The tests now run in parallel and a lot of iterations are printed totally mixed up, making this kind of output useless. There is also not much value in printing all the iterations to the console.\nLets reduce the amount of iterations for training tests.",
        "Issue Links": [
            "/jira/browse/OPENNLP-1448",
            "/jira/browse/OPENNLP-1447",
            "https://github.com/apache/opennlp/pull/227"
        ]
    },
    "OPENNLP-1090": {
        "Key": "OPENNLP-1090",
        "Summary": "BaseToolFactory should not print erros to console",
        "Type": "Improvement",
        "Status": "Closed",
        "Priority": "Trivial",
        "Resolution": "Fixed",
        "Affects Version/s": "None",
        "Fix Version/s": "1.8.1",
        "Component/s": "Machine Learning",
        "Assignee": "J\u00f6rn Kottmann",
        "Reporter": "J\u00f6rn Kottmann",
        "Created": "08/Jun/17 13:16",
        "Updated": "08/Jun/17 14:22",
        "Resolved": "08/Jun/17 14:22",
        "Description": "The BaseToolFactory should just re-throw the exception without printing anything to console. The caller can do that if appropriate.",
        "Issue Links": [
            "https://github.com/apache/opennlp/pull/228"
        ]
    },
    "OPENNLP-1091": {
        "Key": "OPENNLP-1091",
        "Summary": "Fixing issues found via FindBugs and warnings found via IDE",
        "Type": "Improvement",
        "Status": "Closed",
        "Priority": "Minor",
        "Resolution": "Fixed",
        "Affects Version/s": "1.8.0",
        "Fix Version/s": "1.8.1",
        "Component/s": "None",
        "Assignee": "Bruno P. Kinoshita",
        "Reporter": "Bruno P. Kinoshita",
        "Created": "09/Jun/17 22:34",
        "Updated": "28/Jun/17 10:06",
        "Resolved": "28/Jun/17 10:06",
        "Description": "There are several issues that can be found using FindBugs.\n\nmvn clean install findbugs:findbugs findbugs:gui\n\n\nThe opennlp-tools is the only project with issues. Some are mere cosmetics, or not so important. The pull request mentioned in this issue does not fix all issues found, only the ones that I thought would be more important, and that would not have huge impact in the code (i.e. would not have to change much of the current behaviour/code base).\nSome changes are quite useful, such as optimizations that replace string concatenation and use Map#entrySet instead of Map#keySet + another call to Map#get. All the optimizations changes put together, I expect we should see at least a few milliseconds improvement.\nOther changes are quite important, such as comparisons with Object.equals(anArray, anotherArray), which will compare two objects with ==, meaning that even when the arrays are equals, it would still return false.\nIn the pull request, I intentionally did not squash it now, as the second commit include warnings found via the IDE (Eclipse in this case, but I believe it's independent of the IDE). Such as suppressWarnings that are not necessary, and - the most importants - resource leak.\nThis latter issue was fixed with Java8 try-with-resources, mainly in tests, but also in some tools.\nCheers\nBruno",
        "Issue Links": [
            "https://github.com/apache/opennlp/pull/229",
            "https://github.com/apache/opennlp/pull/229"
        ]
    },
    "OPENNLP-1092": {
        "Key": "OPENNLP-1092",
        "Summary": "PosTagger serialization in namefinder model",
        "Type": "Bug",
        "Status": "Closed",
        "Priority": "Major",
        "Resolution": "Fixed",
        "Affects Version/s": "1.8.0,                                            1.8.1",
        "Fix Version/s": "1.8.1",
        "Component/s": "Name Finder",
        "Assignee": "J\u00f6rn Kottmann",
        "Reporter": "Damiano Porta",
        "Created": "12/Jun/17 12:36",
        "Updated": "28/Jun/17 10:06",
        "Resolved": "28/Jun/17 10:06",
        "Description": "I am getting an error during the serialization of the post tagger inside a name finder model.\nThe error is: java.lang.IllegalStateException: Missing serializer for postagger.bin\nI am having this problem via API and via cmd NameFinderTrainer tool.\nThe command is:\nopennlp TokenNameFinderTrainer -data /home/damiano/corpus.train -lang it -model /home/damiano/model.bin -featuregen /home/damiano/test.xml -sequenceCodec BIO -resources /home/damiano/lavoro/java/Parser/src/main/resources/\n\nThe output is:\nWriting name finder model ... Compressed 885605 parameters to 94030\n3451 outcome patterns\nException in thread \"main\" java.lang.IllegalStateException: Missing serializer for postagger.bin\n\tat opennlp.tools.util.model.BaseModel.serialize(BaseModel.java:592)\n\tat opennlp.tools.cmdline.CmdLineUtil.writeModel(CmdLineUtil.java:182)\n\tat opennlp.tools.cmdline.namefind.TokenNameFinderTrainerTool.run(TokenNameFinderTrainerTool.java:188)\n\tat opennlp.tools.cmdline.CLI.main(CLI.java:244)\n\n\nMy generators.xml is:\n\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<generators>\n    <cache>\n        <generators>\n            <window prevLength=\"4\" nextLength=\"2\">\n                <tokenclass />\n            </window>\n            <window prevLength=\"4\" nextLength=\"2\">\n                <token />\n            </window> \n            <!-- Pos Tagger -->                \n            <window prevLength=\"4\" nextLength=\"2\">\n                <tokenpos model=\"postagger.bin\" />\n            </window> \n            <definition />\n            <prevmap />\n            <bigram />\n            <sentence begin=\"true\" end=\"false\" />          \n        </generators>\n    </cache>\n</generators>",
        "Issue Links": [
            "https://github.com/apache/opennlp/pull/237"
        ]
    },
    "OPENNLP-1093": {
        "Key": "OPENNLP-1093",
        "Summary": "Update Maven JBake plug-in version and groupId",
        "Type": "Bug",
        "Status": "Closed",
        "Priority": "Minor",
        "Resolution": "Done",
        "Affects Version/s": "None",
        "Fix Version/s": "None",
        "Component/s": "Website",
        "Assignee": "Bruno P. Kinoshita",
        "Reporter": "Bruno P. Kinoshita",
        "Created": "13/Jun/17 10:42",
        "Updated": "03/Apr/18 23:32",
        "Resolved": "03/Apr/18 23:32",
        "Description": "We found an issue that was fixed in master, but not released. When we asked about it, we learned that the plugin was being maintained elsewhere. We raised a question about how we could help getting the code to Maven central repository.\nIt was published hours ago, so now we can start testing it.\nhttps://github.com/ingenieux/jbake-maven-plugin/issues/18\nhttps://github.com/jbake-org/jbake-maven-plugin/issues/4",
        "Issue Links": [
            "https://github.com/apache/opennlp-site/pull/20"
        ]
    },
    "OPENNLP-1094": {
        "Key": "OPENNLP-1094",
        "Summary": "Remove pmap indirection via int mapping",
        "Type": "Improvement",
        "Status": "Closed",
        "Priority": "Minor",
        "Resolution": "Fixed",
        "Affects Version/s": "None",
        "Fix Version/s": "1.8.1",
        "Component/s": "Machine Learning",
        "Assignee": "J\u00f6rn Kottmann",
        "Reporter": "J\u00f6rn Kottmann",
        "Created": "16/Jun/17 12:32",
        "Updated": "20/Jun/17 09:16",
        "Resolved": "20/Jun/17 09:16",
        "Description": "Currently the hot loop of the classifiers use a mapping from String to int to Context, this can be reduced to a direct mapping from String to Context, which increases performances from 2 % to 10 % for maxent depending on the component.",
        "Issue Links": []
    },
    "OPENNLP-1095": {
        "Key": "OPENNLP-1095",
        "Summary": "Unable to handle emojis",
        "Type": "Bug",
        "Status": "Closed",
        "Priority": "Critical",
        "Resolution": "Not A Problem",
        "Affects Version/s": "None",
        "Fix Version/s": "None",
        "Component/s": "None",
        "Assignee": null,
        "Reporter": "martin",
        "Created": "18/Jun/17 20:36",
        "Updated": "03/Apr/18 22:12",
        "Resolved": "03/Apr/18 22:12",
        "Description": "For example, for this sentence,\nHoseok yelled out Puma at the end \ud83d\ude02\ud83d\ude02\ud83d\ude02\nThe tokenized emojis becomes \"\ud83d\ude02????\". Is this an issue for openNLP or something else?",
        "Issue Links": []
    },
    "OPENNLP-1096": {
        "Key": "OPENNLP-1096",
        "Summary": "Optimize n-gram creation loop for CPU cache usage",
        "Type": "Improvement",
        "Status": "Closed",
        "Priority": "Trivial",
        "Resolution": "Fixed",
        "Affects Version/s": "None",
        "Fix Version/s": "1.8.1",
        "Component/s": "None",
        "Assignee": "J\u00f6rn Kottmann",
        "Reporter": "J\u00f6rn Kottmann",
        "Created": "22/Jun/17 12:27",
        "Updated": "26/Jun/17 12:54",
        "Resolved": "26/Jun/17 12:54",
        "Description": "There are two for loops to read the string and calculate n-grams, the loops should be turned around to be more cache friendly.",
        "Issue Links": [
            "https://github.com/apache/opennlp/pull/235"
        ]
    },
    "OPENNLP-1097": {
        "Key": "OPENNLP-1097",
        "Summary": "Enable language detector normalizers by default",
        "Type": "Improvement",
        "Status": "Closed",
        "Priority": "Minor",
        "Resolution": "Fixed",
        "Affects Version/s": "None",
        "Fix Version/s": "1.8.1",
        "Component/s": "None",
        "Assignee": "J\u00f6rn Kottmann",
        "Reporter": "J\u00f6rn Kottmann",
        "Created": "22/Jun/17 12:48",
        "Updated": "22/Jun/17 14:54",
        "Resolved": "22/Jun/17 14:54",
        "Description": "The normalizes should be used by default in the langdetect context generator.",
        "Issue Links": [
            "https://github.com/apache/opennlp/pull/236"
        ]
    },
    "OPENNLP-1098": {
        "Key": "OPENNLP-1098",
        "Summary": "Create a web page for 'Books-Tutorials-Talks'",
        "Type": "New Feature",
        "Status": "Closed",
        "Priority": "Major",
        "Resolution": "Fixed",
        "Affects Version/s": "None",
        "Fix Version/s": "1.8.1",
        "Component/s": "Website",
        "Assignee": "Suneel Marthi",
        "Reporter": "Suneel Marthi",
        "Created": "26/Jun/17 02:53",
        "Updated": "29/Jun/17 21:56",
        "Resolved": "29/Jun/17 21:39",
        "Description": null,
        "Issue Links": [
            "https://github.com/apache/opennlp-site/pull/22"
        ]
    },
    "OPENNLP-1099": {
        "Key": "OPENNLP-1099",
        "Summary": "Is this a typical tokenization issue?",
        "Type": "Bug",
        "Status": "Closed",
        "Priority": "Major",
        "Resolution": "Not A Problem",
        "Affects Version/s": "None",
        "Fix Version/s": "1.8.1",
        "Component/s": "Lemmatizer",
        "Assignee": null,
        "Reporter": "martin",
        "Created": "29/Jun/17 05:52",
        "Updated": "29/Jun/17 21:53",
        "Resolved": "29/Jun/17 21:46",
        "Description": "I am testing openNLP and found some significant tokenization issue involving punctuation.  \nThank you Costco!\ni love costco!\nI love Costco!!\nFUCK IKEA.\nIn all these cases, the last punctuation is not split so \"Costco!\" and \"IKEA.\" are treated as one token. This looks like a systematic problem.",
        "Issue Links": []
    },
    "OPENNLP-1100": {
        "Key": "OPENNLP-1100",
        "Summary": "Use training datasets from Annotated Semantic Relationships Datasets on GitHub",
        "Type": "Task",
        "Status": "Closed",
        "Priority": "Major",
        "Resolution": "Abandoned",
        "Affects Version/s": "None",
        "Fix Version/s": "None",
        "Component/s": "None",
        "Assignee": "Chris A. Mattmann",
        "Reporter": "Chris A. Mattmann",
        "Created": "29/Jun/17 17:48",
        "Updated": "22/Apr/23 17:20",
        "Resolved": "22/Apr/23 17:20",
        "Description": "See datasets here: \nhttps://github.com/davidsbatista/Annotated-Semantic-Relationships-Datasets\nThere is a lot of ground truth and labeled data in there that seems permissively licensed that we could use.",
        "Issue Links": []
    },
    "OPENNLP-1101": {
        "Key": "OPENNLP-1101",
        "Summary": "Consider how we can leverage code from Annotated Semantic Relationships Datasets",
        "Type": "Task",
        "Status": "Closed",
        "Priority": "Major",
        "Resolution": "Abandoned",
        "Affects Version/s": "None",
        "Fix Version/s": "None",
        "Component/s": "None",
        "Assignee": "Chris A. Mattmann",
        "Reporter": "Chris A. Mattmann",
        "Created": "29/Jun/17 17:49",
        "Updated": "22/Apr/23 17:20",
        "Resolved": "22/Apr/23 17:20",
        "Description": "See: https://github.com/davidsbatista/Annotated-Semantic-Relationships-Datasets\nThere is datasets there but also code. See if we can leverage any of the code for OpenNLP.",
        "Issue Links": []
    },
    "OPENNLP-1102": {
        "Key": "OPENNLP-1102",
        "Summary": "Universal Dependencies eval tests is failing",
        "Type": "Bug",
        "Status": "Closed",
        "Priority": "Major",
        "Resolution": "Fixed",
        "Affects Version/s": "None",
        "Fix Version/s": "1.8.1",
        "Component/s": "Build, Packaging and Test",
        "Assignee": "J\u00f6rn Kottmann",
        "Reporter": "J\u00f6rn Kottmann",
        "Created": "29/Jun/17 22:14",
        "Updated": "30/Jun/17 14:01",
        "Resolved": "30/Jun/17 14:01",
        "Description": "Results :\nFailed tests: \n  UniversalDependency20Eval.trainAndEvalSpanishAncora:82 expected:<0.9046675934566091> but was:<0.9057341692068787>\nTests in error: \n  Conll00ChunkerEval.evalEnglishMaxentQn:95->train:55 \u00bb OutOfMemory Java heap sp...\nTests run: 774, Failures: 1, Errors: 1, Skipped: 1",
        "Issue Links": [
            "https://github.com/apache/opennlp/pull/239"
        ]
    },
    "OPENNLP-1103": {
        "Key": "OPENNLP-1103",
        "Summary": "Add AirNZ use case for OpenNLP to the web site",
        "Type": "Documentation",
        "Status": "Closed",
        "Priority": "Minor",
        "Resolution": "Fixed",
        "Affects Version/s": "None",
        "Fix Version/s": "None",
        "Component/s": "Website",
        "Assignee": "Bruno P. Kinoshita",
        "Reporter": "Bruno P. Kinoshita",
        "Created": "29/Jun/17 23:27",
        "Updated": "30/Jun/17 15:13",
        "Resolved": "30/Jun/17 15:13",
        "Description": "Went to the Wynyard Quarter innovation week some weeks ago, and saw that AirNZ was showing their bot and that it used OpenNLP. Spoke with Joey Faust, Product Manager, and got the following testimonial for our site.\n\nAir New Zealand uses OpenNLP to power its chatbot, Oscar. Launched in February 2017, Oscar provides a conversational interface for customers to ask questions about flights, amenities and policies. Using OpenNLP, we've been able to consistently provide over 50% conversational success and support hundreds of intents.",
        "Issue Links": [
            "https://github.com/apache/opennlp-site/pull/23"
        ]
    },
    "OPENNLP-1104": {
        "Key": "OPENNLP-1104",
        "Summary": "Fix images at the bottom of the Powered By page, and use lower cases for link",
        "Type": "Documentation",
        "Status": "Closed",
        "Priority": "Minor",
        "Resolution": "Fixed",
        "Affects Version/s": "None",
        "Fix Version/s": "None",
        "Component/s": "Website",
        "Assignee": "Bruno P. Kinoshita",
        "Reporter": "Bruno P. Kinoshita",
        "Created": "29/Jun/17 23:50",
        "Updated": "30/Jun/17 20:43",
        "Resolved": "30/Jun/17 15:16",
        "Description": "The current Powered By page is the only page with upper case letter. Besides keeping things concise, there are cases where using lower case URL's may be helpful for SEO (though that's not so relevant for our project I think).\nThe images at the bottom also are not being displayed. I didn't know, but looks like in ASciiDoc you must include the [] 's, even if empty.",
        "Issue Links": [
            "https://github.com/apache/opennlp-site/pull/24"
        ]
    },
    "OPENNLP-1105": {
        "Key": "OPENNLP-1105",
        "Summary": "Add profile for eval tests that need a lot of memory",
        "Type": "Improvement",
        "Status": "Closed",
        "Priority": "Minor",
        "Resolution": "Fixed",
        "Affects Version/s": "None",
        "Fix Version/s": "1.8.1",
        "Component/s": "Build, Packaging and Test",
        "Assignee": "J\u00f6rn Kottmann",
        "Reporter": "J\u00f6rn Kottmann",
        "Created": "30/Jun/17 09:48",
        "Updated": "30/Jun/17 14:01",
        "Resolved": "30/Jun/17 14:01",
        "Description": "There are eval tests that need to much memory to be run together with the other tests. They should be activated by a profile.",
        "Issue Links": [
            "https://github.com/apache/opennlp/pull/240"
        ]
    },
    "OPENNLP-1106": {
        "Key": "OPENNLP-1106",
        "Summary": "Update the coref code to compile against 1.6.0",
        "Type": "Improvement",
        "Status": "Closed",
        "Priority": "Major",
        "Resolution": "Done",
        "Affects Version/s": "None",
        "Fix Version/s": "None",
        "Component/s": "Coref",
        "Assignee": "J\u00f6rn Kottmann",
        "Reporter": "J\u00f6rn Kottmann",
        "Created": "30/Jun/17 13:37",
        "Updated": "03/Apr/18 23:26",
        "Resolved": "03/Apr/18 23:26",
        "Description": "It would be nice if the coref code would compile against an older release version and gets the code a bit updated so it complies mostly with checkstyle rules.",
        "Issue Links": [
            "https://github.com/apache/opennlp-sandbox/pull/2"
        ]
    },
    "OPENNLP-1107": {
        "Key": "OPENNLP-1107",
        "Summary": "Problem running high-memory-tests profile with Morfologik tests",
        "Type": "Test",
        "Status": "Closed",
        "Priority": "Minor",
        "Resolution": "Fixed",
        "Affects Version/s": "None",
        "Fix Version/s": "1.8.1",
        "Component/s": "Build, Packaging and Test,                                            Morfologik Addon",
        "Assignee": "Jeff Zemerick",
        "Reporter": "Jeff Zemerick",
        "Created": "02/Jul/17 12:25",
        "Updated": "03/Jul/17 13:05",
        "Resolved": "03/Jul/17 13:05",
        "Description": "When running the following command on the 1.8.1 tag I get the following error. (The full build log is attached.)\nmvn clean install -T 1C -Phigh-memory-tests -DOPENNLP_DATA_DIR=/opt/opennlp-data/ \n\n[ERROR] Failed to execute goal org.apache.maven.plugins:maven-surefire-plugin:2.19.1:test (default-test) on project opennlp-morfologik-addon: Execution default-test of goal org.apache.maven.plugins:maven-surefire-plugin:2.19.1:test failed: There was an error in the forked process\n[ERROR] java.lang.RuntimeException: Unable to load category: opennlp.tools.HighMemoryUsage\n[ERROR] at org.apache.maven.surefire.group.match.SingleGroupMatcher.loadGroupClasses(SingleGroupMatcher.java:139)\n[ERROR] at org.apache.maven.surefire.common.junit48.FilterFactory.createGroupFilter(FilterFactory.java:100)\n[ERROR] at org.apache.maven.surefire.junitcore.JUnitCoreProvider.createJUnit48Filter(JUnitCoreProvider.java:279)\n[ERROR] at org.apache.maven.surefire.junitcore.JUnitCoreProvider.invoke(JUnitCoreProvider.java:130)\n[ERROR] at org.apache.maven.surefire.booter.ForkedBooter.invokeProviderInSameClassLoader(ForkedBooter.java:290)\n[ERROR] at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:242)\n[ERROR] at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:121)\n[ERROR] Caused by: java.lang.ClassNotFoundException: opennlp.tools.HighMemoryUsage\n[ERROR] at java.net.URLClassLoader.findClass(URLClassLoader.java:381)\n[ERROR] at java.lang.ClassLoader.loadClass(ClassLoader.java:424)\n[ERROR] at sun.misc.Launcher$AppClassLoader.loadClass(Launcher.java:335)\n[ERROR] at java.lang.ClassLoader.loadClass(ClassLoader.java:357)\n[ERROR] at org.apache.maven.surefire.group.match.SingleGroupMatcher.loadGroupClasses(SingleGroupMatcher.java:135)\n[ERROR] ... 6 more\n[ERROR] -> [Help 1]",
        "Issue Links": [
            "https://github.com/apache/opennlp/pull/241"
        ]
    },
    "OPENNLP-1108": {
        "Key": "OPENNLP-1108",
        "Summary": "Default eos char addition causes backward compatbility problems",
        "Type": "Bug",
        "Status": "Closed",
        "Priority": "Major",
        "Resolution": "Won't Fix",
        "Affects Version/s": "None",
        "Fix Version/s": "None",
        "Component/s": "Sentence Detector",
        "Assignee": null,
        "Reporter": "J\u00f6rn Kottmann",
        "Created": "02/Jul/17 18:06",
        "Updated": "03/Jul/17 20:30",
        "Resolved": "03/Jul/17 14:37",
        "Description": "The addition of the \\n as a default eos doesn't work well with existing models that don't contain a list of eos chars, and also doesn't work for users who train with defaults, because they now get different results.",
        "Issue Links": [
            "https://github.com/apache/opennlp/pull/242"
        ]
    },
    "OPENNLP-1109": {
        "Key": "OPENNLP-1109",
        "Summary": "Change repositories in pom.xml to use GitHub repo",
        "Type": "Improvement",
        "Status": "Closed",
        "Priority": "Major",
        "Resolution": "Fixed",
        "Affects Version/s": "None",
        "Fix Version/s": "1.8.1",
        "Component/s": "None",
        "Assignee": "Suneel Marthi",
        "Reporter": "J\u00f6rn Kottmann",
        "Created": "03/Jul/17 18:38",
        "Updated": "03/Jul/17 20:45",
        "Resolved": "03/Jul/17 20:45",
        "Description": "We are now migrated to gitbox and have our main repository at GitHub. The pom.xml needs to be updated to reflect that.",
        "Issue Links": [
            "https://github.com/apache/opennlp/pull/244"
        ]
    },
    "OPENNLP-1110": {
        "Key": "OPENNLP-1110",
        "Summary": "Change visibility of LanguageDetectorContextGenerator and extract interface",
        "Type": "Bug",
        "Status": "Closed",
        "Priority": "Major",
        "Resolution": "Fixed",
        "Affects Version/s": "1.8.1",
        "Fix Version/s": "1.8.1",
        "Component/s": "Language Detector",
        "Assignee": "William Colen",
        "Reporter": "William Colen",
        "Created": "05/Jul/17 11:20",
        "Updated": "05/Jul/17 12:48",
        "Resolved": "05/Jul/17 12:48",
        "Description": "LanguageDetectorContextGenerator should be public and extend an interface.",
        "Issue Links": []
    },
    "OPENNLP-1111": {
        "Key": "OPENNLP-1111",
        "Summary": "Add helper testing scripts for AWS EC2 to the sandbox",
        "Type": "Task",
        "Status": "Open",
        "Priority": "Minor",
        "Resolution": "Unresolved",
        "Affects Version/s": "None",
        "Fix Version/s": "None",
        "Component/s": "Build, Packaging and Test",
        "Assignee": "Jeff Zemerick",
        "Reporter": "Jeff Zemerick",
        "Created": "05/Jul/17 21:34",
        "Updated": "15/Aug/22 16:14",
        "Resolved": null,
        "Description": "Add helper testing scripts for AWS EC2 to the sandbox. These scripts will be updated as they mature.",
        "Issue Links": [
            "https://github.com/apache/opennlp-sandbox/pull/4",
            "https://github.com/apache/opennlp-sandbox/pull/6",
            "https://github.com/apache/opennlp-sandbox/pull/7",
            "https://github.com/apache/opennlp-sandbox/pull/8"
        ]
    },
    "OPENNLP-1112": {
        "Key": "OPENNLP-1112",
        "Summary": "Jenkins should publish daily snapshot builds",
        "Type": "Improvement",
        "Status": "Closed",
        "Priority": "Major",
        "Resolution": "Fixed",
        "Affects Version/s": "None",
        "Fix Version/s": "None",
        "Component/s": "Build, Packaging and Test",
        "Assignee": "J\u00f6rn Kottmann",
        "Reporter": "J\u00f6rn Kottmann",
        "Created": "06/Jul/17 08:56",
        "Updated": "10/Oct/17 09:55",
        "Resolved": "10/Oct/17 09:55",
        "Description": "Jenkins should publish a snapshot build every time the master branch is updated.",
        "Issue Links": []
    },
    "OPENNLP-1113": {
        "Key": "OPENNLP-1113",
        "Summary": "Identify why some eval tests fail on AMD processors",
        "Type": "Test",
        "Status": "Closed",
        "Priority": "Minor",
        "Resolution": "Fixed",
        "Affects Version/s": "1.8.1",
        "Fix Version/s": "1.9.3",
        "Component/s": "None",
        "Assignee": "Jeff Zemerick",
        "Reporter": "Jeff Zemerick",
        "Created": "07/Jul/17 18:14",
        "Updated": "10/Jun/20 11:24",
        "Resolved": "10/Jun/20 11:24",
        "Description": "When running the eval-tests for the 1.8.1 tag some of the tests consistently fail on an EC2 instance. On another virtual machine the tests consistently pass. When the tests fail the failures are consistent with the following:\nFailed tests: \n  ArvoresDeitadasEval.evalPortugueseChunkerQnMultipleThreads:208->chunkerCrossEval:128 expected:<0.9649180953528779> but was:<0.9650518197155942>\n  ArvoresDeitadasEval.evalPortugueseSentenceDetectorMaxentQn:143->sentenceCrossEval:90 expected:<0.99261110833375> but was:<0.9927505074644777>\n  Conll02NameFinderEval.evalSpanishOrganizationMaxentQn:390->eval:90 expected:<0.682961897915169> but was:<0.6798418972332015>\n  ConllXPosTaggerEval.evalSwedishMaxentQn:152->eval:76 expected:<0.9347595473833098> but was:<0.9322842998585573>\nBoth systems are Ubuntu 16.04.2 running OpenJDK 1.8.0_131 but there must be some other differences affecting the tests. Those differences need to be identified.\nVM1 (Tests Consistently Pass)\nApache Maven 3.3.9\nMaven home: /usr/share/maven\nJava version: 1.8.0_131, vendor: Oracle Corporation\nJava home: /usr/lib/jvm/java-8-openjdk-amd64/jre\nDefault locale: en_US, platform encoding: UTF-8\nOS name: \"linux\", version: \"4.4.0-1022-aws\", arch: \"amd64\", family: \"unix\"\nLANG=en_US.UTF-8\nVM2 (Tests Consistently Fail)\nApache Maven 3.3.9\nMaven home: /usr/share/maven\nJava version: 1.8.0_131, vendor: Oracle Corporation\nJava home: /usr/lib/jvm/java-8-openjdk-amd64/jre\nDefault locale: en_US, platform encoding: UTF-8\nOS name: \"linux\", version: \"4.4.0-83-generic\", arch: \"amd64\", family: \"unix\"\nLANG=en_US.UTF-8\nThis VM also consistently fails when using Oracle JDK:\nJava version: 1.8.0_131, vendor: Oracle Corporation\nJava home: /usr/lib/jvm/java-8-oracle/jre\nVM3 (Tests Consistently Pass)\nApache Maven 3.3.9\nMaven home: /usr/share/maven\nJava version: 1.8.0_131, vendor: Oracle Corporation\nJava home: /usr/lib/jvm/java-8-openjdk-amd64/jre\nDefault locale: en_US, platform encoding: UTF-8\nOS name: \"linux\", version: \"4.4.0-83-generic\", arch: \"amd64\", family: \"unix\"\nVM4 (Tests Consistently Fail)\nApache Maven 3.3.9 (bb52d8502b132ec0a5a3f4c09453c07478323dc5; 2015-11-10T11:41:47-05:00)\nMaven home: C:\\Program Files (x86)\\maven\\bin\\..\nJava version: 1.8.0_92, vendor: Oracle Corporation\nJava home: C:\\Program Files\\Java\\jdk1.8.0_92\\jre\nDefault locale: en_US, platform encoding: Cp1252\nOS name: \"windows 10\", version: \"10.0\", arch: \"amd64\", family: \"dos\"",
        "Issue Links": []
    },
    "OPENNLP-1114": {
        "Key": "OPENNLP-1114",
        "Summary": "Update OpenNLP Release Notes",
        "Type": "Improvement",
        "Status": "Closed",
        "Priority": "Major",
        "Resolution": "Fixed",
        "Affects Version/s": "1.8.1",
        "Fix Version/s": "1.8.2",
        "Component/s": "Documentation",
        "Assignee": "Suneel Marthi",
        "Reporter": "Suneel Marthi",
        "Created": "08/Jul/17 15:43",
        "Updated": "16/Jul/17 12:48",
        "Resolved": "11/Jul/17 11:34",
        "Description": "The Release Notes need to be updated to account for the changes to the web site code that need to happen prior to a Release announcement.",
        "Issue Links": []
    },
    "OPENNLP-1115": {
        "Key": "OPENNLP-1115",
        "Summary": "Document Categorizer all events dropped",
        "Type": "Question",
        "Status": "Closed",
        "Priority": "Major",
        "Resolution": "Won't Fix",
        "Affects Version/s": "1.7.2",
        "Fix Version/s": "None",
        "Component/s": "Doccat",
        "Assignee": null,
        "Reporter": "Alessandro Depase",
        "Created": "10/Jul/17 07:51",
        "Updated": "11/Jul/17 11:17",
        "Resolved": "11/Jul/17 11:17",
        "Description": "Hi all,\nI'm trying to perform my first (newbie) document categorization using italian language.\nI'm using the attached train file and i got this output:\n{{$ ./opennlp.bat DoccatTrainer -model it-doccat.bin -lang it -data \"C:\\Users\\adepase\\MPSProjects\\MrJEditor\\languages\\MrJEditor\\sandbox\\source_gen\\MrJEditor\\sandbox\\Train1.train\" -encoding UTF-8\nIndexing events using cutoff of 5\n        Computing event counts...  done. 12 events\n        Indexing...  Dropped event Ok:[bow=ok]\nDropped event Ok:[bow=tutto, bow=bene]\nDropped event Ok:[bow=decisamente, bow=non, bow=male]\nDropped event Ok:[bow=fantastica, bow=scelta]\nDropped event Ok:[bow=non, bow=pensavo, bow=di, bow=poter, bow=essere, bow=cos\u00ec, bow=contento]\nDropped event Ok:[bow=certamente, bow=un'ottimo, bow=risultato]\nDropped event no:[bow=non, bow=va, bow=affatto, bow=bene]\nDropped event no:[bow=per, bow=nulla]\nDropped event no:[bow=niente, bow=affatto, bow=divertente]\nDropped event no:[bow=va, bow=malissimo]\nDropped event no:[bow=va, bow=decisamente, bow=male]\nDropped event no:[bow=sono, bow=molto, bow=triste]\ndone.\nSorting and merging events...\nERROR: Not enough training data\nThe provided training data is not sufficient to create enough events to train a model.\nTo resolve this error use more training data, if this doesn't help there might\nbe some fundamental problem with the training data itself.}}\nI already found a couple of other similar issues, just saying that there are not enough lines (but I have 6 lines for each category and a cutoff of 5) or that without at least 100 lines the categorization quality is not sufficient (ok, but that's just a quality matter, it should work, with bad results, but it should work). The reason for insufficient data is that all the lines are dropped.\nI also tried with java api, same result.\nBut why? What did I miss? I cannot find useful documentation...\nThank you in advance\nKind Regards\n    Alessandro",
        "Issue Links": []
    },
    "OPENNLP-1116": {
        "Key": "OPENNLP-1116",
        "Summary": "Add Concatenate Stream method for Collections of streams",
        "Type": "Improvement",
        "Status": "Closed",
        "Priority": "Trivial",
        "Resolution": "Fixed",
        "Affects Version/s": "1.8.1",
        "Fix Version/s": "1.8.2",
        "Component/s": "Machine Learning",
        "Assignee": "Daniel Russ",
        "Reporter": "Daniel Russ",
        "Created": "13/Jul/17 13:34",
        "Updated": "17/Jul/17 11:58",
        "Resolved": "17/Jul/17 11:58",
        "Description": "Minor change to opennlp.tools.util.ObjectStreamUtls.  First change the signature of the createObjectStream(final ObjectStream<T>... streams)  to concatenateObjectStream(final ObjectStream<T>... streams), and add a method concatenateObjectStream(final Collection<ObjectStream<T>> streams)\nThe reason behind this is that I often pull data from multiple files, whereas it is possible to create an array of ObjectStreams, it is easier to work with Lists.  Also, the name of the method is clearer.  It concatenates a list/array of ObjectStreams  as opposed the the createObjectStream(final Collection<T> collection) which makes an obectstream of items in the collection.",
        "Issue Links": []
    },
    "OPENNLP-1117": {
        "Key": "OPENNLP-1117",
        "Summary": "Fix cmd line training time",
        "Type": "Bug",
        "Status": "Closed",
        "Priority": "Trivial",
        "Resolution": "Fixed",
        "Affects Version/s": "1.7.1",
        "Fix Version/s": "1.8.2",
        "Component/s": "Command Line Interface",
        "Assignee": "Peter Thygesen",
        "Reporter": "Peter Thygesen",
        "Created": "16/Jul/17 08:23",
        "Updated": "16/Jul/17 17:14",
        "Resolved": "16/Jul/17 17:14",
        "Description": "The final execution time for training a model should be printed using System.err not System.out.",
        "Issue Links": [
            "/jira/browse/OPENNLP-137"
        ]
    },
    "OPENNLP-1118": {
        "Key": "OPENNLP-1118",
        "Summary": "Add test data verification to tests under opennlp.tools.eval",
        "Type": "Improvement",
        "Status": "Closed",
        "Priority": "Minor",
        "Resolution": "Fixed",
        "Affects Version/s": "None",
        "Fix Version/s": "1.8.2",
        "Component/s": "Build, Packaging and Test",
        "Assignee": "Jeff Zemerick",
        "Reporter": "Jeff Zemerick",
        "Created": "18/Jul/17 13:08",
        "Updated": "31/Jul/17 13:40",
        "Resolved": "28/Jul/17 09:57",
        "Description": "Add test data verification to tests under opennlp.tools.eval. Each class should verify the test data prior to executing the tests in the class.",
        "Issue Links": []
    },
    "OPENNLP-1119": {
        "Key": "OPENNLP-1119",
        "Summary": "Leipzig sample stream should shuffle data",
        "Type": "Improvement",
        "Status": "Closed",
        "Priority": "Major",
        "Resolution": "Fixed",
        "Affects Version/s": "None",
        "Fix Version/s": "1.8.2",
        "Component/s": "Formats",
        "Assignee": "J\u00f6rn Kottmann",
        "Reporter": "J\u00f6rn Kottmann",
        "Created": "28/Jul/17 10:27",
        "Updated": "31/Aug/17 09:02",
        "Resolved": "31/Aug/17 09:02",
        "Description": "The Leipzig language data files are sorted by the first token of a sentence and the output is also sorted bylanguge.\nTo improve this the following should be done:\n\nThe samples should be build from randomly picked lines taken from a sentences file\nThe samples in the stream should be shuffled",
        "Issue Links": []
    },
    "OPENNLP-1120": {
        "Key": "OPENNLP-1120",
        "Summary": "PrintStream attribute in EvaluationErrorPrinter should be protected",
        "Type": "Bug",
        "Status": "Closed",
        "Priority": "Major",
        "Resolution": "Fixed",
        "Affects Version/s": "1.8.1",
        "Fix Version/s": "1.8.1",
        "Component/s": "Command Line Interface",
        "Assignee": "William Colen",
        "Reporter": "William Colen",
        "Created": "31/Jul/17 10:27",
        "Updated": "31/Jul/17 15:08",
        "Resolved": "31/Jul/17 15:08",
        "Description": "To allow easier customization, the PrintStream attribute in EvaluationErrorPrinter should be protected.",
        "Issue Links": []
    },
    "OPENNLP-1121": {
        "Key": "OPENNLP-1121",
        "Summary": "Invalid NameSample serialization if sequential span is unsorted",
        "Type": "Bug",
        "Status": "Closed",
        "Priority": "Major",
        "Resolution": "Fixed",
        "Affects Version/s": "1.8.1",
        "Fix Version/s": "1.8.1",
        "Component/s": "Name Finder",
        "Assignee": "William Colen",
        "Reporter": "William Colen",
        "Created": "31/Jul/17 15:09",
        "Updated": "02/Aug/17 11:26",
        "Resolved": "02/Aug/17 11:26",
        "Description": null,
        "Issue Links": []
    },
    "OPENNLP-1122": {
        "Key": "OPENNLP-1122",
        "Summary": "Leipzig sample should allow skip initial entries",
        "Type": "Bug",
        "Status": "Closed",
        "Priority": "Major",
        "Resolution": "Fixed",
        "Affects Version/s": "1.8.2",
        "Fix Version/s": "1.8.2",
        "Component/s": "Formats",
        "Assignee": "William Colen",
        "Reporter": "William Colen",
        "Created": "19/Aug/17 17:42",
        "Updated": "31/Aug/17 13:02",
        "Resolved": "31/Aug/17 12:22",
        "Description": null,
        "Issue Links": []
    },
    "OPENNLP-1123": {
        "Key": "OPENNLP-1123",
        "Summary": "Implement early stopping in NameFinderME",
        "Type": "New Feature",
        "Status": "Closed",
        "Priority": "Major",
        "Resolution": "Done",
        "Affects Version/s": "None",
        "Fix Version/s": "1.8.2",
        "Component/s": "Name Finder",
        "Assignee": null,
        "Reporter": "Saurabh Jain",
        "Created": "29/Aug/17 09:23",
        "Updated": "03/Apr/18 23:29",
        "Resolved": "03/Apr/18 23:28",
        "Description": "Implement early stopping in NameFinderME.",
        "Issue Links": []
    },
    "OPENNLP-1124": {
        "Key": "OPENNLP-1124",
        "Summary": "Optimize XML Parser configuration",
        "Type": "Improvement",
        "Status": "Closed",
        "Priority": "Major",
        "Resolution": "Fixed",
        "Affects Version/s": "1.8.2",
        "Fix Version/s": "1.8.2",
        "Component/s": "None",
        "Assignee": "William Colen",
        "Reporter": "William Colen",
        "Created": "29/Aug/17 12:07",
        "Updated": "31/Aug/17 09:03",
        "Resolved": "31/Aug/17 09:03",
        "Description": null,
        "Issue Links": []
    },
    "OPENNLP-1125": {
        "Key": "OPENNLP-1125",
        "Summary": "Change misclassified report layout for LanguageDetector",
        "Type": "Improvement",
        "Status": "Closed",
        "Priority": "Minor",
        "Resolution": "Fixed",
        "Affects Version/s": "1.8.2",
        "Fix Version/s": "1.8.2",
        "Component/s": "Language Detector",
        "Assignee": "William Colen",
        "Reporter": "William Colen",
        "Created": "29/Aug/17 12:27",
        "Updated": "31/Aug/17 12:12",
        "Resolved": "31/Aug/17 12:12",
        "Description": "The layout of the default report is not nice for Language Detector. This will change it to tabular layout.",
        "Issue Links": []
    },
    "OPENNLP-1126": {
        "Key": "OPENNLP-1126",
        "Summary": "Consolidate the two README files into README.md",
        "Type": "Improvement",
        "Status": "Closed",
        "Priority": "Minor",
        "Resolution": "Fixed",
        "Affects Version/s": "None",
        "Fix Version/s": "1.8.2",
        "Component/s": "Build, Packaging and Test",
        "Assignee": "J\u00f6rn Kottmann",
        "Reporter": "J\u00f6rn Kottmann",
        "Created": "04/Sep/17 20:05",
        "Updated": "04/Sep/17 20:37",
        "Resolved": "04/Sep/17 20:37",
        "Description": "It would be nicer to have just the README.md file and render it to html for the binary distribution. The two files, README.md and README, currently mostly duplicate their content.",
        "Issue Links": [
            "https://github.com/apache/opennlp/pull/260"
        ]
    },
    "OPENNLP-1127": {
        "Key": "OPENNLP-1127",
        "Summary": "Fix readme HTML file generated for distribution archives",
        "Type": "Bug",
        "Status": "Closed",
        "Priority": "Trivial",
        "Resolution": "Fixed",
        "Affects Version/s": "1.8.1",
        "Fix Version/s": "1.8.2",
        "Component/s": "Build, Packaging and Test",
        "Assignee": "Bruno P. Kinoshita",
        "Reporter": "Bruno P. Kinoshita",
        "Created": "06/Sep/17 10:55",
        "Updated": "10/Oct/17 09:56",
        "Resolved": "10/Oct/17 09:56",
        "Description": "The current README.md file, in the project root directory, is used by the opennlp-distr module. The readme file is included in distribution files. There are a few changes in the master branch that were not released yet.\nRunning `mvn clean install` will create the distribution files, and inside you should find a README.html created based on the README.md file, plus other files.\nThe Markdown to HTML generation is being done through https://github.com/walokra/markdown-page-generator-plugin.\nThis issue is for enhancements in the README file and also around the markdown-page-generator-plugin use. As 1.8.2 release is in progress, this may be included in 1.8.3.\nCheers\nBruno",
        "Issue Links": [
            "https://github.com/apache/opennlp/pull/261"
        ]
    },
    "OPENNLP-1128": {
        "Key": "OPENNLP-1128",
        "Summary": "Fix checksum in SourceForgeModelEval.verifyTrainingData",
        "Type": "Bug",
        "Status": "Closed",
        "Priority": "Major",
        "Resolution": "Fixed",
        "Affects Version/s": "1.8.2",
        "Fix Version/s": "1.8.2",
        "Component/s": "Build, Packaging and Test",
        "Assignee": "William Colen",
        "Reporter": "William Colen",
        "Created": "07/Sep/17 11:17",
        "Updated": "07/Sep/17 11:24",
        "Resolved": "07/Sep/17 11:24",
        "Description": null,
        "Issue Links": [
            "https://github.com/apache/opennlp/pull/262"
        ]
    },
    "OPENNLP-1129": {
        "Key": "OPENNLP-1129",
        "Summary": "Github mirror - no files under tag for 1.6.0",
        "Type": "Bug",
        "Status": "Closed",
        "Priority": "Minor",
        "Resolution": "Workaround",
        "Affects Version/s": "1.6.0",
        "Fix Version/s": "None",
        "Component/s": "None",
        "Assignee": null,
        "Reporter": "Gus Heck",
        "Created": "10/Sep/17 19:02",
        "Updated": "03/Apr/18 23:25",
        "Resolved": "03/Apr/18 23:25",
        "Description": "https://github.com/apache/opennlp/tree/opennlp-1.6.0\nShows zero files and the release zip on github is just an empty file. Noticed this while trying to verify license/notice file contents for this version.",
        "Issue Links": []
    },
    "OPENNLP-1130": {
        "Key": "OPENNLP-1130",
        "Summary": "Sentence detector format support for NKJP",
        "Type": "New Feature",
        "Status": "Open",
        "Priority": "Minor",
        "Resolution": "Unresolved",
        "Affects Version/s": "None",
        "Fix Version/s": "None",
        "Component/s": "Formats",
        "Assignee": null,
        "Reporter": "Jim Regan",
        "Created": "11/Sep/17 00:54",
        "Updated": "20/Dec/17 10:01",
        "Resolved": null,
        "Description": null,
        "Issue Links": [
            "https://github.com/apache/opennlp/pull/263"
        ]
    },
    "OPENNLP-1131": {
        "Key": "OPENNLP-1131",
        "Summary": "LeipzigLanguageSampleStreamFactory should not load hidden files",
        "Type": "Bug",
        "Status": "Closed",
        "Priority": "Major",
        "Resolution": "Fixed",
        "Affects Version/s": "1.8.2",
        "Fix Version/s": "1.8.3",
        "Component/s": "Language Detector",
        "Assignee": "Peter Thygesen",
        "Reporter": "Peter Thygesen",
        "Created": "14/Sep/17 09:01",
        "Updated": "10/Oct/17 09:58",
        "Resolved": "10/Oct/17 09:58",
        "Description": ".DS_Store file is loaded as a sentence sample file. This is should not happen.\nException in thread \"main\" java.io.UncheckedIOException: java.nio.charset.MalformedInputException: Input length = 1\n\tat java.io.BufferedReader$1.hasNext(BufferedReader.java:574)\n\tat java.util.Iterator.forEachRemaining(Iterator.java:115)\n\tat java.util.Spliterators$IteratorSpliterator.forEachRemaining(Spliterators.java:1801)\n\tat java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:481)\n\tat java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:471)\n\tat java.util.stream.ReduceOps$ReduceOp.evaluateSequential(ReduceOps.java:708)\n\tat java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234)\n\tat java.util.stream.LongPipeline.reduce(LongPipeline.java:438)\n\tat java.util.stream.LongPipeline.sum(LongPipeline.java:396)\n\tat java.util.stream.ReferencePipeline.count(ReferencePipeline.java:526)\n\tat opennlp.tools.formats.leipzig.LeipzigLanguageSampleStream$LeipzigSentencesStream.<init>(LeipzigLanguageSampleStream.java:57)\n\tat opennlp.tools.formats.leipzig.LeipzigLanguageSampleStream.read(LeipzigLanguageSampleStream.java:157)\n\tat opennlp.tools.formats.leipzig.LeipzigLanguageSampleStream.read(LeipzigLanguageSampleStream.java:42)\n\tat opennlp.tools.formats.leipzig.SampleShuffleStream.<init>(SampleShuffleStream.java:38)\n\tat opennlp.tools.formats.leipzig.LeipzigLanguageSampleStreamFactory.create(LeipzigLanguageSampleStreamFactory.java:76)\n\tat opennlp.tools.cmdline.AbstractConverterTool.run(AbstractConverterTool.java:106)\n\tat opennlp.tools.cmdline.CLI.main(CLI.java:256)\nCaused by: java.nio.charset.MalformedInputException: Input length = 1\n\tat java.nio.charset.CoderResult.throwException(CoderResult.java:281)\n\tat sun.nio.cs.StreamDecoder.implRead(StreamDecoder.java:339)\n\tat sun.nio.cs.StreamDecoder.read(StreamDecoder.java:178)\n\tat java.io.InputStreamReader.read(InputStreamReader.java:184)\n\tat java.io.BufferedReader.fill(BufferedReader.java:161)\n\tat java.io.BufferedReader.readLine(BufferedReader.java:324)\n\tat java.io.BufferedReader.readLine(BufferedReader.java:389)\n\tat java.io.BufferedReader$1.hasNext(BufferedReader.java:571)\n\t... 16 more",
        "Issue Links": [
            "https://github.com/apache/opennlp/pull/264"
        ]
    },
    "OPENNLP-1132": {
        "Key": "OPENNLP-1132",
        "Summary": "Fail with exception if not enough lines in leipzig parser",
        "Type": "Bug",
        "Status": "Closed",
        "Priority": "Major",
        "Resolution": "Fixed",
        "Affects Version/s": "1.8.2",
        "Fix Version/s": "1.8.4",
        "Component/s": "Language Detector",
        "Assignee": "Peter Thygesen",
        "Reporter": "Peter Thygesen",
        "Created": "14/Sep/17 09:07",
        "Updated": "26/Dec/17 18:47",
        "Resolved": "26/Dec/17 18:47",
        "Description": "Exception in thread \"main\" java.lang.IndexOutOfBoundsException: toIndex = 100000\n\tat java.util.ArrayList.subListRangeCheck(ArrayList.java:1004)\n\tat java.util.ArrayList.subList(ArrayList.java:996)\n\tat opennlp.tools.formats.leipzig.LeipzigLanguageSampleStream$LeipzigSentencesStream.<init>(LeipzigLanguageSampleStream.java:65)\n\tat opennlp.tools.formats.leipzig.LeipzigLanguageSampleStream.read(LeipzigLanguageSampleStream.java:157)\n\tat opennlp.tools.formats.leipzig.LeipzigLanguageSampleStream.read(LeipzigLanguageSampleStream.java:42)\n\tat opennlp.tools.formats.leipzig.SampleShuffleStream.<init>(SampleShuffleStream.java:38)\n\tat opennlp.tools.formats.leipzig.LeipzigLanguageSampleStreamFactory.create(LeipzigLanguageSampleStreamFactory.java:76)\n\tat opennlp.tools.cmdline.AbstractConverterTool.run(AbstractConverterTool.java:106)\n\tat opennlp.tools.cmdline.CLI.main(CLI.java:256)\nline 65:\nSet<Integer> selectedLines = new HashSet<>(\n          indexes.subList(0, sentencesPerSample * numberOfSamples));\nFails if sentencesPerSample x numberOfSamples is larger than size of indexes (source file).",
        "Issue Links": [
            "https://github.com/apache/opennlp/pull/265"
        ]
    },
    "OPENNLP-1133": {
        "Key": "OPENNLP-1133",
        "Summary": "The Gaussian smoother cannot be used",
        "Type": "Bug",
        "Status": "Closed",
        "Priority": "Major",
        "Resolution": "Fixed",
        "Affects Version/s": "1.8.2",
        "Fix Version/s": "1.8.3",
        "Component/s": "Machine Learning",
        "Assignee": "Daniel Russ",
        "Reporter": "Daniel Russ",
        "Created": "22/Sep/17 15:04",
        "Updated": "10/Oct/17 10:03",
        "Resolved": "10/Oct/17 10:03",
        "Description": "In the  GISTrainer, the variable useGaussianSmoothing cannot be set using the TrainingParameters",
        "Issue Links": [
            "https://github.com/apache/opennlp/pull/272"
        ]
    },
    "OPENNLP-1134": {
        "Key": "OPENNLP-1134",
        "Summary": "Remove dependencies on java.logging",
        "Type": "Improvement",
        "Status": "Closed",
        "Priority": "Minor",
        "Resolution": "Fixed",
        "Affects Version/s": "None",
        "Fix Version/s": "1.8.3",
        "Component/s": "None",
        "Assignee": "J\u00f6rn Kottmann",
        "Reporter": "J\u00f6rn Kottmann",
        "Created": "26/Sep/17 11:49",
        "Updated": "26/Sep/17 14:37",
        "Resolved": "26/Sep/17 14:37",
        "Description": "In two cases this is used instead of System.out.println. It would be better to remove this and either ignore errors or fail with an exception.",
        "Issue Links": [
            "https://github.com/apache/opennlp/pull/266"
        ]
    },
    "OPENNLP-1135": {
        "Key": "OPENNLP-1135",
        "Summary": "Remove support for OSGi",
        "Type": "Wish",
        "Status": "Closed",
        "Priority": "Minor",
        "Resolution": "Fixed",
        "Affects Version/s": "None",
        "Fix Version/s": "2.1.1",
        "Component/s": "None",
        "Assignee": "Atita Arora",
        "Reporter": "J\u00f6rn Kottmann",
        "Created": "26/Sep/17 14:48",
        "Updated": "30/Jan/23 07:40",
        "Resolved": "09/Jan/23 18:35",
        "Description": "Remove the OSGi bundle support from the opennlp-tools jar. OSGi isn't used widely and the ones who are using it know how to use opennlp-tools in an OSGi environment anyway by applying some build tricks.",
        "Issue Links": []
    },
    "OPENNLP-1136": {
        "Key": "OPENNLP-1136",
        "Summary": "Fix tests on Windows",
        "Type": "Test",
        "Status": "Closed",
        "Priority": "Major",
        "Resolution": "Not A Problem",
        "Affects Version/s": "1.8.3",
        "Fix Version/s": "None",
        "Component/s": "Build, Packaging and Test",
        "Assignee": "Jeff Zemerick",
        "Reporter": "Jeff Zemerick",
        "Created": "28/Sep/17 22:00",
        "Updated": "29/Sep/17 12:10",
        "Resolved": "29/Sep/17 12:10",
        "Description": "Two tests fail when built on Windows 10. The failures are due to a difference in line endings in the expected text in the tests' assertions. Changing '\\n' to System.lineSeparator() fixes the assertions.",
        "Issue Links": [
            "https://github.com/apache/opennlp/pull/267"
        ]
    },
    "OPENNLP-1137": {
        "Key": "OPENNLP-1137",
        "Summary": "Add more tests and check overlapping of name spans to NameSample",
        "Type": "Improvement",
        "Status": "Resolved",
        "Priority": "Trivial",
        "Resolution": "Fixed",
        "Affects Version/s": "1.8.2",
        "Fix Version/s": "1.8.3",
        "Component/s": "Name Finder",
        "Assignee": "Koji Sekiguchi",
        "Reporter": "Koji Sekiguchi",
        "Created": "02/Oct/17 11:27",
        "Updated": "03/Oct/17 00:49",
        "Resolved": "03/Oct/17 00:49",
        "Description": "NameSample has the following TODO in its constructor:\n// TODO: Check that name spans are not overlapping, otherwise throw exception\nI added simple code for it and its test.\nAnd I added a test for nested name spans.",
        "Issue Links": [
            "https://github.com/apache/opennlp/pull/268"
        ]
    },
    "OPENNLP-1138": {
        "Key": "OPENNLP-1138",
        "Summary": "Add more tests to Span",
        "Type": "Test",
        "Status": "Resolved",
        "Priority": "Trivial",
        "Resolution": "Fixed",
        "Affects Version/s": "1.8.2",
        "Fix Version/s": "1.8.3",
        "Component/s": "None",
        "Assignee": "Koji Sekiguchi",
        "Reporter": "Koji Sekiguchi",
        "Created": "03/Oct/17 02:45",
        "Updated": "04/Oct/17 02:16",
        "Resolved": "04/Oct/17 02:16",
        "Description": "Span's constructor can throw IllegalArgumentException but there is no tests for it. I'll add tests for them and in addition to that, I'll fix the test for toString() because it doesn't test it  , and I'll remove a redundancy from a constructor.",
        "Issue Links": [
            "https://github.com/apache/opennlp/pull/269"
        ]
    },
    "OPENNLP-1139": {
        "Key": "OPENNLP-1139",
        "Summary": "BilouCodec should use its own constants",
        "Type": "Bug",
        "Status": "Resolved",
        "Priority": "Trivial",
        "Resolution": "Fixed",
        "Affects Version/s": "1.8.2",
        "Fix Version/s": "1.8.3",
        "Component/s": "Name Finder",
        "Assignee": "Koji Sekiguchi",
        "Reporter": "Koji Sekiguchi",
        "Created": "03/Oct/17 07:31",
        "Updated": "04/Oct/17 02:16",
        "Resolved": "04/Oct/17 02:16",
        "Description": "It seems that BilouCodec accidentally uses BioCodec's constants such as BioCodec.START, BioCodec.CONTINUE, etc. It should use its own ones.",
        "Issue Links": [
            "https://github.com/apache/opennlp/pull/270"
        ]
    },
    "OPENNLP-1140": {
        "Key": "OPENNLP-1140",
        "Summary": "Add 20 newsgroups format support",
        "Type": "Improvement",
        "Status": "Closed",
        "Priority": "Major",
        "Resolution": "Fixed",
        "Affects Version/s": "None",
        "Fix Version/s": "1.8.4",
        "Component/s": "Formats",
        "Assignee": "J\u00f6rn Kottmann",
        "Reporter": "Tommaso Teofili",
        "Created": "03/Oct/17 11:50",
        "Updated": "26/Dec/17 18:44",
        "Resolved": "26/Dec/17 18:44",
        "Description": "It'd be nice to have support for 20 newsgroups format, especially for evaluating DocCat models.",
        "Issue Links": []
    },
    "OPENNLP-1141": {
        "Key": "OPENNLP-1141",
        "Summary": "Add DFA and use it from SequenceCodec.areOutcomesCompatible if possible",
        "Type": "Improvement",
        "Status": "Resolved",
        "Priority": "Minor",
        "Resolution": "Invalid",
        "Affects Version/s": "1.8.2",
        "Fix Version/s": "None",
        "Component/s": "Name Finder",
        "Assignee": "Koji Sekiguchi",
        "Reporter": "Koji Sekiguchi",
        "Created": "05/Oct/17 07:50",
        "Updated": "05/Oct/17 09:56",
        "Resolved": "05/Oct/17 09:49",
        "Description": "BioCodec and BilouCodec implement areOutcomesCompatible(). I think they can be written as DFA (Deterministic Finite Automaton).\nIn this ticket, I'll add s simple implementation of DFA and change areOutcomesCompatible() to use it.",
        "Issue Links": [
            "https://github.com/apache/opennlp/pull/271"
        ]
    },
    "OPENNLP-1142": {
        "Key": "OPENNLP-1142",
        "Summary": "Add an experimental annotation",
        "Type": "Improvement",
        "Status": "Closed",
        "Priority": "Minor",
        "Resolution": "Fixed",
        "Affects Version/s": "None",
        "Fix Version/s": "1.8.3",
        "Component/s": "None",
        "Assignee": "J\u00f6rn Kottmann",
        "Reporter": "J\u00f6rn Kottmann",
        "Created": "09/Oct/17 13:05",
        "Updated": "10/Oct/17 08:47",
        "Resolved": "10/Oct/17 08:47",
        "Description": "To mark new APIs which are not stable yet an experimental annotation should be introduced. If the annotation is set our users can't assume the APIs don't break backward compatibility.",
        "Issue Links": [
            "https://github.com/apache/opennlp/pull/273"
        ]
    },
    "OPENNLP-1143": {
        "Key": "OPENNLP-1143",
        "Summary": "Set the Java 9 automatic module name",
        "Type": "Improvement",
        "Status": "Closed",
        "Priority": "Minor",
        "Resolution": "Fixed",
        "Affects Version/s": "None",
        "Fix Version/s": "1.8.3",
        "Component/s": "Build, Packaging and Test",
        "Assignee": "J\u00f6rn Kottmann",
        "Reporter": "J\u00f6rn Kottmann",
        "Created": "09/Oct/17 13:50",
        "Updated": "09/Oct/17 14:42",
        "Resolved": "09/Oct/17 14:42",
        "Description": "The Java 9 module system derives the name from the jar file. This is not the name we prefer and therefore it should be set in the manifest.",
        "Issue Links": [
            "https://github.com/apache/opennlp/pull/274"
        ]
    },
    "OPENNLP-1144": {
        "Key": "OPENNLP-1144",
        "Summary": "Add support for word vector resources",
        "Type": "Improvement",
        "Status": "Closed",
        "Priority": "Major",
        "Resolution": "Fixed",
        "Affects Version/s": "None",
        "Fix Version/s": "1.8.3",
        "Component/s": "None",
        "Assignee": "J\u00f6rn Kottmann",
        "Reporter": "J\u00f6rn Kottmann",
        "Created": "09/Oct/17 14:47",
        "Updated": "21/Nov/17 08:52",
        "Resolved": "21/Nov/17 08:52",
        "Description": "It would be nice to have support for word vector resources and parsing support for the most common formats.",
        "Issue Links": [
            "https://github.com/apache/opennlp/pull/275"
        ]
    },
    "OPENNLP-1145": {
        "Key": "OPENNLP-1145",
        "Summary": "Javadoc of NaiveBayesTrainer class looks incorrect",
        "Type": "Bug",
        "Status": "Closed",
        "Priority": "Trivial",
        "Resolution": "Fixed",
        "Affects Version/s": "1.8.2",
        "Fix Version/s": "1.8.3",
        "Component/s": "Machine Learning",
        "Assignee": "Koji Sekiguchi",
        "Reporter": "Koji Sekiguchi",
        "Created": "16/Oct/17 12:17",
        "Updated": "24/Oct/17 15:28",
        "Resolved": "23/Oct/17 10:33",
        "Description": "It seems that Javadoc of NaiveBayesTrainer class was copied from PerceptronTrainer and hence, it says \"Trains models using the perceptron algorithm.\"",
        "Issue Links": [
            "https://github.com/apache/opennlp/pull/276"
        ]
    },
    "OPENNLP-1146": {
        "Key": "OPENNLP-1146",
        "Summary": "remove unnecessary serialVersionUID",
        "Type": "Improvement",
        "Status": "Closed",
        "Priority": "Trivial",
        "Resolution": "Fixed",
        "Affects Version/s": "1.8.2",
        "Fix Version/s": "1.8.3",
        "Component/s": "Build, Packaging and Test",
        "Assignee": "Koji Sekiguchi",
        "Reporter": "Koji Sekiguchi",
        "Created": "18/Oct/17 03:39",
        "Updated": "24/Oct/17 15:28",
        "Resolved": "19/Oct/17 01:33",
        "Description": "We saw several classes that have unnecessary serialVersionUID constant declaration. Most of them are Stemmer classes that are created by the Snowball to Java compiler. I think we can just remove serialVersionUID from Stemmer classes. Other than Stemmer classes, Exception classes which extend RuntimeException or IOException have serialVersionUID. I'll remove serialVersionUID from these Exception classes as well but add @SuppressWarnings(\"serial\") just in case.",
        "Issue Links": [
            "https://github.com/apache/opennlp/pull/277"
        ]
    },
    "OPENNLP-1147": {
        "Key": "OPENNLP-1147",
        "Summary": "Missing URLs in doc",
        "Type": "Bug",
        "Status": "Closed",
        "Priority": "Trivial",
        "Resolution": "Fixed",
        "Affects Version/s": "1.8.2",
        "Fix Version/s": "1.8.3",
        "Component/s": "Documentation",
        "Assignee": "Koji Sekiguchi",
        "Reporter": "Koji Sekiguchi",
        "Created": "20/Oct/17 08:58",
        "Updated": "24/Oct/17 15:28",
        "Resolved": "23/Oct/17 15:37",
        "Description": "When I read name finder part in document, some missing URLs were there. I'd like to correct some of them which I could find latest/alternative ones.",
        "Issue Links": [
            "https://github.com/apache/opennlp/pull/278"
        ]
    },
    "OPENNLP-1148": {
        "Key": "OPENNLP-1148",
        "Summary": "use StandardCharsets.UTF_8 in doc",
        "Type": "Improvement",
        "Status": "Closed",
        "Priority": "Trivial",
        "Resolution": "Fixed",
        "Affects Version/s": "1.8.2",
        "Fix Version/s": "1.8.3",
        "Component/s": "Documentation",
        "Assignee": "Koji Sekiguchi",
        "Reporter": "Koji Sekiguchi",
        "Created": "20/Oct/17 10:58",
        "Updated": "24/Oct/17 15:27",
        "Resolved": "23/Oct/17 22:17",
        "Description": "In the doc, the use of PlainTextByLineStream() is not unified. Other than specifying StandardCharsets.UTF_8 for its second parameter, there are following variations:\n\nString \"UTF-8\"\nStandardCharsets.UTF8 (not UTF_8)\nCharset.forName(\"UTF-8\")\n\nLet's unify the use to StandardCharsets.UTF_8",
        "Issue Links": [
            "https://github.com/apache/opennlp/pull/279"
        ]
    },
    "OPENNLP-1149": {
        "Key": "OPENNLP-1149",
        "Summary": "remove unused member in PlainTextByLineStream",
        "Type": "Improvement",
        "Status": "Closed",
        "Priority": "Trivial",
        "Resolution": "Fixed",
        "Affects Version/s": "1.8.2",
        "Fix Version/s": "1.8.3",
        "Component/s": "None",
        "Assignee": "Koji Sekiguchi",
        "Reporter": "Koji Sekiguchi",
        "Created": "23/Oct/17 04:55",
        "Updated": "24/Oct/17 15:27",
        "Resolved": "24/Oct/17 08:14",
        "Description": "PlainTextByLineStream has a private member variable \"channel\" but it is never set and hence, it is always null. It can be removed to simplify code.",
        "Issue Links": [
            "https://github.com/apache/opennlp/pull/280"
        ]
    },
    "OPENNLP-1150": {
        "Key": "OPENNLP-1150",
        "Summary": "TokenNameFinderTrainerTool should use ModelUtil.createDefaultTrainingParameters() when mlParams is null",
        "Type": "Improvement",
        "Status": "Open",
        "Priority": "Trivial",
        "Resolution": "Unresolved",
        "Affects Version/s": "1.8.2",
        "Fix Version/s": "None",
        "Component/s": "Name Finder",
        "Assignee": null,
        "Reporter": "Koji Sekiguchi",
        "Created": "23/Oct/17 09:15",
        "Updated": "26/Feb/23 13:16",
        "Resolved": null,
        "Description": "Unlike other TrainerTools, TokenNameFinderTrainerTool create an empty TrainingParameters when mlParams is null by calling the constructor. TokenNameFinderTrainerTool should use ModelUtil.createDefaultTrainingParameters() like as other TrainerTools do to initialize mlParams.",
        "Issue Links": [
            "https://github.com/apache/opennlp/pull/281"
        ]
    },
    "OPENNLP-1151": {
        "Key": "OPENNLP-1151",
        "Summary": "All Sample objects should implement Serializable for easy interation into other tools",
        "Type": "Bug",
        "Status": "Closed",
        "Priority": "Minor",
        "Resolution": "Fixed",
        "Affects Version/s": "None",
        "Fix Version/s": "1.8.3",
        "Component/s": "None",
        "Assignee": "Suneel Marthi",
        "Reporter": "J\u00f6rn Kottmann",
        "Created": "23/Oct/17 11:26",
        "Updated": "24/Oct/17 15:26",
        "Resolved": "24/Oct/17 08:20",
        "Description": "State of the Art frameworks like Apache Flink require that objects are serializable to use them in the pipeline. To use it to prepare training date for OpenNLP the Sample objects should all implement Serializable.",
        "Issue Links": [
            "https://github.com/apache/opennlp/pull/282"
        ]
    },
    "OPENNLP-1152": {
        "Key": "OPENNLP-1152",
        "Summary": "Move contents of RELEASE_NOTES.html into README.html",
        "Type": "Improvement",
        "Status": "Closed",
        "Priority": "Minor",
        "Resolution": "Fixed",
        "Affects Version/s": "None",
        "Fix Version/s": "1.8.3",
        "Component/s": "Build, Packaging and Test",
        "Assignee": "J\u00f6rn Kottmann",
        "Reporter": "J\u00f6rn Kottmann",
        "Created": "24/Oct/17 08:37",
        "Updated": "24/Oct/17 08:53",
        "Resolved": "24/Oct/17 08:53",
        "Description": "The two files are almost duplicated and the two sections about filling issues and links to the jira issues inside the release could be as well in the README.html.",
        "Issue Links": [
            "https://github.com/apache/opennlp/pull/283"
        ]
    },
    "OPENNLP-1153": {
        "Key": "OPENNLP-1153",
        "Summary": "Add model download page to website",
        "Type": "Improvement",
        "Status": "Closed",
        "Priority": "Trivial",
        "Resolution": "Fixed",
        "Affects Version/s": "None",
        "Fix Version/s": "1.8.3",
        "Component/s": "Website",
        "Assignee": "William Colen",
        "Reporter": "William Colen",
        "Created": "02/Nov/17 02:28",
        "Updated": "06/Nov/17 18:18",
        "Resolved": "06/Nov/17 18:18",
        "Description": null,
        "Issue Links": [
            "https://github.com/apache/opennlp-site/pull/40"
        ]
    },
    "OPENNLP-1154": {
        "Key": "OPENNLP-1154",
        "Summary": "change the XML format for feature generator config in NameFinder and POS Tagger",
        "Type": "Improvement",
        "Status": "Resolved",
        "Priority": "Major",
        "Resolution": "Fixed",
        "Affects Version/s": "1.8.3",
        "Fix Version/s": "None",
        "Component/s": "Name Finder",
        "Assignee": "Koji Sekiguchi",
        "Reporter": "Koji Sekiguchi",
        "Created": "10/Nov/17 11:34",
        "Updated": "27/Dec/17 03:55",
        "Resolved": "27/Dec/17 03:55",
        "Description": "NameFinder provides many kinds of feature generator (factories). Users can define their config via XML which looks like:\n\n\r\n<generators>\r\n  <cache> \r\n    <generators>\r\n      <window prevLength = \"2\" nextLength = \"2\">          \r\n        <tokenclass/>\r\n      </window>\r\n      <window prevLength = \"2\" nextLength = \"2\">                \r\n        <token/>\r\n      </window>\r\n      <definition/>\r\n      <prevmap/>\r\n      <bigram/>\r\n      <sentence begin=\"true\" end=\"false\"/>\r\n    </generators>\r\n  </cache> \r\n</generators>\r\n\n\nIf a user wants to implement their own feature generator, he can use <custom .../>, but if he wants to have two or more feature generators at once, he may be able to implement it by providing a wrapper feature generator which wraps two or more feature generators that he originally wants to have, but it is not good.\nI'd like to suggest that we make the config format more flexible like below:\n\n\r\n<generator class=\"opennlp.tools.util.featuregen.AggregatedFeatureGeneratorFactory\">\r\n  <args>\r\n    <generator class=\"opennlp.tools.util.featuregen.CachedFeatureGeneratorFactory\">\r\n      <args>\r\n        <generator class=\"opennlp.tools.util.featuregen.AggregatedFeatureGeneratorFactory\">\r\n          <args>\r\n            <generator class=\"opennlp.tools.util.featuregen.WindowFeatureGeneratorFactory\">\r\n              <args>\r\n                <int name=\"prevLength\">2</int>\r\n                <int name=\"nextLength\">2</int>\r\n                <generator class=\"opennlp.tools.util.featuregen.TokenClassFeatureGeneratorFactory\"/>\r\n              </args>\r\n            </generator>\r\n            <generator class=\"opennlp.tools.util.featuregen.WindowFeatureGeneratorFactory\">\r\n              <args>\r\n                <int name=\"prevLength\">2</int>\r\n                <int name=\"nextLength\">2</int>\r\n                <generator class=\"opennlp.tools.util.featuregen.TokenFeatureGeneratorFactory\"/>\r\n              </args>\r\n            </generator>\r\n          </args>\r\n        </generator>\r\n      </args>\r\n    </generator>\r\n  </args>\r\n</generator>\r\n\n\nIf <args>...</args> is too noisy, I'm thinking another format as well:\n\n\r\n<generator class=\"opennlp.tools.util.featuregen.AggregatedFeatureGeneratorFactory\">\r\n  <generator class=\"opennlp.tools.util.featuregen.CachedFeatureGeneratorFactory\">\r\n    <generator class=\"opennlp.tools.util.featuregen.AggregatedFeatureGeneratorFactory\">\r\n      <generator class=\"opennlp.tools.util.featuregen.WindowFeatureGeneratorFactory\">\r\n        <int name=\"prevLength\">2</int>\r\n        <int name=\"nextLength\">2</int>\r\n        <generator class=\"opennlp.tools.util.featuregen.TokenClassFeatureGeneratorFactory\"/>\r\n      </generator>\r\n      <generator class=\"opennlp.tools.util.featuregen.WindowFeatureGeneratorFactory\">\r\n        <int name=\"prevLength\">2</int>\r\n        <int name=\"nextLength\">2</int>\r\n        <generator class=\"opennlp.tools.util.featuregen.TokenFeatureGeneratorFactory\"/>\r\n      </generator>\r\n    </generator>\r\n  </generator>\r\n</generator>",
        "Issue Links": [
            "/jira/browse/OPENNLP-1161",
            "/jira/browse/OPENNLP-1159",
            "/jira/browse/OPENNLP-1160",
            "https://github.com/apache/opennlp/pull/286"
        ]
    },
    "OPENNLP-1155": {
        "Key": "OPENNLP-1155",
        "Summary": "Remove deprecated leipzig doccat format support",
        "Type": "Improvement",
        "Status": "Closed",
        "Priority": "Minor",
        "Resolution": "Fixed",
        "Affects Version/s": "None",
        "Fix Version/s": "1.8.4",
        "Component/s": "Doccat,                                            Formats",
        "Assignee": "Peter Thygesen",
        "Reporter": "J\u00f6rn Kottmann",
        "Created": "17/Nov/17 11:05",
        "Updated": "05/Dec/17 17:35",
        "Resolved": "05/Dec/17 17:35",
        "Description": null,
        "Issue Links": [
            "https://github.com/apache/opennlp/pull/290"
        ]
    },
    "OPENNLP-1156": {
        "Key": "OPENNLP-1156",
        "Summary": "Downloaded files have invalid hash sums",
        "Type": "Bug",
        "Status": "Closed",
        "Priority": "Major",
        "Resolution": "Not A Problem",
        "Affects Version/s": "1.8.3",
        "Fix Version/s": "1.8.4",
        "Component/s": "Website",
        "Assignee": null,
        "Reporter": "Oleg Popov",
        "Created": "19/Nov/17 10:36",
        "Updated": "26/Dec/17 18:47",
        "Resolved": "26/Dec/17 18:46",
        "Description": "[user@knime out]$ md5sum *\n336ec3cb06862f685a9b670753915ba9  apache-opennlp-1.8.3-bin.tar.gz\n2b1c1ec960646697a621bb52fd389083  apache-opennlp-1.8.3-bin.zip\n070645990b19210408229c045e9ddad9  apache-opennlp-1.8.3-src.tar.gz\ncc1757ad7bb988e6a41cd2c75d128309  apache-opennlp-1.8.3-src.zip\n[user@knime out]$ sha1sum *\n17e1089b41c6cad1a080cf763333f5593d2e39cd  apache-opennlp-1.8.3-bin.tar.gz\nd59af5017ffdb0b81898e39048a8c8b460f13025  apache-opennlp-1.8.3-bin.zip\n5af2aa28c4ce36b61a35d45767dcd47d25c368a4  apache-opennlp-1.8.3-src.tar.gz\n1189d6c5c464f5d32d2f47c08d4b05d65766a0d9  apache-opennlp-1.8.3-src.zip",
        "Issue Links": []
    },
    "OPENNLP-1157": {
        "Key": "OPENNLP-1157",
        "Summary": "Remove tokenizer param from doccat trainer cli",
        "Type": "Bug",
        "Status": "Closed",
        "Priority": "Minor",
        "Resolution": "Fixed",
        "Affects Version/s": "1.8.3",
        "Fix Version/s": "1.8.4",
        "Component/s": "Command Line Interface,                                            Doccat",
        "Assignee": "J\u00f6rn Kottmann",
        "Reporter": "J\u00f6rn Kottmann",
        "Created": "20/Nov/17 19:18",
        "Updated": "20/Nov/17 22:38",
        "Resolved": "20/Nov/17 19:52",
        "Description": "The parameter is not used for training after the tokenization support was removed from doccat.",
        "Issue Links": [
            "https://github.com/apache/opennlp/pull/288"
        ]
    },
    "OPENNLP-1158": {
        "Key": "OPENNLP-1158",
        "Summary": "The Brat Annotation Service does not serialize results appropriately",
        "Type": "Bug",
        "Status": "Closed",
        "Priority": "Major",
        "Resolution": "Fixed",
        "Affects Version/s": "1.8.3",
        "Fix Version/s": "1.8.4",
        "Component/s": "Applications",
        "Assignee": "Daniel Russ",
        "Reporter": "Daniel Russ",
        "Created": "21/Nov/17 19:49",
        "Updated": "05/Dec/17 17:47",
        "Resolved": "05/Dec/17 17:47",
        "Description": "After starting up the BratAnnotatorService NameFinderAnnSerive, BRAT passes text to the service, but it never returns.\n curl -v   -H \"Content-type: text/plain\" -H \"Accept: application/json\" -X POST -d \"I am a fireman\" localhost:8123/ner\n\nAbout to connect() to localhost port 8123 (#0)\nTrying 127.0.0.1... connected\nConnected to localhost (127.0.0.1) port 8123 (#0)\n> POST /ner HTTP/1.1\n> User-Agent: curl/7.19.7 (x86_64-redhat-linux-gnu) libcurl/7.19.7 NSS/3.27.1 zlib/1.2.3 libidn/1.18 libssh2/1.4.2\n> Host: localhost:8123\n> Content-type: text/plain\n> Accept: application/json\n> Content-Length: 14\n> \n< HTTP/1.1 400 Bad Request\n< Content-Type: text/plain\n< Date: Tue, 21 Nov 2017 19:43:15 GMT\n< Connection: close\n< Content-Length: 247\n< \nClosing connection #0\nNo serializer found for class opennlp.bratann.NameFinderResource$NameAnn and no properties discovered to create BeanSerializer (to avoid exception, disable SerializationFeature.FAIL_ON_EMPTY_BEANS) (through reference chain: java.util.HashMap[\"0\"]",
        "Issue Links": []
    },
    "OPENNLP-1159": {
        "Key": "OPENNLP-1159",
        "Summary": "avoid letting users specify AggregatedFeatureGeneratorFactory in XML config",
        "Type": "Improvement",
        "Status": "Resolved",
        "Priority": "Minor",
        "Resolution": "Fixed",
        "Affects Version/s": "1.8.3",
        "Fix Version/s": "None",
        "Component/s": "Formats,                                            Name Finder",
        "Assignee": "Koji Sekiguchi",
        "Reporter": "Koji Sekiguchi",
        "Created": "29/Nov/17 02:18",
        "Updated": "09/Jan/18 01:51",
        "Resolved": "09/Jan/18 01:51",
        "Description": "When I'm working on OPENNLP-1154, I think we should do it for better use.\nI'd like to implement this as an independent ticket from OPENNLP-1154 to make patch easy to read.",
        "Issue Links": [
            "/jira/browse/OPENNLP-1154",
            "https://github.com/apache/opennlp/pull/300"
        ]
    },
    "OPENNLP-1160": {
        "Key": "OPENNLP-1160",
        "Summary": "avoid letting users specify CachedFeatureGeneratorFactory in XML config",
        "Type": "Improvement",
        "Status": "Resolved",
        "Priority": "Minor",
        "Resolution": "Fixed",
        "Affects Version/s": "1.8.3",
        "Fix Version/s": "None",
        "Component/s": "Formats,                                            Name Finder",
        "Assignee": "Koji Sekiguchi",
        "Reporter": "Koji Sekiguchi",
        "Created": "29/Nov/17 02:22",
        "Updated": "12/Jan/18 02:51",
        "Resolved": "12/Jan/18 02:51",
        "Description": "This is similar to OPENNLP-1159. When I'm working on OPENNLP-1154, I think we should do it for better use.\nI'd like to implement this as an independent ticket from OPENNLP-1154 and OPENNLP-1159 to make patch easy to read.\nAnd this ticket is somewhat different from OPENNLP-1159 as users must be able to control the framework uses CachedFeatureGeneratorFactory or not.",
        "Issue Links": [
            "/jira/browse/OPENNLP-1154",
            "https://github.com/apache/opennlp/pull/305"
        ]
    },
    "OPENNLP-1161": {
        "Key": "OPENNLP-1161",
        "Summary": "avoid using concrete tag names of XML config in GeneratorFactory.extractArtifactSerializerMappings()",
        "Type": "Improvement",
        "Status": "Closed",
        "Priority": "Blocker",
        "Resolution": "Won't Fix",
        "Affects Version/s": "1.8.3",
        "Fix Version/s": "None",
        "Component/s": "Formats,                                            Name Finder",
        "Assignee": "Koji Sekiguchi",
        "Reporter": "Koji Sekiguchi",
        "Created": "30/Nov/17 08:51",
        "Updated": "09/Mar/23 15:22",
        "Resolved": "05/Dec/17 02:54",
        "Description": "When working on OPENNLP-1154, I noticed this.\nIn GeneratorFactory.extractArtifactSerializerMappings(), it specifies concrete XML tag names:\n\n\r\n    for (int i = 0; i < allElements.getLength(); i++) {\r\n      if (allElements.item(i) instanceof Element) {\r\n        Element xmlElement = (Element) allElements.item(i);\r\n\r\n        String dictName = xmlElement.getAttribute(\"dict\");\r\n        if (dictName != null) {\r\n\r\n          switch (xmlElement.getTagName()) {\r\n            case \"wordcluster\":\r\n              mapping.put(dictName, new WordClusterDictionary.WordClusterDictionarySerializer());\r\n              break;\r\n\r\n            case \"brownclustertoken\":\r\n              mapping.put(dictName, new BrownCluster.BrownClusterSerializer());\r\n              break;\r\n\r\n            case \"brownclustertokenclass\"://, ;\r\n              mapping.put(dictName, new BrownCluster.BrownClusterSerializer());\r\n              break;\r\n\r\n            case \"brownclusterbigram\": //, ;\r\n              mapping.put(dictName, new BrownCluster.BrownClusterSerializer());\r\n              break;\r\n\r\n            case \"dictionary\":\r\n              mapping.put(dictName, new DictionarySerializer());\r\n              break;\r\n          }\r\n        }\r\n\r\n        String modelName = xmlElement.getAttribute(\"model\");\r\n        if (modelName != null) {\r\n\r\n          switch (xmlElement.getTagName()) {\r\n            case \"tokenpos\":\r\n              mapping.put(modelName, new POSModelSerializer());\r\n              break;\r\n          }\r\n        }\r\n      }\r\n    }\r\n\n\nInstead, we'd better let FeatureGeneratorFactories implement a method that returns mapping (Map<String, ArtifactSerializer<?>>) and in GeneratorFactory.extractArtifactSerializerMappings(), the framework just calls the method of FeatureGeneratorFactories, which are found in XML config.",
        "Issue Links": [
            "/jira/browse/OPENNLP-1154",
            "https://github.com/apache/opennlp/pull/292"
        ]
    },
    "OPENNLP-1162": {
        "Key": "OPENNLP-1162",
        "Summary": "Add a script detector to the language detector",
        "Type": "Improvement",
        "Status": "Open",
        "Priority": "Major",
        "Resolution": "Unresolved",
        "Affects Version/s": "None",
        "Fix Version/s": "None",
        "Component/s": "Language Detector",
        "Assignee": null,
        "Reporter": "J\u00f6rn Kottmann",
        "Created": "30/Nov/17 14:31",
        "Updated": "30/Nov/17 14:31",
        "Resolved": null,
        "Description": "To be able to make better predictions it seems to be helpful to recognize the script a text is written in.\nThe script detector can be added as a new feature to the language detection package and might also be useful stand-alone to certain users.",
        "Issue Links": []
    },
    "OPENNLP-1163": {
        "Key": "OPENNLP-1163",
        "Summary": "Sentence detector doesn't spot abbreviations next to punctuation",
        "Type": "Bug",
        "Status": "Reopened",
        "Priority": "Critical",
        "Resolution": "Unresolved",
        "Affects Version/s": "1.8.3",
        "Fix Version/s": "None",
        "Component/s": "Sentence Detector",
        "Assignee": null,
        "Reporter": "Gabriele Vaccari",
        "Created": "30/Nov/17 14:40",
        "Updated": "27/Feb/23 20:16",
        "Resolved": null,
        "Description": "The Sentence Detector trained with an abbreviations list (see attachment) fails to spot them within a text if they are preceded by a punctuation mark. \nIn Italian, words starting with a vowel may be preceded by an article plus apostrophe sign (single quote). Example: L'ARTICOLO (the article). The term ARTICOLO, especially in legal text, is frequently abbreviated to ART.\nRepro steps:\n1) add the \"art.\" abbreviation in the abbreviations XML file (enclosed, ctrl+F \"art.\", case insensitive)\n2) train a model for the Italian language (training set enclosed) with the following command:\nopennlp SentenceDetectorTrainer -abbDict \"it-abbr.txt\" -lang it -model it-sen.bin -data training-set.txt -encoding UTF-8 \n3) run the model against a test text with the following command:\nopennlp SentenceDetector it-sen.bin < test.txt\nEven though the abbreviation \"art.\" was included in the XML file, the sentence detector breaks the sentence on instances of this abbreviation preceded by article and apostrophe (e.g. nell'art., dall'art., dell'art.). See also the enclosed output file out.txt, lines 6-7, 12-13, 13-14 and 16-17.\nThe issue isn't observed if the apostrophe (single quote) is replaced by a space character.",
        "Issue Links": []
    },
    "OPENNLP-1164": {
        "Key": "OPENNLP-1164",
        "Summary": "Distribute the language model as a Maven artifact",
        "Type": "Task",
        "Status": "Open",
        "Priority": "Minor",
        "Resolution": "Unresolved",
        "Affects Version/s": "None",
        "Fix Version/s": "None",
        "Component/s": "Build, Packaging and Test",
        "Assignee": "Jeff Zemerick",
        "Reporter": "Jeff Zemerick",
        "Created": "30/Nov/17 19:14",
        "Updated": "17/Jan/18 08:45",
        "Resolved": null,
        "Description": "Prepare the language model for distribution as a Maven artifact.",
        "Issue Links": [
            "https://cwiki.apache.org/confluence/display/OPENNLP/NIP-4%3A+Distribute+langdetect+model+as+Maven+dependency",
            "https://cwiki.apache.org/confluence/pages/viewpage.action?pageId=74689120"
        ]
    },
    "OPENNLP-1165": {
        "Key": "OPENNLP-1165",
        "Summary": "Add filename to overlapping annotation exception in NameSample",
        "Type": "Improvement",
        "Status": "Closed",
        "Priority": "Minor",
        "Resolution": "Fixed",
        "Affects Version/s": "1.8.3",
        "Fix Version/s": "1.8.4",
        "Component/s": "Name Finder",
        "Assignee": "Peter Thygesen",
        "Reporter": "Peter Thygesen",
        "Created": "04/Dec/17 09:31",
        "Updated": "04/Dec/17 09:57",
        "Resolved": "04/Dec/17 09:57",
        "Description": "When reading Brat annotated files I noticed that if I had overlapped annotations an exception was thrown, but it did not contain any information about in which file the annotation overlap was found.",
        "Issue Links": [
            "https://github.com/apache/opennlp/pull/293"
        ]
    },
    "OPENNLP-1166": {
        "Key": "OPENNLP-1166",
        "Summary": "TwoPassDataIndexer fails if features contain \\n",
        "Type": "Improvement",
        "Status": "Closed",
        "Priority": "Major",
        "Resolution": "Fixed",
        "Affects Version/s": "1.8.3",
        "Fix Version/s": "1.8.4",
        "Component/s": "Machine Learning",
        "Assignee": "Peter Thygesen",
        "Reporter": "Peter Thygesen",
        "Created": "04/Dec/17 10:44",
        "Updated": "26/Dec/17 18:45",
        "Resolved": "26/Dec/17 18:45",
        "Description": "Training a model with Newline tokens causes TwoPassDataIndexer to throw exception\nException in thread \"main\" java.util.NoSuchElementException\n    at java.util.StringTokenizer.nextToken(StringTokenizer.java:349)\n    at opennlp.tools.ml.model.FileEventStream.read(FileEventStream.java:71)\n    at opennlp.tools.ml.model.FileEventStream.read(FileEventStream.java:35)\n    at opennlp.tools.ml.model.AbstractDataIndexer.index(AbstractDataIndexer.java:168)\n    at opennlp.tools.ml.model.TwoPassDataIndexer.index(TwoPassDataIndexer.java:72)\n    at opennlp.tools.ml.AbstractEventTrainer.getDataIndexer(AbstractEventTrainer.java:68)\n    at opennlp.tools.ml.AbstractEventTrainer.train(AbstractEventTrainer.java:90)\n    at opennlp.tools.namefind.NameFinderME.train(NameFinderME.java:244)\n    at opennlp.tools.cmdline.namefind.TokenNameFinderTrainerTool.run(TokenNameFinderTrainerTool.java:169)\n    at opennlp.tools.cmdline.CLI.main(CLI.java:256)",
        "Issue Links": [
            "https://github.com/apache/opennlp/pull/294"
        ]
    },
    "OPENNLP-1167": {
        "Key": "OPENNLP-1167",
        "Summary": "WordVector toArray methods should be removed",
        "Type": "Task",
        "Status": "Closed",
        "Priority": "Major",
        "Resolution": "Fixed",
        "Affects Version/s": "None",
        "Fix Version/s": "1.8.4",
        "Component/s": "word vectors",
        "Assignee": "Tommaso Teofili",
        "Reporter": "Tommaso Teofili",
        "Created": "14/Dec/17 13:51",
        "Updated": "20/Dec/17 12:39",
        "Resolved": "15/Dec/17 09:49",
        "Description": "WordVector#toDoubleArray and WordVector#toFloatArray always require a copy, have size limitation and therefore should be probably removed.\nAdditionally we should think whether it makes sense to keep FloatArrayVector#toDoubleBuffer and DoubleArrayVector#toFloatBuffer which also require a copy. The alternative is to throw an UnsupportedOperationException in such cases.",
        "Issue Links": [
            "https://github.com/apache/opennlp/pull/295"
        ]
    },
    "OPENNLP-1168": {
        "Key": "OPENNLP-1168",
        "Summary": "Resolved concurrency issue in POS tagger.",
        "Type": "Improvement",
        "Status": "Closed",
        "Priority": "Major",
        "Resolution": "Fixed",
        "Affects Version/s": "1.8.4",
        "Fix Version/s": "1.8.4",
        "Component/s": "POS Tagger",
        "Assignee": null,
        "Reporter": "Niels Schuette",
        "Created": "15/Dec/17 12:08",
        "Updated": "20/Dec/17 12:34",
        "Resolved": "20/Dec/17 12:34",
        "Description": "We encountered a concurrency issue in the pos tagger module in the class DefaultPOSContextGenerator.\nThe issue is demonstrated in DefaultPOSContextGeneratorTest.java. The test \"multithreading()\" consistently fails on our system with the current code if the number of threads (NUMBER_OF_THREADS) is set to 10. If the number of threads is set to 1 (effectively disabling multithreading), the test consistently passes.\nWe resolved the issue by removing a field in DefaultPOSContextGenerator.java.",
        "Issue Links": [
            "https://github.com/apache/opennlp/pull/296"
        ]
    },
    "OPENNLP-1169": {
        "Key": "OPENNLP-1169",
        "Summary": "WordVectorTable should reference WVs by String",
        "Type": "Bug",
        "Status": "Closed",
        "Priority": "Major",
        "Resolution": "Fixed",
        "Affects Version/s": "None",
        "Fix Version/s": "1.8.4",
        "Component/s": "word vectors",
        "Assignee": "Tommaso Teofili",
        "Reporter": "Tommaso Teofili",
        "Created": "16/Dec/17 09:39",
        "Updated": "20/Dec/17 12:40",
        "Resolved": "19/Dec/17 18:40",
        "Description": "WordVectorsTable API retrieves WordVector via CharSequence , this is suboptimal as implementors could store such WVs via an hash table (e.g. MapWordVectorsTable) and the value of CharSequence#toString is not guaranteed to be the stable.\nAdditionally it's more common to have words as Strings rather than CharSequences, being that more consistent with other OpenNLP APIs (e.g. Tokenizer ).\nSo WordVectorsTable\u00a0should instead retrieve {{WordVector}}s using String.",
        "Issue Links": [
            "https://github.com/apache/opennlp/pull/297"
        ]
    },
    "OPENNLP-1170": {
        "Key": "OPENNLP-1170",
        "Summary": "The inclusion of letter's mechanical meaning in NLP processes.",
        "Type": "Improvement",
        "Status": "Reopened",
        "Priority": "Minor",
        "Resolution": "Unresolved",
        "Affects Version/s": "1.8.4",
        "Fix Version/s": "None",
        "Component/s": "Language Detector,                                            Machine Learning",
        "Assignee": null,
        "Reporter": "Jon O Labahn Jr",
        "Created": "18/Dec/17 23:19",
        "Updated": "11/Apr/18 17:14",
        "Resolved": null,
        "Description": "Using the LNSR (\"Lenser\") to Amplify Meaning\nThe understanding that letters, numbers and natual sounds have no underlying meaning is taken for granted by virtually everyone...\nWith Letter/Numeral/Sonic Revealer, the capacity to use letters, numbers and sounds-- with the defining \"functional keywords\"--can give greater depth to documents and written works of all sorts!\nImagine the increase in refinement, as the deep and fundemental mechanics of written communication, are part of your organization's potental...\nPossible Applications:\n1. Speed-Speak: Using single, or strings, of letters numbers and sounds in a meaningful way...  For instance, cutting the sentence, \"Maintain within guidelines.\", down to the letter, \"a\".\n2. Program Computers Using English:. (Currently under development.)  Mathmatizing letter and number mechanics to program devices in common English.\n3. A \"Working\" Word Definition; No Dictionary Required:\nUsing the 26 mechanical kewords, get an approximate functional definition-in English, Spanish, French-or any other language that uses the 26 letter alphabet...(Most useful for deepening one's understanding of expressions.)\nGoals:\nTo expand the use of the LNSR app and techniques; to increase efficiency, understanding and simplification in the above, and as yet undeveloped, applications.",
        "Issue Links": []
    },
    "OPENNLP-1171": {
        "Key": "OPENNLP-1171",
        "Summary": "some tests create temp files and directories but never delete them",
        "Type": "Bug",
        "Status": "Closed",
        "Priority": "Minor",
        "Resolution": "Fixed",
        "Affects Version/s": "1.8.3",
        "Fix Version/s": "1.8.4",
        "Component/s": "Build, Packaging and Test",
        "Assignee": "Koji Sekiguchi",
        "Reporter": "Koji Sekiguchi",
        "Created": "19/Dec/17 07:12",
        "Updated": "20/Dec/17 12:41",
        "Resolved": "20/Dec/17 01:43",
        "Description": "Some temporary files and directories that are created in some tests are never deleted and the number of temporary files/directories is increasing after running mvn clean test.",
        "Issue Links": [
            "https://github.com/apache/opennlp/pull/298"
        ]
    },
    "OPENNLP-1172": {
        "Key": "OPENNLP-1172",
        "Summary": "Add Annotator notes to BratAnnotation",
        "Type": "Improvement",
        "Status": "Closed",
        "Priority": "Minor",
        "Resolution": "Fixed",
        "Affects Version/s": "1.8.3",
        "Fix Version/s": "1.8.4",
        "Component/s": "Formats",
        "Assignee": "Daniel Russ",
        "Reporter": "Daniel Russ",
        "Created": "19/Dec/17 16:43",
        "Updated": "19/Dec/17 20:31",
        "Resolved": "19/Dec/17 20:31",
        "Description": "The Brat Annotator allows Annotators to add Notes to entites/relations.  The BratAnnotation class should reflect it.",
        "Issue Links": [
            "https://github.com/apache/opennlp/pull/299"
        ]
    },
    "OPENNLP-1173": {
        "Key": "OPENNLP-1173",
        "Summary": "Prepare the 1.8.4 release",
        "Type": "Task",
        "Status": "Closed",
        "Priority": "Major",
        "Resolution": "Done",
        "Affects Version/s": "None",
        "Fix Version/s": "1.8.4",
        "Component/s": "None",
        "Assignee": "Jeff Zemerick",
        "Reporter": "Jeff Zemerick",
        "Created": "20/Dec/17 20:32",
        "Updated": "26/Dec/17 14:28",
        "Resolved": "26/Dec/17 14:28",
        "Description": "This is a task to track the 1.8.4 release of OpenNLP.",
        "Issue Links": []
    },
    "OPENNLP-1174": {
        "Key": "OPENNLP-1174",
        "Summary": "remove classic format support in feature generator XML config when it is no longer needed",
        "Type": "Planned Work",
        "Status": "Closed",
        "Priority": "Minor",
        "Resolution": "Fixed",
        "Affects Version/s": "None",
        "Fix Version/s": "2.2.1",
        "Component/s": "None",
        "Assignee": "Richard Zowalla",
        "Reporter": "Koji Sekiguchi",
        "Created": "27/Dec/17 03:00",
        "Updated": "23/Jun/23 08:52",
        "Resolved": "23/Jun/23 08:52",
        "Description": "I put many \"TODO\" marks in the patch for OPENNLP-1154, e.g.:\n\n\r\n@Deprecated // TODO: just remove when back-compat is no longer needed\r\nstatic void register(Map<String, GeneratorFactory.XmlFeatureGeneratorFactory> factoryMap) {\r\n  factoryMap.put(\"generators\", new AggregatedFeatureGeneratorFactory());\r\n}\r\n\n\nBefore merging it, I'd like to create this ticket to get ticket number and add the number in the patch for OPENNLP-1154 so that we can easily find unnecessary codes when we want to remove in the future..",
        "Issue Links": []
    },
    "OPENNLP-1175": {
        "Key": "OPENNLP-1175",
        "Summary": "explain the new format of feature generator XML config",
        "Type": "Bug",
        "Status": "Closed",
        "Priority": "Minor",
        "Resolution": "Fixed",
        "Affects Version/s": "None",
        "Fix Version/s": "1.9.0",
        "Component/s": "Documentation",
        "Assignee": "Koji Sekiguchi",
        "Reporter": "Koji Sekiguchi",
        "Created": "29/Dec/17 08:04",
        "Updated": "21/Jun/18 11:54",
        "Resolved": "21/Jun/18 11:54",
        "Description": "Document should explain the new format of feature generator XML config, rather than classic format.",
        "Issue Links": [
            "https://github.com/apache/opennlp/pull/320"
        ]
    },
    "OPENNLP-1176": {
        "Key": "OPENNLP-1176",
        "Summary": "opennlp.tools.ngram.NGramGenerator.java",
        "Type": "Question",
        "Status": "Closed",
        "Priority": "Trivial",
        "Resolution": "Fixed",
        "Affects Version/s": "None",
        "Fix Version/s": "1.9.0",
        "Component/s": "None",
        "Assignee": null,
        "Reporter": "Prachi Prakash",
        "Created": "31/Dec/17 11:28",
        "Updated": "01/Nov/22 17:36",
        "Resolved": "01/Nov/22 17:35",
        "Description": "Hello All,\nI am new to opennlp and was looking to NGramGenerator.java where I found this piece of code which creates a list of n-grams from a list of words or characters. \nfor (int i = 0; i < input.size() - (n - 2); i++) {\n      final StringBuilder sb = new StringBuilder();\n      if ((i + n) <= input.size()) {\n        for (int x = i; x < (n + i); x++) \n{\r\n          sb.append(input.get(x));\r\n          sb.append(separator);\r\n        }\n        String gram = sb.toString();\n        gram = gram.substring(0, gram.lastIndexOf(separator));\n        outGrams.add(gram);\n      }\n    }\nwhich can be modified to \nfor (int i = 0; i < input.size() - (n - 1); i++) {\n      final StringBuilder sb = new StringBuilder();\n      for (int x = i; x < (n + i); x++) \n{\r\n        sb.append(input.get(x));\r\n        sb.append(separator);\r\n      }\n      String gram = sb.toString();\n      gram = gram.substring(0, gram.lastIndexOf(separator));\n      outGrams.add(gram);\n    }\nwhich will save some comparison can anyone please guide this is not being done.\nThanks,\nPrachi Prakash",
        "Issue Links": []
    },
    "OPENNLP-1177": {
        "Key": "OPENNLP-1177",
        "Summary": "Add way to get SnowballStemmer implementation by language code",
        "Type": "Task",
        "Status": "Open",
        "Priority": "Minor",
        "Resolution": "Unresolved",
        "Affects Version/s": "None",
        "Fix Version/s": "None",
        "Component/s": "Stemmer",
        "Assignee": "Jeff Zemerick",
        "Reporter": "Jeff Zemerick",
        "Created": "01/Jan/18 20:18",
        "Updated": "08/Jan/18 13:09",
        "Resolved": null,
        "Description": "The only way to get a Snowball stemmer implementation is using the ALGORITHM enum. There is no easy way to get a Snowball stemmer implementation using a language code.",
        "Issue Links": [
            "https://github.com/apache/opennlp/pull/301"
        ]
    },
    "OPENNLP-1178": {
        "Key": "OPENNLP-1178",
        "Summary": "Add language code constants",
        "Type": "Task",
        "Status": "Closed",
        "Priority": "Minor",
        "Resolution": "Won't Do",
        "Affects Version/s": "None",
        "Fix Version/s": "None",
        "Component/s": "None",
        "Assignee": "Jeff Zemerick",
        "Reporter": "Jeff Zemerick",
        "Created": "01/Jan/18 20:34",
        "Updated": "24/May/18 18:19",
        "Resolved": "24/May/18 18:19",
        "Description": "There are many places in the code where languages are referenced by hardcoded strings such as \"eng\". Add a class that contains constants for the language codes and replace hardcoded string with the constant values. Use ISO 639-2 language codes.",
        "Issue Links": [
            "https://github.com/apache/opennlp/pull/303"
        ]
    },
    "OPENNLP-1179": {
        "Key": "OPENNLP-1179",
        "Summary": "BRAT Annotator service Fails to start",
        "Type": "Bug",
        "Status": "Closed",
        "Priority": "Major",
        "Resolution": "Fixed",
        "Affects Version/s": "1.8.4",
        "Fix Version/s": "1.9.0",
        "Component/s": "Applications",
        "Assignee": null,
        "Reporter": "Daniel Russ",
        "Created": "02/Jan/18 19:03",
        "Updated": "05/Jan/18 16:27",
        "Resolved": "05/Jan/18 16:26",
        "Description": "me@machine$ brat-annotation-service\nError: Could not find or load main class opennlp.bratann.NameFinderAnnService\ncaused by:\n/usr/bin/java -Xmx1024m -cp 'lib/*' opennlp.bratann.NameFinderAnnService\nshould be:\nVACMD -Xmx1024m -cp $(echo $OPENNLP_HOME/lib/*.jar | tr ' ' ':') opennlp.bratann.NameFinderAnnService $@\nas is found in the opennlp script.  I thought this was fixed already, but clearly was not.",
        "Issue Links": [
            "https://github.com/apache/opennlp/pull/302"
        ]
    },
    "OPENNLP-1180": {
        "Key": "OPENNLP-1180",
        "Summary": "Use String[] instead of StringList in LanguageModel API",
        "Type": "Task",
        "Status": "Closed",
        "Priority": "Major",
        "Resolution": "Fixed",
        "Affects Version/s": "None",
        "Fix Version/s": "1.9.0",
        "Component/s": "language model",
        "Assignee": "Tommaso Teofili",
        "Reporter": "Tommaso Teofili",
        "Created": "08/Jan/18 17:16",
        "Updated": "11/May/18 01:18",
        "Resolved": "09/Jan/18 14:32",
        "Description": "Current LanguageModel\u00a0API uses StringList, however that's less convenient for easy consumption as one needs to look into StringList and adapt its code to convert arrays or collections of Strings into StringList. Additionally this requires more objects to be created that will be soon discarded by garbage collection e.g. the input StringList for LM#calculateProbability and LM#predictNextTokens.\nI propose to deprecate those methods and add new ones with exactly the same signature but using String[] (or String...) instead.\nInternally StringLists can be kept or not, but that would be an implementation detail and allows to move away from using them more easily.",
        "Issue Links": [
            "https://github.com/apache/opennlp/pull/304"
        ]
    },
    "OPENNLP-1181": {
        "Key": "OPENNLP-1181",
        "Summary": "Custom NER model identifying unwanted entities that never taught.",
        "Type": "Bug",
        "Status": "Closed",
        "Priority": "Minor",
        "Resolution": "Not A Problem",
        "Affects Version/s": "1.8.0",
        "Fix Version/s": "None",
        "Component/s": "None",
        "Assignee": null,
        "Reporter": "Mubarak K",
        "Created": "10/Jan/18 07:22",
        "Updated": "03/Apr/18 22:18",
        "Resolved": "03/Apr/18 22:18",
        "Description": "I am new to openNLP and I trained a custom NER model with more than a million sentences using the training API of OpenNlp for identifying the skill that I taught.\nDuring the testing I have found that the model identifying unwanted entities that never taught. \nI want to identify only the words that I taught.\nHow can improve my custom model for above mentioned result?",
        "Issue Links": []
    },
    "OPENNLP-1182": {
        "Key": "OPENNLP-1182",
        "Summary": "Improve error handling in LanguageDetectorConverterTool",
        "Type": "Bug",
        "Status": "Closed",
        "Priority": "Minor",
        "Resolution": "Fixed",
        "Affects Version/s": "1.8.4",
        "Fix Version/s": "2.1.1",
        "Component/s": "Language Detector",
        "Assignee": "Atita Arora",
        "Reporter": "Steven Rowe",
        "Created": "11/Jan/18 20:58",
        "Updated": "03/Jan/23 14:56",
        "Resolved": "03/Jan/23 14:55",
        "Description": "Contrary to the docs (see below), LanguageDetectorConverterTool doesn't actually do anything at all; the class is empty.\n\nThe following sequence of commands shows how to convert the Leipzig Corpora collection at folder leipzig-train/ to the default Language Detector format, by creating groups of 5 sentences as documents and limiting to 10000 documents per language. Them, it shuffles the result and select the first 100000 lines as train corpus and the last 20000 as evaluation corpus:\n\n\t\t\t\t\t\r\n$ bin/opennlp LanguageDetectorConverter leipzig -sentencesDir leipzig-train/ -sentencesPerSample 5 -samplesPerLanguage 10000 > leipzig.txt\r\n$ perl -MList::Util=shuffle -e 'print shuffle(<STDIN>);' < leipzig.txt > leipzig_shuf.txt\r\n$ head -100000 < leipzig_shuf.txt > leipzig.train\r\n$ tail -20000 < leipzig_shuf.txt > leipzig.eval",
        "Issue Links": []
    },
    "OPENNLP-1183": {
        "Key": "OPENNLP-1183",
        "Summary": "Better language model support",
        "Type": "Improvement",
        "Status": "Open",
        "Priority": "Major",
        "Resolution": "Unresolved",
        "Affects Version/s": "None",
        "Fix Version/s": "None",
        "Component/s": "language model",
        "Assignee": null,
        "Reporter": "Tommaso Teofili",
        "Created": "27/Jan/18 08:04",
        "Updated": "09/Sep/19 13:35",
        "Resolved": null,
        "Description": "As per\u00a0ONIP-1\u00a0it would be nice to provide better language modelling support. This means more compact models, faster prediction, more accurate estimations.",
        "Issue Links": []
    },
    "OPENNLP-1184": {
        "Key": "OPENNLP-1184",
        "Summary": "Can't find lemmatizer models",
        "Type": "Question",
        "Status": "Closed",
        "Priority": "Minor",
        "Resolution": "Resolved",
        "Affects Version/s": "None",
        "Fix Version/s": "None",
        "Component/s": "Lemmatizer",
        "Assignee": null,
        "Reporter": "Daniel Khashabi",
        "Created": "29/Jan/18 05:37",
        "Updated": "03/Apr/18 22:15",
        "Resolved": "03/Apr/18 22:15",
        "Description": "Hey there,\u00a0\nThere are some explanations about the lemmatizer components in the OpenNLP.\nThere are some instructions here:\u00a0\nhttps://opennlp.apache.org/docs/1.7.0/manual/opennlp.html#tools.lemmatizer.tagging.api\nWhich apparently use a model named \"en-lemmatizer.bin\".\u00a0\nHowever, in the list of models, there is no such model:\u00a0\n\u00a0\nhttp://opennlp.sourceforge.net/models-1.5/",
        "Issue Links": []
    },
    "OPENNLP-1185": {
        "Key": "OPENNLP-1185",
        "Summary": "Tokenizers should be able to output a new line token",
        "Type": "Improvement",
        "Status": "Closed",
        "Priority": "Major",
        "Resolution": "Fixed",
        "Affects Version/s": "None",
        "Fix Version/s": "2.0.0",
        "Component/s": "Tokenizer",
        "Assignee": null,
        "Reporter": "J\u00f6rn Kottmann",
        "Created": "09/Feb/18 16:32",
        "Updated": "07/Jun/22 11:57",
        "Resolved": "07/Jun/22 11:57",
        "Description": "Some use cases need the tokenizers to also output new line tokens. This is needed e.g. by cTakes to process clinical notes, or by the name finder to process list of names where each name is written in one line. Also it helps the name finder to process news articles.\nTo fix this issue add an option to all three tokenizers to emit new line tokens.",
        "Issue Links": [
            "https://github.com/apache/opennlp/pull/337"
        ]
    },
    "OPENNLP-1186": {
        "Key": "OPENNLP-1186",
        "Summary": "OPENNLP-108 Write the OpenNLP White Paper",
        "Type": "Task",
        "Status": "Closed",
        "Priority": "Major",
        "Resolution": "Duplicate",
        "Affects Version/s": "None",
        "Fix Version/s": "None",
        "Component/s": "Applications",
        "Assignee": null,
        "Reporter": "Anjali Gugle",
        "Created": "16/Feb/18 18:02",
        "Updated": "24/Mar/18 21:57",
        "Resolved": "22/Mar/18 16:00",
        "Description": "Write the OpenNLP White Paper",
        "Issue Links": []
    },
    "OPENNLP-1187": {
        "Key": "OPENNLP-1187",
        "Summary": "Issue in finding accuracy of model",
        "Type": "Bug",
        "Status": "Closed",
        "Priority": "Major",
        "Resolution": "Fixed",
        "Affects Version/s": "1.8.4",
        "Fix Version/s": "2.1.1",
        "Component/s": "Doccat,                                            Machine Learning",
        "Assignee": "Martin Wiesner",
        "Reporter": "Aman Garg",
        "Created": "26/Feb/18 18:44",
        "Updated": "28/Jan/23 15:00",
        "Resolved": "15/Dec/22 07:10",
        "Description": "the trainingStats function in NaiveBayesTrainer class is not working properly and display wrong result.\nIn\u00a0findParameters(), at line 154 i.e.\u00a0\nEvalParameters evalParams = new EvalParameters(params, numOutcomes);\nshould be replaced by following block:\n\u00a0\ndouble[] outcomeTotals = new double[outcomeLabels.length];\n\u00a0 \u00a0 for (int i = 0; i < params.length; ++i) {\n\u00a0 \u00a0 \u00a0 Context context = params[i];\n\u00a0 \u00a0 \u00a0 for (int j = 0; j < context.getOutcomes().length; ++j) \n{\r\n\r\n\u00a0 \u00a0 \u00a0 \u00a0 int outcome = context.getOutcomes()[j];\r\n\r\n\u00a0 \u00a0 \u00a0 \u00a0 double count = context.getParameters()[j];\r\n\r\n\u00a0 \u00a0 \u00a0 \u00a0 outcomeTotals[outcome] += count;\r\n\r\n\u00a0 \u00a0 \u00a0 }\n\n\u00a0 \u00a0 }\nevalParams = new NaiveBayesEvalParameters(params,\noutcomeLabels.length, outcomeTotals, predLabels.length);",
        "Issue Links": []
    },
    "OPENNLP-1188": {
        "Key": "OPENNLP-1188",
        "Summary": "Update Penn Treebank URL",
        "Type": "Task",
        "Status": "Closed",
        "Priority": "Minor",
        "Resolution": "Fixed",
        "Affects Version/s": "None",
        "Fix Version/s": "1.9.0",
        "Component/s": "Documentation",
        "Assignee": "Jeff Zemerick",
        "Reporter": "Jeff Zemerick",
        "Created": "09/Mar/18 14:46",
        "Updated": "21/Jun/18 13:31",
        "Resolved": "21/Jun/18 13:31",
        "Description": "As reported on the users mailing list, the URL for the PennTree Bank needs updated to be https://www.ling.upenn.edu/courses/Fall_2003/ling001/penn_treebank_pos.html\u00a0(from http://www.cis.upenn.edu/~treebank/)\u00a0on the page\u00a0http://opennlp.apache.org/docs/1.8.4/manual/opennlp.html#tools.postagger.tagging.cmdline.",
        "Issue Links": [
            "https://github.com/apache/opennlp/pull/306"
        ]
    },
    "OPENNLP-1189": {
        "Key": "OPENNLP-1189",
        "Summary": "Token model creation fails without at least one <SPLIT> tag",
        "Type": "Bug",
        "Status": "Closed",
        "Priority": "Minor",
        "Resolution": "Fixed",
        "Affects Version/s": "1.8.4",
        "Fix Version/s": "1.9.0",
        "Component/s": "Tokenizer",
        "Assignee": "Jeff Zemerick",
        "Reporter": "Jeff Zemerick",
        "Created": "17/Mar/18 17:42",
        "Updated": "18/May/18 10:37",
        "Resolved": "17/Mar/18 19:16",
        "Description": "The tokenizer training documentation for 1.8.4 states that \"Tokens are either separated by a whitespace or by a special <SPLIT> tag.\" However, it appears that training files if the training data does not contain at least one <SPLIT> tag. To reproduce:\nTraining on the sample data works fine:\nPierre Vinken<SPLIT>, 61 years old<SPLIT>, will join the board as a nonexecutive director Nov. 29<SPLIT>.\n Mr. Vinken is chairman of Elsevier N.V.<SPLIT>, the Dutch publishing group<SPLIT>.\n Rudolph Agnew<SPLIT>, 55 years old and former chairman of Consolidated Gold Fields PLC<SPLIT>,\n was named a nonexecutive director of this British industrial conglomerate<SPLIT>.\nReplacing the <SPLIT> tags with whitespace causes the training to fail with InsufficientTrainingDataException:\nPierre Vinken , 61 years old , will join the board as a nonexecutive director Nov. 29 .\n Mr. Vinken is chairman of Elsevier N.V. , the Dutch publishing group .\n Rudolph Agnew , 55 years old and former chairman of Consolidated Gold Fields PLC ,\n was named a nonexecutive director of this British industrial conglomerate .\nModifying the training data to contain a single <SPLIT> tag\u00a0allows model training to complete successfully:\nPierre Vinken<SPLIT>, 61 years old , will join the board as a nonexecutive director Nov. 29 .\n Mr. Vinken is chairman of Elsevier N.V. , the Dutch publishing group .\n Rudolph Agnew , 55 years old and former chairman of Consolidated Gold Fields PLC ,\n was named a nonexecutive director of this British industrial conglomerate .",
        "Issue Links": [
            "https://opennlp.apache.org/docs/1.8.4/manual/opennlp.html#tools.tokenizer.training",
            "https://github.com/apache/opennlp/pull/307"
        ]
    },
    "OPENNLP-1190": {
        "Key": "OPENNLP-1190",
        "Summary": "CONLL02 format",
        "Type": "Bug",
        "Status": "Open",
        "Priority": "Major",
        "Resolution": "Unresolved",
        "Affects Version/s": "tools-1.5.3",
        "Fix Version/s": "None",
        "Component/s": "Formats",
        "Assignee": null,
        "Reporter": "Luca",
        "Created": "26/Mar/18 10:06",
        "Updated": "03/Apr/18 22:06",
        "Resolved": null,
        "Description": "According to the documentation, the following should work\n\u00a0bin/opennlp TokenNameFinderConverter conll02 -data esp.train -lang es -types per > es_corpus_train_persons.txt\nHowever currently\u00a0it delivers error message since\u00a0 it expects 3 columns instead of 2 that are in the dataset.\nThis is a bug, introduced at line 130 of\u00a0 \u00a0opennlp.tools.formats.Conll02NameSampleStream.java where a length of 3 is imposed.",
        "Issue Links": []
    },
    "OPENNLP-1191": {
        "Key": "OPENNLP-1191",
        "Summary": "achieve compatibility with stanford 2 column input",
        "Type": "New Feature",
        "Status": "Open",
        "Priority": "Major",
        "Resolution": "Unresolved",
        "Affects Version/s": "1.8.4",
        "Fix Version/s": "None",
        "Component/s": "Formats",
        "Assignee": null,
        "Reporter": "Luca",
        "Created": "26/Mar/18 10:13",
        "Updated": "03/Apr/18 22:07",
        "Resolved": null,
        "Description": "Currently, Stanford NER accepts as input a 2 column (e.g. CONLL02) formatted data.\nIt would be great if one could use the same dataset also with OPENNLP in order then to be able to compare the quality of the results.\nCurrently, the CONL002 formatter in opennlp is broken and furthermore it only supports the spanish and dutch languages...",
        "Issue Links": []
    },
    "OPENNLP-1192": {
        "Key": "OPENNLP-1192",
        "Summary": "Remove MD5 hashes from Release process",
        "Type": "New Feature",
        "Status": "Closed",
        "Priority": "Major",
        "Resolution": "Fixed",
        "Affects Version/s": "1.8.4",
        "Fix Version/s": "1.9.0",
        "Component/s": "Build, Packaging and Test",
        "Assignee": "Suneel Marthi",
        "Reporter": "Suneel Marthi",
        "Created": "03/Apr/18 03:00",
        "Updated": "03/Apr/18 13:04",
        "Resolved": "03/Apr/18 13:03",
        "Description": "Per http://www.apache.org/dev/release-publishing.html\u00a0MD5 should not be supported.",
        "Issue Links": [
            "https://github.com/apache/opennlp/pull/309"
        ]
    },
    "OPENNLP-1193": {
        "Key": "OPENNLP-1193",
        "Summary": "Brat format support fails on multi fragment annotations",
        "Type": "Bug",
        "Status": "Closed",
        "Priority": "Major",
        "Resolution": "Fixed",
        "Affects Version/s": "1.8.4",
        "Fix Version/s": "1.9.0",
        "Component/s": "Formats,                                            Name Finder",
        "Assignee": "J\u00f6rn Kottmann",
        "Reporter": "J\u00f6rn Kottmann",
        "Created": "12/Apr/18 13:27",
        "Updated": "22/May/18 11:57",
        "Resolved": "22/May/18 11:57",
        "Description": "The brat format support assumes that annotation with multiple fragments are always appear next to each other, this assumption is false (and is only true if there is a line break). If a single annotation is composed of multiple fragments they should be outputted as multiple name spans as well.",
        "Issue Links": [
            "https://github.com/apache/opennlp/pull/311"
        ]
    },
    "OPENNLP-1194": {
        "Key": "OPENNLP-1194",
        "Summary": "Brat Document Parser should support name type filters",
        "Type": "Improvement",
        "Status": "Closed",
        "Priority": "Major",
        "Resolution": "Fixed",
        "Affects Version/s": "None",
        "Fix Version/s": "1.9.0",
        "Component/s": "Formats",
        "Assignee": "William Colen",
        "Reporter": "William Colen",
        "Created": "20/Apr/18 17:06",
        "Updated": "21/Jun/18 11:55",
        "Resolved": "21/Jun/18 11:55",
        "Description": "Brat Document Parser fails if there is a span overlap. Sometimes we are interested in only some\u00a0types. In that case we could\u00a0ignore the overlapping\u00a0that are not of our interest.",
        "Issue Links": [
            "https://github.com/apache/opennlp/pull/312"
        ]
    },
    "OPENNLP-1195": {
        "Key": "OPENNLP-1195",
        "Summary": "use ArrayMath.argmax() rather than private maxIndex() in PerceptronTrainer and NaiveBayesTrainer",
        "Type": "Improvement",
        "Status": "Resolved",
        "Priority": "Trivial",
        "Resolution": "Fixed",
        "Affects Version/s": "1.8.4",
        "Fix Version/s": "None",
        "Component/s": "None",
        "Assignee": "Koji Sekiguchi",
        "Reporter": "Koji Sekiguchi",
        "Created": "14/May/18 11:01",
        "Updated": "15/May/18 10:15",
        "Resolved": "15/May/18 10:15",
        "Description": "PerceptronTrainer and NaiveBayesTrainer have their own private maxIndex() method and they are identical.\nWhy don't we move it to their parent class?",
        "Issue Links": [
            "https://github.com/apache/opennlp/pull/313",
            "https://github.com/apache/opennlp/pull/315"
        ]
    },
    "OPENNLP-1196": {
        "Key": "OPENNLP-1196",
        "Summary": "move ArrayMath to a more general package",
        "Type": "Improvement",
        "Status": "Resolved",
        "Priority": "Minor",
        "Resolution": "Fixed",
        "Affects Version/s": "1.8.4",
        "Fix Version/s": "None",
        "Component/s": "Machine Learning",
        "Assignee": "Koji Sekiguchi",
        "Reporter": "Koji Sekiguchi",
        "Created": "15/May/18 03:47",
        "Updated": "15/May/18 09:02",
        "Resolved": "15/May/18 09:02",
        "Description": "In OPENNLP-1195, joern mentioned this.\n\nThere are more usages of argmax in the OpenNLP source code.\nI propose we create one common method and then try to only use that one.\nWe could move the ArrayMath to a more general package and place a common method there, or keep the existing one\nI want to solve this before OPENNLP-1195.",
        "Issue Links": [
            "https://github.com/apache/opennlp/pull/314"
        ]
    },
    "OPENNLP-1197": {
        "Key": "OPENNLP-1197",
        "Summary": "FeatureGeneratorUtil.tokenFeature() always returns \"lc\" for Japanese words",
        "Type": "Bug",
        "Status": "Resolved",
        "Priority": "Major",
        "Resolution": "Fixed",
        "Affects Version/s": "1.8.4",
        "Fix Version/s": "1.9.0",
        "Component/s": "Machine Learning",
        "Assignee": "Koji Sekiguchi",
        "Reporter": "Koji Sekiguchi",
        "Created": "16/May/18 05:52",
        "Updated": "27/Jun/18 22:57",
        "Resolved": "27/Jun/18 22:57",
        "Description": "FeatureGeneratorUtil.tokenFeature() always recognizes Japanese words as \"lc\" (lower case). It looks a bug to me because they're not lower case letters, but other than that, it seems that FeatureGeneratorUtil.tokenFeature() takes care only Europe/American languages.\nFor example, in Japanese NER problem, typical token classes are as follows:\n\nDIGIT\nHIRA : \u3042, \u3044, \u3046, \u3048, \u304a etc.\nKATA : \u30a2, \u30a4, \u30a6, \u30a8, \u30aa etc.\nALPHA : we don't need to distinguish lower/upper case\nOTHER\n\nI think it's possible that we get FeatureGeneratorUtil.tokenFeature() to have additional token classes I mentioned above, but later on, someone who comes from Asia and may claim similar thing.\nI'd like to make FeatureGeneratorUtil plugable, but I don't have any idea now.",
        "Issue Links": [
            "https://github.com/apache/opennlp/pull/316",
            "https://github.com/apache/opennlp/pull/322"
        ]
    },
    "OPENNLP-1198": {
        "Key": "OPENNLP-1198",
        "Summary": "add more tests to NGramGeneratorTest",
        "Type": "Test",
        "Status": "Resolved",
        "Priority": "Trivial",
        "Resolution": "Fixed",
        "Affects Version/s": "1.8.4",
        "Fix Version/s": "None",
        "Component/s": "Build, Packaging and Test",
        "Assignee": "Koji Sekiguchi",
        "Reporter": "Koji Sekiguchi",
        "Created": "21/May/18 03:39",
        "Updated": "22/May/18 10:08",
        "Resolved": "22/May/18 09:07",
        "Description": "At present, NGramGeneratorTest has only 2-gram test against the example sentence \"This is a sentence\". I think we'd better to have 1-gram, 3-gram and 4-gram test cases for this example sentence.\nIn addition, it checks the return values by doing like this:\n\n\r\n    Assert.assertEquals(3,  ngrams.size());\r\n    Assert.assertTrue(ngrams.contains(\"This-is\"));\r\n    Assert.assertTrue(ngrams.contains(\"is-a\"));\r\n    Assert.assertTrue(ngrams.contains(\"a-sentence\"));\r\n\n\nbut it cannot check the sequence. I think we should check it like this, instead:\n\n\r\n    Assert.assertEquals(3,  ngrams.size());\r\n    Assert.assertEquals(\"This-is\", ngrams.get(0));\r\n    Assert.assertEquals(\"is-a\", ngrams.get(1));\r\n    Assert.assertEquals(\"a-sentence\", ngrams.get(2));",
        "Issue Links": [
            "https://github.com/apache/opennlp/pull/319"
        ]
    },
    "OPENNLP-1199": {
        "Key": "OPENNLP-1199",
        "Summary": "Correct Loop Bounds for NgramGenerator.generate function",
        "Type": "Improvement",
        "Status": "Resolved",
        "Priority": "Minor",
        "Resolution": "Fixed",
        "Affects Version/s": "None",
        "Fix Version/s": "None",
        "Component/s": "None",
        "Assignee": "J\u00f6rn Kottmann",
        "Reporter": "Prachi Prakash",
        "Created": "21/May/18 18:12",
        "Updated": "23/May/18 00:27",
        "Resolved": "23/May/18 00:27",
        "Description": "A small enhancement to the loop condition of NGramGenerator.generate function which saves a subsequent if condition check. I have also attached the PR link\nPull Request",
        "Issue Links": [
            "https://github.com/apache/opennlp/pull/318"
        ]
    },
    "OPENNLP-1200": {
        "Key": "OPENNLP-1200",
        "Summary": "Unify code to sum up input context features",
        "Type": "Improvement",
        "Status": "Closed",
        "Priority": "Trivial",
        "Resolution": "Fixed",
        "Affects Version/s": "None",
        "Fix Version/s": "1.9.0",
        "Component/s": "Machine Learning",
        "Assignee": "J\u00f6rn Kottmann",
        "Reporter": "J\u00f6rn Kottmann",
        "Created": "22/May/18 11:50",
        "Updated": "22/May/18 11:57",
        "Resolved": "22/May/18 11:57",
        "Description": "The code to sum up input features in the mal package is duplicated and should be unified in a util method.",
        "Issue Links": []
    },
    "OPENNLP-1201": {
        "Key": "OPENNLP-1201",
        "Summary": "add bailout way for certain languages in order to use POS features",
        "Type": "Improvement",
        "Status": "Resolved",
        "Priority": "Major",
        "Resolution": "Fixed",
        "Affects Version/s": "1.8.4",
        "Fix Version/s": "None",
        "Component/s": "Command Line Interface,                                            Formats",
        "Assignee": "Koji Sekiguchi",
        "Reporter": "Koji Sekiguchi",
        "Created": "04/Jun/18 12:57",
        "Updated": "04/Dec/19 00:31",
        "Resolved": "25/Sep/18 06:43",
        "Description": "As OpenNLP tools depend on the fact that text being processed needs to be tokenized in advance (in other words, words in the text are separated each other by space), it is difficult for uses who use certain languages (e.g. CJK) to use POS (Part-of-Speech) features.\nTo simplify the explanation, consider using NameFinder for Japanese text. In NameFinder tools (Train, Eval, Recognize), they require that users should provide Japanese text which has already been tokenized, but once we tokenize Japanese text, it loses POS information. (I think Chinese language has same problem)\nLet me describe this problem for western language users  (English, French, Italian, etc.) without using Japanese letters. I\u2019ll try to use English alphabet, instead.\nSuppose you have a sentence text \u201cisentthemachine\u201d which you want to give NameFinder, you use morphological analyzer in order to tokenize the sentence. There are two possible sequence of tokens:\n\ni (PPSS) / sent (VBD) / the (AT) / machine (NP)\n\n\ni (PPSS) / sent (VBD) / them (PPO) / a (AT) / chine (NP)\n\nAs you noticed, morphological analyzer not only tokenizes the sentence, but also tags POS tag to each token. Same thing takes place in Japanese language (and Chinese language, I think).\nHowever, in OpenNLP feature generator API, it accepts sequence of tokens thru API i.e. `String[] tokens`, I cannot produce POS feature in the feature generator.\nTo solve this problem (and to invite many users to our community), I\u2019d like to suggest that OpenNLP tools allow users to add optional information to each tokenized word.\nFor example, one can give the following text when using NameFinder tools.\n\n\r\n$ cat en-ner.train\r\nI/PPSS sent/VBD the/AT machine/NP\r\n\n\nWhen using such text, they must inform the tool that the token has POS tag in the text by using a certain option e.g. -postag\n\n\r\n$ opennlp TokenNameFinderTrainer -data en-ner.train -model en-ner.bin -postag\r\n\n\nWe can maintain the backward compatibility to set -postag false by default and in this case, existing feature generators work exactly the same as before. If a user set -postag option in the command line, the existing feature generators eliminate \u201c/POS\u201d part of token \u201cword/POS\u201d in the text so that they can produce same features as before.\nI\u2019d like to add a simple feature generator which generates only \u201cPOS\u201d part of token \u201cword/POS\u201d in the text, in addition to managing -postag option. This simple feature generator allows Japanese/Chinese users to produce precise POS features.\nI\u2019d like to focus on NameFinder in this ticket (Let me add this option to other tools (chunker, classifier, etc.) in another ticket, if needed).",
        "Issue Links": [
            "https://github.com/apache/opennlp-addons/pull/1",
            "https://github.com/apache/opennlp-addons/pull/1",
            "https://github.com/apache/opennlp-addons/pull/2",
            "https://github.com/apache/opennlp-addons/pull/2",
            "https://github.com/apache/opennlp/pull/334"
        ]
    },
    "OPENNLP-1202": {
        "Key": "OPENNLP-1202",
        "Summary": "Word tokenization",
        "Type": "Bug",
        "Status": "Resolved",
        "Priority": "Major",
        "Resolution": "Feedback Received",
        "Affects Version/s": "None",
        "Fix Version/s": "None",
        "Component/s": "language model",
        "Assignee": null,
        "Reporter": "Dippy Aggarwal",
        "Created": "12/Jun/18 00:30",
        "Updated": "16/Dec/22 12:30",
        "Resolved": "16/Dec/22 12:30",
        "Description": "Came across an issue\u00a0for identifying words in a sentence. For words such as can't, the tokenization using openNLP yields two words: \"ca\" and \"n't\"\nAs an example (captured in the screenshot), see the tokenization for the string\nWhen heard the Xenogears soundtrack, so can't really describe.\nNote the words marked by ID's 9 and 10 in the openNLP-output.png file.\u00a0\nNot sure if I am missing any parameters that would produce the correct result?\u00a0\nWould appreciate any ideas/community's attention to this issue. Thanks.",
        "Issue Links": []
    },
    "OPENNLP-1203": {
        "Key": "OPENNLP-1203",
        "Summary": "Prepare 1.9.0 release",
        "Type": "Task",
        "Status": "Closed",
        "Priority": "Major",
        "Resolution": "Done",
        "Affects Version/s": "None",
        "Fix Version/s": "None",
        "Component/s": "None",
        "Assignee": "Jeff Zemerick",
        "Reporter": "Jeff Zemerick",
        "Created": "21/Jun/18 13:40",
        "Updated": "05/Jul/18 22:47",
        "Resolved": "03/Jul/18 12:36",
        "Description": "Prepare the 1.9.0 release.",
        "Issue Links": [
            "https://github.com/apache/opennlp-site/pull/51",
            "https://github.com/apache/opennlp-site/pull/52",
            "https://github.com/apache/opennlp-site/pull/53",
            "https://github.com/apache/opennlp-site/pull/54"
        ]
    },
    "OPENNLP-1204": {
        "Key": "OPENNLP-1204",
        "Summary": "Consolidate release guides",
        "Type": "Task",
        "Status": "Closed",
        "Priority": "Minor",
        "Resolution": "Done",
        "Affects Version/s": "None",
        "Fix Version/s": "None",
        "Component/s": "Documentation",
        "Assignee": "Jeff Zemerick",
        "Reporter": "Jeff Zemerick",
        "Created": "22/Jun/18 14:53",
        "Updated": "04/Jul/18 14:11",
        "Resolved": "04/Jul/18 14:10",
        "Description": "Consolidate the two release guides into a single one on the website.\n\nhttps://cwiki.apache.org/confluence/display/OPENNLP/Release+Process\nhttps://opennlp.apache.org/release.html",
        "Issue Links": [
            "https://github.com/apache/opennlp-site/pull/49",
            "https://github.com/apache/opennlp-site/pull/50"
        ]
    },
    "OPENNLP-1205": {
        "Key": "OPENNLP-1205",
        "Summary": "use new XML format of feature generator in OntoNotes4NameFinderEval",
        "Type": "Task",
        "Status": "Closed",
        "Priority": "Trivial",
        "Resolution": "Invalid",
        "Affects Version/s": "1.8.4",
        "Fix Version/s": "None",
        "Component/s": "Build, Packaging and Test",
        "Assignee": "Koji Sekiguchi",
        "Reporter": "Koji Sekiguchi",
        "Created": "28/Jun/18 02:13",
        "Updated": "28/Jun/18 02:17",
        "Resolved": "28/Jun/18 02:17",
        "Description": null,
        "Issue Links": []
    },
    "OPENNLP-1206": {
        "Key": "OPENNLP-1206",
        "Summary": "add TrigramNameFeatureGeneratorFactory",
        "Type": "Task",
        "Status": "Resolved",
        "Priority": "Minor",
        "Resolution": "Fixed",
        "Affects Version/s": "1.8.4",
        "Fix Version/s": "1.9.1",
        "Component/s": "Machine Learning",
        "Assignee": "Koji Sekiguchi",
        "Reporter": "Koji Sekiguchi",
        "Created": "01/Jul/18 03:10",
        "Updated": "11/Aug/18 10:32",
        "Resolved": "11/Jul/18 05:17",
        "Description": "Surprisingly, it's missing.  I noticed it when I tried to use it in my feature generator XML.",
        "Issue Links": [
            "https://github.com/apache/opennlp/pull/324"
        ]
    },
    "OPENNLP-1207": {
        "Key": "OPENNLP-1207",
        "Summary": "Broken MD5 links on download page",
        "Type": "Bug",
        "Status": "Closed",
        "Priority": "Major",
        "Resolution": "Done",
        "Affects Version/s": "None",
        "Fix Version/s": "None",
        "Component/s": "None",
        "Assignee": "Jeff Zemerick",
        "Reporter": "Sebb",
        "Created": "06/Jul/18 13:10",
        "Updated": "10/Jul/18 23:39",
        "Resolved": "10/Jul/18 23:39",
        "Description": "References to MD5 on the download page should be removed as there are no such hashes for the current release (nor should there be as MD5 is deprecated)",
        "Issue Links": [
            "https://github.com/apache/opennlp-site/pull/55"
        ]
    },
    "OPENNLP-1208": {
        "Key": "OPENNLP-1208",
        "Summary": "Please delete old releases from mirroring system",
        "Type": "Bug",
        "Status": "Closed",
        "Priority": "Major",
        "Resolution": "Done",
        "Affects Version/s": "None",
        "Fix Version/s": "None",
        "Component/s": "None",
        "Assignee": "Jeff Zemerick",
        "Reporter": "Sebb",
        "Created": "06/Jul/18 13:55",
        "Updated": "10/Jul/18 23:39",
        "Resolved": "06/Jul/18 15:08",
        "Description": "To reduce the load on the ASF mirrors, projects are required to delete old releases [1]\nPlease can you remove all non-current releases?\nIt's unfair to expect the 3rd party mirrors to carry old releases.\nIt looks like only 1.9.0 is still supported so all other versions should please be removed from the mirrors. \nUse SVN to delete the files from https://www.apache.org/dist/opennlp/, e.g.\n$ svn rm -m\"Release has been superseded\" https://www.apache.org/dist/opennlp/opennlp-1.8.0/\nThanks!\n[1] http://www.apache.org/dev/release.html#when-to-archive",
        "Issue Links": [
            "https://github.com/apache/opennlp-site/pull/56"
        ]
    },
    "OPENNLP-1209": {
        "Key": "OPENNLP-1209",
        "Summary": "Is there documentation for feature gneration?",
        "Type": "Question",
        "Status": "Closed",
        "Priority": "Major",
        "Resolution": "Not A Problem",
        "Affects Version/s": "None",
        "Fix Version/s": "1.9.1",
        "Component/s": "Documentation",
        "Assignee": null,
        "Reporter": "Joseph",
        "Created": "20/Jul/18 13:51",
        "Updated": "31/Dec/18 18:15",
        "Resolved": "31/Dec/18 18:14",
        "Description": "I could not find any documentation about how to use the feature generation while training a model for the name finder.\u00a0 Nor could I find any information about how to train a Maxent or Perceptron model, or how to configure these algorithms.\u00a0\nI am aware of the basic documentation here http://opennlp.apache.org/docs/1.9.0/manual/opennlp.html\u00a0 but it does not help beyond getting started.\nseems other people cannot find any as well\nhttps://stackoverflow.com/questions/11989633/custom-feature-generation-in-opennlp-namefinder-api\nSo basically you have put all this work into creating this software but not included sufficient documentation or example how to configure and use it, which basically renders it useless to us if we cannot figure it out.\nIs there another location where I can find further documentation or examples? If not are there any plans to address this?",
        "Issue Links": []
    },
    "OPENNLP-1210": {
        "Key": "OPENNLP-1210",
        "Summary": "Outdated documentation on -lang argument?",
        "Type": "Bug",
        "Status": "Resolved",
        "Priority": "Major",
        "Resolution": "Fixed",
        "Affects Version/s": "None",
        "Fix Version/s": "1.9.1",
        "Component/s": "None",
        "Assignee": "Koji Sekiguchi",
        "Reporter": "Xiang Ji",
        "Created": "30/Jul/18 18:32",
        "Updated": "01/Aug/18 01:05",
        "Resolved": "01/Aug/18 01:05",
        "Description": "I encountered \"Unsupported language: en\" error when I was trying to run the `TokenNameFinderConverter` or the `TokenNameFinderTrainer`.\n\u00a0\nI'm not sure if I understood the bug correctly but it seems that after 2 hours of trying, I found out that apparently in a certain version after `1.5.3`, OpenNLP changed the language codes from two characters to three characters, i.e. one should have passed in `eng` instead of `en`. But the documentation was never updated on this and no meaningful error message was given (i.e. the program didn't suggest \"supported languages\" instead).",
        "Issue Links": [
            "https://github.com/apache/opennlp/pull/325"
        ]
    },
    "OPENNLP-1211": {
        "Key": "OPENNLP-1211",
        "Summary": "Improve WindowFeatureGeneratorTest",
        "Type": "Test",
        "Status": "Resolved",
        "Priority": "Trivial",
        "Resolution": "Fixed",
        "Affects Version/s": "1.9.0",
        "Fix Version/s": "1.9.1",
        "Component/s": "Build, Packaging and Test",
        "Assignee": "Koji Sekiguchi",
        "Reporter": "Koji Sekiguchi",
        "Created": "11/Aug/18 02:04",
        "Updated": "14/Aug/18 04:04",
        "Resolved": "14/Aug/18 04:04",
        "Description": "I'd like to improve WindowFeatureGeneratorTest from the following perspective:\n\ntestWindowSizeOne should check the contents of the returned features. It checks the length of the features only now\nmost of test methods uses Assert.assertEquals(expected, actual) in opposite way for its arguments when checking the contents of the returned features\n\n\n\r\nAssert.assertEquals(features.get(0), testSentence[testTokenIndex]);\r\n\n\nshould be\n\n\r\nAssert.assertEquals(testSentence[testTokenIndex], features.get(0));\r\n\n\n\nThough I pointed out the arguments in assertEquals() above, I think we'd better use exact concrete string rather than expression such like testSentence[testTokenIndex] for the expected. And also, testForCorrectFeatures uses contains method when checking the contents of the returned features but I think we should avoid using contains when checking the items in a List, rather than writing like this:\n\n\n\r\n    Assert.assertTrue(features.contains(WindowFeatureGenerator.PREV_PREFIX + \"2\" +\r\n        testSentence[testTokenIndex - 2]));\r\n    Assert.assertTrue(features.contains(WindowFeatureGenerator.PREV_PREFIX + \"1\" +\r\n        testSentence[testTokenIndex - 1]));\r\n\r\n    Assert.assertTrue(features.contains(testSentence[testTokenIndex]));\r\n\r\n    Assert.assertTrue(features.contains(WindowFeatureGenerator.NEXT_PREFIX + \"1\" +\r\n        testSentence[testTokenIndex + 1]));\r\n    Assert.assertTrue(features.contains(WindowFeatureGenerator.NEXT_PREFIX + \"2\" +\r\n        testSentence[testTokenIndex + 2]));\r\n\n\nbut I'd like to rewrite them like this:\n\n\r\n    Assert.assertEquals(\"d\",features.get(0));\r\n    Assert.assertEquals(\"p1c\",features.get(1));\r\n    Assert.assertEquals(\"p2b\",features.get(2));\r\n    Assert.assertEquals(\"n1e\",features.get(3));\r\n    Assert.assertEquals(\"n2f\",features.get(4));\r\n\n\nThe second form helps us to understand how WindowFeatureGenerator works and it's easier to read.",
        "Issue Links": [
            "https://github.com/apache/opennlp/pull/326"
        ]
    },
    "OPENNLP-1212": {
        "Key": "OPENNLP-1212",
        "Summary": "TokenFeatureGeneratorFactory doesn't allow us to set lowercase flag",
        "Type": "Bug",
        "Status": "Resolved",
        "Priority": "Minor",
        "Resolution": "Fixed",
        "Affects Version/s": "1.9.0",
        "Fix Version/s": "1.9.1",
        "Component/s": "None",
        "Assignee": "Koji Sekiguchi",
        "Reporter": "Koji Sekiguchi",
        "Created": "11/Aug/18 02:39",
        "Updated": "14/Aug/18 04:04",
        "Resolved": "14/Aug/18 04:04",
        "Description": "As TokenFeatureGenerator can accept lowercase flag but TokenFeatureGeneratorFactory doesn't allow us to set lowercase flag, TokenFeatureGenerator always return lowercase tokens.",
        "Issue Links": [
            "https://github.com/apache/opennlp/pull/327"
        ]
    },
    "OPENNLP-1213": {
        "Key": "OPENNLP-1213",
        "Summary": "Use ja for Japanese language code rather than jp",
        "Type": "Bug",
        "Status": "Resolved",
        "Priority": "Minor",
        "Resolution": "Fixed",
        "Affects Version/s": "1.9.0",
        "Fix Version/s": "1.9.1",
        "Component/s": "None",
        "Assignee": "Koji Sekiguchi",
        "Reporter": "Koji Sekiguchi",
        "Created": "14/Aug/18 03:03",
        "Updated": "24/Aug/18 10:35",
        "Resolved": "24/Aug/18 10:35",
        "Description": "It seems that Factory of sentdetect uses \"jp\" for Japanese language code but I think it is country code. Let's use \"ja\" instead.\nWe could leave \"jp\" for back-compat, but I don't think we need to do it. So I'll just replace \"jp\" with \"ja\" in the patch.",
        "Issue Links": [
            "https://github.com/apache/opennlp/pull/328"
        ]
    },
    "OPENNLP-1214": {
        "Key": "OPENNLP-1214",
        "Summary": "use hash to avoid linear search in DefaultEndOfSentenceScanner",
        "Type": "Improvement",
        "Status": "Reopened",
        "Priority": "Minor",
        "Resolution": "Unresolved",
        "Affects Version/s": "1.9.0",
        "Fix Version/s": "None",
        "Component/s": "None",
        "Assignee": "Koji Sekiguchi",
        "Reporter": "Koji Sekiguchi",
        "Created": "14/Aug/18 03:34",
        "Updated": "22/Dec/22 13:35",
        "Resolved": null,
        "Description": "When DefaultEndOfSentenceScanner scans a sentence, it uses linear search to check if each characters in the sentence is one of eos characters. I think we'd better use HashSet to keep eosCharacters instead of char[].\nIn accordance with this replacement, I'd like to make getEndOfSentenceCharacters() deprecated because it returns char[] and nobody in OpenNLP calls it at present, and I'd like to add the equivalent method which returns Set<Character> of eos chars. Though it cannot keep the order of eos chars but I don't think it can be a problem anyway.",
        "Issue Links": [
            "https://github.com/apache/opennlp/pull/329",
            "https://github.com/apache/opennlp/pull/336"
        ]
    },
    "OPENNLP-1215": {
        "Key": "OPENNLP-1215",
        "Summary": "ParserTrainer's option -head-rules in the document should be -headRules",
        "Type": "Documentation",
        "Status": "Resolved",
        "Priority": "Trivial",
        "Resolution": "Fixed",
        "Affects Version/s": "1.9.0",
        "Fix Version/s": "1.9.1",
        "Component/s": "Documentation",
        "Assignee": "Koji Sekiguchi",
        "Reporter": "Koji Sekiguchi",
        "Created": "29/Aug/18 01:10",
        "Updated": "30/Aug/18 00:41",
        "Resolved": "30/Aug/18 00:41",
        "Description": "There is the section that describes so and I tried to execute:\n\n\r\nopennlp ParserTrainer -model en-parser.bin -data en-parser.train -head-rules opennlp-tools/lang/en/parser/en-head_rules -lang en\r\n\n\nand I got the error `Missing mandatory parameter: -headRules`",
        "Issue Links": [
            "https://github.com/apache/opennlp/pull/330"
        ]
    },
    "OPENNLP-1216": {
        "Key": "OPENNLP-1216",
        "Summary": "opennlp command should allow users to set heap size",
        "Type": "Documentation",
        "Status": "Resolved",
        "Priority": "Minor",
        "Resolution": "Fixed",
        "Affects Version/s": "1.9.0",
        "Fix Version/s": "1.9.1",
        "Component/s": "Command Line Interface",
        "Assignee": "Koji Sekiguchi",
        "Reporter": "Koji Sekiguchi",
        "Created": "29/Aug/18 01:43",
        "Updated": "30/Aug/18 00:52",
        "Resolved": "30/Aug/18 00:52",
        "Description": "When I used ParserTrainer, I got OutOfMemoryError. I checked opennlp shell script, I found uses cannot change the heap size without editing the script.\nI think we should allow uses to set it by doing like this:\n\n\r\n$ JAVA_HEAP=4096m opennlp ParserTrainer ...",
        "Issue Links": [
            "https://github.com/apache/opennlp/pull/331"
        ]
    },
    "OPENNLP-1217": {
        "Key": "OPENNLP-1217",
        "Summary": "opennlp Parser can take only one model file",
        "Type": "Documentation",
        "Status": "Resolved",
        "Priority": "Trivial",
        "Resolution": "Fixed",
        "Affects Version/s": "1.9.0",
        "Fix Version/s": "1.9.1",
        "Component/s": "None",
        "Assignee": "Koji Sekiguchi",
        "Reporter": "Koji Sekiguchi",
        "Created": "29/Aug/18 08:31",
        "Updated": "30/Aug/18 00:45",
        "Resolved": "30/Aug/18 00:45",
        "Description": null,
        "Issue Links": [
            "https://github.com/apache/opennlp/pull/332"
        ]
    },
    "OPENNLP-1218": {
        "Key": "OPENNLP-1218",
        "Summary": "All binary implementation of AbstractModelWriter and DataReader  throws java.io.UTFDataFormatException when large dataset is used for training",
        "Type": "Bug",
        "Status": "Closed",
        "Priority": "Major",
        "Resolution": "Duplicate",
        "Affects Version/s": "1.8.4",
        "Fix Version/s": "2.1.0",
        "Component/s": "None",
        "Assignee": "Martin Wiesner",
        "Reporter": "Sudheer Prem",
        "Created": "30/Aug/18 04:40",
        "Updated": "09/Dec/22 11:56",
        "Resolved": "09/Dec/22 10:45",
        "Description": "All binary implementation of\u00a0AbstractModelWriter and\u00a0DataReader throws \"java.io.UTFDataFormatException: encoded string too long\" in the\u00a0java.io.DataOutputStream.writeUTF method call when a large dataset (more than 64 KB) is used for training. Looks like, this is a known limitation of java.io.DataOutputStream.writeUTF method.\nFollowing is the stack trace:\njava.io.UTFDataFormatException: encoded string too long: 97519 bytes\nat java.io.DataOutputStream.writeUTF(DataOutputStream.java:364)\n at java.io.DataOutputStream.writeUTF(DataOutputStream.java:323)\n at opennlp.tools.ml.naivebayes.BinaryNaiveBayesModelWriter.writeUTF(BinaryNaiveBayesModelWriter.java:67)\n at opennlp.tools.ml.naivebayes.NaiveBayesModelWriter.persist(NaiveBayesModelWriter.java:169)\n at opennlp.tools.ml.model.GenericModelWriter.persist(GenericModelWriter.java:75)\n at opennlp.tools.util.model.ModelUtil.writeModel(ModelUtil.java:71)\n at opennlp.tools.util.model.GenericModelSerializer.serialize(GenericModelSerializer.java:36)\n at opennlp.tools.util.model.GenericModelSerializer.serialize(GenericModelSerializer.java:29)\n at opennlp.tools.util.model.BaseModel.serialize(BaseModel.java:597)\n\u00a0\nThe implementation should use byte array to resolve this issue.\u00a0\nFollowing is the fix to resolve\u00a0this issue.\n\u00a0\npublic void writeUTF(String s) throws java.io.IOException \n{\r\nbyte[] ctxByte = s.getBytes(\"utf-8\");\r\noutput.writeInt(ctxByte.length);\r\noutput.write(ctxByte); \r\n//output.writeUTF(s);\r\n}",
        "Issue Links": [
            "/jira/browse/OPENNLP-1366"
        ]
    },
    "OPENNLP-1219": {
        "Key": "OPENNLP-1219",
        "Summary": "change private instance variable featureGenerators to protected in DefaultNameContextGenerator",
        "Type": "Improvement",
        "Status": "Closed",
        "Priority": "Minor",
        "Resolution": "Fixed",
        "Affects Version/s": "1.9.0",
        "Fix Version/s": "1.9.1",
        "Component/s": "None",
        "Assignee": "Koji Sekiguchi",
        "Reporter": "Koji Sekiguchi",
        "Created": "19/Sep/18 07:53",
        "Updated": "25/Jan/20 20:10",
        "Resolved": "19/Sep/18 08:55",
        "Description": "TokenNameFinderTrainer allows users to customize TokenNameFinderFactory via -factory option. As I want to override DefaultNameContextGenerator.getContext(), I made the sub-class of TokenNameFinderFactory and created an instance of the sub-class of DefaultNameContextGenerator in the constructor of my TokenNameFinderFactory. However, I couldn't implement getContext() method of my DefaultNameContextGenerator because I couldn't access private member featureGenerators.",
        "Issue Links": [
            "https://github.com/apache/opennlp/pull/333"
        ]
    },
    "OPENNLP-1220": {
        "Key": "OPENNLP-1220",
        "Summary": "Add support for Byte Pair Encoding (BPE)",
        "Type": "Improvement",
        "Status": "Open",
        "Priority": "Minor",
        "Resolution": "Unresolved",
        "Affects Version/s": "None",
        "Fix Version/s": "None",
        "Component/s": "None",
        "Assignee": null,
        "Reporter": "J\u00f6rn Kottmann",
        "Created": "25/Sep/18 14:00",
        "Updated": "09/Dec/22 15:28",
        "Resolved": null,
        "Description": "It would be nice to add support for BPE to OpenNLP:\nhttps://arxiv.org/pdf/1508.07909.pdf",
        "Issue Links": []
    },
    "OPENNLP-1221": {
        "Key": "OPENNLP-1221",
        "Summary": "FeatureGeneratorUtil.tokenFeature() is too specific for some languages",
        "Type": "Improvement",
        "Status": "Resolved",
        "Priority": "Minor",
        "Resolution": "Fixed",
        "Affects Version/s": "1.9.0",
        "Fix Version/s": "None",
        "Component/s": "None",
        "Assignee": "Koji Sekiguchi",
        "Reporter": "Koji Sekiguchi",
        "Created": "26/Sep/18 04:22",
        "Updated": "27/Sep/18 01:59",
        "Resolved": "27/Sep/18 01:59",
        "Description": "As I described in OPENNLP-1197, in Japanese NER problem, we usually use only DIGIT, HIRA (\u3042, \u3044, \u3046, \u3048, \u304a etc.), KATA (\u30a2, \u30a4, \u30a6, \u30a8, \u30aa etc.), ALPHA and OTHER for token classes. What FeatureGeneratorUtil.tokenFeature() provides at present are too specific. I don't need to distinguish among lc (lowercase alphabet), ac (all capital letters) and ic (initial capital letter), for example.\nBy way of trial, if I applied the following patch in order to avoid \"too specific token class generation\":\n\n\r\ndiff --git a/opennlp-tools/src/main/java/opennlp/tools/util/featuregen/FeatureGeneratorUtil.java b/opennlp-tools/src/main/java/opennlp/tools/util/featuregen/FeatureGeneratorUtil.java\r\nindex e6b8af95..405938d1 100644\r\n--- a/opennlp-tools/src/main/java/opennlp/tools/util/featuregen/FeatureGeneratorUtil.java\r\n+++ b/opennlp-tools/src/main/java/opennlp/tools/util/featuregen/FeatureGeneratorUtil.java\r\n@@ -29,6 +29,8 @@ public class FeatureGeneratorUtil {\r\n   private static final String TOKEN_AND_CLASS_PREFIX = \"w&c\";\r\n \r\n   private static final Pattern capPeriod = Pattern.compile(\"^[A-Z]\\\\.$\");\r\n+  private static final Pattern pDigit = Pattern.compile(\"^\\\\p{IsDigit}+$\");\r\n+  private static final Pattern pAlpha = Pattern.compile(\"^\\\\p{IsAlphabetic}+$\");\r\n \r\n   /**\r\n    * Generates a class name for the specified token.\r\n@@ -64,48 +66,11 @@ public class FeatureGeneratorUtil {\r\n     else if (pattern.isAllKatakana()) {\r\n       feat = \"jak\";\r\n     }\r\n-    else if (pattern.isAllLowerCaseLetter()) {\r\n-      feat = \"lc\";\r\n+    else if (pDigit.matcher(token).find()) {\r\n+      feat = \"digit\";\r\n     }\r\n-    else if (pattern.digits() == 2) {\r\n-      feat = \"2d\";\r\n-    }\r\n-    else if (pattern.digits() == 4) {\r\n-      feat = \"4d\";\r\n-    }\r\n-    else if (pattern.containsDigit()) {\r\n-      if (pattern.containsLetters()) {\r\n-        feat = \"an\";\r\n-      }\r\n-      else if (pattern.containsHyphen()) {\r\n-        feat = \"dd\";\r\n-      }\r\n-      else if (pattern.containsSlash()) {\r\n-        feat = \"ds\";\r\n-      }\r\n-      else if (pattern.containsComma()) {\r\n-        feat = \"dc\";\r\n-      }\r\n-      else if (pattern.containsPeriod()) {\r\n-        feat = \"dp\";\r\n-      }\r\n-      else {\r\n-        feat = \"num\";\r\n-      }\r\n-    }\r\n-    else if (pattern.isAllCapitalLetter()) {\r\n-      if (token.length() == 1) {\r\n-        feat = \"sc\";\r\n-      }\r\n-      else {\r\n-        feat = \"ac\";\r\n-      }\r\n-    }\r\n-    else if (capPeriod.matcher(token).find()) {\r\n-      feat = \"cp\";\r\n-    }\r\n-    else if (pattern.isInitialCapitalLetter()) {\r\n-      feat = \"ic\";\r\n+    else if (pAlpha.matcher(token).find()) {\r\n+      feat = \"alpha\";\r\n     }\r\n     else {\r\n       feat = \"other\";\r\n\n\ntotal F1 was increased from 82.00% to 82.13%. It may be trivial, but I think I have a lot of room yet to tune and increase the performance.\nFortunately, I could add japanese-addon project to opennlp-addons in the previous ticket, I'd like to add some programs that generate simpler token classes in japanese-addon.",
        "Issue Links": [
            "https://github.com/apache/opennlp-addons/pull/3",
            "https://github.com/apache/opennlp-addons/pull/3"
        ]
    },
    "OPENNLP-1222": {
        "Key": "OPENNLP-1222",
        "Summary": "Make it possible to build OpenNLP with java 11",
        "Type": "Task",
        "Status": "Resolved",
        "Priority": "Major",
        "Resolution": "Fixed",
        "Affects Version/s": "None",
        "Fix Version/s": "1.9.1",
        "Component/s": "Build, Packaging and Test",
        "Assignee": "Tommaso Teofili",
        "Reporter": "Tommaso Teofili",
        "Created": "02/Oct/18 08:32",
        "Updated": "02/Oct/18 12:10",
        "Resolved": "02/Oct/18 12:04",
        "Description": "Currently the build fails when using java 11.\nFailures are mostly due to outdated versions of maven plugins and errors\u00a0during javadoc generation.",
        "Issue Links": [
            "https://github.com/apache/opennlp/pull/335"
        ]
    },
    "OPENNLP-1223": {
        "Key": "OPENNLP-1223",
        "Summary": "Add NameFinder model based on Tiger",
        "Type": "New Feature",
        "Status": "Open",
        "Priority": "Major",
        "Resolution": "Unresolved",
        "Affects Version/s": "None",
        "Fix Version/s": "None",
        "Component/s": "language model",
        "Assignee": null,
        "Reporter": "J. Fiala",
        "Created": "07/Oct/18 19:44",
        "Updated": "16/Dec/22 12:36",
        "Resolved": null,
        "Description": "Add NameFinder model based on the Tiger treebank 2.2 (Universit\u00e4t Stuttgart - www.ims.uni-stuttgart.de/forschung/ressourcen/korpora/tiger.html)\n\u00a0h3. Tasks:\n1.) add model based on tiger \n>>> generated based on 6.271 sentences with tagged names (always given name + surname).\n2.) add a few test sentences \n3.) add small evaluation file \n4.) check licensing issues \nhttp://www.ims.uni-stuttgart.de/forschung/ressourcen/korpora/TIGERCorpus/license/index.html\nContact information: \"If you are interested in a commercial license of the TIGERCorpus, please contact the secretary of Prof. Hans Uszkoreit's chair at Saarland University at sek-hu AT coli DOT uni-saarland DOT de.\"\n\nClarify if a commercial license is needed for distributing a model derived on the corpus.\n\nInput data\n\ntigercorpus-2.2.conll09.tar.gz (Uni Stuttgart)\n www.ims.uni-stuttgart.de/forschung/ressourcen/korpora/tiger.html\nyagoLabels.tsv.7z (Max Planck Institute)\nhttps://www.mpi-inf.mpg.de/departments/databases-and-information-systems/research/yago-naga/yago/downloads/\n\nBasic workflow\n1.) Extract sentences in the tiger database with possible names (two words in sequence tagged as NE)\n2.) Check if possible names include a given name based on the YAGO labels database (given name is assumed as first name)\n3.) If given name is included in YAGO labels as givenName, then tag the person name\n4.) Train with full data set (50.472 sentences - including non-names)\n5.) Evaluate with person data set (6.271 sentences)\n >>> JF 14.10.: see updated model: tiger_2.2_namefinder_all.bin_20181014.bin.7z\nOpen questions\nI first extracted 6.271 sentences mentioning names and trained based on that (filtered) data. Or is it better to use the complete training data (including the sentences without names)? \n>>> JF 14.10.: added steps 4 + 5\nResults\nResults from step 5 above:\nEvaluated 6271 samples with 7659 entities; found: 7662 entities; correct: 7644.\n \u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 TOTAL: precision:\u00a0\u00a0 99,77%;\u00a0 recall:\u00a0\u00a0 99,80%; F1:\u00a0\u00a0 99,78%.\n \u00a0\u00a0\u00a0\u00a0\u00a0 person: precision:\u00a0\u00a0 99,77%;\u00a0 recall:\u00a0\u00a0 99,80%; F1:\u00a0\u00a0 99,78%. [target: 7659; tp: 7644; fp:\u00a0 18]\n\u00a0\nFurther Improvements:\n1.) There may be some names which are referring to locations which have to be refined (e.g. San Juan):\nF\u00fcnf bis sechs Stunden , damit sie zur Besinnung kommen , meint <START:person> Salvador Lopez <END>Gonzalez , das Oberhaupt von <START:person> San Juan <END> <START:person> Juan Chamula <END> , einem pittoresken Ort hoch in den Bergen von .).\n2.) Add support for names with more than two words (e.g. Salvador Lopez Gonzalez above).\n3.) Check for context-sensitive non-name matches (e.g. \"General\")",
        "Issue Links": []
    },
    "OPENNLP-1224": {
        "Key": "OPENNLP-1224",
        "Summary": "Use Daemon threads in executor services",
        "Type": "Improvement",
        "Status": "Resolved",
        "Priority": "Major",
        "Resolution": "Fixed",
        "Affects Version/s": "None",
        "Fix Version/s": "1.9.1",
        "Component/s": "None",
        "Assignee": "Koji Sekiguchi",
        "Reporter": "Edd Spencer",
        "Created": "05/Nov/18 12:00",
        "Updated": "14/Nov/18 05:29",
        "Resolved": "14/Nov/18 05:29",
        "Description": "For all executor services it would be ideal if they are configured to use daemon threads. This will mean that should the process need to be shutdown it will not wait until these threads are complete in order to do so (which can take a long time depending on operation).",
        "Issue Links": [
            "https://github.com/apache/opennlp/pull/338"
        ]
    },
    "OPENNLP-1225": {
        "Key": "OPENNLP-1225",
        "Summary": "Make it possible to iterate through word vector table tokens",
        "Type": "Improvement",
        "Status": "Resolved",
        "Priority": "Major",
        "Resolution": "Fixed",
        "Affects Version/s": "None",
        "Fix Version/s": "1.9.1",
        "Component/s": "word vectors",
        "Assignee": "Tommaso Teofili",
        "Reporter": "Tommaso Teofili",
        "Created": "04/Dec/18 09:01",
        "Updated": "05/Dec/18 10:11",
        "Resolved": "05/Dec/18 10:11",
        "Description": "Currently it's not possible to iterate through the tokens stored in a WordVectorTable, which makes it hard to implement use cases where all or a subset of the existing word vectors need to be processed.",
        "Issue Links": [
            "https://github.com/apache/opennlp/pull/339"
        ]
    },
    "OPENNLP-1226": {
        "Key": "OPENNLP-1226",
        "Summary": "dd.mm.yyyy Date format in txt file for .bin model training",
        "Type": "Question",
        "Status": "Open",
        "Priority": "Minor",
        "Resolution": "Unresolved",
        "Affects Version/s": "None",
        "Fix Version/s": "None",
        "Component/s": "Formats",
        "Assignee": null,
        "Reporter": "Olga",
        "Created": "07/Dec/18 10:59",
        "Updated": "21/Mar/22 16:03",
        "Resolved": null,
        "Description": "My txt file for model training has date tags in <START:date> dd.mm.yyyy <END> format. But when I try to use the trained .bin file, the dates are not extracted as they should. My txt tagged file is written one sentence in line. I was wondering maybe the format, and the fullstops in this date format make a difficulty for the model to learn. In the official OpenNLP documentation I can see there is a bin file with date extraction, but I can't see the txt file containing the tags.\nI tried to open this bin as a txt format but I read in Stack Overflow that I can't do that.\nhttps://stackoverflow.com/questions/26140492/how-can-i-view-the-content-of-a-bin-file-in-opennlp",
        "Issue Links": []
    },
    "OPENNLP-1227": {
        "Key": "OPENNLP-1227",
        "Summary": "Add dockerfile for building OpenNLP container",
        "Type": "New Feature",
        "Status": "Closed",
        "Priority": "Major",
        "Resolution": "Done",
        "Affects Version/s": "None",
        "Fix Version/s": "1.9.3",
        "Component/s": "Build, Packaging and Test",
        "Assignee": "Jeff Zemerick",
        "Reporter": "Jeff Zemerick",
        "Created": "17/Dec/18 12:31",
        "Updated": "21/Jun/20 11:40",
        "Resolved": "21/Jun/20 11:28",
        "Description": "Add dockerfile for building OpenNLP container.",
        "Issue Links": [
            "https://github.com/apache/opennlp/pull/340"
        ]
    },
    "OPENNLP-1228": {
        "Key": "OPENNLP-1228",
        "Summary": "lemmatize function gives wrong result",
        "Type": "Bug",
        "Status": "Open",
        "Priority": "Minor",
        "Resolution": "Unresolved",
        "Affects Version/s": "None",
        "Fix Version/s": "None",
        "Component/s": "Lemmatizer",
        "Assignee": null,
        "Reporter": "Divya Rani",
        "Created": "24/Dec/18 05:30",
        "Updated": "24/Dec/18 05:30",
        "Resolved": null,
        "Description": "The output generated by lemmatize function for the input\u00a0\"brethren\" is \"brother\" which is wrong according to the CoreNLP test suite.\nTest case was taken from https://github.com/stanfordnlp/CoreNLP/blob/731cfe56d31451578eb107aeb632de654b02c18d/test/src/edu/stanford/nlp/process/MorphologyTest.java#L11\nExpected Output:\nhttps://github.com/stanfordnlp/CoreNLP/blob/731cfe56d31451578eb107aeb632de654b02c18d/test/src/edu/stanford/nlp/process/MorphologyTest.java#L45",
        "Issue Links": []
    },
    "OPENNLP-1229": {
        "Key": "OPENNLP-1229",
        "Summary": "stem function giving wrong output",
        "Type": "Bug",
        "Status": "Closed",
        "Priority": "Minor",
        "Resolution": "Won't Fix",
        "Affects Version/s": "None",
        "Fix Version/s": "2.2.0",
        "Component/s": "Stemmer",
        "Assignee": "Martin Wiesner",
        "Reporter": "Divya Rani",
        "Created": "24/Dec/18 05:36",
        "Updated": "22/Apr/23 17:39",
        "Resolved": "27/Feb/23 20:12",
        "Description": "As opennlp is using\u00a0PorterStemmer for stemming PorterStemmer seems to be stemming \"this\" -> \"thi\".",
        "Issue Links": []
    },
    "OPENNLP-1230": {
        "Key": "OPENNLP-1230",
        "Summary": "Replace MD5 and SHA1 with SHA256/512",
        "Type": "Task",
        "Status": "Closed",
        "Priority": "Major",
        "Resolution": "Fixed",
        "Affects Version/s": "None",
        "Fix Version/s": "1.9.1",
        "Component/s": "None",
        "Assignee": "Suneel Marthi",
        "Reporter": "Jeff Zemerick",
        "Created": "27/Dec/18 18:18",
        "Updated": "27/Dec/18 19:31",
        "Resolved": "27/Dec/18 19:31",
        "Description": "Replace MD5 and SHA1 with SHA 512 during Maven package building.",
        "Issue Links": [
            "https://github.com/apache/opennlp/pull/341",
            "https://github.com/apache/opennlp/pull/342"
        ]
    },
    "OPENNLP-1231": {
        "Key": "OPENNLP-1231",
        "Summary": "Add SHA-512 checksum files for artifacts",
        "Type": "Task",
        "Status": "Closed",
        "Priority": "Critical",
        "Resolution": "Fixed",
        "Affects Version/s": "1.9.1",
        "Fix Version/s": "1.9.2",
        "Component/s": "None",
        "Assignee": "Jeff Zemerick",
        "Reporter": "Jeff Zemerick",
        "Created": "27/Dec/18 19:32",
        "Updated": "09/Jan/19 23:41",
        "Resolved": "31/Dec/18 15:32",
        "Description": "Per the Apache Release Distribution Policy, replace MD5/SHA1 checksums with SHA-512.\nUpdate the OpenNLP \"Making a release\" page with any additional steps required for a release.",
        "Issue Links": [
            "https://github.com/apache/opennlp/pull/343",
            "https://opennlp.apache.org/release.html",
            "http://www.apache.org/dev/release-distribution"
        ]
    },
    "OPENNLP-1232": {
        "Key": "OPENNLP-1232",
        "Summary": "Fix table headers on Downloads page",
        "Type": "Task",
        "Status": "Closed",
        "Priority": "Minor",
        "Resolution": "Fixed",
        "Affects Version/s": "None",
        "Fix Version/s": "None",
        "Component/s": "Website",
        "Assignee": "Jeff Zemerick",
        "Reporter": "Jeff Zemerick",
        "Created": "02/Jan/19 17:00",
        "Updated": "02/Jan/19 18:51",
        "Resolved": "02/Jan/19 18:50",
        "Description": "The \"File\" and \"Signatures\" headers are wrong. Replace the headers with something more appropriate.",
        "Issue Links": [
            "https://github.com/apache/opennlp-site/pull/58"
        ]
    },
    "OPENNLP-1233": {
        "Key": "OPENNLP-1233",
        "Summary": "Penn Treebank tag set link insufficient",
        "Type": "Documentation",
        "Status": "Open",
        "Priority": "Trivial",
        "Resolution": "Unresolved",
        "Affects Version/s": "1.9.1",
        "Fix Version/s": "None",
        "Component/s": "Documentation",
        "Assignee": null,
        "Reporter": "Vidyasagar Mundroy",
        "Created": "09/Jan/19 12:21",
        "Updated": "09/Dec/22 11:00",
        "Resolved": null,
        "Description": "The link \"https://www.ling.upenn.edu/courses/Fall_2003/ling001/penn_treebank_pos.html\" provided with name \"Penn Treebank tag set\" in sections Tagging and Chunking of manual does not list tags used for chunking. A proper link is needed for anybody to develop applications using openNLP. Found some info on missing tags at \"https://www.clips.uantwerpen.be/pages/mbsp-tags\" but\u00a0 not sure if the link can be used in the manual.",
        "Issue Links": []
    },
    "OPENNLP-1234": {
        "Key": "OPENNLP-1234",
        "Summary": "Dictionary.asStringSet() is returning single tokens",
        "Type": "Bug",
        "Status": "Closed",
        "Priority": "Major",
        "Resolution": "Won't Fix",
        "Affects Version/s": "None",
        "Fix Version/s": "None",
        "Component/s": "Name Finder",
        "Assignee": null,
        "Reporter": "Evandro Fonseca",
        "Created": "09/Jan/19 18:14",
        "Updated": "05/Nov/20 12:30",
        "Resolved": "05/Nov/20 12:30",
        "Description": "When we use the method Dictionary.asStringSet(), it returns a list of single tokens.\nFor example: European Union -> European. Basically, it returns just the first token of each instance.",
        "Issue Links": [
            "https://github.com/apache/opennlp/pull/344"
        ]
    },
    "OPENNLP-1235": {
        "Key": "OPENNLP-1235",
        "Summary": "lemmatizer decodeLemmas method bug",
        "Type": "Bug",
        "Status": "Open",
        "Priority": "Major",
        "Resolution": "Unresolved",
        "Affects Version/s": "1.8.4,                                            1.9.0,                                            1.9.1",
        "Fix Version/s": "None",
        "Component/s": "Lemmatizer",
        "Assignee": null,
        "Reporter": "Sachin Kumar Saini",
        "Created": "10/Jan/19 10:13",
        "Updated": "10/Jan/19 10:13",
        "Resolved": null,
        "Description": "I got the following permutaion for the text \"Obstruction\":\nR10ojR9baR8smD7tD6rD5uD4cD3tD2iD1oD0n\nWhen i checked the method decodeShortestEditScript in class opennlp.tools.util.StringUti, which is used to decode the word with permutations.\nI got the permIndex variable initialized to 0 and increasing by one to get next permutation letter,\nwhich is gone wrong when the permutation letter has more than 1 digits e.g. in the given permutation R10 mear R and 10, but because of permIndex increating by one, so it is considering as R and 1.",
        "Issue Links": []
    },
    "OPENNLP-1236": {
        "Key": "OPENNLP-1236",
        "Summary": "Add support for Arabic and Greek stemmers",
        "Type": "Improvement",
        "Status": "Closed",
        "Priority": "Minor",
        "Resolution": "Fixed",
        "Affects Version/s": "None",
        "Fix Version/s": "1.9.2",
        "Component/s": "Stemmer",
        "Assignee": "J\u00f6rn Kottmann",
        "Reporter": "Maxime Steinmetz",
        "Created": "14/Jan/19 16:50",
        "Updated": "28/Jan/19 08:35",
        "Resolved": "28/Jan/19 08:35",
        "Description": "The arabic and greek Snowball stemmers are now available (https://github.com/snowballstem/snowball/tree/master/algorithms) and it would be nice to add support for those two\n\u00a0\nThis would require:\n\nConverting the .sbl files into Java code and adding it to the stemmer folder\nUpdating relevant classes to support the\u00a0new stemmers\nAdding a tests for the new stemmers",
        "Issue Links": [
            "https://github.com/apache/opennlp/pull/345"
        ]
    },
    "OPENNLP-1237": {
        "Key": "OPENNLP-1237",
        "Summary": "Document Categorizer example references non-existant method signature",
        "Type": "Documentation",
        "Status": "Resolved",
        "Priority": "Major",
        "Resolution": "Fixed",
        "Affects Version/s": "1.9.1",
        "Fix Version/s": "2.0.0",
        "Component/s": "Documentation",
        "Assignee": "Martin Wiesner",
        "Reporter": "Nick Burch",
        "Created": "29/Jan/19 12:19",
        "Updated": "09/Dec/22 10:57",
        "Resolved": "09/Dec/22 10:57",
        "Description": "In the Document Categorizer section of the manual https://opennlp.apache.org/docs/1.9.1/manual/opennlp.html#tools.doccat there is a code snippet in the training section:\n\n\r\n  model = DocumentCategorizerME.train(\"en\", sampleStream);\r\n\n\nHowever, no matching method is present in the javadocs at https://opennlp.apache.org/docs/1.9.1/apidocs/opennlp-tools/opennlp/tools/doccat/DocumentCategorizerME.html . The nearest seems to be one that takes two additional required parameters: https://opennlp.apache.org/docs/1.9.1/apidocs/opennlp-tools/opennlp/tools/doccat/DocumentCategorizerME.html#train-java.lang.String-opennlp.tools.util.ObjectStream-opennlp.tools.util.TrainingParameters-opennlp.tools.doccat.DoccatFactory-\nIt looks like the code snippet is out of date, and needs updating to cover the API changes that seem to have happened",
        "Issue Links": [
            "/jira/browse/OPENNLP-1319"
        ]
    },
    "OPENNLP-1238": {
        "Key": null,
        "Summary": null,
        "Type": null,
        "Status": null,
        "Priority": null,
        "Resolution": null,
        "Affects Version/s": null,
        "Fix Version/s": null,
        "Component/s": null,
        "Assignee": null,
        "Reporter": null,
        "Created": null,
        "Updated": null,
        "Resolved": null,
        "Description": null,
        "Issue Links": []
    },
    "OPENNLP-1239": {
        "Key": null,
        "Summary": null,
        "Type": null,
        "Status": null,
        "Priority": null,
        "Resolution": null,
        "Affects Version/s": null,
        "Fix Version/s": null,
        "Component/s": null,
        "Assignee": null,
        "Reporter": null,
        "Created": null,
        "Updated": null,
        "Resolved": null,
        "Description": null,
        "Issue Links": []
    },
    "OPENNLP-1240": {
        "Key": null,
        "Summary": null,
        "Type": null,
        "Status": null,
        "Priority": null,
        "Resolution": null,
        "Affects Version/s": null,
        "Fix Version/s": null,
        "Component/s": null,
        "Assignee": null,
        "Reporter": null,
        "Created": null,
        "Updated": null,
        "Resolved": null,
        "Description": null,
        "Issue Links": []
    },
    "OPENNLP-1241": {
        "Key": null,
        "Summary": null,
        "Type": null,
        "Status": null,
        "Priority": null,
        "Resolution": null,
        "Affects Version/s": null,
        "Fix Version/s": null,
        "Component/s": null,
        "Assignee": null,
        "Reporter": null,
        "Created": null,
        "Updated": null,
        "Resolved": null,
        "Description": null,
        "Issue Links": []
    },
    "OPENNLP-1242": {
        "Key": null,
        "Summary": null,
        "Type": null,
        "Status": null,
        "Priority": null,
        "Resolution": null,
        "Affects Version/s": null,
        "Fix Version/s": null,
        "Component/s": null,
        "Assignee": null,
        "Reporter": null,
        "Created": null,
        "Updated": null,
        "Resolved": null,
        "Description": null,
        "Issue Links": []
    },
    "OPENNLP-1243": {
        "Key": null,
        "Summary": null,
        "Type": null,
        "Status": null,
        "Priority": null,
        "Resolution": null,
        "Affects Version/s": null,
        "Fix Version/s": null,
        "Component/s": null,
        "Assignee": null,
        "Reporter": null,
        "Created": null,
        "Updated": null,
        "Resolved": null,
        "Description": null,
        "Issue Links": []
    },
    "OPENNLP-1244": {
        "Key": null,
        "Summary": null,
        "Type": null,
        "Status": null,
        "Priority": null,
        "Resolution": null,
        "Affects Version/s": null,
        "Fix Version/s": null,
        "Component/s": null,
        "Assignee": null,
        "Reporter": null,
        "Created": null,
        "Updated": null,
        "Resolved": null,
        "Description": null,
        "Issue Links": []
    },
    "OPENNLP-1245": {
        "Key": null,
        "Summary": null,
        "Type": null,
        "Status": null,
        "Priority": null,
        "Resolution": null,
        "Affects Version/s": null,
        "Fix Version/s": null,
        "Component/s": null,
        "Assignee": null,
        "Reporter": null,
        "Created": null,
        "Updated": null,
        "Resolved": null,
        "Description": null,
        "Issue Links": []
    },
    "OPENNLP-1246": {
        "Key": null,
        "Summary": null,
        "Type": null,
        "Status": null,
        "Priority": null,
        "Resolution": null,
        "Affects Version/s": null,
        "Fix Version/s": null,
        "Component/s": null,
        "Assignee": null,
        "Reporter": null,
        "Created": null,
        "Updated": null,
        "Resolved": null,
        "Description": null,
        "Issue Links": []
    },
    "OPENNLP-1247": {
        "Key": null,
        "Summary": null,
        "Type": null,
        "Status": null,
        "Priority": null,
        "Resolution": null,
        "Affects Version/s": null,
        "Fix Version/s": null,
        "Component/s": null,
        "Assignee": null,
        "Reporter": null,
        "Created": null,
        "Updated": null,
        "Resolved": null,
        "Description": null,
        "Issue Links": []
    },
    "OPENNLP-1248": {
        "Key": null,
        "Summary": null,
        "Type": null,
        "Status": null,
        "Priority": null,
        "Resolution": null,
        "Affects Version/s": null,
        "Fix Version/s": null,
        "Component/s": null,
        "Assignee": null,
        "Reporter": null,
        "Created": null,
        "Updated": null,
        "Resolved": null,
        "Description": null,
        "Issue Links": []
    },
    "OPENNLP-1249": {
        "Key": null,
        "Summary": null,
        "Type": null,
        "Status": null,
        "Priority": null,
        "Resolution": null,
        "Affects Version/s": null,
        "Fix Version/s": null,
        "Component/s": null,
        "Assignee": null,
        "Reporter": null,
        "Created": null,
        "Updated": null,
        "Resolved": null,
        "Description": null,
        "Issue Links": []
    },
    "OPENNLP-1250": {
        "Key": null,
        "Summary": null,
        "Type": null,
        "Status": null,
        "Priority": null,
        "Resolution": null,
        "Affects Version/s": null,
        "Fix Version/s": null,
        "Component/s": null,
        "Assignee": null,
        "Reporter": null,
        "Created": null,
        "Updated": null,
        "Resolved": null,
        "Description": null,
        "Issue Links": []
    },
    "OPENNLP-1251": {
        "Key": null,
        "Summary": null,
        "Type": null,
        "Status": null,
        "Priority": null,
        "Resolution": null,
        "Affects Version/s": null,
        "Fix Version/s": null,
        "Component/s": null,
        "Assignee": null,
        "Reporter": null,
        "Created": null,
        "Updated": null,
        "Resolved": null,
        "Description": null,
        "Issue Links": []
    },
    "OPENNLP-1252": {
        "Key": null,
        "Summary": null,
        "Type": null,
        "Status": null,
        "Priority": null,
        "Resolution": null,
        "Affects Version/s": null,
        "Fix Version/s": null,
        "Component/s": null,
        "Assignee": null,
        "Reporter": null,
        "Created": null,
        "Updated": null,
        "Resolved": null,
        "Description": null,
        "Issue Links": []
    },
    "OPENNLP-1253": {
        "Key": null,
        "Summary": null,
        "Type": null,
        "Status": null,
        "Priority": null,
        "Resolution": null,
        "Affects Version/s": null,
        "Fix Version/s": null,
        "Component/s": null,
        "Assignee": null,
        "Reporter": null,
        "Created": null,
        "Updated": null,
        "Resolved": null,
        "Description": null,
        "Issue Links": []
    },
    "OPENNLP-1254": {
        "Key": null,
        "Summary": null,
        "Type": null,
        "Status": null,
        "Priority": null,
        "Resolution": null,
        "Affects Version/s": null,
        "Fix Version/s": null,
        "Component/s": null,
        "Assignee": null,
        "Reporter": null,
        "Created": null,
        "Updated": null,
        "Resolved": null,
        "Description": null,
        "Issue Links": []
    },
    "OPENNLP-1255": {
        "Key": null,
        "Summary": null,
        "Type": null,
        "Status": null,
        "Priority": null,
        "Resolution": null,
        "Affects Version/s": null,
        "Fix Version/s": null,
        "Component/s": null,
        "Assignee": null,
        "Reporter": null,
        "Created": null,
        "Updated": null,
        "Resolved": null,
        "Description": null,
        "Issue Links": []
    },
    "OPENNLP-1256": {
        "Key": null,
        "Summary": null,
        "Type": null,
        "Status": null,
        "Priority": null,
        "Resolution": null,
        "Affects Version/s": null,
        "Fix Version/s": null,
        "Component/s": null,
        "Assignee": null,
        "Reporter": null,
        "Created": null,
        "Updated": null,
        "Resolved": null,
        "Description": null,
        "Issue Links": []
    },
    "OPENNLP-1257": {
        "Key": "OPENNLP-1257",
        "Summary": "Splitting in Lemmatizer via tabs",
        "Type": "Bug",
        "Status": "Closed",
        "Priority": "Major",
        "Resolution": "Won't Fix",
        "Affects Version/s": "1.9.1",
        "Fix Version/s": "None",
        "Component/s": "Lemmatizer",
        "Assignee": null,
        "Reporter": "Mingyang Liu",
        "Created": "25/Apr/19 21:54",
        "Updated": "29/Mar/22 13:18",
        "Resolved": "29/Mar/22 13:18",
        "Description": "Splitting the train dataset via tabs not spaces (as in documentation)",
        "Issue Links": [
            "/jira/browse/OPENNLP-1363",
            "https://github.com/apache/opennlp/pull/348"
        ]
    },
    "OPENNLP-1258": {
        "Key": "OPENNLP-1258",
        "Summary": "implement Serializable in langdetect and normalize",
        "Type": "Improvement",
        "Status": "Closed",
        "Priority": "Major",
        "Resolution": "Fixed",
        "Affects Version/s": "None",
        "Fix Version/s": "1.9.3",
        "Component/s": "Language Detector",
        "Assignee": null,
        "Reporter": "Lucas Avan\u00e7o",
        "Created": "26/Apr/19 15:59",
        "Updated": "25/Jan/20 20:00",
        "Resolved": "25/Jan/20 20:00",
        "Description": "It is necessary to make some classes of langdetect and normalizer to implement Serializable in order to save language detection models",
        "Issue Links": [
            "https://github.com/apache/opennlp/pull/349"
        ]
    },
    "OPENNLP-1259": {
        "Key": "OPENNLP-1259",
        "Summary": "Replace Math.Random with Random.nextDouble",
        "Type": "Improvement",
        "Status": "Closed",
        "Priority": "Trivial",
        "Resolution": "Fixed",
        "Affects Version/s": "None",
        "Fix Version/s": "None",
        "Component/s": "None",
        "Assignee": null,
        "Reporter": "bd2019us",
        "Created": "10/May/19 23:37",
        "Updated": "02/Jun/20 14:56",
        "Resolved": "02/Jun/20 14:56",
        "Description": "When compared to Random.nextDouble, there is a slight performance overhead associated with Math.random.\u00a0Switching to Random.nextDouble can reduce this overhead and offers more\u00a0control over the\u00a0randomness in the future.",
        "Issue Links": [
            "https://github.com/apache/opennlp-sandbox/pull/30"
        ]
    },
    "OPENNLP-1260": {
        "Key": "OPENNLP-1260",
        "Summary": "FileWriter -> BufferedWriter for instances FileWrite writing large amounts of data or used within loops",
        "Type": "Improvement",
        "Status": "Closed",
        "Priority": "Minor",
        "Resolution": "Fixed",
        "Affects Version/s": "None",
        "Fix Version/s": "None",
        "Component/s": "None",
        "Assignee": null,
        "Reporter": "bd2019us",
        "Created": "11/May/19 19:42",
        "Updated": "02/Jun/20 14:56",
        "Resolved": "02/Jun/20 14:56",
        "Description": "When instances of FileWriter are used to writer large\u00a0amounts of data or\u00a0used intensively within loops, BufferedWriter can be used\u00a0more optimal IO operations.\nAttached patch details are all performed under the OPENNLP-ADDONS project",
        "Issue Links": [
            "https://github.com/apache/opennlp-addons/pull/4"
        ]
    },
    "OPENNLP-1261": {
        "Key": "OPENNLP-1261",
        "Summary": "Language Detector fails to predict language on long input texts",
        "Type": "Improvement",
        "Status": "Closed",
        "Priority": "Major",
        "Resolution": "Won't Fix",
        "Affects Version/s": "None",
        "Fix Version/s": "1.9.3",
        "Component/s": "Language Detector",
        "Assignee": "J\u00f6rn Kottmann",
        "Reporter": "J\u00f6rn Kottmann",
        "Created": "22/May/19 13:57",
        "Updated": "25/Jan/20 00:42",
        "Resolved": "25/Jan/20 00:42",
        "Description": "If the input text is very long, e.g. 100k chars, then the lang detect component fails to detect the language correctly, even though the text is only written in one language.\nThis issue was tracked down to the context generator, where the count of the ngrams are ignored.",
        "Issue Links": [
            "/jira/browse/OPENNLP-1269",
            "https://github.com/apache/opennlp/pull/350"
        ]
    },
    "OPENNLP-1262": {
        "Key": "OPENNLP-1262",
        "Summary": "LanguageDetectorEvaluatorTest failure in windows",
        "Type": "Bug",
        "Status": "Closed",
        "Priority": "Major",
        "Resolution": "Fixed",
        "Affects Version/s": "None",
        "Fix Version/s": "1.9.2",
        "Component/s": "Language Detector",
        "Assignee": "J\u00f6rn Kottmann",
        "Reporter": "Madhawa Kasun Gunasekara",
        "Created": "23/May/19 14:49",
        "Updated": "25/May/19 09:09",
        "Resolved": "25/May/19 09:09",
        "Description": "Test failed with\u00a0\nMaven Version :\u00a0\nApache Maven 3.6.0 (97c98ec64a1fdfee7767ce5ffb20918da4f719f3; 2018-10-24T20:41:47+02:00)\nMaven home: C:\\Tools\\apache-maven-3.6.0\\bin\\..\nJava version: 1.8.0_202, vendor: Oracle Corporation, runtime: C:\\Program Files\\Java\\jdk1.8.0_202\\jre\nDefault locale: en_US, platform encoding: Cp1252\nOS name: \"windows 10\", version: \"10.0\", arch: \"amd64\", family: \"windows\"\nResults :\nFailed tests:\n LanguageDetectorEvaluatorTest.processSample:75 expected:<...ed Predicted Context[\nfra pob escreve e faz palestras pelo mundo inteiro sobre anjos\nfra pob escreve e faz palestras pelo mundo inteiro sobre anjos]\n> but was:<...ed Predicted Context[\nfra pob escreve e faz palestras pelo mundo inteiro sobre anjos\n]ra pob escreve e faz palestras pelo mundo inteiro sobre anjos\n>\nTests run: 767, Failures: 1, Errors: 0, Skipped: 0\n[INFO] ------------------------------------------------------------------------\n[INFO] Reactor Summary for Apache OpenNLP Reactor 1.9.2-SNAPSHOT:\n[INFO]\n[INFO] Apache OpenNLP Reactor ............................. SUCCESS [ 5.190 s]\n[INFO] Apache OpenNLP Tools ............................... FAILURE [01:40 min]\n[INFO] Apache OpenNLP UIMA Annotators ..................... SKIPPED\n[INFO] Apache OpenNLP Brat Annotator ...................... SKIPPED\n[INFO] Apache OpenNLP Morfologik Addon .................... SKIPPED\n[INFO] Apache OpenNLP Documentation ....................... SKIPPED\n[INFO] Apache OpenNLP Distribution ........................ SKIPPED\n[INFO] ------------------------------------------------------------------------\n[INFO] BUILD FAILURE\n[INFO] ------------------------------------------------------------------------\n[INFO] Total time: 01:46 min\n[INFO] Finished at: 2019-05-23T16:35:43+02:00\n[INFO] ------------------------------------------------------------------------\n[ERROR] Failed to execute goal org.apache.maven.plugins:maven-surefire-plugin:2.19.1:test (default-test) on project opennlp-tools: There are test failures.\n[ERROR]\n[ERROR] Please refer to C:\\Developments\\hobbies\\opennlp\\opennlp-tools\\target\\surefire-reports for the individual test results.\n[ERROR] -> [Help 1]\n[ERROR]\n[ERROR] To see the full stack trace of the errors, re-run Maven with the -e switch.\n[ERROR] Re-run Maven using the -X switch to enable full debug logging.\n[ERROR]\n[ERROR] For more information about the errors and possible solutions, please read the following articles:\n[ERROR] [Help 1] http://cwiki.apache.org/confluence/display/MAVEN/MojoFailureException\n[ERROR]\n[ERROR] After correcting the problems, you can resume the build with the command\n[ERROR] mvn <goals> -rf :opennlp-tools",
        "Issue Links": [
            "https://github.com/apache/opennlp/pull/351"
        ]
    },
    "OPENNLP-1263": {
        "Key": "OPENNLP-1263",
        "Summary": "Build Warnings due to deprecated pom.version",
        "Type": "Task",
        "Status": "Closed",
        "Priority": "Minor",
        "Resolution": "Fixed",
        "Affects Version/s": "None",
        "Fix Version/s": "1.9.2",
        "Component/s": "None",
        "Assignee": "J\u00f6rn Kottmann",
        "Reporter": "Madhawa Kasun Gunasekara",
        "Created": "24/May/19 06:38",
        "Updated": "24/May/19 10:50",
        "Resolved": "24/May/19 10:50",
        "Description": "Apache Maven 3.6.0 (97c98ec64a1fdfee7767ce5ffb20918da4f719f3; 2018-10-24T20:41:47+02:00)\nMaven home: C:\\Tools\\apache-maven-3.6.0\\bin\\..\nJava version: 1.8.0_202, vendor: Oracle Corporation, runtime: C:\\Program Files\\Java\\jdk1.8.0_202\\jre\nDefault locale: en_US, platform encoding: Cp1252\nOS name: \"windows 10\", version: \"10.0\", arch: \"amd64\", family: \"windows\"\n[INFO] Scanning for projects...\n[WARNING]\n[WARNING] Some problems were encountered while building the effective model for org.apache.opennlp:opennlp-distr:pom:1.9.2-SNAPSHOT\n[WARNING] The expression ${pom.version} is deprecated. Please use ${project.version} instead.\n[WARNING]\n[WARNING] It is highly recommended to fix these problems because they threaten the stability of your build.\n[WARNING]\n[WARNING] For this reason, future Maven versions might no longer support building such malformed projects.\n[WARNING]",
        "Issue Links": [
            "https://github.com/apache/opennlp/pull/352"
        ]
    },
    "OPENNLP-1264": {
        "Key": "OPENNLP-1264",
        "Summary": "Trivial fixes to enable building on, gasp, Windows",
        "Type": "Task",
        "Status": "Closed",
        "Priority": "Trivial",
        "Resolution": "Won't Fix",
        "Affects Version/s": "None",
        "Fix Version/s": "None",
        "Component/s": "None",
        "Assignee": "Tim Allison",
        "Reporter": "Tim Allison",
        "Created": "24/May/19 19:03",
        "Updated": "29/Mar/22 13:35",
        "Resolved": "29/Mar/22 13:35",
        "Description": "I had to change 3 things to get a clean build on Windows...I'm not sure the solutions are the most elegant, and these may be user error\n1) I had to turn off (fail on error) in style checking because of a problem w new lines. On nearly every file, I got this failure.\n\n[ERROR] src\\test\\java\\opennlp\\tools\\util\\VersionTest.java:[0] (misc) NewlineAtEndOfFile: File does not end with a newline.\r\n[WARNING] checkstyle:check violations detected but failOnViolation set to false\r\n\n\n2) LanguageDetectorEvaluatorTest#processSample fails because '\\n' are expected, but Windows, of course, writes '\\r\\n' with println\n3) I intentionally have a space in the directory structure to my IdeaProjects directory, which can cause problems on Windows when finding paths.  There are two areas where this happens.",
        "Issue Links": [
            "https://github.com/apache/opennlp/pull/354"
        ]
    },
    "OPENNLP-1265": {
        "Key": "OPENNLP-1265",
        "Summary": "Improve speed of lang detect",
        "Type": "Task",
        "Status": "Open",
        "Priority": "Major",
        "Resolution": "Unresolved",
        "Affects Version/s": "None",
        "Fix Version/s": "None",
        "Component/s": "None",
        "Assignee": "Tim Allison",
        "Reporter": "Tim Allison",
        "Created": "31/May/19 22:54",
        "Updated": "19/Jan/22 13:57",
        "Resolved": null,
        "Description": "Over on TIKA-2790, we found that opennlp's language detector is far, far slower than Optimaize and yalder.\nLet's use this ticket to see what we can do to improve lang detect's speed.",
        "Issue Links": [
            "/jira/browse/OPENNLP-1267",
            "/jira/browse/OPENNLP-1266",
            "/jira/browse/OPENNLP-1269"
        ]
    },
    "OPENNLP-1266": {
        "Key": "OPENNLP-1266",
        "Summary": "Limit normalization regexes in UrlCharSequenceNormalizer",
        "Type": "Task",
        "Status": "Open",
        "Priority": "Major",
        "Resolution": "Unresolved",
        "Affects Version/s": "None",
        "Fix Version/s": "None",
        "Component/s": "None",
        "Assignee": "Tim Allison",
        "Reporter": "Tim Allison",
        "Created": "07/Jun/19 12:54",
        "Updated": "29/Mar/22 13:10",
        "Resolved": null,
        "Description": "The MAIL_REGEX in UrlCharSequenceNormalizer is unbounded and requires backtracking.\u00a0In rare cases, this can cause eye-opening performance costs.\n\u00a0\nI tested the other regexes in the other normalizers.\u00a0 I could be wrong, but they don't appear to require backtracking, and there are no surprising performance costs.",
        "Issue Links": [
            "/jira/browse/OPENNLP-1265",
            "https://github.com/apache/opennlp/pull/355"
        ]
    },
    "OPENNLP-1267": {
        "Key": "OPENNLP-1267",
        "Summary": "Allow the LanguageDetector to stop before processing the full string",
        "Type": "Improvement",
        "Status": "Closed",
        "Priority": "Major",
        "Resolution": "Fixed",
        "Affects Version/s": "None",
        "Fix Version/s": "1.9.3",
        "Component/s": "None",
        "Assignee": "Tim Allison",
        "Reporter": "Tim Allison",
        "Created": "07/Jun/19 13:40",
        "Updated": "24/Jan/20 17:26",
        "Resolved": "24/Jan/20 17:26",
        "Description": "On TIKA-2790, I found that Yalder is stopping after computing character ngrams on roughly the first 60 characters.\u00a0 That likely explains its impressive speed.\u00a0 Let's make this \"stopping short\" feature available in OpenNLP.\n\u00a0\nIdeally, the language detector wouldn't copy the full String, it wouldn't normalize the full String, and it wouldn't compute ngrams on the full String.",
        "Issue Links": [
            "/jira/browse/OPENNLP-1265",
            "https://github.com/apache/opennlp/pull/357"
        ]
    },
    "OPENNLP-1268": {
        "Key": "OPENNLP-1268",
        "Summary": "StringUtil.toLowerCase() should lowercase codepoints, not chars",
        "Type": "Task",
        "Status": "Closed",
        "Priority": "Trivial",
        "Resolution": "Fixed",
        "Affects Version/s": "None",
        "Fix Version/s": "1.9.3",
        "Component/s": "None",
        "Assignee": "Tim Allison",
        "Reporter": "Tim Allison",
        "Created": "07/Jun/19 15:31",
        "Updated": "25/Jan/20 00:24",
        "Resolved": "25/Jan/20 00:23",
        "Description": "StringUtils#toLowerCase() should run Character.tolowerCase() on code points.  It is currently failing to lowercase characters beyond the BMP.",
        "Issue Links": [
            "https://github.com/apache/opennlp/pull/356"
        ]
    },
    "OPENNLP-1269": {
        "Key": "OPENNLP-1269",
        "Summary": "Add alternate to NGramModel that uses straight Strings rather than StringList",
        "Type": "Task",
        "Status": "Closed",
        "Priority": "Trivial",
        "Resolution": "Fixed",
        "Affects Version/s": "None",
        "Fix Version/s": "1.9.3",
        "Component/s": "None",
        "Assignee": "Jeff Zemerick",
        "Reporter": "Tim Allison",
        "Created": "07/Jun/19 18:30",
        "Updated": "25/Jan/20 20:02",
        "Resolved": "25/Jan/20 20:02",
        "Description": "On OPENNLP-1265, I found that we could halve the lang detect speed on longer documents if we didn't create a StringList for every ngram, but rather used a plain String.",
        "Issue Links": [
            "/jira/browse/OPENNLP-1261",
            "/jira/browse/OPENNLP-1265",
            "https://github.com/apache/opennlp/pull/358"
        ]
    },
    "OPENNLP-1270": {
        "Key": "OPENNLP-1270",
        "Summary": "Add new languages to the language detector",
        "Type": "Task",
        "Status": "Open",
        "Priority": "Major",
        "Resolution": "Unresolved",
        "Affects Version/s": "None",
        "Fix Version/s": "None",
        "Component/s": "None",
        "Assignee": "Tim Allison",
        "Reporter": "Tim Allison",
        "Created": "12/Jun/19 13:32",
        "Updated": "19/Jan/22 13:56",
        "Resolved": null,
        "Description": "Leipzig has several other languages that might be useful to add to the language detector.  I've selected some with > 10k sentences.  Once I build the model and evaluate performance, I'll share the reports, the model and a tgz of the *-sentences.txt files.",
        "Issue Links": [
            "/jira/browse/TIKA-3340"
        ]
    },
    "OPENNLP-1271": {
        "Key": "OPENNLP-1271",
        "Summary": "Illegal Argument Exception",
        "Type": "Bug",
        "Status": "Closed",
        "Priority": "Major",
        "Resolution": "Cannot Reproduce",
        "Affects Version/s": "None",
        "Fix Version/s": "None",
        "Component/s": "Name Finder",
        "Assignee": null,
        "Reporter": "Raza Abbas",
        "Created": "15/Aug/19 08:13",
        "Updated": "28/Jan/22 16:04",
        "Resolved": "28/Jan/22 16:03",
        "Description": "I am using this library in some production code. I am getting the following exception once in a while, so I am not being able to reproduce it exactly always.\u00a0\n\u00a0\njava.lang.IllegalArgumentException: The span [18..23) is outside the given text which has length 12!\nat opennlp.tools.util.Span.getCoveredText(Span.java:231)\nat opennlp.tools.util.Span.spansToStrings(Span.java:351)\nat opennlp.tools.tokenize.AbstractTokenizer.tokenize(AbstractTokenizer.java:25)\nat opennlp.tools.tokenize.TokenizerME.tokenize(TokenizerME.java:76)\n\u00a0\n\u00a0\nThis seems like an internal OpenNLP issue, and not how I'm using the library. Any help would be appreciated. Thanks.",
        "Issue Links": []
    },
    "OPENNLP-1272": {
        "Key": "OPENNLP-1272",
        "Summary": "Add support for Catalan and Indonesian stemmers",
        "Type": "Improvement",
        "Status": "Closed",
        "Priority": "Minor",
        "Resolution": "Fixed",
        "Affects Version/s": "None",
        "Fix Version/s": "1.9.3",
        "Component/s": "Stemmer",
        "Assignee": "Jeff Zemerick",
        "Reporter": "Vlad Ciotlausi",
        "Created": "20/Aug/19 09:18",
        "Updated": "25/Jan/20 20:01",
        "Resolved": "25/Jan/20 20:01",
        "Description": "Added Indonesian and Catalan stemmers plus some minor fixes.\n\u00a0\nThis PR includes:\n\nCreating the Java code based on the .sbl files and adding them to the stemmer folder\nUpdating relevant classes to support the\u00a0new stemmers\nAdding tests for the new stemmers\nChanging the romanian unit tests for stemmers because it didn't test a romanian word",
        "Issue Links": [
            "https://github.com/apache/opennlp/pull/363"
        ]
    },
    "OPENNLP-1273": {
        "Key": "OPENNLP-1273",
        "Summary": "Build fails on docs of OpenNLP-tools",
        "Type": "Bug",
        "Status": "Closed",
        "Priority": "Blocker",
        "Resolution": "Fixed",
        "Affects Version/s": "1.9.2",
        "Fix Version/s": "1.9.3",
        "Component/s": "None",
        "Assignee": null,
        "Reporter": "Jiri Zamecnik",
        "Created": "23/Aug/19 13:02",
        "Updated": "02/Mar/20 22:03",
        "Resolved": "02/Mar/20 22:03",
        "Description": "Build of the freshly forked repository fails at opennlp-tools. The error reported (error_report.log) is:\nExit code: 1 - javadoc: error - The code being documented uses modules but the packages defined in https://docs.oracle.com/javase/8/docs/api/ are in the unnamed module.\n\u00a0\nMight be related to: https://bugs.openjdk.java.net/browse/JDK-8212233\nApplying the fix suggested there fixes that error, but build fails later (error_report_fix.log)",
        "Issue Links": [
            "https://github.com/apache/opennlp/pull/370"
        ]
    },
    "OPENNLP-1274": {
        "Key": null,
        "Summary": null,
        "Type": null,
        "Status": null,
        "Priority": null,
        "Resolution": null,
        "Affects Version/s": null,
        "Fix Version/s": null,
        "Component/s": null,
        "Assignee": null,
        "Reporter": null,
        "Created": null,
        "Updated": null,
        "Resolved": null,
        "Description": null,
        "Issue Links": []
    },
    "OPENNLP-1275": {
        "Key": null,
        "Summary": null,
        "Type": null,
        "Status": null,
        "Priority": null,
        "Resolution": null,
        "Affects Version/s": null,
        "Fix Version/s": null,
        "Component/s": null,
        "Assignee": null,
        "Reporter": null,
        "Created": null,
        "Updated": null,
        "Resolved": null,
        "Description": null,
        "Issue Links": []
    },
    "OPENNLP-1276": {
        "Key": null,
        "Summary": null,
        "Type": null,
        "Status": null,
        "Priority": null,
        "Resolution": null,
        "Affects Version/s": null,
        "Fix Version/s": null,
        "Component/s": null,
        "Assignee": null,
        "Reporter": null,
        "Created": null,
        "Updated": null,
        "Resolved": null,
        "Description": null,
        "Issue Links": []
    },
    "OPENNLP-1277": {
        "Key": null,
        "Summary": null,
        "Type": null,
        "Status": null,
        "Priority": null,
        "Resolution": null,
        "Affects Version/s": null,
        "Fix Version/s": null,
        "Component/s": null,
        "Assignee": null,
        "Reporter": null,
        "Created": null,
        "Updated": null,
        "Resolved": null,
        "Description": null,
        "Issue Links": []
    },
    "OPENNLP-1278": {
        "Key": null,
        "Summary": null,
        "Type": null,
        "Status": null,
        "Priority": null,
        "Resolution": null,
        "Affects Version/s": null,
        "Fix Version/s": null,
        "Component/s": null,
        "Assignee": null,
        "Reporter": null,
        "Created": null,
        "Updated": null,
        "Resolved": null,
        "Description": null,
        "Issue Links": []
    },
    "OPENNLP-1279": {
        "Key": null,
        "Summary": null,
        "Type": null,
        "Status": null,
        "Priority": null,
        "Resolution": null,
        "Affects Version/s": null,
        "Fix Version/s": null,
        "Component/s": null,
        "Assignee": null,
        "Reporter": null,
        "Created": null,
        "Updated": null,
        "Resolved": null,
        "Description": null,
        "Issue Links": []
    },
    "OPENNLP-1280": {
        "Key": null,
        "Summary": null,
        "Type": null,
        "Status": null,
        "Priority": null,
        "Resolution": null,
        "Affects Version/s": null,
        "Fix Version/s": null,
        "Component/s": null,
        "Assignee": null,
        "Reporter": null,
        "Created": null,
        "Updated": null,
        "Resolved": null,
        "Description": null,
        "Issue Links": []
    },
    "OPENNLP-1281": {
        "Key": null,
        "Summary": null,
        "Type": null,
        "Status": null,
        "Priority": null,
        "Resolution": null,
        "Affects Version/s": null,
        "Fix Version/s": null,
        "Component/s": null,
        "Assignee": null,
        "Reporter": null,
        "Created": null,
        "Updated": null,
        "Resolved": null,
        "Description": null,
        "Issue Links": []
    },
    "OPENNLP-1282": {
        "Key": null,
        "Summary": null,
        "Type": null,
        "Status": null,
        "Priority": null,
        "Resolution": null,
        "Affects Version/s": null,
        "Fix Version/s": null,
        "Component/s": null,
        "Assignee": null,
        "Reporter": null,
        "Created": null,
        "Updated": null,
        "Resolved": null,
        "Description": null,
        "Issue Links": []
    },
    "OPENNLP-1283": {
        "Key": null,
        "Summary": null,
        "Type": null,
        "Status": null,
        "Priority": null,
        "Resolution": null,
        "Affects Version/s": null,
        "Fix Version/s": null,
        "Component/s": null,
        "Assignee": null,
        "Reporter": null,
        "Created": null,
        "Updated": null,
        "Resolved": null,
        "Description": null,
        "Issue Links": []
    },
    "OPENNLP-1284": {
        "Key": null,
        "Summary": null,
        "Type": null,
        "Status": null,
        "Priority": null,
        "Resolution": null,
        "Affects Version/s": null,
        "Fix Version/s": null,
        "Component/s": null,
        "Assignee": null,
        "Reporter": null,
        "Created": null,
        "Updated": null,
        "Resolved": null,
        "Description": null,
        "Issue Links": []
    },
    "OPENNLP-1285": {
        "Key": "OPENNLP-1285",
        "Summary": "Address failing regression tests on Java 11",
        "Type": "Task",
        "Status": "Closed",
        "Priority": "Major",
        "Resolution": "Fixed",
        "Affects Version/s": "1.9.2,                                            1.9.3",
        "Fix Version/s": "1.9.3",
        "Component/s": "Build, Packaging and Test",
        "Assignee": "Jeff Zemerick",
        "Reporter": "Jeff Zemerick",
        "Created": "14/Dec/19 14:29",
        "Updated": "28/Jan/22 21:46",
        "Resolved": "28/Jan/22 21:45",
        "Description": "When executing the regression tests (mvn test -DOPENNLP_DATA_DIR=/path/to/opennlp-test-data/ -Peval-tests) on Java 11, a few tests fail:\nFailed tests: \n ArvoresDeitadasEval.evalPortugueseChunkerQn:212->chunkerCrossEval:141 expected:<0.9648211936491359> but was:<0.9650171248355313>\n Conll02NameFinderEval.evalSpanishMiscMaxentQn:505->eval:83 expected:<0.470219435736677> but was:<0.4733542319749216>\n Conll02NameFinderEval.evalSpanishOrganizationMaxentQn:421->eval:83 expected:<0.682961897915169> but was:<0.67005444646098>\n ConllXPosTaggerEval.evalSwedishMaxentQn:208->eval:80 expected:<0.9347595473833098> but was:<0.9349363507779349>\nEnvironment details:\nApache Maven 3.6.0\nMaven home: /usr/share/maven\nJava version: 11.0.4, vendor: Ubuntu, runtime: /usr/lib/jvm/java-11-openjdk-amd64\nDefault locale: en_US, platform encoding: UTF-8\nOS name: \"linux\", version: \"5.0.0-37-generic\", arch: \"amd64\", family: \"unix\"",
        "Issue Links": []
    },
    "OPENNLP-1286": {
        "Key": "OPENNLP-1286",
        "Summary": "Updating from 1.7.0 to 1.9.1 breaks",
        "Type": "Bug",
        "Status": "Closed",
        "Priority": "Major",
        "Resolution": "Not A Problem",
        "Affects Version/s": "1.8.0,                                            1.8.1,                                            1.8.2,                                            1.8.3,                                            1.8.4",
        "Fix Version/s": "None",
        "Component/s": "None",
        "Assignee": null,
        "Reporter": "xia0c",
        "Created": "16/Dec/19 17:25",
        "Updated": "02/Jun/20 14:39",
        "Resolved": "02/Jun/20 14:39",
        "Description": "When I try to upgrade Opennlp-tools from 1.7.0 to the version after 1.8.0. The following code breaks.\n\n\r\nimport java.io.FileInputStream;\r\nimport java.io.FileNotFoundException;\r\nimport java.io.IOException;\r\nimport java.io.InputStream;\r\nimport java.nio.file.Paths;\r\n\r\nimport org.junit.Test;\r\n\r\nimport opennlp.tools.doccat.DoccatModel;\r\nimport opennlp.tools.doccat.DocumentCategorizerME;\r\n\r\npublic class TestOpenNLP {\r\n\t\t\r\n\t@Test\r\n\tpublic void demo() throws FileNotFoundException {\r\n\t\tclassify(\"test\");\r\n\t}\r\n\t\r\n\tpublic void classify(String summary) throws FileNotFoundException {\r\n\t\t\r\n\t\t\r\n\t\tString bin = \"/pt-leis.bin\";\r\n\t\tInputStream inputStrean = null;\r\n\t\ttry {\t\t\r\n\t\t\tinputStrean = new FileInputStream(Paths.get(bin).toFile());\r\n\t\t\tDoccatModel doccatModel = new DoccatModel(inputStrean);\r\n\t\t\tDocumentCategorizerME myCategorizer = new DocumentCategorizerME(doccatModel);\r\n\t\t\tdouble[] outcomes = myCategorizer.categorize(summary);\r\n\t\t\tString category = myCategorizer.getBestCategory(outcomes);\r\n\t\t\t} catch (IOException e) {\r\n\t\t\t\tSystem.out.println(e);\r\n\t\t} \r\n\t}\r\n}\r\n\n\nThe code should pass, but it throws an error:\n\n\r\nincompatible types: java.lang.String cannot be converted to java.lang.String[]",
        "Issue Links": []
    },
    "OPENNLP-1287": {
        "Key": "OPENNLP-1287",
        "Summary": "Fix Jenkins build",
        "Type": "Task",
        "Status": "Closed",
        "Priority": "Minor",
        "Resolution": "Won't Fix",
        "Affects Version/s": "1.9.1,                                            1.9.2",
        "Fix Version/s": "None",
        "Component/s": "Build, Packaging and Test",
        "Assignee": "Jeff Zemerick",
        "Reporter": "Jeff Zemerick",
        "Created": "22/Dec/19 14:49",
        "Updated": "28/Jan/22 21:45",
        "Resolved": "28/Jan/22 21:45",
        "Description": "The Jenkins build is failing:\nStarted by timer\nRunning as SYSTEM\nNo JDK named \u2018JDK 1.8.0_131\u2019 found",
        "Issue Links": []
    },
    "OPENNLP-1288": {
        "Key": null,
        "Summary": null,
        "Type": null,
        "Status": null,
        "Priority": null,
        "Resolution": null,
        "Affects Version/s": null,
        "Fix Version/s": null,
        "Component/s": null,
        "Assignee": null,
        "Reporter": null,
        "Created": null,
        "Updated": null,
        "Resolved": null,
        "Description": null,
        "Issue Links": []
    },
    "OPENNLP-1289": {
        "Key": null,
        "Summary": null,
        "Type": null,
        "Status": null,
        "Priority": null,
        "Resolution": null,
        "Affects Version/s": null,
        "Fix Version/s": null,
        "Component/s": null,
        "Assignee": null,
        "Reporter": null,
        "Created": null,
        "Updated": null,
        "Resolved": null,
        "Description": null,
        "Issue Links": []
    },
    "OPENNLP-1290": {
        "Key": null,
        "Summary": null,
        "Type": null,
        "Status": null,
        "Priority": null,
        "Resolution": null,
        "Affects Version/s": null,
        "Fix Version/s": null,
        "Component/s": null,
        "Assignee": null,
        "Reporter": null,
        "Created": null,
        "Updated": null,
        "Resolved": null,
        "Description": null,
        "Issue Links": []
    },
    "OPENNLP-1291": {
        "Key": null,
        "Summary": null,
        "Type": null,
        "Status": null,
        "Priority": null,
        "Resolution": null,
        "Affects Version/s": null,
        "Fix Version/s": null,
        "Component/s": null,
        "Assignee": null,
        "Reporter": null,
        "Created": null,
        "Updated": null,
        "Resolved": null,
        "Description": null,
        "Issue Links": []
    },
    "OPENNLP-1292": {
        "Key": null,
        "Summary": null,
        "Type": null,
        "Status": null,
        "Priority": null,
        "Resolution": null,
        "Affects Version/s": null,
        "Fix Version/s": null,
        "Component/s": null,
        "Assignee": null,
        "Reporter": null,
        "Created": null,
        "Updated": null,
        "Resolved": null,
        "Description": null,
        "Issue Links": []
    },
    "OPENNLP-1293": {
        "Key": null,
        "Summary": null,
        "Type": null,
        "Status": null,
        "Priority": null,
        "Resolution": null,
        "Affects Version/s": null,
        "Fix Version/s": null,
        "Component/s": null,
        "Assignee": null,
        "Reporter": null,
        "Created": null,
        "Updated": null,
        "Resolved": null,
        "Description": null,
        "Issue Links": []
    },
    "OPENNLP-1294": {
        "Key": null,
        "Summary": null,
        "Type": null,
        "Status": null,
        "Priority": null,
        "Resolution": null,
        "Affects Version/s": null,
        "Fix Version/s": null,
        "Component/s": null,
        "Assignee": null,
        "Reporter": null,
        "Created": null,
        "Updated": null,
        "Resolved": null,
        "Description": null,
        "Issue Links": []
    },
    "OPENNLP-1295": {
        "Key": null,
        "Summary": null,
        "Type": null,
        "Status": null,
        "Priority": null,
        "Resolution": null,
        "Affects Version/s": null,
        "Fix Version/s": null,
        "Component/s": null,
        "Assignee": null,
        "Reporter": null,
        "Created": null,
        "Updated": null,
        "Resolved": null,
        "Description": null,
        "Issue Links": []
    },
    "OPENNLP-1296": {
        "Key": null,
        "Summary": null,
        "Type": null,
        "Status": null,
        "Priority": null,
        "Resolution": null,
        "Affects Version/s": null,
        "Fix Version/s": null,
        "Component/s": null,
        "Assignee": null,
        "Reporter": null,
        "Created": null,
        "Updated": null,
        "Resolved": null,
        "Description": null,
        "Issue Links": []
    },
    "OPENNLP-1297": {
        "Key": null,
        "Summary": null,
        "Type": null,
        "Status": null,
        "Priority": null,
        "Resolution": null,
        "Affects Version/s": null,
        "Fix Version/s": null,
        "Component/s": null,
        "Assignee": null,
        "Reporter": null,
        "Created": null,
        "Updated": null,
        "Resolved": null,
        "Description": null,
        "Issue Links": []
    },
    "OPENNLP-1298": {
        "Key": null,
        "Summary": null,
        "Type": null,
        "Status": null,
        "Priority": null,
        "Resolution": null,
        "Affects Version/s": null,
        "Fix Version/s": null,
        "Component/s": null,
        "Assignee": null,
        "Reporter": null,
        "Created": null,
        "Updated": null,
        "Resolved": null,
        "Description": null,
        "Issue Links": []
    },
    "OPENNLP-1299": {
        "Key": "OPENNLP-1299",
        "Summary": "Use https for accessing Maven central",
        "Type": "Task",
        "Status": "Closed",
        "Priority": "Major",
        "Resolution": "Fixed",
        "Affects Version/s": "None",
        "Fix Version/s": "1.9.3",
        "Component/s": "Build, Packaging and Test",
        "Assignee": "Jeff Zemerick",
        "Reporter": "Jeff Zemerick",
        "Created": "19/Feb/20 13:39",
        "Updated": "19/Feb/20 14:06",
        "Resolved": "19/Feb/20 13:42",
        "Description": "Use https for accessing Maven central.",
        "Issue Links": [
            "https://github.com/apache/opennlp/pull/371"
        ]
    },
    "OPENNLP-1300": {
        "Key": "OPENNLP-1300",
        "Summary": "Some dependencies contain CVEs",
        "Type": "Dependency upgrade",
        "Status": "Closed",
        "Priority": "Major",
        "Resolution": "Fixed",
        "Affects Version/s": "None",
        "Fix Version/s": "1.9.3",
        "Component/s": "None",
        "Assignee": "Jeff Zemerick",
        "Reporter": "XuCongying",
        "Created": "01/Mar/20 13:26",
        "Updated": "02/Jun/20 14:31",
        "Resolved": "02/Jun/20 14:31",
        "Description": "Hi, I noticed that your project are using vulnerable libraries which are related to some CVEs. To prevent potential security risks it may cause, I suggest to update the library dependency. Here is the details:\nVulnerable Library Version: org.apache.uima : uimaj-core : 2.3.1\n  CVE ID: [CVE-2017-15691](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2017-15691)\n  Import Path: opennlp-uima/pom.xml\n  Suggested Safe Versions: 2.10.2, 2.10.3, 2.10.4, 3.0.0, 3.0.0-beta, 3.0.1, 3.0.2, 3.1.0, 3.1.1",
        "Issue Links": [
            "https://github.com/apache/opennlp/pull/372"
        ]
    },
    "OPENNLP-1301": {
        "Key": "OPENNLP-1301",
        "Summary": "Update dependency versions",
        "Type": "Task",
        "Status": "Closed",
        "Priority": "Major",
        "Resolution": "Fixed",
        "Affects Version/s": "None",
        "Fix Version/s": "1.9.3",
        "Component/s": "Build, Packaging and Test",
        "Assignee": "Jeff Zemerick",
        "Reporter": "Jeff Zemerick",
        "Created": "06/Mar/20 13:07",
        "Updated": "28/Jan/22 21:33",
        "Resolved": "28/Jan/22 21:33",
        "Description": "There are quite a few dependencies that have newer versions. See about updating them.",
        "Issue Links": [
            "https://github.com/apache/opennlp/pull/373"
        ]
    },
    "OPENNLP-1302": {
        "Key": "OPENNLP-1302",
        "Summary": "Javadoc",
        "Type": "Documentation",
        "Status": "Resolved",
        "Priority": "Trivial",
        "Resolution": "Fixed",
        "Affects Version/s": "1.9.2",
        "Fix Version/s": "1.9.2",
        "Component/s": "Documentation",
        "Assignee": null,
        "Reporter": "Jongwoo Jeon",
        "Created": "09/Apr/20 03:38",
        "Updated": "16/May/20 08:58",
        "Resolved": "10/Apr/20 07:52",
        "Description": "Hi, I've noticed that in\u00a0[opennlp github|https://github.com/apache/opennlp/tree/master/opennlp-uima/src/main/java/opennlp/uima/normalizer], Normalizer.java and StringDictionary.java seem to miss @param and @return tags for documentation. The other file, NumberUtil.java, seems to have these tags. Just wondering if these tags were omitted on purpose.",
        "Issue Links": [
            "https://github.com/apache/opennlp/pull/374",
            "https://github.com/apache/opennlp/pull/374"
        ]
    },
    "OPENNLP-1303": {
        "Key": "OPENNLP-1303",
        "Summary": "Unable to build opennlp",
        "Type": "Bug",
        "Status": "Closed",
        "Priority": null,
        "Resolution": "Fixed",
        "Affects Version/s": "None",
        "Fix Version/s": "1.9.3",
        "Component/s": "None",
        "Assignee": "Peter Thygesen",
        "Reporter": "Peter Thygesen",
        "Created": "01/May/20 19:51",
        "Updated": "02/Jun/20 14:30",
        "Resolved": "02/Jun/20 14:30",
        "Description": "cloned opennlp\nran mvn clean install with a jdk8 and maven 3.3.9 (according to README)\n[*ERROR*] Failed to execute goal org.apache.maven.plugins:maven-javadoc-plugin:3.1.1:jar (create-javadoc-jar) on project opennlp-tools: MavenReportException: Error while generating Javadoc:\u00a0\n[*ERROR*] Exit code: 1 - /Users/thygesen/Projects/apache/test/opennlp/opennlp-tools/src/main/java/opennlp/tools/lemmatizer/DictionaryLemmatizer.java:55: warning: no @throws for java.io.IOException\nQuick analysis show that the pom.xml line:\n<additionalparam>-Xdoclint:none</additionalparam>\nin the javadoc plugin should be:\n<doclint>none</doclint>",
        "Issue Links": []
    },
    "OPENNLP-1304": {
        "Key": "OPENNLP-1304",
        "Summary": "NullPointerException in LemmatizerME",
        "Type": "Bug",
        "Status": "Closed",
        "Priority": "Major",
        "Resolution": "Cannot Reproduce",
        "Affects Version/s": "1.9.2",
        "Fix Version/s": "None",
        "Component/s": "Lemmatizer",
        "Assignee": null,
        "Reporter": "Markus Jelsma",
        "Created": "15/May/20 16:02",
        "Updated": "03/Jun/20 08:16",
        "Resolved": "02/Jun/20 14:29",
        "Description": "In our unit tests we have a basic lemmatizer model for Japanese. The Lemmatizer throws:\n\n\r\njava.lang.NullPointerException\r\n        at opennlp.tools.lemmatizer.LemmatizerME.predictSES(LemmatizerME.java:116)\r\n        at opennlp.tools.lemmatizer.LemmatizerME.lemmatize(LemmatizerME.java:91) \n\nfor the following input:\n\n\r\ntokens: \u30c7\u30f3, \u30fb, \u30d8\u30eb\u30c7\u30eb\r\ntags: PROPN, SYM, PROPN \n\nI attached the used lemmatizer model in case if needed.",
        "Issue Links": []
    },
    "OPENNLP-1305": {
        "Key": "OPENNLP-1305",
        "Summary": "Disable DTD loading for LetsmtDocument",
        "Type": "Task",
        "Status": "Closed",
        "Priority": "Major",
        "Resolution": "Fixed",
        "Affects Version/s": "1.9.2",
        "Fix Version/s": "1.9.3",
        "Component/s": "None",
        "Assignee": "Jeff Zemerick",
        "Reporter": "Jeff Zemerick",
        "Created": "01/Jun/20 16:50",
        "Updated": "02/Jun/20 11:43",
        "Resolved": "02/Jun/20 11:43",
        "Description": "Disable DTD loading for LetsmtDocument.",
        "Issue Links": []
    },
    "OPENNLP-1306": {
        "Key": "OPENNLP-1306",
        "Summary": "NameSample overlap exception not helpful",
        "Type": "Improvement",
        "Status": "Closed",
        "Priority": "Major",
        "Resolution": "Fixed",
        "Affects Version/s": "1.9.2",
        "Fix Version/s": "2.0.0",
        "Component/s": "Name Finder",
        "Assignee": null,
        "Reporter": "Markus Jelsma",
        "Created": "06/Aug/20 11:04",
        "Updated": "07/Jun/22 11:57",
        "Resolved": "07/Jun/22 11:57",
        "Description": "I got this for some very large training file.\n\n\r\n         Computing event counts...  Exception in thread \"main\" java.lang.RuntimeException: name spans [27..29) person and [27..27) person are overlapped in file: null\r\n        at opennlp.tools.namefind.NameSample.<init>(NameSample.java:79)\r\n        at opennlp.tools.namefind.NameSample.<init>(NameSample.java:97)\r\n        at opennlp.tools.namefind.NameSample.<init>(NameSample.java:101)\r\n\n\nWith this exception it is impossible to track the error if you have a large training file.\n\u00a0\nExceptions about mismatching <START:> and <END> tags at least give a little bit of context. This patch adds the sentence parts to the exception, making it simple to grep the training file for the bad sentence.",
        "Issue Links": []
    },
    "OPENNLP-1307": {
        "Key": "OPENNLP-1307",
        "Summary": "Incorrect code example for Document Categorization (9.3)",
        "Type": "Documentation",
        "Status": "Closed",
        "Priority": "Major",
        "Resolution": "Fixed",
        "Affects Version/s": "1.9.3",
        "Fix Version/s": "2.1.1",
        "Component/s": "Doccat",
        "Assignee": "Martin Wiesner",
        "Reporter": "John Slocum",
        "Created": "25/Aug/20 18:10",
        "Updated": "10/Dec/22 14:20",
        "Resolved": "10/Dec/22 14:20",
        "Description": "in https://opennlp.apache.org/docs/1.9.3/manual/opennlp.html#tools.doccat.classifying.api,\nthe code example feeds a String into DocumentCategorizerME.categorize(). The method itself takes an array. I flagged priority as Major because this was a killer - obviously it's a self-documenting bug when you run it, but I made the mistake of assuming that the array actually needed would be an array of documents - instead it needs to be an array of tokens from a single document, i.e. one needs to split() the doc on whitespace. Lost 24 hours experimenting with algos (maxent vs. naive_bayes) and params (cutoff, iterations, etc) before figuring this one out.\n\u00a0\nCurrent(wrong) version:\n\u00a0\n\n\r\nString inputText = ...\r\nDocumentCategorizerME myCategorizer = new DocumentCategorizerME(m);\r\ndouble[] outcomes = myCategorizer.categorize(inputText);\r\nString category = myCategorizer.getBestCategory(outcomes);\r\n\n\n\u00a0\nShould be more like:\n\u00a0\n\n\r\nString inputText = ... // sanitized document to be categorized\r\nDocumentCategorizerME myCategorizer = new DocumentCategorizerME(m);\r\ndouble[] outcomes = myCategorizer.categorize(inputText.split(\" \");\r\nString category = myCategorizer.getBestCategory(outcomes);",
        "Issue Links": []
    },
    "OPENNLP-1308": {
        "Key": "OPENNLP-1308",
        "Summary": "Incorrect code snippet in Name Finder Training -> Training Api",
        "Type": "Documentation",
        "Status": "Resolved",
        "Priority": "Trivial",
        "Resolution": "Fixed",
        "Affects Version/s": "None",
        "Fix Version/s": "1.9.4",
        "Component/s": "None",
        "Assignee": null,
        "Reporter": "Mikalai Dudko",
        "Created": "28/Aug/20 19:17",
        "Updated": "08/Oct/21 22:49",
        "Resolved": "23/Sep/20 18:37",
        "Description": "Manual -> Name Finder Training -> Training Api section ->\u00a0TokenNameFinderFactory and modelOut\n\n\r\nObjectStream<String> lineStream =\r\n\t\tnew PlainTextByLineStream(new FileInputStream(\"en-ner-person.train\"), StandardCharsets.UTF_8);\r\n\r\nTokenNameFinderModel model;\r\n\r\ntry (ObjectStream<NameSample> sampleStream = new NameSampleDataStream(lineStream)) {\r\n  model = NameFinderME.train(\"en\", \"person\", sampleStream, TrainingParameters.defaultParams(),\r\n            TokenNameFinderFactory nameFinderFactory);\r\n}\r\n\r\ntry (modelOut = new BufferedOutputStream(new FileOutputStream(modelFile)){\r\n  model.serialize(modelOut);\r\n}",
        "Issue Links": []
    },
    "OPENNLP-1309": {
        "Key": "OPENNLP-1309",
        "Summary": "NameFinderME - Unexpected result using unchanged training data",
        "Type": "Bug",
        "Status": "Closed",
        "Priority": "Major",
        "Resolution": "Not A Bug",
        "Affects Version/s": "1.9.2",
        "Fix Version/s": "None",
        "Component/s": "Name Finder",
        "Assignee": null,
        "Reporter": "Michael",
        "Created": "23/Sep/20 19:47",
        "Updated": "02/Oct/20 16:55",
        "Resolved": "02/Oct/20 16:55",
        "Description": "Hello,\nBased on NameFinderMETest.java\u00a0/ function testNameFinder(), I have written a simple test code and changed the test sentence\n from (1):\n\n\r\nString[] sentence = {\"Alisa\",\r\n \"appreciated\",\r\n \"the\",\r\n \"hint\",\r\n \"and\",\r\n \"enjoyed\",\r\n \"a\",\r\n \"delicious\",\r\n \"traditional\",\r\n \"meal.\"};\r\n\n\nto (2):\n\n\r\nString[] sentence = {\"Alisa\",\r\n \"and\",\r\n \"Mike\",\r\n \"appreciated\",\r\n \"the\",\r\n \"hint\",\r\n \"and\",\r\n \"enjoyed\",\r\n \"a\",\r\n \"delicious\",\r\n \"traditional\",\r\n \"meal.\"};\r\n\n\n(Just added \"and Mike\") and expected to get 2 results (two names Alisa and Mike) because both names are annotated in the training data. I just get 1 result (Mike) for (2). I used the training data file\u00a0AnnotatedSentences.txt\u00a0\u00a0(unchanged).\nCan anyone tell me what's wrong? Thanks.\nTest code:\n\u00a0\n\n\r\nString trainingDatafilePath = \"opennlp/tools/namefind/AnnotatedSentences.txt\";\r\nString encoding = \"ISO-8859-1\";\r\n ObjectStream<NameSample> sampleStream = new NameSampleDataStream(new PlainTextByLineStream(new MarkableFileInputStreamFactory(new File(trainingDatafilePath+\"AnnotatedSentences.txt\")), encoding));\r\n \r\n TrainingParameters params = new TrainingParameters();\r\n params.put(TrainingParameters.ITERATIONS_PARAM, 70);\r\n params.put(TrainingParameters.CUTOFF_PARAM, 1);\r\nTokenNameFinderModel nameFinderModel = NameFinderME.train(\"eng\", null, sampleStream,\r\n params, TokenNameFinderFactory.create(null, null, Collections.emptyMap(), new BioCodec()));\r\nTokenNameFinder nameFinder = new NameFinderME(nameFinderModel);\r\n// now test if it can detect the sample sentences\r\n String[] sentence = {\"Alisa\",\r\n \"and\",\r\n \"Mike\",\r\n \"appreciated\",\r\n \"the\",\r\n \"hint\",\r\n \"and\",\r\n \"enjoyed\",\r\n \"a\",\r\n \"delicious\",\r\n \"traditional\",\r\n \"meal.\"};\r\nSpan[] names = nameFinder.find(sentence);\r\n if (names != null && names.length != 0) {\r\n System.out.println(\" > Found [\"+names.length+\"] results\");\r\n for(Span name : names){\r\n String personName=\"\";\r\n for(int i=name.getStart(); i<name.getEnd(); i++){\r\n personName+=sentence[i]+\" \";\r\n }\r\n System.out.println(\" > Result \"+1+\": Type: [\"+name.getType()+\"] : PersonName: [\"+personName+\"]\\t [probability=\"+name.getProb()+\"]\");\r\n }\r\n } else {\r\n System.out.println(\" > No results found\");\r\n }\r\n\n\n\u00a0\n\u00a0\nResult for (1):\nIndexing events with TwoPass using cutoff of 1\n Computing event counts... done. 1392 events\n Indexing... done.\n Collecting events... Done indexing in 0.22 s.\n Incorporating indexed data for training... \n done.\n Number of Event Tokens: 1392\n Number of Outcomes: 3\n Number of Predicates: 9164\n Computing model parameters...\n Performing 70 iterations.\n 1: . (1355/1392) 0.9734195402298851\n 2: . (1383/1392) 0.9935344827586207\n 3: . (1390/1392) 0.9985632183908046\n 4: . (1390/1392) 0.9985632183908046\n 5: . (1391/1392) 0.9992816091954023\n 6: . (1392/1392) 1.0\n 7: . (1392/1392) 1.0\n 8: . (1392/1392) 1.0\n 9: . (1392/1392) 1.0\n Stopping: change in training set accuracy less than 1.0E-5\n Stats: (1392/1392) 1.0\n ...done.\nFound [1] results\nResult 1: Type: [default] : PersonName: [Alisa ] [probability=0.5483001511243855]\n\u00a0\nResult for (2):\nIndexing events with TwoPass using cutoff of 1\n Computing event counts... done. 1392 events\n Indexing... done.\n Collecting events... Done indexing in 0.22 s.\n Incorporating indexed data for training... \n done.\n Number of Event Tokens: 1392\n Number of Outcomes: 3\n Number of Predicates: 9164\n Computing model parameters...\n Performing 70 iterations.\n 1: . (1355/1392) 0.9734195402298851\n 2: . (1383/1392) 0.9935344827586207\n 3: . (1390/1392) 0.9985632183908046\n 4: . (1390/1392) 0.9985632183908046\n 5: . (1391/1392) 0.9992816091954023\n 6: . (1392/1392) 1.0\n 7: . (1392/1392) 1.0\n 8: . (1392/1392) 1.0\n 9: . (1392/1392) 1.0\n Stopping: change in training set accuracy less than 1.0E-5\n Stats: (1392/1392) 1.0\n ...done.\nFound [1] results\nResult 1: Type: [default] : PersonName: [Mike ] [probability=0.460685209028902]",
        "Issue Links": []
    },
    "OPENNLP-1310": {
        "Key": "OPENNLP-1310",
        "Summary": "Add unit test for WhitespaceTokenStream",
        "Type": "Test",
        "Status": "Closed",
        "Priority": "Minor",
        "Resolution": "Fixed",
        "Affects Version/s": "None",
        "Fix Version/s": "1.9.4",
        "Component/s": "Tokenizer",
        "Assignee": null,
        "Reporter": "Alan Wang",
        "Created": "29/Oct/20 02:00",
        "Updated": "05/Nov/20 12:33",
        "Resolved": "05/Nov/20 12:33",
        "Description": "test if it can tokenize whitespace separated and the split chars tokens.",
        "Issue Links": []
    },
    "OPENNLP-1311": {
        "Key": "OPENNLP-1311",
        "Summary": "Replace try-finally with try-with-resources.",
        "Type": "Improvement",
        "Status": "Resolved",
        "Priority": "Major",
        "Resolution": "Fixed",
        "Affects Version/s": "None",
        "Fix Version/s": "1.9.4",
        "Component/s": "None",
        "Assignee": null,
        "Reporter": "Alan Wang",
        "Created": "05/Nov/20 07:39",
        "Updated": "08/Oct/21 22:49",
        "Resolved": "26/Nov/20 09:01",
        "Description": "We can use try-with-resources to ensure that resources will be closed, simplify the code.",
        "Issue Links": []
    },
    "OPENNLP-1312": {
        "Key": "OPENNLP-1312",
        "Summary": "Custom TokenNameFinder result is not valid",
        "Type": "Question",
        "Status": "Closed",
        "Priority": "Major",
        "Resolution": "Feedback Received",
        "Affects Version/s": "1.9.3",
        "Fix Version/s": "None",
        "Component/s": "Name Finder",
        "Assignee": null,
        "Reporter": "Yoonhee Park",
        "Created": "09/Nov/20 06:43",
        "Updated": "16/Dec/22 12:27",
        "Resolved": "16/Dec/22 12:27",
        "Description": "If I run TokenNameFinderEvaluator after creating a custom model,\u00a0 evaluation F1 is 100%.\nbut if I test(TokenNameFinder) a document used for training and evaluation, the entity is not tagged.\n\u00a0\n\u00a0\n % opennlp.bat\u00a0TokenNameFinderEvaluator\u00a0-model\u00a0test_model.bin\u00a0-data\u00a0eval.data\n Evaluated 5 samples with 1 entities; found: 1 entities; correct: 1.\n TOTAL: precision: 100.00%; recall: 100.00%; F1: 100.00%.\n micro: precision: 100.00%; recall: 100.00%; F1: 100.00%.\u00a0[target: 1; tp: 1; fp: 0]%\u00a0\n \u00a0\n \u00a0\n % opennlp.bat\u00a0TokenNameFinder test_model.bin\u00a0<\u00a0test.txt\n >>> Not Tagged Result\n How do I fix this issue?",
        "Issue Links": []
    },
    "OPENNLP-1313": {
        "Key": "OPENNLP-1313",
        "Summary": "loops improved in opennlp-tools",
        "Type": "Improvement",
        "Status": "Resolved",
        "Priority": "Minor",
        "Resolution": "Fixed",
        "Affects Version/s": "None",
        "Fix Version/s": "1.9.4",
        "Component/s": "None",
        "Assignee": null,
        "Reporter": "Alan Wang",
        "Created": "12/Nov/20 07:49",
        "Updated": "08/Oct/21 22:49",
        "Resolved": "26/Nov/20 09:03",
        "Description": "use for-each loops to improve code readability",
        "Issue Links": []
    },
    "OPENNLP-1314": {
        "Key": "OPENNLP-1314",
        "Summary": "ConlluWordLine to print line contents when throwing format error",
        "Type": "Improvement",
        "Status": "Resolved",
        "Priority": "Trivial",
        "Resolution": "Fixed",
        "Affects Version/s": "1.9.3",
        "Fix Version/s": "2.1.0",
        "Component/s": "Formats",
        "Assignee": "Martin Wiesner",
        "Reporter": "Markus Jelsma",
        "Created": "17/Nov/20 15:21",
        "Updated": "09/Dec/22 18:41",
        "Resolved": "09/Dec/22 18:40",
        "Description": "Exception thrown for edit/formatting errors is not helpful in debugging. This tiny patch makes my day much easier.",
        "Issue Links": [
            "/jira/browse/OPENNLP-1372"
        ]
    },
    "OPENNLP-1315": {
        "Key": "OPENNLP-1315",
        "Summary": "Remove unnecessary call to \"toString()\"",
        "Type": "Improvement",
        "Status": "Resolved",
        "Priority": "Minor",
        "Resolution": "Fixed",
        "Affects Version/s": "None",
        "Fix Version/s": "1.9.4",
        "Component/s": "None",
        "Assignee": null,
        "Reporter": "Alan Wang",
        "Created": "20/Nov/20 09:28",
        "Updated": "08/Oct/21 22:49",
        "Resolved": "26/Nov/20 09:04",
        "Description": null,
        "Issue Links": []
    },
    "OPENNLP-1316": {
        "Key": "OPENNLP-1316",
        "Summary": "Expand common contractions in the english language",
        "Type": "Question",
        "Status": "Open",
        "Priority": "Minor",
        "Resolution": "Unresolved",
        "Affects Version/s": "None",
        "Fix Version/s": "None",
        "Component/s": "None",
        "Assignee": null,
        "Reporter": "Alan Wang",
        "Created": "30/Nov/20 12:16",
        "Updated": "26/Feb/23 14:59",
        "Resolved": null,
        "Description": "Hi, I want to know if OPENNLP needs to expand contractions.\ni.g.\u00a0n't\u00a0 -> not, 've\u00a0 -> have, 'm\u00a0 -> am, but 's can be extended to is\u00a0or has, 'd\u00a0can be extended to had\u00a0or\u00a0would, depending on the context.\n1\u3001Use POSTag to mark contractions to determine which extension is to be used.\n2\u3001Like nltk, extend only some contractions that are not ambiguous.\nThanks!",
        "Issue Links": []
    },
    "OPENNLP-1317": {
        "Key": "OPENNLP-1317",
        "Summary": "'if' and 'return' statement can be simplified",
        "Type": "Improvement",
        "Status": "Resolved",
        "Priority": "Minor",
        "Resolution": "Fixed",
        "Affects Version/s": "None",
        "Fix Version/s": "1.9.4",
        "Component/s": "None",
        "Assignee": null,
        "Reporter": "Alan Wang",
        "Created": "03/Dec/20 07:48",
        "Updated": "08/Oct/21 22:49",
        "Resolved": "24/Dec/20 12:27",
        "Description": null,
        "Issue Links": []
    },
    "OPENNLP-1318": {
        "Key": "OPENNLP-1318",
        "Summary": "Add ability to download models from within OpenNLP",
        "Type": "Task",
        "Status": "Closed",
        "Priority": "Major",
        "Resolution": "Fixed",
        "Affects Version/s": "None",
        "Fix Version/s": "2.0.0",
        "Component/s": "None",
        "Assignee": "Jeff Zemerick",
        "Reporter": "Jeff Zemerick",
        "Created": "03/Dec/20 14:07",
        "Updated": "07/Jun/22 11:57",
        "Resolved": "07/Jun/22 11:57",
        "Description": "Add ability to download models from within OpenNLP.",
        "Issue Links": []
    },
    "OPENNLP-1319": {
        "Key": "OPENNLP-1319",
        "Summary": "The Training API code is outdated in Manual",
        "Type": "Documentation",
        "Status": "Closed",
        "Priority": "Major",
        "Resolution": "Fixed",
        "Affects Version/s": "None",
        "Fix Version/s": "2.0.0",
        "Component/s": "None",
        "Assignee": null,
        "Reporter": "Alan Wang",
        "Created": "11/Dec/20 08:50",
        "Updated": "09/Dec/22 18:13",
        "Resolved": "07/Jun/22 11:58",
        "Description": "POSModel model = null;\r\n\r\ntry (InputStream dataIn = new FileInputStream(\"en-pos.train\")){\r\n  ObjectStream<String> lineStream = new PlainTextByLineStream(dataIn, StandardCharsets.UTF_8);\r\n  ObjectStream<POSSample> sampleStream = new WordTagSampleStream(lineStream);\r\n\r\n  model = POSTaggerME.train(\"en\", sampleStream, TrainingParameters.defaultParams(), null, null);\r\n}\r\n\n\n1\u3001PlainTextByLineStream use InputStreamFactory now.\n2\u3001Update parameters of the train method.",
        "Issue Links": [
            "/jira/browse/OPENNLP-1347",
            "/jira/browse/OPENNLP-1237"
        ]
    },
    "OPENNLP-1320": {
        "Key": "OPENNLP-1320",
        "Summary": "Makes lemmatize of MorfologikLemmatizer thread-safe",
        "Type": "Bug",
        "Status": "Closed",
        "Priority": "Major",
        "Resolution": "Fixed",
        "Affects Version/s": "None",
        "Fix Version/s": "2.1.1",
        "Component/s": "None",
        "Assignee": "Richard Zowalla",
        "Reporter": "Lucas Avan\u00e7o",
        "Created": "14/Dec/20 12:58",
        "Updated": "23/Nov/22 14:35",
        "Resolved": "23/Nov/22 14:33",
        "Description": "The method lemmatize of MorfologikLemmatizer is not thread-safe.\nConcurrent invokes may rise exceptions and return unpredictable resutls.\nIt seems that the whole method must be sync because the variable returned by the morfologik lib is shared between threads.",
        "Issue Links": []
    },
    "OPENNLP-1321": {
        "Key": "OPENNLP-1321",
        "Summary": "Use LinkedHashMap for deterministic iteration order",
        "Type": "Improvement",
        "Status": "Closed",
        "Priority": "Minor",
        "Resolution": "Done",
        "Affects Version/s": "None",
        "Fix Version/s": "1.9.4",
        "Component/s": "None",
        "Assignee": null,
        "Reporter": "Yi-Lin Wang",
        "Created": "19/Dec/20 22:09",
        "Updated": "20/Dec/20 13:45",
        "Resolved": "20/Dec/20 13:45",
        "Description": "The test\u00a0opennlp.tools.ml.naivebayes.NaiveBayesSerializedCorrectnessTest#testPlainTextModel\u00a0can fail due to a different iteration order of HashMap. The error message is as follows:\n\u00a0\n{{[ERROR] testPlainTextModel(opennlp.tools.ml.naivebayes.NaiveBayesSerializedCorrectnessTest)  Time elapsed: 0.01 s  <<< FAILURE!\norg.junit.ComparisonFailure:\nexpected:<...ports\n...}}\nThe fix is to change HaskMap to LinkedHashMap so that the iteration order remains stable and the failure will not occur any more. In this way, the test will be more stable.",
        "Issue Links": []
    },
    "OPENNLP-1322": {
        "Key": "OPENNLP-1322",
        "Summary": "Simplify some code of List",
        "Type": "Improvement",
        "Status": "Closed",
        "Priority": "Minor",
        "Resolution": "Fixed",
        "Affects Version/s": "None",
        "Fix Version/s": "1.9.4",
        "Component/s": "None",
        "Assignee": null,
        "Reporter": "Alan Wang",
        "Created": "24/Dec/20 12:23",
        "Updated": "28/Jan/22 21:43",
        "Resolved": "28/Jan/22 21:43",
        "Description": null,
        "Issue Links": []
    },
    "OPENNLP-1323": {
        "Key": "OPENNLP-1323",
        "Summary": "Test Failure",
        "Type": "Bug",
        "Status": "Closed",
        "Priority": "Major",
        "Resolution": "Not A Problem",
        "Affects Version/s": "None",
        "Fix Version/s": "None",
        "Component/s": "Build, Packaging and Test",
        "Assignee": null,
        "Reporter": "Soodeh",
        "Created": "26/Dec/20 23:33",
        "Updated": "21/Mar/22 15:03",
        "Resolved": "21/Mar/22 15:03",
        "Description": "Hi,\u00a0\nI have generated tests for \"Opennlp tools\" classes using Evosuite (version 1.0.6)framework but when I run generated tests I have this failure (full trace):\n<testcase name*=\"test04\" ** classname=\"opennlp.tools.formats.brat.AnnotationConfiguration_ESTest\" ** time=\"0.012\">*\n\u00a0 \u00a0 <failure message*=\"Exception was not thrown in org.evosuite.runtime.mock.java.io.MockFileInputStream but in java.io.FilePermission.init(FilePermission.java:191): java.lang.NullPointerException: name can't be null\" ** type=\"java.lang.AssertionError\"><![CDATA[*java.lang.AssertionError: Exception was not thrown in org.evosuite.runtime.mock.java.io.MockFileInputStream but in java.io.FilePermission.init(FilePermission.java:191): java.lang.NullPointerException: name can't be null\nat org.evosuite.runtime.EvoAssertions.assertThrownBy(EvoAssertions.java:112)\nat org.evosuite.runtime.EvoAssertions.verifyException(EvoAssertions.java:49)\nat opennlp.tools.formats.brat.AnnotationConfiguration_ESTest.test04(AnnotationConfiguration_ESTest.java:91)\nat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\nat java.lang.reflect.Method.invoke(Method.java:498)\nat org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:50)\nat org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)\nat org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:47)\nat org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)\nat org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:298)\nat org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:292)\nat java.util.concurrent.FutureTask.run(FutureTask.java:266)\nat java.lang.Thread.run(Thread.java:748)\n]]></failure>\n\u00a0\nAnd this is the generated test:\n@Test(timeout = 4000)\npublic void test04() throws Throwable {\n try \n{ \r\n AnnotationConfiguration.parse((File) null);\r\n fail(\"Expecting exception: NullPointerException\");\r\n \r\n }\n catch(NullPointerException e) \n{\r\n //\r\n // no message in exception (getMessage() returned null)\r\n //\r\n verifyException(\"org.evosuite.runtime.mock.java.io.MockFileInputStream\", e);\r\n }\n}\n\u00a0\nThanks.",
        "Issue Links": []
    },
    "OPENNLP-1324": {
        "Key": "OPENNLP-1324",
        "Summary": "Train models on Universal Dependencies",
        "Type": "Task",
        "Status": "Closed",
        "Priority": "Major",
        "Resolution": "Done",
        "Affects Version/s": "None",
        "Fix Version/s": "1.9.3",
        "Component/s": "None",
        "Assignee": "Jeff Zemerick",
        "Reporter": "Jeff Zemerick",
        "Created": "05/Jan/21 16:54",
        "Updated": "07/Jun/21 20:07",
        "Resolved": "07/Jun/21 20:07",
        "Description": "Train models on Universal Dependencies.",
        "Issue Links": []
    },
    "OPENNLP-1325": {
        "Key": "OPENNLP-1325",
        "Summary": "'if' replaceable with 'switch'",
        "Type": "Improvement",
        "Status": "Closed",
        "Priority": "Minor",
        "Resolution": "Fixed",
        "Affects Version/s": "None",
        "Fix Version/s": "1.9.4",
        "Component/s": "None",
        "Assignee": null,
        "Reporter": "Alan Wang",
        "Created": "03/Feb/21 07:17",
        "Updated": "28/Jan/22 21:42",
        "Resolved": "28/Jan/22 21:42",
        "Description": null,
        "Issue Links": []
    },
    "OPENNLP-1326": {
        "Key": "OPENNLP-1326",
        "Summary": "build failed on AArch64, Fedora 33, Java 11",
        "Type": "Bug",
        "Status": "Closed",
        "Priority": "Major",
        "Resolution": "Not A Bug",
        "Affects Version/s": "None",
        "Fix Version/s": "None",
        "Component/s": "None",
        "Assignee": "Jeff Zemerick",
        "Reporter": "Lutz Weischer",
        "Created": "08/Feb/21 10:48",
        "Updated": "12/Feb/21 14:50",
        "Resolved": "12/Feb/21 14:50",
        "Description": "current GitHub master \n... \n[INFO] \u2014 maven-bundle-plugin:4.2.1:install (default-install) @ opennlp-tools \u2014\n[INFO] Installing org/apache/opennlp/opennlp-tools/1.9.4-SNAPSHOT/opennlp-tools-1.9.4-SNAPSHOT.jar\n[INFO] Writing OBR metadata\n[INFO]\n[INFO] -----------------< org.apache.opennlp:opennlp-uima >------------------\n[INFO] Building Apache OpenNLP UIMA Annotators 1.9.4-SNAPSHOT             [3/7]\n[INFO] -------------------------------[ jar ]--------------------------------\nDownloading from central: https://repo.maven.apache.org/maven2/org/apache/maven/plugins/maven-dependency-plugin/2.1/maven-dependency-plugin-2.1.pom\nDownloaded from central: https://repo.maven.apache.org/maven2/org/apache/maven/plugins/maven-dependency-plugin/2.1/maven-dependency-plugin-2.1.pom (8.1 kB at 95 kB/s)\nDownloading from central: https://repo.maven.apache.org/maven2/org/apache/maven/plugins/maven-dependency-plugin/2.1/maven-dependency-plugin-2.1.jar\nDownloaded from central: https://repo.maven.apache.org/maven2/org/apache/maven/plugins/maven-dependency-plugin/2.1/maven-dependency-plugin-2.1.jar (106 kB at 752 kB/s)\nDownloading from ApacheIncubatorRepository: http://people.apache.org/repo/m2-incubating-repository/org/apache/uima/uimaj-core/3.1.1/uimaj-core-3.1.1.pom\nDownloading from apache.snapshots: https://repository.apache.org/snapshots/org/apache/uima/uimaj-core/3.1.1/uimaj-core-3.1.1.pom\nDownloading from central: https://repo.maven.apache.org/maven2/org/apache/uima/uimaj-core/3.1.1/uimaj-core-3.1.1.pom\nDownloaded from central: https://repo.maven.apache.org/maven2/org/apache/uima/uimaj-core/3.1.1/uimaj-core-3.1.1.pom (14 kB at 15 kB/s)\nDownloading from ApacheIncubatorRepository: http://people.apache.org/repo/m2-incubating-repository/org/apache/uima/uimaj-parent/3.1.1/uimaj-parent-3.1.1.pom\nDownloading from apache.snapshots: https://repository.apache.org/snapshots/org/apache/uima/uimaj-parent/3.1.1/uimaj-parent-3.1.1.pom\nDownloading from central: https://repo.maven.apache.org/maven2/org/apache/uima/uimaj-parent/3.1.1/uimaj-parent-3.1.1.pom\nDownloaded from central: https://repo.maven.apache.org/maven2/org/apache/uima/uimaj-parent/3.1.1/uimaj-parent-3.1.1.pom (17 kB at 68 kB/s)\nDownloading from ApacheIncubatorRepository: http://people.apache.org/repo/m2-incubating-repository/org/apache/uima/parent-pom/13/parent-pom-13.pom\nDownloading from apache.snapshots: https://repository.apache.org/snapshots/org/apache/uima/parent-pom/13/parent-pom-13.pom\nDownloading from central: https://repo.maven.apache.org/maven2/org/apache/uima/parent-pom/13/parent-pom-13.pom\nDownloaded from central: https://repo.maven.apache.org/maven2/org/apache/uima/parent-pom/13/parent-pom-13.pom (139 kB at 114 kB/s)\nDownloading from ApacheIncubatorRepository: http://people.apache.org/repo/m2-incubating-repository/org/bitbucket/mstrobel/procyon-compilertools/0.5.32/procyon-compilertools-0.5.32.pom\nDownloading from apache.snapshots: https://repository.apache.org/snapshots/org/bitbucket/mstrobel/procyon-compilertools/0.5.32/procyon-compilertools-0.5.32.pom\nDownloading from central: https://repo.maven.apache.org/maven2/org/bitbucket/mstrobel/procyon-compilertools/0.5.32/procyon-compilertools-0.5.32.pom\nDownloaded from central: https://repo.maven.apache.org/maven2/org/bitbucket/mstrobel/procyon-compilertools/0.5.32/procyon-compilertools-0.5.32.pom (2.1 kB at 2.8 kB/s)\nDownloading from ApacheIncubatorRepository: http://people.apache.org/repo/m2-incubating-repository/org/bitbucket/mstrobel/procyon-core/0.5.32/procyon-core-0.5.32.pom\nDownloading from apache.snapshots: https://repository.apache.org/snapshots/org/bitbucket/mstrobel/procyon-core/0.5.32/procyon-core-0.5.32.pom\nDownloading from central: https://repo.maven.apache.org/maven2/org/bitbucket/mstrobel/procyon-core/0.5.32/procyon-core-0.5.32.pom\nDownloaded from central: https://repo.maven.apache.org/maven2/org/bitbucket/mstrobel/procyon-core/0.5.32/procyon-core-0.5.32.pom (1.7 kB at 34 kB/s)\nDownloading from ApacheIncubatorRepository: http://people.apache.org/repo/m2-incubating-repository/com/sun/xml/bind/jaxb-impl/2.3.1/jaxb-impl-2.3.1.pom\nDownloading from apache.snapshots: https://repository.apache.org/snapshots/com/sun/xml/bind/jaxb-impl/2.3.1/jaxb-impl-2.3.1.pom\nDownloading from central: https://repo.maven.apache.org/maven2/com/sun/xml/bind/jaxb-impl/2.3.1/jaxb-impl-2.3.1.pom\nDownloaded from central: https://repo.maven.apache.org/maven2/com/sun/xml/bind/jaxb-impl/2.3.1/jaxb-impl-2.3.1.pom (15 kB at 25 kB/s)\nDownloading from ApacheIncubatorRepository: http://people.apache.org/repo/m2-incubating-repository/com/sun/xml/bind/mvn/jaxb-bundles/2.3.1/jaxb-bundles-2.3.1.pom\nDownloading from apache.snapshots: https://repository.apache.org/snapshots/com/sun/xml/bind/mvn/jaxb-bundles/2.3.1/jaxb-bundles-2.3.1.pom\nDownloading from central: https://repo.maven.apache.org/maven2/com/sun/xml/bind/mvn/jaxb-bundles/2.3.1/jaxb-bundles-2.3.1.pom\nDownloaded from central: https://repo.maven.apache.org/maven2/com/sun/xml/bind/mvn/jaxb-bundles/2.3.1/jaxb-bundles-2.3.1.pom (2.9 kB at 1.7 kB/s)\nDownloading from ApacheIncubatorRepository: http://people.apache.org/repo/m2-incubating-repository/org/apache/uima/uimaj-core/3.1.1/uimaj-core-3.1.1.jar\nDownloading from ApacheIncubatorRepository: http://people.apache.org/repo/m2-incubating-repository/org/apache/opennlp/opennlp-tools/1.9.4-SNAPSHOT/opennlp-tools-1.9.4-SNAPSHOT-tests.jar\nDownloading from ApacheIncubatorRepository: http://people.apache.org/repo/m2-incubating-repository/com/sun/xml/bind/jaxb-impl/2.3.1/jaxb-impl-2.3.1.jar\nDownloading from ApacheIncubatorRepository: http://people.apache.org/repo/m2-incubating-repository/org/bitbucket/mstrobel/procyon-core/0.5.32/procyon-core-0.5.32.jar\nDownloading from ApacheIncubatorRepository: http://people.apache.org/repo/m2-incubating-repository/org/bitbucket/mstrobel/procyon-compilertools/0.5.32/procyon-compilertools-0.5.32.jar\nDownloading from apache.snapshots: https://repository.apache.org/snapshots/org/apache/uima/uimaj-core/3.1.1/uimaj-core-3.1.1.jar\nDownloading from apache.snapshots: https://repository.apache.org/snapshots/com/sun/xml/bind/jaxb-impl/2.3.1/jaxb-impl-2.3.1.jar\nDownloading from apache.snapshots: https://repository.apache.org/snapshots/org/bitbucket/mstrobel/procyon-core/0.5.32/procyon-core-0.5.32.jar\nDownloading from apache.snapshots: https://repository.apache.org/snapshots/org/bitbucket/mstrobel/procyon-compilertools/0.5.32/procyon-compilertools-0.5.32.jar\nDownloading from apache.snapshots: https://repository.apache.org/snapshots/org/apache/opennlp/opennlp-tools/1.9.4-SNAPSHOT/opennlp-tools-1.9.4-SNAPSHOT-tests.jar\nDownloading from central: https://repo.maven.apache.org/maven2/org/apache/uima/uimaj-core/3.1.1/uimaj-core-3.1.1.jar\nDownloading from central: https://repo.maven.apache.org/maven2/com/sun/xml/bind/jaxb-impl/2.3.1/jaxb-impl-2.3.1.jar\nDownloading from central: https://repo.maven.apache.org/maven2/org/bitbucket/mstrobel/procyon-core/0.5.32/procyon-core-0.5.32.jar\nDownloading from central: https://repo.maven.apache.org/maven2/org/bitbucket/mstrobel/procyon-compilertools/0.5.32/procyon-compilertools-0.5.32.jar\nDownloaded from central: https://repo.maven.apache.org/maven2/org/bitbucket/mstrobel/procyon-core/0.5.32/procyon-core-0.5.32.jar (191 kB at 95 kB/s)\nDownloaded from central: https://repo.maven.apache.org/maven2/com/sun/xml/bind/jaxb-impl/2.3.1/jaxb-impl-2.3.1.jar (1.1 MB at 68 kB/s)\nDownloaded from central: https://repo.maven.apache.org/maven2/org/apache/uima/uimaj-core/3.1.1/uimaj-core-3.1.1.jar (1.8 MB at 81 kB/s)\nDownloaded from central: https://repo.maven.apache.org/maven2/org/bitbucket/mstrobel/procyon-compilertools/0.5.32/procyon-compilertools-0.5.32.jar (1.5 MB at 59 kB/s)\n[INFO] ------------------------------------------------------------------------\n[INFO] Reactor Summary for Apache OpenNLP Reactor 1.9.4-SNAPSHOT:\n[INFO]\n[INFO] Apache OpenNLP Reactor ............................. SUCCESS [ 42.258 s]\n[INFO] Apache OpenNLP Tools ............................... SUCCESS [01:48 min]\n[INFO] Apache OpenNLP UIMA Annotators ..................... FAILURE [ 36.936 s]\n[INFO] Apache OpenNLP Brat Annotator ...................... SKIPPED\n[INFO] Apache OpenNLP Morfologik Addon .................... SKIPPED\n[INFO] Apache OpenNLP Documentation ....................... SKIPPED\n[INFO] Apache OpenNLP Distribution ........................ SKIPPED\n[INFO] ------------------------------------------------------------------------\n[INFO] BUILD FAILURE\n[INFO] ------------------------------------------------------------------------\n[INFO] Total time:  03:11 min\n[INFO] Finished at: 2021-02-08T11:38:57+01:00\n[INFO] ------------------------------------------------------------------------\n[ERROR] Failed to execute goal on project opennlp-uima: Could not resolve dependencies for project org.apache.opennlp:opennlp-uima:jar:1.9.4-SNAPSHOT: Could not find artifact org.apache.opennlp:opennlp-tools:jar:tests:1.9.4-SNAPSHOT in ApacheIncubatorRepository (http://people.apache.org/repo/m2-incubating-repository/) -> [Help 1]\n[ERROR]\n[ERROR] To see the full stack trace of the errors, re-run Maven with the -e switch.\n[ERROR] Re-run Maven using the -X switch to enable full debug logging.\n[ERROR]\n[ERROR] For more information about the errors and possible solutions, please read the following articles:\n[ERROR] [Help 1] http://cwiki.apache.org/confluence/display/MAVEN/DependencyResolutionException\n[ERROR]\n[ERROR] After correcting the problems, you can resume the build with the command\n[ERROR]   mvn <args> -rf :opennlp-uima\n[jw@cn06 opennlp]$",
        "Issue Links": []
    },
    "OPENNLP-1327": {
        "Key": "OPENNLP-1327",
        "Summary": "Add site .asf.yaml file",
        "Type": "Improvement",
        "Status": "Resolved",
        "Priority": "Minor",
        "Resolution": "Fixed",
        "Affects Version/s": "1.9.3",
        "Fix Version/s": "1.9.4",
        "Component/s": "Website",
        "Assignee": "Bruno P. Kinoshita",
        "Reporter": "Bruno P. Kinoshita",
        "Created": "18/Feb/21 18:13",
        "Updated": "20/Feb/21 04:23",
        "Resolved": "20/Feb/21 04:22",
        "Description": "Placeholder for https://github.com/apache/opennlp-site/pull/64",
        "Issue Links": []
    },
    "OPENNLP-1328": {
        "Key": "OPENNLP-1328",
        "Summary": "Document model release process on the website",
        "Type": "Task",
        "Status": "Resolved",
        "Priority": "Major",
        "Resolution": "Duplicate",
        "Affects Version/s": "None",
        "Fix Version/s": "None",
        "Component/s": "Documentation,                                            Website",
        "Assignee": "Jeff Zemerick",
        "Reporter": "Jeff Zemerick",
        "Created": "15/Mar/21 22:18",
        "Updated": "02/Jan/23 19:29",
        "Resolved": "02/Jan/23 19:29",
        "Description": "Document model release process on the website. Include how to sign, hash, and prepare the model files for a release vote.",
        "Issue Links": [
            "/jira/browse/OPENNLP-1433"
        ]
    },
    "OPENNLP-1329": {
        "Key": "OPENNLP-1329",
        "Summary": "Publish website using .asf.yaml",
        "Type": "Task",
        "Status": "Closed",
        "Priority": "Major",
        "Resolution": "Done",
        "Affects Version/s": "None",
        "Fix Version/s": "None",
        "Component/s": "Website",
        "Assignee": "Jeff Zemerick",
        "Reporter": "Jeff Zemerick",
        "Created": "31/May/21 15:40",
        "Updated": "28/Jan/22 16:05",
        "Resolved": "28/Jan/22 16:05",
        "Description": "Publish website using .asf.yaml.\nSee example: https://github.com/apache/infrastructure-website/blob/asf-site/.asf.yaml\nMore info: https://cwiki.apache.org/confluence/display/INFRA/Git+-+.asf.yaml+features#Git.asf.yamlfeatures-WebSiteDeploymentServiceforGitRepositories",
        "Issue Links": []
    },
    "OPENNLP-1330": {
        "Key": "OPENNLP-1330",
        "Summary": "Parser top k parses doesn't show \"top\" (highest probability) parses.",
        "Type": "Bug",
        "Status": "Closed",
        "Priority": "Minor",
        "Resolution": "Fixed",
        "Affects Version/s": "1.9.3",
        "Fix Version/s": "1.9.4",
        "Component/s": "Parser",
        "Assignee": null,
        "Reporter": "Eric Ihli",
        "Created": "10/Jun/21 05:10",
        "Updated": "23/Jun/21 12:37",
        "Resolved": "23/Jun/21 12:36",
        "Description": "The default \"top n parses\" of 1 shows the most likely parse; one with a log prob of -2.9.\nPassing in anything greater than 1 returns the least probable parses.\n\n\r\n\u279c bin git:(master) echo \"Eric is testing.\" | ./opennlp Parser -k 1 ~/src/prhyme/resources/models/en-parser-chunking.bin\r\nLoading Parser model ... done (2.515s)\r\n0 -2.913239374955309 (TOP (S (NP (NNP Eric)) (VP (VBZ is)) (. testing.)))\r\n\r\nAverage: 41.7 sent/s\r\nTotal: 1 sent\r\nRuntime: 0.024s\r\nExecution time: 2.585 seconds\r\n\u279c bin git:(master) echo \"Eric is testing.\" | ./opennlp Parser -k 2 ~/src/prhyme/resources/models/en-parser-chunking.bin\r\nLoading Parser model ... done (2.578s)\r\n0 -14.968552218782305 (TOP (S (NP (NNP Eric)) (SBAR (S (ADVP (VBZ is)) (VBG testing.)))))\r\n1 -13.957766393572408 (TOP (S (SBAR (S (NP (NNP Eric)) (ADVP (VBZ is)))) (VBG testing.)))\r\n\r\nAverage: 95.2 sent/s\r\nTotal: 2 sent\r\nRuntime: 0.021s\r\nExecution time: 2.640 seconds\r\n\r\n\n\n\u00a0The fix is clear and simple. We should be taking from the first of the TreeSet rather than from the end.\n\n\r\n\r\n else if (numParses == 1) {\r\n return new Parse[] {completeParses.first()};\r\n }\r\n else {\r\n List<Parse> topParses = new ArrayList<>(numParses);\r\n while (!completeParses.isEmpty() && topParses.size() < numParses) {\r\n Parse tp = completeParses.last();      //// <--- Change to .first()\r\n completeParses.remove(tp);\r\n topParses.add(tp);\r\n //parses.remove(tp);\r\n }\r\n return topParses.toArray(new Parse[topParses.size()]);\r\n }\n\nAfter patch, results are what I expect.\n\u00a0\n\n\r\n\u279c bin git:(master) \u2717 echo \"Eric is testing.\" | ./opennlp Parser -k 1 ~/src/prhyme/resources/models/en-parser-chunking.bin\r\nLoading Parser model ... done (2.517s)\r\n0 -2.913239374955309 (TOP (S (NP (NNP Eric)) (VP (VBZ is)) (. testing.)))\r\n\r\nAverage: 45.5 sent/s\r\nTotal: 1 sent\r\nRuntime: 0.022s\r\nExecution time: 2.580 seconds\r\n\u279c bin git:(master) \u2717 echo \"Eric is testing.\" | ./opennlp Parser -k 2 ~/src/prhyme/resources/models/en-parser-chunking.bin\r\nLoading Parser model ... done (2.530s)\r\n0 -2.913239374955309 (TOP (S (NP (NNP Eric)) (VP (VBZ is)) (. testing.)))\r\n1 -3.1132674983145825 (TOP (S (NP (NNP Eric)) (VP (VBZ is) (NP (NN testing.)))))\r\n\r\nAverage: 90.9 sent/s\r\nTotal: 2 sent\r\nRuntime: 0.022s\r\nExecution time: 2.596 seconds",
        "Issue Links": []
    },
    "OPENNLP-1331": {
        "Key": "OPENNLP-1331",
        "Summary": "Refactor interfaces to opennlp-commons project",
        "Type": "Task",
        "Status": "Closed",
        "Priority": "Major",
        "Resolution": "Won't Fix",
        "Affects Version/s": "1.9.3",
        "Fix Version/s": "None",
        "Component/s": "None",
        "Assignee": "Jeff Zemerick",
        "Reporter": "Jeff Zemerick",
        "Created": "14/Jun/21 14:32",
        "Updated": "02/Apr/22 19:26",
        "Resolved": "02/Apr/22 19:26",
        "Description": "Refactor interfaces to opennlp-commons project.",
        "Issue Links": []
    },
    "OPENNLP-1332": {
        "Key": "OPENNLP-1332",
        "Summary": "Default chunker context generator has inconsistent format",
        "Type": "Improvement",
        "Status": "Closed",
        "Priority": "Minor",
        "Resolution": "Fixed",
        "Affects Version/s": "None",
        "Fix Version/s": "2.1.1",
        "Component/s": "None",
        "Assignee": "Bruno P. Kinoshita",
        "Reporter": "Stephen Foster",
        "Created": "17/Jun/21 21:17",
        "Updated": "30/Jan/23 21:23",
        "Resolved": "30/Nov/22 14:56",
        "Description": "In DefaultChunkerContextGenerator, when p_2 is assigned on line 56, it follows a different format from every other assignment:\n\n\r\np_2\u00a0=\u00a0\"p_2\"\u00a0+\u00a0preds[i\u00a0-\u00a02];\r\n\n\nThe \"p_2\" is missing an equals sign - to be consistent it should read:\n\n\r\np_2\u00a0=\u00a0\"p_2=\"\u00a0+\u00a0preds[i\u00a0-\u00a02];\r\n\n\nApologies if this is a known issue - I did a brief search but didn't see anything.",
        "Issue Links": [
            "/jira/browse/OPENNLP-1459"
        ]
    },
    "OPENNLP-1333": {
        "Key": "OPENNLP-1333",
        "Summary": "Write unit test for parser top \"k\" parses",
        "Type": "Test",
        "Status": "Closed",
        "Priority": "Major",
        "Resolution": "Fixed",
        "Affects Version/s": "1.9.3",
        "Fix Version/s": "2.2.0",
        "Component/s": "Build, Packaging and Test,                                            Parser",
        "Assignee": "Martin Wiesner",
        "Reporter": "Jeff Zemerick",
        "Created": "23/Jun/21 12:33",
        "Updated": "22/Apr/23 17:39",
        "Resolved": "04/Mar/23 20:44",
        "Description": "In OPENNLP-1330 the order of the parser's top \"k\" parses was being returned in the opposite order. A unit test is needed. See the discussion on the pull request at https://github.com/apache/opennlp/pull/392\u00a0for more information.",
        "Issue Links": []
    },
    "OPENNLP-1334": {
        "Key": "OPENNLP-1334",
        "Summary": "Maven Apache OpenNLP error with opennlp-distr installation",
        "Type": "Bug",
        "Status": "Closed",
        "Priority": "Major",
        "Resolution": "Duplicate",
        "Affects Version/s": "None",
        "Fix Version/s": "None",
        "Component/s": "None",
        "Assignee": "Jeff Zemerick",
        "Reporter": "Samuel Boaknin",
        "Created": "12/Jul/21 16:16",
        "Updated": "21/Mar/22 13:32",
        "Resolved": "21/Mar/22 13:32",
        "Description": "I am trying to install openNLP via maven. I had a few errors, but I fixed all of them, until I got this error here:\n\n\r\n[INFO] Building Apache OpenNLP Distribution 1.9.3                         [7/7]\r\n[INFO] --------------------------------[ pom ]---------------------------------\r\n[INFO]\r\n[INFO] --- maven-enforcer-plugin:3.0.0-M2:enforce (enforce-java) @ opennlp-distr ---\r\n[INFO]\r\n[INFO] --- forbiddenapis:2.7:check (default) @ opennlp-distr ---\r\n[INFO] Skipping execution for packaging \"pom\"\r\n[INFO]\r\n[INFO] --- forbiddenapis:2.7:testCheck (default) @ opennlp-distr ---\r\n[INFO] Skipping execution for packaging \"pom\"\r\n[INFO]\r\n[INFO] --- maven-checkstyle-plugin:2.17:check (validate) @ opennlp-distr ---\r\n[INFO] Starting audit...\r\nAudit done.\r\n[INFO]\r\n[INFO] --- markdown-page-generator-plugin:1.0.0:generate (default) @ opennlp-distr ---\r\n[INFO] Using 'UTF-8' encoding to copy filtered resources.\r\n[INFO] Copying 11982 resources\r\n[INFO] Pre-processing markdown files from input directory: C:\\apache-opennlp-1.9.3-src\\opennlp-distr\\target\\filtered-md\r\n[INFO] Process Pegdown extension options\r\n[INFO] Parse Markdown to HTML\r\n[INFO] ------------------------------------------------------------------------\r\n[INFO] Reactor Summary for Apache OpenNLP Reactor 1.9.3:\r\n[INFO]\r\n[INFO] Apache OpenNLP Reactor ............................. SUCCESS [ 14.373 s]\r\n[INFO] Apache OpenNLP Tools ............................... SUCCESS [01:33 min]\r\n[INFO] Apache OpenNLP UIMA Annotators ..................... SUCCESS [ 10.563 s]\r\n[INFO] Apache OpenNLP Brat Annotator ...................... SUCCESS [ 12.244 s]\r\n[INFO] Apache OpenNLP Morfologik Addon .................... SUCCESS [  5.673 s]\r\n[INFO] Apache OpenNLP Documentation ....................... SUCCESS [  2.429 s]\r\n[INFO] Apache OpenNLP Distribution ........................ FAILURE [01:41 min]\r\n[INFO] ------------------------------------------------------------------------\r\n[INFO] BUILD FAILURE\r\n[INFO] ------------------------------------------------------------------------\r\n[INFO] Total time:  04:04 min\r\n[INFO] Finished at: 2021-07-12T12:13:25-04:00\r\n[INFO] ------------------------------------------------------------------------\r\n[ERROR] Failed to execute goal com.ruleoftech:markdown-page-generator-plugin:1.0.0:generate (default) on project opennlp-distr: Execution default of goal com.ruleoftech:markdown-page-generator-plugin:1.0.0:generate failed: Error creating extended parser class: Could not determine whether class 'org.pegdown.Parser$$parboiled' has already been loaded: Unable to make protected final java.lang.Class java.lang.ClassLoader.findLoadedClass(java.lang.String) accessible: module java.base does not \"opens java.lang\" to unnamed module @121c16d8 -> [Help 1]\r\n[ERROR]\r\n[ERROR] To see the full stack trace of the errors, re-run Maven with the -e switch.\r\n[ERROR] Re-run Maven using the -X switch to enable full debug logging.\r\n[ERROR]\r\n[ERROR] For more information about the errors and possible solutions, please read the following articles:\r\n[ERROR] [Help 1] http://cwiki.apache.org/confluence/display/MAVEN/PluginExecutionException\r\n[ERROR]\r\n[ERROR] After correcting the problems, you can resume the build with the command\r\n[ERROR]   mvn <args> -rf :opennlp-distr\r\n\n\nI looked online to try to find what to make of it, but I couldn't turn up anything. I followed the help link that was referenced (found here), but it wasn't very helpful. I read through the error, but I don't have an idea as to how to debug it or fix it. Any ideas?\n\u00a0\nEDIT: I'm attaching a debug log below; It goes on for a while, so I' snippeted what I found interesting...",
        "Issue Links": [
            "/jira/browse/OPENNLP-1359",
            "/jira/browse/OPENNLP-1359"
        ]
    },
    "OPENNLP-1335": {
        "Key": "OPENNLP-1335",
        "Summary": "Correct the spelling mistakens in the document of \"src\\docbkx\\chunker.xml\".",
        "Type": "Improvement",
        "Status": "Closed",
        "Priority": "Trivial",
        "Resolution": "Fixed",
        "Affects Version/s": "1.9.4",
        "Fix Version/s": "1.9.4",
        "Component/s": "Documentation",
        "Assignee": null,
        "Reporter": "Gongmingwang",
        "Created": "12/Aug/21 07:59",
        "Updated": "12/Aug/21 12:33",
        "Resolved": "12/Aug/21 11:16",
        "Description": "I have found some spelling mistakens in the document of \"src\\docbkx\\chunker.xml\" as follows.\n1. The proper noun \"English\" is written as \"english.\". The first letter of the word \"English\" should be capitalized.\n2. In line 77, the words \"an other\" should be corrected as \"another\".\n3. In line 78, the words \"its\" should be corrected as \"it is\".\n4. In line 148, the words \"ne\" should be corrected as \"new\".\n5. In line 153, the words \"that\" should be corrected as \"which\".\n6. In line 155, the words \"train\" should be corrected as \"training\".\n7. In line 255, the words \"built in\" should be corrected as \"built-in\".\n8. In line 282, the words \"he\" should be corrected as \"The\".",
        "Issue Links": []
    },
    "OPENNLP-1336": {
        "Key": "OPENNLP-1336",
        "Summary": "Correct the spelling mistakens in the document of \"src\\docbkx\\postagger.xml\".",
        "Type": "Improvement",
        "Status": "Closed",
        "Priority": "Trivial",
        "Resolution": "Fixed",
        "Affects Version/s": "1.9.4",
        "Fix Version/s": "1.9.4",
        "Component/s": "Documentation,                                            POS Tagger",
        "Assignee": null,
        "Reporter": "Wanggongming",
        "Created": "16/Aug/21 08:22",
        "Updated": "26/Aug/21 05:06",
        "Resolved": "26/Aug/21 05:06",
        "Description": "I have found some spelling mistakes in the document of \"src\\docbkx\\ postagger.xml\" as follows.\n1. The proper noun \"English\" is written as \"english.\". The first letter of the word \"English\" should be capitalized.\n2. In line 53, the words \"the POS Tagger\" should be corrected as \"The POS Tagger \".\n3. In line 68, the words \"an other\" should be corrected as \"another\".\n4. In line 69, the words \"its\" should be corrected as \"it is\".\n5. In line 235, the words \"in a xml\" should be corrected as \"in an xml\".\n6. In line 248, the words \"built in\" should be corrected as \"built-in\".\n7. In line 270, the words \"to cross validate a\" should be corrected as \"for cross-validation of the\".",
        "Issue Links": []
    },
    "OPENNLP-1337": {
        "Key": "OPENNLP-1337",
        "Summary": "Correct the spelling mistakens in the document of \"src\\docbkx\\postagger.xml\".",
        "Type": "Improvement",
        "Status": "Closed",
        "Priority": "Trivial",
        "Resolution": "Fixed",
        "Affects Version/s": "1.9.4",
        "Fix Version/s": "1.9.4",
        "Component/s": "Documentation,                                            POS Tagger",
        "Assignee": null,
        "Reporter": "Wanggongming",
        "Created": "16/Aug/21 08:23",
        "Updated": "08/Feb/22 14:15",
        "Resolved": "08/Feb/22 14:15",
        "Description": "I have found some spelling mistakes in the document of \"src\\docbkx\\ postagger.xml\" as follows.\n1. The proper noun \"English\" is written as \"english.\". The first letter of the word \"English\" should be capitalized.\n2. In line 53, the words \"the POS Tagger\" should be corrected as \"The POS Tagger \".\n3. In line 68, the words \"an other\" should be corrected as \"another\".\n4. In line 69, the words \"its\" should be corrected as \"it is\".\n5. In line 235, the words \"in a xml\" should be corrected as \"in an xml\".\n6. In line 248, the words \"built in\" should be corrected as \"built-in\".\n7. In line 270, the words \"to cross validate a\" should be corrected as \"for cross-validation of the\".",
        "Issue Links": []
    },
    "OPENNLP-1338": {
        "Key": "OPENNLP-1338",
        "Summary": "Refactor DummyNameFinder to improve test logic",
        "Type": "Improvement",
        "Status": "Closed",
        "Priority": "Minor",
        "Resolution": "Fixed",
        "Affects Version/s": "None",
        "Fix Version/s": "1.9.4",
        "Component/s": "None",
        "Assignee": null,
        "Reporter": "Xiao Wang",
        "Created": "19/Sep/21 19:39",
        "Updated": "08/Oct/21 22:14",
        "Resolved": "08/Oct/21 22:14",
        "Description": "Description\nI noticed that there is a test class DummyNameFinder implements production interface TokenNameFinder to assist testing  Evaluator.evaluateSample(NameSample). This might not be the best priactice in unit testing and can be improved by leveraging mocking frameworks.\nCurrent Implementation\n\nDummyNameFinder implements TokenNameFinder and overrides methods to return fixed object for find().\nIn test case, the child test class is used to assit testing by passing as a parameter to contructor of TokenNameFinderEvaluator.\n\nProposed Implementation\n\nReplace DummyNameFinder with a mocking object created by Mockito.\nUse method stub to control the behavior of find().\nCreate a method to return the mocking object for reusing.\n\nMotivation\n\nDecouple test class DummyNameFinder from production interface TokenNameFinder.\nRemove the redundant test child class PrintingVisitor\nRemove the redundant overridden methods clearAdaptiveData()\nMake testing logic more explict.\n\nMore Thought\n\nWe can further improve the testing logic by creating mock object inside of the test case and only stub find(String[]) method.",
        "Issue Links": []
    },
    "OPENNLP-1339": {
        "Key": "OPENNLP-1339",
        "Summary": "Refactor StoringStatusListener to improve test logic",
        "Type": "Improvement",
        "Status": "Closed",
        "Priority": "Minor",
        "Resolution": "Invalid",
        "Affects Version/s": "None",
        "Fix Version/s": "None",
        "Component/s": "None",
        "Assignee": null,
        "Reporter": "Xiao Wang",
        "Created": "21/Sep/21 05:53",
        "Updated": "21/Sep/21 06:08",
        "Resolved": "21/Sep/21 06:08",
        "Description": "Description\nI noticed that there is a test class StoringStatusListener implements production interface StatusListener to assist testing  PluginBuilder.build(). This might not be the best priactice in unit testing and can be improved by leveraging mocking frameworks.\nCurrent Implementation\n\nStoringStatusListener implements StatusListener and overrides methods to track the input parameters of StatusListener.log(StatusData).\nIn test case, the child test class is used in assertion statement to make sure the log method never been executed.\n\nProposed Implementation\n\nReplace StoringStatusListener with a mocking object created by Mockito.\nUse method stub to control the behavior of getStatusLevel().\nUse ArgumentCapture to capture the input argument for StatusListener.log(StatusData) and use it in the assertion statement.\n\nMotivation\n\nDecouple test class StoringStatusListener from production interface StatusListener.\nRemove the redundant test child class StoringStatusListener\nRemove the redundant overridden methods close()\nMake testing logic more explict by directly verify the input argument through ArgumentCapture.\n\nMore Thought\n\nIf we only want to make sure that the log(StatusData) method was never been executed, we can verify it by Mockito.times() and get rid of the ArgumentCapture. It can make the test condition even more clear.",
        "Issue Links": []
    },
    "OPENNLP-1340": {
        "Key": "OPENNLP-1340",
        "Summary": "Get the probability for a sequence without copying the probabilities",
        "Type": "Wish",
        "Status": "Closed",
        "Priority": "Trivial",
        "Resolution": "Fixed",
        "Affects Version/s": "1.9.3",
        "Fix Version/s": "2.1.1",
        "Component/s": "POS Tagger",
        "Assignee": "Richard Zowalla",
        "Reporter": "Reece H. Dunn",
        "Created": "03/Oct/21 12:02",
        "Updated": "03/Jan/23 14:49",
        "Resolved": "03/Jan/23 14:49",
        "Description": "The \"opennlp.tools.util.Sequence\" class has a \"getOutcomes\" method that returns the outcomes as the underlying list without copying the data. However, the \"getProbs\" method returns the probabilities as an array copy of the underlying probabilities list.\nIt would be useful to have the following accessor methods to avoid the copy (and an accessor for the outcomes for API consistency):\n\n\r\npublic int getSize() {\r\n    return outcomes.size();\r\n}\r\n\r\npublic String getOutcome(int index) {\r\n    return outcomes.get(index);\r\n}\r\n\r\npublic double getProb(int index) {\r\n    return probs.get(index);\r\n}\r\n\n\nThe motivation is that I want to convert the \"POSTagger.topKSequences\" to a \"Map<String, Double>\", in addition to locating the highest probability tag in the result.",
        "Issue Links": []
    },
    "OPENNLP-1341": {
        "Key": "OPENNLP-1341",
        "Summary": "Make the ConlluPOSSampleStream constructor public",
        "Type": "Wish",
        "Status": "Closed",
        "Priority": "Trivial",
        "Resolution": "Fixed",
        "Affects Version/s": "1.9.3",
        "Fix Version/s": "2.1.1",
        "Component/s": "POS Tagger",
        "Assignee": "Bruno P. Kinoshita",
        "Reporter": "Reece H. Dunn",
        "Created": "04/Oct/21 12:12",
        "Updated": "30/Nov/22 16:12",
        "Resolved": "30/Nov/22 14:55",
        "Description": "The constructor for ConlluPOSSampleStream is currently package private as it does not have a public/private keyword before it. Making it public will allow an application to create that stream for use in training a POS model.\nThe other conllu stream classes (ConlluStream, ConlluLemmaSampleStream, ConlluTokenSampleStream, ConlluSentenceSampleStream) have public constructors, allowing them to be used in training their respective models.\nThe ConlluPOSSampleStreamFactory and ConlluLemmaSampleStreamFactory classes are marked as internal use only, and rely on an API suited to the opennlp cli. Note: ConlluSentenceSampleStreamFactory and ConlluTokenSampleStreamFactory are missing an internal use only comment, but should have one.",
        "Issue Links": []
    },
    "OPENNLP-1342": {
        "Key": "OPENNLP-1342",
        "Summary": "Publish docker image to DockerHub",
        "Type": "Task",
        "Status": "Open",
        "Priority": "Major",
        "Resolution": "Unresolved",
        "Affects Version/s": "None",
        "Fix Version/s": "None",
        "Component/s": "Build, Packaging and Test",
        "Assignee": null,
        "Reporter": "Jeff Zemerick",
        "Created": "22/Oct/21 12:40",
        "Updated": "30/Dec/22 21:05",
        "Resolved": null,
        "Description": "Publish the OpenNLP docker image to DockerHub. It would be good if the image publishing can be incorporated into the release process.",
        "Issue Links": []
    },
    "OPENNLP-1343": {
        "Key": "OPENNLP-1343",
        "Summary": "Full CoNLL-U Format support",
        "Type": "Improvement",
        "Status": "Closed",
        "Priority": "Minor",
        "Resolution": "Fixed",
        "Affects Version/s": "1.9.3",
        "Fix Version/s": "2.0.0",
        "Component/s": "Formats",
        "Assignee": null,
        "Reporter": "Jeroen Steggink",
        "Created": "30/Oct/21 13:45",
        "Updated": "26/Oct/22 14:39",
        "Resolved": "26/Oct/22 14:39",
        "Description": "The current CoNLL-U parsers don't fully support all the options the format has to offer. I have added support for the following optional comments:\n\n\r\ntranslit = ....\r\ntext_`locale` = ...\r\nnewdoc\r\nnewpar\r\nnewdoc id somedocid\r\nnewpar id someparid\n\nI have created a PR on Github:\nhttps://github.com/apache/opennlp/pull/397\nJeroen",
        "Issue Links": []
    },
    "OPENNLP-1344": {
        "Key": "OPENNLP-1344",
        "Summary": "Broken link (404) for Leipzig corpora in OpenNLP Manual",
        "Type": "Documentation",
        "Status": "Closed",
        "Priority": "Minor",
        "Resolution": "Fixed",
        "Affects Version/s": "None",
        "Fix Version/s": "2.1.1",
        "Component/s": "Documentation",
        "Assignee": "Martin Wiesner",
        "Reporter": "Phillip Rhodes",
        "Created": "23/Nov/21 00:10",
        "Updated": "06/Jan/23 13:46",
        "Resolved": "10/Dec/22 14:21",
        "Description": "In the User Manual at:\nhttps://opennlp.apache.org/docs/1.9.4/manual/opennlp.html\nThe download link for the Leipzig Corpora is listed as:\nhttps://corpora.uni-leipzig.de/download.html\nhowever this link returns a 404 Not Found error. The correct link now appears to be:\nhttps://wortschatz.uni-leipzig.de/en/download",
        "Issue Links": [
            "/jira/browse/OPENNLP-1436",
            "/jira/browse/OPENNLP-1436"
        ]
    },
    "OPENNLP-1345": {
        "Key": "OPENNLP-1345",
        "Summary": "The Training API code for Sentence Detection is outdated in manual",
        "Type": "Bug",
        "Status": "Resolved",
        "Priority": "Minor",
        "Resolution": "Fixed",
        "Affects Version/s": "1.9.4",
        "Fix Version/s": "2.0.0",
        "Component/s": "Documentation",
        "Assignee": null,
        "Reporter": "Phillip Rhodes",
        "Created": "24/Nov/21 00:16",
        "Updated": "09/Dec/22 18:22",
        "Resolved": "09/Dec/22 18:22",
        "Description": "The Training API example code at https://opennlp.apache.org/docs/1.9.4/manual/opennlp.html in the section on Sentence Detection training is incorrect. The current code sample is:\n\n\r\nObjectStream<String> lineStream =\r\n  new PlainTextByLineStream(new FileInputStream(\"en-sent.train\"), StandardCharsets.UTF_8);\r\n \n\nBut PlainTextByLineStream no longer takes an InputStream as the first argument to its constructor. It now requires an InputStreamFactory.\nNOTE: this same pattern reappears in multiple places in the current manual. See also, OPENNLP-1319",
        "Issue Links": [
            "/jira/browse/OPENNLP-1346",
            "/jira/browse/OPENNLP-1362"
        ]
    },
    "OPENNLP-1346": {
        "Key": "OPENNLP-1346",
        "Summary": "The Training API code for Tokenization is outdated in manual (1/2)",
        "Type": "Bug",
        "Status": "Resolved",
        "Priority": "Minor",
        "Resolution": "Fixed",
        "Affects Version/s": "1.9.4",
        "Fix Version/s": "2.0.0",
        "Component/s": "Documentation",
        "Assignee": "Martin Wiesner",
        "Reporter": "Phillip Rhodes",
        "Created": "24/Nov/21 00:17",
        "Updated": "09/Dec/22 18:20",
        "Resolved": "09/Dec/22 18:20",
        "Description": "The Training API example code at https://opennlp.apache.org/docs/1.9.4/manual/opennlp.html in the section dealing with Tokenizer training\u00a0 incorrect. The current code sample is:\n\n\r\nObjectStream<String> lineStream = new PlainTextByLineStream(new FileInputStream(\"en-sent.train\"),\r\n    StandardCharsets.UTF_8);\n\nBut PlainTextByLineStream no longer takes an InputStream as the first argument to its constructor. It now requires an InputStreamFactory.\nNOTE: this same pattern reappears in multiple places in the current manual. See also, OPENNLP-1319 and OPENNLP-1345",
        "Issue Links": [
            "/jira/browse/OPENNLP-1345",
            "/jira/browse/OPENNLP-1348",
            "/jira/browse/OPENNLP-1362"
        ]
    },
    "OPENNLP-1347": {
        "Key": "OPENNLP-1347",
        "Summary": "The Training API code for Tokenization is outdated in manual (2/2)",
        "Type": "Bug",
        "Status": "Resolved",
        "Priority": "Minor",
        "Resolution": "Fixed",
        "Affects Version/s": "1.9.4",
        "Fix Version/s": "2.0.0",
        "Component/s": "Documentation",
        "Assignee": "Martin Wiesner",
        "Reporter": "Phillip Rhodes",
        "Created": "24/Nov/21 00:29",
        "Updated": "09/Dec/22 18:13",
        "Resolved": "09/Dec/22 18:13",
        "Description": "The code sample in the manual at <> in the section on Tokenizer training has is incorrect. The current code sample is:\n\u00a0\n\n\r\ntry {\r\n  model = TokenizerME.train(\"en\", sampleStream, true, TrainingParameters.defaultParams());\r\n} \n\nBut TokenizerME.train() now has a new signature which requires a TokenizerFactory. The above does not compile with the 1.9.4 library version.",
        "Issue Links": [
            "/jira/browse/OPENNLP-1319"
        ]
    },
    "OPENNLP-1348": {
        "Key": "OPENNLP-1348",
        "Summary": "The Training API code for NamedEntityRecognition is outdated in manual",
        "Type": "Bug",
        "Status": "Resolved",
        "Priority": "Minor",
        "Resolution": "Fixed",
        "Affects Version/s": "1.9.4",
        "Fix Version/s": "2.0.0",
        "Component/s": "Documentation",
        "Assignee": "Martin Wiesner",
        "Reporter": "Phillip Rhodes",
        "Created": "24/Nov/21 00:53",
        "Updated": "09/Dec/22 18:16",
        "Resolved": "09/Dec/22 18:16",
        "Description": "The Training API example code at https://opennlp.apache.org/docs/1.9.4/manual/opennlp.html in the section dealing with TokenNameFinder training\u00a0 incorrect. The current code sample includes:\n\n\r\nObjectStream<String> lineStream = new PlainTextByLineStream(new FileInputStream(\"en-sent.train\"),\r\n    StandardCharsets.UTF_8);\n\nBut PlainTextByLineStream no longer takes an InputStream as the first argument to its constructor. It now requires an InputStreamFactory.\nNOTE: this same pattern reappears in multiple places in the current manual. See also, OPENNLP-1319, and OPENNLP-1345, and OPENNLP-1346",
        "Issue Links": [
            "/jira/browse/OPENNLP-1346",
            "/jira/browse/OPENNLP-1349",
            "/jira/browse/OPENNLP-1362"
        ]
    },
    "OPENNLP-1349": {
        "Key": "OPENNLP-1349",
        "Summary": "The Training API code for Document Categorization is outdated in manual",
        "Type": "Bug",
        "Status": "Resolved",
        "Priority": "Minor",
        "Resolution": "Fixed",
        "Affects Version/s": "1.9.4",
        "Fix Version/s": "2.0.0",
        "Component/s": "Documentation",
        "Assignee": "Martin Wiesner",
        "Reporter": "Phillip Rhodes",
        "Created": "24/Nov/21 01:06",
        "Updated": "09/Dec/22 18:19",
        "Resolved": "09/Dec/22 18:19",
        "Description": "The Training API example code at https://opennlp.apache.org/docs/1.9.4/manual/opennlp.html in the section dealing with TokenNameFinder training\u00a0 incorrect. The current code sample includes:\n\n\r\ntry (dataIn = new FileInputStream(\"en-sentiment.train\")) {\r\n  ObjectStream<String> lineStream =\r\n\t\tnew PlainTextByLineStream(dataIn, StandardCharsets.UTF_8);\r\n}\n\nBut PlainTextByLineStream no longer takes an InputStream as the first argument to its constructor. It now requires an InputStreamFactory.\nNOTE: this same pattern reappears in multiple places in the current manual. See also, OPENNLP-1319,\u00a0 OPENNLP-1345, and OPENNLP-1346\u00a0among others.",
        "Issue Links": [
            "/jira/browse/OPENNLP-1348",
            "/jira/browse/OPENNLP-1362"
        ]
    },
    "OPENNLP-1350": {
        "Key": "OPENNLP-1350",
        "Summary": "MAIL_REGEX in UrlCharSequenceNormalizer causes quadratic complexity for certain input, and is also a bit imprecise",
        "Type": "Bug",
        "Status": "Resolved",
        "Priority": "Minor",
        "Resolution": "Fixed",
        "Affects Version/s": "1.9.3",
        "Fix Version/s": "1.9.4",
        "Component/s": "Language Detector",
        "Assignee": "Bruno P. Kinoshita",
        "Reporter": "Jon Marius Venstad",
        "Created": "16/Dec/21 20:59",
        "Updated": "08/Jan/22 10:32",
        "Resolved": "07/Jan/22 09:17",
        "Description": "The regex used to strip email addresses from input, in UrlCharSequenceNormalizer, has quadratic complexity when used with String.replaceAll, and when input is a long sequence of characters from the first character set, i.e., [-_.0-9A-Za-z], which fails to match the whole regex; then, the regex is evaluated again for each suffix of this sequence, with linear cost each time.\u00a0\nThis problem is promptly solved by adding a negative lookbehind with a single character from that same set, to the first part of the regex.\u00a0\n\u00a0\nAdditionally, the character\u00a0{} is allowed in the domain part of the mail address, where it is in fact illegal. Likewise, the character + is disallowed in the local part (the first first), where it _is legal, and even quite common. The set of legal characters in the first part is actually quite bonkers, per the RFC, but such usage is probably less common. See https://en.wikipedia.org/wiki/Email_address\u00a0for details.\u00a0\n\u00a0\nThe suggested fix is to change the MAIL_REGEX declaration to\n\n\r\nprivate static final Pattern MAIL_REGEX =\r\n\u00a0 \u00a0 \u00a0 Pattern.compile(\"(?<![-+_.0-9A-Za-z])[-+_.0-9A-Za-z]+@[-0-9A-Za-z]+[-.0-9A-Za-z]+\"); \n\nFor a sequence of ~100k characters, the run time is ~1minute \"on my machine\". With this change, it reduces to a few milliseconds.",
        "Issue Links": []
    },
    "OPENNLP-1351": {
        "Key": "OPENNLP-1351",
        "Summary": "Support ONNX models",
        "Type": "Task",
        "Status": "Closed",
        "Priority": "Major",
        "Resolution": "Fixed",
        "Affects Version/s": "None",
        "Fix Version/s": "2.0.0",
        "Component/s": "None",
        "Assignee": "Jeff Zemerick",
        "Reporter": "Jeff Zemerick",
        "Created": "27/Dec/21 21:58",
        "Updated": "07/Jun/22 11:58",
        "Resolved": "07/Jun/22 11:58",
        "Description": "With support for ONNX models, OpenNLP can utilize the newer transformer architecture models. Models can be trained in PyTorch or Tensorflow and converted to ONNX and used from OpenNLP.\nThis task is to provide OpenNLP interface implementations using ONNX models.",
        "Issue Links": []
    },
    "OPENNLP-1352": {
        "Key": "OPENNLP-1352",
        "Summary": "Migrate from Travis CI to GH Actions?",
        "Type": "Improvement",
        "Status": "Closed",
        "Priority": "Trivial",
        "Resolution": "Fixed",
        "Affects Version/s": "1.9.3",
        "Fix Version/s": "1.9.4",
        "Component/s": "Build, Packaging and Test",
        "Assignee": "Bruno P. Kinoshita",
        "Reporter": "Bruno P. Kinoshita",
        "Created": "07/Jan/22 08:36",
        "Updated": "22/Mar/22 15:44",
        "Resolved": "14/Jan/22 01:54",
        "Description": "Does anyone have any opinion on this? Travis CI seems to be quite slow now, both to start the tests, and also to run them.\nMigrating to GH Actions is now trivial. Other ASF projects have moved to Actions (Commons) or are using ASF infra (Jena).",
        "Issue Links": []
    },
    "OPENNLP-1353": {
        "Key": "OPENNLP-1353",
        "Summary": "DictonaryLemmatizer missing charset",
        "Type": "Bug",
        "Status": "Closed",
        "Priority": "Major",
        "Resolution": "Fixed",
        "Affects Version/s": "1.9.3",
        "Fix Version/s": "2.0.0",
        "Component/s": "Lemmatizer",
        "Assignee": null,
        "Reporter": "Robert",
        "Created": "17/Jan/22 15:35",
        "Updated": "07/Jun/22 11:58",
        "Resolved": "07/Jun/22 11:58",
        "Description": "The initialization of the DictonaryLemmatizer is not decoding the inputstream correctly due to missing charset.\nMy dictionary file for the lemmatizer is utf-8 encoded. At DictonaryLemmatizer initialization the system fallback encoding is used because no charset is specified for the InputStreamReader. In my case windows-1252. This leads to the problem that the correct lemmas of words are not found.\nE.g. My lemma.dict file contains following line (utf-8):\n\n\r\nm\u00e4use      NN     maus   //German word of mice\r\n\n\nAnd the InputStreamReader decodes it as windows-1252:\n\n\r\nm\u00c3\u00a4use \u00a0 \u00a0NN \u00a0 \u00a0maus",
        "Issue Links": []
    },
    "OPENNLP-1354": {
        "Key": "OPENNLP-1354",
        "Summary": "Change build to use Java 11",
        "Type": "Task",
        "Status": "Closed",
        "Priority": "Major",
        "Resolution": "Fixed",
        "Affects Version/s": "None",
        "Fix Version/s": "2.0.0",
        "Component/s": "Build, Packaging and Test",
        "Assignee": "Jeff Zemerick",
        "Reporter": "Jeff Zemerick",
        "Created": "17/Jan/22 17:04",
        "Updated": "07/Jun/22 11:58",
        "Resolved": "07/Jun/22 11:58",
        "Description": "OpenNLP still requires Java 8. Change it to build using Java 11.",
        "Issue Links": [
            "/jira/browse/OPENNLP-1359"
        ]
    },
    "OPENNLP-1355": {
        "Key": "OPENNLP-1355",
        "Summary": "Document ONNX capability introduced in OPENNLP-1351",
        "Type": "Task",
        "Status": "Closed",
        "Priority": "Major",
        "Resolution": "Fixed",
        "Affects Version/s": "None",
        "Fix Version/s": "2.0.0",
        "Component/s": "Documentation",
        "Assignee": "Jeff Zemerick",
        "Reporter": "Jeff Zemerick",
        "Created": "28/Jan/22 16:00",
        "Updated": "07/Jun/22 11:58",
        "Resolved": "07/Jun/22 11:58",
        "Description": "Document ONNX capability introduced in OPENNLP-1351.",
        "Issue Links": []
    },
    "OPENNLP-1356": {
        "Key": "OPENNLP-1356",
        "Summary": "Document the ONNX implementations",
        "Type": "Task",
        "Status": "Closed",
        "Priority": "Major",
        "Resolution": "Fixed",
        "Affects Version/s": "None",
        "Fix Version/s": "2.0.0",
        "Component/s": "Documentation",
        "Assignee": "Jeff Zemerick",
        "Reporter": "Jeff Zemerick",
        "Created": "17/Feb/22 14:23",
        "Updated": "07/Jun/22 11:58",
        "Resolved": "07/Jun/22 11:58",
        "Description": null,
        "Issue Links": []
    },
    "OPENNLP-1357": {
        "Key": "OPENNLP-1357",
        "Summary": "Use CharSequence to allow for memory management",
        "Type": "Improvement",
        "Status": "Closed",
        "Priority": "Minor",
        "Resolution": "Fixed",
        "Affects Version/s": "1.9.4",
        "Fix Version/s": "2.1.1",
        "Component/s": "Sentence Detector",
        "Assignee": "Martin Wiesner",
        "Reporter": "Paul Austin",
        "Created": "14/Mar/22 18:26",
        "Updated": "28/Jan/23 14:59",
        "Resolved": "15/Dec/22 07:10",
        "Description": "Most of the classes in OpenNLP require the inputs to be as String, StringBuffer, or char[]. This means that you have to load all the data into memory.\nMany of these cases (String and StringBuffer args) could be replaced with a single method that accepts CharSequence as a parameter.\nFor example DefaultEndOfSentenceScanner\n\u00a0\n\n\r\n public List<Integer> getPositions(CharSequence s) {\r\n\u00a0 \u00a0 List<Integer> l = new ArrayList<>();\r\n  \u00a0 for (int i = 0; i < s.length(); i++) {\r\n      char c = s.charAt(i);\r\n  \u00a0 \u00a0 if (eosCharacters.contains(c)) {\r\n\u00a0 \u00a0 \u00a0 \u00a0 l.add(i);\r\n\u00a0 \u00a0 \u00a0 }\r\n\u00a0 \u00a0 }\r\n\u00a0 \u00a0 return l;\r\n  }\r\n\n\nThis would allow for users to manage the memory overhead for large data sets. And in some cases require less temporary memory conversion to char buffers.\nSome code such as the SDContextGenerator already uses CharSequence.\u00a0 However in SentenceDetectorME there is an unnecessary conversion to a StringBuffer. The sb isn't modified and the SDContextGenerator.getContext takes CharSequence as an arg and String is a CharSequence.\n\u00a0\n\n\r\npublic Span[] sentPosDetect(String s) {\r\n\u00a0 \u00a0 sentProbs.clear();\r\n\u00a0 \u00a0 StringBuffer sb = new StringBuffer(s);\n\n\u00a0\nI can create a pull request(s) for the above if you think it is useful.",
        "Issue Links": []
    },
    "OPENNLP-1358": {
        "Key": "OPENNLP-1358",
        "Summary": "Failing tests on Windows 11 and Java 17",
        "Type": "Task",
        "Status": "Closed",
        "Priority": "Minor",
        "Resolution": "Fixed",
        "Affects Version/s": "1.9.4",
        "Fix Version/s": "2.1.1",
        "Component/s": "None",
        "Assignee": "Richard Zowalla",
        "Reporter": "Jeff Zemerick",
        "Created": "18/Mar/22 14:01",
        "Updated": "01/Jan/23 16:46",
        "Resolved": "01/Jan/23 16:46",
        "Description": "The following tests are failing on Windows 11 and Java 17 build. The tests pass on Ubuntu 20.04 with Java 17.\n[ERROR] Failures:\n[ERROR] \u00a0 BratDocumentParserTest.testParse:55 expected:<3> but was:<1>\n[ERROR] \u00a0 BratDocumentTest.testDocumentWithEntitiesParsing:47\n[ERROR] \u00a0 BratNameSampleStreamTest.readNoOverlap:65 expected:<8> but was:<7>\n[ERROR] \u00a0 BratNameSampleStreamTest.readOverlapFail Expected exception: java.lang.RuntimeException\n[INFO]\n[ERROR] Tests run: 784, Failures: 4, Errors: 0, Skipped: 0\nApache Maven 3.8.5 (3599d3414f046de2324203b78ddcf9b5e4388aa0)\nMaven home: C:\\Program Files\\apache-maven\nJava version: 17.0.2, vendor: Amazon.com Inc., runtime: C:\\Program Files\\Amazon Corretto\\jdk17.0.2_8\nDefault locale: en_US, platform encoding: Cp1252\nOS name: \"windows 11\", version: \"10.0\", arch: \"amd64\", family: \"windows\"",
        "Issue Links": []
    },
    "OPENNLP-1359": {
        "Key": "OPENNLP-1359",
        "Summary": "Build fails with Java 17",
        "Type": "Task",
        "Status": "Closed",
        "Priority": "Major",
        "Resolution": "Fixed",
        "Affects Version/s": "1.9.4",
        "Fix Version/s": "2.0.0",
        "Component/s": "None",
        "Assignee": "Jeff Zemerick",
        "Reporter": "Jeff Zemerick",
        "Created": "20/Mar/22 20:48",
        "Updated": "07/Jun/22 11:59",
        "Resolved": "07/Jun/22 11:59",
        "Description": "The build fails when using Java 17.\nApache Maven 3.8.5 (3599d3414f046de2324203b78ddcf9b5e4388aa0)\nMaven home: /opt/apache-maven\nJava version: 11.0.14, vendor: Ubuntu, runtime: /usr/lib/jvm/java-11-openjdk-amd64\nDefault locale: en_US, platform encoding: UTF-8\nOS name: \"linux\", version: \"5.13.0-35-generic\", arch: \"amd64\", family: \"unix\"\nException during build:\n[INFO] \u2014 maven-bundle-plugin:4.2.1:bundle (default-bundle) @ opennlp-tools \u2014\n[ERROR] An internal error occurred\njava.util.ConcurrentModificationException\n\u00a0 \u00a0 at java.util.TreeMap.callMappingFunctionWithCheck (TreeMap.java:750)\n\u00a0 \u00a0 at java.util.TreeMap.computeIfAbsent (TreeMap.java:558)\n\u00a0 \u00a0 at aQute.bnd.osgi.Jar.putResource (Jar.java:288)\n\u00a0 \u00a0 at aQute.bnd.osgi.Jar$1.visitFile (Jar.java:202)\n\u00a0 \u00a0 at aQute.bnd.osgi.Jar$1.visitFile (Jar.java:177)\n\u00a0 \u00a0 at java.nio.file.Files.walkFileTree (Files.java:2811)\n\u00a0 \u00a0 at aQute.bnd.osgi.Jar.buildFromDirectory (Jar.java:176)\n\u00a0 \u00a0 at aQute.bnd.osgi.Jar.<init> (Jar.java:119)\n\u00a0 \u00a0 at aQute.bnd.osgi.Jar.<init> (Jar.java:172)\n\u00a0 \u00a0 at org.apache.felix.bundleplugin.BundlePlugin.getOSGiBuilder (BundlePlugin.java:604)\n\u00a0 \u00a0 at org.apache.felix.bundleplugin.BundlePlugin.buildOSGiBundle (BundlePlugin.java:936)\n\u00a0 \u00a0 at org.apache.felix.bundleplugin.BundlePlugin.execute (BundlePlugin.java:443)\n\u00a0 \u00a0 at org.apache.felix.bundleplugin.BundlePlugin.execute (BundlePlugin.java:364)\n\u00a0 \u00a0 at org.apache.maven.plugin.DefaultBuildPluginManager.executeMojo (DefaultBuildPluginManager.java:137)\n\u00a0 \u00a0 at org.apache.maven.lifecycle.internal.MojoExecutor.doExecute (MojoExecutor.java:301)\n\u00a0 \u00a0 at org.apache.maven.lifecycle.internal.MojoExecutor.execute (MojoExecutor.java:211)\n\u00a0 \u00a0 at org.apache.maven.lifecycle.internal.MojoExecutor.execute (MojoExecutor.java:165)\n\u00a0 \u00a0 at org.apache.maven.lifecycle.internal.MojoExecutor.execute (MojoExecutor.java:157)\n\u00a0 \u00a0 at org.apache.maven.lifecycle.internal.LifecycleModuleBuilder.buildProject (LifecycleModuleBuilder.java:121)\n\u00a0 \u00a0 at org.apache.maven.lifecycle.internal.LifecycleModuleBuilder.buildProject (LifecycleModuleBuilder.java:81)\n\u00a0 \u00a0 at org.apache.maven.lifecycle.internal.builder.singlethreaded.SingleThreadedBuilder.build (SingleThreadedBuilder.java:56)\n\u00a0 \u00a0 at org.apache.maven.lifecycle.internal.LifecycleStarter.execute (LifecycleStarter.java:127)\n\u00a0 \u00a0 at org.apache.maven.DefaultMaven.doExecute (DefaultMaven.java:294)\n\u00a0 \u00a0 at org.apache.maven.DefaultMaven.doExecute (DefaultMaven.java:192)\n\u00a0 \u00a0 at org.apache.maven.DefaultMaven.execute (DefaultMaven.java:105)\n\u00a0 \u00a0 at org.apache.maven.cli.MavenCli.execute (MavenCli.java:960)\n\u00a0 \u00a0 at org.apache.maven.cli.MavenCli.doMain (MavenCli.java:293)\n\u00a0 \u00a0 at org.apache.maven.cli.MavenCli.main (MavenCli.java:196)\n\u00a0 \u00a0 at jdk.internal.reflect.NativeMethodAccessorImpl.invoke0 (Native Method)\n\u00a0 \u00a0 at jdk.internal.reflect.NativeMethodAccessorImpl.invoke (NativeMethodAccessorImpl.java:77)\n\u00a0 \u00a0 at jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke (DelegatingMethodAccessorImpl.java:43)\n\u00a0 \u00a0 at java.lang.reflect.Method.invoke (Method.java:568)\n\u00a0 \u00a0 at org.codehaus.plexus.classworlds.launcher.Launcher.launchEnhanced (Launcher.java:282)\n\u00a0 \u00a0 at org.codehaus.plexus.classworlds.launcher.Launcher.launch (Launcher.java:225)\n\u00a0 \u00a0 at org.codehaus.plexus.classworlds.launcher.Launcher.mainWithExitCode (Launcher.java:406)\n\u00a0 \u00a0 at org.codehaus.plexus.classworlds.launcher.Launcher.main (Launcher.java:347)",
        "Issue Links": [
            "/jira/browse/OPENNLP-1334",
            "/jira/browse/OPENNLP-1334",
            "/jira/browse/OPENNLP-1354"
        ]
    },
    "OPENNLP-1360": {
        "Key": "OPENNLP-1360",
        "Summary": "Update the contribution guidelines on the website",
        "Type": "Task",
        "Status": "Closed",
        "Priority": "Major",
        "Resolution": "Fixed",
        "Affects Version/s": "None",
        "Fix Version/s": "None",
        "Component/s": "Website",
        "Assignee": "Jeff Zemerick",
        "Reporter": "Jeff Zemerick",
        "Created": "21/Mar/22 16:03",
        "Updated": "17/Oct/22 19:34",
        "Resolved": "17/Oct/22 19:34",
        "Description": "Update the contribution guidelines on the website.",
        "Issue Links": []
    },
    "OPENNLP-1361": {
        "Key": "OPENNLP-1361",
        "Summary": "Upgrade JUnit to version 5",
        "Type": "Task",
        "Status": "Closed",
        "Priority": "Minor",
        "Resolution": "Fixed",
        "Affects Version/s": "None",
        "Fix Version/s": "2.1.0",
        "Component/s": "Build, Packaging and Test",
        "Assignee": "Richard Zowalla",
        "Reporter": "Jeff Zemerick",
        "Created": "28/Mar/22 19:45",
        "Updated": "07/Nov/22 13:11",
        "Resolved": "07/Nov/22 13:11",
        "Description": "Upgrade JUnit to version 5.",
        "Issue Links": []
    },
    "OPENNLP-1362": {
        "Key": "OPENNLP-1362",
        "Summary": "Update document to be compatible with latest version PlainTextByLineStream class",
        "Type": "Task",
        "Status": "Closed",
        "Priority": "Major",
        "Resolution": "Fixed",
        "Affects Version/s": "None",
        "Fix Version/s": "2.0.0",
        "Component/s": "Documentation",
        "Assignee": null,
        "Reporter": "Jeff Zemerick",
        "Created": "28/Mar/22 19:54",
        "Updated": "09/Dec/22 18:22",
        "Resolved": "26/Oct/22 16:01",
        "Description": "Update document to be compatible with latest version PlainTextByLineStream class.\n(This was created for pull request https://github.com/apache/opennlp/pull/346.)\n\u00a0\nThe original PR was\u00a0https://github.com/apache/opennlp/pull/346.\nThat PR had merge conflicts that could not be resolved inside the PR.\nSo\u00a0https://github.com/apache/opennlp/pull/408\u00a0was created to include the changes and resolve the merge conflicts.",
        "Issue Links": [
            "/jira/browse/OPENNLP-1345",
            "/jira/browse/OPENNLP-1346",
            "/jira/browse/OPENNLP-1348",
            "/jira/browse/OPENNLP-1349"
        ]
    },
    "OPENNLP-1363": {
        "Key": "OPENNLP-1363",
        "Summary": "Verify the documentation of the lemmatizer input format",
        "Type": "Documentation",
        "Status": "Closed",
        "Priority": "Minor",
        "Resolution": "Fixed",
        "Affects Version/s": "2.1.0",
        "Fix Version/s": "2.1.1",
        "Component/s": "Documentation",
        "Assignee": "Atita Arora",
        "Reporter": "Jeff Zemerick",
        "Created": "29/Mar/22 13:17",
        "Updated": "09/Jan/23 18:57",
        "Resolved": "20/Dec/22 07:19",
        "Description": "In OPENNLP-1257, a change was proposed to update the code to split the lemmatizer input by spaces instead of by tab. I believe tab is the desired delimiter but we need to make sure the documentation is consistent.\nRefer to https://opennlp.apache.org/docs/1.9.4/manual/opennlp.html#tools.lemmatizer , in particular the following sentences:\n\"The training data consist of three columns separated by spaces. Each word has been put on a separate line and there is an empty line after each sentence. The first column contains the current word, the second its part-of-speech tag and the third its lemma. Here is an example of the file format:\"\nDetermine if that first line should read \"separated by tabs\" instead.",
        "Issue Links": [
            "/jira/browse/OPENNLP-1257"
        ]
    },
    "OPENNLP-1364": {
        "Key": "OPENNLP-1364",
        "Summary": "Move setKeepNewLines to the Tokenizer class",
        "Type": "Task",
        "Status": "Closed",
        "Priority": "Minor",
        "Resolution": "Fixed",
        "Affects Version/s": "None",
        "Fix Version/s": "2.0.0",
        "Component/s": "Tokenizer",
        "Assignee": "Jeff Zemerick",
        "Reporter": "Jeff Zemerick",
        "Created": "02/Apr/22 19:23",
        "Updated": "07/Jun/22 11:59",
        "Resolved": "07/Jun/22 11:59",
        "Description": "In OPENNLP-1185, an option to keep new lines was added to the tokenizer classes. A function setKeepNewLines() was added to the tokenizer classes. See if this function can be moved to the abstract Tokenizer class.",
        "Issue Links": []
    },
    "OPENNLP-1365": {
        "Key": "OPENNLP-1365",
        "Summary": "Prepare 2.0 release",
        "Type": "Task",
        "Status": "Closed",
        "Priority": "Major",
        "Resolution": "Fixed",
        "Affects Version/s": "None",
        "Fix Version/s": "2.0.0",
        "Component/s": "Build, Packaging and Test",
        "Assignee": "Jeff Zemerick",
        "Reporter": "Jeff Zemerick",
        "Created": "07/Apr/22 18:16",
        "Updated": "17/Oct/22 20:10",
        "Resolved": "17/Oct/22 20:10",
        "Description": "Prepare 2.0 release.",
        "Issue Links": []
    },
    "OPENNLP-1366": {
        "Key": "OPENNLP-1366",
        "Summary": "Training of MaxEnt Model with large corpora fails with java.io.UTFDataFormatException",
        "Type": "Improvement",
        "Status": "Closed",
        "Priority": "Major",
        "Resolution": "Fixed",
        "Affects Version/s": "1.9.4,                                            2.0.0",
        "Fix Version/s": "2.1.0",
        "Component/s": "Lemmatizer",
        "Assignee": "Richard Zowalla",
        "Reporter": "Richard Zowalla",
        "Created": "11/Apr/22 14:21",
        "Updated": "09/Dec/22 10:45",
        "Resolved": "07/Nov/22 13:10",
        "Description": "As written on [dev@opennlp.a.o|https://lists.apache.org/thread/vc5lfzj81tco703noqxpvy8sfj8fw8b1], we are working on training a large opennlp maxent model for lemmatizing\nGerman texts. We use a wikipedia tree bank from T\u00fcbingen.\nThis consumes > 2 TB of RAM during training but will finish after some time. However, writing this model will result in a \u00a0java.io.UTFDataFormatException\u00a0\nHowever, training such a big model isn't feasable for debugging. Gladly, a similar with a smaller dataset is found on Stackoverflow: https://stackoverflow.com/questions/70064477/opennlp-lemmatizertrainer-utfdataformatexception-encoded-string-too-long\u00a0\nIt contains the OpenNLP CLI command to train a lemmatizer on a much smaller dataset.\nThe stacktrace is raced while writing a String as UTF in DataOutputStream, which has a hard-coded size limitation in the JDK (for reasons behind my knowledge )\nStacktrace:\n\n\r\njava.io.UTFDataFormatException: encoded string too long: 383769 bytes\r\n        at java.base/java.io.DataOutputStream.writeUTF(DataOutputStream.java:364)\r\n        at java.base/java.io.DataOutputStream.writeUTF(DataOutputStream.java:323)\r\n        at opennlp.tools.ml.maxent.io.BinaryGISModelWriter.writeUTF(BinaryGISModelWriter.java:71)\r\n        at opennlp.tools.ml.maxent.io.GISModelWriter.persist(GISModelWriter.java:97)\r\n        at opennlp.tools.ml.model.GenericModelWriter.persist(GenericModelWriter.java:75)\r\n        at opennlp.tools.util.model.ModelUtil.writeModel(ModelUtil.java:71)\r\n        at opennlp.tools.util.model.GenericModelSerializer.serialize(GenericModelSerializer.java:36)\r\n        at opennlp.tools.util.model.GenericModelSerializer.serialize(GenericModelSerializer.java:29)\r\n        at opennlp.tools.util.model.BaseModel.serialize(BaseModel.java:597)\r\n        at opennlp.tools.cmdline.CmdLineUtil.writeModel(CmdLineUtil.java:182)\r\n        at opennlp.tools.cmdline.lemmatizer.LemmatizerTrainerTool.run(LemmatizerTrainerTool.java:77)\r\n        at opennlp.tools.cmdline.CLI.main(CLI.java:256)",
        "Issue Links": [
            "/jira/browse/OPENNLP-1218",
            "https://stackoverflow.com/questions/70064477/how-to-handle-lemmatizertrainer-utfdataformatexception-encoded-string-too-long"
        ]
    },
    "OPENNLP-1367": {
        "Key": "OPENNLP-1367",
        "Summary": "Update checkstyle rules for a recent checkstyle version",
        "Type": "Task",
        "Status": "Closed",
        "Priority": "Major",
        "Resolution": "Fixed",
        "Affects Version/s": "None",
        "Fix Version/s": "2.1.1",
        "Component/s": "Build, Packaging and Test",
        "Assignee": "Martin Wiesner",
        "Reporter": "Jeff Zemerick",
        "Created": "13/Apr/22 19:50",
        "Updated": "06/Jan/23 13:03",
        "Resolved": "06/Jan/23 13:03",
        "Description": "Update checkstyle rules for checkstyle 8+",
        "Issue Links": []
    },
    "OPENNLP-1368": {
        "Key": "OPENNLP-1368",
        "Summary": "Allow OpenNLP 2.x to use OpenNLP 1.x models",
        "Type": "Task",
        "Status": "Closed",
        "Priority": "Major",
        "Resolution": "Fixed",
        "Affects Version/s": "2.0.0",
        "Fix Version/s": "2.0.0",
        "Component/s": "Machine Learning",
        "Assignee": "Jeff Zemerick",
        "Reporter": "Jeff Zemerick",
        "Created": "20/Apr/22 13:48",
        "Updated": "10/Jun/22 12:10",
        "Resolved": "10/Jun/22 12:10",
        "Description": "Allow OpenNLP 2.x to use OpenNLP 1.x models",
        "Issue Links": []
    },
    "OPENNLP-1369": {
        "Key": "OPENNLP-1369",
        "Summary": "NPE when serializing a TokenNameFinder model trained with POSTaggerNameFeatureGeneratorFactory",
        "Type": "Bug",
        "Status": "Open",
        "Priority": "Major",
        "Resolution": "Unresolved",
        "Affects Version/s": "None",
        "Fix Version/s": "None",
        "Component/s": "None",
        "Assignee": null,
        "Reporter": "Lucas Avan\u00e7o",
        "Created": "09/May/22 13:19",
        "Updated": "10/Mar/23 11:43",
        "Resolved": null,
        "Description": "There is an issue of null pointer when trying to serialize a TokenNameFinder model trained using as one of feature generators POSTaggerNameFeatureGeneratorFactory.\nIn this method \u00a0opennlp.tools.util.model.BaseModel#serialize(java.io.OutputStream) there is a for which iterates over the artifactMap of the POS-model that must be serialized together, but a NPE occurs because generator.featuregen is not found inside of pt-pos-perceptron.zip\n\u00a0\n<generator class=\"opennlp.tools.util.featuregen.WindowFeatureGeneratorFactory\">\n\u00a0 \u00a0 <int name=\"prevLength\">2</int>\n\u00a0 \u00a0 <int name=\"nextLength\">2</int>\n\u00a0 \u00a0 <generator class=\"opennlp.tools.util.featuregen.POSTaggerNameFeatureGeneratorFactory\">\n\u00a0 \u00a0 <str name=\"model\">pt-pos-perceptron.zip</str>\n\u00a0 \u00a0 </generator>\n\u00a0 </generator>\n\u00a0\nThis is the POS-tagger model used:\nhttp://opennlp.sourceforge.net/models-1.5/pt-pos-perceptron.bin",
        "Issue Links": []
    },
    "OPENNLP-1370": {
        "Key": "OPENNLP-1370",
        "Summary": "Update date in NOTICE file",
        "Type": "Task",
        "Status": "Closed",
        "Priority": "Major",
        "Resolution": "Fixed",
        "Affects Version/s": "1.9.4",
        "Fix Version/s": "2.1.0",
        "Component/s": "Build, Packaging and Test",
        "Assignee": null,
        "Reporter": "Jeff Zemerick",
        "Created": "26/May/22 13:37",
        "Updated": "07/Nov/22 13:11",
        "Resolved": "07/Nov/22 13:11",
        "Description": "Per kinow on the mailing list \u2013\nI downloaded a ZIP from Maven (opennlp-distr-2.0.0-bin.zip) and its NOTICE had 2017. At least in Apache Commons and Jena we try to keep the NOTICE file up to date (I think it's an ASF policy?)",
        "Issue Links": []
    },
    "OPENNLP-1371": {
        "Key": "OPENNLP-1371",
        "Summary": "Update language codes in documentation",
        "Type": "Task",
        "Status": "Closed",
        "Priority": "Major",
        "Resolution": "Fixed",
        "Affects Version/s": "None",
        "Fix Version/s": "2.1.0",
        "Component/s": "Documentation",
        "Assignee": "Kumar A",
        "Reporter": "Jeff Zemerick",
        "Created": "05/Jun/22 21:12",
        "Updated": "07/Nov/22 13:11",
        "Resolved": "07/Nov/22 13:11",
        "Description": "The documentation uses two letter language codes (\"en\"). They need changed to three letter language codes (\"eng\"). I believe this applies to all code samples.",
        "Issue Links": []
    },
    "OPENNLP-1372": {
        "Key": "OPENNLP-1372",
        "Summary": "ConlluWordLine to include line text in invalid number of fields exception",
        "Type": "Improvement",
        "Status": "Closed",
        "Priority": "Minor",
        "Resolution": "Fixed",
        "Affects Version/s": "1.9.4,                                            2.0.0",
        "Fix Version/s": "2.1.0",
        "Component/s": "None",
        "Assignee": "Markus Jelsma",
        "Reporter": "Markus Jelsma",
        "Created": "14/Jun/22 10:44",
        "Updated": "09/Dec/22 18:40",
        "Resolved": "07/Nov/22 13:11",
        "Description": "Some training Conllu training data from UD, or elsewhere, may not always have exactly 10 fields. The current exception does not mention the erroneous line which is not helpful in debugging.",
        "Issue Links": [
            "/jira/browse/OPENNLP-1314"
        ]
    },
    "OPENNLP-1373": {
        "Key": "OPENNLP-1373",
        "Summary": "Fix CLI examples for CoNLL-2003 on documentation",
        "Type": "Task",
        "Status": "Closed",
        "Priority": "Major",
        "Resolution": "Fixed",
        "Affects Version/s": "2.0.0",
        "Fix Version/s": "2.2.0",
        "Component/s": "Documentation",
        "Assignee": "Atita Arora",
        "Reporter": "Jeff Zemerick",
        "Created": "01/Jul/22 18:25",
        "Updated": "22/Apr/23 17:39",
        "Resolved": "26/Feb/23 13:07",
        "Description": "Several of the CLI examples under the CoNLL-2003 section in the user's manual are incorrect. Update the CLI examples where needed.\nSection: https://opennlp.apache.org/docs/2.0.0/manual/opennlp.html#tools.corpora.conll.2003",
        "Issue Links": []
    },
    "OPENNLP-1374": {
        "Key": "OPENNLP-1374",
        "Summary": "Update ONNX code to allow for unlimited text length and for reusability",
        "Type": "Task",
        "Status": "Closed",
        "Priority": "Major",
        "Resolution": "Fixed",
        "Affects Version/s": "2.0.0",
        "Fix Version/s": "2.1.0",
        "Component/s": "Deep Learning",
        "Assignee": "Jeff Zemerick",
        "Reporter": "Jeff Zemerick",
        "Created": "20/Jul/22 14:26",
        "Updated": "07/Nov/22 13:10",
        "Resolved": "07/Nov/22 13:10",
        "Description": "There are a few updates needed in the ONNX code that make sense to make together.\n\nAllow for processing text of unlimited length. Currently requires input text to be broken up outside of OpenNLP prior to inference.\nUse constants for labels. Allow the labels for B_PER and I_PER to be customized by the user (if needed).\nRefactor the code for better reuse looking down the road at other interface implementations.",
        "Issue Links": []
    },
    "OPENNLP-1375": {
        "Key": "OPENNLP-1375",
        "Summary": "Enable optional GPU inference in ONNX Runtime config",
        "Type": "Task",
        "Status": "Closed",
        "Priority": "Major",
        "Resolution": "Fixed",
        "Affects Version/s": "2.0.0",
        "Fix Version/s": "2.1.0",
        "Component/s": "None",
        "Assignee": "Jeff Zemerick",
        "Reporter": "Jeff Zemerick",
        "Created": "22/Jul/22 18:49",
        "Updated": "07/Nov/22 13:11",
        "Resolved": "07/Nov/22 13:11",
        "Description": "Enable optional GPU inference in ONNX Runtime config. Expose a property (probably through a constructor) to enable GPU inference when doing inference using ONNX Runtime.",
        "Issue Links": []
    },
    "OPENNLP-1376": {
        "Key": "OPENNLP-1376",
        "Summary": "OpenNLP site Get Involved page subscribe and unsubscribe email domain names incorrect",
        "Type": "Bug",
        "Status": "Closed",
        "Priority": "Major",
        "Resolution": "Fixed",
        "Affects Version/s": "None",
        "Fix Version/s": "None",
        "Component/s": "Website",
        "Assignee": "Bertrand Rigaldies",
        "Reporter": "Bertrand Rigaldies",
        "Created": "24/Jul/22 17:31",
        "Updated": "26/Jul/22 11:41",
        "Resolved": "26/Jul/22 11:41",
        "Description": "On the OpenNLP [Get Involved page](https://opennlp.apache.org/get-involved.html), the Subcribe and Unsubcribe email addresses have domain names \"users.apache.org\" (see attachment too) which did not work for me when I attempted to subscribe. It worked for me when using domain names \"opennlp.apache.org\".",
        "Issue Links": []
    },
    "OPENNLP-1377": {
        "Key": "OPENNLP-1377",
        "Summary": "Create link to ASF Slack #opennlp channel",
        "Type": "Task",
        "Status": "Open",
        "Priority": "Major",
        "Resolution": "Unresolved",
        "Affects Version/s": "None",
        "Fix Version/s": "None",
        "Component/s": "Website",
        "Assignee": null,
        "Reporter": "Jeff Zemerick",
        "Created": "24/Jul/22 22:46",
        "Updated": "25/Jul/22 22:34",
        "Resolved": null,
        "Description": "Create link to ASF Slack #opennlp channel under \"Get Involved\" page",
        "Issue Links": []
    },
    "OPENNLP-1378": {
        "Key": "OPENNLP-1378",
        "Summary": "manifest is null",
        "Type": "Bug",
        "Status": "Closed",
        "Priority": "Major",
        "Resolution": "Not A Problem",
        "Affects Version/s": "2.0.0",
        "Fix Version/s": "None",
        "Component/s": "Build, Packaging and Test",
        "Assignee": null,
        "Reporter": "J F Wellum",
        "Created": "27/Jul/22 07:40",
        "Updated": "17/Oct/22 13:40",
        "Resolved": "17/Oct/22 13:40",
        "Description": "\"Failed to execute goal org.codehaus.mojo:exec-maven-plugin:3.0.0:exec (default-cli) on project SentDetect_Java: Command execution failed.\"\nPlease see attached for stack trace and code",
        "Issue Links": []
    },
    "OPENNLP-1379": {
        "Key": "OPENNLP-1379",
        "Summary": "Allow inputs to ONNX model to be customizable",
        "Type": "Task",
        "Status": "Closed",
        "Priority": "Major",
        "Resolution": "Fixed",
        "Affects Version/s": "2.0.0",
        "Fix Version/s": "2.1.0",
        "Component/s": "None",
        "Assignee": "Jeff Zemerick",
        "Reporter": "Jeff Zemerick",
        "Created": "28/Jul/22 18:38",
        "Updated": "07/Nov/22 13:11",
        "Resolved": "07/Nov/22 13:11",
        "Description": "Allow inputs to ONNX model to be customizable. Some models require inputs different than how it is coded now. Additionally, the outputs need to be customizable as well.\nAllow the user to have more control over the inputs and outputs.",
        "Issue Links": []
    },
    "OPENNLP-1380": {
        "Key": "OPENNLP-1380",
        "Summary": "Add opennlp-dl dependency to Maven page",
        "Type": "Task",
        "Status": "Closed",
        "Priority": "Trivial",
        "Resolution": "Fixed",
        "Affects Version/s": "None",
        "Fix Version/s": "2.1.0",
        "Component/s": "Website",
        "Assignee": "Jeff Zemerick",
        "Reporter": "Jeff Zemerick",
        "Created": "28/Jul/22 22:07",
        "Updated": "07/Nov/22 13:12",
        "Resolved": "07/Nov/22 13:12",
        "Description": "Add opennlp-dl dependency to Maven page at https://opennlp.apache.org/maven-dependency.html.\nThe ONNX code in the opennlp-dl project is separate from the opennlp-tools project. It would be nice to have a new section on that page, e.g.:\nOpenNLP DL Dependency\nTo use the OpenNLP ONNX Runtime integration define the following dependency:\n\u00a0<dependency><groupId>org.apache.opennlp</groupId><artifactId>opennlp-dl</artifactId><version>2.0.0</version></dependency>",
        "Issue Links": []
    },
    "OPENNLP-1381": {
        "Key": "OPENNLP-1381",
        "Summary": "OpenJDK 18+: CLITest fails with java.lang.UnsupportedOperationException: The Security Manager is deprecated and will be removed in a future release",
        "Type": "Bug",
        "Status": "Closed",
        "Priority": "Major",
        "Resolution": "Fixed",
        "Affects Version/s": "2.1.0",
        "Fix Version/s": "2.1.1",
        "Component/s": "Command Line Interface",
        "Assignee": "Richard Zowalla",
        "Reporter": "Bertrand Rigaldies",
        "Created": "01/Aug/22 01:12",
        "Updated": "28/Jan/23 15:00",
        "Resolved": "31/Dec/22 08:40",
        "Description": "As of OpenJDK 18, the Security Manager has been deprecated (see JEP-411 which fails all tests in CLITest.java:\njava.lang.UnsupportedOperationException: The Security Manager is deprecated and will be removed in a future release\n\u00a0 \u00a0 at java.base/java.lang.System.setSecurityManager(System.java:416)\n\u00a0 \u00a0 at opennlp.tools.cmdline.CLITest.installNoExitSecurityManager(CLITest.java:66)\n\u00a0 \u00a0 at java.base/jdk.internal.reflect.DirectMethodHandleAccessor.invoke(DirectMethodHandleAccessor.java:104)\n\u00a0 \u00a0 at java.base/java.lang.reflect.Method.invoke(Method.java:577)\n\u00a0 \u00a0 at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)\n\u00a0 \u00a0 at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)\n\u00a0 \u00a0 at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)\n\u00a0 \u00a0 at org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33)\n\u00a0 \u00a0 at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24)\n\u00a0 \u00a0 at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)\n\u00a0 \u00a0 at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)\n\u00a0 \u00a0 at org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)\n\u00a0 \u00a0 at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)\n\u00a0 \u00a0 at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)\n\u00a0 \u00a0 at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)\n\u00a0 \u00a0 at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)\n\u00a0 \u00a0 at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)\n\u00a0 \u00a0 at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)\n\u00a0 \u00a0 at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)\n\u00a0 \u00a0 at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)\n\u00a0 \u00a0 at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)\n\u00a0 \u00a0 at org.junit.runners.ParentRunner.run(ParentRunner.java:413)\n\u00a0 \u00a0 at org.junit.runner.JUnitCore.run(JUnitCore.java:137)\n\u00a0 \u00a0 at com.intellij.junit4.JUnit4IdeaTestRunner.startRunnerWithArgs(JUnit4IdeaTestRunner.java:69)\n\u00a0 \u00a0 at com.intellij.rt.junit.IdeaTestRunner$Repeater$1.execute(IdeaTestRunner.java:38)\n\u00a0 \u00a0 at com.intellij.rt.execution.junit.TestsRepeater.repeat(TestsRepeater.java:11)\n\u00a0 \u00a0 at com.intellij.rt.junit.IdeaTestRunner$Repeater.startRunnerWithArgs(IdeaTestRunner.java:35)\n\u00a0 \u00a0 at com.intellij.rt.junit.JUnitStarter.prepareStreamsAndStart(JUnitStarter.java:235)\n\u00a0 \u00a0 at com.intellij.rt.junit.JUnitStarter.main(JUnitStarter.java:54)",
        "Issue Links": []
    },
    "OPENNLP-1382": {
        "Key": "OPENNLP-1382",
        "Summary": "Create an DocumentCategorizerDLEvaluatorTool",
        "Type": "Task",
        "Status": "Open",
        "Priority": "Minor",
        "Resolution": "Unresolved",
        "Affects Version/s": "2.0.0",
        "Fix Version/s": "None",
        "Component/s": "None",
        "Assignee": "Jeff Zemerick",
        "Reporter": "Jeff Zemerick",
        "Created": "03/Aug/22 11:14",
        "Updated": "22/Aug/22 14:16",
        "Resolved": null,
        "Description": "Create an DocumentCategorizerDLEvaluatorTool for evaluating document classification ONNX models.\nThere is a circular dependency between opennlp-tools and opennlp-dl so it can't be a CLI tool like the others. (At least not right now without some refactoring.) So just get the tool in there and working and we can make it a CLI tool later.",
        "Issue Links": []
    },
    "OPENNLP-1383": {
        "Key": "OPENNLP-1383",
        "Summary": "Unload to perform document classification inference: class [[[F cannot be cast to class [[F ([[[F and [[F are in module java.base of loader 'bootstrap')",
        "Type": "Bug",
        "Status": "Closed",
        "Priority": "Critical",
        "Resolution": "Not A Problem",
        "Affects Version/s": "2.0.0",
        "Fix Version/s": "None",
        "Component/s": "Deep Learning",
        "Assignee": null,
        "Reporter": "karam madi",
        "Created": "15/Aug/22 12:45",
        "Updated": "19/Aug/22 12:32",
        "Resolved": "19/Aug/22 12:32",
        "Description": "I am trying to infer many versions (Classification/ Sentiment Analysis) of Transformers models (fine-tuned) with the format .onnx using the OpenNLP library in java. I receive all the time the same error, which is \"Unload to perform document classification inference: class [[[F cannot be cast to class [[F ([[[F and [[F are in module java. base of loader 'bootstrap')\".\nThis was in the \"Infer\" function of DocumentCategorizerInference class by executing getValue() in line 30. Could you please help me to know why I am receiving this exception?\nNote: I have also tried the test demo here:https://github.com/apache/opennlp/blob/master/opennlp-dl/src/test/java/opennlp/dl/doccat/DocumentCategorizerDLEval.java, and I got the same error.\nThank you very much for your efforts.\nAws khadour",
        "Issue Links": []
    },
    "OPENNLP-1384": {
        "Key": "OPENNLP-1384",
        "Summary": "Automatically generate classifications map from model's config.json",
        "Type": "Task",
        "Status": "Open",
        "Priority": "Major",
        "Resolution": "Unresolved",
        "Affects Version/s": "2.0.0",
        "Fix Version/s": "None",
        "Component/s": "Deep Learning",
        "Assignee": null,
        "Reporter": "Jeff Zemerick",
        "Created": "24/Aug/22 13:37",
        "Updated": "22/Apr/23 17:14",
        "Resolved": null,
        "Description": "Automatically generate classifications map from model's config.json.\nCurrently, the implementations utilizing ONNX Runtime require a Map that stores the model-assigned value along with the human readable name for each value. This map must be created manually:\nMap<Integer, String> classifications = new HashMap<>();\nclassifications.put(0, \"negative\");\nclassifications.put(1, \"positive\");\nHow to create this map is determined by looking at the model's config.json file. This task is to have OpenNLP read the config.json file and make the map automatically instead of requiring the user to make it manually.",
        "Issue Links": []
    },
    "OPENNLP-1385": {
        "Key": "OPENNLP-1385",
        "Summary": "Fix discrepancy in tokenizer documentation",
        "Type": "Task",
        "Status": "Closed",
        "Priority": "Major",
        "Resolution": "Fixed",
        "Affects Version/s": "1.9.4,                                            2.0.0",
        "Fix Version/s": "2.1.1",
        "Component/s": "Documentation,                                            Tokenizer",
        "Assignee": "Atita Arora",
        "Reporter": "Jeff Zemerick",
        "Created": "17/Sep/22 18:31",
        "Updated": "23/Nov/22 14:39",
        "Resolved": "23/Nov/22 14:38",
        "Description": "In the tokenizer documentation in the user guide, the usage of the tool shows a cutoff option:\n        -cutoff num\n                minimal number of times a feature must be seen, ignored if -params is used.\nHowever, this option is not present in the usage when running the CLI:\nArguments description:\n\u00a0 \u00a0 \u00a0 \u00a0 -factory factoryName\n\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 A sub-class of TokenizerFactory where to get implementation and resources.\n\u00a0 \u00a0 \u00a0 \u00a0 -abbDict path\n\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 abbreviation dictionary in XML format.\n\u00a0 \u00a0 \u00a0 \u00a0 -alphaNumOpt isAlphaNumOpt\n\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 Optimization flag to skip alpha numeric tokens for further tokenization\n\u00a0 \u00a0 \u00a0 \u00a0 -params paramsFile\n\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 training parameters file.\n\u00a0 \u00a0 \u00a0 \u00a0 -lang language\n\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 language which is being processed.\n\u00a0 \u00a0 \u00a0 \u00a0 -model modelFile\n\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 output model file.\n\u00a0 \u00a0 \u00a0 \u00a0 -data sampleData\n\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 data to be used, usually a file name.\n\u00a0 \u00a0 \u00a0 \u00a0 -encoding charsetName\n\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 encoding for reading and writing text, if absent the system default is used.\nThe CLI does not recognize cutoff as an option so it is likely the documentation is incorrect but a review of the code should probably be done first to be sure.",
        "Issue Links": []
    },
    "OPENNLP-1386": {
        "Key": "OPENNLP-1386",
        "Summary": "Make parameter names in the params file be not case-sensitive",
        "Type": "Task",
        "Status": "Closed",
        "Priority": "Minor",
        "Resolution": "Fixed",
        "Affects Version/s": "1.9.4,                                            2.0.0",
        "Fix Version/s": "2.1.0",
        "Component/s": "Tokenizer",
        "Assignee": "Jeff Zemerick",
        "Reporter": "Jeff Zemerick",
        "Created": "17/Sep/22 18:41",
        "Updated": "07/Nov/22 13:12",
        "Resolved": "07/Nov/22 13:12",
        "Description": "When training a model, there is the option of supplying a params file using the -params option. The names of the parameters in this file are case sensitive.\nFor instance, \"Cutoff=1\" is valid while \"cutoff=1\" is not valid.\nHaving these parameters not be case sensitive would be helpful.\n(The parameters are in the TrainingParameters class.)",
        "Issue Links": []
    },
    "OPENNLP-1387": {
        "Key": "OPENNLP-1387",
        "Summary": "Fix alphaNumOpt in tokenizer example",
        "Type": "Task",
        "Status": "Closed",
        "Priority": "Major",
        "Resolution": "Fixed",
        "Affects Version/s": "1.9.4,                                            2.0.0",
        "Fix Version/s": "2.1.0",
        "Component/s": "Documentation,                                            Tokenizer",
        "Assignee": "Atita Arora",
        "Reporter": "Jeff Zemerick",
        "Created": "17/Sep/22 19:29",
        "Updated": "07/Nov/22 13:10",
        "Resolved": "07/Nov/22 13:10",
        "Description": "The example command for the tokenizer in the documentation is:\nopennlp TokenizerTrainer -model en-token.bin -alphaNumOpt -lang en -data en-token.train -encoding UTF-8\nThis is an invalid command because the alphaNumOpt parameter must have a value. Running this command as-is will give the error \"Number of parameters must be always be even.\"\u00a0\nThe documentation for alphaNumOpt specifies it must have a value:\n\n-alphaNumOpt isAlphaNumOpt\nOptimization flag to skip alpha numeric tokens for further tokenization",
        "Issue Links": []
    },
    "OPENNLP-1388": {
        "Key": "OPENNLP-1388",
        "Summary": "Inconsistency in span.getCoveredText()",
        "Type": "Task",
        "Status": "Open",
        "Priority": "Major",
        "Resolution": "Unresolved",
        "Affects Version/s": "1.9.4,                                            2.0.0",
        "Fix Version/s": "None",
        "Component/s": "None",
        "Assignee": "Jeff Zemerick",
        "Reporter": "Jeff Zemerick",
        "Created": "13/Oct/22 13:25",
        "Updated": "17/Oct/22 12:29",
        "Resolved": null,
        "Description": "Span.getCoveredText() is getting the string based on the character start/end and not the token start/end.\nExample:\nstring = \"Neil Abercrombie Anibal Acevedo-Vila Gary Ackerman\"\nspan = [0..2) person\nspan.getCoveredText(sentence)) returns \"Ne\" and not \"Neil Abercrombie\"\nWhat is the correct behavior?\nThere is a branch that illustrates this at https://github.com/apache/opennlp/compare/master...jzonthemtn:opennlp:OPENNLP-1388.",
        "Issue Links": []
    },
    "OPENNLP-1389": {
        "Key": "OPENNLP-1389",
        "Summary": "Update the enforcer text to say Java 11 instead of 8",
        "Type": "Task",
        "Status": "Closed",
        "Priority": "Trivial",
        "Resolution": "Fixed",
        "Affects Version/s": "None",
        "Fix Version/s": "2.1.0",
        "Component/s": "None",
        "Assignee": "Atita Arora",
        "Reporter": "Jeff Zemerick",
        "Created": "14/Oct/22 13:28",
        "Updated": "07/Nov/22 13:12",
        "Resolved": "07/Nov/22 13:12",
        "Description": "In the pom.xml:\n<message>Java 8 or higher is required to compile this module</message>\nJava 11 is required so the message text needs updated.",
        "Issue Links": []
    },
    "OPENNLP-1390": {
        "Key": null,
        "Summary": null,
        "Type": null,
        "Status": null,
        "Priority": null,
        "Resolution": null,
        "Affects Version/s": null,
        "Fix Version/s": null,
        "Component/s": null,
        "Assignee": null,
        "Reporter": null,
        "Created": null,
        "Updated": null,
        "Resolved": null,
        "Description": null,
        "Issue Links": []
    },
    "OPENNLP-1391": {
        "Key": "OPENNLP-1391",
        "Summary": "Publish snapshot builds",
        "Type": "Task",
        "Status": "Closed",
        "Priority": "Major",
        "Resolution": "Done",
        "Affects Version/s": "None",
        "Fix Version/s": "2.1.1",
        "Component/s": "Build, Packaging and Test",
        "Assignee": "Richard Zowalla",
        "Reporter": "Jeff Zemerick",
        "Created": "17/Oct/22 20:45",
        "Updated": "26/Nov/22 00:18",
        "Resolved": "26/Nov/22 00:18",
        "Description": "Update GitHub actions to publish snapshot build artifacts.\nhttps://repository.apache.org/content/groups/snapshots/org/apache/opennlp/opennlp/",
        "Issue Links": []
    },
    "OPENNLP-1392": {
        "Key": "OPENNLP-1392",
        "Summary": "POS models created with 2.x are trained with different parameters due to conditional",
        "Type": "Task",
        "Status": "Closed",
        "Priority": "Major",
        "Resolution": "Fixed",
        "Affects Version/s": "2.0.0",
        "Fix Version/s": "2.1.0",
        "Component/s": "POS Tagger",
        "Assignee": "Jeff Zemerick",
        "Reporter": "Jeff Zemerick",
        "Created": "26/Oct/22 15:52",
        "Updated": "07/Nov/22 13:10",
        "Resolved": "07/Nov/22 13:10",
        "Description": "POS models that are trained with version 2.x are trained with different parameters than what's expected due to a conditional in POSTaggerFactory that looked at the minor revision. This conditional assumes the major version is 1.\nThe conditional needs updated to check the major version, too.\nTo reproduce, run the ConllXPosTaggerEval.evalDanishMaxentGis() test.",
        "Issue Links": []
    },
    "OPENNLP-1393": {
        "Key": "OPENNLP-1393",
        "Summary": "Update DoccatDL tests for OPENNLP-1374",
        "Type": "Task",
        "Status": "Closed",
        "Priority": "Major",
        "Resolution": "Fixed",
        "Affects Version/s": "None",
        "Fix Version/s": "2.1.0",
        "Component/s": "Build, Packaging and Test,                                            Deep Learning",
        "Assignee": "Jeff Zemerick",
        "Reporter": "Jeff Zemerick",
        "Created": "27/Oct/22 16:26",
        "Updated": "07/Nov/22 13:10",
        "Resolved": "07/Nov/22 13:10",
        "Description": "In OPENNLP-1374, the doccat DL code was changed to split text when doing the inference to avoid the limitation of only working on short text.\nThis change caused the expected Eval test results to also change and they were not updated at that time.\nNeed to update the expected Eval test results.",
        "Issue Links": []
    },
    "OPENNLP-1394": {
        "Key": "OPENNLP-1394",
        "Summary": "Reduce compiler warnings during build",
        "Type": "Improvement",
        "Status": "Closed",
        "Priority": "Minor",
        "Resolution": "Fixed",
        "Affects Version/s": "2.0.0",
        "Fix Version/s": "2.1.1",
        "Component/s": "None",
        "Assignee": "Martin Wiesner",
        "Reporter": "Martin Wiesner",
        "Created": "30/Oct/22 15:45",
        "Updated": "23/Nov/22 16:10",
        "Resolved": "23/Nov/22 16:10",
        "Description": "While working on OPENNLP-1366, I noticed a significant amount of javac warnings due to switch to Java-11, such as unchecked variable assignments, unclear types. Furthermore several deprecation warnings arose during build.\n\u00a0\nGoal:\nReduce the amount of compiler warnings to a minimum.",
        "Issue Links": []
    },
    "OPENNLP-1395": {
        "Key": "OPENNLP-1395",
        "Summary": "Release OpenNLP 2.1.0",
        "Type": "Task",
        "Status": "Closed",
        "Priority": "Major",
        "Resolution": "Fixed",
        "Affects Version/s": "None",
        "Fix Version/s": "2.1.0",
        "Component/s": "Build, Packaging and Test",
        "Assignee": "Jeff Zemerick",
        "Reporter": "Jeff Zemerick",
        "Created": "31/Oct/22 12:55",
        "Updated": "09/Jan/23 18:36",
        "Resolved": "09/Dec/22 10:40",
        "Description": "This ticket is to track the work to release OpenNLP 2.1.0.",
        "Issue Links": []
    },
    "OPENNLP-1396": {
        "Key": "OPENNLP-1396",
        "Summary": "Use SentenceDetector to split input text into sentences for NameFinderDL",
        "Type": "Task",
        "Status": "Open",
        "Priority": "Major",
        "Resolution": "Unresolved",
        "Affects Version/s": "2.0.0",
        "Fix Version/s": "None",
        "Component/s": "Name Finder",
        "Assignee": "Jeff Zemerick",
        "Reporter": "Jeff Zemerick",
        "Created": "20/Nov/22 13:49",
        "Updated": "20/Nov/22 13:49",
        "Resolved": null,
        "Description": "Use a SentenceDetector to split input text into sentences for NameFinderDL. This is required when the input for inference is too long. The input text needs to either be split by OpenNLP or by the application using OpenNLP. I think it would be best to at least have an option for OpenNLP to split the text, while allowing the application to split the text itself if the developer needs more control over the process.",
        "Issue Links": []
    },
    "OPENNLP-1397": {
        "Key": "OPENNLP-1397",
        "Summary": "Build should fail fast if an unsupported JDK is used",
        "Type": "Task",
        "Status": "Closed",
        "Priority": "Minor",
        "Resolution": "Fixed",
        "Affects Version/s": "2.0.0,                                            2.1.0",
        "Fix Version/s": "2.1.1",
        "Component/s": "Build, Packaging and Test",
        "Assignee": "Suneel Marthi",
        "Reporter": "Jeff Zemerick",
        "Created": "22/Nov/22 15:19",
        "Updated": "23/Nov/22 13:53",
        "Resolved": "23/Nov/22 13:53",
        "Description": "The build should fail fast if an unsupported JDK is used. Check to see if the Maven Enforcer plugin is configured correctly or if something else is needed.\nThis issue came about from smarthi testing the OpenNLP 2.1.0 RC1 using Amazon Corretto 8. The build did not fail until a failed unit test.",
        "Issue Links": []
    },
    "OPENNLP-1398": {
        "Key": "OPENNLP-1398",
        "Summary": "Address temporary file information disclosure vulnerability",
        "Type": "Task",
        "Status": "Closed",
        "Priority": "Minor",
        "Resolution": "Fixed",
        "Affects Version/s": "None",
        "Fix Version/s": "2.1.1",
        "Component/s": "None",
        "Assignee": "Jeff Zemerick",
        "Reporter": "Jeff Zemerick",
        "Created": "23/Nov/22 14:39",
        "Updated": "01/Feb/23 17:18",
        "Resolved": "01/Feb/23 17:18",
        "Description": "See the description that was written in the pull request at https://github.com/apache/opennlp/pull/435.",
        "Issue Links": []
    },
    "OPENNLP-1399": {
        "Key": "OPENNLP-1399",
        "Summary": "Integrate ASF Matomo into OpenNLP website",
        "Type": "Task",
        "Status": "Closed",
        "Priority": "Minor",
        "Resolution": "Fixed",
        "Affects Version/s": "2.1.0",
        "Fix Version/s": "2.1.1",
        "Component/s": "Website",
        "Assignee": "Richard Zowalla",
        "Reporter": "Richard Zowalla",
        "Created": "30/Nov/22 18:46",
        "Updated": "28/Jan/23 15:00",
        "Resolved": "02/Dec/22 15:13",
        "Description": "as the title says",
        "Issue Links": []
    },
    "OPENNLP-1400": {
        "Key": "OPENNLP-1400",
        "Summary": "Enhance JavaDoc in opennlp.tools.sentdetect package",
        "Type": "Improvement",
        "Status": "Closed",
        "Priority": "Minor",
        "Resolution": "Fixed",
        "Affects Version/s": "2.1.0",
        "Fix Version/s": "2.1.1",
        "Component/s": "Documentation",
        "Assignee": "Bruno P. Kinoshita",
        "Reporter": "Martin Wiesner",
        "Created": "02/Dec/22 13:31",
        "Updated": "28/Jan/23 15:00",
        "Resolved": "02/Dec/22 14:06",
        "Description": "The JavaDoc the opennlp.tools.sentdetect package suffers from several inconsistencies and missing descriptions. Moreover, several typos are present that need sanitizing.\nIt needs enhancements and/or additions to provide more clarity.",
        "Issue Links": []
    },
    "OPENNLP-1401": {
        "Key": "OPENNLP-1401",
        "Summary": "Enhance JavaDoc in opennlp.tools.chunker package",
        "Type": "Improvement",
        "Status": "Closed",
        "Priority": "Minor",
        "Resolution": "Fixed",
        "Affects Version/s": "2.1.0",
        "Fix Version/s": "2.1.1",
        "Component/s": "Chunker,                                            Documentation",
        "Assignee": "Bruno P. Kinoshita",
        "Reporter": "Martin Wiesner",
        "Created": "04/Dec/22 09:09",
        "Updated": "28/Jan/23 15:00",
        "Resolved": "04/Dec/22 09:30",
        "Description": "The JavaDoc the opennlp.tools.chunker package suffers from several inconsistencies and missing descriptions. Moreover, several typos are present that need sanitizing.\nIt needs enhancements and/or additions to provide more clarity for readers of that part of the OpenNLP API.",
        "Issue Links": []
    },
    "OPENNLP-1402": {
        "Key": "OPENNLP-1402",
        "Summary": "Replace Travis with GitHub actions on opennlp-site",
        "Type": "Task",
        "Status": "Closed",
        "Priority": "Trivial",
        "Resolution": "Fixed",
        "Affects Version/s": "None",
        "Fix Version/s": "2.1.1",
        "Component/s": "Website",
        "Assignee": "Richard Zowalla",
        "Reporter": "Richard Zowalla",
        "Created": "04/Dec/22 09:52",
        "Updated": "04/Dec/22 11:26",
        "Resolved": "04/Dec/22 11:26",
        "Description": "as the title says",
        "Issue Links": []
    },
    "OPENNLP-1403": {
        "Key": "OPENNLP-1403",
        "Summary": "Enhance JavaDoc in opennlp.tools.langdetect and opennlp.tools.languagemodel packages",
        "Type": "Improvement",
        "Status": "Closed",
        "Priority": "Minor",
        "Resolution": "Fixed",
        "Affects Version/s": "2.1.0",
        "Fix Version/s": "2.1.1",
        "Component/s": "Documentation",
        "Assignee": "Bruno P. Kinoshita",
        "Reporter": "Martin Wiesner",
        "Created": "04/Dec/22 11:46",
        "Updated": "28/Jan/23 15:00",
        "Resolved": "04/Dec/22 13:29",
        "Description": "The JavaDoc of the opennlp.tools.langdetect and opennlp.tools.languagemodel packages suffer from several inconsistencies and missing descriptions. Moreover, several typos are present that need sanitizing.\nIt needs enhancements and/or additions to provide more clarity for readers of that part of the OpenNLP API.",
        "Issue Links": []
    },
    "OPENNLP-1404": {
        "Key": "OPENNLP-1404",
        "Summary": "Enhance JavaDoc in opennlp.tools.postag package",
        "Type": "Improvement",
        "Status": "Closed",
        "Priority": "Minor",
        "Resolution": "Fixed",
        "Affects Version/s": "2.1.0",
        "Fix Version/s": "2.1.1",
        "Component/s": "Documentation,                                            POS Tagger",
        "Assignee": "Martin Wiesner",
        "Reporter": "Martin Wiesner",
        "Created": "04/Dec/22 13:32",
        "Updated": "12/Dec/22 13:04",
        "Resolved": "12/Dec/22 13:04",
        "Description": "The JavaDoc of the opennlp.tools.postag package suffers from several inconsistencies and missing descriptions. Moreover, several typos are present that need sanitizing.\nIt needs enhancements and/or additions to provide more clarity for readers of this part of the OpenNLP API.",
        "Issue Links": []
    },
    "OPENNLP-1405": {
        "Key": "OPENNLP-1405",
        "Summary": "Enhance JavaDoc in opennlp.tools.tokenize package",
        "Type": "Improvement",
        "Status": "Closed",
        "Priority": "Minor",
        "Resolution": "Fixed",
        "Affects Version/s": "2.0.0",
        "Fix Version/s": "2.1.1",
        "Component/s": "Documentation,                                            Tokenizer",
        "Assignee": "Martin Wiesner",
        "Reporter": "Martin Wiesner",
        "Created": "04/Dec/22 17:40",
        "Updated": "10/Dec/22 14:22",
        "Resolved": "10/Dec/22 14:22",
        "Description": "The JavaDoc the opennlp.tools.tokenize package suffers from several inconsistencies and missing descriptions. Moreover, several typos are present that need sanitizing.\nIt needs enhancements and/or additions to provide more clarity for readers.",
        "Issue Links": []
    },
    "OPENNLP-1406": {
        "Key": "OPENNLP-1406",
        "Summary": "Enhance JavaDoc in opennlp.tools.parser package",
        "Type": "Improvement",
        "Status": "Closed",
        "Priority": "Minor",
        "Resolution": "Fixed",
        "Affects Version/s": "2.1.0",
        "Fix Version/s": "2.1.1",
        "Component/s": "Documentation,                                            Parser",
        "Assignee": "Martin Wiesner",
        "Reporter": "Martin Wiesner",
        "Created": "04/Dec/22 17:42",
        "Updated": "10/Dec/22 14:19",
        "Resolved": "10/Dec/22 14:19",
        "Description": "The JavaDoc the opennlp.tools.parser package suffers from several inconsistencies and missing descriptions. Moreover, several typos are present that need sanitizing.\nIt needs enhancements and/or additions to provide more clarity for readers.",
        "Issue Links": []
    },
    "OPENNLP-1407": {
        "Key": "OPENNLP-1407",
        "Summary": "Incorporate a sentence detector into the NER",
        "Type": "Task",
        "Status": "Closed",
        "Priority": "Major",
        "Resolution": "Fixed",
        "Affects Version/s": "None",
        "Fix Version/s": "2.1.1",
        "Component/s": "Deep Learning,                                            Sentence Detector",
        "Assignee": "Jeff Zemerick",
        "Reporter": "Jeff Zemerick",
        "Created": "05/Dec/22 19:19",
        "Updated": "10/Dec/22 14:18",
        "Resolved": "10/Dec/22 14:18",
        "Description": "Incorporate a sentence detector into the NER to split the input text by sentence prior to inference.",
        "Issue Links": []
    },
    "OPENNLP-1408": {
        "Key": "OPENNLP-1408",
        "Summary": "Enhance JavaDoc in opennlp.tools.doccat package",
        "Type": "Improvement",
        "Status": "Closed",
        "Priority": "Minor",
        "Resolution": "Fixed",
        "Affects Version/s": "2.1.0",
        "Fix Version/s": "2.1.1",
        "Component/s": "Doccat,                                            Documentation",
        "Assignee": "Martin Wiesner",
        "Reporter": "Martin Wiesner",
        "Created": "09/Dec/22 10:35",
        "Updated": "12/Dec/22 13:03",
        "Resolved": "12/Dec/22 13:03",
        "Description": "The JavaDoc the opennlp.tools.doccat package suffers from several inconsistencies and missing descriptions. Moreover, several typos are present that need sanitizing.\nIt needs enhancements and/or additions to provide more clarity for readers.",
        "Issue Links": []
    },
    "OPENNLP-1409": {
        "Key": "OPENNLP-1409",
        "Summary": "Enhance JavaDoc in opennlp.tools.lemmatizer package",
        "Type": "Improvement",
        "Status": "Closed",
        "Priority": "Minor",
        "Resolution": "Fixed",
        "Affects Version/s": "2.1.0",
        "Fix Version/s": "2.1.1",
        "Component/s": "Lemmatizer",
        "Assignee": "Martin Wiesner",
        "Reporter": "Martin Wiesner",
        "Created": "10/Dec/22 16:05",
        "Updated": "11/Dec/22 14:15",
        "Resolved": "11/Dec/22 14:15",
        "Description": "The JavaDoc the opennlp.tools.lemmatizer package suffers from several inconsistencies and missing descriptions. Moreover, several typos are present that need sanitizing.\nIt needs enhancements and/or additions to provide more clarity for readers.",
        "Issue Links": []
    },
    "OPENNLP-1410": {
        "Key": "OPENNLP-1410",
        "Summary": "Enhance JavaDoc in opennlp.tools.namefind package",
        "Type": "Improvement",
        "Status": "Closed",
        "Priority": "Minor",
        "Resolution": "Fixed",
        "Affects Version/s": "2.1.0",
        "Fix Version/s": "2.1.1",
        "Component/s": "Name Finder",
        "Assignee": "Martin Wiesner",
        "Reporter": "Martin Wiesner",
        "Created": "10/Dec/22 16:07",
        "Updated": "28/Jan/23 15:00",
        "Resolved": "30/Dec/22 19:11",
        "Description": "The JavaDoc the opennlp.tools.namefind package suffers from several inconsistencies and missing descriptions. Moreover, several typos are present that need sanitizing.\nIt needs enhancements and/or additions to provide more clarity for readers.",
        "Issue Links": []
    },
    "OPENNLP-1411": {
        "Key": "OPENNLP-1411",
        "Summary": "Provide equals and hashCode for POSModel",
        "Type": "Improvement",
        "Status": "Closed",
        "Priority": "Minor",
        "Resolution": "Fixed",
        "Affects Version/s": "2.1.0",
        "Fix Version/s": "2.1.1",
        "Component/s": "POS Tagger",
        "Assignee": "Martin Wiesner",
        "Reporter": "Martin Wiesner",
        "Created": "11/Dec/22 14:54",
        "Updated": "28/Jan/23 15:00",
        "Resolved": "14/Dec/22 13:39",
        "Description": "The test\u00a0opennlp.tools.postag.POSModelTest\u00a0signals by two TODOs that no actual assertions are made to check whether (de-)serialized POSModel instances are correctly read in again.\nIn other words: opennlp.tools.postag.POSModel lacks a valid equals/hashCode implementation by which one could verify a valid state (=equality) after (de-)serialization has occurred.\nIn addition, two possible base classes GISModel and PerceptronModel also require valid equals/hashCode implementations, so that POSModel's equals/hashCode will work properly.\nAim:\n\nProvide an improved implementation of the POS-related \"Model\" classes.\nRemove both TODOs in POSModelTest\nImprove both test cases (MaxEnt/GIS and Perceptron) with further test assertions.",
        "Issue Links": []
    },
    "OPENNLP-1412": {
        "Key": "OPENNLP-1412",
        "Summary": "Provide equals and hashCode for ParserModel and TokenizerModel",
        "Type": "Improvement",
        "Status": "Closed",
        "Priority": "Minor",
        "Resolution": "Fixed",
        "Affects Version/s": "2.1.0",
        "Fix Version/s": "2.1.1",
        "Component/s": "Parser,                                            Tokenizer",
        "Assignee": "Martin Wiesner",
        "Reporter": "Martin Wiesner",
        "Created": "11/Dec/22 18:00",
        "Updated": "28/Jan/23 15:00",
        "Resolved": "30/Dec/22 19:11",
        "Description": "The tests opennlp.tools.tokenize.TokenizerModelTest, opennlp.tools.parser.chunking.ParserTest, and opennlp.tools.parser.treeinsert.ParserTest signal by TODOs that no actual assertions are made to check whether (de-)serialized Model instances are correctly read in again.\nIn other words: Those (Tokenizer/Parser) models lacks a valid equals/hashCode implementation by which one could verify a valid state (=equality) after (de-)serialization has occurred.\nAim:\n\nProvide an improved implementation of the related \"Model\" classes.\nRemove existing TODOs in TokenizerModelTest and ParserTest\nImprove the three test classes with further test assertions.",
        "Issue Links": []
    },
    "OPENNLP-1413": {
        "Key": "OPENNLP-1413",
        "Summary": "Enhance JavaDoc in opennlp.tools.util package",
        "Type": "Improvement",
        "Status": "Closed",
        "Priority": "Minor",
        "Resolution": "Fixed",
        "Affects Version/s": "2.1.0",
        "Fix Version/s": "2.1.1",
        "Component/s": "Documentation",
        "Assignee": "Martin Wiesner",
        "Reporter": "Martin Wiesner",
        "Created": "15/Dec/22 15:23",
        "Updated": "29/Dec/22 15:34",
        "Resolved": "29/Dec/22 15:33",
        "Description": "The JavaDoc the\u00a0opennlp.tools.util\u00a0package suffers from several inconsistencies and missing descriptions. Moreover, several typos are present that need sanitizing.\nIt needs enhancements and/or additions to provide more clarity for readers.",
        "Issue Links": []
    },
    "OPENNLP-1414": {
        "Key": "OPENNLP-1414",
        "Summary": "Investigate why DownloadUtil can't retrieve NL models via CDN",
        "Type": "Improvement",
        "Status": "Closed",
        "Priority": "Minor",
        "Resolution": "Fixed",
        "Affects Version/s": "2.1.0",
        "Fix Version/s": "2.1.1",
        "Component/s": "None",
        "Assignee": "Martin Wiesner",
        "Reporter": "Martin Wiesner",
        "Created": "16/Dec/22 12:01",
        "Updated": "30/Dec/22 12:01",
        "Resolved": "30/Dec/22 12:00",
        "Description": "While working on OPENNLP-1413, I discovered that the class\u00a0opennlp.tools.util.DownloadUtil has a runtime issue with downloading resources (models) for the Dutch locale (nl). Other locales referenced via the static initializer block are accessible and can be downloaded.\nMoreover, a JUnit test is missing and should be provided.\nAim:\n\nInvestigate what's wrong with NL resources.\nIf possible, fix the problem with retrieving Dutch models.\nProvide a JUnit tests that demonstrates correct behavior for all locales.\n\nJavaDoc is improved via OPENNLP-1413. Don't work on it twice...\nNote:\nFor Dutch community this affects other parts of the Tools component as Model classes rely on DownloadUtil in at least one constructor. Therefore, this should be fixed before the next release.",
        "Issue Links": []
    },
    "OPENNLP-1415": {
        "Key": "OPENNLP-1415",
        "Summary": "Enhance JavaDoc in opennlp.tools.formats.masc package",
        "Type": "Improvement",
        "Status": "Closed",
        "Priority": "Minor",
        "Resolution": "Fixed",
        "Affects Version/s": "2.1.0",
        "Fix Version/s": "2.1.1",
        "Component/s": "Formats",
        "Assignee": "Martin Wiesner",
        "Reporter": "Martin Wiesner",
        "Created": "17/Dec/22 18:02",
        "Updated": "20/Dec/22 16:24",
        "Resolved": "20/Dec/22 16:24",
        "Description": "The JavaDoc the\u00a0opennlp.tools.formats.masc\u00a0package suffers from several inconsistencies and missing descriptions. Moreover, several typos are present that need sanitizing.\nIt needs enhancements and/or additions to provide more clarity for readers.",
        "Issue Links": []
    },
    "OPENNLP-1416": {
        "Key": "OPENNLP-1416",
        "Summary": "Enhance JavaDoc in opennlp.tools.formats.ad package",
        "Type": "Improvement",
        "Status": "Closed",
        "Priority": "Minor",
        "Resolution": "Fixed",
        "Affects Version/s": "2.1.0",
        "Fix Version/s": "2.1.1",
        "Component/s": "Formats",
        "Assignee": "Martin Wiesner",
        "Reporter": "Martin Wiesner",
        "Created": "17/Dec/22 21:11",
        "Updated": "20/Dec/22 16:25",
        "Resolved": "20/Dec/22 16:25",
        "Description": "The JavaDoc the\u00a0opennlp.tools.formats.ad\u00a0package suffers from several inconsistencies and missing descriptions. Moreover, several typos are present that need sanitizing.\nIt needs enhancements and/or additions to provide more clarity for readers.",
        "Issue Links": []
    },
    "OPENNLP-1417": {
        "Key": "OPENNLP-1417",
        "Summary": "Reduce unchecked assignments and raw types in TrainerFactory",
        "Type": "Improvement",
        "Status": "Closed",
        "Priority": "Minor",
        "Resolution": "Fixed",
        "Affects Version/s": "2.1.0",
        "Fix Version/s": "2.1.1",
        "Component/s": "Machine Learning",
        "Assignee": "Martin Wiesner",
        "Reporter": "Martin Wiesner",
        "Created": "18/Dec/22 12:11",
        "Updated": "20/Dec/22 16:23",
        "Resolved": "20/Dec/22 16:23",
        "Description": "The class\u00a0opennlp.tools.ml.TrainerFactory shows unchecked assignments and raw types.\nAims:\n\nReduce the compiler warnings as best as possible\nAdapt dependent classes\nImprove JavaDoc accordingly",
        "Issue Links": []
    },
    "OPENNLP-1418": {
        "Key": "OPENNLP-1418",
        "Summary": "Rename master branch to main",
        "Type": "Task",
        "Status": "Resolved",
        "Priority": "Major",
        "Resolution": "Fixed",
        "Affects Version/s": "None",
        "Fix Version/s": "None",
        "Component/s": "None",
        "Assignee": "Richard Zowalla",
        "Reporter": "Jeff Zemerick",
        "Created": "19/Dec/22 19:33",
        "Updated": "22/Dec/22 13:31",
        "Resolved": "22/Dec/22 13:31",
        "Description": "After a discussion on the mailing list it was decided to rename the master branch to main.\u00a0\nWe should rename the branches on both the opennlp and opennlp-site repositories. GitHub Actions and BuildBot will need updated (respectively) after the change.",
        "Issue Links": []
    },
    "OPENNLP-1419": {
        "Key": "OPENNLP-1419",
        "Summary": "Enhance Tests and JavaDoc in opennlp.morfologik package",
        "Type": "Improvement",
        "Status": "Closed",
        "Priority": "Minor",
        "Resolution": "Fixed",
        "Affects Version/s": "2.1.0",
        "Fix Version/s": "2.1.1",
        "Component/s": "Morfologik Addon",
        "Assignee": "Martin Wiesner",
        "Reporter": "Martin Wiesner",
        "Created": "19/Dec/22 21:28",
        "Updated": "28/Jan/23 15:00",
        "Resolved": "22/Dec/22 09:45",
        "Description": "The (JUnit) tests in opennlp.morfologik package show an anti-pattern of test classes relying on each other, that is: code is mixed around and feels near to spaghetti. Moreover, the naming of some of the existing test classes is not consistent with the classes under test. This should both be fixed and improved.\nThe JavaDoc the\u00a0opennlp.morfologik package shows several inconsistencies and missing descriptions. Moreover, several typos are present that need sanitizing, especially in class names.\nBoth aspects need a cure and the package some additions to provide more clarity for readers of the API and devs with respect to understanding the test setup correctly.",
        "Issue Links": []
    },
    "OPENNLP-1420": {
        "Key": "OPENNLP-1420",
        "Summary": "uimaj-core 3.3.1",
        "Type": "Dependency upgrade",
        "Status": "Closed",
        "Priority": "Minor",
        "Resolution": "Fixed",
        "Affects Version/s": "2.0.0",
        "Fix Version/s": "2.1.1",
        "Component/s": "None",
        "Assignee": "Richard Zowalla",
        "Reporter": "Richard Zowalla",
        "Created": "20/Dec/22 07:45",
        "Updated": "01/Feb/23 17:18",
        "Resolved": "01/Feb/23 17:18",
        "Description": "https://github.com/apache/opennlp/pull/463",
        "Issue Links": []
    },
    "OPENNLP-1421": {
        "Key": "OPENNLP-1421",
        "Summary": "Improve tests in opennlp.tools.formats package",
        "Type": "Improvement",
        "Status": "Closed",
        "Priority": "Minor",
        "Resolution": "Fixed",
        "Affects Version/s": "2.1.0",
        "Fix Version/s": "2.1.1",
        "Component/s": "Build, Packaging and Test,                                            Formats",
        "Assignee": "Martin Wiesner",
        "Reporter": "Martin Wiesner",
        "Created": "21/Dec/22 12:39",
        "Updated": "23/Dec/22 20:56",
        "Resolved": "23/Dec/22 20:56",
        "Description": "The unit tests for the opennlp.tools.formats\u00a0package can be optimized towards less code duplication. For the current test classes, this is observed for reading or loading (file-based) resources required to conduct the actual testing.\nAims:\n\nReduce code duplication\nExtract common ways of finding/scanning/reading resource files\nOptimize tests towards clarity",
        "Issue Links": []
    },
    "OPENNLP-1422": {
        "Key": "OPENNLP-1422",
        "Summary": "Enhance JavaDoc in opennlp.tools.formats sub-packages",
        "Type": "Improvement",
        "Status": "Closed",
        "Priority": "Minor",
        "Resolution": "Fixed",
        "Affects Version/s": "2.1.0",
        "Fix Version/s": "2.1.1",
        "Component/s": "Formats",
        "Assignee": "Martin Wiesner",
        "Reporter": "Martin Wiesner",
        "Created": "22/Dec/22 14:09",
        "Updated": "27/Dec/22 19:05",
        "Resolved": "27/Dec/22 19:05",
        "Description": "The JavaDoc the\u00a0opennlp.tools.formats.* sub-packages suffer from several inconsistencies and missing descriptions. Moreover, several typos are present that need sanitizing.\nThe classes, interfaces, etc., require enhancements and/or additions to provide more clarity for readers.",
        "Issue Links": []
    },
    "OPENNLP-1423": {
        "Key": "OPENNLP-1423",
        "Summary": "Enhance JavaDoc in opennlp.tools.ml package",
        "Type": "Improvement",
        "Status": "Closed",
        "Priority": "Minor",
        "Resolution": "Fixed",
        "Affects Version/s": "2.1.0",
        "Fix Version/s": "2.1.1",
        "Component/s": "Machine Learning",
        "Assignee": "Martin Wiesner",
        "Reporter": "Martin Wiesner",
        "Created": "22/Dec/22 21:27",
        "Updated": "27/Dec/22 19:05",
        "Resolved": "27/Dec/22 19:05",
        "Description": "The JavaDoc of the opennlp.tools.ml packages suffer from several inconsistencies and missing descriptions. Moreover, several typos are present that need sanitizing.\nThe classes, interfaces, etc., require enhancements and/or additions to provide more clarity for readers.",
        "Issue Links": []
    },
    "OPENNLP-1424": {
        "Key": "OPENNLP-1424",
        "Summary": "Introduce @ThreadSafe as marker annotation for threadsafe OpenNLP classes",
        "Type": "Wish",
        "Status": "Closed",
        "Priority": "Minor",
        "Resolution": "Fixed",
        "Affects Version/s": "None",
        "Fix Version/s": "2.1.1",
        "Component/s": "None",
        "Assignee": "Martin Wiesner",
        "Reporter": "Richard Zowalla",
        "Created": "23/Dec/22 19:54",
        "Updated": "28/Jan/23 15:00",
        "Resolved": "08/Jan/23 08:47",
        "Description": "It would be neat to add an annotation to mark @ThreadSafe classes in OpenNLP. \nWe could use that annotation to generate a list / overview of thread safe components in OpenNLP to improve user experience.",
        "Issue Links": [
            "/jira/browse/OPENNLP-1439"
        ]
    },
    "OPENNLP-1425": {
        "Key": "OPENNLP-1425",
        "Summary": "Remove long-time deprecated update method in AbstractDataIndexer",
        "Type": "Improvement",
        "Status": "Closed",
        "Priority": "Minor",
        "Resolution": "Fixed",
        "Affects Version/s": "2.1.0",
        "Fix Version/s": "2.1.1",
        "Component/s": "Machine Learning",
        "Assignee": "Martin Wiesner",
        "Reporter": "Martin Wiesner",
        "Created": "26/Dec/22 09:38",
        "Updated": "28/Jan/23 15:00",
        "Resolved": "28/Dec/22 11:24",
        "Description": "While working on OPENNLP-1423, rzo1 noted a deprecated a method in AbstractDataIndexer in the related PR:\u00a0\nupdate(String[] ec, Set<String> predicateSet,\nMap<String,Integer> counter, int cutoff)\nThe JavaDoc indicated \"@deprecated will be removed after 1.8.1 release\".\u00a0\nAim:\n\nRemove this method and fulfill the statement made in the JavaDoc\nRework existing code.",
        "Issue Links": []
    },
    "OPENNLP-1426": {
        "Key": "OPENNLP-1426",
        "Summary": "Improve tests in opennlp.tools.formats.brat by adding assertions",
        "Type": "Improvement",
        "Status": "Closed",
        "Priority": "Minor",
        "Resolution": "Fixed",
        "Affects Version/s": "2.1.0",
        "Fix Version/s": "2.1.1",
        "Component/s": "Build, Packaging and Test,                                            Formats",
        "Assignee": "Martin Wiesner",
        "Reporter": "Martin Wiesner",
        "Created": "27/Dec/22 22:11",
        "Updated": "29/Dec/22 15:32",
        "Resolved": "29/Dec/22 15:32",
        "Description": "The unit tests for the\u00a0opennlp.tools.formats.brat\u00a0package can be improved to resolve existing TODOs.\nAims:\n\nResolve TODOs by providing necessary assertions to show correctness\nRemove inter-test dependencies\u00a0\nOptimize tests towards clarity",
        "Issue Links": []
    },
    "OPENNLP-1427": {
        "Key": "OPENNLP-1427",
        "Summary": "Fix incorrect URL for French Tokenizer model files on OpenNLP site",
        "Type": "Improvement",
        "Status": "Resolved",
        "Priority": "Minor",
        "Resolution": "Fixed",
        "Affects Version/s": "None",
        "Fix Version/s": "None",
        "Component/s": "Website",
        "Assignee": "Martin Wiesner",
        "Reporter": "Martin Wiesner",
        "Created": "29/Dec/22 21:18",
        "Updated": "30/Dec/22 18:50",
        "Resolved": "30/Dec/22 18:50",
        "Description": "While working on OpenNLP-1414, it was found that model download page contains incorrect URLs for the French Tokenizer models.\nThe related\u00a0jbake file needs adjustments in lines 172 to 174.\nIncorrect, current state for Tokenizer FR:\n\n\n\n https://www.apache.org/dyn/closer.cgi/opennlp/models/ud-models-1.0/opennlp-en-ud-ewt-tokens-1.0-1.9.3.bin[opennlp-en-ud-ewt-tokens-1.0-1.9.3.bin]\n\n\nhttps://www.apache.org/dyn/closer.cgi/opennlp/models/ud-models-1.0/opennlp-en-ud-ewt-tokens-1.0-1.9.3.bin.sha512[sha512]\nhttps://www.apache.org/dyn/closer.cgi/opennlp/models/ud-models-1.0/opennlp-en-ud-ewt-tokens-1.0-1.9.3.bin.asc[asc]",
        "Issue Links": []
    },
    "OPENNLP-1428": {
        "Key": "OPENNLP-1428",
        "Summary": "Enhance DownloadUtil to avoid the use of hard-coded model urls",
        "Type": "Improvement",
        "Status": "Closed",
        "Priority": "Major",
        "Resolution": "Fixed",
        "Affects Version/s": "2.1.1",
        "Fix Version/s": "2.1.1",
        "Component/s": "None",
        "Assignee": "Richard Zowalla",
        "Reporter": "Richard Zowalla",
        "Created": "30/Dec/22 12:03",
        "Updated": "28/Jan/23 15:00",
        "Resolved": "02/Jan/23 19:04",
        "Description": "As pointed out in https://github.com/apache/opennlp/pull/472, we should not rely on hard-coded URLs in DownloadUtil.\nInstead we can parse the content of https://dlcdn.apache.org/opennlp/models/ud-models-1.0/ and automatically derive the related model files from it.",
        "Issue Links": []
    },
    "OPENNLP-1429": {
        "Key": "OPENNLP-1429",
        "Summary": "Add the Internal annotation to interfaces and classes documented accordingly",
        "Type": "Improvement",
        "Status": "Closed",
        "Priority": "Minor",
        "Resolution": "Fixed",
        "Affects Version/s": "2.1.0",
        "Fix Version/s": "2.1.1",
        "Component/s": "None",
        "Assignee": "Martin Wiesner",
        "Reporter": "Martin Wiesner",
        "Created": "30/Dec/22 15:42",
        "Updated": "02/Jan/23 10:22",
        "Resolved": "02/Jan/23 10:22",
        "Description": "Recently the @Internal annotation was introduced. It can be used as a marker to signal that classes, interfaces or method signatures might change. It should be used throughout all classes that have JavaDoc related text comments.\nAims:\n\nIntroduce @Internal where appropriate\nCheck / improve JavaDoc formatting or style.",
        "Issue Links": []
    },
    "OPENNLP-1430": {
        "Key": "OPENNLP-1430",
        "Summary": "Remove AbstractTempDirTest after @TempDir (JUnit5) is fixed in Windows (Server) environments",
        "Type": "Task",
        "Status": "Open",
        "Priority": "Minor",
        "Resolution": "Unresolved",
        "Affects Version/s": "None",
        "Fix Version/s": "None",
        "Component/s": "Build, Packaging and Test",
        "Assignee": null,
        "Reporter": "Richard Zowalla",
        "Created": "31/Dec/22 08:44",
        "Updated": "31/Dec/22 08:44",
        "Resolved": null,
        "Description": "@TempDir is currently broken in Windows environment on GitHub actions, see https://github.com/junit-team/junit5/issues/2811\nTherefore, https://github.com/apache/opennlp/pull/476 introduced a workaround to manually deal with it by introducing AbstractTempDirTest\nIf the related JUnit issue is fixed, we can drop `AbstractTempDirTest* and switch back to @TempDir",
        "Issue Links": []
    },
    "OPENNLP-1431": {
        "Key": "OPENNLP-1431",
        "Summary": "Enhance JavaDoc in opennlp.tools.dictionary and opennlp.tools.entitylinker packages",
        "Type": "Improvement",
        "Status": "Closed",
        "Priority": "Minor",
        "Resolution": "Fixed",
        "Affects Version/s": "2.1.0",
        "Fix Version/s": "2.1.1",
        "Component/s": "Entity Linker",
        "Assignee": "Martin Wiesner",
        "Reporter": "Martin Wiesner",
        "Created": "31/Dec/22 15:39",
        "Updated": "02/Jan/23 14:04",
        "Resolved": "02/Jan/23 14:04",
        "Description": "The JavaDoc of the\u00a0opennlp.tools.dictionary\u00a0and\u00a0opennlp.tools.entitylinker\u00a0packages suffer from several inconsistencies and missing descriptions. Moreover, several typos are present that need sanitizing.\nIt needs enhancements and/or additions to provide more clarity for readers of that part of the OpenNLP API.",
        "Issue Links": []
    },
    "OPENNLP-1432": {
        "Key": "OPENNLP-1432",
        "Summary": "Provide tests for opennlp.tools.util.wordvector package",
        "Type": "Test",
        "Status": "Closed",
        "Priority": "Minor",
        "Resolution": "Fixed",
        "Affects Version/s": "2.1.0",
        "Fix Version/s": "2.1.1",
        "Component/s": "Build, Packaging and Test,                                            word vectors",
        "Assignee": "Martin Wiesner",
        "Reporter": "Martin Wiesner",
        "Created": "01/Jan/23 21:12",
        "Updated": "02/Jan/23 14:01",
        "Resolved": "02/Jan/23 14:01",
        "Description": "With\u00a0OPENNLP-1144, support for word vectors was introduced. However, no JUnit tests were provided with that implementation.\nAims\n\nProvide tests for opennlp.tools.util.wordvector package\nRaise code coverage for the corresponding package\nImprove JavaDoc along the way",
        "Issue Links": []
    },
    "OPENNLP-1433": {
        "Key": "OPENNLP-1433",
        "Summary": "Document how to do model releases",
        "Type": "Task",
        "Status": "Resolved",
        "Priority": "Major",
        "Resolution": "Fixed",
        "Affects Version/s": "None",
        "Fix Version/s": "None",
        "Component/s": "Documentation,                                            Models,                                            Website",
        "Assignee": "Richard Zowalla",
        "Reporter": "Jeff Zemerick",
        "Created": "02/Jan/23 14:03",
        "Updated": "06/Jan/23 12:18",
        "Resolved": "06/Jan/23 12:18",
        "Description": "Document how to do model releases. We should have a page on opennlp-site that describes how to do a model release. It should contain the model naming conventions, release process, etc.\nSee conversation on https://github.com/apache/opennlp/pull/473.",
        "Issue Links": [
            "/jira/browse/OPENNLP-1328"
        ]
    },
    "OPENNLP-1434": {
        "Key": "OPENNLP-1434",
        "Summary": "Enhance JavaDoc in opennlp.uima packages",
        "Type": "Improvement",
        "Status": "Closed",
        "Priority": "Minor",
        "Resolution": "Fixed",
        "Affects Version/s": "2.1.0",
        "Fix Version/s": "2.1.1",
        "Component/s": "UIMA Integration",
        "Assignee": "Martin Wiesner",
        "Reporter": "Martin Wiesner",
        "Created": "02/Jan/23 16:44",
        "Updated": "13/Jan/23 14:53",
        "Resolved": "03/Jan/23 14:54",
        "Description": "The JavaDoc the\u00a0opennlp.uima.* packages suffer from several inconsistencies and missing descriptions. Moreover, several typos are present that need sanitizing.\nThe classes, interfaces, etc., require enhancements and/or additions to provide more clarity for readers.",
        "Issue Links": []
    },
    "OPENNLP-1435": {
        "Key": "OPENNLP-1435",
        "Summary": "Clear typos from opennlp-docs module",
        "Type": "Improvement",
        "Status": "Closed",
        "Priority": "Minor",
        "Resolution": "Fixed",
        "Affects Version/s": "2.1.0",
        "Fix Version/s": "2.1.1",
        "Component/s": "Documentation",
        "Assignee": "Martin Wiesner",
        "Reporter": "Martin Wiesner",
        "Created": "02/Jan/23 19:02",
        "Updated": "03/Jan/23 14:50",
        "Resolved": "03/Jan/23 14:50",
        "Description": "The opennlp-docs module shows several typos in several docbkx files.\nAims:\n\nResolve obvious typos.\nConvert http to https URLs if possible.",
        "Issue Links": []
    },
    "OPENNLP-1436": {
        "Key": "OPENNLP-1436",
        "Summary": "Fix link to Leipzig corpus",
        "Type": "Task",
        "Status": "Closed",
        "Priority": "Major",
        "Resolution": "Duplicate",
        "Affects Version/s": "None",
        "Fix Version/s": "None",
        "Component/s": "Documentation",
        "Assignee": "Atita Arora",
        "Reporter": "Jeff Zemerick",
        "Created": "03/Jan/23 14:06",
        "Updated": "09/Jan/23 19:00",
        "Resolved": "06/Jan/23 13:46",
        "Description": "Fix the link to the Leipzig corpus in the documentation:\nThe Leipzig Corpora collection presents corpora in different languages. The corpora is a collection of individual sentences collected from the web and newspapers. The Corpora is available as plain text and as MySQL database tables. The OpenNLP integration can only use the plain text version. The individual plain text packages can be downloaded here:\u00a0http://corpora.uni-leipzig.de/download.html",
        "Issue Links": [
            "/jira/browse/OPENNLP-1344",
            "/jira/browse/OPENNLP-1344"
        ]
    },
    "OPENNLP-1437": {
        "Key": "OPENNLP-1437",
        "Summary": "Change removeChar() in NumberUtil.java with String.replaceAll",
        "Type": "Task",
        "Status": "Closed",
        "Priority": "Major",
        "Resolution": "Fixed",
        "Affects Version/s": "None",
        "Fix Version/s": "2.1.1",
        "Component/s": "None",
        "Assignee": "Atita Arora",
        "Reporter": "Jeff Zemerick",
        "Created": "03/Jan/23 14:53",
        "Updated": "11/Jan/23 16:48",
        "Resolved": "11/Jan/23 15:17",
        "Description": "Change removeChar() in NumberUtil.java with String.replaceAll(). See the conversation on the pull request at https://github.com/apache/opennlp/pull/479/files.",
        "Issue Links": []
    },
    "OPENNLP-1438": {
        "Key": "OPENNLP-1438",
        "Summary": "Fix Release Documentation",
        "Type": "Task",
        "Status": "Open",
        "Priority": "Major",
        "Resolution": "Unresolved",
        "Affects Version/s": "None",
        "Fix Version/s": "None",
        "Component/s": "None",
        "Assignee": "Richard Zowalla",
        "Reporter": "Richard Zowalla",
        "Created": "03/Jan/23 17:56",
        "Updated": "03/Jan/23 17:56",
        "Resolved": null,
        "Description": "see discussion / findings in https://github.com/apache/opennlp-site/pull/78 regarding the KEYS file\nSource of truth is KEYS in dist/release according to https://people.apache.org/keys/",
        "Issue Links": []
    },
    "OPENNLP-1439": {
        "Key": "OPENNLP-1439",
        "Summary": "Use @ThreadSafe to declare thread-safe classes",
        "Type": "Task",
        "Status": "Open",
        "Priority": "Minor",
        "Resolution": "Unresolved",
        "Affects Version/s": "None",
        "Fix Version/s": "None",
        "Component/s": "None",
        "Assignee": null,
        "Reporter": "Richard Zowalla",
        "Created": "08/Jan/23 08:49",
        "Updated": "20/Jan/23 07:50",
        "Resolved": null,
        "Description": "With https://issues.apache.org/jira/browse/OPENNLP-1424 the @ThreadSafe annotation was introduced within OpenNLP. \nAim of this issue is to investigate current classes and declare them with @ThreadSafe, if they can be savely used in an concurrent setting. \nAn example for a @ThreadSafe class would be \n\nMorfologikLemmatizerm see https://github.com/apache/opennlp/pull/436",
        "Issue Links": [
            "/jira/browse/OPENNLP-936",
            "/jira/browse/OPENNLP-1424"
        ]
    },
    "OPENNLP-1440": {
        "Key": "OPENNLP-1440",
        "Summary": "Ensure files are read via buffered IO operations",
        "Type": "Improvement",
        "Status": "Closed",
        "Priority": "Minor",
        "Resolution": "Fixed",
        "Affects Version/s": "2.1.0",
        "Fix Version/s": "2.1.1",
        "Component/s": "Applications",
        "Assignee": "Martin Wiesner",
        "Reporter": "Martin Wiesner",
        "Created": "09/Jan/23 20:39",
        "Updated": "11/Jan/23 15:16",
        "Resolved": "11/Jan/23 09:15",
        "Description": "Several classes in opennnlp.tools exist which read files via FileInputStream without using buffered IO. If IO is not buffered, this can impose a (high) performance penalty as the JVM will have to use native (JNI) calls more often (resulting in more sys-calls to the OS).\nWe can avoid that by adapting existing classes to use BufferedInputStream or BufferedReader more consequently.",
        "Issue Links": []
    },
    "OPENNLP-1441": {
        "Key": "OPENNLP-1441",
        "Summary": "Check and possibly replace usage of String.replaceAll(...) in code-base",
        "Type": "Improvement",
        "Status": "Closed",
        "Priority": "Major",
        "Resolution": "Fixed",
        "Affects Version/s": "2.1.0",
        "Fix Version/s": "2.1.1",
        "Component/s": "None",
        "Assignee": "Martin Wiesner",
        "Reporter": "Richard Zowalla",
        "Created": "11/Jan/23 12:05",
        "Updated": "28/Jan/23 15:00",
        "Resolved": "14/Jan/23 19:02",
        "Description": "String.replaceAll(...) is known to have a severe performance impact, if used often.\nWe should check the usage in OpenNLP and replace it, if needed.",
        "Issue Links": []
    },
    "OPENNLP-1442": {
        "Key": "OPENNLP-1442",
        "Summary": "Use ONNX Runtime to support sentence-transformers",
        "Type": "Task",
        "Status": "Closed",
        "Priority": "Major",
        "Resolution": "Done",
        "Affects Version/s": "None",
        "Fix Version/s": "2.2.0",
        "Component/s": "Deep Learning",
        "Assignee": "Jeff Zemerick",
        "Reporter": "Jeff Zemerick",
        "Created": "11/Jan/23 14:58",
        "Updated": "22/Apr/23 17:39",
        "Resolved": "31/Mar/23 19:19",
        "Description": "Use ONNX Runtime to support sentence-transformers. OpenNLP should be able to generate embeddings using an ONNX model.",
        "Issue Links": []
    },
    "OPENNLP-1443": {
        "Key": "OPENNLP-1443",
        "Summary": "Enhance JavaDoc in opennlp.tools.cmdline package",
        "Type": "Improvement",
        "Status": "Closed",
        "Priority": "Minor",
        "Resolution": "Fixed",
        "Affects Version/s": "2.1.0",
        "Fix Version/s": "2.1.1",
        "Component/s": "Command Line Interface",
        "Assignee": "Martin Wiesner",
        "Reporter": "Martin Wiesner",
        "Created": "13/Jan/23 14:50",
        "Updated": "28/Jan/23 15:00",
        "Resolved": "17/Jan/23 14:18",
        "Description": "The JavaDoc of the opennlp.tools.cmdline (sub-) packages suffer from several inconsistencies and missing descriptions. Moreover, several typos are present that need sanitizing.\nThe classes, interfaces, etc., require enhancements and/or additions to provide more clarity for readers.",
        "Issue Links": []
    },
    "OPENNLP-1444": {
        "Key": "OPENNLP-1444",
        "Summary": "Fix typos scattered in all packages",
        "Type": "Improvement",
        "Status": "Closed",
        "Priority": "Minor",
        "Resolution": "Fixed",
        "Affects Version/s": "2.1.0",
        "Fix Version/s": "2.1.1",
        "Component/s": "None",
        "Assignee": "Martin Wiesner",
        "Reporter": "Martin Wiesner",
        "Created": "13/Jan/23 16:44",
        "Updated": "28/Jan/23 14:59",
        "Resolved": "17/Jan/23 19:21",
        "Description": "Several classes or interfaces in various packages shows several typos that should be sanitized.",
        "Issue Links": []
    },
    "OPENNLP-1445": {
        "Key": "OPENNLP-1445",
        "Summary": "Run GH action \"Publish snapshots\" only on ASF repo",
        "Type": "Task",
        "Status": "Resolved",
        "Priority": "Major",
        "Resolution": "Fixed",
        "Affects Version/s": "None",
        "Fix Version/s": "None",
        "Component/s": "None",
        "Assignee": "Richard Zowalla",
        "Reporter": "Richard Zowalla",
        "Created": "17/Jan/23 19:14",
        "Updated": "18/Jan/23 06:50",
        "Resolved": "18/Jan/23 06:50",
        "Description": null,
        "Issue Links": []
    },
    "OPENNLP-1446": {
        "Key": "OPENNLP-1446",
        "Summary": "Investigate why LeskEvaluatorTest and MFSEvaluatorTest fail while parsing 'EnglishLS.train'",
        "Type": "Task",
        "Status": "Open",
        "Priority": "Minor",
        "Resolution": "Unresolved",
        "Affects Version/s": "2.1.0",
        "Fix Version/s": "None",
        "Component/s": "wsd",
        "Assignee": null,
        "Reporter": "Martin Wiesner",
        "Created": "19/Jan/23 16:18",
        "Updated": "19/Jan/23 16:22",
        "Resolved": null,
        "Description": "The LeskEvaluatorTest & MFSEvaluatorTest in the opennlp-wsd sandbox component both fail parsing the 'EnglishLS.train' file. The data is kept original, downloaded from https://web.eecs.umich.edu/~mihalcea/senseval/senseval3/data.html\nAims:\n\nInvestigate what causes the xml parsing to fail\nFix it and make both existing tests pass\nOptional: Improve the existing test code to be more strict.\n\nNote:\nThe test setup to reproduce this is on a branch and to be merged into the main branch.",
        "Issue Links": []
    },
    "OPENNLP-1447": {
        "Key": "OPENNLP-1447",
        "Summary": "Move from System.out/System.err to SLF4J",
        "Type": "Epic",
        "Status": "Closed",
        "Priority": "Major",
        "Resolution": "Fixed",
        "Affects Version/s": "None",
        "Fix Version/s": "2.2.0",
        "Component/s": "None",
        "Assignee": "Richard Zowalla",
        "Reporter": "Richard Zowalla",
        "Created": "20/Jan/23 07:22",
        "Updated": "22/Apr/23 17:39",
        "Resolved": "09/Mar/23 14:12",
        "Description": "As discussed on the mailing list, we are in favour of moving from System.out / System.err to proper log output.\nThe discussion is here: https://lists.apache.org/thread/vt748qbz5onhwhh70kky9wk1o5zm42tm\nTo reduce reviewer burden, we should tackle the task in several steps.",
        "Issue Links": [
            "/jira/browse/OPENNLP-675",
            "/jira/browse/OPENNLP-1089"
        ]
    },
    "OPENNLP-1448": {
        "Key": "OPENNLP-1447 Move from System.out/System.err to SLF4J",
        "Summary": "Introduce SLF4J in OpenNLP",
        "Type": "Sub-task",
        "Status": "Closed",
        "Priority": "Major",
        "Resolution": "Fixed",
        "Affects Version/s": "2.0.0,                                            2.1.0,                                            2.1.1",
        "Fix Version/s": "2.2.0",
        "Component/s": "None",
        "Assignee": "Richard Zowalla",
        "Reporter": "Richard Zowalla",
        "Created": "20/Jan/23 07:23",
        "Updated": "22/Apr/23 17:39",
        "Resolved": "28/Feb/23 07:36",
        "Description": "This will be the first step regarding OPENNLP-1447.\nGoal is to replace System.err / System.out calls with logger output, which is configurable.",
        "Issue Links": [
            "/jira/browse/OPENNLP-1089"
        ]
    },
    "OPENNLP-1449": {
        "Key": "OPENNLP-1447 Move from System.out/System.err to SLF4J",
        "Summary": "Revise log levels in OpenNLP",
        "Type": "Sub-task",
        "Status": "Closed",
        "Priority": "Major",
        "Resolution": "Fixed",
        "Affects Version/s": "None",
        "Fix Version/s": "2.2.0",
        "Component/s": "None",
        "Assignee": "Richard Zowalla",
        "Reporter": "Richard Zowalla",
        "Created": "20/Jan/23 07:25",
        "Updated": "22/Apr/23 17:39",
        "Resolved": "02/Mar/23 07:25",
        "Description": "After introducing slf4j in OpenNLP, we should discuss the log levels.\nWe have a lot of different variants in the code base:\n\nSystem.err\nSystem.out\n\"[WARN] ...\" via System.err / System.println\n\"[ERROR] ...\" via System.err / System.println\n\nGoal is to define / discuss proper log levels as provided by SLF4J (trace, debug, etc.)",
        "Issue Links": []
    },
    "OPENNLP-1450": {
        "Key": "OPENNLP-1447 Move from System.out/System.err to SLF4J",
        "Summary": "Revise log messages in OpenNLP",
        "Type": "Sub-task",
        "Status": "Closed",
        "Priority": "Major",
        "Resolution": "Fixed",
        "Affects Version/s": "None",
        "Fix Version/s": "2.2.0",
        "Component/s": "None",
        "Assignee": "Richard Zowalla",
        "Reporter": "Richard Zowalla",
        "Created": "20/Jan/23 07:26",
        "Updated": "22/Apr/23 17:39",
        "Resolved": "09/Mar/23 14:12",
        "Description": "We should replace string concat with variable replacement provided by SLF4J-API and revise the log messages, if needed.",
        "Issue Links": []
    },
    "OPENNLP-1451": {
        "Key": "OPENNLP-1447 Move from System.out/System.err to SLF4J",
        "Summary": "Reduce log output during builds",
        "Type": "Sub-task",
        "Status": "Closed",
        "Priority": "Major",
        "Resolution": "Fixed",
        "Affects Version/s": "None",
        "Fix Version/s": "2.2.0",
        "Component/s": "None",
        "Assignee": null,
        "Reporter": "Richard Zowalla",
        "Created": "20/Jan/23 07:27",
        "Updated": "22/Apr/23 17:39",
        "Resolved": "04/Mar/23 08:10",
        "Description": "Reduce log output during a build.",
        "Issue Links": []
    },
    "OPENNLP-1452": {
        "Key": "OPENNLP-1452",
        "Summary": "Upgrade to Apache Parent 29",
        "Type": "Dependency upgrade",
        "Status": "Closed",
        "Priority": "Trivial",
        "Resolution": "Fixed",
        "Affects Version/s": "2.1.0",
        "Fix Version/s": "2.1.1",
        "Component/s": "None",
        "Assignee": "Richard Zowalla",
        "Reporter": "Richard Zowalla",
        "Created": "20/Jan/23 08:41",
        "Updated": "28/Jan/23 14:59",
        "Resolved": "23/Jan/23 09:57",
        "Description": "https://maven.apache.org/pom/asf/",
        "Issue Links": []
    },
    "OPENNLP-1453": {
        "Key": "OPENNLP-1447 Move from System.out/System.err to SLF4J",
        "Summary": "Revise CLI tool descriptions",
        "Type": "Sub-task",
        "Status": "Closed",
        "Priority": "Minor",
        "Resolution": "Fixed",
        "Affects Version/s": "2.1.0",
        "Fix Version/s": "2.2.0",
        "Component/s": "Command Line Interface",
        "Assignee": "Martin Wiesner",
        "Reporter": "Richard Zowalla",
        "Created": "20/Jan/23 08:49",
        "Updated": "22/Apr/23 17:39",
        "Resolved": "04/Mar/23 21:05",
        "Description": "We have a lot of inconsistency in the wording of the tool descriptions. Would be nice to have it in a consistent way",
        "Issue Links": []
    },
    "OPENNLP-1454": {
        "Key": "OPENNLP-1454",
        "Summary": "Convert System.out statements to debug logging statements in 'opennlp-similarity' sandbox component",
        "Type": "Task",
        "Status": "Closed",
        "Priority": "Minor",
        "Resolution": "Fixed",
        "Affects Version/s": "2.1.0,                                            2.1.1,                                            2.2.0",
        "Fix Version/s": "2.2.1",
        "Component/s": "Similarity",
        "Assignee": "Martin Wiesner",
        "Reporter": "Martin Wiesner",
        "Created": "26/Jan/23 08:56",
        "Updated": "28/Apr/23 18:55",
        "Resolved": "28/Apr/23 18:55",
        "Description": "In several classes of the 'opennlp-similarity' sandbox component, commented System.out statements exist that have a debug statement flavor. Yet, in tests and at runtime those spam the console quite heavily. That's why those have been commented out during the compatibility migration towards tools version 2.1.x conducted for all sandbox components.\nThe aim of that issue is to convert those spammy log behavior by making use of the slf4j-api. The code contains the spots marked with a TODO notice and this issue number for which a switch to a logging framework with \"trace\" or \"debug\" levels could be considered.",
        "Issue Links": []
    },
    "OPENNLP-1455": {
        "Key": "OPENNLP-1455",
        "Summary": "Change test strategy for tests in 'opennlp-similarity' sandbox component dependent on 'api.datamarket.azure.com'",
        "Type": "Task",
        "Status": "Open",
        "Priority": "Major",
        "Resolution": "Unresolved",
        "Affects Version/s": "2.1.0",
        "Fix Version/s": "None",
        "Component/s": "Similarity",
        "Assignee": null,
        "Reporter": "Martin Wiesner",
        "Created": "26/Jan/23 09:19",
        "Updated": "26/Jan/23 09:22",
        "Resolved": null,
        "Description": "Some tests in the sandbox component 'opennlp-similarity' fail with:\n\u00a0\n\"UnknownHostException: api.datamarket.azure.com: nodename nor servname provided, or\nnot known\"\n\u00a0\nThose have be set to @Ignore during the recent migration to OPENNLP 2.1.x\n\u00a0\nAims:\n\nRethink and rework the test strategy to avoid making calls to external cloud services which no longer exist.\nOptimize Test classes to avoid code duplication.\n\nAffected tests classes are:\n(a) StoryDiscourseNavigatorTest, and\n(b)\u00a0MultiSentenceSearchResultsProcessorTest",
        "Issue Links": []
    },
    "OPENNLP-1456": {
        "Key": "OPENNLP-1456",
        "Summary": "jira-report plugin throws NPE during release build",
        "Type": "Task",
        "Status": "Closed",
        "Priority": "Minor",
        "Resolution": "Fixed",
        "Affects Version/s": "None",
        "Fix Version/s": "2.1.1",
        "Component/s": "Build, Packaging and Test",
        "Assignee": "Jeff Zemerick",
        "Reporter": "Jeff Zemerick",
        "Created": "28/Jan/23 14:44",
        "Updated": "27/Apr/23 11:35",
        "Resolved": "01/Feb/23 22:31",
        "Description": "The jira-report plugin is throwing an NPE during the release build. This likely explains why the list of Jira issues fixed for the build in the release notes was empty for the last release. Note that this NPE does not stop the build so the error is very easy to miss.\nTo reproduce, run mvn package -Papache-release.\n\u00a0\n[INFO] \u2014 maven-changes-plugin:2.12.1:jira-report (default-cli) @ opennlp-distr ---\n[WARNING]\u00a0\njava.lang.NullPointerException\n\u00a0 \u00a0 at org.apache.maven.plugin.jira.RestJiraDownloader.processPriority (RestJiraDownloader.java:392)\n\u00a0 \u00a0 at org.apache.maven.plugin.jira.RestJiraDownloader.buildIssues (RestJiraDownloader.java:329)\n\u00a0 \u00a0 at org.apache.maven.plugin.jira.RestJiraDownloader.doExecute (RestJiraDownloader.java:172)\n\u00a0 \u00a0 at org.apache.maven.plugin.jira.AdaptiveJiraDownloader.doExecute (AdaptiveJiraDownloader.java:45)\n\u00a0 \u00a0 at org.apache.maven.plugin.jira.JiraMojo.executeReport (JiraMojo.java:346)\n\u00a0 \u00a0 at org.apache.maven.reporting.AbstractMavenReport.generate (AbstractMavenReport.java:255)\n\u00a0 \u00a0 at org.apache.maven.reporting.AbstractMavenReport.generate (AbstractMavenReport.java:210)\n\u00a0 \u00a0 at org.apache.maven.plugin.changes.AbstractChangesReport.execute (AbstractChangesReport.java:203)\n\u00a0 \u00a0 at org.apache.maven.plugin.DefaultBuildPluginManager.executeMojo (DefaultBuildPluginManager.java:137)\n\u00a0 \u00a0 at org.apache.maven.lifecycle.internal.MojoExecutor.execute (MojoExecutor.java:210)\n\u00a0 \u00a0 at org.apache.maven.lifecycle.internal.MojoExecutor.execute (MojoExecutor.java:156)\n\u00a0 \u00a0 at org.apache.maven.lifecycle.internal.MojoExecutor.execute (MojoExecutor.java:148)\n\u00a0 \u00a0 at org.apache.maven.lifecycle.internal.LifecycleModuleBuilder.buildProject (LifecycleModuleBuilder.java:117)\n\u00a0 \u00a0 at org.apache.maven.lifecycle.internal.LifecycleModuleBuilder.buildProject (LifecycleModuleBuilder.java:81)\n\u00a0 \u00a0 at org.apache.maven.lifecycle.internal.builder.singlethreaded.SingleThreadedBuilder.build (SingleThreadedBuilder.java:56)\n\u00a0 \u00a0 at org.apache.maven.lifecycle.internal.LifecycleStarter.execute (LifecycleStarter.java:128)\n\u00a0 \u00a0 at org.apache.maven.DefaultMaven.doExecute (DefaultMaven.java:305)\n\u00a0 \u00a0 at org.apache.maven.DefaultMaven.doExecute (DefaultMaven.java:192)\n\u00a0 \u00a0 at org.apache.maven.DefaultMaven.execute (DefaultMaven.java:105)\n\u00a0 \u00a0 at org.apache.maven.cli.MavenCli.execute (MavenCli.java:957)\n\u00a0 \u00a0 at org.apache.maven.cli.MavenCli.doMain (MavenCli.java:289)\n\u00a0 \u00a0 at org.apache.maven.cli.MavenCli.main (MavenCli.java:193)\n\u00a0 \u00a0 at jdk.internal.reflect.NativeMethodAccessorImpl.invoke0 (Native Method)\n\u00a0 \u00a0 at jdk.internal.reflect.NativeMethodAccessorImpl.invoke (NativeMethodAccessorImpl.java:62)\n\u00a0 \u00a0 at jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke (DelegatingMethodAccessorImpl.java:43)\n\u00a0 \u00a0 at java.lang.reflect.Method.invoke (Method.java:566)\n\u00a0 \u00a0 at org.codehaus.plexus.classworlds.launcher.Launcher.launchEnhanced (Launcher.java:282)\n\u00a0 \u00a0 at org.codehaus.plexus.classworlds.launcher.Launcher.launch (Launcher.java:225)\n\u00a0 \u00a0 at org.codehaus.plexus.classworlds.launcher.Launcher.mainWithExitCode (Launcher.java:406)\n\u00a0 \u00a0 at org.codehaus.plexus.classworlds.launcher.Launcher.main (Launcher.java:347)",
        "Issue Links": []
    },
    "OPENNLP-1457": {
        "Key": "OPENNLP-1457",
        "Summary": "Update release guide for how to set gpg tty for a headless build",
        "Type": "Task",
        "Status": "Open",
        "Priority": "Minor",
        "Resolution": "Unresolved",
        "Affects Version/s": "None",
        "Fix Version/s": "None",
        "Component/s": "Build, Packaging and Test",
        "Assignee": null,
        "Reporter": "Jeff Zemerick",
        "Created": "28/Jan/23 14:50",
        "Updated": "27/Apr/23 11:36",
        "Resolved": null,
        "Description": "Update release guide for how to set gpg tty for a headless build.\nWhen building on a VM like on AWS without a UI, the mvn release:prepare command will fail when trying to ask for the gpg signing password.\nThe commands in this answer allow it work - https://stackoverflow.com/a/57591830/1428388 - so updating the release guide with these commands would be helpful.",
        "Issue Links": [
            "/jira/browse/OPENNLP-1492"
        ]
    },
    "OPENNLP-1458": {
        "Key": "OPENNLP-1458",
        "Summary": "Update NOTICE file to say 2023 instead of 2022",
        "Type": "Task",
        "Status": "Closed",
        "Priority": "Major",
        "Resolution": "Fixed",
        "Affects Version/s": "2.1.0",
        "Fix Version/s": "2.1.1",
        "Component/s": "None",
        "Assignee": "Jeff Zemerick",
        "Reporter": "Jeff Zemerick",
        "Created": "30/Jan/23 13:57",
        "Updated": "31/Jan/23 16:31",
        "Resolved": "31/Jan/23 16:31",
        "Description": "Update NOTICE file to say 2023 instead of 2022. This was found during 2.1.1 RC1 testing.",
        "Issue Links": []
    },
    "OPENNLP-1459": {
        "Key": "OPENNLP-1459",
        "Summary": "Investigate eval-tests failures in OpenNLP 2.1.1 RC1",
        "Type": "Task",
        "Status": "Closed",
        "Priority": "Major",
        "Resolution": "Fixed",
        "Affects Version/s": "2.1.1",
        "Fix Version/s": "2.1.1",
        "Component/s": "None",
        "Assignee": "Jeff Zemerick",
        "Reporter": "Jeff Zemerick",
        "Created": "30/Jan/23 14:00",
        "Updated": "31/Jan/23 13:49",
        "Resolved": "31/Jan/23 13:49",
        "Description": "Investigate eval-tests failures in OpenNLP 2.1.1 RC1. Both of these tests pass in OpenNLP 2.1.0.\n[ERROR] Failures:\n[ERROR] \u00a0 ArvoresDeitadasEval.evalPortugueseChunkerQn:211->chunkerCrossEval:140 expected: <0.9648211936491359> but was: <0.9651009811896799>\n[ERROR] \u00a0 SourceForgeModelEval.evalChunkerModel:345 expected: <226003515785585284478071030961407561943> but was: <304922886851384639120257052245406261332>\n$ mvn -v\nApache Maven 3.8.4 (9b656c72d54e5bacbed989b64718c159fe39b537)\nMaven home: /opt/apache-maven\nJava version: 11.0.17, vendor: Ubuntu, runtime: /usr/lib/jvm/java-11-openjdk-amd64\nDefault locale: en_US, platform encoding: UTF-8\nOS name: \"linux\", version: \"5.15.0-58-generic\", arch: \"amd64\", family: \"unix\"",
        "Issue Links": [
            "/jira/browse/OPENNLP-1332"
        ]
    },
    "OPENNLP-1460": {
        "Key": "OPENNLP-1460",
        "Summary": "Run Evaluation Tests on Jenkins CI",
        "Type": "Task",
        "Status": "Closed",
        "Priority": "Major",
        "Resolution": "Fixed",
        "Affects Version/s": "None",
        "Fix Version/s": "None",
        "Component/s": "None",
        "Assignee": "Richard Zowalla",
        "Reporter": "Richard Zowalla",
        "Created": "13/Feb/23 19:49",
        "Updated": "04/Mar/23 07:41",
        "Resolved": "04/Mar/23 07:41",
        "Description": "I had a quick chat with jzemerick and talked with mawiesne last week. It would be neat to run the eval tests in CI (and not just on local machines before releases).\nI asked INFRA about the license implications and they said, that there isn't a problem if it isn't redistributed. They suggest to add the data to https://nightlies.apache.org/\nData can be published from Jenkins: https://nightlies.apache.org/jenkins-publishing.html\nTasks:\n\nGet OpenNLP on Jenkins\nGet the eval data via a Jenkins job to nightlies.a.o\nCreate a Jenkins job to run the eval tests with the data hosted at nightlies.a.o",
        "Issue Links": []
    },
    "OPENNLP-1461": {
        "Key": "OPENNLP-1460 Run Evaluation Tests on Jenkins CI",
        "Summary": "Create OpenNLP on Jenkins",
        "Type": "Sub-task",
        "Status": "Closed",
        "Priority": "Major",
        "Resolution": "Fixed",
        "Affects Version/s": "None",
        "Fix Version/s": "None",
        "Component/s": "None",
        "Assignee": "Bruno P. Kinoshita",
        "Reporter": "Richard Zowalla",
        "Created": "13/Feb/23 19:51",
        "Updated": "03/Mar/23 22:27",
        "Resolved": "03/Mar/23 22:27",
        "Description": "Create OpenNLP on https://ci-builds.apache.org/\nIt might be just possible for you after logging in or requires an INFRA ticket. Didn't find any documentation about .it",
        "Issue Links": []
    },
    "OPENNLP-1462": {
        "Key": "OPENNLP-1460 Run Evaluation Tests on Jenkins CI",
        "Summary": "Get the eval data via a Jenkins job to nightlies.a.o",
        "Type": "Sub-task",
        "Status": "Closed",
        "Priority": "Major",
        "Resolution": "Fixed",
        "Affects Version/s": "None",
        "Fix Version/s": "None",
        "Component/s": "None",
        "Assignee": "Richard Zowalla",
        "Reporter": "Richard Zowalla",
        "Created": "13/Feb/23 19:52",
        "Updated": "03/Mar/23 22:27",
        "Resolved": "03/Mar/23 22:27",
        "Description": "Evaluation data needs to be deployed to nightlies.a.o\nTo do so, we need to follow the steps outlined in https://nightlies.apache.org/jenkins-publishing.html\nNote, that we only need to conduct this steps once.",
        "Issue Links": []
    },
    "OPENNLP-1463": {
        "Key": "OPENNLP-1460 Run Evaluation Tests on Jenkins CI",
        "Summary": "Create a Jenkins job to run the eval tests",
        "Type": "Sub-task",
        "Status": "Closed",
        "Priority": "Major",
        "Resolution": "Fixed",
        "Affects Version/s": "None",
        "Fix Version/s": "None",
        "Component/s": "None",
        "Assignee": "Richard Zowalla",
        "Reporter": "Richard Zowalla",
        "Created": "13/Feb/23 19:52",
        "Updated": "04/Mar/23 07:41",
        "Resolved": "04/Mar/23 07:41",
        "Description": "If the eval data is available on nightlies.a.o, we need a job to actually run the evaluation tests on Jenkins.",
        "Issue Links": []
    },
    "OPENNLP-1464": {
        "Key": "OPENNLP-1464",
        "Summary": "Update dependency commons-io to version 2.11.0",
        "Type": "Task",
        "Status": "Closed",
        "Priority": "Trivial",
        "Resolution": "Fixed",
        "Affects Version/s": "2.1.0,                                            2.1.1",
        "Fix Version/s": "2.2.0",
        "Component/s": "None",
        "Assignee": "Martin Wiesner",
        "Reporter": "Martin Wiesner",
        "Created": "17/Feb/23 20:57",
        "Updated": "22/Apr/23 17:39",
        "Resolved": "25/Feb/23 22:12",
        "Description": "OpenNLP references an outdated version of commons-io as a dependency, that is version 2.6. The most recent commons-io version 2.11.0 resolves several bugs, see:\nhttps://commons.apache.org/proper/commons-io/changes-report.html#a2.11.0\nAim:\n\nModernizes commons-io to version 2.11.0",
        "Issue Links": []
    },
    "OPENNLP-1465": {
        "Key": "OPENNLP-1465",
        "Summary": "Clear out unnecessary semicolons from existing classes",
        "Type": "Task",
        "Status": "Resolved",
        "Priority": "Trivial",
        "Resolution": "Fixed",
        "Affects Version/s": "2.1.0,                                            2.1.1",
        "Fix Version/s": "None",
        "Component/s": "None",
        "Assignee": "Martin Wiesner",
        "Reporter": "Martin Wiesner",
        "Created": "17/Feb/23 21:05",
        "Updated": "18/Feb/23 12:04",
        "Resolved": "18/Feb/23 12:04",
        "Description": "Even though, extra semicolons are valid in Java, they are redundant and should be removed. Several classes show those orphaned or accidentially coded semicolons.\nAim:\n\nClear out those extra semicolons.",
        "Issue Links": []
    },
    "OPENNLP-1466": {
        "Key": "OPENNLP-1466",
        "Summary": "Convert the use of Collection#toArray(..) more performant version under modern JVMs",
        "Type": "Improvement",
        "Status": "Closed",
        "Priority": "Major",
        "Resolution": "Fixed",
        "Affects Version/s": "2.1.0,                                            2.1.1",
        "Fix Version/s": "2.2.0",
        "Component/s": "None",
        "Assignee": "Martin Wiesner",
        "Reporter": "Martin Wiesner",
        "Created": "17/Feb/23 21:27",
        "Updated": "22/Apr/23 17:39",
        "Resolved": "25/Feb/23 22:12",
        "Description": "In older Java versions, using a pre-sized array was preferred, as the reflection call necessary to create an array of pre-computed size was rather slow. However, since Java 6+, the performance of the empty array version the same, and sometimes even better. [1] [2]\nThe code of many OpenNLP classes still relies on the old style of converting collections to arrays, via someCollection.toArray(...size()) or similar, in essence: via a pre-computed length. However, the zero-sized initialization is considered (and demonstrated) to be faster under Java 11+ vms. [3]\nAims\n\nMigrate the old\u00a0 way of creating / converting to arrays to the more performant version.\nEnsure all tests hold no drawbacks show up.\n\n\u00a0\n[1]: https://shipilev.net/blog/2016/arrays-wisdom-ancients/#_new_reflective_array\n[2]: https://www.baeldung.com/java-collection-toarray-methods#performance-trials\n[3]: https://www.baeldung.com/java-collection-toarray-methods#benchmarks-on-newer-jdks",
        "Issue Links": []
    },
    "OPENNLP-1467": {
        "Key": "OPENNLP-1467",
        "Summary": "Update dependency onnxruntime to version 1.14.0",
        "Type": "Task",
        "Status": "Closed",
        "Priority": "Minor",
        "Resolution": "Fixed",
        "Affects Version/s": "2.1.0,                                            2.1.1",
        "Fix Version/s": "2.2.0",
        "Component/s": "Deep Learning",
        "Assignee": "Martin Wiesner",
        "Reporter": "Martin Wiesner",
        "Created": "17/Feb/23 21:41",
        "Updated": "22/Apr/23 17:39",
        "Resolved": "25/Feb/23 22:11",
        "Description": "OpenNLP references an outdated version of onnxruntime as a dependency, that is version 1.10.0. The most recent\u00a0onnxruntime version 1.14.0 resolves several bugs and improves performance, see: https://github.com/microsoft/onnxruntime/releases\nAim:\n\nModernizes onnxruntime to latest version 1.14.0\nEnable modern dev platforms: \"Mac M1 support in Python and Java packages\", cf [1]\n\n[1] https://github.com/microsoft/onnxruntime/releases/tag/v1.12.0",
        "Issue Links": []
    },
    "OPENNLP-1468": {
        "Key": "OPENNLP-1468",
        "Summary": "Simplify test assertions in JUnit tests",
        "Type": "Improvement",
        "Status": "Closed",
        "Priority": "Minor",
        "Resolution": "Fixed",
        "Affects Version/s": "2.1.0,                                            2.1.1",
        "Fix Version/s": "2.2.0",
        "Component/s": "Build, Packaging and Test",
        "Assignee": "Martin Wiesner",
        "Reporter": "Martin Wiesner",
        "Created": "18/Feb/23 06:16",
        "Updated": "22/Apr/23 17:39",
        "Resolved": "25/Feb/23 22:11",
        "Description": "Some existing Test assertions can be simplified so they read more clearly.\nAim:\n\nSimplify tests assertions to be / read less complex",
        "Issue Links": []
    },
    "OPENNLP-1469": {
        "Key": "OPENNLP-1469",
        "Summary": "Update dependency junit-jupiter to version 5.9.2",
        "Type": "Task",
        "Status": "Closed",
        "Priority": "Minor",
        "Resolution": "Fixed",
        "Affects Version/s": "2.1.0,                                            2.1.1",
        "Fix Version/s": "2.2.0",
        "Component/s": "Build, Packaging and Test",
        "Assignee": "Martin Wiesner",
        "Reporter": "Martin Wiesner",
        "Created": "18/Feb/23 06:27",
        "Updated": "22/Apr/23 17:39",
        "Resolved": "25/Feb/23 22:10",
        "Description": "OpenNLP references an outdated version of junit-jupiter as a dependency. The most recent version 5.9.2 resolves several bugs, see:\nhttps://junit.org/junit5/docs/current/release-notes/#release-notes-5.9.2\nAim:\n\nModernizes junit-jupiter to version 5.9.2",
        "Issue Links": []
    },
    "OPENNLP-1470": {
        "Key": "OPENNLP-1470",
        "Summary": "Modernize maven.yml to fix deprecation warnings",
        "Type": "Task",
        "Status": "Closed",
        "Priority": "Trivial",
        "Resolution": "Fixed",
        "Affects Version/s": "2.1.0,                                            2.1.1",
        "Fix Version/s": "2.2.0",
        "Component/s": "Build, Packaging and Test",
        "Assignee": "Martin Wiesner",
        "Reporter": "Martin Wiesner",
        "Created": "18/Feb/23 07:07",
        "Updated": "22/Apr/23 17:39",
        "Resolved": "18/Feb/23 12:01",
        "Description": "In the build output of GH actions we find warnings like this:\nWarning: The `save-state` command is deprecated and will be disabled soon. Please upgrade to using Environment Files. For more information see: https://github.blog/changelog/2022-10-11-github-actions-deprecating-save-state-and-set-output-commands/\nand\nWarning: The `set-output` command is deprecated and will be disabled soon. Please upgrade to using Environment Files. For more information see: https://github.blog/changelog/2022-10-11-github-actions-deprecating-save-state-and-set-output-commands/\nTherefore, maven.yml needs some modernizations.",
        "Issue Links": []
    },
    "OPENNLP-1471": {
        "Key": "OPENNLP-1471",
        "Summary": "Ensure Dictionary#asStringSet() implements hashCode() and equals() correctly",
        "Type": "Improvement",
        "Status": "Closed",
        "Priority": "Minor",
        "Resolution": "Fixed",
        "Affects Version/s": "2.1.0,                                            2.1.1",
        "Fix Version/s": "2.2.0",
        "Component/s": "None",
        "Assignee": "Martin Wiesner",
        "Reporter": "Martin Wiesner",
        "Created": "19/Feb/23 12:45",
        "Updated": "22/Apr/23 17:39",
        "Resolved": "25/Feb/23 22:09",
        "Description": "The tests\u00a0 (a)\u00a0\u00a0DictionaryAsSetCaseInsensitiveTest and\u00a0\n(b) DictionaryAsSetCaseSensitiveTest have an open TODO that points to a bug in Dictionary#asStringSet()\n\u00a0\n// TODO: should it be equal??\nAssertions.assertNotSame(setA.hashCode(), setB.hashCode());\nTo cure this, the implementation of Dictionary#asStringSet() needs override hashCode and equals properly.\nAfter fixing the implementation, the following assertion must hold:\nAssertions.assertEquals(setA, setB);\nAssertions.assertEquals(setA.hashCode(), setB.hashCode());\nwhere setA and setB are obtained via Dictionary#asStringSet().",
        "Issue Links": []
    },
    "OPENNLP-1472": {
        "Key": "OPENNLP-1472",
        "Summary": "Fix flaky (sub-) test of GradientDescentUtilsTest in sandbox component 'nlp-utils'",
        "Type": "Test",
        "Status": "Closed",
        "Priority": "Major",
        "Resolution": "Fixed",
        "Affects Version/s": "2.1.1",
        "Fix Version/s": "2.2.0",
        "Component/s": "None",
        "Assignee": "Martin Wiesner",
        "Reporter": "Martin Wiesner",
        "Created": "20/Feb/23 12:37",
        "Updated": "22/Apr/23 17:39",
        "Resolved": "25/Feb/23 22:07",
        "Description": "A flaky test has been discovered with recent modernizations of the sandbox components. It lives in 'nlp-utils' and the problem signals a fragile test setup or potentially numerical instabilities:\nError: org.apache.opennlp.utils.regression.GradientDescentUtilsTest.testConvergence Time elapsed: 1.156 s <<< ERROR! \n3270java.lang.RuntimeException: failed to converge at iteration 75129 with cost going from 5.010577258277822 to 5.010577258277823 \n3271 at org.apache.opennlp.utils.regression.GradientDescentUtilsTest.testConvergence(GradientDescentUtilsTest.java:34)\nThe problem (sometimes) occurs on different platforms / environments (Win, Lin, Mac).\nAims:\n\nInvestigate the cause of the flakyness\nFix the test (environment / setup) so it runs reliably.",
        "Issue Links": []
    },
    "OPENNLP-1473": {
        "Key": "OPENNLP-1473",
        "Summary": "Add .asf.yaml",
        "Type": "Task",
        "Status": "Resolved",
        "Priority": "Trivial",
        "Resolution": "Fixed",
        "Affects Version/s": "None",
        "Fix Version/s": "2.2.0",
        "Component/s": "Documentation",
        "Assignee": "Bruno P. Kinoshita",
        "Reporter": "Bruno P. Kinoshita",
        "Created": "26/Feb/23 19:30",
        "Updated": "22/Apr/23 17:39",
        "Resolved": "27/Feb/23 15:00",
        "Description": null,
        "Issue Links": []
    },
    "OPENNLP-1474": {
        "Key": "OPENNLP-1474",
        "Summary": "Create tokenizer factories for other langs (Spanish, Italian, ...)",
        "Type": "Improvement",
        "Status": "Closed",
        "Priority": "Major",
        "Resolution": "Fixed",
        "Affects Version/s": "2.1.1",
        "Fix Version/s": "2.2.0",
        "Component/s": "Tokenizer",
        "Assignee": "Martin Wiesner",
        "Reporter": "Bruno P. Kinoshita",
        "Created": "27/Feb/23 07:55",
        "Updated": "22/Apr/23 17:39",
        "Resolved": "06/Mar/23 19:24",
        "Description": "From https://github.com/apache/opennlp/pull/506#issuecomment-1445849746\nWe can create more factories for languages such as Spanish and Italian. For example:\n\n// From: https://it.wikipedia.org/wiki/Alfabeto_italiano\r\nprivate static final Pattern ITALIAN = Pattern.compile(\"^[0-9a-z\u00e0\u00e8\u00e9\u00ec\u00ee\u00ed\u00f2\u00f3\u00f9\u00fcA-Z\u00c0\u00c8\u00c9\u00cc\u00ce\u00cd\u00d2\u00d3\u00d9\u00dc]+$\");\r\n// From: https://en.wikiversity.org/wiki/Alphabet/Spanish_alphabet & https://en.wikipedia.org/wiki/Spanish_orthography#Alphabet_in_Spanish & https://www.fundeu.es/consulta/tilde-en-la-y-y-griega-o-ye-24786/\r\nprivate static final Pattern SPANISH = Pattern.compile(\"^[0-9a-z\u00e1\u00e9\u00ed\u00f3\u00fa\u00fc\u00fd\u00f1A-Z\u00c1\u00c9\u00cd\u00d3\u00da\u00dd\u00d1]+$\"); \n\nCommunity feedback would be appreciated.",
        "Issue Links": [
            "/jira/browse/OPENNLP-141",
            "/jira/browse/OPENNLP-1479"
        ]
    },
    "OPENNLP-1475": {
        "Key": "OPENNLP-1475",
        "Summary": "Update build dependency forbiddenapis to version 3.4",
        "Type": "Improvement",
        "Status": "Closed",
        "Priority": "Trivial",
        "Resolution": "Fixed",
        "Affects Version/s": "2.1.0,                                            2.1.1",
        "Fix Version/s": "2.2.0",
        "Component/s": "Build, Packaging and Test",
        "Assignee": "Martin Wiesner",
        "Reporter": "Martin Wiesner",
        "Created": "03/Mar/23 19:34",
        "Updated": "22/Apr/23 17:39",
        "Resolved": "04/Mar/23 08:02",
        "Description": "OpenNLP references an outdated version of the forbidden-apis maven plugin, that is version 2.7. The most version 3.4 resolves several bugs and improves support for newer JDK versions - details see:\nhttps://github.com/policeman-tools/forbidden-apis/wiki/Changes\nAim:\n\nModernize forbidden-apis to latest version 3.4\nAdd support for checks on newer JDK versions",
        "Issue Links": []
    },
    "OPENNLP-1476": {
        "Key": "OPENNLP-1476",
        "Summary": "Modernize DictionaryEntryPersistor to create XMLReader via javax.xml.parsers.SAXParserFactory",
        "Type": "Improvement",
        "Status": "Closed",
        "Priority": "Minor",
        "Resolution": "Fixed",
        "Affects Version/s": "2.1.0,                                            2.1.1",
        "Fix Version/s": "2.2.0",
        "Component/s": "None",
        "Assignee": "Martin Wiesner",
        "Reporter": "Martin Wiesner",
        "Created": "03/Mar/23 20:01",
        "Updated": "22/Apr/23 17:39",
        "Resolved": "09/Mar/23 14:11",
        "Description": "Atm, org.xml.sax.helpers.XMLReaderFactory is used in\u00a0DictionaryEntryPersistor. However, this the use of XMLReaderFactory is deprecated since Java 9, that is:\n\n\r\nDeprecated\r\nIt is recommended to use javax.xml.parsers.SAXParserFactory instead.\r\n\n\nAim(s):\n\nSwitch to SAXParserFactory to obtain instances of XMLReader to modern way.",
        "Issue Links": []
    },
    "OPENNLP-1477": {
        "Key": "OPENNLP-1477",
        "Summary": "Modernize ExtensionLoader to avoid deprecated Class API",
        "Type": "Improvement",
        "Status": "Closed",
        "Priority": "Minor",
        "Resolution": "Fixed",
        "Affects Version/s": "2.1.0,                                            2.1.1",
        "Fix Version/s": "2.2.0",
        "Component/s": "None",
        "Assignee": "Martin Wiesner",
        "Reporter": "Martin Wiesner",
        "Created": "03/Mar/23 21:17",
        "Updated": "22/Apr/23 17:39",
        "Resolved": "06/Mar/23 18:28",
        "Description": "Right now,\u00a0ExtensionLoader calls \n\n\r\nextClazz.newInstance();\r\n\n\nThis call is deprecated in newer JDK versions. It is advised to use\n\n\r\nreturn (T) extClazz.getDeclaredConstructor().newInstance();\r\n\n\ninstead in this case.\nAim(s):\n\nRemove the deprecated form in exchange for the recommended one.",
        "Issue Links": []
    },
    "OPENNLP-1478": {
        "Key": "OPENNLP-1478",
        "Summary": "Investigate and fix test failures on Linux/Ubuntu environment in opennlp-dl",
        "Type": "Bug",
        "Status": "Closed",
        "Priority": "Major",
        "Resolution": "Fixed",
        "Affects Version/s": "2.1.0",
        "Fix Version/s": "2.1.1",
        "Component/s": "Deep Learning",
        "Assignee": null,
        "Reporter": "Richard Zowalla",
        "Created": "04/Mar/23 07:44",
        "Updated": "20/Apr/23 18:10",
        "Resolved": "20/Apr/23 18:10",
        "Description": "We have some evaluation tests in the opennlp-dl module, which require our attentation. They were also encountered during the 2.1.0 release vote.\nGoal of this ticket is to fix the failures / errors.\n\n\r\n[INFO] -------------------------------------------------------\r\n[INFO]  T E S T S\r\n[INFO] -------------------------------------------------------\r\n[INFO] Running opennlp.dl.doccat.scoring.AverageClassificationScoringStrategyTest\r\n[INFO] Running opennlp.dl.doccat.DocumentCategorizerDLEval\r\n[INFO] Tests run: 2, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.078 s - in opennlp.dl.doccat.scoring.AverageClassificationScoringStrategyTest\r\n[INFO] Running opennlp.dl.namefinder.NameFinderDLEval\r\n[ERROR] Tests run: 7, Failures: 1, Errors: 0, Skipped: 0, Time elapsed: 11.675 s <<< FAILURE! - in opennlp.dl.namefinder.NameFinderDLEval\r\n[ERROR] tokenNameFinder1Test  Time elapsed: 1.661 s  <<< FAILURE!\r\norg.opentest4j.AssertionFailedError: expected: <8.251646041870117> but was: <8.251642227172852>\r\n\tat opennlp.dl.namefinder.NameFinderDLEval.tokenNameFinder1Test(NameFinderDLEval.java:67)\r\n\r\n[ERROR] Tests run: 6, Failures: 3, Errors: 1, Skipped: 1, Time elapsed: 14.863 s <<< FAILURE! - in opennlp.dl.doccat.DocumentCategorizerDLEval\r\n[ERROR] scoreMap  Time elapsed: 3.41 s  <<< FAILURE!\r\norg.opentest4j.AssertionFailedError: expected: <0.04995147883892059> but was: <0.049951449036598206>\r\n\tat opennlp.dl.doccat.DocumentCategorizerDLEval.scoreMap(DocumentCategorizerDLEval.java:179)\r\n\r\n[ERROR] categorizeWithInferenceOptions  Time elapsed: 0.946 s  <<< FAILURE!\r\norg.opentest4j.AssertionFailedError: array contents differ at index [1], expected: <0.11486853659152985> but was: <0.11486850678920746>\r\n\tat opennlp.dl.doccat.DocumentCategorizerDLEval.categorizeWithInferenceOptions(DocumentCategorizerDLEval.java:154)\r\n\r\n[ERROR] sortedScoreMap  Time elapsed: 3.079 s  <<< ERROR!\r\njava.lang.NullPointerException: Cannot invoke \"java.util.Set.size()\" because the return value of \"java.util.Map.get(Object)\" is null\r\n\tat opennlp.dl.doccat.DocumentCategorizerDLEval.sortedScoreMap(DocumentCategorizerDLEval.java:202)\r\n\r\n[ERROR] categorize  Time elapsed: 3.61 s  <<< FAILURE!\r\norg.opentest4j.AssertionFailedError: array contents differ at index [0], expected: <0.3391093313694> but was: <0.33910930156707764>\r\n\tat opennlp.dl.doccat.DocumentCategorizerDLEval.categorize(DocumentCategorizerDLEval.java:86)\r\n\r\n[INFO] \r\n[INFO] Results:\r\n[INFO] \r\n[ERROR] Failures: \r\n[ERROR]   DocumentCategorizerDLEval.categorize:86 array contents differ at index [0], expected: <0.3391093313694> but was: <0.33910930156707764>\r\n[ERROR]   DocumentCategorizerDLEval.categorizeWithInferenceOptions:154 array contents differ at index [1], expected: <0.11486853659152985> but was: <0.11486850678920746>\r\n[ERROR]   DocumentCategorizerDLEval.scoreMap:179 expected: <0.04995147883892059> but was: <0.049951449036598206>\r\n[ERROR]   NameFinderDLEval.tokenNameFinder1Test:67 expected: <8.251646041870117> but was: <8.251642227172852>\r\n[ERROR] Errors: \r\n[ERROR]   DocumentCategorizerDLEval.sortedScoreMap:202 NullPointer Cannot invoke \"java.u...\r\n[INFO] \r\n[ERROR] Tests run: 15, Failures: 4, Errors: 1, Skipped: 1",
        "Issue Links": []
    },
    "OPENNLP-1479": {
        "Key": "OPENNLP-1479",
        "Summary": "Write better tests for pattern verification (tokenizers)",
        "Type": "Improvement",
        "Status": "Open",
        "Priority": "Major",
        "Resolution": "Unresolved",
        "Affects Version/s": "2.1.1",
        "Fix Version/s": "None",
        "Component/s": "Tokenizer",
        "Assignee": null,
        "Reporter": "Bruno P. Kinoshita",
        "Created": "05/Mar/23 10:15",
        "Updated": "07/Apr/23 06:45",
        "Resolved": null,
        "Description": "From https://github.com/apache/opennlp/pull/516#issuecomment-1455015772\nAt the moment our tests verify that the tokenizer objects are created correctly (i.e. tests getters and setters, constructor, etc.), without verifying the actual behavior when used in conjunction with other classes (factory, tokenizer, trainers, etc).\nIt would be best to test the patterns used in the factories for different languages with some interesting sample data (maybe something from project gutenberg, open source news sites, etc.).",
        "Issue Links": [
            "/jira/browse/OPENNLP-1474"
        ]
    },
    "OPENNLP-1480": {
        "Key": "OPENNLP-1480",
        "Summary": "Quick fix for HTML href javadoc",
        "Type": "Bug",
        "Status": "Resolved",
        "Priority": "Trivial",
        "Resolution": "Fixed",
        "Affects Version/s": "2.1.1",
        "Fix Version/s": "2.2.0",
        "Component/s": "Documentation",
        "Assignee": "Bruno P. Kinoshita",
        "Reporter": "Bruno P. Kinoshita",
        "Created": "05/Mar/23 14:26",
        "Updated": "22/Apr/23 17:39",
        "Resolved": "05/Mar/23 15:14",
        "Description": null,
        "Issue Links": []
    },
    "OPENNLP-1481": {
        "Key": "OPENNLP-1481",
        "Summary": "Address failing ONNX Runtime tests",
        "Type": "Task",
        "Status": "Closed",
        "Priority": "Major",
        "Resolution": "Fixed",
        "Affects Version/s": "2.1.1",
        "Fix Version/s": "2.2.0",
        "Component/s": "Build, Packaging and Test,                                            Deep Learning",
        "Assignee": "Jeff Zemerick",
        "Reporter": "Jeff Zemerick",
        "Created": "15/Mar/23 14:41",
        "Updated": "22/Apr/23 17:39",
        "Resolved": "18/Mar/23 11:49",
        "Description": "Address failing ONNX Runtime tests.\u00a0\nSee the build log at https://ci-builds.apache.org/blue/organizations/jenkins/OpenNLP%2Feval-tests/detail/eval-tests/14/pipeline/.\nAdd a delta value for the tests.\nThe reason for the delta need is that the predicted floating point values seem to between different computers.",
        "Issue Links": []
    },
    "OPENNLP-1482": {
        "Key": "OPENNLP-1482",
        "Summary": "Document the OpenNLP eval test data",
        "Type": "Task",
        "Status": "Resolved",
        "Priority": "Major",
        "Resolution": "Fixed",
        "Affects Version/s": "None",
        "Fix Version/s": "None",
        "Component/s": "Documentation",
        "Assignee": "Atita Arora",
        "Reporter": "Jeff Zemerick",
        "Created": "15/Mar/23 14:55",
        "Updated": "25/Apr/23 08:01",
        "Resolved": "25/Apr/23 08:01",
        "Description": "Document the OpenNLP eval test data. Include things like what it is, where it is, how to use it, how to change it, etc.\nhttps://nightlies.apache.org/opennlp/opennlp-data.zip\nHow to change files on nightlies: https://nightlies.apache.org/authoring.html",
        "Issue Links": []
    },
    "OPENNLP-1483": {
        "Key": "OPENNLP-1483",
        "Summary": "Apply Java language migration aids",
        "Type": "Improvement",
        "Status": "Closed",
        "Priority": "Minor",
        "Resolution": "Fixed",
        "Affects Version/s": "2.1.1",
        "Fix Version/s": "2.2.0",
        "Component/s": "None",
        "Assignee": "Martin Wiesner",
        "Reporter": "Martin Wiesner",
        "Created": "24/Mar/23 22:47",
        "Updated": "22/Apr/23 17:39",
        "Resolved": "25/Mar/23 20:01",
        "Description": "Several Java language migration steps can be applied across the code in opennlp-tools.\nAims:\n\nModernize existing code and tests by transforming patterns of older style.\nAdjust JavaDoc where necessary where helpful.",
        "Issue Links": []
    },
    "OPENNLP-1484": {
        "Key": "OPENNLP-1484",
        "Summary": "GitHub Actions: Don't run deploy snapshots, if we have a release version",
        "Type": "Improvement",
        "Status": "Closed",
        "Priority": "Major",
        "Resolution": "Fixed",
        "Affects Version/s": "2.1.1",
        "Fix Version/s": "None",
        "Component/s": "None",
        "Assignee": "Richard Zowalla",
        "Reporter": "Richard Zowalla",
        "Created": "11/Apr/23 09:29",
        "Updated": "11/Apr/23 18:22",
        "Resolved": "11/Apr/23 18:22",
        "Description": "https://github.com/apache/opennlp/actions/runs/4656825636/jobs/8240823768",
        "Issue Links": []
    },
    "OPENNLP-1485": {
        "Key": "OPENNLP-1485",
        "Summary": "OpenNLP DOAP file has a parsing error",
        "Type": "Bug",
        "Status": "Open",
        "Priority": "Minor",
        "Resolution": "Unresolved",
        "Affects Version/s": "2.1.1",
        "Fix Version/s": "None",
        "Component/s": "Documentation",
        "Assignee": null,
        "Reporter": "Claude Warren",
        "Created": "20/Apr/23 07:34",
        "Updated": "20/Apr/23 07:34",
        "Resolved": null,
        "Description": "The DOAP file [1] as listed in [2] has the error:\n[line: 49, col: 22] {E201} Multiple children of property element\n[1] http://opennlp.apache.org/doap_opennlp.rdf\n[2] https://svn.apache.org/repos/asf/comdev/projects.apache.org/trunk/data/projects.xml",
        "Issue Links": []
    },
    "OPENNLP-1486": {
        "Key": "OPENNLP-1486",
        "Summary": "Switch to BufferedWriter in various sandbox components",
        "Type": "Improvement",
        "Status": "Closed",
        "Priority": "Minor",
        "Resolution": "Fixed",
        "Affects Version/s": "2.0.0,                                            2.1.1",
        "Fix Version/s": "2.2.1",
        "Component/s": "Coref",
        "Assignee": "Martin Wiesner",
        "Reporter": "Martin Wiesner",
        "Created": "21/Apr/23 07:31",
        "Updated": "28/Apr/23 18:57",
        "Resolved": "28/Apr/23 18:57",
        "Description": "As reported in PR #29, several classes don't used buffered IO when writing data/files to disk. This should be improved. The original PR became incompatible over time and the original contributor did not show activity for a longer time. Therefore, this issue shall catch his idea and improve the state from the current state of the sandbox code base.\nPR #29 addressed the following components:\n\nmodelbuilder-addon\nopennlp-coref\n\nThe above list is potentially not complete and can or should be extended.",
        "Issue Links": []
    },
    "OPENNLP-1487": {
        "Key": "OPENNLP-1487",
        "Summary": "Update dependency log4j2 to version 2.20.0",
        "Type": "Improvement",
        "Status": "Closed",
        "Priority": "Minor",
        "Resolution": "Fixed",
        "Affects Version/s": "2.1.1,                                            2.2.0",
        "Fix Version/s": "2.2.1",
        "Component/s": "None",
        "Assignee": "Martin Wiesner",
        "Reporter": "Martin Wiesner",
        "Created": "22/Apr/23 10:29",
        "Updated": "28/Apr/23 18:59",
        "Resolved": "28/Apr/23 18:59",
        "Description": "OpenNLP 2.1.1 references an outdated version of the log4j2 (2.19.0). The most recent version 2.20.0 resolves several bugs and brings enhancements - details see:\nhttps://logging.apache.org/log4j/2.x/release-notes/2.20.0.html\nAim:\n\nModernize log4j2 to latest version 2.20.0",
        "Issue Links": []
    },
    "OPENNLP-1488": {
        "Key": "OPENNLP-1488",
        "Summary": "Update build dependency forbiddenapis to version 3.5.1",
        "Type": "Improvement",
        "Status": "Closed",
        "Priority": "Minor",
        "Resolution": "Fixed",
        "Affects Version/s": "2.1.1,                                            2.2.0",
        "Fix Version/s": "2.2.1",
        "Component/s": "None",
        "Assignee": "Martin Wiesner",
        "Reporter": "Martin Wiesner",
        "Created": "22/Apr/23 10:33",
        "Updated": "28/Apr/23 18:59",
        "Resolved": "28/Apr/23 18:59",
        "Description": "OpenNLP references an outdated version of the\u00a0forbidden-apis maven plugin, that is version 3.4. The most version 3.5.1 resolves several bugs and improves support for newer JDK versions - details see:\nhttps://github.com/policeman-tools/forbidden-apis/wiki/Changes\nAim:\n\nModernize forbidden-apis to latest version 3.5.1\nAdd support for Java 20 and Java 21 bytecode compatibility",
        "Issue Links": []
    },
    "OPENNLP-1489": {
        "Key": "OPENNLP-1489",
        "Summary": "Update dependency morfologik to version 2.1.9",
        "Type": "Improvement",
        "Status": "Closed",
        "Priority": "Minor",
        "Resolution": "Fixed",
        "Affects Version/s": "2.1.1,                                            2.2.0",
        "Fix Version/s": "2.2.1",
        "Component/s": "None",
        "Assignee": "Martin Wiesner",
        "Reporter": "Martin Wiesner",
        "Created": "22/Apr/23 10:46",
        "Updated": "28/Apr/23 19:00",
        "Resolved": "28/Apr/23 19:00",
        "Description": "OpenNLP references an outdated version of the morfologik (2.1.7). The most recent version 2.1.9 brings enhancements - details see:\nhttps://github.com/morfologik/morfologik-stemming/blob/master/CHANGES.txt\nAim:\n\nModernize morfologik to latest version 2.1.9",
        "Issue Links": []
    },
    "OPENNLP-1490": {
        "Key": "OPENNLP-1490",
        "Summary": "Update build dependency enforcer plugin to version 3.3.0",
        "Type": "Improvement",
        "Status": "Closed",
        "Priority": "Minor",
        "Resolution": "Fixed",
        "Affects Version/s": "2.1.1,                                            2.2.0",
        "Fix Version/s": "2.2.1",
        "Component/s": "Build, Packaging and Test",
        "Assignee": "Martin Wiesner",
        "Reporter": "Martin Wiesner",
        "Created": "22/Apr/23 10:55",
        "Updated": "28/Apr/23 19:00",
        "Resolved": "28/Apr/23 19:00",
        "Description": "OpenNLP references an outdated version of the enforcer maven plugin, that is version 3.0.0-M3. The most version 3.3.0 resolves several bugs and brings many improvements - details see:\nhttps://github.com/apache/maven-enforcer/releases\nAim:\n\nModernize the enforcer plugin to latest version 3.3.0",
        "Issue Links": []
    },
    "OPENNLP-1491": {
        "Key": "OPENNLP-1491",
        "Summary": "Update build dependency javadoc plugin to version 3.5.0",
        "Type": "Improvement",
        "Status": "Closed",
        "Priority": "Minor",
        "Resolution": "Fixed",
        "Affects Version/s": "2.1.1,                                            2.2.0",
        "Fix Version/s": "2.2.1",
        "Component/s": "None",
        "Assignee": "Martin Wiesner",
        "Reporter": "Martin Wiesner",
        "Created": "22/Apr/23 11:09",
        "Updated": "28/Apr/23 19:01",
        "Resolved": "28/Apr/23 19:01",
        "Description": "OpenNLP references an outdated version of the javadoc maven plugin, that is version 3.1.1. The most version 3.5.0 resolves several bugs and brings many improvements - details see:\nhttps://github.com/apache/maven-javadoc-plugin/releases\nAim:\n\nModernize the javadoc plugin to latest version 3.5.0",
        "Issue Links": []
    },
    "OPENNLP-1492": {
        "Key": "OPENNLP-1492",
        "Summary": "Release process updates",
        "Type": "Task",
        "Status": "Open",
        "Priority": "Minor",
        "Resolution": "Unresolved",
        "Affects Version/s": "None",
        "Fix Version/s": "None",
        "Component/s": "Documentation",
        "Assignee": null,
        "Reporter": "Jeff Zemerick",
        "Created": "27/Apr/23 11:31",
        "Updated": "27/Apr/23 11:36",
        "Resolved": null,
        "Description": "Notes for possible updates I made during the last release:\n\nAdd note to the Release Guide (https://opennlp.apache.org/release.html) to first check the eval tests build at https://builds.apache.org/job/OpenNLP/\nhttps://issues.apache.org/jira/browse/OPENNLP-1457\nUpdate staging repository link to\u00a0https://repository.apache.org/#stagingRepositories",
        "Issue Links": [
            "/jira/browse/OPENNLP-1457"
        ]
    },
    "OPENNLP-1493": {
        "Key": "OPENNLP-1493",
        "Summary": "Add tests for ModelLoader classes in cmdline sub-packages",
        "Type": "Test",
        "Status": "Closed",
        "Priority": "Minor",
        "Resolution": "Fixed",
        "Affects Version/s": "2.2.0",
        "Fix Version/s": "2.2.1",
        "Component/s": "Command Line Interface",
        "Assignee": "Martin Wiesner",
        "Reporter": "Martin Wiesner",
        "Created": "07/May/23 07:26",
        "Updated": "17/May/23 14:21",
        "Resolved": "17/May/23 14:21",
        "Description": "Atm, no test exist which verify that ModelLoader and derived classes work.\nAims:\n\nProvide corresponding tests for cmdline \"...Loader\" classes.\nIndirectly demonstrate (public) model files can be loaded.",
        "Issue Links": []
    },
    "OPENNLP-1494": {
        "Key": "OPENNLP-1494",
        "Summary": "Improve resource handling of AutoCloseable streams in several classes",
        "Type": "Improvement",
        "Status": "Closed",
        "Priority": "Trivial",
        "Resolution": "Fixed",
        "Affects Version/s": "2.2.0",
        "Fix Version/s": "2.2.1",
        "Component/s": "None",
        "Assignee": "Martin Wiesner",
        "Reporter": "Martin Wiesner",
        "Created": "19/May/23 07:07",
        "Updated": "22/May/23 06:29",
        "Resolved": "22/May/23 06:29",
        "Description": "As the title says.\nAim:\n\nMake use of try-with-resources to ensure close() method is called in case of exceptions during processing of a streamed resource.",
        "Issue Links": []
    },
    "OPENNLP-1495": {
        "Key": "OPENNLP-1495",
        "Summary": "Reduce code duplication in opennlp.tools.ml package",
        "Type": "Improvement",
        "Status": "Closed",
        "Priority": "Minor",
        "Resolution": "Fixed",
        "Affects Version/s": "2.2.0",
        "Fix Version/s": "2.2.1",
        "Component/s": "Build, Packaging and Test,                                            Machine Learning",
        "Assignee": "Martin Wiesner",
        "Reporter": "Martin Wiesner",
        "Created": "19/May/23 17:25",
        "Updated": "22/May/23 06:29",
        "Resolved": "22/May/23 06:29",
        "Description": "Several classes in the opennlp.tools.ml package which inherit from AbstractModelWriter suffer from code duplication, e.g. PerceptronModelWriter, GISModelWriter, and NaiveBayesModelWriter\nAims:\n\nCode duplication should & can be cleared from that part of the code base.\nMoreover, some of the the related tests classes can be (a) simplified, (b) improved for reduced execution time and (c) better readability.",
        "Issue Links": []
    },
    "OPENNLP-1496": {
        "Key": "OPENNLP-1496",
        "Summary": "Migrate OpenNLP towards JDK 17",
        "Type": "Task",
        "Status": "Closed",
        "Priority": "Major",
        "Resolution": "Fixed",
        "Affects Version/s": "2.2.0",
        "Fix Version/s": "2.2.1",
        "Component/s": "None",
        "Assignee": "Martin Wiesner",
        "Reporter": "Martin Wiesner",
        "Created": "24/May/23 15:42",
        "Updated": "10/Jun/23 18:34",
        "Resolved": "10/Jun/23 18:34",
        "Description": "Time progresses and Java 11 LTS is set to be EOL with 30 Sep 2023 (see: https://endoflife.date/java). This date will hit pretty soon1.\nWith that in mind, the project should consider to migrate the build towards the next LTS release, Java 17. This will be supported until at least 30 Sep 2026.\nAims:\n\nKeep pace with the Java ecosystem,\nModernizes the code base with new(er) language features,\nBenefit from nice performance enhancements and fixes provided with 17.x LTS.\n\n\u2013\n1 Keep in mind the summer is coming and many other tasks are on our lists",
        "Issue Links": []
    },
    "OPENNLP-1497": {
        "Key": "OPENNLP-1497",
        "Summary": "Remove unnecessary test dependency commons-io",
        "Type": "Improvement",
        "Status": "Closed",
        "Priority": "Minor",
        "Resolution": "Fixed",
        "Affects Version/s": "2.2.0",
        "Fix Version/s": "2.2.1",
        "Component/s": "Build, Packaging and Test",
        "Assignee": "Martin Wiesner",
        "Reporter": "Martin Wiesner",
        "Created": "08/Jun/23 20:30",
        "Updated": "12/Jun/23 05:34",
        "Resolved": "12/Jun/23 05:34",
        "Description": "At the moment, opennlp-tools depends on commons-io as a test dependency. However,\u00a0 classes from commons-io are used in merely three cases to conduct file related operations. Those can easily be realized via Java's built-in classes.\nFor this reason, the dependency can be kicked out as from opennlp-tools pom.xml\u00a0as there is no real necessity any more.",
        "Issue Links": []
    },
    "OPENNLP-1498": {
        "Key": "OPENNLP-1498",
        "Summary": "Update dependency onnx-runtime to version 1.15.0",
        "Type": "Dependency upgrade",
        "Status": "Closed",
        "Priority": "Minor",
        "Resolution": "Fixed",
        "Affects Version/s": "2.2.0",
        "Fix Version/s": "2.2.1",
        "Component/s": "Deep Learning",
        "Assignee": "Martin Wiesner",
        "Reporter": "Martin Wiesner",
        "Created": "08/Jun/23 21:06",
        "Updated": "12/Jun/23 05:31",
        "Resolved": "12/Jun/23 05:31",
        "Description": "As the title says. ONNX release notes see: https://github.com/microsoft/onnxruntime/releases/tag/v1.15.0",
        "Issue Links": []
    },
    "OPENNLP-1499": {
        "Key": "OPENNLP-1499",
        "Summary": "Update dependency jersey to version 2.39.1",
        "Type": "Dependency upgrade",
        "Status": "Closed",
        "Priority": "Minor",
        "Resolution": "Fixed",
        "Affects Version/s": "2.2.0",
        "Fix Version/s": "2.2.1",
        "Component/s": "None",
        "Assignee": "Martin Wiesner",
        "Reporter": "Martin Wiesner",
        "Created": "08/Jun/23 21:21",
        "Updated": "12/Jun/23 05:32",
        "Resolved": "12/Jun/23 05:32",
        "Description": "As the title says, release note(s) see: https://github.com/eclipse-ee4j/jersey/releases",
        "Issue Links": []
    },
    "OPENNLP-1500": {
        "Key": "OPENNLP-1500",
        "Summary": "Update dependency uimaj-core to version 3.4.1",
        "Type": "Dependency upgrade",
        "Status": "Closed",
        "Priority": "Minor",
        "Resolution": "Fixed",
        "Affects Version/s": "2.2.0",
        "Fix Version/s": "2.2.1",
        "Component/s": "UIMA Integration",
        "Assignee": "Martin Wiesner",
        "Reporter": "Martin Wiesner",
        "Created": "08/Jun/23 21:31",
        "Updated": "12/Jun/23 05:33",
        "Resolved": "12/Jun/23 05:33",
        "Description": "As the title says, release notes see:\n\nhttps://uima.apache.org/news.html#uimaj-3.4.1\nhttps://uima.apache.org/news.html#02%20Feb%202023",
        "Issue Links": []
    }
}